
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.0.3 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="http://doubleml.org"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>     to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.603179</td>
      <td>0.345424</td>
      <td>0.202174</td>
      <td>0.813673</td>
      <td>-0.731511</td>
      <td>0.176744</td>
      <td>-0.948723</td>
      <td>-0.702634</td>
      <td>0.090248</td>
      <td>-0.593315</td>
      <td>-0.977233</td>
      <td>0.892751</td>
      <td>1.343368</td>
      <td>-0.200990</td>
      <td>0.246546</td>
      <td>-0.617592</td>
      <td>-0.052978</td>
      <td>-0.368791</td>
      <td>0.185624</td>
      <td>0.571996</td>
      <td>-1.572533</td>
      <td>-1.428472</td>
      <td>-0.786928</td>
      <td>0.841478</td>
      <td>1.478742</td>
      <td>-0.476195</td>
      <td>-0.456771</td>
      <td>-0.291681</td>
      <td>-0.286429</td>
      <td>1.657002</td>
      <td>1.014249</td>
      <td>1.259237</td>
      <td>0.372325</td>
      <td>0.103423</td>
      <td>0.912535</td>
      <td>0.101129</td>
      <td>0.007043</td>
      <td>0.247580</td>
      <td>1.207219</td>
      <td>0.545047</td>
      <td>...</td>
      <td>-0.286409</td>
      <td>0.448917</td>
      <td>-0.164763</td>
      <td>-1.398370</td>
      <td>-0.369840</td>
      <td>-0.433790</td>
      <td>-0.174341</td>
      <td>0.384376</td>
      <td>0.372462</td>
      <td>-1.199695</td>
      <td>0.076970</td>
      <td>-0.124317</td>
      <td>0.905766</td>
      <td>0.392349</td>
      <td>-0.261669</td>
      <td>0.184889</td>
      <td>-0.626047</td>
      <td>-0.245075</td>
      <td>0.291271</td>
      <td>0.840481</td>
      <td>0.781236</td>
      <td>-0.812493</td>
      <td>-0.841878</td>
      <td>-0.057978</td>
      <td>-1.240023</td>
      <td>-0.424364</td>
      <td>-0.605102</td>
      <td>0.198909</td>
      <td>1.159834</td>
      <td>0.150964</td>
      <td>-0.867253</td>
      <td>0.210755</td>
      <td>0.230712</td>
      <td>0.489800</td>
      <td>-0.264209</td>
      <td>-0.921135</td>
      <td>-0.695551</td>
      <td>1.324461</td>
      <td>1.259904</td>
      <td>0.476670</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.003745</td>
      <td>-0.087851</td>
      <td>-0.455873</td>
      <td>-0.781241</td>
      <td>-0.329740</td>
      <td>0.216557</td>
      <td>1.119376</td>
      <td>0.210812</td>
      <td>-0.414629</td>
      <td>-0.074964</td>
      <td>-0.673330</td>
      <td>1.166780</td>
      <td>1.385477</td>
      <td>0.196580</td>
      <td>0.185998</td>
      <td>-0.651796</td>
      <td>0.737652</td>
      <td>0.107697</td>
      <td>-0.076096</td>
      <td>-0.150837</td>
      <td>-1.353551</td>
      <td>-1.404022</td>
      <td>-0.365437</td>
      <td>-0.166760</td>
      <td>0.748085</td>
      <td>0.401847</td>
      <td>1.373144</td>
      <td>1.095584</td>
      <td>-0.646750</td>
      <td>-1.524334</td>
      <td>-1.647646</td>
      <td>0.287417</td>
      <td>1.020522</td>
      <td>1.344155</td>
      <td>0.717933</td>
      <td>-0.248793</td>
      <td>0.913534</td>
      <td>-0.121746</td>
      <td>-0.698275</td>
      <td>-0.112004</td>
      <td>...</td>
      <td>0.411514</td>
      <td>-0.481352</td>
      <td>0.514681</td>
      <td>1.287138</td>
      <td>0.811194</td>
      <td>-0.060918</td>
      <td>-0.136434</td>
      <td>0.137693</td>
      <td>1.123933</td>
      <td>0.315692</td>
      <td>0.004979</td>
      <td>-0.688900</td>
      <td>-0.839664</td>
      <td>-0.026947</td>
      <td>0.030747</td>
      <td>0.359083</td>
      <td>0.027505</td>
      <td>-0.186045</td>
      <td>-0.070751</td>
      <td>-0.094387</td>
      <td>-0.246572</td>
      <td>-0.268345</td>
      <td>-0.384744</td>
      <td>-0.113563</td>
      <td>0.282483</td>
      <td>0.053374</td>
      <td>-0.209792</td>
      <td>-0.133243</td>
      <td>-0.323202</td>
      <td>0.369905</td>
      <td>-1.093626</td>
      <td>-0.098299</td>
      <td>-0.209783</td>
      <td>0.244600</td>
      <td>0.318637</td>
      <td>-1.531867</td>
      <td>-0.102946</td>
      <td>-1.000224</td>
      <td>-0.446889</td>
      <td>0.145639</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.600264</td>
      <td>-0.360189</td>
      <td>-0.719627</td>
      <td>0.802393</td>
      <td>0.463186</td>
      <td>1.339938</td>
      <td>0.827898</td>
      <td>0.793439</td>
      <td>-0.179853</td>
      <td>-0.806861</td>
      <td>0.147167</td>
      <td>-0.461940</td>
      <td>0.798810</td>
      <td>0.903659</td>
      <td>0.077751</td>
      <td>0.375444</td>
      <td>-1.747897</td>
      <td>-0.804921</td>
      <td>0.186645</td>
      <td>0.640728</td>
      <td>0.905101</td>
      <td>0.242051</td>
      <td>0.640083</td>
      <td>0.205894</td>
      <td>1.447279</td>
      <td>-0.079452</td>
      <td>1.047344</td>
      <td>0.736230</td>
      <td>-0.316150</td>
      <td>-0.673060</td>
      <td>-0.397820</td>
      <td>0.471373</td>
      <td>0.266447</td>
      <td>-0.469101</td>
      <td>-0.409210</td>
      <td>-0.918651</td>
      <td>0.293577</td>
      <td>0.409282</td>
      <td>0.258684</td>
      <td>-0.249463</td>
      <td>...</td>
      <td>-0.651992</td>
      <td>-0.094204</td>
      <td>-1.413039</td>
      <td>-0.078678</td>
      <td>0.035088</td>
      <td>-1.396643</td>
      <td>-0.231145</td>
      <td>-0.973632</td>
      <td>-0.323141</td>
      <td>-0.692000</td>
      <td>-0.666451</td>
      <td>-0.559022</td>
      <td>0.739847</td>
      <td>0.049219</td>
      <td>1.326098</td>
      <td>0.460642</td>
      <td>0.670282</td>
      <td>-0.550803</td>
      <td>-0.316747</td>
      <td>-1.161029</td>
      <td>-0.980866</td>
      <td>-1.428228</td>
      <td>-0.069261</td>
      <td>0.119424</td>
      <td>-1.484272</td>
      <td>0.178126</td>
      <td>0.494895</td>
      <td>0.498722</td>
      <td>0.159694</td>
      <td>-1.655109</td>
      <td>-0.771252</td>
      <td>-0.520578</td>
      <td>0.907301</td>
      <td>0.291254</td>
      <td>0.646310</td>
      <td>-0.334720</td>
      <td>-0.773771</td>
      <td>-1.794559</td>
      <td>-0.901158</td>
      <td>-0.047109</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.249352</td>
      <td>-0.548236</td>
      <td>-0.365441</td>
      <td>-0.438035</td>
      <td>-0.172908</td>
      <td>-0.531302</td>
      <td>-0.134719</td>
      <td>-1.481296</td>
      <td>-1.512477</td>
      <td>-1.188101</td>
      <td>0.112610</td>
      <td>0.033074</td>
      <td>-0.351066</td>
      <td>-0.682688</td>
      <td>0.285489</td>
      <td>-0.125824</td>
      <td>0.511440</td>
      <td>-0.283734</td>
      <td>-1.552747</td>
      <td>-0.769086</td>
      <td>-0.340758</td>
      <td>-1.300916</td>
      <td>0.163827</td>
      <td>0.363768</td>
      <td>0.460881</td>
      <td>-0.139300</td>
      <td>0.219418</td>
      <td>0.521426</td>
      <td>-0.375142</td>
      <td>0.606846</td>
      <td>1.442102</td>
      <td>0.206872</td>
      <td>1.651577</td>
      <td>1.195220</td>
      <td>0.396455</td>
      <td>-0.979141</td>
      <td>0.371412</td>
      <td>-0.192659</td>
      <td>-0.719182</td>
      <td>-1.069711</td>
      <td>...</td>
      <td>0.543476</td>
      <td>-0.410792</td>
      <td>0.049672</td>
      <td>-0.419956</td>
      <td>-0.344733</td>
      <td>0.505467</td>
      <td>0.315591</td>
      <td>0.458667</td>
      <td>0.634062</td>
      <td>-0.499380</td>
      <td>-0.290878</td>
      <td>-1.129380</td>
      <td>-0.895923</td>
      <td>-0.878061</td>
      <td>-0.993334</td>
      <td>-0.307005</td>
      <td>-0.640479</td>
      <td>-0.847249</td>
      <td>-0.100123</td>
      <td>-0.351091</td>
      <td>0.200252</td>
      <td>-0.473390</td>
      <td>-0.397107</td>
      <td>-0.056770</td>
      <td>-1.099990</td>
      <td>0.047037</td>
      <td>0.363466</td>
      <td>0.432844</td>
      <td>-0.925643</td>
      <td>-0.918180</td>
      <td>-1.071594</td>
      <td>0.281655</td>
      <td>-0.282752</td>
      <td>-1.337985</td>
      <td>0.368867</td>
      <td>-0.307551</td>
      <td>-0.159299</td>
      <td>-2.342259</td>
      <td>-0.642174</td>
      <td>-0.283547</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.494201</td>
      <td>-0.335479</td>
      <td>-0.306526</td>
      <td>0.349251</td>
      <td>-0.226900</td>
      <td>-0.007373</td>
      <td>0.575607</td>
      <td>0.457106</td>
      <td>0.112682</td>
      <td>-0.206641</td>
      <td>-0.704866</td>
      <td>1.253972</td>
      <td>0.080489</td>
      <td>-0.300072</td>
      <td>0.031946</td>
      <td>-0.015467</td>
      <td>0.244153</td>
      <td>0.615639</td>
      <td>0.592569</td>
      <td>0.703681</td>
      <td>0.602946</td>
      <td>-0.056199</td>
      <td>-0.540432</td>
      <td>0.395951</td>
      <td>-0.067181</td>
      <td>-0.818482</td>
      <td>-0.138666</td>
      <td>-0.326761</td>
      <td>-0.208750</td>
      <td>0.253754</td>
      <td>-0.193126</td>
      <td>-0.006646</td>
      <td>0.765761</td>
      <td>1.074865</td>
      <td>-0.413297</td>
      <td>-0.543530</td>
      <td>-0.291981</td>
      <td>0.024752</td>
      <td>-1.121088</td>
      <td>-0.437688</td>
      <td>...</td>
      <td>-0.072553</td>
      <td>0.087901</td>
      <td>-0.588465</td>
      <td>-0.040825</td>
      <td>0.214274</td>
      <td>0.457243</td>
      <td>0.085332</td>
      <td>-0.168100</td>
      <td>-0.337454</td>
      <td>-1.091914</td>
      <td>-0.129565</td>
      <td>-0.766363</td>
      <td>-0.528367</td>
      <td>0.313537</td>
      <td>0.211317</td>
      <td>0.861415</td>
      <td>0.644608</td>
      <td>1.150543</td>
      <td>0.280026</td>
      <td>-0.286824</td>
      <td>0.262107</td>
      <td>-0.287492</td>
      <td>-0.803105</td>
      <td>0.476903</td>
      <td>0.360691</td>
      <td>0.066048</td>
      <td>0.132697</td>
      <td>0.438021</td>
      <td>0.072222</td>
      <td>0.420160</td>
      <td>0.001605</td>
      <td>0.253822</td>
      <td>0.046523</td>
      <td>1.052065</td>
      <td>-0.448607</td>
      <td>0.038362</td>
      <td>0.399037</td>
      <td>1.045486</td>
      <td>1.335296</td>
      <td>0.830502</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1.050242</td>
      <td>-0.584848</td>
      <td>-0.575030</td>
      <td>-0.609539</td>
      <td>0.410801</td>
      <td>0.830058</td>
      <td>0.939635</td>
      <td>-0.385537</td>
      <td>-0.364969</td>
      <td>0.124013</td>
      <td>-0.553937</td>
      <td>0.611122</td>
      <td>1.471517</td>
      <td>0.598337</td>
      <td>0.299759</td>
      <td>0.225902</td>
      <td>0.272911</td>
      <td>-0.673084</td>
      <td>-0.374469</td>
      <td>-0.511241</td>
      <td>0.152514</td>
      <td>0.311113</td>
      <td>0.867056</td>
      <td>0.780999</td>
      <td>0.406654</td>
      <td>0.004981</td>
      <td>0.574094</td>
      <td>-0.336967</td>
      <td>0.048879</td>
      <td>0.855388</td>
      <td>1.166664</td>
      <td>0.195485</td>
      <td>0.673504</td>
      <td>-0.281681</td>
      <td>0.557364</td>
      <td>-0.230572</td>
      <td>0.390116</td>
      <td>0.498801</td>
      <td>0.985408</td>
      <td>1.190954</td>
      <td>...</td>
      <td>-0.840067</td>
      <td>-1.201251</td>
      <td>-1.219450</td>
      <td>0.256647</td>
      <td>0.333183</td>
      <td>-0.610313</td>
      <td>0.397152</td>
      <td>-0.889153</td>
      <td>-0.065976</td>
      <td>-0.670144</td>
      <td>0.105858</td>
      <td>-0.497877</td>
      <td>-0.077776</td>
      <td>-0.244963</td>
      <td>1.284880</td>
      <td>0.717745</td>
      <td>-0.742991</td>
      <td>0.179509</td>
      <td>-0.213607</td>
      <td>-0.292095</td>
      <td>0.836567</td>
      <td>-0.013928</td>
      <td>0.330510</td>
      <td>0.130375</td>
      <td>0.109778</td>
      <td>-0.011822</td>
      <td>-0.196849</td>
      <td>0.090163</td>
      <td>-0.888993</td>
      <td>-0.575602</td>
      <td>-1.074181</td>
      <td>0.177790</td>
      <td>0.037105</td>
      <td>-1.042324</td>
      <td>-0.470757</td>
      <td>-0.521624</td>
      <td>-0.589808</td>
      <td>0.240073</td>
      <td>0.463822</td>
      <td>0.218630</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.464674</td>
      <td>-0.722681</td>
      <td>-0.806677</td>
      <td>-0.161486</td>
      <td>-0.177886</td>
      <td>1.120864</td>
      <td>0.925713</td>
      <td>-0.200545</td>
      <td>-1.234411</td>
      <td>-1.467255</td>
      <td>-1.552450</td>
      <td>0.327937</td>
      <td>0.411154</td>
      <td>0.259280</td>
      <td>0.667373</td>
      <td>0.958347</td>
      <td>-0.608413</td>
      <td>-0.737234</td>
      <td>-0.372984</td>
      <td>-0.513510</td>
      <td>-0.713878</td>
      <td>-0.452830</td>
      <td>0.239449</td>
      <td>0.058965</td>
      <td>0.361420</td>
      <td>-0.102984</td>
      <td>-0.471074</td>
      <td>0.902713</td>
      <td>0.728887</td>
      <td>0.544322</td>
      <td>0.325206</td>
      <td>1.900157</td>
      <td>1.792625</td>
      <td>0.458144</td>
      <td>1.269320</td>
      <td>-0.364116</td>
      <td>-0.551729</td>
      <td>-0.249896</td>
      <td>-0.639338</td>
      <td>-0.027798</td>
      <td>...</td>
      <td>0.389086</td>
      <td>0.648529</td>
      <td>-0.292186</td>
      <td>0.160308</td>
      <td>-0.114927</td>
      <td>0.323804</td>
      <td>0.662314</td>
      <td>0.103131</td>
      <td>0.958520</td>
      <td>-0.027836</td>
      <td>0.471963</td>
      <td>0.320668</td>
      <td>0.548351</td>
      <td>1.369456</td>
      <td>0.437111</td>
      <td>0.189561</td>
      <td>-0.282694</td>
      <td>-0.634425</td>
      <td>0.523469</td>
      <td>0.732887</td>
      <td>0.963543</td>
      <td>-0.073086</td>
      <td>0.381290</td>
      <td>0.433400</td>
      <td>-0.565865</td>
      <td>0.342648</td>
      <td>0.730164</td>
      <td>0.589557</td>
      <td>-1.064099</td>
      <td>1.137363</td>
      <td>-0.790602</td>
      <td>-0.899546</td>
      <td>-0.047674</td>
      <td>-0.404483</td>
      <td>-0.395999</td>
      <td>0.208744</td>
      <td>0.667647</td>
      <td>-1.684102</td>
      <td>-0.882855</td>
      <td>-0.188655</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.046483</td>
      <td>0.246456</td>
      <td>-0.721910</td>
      <td>-1.098610</td>
      <td>0.074489</td>
      <td>-0.104567</td>
      <td>0.474617</td>
      <td>-0.474981</td>
      <td>0.270195</td>
      <td>-0.721191</td>
      <td>-0.246807</td>
      <td>-0.005290</td>
      <td>0.577158</td>
      <td>-0.260380</td>
      <td>0.570698</td>
      <td>-0.390401</td>
      <td>0.255764</td>
      <td>-0.129580</td>
      <td>-0.398205</td>
      <td>0.649755</td>
      <td>-0.706914</td>
      <td>-0.915337</td>
      <td>0.147288</td>
      <td>0.486609</td>
      <td>-0.131513</td>
      <td>0.332044</td>
      <td>-0.615641</td>
      <td>0.033961</td>
      <td>0.633243</td>
      <td>0.813500</td>
      <td>0.702147</td>
      <td>0.191006</td>
      <td>0.233083</td>
      <td>0.813880</td>
      <td>1.315352</td>
      <td>0.219249</td>
      <td>0.221776</td>
      <td>-0.255041</td>
      <td>-0.644158</td>
      <td>0.005834</td>
      <td>...</td>
      <td>-0.136060</td>
      <td>0.171977</td>
      <td>-0.640148</td>
      <td>-0.009516</td>
      <td>0.523085</td>
      <td>0.220921</td>
      <td>0.530454</td>
      <td>-0.126522</td>
      <td>-0.274941</td>
      <td>-0.104931</td>
      <td>-0.431411</td>
      <td>-0.622192</td>
      <td>0.147667</td>
      <td>-0.152387</td>
      <td>-0.087819</td>
      <td>-0.009682</td>
      <td>-0.253950</td>
      <td>0.526672</td>
      <td>-0.299405</td>
      <td>0.511602</td>
      <td>0.389682</td>
      <td>-0.758613</td>
      <td>-0.059528</td>
      <td>0.070868</td>
      <td>-0.621099</td>
      <td>0.210591</td>
      <td>0.502123</td>
      <td>0.476827</td>
      <td>-0.600633</td>
      <td>-0.154076</td>
      <td>0.237854</td>
      <td>-0.428853</td>
      <td>-0.187499</td>
      <td>0.351508</td>
      <td>-0.322691</td>
      <td>-0.125722</td>
      <td>-0.089547</td>
      <td>-1.336268</td>
      <td>-0.571331</td>
      <td>0.121969</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.081806</td>
      <td>-1.383299</td>
      <td>-0.712706</td>
      <td>0.218857</td>
      <td>-0.717200</td>
      <td>-0.372671</td>
      <td>0.307533</td>
      <td>-1.744850</td>
      <td>-0.474427</td>
      <td>-0.970435</td>
      <td>-0.507200</td>
      <td>0.516152</td>
      <td>0.588622</td>
      <td>0.438909</td>
      <td>1.244962</td>
      <td>0.392586</td>
      <td>-0.076342</td>
      <td>1.462289</td>
      <td>-0.162107</td>
      <td>-0.508487</td>
      <td>-0.668668</td>
      <td>-0.281731</td>
      <td>0.668625</td>
      <td>1.407747</td>
      <td>0.777989</td>
      <td>-0.251279</td>
      <td>-1.111917</td>
      <td>-0.410165</td>
      <td>-0.426420</td>
      <td>-0.148024</td>
      <td>1.031674</td>
      <td>0.543243</td>
      <td>-0.021563</td>
      <td>0.352105</td>
      <td>0.911688</td>
      <td>-0.597411</td>
      <td>0.935152</td>
      <td>-0.319926</td>
      <td>-0.694213</td>
      <td>0.834598</td>
      <td>...</td>
      <td>0.028677</td>
      <td>0.250569</td>
      <td>-0.130751</td>
      <td>-0.183793</td>
      <td>-0.503520</td>
      <td>-0.834494</td>
      <td>0.541527</td>
      <td>0.108187</td>
      <td>0.483724</td>
      <td>-0.089633</td>
      <td>-0.172215</td>
      <td>-0.592023</td>
      <td>0.756202</td>
      <td>-0.051231</td>
      <td>0.601214</td>
      <td>0.942090</td>
      <td>-0.045899</td>
      <td>-0.163516</td>
      <td>-0.133609</td>
      <td>0.361885</td>
      <td>-0.048083</td>
      <td>0.032579</td>
      <td>0.699911</td>
      <td>0.963754</td>
      <td>-1.163803</td>
      <td>-1.540469</td>
      <td>-0.879766</td>
      <td>-0.021196</td>
      <td>0.161114</td>
      <td>-0.509610</td>
      <td>-0.814188</td>
      <td>0.134322</td>
      <td>0.984687</td>
      <td>0.030001</td>
      <td>1.168202</td>
      <td>-0.575932</td>
      <td>-0.024594</td>
      <td>-0.470730</td>
      <td>0.199463</td>
      <td>0.040318</td>
    </tr>
    <tr>
      <th>9</th>
      <td>1.089650</td>
      <td>0.003932</td>
      <td>0.345650</td>
      <td>0.123048</td>
      <td>-0.470195</td>
      <td>0.681338</td>
      <td>0.767226</td>
      <td>0.351516</td>
      <td>0.066472</td>
      <td>-0.958813</td>
      <td>-0.493585</td>
      <td>0.506939</td>
      <td>1.656680</td>
      <td>-0.296147</td>
      <td>0.335794</td>
      <td>0.256771</td>
      <td>-0.211994</td>
      <td>-0.674042</td>
      <td>-1.162987</td>
      <td>-1.427684</td>
      <td>0.029389</td>
      <td>-0.661480</td>
      <td>0.378135</td>
      <td>0.461728</td>
      <td>0.853325</td>
      <td>-0.139427</td>
      <td>1.284645</td>
      <td>0.898313</td>
      <td>0.779920</td>
      <td>0.037546</td>
      <td>0.856895</td>
      <td>0.633321</td>
      <td>-0.133674</td>
      <td>0.123478</td>
      <td>0.490221</td>
      <td>0.825865</td>
      <td>-0.008967</td>
      <td>0.576731</td>
      <td>0.093456</td>
      <td>-0.145311</td>
      <td>...</td>
      <td>0.125704</td>
      <td>-1.198854</td>
      <td>-2.041133</td>
      <td>-1.002768</td>
      <td>-0.126593</td>
      <td>0.059090</td>
      <td>0.129476</td>
      <td>0.436044</td>
      <td>1.427202</td>
      <td>0.737025</td>
      <td>0.165723</td>
      <td>-0.550201</td>
      <td>-0.963269</td>
      <td>-0.381563</td>
      <td>-0.127697</td>
      <td>0.679827</td>
      <td>-0.449356</td>
      <td>0.458484</td>
      <td>-0.234981</td>
      <td>0.426444</td>
      <td>-0.292917</td>
      <td>0.363643</td>
      <td>0.205009</td>
      <td>-0.052127</td>
      <td>-0.218277</td>
      <td>-0.122651</td>
      <td>0.355281</td>
      <td>0.102419</td>
      <td>-0.161223</td>
      <td>-0.390862</td>
      <td>0.394334</td>
      <td>0.747545</td>
      <td>0.107427</td>
      <td>0.584127</td>
      <td>0.618939</td>
      <td>0.108195</td>
      <td>0.641437</td>
      <td>1.178537</td>
      <td>1.056967</td>
      <td>0.720472</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-0.016383</td>
      <td>-0.413140</td>
      <td>-0.287366</td>
      <td>0.021558</td>
      <td>-0.018782</td>
      <td>0.677806</td>
      <td>0.890602</td>
      <td>-0.223874</td>
      <td>-0.279570</td>
      <td>-1.097200</td>
      <td>-0.496463</td>
      <td>0.686262</td>
      <td>-0.084196</td>
      <td>0.531599</td>
      <td>0.278678</td>
      <td>-0.330553</td>
      <td>0.328827</td>
      <td>0.939542</td>
      <td>-0.279863</td>
      <td>-0.837773</td>
      <td>-0.607587</td>
      <td>-1.085174</td>
      <td>-0.002062</td>
      <td>0.457263</td>
      <td>-0.013662</td>
      <td>-0.455014</td>
      <td>0.509499</td>
      <td>0.191294</td>
      <td>0.029901</td>
      <td>0.725317</td>
      <td>1.045432</td>
      <td>0.794845</td>
      <td>1.057181</td>
      <td>-0.249285</td>
      <td>0.853385</td>
      <td>-0.132497</td>
      <td>-1.433114</td>
      <td>-0.799107</td>
      <td>0.577181</td>
      <td>0.422194</td>
      <td>...</td>
      <td>-1.000448</td>
      <td>-0.375022</td>
      <td>0.162805</td>
      <td>0.837516</td>
      <td>0.073420</td>
      <td>-0.099825</td>
      <td>-0.413176</td>
      <td>-0.786958</td>
      <td>0.004863</td>
      <td>-0.315129</td>
      <td>0.167597</td>
      <td>0.312865</td>
      <td>1.223047</td>
      <td>0.898769</td>
      <td>-0.623554</td>
      <td>0.623121</td>
      <td>0.257847</td>
      <td>-0.180145</td>
      <td>0.129476</td>
      <td>-0.323559</td>
      <td>0.314943</td>
      <td>0.368860</td>
      <td>0.282191</td>
      <td>0.190511</td>
      <td>-0.917702</td>
      <td>-1.514871</td>
      <td>-0.736361</td>
      <td>0.620755</td>
      <td>0.529113</td>
      <td>0.546738</td>
      <td>-0.042295</td>
      <td>0.271562</td>
      <td>-0.075400</td>
      <td>0.534273</td>
      <td>-0.044243</td>
      <td>-0.469550</td>
      <td>0.059662</td>
      <td>0.085762</td>
      <td>0.426255</td>
      <td>0.280116</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.727555</td>
      <td>-1.618889</td>
      <td>-0.547913</td>
      <td>-0.714146</td>
      <td>-0.260730</td>
      <td>0.735326</td>
      <td>0.578945</td>
      <td>-0.256089</td>
      <td>-1.235680</td>
      <td>-0.880820</td>
      <td>0.041919</td>
      <td>0.469167</td>
      <td>0.562104</td>
      <td>1.139649</td>
      <td>1.134263</td>
      <td>-0.054604</td>
      <td>0.152351</td>
      <td>-0.036514</td>
      <td>-0.238089</td>
      <td>-1.686362</td>
      <td>-0.450090</td>
      <td>0.575598</td>
      <td>0.395719</td>
      <td>0.775840</td>
      <td>0.925252</td>
      <td>-0.007267</td>
      <td>-0.467259</td>
      <td>-0.285168</td>
      <td>-0.251119</td>
      <td>-0.862113</td>
      <td>0.101184</td>
      <td>-0.263411</td>
      <td>-0.074338</td>
      <td>0.063535</td>
      <td>1.288316</td>
      <td>-0.298003</td>
      <td>-0.329513</td>
      <td>0.115115</td>
      <td>0.874392</td>
      <td>0.636750</td>
      <td>...</td>
      <td>-0.683335</td>
      <td>-0.680031</td>
      <td>-0.172852</td>
      <td>0.833871</td>
      <td>0.364091</td>
      <td>-0.353587</td>
      <td>-0.074056</td>
      <td>-0.569896</td>
      <td>-0.596340</td>
      <td>0.089346</td>
      <td>-0.079455</td>
      <td>-0.302630</td>
      <td>1.202876</td>
      <td>1.582927</td>
      <td>1.498123</td>
      <td>1.783890</td>
      <td>-0.455739</td>
      <td>-0.127730</td>
      <td>0.013501</td>
      <td>0.752904</td>
      <td>1.263891</td>
      <td>0.172271</td>
      <td>-0.158256</td>
      <td>0.438061</td>
      <td>-1.479083</td>
      <td>-0.170268</td>
      <td>0.065493</td>
      <td>0.227543</td>
      <td>-0.042140</td>
      <td>-1.616415</td>
      <td>-0.541239</td>
      <td>-0.163876</td>
      <td>0.492114</td>
      <td>-0.460731</td>
      <td>0.315323</td>
      <td>-0.310424</td>
      <td>-0.711111</td>
      <td>-2.856626</td>
      <td>-0.815535</td>
      <td>-0.480250</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.375039</td>
      <td>-0.772091</td>
      <td>-0.523241</td>
      <td>0.434906</td>
      <td>0.427019</td>
      <td>0.614256</td>
      <td>0.226624</td>
      <td>-0.229295</td>
      <td>-0.553545</td>
      <td>-1.044557</td>
      <td>-0.801612</td>
      <td>0.586656</td>
      <td>0.479314</td>
      <td>0.137549</td>
      <td>0.739319</td>
      <td>-0.433989</td>
      <td>-0.189491</td>
      <td>0.211333</td>
      <td>-0.564581</td>
      <td>0.125966</td>
      <td>-0.425152</td>
      <td>-0.929529</td>
      <td>-0.639532</td>
      <td>0.624156</td>
      <td>-0.259224</td>
      <td>-0.833201</td>
      <td>0.625219</td>
      <td>0.173939</td>
      <td>-0.956016</td>
      <td>0.290461</td>
      <td>-0.634433</td>
      <td>-0.772918</td>
      <td>0.798911</td>
      <td>0.726052</td>
      <td>-0.719553</td>
      <td>-0.118743</td>
      <td>1.007322</td>
      <td>0.509532</td>
      <td>0.166434</td>
      <td>-0.114827</td>
      <td>...</td>
      <td>0.086986</td>
      <td>-0.164075</td>
      <td>-0.875763</td>
      <td>-0.040993</td>
      <td>0.541016</td>
      <td>-0.045931</td>
      <td>-0.774120</td>
      <td>-0.521465</td>
      <td>0.002952</td>
      <td>0.110485</td>
      <td>-0.085179</td>
      <td>0.349764</td>
      <td>0.091192</td>
      <td>-0.551868</td>
      <td>-0.117330</td>
      <td>0.511773</td>
      <td>0.533344</td>
      <td>0.811682</td>
      <td>-0.294998</td>
      <td>-0.697845</td>
      <td>0.000408</td>
      <td>-0.931169</td>
      <td>-1.100896</td>
      <td>-0.133044</td>
      <td>-0.126297</td>
      <td>-0.138911</td>
      <td>-0.868823</td>
      <td>-0.265379</td>
      <td>-1.121262</td>
      <td>-1.329033</td>
      <td>-1.258106</td>
      <td>-0.314079</td>
      <td>-0.495153</td>
      <td>0.122757</td>
      <td>0.233652</td>
      <td>-0.274438</td>
      <td>-0.383370</td>
      <td>-1.729385</td>
      <td>-1.114026</td>
      <td>0.119210</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-1.244536</td>
      <td>0.129159</td>
      <td>0.072028</td>
      <td>0.255389</td>
      <td>1.042653</td>
      <td>0.455243</td>
      <td>-0.081408</td>
      <td>-0.162052</td>
      <td>-0.720567</td>
      <td>-0.630383</td>
      <td>0.206455</td>
      <td>0.463970</td>
      <td>0.685577</td>
      <td>0.086878</td>
      <td>-0.296610</td>
      <td>-1.154723</td>
      <td>-0.167082</td>
      <td>-0.489571</td>
      <td>0.791303</td>
      <td>0.827117</td>
      <td>-0.371768</td>
      <td>0.129268</td>
      <td>0.849827</td>
      <td>0.777722</td>
      <td>0.475648</td>
      <td>-1.225186</td>
      <td>-0.397104</td>
      <td>-0.161277</td>
      <td>1.096253</td>
      <td>-0.686347</td>
      <td>-0.157384</td>
      <td>-0.029333</td>
      <td>0.385222</td>
      <td>-0.645360</td>
      <td>0.417692</td>
      <td>0.443386</td>
      <td>-0.006034</td>
      <td>-0.237691</td>
      <td>-0.035242</td>
      <td>1.709718</td>
      <td>...</td>
      <td>0.808387</td>
      <td>0.426766</td>
      <td>-0.802031</td>
      <td>-0.324613</td>
      <td>-0.615789</td>
      <td>0.349306</td>
      <td>-0.890119</td>
      <td>-0.512241</td>
      <td>-0.260877</td>
      <td>-0.799997</td>
      <td>-0.896040</td>
      <td>-0.895819</td>
      <td>0.115402</td>
      <td>0.483218</td>
      <td>-0.384056</td>
      <td>0.360944</td>
      <td>-1.086341</td>
      <td>-0.364231</td>
      <td>-0.205920</td>
      <td>0.201930</td>
      <td>-1.006249</td>
      <td>-0.099028</td>
      <td>-0.926114</td>
      <td>-0.927632</td>
      <td>-1.102936</td>
      <td>-0.980941</td>
      <td>-1.384788</td>
      <td>-0.209878</td>
      <td>0.144900</td>
      <td>-0.863878</td>
      <td>-0.349757</td>
      <td>-0.542187</td>
      <td>0.812082</td>
      <td>0.878580</td>
      <td>1.046449</td>
      <td>-0.728383</td>
      <td>-0.546279</td>
      <td>-1.631590</td>
      <td>-2.350456</td>
      <td>-1.796805</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.127445</td>
      <td>-0.705089</td>
      <td>-0.364874</td>
      <td>-0.048894</td>
      <td>0.528262</td>
      <td>0.734769</td>
      <td>0.181836</td>
      <td>-0.135659</td>
      <td>-0.362559</td>
      <td>-0.881680</td>
      <td>-0.956757</td>
      <td>0.052201</td>
      <td>-0.036818</td>
      <td>-0.344880</td>
      <td>1.219340</td>
      <td>0.932122</td>
      <td>0.069339</td>
      <td>0.053857</td>
      <td>-0.470135</td>
      <td>-0.658482</td>
      <td>-0.085082</td>
      <td>0.358067</td>
      <td>-0.018756</td>
      <td>0.307153</td>
      <td>0.321563</td>
      <td>0.092252</td>
      <td>0.198823</td>
      <td>0.926512</td>
      <td>0.249210</td>
      <td>-0.657855</td>
      <td>0.487294</td>
      <td>-0.508500</td>
      <td>0.027480</td>
      <td>0.287969</td>
      <td>0.226177</td>
      <td>-0.106779</td>
      <td>0.342078</td>
      <td>0.215052</td>
      <td>-0.758336</td>
      <td>-0.240734</td>
      <td>...</td>
      <td>0.920150</td>
      <td>-0.241166</td>
      <td>-0.579878</td>
      <td>-0.785078</td>
      <td>-1.102005</td>
      <td>-0.224165</td>
      <td>1.396922</td>
      <td>-0.518561</td>
      <td>-0.609442</td>
      <td>-0.539617</td>
      <td>0.214192</td>
      <td>-0.053790</td>
      <td>1.061549</td>
      <td>-0.268459</td>
      <td>0.071371</td>
      <td>-0.931570</td>
      <td>-0.568571</td>
      <td>-0.387740</td>
      <td>0.114037</td>
      <td>-0.298019</td>
      <td>-0.352533</td>
      <td>-0.240157</td>
      <td>-0.497703</td>
      <td>-0.222472</td>
      <td>0.715251</td>
      <td>0.614802</td>
      <td>-0.656725</td>
      <td>0.748791</td>
      <td>0.552928</td>
      <td>-0.080016</td>
      <td>-0.215640</td>
      <td>-0.036455</td>
      <td>0.470287</td>
      <td>0.730451</td>
      <td>0.403794</td>
      <td>-1.652671</td>
      <td>-0.195321</td>
      <td>-3.076159</td>
      <td>-2.157283</td>
      <td>-1.242990</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.114706</td>
      <td>-0.198944</td>
      <td>-0.186690</td>
      <td>-0.581451</td>
      <td>-0.657633</td>
      <td>-0.139009</td>
      <td>0.097851</td>
      <td>0.044582</td>
      <td>-0.351395</td>
      <td>-0.797485</td>
      <td>-0.895469</td>
      <td>0.241032</td>
      <td>0.313384</td>
      <td>-0.350573</td>
      <td>0.707800</td>
      <td>-0.084215</td>
      <td>-0.287053</td>
      <td>0.331770</td>
      <td>-0.530957</td>
      <td>0.893098</td>
      <td>-0.153442</td>
      <td>0.023359</td>
      <td>0.004054</td>
      <td>0.563159</td>
      <td>-0.307088</td>
      <td>-0.057654</td>
      <td>1.172432</td>
      <td>0.805623</td>
      <td>0.988403</td>
      <td>0.976820</td>
      <td>0.557134</td>
      <td>0.124182</td>
      <td>0.339634</td>
      <td>-0.258199</td>
      <td>1.182449</td>
      <td>0.228848</td>
      <td>-0.095870</td>
      <td>-0.391636</td>
      <td>0.289460</td>
      <td>-0.458274</td>
      <td>...</td>
      <td>0.855004</td>
      <td>-0.140145</td>
      <td>0.465170</td>
      <td>-0.581988</td>
      <td>-0.464113</td>
      <td>-0.048317</td>
      <td>0.191157</td>
      <td>0.424479</td>
      <td>-0.345356</td>
      <td>-0.227587</td>
      <td>-0.719806</td>
      <td>-0.865237</td>
      <td>0.354372</td>
      <td>-0.680887</td>
      <td>-0.290408</td>
      <td>0.159487</td>
      <td>-0.098848</td>
      <td>0.206650</td>
      <td>-1.126145</td>
      <td>0.515842</td>
      <td>0.416226</td>
      <td>-0.175310</td>
      <td>-0.349854</td>
      <td>0.013458</td>
      <td>-1.188536</td>
      <td>-0.794428</td>
      <td>-0.133987</td>
      <td>-0.461053</td>
      <td>-0.313155</td>
      <td>0.401245</td>
      <td>-1.071583</td>
      <td>0.917155</td>
      <td>0.260292</td>
      <td>-0.290692</td>
      <td>0.165882</td>
      <td>-0.215506</td>
      <td>1.307315</td>
      <td>-1.602994</td>
      <td>-1.346917</td>
      <td>-1.080867</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.062607</td>
      <td>-1.192300</td>
      <td>-1.056379</td>
      <td>0.022888</td>
      <td>0.706106</td>
      <td>0.478993</td>
      <td>0.872912</td>
      <td>0.837025</td>
      <td>-0.787082</td>
      <td>-0.704995</td>
      <td>-0.245393</td>
      <td>-0.059892</td>
      <td>1.064146</td>
      <td>0.355144</td>
      <td>1.096594</td>
      <td>-0.445920</td>
      <td>-0.229104</td>
      <td>-0.063596</td>
      <td>-0.632036</td>
      <td>0.653142</td>
      <td>-0.061211</td>
      <td>0.279873</td>
      <td>0.882767</td>
      <td>0.218449</td>
      <td>-0.319792</td>
      <td>0.704801</td>
      <td>0.418982</td>
      <td>-0.505275</td>
      <td>-0.523177</td>
      <td>0.044671</td>
      <td>-0.932638</td>
      <td>-0.600301</td>
      <td>-0.176659</td>
      <td>-0.363703</td>
      <td>0.060065</td>
      <td>-0.105715</td>
      <td>0.379775</td>
      <td>-0.621378</td>
      <td>-0.667152</td>
      <td>-0.710508</td>
      <td>...</td>
      <td>0.445824</td>
      <td>0.412686</td>
      <td>-1.525964</td>
      <td>0.117856</td>
      <td>-0.247274</td>
      <td>-0.315228</td>
      <td>0.463364</td>
      <td>-0.488953</td>
      <td>-0.486015</td>
      <td>-0.764714</td>
      <td>0.200890</td>
      <td>0.121686</td>
      <td>0.859154</td>
      <td>0.298910</td>
      <td>0.841658</td>
      <td>0.191929</td>
      <td>-0.546770</td>
      <td>-0.947083</td>
      <td>-0.011363</td>
      <td>0.096893</td>
      <td>-0.046180</td>
      <td>-0.572944</td>
      <td>-0.369867</td>
      <td>-0.018510</td>
      <td>-0.919648</td>
      <td>1.023209</td>
      <td>0.185016</td>
      <td>0.904275</td>
      <td>0.923206</td>
      <td>0.378269</td>
      <td>-0.336708</td>
      <td>-0.227396</td>
      <td>0.364668</td>
      <td>-0.415581</td>
      <td>-0.528801</td>
      <td>-0.422675</td>
      <td>0.076819</td>
      <td>-2.629768</td>
      <td>-1.481915</td>
      <td>-0.895969</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.190021</td>
      <td>-1.279466</td>
      <td>-0.343637</td>
      <td>0.200760</td>
      <td>-0.224603</td>
      <td>0.976323</td>
      <td>0.077748</td>
      <td>-0.689647</td>
      <td>-0.662546</td>
      <td>-1.449654</td>
      <td>-0.700028</td>
      <td>0.334003</td>
      <td>1.332871</td>
      <td>0.173944</td>
      <td>-0.269814</td>
      <td>-1.239212</td>
      <td>0.410808</td>
      <td>0.230943</td>
      <td>-0.342327</td>
      <td>0.194629</td>
      <td>0.520093</td>
      <td>-0.232098</td>
      <td>-0.164188</td>
      <td>0.078273</td>
      <td>-0.813943</td>
      <td>-0.657961</td>
      <td>-0.130361</td>
      <td>0.809844</td>
      <td>0.197052</td>
      <td>-0.017394</td>
      <td>-0.213357</td>
      <td>0.099057</td>
      <td>0.055207</td>
      <td>0.393075</td>
      <td>-0.580753</td>
      <td>-0.799945</td>
      <td>0.317470</td>
      <td>0.565661</td>
      <td>0.893511</td>
      <td>1.145273</td>
      <td>...</td>
      <td>-0.266010</td>
      <td>0.292282</td>
      <td>-1.413209</td>
      <td>-0.939102</td>
      <td>0.537739</td>
      <td>-0.044224</td>
      <td>1.028572</td>
      <td>0.000560</td>
      <td>0.091790</td>
      <td>-0.431957</td>
      <td>-0.031320</td>
      <td>0.189640</td>
      <td>-0.642045</td>
      <td>0.142914</td>
      <td>0.250100</td>
      <td>-0.234646</td>
      <td>-0.223206</td>
      <td>-0.181642</td>
      <td>0.379795</td>
      <td>0.308027</td>
      <td>0.678065</td>
      <td>-0.800701</td>
      <td>-0.161165</td>
      <td>-0.186139</td>
      <td>0.418410</td>
      <td>-0.480367</td>
      <td>0.386873</td>
      <td>-0.077184</td>
      <td>-0.175295</td>
      <td>-0.381453</td>
      <td>-0.253134</td>
      <td>0.773048</td>
      <td>0.683789</td>
      <td>0.598544</td>
      <td>-0.513862</td>
      <td>-0.242499</td>
      <td>-0.348364</td>
      <td>-4.098281</td>
      <td>-2.379417</td>
      <td>-1.123914</td>
    </tr>
    <tr>
      <th>18</th>
      <td>1.248089</td>
      <td>0.168574</td>
      <td>0.571412</td>
      <td>0.228872</td>
      <td>-0.479340</td>
      <td>0.893950</td>
      <td>1.185699</td>
      <td>-0.190406</td>
      <td>-1.007927</td>
      <td>-1.344570</td>
      <td>-0.131337</td>
      <td>1.105592</td>
      <td>-0.538353</td>
      <td>-0.829021</td>
      <td>-0.473492</td>
      <td>-0.073219</td>
      <td>0.372241</td>
      <td>0.071965</td>
      <td>0.268155</td>
      <td>0.619713</td>
      <td>-0.834280</td>
      <td>-0.115773</td>
      <td>0.601626</td>
      <td>-0.084974</td>
      <td>0.153025</td>
      <td>-0.164379</td>
      <td>0.548743</td>
      <td>0.246377</td>
      <td>0.269015</td>
      <td>0.539588</td>
      <td>0.352948</td>
      <td>-0.626694</td>
      <td>0.185767</td>
      <td>-0.145968</td>
      <td>1.138216</td>
      <td>0.306766</td>
      <td>0.427826</td>
      <td>0.877092</td>
      <td>-0.303302</td>
      <td>-0.473076</td>
      <td>...</td>
      <td>0.058344</td>
      <td>-0.095925</td>
      <td>-0.075257</td>
      <td>0.256633</td>
      <td>0.380316</td>
      <td>-0.560910</td>
      <td>0.080101</td>
      <td>0.192866</td>
      <td>0.682217</td>
      <td>0.393556</td>
      <td>-0.665369</td>
      <td>0.060134</td>
      <td>0.260986</td>
      <td>-0.340236</td>
      <td>-0.230625</td>
      <td>0.582402</td>
      <td>0.230664</td>
      <td>-1.300724</td>
      <td>-1.629712</td>
      <td>-0.197194</td>
      <td>-0.161249</td>
      <td>-0.497804</td>
      <td>-0.168865</td>
      <td>-0.491729</td>
      <td>0.394054</td>
      <td>0.185271</td>
      <td>0.216376</td>
      <td>-0.052759</td>
      <td>0.104411</td>
      <td>-0.161992</td>
      <td>-0.185981</td>
      <td>0.657692</td>
      <td>0.214044</td>
      <td>-0.330167</td>
      <td>0.883602</td>
      <td>-0.215000</td>
      <td>-0.854962</td>
      <td>0.185333</td>
      <td>0.909678</td>
      <td>0.380722</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.455072</td>
      <td>0.399925</td>
      <td>-0.686136</td>
      <td>-0.317957</td>
      <td>-0.367037</td>
      <td>1.086304</td>
      <td>-0.396079</td>
      <td>-0.953094</td>
      <td>-0.564022</td>
      <td>-1.094428</td>
      <td>0.345987</td>
      <td>-0.154330</td>
      <td>0.616130</td>
      <td>-0.750848</td>
      <td>0.714723</td>
      <td>0.979513</td>
      <td>0.110905</td>
      <td>-0.657042</td>
      <td>-0.298881</td>
      <td>-0.231362</td>
      <td>0.276324</td>
      <td>0.053830</td>
      <td>1.187949</td>
      <td>0.225076</td>
      <td>0.606061</td>
      <td>-0.973680</td>
      <td>0.565203</td>
      <td>0.809180</td>
      <td>-0.156470</td>
      <td>0.207344</td>
      <td>0.341382</td>
      <td>0.004891</td>
      <td>1.031121</td>
      <td>0.017016</td>
      <td>0.603946</td>
      <td>0.056860</td>
      <td>0.293636</td>
      <td>-0.165696</td>
      <td>-0.477606</td>
      <td>0.336815</td>
      <td>...</td>
      <td>0.187350</td>
      <td>0.096768</td>
      <td>-0.441777</td>
      <td>-0.600653</td>
      <td>-0.499802</td>
      <td>-0.780752</td>
      <td>-0.763666</td>
      <td>-0.820331</td>
      <td>-0.551850</td>
      <td>-0.735052</td>
      <td>0.088211</td>
      <td>-1.187075</td>
      <td>0.957875</td>
      <td>0.826769</td>
      <td>0.030468</td>
      <td>0.675686</td>
      <td>0.313032</td>
      <td>-0.942941</td>
      <td>-0.297592</td>
      <td>1.104518</td>
      <td>1.124386</td>
      <td>-0.001449</td>
      <td>0.185734</td>
      <td>0.239248</td>
      <td>-0.176710</td>
      <td>0.360149</td>
      <td>-0.656742</td>
      <td>0.596594</td>
      <td>-0.086774</td>
      <td>0.382336</td>
      <td>-0.696021</td>
      <td>-0.096393</td>
      <td>-0.853614</td>
      <td>-1.102171</td>
      <td>0.347223</td>
      <td>-1.152725</td>
      <td>-0.139301</td>
      <td>-0.808995</td>
      <td>0.182547</td>
      <td>0.229903</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-1.437769</td>
      <td>-0.853144</td>
      <td>0.262299</td>
      <td>0.146776</td>
      <td>-0.091298</td>
      <td>-0.156459</td>
      <td>0.060450</td>
      <td>0.435736</td>
      <td>-0.370085</td>
      <td>-0.288820</td>
      <td>0.198134</td>
      <td>0.059765</td>
      <td>-0.434025</td>
      <td>0.339761</td>
      <td>1.056452</td>
      <td>1.562878</td>
      <td>1.277902</td>
      <td>0.009397</td>
      <td>0.396002</td>
      <td>-0.300168</td>
      <td>-0.103686</td>
      <td>0.020888</td>
      <td>0.529353</td>
      <td>0.478025</td>
      <td>0.046815</td>
      <td>-0.650966</td>
      <td>0.667907</td>
      <td>1.046192</td>
      <td>0.859654</td>
      <td>0.292319</td>
      <td>-0.432159</td>
      <td>-0.247890</td>
      <td>-0.790215</td>
      <td>0.809744</td>
      <td>0.952825</td>
      <td>0.102418</td>
      <td>0.295474</td>
      <td>0.156597</td>
      <td>0.014782</td>
      <td>0.496230</td>
      <td>...</td>
      <td>-0.266630</td>
      <td>1.090978</td>
      <td>-0.049770</td>
      <td>0.186889</td>
      <td>-0.300182</td>
      <td>-0.175537</td>
      <td>-0.741942</td>
      <td>-0.032427</td>
      <td>0.248515</td>
      <td>-0.737000</td>
      <td>0.507574</td>
      <td>-1.164505</td>
      <td>0.226848</td>
      <td>0.466082</td>
      <td>0.971870</td>
      <td>-0.269888</td>
      <td>0.545435</td>
      <td>0.128531</td>
      <td>0.278304</td>
      <td>0.663442</td>
      <td>0.288578</td>
      <td>-0.402159</td>
      <td>-0.745531</td>
      <td>-0.514162</td>
      <td>-0.250710</td>
      <td>-0.600093</td>
      <td>-0.118102</td>
      <td>-0.541130</td>
      <td>-0.299872</td>
      <td>0.346604</td>
      <td>0.604108</td>
      <td>0.018655</td>
      <td>-0.711300</td>
      <td>0.511087</td>
      <td>0.154077</td>
      <td>-0.214188</td>
      <td>0.231997</td>
      <td>-4.096824</td>
      <td>-2.466708</td>
      <td>-0.856036</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.512913</td>
      <td>-1.067152</td>
      <td>-0.116787</td>
      <td>0.282099</td>
      <td>-0.621490</td>
      <td>0.693818</td>
      <td>0.883799</td>
      <td>0.138604</td>
      <td>0.224627</td>
      <td>-0.539056</td>
      <td>-1.408166</td>
      <td>-0.732541</td>
      <td>-0.394544</td>
      <td>0.030934</td>
      <td>0.567561</td>
      <td>0.077917</td>
      <td>-0.233766</td>
      <td>-0.233984</td>
      <td>-0.037821</td>
      <td>-0.878701</td>
      <td>-0.410731</td>
      <td>-0.235183</td>
      <td>0.990548</td>
      <td>0.723806</td>
      <td>0.152584</td>
      <td>-1.219135</td>
      <td>-0.127384</td>
      <td>-0.494257</td>
      <td>-0.402986</td>
      <td>0.469140</td>
      <td>-0.127927</td>
      <td>-0.427392</td>
      <td>-0.067804</td>
      <td>0.791433</td>
      <td>0.672921</td>
      <td>-0.020824</td>
      <td>0.540621</td>
      <td>-1.141187</td>
      <td>0.175408</td>
      <td>0.278676</td>
      <td>...</td>
      <td>0.014717</td>
      <td>-0.236054</td>
      <td>-0.579811</td>
      <td>-1.035617</td>
      <td>-0.629156</td>
      <td>-0.881735</td>
      <td>-0.115710</td>
      <td>-0.501197</td>
      <td>0.717037</td>
      <td>-0.510634</td>
      <td>-0.403629</td>
      <td>-0.249451</td>
      <td>0.900470</td>
      <td>0.549591</td>
      <td>0.762730</td>
      <td>-0.442742</td>
      <td>-0.375042</td>
      <td>-0.862893</td>
      <td>0.400681</td>
      <td>-0.179014</td>
      <td>-0.148490</td>
      <td>0.584780</td>
      <td>0.502655</td>
      <td>-1.173626</td>
      <td>-0.795569</td>
      <td>0.173052</td>
      <td>-0.326992</td>
      <td>-0.495767</td>
      <td>-1.015115</td>
      <td>-0.130841</td>
      <td>-0.995096</td>
      <td>-0.479325</td>
      <td>0.346318</td>
      <td>-0.172089</td>
      <td>0.293482</td>
      <td>-1.397569</td>
      <td>-0.876781</td>
      <td>0.692560</td>
      <td>1.773589</td>
      <td>0.766861</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.659548</td>
      <td>-0.618883</td>
      <td>0.066826</td>
      <td>0.868478</td>
      <td>0.298422</td>
      <td>0.571746</td>
      <td>-0.348978</td>
      <td>-0.644784</td>
      <td>-0.503060</td>
      <td>-0.531440</td>
      <td>0.602376</td>
      <td>0.403711</td>
      <td>1.804010</td>
      <td>-0.310318</td>
      <td>0.592724</td>
      <td>-0.874474</td>
      <td>-1.836849</td>
      <td>-0.296962</td>
      <td>-0.975888</td>
      <td>0.017534</td>
      <td>-0.177541</td>
      <td>-0.835665</td>
      <td>-0.066526</td>
      <td>-0.256030</td>
      <td>1.681438</td>
      <td>-0.198300</td>
      <td>2.007367</td>
      <td>0.623923</td>
      <td>0.443381</td>
      <td>1.024826</td>
      <td>0.696741</td>
      <td>0.392520</td>
      <td>1.111513</td>
      <td>-0.485359</td>
      <td>0.119449</td>
      <td>0.402658</td>
      <td>1.317962</td>
      <td>-0.190269</td>
      <td>0.045199</td>
      <td>-0.561314</td>
      <td>...</td>
      <td>-0.007125</td>
      <td>0.268955</td>
      <td>0.175515</td>
      <td>-0.725542</td>
      <td>-0.272555</td>
      <td>0.010218</td>
      <td>0.830772</td>
      <td>0.671019</td>
      <td>0.150536</td>
      <td>-0.315455</td>
      <td>-0.055791</td>
      <td>-0.361397</td>
      <td>-0.003978</td>
      <td>-0.981733</td>
      <td>0.146305</td>
      <td>0.989483</td>
      <td>0.524241</td>
      <td>0.092194</td>
      <td>0.147607</td>
      <td>0.987550</td>
      <td>0.270788</td>
      <td>-0.486960</td>
      <td>0.390629</td>
      <td>-0.044716</td>
      <td>-0.641556</td>
      <td>1.229598</td>
      <td>-0.022292</td>
      <td>1.076921</td>
      <td>-0.166034</td>
      <td>-0.597200</td>
      <td>-0.416090</td>
      <td>-0.697139</td>
      <td>-0.838085</td>
      <td>-1.294119</td>
      <td>-0.285142</td>
      <td>-0.620233</td>
      <td>0.289196</td>
      <td>1.123625</td>
      <td>1.701734</td>
      <td>1.952833</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.839685</td>
      <td>0.365927</td>
      <td>0.217915</td>
      <td>-0.007011</td>
      <td>-0.868288</td>
      <td>0.556240</td>
      <td>0.379286</td>
      <td>-0.456223</td>
      <td>-0.503996</td>
      <td>-1.082529</td>
      <td>-0.564091</td>
      <td>-0.467159</td>
      <td>0.288660</td>
      <td>-0.219344</td>
      <td>0.179133</td>
      <td>-1.270978</td>
      <td>0.647123</td>
      <td>-0.041596</td>
      <td>0.244245</td>
      <td>-0.255684</td>
      <td>0.736302</td>
      <td>0.362841</td>
      <td>1.125286</td>
      <td>0.811537</td>
      <td>-0.203654</td>
      <td>-0.511538</td>
      <td>0.807528</td>
      <td>1.015278</td>
      <td>-0.379820</td>
      <td>0.221507</td>
      <td>-0.046761</td>
      <td>-0.339099</td>
      <td>-0.143283</td>
      <td>-0.513143</td>
      <td>1.085400</td>
      <td>-0.462510</td>
      <td>-0.479598</td>
      <td>-0.389265</td>
      <td>-0.180289</td>
      <td>0.165263</td>
      <td>...</td>
      <td>0.560139</td>
      <td>0.848824</td>
      <td>-0.749847</td>
      <td>-0.615700</td>
      <td>-0.766333</td>
      <td>-0.456864</td>
      <td>0.335374</td>
      <td>-0.455486</td>
      <td>0.362106</td>
      <td>0.050352</td>
      <td>0.194145</td>
      <td>-0.291463</td>
      <td>0.354206</td>
      <td>-0.385493</td>
      <td>0.833889</td>
      <td>0.263069</td>
      <td>-0.249327</td>
      <td>-1.044142</td>
      <td>-0.254007</td>
      <td>0.466687</td>
      <td>-0.857832</td>
      <td>-0.438780</td>
      <td>-0.183797</td>
      <td>-0.115081</td>
      <td>0.232641</td>
      <td>-0.055466</td>
      <td>-0.015922</td>
      <td>0.537175</td>
      <td>-0.422477</td>
      <td>0.051666</td>
      <td>-0.671490</td>
      <td>-0.435385</td>
      <td>2.121887</td>
      <td>-0.369531</td>
      <td>-0.490262</td>
      <td>-0.656825</td>
      <td>-0.400727</td>
      <td>1.894984</td>
      <td>1.458346</td>
      <td>0.934876</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-0.133527</td>
      <td>0.487239</td>
      <td>-0.220690</td>
      <td>0.116175</td>
      <td>-0.151245</td>
      <td>0.658078</td>
      <td>0.624762</td>
      <td>-0.080007</td>
      <td>-0.282590</td>
      <td>-1.550264</td>
      <td>-0.734905</td>
      <td>0.226525</td>
      <td>0.592831</td>
      <td>1.091186</td>
      <td>0.104974</td>
      <td>0.150348</td>
      <td>1.044339</td>
      <td>-0.100281</td>
      <td>-0.185542</td>
      <td>1.052616</td>
      <td>-0.249235</td>
      <td>0.007856</td>
      <td>0.208749</td>
      <td>-0.179185</td>
      <td>0.497158</td>
      <td>-0.460181</td>
      <td>1.305584</td>
      <td>0.364116</td>
      <td>0.040700</td>
      <td>0.781406</td>
      <td>-0.075826</td>
      <td>-0.439068</td>
      <td>0.438818</td>
      <td>-0.151664</td>
      <td>-0.092997</td>
      <td>-1.990484</td>
      <td>-0.929056</td>
      <td>0.250618</td>
      <td>0.248163</td>
      <td>0.249697</td>
      <td>...</td>
      <td>-0.013747</td>
      <td>0.659470</td>
      <td>0.070352</td>
      <td>0.734602</td>
      <td>-0.870915</td>
      <td>-0.583119</td>
      <td>-0.241413</td>
      <td>0.144300</td>
      <td>0.449945</td>
      <td>-0.128149</td>
      <td>-0.446913</td>
      <td>-0.107200</td>
      <td>0.741775</td>
      <td>-0.106708</td>
      <td>-0.144632</td>
      <td>-0.264083</td>
      <td>0.291933</td>
      <td>0.435445</td>
      <td>0.710465</td>
      <td>0.581907</td>
      <td>0.494367</td>
      <td>-0.623760</td>
      <td>-0.507570</td>
      <td>-0.589955</td>
      <td>-0.917393</td>
      <td>-0.163215</td>
      <td>-0.651473</td>
      <td>-0.056904</td>
      <td>-0.394544</td>
      <td>-0.468103</td>
      <td>-1.096594</td>
      <td>-0.627971</td>
      <td>0.138980</td>
      <td>0.039537</td>
      <td>-0.085451</td>
      <td>-0.479107</td>
      <td>0.150110</td>
      <td>-0.400947</td>
      <td>0.294554</td>
      <td>0.841833</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>0.833293</td>
      <td>1.261947</td>
      <td>-0.403092</td>
      <td>0.051696</td>
      <td>0.665500</td>
      <td>-0.493938</td>
      <td>-0.067909</td>
      <td>0.211793</td>
      <td>0.194723</td>
      <td>-0.044013</td>
      <td>-0.048035</td>
      <td>0.719507</td>
      <td>0.502666</td>
      <td>-0.958024</td>
      <td>-0.620743</td>
      <td>-0.455833</td>
      <td>-0.086640</td>
      <td>0.738344</td>
      <td>0.465970</td>
      <td>-0.655571</td>
      <td>-0.848576</td>
      <td>-0.304881</td>
      <td>0.287942</td>
      <td>1.293064</td>
      <td>0.220876</td>
      <td>0.879695</td>
      <td>0.083454</td>
      <td>0.349475</td>
      <td>0.486700</td>
      <td>1.306370</td>
      <td>0.571855</td>
      <td>0.525603</td>
      <td>0.140553</td>
      <td>-0.200343</td>
      <td>-0.353104</td>
      <td>0.718966</td>
      <td>-0.203633</td>
      <td>0.632935</td>
      <td>-0.199349</td>
      <td>-0.063933</td>
      <td>...</td>
      <td>0.166197</td>
      <td>-0.416584</td>
      <td>-0.806248</td>
      <td>-0.498586</td>
      <td>-0.527397</td>
      <td>-0.052050</td>
      <td>0.653604</td>
      <td>-0.049253</td>
      <td>0.806634</td>
      <td>0.019270</td>
      <td>0.017990</td>
      <td>-0.408826</td>
      <td>-0.556662</td>
      <td>-0.461301</td>
      <td>-0.316006</td>
      <td>-1.141519</td>
      <td>-0.625623</td>
      <td>-0.444839</td>
      <td>-0.319674</td>
      <td>0.004969</td>
      <td>-0.488798</td>
      <td>-0.380426</td>
      <td>0.031780</td>
      <td>0.581384</td>
      <td>0.686750</td>
      <td>0.031277</td>
      <td>-0.842805</td>
      <td>0.027619</td>
      <td>-0.403247</td>
      <td>0.091624</td>
      <td>-0.177949</td>
      <td>-0.458766</td>
      <td>-0.298100</td>
      <td>1.065415</td>
      <td>-0.084853</td>
      <td>0.166935</td>
      <td>-0.094993</td>
      <td>2.523711</td>
      <td>1.474172</td>
      <td>0.826684</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.010408</td>
      <td>0.273664</td>
      <td>-0.464312</td>
      <td>-0.584670</td>
      <td>-0.183712</td>
      <td>0.229845</td>
      <td>-0.007557</td>
      <td>-0.267995</td>
      <td>0.624382</td>
      <td>0.337794</td>
      <td>-0.623474</td>
      <td>-0.291064</td>
      <td>1.069421</td>
      <td>0.178794</td>
      <td>-0.334044</td>
      <td>-1.073936</td>
      <td>-0.964018</td>
      <td>-0.005705</td>
      <td>1.044216</td>
      <td>-0.030195</td>
      <td>-0.433761</td>
      <td>-0.114855</td>
      <td>0.730882</td>
      <td>-0.037219</td>
      <td>0.523481</td>
      <td>0.542684</td>
      <td>-0.347732</td>
      <td>0.245480</td>
      <td>-1.294156</td>
      <td>-0.688689</td>
      <td>-0.276344</td>
      <td>-0.547629</td>
      <td>-0.315259</td>
      <td>1.375977</td>
      <td>0.314853</td>
      <td>0.689276</td>
      <td>-0.261147</td>
      <td>1.048550</td>
      <td>-0.020259</td>
      <td>-0.321418</td>
      <td>...</td>
      <td>-0.492370</td>
      <td>-0.316197</td>
      <td>-0.085283</td>
      <td>1.019496</td>
      <td>0.895179</td>
      <td>0.349492</td>
      <td>-0.885896</td>
      <td>0.283757</td>
      <td>0.307458</td>
      <td>0.281646</td>
      <td>0.038960</td>
      <td>-0.920750</td>
      <td>-0.752379</td>
      <td>-0.400793</td>
      <td>0.085588</td>
      <td>0.310824</td>
      <td>1.044721</td>
      <td>-0.587111</td>
      <td>0.546907</td>
      <td>-1.499835</td>
      <td>-0.885890</td>
      <td>-0.074747</td>
      <td>-0.576732</td>
      <td>-0.306254</td>
      <td>-0.461892</td>
      <td>1.092153</td>
      <td>-0.654709</td>
      <td>0.004745</td>
      <td>-1.076318</td>
      <td>-0.348850</td>
      <td>0.023938</td>
      <td>-0.678851</td>
      <td>-0.057034</td>
      <td>0.682147</td>
      <td>0.197406</td>
      <td>0.078475</td>
      <td>-0.840280</td>
      <td>-2.468443</td>
      <td>-1.640439</td>
      <td>-0.953850</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.741472</td>
      <td>0.376960</td>
      <td>-0.175517</td>
      <td>0.009280</td>
      <td>0.573614</td>
      <td>0.299641</td>
      <td>-0.431284</td>
      <td>0.530326</td>
      <td>0.071106</td>
      <td>-0.156542</td>
      <td>-0.263558</td>
      <td>0.030971</td>
      <td>1.249263</td>
      <td>1.156125</td>
      <td>-0.583360</td>
      <td>-0.980834</td>
      <td>-0.445826</td>
      <td>0.643306</td>
      <td>1.082780</td>
      <td>-0.507631</td>
      <td>0.283120</td>
      <td>1.118632</td>
      <td>0.468288</td>
      <td>0.117318</td>
      <td>-0.108980</td>
      <td>-0.512902</td>
      <td>1.059588</td>
      <td>-0.656398</td>
      <td>-0.039635</td>
      <td>-0.271417</td>
      <td>-0.085545</td>
      <td>-0.115751</td>
      <td>0.019739</td>
      <td>-0.169576</td>
      <td>-0.622102</td>
      <td>-0.254460</td>
      <td>-0.425536</td>
      <td>0.287652</td>
      <td>-0.696715</td>
      <td>0.202233</td>
      <td>...</td>
      <td>-0.851072</td>
      <td>-0.840401</td>
      <td>0.031898</td>
      <td>-0.061535</td>
      <td>-0.111139</td>
      <td>-0.193468</td>
      <td>-0.456265</td>
      <td>0.409098</td>
      <td>0.693697</td>
      <td>-0.142990</td>
      <td>-0.450710</td>
      <td>-0.071717</td>
      <td>-0.464964</td>
      <td>-0.935102</td>
      <td>-0.286701</td>
      <td>0.325225</td>
      <td>0.521202</td>
      <td>-0.607046</td>
      <td>0.828033</td>
      <td>-0.350800</td>
      <td>-0.083719</td>
      <td>0.288436</td>
      <td>-0.073860</td>
      <td>-0.266200</td>
      <td>-0.099127</td>
      <td>-0.103888</td>
      <td>0.020431</td>
      <td>0.001755</td>
      <td>-0.916057</td>
      <td>-0.492341</td>
      <td>-1.287792</td>
      <td>0.269965</td>
      <td>0.692427</td>
      <td>0.465439</td>
      <td>0.129811</td>
      <td>-0.060899</td>
      <td>-0.033755</td>
      <td>-0.173605</td>
      <td>-0.328089</td>
      <td>-0.377984</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.616872</td>
      <td>-0.262800</td>
      <td>-0.118967</td>
      <td>-0.026067</td>
      <td>-0.441116</td>
      <td>-0.270415</td>
      <td>-0.033367</td>
      <td>-0.904136</td>
      <td>-0.069206</td>
      <td>-0.195564</td>
      <td>-0.542015</td>
      <td>0.329081</td>
      <td>-1.483364</td>
      <td>-1.341459</td>
      <td>-0.446229</td>
      <td>-0.604054</td>
      <td>-0.356939</td>
      <td>0.184775</td>
      <td>1.191520</td>
      <td>0.359286</td>
      <td>0.129985</td>
      <td>0.294711</td>
      <td>-0.137719</td>
      <td>-0.086265</td>
      <td>0.283580</td>
      <td>0.606124</td>
      <td>-0.022896</td>
      <td>-0.674901</td>
      <td>-0.642528</td>
      <td>-0.308925</td>
      <td>0.233032</td>
      <td>-0.414010</td>
      <td>-0.147833</td>
      <td>0.851295</td>
      <td>-0.119948</td>
      <td>-0.706646</td>
      <td>-0.639085</td>
      <td>0.335894</td>
      <td>0.175238</td>
      <td>-0.363302</td>
      <td>...</td>
      <td>0.861524</td>
      <td>0.397553</td>
      <td>0.408879</td>
      <td>0.278331</td>
      <td>-0.430980</td>
      <td>0.047156</td>
      <td>0.757751</td>
      <td>0.952534</td>
      <td>0.502279</td>
      <td>-0.110385</td>
      <td>-0.742386</td>
      <td>-0.452700</td>
      <td>0.189602</td>
      <td>0.404722</td>
      <td>-0.175701</td>
      <td>-0.864684</td>
      <td>0.221429</td>
      <td>-0.157287</td>
      <td>0.170392</td>
      <td>-0.288664</td>
      <td>-0.786668</td>
      <td>-0.771367</td>
      <td>-0.348240</td>
      <td>0.174046</td>
      <td>1.048310</td>
      <td>0.499702</td>
      <td>0.118526</td>
      <td>0.079309</td>
      <td>-0.686957</td>
      <td>0.076104</td>
      <td>-0.392765</td>
      <td>-0.000120</td>
      <td>-0.227330</td>
      <td>-0.641938</td>
      <td>-1.003547</td>
      <td>-0.831826</td>
      <td>-1.599442</td>
      <td>0.108562</td>
      <td>0.376711</td>
      <td>0.502535</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.246179</td>
      <td>-0.175636</td>
      <td>0.412845</td>
      <td>-0.012211</td>
      <td>0.332153</td>
      <td>0.488542</td>
      <td>0.551407</td>
      <td>1.271432</td>
      <td>2.166472</td>
      <td>1.326637</td>
      <td>0.932333</td>
      <td>0.172002</td>
      <td>-0.093685</td>
      <td>0.763597</td>
      <td>0.552496</td>
      <td>0.210373</td>
      <td>0.964335</td>
      <td>0.286868</td>
      <td>1.150770</td>
      <td>-0.431910</td>
      <td>-0.039186</td>
      <td>0.925352</td>
      <td>0.580956</td>
      <td>1.074412</td>
      <td>-0.113336</td>
      <td>-0.774703</td>
      <td>-0.046299</td>
      <td>0.000788</td>
      <td>-0.086260</td>
      <td>0.333351</td>
      <td>-0.620990</td>
      <td>-0.684527</td>
      <td>-0.430739</td>
      <td>0.312183</td>
      <td>0.566637</td>
      <td>0.164489</td>
      <td>-0.165575</td>
      <td>-0.170810</td>
      <td>-1.251483</td>
      <td>-0.355827</td>
      <td>...</td>
      <td>-0.130487</td>
      <td>1.048470</td>
      <td>0.515153</td>
      <td>-0.366629</td>
      <td>-0.223320</td>
      <td>0.423115</td>
      <td>-0.229308</td>
      <td>-0.754734</td>
      <td>-0.159328</td>
      <td>-0.511881</td>
      <td>-1.194598</td>
      <td>0.443059</td>
      <td>-0.652981</td>
      <td>0.494361</td>
      <td>1.111835</td>
      <td>-0.277491</td>
      <td>0.458496</td>
      <td>0.583058</td>
      <td>0.471083</td>
      <td>-0.666426</td>
      <td>-0.831184</td>
      <td>0.201926</td>
      <td>0.052661</td>
      <td>0.833081</td>
      <td>0.508617</td>
      <td>0.126155</td>
      <td>-0.110796</td>
      <td>0.370644</td>
      <td>-0.191019</td>
      <td>-0.578714</td>
      <td>-0.440047</td>
      <td>-0.073764</td>
      <td>-0.617194</td>
      <td>0.681158</td>
      <td>-0.408230</td>
      <td>-0.326047</td>
      <td>-0.432655</td>
      <td>0.338124</td>
      <td>1.245348</td>
      <td>-0.147768</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7fb4d8038df0&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef  std err          t         P&gt;|t|     2.5 %    97.5 %
D  0.915285  0.04824  18.973664  2.815807e-80  0.820737  1.009834
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  6.029 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>