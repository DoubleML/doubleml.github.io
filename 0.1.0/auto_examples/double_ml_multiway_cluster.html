
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.1.0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="http://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>     to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-0.149395</td>
      <td>0.515805</td>
      <td>0.626701</td>
      <td>-0.010673</td>
      <td>-0.465987</td>
      <td>-0.964634</td>
      <td>-0.953802</td>
      <td>0.294612</td>
      <td>0.334703</td>
      <td>-0.469447</td>
      <td>0.287564</td>
      <td>-0.367647</td>
      <td>-0.320102</td>
      <td>-0.119439</td>
      <td>0.358898</td>
      <td>-0.084783</td>
      <td>0.440707</td>
      <td>-0.182108</td>
      <td>-0.116954</td>
      <td>0.999202</td>
      <td>-0.025996</td>
      <td>-1.320164</td>
      <td>-0.116722</td>
      <td>-0.817763</td>
      <td>0.357636</td>
      <td>0.319034</td>
      <td>0.535329</td>
      <td>0.950340</td>
      <td>-0.748324</td>
      <td>0.709388</td>
      <td>0.734815</td>
      <td>0.429926</td>
      <td>1.120870</td>
      <td>0.390837</td>
      <td>-0.229227</td>
      <td>-0.694411</td>
      <td>-0.821799</td>
      <td>0.189017</td>
      <td>-0.690923</td>
      <td>0.819296</td>
      <td>...</td>
      <td>0.742735</td>
      <td>-0.111654</td>
      <td>0.337611</td>
      <td>0.993171</td>
      <td>0.430246</td>
      <td>0.645361</td>
      <td>-0.078902</td>
      <td>0.885956</td>
      <td>-0.018403</td>
      <td>-0.441027</td>
      <td>0.764898</td>
      <td>0.497816</td>
      <td>1.642793</td>
      <td>0.156854</td>
      <td>-0.133348</td>
      <td>0.503977</td>
      <td>0.556203</td>
      <td>-0.353810</td>
      <td>0.157136</td>
      <td>-0.993135</td>
      <td>0.581245</td>
      <td>0.656180</td>
      <td>0.257422</td>
      <td>0.192495</td>
      <td>-0.475792</td>
      <td>0.774104</td>
      <td>0.154041</td>
      <td>0.186496</td>
      <td>0.075991</td>
      <td>-0.684481</td>
      <td>-0.577640</td>
      <td>-0.608777</td>
      <td>-0.600169</td>
      <td>0.054249</td>
      <td>0.078232</td>
      <td>-0.837318</td>
      <td>0.559685</td>
      <td>-0.872590</td>
      <td>-0.780588</td>
      <td>-0.633972</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.744390</td>
      <td>-0.627447</td>
      <td>-0.452550</td>
      <td>-0.272636</td>
      <td>0.285805</td>
      <td>-0.547151</td>
      <td>1.068665</td>
      <td>0.500209</td>
      <td>-0.080350</td>
      <td>0.235288</td>
      <td>1.149808</td>
      <td>0.916020</td>
      <td>-0.426916</td>
      <td>0.319523</td>
      <td>0.702608</td>
      <td>-0.013184</td>
      <td>-0.426102</td>
      <td>-1.570496</td>
      <td>-0.440771</td>
      <td>0.070865</td>
      <td>-0.228431</td>
      <td>-0.409097</td>
      <td>-0.468332</td>
      <td>-0.608186</td>
      <td>1.059370</td>
      <td>0.849702</td>
      <td>0.386506</td>
      <td>0.540738</td>
      <td>0.548268</td>
      <td>0.262572</td>
      <td>-0.156153</td>
      <td>-0.099254</td>
      <td>0.306592</td>
      <td>0.251081</td>
      <td>-1.223920</td>
      <td>-0.399678</td>
      <td>-0.624233</td>
      <td>-0.840031</td>
      <td>-0.886811</td>
      <td>-0.256257</td>
      <td>...</td>
      <td>0.281000</td>
      <td>-0.017422</td>
      <td>-0.428246</td>
      <td>0.964347</td>
      <td>-0.368602</td>
      <td>0.435540</td>
      <td>-0.261939</td>
      <td>-0.456300</td>
      <td>-0.868639</td>
      <td>0.741315</td>
      <td>0.115854</td>
      <td>-0.125244</td>
      <td>0.085107</td>
      <td>0.801076</td>
      <td>0.510987</td>
      <td>0.286432</td>
      <td>-0.447818</td>
      <td>-0.583387</td>
      <td>0.246488</td>
      <td>0.675301</td>
      <td>0.322836</td>
      <td>-0.180479</td>
      <td>0.519526</td>
      <td>0.043262</td>
      <td>0.038291</td>
      <td>-0.038186</td>
      <td>-0.080552</td>
      <td>0.045943</td>
      <td>0.139535</td>
      <td>-0.143988</td>
      <td>0.918744</td>
      <td>0.109555</td>
      <td>-0.102944</td>
      <td>-0.046942</td>
      <td>-0.573911</td>
      <td>0.167027</td>
      <td>-0.317322</td>
      <td>-1.952420</td>
      <td>-0.376926</td>
      <td>-0.185251</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.759766</td>
      <td>0.571533</td>
      <td>0.047506</td>
      <td>-0.781400</td>
      <td>0.182253</td>
      <td>0.843035</td>
      <td>-0.644424</td>
      <td>-1.459852</td>
      <td>-0.011501</td>
      <td>1.113964</td>
      <td>0.161595</td>
      <td>-0.532825</td>
      <td>-0.618346</td>
      <td>0.470982</td>
      <td>0.566537</td>
      <td>-0.355936</td>
      <td>-0.657923</td>
      <td>-1.046576</td>
      <td>0.832735</td>
      <td>-0.125982</td>
      <td>0.141540</td>
      <td>-1.182897</td>
      <td>-0.305857</td>
      <td>-0.230763</td>
      <td>-0.068786</td>
      <td>0.138284</td>
      <td>1.033003</td>
      <td>1.080097</td>
      <td>-0.617321</td>
      <td>-0.162579</td>
      <td>0.076705</td>
      <td>0.134020</td>
      <td>-1.008296</td>
      <td>-1.093305</td>
      <td>-0.510965</td>
      <td>-0.863511</td>
      <td>0.686560</td>
      <td>-0.228898</td>
      <td>-1.161238</td>
      <td>-0.290648</td>
      <td>...</td>
      <td>0.099643</td>
      <td>-0.716298</td>
      <td>-0.629717</td>
      <td>0.627797</td>
      <td>0.485435</td>
      <td>-0.146412</td>
      <td>0.514657</td>
      <td>0.276549</td>
      <td>-0.702749</td>
      <td>-0.826818</td>
      <td>0.848094</td>
      <td>-0.569183</td>
      <td>-0.828436</td>
      <td>0.010987</td>
      <td>-0.379469</td>
      <td>0.771928</td>
      <td>0.074071</td>
      <td>-0.183653</td>
      <td>0.034191</td>
      <td>0.334700</td>
      <td>-0.080924</td>
      <td>0.756959</td>
      <td>0.450042</td>
      <td>-0.034507</td>
      <td>-0.095169</td>
      <td>0.541818</td>
      <td>-0.200229</td>
      <td>0.168352</td>
      <td>0.256614</td>
      <td>-0.157630</td>
      <td>-0.402962</td>
      <td>-0.814688</td>
      <td>-0.121170</td>
      <td>0.148093</td>
      <td>0.918887</td>
      <td>0.056024</td>
      <td>0.677779</td>
      <td>1.480044</td>
      <td>0.018188</td>
      <td>-0.054041</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.197842</td>
      <td>0.635931</td>
      <td>-0.089807</td>
      <td>0.056095</td>
      <td>-0.999377</td>
      <td>-1.211024</td>
      <td>-0.124828</td>
      <td>0.120478</td>
      <td>0.385291</td>
      <td>-0.221104</td>
      <td>0.904852</td>
      <td>0.488404</td>
      <td>-0.662701</td>
      <td>-0.158975</td>
      <td>1.086078</td>
      <td>-0.235252</td>
      <td>0.435209</td>
      <td>-0.408087</td>
      <td>1.196999</td>
      <td>1.034998</td>
      <td>0.637091</td>
      <td>-0.615938</td>
      <td>-0.678893</td>
      <td>-1.840170</td>
      <td>0.023051</td>
      <td>-0.154715</td>
      <td>-0.066086</td>
      <td>1.444761</td>
      <td>1.280085</td>
      <td>0.814004</td>
      <td>0.517315</td>
      <td>0.453997</td>
      <td>-0.297863</td>
      <td>0.746146</td>
      <td>-0.272631</td>
      <td>-0.811187</td>
      <td>0.099439</td>
      <td>-0.006328</td>
      <td>0.337587</td>
      <td>-0.292972</td>
      <td>...</td>
      <td>0.421947</td>
      <td>-0.157940</td>
      <td>0.084875</td>
      <td>1.376858</td>
      <td>-0.793646</td>
      <td>-0.354019</td>
      <td>0.323451</td>
      <td>-0.832754</td>
      <td>-0.128497</td>
      <td>-0.280262</td>
      <td>0.449097</td>
      <td>0.177515</td>
      <td>-0.548345</td>
      <td>-0.735605</td>
      <td>0.253853</td>
      <td>0.481367</td>
      <td>-0.020644</td>
      <td>-0.164990</td>
      <td>0.623369</td>
      <td>-0.170376</td>
      <td>0.703928</td>
      <td>0.423477</td>
      <td>-0.286750</td>
      <td>-0.085500</td>
      <td>0.222036</td>
      <td>-1.418673</td>
      <td>-0.183947</td>
      <td>0.116621</td>
      <td>-0.370096</td>
      <td>-0.883444</td>
      <td>-1.047289</td>
      <td>-0.492784</td>
      <td>-0.306310</td>
      <td>-0.079601</td>
      <td>-0.906413</td>
      <td>-0.686783</td>
      <td>-0.225036</td>
      <td>0.113486</td>
      <td>0.342766</td>
      <td>0.241585</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.358860</td>
      <td>0.203957</td>
      <td>-0.284903</td>
      <td>-0.715008</td>
      <td>-0.368533</td>
      <td>-1.061570</td>
      <td>-0.822577</td>
      <td>-1.107307</td>
      <td>-1.050848</td>
      <td>-0.162366</td>
      <td>0.376484</td>
      <td>0.103547</td>
      <td>0.294189</td>
      <td>0.379749</td>
      <td>1.071314</td>
      <td>0.353440</td>
      <td>0.077493</td>
      <td>-0.497597</td>
      <td>-0.515702</td>
      <td>-0.307353</td>
      <td>0.145616</td>
      <td>-0.070220</td>
      <td>-0.849561</td>
      <td>-0.950129</td>
      <td>-0.264790</td>
      <td>-0.341733</td>
      <td>-0.022602</td>
      <td>0.425665</td>
      <td>-0.732825</td>
      <td>-0.187737</td>
      <td>-0.391271</td>
      <td>0.086011</td>
      <td>-0.584415</td>
      <td>0.714061</td>
      <td>-0.203716</td>
      <td>-0.058157</td>
      <td>0.021953</td>
      <td>0.941858</td>
      <td>0.578924</td>
      <td>-0.703357</td>
      <td>...</td>
      <td>-0.036892</td>
      <td>-0.371390</td>
      <td>0.038683</td>
      <td>0.377953</td>
      <td>-0.335349</td>
      <td>-0.973570</td>
      <td>-0.412507</td>
      <td>-0.486876</td>
      <td>-0.396802</td>
      <td>0.336106</td>
      <td>0.523327</td>
      <td>0.307199</td>
      <td>0.991483</td>
      <td>-0.680494</td>
      <td>-0.768153</td>
      <td>1.500932</td>
      <td>-0.127010</td>
      <td>-0.267127</td>
      <td>0.219213</td>
      <td>-0.379824</td>
      <td>0.347012</td>
      <td>0.426533</td>
      <td>0.371633</td>
      <td>1.115199</td>
      <td>0.466443</td>
      <td>-0.069997</td>
      <td>-0.560556</td>
      <td>0.406914</td>
      <td>-0.695217</td>
      <td>-1.292951</td>
      <td>-1.164427</td>
      <td>0.269292</td>
      <td>-0.888761</td>
      <td>-0.116794</td>
      <td>0.010707</td>
      <td>0.217484</td>
      <td>1.218425</td>
      <td>-2.438377</td>
      <td>-1.572907</td>
      <td>-1.040335</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.051556</td>
      <td>-0.506424</td>
      <td>-0.626392</td>
      <td>-0.386869</td>
      <td>1.024587</td>
      <td>0.992705</td>
      <td>1.196715</td>
      <td>0.306472</td>
      <td>0.337954</td>
      <td>1.258714</td>
      <td>1.115270</td>
      <td>0.782203</td>
      <td>0.596213</td>
      <td>0.820762</td>
      <td>0.757283</td>
      <td>-0.295536</td>
      <td>-0.670319</td>
      <td>-0.026980</td>
      <td>0.104323</td>
      <td>-0.387446</td>
      <td>-0.161672</td>
      <td>-1.236920</td>
      <td>-0.193487</td>
      <td>-0.460774</td>
      <td>-1.317541</td>
      <td>-0.058978</td>
      <td>-0.369116</td>
      <td>-0.302757</td>
      <td>0.292480</td>
      <td>0.032811</td>
      <td>0.092733</td>
      <td>0.481920</td>
      <td>-0.691483</td>
      <td>0.506777</td>
      <td>0.750484</td>
      <td>-0.381934</td>
      <td>-0.369117</td>
      <td>-0.171481</td>
      <td>0.650628</td>
      <td>0.785417</td>
      <td>...</td>
      <td>0.329280</td>
      <td>0.379300</td>
      <td>0.470824</td>
      <td>-0.143072</td>
      <td>-0.466679</td>
      <td>0.646579</td>
      <td>0.813569</td>
      <td>-0.448848</td>
      <td>-0.892431</td>
      <td>0.707006</td>
      <td>0.843537</td>
      <td>0.057951</td>
      <td>-0.470227</td>
      <td>-1.425686</td>
      <td>-0.653420</td>
      <td>-0.349902</td>
      <td>0.753479</td>
      <td>0.005578</td>
      <td>-0.147786</td>
      <td>-1.318122</td>
      <td>0.261698</td>
      <td>0.265348</td>
      <td>0.522243</td>
      <td>0.217096</td>
      <td>0.145307</td>
      <td>-0.668146</td>
      <td>-0.570847</td>
      <td>0.834994</td>
      <td>-0.065323</td>
      <td>0.126713</td>
      <td>-0.593104</td>
      <td>1.094519</td>
      <td>0.284986</td>
      <td>0.171884</td>
      <td>0.045371</td>
      <td>0.670404</td>
      <td>0.117125</td>
      <td>-1.174781</td>
      <td>-0.989085</td>
      <td>-1.117791</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.081994</td>
      <td>1.592399</td>
      <td>0.063714</td>
      <td>0.282237</td>
      <td>0.026579</td>
      <td>0.224567</td>
      <td>0.061597</td>
      <td>-0.510797</td>
      <td>0.079285</td>
      <td>1.170457</td>
      <td>1.175799</td>
      <td>0.283446</td>
      <td>1.208724</td>
      <td>1.404610</td>
      <td>1.612515</td>
      <td>0.650536</td>
      <td>-0.181142</td>
      <td>-0.100597</td>
      <td>-0.228918</td>
      <td>-0.918994</td>
      <td>-0.196412</td>
      <td>-0.229195</td>
      <td>0.431897</td>
      <td>-0.330675</td>
      <td>-0.034952</td>
      <td>0.255729</td>
      <td>0.482186</td>
      <td>0.238055</td>
      <td>0.062640</td>
      <td>0.527266</td>
      <td>0.453858</td>
      <td>0.260264</td>
      <td>0.405063</td>
      <td>-0.540010</td>
      <td>-0.759881</td>
      <td>-0.171069</td>
      <td>-0.550339</td>
      <td>0.444823</td>
      <td>0.402211</td>
      <td>-0.179593</td>
      <td>...</td>
      <td>0.027260</td>
      <td>0.538221</td>
      <td>-0.135673</td>
      <td>0.879313</td>
      <td>0.317976</td>
      <td>0.459153</td>
      <td>-1.131486</td>
      <td>-0.888556</td>
      <td>-1.339519</td>
      <td>-0.096972</td>
      <td>-0.593118</td>
      <td>0.861300</td>
      <td>-0.085882</td>
      <td>-0.899450</td>
      <td>-1.556487</td>
      <td>-0.749244</td>
      <td>-0.395956</td>
      <td>-0.913689</td>
      <td>-0.959421</td>
      <td>-0.489525</td>
      <td>-0.164932</td>
      <td>0.902844</td>
      <td>-0.433066</td>
      <td>-0.779437</td>
      <td>-0.626437</td>
      <td>-0.411830</td>
      <td>-0.123158</td>
      <td>-0.930311</td>
      <td>-0.706997</td>
      <td>-0.055234</td>
      <td>-0.588465</td>
      <td>0.861739</td>
      <td>0.483910</td>
      <td>0.343387</td>
      <td>-0.270480</td>
      <td>0.757801</td>
      <td>0.755450</td>
      <td>3.616986</td>
      <td>2.441460</td>
      <td>0.509369</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.518277</td>
      <td>-0.009264</td>
      <td>-0.977742</td>
      <td>0.054520</td>
      <td>-0.946501</td>
      <td>-0.787214</td>
      <td>-0.515074</td>
      <td>0.445981</td>
      <td>1.322024</td>
      <td>0.005543</td>
      <td>0.426641</td>
      <td>-0.160904</td>
      <td>-0.850435</td>
      <td>-0.059281</td>
      <td>0.689253</td>
      <td>0.293767</td>
      <td>0.181287</td>
      <td>0.163159</td>
      <td>0.167693</td>
      <td>-0.351622</td>
      <td>-1.110054</td>
      <td>-0.560575</td>
      <td>0.642901</td>
      <td>0.253232</td>
      <td>0.108396</td>
      <td>0.304678</td>
      <td>0.215150</td>
      <td>-0.529236</td>
      <td>-1.796869</td>
      <td>-0.298555</td>
      <td>0.278803</td>
      <td>0.634373</td>
      <td>-0.708126</td>
      <td>-1.042203</td>
      <td>0.046386</td>
      <td>-0.592856</td>
      <td>0.496114</td>
      <td>1.361818</td>
      <td>-0.072357</td>
      <td>0.340279</td>
      <td>...</td>
      <td>0.997576</td>
      <td>0.032495</td>
      <td>-0.067810</td>
      <td>0.705631</td>
      <td>-1.397966</td>
      <td>0.128863</td>
      <td>0.636038</td>
      <td>0.761223</td>
      <td>-0.873523</td>
      <td>-0.840018</td>
      <td>-0.081361</td>
      <td>0.234137</td>
      <td>0.623204</td>
      <td>0.793258</td>
      <td>-0.984785</td>
      <td>0.449793</td>
      <td>1.139085</td>
      <td>-0.245989</td>
      <td>0.865080</td>
      <td>0.170106</td>
      <td>0.595169</td>
      <td>-0.107960</td>
      <td>-0.387029</td>
      <td>-0.933505</td>
      <td>-0.552636</td>
      <td>-0.196164</td>
      <td>-1.476688</td>
      <td>-0.116684</td>
      <td>0.297057</td>
      <td>0.365869</td>
      <td>-0.434966</td>
      <td>-0.371779</td>
      <td>-0.889786</td>
      <td>-1.197894</td>
      <td>-0.982901</td>
      <td>-0.134674</td>
      <td>-0.177729</td>
      <td>-0.809433</td>
      <td>-0.546136</td>
      <td>-0.138178</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.403833</td>
      <td>0.294467</td>
      <td>0.094327</td>
      <td>-0.163402</td>
      <td>-0.222638</td>
      <td>0.176544</td>
      <td>1.011176</td>
      <td>0.375919</td>
      <td>0.332874</td>
      <td>0.218504</td>
      <td>-0.402583</td>
      <td>0.187164</td>
      <td>0.599372</td>
      <td>-0.895689</td>
      <td>0.973279</td>
      <td>0.226465</td>
      <td>-0.305443</td>
      <td>-0.108065</td>
      <td>-0.504775</td>
      <td>0.580106</td>
      <td>-0.393954</td>
      <td>-1.131058</td>
      <td>-0.449346</td>
      <td>-0.436372</td>
      <td>-0.362837</td>
      <td>-0.915260</td>
      <td>0.136212</td>
      <td>0.762391</td>
      <td>-0.385754</td>
      <td>0.525792</td>
      <td>0.724346</td>
      <td>0.708484</td>
      <td>-0.856465</td>
      <td>0.276856</td>
      <td>-1.293404</td>
      <td>-0.870040</td>
      <td>-0.860798</td>
      <td>0.392360</td>
      <td>-0.001248</td>
      <td>-0.065226</td>
      <td>...</td>
      <td>0.301085</td>
      <td>0.266126</td>
      <td>-0.799034</td>
      <td>0.087460</td>
      <td>-0.264015</td>
      <td>0.255703</td>
      <td>0.309943</td>
      <td>-0.178884</td>
      <td>-1.562182</td>
      <td>-0.015400</td>
      <td>1.040754</td>
      <td>1.007247</td>
      <td>-0.344672</td>
      <td>-0.518049</td>
      <td>-0.631012</td>
      <td>0.127864</td>
      <td>0.456057</td>
      <td>-0.662753</td>
      <td>-0.761237</td>
      <td>-0.474522</td>
      <td>-0.485231</td>
      <td>-0.615678</td>
      <td>0.071644</td>
      <td>0.313069</td>
      <td>0.107175</td>
      <td>0.263967</td>
      <td>0.871279</td>
      <td>-0.027341</td>
      <td>0.539767</td>
      <td>0.035973</td>
      <td>-0.871392</td>
      <td>0.082921</td>
      <td>-1.249225</td>
      <td>0.091726</td>
      <td>0.247597</td>
      <td>-0.565807</td>
      <td>0.009822</td>
      <td>0.628824</td>
      <td>0.024818</td>
      <td>0.020663</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-0.389785</td>
      <td>0.845345</td>
      <td>0.284476</td>
      <td>-0.536160</td>
      <td>0.366461</td>
      <td>-0.008220</td>
      <td>-0.445698</td>
      <td>0.449535</td>
      <td>-0.634013</td>
      <td>-0.104812</td>
      <td>0.807832</td>
      <td>0.424421</td>
      <td>1.000400</td>
      <td>-0.141807</td>
      <td>0.791882</td>
      <td>-0.090532</td>
      <td>-0.039118</td>
      <td>-0.949484</td>
      <td>-0.566490</td>
      <td>0.562298</td>
      <td>-0.355360</td>
      <td>-1.348865</td>
      <td>-0.436514</td>
      <td>-1.328814</td>
      <td>-0.476874</td>
      <td>0.242949</td>
      <td>-0.194369</td>
      <td>0.934349</td>
      <td>-0.378783</td>
      <td>1.099855</td>
      <td>-0.385549</td>
      <td>0.700798</td>
      <td>-0.620782</td>
      <td>0.393628</td>
      <td>0.626580</td>
      <td>0.237433</td>
      <td>0.137930</td>
      <td>0.580934</td>
      <td>-0.418198</td>
      <td>0.304744</td>
      <td>...</td>
      <td>0.776795</td>
      <td>-0.461356</td>
      <td>0.610174</td>
      <td>0.368934</td>
      <td>-0.676727</td>
      <td>-0.125446</td>
      <td>0.404530</td>
      <td>-0.125104</td>
      <td>-0.103178</td>
      <td>0.169510</td>
      <td>-0.630797</td>
      <td>0.216981</td>
      <td>1.136482</td>
      <td>0.471880</td>
      <td>-1.224153</td>
      <td>0.896391</td>
      <td>0.070131</td>
      <td>0.746271</td>
      <td>0.249017</td>
      <td>-0.179356</td>
      <td>-0.303598</td>
      <td>0.580486</td>
      <td>-0.041959</td>
      <td>-0.796558</td>
      <td>-0.862767</td>
      <td>0.297459</td>
      <td>-0.288862</td>
      <td>0.653383</td>
      <td>1.436568</td>
      <td>-0.068542</td>
      <td>-0.569852</td>
      <td>0.306504</td>
      <td>1.014163</td>
      <td>-0.212575</td>
      <td>0.469746</td>
      <td>-0.450709</td>
      <td>0.066182</td>
      <td>1.475562</td>
      <td>1.292954</td>
      <td>0.921804</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.570824</td>
      <td>0.139875</td>
      <td>0.308113</td>
      <td>0.294576</td>
      <td>0.010693</td>
      <td>0.175041</td>
      <td>0.151597</td>
      <td>0.810735</td>
      <td>0.404867</td>
      <td>1.576370</td>
      <td>0.860785</td>
      <td>-0.302792</td>
      <td>-0.501219</td>
      <td>-0.414366</td>
      <td>-0.329016</td>
      <td>-0.480388</td>
      <td>-1.381918</td>
      <td>0.447293</td>
      <td>0.260947</td>
      <td>-0.533571</td>
      <td>-0.394902</td>
      <td>-0.493202</td>
      <td>0.501207</td>
      <td>-1.085070</td>
      <td>-0.444962</td>
      <td>-0.269927</td>
      <td>0.032547</td>
      <td>0.934962</td>
      <td>-0.041002</td>
      <td>-0.052198</td>
      <td>0.032043</td>
      <td>0.123501</td>
      <td>-0.841872</td>
      <td>-0.156205</td>
      <td>0.459461</td>
      <td>0.280425</td>
      <td>0.223686</td>
      <td>0.212883</td>
      <td>-0.308275</td>
      <td>0.504677</td>
      <td>...</td>
      <td>0.535745</td>
      <td>-0.351880</td>
      <td>0.846329</td>
      <td>1.817837</td>
      <td>0.322964</td>
      <td>-0.151995</td>
      <td>0.325688</td>
      <td>-0.294602</td>
      <td>-0.551548</td>
      <td>-0.635193</td>
      <td>-0.205377</td>
      <td>-1.193516</td>
      <td>0.313445</td>
      <td>-0.345414</td>
      <td>-0.014656</td>
      <td>0.328120</td>
      <td>-1.111695</td>
      <td>-0.216433</td>
      <td>0.377413</td>
      <td>-0.062647</td>
      <td>0.041220</td>
      <td>0.172943</td>
      <td>0.230069</td>
      <td>-0.193859</td>
      <td>-1.105080</td>
      <td>0.057934</td>
      <td>-0.427926</td>
      <td>0.679697</td>
      <td>-0.141473</td>
      <td>-0.125504</td>
      <td>-0.590835</td>
      <td>0.348607</td>
      <td>-0.114751</td>
      <td>0.228954</td>
      <td>0.261394</td>
      <td>0.333463</td>
      <td>0.747920</td>
      <td>1.755756</td>
      <td>1.265759</td>
      <td>0.772574</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.624087</td>
      <td>1.094901</td>
      <td>0.063146</td>
      <td>-1.085000</td>
      <td>-0.098518</td>
      <td>-0.333374</td>
      <td>0.050526</td>
      <td>-0.710649</td>
      <td>-0.740822</td>
      <td>-0.288716</td>
      <td>1.330874</td>
      <td>-0.428952</td>
      <td>-0.718643</td>
      <td>-0.460657</td>
      <td>-0.238232</td>
      <td>0.023884</td>
      <td>-1.009670</td>
      <td>0.244752</td>
      <td>0.066469</td>
      <td>-0.077507</td>
      <td>0.177524</td>
      <td>0.570773</td>
      <td>0.034733</td>
      <td>-0.807752</td>
      <td>-0.085280</td>
      <td>0.226597</td>
      <td>-0.299816</td>
      <td>0.299292</td>
      <td>-1.064687</td>
      <td>-0.215485</td>
      <td>-0.526665</td>
      <td>0.098828</td>
      <td>-0.735452</td>
      <td>-0.190122</td>
      <td>-0.654514</td>
      <td>-0.163599</td>
      <td>-0.339293</td>
      <td>-0.122836</td>
      <td>-1.697232</td>
      <td>-0.264228</td>
      <td>...</td>
      <td>0.365691</td>
      <td>0.885516</td>
      <td>1.573223</td>
      <td>0.361720</td>
      <td>-0.436707</td>
      <td>-0.424631</td>
      <td>0.312040</td>
      <td>0.181354</td>
      <td>-0.941176</td>
      <td>-0.083166</td>
      <td>0.318039</td>
      <td>-0.468208</td>
      <td>0.264019</td>
      <td>-0.118298</td>
      <td>-1.373833</td>
      <td>0.414522</td>
      <td>-0.509337</td>
      <td>0.374957</td>
      <td>-0.850614</td>
      <td>-0.354284</td>
      <td>-0.579759</td>
      <td>-0.463691</td>
      <td>0.091881</td>
      <td>-0.626295</td>
      <td>-0.269866</td>
      <td>0.346291</td>
      <td>-0.936049</td>
      <td>-0.051353</td>
      <td>0.299073</td>
      <td>-0.765873</td>
      <td>-0.578857</td>
      <td>0.093099</td>
      <td>-0.736575</td>
      <td>-0.159707</td>
      <td>-0.436031</td>
      <td>0.189743</td>
      <td>-0.270175</td>
      <td>0.951243</td>
      <td>1.442850</td>
      <td>1.260357</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-0.441920</td>
      <td>0.059326</td>
      <td>0.921322</td>
      <td>0.721672</td>
      <td>-0.346220</td>
      <td>0.930173</td>
      <td>-1.179186</td>
      <td>-0.815941</td>
      <td>-0.436555</td>
      <td>0.045525</td>
      <td>-0.411029</td>
      <td>-0.059029</td>
      <td>-0.160242</td>
      <td>0.308607</td>
      <td>0.125271</td>
      <td>-0.121919</td>
      <td>-0.041411</td>
      <td>0.090336</td>
      <td>0.325629</td>
      <td>0.038844</td>
      <td>0.196382</td>
      <td>-0.368801</td>
      <td>0.344459</td>
      <td>0.044314</td>
      <td>-0.401664</td>
      <td>-0.307310</td>
      <td>0.708760</td>
      <td>0.252867</td>
      <td>-1.384021</td>
      <td>-0.294166</td>
      <td>1.027750</td>
      <td>-0.702187</td>
      <td>-1.010499</td>
      <td>-1.327515</td>
      <td>0.112660</td>
      <td>-0.019235</td>
      <td>-0.034852</td>
      <td>0.457608</td>
      <td>0.269283</td>
      <td>0.298296</td>
      <td>...</td>
      <td>-0.532631</td>
      <td>-1.025110</td>
      <td>-0.018207</td>
      <td>-0.458014</td>
      <td>-1.483816</td>
      <td>-0.016456</td>
      <td>-0.631961</td>
      <td>0.062846</td>
      <td>-2.052322</td>
      <td>-0.994613</td>
      <td>0.063386</td>
      <td>-0.690855</td>
      <td>0.838724</td>
      <td>0.839964</td>
      <td>-0.078797</td>
      <td>0.619444</td>
      <td>0.001015</td>
      <td>0.424253</td>
      <td>0.257110</td>
      <td>-0.077722</td>
      <td>-0.273367</td>
      <td>-0.648311</td>
      <td>-0.664522</td>
      <td>-0.465036</td>
      <td>0.357393</td>
      <td>1.101250</td>
      <td>0.072352</td>
      <td>-0.249992</td>
      <td>-0.312156</td>
      <td>-0.814503</td>
      <td>-0.190684</td>
      <td>0.656436</td>
      <td>-0.356515</td>
      <td>-0.688834</td>
      <td>0.036010</td>
      <td>-0.580436</td>
      <td>-0.665122</td>
      <td>-0.349334</td>
      <td>0.208258</td>
      <td>0.737545</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.346745</td>
      <td>-0.052180</td>
      <td>-0.307136</td>
      <td>-0.121081</td>
      <td>-0.262234</td>
      <td>0.246774</td>
      <td>0.162445</td>
      <td>0.815643</td>
      <td>-0.792543</td>
      <td>-0.568243</td>
      <td>0.404140</td>
      <td>0.111476</td>
      <td>-1.090133</td>
      <td>0.894162</td>
      <td>0.943261</td>
      <td>1.139048</td>
      <td>-0.558554</td>
      <td>0.311191</td>
      <td>1.393593</td>
      <td>0.959541</td>
      <td>-0.449047</td>
      <td>-1.491524</td>
      <td>-0.255899</td>
      <td>-0.542306</td>
      <td>0.739435</td>
      <td>-0.219682</td>
      <td>-0.876467</td>
      <td>-0.246931</td>
      <td>-1.173265</td>
      <td>-0.069969</td>
      <td>-0.132459</td>
      <td>-0.617603</td>
      <td>-0.814302</td>
      <td>0.478165</td>
      <td>-0.490273</td>
      <td>-1.231149</td>
      <td>0.579141</td>
      <td>0.889057</td>
      <td>-0.860191</td>
      <td>-0.223924</td>
      <td>...</td>
      <td>0.273272</td>
      <td>1.008599</td>
      <td>1.193956</td>
      <td>0.562117</td>
      <td>0.093888</td>
      <td>0.300357</td>
      <td>-0.069037</td>
      <td>0.150996</td>
      <td>0.046580</td>
      <td>0.034432</td>
      <td>0.419015</td>
      <td>1.128610</td>
      <td>-0.269361</td>
      <td>-0.813349</td>
      <td>-0.188899</td>
      <td>0.750613</td>
      <td>-0.618832</td>
      <td>-0.126217</td>
      <td>0.378263</td>
      <td>-0.445454</td>
      <td>-0.390837</td>
      <td>0.880215</td>
      <td>-0.308247</td>
      <td>0.086086</td>
      <td>-0.866365</td>
      <td>0.411826</td>
      <td>-0.256305</td>
      <td>0.574949</td>
      <td>-0.528190</td>
      <td>-0.038647</td>
      <td>-0.233200</td>
      <td>-0.531874</td>
      <td>-1.646598</td>
      <td>-0.844268</td>
      <td>-0.811875</td>
      <td>0.032626</td>
      <td>-0.534702</td>
      <td>-0.339768</td>
      <td>-0.702111</td>
      <td>-0.908676</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.213518</td>
      <td>0.511798</td>
      <td>0.365244</td>
      <td>-0.740339</td>
      <td>-0.243334</td>
      <td>0.385519</td>
      <td>-0.153470</td>
      <td>-0.363589</td>
      <td>-0.164898</td>
      <td>0.096663</td>
      <td>0.900007</td>
      <td>0.323332</td>
      <td>-0.494890</td>
      <td>-0.905484</td>
      <td>0.651366</td>
      <td>0.590713</td>
      <td>-0.452082</td>
      <td>-0.057488</td>
      <td>0.437580</td>
      <td>0.582480</td>
      <td>0.230711</td>
      <td>-0.170837</td>
      <td>-0.563970</td>
      <td>-1.006586</td>
      <td>-0.437596</td>
      <td>0.024841</td>
      <td>0.560462</td>
      <td>0.540115</td>
      <td>-0.068050</td>
      <td>0.299962</td>
      <td>-0.305935</td>
      <td>-0.462345</td>
      <td>-1.438949</td>
      <td>-0.683528</td>
      <td>-0.411354</td>
      <td>-0.797003</td>
      <td>-0.284403</td>
      <td>-0.373296</td>
      <td>-0.761835</td>
      <td>0.791691</td>
      <td>...</td>
      <td>0.396696</td>
      <td>-0.206920</td>
      <td>0.066749</td>
      <td>1.426460</td>
      <td>-0.175587</td>
      <td>-0.800932</td>
      <td>0.206882</td>
      <td>0.125664</td>
      <td>-0.361779</td>
      <td>-0.135792</td>
      <td>0.563315</td>
      <td>0.380872</td>
      <td>0.537079</td>
      <td>0.419866</td>
      <td>-0.433051</td>
      <td>-0.685121</td>
      <td>-1.131647</td>
      <td>-0.635200</td>
      <td>-0.382003</td>
      <td>-1.073125</td>
      <td>-0.984604</td>
      <td>-0.878095</td>
      <td>0.392348</td>
      <td>0.497600</td>
      <td>-0.494776</td>
      <td>-0.071364</td>
      <td>-0.685450</td>
      <td>-0.136920</td>
      <td>-1.105605</td>
      <td>-0.237085</td>
      <td>-1.038870</td>
      <td>-0.182424</td>
      <td>-0.547107</td>
      <td>-1.271001</td>
      <td>-0.092914</td>
      <td>-0.346718</td>
      <td>0.791246</td>
      <td>0.311880</td>
      <td>0.319766</td>
      <td>0.677329</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.963779</td>
      <td>0.783978</td>
      <td>0.024106</td>
      <td>-0.413388</td>
      <td>-0.231641</td>
      <td>-0.924362</td>
      <td>0.086596</td>
      <td>0.079395</td>
      <td>0.032384</td>
      <td>0.285600</td>
      <td>1.261518</td>
      <td>1.372942</td>
      <td>-0.002900</td>
      <td>-0.745065</td>
      <td>-0.352534</td>
      <td>0.197804</td>
      <td>0.631862</td>
      <td>0.510907</td>
      <td>-0.750535</td>
      <td>0.148928</td>
      <td>-1.821308</td>
      <td>-1.285348</td>
      <td>0.351387</td>
      <td>-0.829163</td>
      <td>0.096619</td>
      <td>1.394340</td>
      <td>0.591138</td>
      <td>0.777348</td>
      <td>-0.872316</td>
      <td>0.616895</td>
      <td>-0.913364</td>
      <td>-0.836027</td>
      <td>-0.863961</td>
      <td>0.658954</td>
      <td>-0.145928</td>
      <td>0.049247</td>
      <td>-1.088386</td>
      <td>0.694514</td>
      <td>0.471518</td>
      <td>-0.726524</td>
      <td>...</td>
      <td>-0.850352</td>
      <td>-0.165755</td>
      <td>-0.895509</td>
      <td>0.813999</td>
      <td>-0.847719</td>
      <td>-0.968871</td>
      <td>-0.445010</td>
      <td>0.588675</td>
      <td>-0.768954</td>
      <td>0.483157</td>
      <td>0.084483</td>
      <td>-0.540153</td>
      <td>-0.701467</td>
      <td>-0.495162</td>
      <td>-0.203676</td>
      <td>-0.040076</td>
      <td>-0.199802</td>
      <td>-0.462415</td>
      <td>0.146215</td>
      <td>-0.725868</td>
      <td>-0.636060</td>
      <td>0.612493</td>
      <td>0.342710</td>
      <td>-0.601734</td>
      <td>-0.379599</td>
      <td>0.396882</td>
      <td>-0.418521</td>
      <td>-0.029474</td>
      <td>-0.445370</td>
      <td>-0.274064</td>
      <td>-0.953134</td>
      <td>-0.266176</td>
      <td>-0.771835</td>
      <td>-0.360660</td>
      <td>-0.990599</td>
      <td>-0.245719</td>
      <td>-0.650980</td>
      <td>1.279869</td>
      <td>0.659627</td>
      <td>0.723739</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.085308</td>
      <td>0.842833</td>
      <td>-0.554621</td>
      <td>0.039369</td>
      <td>0.629034</td>
      <td>0.845383</td>
      <td>0.114950</td>
      <td>0.857067</td>
      <td>0.680244</td>
      <td>1.322688</td>
      <td>0.929825</td>
      <td>0.772467</td>
      <td>0.777686</td>
      <td>0.389766</td>
      <td>0.185348</td>
      <td>-0.504960</td>
      <td>-0.114322</td>
      <td>-0.616865</td>
      <td>-0.451217</td>
      <td>-0.245658</td>
      <td>0.642722</td>
      <td>-0.789638</td>
      <td>-0.275127</td>
      <td>-0.303409</td>
      <td>-0.157296</td>
      <td>1.095480</td>
      <td>-0.553161</td>
      <td>0.005799</td>
      <td>-0.806301</td>
      <td>-0.371278</td>
      <td>-0.103242</td>
      <td>0.423999</td>
      <td>0.085513</td>
      <td>0.179029</td>
      <td>-0.666286</td>
      <td>-1.217254</td>
      <td>-0.794334</td>
      <td>-0.619793</td>
      <td>-0.430292</td>
      <td>0.370119</td>
      <td>...</td>
      <td>0.881000</td>
      <td>0.191632</td>
      <td>1.509574</td>
      <td>-0.135959</td>
      <td>0.406134</td>
      <td>0.960619</td>
      <td>0.168368</td>
      <td>-1.142351</td>
      <td>-1.845469</td>
      <td>-0.632940</td>
      <td>0.855876</td>
      <td>1.225278</td>
      <td>0.635393</td>
      <td>-0.744457</td>
      <td>-1.038216</td>
      <td>0.476910</td>
      <td>0.112149</td>
      <td>0.584718</td>
      <td>-0.048776</td>
      <td>0.368891</td>
      <td>-0.389287</td>
      <td>1.278697</td>
      <td>0.194274</td>
      <td>-1.159304</td>
      <td>-0.448396</td>
      <td>1.075040</td>
      <td>1.460613</td>
      <td>-0.026165</td>
      <td>-1.303457</td>
      <td>-1.931476</td>
      <td>-1.035354</td>
      <td>0.356474</td>
      <td>-0.627523</td>
      <td>-0.291571</td>
      <td>0.030684</td>
      <td>-0.173682</td>
      <td>-0.538720</td>
      <td>1.823128</td>
      <td>0.635998</td>
      <td>0.639270</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.582149</td>
      <td>0.334371</td>
      <td>0.705503</td>
      <td>0.182617</td>
      <td>0.302793</td>
      <td>0.028293</td>
      <td>0.360251</td>
      <td>-0.502434</td>
      <td>-0.044018</td>
      <td>0.203251</td>
      <td>0.902606</td>
      <td>-0.122992</td>
      <td>-0.991046</td>
      <td>0.219611</td>
      <td>-0.365835</td>
      <td>0.179182</td>
      <td>-0.570618</td>
      <td>-0.639576</td>
      <td>0.573243</td>
      <td>0.838517</td>
      <td>0.020912</td>
      <td>-1.016293</td>
      <td>-0.111502</td>
      <td>-1.293319</td>
      <td>0.175536</td>
      <td>-0.165499</td>
      <td>0.809527</td>
      <td>0.969808</td>
      <td>0.294028</td>
      <td>0.625791</td>
      <td>1.010467</td>
      <td>0.225320</td>
      <td>-0.323529</td>
      <td>0.109562</td>
      <td>-0.234626</td>
      <td>-0.620973</td>
      <td>-0.510289</td>
      <td>-0.003455</td>
      <td>-0.081565</td>
      <td>0.048971</td>
      <td>...</td>
      <td>-0.508731</td>
      <td>0.131731</td>
      <td>-0.144611</td>
      <td>-0.122273</td>
      <td>-0.899909</td>
      <td>0.520821</td>
      <td>-0.654167</td>
      <td>0.103519</td>
      <td>-0.286503</td>
      <td>-1.175982</td>
      <td>0.300299</td>
      <td>-0.285349</td>
      <td>-0.000327</td>
      <td>-0.114146</td>
      <td>-0.404250</td>
      <td>0.835551</td>
      <td>-0.545750</td>
      <td>-0.438072</td>
      <td>0.132989</td>
      <td>-0.210071</td>
      <td>0.279429</td>
      <td>-0.325824</td>
      <td>0.028160</td>
      <td>0.293424</td>
      <td>-0.071876</td>
      <td>0.324288</td>
      <td>0.165191</td>
      <td>-0.151127</td>
      <td>-0.360095</td>
      <td>-0.931303</td>
      <td>-0.184481</td>
      <td>0.223396</td>
      <td>-1.243147</td>
      <td>-0.755027</td>
      <td>-1.054583</td>
      <td>-0.654833</td>
      <td>-0.039813</td>
      <td>-0.823437</td>
      <td>-0.330632</td>
      <td>0.586556</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.871191</td>
      <td>0.688212</td>
      <td>-0.729549</td>
      <td>0.087946</td>
      <td>0.820701</td>
      <td>0.203090</td>
      <td>0.050724</td>
      <td>-0.482251</td>
      <td>-0.353662</td>
      <td>0.179061</td>
      <td>-0.188069</td>
      <td>0.649511</td>
      <td>-0.229312</td>
      <td>0.667238</td>
      <td>1.219047</td>
      <td>0.501121</td>
      <td>-0.427278</td>
      <td>0.312686</td>
      <td>-0.172516</td>
      <td>-0.024676</td>
      <td>-1.153695</td>
      <td>-0.647673</td>
      <td>-0.674228</td>
      <td>-0.691794</td>
      <td>0.586408</td>
      <td>-0.504713</td>
      <td>0.100573</td>
      <td>0.359066</td>
      <td>-0.427886</td>
      <td>0.700277</td>
      <td>0.415147</td>
      <td>-0.610641</td>
      <td>-0.656008</td>
      <td>0.358648</td>
      <td>0.342573</td>
      <td>-0.254978</td>
      <td>0.341848</td>
      <td>0.486822</td>
      <td>-0.521552</td>
      <td>0.189485</td>
      <td>...</td>
      <td>0.761555</td>
      <td>-0.413962</td>
      <td>0.202875</td>
      <td>-0.693801</td>
      <td>-0.704328</td>
      <td>-1.097416</td>
      <td>-1.132213</td>
      <td>-1.131108</td>
      <td>-0.342560</td>
      <td>0.240490</td>
      <td>-0.307361</td>
      <td>0.769157</td>
      <td>0.616324</td>
      <td>0.156743</td>
      <td>-0.009460</td>
      <td>0.702005</td>
      <td>0.302969</td>
      <td>0.482734</td>
      <td>-0.437785</td>
      <td>-0.357305</td>
      <td>-0.167723</td>
      <td>-1.086939</td>
      <td>-0.035837</td>
      <td>0.020802</td>
      <td>-0.515821</td>
      <td>-0.510275</td>
      <td>-0.668982</td>
      <td>-0.741487</td>
      <td>-0.745927</td>
      <td>-0.912606</td>
      <td>-0.643328</td>
      <td>0.096549</td>
      <td>-0.291827</td>
      <td>1.063120</td>
      <td>0.131624</td>
      <td>-0.482064</td>
      <td>0.967117</td>
      <td>0.696720</td>
      <td>0.566516</td>
      <td>0.858760</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.526320</td>
      <td>0.271092</td>
      <td>0.440715</td>
      <td>0.503294</td>
      <td>-0.398755</td>
      <td>0.232328</td>
      <td>-0.454628</td>
      <td>0.089595</td>
      <td>-0.337313</td>
      <td>0.600075</td>
      <td>0.676683</td>
      <td>0.713208</td>
      <td>1.128668</td>
      <td>0.560786</td>
      <td>0.078846</td>
      <td>-0.928002</td>
      <td>-1.669259</td>
      <td>0.839089</td>
      <td>-0.111728</td>
      <td>-0.460613</td>
      <td>0.207201</td>
      <td>-0.685439</td>
      <td>-0.636180</td>
      <td>-0.973663</td>
      <td>-0.876923</td>
      <td>0.592142</td>
      <td>0.257222</td>
      <td>-0.092614</td>
      <td>-0.037787</td>
      <td>0.965803</td>
      <td>-0.028452</td>
      <td>0.105363</td>
      <td>-0.733713</td>
      <td>-1.029019</td>
      <td>-0.738075</td>
      <td>-0.557406</td>
      <td>0.115284</td>
      <td>-0.464874</td>
      <td>-0.373374</td>
      <td>0.176475</td>
      <td>...</td>
      <td>1.084485</td>
      <td>0.519722</td>
      <td>0.613874</td>
      <td>-0.188202</td>
      <td>-1.620817</td>
      <td>-0.614735</td>
      <td>-0.007969</td>
      <td>-0.523620</td>
      <td>-0.531116</td>
      <td>-0.684993</td>
      <td>-0.109324</td>
      <td>0.046425</td>
      <td>0.860450</td>
      <td>-0.061786</td>
      <td>-2.296449</td>
      <td>-0.912614</td>
      <td>-0.258482</td>
      <td>-0.726824</td>
      <td>-0.012594</td>
      <td>-0.225820</td>
      <td>0.197769</td>
      <td>0.565939</td>
      <td>0.611901</td>
      <td>-0.190925</td>
      <td>-0.384673</td>
      <td>0.788773</td>
      <td>0.938526</td>
      <td>0.870864</td>
      <td>-1.302744</td>
      <td>-0.163669</td>
      <td>0.222661</td>
      <td>0.460989</td>
      <td>-0.768058</td>
      <td>-0.580751</td>
      <td>-0.291785</td>
      <td>0.531355</td>
      <td>-0.119381</td>
      <td>1.423169</td>
      <td>1.735118</td>
      <td>0.598319</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.027824</td>
      <td>0.854911</td>
      <td>1.076180</td>
      <td>-0.049902</td>
      <td>-0.291457</td>
      <td>-0.008236</td>
      <td>-0.158628</td>
      <td>-0.354909</td>
      <td>-0.808211</td>
      <td>0.298592</td>
      <td>0.468972</td>
      <td>0.628460</td>
      <td>-0.349026</td>
      <td>-0.277757</td>
      <td>0.358359</td>
      <td>-0.504677</td>
      <td>-0.263999</td>
      <td>0.776440</td>
      <td>-0.413078</td>
      <td>0.090771</td>
      <td>0.100992</td>
      <td>-0.302860</td>
      <td>-0.296247</td>
      <td>-0.056271</td>
      <td>0.157067</td>
      <td>-0.466629</td>
      <td>0.047818</td>
      <td>-0.131201</td>
      <td>-1.321025</td>
      <td>0.324480</td>
      <td>-0.685990</td>
      <td>0.007590</td>
      <td>0.032463</td>
      <td>-0.315227</td>
      <td>-0.986472</td>
      <td>-0.245263</td>
      <td>0.200640</td>
      <td>-0.009664</td>
      <td>-0.605899</td>
      <td>-0.450647</td>
      <td>...</td>
      <td>-0.155259</td>
      <td>-0.284590</td>
      <td>-0.864230</td>
      <td>0.268055</td>
      <td>-1.156568</td>
      <td>-0.207065</td>
      <td>-0.281710</td>
      <td>0.235697</td>
      <td>-1.447522</td>
      <td>-0.708675</td>
      <td>-0.015395</td>
      <td>-0.416577</td>
      <td>0.593701</td>
      <td>-0.098246</td>
      <td>-0.108222</td>
      <td>-0.218051</td>
      <td>-0.237950</td>
      <td>-0.137398</td>
      <td>0.632517</td>
      <td>-0.521739</td>
      <td>-0.259951</td>
      <td>0.411647</td>
      <td>0.968721</td>
      <td>-0.389827</td>
      <td>0.813865</td>
      <td>-0.714122</td>
      <td>-0.332496</td>
      <td>0.676511</td>
      <td>-0.017584</td>
      <td>0.728081</td>
      <td>0.082164</td>
      <td>0.596511</td>
      <td>-0.122479</td>
      <td>0.106903</td>
      <td>0.957777</td>
      <td>-1.044975</td>
      <td>-0.036800</td>
      <td>0.898658</td>
      <td>0.305868</td>
      <td>0.245182</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.448266</td>
      <td>1.501558</td>
      <td>0.316988</td>
      <td>-0.178011</td>
      <td>-0.194514</td>
      <td>-0.401467</td>
      <td>-0.484534</td>
      <td>0.196310</td>
      <td>0.325194</td>
      <td>-0.260452</td>
      <td>0.426934</td>
      <td>0.243323</td>
      <td>-0.048969</td>
      <td>0.801100</td>
      <td>0.592044</td>
      <td>0.524052</td>
      <td>0.194078</td>
      <td>0.282961</td>
      <td>0.157753</td>
      <td>0.458408</td>
      <td>0.690254</td>
      <td>-0.501076</td>
      <td>-0.220758</td>
      <td>0.065161</td>
      <td>-0.022042</td>
      <td>-0.681345</td>
      <td>-0.039929</td>
      <td>0.473404</td>
      <td>-0.535287</td>
      <td>0.119616</td>
      <td>0.668779</td>
      <td>0.587382</td>
      <td>0.621438</td>
      <td>-0.480814</td>
      <td>-1.430695</td>
      <td>-1.338165</td>
      <td>0.304757</td>
      <td>1.137905</td>
      <td>0.400923</td>
      <td>1.172090</td>
      <td>...</td>
      <td>0.160515</td>
      <td>-0.168030</td>
      <td>-0.007164</td>
      <td>-0.025658</td>
      <td>-0.681727</td>
      <td>-0.399237</td>
      <td>0.180507</td>
      <td>0.631992</td>
      <td>-0.854718</td>
      <td>-0.688503</td>
      <td>0.293535</td>
      <td>-0.428593</td>
      <td>0.076518</td>
      <td>0.648561</td>
      <td>0.646865</td>
      <td>0.478053</td>
      <td>-0.364517</td>
      <td>-1.009050</td>
      <td>0.026347</td>
      <td>0.312082</td>
      <td>0.482405</td>
      <td>0.704484</td>
      <td>0.747332</td>
      <td>-1.158818</td>
      <td>-0.903001</td>
      <td>-0.362827</td>
      <td>0.390305</td>
      <td>0.249719</td>
      <td>-0.216239</td>
      <td>-0.236606</td>
      <td>-0.061563</td>
      <td>0.856781</td>
      <td>-0.615494</td>
      <td>0.083069</td>
      <td>-1.031777</td>
      <td>0.220495</td>
      <td>-0.259782</td>
      <td>1.585239</td>
      <td>0.868502</td>
      <td>0.129104</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.463353</td>
      <td>0.012387</td>
      <td>0.419917</td>
      <td>-0.331887</td>
      <td>-0.768422</td>
      <td>-0.035738</td>
      <td>-0.727785</td>
      <td>-0.213951</td>
      <td>-0.907053</td>
      <td>0.662260</td>
      <td>-0.187177</td>
      <td>-0.121470</td>
      <td>-0.623558</td>
      <td>-0.061835</td>
      <td>0.686785</td>
      <td>0.628699</td>
      <td>-0.630649</td>
      <td>0.131843</td>
      <td>0.762437</td>
      <td>0.386116</td>
      <td>0.045254</td>
      <td>-1.461742</td>
      <td>-0.485682</td>
      <td>-0.167581</td>
      <td>-0.200726</td>
      <td>-0.497865</td>
      <td>0.135742</td>
      <td>0.824896</td>
      <td>-1.000035</td>
      <td>0.337140</td>
      <td>-0.034491</td>
      <td>-0.307352</td>
      <td>-0.691114</td>
      <td>-0.147786</td>
      <td>-0.538155</td>
      <td>-1.057060</td>
      <td>-0.391343</td>
      <td>-0.041221</td>
      <td>-1.304982</td>
      <td>0.785420</td>
      <td>...</td>
      <td>0.932723</td>
      <td>0.598127</td>
      <td>0.185862</td>
      <td>-0.248101</td>
      <td>-1.486206</td>
      <td>-0.063366</td>
      <td>-0.651404</td>
      <td>-0.293781</td>
      <td>-0.187106</td>
      <td>0.392689</td>
      <td>0.229862</td>
      <td>-0.105895</td>
      <td>0.283164</td>
      <td>-0.643139</td>
      <td>0.468435</td>
      <td>0.182762</td>
      <td>0.452127</td>
      <td>0.878144</td>
      <td>-0.464592</td>
      <td>0.526052</td>
      <td>-0.168198</td>
      <td>1.112656</td>
      <td>1.007933</td>
      <td>-0.981010</td>
      <td>-1.221934</td>
      <td>-0.049583</td>
      <td>-1.272662</td>
      <td>-0.764835</td>
      <td>-0.285702</td>
      <td>0.397607</td>
      <td>-0.071261</td>
      <td>-0.061990</td>
      <td>-0.509767</td>
      <td>-0.318872</td>
      <td>0.027180</td>
      <td>-0.091959</td>
      <td>-0.092539</td>
      <td>1.920997</td>
      <td>1.298359</td>
      <td>0.921103</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.159316</td>
      <td>-0.930125</td>
      <td>-0.067769</td>
      <td>-0.151798</td>
      <td>0.298418</td>
      <td>0.155173</td>
      <td>-0.227785</td>
      <td>-0.545779</td>
      <td>0.700773</td>
      <td>1.017735</td>
      <td>0.009964</td>
      <td>-0.070870</td>
      <td>-0.265947</td>
      <td>0.228844</td>
      <td>0.134928</td>
      <td>0.103922</td>
      <td>-1.797074</td>
      <td>-0.412378</td>
      <td>-0.910330</td>
      <td>-0.208552</td>
      <td>0.845465</td>
      <td>0.139164</td>
      <td>0.494511</td>
      <td>-0.950017</td>
      <td>-0.652601</td>
      <td>-0.298760</td>
      <td>-0.837499</td>
      <td>0.250644</td>
      <td>-0.054339</td>
      <td>0.453244</td>
      <td>0.690391</td>
      <td>1.351453</td>
      <td>1.139019</td>
      <td>1.166659</td>
      <td>0.139668</td>
      <td>-0.701834</td>
      <td>-0.236769</td>
      <td>-0.156630</td>
      <td>-0.546978</td>
      <td>0.619343</td>
      <td>...</td>
      <td>0.850666</td>
      <td>-0.827977</td>
      <td>-1.217478</td>
      <td>0.884975</td>
      <td>-0.092095</td>
      <td>-0.485264</td>
      <td>-0.873364</td>
      <td>-0.599776</td>
      <td>-1.335240</td>
      <td>-1.156274</td>
      <td>0.361789</td>
      <td>-0.213127</td>
      <td>0.225695</td>
      <td>-0.253602</td>
      <td>0.065396</td>
      <td>1.095764</td>
      <td>1.084498</td>
      <td>0.038760</td>
      <td>-0.377053</td>
      <td>-1.158940</td>
      <td>-1.884630</td>
      <td>0.394547</td>
      <td>-0.192116</td>
      <td>-0.657718</td>
      <td>-0.399801</td>
      <td>-0.169602</td>
      <td>-0.997903</td>
      <td>0.039348</td>
      <td>0.272335</td>
      <td>-0.126445</td>
      <td>-0.463545</td>
      <td>0.384530</td>
      <td>-0.138263</td>
      <td>-0.709317</td>
      <td>1.189009</td>
      <td>-0.200351</td>
      <td>-0.083987</td>
      <td>1.331050</td>
      <td>1.303381</td>
      <td>0.281222</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.771772</td>
      <td>0.695262</td>
      <td>0.072315</td>
      <td>-0.267415</td>
      <td>-0.620878</td>
      <td>1.092743</td>
      <td>-0.754454</td>
      <td>0.638334</td>
      <td>-0.225590</td>
      <td>0.310119</td>
      <td>0.146239</td>
      <td>0.202910</td>
      <td>0.821188</td>
      <td>-0.305523</td>
      <td>-0.631403</td>
      <td>0.154496</td>
      <td>-0.729406</td>
      <td>0.100148</td>
      <td>-0.827778</td>
      <td>0.844349</td>
      <td>-0.258901</td>
      <td>-0.591884</td>
      <td>1.039709</td>
      <td>-0.159356</td>
      <td>0.734054</td>
      <td>-0.550035</td>
      <td>-0.212630</td>
      <td>-0.504693</td>
      <td>-0.309802</td>
      <td>0.596443</td>
      <td>1.097243</td>
      <td>1.594052</td>
      <td>-0.760546</td>
      <td>0.088384</td>
      <td>0.647673</td>
      <td>-0.776667</td>
      <td>-0.065630</td>
      <td>-0.907870</td>
      <td>-0.697889</td>
      <td>0.353690</td>
      <td>...</td>
      <td>-0.231069</td>
      <td>0.216281</td>
      <td>0.481682</td>
      <td>1.023768</td>
      <td>0.318917</td>
      <td>-0.608923</td>
      <td>0.115797</td>
      <td>0.088372</td>
      <td>-0.279953</td>
      <td>-0.012456</td>
      <td>-0.369066</td>
      <td>-0.440441</td>
      <td>-0.415719</td>
      <td>-0.100244</td>
      <td>0.693964</td>
      <td>-0.793593</td>
      <td>0.793945</td>
      <td>0.120156</td>
      <td>0.494247</td>
      <td>-0.135490</td>
      <td>-0.814709</td>
      <td>1.170002</td>
      <td>0.643172</td>
      <td>1.010920</td>
      <td>-0.271536</td>
      <td>0.203986</td>
      <td>0.222180</td>
      <td>0.780245</td>
      <td>0.248642</td>
      <td>-0.116736</td>
      <td>0.572470</td>
      <td>0.435307</td>
      <td>0.028989</td>
      <td>-0.369911</td>
      <td>-0.694650</td>
      <td>-0.527768</td>
      <td>-0.113531</td>
      <td>2.470462</td>
      <td>1.425002</td>
      <td>0.948116</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>0.139769</td>
      <td>-0.431649</td>
      <td>-0.331010</td>
      <td>0.045727</td>
      <td>0.294023</td>
      <td>-0.237098</td>
      <td>0.946047</td>
      <td>0.283540</td>
      <td>0.609731</td>
      <td>0.459908</td>
      <td>0.964616</td>
      <td>0.490466</td>
      <td>-0.169481</td>
      <td>0.060118</td>
      <td>-0.353440</td>
      <td>0.408601</td>
      <td>0.904965</td>
      <td>-0.269973</td>
      <td>-0.692155</td>
      <td>-0.171771</td>
      <td>-0.412199</td>
      <td>-0.132285</td>
      <td>0.077280</td>
      <td>-0.703405</td>
      <td>-0.086431</td>
      <td>-0.725171</td>
      <td>-0.523835</td>
      <td>-0.193995</td>
      <td>0.074987</td>
      <td>0.101130</td>
      <td>-1.062040</td>
      <td>0.198250</td>
      <td>-0.344147</td>
      <td>-0.125724</td>
      <td>0.283998</td>
      <td>0.141304</td>
      <td>0.313698</td>
      <td>-0.961446</td>
      <td>-1.422306</td>
      <td>-0.136470</td>
      <td>...</td>
      <td>0.153115</td>
      <td>-0.345798</td>
      <td>-0.117364</td>
      <td>1.204344</td>
      <td>0.650966</td>
      <td>0.348663</td>
      <td>-0.256459</td>
      <td>0.824820</td>
      <td>-0.798417</td>
      <td>-0.068064</td>
      <td>-0.212301</td>
      <td>-0.916127</td>
      <td>-0.556437</td>
      <td>-0.675789</td>
      <td>-0.382018</td>
      <td>0.448079</td>
      <td>-0.064881</td>
      <td>0.170480</td>
      <td>-0.574590</td>
      <td>0.849255</td>
      <td>0.321142</td>
      <td>-0.845500</td>
      <td>-0.637000</td>
      <td>0.788394</td>
      <td>-0.154933</td>
      <td>0.778931</td>
      <td>0.984924</td>
      <td>0.199436</td>
      <td>-0.107112</td>
      <td>-0.341295</td>
      <td>0.161388</td>
      <td>0.449329</td>
      <td>0.470316</td>
      <td>-0.198003</td>
      <td>0.700079</td>
      <td>-0.910072</td>
      <td>0.125172</td>
      <td>-1.216559</td>
      <td>-0.919755</td>
      <td>-1.138845</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.863466</td>
      <td>0.147925</td>
      <td>-0.984332</td>
      <td>-0.164506</td>
      <td>0.519312</td>
      <td>-0.161284</td>
      <td>0.342624</td>
      <td>0.049450</td>
      <td>0.466096</td>
      <td>0.192059</td>
      <td>0.865147</td>
      <td>0.082448</td>
      <td>-0.438725</td>
      <td>-0.018144</td>
      <td>0.503813</td>
      <td>-0.876284</td>
      <td>-0.773463</td>
      <td>-0.347717</td>
      <td>-0.615192</td>
      <td>0.516486</td>
      <td>1.040160</td>
      <td>0.214040</td>
      <td>0.197341</td>
      <td>-1.310501</td>
      <td>-0.554372</td>
      <td>0.045302</td>
      <td>0.884440</td>
      <td>1.189364</td>
      <td>0.001257</td>
      <td>-0.051079</td>
      <td>0.067160</td>
      <td>-0.084905</td>
      <td>-0.769923</td>
      <td>0.271755</td>
      <td>0.739294</td>
      <td>0.237444</td>
      <td>-0.710895</td>
      <td>-0.236862</td>
      <td>-0.518064</td>
      <td>-0.598556</td>
      <td>...</td>
      <td>0.867745</td>
      <td>0.994940</td>
      <td>0.009266</td>
      <td>-0.445457</td>
      <td>-0.677991</td>
      <td>-0.407521</td>
      <td>0.876702</td>
      <td>0.130395</td>
      <td>-0.874200</td>
      <td>-0.193763</td>
      <td>0.297908</td>
      <td>-0.391164</td>
      <td>0.797261</td>
      <td>-0.352511</td>
      <td>0.673573</td>
      <td>-0.353505</td>
      <td>0.341685</td>
      <td>-0.599177</td>
      <td>-0.707471</td>
      <td>1.047234</td>
      <td>0.506132</td>
      <td>-0.713704</td>
      <td>-0.325332</td>
      <td>-0.024960</td>
      <td>0.584177</td>
      <td>-0.436256</td>
      <td>-0.313010</td>
      <td>0.045178</td>
      <td>0.648781</td>
      <td>-0.701803</td>
      <td>0.714401</td>
      <td>0.769430</td>
      <td>-0.468625</td>
      <td>-0.274321</td>
      <td>0.150268</td>
      <td>0.200262</td>
      <td>-0.506651</td>
      <td>-0.800577</td>
      <td>-0.013342</td>
      <td>-1.013709</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.743639</td>
      <td>-0.449753</td>
      <td>0.694087</td>
      <td>0.088542</td>
      <td>-0.719821</td>
      <td>-0.066350</td>
      <td>0.442958</td>
      <td>-0.668164</td>
      <td>0.215409</td>
      <td>0.230212</td>
      <td>0.685390</td>
      <td>0.189604</td>
      <td>-0.218505</td>
      <td>0.400108</td>
      <td>0.223915</td>
      <td>-0.573682</td>
      <td>0.981800</td>
      <td>-1.036858</td>
      <td>-0.150173</td>
      <td>0.724501</td>
      <td>-0.484750</td>
      <td>0.394907</td>
      <td>0.454355</td>
      <td>1.763650</td>
      <td>0.011722</td>
      <td>-0.376043</td>
      <td>-0.754727</td>
      <td>-0.367950</td>
      <td>0.105677</td>
      <td>-0.078011</td>
      <td>0.192276</td>
      <td>-0.112464</td>
      <td>-0.060166</td>
      <td>0.794497</td>
      <td>-0.440910</td>
      <td>-0.469243</td>
      <td>-0.275687</td>
      <td>-0.860585</td>
      <td>-0.302862</td>
      <td>-0.826406</td>
      <td>...</td>
      <td>0.235849</td>
      <td>-0.557255</td>
      <td>-0.392084</td>
      <td>-0.215064</td>
      <td>1.116807</td>
      <td>0.654469</td>
      <td>0.810396</td>
      <td>0.737000</td>
      <td>0.636622</td>
      <td>0.918727</td>
      <td>0.497725</td>
      <td>-0.782411</td>
      <td>-0.725059</td>
      <td>-0.696788</td>
      <td>-0.086271</td>
      <td>0.706147</td>
      <td>0.149979</td>
      <td>0.341844</td>
      <td>-0.385712</td>
      <td>-0.007385</td>
      <td>-0.435674</td>
      <td>0.299693</td>
      <td>-0.527226</td>
      <td>-0.155214</td>
      <td>0.963387</td>
      <td>0.197813</td>
      <td>-0.037409</td>
      <td>0.759126</td>
      <td>-0.076258</td>
      <td>0.216526</td>
      <td>0.221396</td>
      <td>-1.735644</td>
      <td>0.157617</td>
      <td>-0.097127</td>
      <td>0.894894</td>
      <td>-0.817819</td>
      <td>-0.099891</td>
      <td>0.915379</td>
      <td>0.546037</td>
      <td>-0.145512</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.365201</td>
      <td>1.277776</td>
      <td>-0.364155</td>
      <td>0.382237</td>
      <td>0.988848</td>
      <td>0.577648</td>
      <td>-0.415663</td>
      <td>0.013660</td>
      <td>-0.339016</td>
      <td>-0.672042</td>
      <td>-0.259787</td>
      <td>-0.274428</td>
      <td>-0.487577</td>
      <td>0.842293</td>
      <td>1.340919</td>
      <td>0.130766</td>
      <td>0.646112</td>
      <td>-0.119599</td>
      <td>-0.343080</td>
      <td>0.464985</td>
      <td>-0.797305</td>
      <td>0.075657</td>
      <td>0.644509</td>
      <td>0.479591</td>
      <td>-0.096665</td>
      <td>-0.066234</td>
      <td>-0.891642</td>
      <td>-0.834992</td>
      <td>0.111313</td>
      <td>0.356854</td>
      <td>-0.281306</td>
      <td>0.316498</td>
      <td>-0.110931</td>
      <td>-0.165133</td>
      <td>0.353016</td>
      <td>-0.269203</td>
      <td>0.293477</td>
      <td>-0.697324</td>
      <td>-0.496891</td>
      <td>-1.169875</td>
      <td>...</td>
      <td>0.202160</td>
      <td>0.452495</td>
      <td>0.009715</td>
      <td>0.548263</td>
      <td>-0.641789</td>
      <td>-0.432788</td>
      <td>-0.968093</td>
      <td>0.584789</td>
      <td>1.358474</td>
      <td>-0.171202</td>
      <td>-0.535199</td>
      <td>-0.430905</td>
      <td>-0.342470</td>
      <td>-0.501972</td>
      <td>-0.476994</td>
      <td>0.418223</td>
      <td>0.253611</td>
      <td>-0.239476</td>
      <td>0.281479</td>
      <td>0.140177</td>
      <td>0.322103</td>
      <td>0.418609</td>
      <td>-1.248233</td>
      <td>-0.502180</td>
      <td>-0.175264</td>
      <td>1.238597</td>
      <td>0.602401</td>
      <td>-0.381169</td>
      <td>-0.011374</td>
      <td>0.688799</td>
      <td>-0.054782</td>
      <td>0.546401</td>
      <td>-0.650444</td>
      <td>-0.402792</td>
      <td>0.295964</td>
      <td>0.584794</td>
      <td>0.832859</td>
      <td>-0.387036</td>
      <td>0.969444</td>
      <td>0.797596</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.023696</td>
      <td>0.506527</td>
      <td>-0.198794</td>
      <td>0.193780</td>
      <td>-0.097641</td>
      <td>-0.548587</td>
      <td>0.437925</td>
      <td>0.571596</td>
      <td>0.444979</td>
      <td>-0.359636</td>
      <td>2.299970</td>
      <td>-0.015615</td>
      <td>0.519262</td>
      <td>-0.038431</td>
      <td>1.097494</td>
      <td>0.741967</td>
      <td>-0.349644</td>
      <td>-1.148195</td>
      <td>-1.271078</td>
      <td>-0.216762</td>
      <td>-0.638248</td>
      <td>0.446694</td>
      <td>0.478148</td>
      <td>-0.724304</td>
      <td>-0.285986</td>
      <td>-0.349099</td>
      <td>-0.418050</td>
      <td>-0.784054</td>
      <td>-0.224998</td>
      <td>-0.890769</td>
      <td>0.284219</td>
      <td>0.714548</td>
      <td>0.065859</td>
      <td>0.993991</td>
      <td>-0.101348</td>
      <td>-0.280861</td>
      <td>-1.235767</td>
      <td>-1.072923</td>
      <td>0.117487</td>
      <td>0.358350</td>
      <td>...</td>
      <td>0.173749</td>
      <td>0.150943</td>
      <td>-1.070241</td>
      <td>-0.239320</td>
      <td>-0.162012</td>
      <td>-0.496774</td>
      <td>-0.126237</td>
      <td>1.651229</td>
      <td>-0.211287</td>
      <td>-0.347382</td>
      <td>-0.481866</td>
      <td>-0.213362</td>
      <td>-0.423076</td>
      <td>-0.638994</td>
      <td>0.168472</td>
      <td>0.244574</td>
      <td>-0.944587</td>
      <td>-1.018688</td>
      <td>-0.496611</td>
      <td>-0.387327</td>
      <td>0.156310</td>
      <td>-1.014248</td>
      <td>-0.392324</td>
      <td>0.815819</td>
      <td>0.034459</td>
      <td>-0.229884</td>
      <td>-0.584368</td>
      <td>0.230601</td>
      <td>-0.112220</td>
      <td>-0.403909</td>
      <td>-0.311584</td>
      <td>-0.321711</td>
      <td>-0.096306</td>
      <td>-0.314516</td>
      <td>0.643245</td>
      <td>1.136623</td>
      <td>0.355677</td>
      <td>0.095034</td>
      <td>0.618764</td>
      <td>-0.179435</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 103 columns</p>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f219db4b0a0&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err        t          P&gt;|t|     2.5 %    97.5 %
D  1.088088  0.034595  31.4518  3.966357e-217  1.020282  1.155893
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  6.265 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>