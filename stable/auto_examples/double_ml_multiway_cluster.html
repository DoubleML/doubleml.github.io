
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-0.179398</td>
      <td>-0.152027</td>
      <td>-1.226566</td>
      <td>-0.379006</td>
      <td>-0.309926</td>
      <td>-0.161156</td>
      <td>0.197955</td>
      <td>0.028623</td>
      <td>0.260876</td>
      <td>0.162222</td>
      <td>0.329822</td>
      <td>0.036550</td>
      <td>-0.546838</td>
      <td>0.124822</td>
      <td>0.198086</td>
      <td>-0.313283</td>
      <td>-0.306816</td>
      <td>0.166590</td>
      <td>-0.396132</td>
      <td>-0.228607</td>
      <td>0.311968</td>
      <td>-0.164980</td>
      <td>0.406927</td>
      <td>0.436803</td>
      <td>0.217503</td>
      <td>-0.195635</td>
      <td>-0.222627</td>
      <td>0.369839</td>
      <td>-1.363108</td>
      <td>-0.631649</td>
      <td>0.658675</td>
      <td>0.482965</td>
      <td>0.052831</td>
      <td>0.029792</td>
      <td>0.798784</td>
      <td>0.268211</td>
      <td>-0.448341</td>
      <td>-1.024781</td>
      <td>-0.072865</td>
      <td>0.056378</td>
      <td>...</td>
      <td>0.457899</td>
      <td>-0.017857</td>
      <td>0.353800</td>
      <td>-0.242709</td>
      <td>-0.659114</td>
      <td>-0.346702</td>
      <td>-1.070043</td>
      <td>0.384233</td>
      <td>-0.228702</td>
      <td>-0.641066</td>
      <td>-0.425181</td>
      <td>-0.592000</td>
      <td>-0.306479</td>
      <td>-0.542312</td>
      <td>-0.717998</td>
      <td>-0.247292</td>
      <td>0.637597</td>
      <td>-0.597168</td>
      <td>-1.231927</td>
      <td>-1.836343</td>
      <td>-0.888904</td>
      <td>-0.365967</td>
      <td>0.128200</td>
      <td>-0.174094</td>
      <td>1.132090</td>
      <td>0.351222</td>
      <td>1.170024</td>
      <td>1.022336</td>
      <td>0.252769</td>
      <td>0.106482</td>
      <td>1.242250</td>
      <td>0.391723</td>
      <td>0.660836</td>
      <td>-0.790580</td>
      <td>0.144522</td>
      <td>0.042488</td>
      <td>0.215873</td>
      <td>-0.843478</td>
      <td>-0.768056</td>
      <td>-0.252448</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.766170</td>
      <td>0.044171</td>
      <td>-0.554399</td>
      <td>-0.408262</td>
      <td>0.092428</td>
      <td>-0.360137</td>
      <td>-0.533780</td>
      <td>0.302208</td>
      <td>0.480162</td>
      <td>-0.020056</td>
      <td>-0.615655</td>
      <td>0.503012</td>
      <td>-0.187982</td>
      <td>-0.043891</td>
      <td>1.163402</td>
      <td>0.845463</td>
      <td>0.400530</td>
      <td>0.536012</td>
      <td>0.526020</td>
      <td>0.288673</td>
      <td>0.744063</td>
      <td>0.479638</td>
      <td>0.743926</td>
      <td>-0.026645</td>
      <td>0.738107</td>
      <td>0.727900</td>
      <td>0.273220</td>
      <td>-0.877152</td>
      <td>-1.025697</td>
      <td>-0.758957</td>
      <td>-0.727301</td>
      <td>-1.548243</td>
      <td>-1.070983</td>
      <td>-0.286931</td>
      <td>0.759880</td>
      <td>0.325675</td>
      <td>-0.200598</td>
      <td>-0.244530</td>
      <td>0.131119</td>
      <td>-0.041648</td>
      <td>...</td>
      <td>0.074551</td>
      <td>-0.006278</td>
      <td>0.231144</td>
      <td>-0.220529</td>
      <td>0.847921</td>
      <td>-0.146467</td>
      <td>0.030565</td>
      <td>0.389607</td>
      <td>0.522760</td>
      <td>0.011140</td>
      <td>0.012029</td>
      <td>0.746487</td>
      <td>-0.571626</td>
      <td>-0.933462</td>
      <td>-0.644651</td>
      <td>-0.067317</td>
      <td>0.340435</td>
      <td>-0.366177</td>
      <td>-0.671161</td>
      <td>0.210972</td>
      <td>-0.465018</td>
      <td>0.181949</td>
      <td>-0.678147</td>
      <td>-0.493150</td>
      <td>0.455330</td>
      <td>0.883911</td>
      <td>0.375846</td>
      <td>-0.079830</td>
      <td>0.809599</td>
      <td>0.478115</td>
      <td>0.884401</td>
      <td>0.918577</td>
      <td>0.975636</td>
      <td>-0.076707</td>
      <td>0.499799</td>
      <td>1.043124</td>
      <td>0.405651</td>
      <td>-2.011108</td>
      <td>-1.944899</td>
      <td>-0.869425</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.683098</td>
      <td>0.176090</td>
      <td>-0.456874</td>
      <td>-0.579143</td>
      <td>0.150283</td>
      <td>0.021495</td>
      <td>0.633440</td>
      <td>-0.225400</td>
      <td>0.132339</td>
      <td>0.480299</td>
      <td>0.193592</td>
      <td>0.363291</td>
      <td>-0.806183</td>
      <td>-0.025520</td>
      <td>0.109715</td>
      <td>0.175669</td>
      <td>0.237972</td>
      <td>0.578763</td>
      <td>-0.995848</td>
      <td>-0.693134</td>
      <td>-1.085352</td>
      <td>0.315943</td>
      <td>0.341899</td>
      <td>0.864049</td>
      <td>-0.766281</td>
      <td>-0.211682</td>
      <td>-1.077235</td>
      <td>-0.741930</td>
      <td>-0.540953</td>
      <td>-0.752401</td>
      <td>-1.755893</td>
      <td>0.201979</td>
      <td>0.742602</td>
      <td>0.517180</td>
      <td>-0.087760</td>
      <td>-0.289214</td>
      <td>0.165293</td>
      <td>-0.296472</td>
      <td>-0.617167</td>
      <td>-1.157582</td>
      <td>...</td>
      <td>-0.883841</td>
      <td>-0.022342</td>
      <td>0.272136</td>
      <td>-0.502594</td>
      <td>0.741236</td>
      <td>0.189077</td>
      <td>0.449528</td>
      <td>-0.373757</td>
      <td>0.519159</td>
      <td>1.081222</td>
      <td>0.772042</td>
      <td>0.757481</td>
      <td>0.498806</td>
      <td>-0.553378</td>
      <td>-0.316341</td>
      <td>0.318299</td>
      <td>0.626226</td>
      <td>-1.371107</td>
      <td>-0.289991</td>
      <td>0.120130</td>
      <td>-1.002033</td>
      <td>0.016879</td>
      <td>0.628551</td>
      <td>-0.192831</td>
      <td>1.017726</td>
      <td>0.003213</td>
      <td>-0.535823</td>
      <td>0.260339</td>
      <td>-0.275430</td>
      <td>0.063344</td>
      <td>0.769811</td>
      <td>0.737439</td>
      <td>0.882999</td>
      <td>1.209711</td>
      <td>-0.401006</td>
      <td>-0.169313</td>
      <td>-0.704703</td>
      <td>-2.986242</td>
      <td>-2.048281</td>
      <td>-0.919272</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.058832</td>
      <td>0.670723</td>
      <td>-0.652989</td>
      <td>-0.916353</td>
      <td>-0.531860</td>
      <td>0.081664</td>
      <td>0.679056</td>
      <td>-0.308605</td>
      <td>-0.114716</td>
      <td>-0.387221</td>
      <td>-0.651154</td>
      <td>1.013110</td>
      <td>0.336126</td>
      <td>-0.353925</td>
      <td>-0.376751</td>
      <td>-0.965457</td>
      <td>-0.196108</td>
      <td>0.594568</td>
      <td>-0.259120</td>
      <td>0.186280</td>
      <td>-0.431085</td>
      <td>-0.557395</td>
      <td>0.528451</td>
      <td>0.179991</td>
      <td>-0.316469</td>
      <td>0.136480</td>
      <td>-0.376294</td>
      <td>-0.030463</td>
      <td>-0.129085</td>
      <td>-0.340243</td>
      <td>-0.307614</td>
      <td>0.100931</td>
      <td>-0.945686</td>
      <td>0.742854</td>
      <td>0.091354</td>
      <td>0.605736</td>
      <td>-0.064633</td>
      <td>0.173070</td>
      <td>-0.176616</td>
      <td>-0.101976</td>
      <td>...</td>
      <td>0.008702</td>
      <td>-0.099024</td>
      <td>0.158398</td>
      <td>-0.763047</td>
      <td>-0.107158</td>
      <td>-0.431518</td>
      <td>-0.824734</td>
      <td>0.822694</td>
      <td>0.623136</td>
      <td>0.472703</td>
      <td>-0.543629</td>
      <td>-0.150741</td>
      <td>-0.443049</td>
      <td>-0.053730</td>
      <td>0.239952</td>
      <td>0.449709</td>
      <td>0.133340</td>
      <td>-1.012026</td>
      <td>-0.610584</td>
      <td>-0.412093</td>
      <td>-0.003544</td>
      <td>0.133279</td>
      <td>0.490281</td>
      <td>0.282747</td>
      <td>0.538260</td>
      <td>-0.031862</td>
      <td>0.755516</td>
      <td>0.130383</td>
      <td>0.310953</td>
      <td>-0.911823</td>
      <td>0.074239</td>
      <td>-0.120487</td>
      <td>0.178994</td>
      <td>-0.462784</td>
      <td>-0.428566</td>
      <td>0.693387</td>
      <td>-0.445472</td>
      <td>0.336219</td>
      <td>0.742542</td>
      <td>0.504387</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.573355</td>
      <td>-0.688880</td>
      <td>-2.069332</td>
      <td>-0.510345</td>
      <td>-0.330054</td>
      <td>0.071141</td>
      <td>-0.242651</td>
      <td>-0.738560</td>
      <td>0.171744</td>
      <td>0.243771</td>
      <td>0.302087</td>
      <td>0.175195</td>
      <td>-0.082383</td>
      <td>1.117903</td>
      <td>0.985618</td>
      <td>0.638066</td>
      <td>0.001398</td>
      <td>-0.230354</td>
      <td>0.028138</td>
      <td>0.439737</td>
      <td>-0.098510</td>
      <td>0.068110</td>
      <td>-0.168266</td>
      <td>0.506626</td>
      <td>0.419168</td>
      <td>0.544043</td>
      <td>0.738665</td>
      <td>1.063058</td>
      <td>-0.013765</td>
      <td>0.252832</td>
      <td>-0.437738</td>
      <td>-0.624826</td>
      <td>-0.308198</td>
      <td>0.700059</td>
      <td>0.487268</td>
      <td>0.754884</td>
      <td>-0.653562</td>
      <td>-0.485288</td>
      <td>-0.673872</td>
      <td>-0.911609</td>
      <td>...</td>
      <td>-0.081793</td>
      <td>-0.359811</td>
      <td>-0.213167</td>
      <td>-1.133944</td>
      <td>-0.564489</td>
      <td>-0.351307</td>
      <td>1.141754</td>
      <td>-1.155509</td>
      <td>0.175107</td>
      <td>0.882020</td>
      <td>0.973713</td>
      <td>0.061638</td>
      <td>0.227806</td>
      <td>-0.549423</td>
      <td>-0.340611</td>
      <td>0.301902</td>
      <td>0.584178</td>
      <td>-0.563804</td>
      <td>-0.330049</td>
      <td>-0.675399</td>
      <td>-0.004164</td>
      <td>0.357137</td>
      <td>-0.040241</td>
      <td>-0.239314</td>
      <td>0.477948</td>
      <td>0.230679</td>
      <td>0.105349</td>
      <td>1.275319</td>
      <td>0.728656</td>
      <td>0.058310</td>
      <td>0.102761</td>
      <td>-0.219763</td>
      <td>-0.456168</td>
      <td>0.317409</td>
      <td>-0.836023</td>
      <td>0.194530</td>
      <td>-0.767804</td>
      <td>-3.514754</td>
      <td>-2.426309</td>
      <td>-0.454758</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.585154</td>
      <td>0.795580</td>
      <td>-0.908914</td>
      <td>-1.056621</td>
      <td>-1.276110</td>
      <td>0.209939</td>
      <td>-0.524601</td>
      <td>-0.500217</td>
      <td>0.576295</td>
      <td>-0.011369</td>
      <td>-0.843011</td>
      <td>-0.681957</td>
      <td>-0.168135</td>
      <td>0.135095</td>
      <td>0.043271</td>
      <td>-0.170506</td>
      <td>-1.145761</td>
      <td>0.432230</td>
      <td>0.386282</td>
      <td>-0.049526</td>
      <td>0.345616</td>
      <td>-1.116551</td>
      <td>0.442480</td>
      <td>0.676186</td>
      <td>0.251196</td>
      <td>-0.127172</td>
      <td>-0.247251</td>
      <td>-0.051205</td>
      <td>0.287019</td>
      <td>-0.751384</td>
      <td>0.223831</td>
      <td>0.535458</td>
      <td>0.260784</td>
      <td>-0.001668</td>
      <td>0.460137</td>
      <td>0.689624</td>
      <td>0.472169</td>
      <td>0.250244</td>
      <td>-0.409814</td>
      <td>-0.459476</td>
      <td>...</td>
      <td>-0.196938</td>
      <td>0.173351</td>
      <td>0.043187</td>
      <td>-0.934093</td>
      <td>0.476676</td>
      <td>-1.456804</td>
      <td>-0.595125</td>
      <td>-0.330219</td>
      <td>0.864007</td>
      <td>0.997517</td>
      <td>0.451313</td>
      <td>0.321715</td>
      <td>-0.714368</td>
      <td>-0.134245</td>
      <td>-0.534523</td>
      <td>0.442343</td>
      <td>1.149995</td>
      <td>0.946417</td>
      <td>0.729817</td>
      <td>-0.347231</td>
      <td>0.418859</td>
      <td>0.394455</td>
      <td>0.133455</td>
      <td>-0.285958</td>
      <td>0.315721</td>
      <td>0.339070</td>
      <td>1.182991</td>
      <td>-0.216309</td>
      <td>-0.311981</td>
      <td>0.345239</td>
      <td>0.480260</td>
      <td>0.361898</td>
      <td>-0.240675</td>
      <td>0.253922</td>
      <td>0.116090</td>
      <td>-0.355216</td>
      <td>0.013970</td>
      <td>-0.527939</td>
      <td>-0.097010</td>
      <td>-0.517732</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.300634</td>
      <td>-0.071915</td>
      <td>-0.439174</td>
      <td>-0.417693</td>
      <td>0.484299</td>
      <td>0.406662</td>
      <td>0.146635</td>
      <td>-0.362833</td>
      <td>0.507816</td>
      <td>-0.597524</td>
      <td>0.281204</td>
      <td>-0.164036</td>
      <td>-1.117336</td>
      <td>-0.536083</td>
      <td>0.277416</td>
      <td>0.785682</td>
      <td>0.099486</td>
      <td>1.217244</td>
      <td>-0.370712</td>
      <td>-0.386897</td>
      <td>-1.144242</td>
      <td>0.616566</td>
      <td>-0.075449</td>
      <td>-0.517781</td>
      <td>0.571698</td>
      <td>0.563806</td>
      <td>-0.683367</td>
      <td>-0.625520</td>
      <td>-0.143465</td>
      <td>-0.512647</td>
      <td>-0.135177</td>
      <td>0.335485</td>
      <td>-0.146964</td>
      <td>0.978512</td>
      <td>-0.115124</td>
      <td>-0.178543</td>
      <td>0.477458</td>
      <td>-0.223906</td>
      <td>0.310280</td>
      <td>0.340960</td>
      <td>...</td>
      <td>0.795790</td>
      <td>-0.587426</td>
      <td>-0.825280</td>
      <td>1.139232</td>
      <td>0.727305</td>
      <td>0.066957</td>
      <td>0.237295</td>
      <td>0.351030</td>
      <td>0.392338</td>
      <td>0.589981</td>
      <td>0.478697</td>
      <td>0.176340</td>
      <td>0.667257</td>
      <td>0.377691</td>
      <td>0.437405</td>
      <td>0.292914</td>
      <td>0.206629</td>
      <td>-1.413106</td>
      <td>-0.618019</td>
      <td>0.158828</td>
      <td>-0.138615</td>
      <td>-0.304092</td>
      <td>-0.754827</td>
      <td>-1.364011</td>
      <td>-0.291317</td>
      <td>-0.001372</td>
      <td>-0.457050</td>
      <td>-0.783119</td>
      <td>-0.433259</td>
      <td>-0.591037</td>
      <td>0.515565</td>
      <td>1.504738</td>
      <td>1.208121</td>
      <td>0.636170</td>
      <td>-0.497106</td>
      <td>0.139824</td>
      <td>-0.026066</td>
      <td>-0.359267</td>
      <td>0.122287</td>
      <td>0.785690</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.647997</td>
      <td>-0.316799</td>
      <td>-0.284882</td>
      <td>-0.174557</td>
      <td>-0.516089</td>
      <td>-0.040528</td>
      <td>-0.143225</td>
      <td>0.686333</td>
      <td>1.487590</td>
      <td>-0.410347</td>
      <td>-0.670215</td>
      <td>-0.094991</td>
      <td>-0.543190</td>
      <td>0.066340</td>
      <td>1.166090</td>
      <td>0.253335</td>
      <td>0.668714</td>
      <td>1.036840</td>
      <td>-0.495215</td>
      <td>0.640307</td>
      <td>-0.507832</td>
      <td>-0.901974</td>
      <td>-0.253874</td>
      <td>0.916346</td>
      <td>0.392823</td>
      <td>0.512498</td>
      <td>-0.171730</td>
      <td>-1.242191</td>
      <td>-1.678892</td>
      <td>0.013170</td>
      <td>-0.198510</td>
      <td>0.212118</td>
      <td>0.087370</td>
      <td>1.239891</td>
      <td>0.415435</td>
      <td>0.766693</td>
      <td>-0.766374</td>
      <td>-0.333085</td>
      <td>0.582809</td>
      <td>-0.040919</td>
      <td>...</td>
      <td>0.261522</td>
      <td>-0.108805</td>
      <td>-0.652478</td>
      <td>-0.001898</td>
      <td>1.249802</td>
      <td>-0.029858</td>
      <td>-0.226762</td>
      <td>0.215031</td>
      <td>0.584318</td>
      <td>-0.387075</td>
      <td>0.392342</td>
      <td>0.073472</td>
      <td>-0.546044</td>
      <td>-0.871947</td>
      <td>-0.206484</td>
      <td>0.250432</td>
      <td>0.098084</td>
      <td>-0.099908</td>
      <td>-0.593527</td>
      <td>-0.618398</td>
      <td>-1.181822</td>
      <td>-0.172338</td>
      <td>-0.269357</td>
      <td>-0.934100</td>
      <td>0.108757</td>
      <td>0.097070</td>
      <td>0.532508</td>
      <td>1.172534</td>
      <td>-0.503485</td>
      <td>-0.551385</td>
      <td>0.101857</td>
      <td>0.429207</td>
      <td>0.283538</td>
      <td>-0.073537</td>
      <td>1.456598</td>
      <td>-0.233523</td>
      <td>-1.146843</td>
      <td>-0.457599</td>
      <td>-0.794277</td>
      <td>0.203875</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.162337</td>
      <td>0.021835</td>
      <td>-0.236080</td>
      <td>-0.777393</td>
      <td>-0.100937</td>
      <td>-0.466061</td>
      <td>0.315973</td>
      <td>0.196465</td>
      <td>0.819011</td>
      <td>-0.399640</td>
      <td>0.222158</td>
      <td>0.576464</td>
      <td>-0.169467</td>
      <td>-0.514782</td>
      <td>0.234859</td>
      <td>-0.573847</td>
      <td>0.138051</td>
      <td>-0.478158</td>
      <td>-0.365103</td>
      <td>1.169402</td>
      <td>-0.394511</td>
      <td>0.254253</td>
      <td>-0.083374</td>
      <td>0.225158</td>
      <td>-0.612866</td>
      <td>-0.014193</td>
      <td>-0.049727</td>
      <td>-1.011948</td>
      <td>-1.251261</td>
      <td>-0.234808</td>
      <td>-0.233040</td>
      <td>-0.948633</td>
      <td>-0.218478</td>
      <td>0.818436</td>
      <td>0.274422</td>
      <td>0.032869</td>
      <td>-0.314158</td>
      <td>0.864233</td>
      <td>-0.243109</td>
      <td>0.446881</td>
      <td>...</td>
      <td>-0.143254</td>
      <td>-0.278427</td>
      <td>-0.177921</td>
      <td>-0.416791</td>
      <td>-1.013643</td>
      <td>-1.195703</td>
      <td>-1.166641</td>
      <td>0.773356</td>
      <td>-0.143860</td>
      <td>-0.182857</td>
      <td>-0.204700</td>
      <td>0.114418</td>
      <td>0.253902</td>
      <td>0.974920</td>
      <td>0.961119</td>
      <td>-0.212829</td>
      <td>0.501260</td>
      <td>0.328420</td>
      <td>0.109348</td>
      <td>0.386244</td>
      <td>0.064114</td>
      <td>-0.534192</td>
      <td>-0.289153</td>
      <td>-0.690969</td>
      <td>0.533228</td>
      <td>0.058359</td>
      <td>0.206164</td>
      <td>-0.155854</td>
      <td>0.927370</td>
      <td>-0.037953</td>
      <td>1.778531</td>
      <td>-0.134759</td>
      <td>-0.254242</td>
      <td>-0.358504</td>
      <td>0.429934</td>
      <td>-0.186659</td>
      <td>-0.364339</td>
      <td>1.799630</td>
      <td>-0.031755</td>
      <td>0.100363</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-1.141390</td>
      <td>0.466567</td>
      <td>0.118424</td>
      <td>0.517381</td>
      <td>-1.413101</td>
      <td>-0.965083</td>
      <td>0.445819</td>
      <td>-0.022838</td>
      <td>0.162268</td>
      <td>0.528453</td>
      <td>-0.142095</td>
      <td>0.599000</td>
      <td>-0.265109</td>
      <td>0.335227</td>
      <td>0.840157</td>
      <td>-0.833747</td>
      <td>-0.779333</td>
      <td>-0.670714</td>
      <td>-0.680591</td>
      <td>0.251152</td>
      <td>0.263976</td>
      <td>0.177755</td>
      <td>0.063906</td>
      <td>-1.611052</td>
      <td>-0.771264</td>
      <td>0.267632</td>
      <td>-0.077355</td>
      <td>0.134246</td>
      <td>0.013819</td>
      <td>-0.210077</td>
      <td>-0.027183</td>
      <td>-0.480574</td>
      <td>0.107405</td>
      <td>0.904040</td>
      <td>0.243471</td>
      <td>0.297451</td>
      <td>0.550932</td>
      <td>-0.310888</td>
      <td>-0.687775</td>
      <td>-0.788095</td>
      <td>...</td>
      <td>-0.155302</td>
      <td>0.146135</td>
      <td>-0.378249</td>
      <td>0.508712</td>
      <td>-0.224207</td>
      <td>0.208103</td>
      <td>0.121610</td>
      <td>0.117623</td>
      <td>0.646155</td>
      <td>1.140418</td>
      <td>0.537902</td>
      <td>0.968691</td>
      <td>-0.860881</td>
      <td>0.038026</td>
      <td>-0.219916</td>
      <td>0.315110</td>
      <td>0.678310</td>
      <td>0.711487</td>
      <td>-0.397660</td>
      <td>0.141200</td>
      <td>0.292385</td>
      <td>-0.088150</td>
      <td>-0.152348</td>
      <td>-0.713463</td>
      <td>0.831762</td>
      <td>-0.126671</td>
      <td>0.134786</td>
      <td>-0.648620</td>
      <td>-0.914568</td>
      <td>-0.000700</td>
      <td>0.980703</td>
      <td>0.676781</td>
      <td>0.685350</td>
      <td>0.365278</td>
      <td>-0.520701</td>
      <td>-0.166310</td>
      <td>1.113503</td>
      <td>-2.270468</td>
      <td>-1.834897</td>
      <td>-0.173754</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.530060</td>
      <td>-0.130391</td>
      <td>-0.042666</td>
      <td>-0.076532</td>
      <td>-1.228495</td>
      <td>0.453932</td>
      <td>-0.578865</td>
      <td>-0.940360</td>
      <td>0.236968</td>
      <td>-0.429789</td>
      <td>-0.187950</td>
      <td>-0.066101</td>
      <td>-0.728790</td>
      <td>1.771277</td>
      <td>1.281195</td>
      <td>0.269996</td>
      <td>-0.311193</td>
      <td>0.075707</td>
      <td>-0.094300</td>
      <td>0.061381</td>
      <td>0.248960</td>
      <td>-0.186898</td>
      <td>0.092530</td>
      <td>0.426568</td>
      <td>0.018008</td>
      <td>-0.503074</td>
      <td>-0.729304</td>
      <td>-0.987337</td>
      <td>0.487710</td>
      <td>-1.009596</td>
      <td>-1.080397</td>
      <td>-0.468276</td>
      <td>-0.319962</td>
      <td>-0.362413</td>
      <td>-0.277985</td>
      <td>0.279382</td>
      <td>-0.436233</td>
      <td>-0.210923</td>
      <td>0.097399</td>
      <td>-0.161913</td>
      <td>...</td>
      <td>-0.039512</td>
      <td>1.157694</td>
      <td>-0.258627</td>
      <td>0.025744</td>
      <td>0.905916</td>
      <td>0.264277</td>
      <td>-0.030152</td>
      <td>0.129106</td>
      <td>0.931107</td>
      <td>1.368065</td>
      <td>0.000658</td>
      <td>-0.373872</td>
      <td>0.003591</td>
      <td>0.102444</td>
      <td>0.514582</td>
      <td>0.041621</td>
      <td>1.008716</td>
      <td>-0.729097</td>
      <td>-0.068201</td>
      <td>-0.181824</td>
      <td>0.186331</td>
      <td>0.162833</td>
      <td>0.683743</td>
      <td>-0.769455</td>
      <td>0.361969</td>
      <td>-0.406243</td>
      <td>0.144612</td>
      <td>1.548934</td>
      <td>1.127186</td>
      <td>0.786859</td>
      <td>-0.354875</td>
      <td>-0.266703</td>
      <td>0.786058</td>
      <td>-0.221402</td>
      <td>0.463787</td>
      <td>0.940859</td>
      <td>-1.001086</td>
      <td>-0.878725</td>
      <td>-0.735386</td>
      <td>0.339837</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.119524</td>
      <td>0.852640</td>
      <td>0.224004</td>
      <td>-0.262223</td>
      <td>-0.469669</td>
      <td>-0.377540</td>
      <td>0.325125</td>
      <td>0.217303</td>
      <td>0.053424</td>
      <td>-1.168501</td>
      <td>-1.457833</td>
      <td>-0.564021</td>
      <td>-0.862816</td>
      <td>0.630285</td>
      <td>1.335565</td>
      <td>-0.318350</td>
      <td>-0.707692</td>
      <td>-0.664185</td>
      <td>-1.399170</td>
      <td>0.010154</td>
      <td>0.160021</td>
      <td>-0.676067</td>
      <td>0.733880</td>
      <td>0.727064</td>
      <td>-0.092695</td>
      <td>0.049121</td>
      <td>-0.589873</td>
      <td>-0.731146</td>
      <td>-1.208429</td>
      <td>-1.025595</td>
      <td>0.802274</td>
      <td>1.090395</td>
      <td>0.274093</td>
      <td>0.536151</td>
      <td>0.949191</td>
      <td>1.134609</td>
      <td>-0.625797</td>
      <td>-0.549373</td>
      <td>-0.629721</td>
      <td>-0.081816</td>
      <td>...</td>
      <td>0.250116</td>
      <td>0.682418</td>
      <td>-0.184760</td>
      <td>-1.013057</td>
      <td>-0.705817</td>
      <td>0.427089</td>
      <td>0.362015</td>
      <td>0.086698</td>
      <td>0.754238</td>
      <td>0.314978</td>
      <td>-0.365838</td>
      <td>0.198863</td>
      <td>-0.640724</td>
      <td>1.110007</td>
      <td>0.850014</td>
      <td>-0.136190</td>
      <td>0.857279</td>
      <td>0.319585</td>
      <td>-0.372137</td>
      <td>-0.280398</td>
      <td>-1.046515</td>
      <td>0.246905</td>
      <td>-0.646754</td>
      <td>-0.719480</td>
      <td>-0.386694</td>
      <td>-0.089344</td>
      <td>-0.543164</td>
      <td>1.456328</td>
      <td>-0.483941</td>
      <td>-1.041425</td>
      <td>-0.168375</td>
      <td>-0.050043</td>
      <td>1.184637</td>
      <td>0.895457</td>
      <td>0.806798</td>
      <td>-0.212675</td>
      <td>-1.037339</td>
      <td>0.314200</td>
      <td>-0.431056</td>
      <td>0.039306</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.036888</td>
      <td>-1.253208</td>
      <td>-1.353282</td>
      <td>0.310711</td>
      <td>0.011281</td>
      <td>0.100025</td>
      <td>0.283179</td>
      <td>-0.222629</td>
      <td>1.159668</td>
      <td>-0.187474</td>
      <td>0.148781</td>
      <td>-0.896947</td>
      <td>-1.146026</td>
      <td>0.172775</td>
      <td>0.917035</td>
      <td>-0.049211</td>
      <td>-0.396762</td>
      <td>-0.007726</td>
      <td>-0.122732</td>
      <td>0.082786</td>
      <td>0.686284</td>
      <td>1.364724</td>
      <td>-1.034415</td>
      <td>-0.482957</td>
      <td>0.127281</td>
      <td>1.260587</td>
      <td>0.599237</td>
      <td>0.302567</td>
      <td>-0.184426</td>
      <td>0.859683</td>
      <td>-0.241497</td>
      <td>0.810143</td>
      <td>0.296502</td>
      <td>0.777824</td>
      <td>-0.336812</td>
      <td>0.479259</td>
      <td>0.382037</td>
      <td>-0.937086</td>
      <td>0.006511</td>
      <td>0.028801</td>
      <td>...</td>
      <td>0.457703</td>
      <td>0.221798</td>
      <td>-0.513843</td>
      <td>-0.236135</td>
      <td>0.093075</td>
      <td>-0.281267</td>
      <td>-0.253325</td>
      <td>-0.161444</td>
      <td>0.297232</td>
      <td>-0.144442</td>
      <td>-0.009408</td>
      <td>0.193253</td>
      <td>-0.007182</td>
      <td>-0.100974</td>
      <td>-0.177340</td>
      <td>0.178432</td>
      <td>0.361702</td>
      <td>-0.794786</td>
      <td>-0.959248</td>
      <td>-0.980020</td>
      <td>-1.210388</td>
      <td>0.006014</td>
      <td>-0.197837</td>
      <td>1.085601</td>
      <td>-0.483069</td>
      <td>-0.347818</td>
      <td>0.504554</td>
      <td>-0.275541</td>
      <td>-0.841278</td>
      <td>-0.131993</td>
      <td>-0.382940</td>
      <td>-0.239473</td>
      <td>0.472750</td>
      <td>-0.464475</td>
      <td>-0.232325</td>
      <td>-0.749750</td>
      <td>-0.662247</td>
      <td>-1.208732</td>
      <td>-0.519355</td>
      <td>0.165184</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.624344</td>
      <td>0.071978</td>
      <td>-0.983528</td>
      <td>0.108670</td>
      <td>-0.134856</td>
      <td>0.002645</td>
      <td>-0.117418</td>
      <td>-1.236723</td>
      <td>0.716790</td>
      <td>-0.318620</td>
      <td>0.074664</td>
      <td>-0.410280</td>
      <td>-1.046427</td>
      <td>0.220278</td>
      <td>0.166668</td>
      <td>-1.126494</td>
      <td>-1.042856</td>
      <td>0.178308</td>
      <td>0.593300</td>
      <td>1.110993</td>
      <td>1.346040</td>
      <td>1.230720</td>
      <td>0.637230</td>
      <td>-0.049759</td>
      <td>-0.257788</td>
      <td>0.442050</td>
      <td>-0.284957</td>
      <td>-0.624014</td>
      <td>0.057143</td>
      <td>0.510502</td>
      <td>0.712169</td>
      <td>0.323146</td>
      <td>0.780907</td>
      <td>-0.507666</td>
      <td>-1.704168</td>
      <td>-1.093567</td>
      <td>-0.137897</td>
      <td>-0.488936</td>
      <td>-0.250969</td>
      <td>0.606522</td>
      <td>...</td>
      <td>-0.341392</td>
      <td>-0.525330</td>
      <td>-0.572882</td>
      <td>0.286543</td>
      <td>-0.050210</td>
      <td>-0.352010</td>
      <td>0.625337</td>
      <td>-0.185420</td>
      <td>-0.026054</td>
      <td>1.062592</td>
      <td>0.729115</td>
      <td>0.042408</td>
      <td>0.600819</td>
      <td>0.070409</td>
      <td>-0.408625</td>
      <td>0.046143</td>
      <td>0.679329</td>
      <td>0.463260</td>
      <td>0.730750</td>
      <td>0.862597</td>
      <td>-0.059376</td>
      <td>-0.109760</td>
      <td>-0.278206</td>
      <td>-0.206014</td>
      <td>-0.945413</td>
      <td>-1.090309</td>
      <td>-1.401693</td>
      <td>0.254120</td>
      <td>0.374126</td>
      <td>0.446691</td>
      <td>0.820252</td>
      <td>1.054758</td>
      <td>-0.333573</td>
      <td>-0.638185</td>
      <td>-0.857816</td>
      <td>-0.199583</td>
      <td>0.377351</td>
      <td>0.045788</td>
      <td>-0.504492</td>
      <td>-0.437958</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.014538</td>
      <td>0.361124</td>
      <td>-0.519197</td>
      <td>0.505161</td>
      <td>-1.118379</td>
      <td>-0.547103</td>
      <td>0.878230</td>
      <td>-0.550024</td>
      <td>0.251836</td>
      <td>-0.818951</td>
      <td>-0.106498</td>
      <td>0.149829</td>
      <td>0.470390</td>
      <td>0.911540</td>
      <td>0.445195</td>
      <td>0.400062</td>
      <td>-0.366759</td>
      <td>0.355160</td>
      <td>0.518793</td>
      <td>-0.523291</td>
      <td>-0.306464</td>
      <td>-0.593082</td>
      <td>0.086719</td>
      <td>0.690196</td>
      <td>0.680770</td>
      <td>0.164957</td>
      <td>-2.194687</td>
      <td>-0.264974</td>
      <td>-0.188589</td>
      <td>-0.242442</td>
      <td>-0.327569</td>
      <td>0.287186</td>
      <td>-0.638207</td>
      <td>-0.000581</td>
      <td>0.453174</td>
      <td>0.080125</td>
      <td>-0.279779</td>
      <td>-0.080234</td>
      <td>0.105263</td>
      <td>-0.068475</td>
      <td>...</td>
      <td>0.165591</td>
      <td>-0.821827</td>
      <td>-0.542298</td>
      <td>-0.358563</td>
      <td>0.712659</td>
      <td>-0.387584</td>
      <td>-0.635826</td>
      <td>-0.238834</td>
      <td>0.109040</td>
      <td>1.120548</td>
      <td>0.552689</td>
      <td>1.098770</td>
      <td>0.097676</td>
      <td>0.602214</td>
      <td>-0.261034</td>
      <td>-0.063694</td>
      <td>-0.033052</td>
      <td>0.050690</td>
      <td>-0.686552</td>
      <td>-0.499218</td>
      <td>-1.553409</td>
      <td>-0.994383</td>
      <td>-1.052859</td>
      <td>-0.187849</td>
      <td>-0.409720</td>
      <td>0.049359</td>
      <td>0.222058</td>
      <td>1.771317</td>
      <td>0.245564</td>
      <td>0.341134</td>
      <td>0.710908</td>
      <td>0.068640</td>
      <td>-0.765039</td>
      <td>-0.439010</td>
      <td>0.985971</td>
      <td>0.154514</td>
      <td>0.297852</td>
      <td>-0.641985</td>
      <td>-1.001340</td>
      <td>0.090108</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-0.133385</td>
      <td>0.217666</td>
      <td>-0.286040</td>
      <td>1.418733</td>
      <td>0.713440</td>
      <td>0.460055</td>
      <td>1.080626</td>
      <td>0.043560</td>
      <td>-0.141136</td>
      <td>-0.210333</td>
      <td>-0.219569</td>
      <td>0.861611</td>
      <td>-0.420310</td>
      <td>0.485376</td>
      <td>1.335345</td>
      <td>0.463696</td>
      <td>-1.517868</td>
      <td>0.455846</td>
      <td>0.417517</td>
      <td>0.324186</td>
      <td>-0.413923</td>
      <td>-0.104030</td>
      <td>-1.070792</td>
      <td>-0.187547</td>
      <td>0.376573</td>
      <td>0.255543</td>
      <td>-0.964991</td>
      <td>1.273769</td>
      <td>-0.018542</td>
      <td>0.670889</td>
      <td>-0.520950</td>
      <td>0.542381</td>
      <td>0.269868</td>
      <td>1.628030</td>
      <td>0.335357</td>
      <td>1.329739</td>
      <td>0.907524</td>
      <td>-0.042868</td>
      <td>0.692291</td>
      <td>0.514526</td>
      <td>...</td>
      <td>-1.284779</td>
      <td>0.060838</td>
      <td>0.312436</td>
      <td>-0.294083</td>
      <td>0.195734</td>
      <td>0.251123</td>
      <td>0.257778</td>
      <td>0.882237</td>
      <td>1.269818</td>
      <td>0.951311</td>
      <td>1.275958</td>
      <td>0.732830</td>
      <td>-0.190649</td>
      <td>-0.430419</td>
      <td>-0.010228</td>
      <td>-1.013916</td>
      <td>1.314971</td>
      <td>0.594636</td>
      <td>-0.093348</td>
      <td>-0.715395</td>
      <td>-0.416184</td>
      <td>0.115831</td>
      <td>0.070827</td>
      <td>0.222122</td>
      <td>-0.337363</td>
      <td>-0.744616</td>
      <td>1.163270</td>
      <td>-0.458518</td>
      <td>-0.293998</td>
      <td>0.192885</td>
      <td>0.322676</td>
      <td>-0.382664</td>
      <td>0.544679</td>
      <td>-0.284158</td>
      <td>0.503844</td>
      <td>1.054500</td>
      <td>-0.180889</td>
      <td>0.330962</td>
      <td>0.542845</td>
      <td>0.785516</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.711160</td>
      <td>0.943955</td>
      <td>-0.458633</td>
      <td>-0.010307</td>
      <td>-1.098425</td>
      <td>-1.678962</td>
      <td>-0.387045</td>
      <td>-0.363345</td>
      <td>0.909291</td>
      <td>0.021004</td>
      <td>-0.447677</td>
      <td>0.208322</td>
      <td>-0.040739</td>
      <td>-0.460383</td>
      <td>0.688482</td>
      <td>0.435884</td>
      <td>0.062156</td>
      <td>0.577677</td>
      <td>-0.253343</td>
      <td>0.726163</td>
      <td>0.297679</td>
      <td>0.173803</td>
      <td>-0.294797</td>
      <td>-0.394549</td>
      <td>0.075608</td>
      <td>-0.030067</td>
      <td>-0.549029</td>
      <td>0.235789</td>
      <td>-0.602287</td>
      <td>-0.135077</td>
      <td>-0.897135</td>
      <td>0.314150</td>
      <td>0.349907</td>
      <td>-0.304645</td>
      <td>-0.229461</td>
      <td>0.508554</td>
      <td>1.089165</td>
      <td>-0.140753</td>
      <td>0.397213</td>
      <td>-0.630701</td>
      <td>...</td>
      <td>0.236345</td>
      <td>-0.600081</td>
      <td>0.450871</td>
      <td>-0.333511</td>
      <td>-0.351340</td>
      <td>-0.857886</td>
      <td>-0.607774</td>
      <td>0.555264</td>
      <td>0.537292</td>
      <td>-0.370588</td>
      <td>-0.696583</td>
      <td>-0.672199</td>
      <td>0.924317</td>
      <td>0.051561</td>
      <td>0.291967</td>
      <td>0.824028</td>
      <td>0.257492</td>
      <td>-0.608118</td>
      <td>-0.454168</td>
      <td>0.070241</td>
      <td>0.453913</td>
      <td>-0.096793</td>
      <td>-0.274346</td>
      <td>-0.667988</td>
      <td>0.048622</td>
      <td>-0.413854</td>
      <td>0.287003</td>
      <td>-0.438070</td>
      <td>-0.493054</td>
      <td>0.069677</td>
      <td>0.102686</td>
      <td>0.519365</td>
      <td>-0.066611</td>
      <td>0.772480</td>
      <td>-0.124105</td>
      <td>0.359282</td>
      <td>-1.325904</td>
      <td>-0.062636</td>
      <td>-0.306958</td>
      <td>0.215782</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.510412</td>
      <td>-0.690811</td>
      <td>-0.622965</td>
      <td>0.490577</td>
      <td>0.118832</td>
      <td>-0.011821</td>
      <td>0.712340</td>
      <td>-0.204313</td>
      <td>0.048829</td>
      <td>0.719470</td>
      <td>0.613360</td>
      <td>0.025507</td>
      <td>-0.016414</td>
      <td>-0.013434</td>
      <td>0.427560</td>
      <td>-0.688539</td>
      <td>-1.216489</td>
      <td>-0.291784</td>
      <td>-0.160945</td>
      <td>-0.044120</td>
      <td>-0.756677</td>
      <td>0.470010</td>
      <td>0.573547</td>
      <td>0.528959</td>
      <td>0.626245</td>
      <td>-0.301843</td>
      <td>-0.194992</td>
      <td>0.106559</td>
      <td>-0.013894</td>
      <td>-0.370132</td>
      <td>-1.001897</td>
      <td>0.195458</td>
      <td>0.239227</td>
      <td>0.794534</td>
      <td>-0.440439</td>
      <td>0.675755</td>
      <td>0.466444</td>
      <td>0.168034</td>
      <td>-0.056977</td>
      <td>0.379933</td>
      <td>...</td>
      <td>-0.067844</td>
      <td>0.224334</td>
      <td>0.817573</td>
      <td>0.303978</td>
      <td>0.705539</td>
      <td>0.154099</td>
      <td>0.017361</td>
      <td>0.372792</td>
      <td>0.863932</td>
      <td>0.921971</td>
      <td>0.590374</td>
      <td>-0.043329</td>
      <td>0.060791</td>
      <td>-0.589881</td>
      <td>-0.063090</td>
      <td>-0.552535</td>
      <td>0.770178</td>
      <td>-0.391426</td>
      <td>-0.178286</td>
      <td>0.180326</td>
      <td>-0.512918</td>
      <td>-0.101161</td>
      <td>-0.524571</td>
      <td>-0.339442</td>
      <td>0.198671</td>
      <td>-0.313470</td>
      <td>-0.663250</td>
      <td>0.174253</td>
      <td>0.829546</td>
      <td>0.650094</td>
      <td>0.189159</td>
      <td>0.212992</td>
      <td>0.538544</td>
      <td>0.583975</td>
      <td>0.754801</td>
      <td>-0.032737</td>
      <td>1.065043</td>
      <td>-2.362813</td>
      <td>-1.889249</td>
      <td>-0.869969</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.581872</td>
      <td>-0.734108</td>
      <td>-0.226886</td>
      <td>0.315241</td>
      <td>0.564357</td>
      <td>0.930622</td>
      <td>-0.395261</td>
      <td>-1.095626</td>
      <td>-0.717350</td>
      <td>-1.311170</td>
      <td>-0.125511</td>
      <td>0.310444</td>
      <td>0.199628</td>
      <td>-0.302693</td>
      <td>0.573878</td>
      <td>1.191672</td>
      <td>0.665929</td>
      <td>1.319274</td>
      <td>0.255377</td>
      <td>0.014733</td>
      <td>-0.189416</td>
      <td>0.780467</td>
      <td>0.467579</td>
      <td>1.168471</td>
      <td>0.207278</td>
      <td>-0.122849</td>
      <td>-0.447088</td>
      <td>-0.622617</td>
      <td>0.011008</td>
      <td>0.175717</td>
      <td>0.031587</td>
      <td>-0.178379</td>
      <td>-0.995842</td>
      <td>0.322538</td>
      <td>-0.038866</td>
      <td>0.663003</td>
      <td>0.243323</td>
      <td>-0.255993</td>
      <td>-0.233294</td>
      <td>-0.342014</td>
      <td>...</td>
      <td>-0.729535</td>
      <td>0.178430</td>
      <td>0.211104</td>
      <td>0.174506</td>
      <td>0.250538</td>
      <td>-0.455297</td>
      <td>0.002892</td>
      <td>0.614777</td>
      <td>0.518205</td>
      <td>0.116486</td>
      <td>-0.168908</td>
      <td>0.045965</td>
      <td>1.847411</td>
      <td>2.051831</td>
      <td>-0.003969</td>
      <td>-0.907338</td>
      <td>1.162499</td>
      <td>-1.241158</td>
      <td>-1.596073</td>
      <td>-0.716020</td>
      <td>-0.452002</td>
      <td>-0.187468</td>
      <td>0.713640</td>
      <td>-0.989443</td>
      <td>-0.238955</td>
      <td>0.162122</td>
      <td>0.648808</td>
      <td>1.243772</td>
      <td>-0.290152</td>
      <td>0.202998</td>
      <td>0.595804</td>
      <td>0.145171</td>
      <td>0.839991</td>
      <td>0.304051</td>
      <td>-0.825252</td>
      <td>-0.687837</td>
      <td>-0.402323</td>
      <td>-0.795113</td>
      <td>-0.268530</td>
      <td>0.022224</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.726979</td>
      <td>0.233959</td>
      <td>-1.288134</td>
      <td>-1.346798</td>
      <td>-0.383101</td>
      <td>-0.226925</td>
      <td>0.954640</td>
      <td>-0.090780</td>
      <td>0.467500</td>
      <td>-0.008448</td>
      <td>-0.254887</td>
      <td>-0.333752</td>
      <td>-0.649926</td>
      <td>-0.662670</td>
      <td>0.753354</td>
      <td>-0.430546</td>
      <td>-0.324280</td>
      <td>0.505679</td>
      <td>-0.168257</td>
      <td>-0.149932</td>
      <td>-0.848981</td>
      <td>0.308500</td>
      <td>-0.463093</td>
      <td>-0.644056</td>
      <td>0.438680</td>
      <td>0.571428</td>
      <td>-0.427738</td>
      <td>0.033821</td>
      <td>0.046104</td>
      <td>0.951387</td>
      <td>0.554673</td>
      <td>0.265959</td>
      <td>0.118413</td>
      <td>0.847018</td>
      <td>0.204908</td>
      <td>-0.335657</td>
      <td>-0.571054</td>
      <td>-0.586885</td>
      <td>-0.273918</td>
      <td>-0.220400</td>
      <td>...</td>
      <td>-0.612724</td>
      <td>-1.325041</td>
      <td>-1.367894</td>
      <td>0.181893</td>
      <td>0.761004</td>
      <td>0.290689</td>
      <td>-0.549139</td>
      <td>-0.809101</td>
      <td>-0.174601</td>
      <td>0.040354</td>
      <td>-0.131349</td>
      <td>0.533639</td>
      <td>-0.118612</td>
      <td>0.036048</td>
      <td>0.249606</td>
      <td>0.335061</td>
      <td>0.449003</td>
      <td>-0.415515</td>
      <td>-0.160098</td>
      <td>0.564861</td>
      <td>-0.160077</td>
      <td>-0.046452</td>
      <td>-0.685995</td>
      <td>-0.327647</td>
      <td>-0.010741</td>
      <td>-0.662782</td>
      <td>-1.088816</td>
      <td>0.970466</td>
      <td>1.010005</td>
      <td>0.566799</td>
      <td>-0.868362</td>
      <td>0.144156</td>
      <td>-0.729648</td>
      <td>-0.250154</td>
      <td>-0.941915</td>
      <td>-0.345571</td>
      <td>-0.700707</td>
      <td>-3.188771</td>
      <td>-2.266924</td>
      <td>-1.695371</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-1.044377</td>
      <td>-1.122584</td>
      <td>-0.511140</td>
      <td>-0.215849</td>
      <td>-0.076746</td>
      <td>-0.792134</td>
      <td>1.057802</td>
      <td>0.522230</td>
      <td>0.560618</td>
      <td>0.017068</td>
      <td>-0.177213</td>
      <td>-0.561889</td>
      <td>-0.325777</td>
      <td>1.288195</td>
      <td>0.949623</td>
      <td>0.254330</td>
      <td>-0.533866</td>
      <td>0.234852</td>
      <td>-0.515732</td>
      <td>0.401346</td>
      <td>-0.745198</td>
      <td>0.055332</td>
      <td>-0.927325</td>
      <td>-0.743677</td>
      <td>-0.573261</td>
      <td>0.674831</td>
      <td>-0.752548</td>
      <td>-1.516575</td>
      <td>0.116736</td>
      <td>-0.202323</td>
      <td>-1.021992</td>
      <td>-0.208034</td>
      <td>-0.470570</td>
      <td>0.058129</td>
      <td>0.842001</td>
      <td>0.740349</td>
      <td>0.627138</td>
      <td>1.045396</td>
      <td>-0.130586</td>
      <td>-0.298399</td>
      <td>...</td>
      <td>0.633142</td>
      <td>0.960555</td>
      <td>-0.228861</td>
      <td>-0.338011</td>
      <td>0.354423</td>
      <td>0.418548</td>
      <td>-1.043583</td>
      <td>0.706162</td>
      <td>-0.046614</td>
      <td>-0.243006</td>
      <td>0.665613</td>
      <td>0.320740</td>
      <td>-0.407730</td>
      <td>0.174934</td>
      <td>0.057255</td>
      <td>0.318134</td>
      <td>1.185004</td>
      <td>-0.499622</td>
      <td>-1.480200</td>
      <td>-0.170806</td>
      <td>0.119056</td>
      <td>-0.354109</td>
      <td>-0.140957</td>
      <td>-0.310560</td>
      <td>-0.041602</td>
      <td>-1.371047</td>
      <td>-0.648497</td>
      <td>0.473145</td>
      <td>0.001263</td>
      <td>-0.094719</td>
      <td>-0.368776</td>
      <td>1.121279</td>
      <td>-0.322059</td>
      <td>-0.464274</td>
      <td>-0.905214</td>
      <td>-0.477599</td>
      <td>0.442037</td>
      <td>-4.083103</td>
      <td>-2.530399</td>
      <td>-1.069694</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.618414</td>
      <td>0.175885</td>
      <td>-0.659390</td>
      <td>-0.461665</td>
      <td>-0.194301</td>
      <td>0.379216</td>
      <td>0.494920</td>
      <td>-0.193263</td>
      <td>-0.002113</td>
      <td>-0.787657</td>
      <td>0.325731</td>
      <td>0.035975</td>
      <td>0.713843</td>
      <td>1.251098</td>
      <td>1.290168</td>
      <td>0.607833</td>
      <td>0.398186</td>
      <td>-0.201663</td>
      <td>0.492630</td>
      <td>0.497259</td>
      <td>0.078582</td>
      <td>0.194720</td>
      <td>0.093466</td>
      <td>-0.030728</td>
      <td>0.858605</td>
      <td>1.174037</td>
      <td>0.402963</td>
      <td>0.189584</td>
      <td>1.080107</td>
      <td>-1.346838</td>
      <td>-0.174152</td>
      <td>1.049141</td>
      <td>0.312241</td>
      <td>0.565931</td>
      <td>-0.025283</td>
      <td>-0.192636</td>
      <td>-0.488724</td>
      <td>0.209091</td>
      <td>0.383945</td>
      <td>-0.677078</td>
      <td>...</td>
      <td>0.393103</td>
      <td>0.189196</td>
      <td>-1.252521</td>
      <td>-0.389983</td>
      <td>0.053624</td>
      <td>-0.605749</td>
      <td>-0.497835</td>
      <td>1.108556</td>
      <td>-0.343272</td>
      <td>1.078050</td>
      <td>-0.144839</td>
      <td>-0.092008</td>
      <td>-0.824931</td>
      <td>0.580806</td>
      <td>-0.489133</td>
      <td>-0.607705</td>
      <td>-0.270299</td>
      <td>-0.461183</td>
      <td>-0.105775</td>
      <td>-0.881861</td>
      <td>-0.176094</td>
      <td>0.793490</td>
      <td>0.435756</td>
      <td>0.537819</td>
      <td>0.478981</td>
      <td>1.236712</td>
      <td>0.291399</td>
      <td>0.213484</td>
      <td>-0.138208</td>
      <td>0.112354</td>
      <td>0.725231</td>
      <td>-0.282360</td>
      <td>0.266861</td>
      <td>0.507126</td>
      <td>-1.624529</td>
      <td>-0.958757</td>
      <td>-0.822953</td>
      <td>-0.465884</td>
      <td>-1.374806</td>
      <td>-1.090996</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-1.306904</td>
      <td>0.195046</td>
      <td>-1.259521</td>
      <td>-0.718841</td>
      <td>-0.663720</td>
      <td>-0.652261</td>
      <td>-0.297439</td>
      <td>0.630451</td>
      <td>0.285427</td>
      <td>0.490057</td>
      <td>0.435900</td>
      <td>-0.862791</td>
      <td>-0.251067</td>
      <td>1.023551</td>
      <td>1.874742</td>
      <td>1.145308</td>
      <td>0.011487</td>
      <td>1.033801</td>
      <td>-0.452356</td>
      <td>0.568251</td>
      <td>0.497705</td>
      <td>1.120683</td>
      <td>0.773160</td>
      <td>-0.188916</td>
      <td>0.011667</td>
      <td>-0.581269</td>
      <td>0.805973</td>
      <td>-0.271167</td>
      <td>-0.097417</td>
      <td>0.435020</td>
      <td>0.553557</td>
      <td>0.390405</td>
      <td>0.832769</td>
      <td>0.568022</td>
      <td>0.603284</td>
      <td>-0.122887</td>
      <td>0.080648</td>
      <td>-0.902125</td>
      <td>-0.060826</td>
      <td>-0.804577</td>
      <td>...</td>
      <td>0.322233</td>
      <td>0.273178</td>
      <td>-0.151171</td>
      <td>-0.804959</td>
      <td>-0.129586</td>
      <td>-0.906589</td>
      <td>-0.403117</td>
      <td>1.079791</td>
      <td>1.454752</td>
      <td>1.257518</td>
      <td>0.738276</td>
      <td>0.255462</td>
      <td>-0.213205</td>
      <td>0.219494</td>
      <td>0.391590</td>
      <td>0.058537</td>
      <td>1.411284</td>
      <td>0.606471</td>
      <td>-0.026664</td>
      <td>-1.132938</td>
      <td>-0.587391</td>
      <td>-0.089163</td>
      <td>-0.479422</td>
      <td>0.764917</td>
      <td>-0.560298</td>
      <td>-0.311198</td>
      <td>-0.180872</td>
      <td>0.645000</td>
      <td>-0.243522</td>
      <td>0.023387</td>
      <td>0.583966</td>
      <td>-0.425854</td>
      <td>0.401846</td>
      <td>0.630264</td>
      <td>1.256099</td>
      <td>1.370188</td>
      <td>-0.884978</td>
      <td>-1.426843</td>
      <td>-0.631649</td>
      <td>-0.170065</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.581057</td>
      <td>0.543862</td>
      <td>-0.094243</td>
      <td>0.287282</td>
      <td>-0.018287</td>
      <td>0.130378</td>
      <td>0.267178</td>
      <td>0.381849</td>
      <td>0.050077</td>
      <td>-0.053463</td>
      <td>-0.266428</td>
      <td>0.552718</td>
      <td>0.601557</td>
      <td>-0.225957</td>
      <td>0.056729</td>
      <td>-0.931826</td>
      <td>-0.301685</td>
      <td>0.052578</td>
      <td>-1.382319</td>
      <td>0.665162</td>
      <td>0.135228</td>
      <td>-0.405788</td>
      <td>-1.114721</td>
      <td>0.424545</td>
      <td>0.438617</td>
      <td>0.130227</td>
      <td>0.115679</td>
      <td>-0.560109</td>
      <td>-0.309125</td>
      <td>0.504960</td>
      <td>1.398514</td>
      <td>0.714087</td>
      <td>-0.076539</td>
      <td>0.056428</td>
      <td>0.744228</td>
      <td>0.239993</td>
      <td>0.302006</td>
      <td>-0.105739</td>
      <td>0.041724</td>
      <td>-0.902220</td>
      <td>...</td>
      <td>0.387422</td>
      <td>0.605808</td>
      <td>0.286444</td>
      <td>-0.621974</td>
      <td>0.035700</td>
      <td>-1.325286</td>
      <td>0.007109</td>
      <td>0.059781</td>
      <td>1.224633</td>
      <td>-0.347572</td>
      <td>-0.362036</td>
      <td>0.271511</td>
      <td>-0.422033</td>
      <td>0.781235</td>
      <td>-0.810830</td>
      <td>0.516186</td>
      <td>0.140927</td>
      <td>-0.594074</td>
      <td>-0.464077</td>
      <td>-1.242447</td>
      <td>-0.384996</td>
      <td>-0.123765</td>
      <td>-0.174197</td>
      <td>0.309812</td>
      <td>0.423321</td>
      <td>-0.226964</td>
      <td>1.367696</td>
      <td>0.440116</td>
      <td>0.128155</td>
      <td>0.090635</td>
      <td>0.534613</td>
      <td>1.121193</td>
      <td>0.605604</td>
      <td>-0.670144</td>
      <td>-0.007239</td>
      <td>-0.642470</td>
      <td>-0.327524</td>
      <td>2.597421</td>
      <td>1.697975</td>
      <td>0.862518</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-1.074932</td>
      <td>0.414169</td>
      <td>-0.167604</td>
      <td>0.572198</td>
      <td>0.393656</td>
      <td>0.235771</td>
      <td>1.096213</td>
      <td>0.854256</td>
      <td>1.288080</td>
      <td>0.002065</td>
      <td>0.449308</td>
      <td>0.462959</td>
      <td>0.260740</td>
      <td>-0.136715</td>
      <td>-0.468253</td>
      <td>-0.083017</td>
      <td>0.054701</td>
      <td>1.112864</td>
      <td>0.710300</td>
      <td>0.140754</td>
      <td>-0.536594</td>
      <td>-0.001543</td>
      <td>0.473445</td>
      <td>0.690864</td>
      <td>0.523469</td>
      <td>-0.490630</td>
      <td>-0.652184</td>
      <td>-0.199142</td>
      <td>-0.208221</td>
      <td>0.707103</td>
      <td>1.202002</td>
      <td>0.324414</td>
      <td>0.530823</td>
      <td>0.079963</td>
      <td>0.503281</td>
      <td>0.087135</td>
      <td>-0.107505</td>
      <td>0.227277</td>
      <td>0.569419</td>
      <td>0.868814</td>
      <td>...</td>
      <td>-0.010652</td>
      <td>0.705954</td>
      <td>-0.284677</td>
      <td>-0.042806</td>
      <td>0.146222</td>
      <td>0.085408</td>
      <td>-0.653669</td>
      <td>-0.516898</td>
      <td>0.256543</td>
      <td>0.601547</td>
      <td>0.480665</td>
      <td>-0.079793</td>
      <td>-0.719545</td>
      <td>0.379137</td>
      <td>-0.010757</td>
      <td>0.132273</td>
      <td>0.800070</td>
      <td>-0.771183</td>
      <td>-1.049015</td>
      <td>0.489599</td>
      <td>-0.073835</td>
      <td>0.417855</td>
      <td>0.416835</td>
      <td>-0.390624</td>
      <td>0.607871</td>
      <td>1.054142</td>
      <td>-0.094933</td>
      <td>0.547461</td>
      <td>0.535564</td>
      <td>0.025776</td>
      <td>-0.093766</td>
      <td>-0.403069</td>
      <td>-0.341246</td>
      <td>-0.372939</td>
      <td>-0.312274</td>
      <td>-0.152871</td>
      <td>-0.205208</td>
      <td>-1.085184</td>
      <td>-0.530825</td>
      <td>-0.205504</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.617723</td>
      <td>0.539130</td>
      <td>-0.655187</td>
      <td>-0.501855</td>
      <td>-0.378440</td>
      <td>0.204104</td>
      <td>-0.395146</td>
      <td>0.472651</td>
      <td>0.222174</td>
      <td>-0.258372</td>
      <td>-0.199946</td>
      <td>0.401193</td>
      <td>-0.873121</td>
      <td>-1.219494</td>
      <td>0.512307</td>
      <td>-0.178974</td>
      <td>0.135296</td>
      <td>-0.628606</td>
      <td>-0.649194</td>
      <td>0.644626</td>
      <td>-0.494923</td>
      <td>-0.867088</td>
      <td>-0.568914</td>
      <td>0.108167</td>
      <td>-0.487062</td>
      <td>0.179641</td>
      <td>0.529315</td>
      <td>0.842301</td>
      <td>-0.128722</td>
      <td>-0.095326</td>
      <td>-0.334484</td>
      <td>-0.974809</td>
      <td>-0.413352</td>
      <td>0.307758</td>
      <td>-0.014056</td>
      <td>-0.021990</td>
      <td>-0.966704</td>
      <td>-0.620473</td>
      <td>-0.053581</td>
      <td>-0.131880</td>
      <td>...</td>
      <td>-0.805662</td>
      <td>0.509645</td>
      <td>-0.423291</td>
      <td>0.098773</td>
      <td>-0.321382</td>
      <td>-0.360478</td>
      <td>0.330088</td>
      <td>1.024161</td>
      <td>0.429182</td>
      <td>1.049007</td>
      <td>0.732991</td>
      <td>0.279844</td>
      <td>0.350634</td>
      <td>-0.019660</td>
      <td>0.970080</td>
      <td>-0.114340</td>
      <td>-0.507555</td>
      <td>0.778659</td>
      <td>0.327218</td>
      <td>0.064476</td>
      <td>0.416515</td>
      <td>1.227071</td>
      <td>0.974778</td>
      <td>0.061376</td>
      <td>0.754767</td>
      <td>-0.363316</td>
      <td>0.033619</td>
      <td>1.001793</td>
      <td>1.102914</td>
      <td>1.006112</td>
      <td>-0.070490</td>
      <td>0.871991</td>
      <td>0.137642</td>
      <td>-0.338122</td>
      <td>1.126033</td>
      <td>0.172656</td>
      <td>0.436985</td>
      <td>1.368477</td>
      <td>0.412058</td>
      <td>-0.468611</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.034171</td>
      <td>1.833027</td>
      <td>-0.229776</td>
      <td>-0.061774</td>
      <td>-0.565479</td>
      <td>0.440849</td>
      <td>0.399270</td>
      <td>0.502293</td>
      <td>1.414102</td>
      <td>0.848132</td>
      <td>-0.419568</td>
      <td>0.357425</td>
      <td>0.109140</td>
      <td>0.811955</td>
      <td>-1.410247</td>
      <td>-1.329722</td>
      <td>0.261455</td>
      <td>0.203862</td>
      <td>-0.353371</td>
      <td>1.641238</td>
      <td>0.170067</td>
      <td>-0.165296</td>
      <td>-0.481912</td>
      <td>0.152505</td>
      <td>0.123874</td>
      <td>0.168482</td>
      <td>0.129714</td>
      <td>-1.572229</td>
      <td>-0.338966</td>
      <td>-0.085640</td>
      <td>0.228892</td>
      <td>-1.426991</td>
      <td>-1.363728</td>
      <td>0.400599</td>
      <td>0.605004</td>
      <td>0.441197</td>
      <td>-0.427195</td>
      <td>1.042295</td>
      <td>0.528080</td>
      <td>0.424343</td>
      <td>...</td>
      <td>-0.639223</td>
      <td>-0.039637</td>
      <td>-0.675184</td>
      <td>-0.601892</td>
      <td>0.779481</td>
      <td>-0.723130</td>
      <td>1.263526</td>
      <td>0.194114</td>
      <td>0.057991</td>
      <td>-0.363601</td>
      <td>0.047106</td>
      <td>-0.828738</td>
      <td>-0.253084</td>
      <td>-1.054274</td>
      <td>-1.015627</td>
      <td>-0.721802</td>
      <td>0.318930</td>
      <td>0.295985</td>
      <td>0.339611</td>
      <td>0.118972</td>
      <td>0.046189</td>
      <td>0.521072</td>
      <td>-0.226357</td>
      <td>0.074172</td>
      <td>0.971067</td>
      <td>0.451571</td>
      <td>0.490885</td>
      <td>-0.140622</td>
      <td>0.126352</td>
      <td>0.234471</td>
      <td>0.040687</td>
      <td>0.772818</td>
      <td>1.325552</td>
      <td>0.020065</td>
      <td>0.142936</td>
      <td>-0.050771</td>
      <td>0.181297</td>
      <td>2.973693</td>
      <td>1.771036</td>
      <td>0.454614</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.169335</td>
      <td>0.225178</td>
      <td>-0.409083</td>
      <td>0.345456</td>
      <td>0.586512</td>
      <td>0.256866</td>
      <td>-0.512710</td>
      <td>-0.489140</td>
      <td>-0.203398</td>
      <td>-0.239584</td>
      <td>-0.691742</td>
      <td>0.236121</td>
      <td>-0.470725</td>
      <td>0.363398</td>
      <td>-0.210173</td>
      <td>0.211339</td>
      <td>0.417678</td>
      <td>-0.380933</td>
      <td>-0.430945</td>
      <td>0.240593</td>
      <td>-0.485067</td>
      <td>-0.396460</td>
      <td>-0.263211</td>
      <td>1.264977</td>
      <td>-0.644961</td>
      <td>-0.003541</td>
      <td>-0.672152</td>
      <td>0.396169</td>
      <td>-0.361592</td>
      <td>-0.613022</td>
      <td>0.098173</td>
      <td>0.079613</td>
      <td>-0.713585</td>
      <td>-0.061542</td>
      <td>-0.392730</td>
      <td>0.350426</td>
      <td>0.806693</td>
      <td>0.411632</td>
      <td>0.728658</td>
      <td>-0.203082</td>
      <td>...</td>
      <td>0.422158</td>
      <td>0.015823</td>
      <td>0.107220</td>
      <td>-0.410749</td>
      <td>0.329098</td>
      <td>-0.177680</td>
      <td>-0.281110</td>
      <td>-1.266974</td>
      <td>-1.350691</td>
      <td>0.046835</td>
      <td>-0.308870</td>
      <td>0.275711</td>
      <td>-0.280548</td>
      <td>-0.250227</td>
      <td>-0.051479</td>
      <td>-0.015494</td>
      <td>-0.777365</td>
      <td>0.382357</td>
      <td>0.199822</td>
      <td>0.727768</td>
      <td>0.616566</td>
      <td>0.267121</td>
      <td>-0.530387</td>
      <td>0.151759</td>
      <td>-0.273944</td>
      <td>0.000884</td>
      <td>0.417989</td>
      <td>-0.064027</td>
      <td>1.233106</td>
      <td>0.771928</td>
      <td>0.810478</td>
      <td>-0.236127</td>
      <td>-0.090543</td>
      <td>-0.968502</td>
      <td>0.118656</td>
      <td>0.511067</td>
      <td>0.264908</td>
      <td>-3.177427</td>
      <td>-1.988566</td>
      <td>-1.007753</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.115966</td>
      <td>1.002320</td>
      <td>0.027415</td>
      <td>-0.730825</td>
      <td>-1.462228</td>
      <td>-1.122375</td>
      <td>-0.919937</td>
      <td>0.037558</td>
      <td>-0.863507</td>
      <td>-0.589995</td>
      <td>-0.303940</td>
      <td>0.495878</td>
      <td>0.315675</td>
      <td>-0.299663</td>
      <td>0.022372</td>
      <td>-0.482727</td>
      <td>-1.000179</td>
      <td>-0.198997</td>
      <td>0.283473</td>
      <td>0.145185</td>
      <td>-0.454703</td>
      <td>-0.457335</td>
      <td>-0.132372</td>
      <td>-0.432147</td>
      <td>0.085058</td>
      <td>0.282752</td>
      <td>0.285627</td>
      <td>1.047444</td>
      <td>0.703778</td>
      <td>0.546941</td>
      <td>-1.366143</td>
      <td>-0.654396</td>
      <td>-0.658322</td>
      <td>0.730921</td>
      <td>0.389745</td>
      <td>1.162639</td>
      <td>-0.510107</td>
      <td>-0.448075</td>
      <td>0.823216</td>
      <td>-0.071937</td>
      <td>...</td>
      <td>-0.726059</td>
      <td>-0.166990</td>
      <td>-0.149384</td>
      <td>0.554007</td>
      <td>0.524369</td>
      <td>0.287492</td>
      <td>-0.209281</td>
      <td>1.043247</td>
      <td>-0.300334</td>
      <td>-0.063815</td>
      <td>-0.471118</td>
      <td>-0.925006</td>
      <td>-0.218826</td>
      <td>-0.318356</td>
      <td>0.562280</td>
      <td>1.253944</td>
      <td>-0.842949</td>
      <td>0.569998</td>
      <td>1.024576</td>
      <td>0.911815</td>
      <td>0.141579</td>
      <td>0.051836</td>
      <td>0.825358</td>
      <td>-0.205781</td>
      <td>0.019918</td>
      <td>0.674802</td>
      <td>0.091750</td>
      <td>0.435913</td>
      <td>-0.277016</td>
      <td>-0.604266</td>
      <td>-0.500442</td>
      <td>-1.423236</td>
      <td>0.000358</td>
      <td>-0.037043</td>
      <td>0.541858</td>
      <td>0.418662</td>
      <td>-0.653701</td>
      <td>-0.191417</td>
      <td>0.410237</td>
      <td>0.277595</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.169555</td>
      <td>0.139707</td>
      <td>-0.771957</td>
      <td>-0.395149</td>
      <td>0.328207</td>
      <td>-0.455188</td>
      <td>-0.271272</td>
      <td>-0.482257</td>
      <td>-0.376991</td>
      <td>-0.270273</td>
      <td>0.214893</td>
      <td>-0.476315</td>
      <td>0.297286</td>
      <td>0.237192</td>
      <td>0.036874</td>
      <td>-0.608895</td>
      <td>-0.526922</td>
      <td>0.564287</td>
      <td>-0.487145</td>
      <td>-0.988970</td>
      <td>-0.785386</td>
      <td>-0.920619</td>
      <td>-0.141869</td>
      <td>-0.369458</td>
      <td>0.581864</td>
      <td>-0.134581</td>
      <td>-1.148407</td>
      <td>0.565026</td>
      <td>0.097037</td>
      <td>-0.202968</td>
      <td>-0.610926</td>
      <td>-0.139557</td>
      <td>-0.485532</td>
      <td>-0.198624</td>
      <td>0.915236</td>
      <td>0.653755</td>
      <td>0.385967</td>
      <td>-0.175880</td>
      <td>-0.413325</td>
      <td>0.326992</td>
      <td>...</td>
      <td>-0.176734</td>
      <td>0.838948</td>
      <td>0.615025</td>
      <td>-0.788401</td>
      <td>-0.601107</td>
      <td>-0.533407</td>
      <td>0.148898</td>
      <td>-0.998685</td>
      <td>0.709252</td>
      <td>0.867864</td>
      <td>0.327249</td>
      <td>-0.276560</td>
      <td>0.480084</td>
      <td>0.398424</td>
      <td>-0.083161</td>
      <td>0.463348</td>
      <td>-0.208584</td>
      <td>0.370318</td>
      <td>-0.155402</td>
      <td>-0.452687</td>
      <td>0.718957</td>
      <td>-0.287702</td>
      <td>-1.242176</td>
      <td>0.178642</td>
      <td>-0.086471</td>
      <td>0.686014</td>
      <td>-0.995475</td>
      <td>0.320547</td>
      <td>0.938091</td>
      <td>-0.550282</td>
      <td>-0.542782</td>
      <td>-0.399172</td>
      <td>-0.275844</td>
      <td>0.290093</td>
      <td>-0.839160</td>
      <td>-0.667321</td>
      <td>0.324468</td>
      <td>-0.660136</td>
      <td>0.126537</td>
      <td>0.083204</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f5109890160&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>     coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.0855  0.042824  25.347706  9.525404e-142  1.001566  1.169435
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  6.650 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>