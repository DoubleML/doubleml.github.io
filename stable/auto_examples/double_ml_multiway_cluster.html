
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.1.1 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>     to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.132178</td>
      <td>0.377176</td>
      <td>0.667685</td>
      <td>-0.847793</td>
      <td>-0.080120</td>
      <td>0.799806</td>
      <td>-0.035891</td>
      <td>-1.026681</td>
      <td>-0.268133</td>
      <td>0.954672</td>
      <td>0.877105</td>
      <td>-1.547594</td>
      <td>0.086544</td>
      <td>-0.060578</td>
      <td>-0.243024</td>
      <td>-0.224211</td>
      <td>0.094252</td>
      <td>1.048407</td>
      <td>-0.065899</td>
      <td>1.286877</td>
      <td>1.728802</td>
      <td>-0.032005</td>
      <td>-0.029893</td>
      <td>-0.367433</td>
      <td>-0.027622</td>
      <td>-0.016274</td>
      <td>-0.759255</td>
      <td>0.325194</td>
      <td>0.922182</td>
      <td>0.929155</td>
      <td>0.446517</td>
      <td>0.284734</td>
      <td>-0.457234</td>
      <td>0.126731</td>
      <td>0.562205</td>
      <td>0.660521</td>
      <td>0.583299</td>
      <td>0.015453</td>
      <td>0.016766</td>
      <td>0.620006</td>
      <td>...</td>
      <td>0.380029</td>
      <td>0.562277</td>
      <td>-0.863132</td>
      <td>-0.840041</td>
      <td>-0.803220</td>
      <td>-0.548135</td>
      <td>-0.420827</td>
      <td>0.455954</td>
      <td>0.809807</td>
      <td>1.217881</td>
      <td>0.487964</td>
      <td>-0.230568</td>
      <td>-0.415758</td>
      <td>-0.659887</td>
      <td>0.836866</td>
      <td>-0.611103</td>
      <td>-1.247443</td>
      <td>-0.727362</td>
      <td>0.763312</td>
      <td>-1.004072</td>
      <td>0.058261</td>
      <td>-0.085985</td>
      <td>-0.555164</td>
      <td>-1.378908</td>
      <td>-0.884783</td>
      <td>0.142408</td>
      <td>-0.065701</td>
      <td>0.779200</td>
      <td>-0.704978</td>
      <td>-0.340949</td>
      <td>0.797571</td>
      <td>0.922853</td>
      <td>0.888787</td>
      <td>-0.076663</td>
      <td>0.393890</td>
      <td>-0.054365</td>
      <td>-0.408415</td>
      <td>1.406257</td>
      <td>0.677274</td>
      <td>0.339188</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.114633</td>
      <td>-0.142428</td>
      <td>0.786491</td>
      <td>-0.607264</td>
      <td>-0.531247</td>
      <td>-0.693508</td>
      <td>-0.358547</td>
      <td>-0.142854</td>
      <td>0.118616</td>
      <td>-0.670449</td>
      <td>0.957260</td>
      <td>0.292842</td>
      <td>0.950288</td>
      <td>1.165180</td>
      <td>1.400848</td>
      <td>0.857073</td>
      <td>-0.612021</td>
      <td>0.343203</td>
      <td>0.125427</td>
      <td>0.468989</td>
      <td>0.243064</td>
      <td>-0.492158</td>
      <td>-1.105733</td>
      <td>-0.527132</td>
      <td>1.080278</td>
      <td>0.519428</td>
      <td>-0.037426</td>
      <td>-0.505848</td>
      <td>0.420427</td>
      <td>0.443546</td>
      <td>0.910503</td>
      <td>0.001168</td>
      <td>-0.796518</td>
      <td>0.865204</td>
      <td>0.259632</td>
      <td>1.149797</td>
      <td>-1.034323</td>
      <td>-1.449206</td>
      <td>-0.505812</td>
      <td>1.368374</td>
      <td>...</td>
      <td>-0.282445</td>
      <td>0.309666</td>
      <td>-0.492329</td>
      <td>0.585384</td>
      <td>0.334188</td>
      <td>-0.192948</td>
      <td>-0.065721</td>
      <td>1.035432</td>
      <td>-0.102492</td>
      <td>0.060984</td>
      <td>-0.699207</td>
      <td>0.968221</td>
      <td>1.245122</td>
      <td>0.245571</td>
      <td>0.327096</td>
      <td>0.462428</td>
      <td>-0.866349</td>
      <td>-1.029934</td>
      <td>-0.588163</td>
      <td>-0.692578</td>
      <td>-0.134865</td>
      <td>-0.357502</td>
      <td>0.061849</td>
      <td>-1.128408</td>
      <td>0.250542</td>
      <td>0.263098</td>
      <td>0.311945</td>
      <td>0.756845</td>
      <td>-0.031570</td>
      <td>-1.428067</td>
      <td>-0.457563</td>
      <td>0.087238</td>
      <td>-0.265561</td>
      <td>0.864949</td>
      <td>0.413940</td>
      <td>-0.175607</td>
      <td>-0.485412</td>
      <td>3.207212</td>
      <td>2.467480</td>
      <td>1.485157</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.011632</td>
      <td>0.568267</td>
      <td>0.125253</td>
      <td>-0.555740</td>
      <td>-0.562053</td>
      <td>0.320353</td>
      <td>-0.344679</td>
      <td>0.239454</td>
      <td>-0.322013</td>
      <td>-0.534778</td>
      <td>1.043494</td>
      <td>-0.035659</td>
      <td>-0.334644</td>
      <td>-0.321342</td>
      <td>-0.709594</td>
      <td>-0.871793</td>
      <td>0.073674</td>
      <td>-1.302728</td>
      <td>-1.037216</td>
      <td>-0.304828</td>
      <td>0.513690</td>
      <td>0.436986</td>
      <td>0.564069</td>
      <td>0.503254</td>
      <td>0.225527</td>
      <td>-0.934660</td>
      <td>-0.968877</td>
      <td>-0.906874</td>
      <td>0.814996</td>
      <td>-0.432819</td>
      <td>-0.890418</td>
      <td>0.078560</td>
      <td>0.226595</td>
      <td>1.242548</td>
      <td>-0.593629</td>
      <td>0.416873</td>
      <td>1.163975</td>
      <td>-0.430847</td>
      <td>-0.625514</td>
      <td>0.523218</td>
      <td>...</td>
      <td>-0.171029</td>
      <td>0.431664</td>
      <td>0.485126</td>
      <td>0.681602</td>
      <td>0.554391</td>
      <td>-0.575263</td>
      <td>-0.021799</td>
      <td>-0.412689</td>
      <td>0.343950</td>
      <td>0.211818</td>
      <td>-0.105095</td>
      <td>-0.432051</td>
      <td>0.561717</td>
      <td>1.223971</td>
      <td>0.013762</td>
      <td>-0.429962</td>
      <td>-1.414624</td>
      <td>-0.124398</td>
      <td>0.373133</td>
      <td>-0.035858</td>
      <td>0.488293</td>
      <td>-0.530886</td>
      <td>0.545527</td>
      <td>0.141752</td>
      <td>-1.315147</td>
      <td>-0.535330</td>
      <td>0.579017</td>
      <td>1.491410</td>
      <td>0.275946</td>
      <td>-0.560099</td>
      <td>-0.502099</td>
      <td>0.750624</td>
      <td>-0.275626</td>
      <td>0.157237</td>
      <td>0.667150</td>
      <td>0.226208</td>
      <td>-0.150828</td>
      <td>-0.540271</td>
      <td>-0.326222</td>
      <td>-0.101473</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.820184</td>
      <td>0.394720</td>
      <td>-0.259198</td>
      <td>-0.017800</td>
      <td>0.107535</td>
      <td>0.485035</td>
      <td>-0.751834</td>
      <td>-0.623169</td>
      <td>0.112099</td>
      <td>0.102864</td>
      <td>-0.203845</td>
      <td>-0.498001</td>
      <td>0.341695</td>
      <td>0.100940</td>
      <td>0.314639</td>
      <td>-0.185894</td>
      <td>-0.021572</td>
      <td>1.396363</td>
      <td>-0.604795</td>
      <td>-0.256859</td>
      <td>0.246411</td>
      <td>-0.033495</td>
      <td>-0.232052</td>
      <td>0.600092</td>
      <td>1.365717</td>
      <td>-0.472437</td>
      <td>-1.163544</td>
      <td>-0.361467</td>
      <td>-0.675047</td>
      <td>0.644631</td>
      <td>0.513471</td>
      <td>0.765698</td>
      <td>0.004310</td>
      <td>0.549910</td>
      <td>-0.231052</td>
      <td>0.177475</td>
      <td>-0.405306</td>
      <td>-0.465278</td>
      <td>0.057372</td>
      <td>0.801035</td>
      <td>...</td>
      <td>0.054181</td>
      <td>-0.016257</td>
      <td>-0.047295</td>
      <td>-0.808574</td>
      <td>-0.711390</td>
      <td>-0.340992</td>
      <td>0.176597</td>
      <td>-0.412883</td>
      <td>-0.673379</td>
      <td>-0.159598</td>
      <td>-0.215649</td>
      <td>-0.252354</td>
      <td>-0.464104</td>
      <td>0.170499</td>
      <td>0.190174</td>
      <td>-0.638375</td>
      <td>-1.095923</td>
      <td>0.039382</td>
      <td>0.039963</td>
      <td>-0.184529</td>
      <td>0.457559</td>
      <td>-0.438182</td>
      <td>0.540138</td>
      <td>-0.789941</td>
      <td>-0.152180</td>
      <td>0.214475</td>
      <td>0.856432</td>
      <td>-0.519926</td>
      <td>0.124686</td>
      <td>-0.568747</td>
      <td>-0.076858</td>
      <td>0.448342</td>
      <td>0.549790</td>
      <td>0.487841</td>
      <td>-0.720441</td>
      <td>-1.017908</td>
      <td>0.768474</td>
      <td>1.946469</td>
      <td>2.531662</td>
      <td>1.258193</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.547015</td>
      <td>0.071786</td>
      <td>0.121662</td>
      <td>-0.011131</td>
      <td>0.730996</td>
      <td>1.324020</td>
      <td>0.037761</td>
      <td>-0.091769</td>
      <td>-0.105767</td>
      <td>-0.371771</td>
      <td>0.636292</td>
      <td>0.259778</td>
      <td>0.072819</td>
      <td>0.011998</td>
      <td>-0.912242</td>
      <td>-0.342672</td>
      <td>-0.545081</td>
      <td>-0.250440</td>
      <td>0.453378</td>
      <td>0.359042</td>
      <td>0.753796</td>
      <td>-0.512529</td>
      <td>0.591709</td>
      <td>0.476491</td>
      <td>0.675126</td>
      <td>0.750694</td>
      <td>0.668505</td>
      <td>0.314938</td>
      <td>0.772476</td>
      <td>0.498692</td>
      <td>0.058766</td>
      <td>-0.266273</td>
      <td>-0.944971</td>
      <td>-0.060998</td>
      <td>-0.026648</td>
      <td>-0.221259</td>
      <td>-0.154673</td>
      <td>0.062033</td>
      <td>-0.181364</td>
      <td>0.541632</td>
      <td>...</td>
      <td>-0.550253</td>
      <td>-0.005952</td>
      <td>-0.330318</td>
      <td>-1.017308</td>
      <td>0.310565</td>
      <td>-0.995820</td>
      <td>-0.189933</td>
      <td>0.364655</td>
      <td>-0.424486</td>
      <td>0.848579</td>
      <td>0.173427</td>
      <td>0.507989</td>
      <td>-0.187804</td>
      <td>-1.071193</td>
      <td>1.087807</td>
      <td>-0.689833</td>
      <td>-1.300545</td>
      <td>-0.485062</td>
      <td>0.204562</td>
      <td>0.213799</td>
      <td>0.525060</td>
      <td>0.251019</td>
      <td>0.432831</td>
      <td>-0.159855</td>
      <td>-0.878685</td>
      <td>0.133899</td>
      <td>0.204563</td>
      <td>0.052716</td>
      <td>0.704266</td>
      <td>0.766100</td>
      <td>0.797587</td>
      <td>-0.114779</td>
      <td>-0.434407</td>
      <td>-0.441757</td>
      <td>-0.714990</td>
      <td>0.293239</td>
      <td>-0.002566</td>
      <td>0.866759</td>
      <td>1.329016</td>
      <td>0.526678</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.703692</td>
      <td>0.119877</td>
      <td>0.836765</td>
      <td>0.246001</td>
      <td>1.287934</td>
      <td>0.209957</td>
      <td>-0.096899</td>
      <td>-0.489603</td>
      <td>-0.516282</td>
      <td>-0.021170</td>
      <td>-0.257248</td>
      <td>-0.421461</td>
      <td>0.381897</td>
      <td>-0.148286</td>
      <td>-0.360109</td>
      <td>0.020071</td>
      <td>0.829302</td>
      <td>0.180931</td>
      <td>0.363117</td>
      <td>0.006972</td>
      <td>-0.448596</td>
      <td>-0.019573</td>
      <td>0.028656</td>
      <td>-0.203859</td>
      <td>0.399764</td>
      <td>0.549103</td>
      <td>-0.077473</td>
      <td>-0.548188</td>
      <td>0.265155</td>
      <td>-0.258219</td>
      <td>0.022530</td>
      <td>0.535147</td>
      <td>-0.127189</td>
      <td>0.527522</td>
      <td>0.661295</td>
      <td>-0.340850</td>
      <td>-0.296106</td>
      <td>0.759926</td>
      <td>-0.133709</td>
      <td>0.364947</td>
      <td>...</td>
      <td>-0.516038</td>
      <td>0.087315</td>
      <td>-0.638179</td>
      <td>-0.796342</td>
      <td>0.018728</td>
      <td>-0.757525</td>
      <td>-0.448664</td>
      <td>-0.036725</td>
      <td>-0.615010</td>
      <td>0.228422</td>
      <td>-0.154375</td>
      <td>0.216234</td>
      <td>0.116937</td>
      <td>0.050777</td>
      <td>0.901337</td>
      <td>1.283028</td>
      <td>-0.163105</td>
      <td>-0.671932</td>
      <td>0.477973</td>
      <td>-0.232043</td>
      <td>-0.226651</td>
      <td>-0.594521</td>
      <td>0.203940</td>
      <td>-0.004431</td>
      <td>-0.953476</td>
      <td>0.241343</td>
      <td>0.355374</td>
      <td>-0.234344</td>
      <td>0.615781</td>
      <td>0.525413</td>
      <td>1.133572</td>
      <td>0.002566</td>
      <td>-0.657310</td>
      <td>1.475354</td>
      <td>0.942379</td>
      <td>0.125143</td>
      <td>-0.444658</td>
      <td>-1.440308</td>
      <td>-1.067924</td>
      <td>-0.663452</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.618279</td>
      <td>-0.250694</td>
      <td>1.444130</td>
      <td>-0.441563</td>
      <td>-0.467309</td>
      <td>-0.209237</td>
      <td>-0.494505</td>
      <td>0.378762</td>
      <td>0.729033</td>
      <td>0.571166</td>
      <td>0.074986</td>
      <td>-0.425638</td>
      <td>-0.499166</td>
      <td>-0.058700</td>
      <td>-0.383221</td>
      <td>-0.379151</td>
      <td>-0.092952</td>
      <td>0.471847</td>
      <td>-0.842460</td>
      <td>-0.071268</td>
      <td>-0.319028</td>
      <td>-0.703865</td>
      <td>0.145338</td>
      <td>-0.979066</td>
      <td>-0.813494</td>
      <td>1.022291</td>
      <td>0.789448</td>
      <td>0.710844</td>
      <td>-0.069359</td>
      <td>0.905160</td>
      <td>-0.032603</td>
      <td>0.198841</td>
      <td>-0.711941</td>
      <td>0.181311</td>
      <td>-0.438984</td>
      <td>1.152432</td>
      <td>-0.607782</td>
      <td>-0.364206</td>
      <td>-1.431743</td>
      <td>-0.067886</td>
      <td>...</td>
      <td>0.146851</td>
      <td>0.950022</td>
      <td>0.560576</td>
      <td>0.388976</td>
      <td>0.661399</td>
      <td>0.214267</td>
      <td>-0.360926</td>
      <td>1.011738</td>
      <td>0.279513</td>
      <td>0.265028</td>
      <td>-0.054792</td>
      <td>0.331299</td>
      <td>0.814339</td>
      <td>0.109143</td>
      <td>0.493123</td>
      <td>-0.238450</td>
      <td>-0.355062</td>
      <td>-1.193999</td>
      <td>-0.024778</td>
      <td>-0.373667</td>
      <td>-0.587284</td>
      <td>-0.154820</td>
      <td>0.127929</td>
      <td>0.199448</td>
      <td>-0.362325</td>
      <td>-0.926906</td>
      <td>-0.025158</td>
      <td>1.360407</td>
      <td>0.055090</td>
      <td>1.057738</td>
      <td>0.062414</td>
      <td>0.257376</td>
      <td>0.623741</td>
      <td>0.253706</td>
      <td>0.679845</td>
      <td>0.492950</td>
      <td>-0.539259</td>
      <td>-0.045656</td>
      <td>0.553442</td>
      <td>0.171374</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.486801</td>
      <td>-0.910926</td>
      <td>0.433200</td>
      <td>-0.896097</td>
      <td>0.098965</td>
      <td>0.108699</td>
      <td>-0.690195</td>
      <td>0.153237</td>
      <td>-0.186497</td>
      <td>-0.375587</td>
      <td>0.448907</td>
      <td>0.057625</td>
      <td>-0.258451</td>
      <td>-0.058075</td>
      <td>-0.265616</td>
      <td>-0.044066</td>
      <td>0.319668</td>
      <td>-0.008173</td>
      <td>-0.114548</td>
      <td>0.567885</td>
      <td>0.135464</td>
      <td>0.284927</td>
      <td>-0.000668</td>
      <td>-1.050890</td>
      <td>-0.222245</td>
      <td>-0.056369</td>
      <td>0.392766</td>
      <td>0.201028</td>
      <td>0.420281</td>
      <td>-0.352188</td>
      <td>0.125559</td>
      <td>0.247445</td>
      <td>0.362874</td>
      <td>0.038524</td>
      <td>0.641634</td>
      <td>-0.034781</td>
      <td>-0.006809</td>
      <td>-0.120361</td>
      <td>-0.413217</td>
      <td>0.864753</td>
      <td>...</td>
      <td>0.757334</td>
      <td>0.657182</td>
      <td>-0.020490</td>
      <td>-1.065368</td>
      <td>-0.487597</td>
      <td>-1.098900</td>
      <td>-0.041043</td>
      <td>-0.169672</td>
      <td>-0.305906</td>
      <td>-1.518095</td>
      <td>0.052892</td>
      <td>-0.574516</td>
      <td>-0.330720</td>
      <td>-0.320761</td>
      <td>-0.280276</td>
      <td>0.568376</td>
      <td>-0.694861</td>
      <td>-0.279631</td>
      <td>0.398723</td>
      <td>-0.243832</td>
      <td>-0.254112</td>
      <td>-1.533773</td>
      <td>-0.239825</td>
      <td>-0.201370</td>
      <td>0.090316</td>
      <td>-0.706170</td>
      <td>0.186426</td>
      <td>0.349130</td>
      <td>-0.688355</td>
      <td>-0.199386</td>
      <td>0.908470</td>
      <td>0.730086</td>
      <td>-0.160895</td>
      <td>-1.318359</td>
      <td>-0.704122</td>
      <td>0.652735</td>
      <td>0.022272</td>
      <td>0.247065</td>
      <td>0.440991</td>
      <td>-0.263787</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.307011</td>
      <td>-0.373505</td>
      <td>-0.393574</td>
      <td>-0.170118</td>
      <td>0.756040</td>
      <td>0.921662</td>
      <td>-0.197237</td>
      <td>-1.349336</td>
      <td>-0.168947</td>
      <td>-0.416143</td>
      <td>0.328245</td>
      <td>-0.796209</td>
      <td>0.733746</td>
      <td>0.586606</td>
      <td>0.440428</td>
      <td>-0.582710</td>
      <td>-0.813510</td>
      <td>0.108826</td>
      <td>0.307634</td>
      <td>0.106889</td>
      <td>-0.507164</td>
      <td>-0.571746</td>
      <td>-0.814329</td>
      <td>0.016720</td>
      <td>-0.541932</td>
      <td>-0.198005</td>
      <td>-1.044891</td>
      <td>-0.506276</td>
      <td>0.363834</td>
      <td>-0.493971</td>
      <td>0.431050</td>
      <td>0.574316</td>
      <td>-0.282375</td>
      <td>0.240836</td>
      <td>0.264766</td>
      <td>-0.149352</td>
      <td>0.242865</td>
      <td>0.232537</td>
      <td>0.692837</td>
      <td>1.000071</td>
      <td>...</td>
      <td>-0.316225</td>
      <td>-0.182547</td>
      <td>-0.999379</td>
      <td>-0.491464</td>
      <td>-0.492580</td>
      <td>-0.751011</td>
      <td>-0.367875</td>
      <td>-0.059238</td>
      <td>0.309888</td>
      <td>0.722643</td>
      <td>0.133570</td>
      <td>1.410768</td>
      <td>-0.143420</td>
      <td>0.167133</td>
      <td>0.086861</td>
      <td>-0.637971</td>
      <td>-1.717253</td>
      <td>-0.574669</td>
      <td>0.183926</td>
      <td>-0.131522</td>
      <td>-0.844891</td>
      <td>-0.167487</td>
      <td>-0.087810</td>
      <td>-0.487253</td>
      <td>-0.842698</td>
      <td>0.292765</td>
      <td>1.049567</td>
      <td>1.424633</td>
      <td>-0.346519</td>
      <td>-0.263821</td>
      <td>0.177685</td>
      <td>-0.805376</td>
      <td>0.485314</td>
      <td>0.769024</td>
      <td>-0.055078</td>
      <td>-0.402674</td>
      <td>0.360992</td>
      <td>1.326156</td>
      <td>1.577785</td>
      <td>0.191003</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.123696</td>
      <td>-0.274138</td>
      <td>0.044389</td>
      <td>0.497480</td>
      <td>-0.090325</td>
      <td>0.105373</td>
      <td>-0.408077</td>
      <td>-0.827444</td>
      <td>0.506973</td>
      <td>0.021466</td>
      <td>0.311280</td>
      <td>-0.852691</td>
      <td>-0.287731</td>
      <td>-0.168649</td>
      <td>-0.273632</td>
      <td>0.361613</td>
      <td>0.369922</td>
      <td>0.030418</td>
      <td>-1.188573</td>
      <td>-0.216098</td>
      <td>0.235855</td>
      <td>-0.247969</td>
      <td>-0.931768</td>
      <td>0.388227</td>
      <td>0.319796</td>
      <td>-0.066508</td>
      <td>-0.037792</td>
      <td>-0.321913</td>
      <td>-0.097195</td>
      <td>-0.198608</td>
      <td>-1.161155</td>
      <td>0.667524</td>
      <td>0.161612</td>
      <td>0.980641</td>
      <td>1.390098</td>
      <td>1.263303</td>
      <td>-1.065730</td>
      <td>-0.578411</td>
      <td>0.028401</td>
      <td>0.749470</td>
      <td>...</td>
      <td>0.014630</td>
      <td>0.755644</td>
      <td>1.009976</td>
      <td>0.228413</td>
      <td>-0.481933</td>
      <td>-0.197228</td>
      <td>-0.576037</td>
      <td>0.070259</td>
      <td>-0.776220</td>
      <td>-0.448719</td>
      <td>-0.215079</td>
      <td>-0.120169</td>
      <td>0.811407</td>
      <td>0.392200</td>
      <td>0.175780</td>
      <td>-0.002517</td>
      <td>-1.407515</td>
      <td>-1.547706</td>
      <td>-0.137878</td>
      <td>-0.446235</td>
      <td>-0.355981</td>
      <td>-0.557167</td>
      <td>0.849141</td>
      <td>-0.954079</td>
      <td>-0.680898</td>
      <td>0.275507</td>
      <td>-0.224135</td>
      <td>-0.019504</td>
      <td>-0.724020</td>
      <td>-0.618379</td>
      <td>-0.919449</td>
      <td>0.317157</td>
      <td>-1.116257</td>
      <td>0.036051</td>
      <td>0.317143</td>
      <td>0.798015</td>
      <td>-0.046794</td>
      <td>-1.383036</td>
      <td>-0.361716</td>
      <td>-0.448506</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.634806</td>
      <td>-0.012279</td>
      <td>-0.158129</td>
      <td>-0.089472</td>
      <td>0.812095</td>
      <td>0.851869</td>
      <td>-0.135966</td>
      <td>0.414515</td>
      <td>-0.616096</td>
      <td>-0.400762</td>
      <td>0.588576</td>
      <td>-0.202489</td>
      <td>-0.373882</td>
      <td>0.449868</td>
      <td>0.429585</td>
      <td>-0.620364</td>
      <td>-0.406502</td>
      <td>0.453444</td>
      <td>-0.896992</td>
      <td>0.133646</td>
      <td>0.118372</td>
      <td>0.721571</td>
      <td>1.156198</td>
      <td>0.609596</td>
      <td>1.537003</td>
      <td>-0.560971</td>
      <td>-0.595669</td>
      <td>-0.195998</td>
      <td>0.902443</td>
      <td>0.624433</td>
      <td>-0.012683</td>
      <td>0.404143</td>
      <td>-0.542007</td>
      <td>-1.511627</td>
      <td>0.054578</td>
      <td>-0.178186</td>
      <td>-0.519879</td>
      <td>0.507654</td>
      <td>-0.251276</td>
      <td>-0.643506</td>
      <td>...</td>
      <td>0.058904</td>
      <td>1.049691</td>
      <td>1.017192</td>
      <td>0.458861</td>
      <td>1.094180</td>
      <td>0.616467</td>
      <td>0.731343</td>
      <td>0.792310</td>
      <td>1.040354</td>
      <td>1.204073</td>
      <td>0.135268</td>
      <td>-0.081291</td>
      <td>0.205551</td>
      <td>0.060480</td>
      <td>0.429346</td>
      <td>-0.514900</td>
      <td>-1.567460</td>
      <td>-1.167218</td>
      <td>0.070240</td>
      <td>-0.819890</td>
      <td>-0.067531</td>
      <td>-0.438305</td>
      <td>-0.686966</td>
      <td>-0.770789</td>
      <td>-1.028929</td>
      <td>-0.187143</td>
      <td>0.029735</td>
      <td>-0.390101</td>
      <td>1.026859</td>
      <td>-0.491386</td>
      <td>0.254216</td>
      <td>-0.971420</td>
      <td>-0.138312</td>
      <td>-0.188277</td>
      <td>-0.048056</td>
      <td>0.246574</td>
      <td>0.906669</td>
      <td>1.723574</td>
      <td>2.021023</td>
      <td>1.290338</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.906854</td>
      <td>0.624015</td>
      <td>-0.030223</td>
      <td>0.416535</td>
      <td>-0.488790</td>
      <td>0.198471</td>
      <td>-0.022955</td>
      <td>-0.448348</td>
      <td>-0.780327</td>
      <td>-0.114499</td>
      <td>0.941705</td>
      <td>-0.047539</td>
      <td>0.481722</td>
      <td>-0.250555</td>
      <td>-0.406529</td>
      <td>-0.821540</td>
      <td>0.086303</td>
      <td>-0.236488</td>
      <td>-0.552094</td>
      <td>0.433960</td>
      <td>-0.122320</td>
      <td>0.746660</td>
      <td>0.200715</td>
      <td>-0.456595</td>
      <td>-0.297388</td>
      <td>-0.190963</td>
      <td>1.172895</td>
      <td>0.391853</td>
      <td>1.518397</td>
      <td>1.218011</td>
      <td>0.381293</td>
      <td>0.089153</td>
      <td>-0.105759</td>
      <td>0.864608</td>
      <td>0.796035</td>
      <td>0.725628</td>
      <td>0.934843</td>
      <td>0.186679</td>
      <td>-0.498492</td>
      <td>0.769345</td>
      <td>...</td>
      <td>-1.144995</td>
      <td>0.463986</td>
      <td>0.320468</td>
      <td>0.975528</td>
      <td>-0.395189</td>
      <td>0.136472</td>
      <td>0.332197</td>
      <td>-0.550630</td>
      <td>0.336522</td>
      <td>-0.096867</td>
      <td>0.032392</td>
      <td>-0.288411</td>
      <td>-1.042811</td>
      <td>0.640334</td>
      <td>0.223514</td>
      <td>0.130987</td>
      <td>-0.748554</td>
      <td>-0.651284</td>
      <td>0.917867</td>
      <td>-0.721719</td>
      <td>-0.236034</td>
      <td>-0.417827</td>
      <td>1.072965</td>
      <td>0.491738</td>
      <td>-0.565392</td>
      <td>0.262706</td>
      <td>0.603271</td>
      <td>0.028662</td>
      <td>0.511282</td>
      <td>0.067655</td>
      <td>0.401725</td>
      <td>-0.439959</td>
      <td>-0.797707</td>
      <td>-0.500954</td>
      <td>0.376906</td>
      <td>1.109472</td>
      <td>0.288681</td>
      <td>2.012024</td>
      <td>1.256310</td>
      <td>0.151355</td>
    </tr>
    <tr>
      <th>12</th>
      <td>1.108332</td>
      <td>1.044561</td>
      <td>0.295111</td>
      <td>0.691827</td>
      <td>-0.383015</td>
      <td>-0.195334</td>
      <td>0.476250</td>
      <td>-0.093251</td>
      <td>-0.076784</td>
      <td>-0.752328</td>
      <td>-0.676552</td>
      <td>-0.490041</td>
      <td>-0.447875</td>
      <td>0.299768</td>
      <td>0.208337</td>
      <td>-0.634972</td>
      <td>-0.825566</td>
      <td>-0.166175</td>
      <td>-0.537867</td>
      <td>0.376987</td>
      <td>0.131197</td>
      <td>-0.281463</td>
      <td>0.359287</td>
      <td>0.415776</td>
      <td>-0.484364</td>
      <td>-0.933622</td>
      <td>-0.749415</td>
      <td>-0.098274</td>
      <td>-0.199482</td>
      <td>0.341222</td>
      <td>0.027666</td>
      <td>0.006282</td>
      <td>0.191678</td>
      <td>1.317778</td>
      <td>1.088570</td>
      <td>1.627043</td>
      <td>0.007179</td>
      <td>-0.121668</td>
      <td>-0.927203</td>
      <td>-0.325562</td>
      <td>...</td>
      <td>-0.685534</td>
      <td>-0.886289</td>
      <td>-0.884056</td>
      <td>0.038716</td>
      <td>0.129791</td>
      <td>0.013545</td>
      <td>-0.267933</td>
      <td>0.689604</td>
      <td>-0.731006</td>
      <td>0.351286</td>
      <td>0.959167</td>
      <td>-0.147744</td>
      <td>-1.078148</td>
      <td>-0.408036</td>
      <td>0.263750</td>
      <td>0.586033</td>
      <td>-1.242109</td>
      <td>-0.993500</td>
      <td>-0.755427</td>
      <td>-1.490451</td>
      <td>-0.176428</td>
      <td>-0.293420</td>
      <td>-0.454250</td>
      <td>-1.116949</td>
      <td>0.516925</td>
      <td>0.504380</td>
      <td>0.448650</td>
      <td>-0.136098</td>
      <td>0.200184</td>
      <td>-0.395819</td>
      <td>-0.212869</td>
      <td>-0.146285</td>
      <td>-0.933484</td>
      <td>0.093418</td>
      <td>-0.409950</td>
      <td>0.102604</td>
      <td>0.206221</td>
      <td>1.463232</td>
      <td>1.186886</td>
      <td>0.450332</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.721071</td>
      <td>-0.253855</td>
      <td>0.938561</td>
      <td>-0.003960</td>
      <td>0.154689</td>
      <td>-0.093047</td>
      <td>-0.217442</td>
      <td>0.393530</td>
      <td>0.269376</td>
      <td>0.191972</td>
      <td>1.090229</td>
      <td>0.624141</td>
      <td>-0.070988</td>
      <td>-0.210169</td>
      <td>-0.713507</td>
      <td>-0.685952</td>
      <td>0.018512</td>
      <td>-1.025039</td>
      <td>0.125301</td>
      <td>-0.335504</td>
      <td>-0.029124</td>
      <td>-0.871754</td>
      <td>-0.097938</td>
      <td>-0.208958</td>
      <td>1.447019</td>
      <td>-0.167415</td>
      <td>-1.236904</td>
      <td>-0.639859</td>
      <td>0.142266</td>
      <td>1.042011</td>
      <td>-0.217751</td>
      <td>-0.469627</td>
      <td>-0.720801</td>
      <td>0.186892</td>
      <td>0.074237</td>
      <td>-0.535916</td>
      <td>0.191229</td>
      <td>0.089673</td>
      <td>0.305381</td>
      <td>0.593124</td>
      <td>...</td>
      <td>-0.195982</td>
      <td>0.417940</td>
      <td>0.417634</td>
      <td>-0.916216</td>
      <td>-0.500989</td>
      <td>-0.220937</td>
      <td>0.433512</td>
      <td>0.077586</td>
      <td>-0.014005</td>
      <td>-0.492463</td>
      <td>0.437605</td>
      <td>0.852831</td>
      <td>-0.510296</td>
      <td>-0.010599</td>
      <td>0.356900</td>
      <td>-0.008701</td>
      <td>-1.491157</td>
      <td>-1.122940</td>
      <td>0.368329</td>
      <td>0.184639</td>
      <td>-1.299349</td>
      <td>0.422742</td>
      <td>0.035118</td>
      <td>-1.239274</td>
      <td>0.415817</td>
      <td>1.449984</td>
      <td>1.227172</td>
      <td>0.260191</td>
      <td>-0.936442</td>
      <td>0.257445</td>
      <td>0.017200</td>
      <td>1.458286</td>
      <td>1.435194</td>
      <td>0.900280</td>
      <td>1.192402</td>
      <td>0.812250</td>
      <td>-0.048848</td>
      <td>0.220404</td>
      <td>0.974004</td>
      <td>0.024169</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.782357</td>
      <td>-0.609652</td>
      <td>-1.033348</td>
      <td>-0.370194</td>
      <td>-0.277796</td>
      <td>0.681989</td>
      <td>-0.066615</td>
      <td>-0.727458</td>
      <td>0.079917</td>
      <td>-0.091671</td>
      <td>0.504762</td>
      <td>-0.168189</td>
      <td>-0.152615</td>
      <td>-0.909680</td>
      <td>0.276082</td>
      <td>-0.770025</td>
      <td>-0.483679</td>
      <td>-0.537304</td>
      <td>-0.511901</td>
      <td>-0.870735</td>
      <td>-0.283509</td>
      <td>-0.924172</td>
      <td>-0.601435</td>
      <td>-0.108130</td>
      <td>-0.220823</td>
      <td>-0.481772</td>
      <td>-0.061466</td>
      <td>0.983533</td>
      <td>0.668010</td>
      <td>0.727686</td>
      <td>0.531588</td>
      <td>-0.295753</td>
      <td>-0.778735</td>
      <td>-0.516095</td>
      <td>0.541099</td>
      <td>0.250771</td>
      <td>-0.137119</td>
      <td>-0.049286</td>
      <td>-0.265008</td>
      <td>0.709511</td>
      <td>...</td>
      <td>-0.388441</td>
      <td>-0.116485</td>
      <td>-0.394593</td>
      <td>-0.322263</td>
      <td>0.133330</td>
      <td>-0.391385</td>
      <td>0.476304</td>
      <td>0.350749</td>
      <td>-0.454507</td>
      <td>0.225988</td>
      <td>0.378477</td>
      <td>0.404471</td>
      <td>0.610996</td>
      <td>0.629725</td>
      <td>-0.695285</td>
      <td>-1.086452</td>
      <td>-1.291695</td>
      <td>-0.242131</td>
      <td>-0.357520</td>
      <td>-0.990830</td>
      <td>0.026138</td>
      <td>0.587229</td>
      <td>0.152427</td>
      <td>-0.488598</td>
      <td>0.549963</td>
      <td>0.523434</td>
      <td>0.656437</td>
      <td>0.233073</td>
      <td>0.798488</td>
      <td>-0.005943</td>
      <td>0.177431</td>
      <td>-0.514192</td>
      <td>0.454663</td>
      <td>-0.612801</td>
      <td>-0.265207</td>
      <td>1.584339</td>
      <td>-0.624726</td>
      <td>-0.571336</td>
      <td>-0.661459</td>
      <td>-0.648484</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-0.183081</td>
      <td>1.182317</td>
      <td>-0.369474</td>
      <td>0.230627</td>
      <td>0.748176</td>
      <td>0.284188</td>
      <td>-1.526219</td>
      <td>-1.331060</td>
      <td>0.714353</td>
      <td>-0.545527</td>
      <td>0.315723</td>
      <td>-0.270073</td>
      <td>-0.487585</td>
      <td>-0.129797</td>
      <td>-0.548434</td>
      <td>-0.322776</td>
      <td>-0.336938</td>
      <td>0.320526</td>
      <td>-0.476177</td>
      <td>0.974905</td>
      <td>0.017700</td>
      <td>0.917897</td>
      <td>1.162958</td>
      <td>0.212072</td>
      <td>0.597366</td>
      <td>0.993921</td>
      <td>-0.282152</td>
      <td>0.707232</td>
      <td>-0.517813</td>
      <td>0.631495</td>
      <td>-0.133076</td>
      <td>1.618131</td>
      <td>-0.046288</td>
      <td>0.145839</td>
      <td>0.075984</td>
      <td>-0.234538</td>
      <td>0.683615</td>
      <td>0.157265</td>
      <td>0.696751</td>
      <td>0.133029</td>
      <td>...</td>
      <td>0.210036</td>
      <td>0.820195</td>
      <td>1.386401</td>
      <td>0.623134</td>
      <td>-0.059030</td>
      <td>-0.013828</td>
      <td>0.959699</td>
      <td>0.994125</td>
      <td>0.498687</td>
      <td>-0.253711</td>
      <td>-0.304939</td>
      <td>-0.128708</td>
      <td>0.776771</td>
      <td>-0.136820</td>
      <td>0.496479</td>
      <td>0.525635</td>
      <td>-0.561802</td>
      <td>-0.868286</td>
      <td>-0.816541</td>
      <td>0.021477</td>
      <td>-0.703484</td>
      <td>-0.659259</td>
      <td>0.076929</td>
      <td>-0.310402</td>
      <td>-0.128230</td>
      <td>0.698801</td>
      <td>0.436558</td>
      <td>0.391237</td>
      <td>-1.568426</td>
      <td>-0.802547</td>
      <td>0.202287</td>
      <td>0.483061</td>
      <td>0.721441</td>
      <td>-0.048605</td>
      <td>-1.024777</td>
      <td>-0.321810</td>
      <td>-0.793035</td>
      <td>-1.250474</td>
      <td>-0.856067</td>
      <td>-0.421043</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.265384</td>
      <td>-0.267721</td>
      <td>0.196329</td>
      <td>-0.447933</td>
      <td>-0.614928</td>
      <td>-0.468912</td>
      <td>-0.638984</td>
      <td>-0.226357</td>
      <td>1.513973</td>
      <td>0.945286</td>
      <td>0.872883</td>
      <td>-0.349615</td>
      <td>-0.644935</td>
      <td>0.169279</td>
      <td>-0.231177</td>
      <td>-0.163303</td>
      <td>-0.246943</td>
      <td>-1.446520</td>
      <td>-1.233756</td>
      <td>0.266093</td>
      <td>0.317008</td>
      <td>0.508217</td>
      <td>-1.029055</td>
      <td>0.467300</td>
      <td>0.293616</td>
      <td>1.188702</td>
      <td>0.536099</td>
      <td>0.279879</td>
      <td>1.105936</td>
      <td>0.134804</td>
      <td>-0.012967</td>
      <td>-0.279328</td>
      <td>-0.920603</td>
      <td>-0.293970</td>
      <td>1.503042</td>
      <td>0.822954</td>
      <td>-0.404355</td>
      <td>-0.386595</td>
      <td>-0.750081</td>
      <td>-0.691329</td>
      <td>...</td>
      <td>-0.979499</td>
      <td>-0.328957</td>
      <td>-0.234274</td>
      <td>0.163682</td>
      <td>0.148370</td>
      <td>-0.087836</td>
      <td>-0.175654</td>
      <td>-0.978616</td>
      <td>-0.950643</td>
      <td>0.282470</td>
      <td>0.860401</td>
      <td>0.732676</td>
      <td>-0.161870</td>
      <td>0.325166</td>
      <td>0.023528</td>
      <td>-0.508195</td>
      <td>-0.182923</td>
      <td>-0.674853</td>
      <td>0.382403</td>
      <td>0.440878</td>
      <td>-0.660246</td>
      <td>-0.881146</td>
      <td>0.396659</td>
      <td>-0.072308</td>
      <td>-0.024405</td>
      <td>0.630072</td>
      <td>0.175027</td>
      <td>-0.424682</td>
      <td>0.401276</td>
      <td>-0.011209</td>
      <td>-0.058827</td>
      <td>-0.702822</td>
      <td>-0.198819</td>
      <td>0.756958</td>
      <td>-0.068327</td>
      <td>0.279005</td>
      <td>0.566997</td>
      <td>0.988186</td>
      <td>1.398071</td>
      <td>1.319268</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.623398</td>
      <td>0.425141</td>
      <td>0.410606</td>
      <td>0.476068</td>
      <td>-0.745395</td>
      <td>1.097822</td>
      <td>0.994910</td>
      <td>0.055400</td>
      <td>0.112103</td>
      <td>0.339064</td>
      <td>0.337814</td>
      <td>-0.569003</td>
      <td>-0.695771</td>
      <td>-0.638700</td>
      <td>-0.530809</td>
      <td>-1.096254</td>
      <td>0.112349</td>
      <td>-1.336636</td>
      <td>-1.222302</td>
      <td>0.745683</td>
      <td>-0.662167</td>
      <td>0.180048</td>
      <td>0.491540</td>
      <td>0.003192</td>
      <td>0.198578</td>
      <td>-0.674575</td>
      <td>-0.526232</td>
      <td>-0.908846</td>
      <td>-0.994189</td>
      <td>-0.767947</td>
      <td>-0.896720</td>
      <td>0.190174</td>
      <td>-0.796718</td>
      <td>-0.396975</td>
      <td>0.129186</td>
      <td>0.240739</td>
      <td>-0.431924</td>
      <td>0.046302</td>
      <td>0.197814</td>
      <td>-0.189035</td>
      <td>...</td>
      <td>-0.306182</td>
      <td>1.007996</td>
      <td>-0.104715</td>
      <td>0.042546</td>
      <td>0.704921</td>
      <td>0.047636</td>
      <td>-0.086412</td>
      <td>-0.495435</td>
      <td>-0.697057</td>
      <td>-1.009514</td>
      <td>-0.732679</td>
      <td>0.897631</td>
      <td>0.462111</td>
      <td>-0.412444</td>
      <td>0.157288</td>
      <td>-0.826631</td>
      <td>-1.019268</td>
      <td>-0.427232</td>
      <td>-0.125289</td>
      <td>0.714082</td>
      <td>-0.282087</td>
      <td>-0.856732</td>
      <td>0.034244</td>
      <td>0.861040</td>
      <td>0.288601</td>
      <td>-0.051265</td>
      <td>0.372193</td>
      <td>-0.101788</td>
      <td>0.100804</td>
      <td>-0.808036</td>
      <td>0.679334</td>
      <td>0.098504</td>
      <td>0.259335</td>
      <td>-0.029929</td>
      <td>-0.496488</td>
      <td>-0.849467</td>
      <td>-0.329860</td>
      <td>1.384729</td>
      <td>0.863422</td>
      <td>0.051211</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.521413</td>
      <td>0.484332</td>
      <td>-0.753818</td>
      <td>-0.539434</td>
      <td>-0.217119</td>
      <td>0.538028</td>
      <td>0.053544</td>
      <td>0.153883</td>
      <td>-0.016630</td>
      <td>-0.625577</td>
      <td>0.861343</td>
      <td>-0.250273</td>
      <td>0.030286</td>
      <td>-0.246113</td>
      <td>0.316118</td>
      <td>1.073790</td>
      <td>0.049974</td>
      <td>0.236601</td>
      <td>0.708430</td>
      <td>1.042518</td>
      <td>0.698200</td>
      <td>1.163848</td>
      <td>-0.342543</td>
      <td>0.401920</td>
      <td>0.172776</td>
      <td>0.673983</td>
      <td>-0.361383</td>
      <td>0.459900</td>
      <td>1.478185</td>
      <td>-0.512974</td>
      <td>-0.078781</td>
      <td>0.447504</td>
      <td>-0.046819</td>
      <td>-0.522986</td>
      <td>-0.330835</td>
      <td>0.055725</td>
      <td>0.522234</td>
      <td>0.020521</td>
      <td>-0.119984</td>
      <td>0.359283</td>
      <td>...</td>
      <td>-0.118572</td>
      <td>0.583417</td>
      <td>0.547564</td>
      <td>-0.204634</td>
      <td>-0.521324</td>
      <td>0.296480</td>
      <td>-0.511138</td>
      <td>-0.224051</td>
      <td>0.154526</td>
      <td>0.438625</td>
      <td>0.339396</td>
      <td>0.568819</td>
      <td>-0.149634</td>
      <td>-0.595913</td>
      <td>0.102712</td>
      <td>-0.225874</td>
      <td>-0.637420</td>
      <td>0.293752</td>
      <td>0.478138</td>
      <td>0.228189</td>
      <td>0.191969</td>
      <td>-0.787467</td>
      <td>0.532146</td>
      <td>-0.368479</td>
      <td>-0.745817</td>
      <td>-0.593411</td>
      <td>0.457119</td>
      <td>0.375681</td>
      <td>-0.351058</td>
      <td>-0.043271</td>
      <td>-0.783911</td>
      <td>-0.707776</td>
      <td>-0.365049</td>
      <td>0.172648</td>
      <td>-0.049796</td>
      <td>-1.037198</td>
      <td>-0.142919</td>
      <td>0.530270</td>
      <td>0.343849</td>
      <td>-0.001193</td>
    </tr>
    <tr>
      <th>19</th>
      <td>1.259496</td>
      <td>-0.371966</td>
      <td>-0.717767</td>
      <td>-0.575228</td>
      <td>-0.172519</td>
      <td>0.433222</td>
      <td>-0.150281</td>
      <td>-0.331503</td>
      <td>-0.865649</td>
      <td>-0.977894</td>
      <td>-0.386525</td>
      <td>-0.379918</td>
      <td>0.166463</td>
      <td>-0.666274</td>
      <td>-0.662368</td>
      <td>-0.772400</td>
      <td>-0.581697</td>
      <td>-0.034391</td>
      <td>-0.306223</td>
      <td>0.637448</td>
      <td>-0.354590</td>
      <td>-0.005556</td>
      <td>-0.298848</td>
      <td>-0.121724</td>
      <td>0.347968</td>
      <td>0.592622</td>
      <td>-0.092767</td>
      <td>0.997525</td>
      <td>0.556031</td>
      <td>0.537062</td>
      <td>0.484668</td>
      <td>0.905993</td>
      <td>-0.623014</td>
      <td>1.143719</td>
      <td>0.155082</td>
      <td>1.158308</td>
      <td>-0.701936</td>
      <td>0.221405</td>
      <td>0.104484</td>
      <td>0.378047</td>
      <td>...</td>
      <td>-0.746820</td>
      <td>0.076491</td>
      <td>-0.683747</td>
      <td>-0.516027</td>
      <td>-0.722907</td>
      <td>-1.005082</td>
      <td>-0.165198</td>
      <td>-0.800450</td>
      <td>-0.921996</td>
      <td>-0.855606</td>
      <td>-0.486404</td>
      <td>0.758180</td>
      <td>0.108648</td>
      <td>-0.276669</td>
      <td>0.691055</td>
      <td>-0.392002</td>
      <td>-0.467209</td>
      <td>0.495349</td>
      <td>1.124275</td>
      <td>-0.552471</td>
      <td>-0.108185</td>
      <td>0.349510</td>
      <td>0.368073</td>
      <td>0.526187</td>
      <td>-0.048041</td>
      <td>-0.402920</td>
      <td>1.093560</td>
      <td>0.359766</td>
      <td>0.183874</td>
      <td>-0.036923</td>
      <td>0.264499</td>
      <td>-0.281051</td>
      <td>1.195450</td>
      <td>0.321932</td>
      <td>-0.430882</td>
      <td>-0.528255</td>
      <td>-0.655540</td>
      <td>-0.129337</td>
      <td>0.856645</td>
      <td>0.565346</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.169912</td>
      <td>0.567142</td>
      <td>0.511644</td>
      <td>-0.184130</td>
      <td>0.921917</td>
      <td>-0.472407</td>
      <td>-0.491246</td>
      <td>-0.798095</td>
      <td>0.332900</td>
      <td>0.679345</td>
      <td>0.832349</td>
      <td>-0.148548</td>
      <td>0.811934</td>
      <td>0.771303</td>
      <td>0.428120</td>
      <td>1.035202</td>
      <td>0.850164</td>
      <td>-0.727816</td>
      <td>-0.626306</td>
      <td>-0.769807</td>
      <td>0.357258</td>
      <td>0.290892</td>
      <td>-0.143165</td>
      <td>-0.568509</td>
      <td>0.044977</td>
      <td>-0.218283</td>
      <td>-0.515818</td>
      <td>0.231534</td>
      <td>-0.252468</td>
      <td>-0.036973</td>
      <td>0.344583</td>
      <td>1.203119</td>
      <td>-0.397307</td>
      <td>0.158824</td>
      <td>0.541268</td>
      <td>0.094904</td>
      <td>0.601726</td>
      <td>-0.605334</td>
      <td>0.270021</td>
      <td>0.693818</td>
      <td>...</td>
      <td>-0.079723</td>
      <td>0.500337</td>
      <td>0.749392</td>
      <td>-0.077404</td>
      <td>-0.167427</td>
      <td>-0.450687</td>
      <td>-0.198353</td>
      <td>-0.330808</td>
      <td>0.081347</td>
      <td>0.824290</td>
      <td>0.635528</td>
      <td>-0.103128</td>
      <td>-0.145101</td>
      <td>0.391996</td>
      <td>-1.665001</td>
      <td>-0.759254</td>
      <td>-0.740396</td>
      <td>-1.123731</td>
      <td>0.801283</td>
      <td>0.074134</td>
      <td>0.141664</td>
      <td>0.233752</td>
      <td>0.636146</td>
      <td>-0.570151</td>
      <td>-0.184569</td>
      <td>-0.527397</td>
      <td>0.004733</td>
      <td>0.467174</td>
      <td>0.283146</td>
      <td>-0.576143</td>
      <td>-0.202843</td>
      <td>-0.379726</td>
      <td>0.377887</td>
      <td>0.248223</td>
      <td>-0.041169</td>
      <td>0.397745</td>
      <td>-0.469443</td>
      <td>2.953854</td>
      <td>2.217385</td>
      <td>-0.094822</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.489360</td>
      <td>0.694214</td>
      <td>0.233548</td>
      <td>0.434145</td>
      <td>0.300226</td>
      <td>-1.103585</td>
      <td>-1.052854</td>
      <td>-0.334378</td>
      <td>-0.144839</td>
      <td>-0.393889</td>
      <td>0.606482</td>
      <td>-0.125104</td>
      <td>-0.546536</td>
      <td>1.425577</td>
      <td>-0.659992</td>
      <td>-0.213968</td>
      <td>-0.464775</td>
      <td>-0.100029</td>
      <td>0.253091</td>
      <td>0.428189</td>
      <td>0.525086</td>
      <td>0.534105</td>
      <td>1.113136</td>
      <td>0.265913</td>
      <td>0.590321</td>
      <td>-0.442108</td>
      <td>-0.068791</td>
      <td>-1.118924</td>
      <td>0.077525</td>
      <td>0.617300</td>
      <td>0.919667</td>
      <td>-0.332226</td>
      <td>0.045318</td>
      <td>0.107334</td>
      <td>0.065221</td>
      <td>0.405726</td>
      <td>0.082695</td>
      <td>-0.235383</td>
      <td>0.610329</td>
      <td>0.911655</td>
      <td>...</td>
      <td>-0.566908</td>
      <td>0.066843</td>
      <td>-0.152004</td>
      <td>-0.841107</td>
      <td>-1.573729</td>
      <td>-0.658090</td>
      <td>-0.451152</td>
      <td>0.460616</td>
      <td>0.518390</td>
      <td>0.541757</td>
      <td>0.391660</td>
      <td>-0.474160</td>
      <td>-0.615294</td>
      <td>0.545443</td>
      <td>-0.497829</td>
      <td>-0.730176</td>
      <td>0.256467</td>
      <td>-1.045667</td>
      <td>0.316098</td>
      <td>-0.566305</td>
      <td>-1.087754</td>
      <td>-1.124437</td>
      <td>0.061304</td>
      <td>-0.349101</td>
      <td>-0.229835</td>
      <td>-0.461217</td>
      <td>0.094489</td>
      <td>-0.110163</td>
      <td>0.152370</td>
      <td>-0.393503</td>
      <td>0.069254</td>
      <td>-0.294844</td>
      <td>-0.310115</td>
      <td>-0.773909</td>
      <td>0.667748</td>
      <td>-0.317262</td>
      <td>0.866799</td>
      <td>1.139028</td>
      <td>1.019719</td>
      <td>0.718218</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.729069</td>
      <td>0.348477</td>
      <td>-0.125552</td>
      <td>-0.008925</td>
      <td>-0.676842</td>
      <td>-0.359001</td>
      <td>-0.413573</td>
      <td>0.714179</td>
      <td>0.905291</td>
      <td>0.782936</td>
      <td>1.161956</td>
      <td>-0.403370</td>
      <td>-0.399235</td>
      <td>0.432050</td>
      <td>0.356697</td>
      <td>-0.174873</td>
      <td>-0.750020</td>
      <td>0.174489</td>
      <td>-0.956883</td>
      <td>0.769347</td>
      <td>-0.145820</td>
      <td>-0.105301</td>
      <td>0.908369</td>
      <td>0.012446</td>
      <td>0.372114</td>
      <td>-0.864800</td>
      <td>-1.174711</td>
      <td>-0.312218</td>
      <td>0.830713</td>
      <td>0.179876</td>
      <td>0.137977</td>
      <td>0.831514</td>
      <td>0.045316</td>
      <td>-0.115547</td>
      <td>0.495643</td>
      <td>0.684414</td>
      <td>-0.056659</td>
      <td>0.497905</td>
      <td>0.517214</td>
      <td>0.612443</td>
      <td>...</td>
      <td>-1.772592</td>
      <td>-0.396353</td>
      <td>-0.767780</td>
      <td>0.514778</td>
      <td>0.202856</td>
      <td>-0.541951</td>
      <td>-1.033093</td>
      <td>0.155390</td>
      <td>-1.101139</td>
      <td>0.548489</td>
      <td>0.161535</td>
      <td>0.197530</td>
      <td>-0.160822</td>
      <td>0.019654</td>
      <td>0.033684</td>
      <td>0.112986</td>
      <td>-1.793308</td>
      <td>-0.859806</td>
      <td>-0.011653</td>
      <td>-0.438717</td>
      <td>-0.167687</td>
      <td>0.215516</td>
      <td>-0.299298</td>
      <td>0.209812</td>
      <td>-1.140885</td>
      <td>-0.816974</td>
      <td>-0.237510</td>
      <td>0.089690</td>
      <td>0.063185</td>
      <td>-0.628308</td>
      <td>-0.125047</td>
      <td>-0.432426</td>
      <td>-0.363660</td>
      <td>0.583062</td>
      <td>-0.008976</td>
      <td>-0.353664</td>
      <td>0.423047</td>
      <td>-0.582284</td>
      <td>-0.631994</td>
      <td>-0.923616</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.156646</td>
      <td>-0.516211</td>
      <td>-0.744378</td>
      <td>0.189967</td>
      <td>-0.065346</td>
      <td>0.167899</td>
      <td>-0.255304</td>
      <td>0.317709</td>
      <td>0.751642</td>
      <td>0.599192</td>
      <td>1.026805</td>
      <td>-0.093092</td>
      <td>-0.487796</td>
      <td>-0.074817</td>
      <td>-0.414165</td>
      <td>-0.878922</td>
      <td>-1.236085</td>
      <td>-0.198229</td>
      <td>0.492220</td>
      <td>-0.077197</td>
      <td>-0.302113</td>
      <td>-0.452919</td>
      <td>0.679281</td>
      <td>0.367745</td>
      <td>0.815487</td>
      <td>-0.599194</td>
      <td>-0.539460</td>
      <td>0.023387</td>
      <td>0.470003</td>
      <td>0.376580</td>
      <td>0.489107</td>
      <td>0.983520</td>
      <td>0.149774</td>
      <td>1.033925</td>
      <td>-0.557276</td>
      <td>-0.476080</td>
      <td>-0.545087</td>
      <td>0.133458</td>
      <td>-0.261357</td>
      <td>0.254404</td>
      <td>...</td>
      <td>-0.031554</td>
      <td>0.107073</td>
      <td>-0.921004</td>
      <td>-0.377874</td>
      <td>-0.667497</td>
      <td>-0.023586</td>
      <td>-0.416183</td>
      <td>-0.385613</td>
      <td>-0.186280</td>
      <td>-0.326415</td>
      <td>-0.462619</td>
      <td>-0.063574</td>
      <td>0.819752</td>
      <td>0.866260</td>
      <td>0.291574</td>
      <td>-0.511705</td>
      <td>-1.491251</td>
      <td>-0.998629</td>
      <td>0.087592</td>
      <td>0.617591</td>
      <td>-0.034034</td>
      <td>-0.095247</td>
      <td>0.558371</td>
      <td>-0.394920</td>
      <td>0.203443</td>
      <td>0.811682</td>
      <td>-0.488434</td>
      <td>0.167299</td>
      <td>0.537932</td>
      <td>0.554057</td>
      <td>-0.495293</td>
      <td>-0.625276</td>
      <td>-0.097880</td>
      <td>-0.406696</td>
      <td>-0.978137</td>
      <td>0.183587</td>
      <td>0.491229</td>
      <td>-0.890634</td>
      <td>-1.011902</td>
      <td>-0.702213</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.523249</td>
      <td>0.628429</td>
      <td>0.638835</td>
      <td>0.531180</td>
      <td>0.159332</td>
      <td>0.526046</td>
      <td>-0.169345</td>
      <td>-0.583782</td>
      <td>-0.516261</td>
      <td>-0.043403</td>
      <td>0.866449</td>
      <td>1.169759</td>
      <td>1.586762</td>
      <td>0.239674</td>
      <td>-0.724120</td>
      <td>-0.932870</td>
      <td>-0.624392</td>
      <td>-1.105261</td>
      <td>-1.043965</td>
      <td>0.335455</td>
      <td>-0.872821</td>
      <td>-0.887216</td>
      <td>-0.742424</td>
      <td>-0.749282</td>
      <td>-0.344269</td>
      <td>-0.648218</td>
      <td>-0.055787</td>
      <td>0.275156</td>
      <td>0.102482</td>
      <td>0.286667</td>
      <td>0.080029</td>
      <td>-0.217477</td>
      <td>-0.137941</td>
      <td>-0.053477</td>
      <td>0.363021</td>
      <td>-1.083301</td>
      <td>-0.394219</td>
      <td>-0.675528</td>
      <td>0.291959</td>
      <td>0.247005</td>
      <td>...</td>
      <td>-0.857873</td>
      <td>0.434557</td>
      <td>-0.554311</td>
      <td>0.404504</td>
      <td>0.134131</td>
      <td>-0.487218</td>
      <td>0.844630</td>
      <td>-0.136470</td>
      <td>0.224247</td>
      <td>0.016419</td>
      <td>-0.178551</td>
      <td>-0.055036</td>
      <td>0.028639</td>
      <td>0.383402</td>
      <td>0.933783</td>
      <td>0.938967</td>
      <td>-0.848547</td>
      <td>-0.623964</td>
      <td>0.210164</td>
      <td>0.252769</td>
      <td>-1.101492</td>
      <td>0.005493</td>
      <td>-0.654616</td>
      <td>-1.305663</td>
      <td>-1.237503</td>
      <td>1.744216</td>
      <td>1.615641</td>
      <td>0.638893</td>
      <td>1.296814</td>
      <td>0.410863</td>
      <td>0.232825</td>
      <td>-0.525953</td>
      <td>-0.244377</td>
      <td>0.313680</td>
      <td>0.468416</td>
      <td>-0.255422</td>
      <td>0.120052</td>
      <td>2.583047</td>
      <td>1.347207</td>
      <td>0.648718</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.403285</td>
      <td>-0.573295</td>
      <td>-1.326945</td>
      <td>-0.232926</td>
      <td>0.443016</td>
      <td>0.029145</td>
      <td>0.513781</td>
      <td>-0.185125</td>
      <td>-0.019661</td>
      <td>0.235201</td>
      <td>-0.192564</td>
      <td>-0.215471</td>
      <td>1.060035</td>
      <td>-0.114914</td>
      <td>0.657701</td>
      <td>-0.114012</td>
      <td>0.020557</td>
      <td>1.518172</td>
      <td>1.322375</td>
      <td>0.828353</td>
      <td>0.668618</td>
      <td>-0.433723</td>
      <td>-0.897802</td>
      <td>-0.701236</td>
      <td>-0.699788</td>
      <td>-0.249266</td>
      <td>-0.122059</td>
      <td>-0.045545</td>
      <td>0.409529</td>
      <td>-0.178035</td>
      <td>-0.263481</td>
      <td>-0.235111</td>
      <td>0.686838</td>
      <td>0.031597</td>
      <td>-0.883565</td>
      <td>-0.555859</td>
      <td>-0.563018</td>
      <td>0.188077</td>
      <td>0.810988</td>
      <td>0.394540</td>
      <td>...</td>
      <td>-0.426355</td>
      <td>-0.251271</td>
      <td>0.450316</td>
      <td>-0.431166</td>
      <td>-0.360389</td>
      <td>-0.447286</td>
      <td>0.776219</td>
      <td>0.105921</td>
      <td>-0.928220</td>
      <td>-0.017824</td>
      <td>0.877767</td>
      <td>-0.613238</td>
      <td>0.027940</td>
      <td>-0.530320</td>
      <td>0.553525</td>
      <td>0.796191</td>
      <td>0.015808</td>
      <td>-0.544827</td>
      <td>0.254462</td>
      <td>-0.763211</td>
      <td>-0.332203</td>
      <td>-0.117748</td>
      <td>-0.415172</td>
      <td>0.226557</td>
      <td>-0.647803</td>
      <td>0.434627</td>
      <td>-0.302632</td>
      <td>-0.561395</td>
      <td>-1.404286</td>
      <td>-0.729071</td>
      <td>-0.659082</td>
      <td>-1.555961</td>
      <td>-0.991864</td>
      <td>-0.722778</td>
      <td>-0.246353</td>
      <td>-0.833717</td>
      <td>-0.103987</td>
      <td>-1.864165</td>
      <td>-1.228787</td>
      <td>-1.144181</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.371559</td>
      <td>0.422999</td>
      <td>-0.996700</td>
      <td>0.081693</td>
      <td>-0.859392</td>
      <td>-0.851042</td>
      <td>0.063258</td>
      <td>-0.985800</td>
      <td>-0.330695</td>
      <td>-0.530351</td>
      <td>0.587509</td>
      <td>0.491819</td>
      <td>1.021332</td>
      <td>0.622284</td>
      <td>1.076593</td>
      <td>1.130376</td>
      <td>-0.086017</td>
      <td>0.910005</td>
      <td>0.618167</td>
      <td>-0.086305</td>
      <td>-0.527785</td>
      <td>0.553412</td>
      <td>-1.118969</td>
      <td>-0.130543</td>
      <td>-0.182449</td>
      <td>0.374352</td>
      <td>0.402055</td>
      <td>0.547581</td>
      <td>1.200369</td>
      <td>0.128171</td>
      <td>0.922995</td>
      <td>0.366767</td>
      <td>0.577685</td>
      <td>0.319363</td>
      <td>-0.058107</td>
      <td>1.216446</td>
      <td>0.202244</td>
      <td>-0.714160</td>
      <td>-0.210659</td>
      <td>-0.608705</td>
      <td>...</td>
      <td>0.429700</td>
      <td>-0.296804</td>
      <td>-0.534769</td>
      <td>-0.073544</td>
      <td>-0.296760</td>
      <td>-0.086658</td>
      <td>-0.200708</td>
      <td>-0.158045</td>
      <td>-0.453499</td>
      <td>-0.754833</td>
      <td>0.476198</td>
      <td>0.102025</td>
      <td>0.288998</td>
      <td>0.016374</td>
      <td>-0.342899</td>
      <td>0.410434</td>
      <td>0.337118</td>
      <td>0.638432</td>
      <td>1.438946</td>
      <td>1.386230</td>
      <td>0.986500</td>
      <td>0.391415</td>
      <td>0.139024</td>
      <td>-0.027540</td>
      <td>0.098589</td>
      <td>0.027266</td>
      <td>-0.440234</td>
      <td>0.325941</td>
      <td>-0.501835</td>
      <td>-0.151842</td>
      <td>0.137922</td>
      <td>0.631050</td>
      <td>0.364539</td>
      <td>0.672559</td>
      <td>0.308576</td>
      <td>-0.457917</td>
      <td>0.665680</td>
      <td>2.969986</td>
      <td>1.578527</td>
      <td>0.478697</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.148075</td>
      <td>-0.590912</td>
      <td>0.052018</td>
      <td>0.355944</td>
      <td>-0.301539</td>
      <td>0.290643</td>
      <td>-0.708188</td>
      <td>0.637010</td>
      <td>-0.743508</td>
      <td>0.415114</td>
      <td>0.183772</td>
      <td>0.342589</td>
      <td>0.302185</td>
      <td>0.197198</td>
      <td>-0.426337</td>
      <td>0.132940</td>
      <td>-0.624705</td>
      <td>0.239260</td>
      <td>-0.542672</td>
      <td>-0.512240</td>
      <td>-0.435540</td>
      <td>0.535327</td>
      <td>-0.969717</td>
      <td>-1.490508</td>
      <td>0.499710</td>
      <td>-1.202340</td>
      <td>0.416256</td>
      <td>-0.215462</td>
      <td>-0.170080</td>
      <td>-0.205482</td>
      <td>0.350599</td>
      <td>-0.080752</td>
      <td>1.571585</td>
      <td>0.176350</td>
      <td>-0.641721</td>
      <td>-0.238488</td>
      <td>-0.018970</td>
      <td>0.782284</td>
      <td>0.108321</td>
      <td>-0.384460</td>
      <td>...</td>
      <td>-0.133868</td>
      <td>0.294864</td>
      <td>0.184417</td>
      <td>-0.485503</td>
      <td>0.622191</td>
      <td>0.386036</td>
      <td>-0.139743</td>
      <td>-0.614945</td>
      <td>0.274810</td>
      <td>-0.567084</td>
      <td>0.451823</td>
      <td>0.778273</td>
      <td>1.035154</td>
      <td>1.415296</td>
      <td>0.420421</td>
      <td>0.109486</td>
      <td>-0.917535</td>
      <td>0.255023</td>
      <td>0.950345</td>
      <td>0.108765</td>
      <td>0.622950</td>
      <td>0.319513</td>
      <td>-0.641038</td>
      <td>-0.525943</td>
      <td>-0.508135</td>
      <td>-0.183194</td>
      <td>-0.161957</td>
      <td>0.791273</td>
      <td>-0.063620</td>
      <td>0.035220</td>
      <td>-0.607024</td>
      <td>0.432953</td>
      <td>-0.364234</td>
      <td>-0.871190</td>
      <td>-0.127886</td>
      <td>-0.051137</td>
      <td>-0.046714</td>
      <td>-2.458844</td>
      <td>-1.572229</td>
      <td>-0.823934</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.780301</td>
      <td>-0.603481</td>
      <td>-0.964467</td>
      <td>0.506316</td>
      <td>-0.403391</td>
      <td>-0.324790</td>
      <td>-0.627979</td>
      <td>0.365542</td>
      <td>-0.548777</td>
      <td>-0.388200</td>
      <td>-0.961859</td>
      <td>-0.550926</td>
      <td>0.158608</td>
      <td>0.054819</td>
      <td>0.385973</td>
      <td>0.528009</td>
      <td>-0.236121</td>
      <td>-0.571801</td>
      <td>0.016687</td>
      <td>-0.354022</td>
      <td>0.285723</td>
      <td>1.169360</td>
      <td>0.197390</td>
      <td>0.886109</td>
      <td>0.573714</td>
      <td>-0.472678</td>
      <td>0.008344</td>
      <td>0.255174</td>
      <td>-0.706688</td>
      <td>-0.185684</td>
      <td>-0.019694</td>
      <td>0.925027</td>
      <td>0.441464</td>
      <td>0.694742</td>
      <td>0.036080</td>
      <td>1.349361</td>
      <td>-0.122533</td>
      <td>0.352018</td>
      <td>-1.080974</td>
      <td>-0.454651</td>
      <td>...</td>
      <td>-0.010455</td>
      <td>-0.751374</td>
      <td>-0.564900</td>
      <td>0.001854</td>
      <td>-0.217921</td>
      <td>-0.886858</td>
      <td>-0.802455</td>
      <td>0.562354</td>
      <td>0.242613</td>
      <td>-0.017627</td>
      <td>1.280357</td>
      <td>0.124245</td>
      <td>0.274656</td>
      <td>-0.143808</td>
      <td>-0.138242</td>
      <td>0.355913</td>
      <td>0.366804</td>
      <td>0.288513</td>
      <td>0.569204</td>
      <td>-0.443857</td>
      <td>-0.567198</td>
      <td>-0.159761</td>
      <td>-0.190797</td>
      <td>-0.040800</td>
      <td>-0.622344</td>
      <td>-0.680883</td>
      <td>0.704012</td>
      <td>-0.439302</td>
      <td>-0.461469</td>
      <td>-0.275350</td>
      <td>-1.050252</td>
      <td>-0.505835</td>
      <td>-0.924206</td>
      <td>-0.182280</td>
      <td>-0.808020</td>
      <td>-0.801828</td>
      <td>0.103043</td>
      <td>1.246305</td>
      <td>1.627574</td>
      <td>0.981815</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.846622</td>
      <td>0.219767</td>
      <td>-0.142568</td>
      <td>-0.295834</td>
      <td>0.580697</td>
      <td>-0.149175</td>
      <td>-0.841423</td>
      <td>-0.682809</td>
      <td>-0.936187</td>
      <td>0.772574</td>
      <td>-0.033070</td>
      <td>-0.507278</td>
      <td>-0.989689</td>
      <td>-0.345657</td>
      <td>0.467210</td>
      <td>-0.060381</td>
      <td>-0.256842</td>
      <td>0.558984</td>
      <td>0.505531</td>
      <td>1.779579</td>
      <td>0.620208</td>
      <td>0.114783</td>
      <td>0.023351</td>
      <td>-0.571520</td>
      <td>-0.321475</td>
      <td>-0.211437</td>
      <td>0.015389</td>
      <td>-0.127010</td>
      <td>-0.074356</td>
      <td>0.683455</td>
      <td>-0.098564</td>
      <td>0.159468</td>
      <td>0.195945</td>
      <td>1.146607</td>
      <td>0.468381</td>
      <td>0.858362</td>
      <td>-0.025259</td>
      <td>0.003269</td>
      <td>0.431526</td>
      <td>-0.278134</td>
      <td>...</td>
      <td>-1.508023</td>
      <td>-0.674335</td>
      <td>-0.449511</td>
      <td>0.057759</td>
      <td>0.144067</td>
      <td>-1.037671</td>
      <td>-1.472943</td>
      <td>0.836515</td>
      <td>-0.762166</td>
      <td>-0.963685</td>
      <td>0.181860</td>
      <td>1.080335</td>
      <td>-0.345639</td>
      <td>-1.531816</td>
      <td>-0.807935</td>
      <td>-0.369566</td>
      <td>-0.181154</td>
      <td>0.722817</td>
      <td>0.736528</td>
      <td>0.867348</td>
      <td>0.669496</td>
      <td>1.007468</td>
      <td>0.152736</td>
      <td>-0.895495</td>
      <td>0.330216</td>
      <td>0.167474</td>
      <td>-0.157031</td>
      <td>-0.816473</td>
      <td>-0.206113</td>
      <td>0.110871</td>
      <td>-0.017605</td>
      <td>-0.310687</td>
      <td>-0.547665</td>
      <td>-0.631262</td>
      <td>0.082851</td>
      <td>0.660194</td>
      <td>0.135810</td>
      <td>-1.052219</td>
      <td>-1.001514</td>
      <td>-0.942185</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f4e81f7c670&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.056305  0.036016  29.328661  4.472279e-189  0.985715  1.126896
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  6.092 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>