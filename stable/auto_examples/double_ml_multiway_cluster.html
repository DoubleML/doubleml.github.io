
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.101715efdecc9b59cb6e1ddfa685c31f.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d8bbf5861d671d414e1a.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">


    
    <a class="navbar-brand" href="../index.html">
      <p class="title">DoubleML</p>
    </a>
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  DoubleML
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/install.html">
  Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/intro.html">
  Getting started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../guide/guide.html">
  User guide
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api.html">
  Python API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference external nav-link" href="https://docs.doubleml.org/r/stable/">
  R API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../release/release.html">
  Release notes
 </a>
</li>

        
      </ul>

      <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><p class="logo" style="text-align:center;"><a href="../index.html">
    <img class="logo" src="../logo.png" alt="Logo" width="65%" height="65%">
</a></p><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l2 current active">
  <a class="current reference internal" href="#">
   Multiway Cluster Robust DML
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="double_ml_bonus_data.html">
   DML: Bonus Data
  </a>
 </li>
</ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulate-multiway-cluster-data">
   Simulate multiway cluster data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
   Initialize the objects of class DoubleMLData and DoubleMLPLIV
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#split-samples-and-transfer-the-sample-splitting-to-the-object">
   Split samples and transfer the sample splitting to the object
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fit-the-model-and-show-a-summary">
   Fit the model and show a summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing">
   Visualization of sample splitting with tuple and linear indexing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold">
     Visualize sample splitting with tuples (one plot per fold)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
     Visualize sample splitting with linear indexing (one column per fold)
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.835163</td>
      <td>0.416804</td>
      <td>0.798073</td>
      <td>-0.274771</td>
      <td>0.673546</td>
      <td>0.183923</td>
      <td>-0.825769</td>
      <td>-0.300685</td>
      <td>-0.793411</td>
      <td>-0.612531</td>
      <td>-0.957728</td>
      <td>-0.042994</td>
      <td>0.576536</td>
      <td>1.189571</td>
      <td>-0.675412</td>
      <td>0.199370</td>
      <td>-1.130109</td>
      <td>-1.409043</td>
      <td>-0.553240</td>
      <td>0.369092</td>
      <td>-0.245003</td>
      <td>-0.832998</td>
      <td>0.010105</td>
      <td>0.609919</td>
      <td>0.636883</td>
      <td>0.910635</td>
      <td>0.738032</td>
      <td>0.546803</td>
      <td>1.075094</td>
      <td>-0.286926</td>
      <td>-0.697610</td>
      <td>0.230100</td>
      <td>0.261525</td>
      <td>-0.740066</td>
      <td>0.007100</td>
      <td>0.856767</td>
      <td>0.242054</td>
      <td>1.034960</td>
      <td>1.122056</td>
      <td>0.430300</td>
      <td>...</td>
      <td>0.042417</td>
      <td>-0.112023</td>
      <td>0.368757</td>
      <td>-0.204594</td>
      <td>0.092419</td>
      <td>-0.023664</td>
      <td>-0.773387</td>
      <td>-1.143165</td>
      <td>-0.332278</td>
      <td>-0.194422</td>
      <td>-0.173651</td>
      <td>-0.306237</td>
      <td>-0.097143</td>
      <td>-0.486393</td>
      <td>-0.198822</td>
      <td>1.038506</td>
      <td>-0.222721</td>
      <td>-0.505352</td>
      <td>0.510740</td>
      <td>0.138395</td>
      <td>0.309485</td>
      <td>0.576296</td>
      <td>0.035779</td>
      <td>0.780614</td>
      <td>1.051943</td>
      <td>0.770669</td>
      <td>-0.077355</td>
      <td>-0.122930</td>
      <td>-0.976961</td>
      <td>-0.501939</td>
      <td>0.027861</td>
      <td>0.286105</td>
      <td>0.613060</td>
      <td>0.525546</td>
      <td>0.726951</td>
      <td>0.395315</td>
      <td>1.060044</td>
      <td>1.368201</td>
      <td>0.611366</td>
      <td>0.334539</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.174260</td>
      <td>-0.546100</td>
      <td>-0.521786</td>
      <td>0.417334</td>
      <td>-0.054631</td>
      <td>0.933370</td>
      <td>-0.726888</td>
      <td>-1.048770</td>
      <td>0.617187</td>
      <td>-0.607604</td>
      <td>0.941869</td>
      <td>0.957564</td>
      <td>1.014126</td>
      <td>0.837181</td>
      <td>-0.165077</td>
      <td>-0.167997</td>
      <td>-0.605788</td>
      <td>-0.561643</td>
      <td>-0.405547</td>
      <td>-0.105400</td>
      <td>-0.448353</td>
      <td>0.729064</td>
      <td>0.993596</td>
      <td>0.653551</td>
      <td>0.544715</td>
      <td>1.004032</td>
      <td>1.292012</td>
      <td>0.391788</td>
      <td>0.425301</td>
      <td>0.821692</td>
      <td>0.681201</td>
      <td>0.768445</td>
      <td>0.217511</td>
      <td>-0.547499</td>
      <td>0.574741</td>
      <td>1.193188</td>
      <td>0.288838</td>
      <td>2.226703</td>
      <td>1.308177</td>
      <td>0.427707</td>
      <td>...</td>
      <td>0.586045</td>
      <td>-0.580113</td>
      <td>0.557616</td>
      <td>0.488936</td>
      <td>-0.919975</td>
      <td>-0.571433</td>
      <td>-0.888015</td>
      <td>0.293995</td>
      <td>0.603007</td>
      <td>-0.134350</td>
      <td>0.644203</td>
      <td>-0.005646</td>
      <td>0.893497</td>
      <td>0.137051</td>
      <td>-0.367220</td>
      <td>-0.613310</td>
      <td>-0.642618</td>
      <td>-0.012198</td>
      <td>0.338904</td>
      <td>0.632858</td>
      <td>-0.380051</td>
      <td>-0.492569</td>
      <td>-0.479796</td>
      <td>0.737469</td>
      <td>-0.193660</td>
      <td>-0.409469</td>
      <td>-0.355102</td>
      <td>0.077050</td>
      <td>-0.824579</td>
      <td>0.444202</td>
      <td>0.100728</td>
      <td>-0.200629</td>
      <td>0.500141</td>
      <td>0.241183</td>
      <td>0.325378</td>
      <td>-0.157017</td>
      <td>-0.183318</td>
      <td>-1.704469</td>
      <td>-0.473903</td>
      <td>0.243211</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.646466</td>
      <td>-0.685404</td>
      <td>-0.052036</td>
      <td>-0.817620</td>
      <td>-0.037557</td>
      <td>0.396510</td>
      <td>0.236082</td>
      <td>-0.324510</td>
      <td>0.072294</td>
      <td>0.168503</td>
      <td>-0.143215</td>
      <td>-0.195433</td>
      <td>-0.445145</td>
      <td>-0.169450</td>
      <td>-0.487507</td>
      <td>0.561673</td>
      <td>0.153894</td>
      <td>0.204096</td>
      <td>-0.040986</td>
      <td>-0.247657</td>
      <td>-0.724769</td>
      <td>-0.074614</td>
      <td>0.292821</td>
      <td>0.311290</td>
      <td>0.298203</td>
      <td>1.000227</td>
      <td>-0.450160</td>
      <td>0.023208</td>
      <td>-0.746133</td>
      <td>0.709059</td>
      <td>-1.159628</td>
      <td>1.206943</td>
      <td>-0.254043</td>
      <td>0.124089</td>
      <td>0.231677</td>
      <td>0.009753</td>
      <td>-0.121937</td>
      <td>0.581992</td>
      <td>0.765876</td>
      <td>-0.431463</td>
      <td>...</td>
      <td>0.104979</td>
      <td>0.103255</td>
      <td>0.809667</td>
      <td>0.021391</td>
      <td>-0.761366</td>
      <td>1.208008</td>
      <td>0.070185</td>
      <td>0.314477</td>
      <td>0.106569</td>
      <td>0.163808</td>
      <td>-0.573212</td>
      <td>-0.450240</td>
      <td>-0.795191</td>
      <td>0.761223</td>
      <td>0.608861</td>
      <td>0.317312</td>
      <td>0.216540</td>
      <td>0.433055</td>
      <td>0.449167</td>
      <td>-0.263040</td>
      <td>-0.287160</td>
      <td>0.026109</td>
      <td>0.150163</td>
      <td>-0.104121</td>
      <td>0.824333</td>
      <td>-0.650266</td>
      <td>-0.502205</td>
      <td>0.172730</td>
      <td>-0.251464</td>
      <td>-0.333997</td>
      <td>-1.019064</td>
      <td>-0.759948</td>
      <td>0.390782</td>
      <td>-0.124022</td>
      <td>1.061160</td>
      <td>0.443565</td>
      <td>1.038616</td>
      <td>-0.673622</td>
      <td>-0.370284</td>
      <td>0.778931</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.386118</td>
      <td>0.770473</td>
      <td>0.912162</td>
      <td>0.151266</td>
      <td>0.293174</td>
      <td>-0.369283</td>
      <td>-0.590678</td>
      <td>-0.836709</td>
      <td>-0.132347</td>
      <td>-0.774944</td>
      <td>0.362256</td>
      <td>0.419958</td>
      <td>1.093635</td>
      <td>0.687073</td>
      <td>-0.329847</td>
      <td>0.772190</td>
      <td>1.272350</td>
      <td>0.091474</td>
      <td>0.589778</td>
      <td>0.119354</td>
      <td>-0.297132</td>
      <td>0.519508</td>
      <td>-0.038317</td>
      <td>-0.027026</td>
      <td>0.079639</td>
      <td>0.730131</td>
      <td>-0.499165</td>
      <td>0.190317</td>
      <td>0.677393</td>
      <td>-0.668029</td>
      <td>-0.640824</td>
      <td>0.347466</td>
      <td>-0.744437</td>
      <td>0.413966</td>
      <td>0.327438</td>
      <td>0.118217</td>
      <td>-0.205083</td>
      <td>0.794525</td>
      <td>0.426081</td>
      <td>-0.280237</td>
      <td>...</td>
      <td>0.613080</td>
      <td>0.967054</td>
      <td>0.453885</td>
      <td>0.543882</td>
      <td>-0.691661</td>
      <td>0.183046</td>
      <td>-0.607798</td>
      <td>-1.933359</td>
      <td>0.035315</td>
      <td>-0.179383</td>
      <td>-0.629274</td>
      <td>-0.487144</td>
      <td>-0.114839</td>
      <td>-0.462600</td>
      <td>-0.756648</td>
      <td>-1.470982</td>
      <td>0.076178</td>
      <td>-1.050785</td>
      <td>-0.736017</td>
      <td>-1.036736</td>
      <td>0.219767</td>
      <td>0.603072</td>
      <td>0.586048</td>
      <td>0.799857</td>
      <td>1.048893</td>
      <td>-0.615277</td>
      <td>-0.367205</td>
      <td>-0.954717</td>
      <td>-1.189354</td>
      <td>-0.733630</td>
      <td>-0.941930</td>
      <td>-1.337830</td>
      <td>0.033232</td>
      <td>0.623581</td>
      <td>-0.626473</td>
      <td>-0.450478</td>
      <td>-0.266039</td>
      <td>-1.205240</td>
      <td>-0.455470</td>
      <td>-0.106606</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.668341</td>
      <td>-0.808855</td>
      <td>0.258147</td>
      <td>0.161075</td>
      <td>-0.054899</td>
      <td>0.132671</td>
      <td>-0.563613</td>
      <td>0.479969</td>
      <td>0.067267</td>
      <td>-1.083562</td>
      <td>0.167353</td>
      <td>-0.553701</td>
      <td>-0.735720</td>
      <td>-1.024922</td>
      <td>-0.594179</td>
      <td>-0.917335</td>
      <td>-0.991319</td>
      <td>-0.557611</td>
      <td>-0.071718</td>
      <td>0.042540</td>
      <td>-0.055135</td>
      <td>0.609052</td>
      <td>0.715704</td>
      <td>0.155633</td>
      <td>-0.844873</td>
      <td>-0.287811</td>
      <td>0.093128</td>
      <td>-0.807084</td>
      <td>-0.657042</td>
      <td>-0.498953</td>
      <td>-1.212567</td>
      <td>-0.546154</td>
      <td>0.370493</td>
      <td>-0.255752</td>
      <td>-0.880218</td>
      <td>0.150272</td>
      <td>-0.091654</td>
      <td>-0.369415</td>
      <td>-0.364505</td>
      <td>-0.559111</td>
      <td>...</td>
      <td>0.043326</td>
      <td>-0.153526</td>
      <td>0.315603</td>
      <td>-0.951975</td>
      <td>0.003992</td>
      <td>-0.228358</td>
      <td>-1.033815</td>
      <td>0.144691</td>
      <td>-0.702754</td>
      <td>0.235775</td>
      <td>-0.156257</td>
      <td>0.894278</td>
      <td>-0.226942</td>
      <td>1.252865</td>
      <td>0.512723</td>
      <td>-0.249535</td>
      <td>-0.281140</td>
      <td>0.130962</td>
      <td>-0.011885</td>
      <td>0.164505</td>
      <td>0.622662</td>
      <td>0.446556</td>
      <td>0.104005</td>
      <td>-0.833326</td>
      <td>1.783499</td>
      <td>0.113137</td>
      <td>0.219217</td>
      <td>-0.308395</td>
      <td>-1.260432</td>
      <td>-0.341744</td>
      <td>-0.096903</td>
      <td>0.473977</td>
      <td>0.238537</td>
      <td>-0.518913</td>
      <td>-0.314016</td>
      <td>-0.226791</td>
      <td>-0.066933</td>
      <td>-0.701570</td>
      <td>-0.283861</td>
      <td>0.322503</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.641110</td>
      <td>-0.200957</td>
      <td>-0.225366</td>
      <td>-1.086346</td>
      <td>0.147458</td>
      <td>-0.014288</td>
      <td>-0.041363</td>
      <td>-0.673493</td>
      <td>0.797896</td>
      <td>1.245044</td>
      <td>0.517341</td>
      <td>-0.229694</td>
      <td>-0.341987</td>
      <td>0.772815</td>
      <td>0.725958</td>
      <td>0.585426</td>
      <td>-0.642099</td>
      <td>-0.405376</td>
      <td>-0.253422</td>
      <td>-0.214144</td>
      <td>0.128776</td>
      <td>-0.226297</td>
      <td>-0.151765</td>
      <td>-0.119250</td>
      <td>-0.069054</td>
      <td>0.931090</td>
      <td>1.043312</td>
      <td>0.733301</td>
      <td>-0.689645</td>
      <td>-0.207029</td>
      <td>1.458078</td>
      <td>0.934878</td>
      <td>-0.116123</td>
      <td>-0.427892</td>
      <td>0.428237</td>
      <td>0.250727</td>
      <td>-0.172704</td>
      <td>0.501973</td>
      <td>0.353118</td>
      <td>0.000905</td>
      <td>...</td>
      <td>-0.293711</td>
      <td>-0.767516</td>
      <td>0.615683</td>
      <td>0.473813</td>
      <td>-0.315281</td>
      <td>0.571951</td>
      <td>0.866830</td>
      <td>0.064491</td>
      <td>0.302638</td>
      <td>-1.150412</td>
      <td>-0.290707</td>
      <td>-1.374805</td>
      <td>0.565212</td>
      <td>0.631110</td>
      <td>0.046510</td>
      <td>0.605328</td>
      <td>-0.301398</td>
      <td>-1.203091</td>
      <td>0.981297</td>
      <td>0.921772</td>
      <td>0.240507</td>
      <td>-0.181607</td>
      <td>0.275136</td>
      <td>0.326414</td>
      <td>0.523682</td>
      <td>0.382685</td>
      <td>-0.282943</td>
      <td>-0.007756</td>
      <td>-0.273131</td>
      <td>0.121235</td>
      <td>-0.277462</td>
      <td>0.315473</td>
      <td>-1.427333</td>
      <td>-1.274725</td>
      <td>-0.137468</td>
      <td>-0.697878</td>
      <td>-0.692649</td>
      <td>-0.347225</td>
      <td>-0.618683</td>
      <td>-0.831255</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.416571</td>
      <td>-0.050129</td>
      <td>-0.648108</td>
      <td>-0.054748</td>
      <td>0.484937</td>
      <td>0.442340</td>
      <td>0.022499</td>
      <td>-0.547398</td>
      <td>0.904463</td>
      <td>-1.126699</td>
      <td>0.180198</td>
      <td>0.440181</td>
      <td>-0.441488</td>
      <td>0.070224</td>
      <td>-0.317780</td>
      <td>0.035010</td>
      <td>0.305148</td>
      <td>0.228228</td>
      <td>0.701000</td>
      <td>0.676373</td>
      <td>-0.565249</td>
      <td>-0.197019</td>
      <td>1.234998</td>
      <td>1.402606</td>
      <td>1.005262</td>
      <td>0.120439</td>
      <td>0.416700</td>
      <td>-0.414206</td>
      <td>-0.888824</td>
      <td>-0.179038</td>
      <td>-0.668080</td>
      <td>-0.633651</td>
      <td>-0.512440</td>
      <td>-0.685862</td>
      <td>-0.545439</td>
      <td>0.589339</td>
      <td>0.093561</td>
      <td>0.524116</td>
      <td>0.809099</td>
      <td>1.760439</td>
      <td>...</td>
      <td>0.238887</td>
      <td>-0.418108</td>
      <td>0.911295</td>
      <td>-0.318356</td>
      <td>0.353305</td>
      <td>0.228761</td>
      <td>-0.636656</td>
      <td>0.142871</td>
      <td>0.384865</td>
      <td>-0.183143</td>
      <td>0.521606</td>
      <td>-0.107315</td>
      <td>0.169578</td>
      <td>0.194827</td>
      <td>0.727201</td>
      <td>0.460727</td>
      <td>-0.172829</td>
      <td>0.563746</td>
      <td>1.198090</td>
      <td>0.204513</td>
      <td>1.783303</td>
      <td>1.422063</td>
      <td>0.830431</td>
      <td>0.584561</td>
      <td>0.901410</td>
      <td>0.891614</td>
      <td>0.305294</td>
      <td>-0.057728</td>
      <td>-0.221071</td>
      <td>-0.151680</td>
      <td>-0.734477</td>
      <td>0.470353</td>
      <td>-0.782707</td>
      <td>0.246017</td>
      <td>0.975489</td>
      <td>0.042323</td>
      <td>-0.533283</td>
      <td>1.699399</td>
      <td>1.163993</td>
      <td>1.020034</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.268865</td>
      <td>0.493655</td>
      <td>-0.368493</td>
      <td>-0.113223</td>
      <td>1.021059</td>
      <td>0.592998</td>
      <td>-0.467910</td>
      <td>-0.728614</td>
      <td>-0.049784</td>
      <td>-0.317366</td>
      <td>-0.403446</td>
      <td>-0.272063</td>
      <td>-0.630567</td>
      <td>0.700313</td>
      <td>0.784287</td>
      <td>-0.073618</td>
      <td>0.359206</td>
      <td>0.567465</td>
      <td>0.463601</td>
      <td>-0.129217</td>
      <td>-0.755369</td>
      <td>0.231585</td>
      <td>1.130339</td>
      <td>1.058879</td>
      <td>0.252846</td>
      <td>0.576372</td>
      <td>-0.156623</td>
      <td>-0.584746</td>
      <td>-0.404995</td>
      <td>0.735946</td>
      <td>1.149751</td>
      <td>0.841976</td>
      <td>-0.399307</td>
      <td>0.718309</td>
      <td>0.292536</td>
      <td>0.865314</td>
      <td>0.402637</td>
      <td>0.659800</td>
      <td>0.805640</td>
      <td>1.160638</td>
      <td>...</td>
      <td>0.530445</td>
      <td>0.434507</td>
      <td>-0.225255</td>
      <td>0.353195</td>
      <td>-0.109445</td>
      <td>0.112819</td>
      <td>-0.140492</td>
      <td>-0.090132</td>
      <td>1.348812</td>
      <td>0.560606</td>
      <td>-0.093133</td>
      <td>-0.324180</td>
      <td>-0.398582</td>
      <td>0.504371</td>
      <td>-1.089045</td>
      <td>0.022353</td>
      <td>0.275389</td>
      <td>0.121313</td>
      <td>0.176465</td>
      <td>-0.175034</td>
      <td>-0.648243</td>
      <td>-0.142853</td>
      <td>0.289466</td>
      <td>-0.958742</td>
      <td>0.507217</td>
      <td>-0.828894</td>
      <td>-0.530318</td>
      <td>0.371016</td>
      <td>-0.290218</td>
      <td>-0.497054</td>
      <td>0.831163</td>
      <td>0.075288</td>
      <td>-0.096880</td>
      <td>0.453011</td>
      <td>0.763218</td>
      <td>-0.141307</td>
      <td>-0.123852</td>
      <td>0.394712</td>
      <td>0.043360</td>
      <td>0.202010</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.039582</td>
      <td>-0.611154</td>
      <td>0.418846</td>
      <td>0.634205</td>
      <td>0.971971</td>
      <td>0.944779</td>
      <td>-0.406495</td>
      <td>-0.520570</td>
      <td>-0.552372</td>
      <td>-0.803242</td>
      <td>0.279352</td>
      <td>0.711593</td>
      <td>-0.408677</td>
      <td>-0.181946</td>
      <td>0.120605</td>
      <td>0.954245</td>
      <td>0.285288</td>
      <td>-0.211600</td>
      <td>-0.828115</td>
      <td>-0.329011</td>
      <td>-0.410415</td>
      <td>-0.420673</td>
      <td>-0.397408</td>
      <td>-0.958825</td>
      <td>-0.448665</td>
      <td>0.144979</td>
      <td>-0.238745</td>
      <td>-0.643305</td>
      <td>-0.720542</td>
      <td>0.000760</td>
      <td>0.334483</td>
      <td>0.392589</td>
      <td>-0.228184</td>
      <td>-0.953280</td>
      <td>0.103583</td>
      <td>0.651556</td>
      <td>-0.057994</td>
      <td>0.569741</td>
      <td>1.336155</td>
      <td>0.621192</td>
      <td>...</td>
      <td>0.509657</td>
      <td>-1.009656</td>
      <td>-0.778825</td>
      <td>0.632703</td>
      <td>0.816229</td>
      <td>0.667478</td>
      <td>-0.279583</td>
      <td>-0.653495</td>
      <td>0.921424</td>
      <td>0.196033</td>
      <td>0.610652</td>
      <td>0.013410</td>
      <td>-0.565483</td>
      <td>0.090552</td>
      <td>-0.284900</td>
      <td>0.178300</td>
      <td>1.112433</td>
      <td>-0.833525</td>
      <td>0.064568</td>
      <td>-0.047871</td>
      <td>-0.197898</td>
      <td>0.072261</td>
      <td>0.097453</td>
      <td>-0.080835</td>
      <td>1.061882</td>
      <td>-0.278192</td>
      <td>0.468289</td>
      <td>0.077173</td>
      <td>-0.343051</td>
      <td>-0.931496</td>
      <td>-0.046912</td>
      <td>-0.818728</td>
      <td>-0.796867</td>
      <td>-0.178199</td>
      <td>-0.704402</td>
      <td>-1.088977</td>
      <td>-1.715821</td>
      <td>-0.188734</td>
      <td>-0.153247</td>
      <td>0.442109</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.012279</td>
      <td>-0.532448</td>
      <td>0.527189</td>
      <td>0.350332</td>
      <td>1.113210</td>
      <td>0.656765</td>
      <td>-0.607866</td>
      <td>-0.263339</td>
      <td>0.945078</td>
      <td>-0.473679</td>
      <td>0.068583</td>
      <td>0.667029</td>
      <td>0.177888</td>
      <td>-0.607445</td>
      <td>-1.146662</td>
      <td>0.299966</td>
      <td>0.225270</td>
      <td>-0.622503</td>
      <td>-0.764113</td>
      <td>-0.381386</td>
      <td>0.579179</td>
      <td>0.240470</td>
      <td>0.777775</td>
      <td>0.339028</td>
      <td>-0.133915</td>
      <td>-0.472954</td>
      <td>0.040544</td>
      <td>-0.456066</td>
      <td>0.043986</td>
      <td>0.338190</td>
      <td>0.764808</td>
      <td>0.149736</td>
      <td>0.226833</td>
      <td>-0.338636</td>
      <td>0.074429</td>
      <td>-0.191967</td>
      <td>-0.537298</td>
      <td>0.834699</td>
      <td>0.131460</td>
      <td>0.162699</td>
      <td>...</td>
      <td>0.103294</td>
      <td>-0.126801</td>
      <td>1.023070</td>
      <td>0.640513</td>
      <td>-0.944033</td>
      <td>-0.339652</td>
      <td>0.220837</td>
      <td>-0.529735</td>
      <td>0.788188</td>
      <td>0.493241</td>
      <td>0.127331</td>
      <td>0.417945</td>
      <td>0.908601</td>
      <td>0.882970</td>
      <td>-0.345722</td>
      <td>0.789891</td>
      <td>0.287742</td>
      <td>-0.689085</td>
      <td>-0.222769</td>
      <td>-0.415252</td>
      <td>-0.145056</td>
      <td>1.030106</td>
      <td>0.344020</td>
      <td>-0.199480</td>
      <td>1.361134</td>
      <td>0.044316</td>
      <td>-0.365950</td>
      <td>-0.189665</td>
      <td>-1.170734</td>
      <td>-0.229172</td>
      <td>-0.638012</td>
      <td>-0.108590</td>
      <td>-0.291155</td>
      <td>-0.813845</td>
      <td>-0.369089</td>
      <td>-0.083372</td>
      <td>-0.202936</td>
      <td>-0.192231</td>
      <td>-0.510007</td>
      <td>-0.077755</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.188047</td>
      <td>-0.651767</td>
      <td>-0.437146</td>
      <td>0.459896</td>
      <td>1.140085</td>
      <td>-0.139644</td>
      <td>-1.027160</td>
      <td>-0.671200</td>
      <td>0.148511</td>
      <td>-0.816352</td>
      <td>-0.126847</td>
      <td>-0.113109</td>
      <td>0.025058</td>
      <td>-0.128833</td>
      <td>-0.478181</td>
      <td>-0.504132</td>
      <td>-0.407194</td>
      <td>-0.833978</td>
      <td>-0.297910</td>
      <td>0.280371</td>
      <td>-0.602867</td>
      <td>-0.155131</td>
      <td>0.034697</td>
      <td>0.261484</td>
      <td>-0.180374</td>
      <td>-0.045482</td>
      <td>-0.384250</td>
      <td>-0.507195</td>
      <td>-0.488692</td>
      <td>-0.468411</td>
      <td>0.868131</td>
      <td>-0.531286</td>
      <td>0.140866</td>
      <td>0.076899</td>
      <td>0.442115</td>
      <td>0.019116</td>
      <td>-1.141206</td>
      <td>0.945658</td>
      <td>1.531114</td>
      <td>-0.621663</td>
      <td>...</td>
      <td>0.436849</td>
      <td>0.939915</td>
      <td>0.941065</td>
      <td>0.627299</td>
      <td>0.949608</td>
      <td>-0.030835</td>
      <td>-0.973854</td>
      <td>-0.067664</td>
      <td>0.324205</td>
      <td>0.462813</td>
      <td>0.514222</td>
      <td>0.447851</td>
      <td>-0.163043</td>
      <td>0.258917</td>
      <td>-1.050270</td>
      <td>0.292471</td>
      <td>0.736327</td>
      <td>-0.935802</td>
      <td>0.145171</td>
      <td>-0.252597</td>
      <td>0.154048</td>
      <td>0.454826</td>
      <td>0.289460</td>
      <td>-0.230648</td>
      <td>0.497623</td>
      <td>-0.063810</td>
      <td>0.168050</td>
      <td>-0.184648</td>
      <td>-0.432965</td>
      <td>-0.343442</td>
      <td>-0.088057</td>
      <td>0.546899</td>
      <td>0.757625</td>
      <td>0.213458</td>
      <td>-0.216485</td>
      <td>0.461178</td>
      <td>0.225821</td>
      <td>-1.153215</td>
      <td>-0.725618</td>
      <td>-0.289046</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.517398</td>
      <td>-0.552604</td>
      <td>-0.802692</td>
      <td>-0.858005</td>
      <td>-0.170881</td>
      <td>-0.688239</td>
      <td>-0.921830</td>
      <td>-0.195156</td>
      <td>-0.166599</td>
      <td>-0.343242</td>
      <td>0.569655</td>
      <td>-0.209127</td>
      <td>-0.561465</td>
      <td>-0.007223</td>
      <td>1.022125</td>
      <td>0.248561</td>
      <td>0.334479</td>
      <td>0.309887</td>
      <td>0.378264</td>
      <td>0.422011</td>
      <td>-0.971947</td>
      <td>-1.512378</td>
      <td>-0.238947</td>
      <td>0.633175</td>
      <td>-0.413892</td>
      <td>0.919262</td>
      <td>0.710031</td>
      <td>-0.058454</td>
      <td>-0.186838</td>
      <td>-0.563361</td>
      <td>-0.175103</td>
      <td>-0.269983</td>
      <td>-0.645592</td>
      <td>-0.536682</td>
      <td>0.086051</td>
      <td>-0.363526</td>
      <td>0.142680</td>
      <td>-0.145031</td>
      <td>0.678379</td>
      <td>0.621888</td>
      <td>...</td>
      <td>0.853300</td>
      <td>-0.604253</td>
      <td>0.639271</td>
      <td>-0.116170</td>
      <td>-0.367368</td>
      <td>0.826746</td>
      <td>-0.969198</td>
      <td>-0.586927</td>
      <td>1.102869</td>
      <td>-0.452067</td>
      <td>1.249070</td>
      <td>0.493660</td>
      <td>0.807505</td>
      <td>0.755728</td>
      <td>1.018894</td>
      <td>0.683852</td>
      <td>-0.489514</td>
      <td>-1.683874</td>
      <td>0.634516</td>
      <td>-1.469653</td>
      <td>-0.822496</td>
      <td>-0.352072</td>
      <td>-0.218884</td>
      <td>0.484199</td>
      <td>0.195308</td>
      <td>-0.107915</td>
      <td>0.855273</td>
      <td>0.266708</td>
      <td>0.106786</td>
      <td>0.198271</td>
      <td>-0.795347</td>
      <td>0.544523</td>
      <td>0.395336</td>
      <td>1.582195</td>
      <td>1.545357</td>
      <td>-0.323733</td>
      <td>-0.121804</td>
      <td>-0.696988</td>
      <td>-0.946304</td>
      <td>-0.574131</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.055049</td>
      <td>-0.364277</td>
      <td>0.327540</td>
      <td>-0.133077</td>
      <td>0.672570</td>
      <td>0.506425</td>
      <td>0.444270</td>
      <td>-0.881075</td>
      <td>0.733811</td>
      <td>-0.899728</td>
      <td>-0.549230</td>
      <td>0.065119</td>
      <td>1.231070</td>
      <td>2.584509</td>
      <td>0.017743</td>
      <td>0.610616</td>
      <td>0.570150</td>
      <td>0.783856</td>
      <td>0.545027</td>
      <td>-0.408742</td>
      <td>-1.001700</td>
      <td>0.066539</td>
      <td>0.435425</td>
      <td>0.475752</td>
      <td>-0.005971</td>
      <td>1.194019</td>
      <td>0.845872</td>
      <td>-0.711275</td>
      <td>0.177930</td>
      <td>0.716789</td>
      <td>0.548725</td>
      <td>0.268945</td>
      <td>-0.589519</td>
      <td>-0.815114</td>
      <td>0.316026</td>
      <td>1.190835</td>
      <td>-1.154434</td>
      <td>0.511186</td>
      <td>0.784687</td>
      <td>0.469597</td>
      <td>...</td>
      <td>1.322177</td>
      <td>-0.146865</td>
      <td>0.240100</td>
      <td>-0.208081</td>
      <td>-0.473915</td>
      <td>1.476137</td>
      <td>-1.117630</td>
      <td>-0.464884</td>
      <td>0.805469</td>
      <td>-0.009235</td>
      <td>0.271991</td>
      <td>-0.400393</td>
      <td>-0.746442</td>
      <td>0.231257</td>
      <td>-0.840397</td>
      <td>-0.366303</td>
      <td>0.735850</td>
      <td>0.575426</td>
      <td>0.957831</td>
      <td>-0.950930</td>
      <td>-0.045080</td>
      <td>0.490268</td>
      <td>0.027217</td>
      <td>0.412564</td>
      <td>0.711082</td>
      <td>0.700901</td>
      <td>-0.821936</td>
      <td>-0.803364</td>
      <td>-0.302131</td>
      <td>-0.425295</td>
      <td>-0.460672</td>
      <td>-0.670949</td>
      <td>0.604629</td>
      <td>-0.258481</td>
      <td>-0.670526</td>
      <td>-1.014810</td>
      <td>-0.921022</td>
      <td>-0.112791</td>
      <td>-0.482475</td>
      <td>-0.846628</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.388384</td>
      <td>1.075727</td>
      <td>-0.501140</td>
      <td>-0.212394</td>
      <td>-0.265803</td>
      <td>0.077620</td>
      <td>-0.261649</td>
      <td>-0.856038</td>
      <td>0.562229</td>
      <td>-0.107320</td>
      <td>0.985504</td>
      <td>0.242040</td>
      <td>-0.084957</td>
      <td>0.905283</td>
      <td>-0.083892</td>
      <td>-0.516853</td>
      <td>-0.729942</td>
      <td>-0.021370</td>
      <td>0.556051</td>
      <td>0.502149</td>
      <td>0.132401</td>
      <td>-0.111402</td>
      <td>-0.982861</td>
      <td>-0.323804</td>
      <td>-0.101902</td>
      <td>0.071431</td>
      <td>0.220599</td>
      <td>-0.284927</td>
      <td>0.808508</td>
      <td>0.055495</td>
      <td>-0.483050</td>
      <td>-0.762956</td>
      <td>0.090783</td>
      <td>-0.783538</td>
      <td>0.855153</td>
      <td>0.266361</td>
      <td>-0.436390</td>
      <td>0.217061</td>
      <td>1.062394</td>
      <td>-0.136957</td>
      <td>...</td>
      <td>0.213933</td>
      <td>-1.048763</td>
      <td>-0.303191</td>
      <td>-0.092207</td>
      <td>0.768124</td>
      <td>1.532455</td>
      <td>-0.114981</td>
      <td>-0.088855</td>
      <td>0.090597</td>
      <td>1.085772</td>
      <td>1.262629</td>
      <td>-0.184103</td>
      <td>-0.255523</td>
      <td>-0.929028</td>
      <td>-0.109050</td>
      <td>1.161472</td>
      <td>0.548858</td>
      <td>0.248889</td>
      <td>0.549214</td>
      <td>0.624710</td>
      <td>0.159187</td>
      <td>-0.021195</td>
      <td>-0.371394</td>
      <td>0.894001</td>
      <td>1.183081</td>
      <td>0.906333</td>
      <td>-0.829468</td>
      <td>-1.305330</td>
      <td>0.545265</td>
      <td>-0.440415</td>
      <td>-0.262097</td>
      <td>-1.025760</td>
      <td>-0.178574</td>
      <td>0.234500</td>
      <td>0.982846</td>
      <td>-0.986382</td>
      <td>0.343799</td>
      <td>-0.354383</td>
      <td>-0.436896</td>
      <td>0.106411</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.486057</td>
      <td>0.673093</td>
      <td>-0.165236</td>
      <td>0.070545</td>
      <td>0.881791</td>
      <td>-2.050397</td>
      <td>-1.754381</td>
      <td>-0.148766</td>
      <td>0.983407</td>
      <td>-0.016204</td>
      <td>-0.104680</td>
      <td>0.172793</td>
      <td>0.762524</td>
      <td>0.777432</td>
      <td>0.704905</td>
      <td>0.009402</td>
      <td>-0.193731</td>
      <td>-0.571622</td>
      <td>-0.668101</td>
      <td>0.283763</td>
      <td>-0.057408</td>
      <td>0.797731</td>
      <td>2.098939</td>
      <td>0.982832</td>
      <td>-0.125437</td>
      <td>-0.411686</td>
      <td>1.009754</td>
      <td>1.031146</td>
      <td>0.865847</td>
      <td>0.472501</td>
      <td>-1.078260</td>
      <td>-0.607651</td>
      <td>0.201130</td>
      <td>-1.025819</td>
      <td>0.219890</td>
      <td>0.230694</td>
      <td>-1.173554</td>
      <td>-0.606637</td>
      <td>0.312122</td>
      <td>0.519960</td>
      <td>...</td>
      <td>0.582299</td>
      <td>-0.417310</td>
      <td>0.646344</td>
      <td>0.109720</td>
      <td>-0.245832</td>
      <td>-0.277777</td>
      <td>-0.545060</td>
      <td>-1.079152</td>
      <td>0.343878</td>
      <td>-0.173478</td>
      <td>0.261202</td>
      <td>0.488727</td>
      <td>0.331787</td>
      <td>0.629226</td>
      <td>-0.505096</td>
      <td>-0.617728</td>
      <td>0.252443</td>
      <td>-0.342767</td>
      <td>0.539113</td>
      <td>0.592510</td>
      <td>-0.144937</td>
      <td>0.510470</td>
      <td>0.178819</td>
      <td>0.977733</td>
      <td>1.574695</td>
      <td>-0.420644</td>
      <td>0.353039</td>
      <td>0.531835</td>
      <td>-0.479359</td>
      <td>0.095927</td>
      <td>-0.343157</td>
      <td>0.411648</td>
      <td>0.632308</td>
      <td>0.330260</td>
      <td>0.651781</td>
      <td>-0.334775</td>
      <td>-0.067904</td>
      <td>0.197027</td>
      <td>0.465458</td>
      <td>0.641479</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.875661</td>
      <td>0.730655</td>
      <td>0.857605</td>
      <td>0.962885</td>
      <td>1.411200</td>
      <td>0.276293</td>
      <td>-0.389944</td>
      <td>0.514322</td>
      <td>0.621131</td>
      <td>-0.400580</td>
      <td>-0.477138</td>
      <td>-0.617935</td>
      <td>-0.272647</td>
      <td>0.414808</td>
      <td>0.222825</td>
      <td>0.024860</td>
      <td>0.388984</td>
      <td>0.259906</td>
      <td>-0.151976</td>
      <td>-0.163018</td>
      <td>0.900808</td>
      <td>0.423820</td>
      <td>-0.211254</td>
      <td>-0.772660</td>
      <td>-0.017596</td>
      <td>0.774132</td>
      <td>0.499330</td>
      <td>0.252932</td>
      <td>0.490261</td>
      <td>1.042800</td>
      <td>0.289107</td>
      <td>-0.674287</td>
      <td>-0.729896</td>
      <td>-1.376162</td>
      <td>0.292559</td>
      <td>0.143865</td>
      <td>-0.233149</td>
      <td>-0.502735</td>
      <td>0.857238</td>
      <td>0.528750</td>
      <td>...</td>
      <td>-0.466824</td>
      <td>-0.049532</td>
      <td>-0.098601</td>
      <td>-0.007905</td>
      <td>-0.019303</td>
      <td>0.767761</td>
      <td>0.441884</td>
      <td>-0.103294</td>
      <td>0.758599</td>
      <td>-0.507610</td>
      <td>-0.253272</td>
      <td>-0.515594</td>
      <td>0.839951</td>
      <td>0.235212</td>
      <td>0.037400</td>
      <td>-0.738970</td>
      <td>-0.158034</td>
      <td>-0.139160</td>
      <td>0.006025</td>
      <td>-0.810045</td>
      <td>0.313850</td>
      <td>-0.017137</td>
      <td>-0.218417</td>
      <td>-1.447073</td>
      <td>0.637588</td>
      <td>0.071550</td>
      <td>-0.624292</td>
      <td>-0.449950</td>
      <td>-0.447056</td>
      <td>-0.510284</td>
      <td>-0.003828</td>
      <td>0.045517</td>
      <td>-0.515627</td>
      <td>-0.284491</td>
      <td>0.707527</td>
      <td>-0.896638</td>
      <td>-0.375134</td>
      <td>-0.154774</td>
      <td>0.212973</td>
      <td>0.359160</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.277856</td>
      <td>-0.299789</td>
      <td>-0.376148</td>
      <td>-0.522066</td>
      <td>0.047344</td>
      <td>0.225006</td>
      <td>0.004426</td>
      <td>0.034119</td>
      <td>-0.753192</td>
      <td>-0.754411</td>
      <td>-0.741314</td>
      <td>-1.191247</td>
      <td>0.141370</td>
      <td>-0.388202</td>
      <td>-0.584537</td>
      <td>-0.076725</td>
      <td>-0.833884</td>
      <td>-0.788374</td>
      <td>-0.695532</td>
      <td>0.212597</td>
      <td>0.575332</td>
      <td>-0.153945</td>
      <td>-0.561335</td>
      <td>-0.248138</td>
      <td>0.292741</td>
      <td>-0.003908</td>
      <td>1.091377</td>
      <td>-0.269794</td>
      <td>0.522943</td>
      <td>-0.251788</td>
      <td>-0.079982</td>
      <td>0.941332</td>
      <td>-0.574554</td>
      <td>-0.373389</td>
      <td>-0.138475</td>
      <td>1.510945</td>
      <td>0.224687</td>
      <td>0.587529</td>
      <td>0.224201</td>
      <td>-0.258150</td>
      <td>...</td>
      <td>-0.229309</td>
      <td>-1.207667</td>
      <td>0.413875</td>
      <td>0.442182</td>
      <td>-0.221758</td>
      <td>0.338905</td>
      <td>-0.385971</td>
      <td>-0.337934</td>
      <td>0.687928</td>
      <td>-0.038351</td>
      <td>-0.454614</td>
      <td>-0.316101</td>
      <td>0.321387</td>
      <td>0.429351</td>
      <td>-1.110270</td>
      <td>1.063680</td>
      <td>0.724449</td>
      <td>-0.630900</td>
      <td>0.163632</td>
      <td>0.128047</td>
      <td>0.460893</td>
      <td>0.650938</td>
      <td>-0.324778</td>
      <td>0.049216</td>
      <td>0.926067</td>
      <td>-1.246284</td>
      <td>-0.579571</td>
      <td>-0.718001</td>
      <td>-0.805793</td>
      <td>-1.096166</td>
      <td>0.050223</td>
      <td>0.883077</td>
      <td>1.316797</td>
      <td>1.463956</td>
      <td>0.159165</td>
      <td>-0.393190</td>
      <td>-0.582066</td>
      <td>-0.937729</td>
      <td>-0.151774</td>
      <td>0.741091</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.472998</td>
      <td>-0.231747</td>
      <td>0.429715</td>
      <td>0.676655</td>
      <td>0.674200</td>
      <td>0.159159</td>
      <td>-0.940400</td>
      <td>-0.788590</td>
      <td>0.023798</td>
      <td>0.190456</td>
      <td>0.753481</td>
      <td>-0.156173</td>
      <td>-0.027264</td>
      <td>1.193601</td>
      <td>0.020759</td>
      <td>0.194487</td>
      <td>-1.026484</td>
      <td>-0.552547</td>
      <td>-0.988121</td>
      <td>-0.082350</td>
      <td>-0.062413</td>
      <td>0.822425</td>
      <td>0.039258</td>
      <td>-0.149315</td>
      <td>1.071194</td>
      <td>0.100612</td>
      <td>0.267730</td>
      <td>-0.051497</td>
      <td>-0.296228</td>
      <td>-0.084587</td>
      <td>0.211555</td>
      <td>-0.132920</td>
      <td>-0.819811</td>
      <td>0.432616</td>
      <td>0.012888</td>
      <td>-0.298614</td>
      <td>0.550636</td>
      <td>-0.108220</td>
      <td>0.153732</td>
      <td>1.056080</td>
      <td>...</td>
      <td>0.497888</td>
      <td>0.280551</td>
      <td>1.307569</td>
      <td>1.490060</td>
      <td>0.415210</td>
      <td>0.245314</td>
      <td>0.000805</td>
      <td>0.810299</td>
      <td>0.929512</td>
      <td>-0.079201</td>
      <td>-0.038982</td>
      <td>0.140825</td>
      <td>0.502323</td>
      <td>0.028885</td>
      <td>-0.256972</td>
      <td>0.399512</td>
      <td>-0.426989</td>
      <td>-1.144298</td>
      <td>1.049322</td>
      <td>0.774702</td>
      <td>-0.155421</td>
      <td>0.267635</td>
      <td>0.125818</td>
      <td>-0.194573</td>
      <td>1.136734</td>
      <td>0.098766</td>
      <td>-0.404556</td>
      <td>-0.689107</td>
      <td>-1.044052</td>
      <td>-0.721651</td>
      <td>1.046200</td>
      <td>-0.026932</td>
      <td>-0.330537</td>
      <td>-0.479057</td>
      <td>-0.607549</td>
      <td>0.001597</td>
      <td>-0.436375</td>
      <td>-0.565279</td>
      <td>-0.816569</td>
      <td>-0.548786</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.638482</td>
      <td>-0.107268</td>
      <td>0.996071</td>
      <td>0.254143</td>
      <td>1.168521</td>
      <td>-0.122192</td>
      <td>-0.309442</td>
      <td>0.050428</td>
      <td>-0.075428</td>
      <td>-0.220962</td>
      <td>0.511735</td>
      <td>0.207220</td>
      <td>-0.737296</td>
      <td>0.247706</td>
      <td>0.185613</td>
      <td>0.818856</td>
      <td>0.017084</td>
      <td>-0.213978</td>
      <td>-0.187813</td>
      <td>-0.640585</td>
      <td>-1.055139</td>
      <td>-1.346889</td>
      <td>-0.716505</td>
      <td>0.462680</td>
      <td>0.567679</td>
      <td>0.391390</td>
      <td>0.227668</td>
      <td>-0.238099</td>
      <td>-1.073618</td>
      <td>0.051828</td>
      <td>-1.062877</td>
      <td>-0.735219</td>
      <td>-0.574513</td>
      <td>0.322151</td>
      <td>-0.908847</td>
      <td>-0.457408</td>
      <td>0.915773</td>
      <td>1.187934</td>
      <td>0.156640</td>
      <td>0.062306</td>
      <td>...</td>
      <td>0.177038</td>
      <td>0.025299</td>
      <td>-0.226030</td>
      <td>0.254502</td>
      <td>0.312158</td>
      <td>0.455295</td>
      <td>0.062688</td>
      <td>-0.716871</td>
      <td>0.644601</td>
      <td>-0.404384</td>
      <td>-0.225702</td>
      <td>0.220017</td>
      <td>0.478201</td>
      <td>-0.055203</td>
      <td>-0.536087</td>
      <td>-0.537412</td>
      <td>0.216501</td>
      <td>-0.235709</td>
      <td>1.895153</td>
      <td>0.620603</td>
      <td>-0.650607</td>
      <td>-0.265264</td>
      <td>-1.037693</td>
      <td>-0.287247</td>
      <td>0.873703</td>
      <td>1.330732</td>
      <td>0.655304</td>
      <td>-0.067380</td>
      <td>-0.982646</td>
      <td>-1.182158</td>
      <td>-0.371847</td>
      <td>-0.362791</td>
      <td>0.142723</td>
      <td>0.110746</td>
      <td>0.420457</td>
      <td>0.201474</td>
      <td>-0.032134</td>
      <td>-1.220846</td>
      <td>-1.047414</td>
      <td>-0.619853</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.666565</td>
      <td>-0.387605</td>
      <td>-0.401286</td>
      <td>0.314355</td>
      <td>0.355523</td>
      <td>0.179323</td>
      <td>-0.787464</td>
      <td>-0.914637</td>
      <td>-0.277586</td>
      <td>-1.074128</td>
      <td>-1.039654</td>
      <td>1.105494</td>
      <td>0.594021</td>
      <td>1.295194</td>
      <td>-0.040649</td>
      <td>-0.195311</td>
      <td>0.852700</td>
      <td>0.510027</td>
      <td>0.324688</td>
      <td>0.484317</td>
      <td>0.474373</td>
      <td>0.600731</td>
      <td>-0.065325</td>
      <td>0.126712</td>
      <td>0.500746</td>
      <td>0.640118</td>
      <td>-0.785614</td>
      <td>-0.656986</td>
      <td>-0.709999</td>
      <td>-0.127523</td>
      <td>0.938134</td>
      <td>0.776716</td>
      <td>0.122071</td>
      <td>-0.204500</td>
      <td>0.236848</td>
      <td>-0.099803</td>
      <td>-0.166794</td>
      <td>-0.234313</td>
      <td>0.572215</td>
      <td>0.276117</td>
      <td>...</td>
      <td>-0.198893</td>
      <td>-0.531055</td>
      <td>0.371500</td>
      <td>0.473145</td>
      <td>-0.732091</td>
      <td>0.642743</td>
      <td>-1.480107</td>
      <td>-0.426945</td>
      <td>0.742389</td>
      <td>1.295000</td>
      <td>1.131363</td>
      <td>0.808646</td>
      <td>0.008405</td>
      <td>0.769572</td>
      <td>-0.443193</td>
      <td>-0.369397</td>
      <td>-0.476665</td>
      <td>-0.107713</td>
      <td>1.112147</td>
      <td>-0.179194</td>
      <td>0.079866</td>
      <td>0.636093</td>
      <td>0.524735</td>
      <td>-0.652197</td>
      <td>-0.065944</td>
      <td>0.200257</td>
      <td>-0.696727</td>
      <td>-0.290185</td>
      <td>-0.728597</td>
      <td>-0.045445</td>
      <td>-1.252627</td>
      <td>0.124986</td>
      <td>0.006999</td>
      <td>-0.944654</td>
      <td>0.043060</td>
      <td>0.336262</td>
      <td>0.237715</td>
      <td>-2.884758</td>
      <td>-2.388661</td>
      <td>-0.633561</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.270283</td>
      <td>-0.880756</td>
      <td>-1.000330</td>
      <td>-0.010271</td>
      <td>0.763445</td>
      <td>-0.611376</td>
      <td>0.044739</td>
      <td>0.696570</td>
      <td>-0.557811</td>
      <td>-0.922979</td>
      <td>0.012093</td>
      <td>0.451830</td>
      <td>-0.110177</td>
      <td>-0.079688</td>
      <td>0.212445</td>
      <td>0.597768</td>
      <td>-0.123329</td>
      <td>-1.204314</td>
      <td>-0.291787</td>
      <td>-0.593828</td>
      <td>-0.287770</td>
      <td>-0.217800</td>
      <td>0.252837</td>
      <td>0.927546</td>
      <td>0.835338</td>
      <td>0.110479</td>
      <td>0.376650</td>
      <td>0.156752</td>
      <td>0.560110</td>
      <td>0.463100</td>
      <td>-0.074702</td>
      <td>0.034248</td>
      <td>-0.413057</td>
      <td>-1.214478</td>
      <td>0.401478</td>
      <td>0.769481</td>
      <td>-1.063018</td>
      <td>-0.700367</td>
      <td>-0.149812</td>
      <td>0.661826</td>
      <td>...</td>
      <td>-0.003281</td>
      <td>-0.216229</td>
      <td>-0.284543</td>
      <td>0.712734</td>
      <td>-0.262433</td>
      <td>1.067522</td>
      <td>0.258296</td>
      <td>0.680380</td>
      <td>0.797548</td>
      <td>0.087946</td>
      <td>0.592969</td>
      <td>0.659552</td>
      <td>0.344355</td>
      <td>0.416287</td>
      <td>-1.269985</td>
      <td>-0.461884</td>
      <td>0.400153</td>
      <td>-0.220916</td>
      <td>0.112303</td>
      <td>1.793826</td>
      <td>-0.833446</td>
      <td>-1.245025</td>
      <td>-0.400628</td>
      <td>-0.317748</td>
      <td>0.661695</td>
      <td>0.422542</td>
      <td>-0.126198</td>
      <td>0.900816</td>
      <td>-0.770405</td>
      <td>-1.635557</td>
      <td>-0.890307</td>
      <td>0.289053</td>
      <td>-0.046157</td>
      <td>0.286930</td>
      <td>0.144203</td>
      <td>-0.651733</td>
      <td>1.288619</td>
      <td>-2.318563</td>
      <td>-1.788291</td>
      <td>-0.320675</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.443221</td>
      <td>0.969737</td>
      <td>1.170460</td>
      <td>1.057143</td>
      <td>1.083700</td>
      <td>0.439456</td>
      <td>-0.644713</td>
      <td>-0.306637</td>
      <td>-0.288285</td>
      <td>0.180730</td>
      <td>0.302858</td>
      <td>-0.082107</td>
      <td>0.315833</td>
      <td>0.245368</td>
      <td>-0.710805</td>
      <td>-0.394943</td>
      <td>-1.055725</td>
      <td>-0.427153</td>
      <td>-0.153947</td>
      <td>0.351763</td>
      <td>-0.565227</td>
      <td>-1.266956</td>
      <td>0.088482</td>
      <td>0.724341</td>
      <td>0.728768</td>
      <td>0.324084</td>
      <td>0.062765</td>
      <td>-0.288160</td>
      <td>-0.196374</td>
      <td>-0.667847</td>
      <td>0.224809</td>
      <td>0.374251</td>
      <td>-0.336733</td>
      <td>-0.872322</td>
      <td>-0.300894</td>
      <td>-1.009292</td>
      <td>-0.454710</td>
      <td>0.062828</td>
      <td>-0.407229</td>
      <td>-0.529451</td>
      <td>...</td>
      <td>0.350876</td>
      <td>-0.467943</td>
      <td>-0.168493</td>
      <td>0.087573</td>
      <td>0.386973</td>
      <td>0.645830</td>
      <td>-1.061475</td>
      <td>-0.478447</td>
      <td>0.355902</td>
      <td>-0.037196</td>
      <td>-0.469564</td>
      <td>0.315359</td>
      <td>0.402861</td>
      <td>1.311604</td>
      <td>-0.478427</td>
      <td>0.037506</td>
      <td>0.206616</td>
      <td>-1.039293</td>
      <td>0.724308</td>
      <td>0.432463</td>
      <td>0.652099</td>
      <td>0.137488</td>
      <td>-0.507095</td>
      <td>-0.995071</td>
      <td>1.560162</td>
      <td>1.837601</td>
      <td>0.911415</td>
      <td>-0.635233</td>
      <td>0.396110</td>
      <td>1.086994</td>
      <td>0.001594</td>
      <td>-1.258906</td>
      <td>0.716909</td>
      <td>0.500902</td>
      <td>0.107933</td>
      <td>-1.107944</td>
      <td>-0.317787</td>
      <td>2.097729</td>
      <td>1.267827</td>
      <td>1.347781</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.245797</td>
      <td>-0.714422</td>
      <td>-0.860014</td>
      <td>-0.492092</td>
      <td>-0.456516</td>
      <td>-0.758441</td>
      <td>-1.229310</td>
      <td>-0.447470</td>
      <td>-0.469561</td>
      <td>-1.312838</td>
      <td>0.169890</td>
      <td>0.497447</td>
      <td>0.819013</td>
      <td>-0.002719</td>
      <td>0.116723</td>
      <td>-0.085199</td>
      <td>-0.546576</td>
      <td>-0.187500</td>
      <td>-0.481577</td>
      <td>-0.174105</td>
      <td>0.201374</td>
      <td>0.617353</td>
      <td>0.423736</td>
      <td>-0.283204</td>
      <td>-0.337098</td>
      <td>-0.220753</td>
      <td>-0.426889</td>
      <td>-0.626622</td>
      <td>-0.200801</td>
      <td>0.043356</td>
      <td>-0.554958</td>
      <td>-0.004349</td>
      <td>0.127840</td>
      <td>-1.448508</td>
      <td>-0.806994</td>
      <td>0.793889</td>
      <td>-0.093849</td>
      <td>0.094231</td>
      <td>0.232108</td>
      <td>0.007594</td>
      <td>...</td>
      <td>0.858652</td>
      <td>-0.511412</td>
      <td>0.116933</td>
      <td>-0.136130</td>
      <td>0.176785</td>
      <td>1.249130</td>
      <td>-0.440359</td>
      <td>-0.040115</td>
      <td>0.390948</td>
      <td>-0.400735</td>
      <td>-0.164920</td>
      <td>0.273961</td>
      <td>1.198167</td>
      <td>0.892003</td>
      <td>0.108400</td>
      <td>0.476629</td>
      <td>0.316410</td>
      <td>-0.896931</td>
      <td>-0.394935</td>
      <td>0.862902</td>
      <td>0.127761</td>
      <td>0.417700</td>
      <td>0.836159</td>
      <td>0.242127</td>
      <td>1.261247</td>
      <td>-0.399001</td>
      <td>-0.939111</td>
      <td>-1.230521</td>
      <td>-0.683088</td>
      <td>-0.588834</td>
      <td>-0.404090</td>
      <td>-0.232893</td>
      <td>-0.641452</td>
      <td>0.516030</td>
      <td>-0.551200</td>
      <td>-1.051432</td>
      <td>-0.734094</td>
      <td>-2.510046</td>
      <td>-1.793140</td>
      <td>-0.492450</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.426235</td>
      <td>0.073274</td>
      <td>0.522805</td>
      <td>0.818363</td>
      <td>0.329363</td>
      <td>0.365251</td>
      <td>-0.444183</td>
      <td>0.101166</td>
      <td>0.584191</td>
      <td>-0.071062</td>
      <td>0.518024</td>
      <td>1.321375</td>
      <td>1.818138</td>
      <td>-0.216187</td>
      <td>-1.349400</td>
      <td>-1.337388</td>
      <td>-1.347864</td>
      <td>0.367921</td>
      <td>0.861651</td>
      <td>1.511440</td>
      <td>0.115093</td>
      <td>-0.140876</td>
      <td>0.038723</td>
      <td>0.089753</td>
      <td>-0.024931</td>
      <td>0.083883</td>
      <td>-0.292579</td>
      <td>-0.145792</td>
      <td>0.792377</td>
      <td>1.247312</td>
      <td>-0.118022</td>
      <td>-1.343874</td>
      <td>-0.205406</td>
      <td>-0.954750</td>
      <td>0.055789</td>
      <td>0.218592</td>
      <td>-0.197596</td>
      <td>0.440046</td>
      <td>0.211631</td>
      <td>0.635219</td>
      <td>...</td>
      <td>-0.162582</td>
      <td>0.437575</td>
      <td>-0.065772</td>
      <td>0.353283</td>
      <td>-0.179625</td>
      <td>0.216896</td>
      <td>-0.039327</td>
      <td>-0.267257</td>
      <td>0.708985</td>
      <td>1.186256</td>
      <td>0.646532</td>
      <td>0.035666</td>
      <td>0.586261</td>
      <td>0.400731</td>
      <td>0.135120</td>
      <td>-0.323999</td>
      <td>0.397566</td>
      <td>-1.869833</td>
      <td>-0.840423</td>
      <td>-0.235653</td>
      <td>-0.924570</td>
      <td>0.375004</td>
      <td>-1.713054</td>
      <td>-0.105223</td>
      <td>0.872014</td>
      <td>-0.157929</td>
      <td>0.202242</td>
      <td>-0.362363</td>
      <td>-0.205976</td>
      <td>0.538345</td>
      <td>0.648461</td>
      <td>0.048298</td>
      <td>0.763344</td>
      <td>-0.150504</td>
      <td>0.112070</td>
      <td>-1.280752</td>
      <td>-0.088263</td>
      <td>-0.386430</td>
      <td>-0.173164</td>
      <td>-0.019030</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-0.036048</td>
      <td>-0.230310</td>
      <td>-0.365972</td>
      <td>-0.606325</td>
      <td>-0.384952</td>
      <td>0.071103</td>
      <td>-1.139815</td>
      <td>0.170529</td>
      <td>0.527587</td>
      <td>-0.650798</td>
      <td>0.432264</td>
      <td>1.101994</td>
      <td>-0.048565</td>
      <td>0.071170</td>
      <td>0.921621</td>
      <td>1.585785</td>
      <td>0.037093</td>
      <td>0.546711</td>
      <td>0.955386</td>
      <td>0.790658</td>
      <td>0.318947</td>
      <td>1.027132</td>
      <td>0.407195</td>
      <td>-0.202292</td>
      <td>-0.619127</td>
      <td>1.255486</td>
      <td>-0.772047</td>
      <td>-0.285798</td>
      <td>-0.351805</td>
      <td>-0.165470</td>
      <td>0.317941</td>
      <td>0.860355</td>
      <td>0.467131</td>
      <td>0.994921</td>
      <td>0.513307</td>
      <td>0.946931</td>
      <td>-0.471441</td>
      <td>0.250187</td>
      <td>-0.292937</td>
      <td>0.656232</td>
      <td>...</td>
      <td>0.043765</td>
      <td>0.312875</td>
      <td>0.466939</td>
      <td>-0.366158</td>
      <td>-0.104260</td>
      <td>0.718524</td>
      <td>-0.083596</td>
      <td>0.003212</td>
      <td>0.120964</td>
      <td>0.387920</td>
      <td>0.656080</td>
      <td>0.089858</td>
      <td>-0.337349</td>
      <td>0.907338</td>
      <td>0.028501</td>
      <td>0.321077</td>
      <td>0.466918</td>
      <td>0.013682</td>
      <td>0.711324</td>
      <td>-0.258892</td>
      <td>-0.167629</td>
      <td>0.951508</td>
      <td>-0.164954</td>
      <td>-0.856119</td>
      <td>0.314791</td>
      <td>0.544734</td>
      <td>0.596831</td>
      <td>0.380727</td>
      <td>-0.956465</td>
      <td>-1.123980</td>
      <td>-0.375393</td>
      <td>-0.316825</td>
      <td>-0.133003</td>
      <td>-0.285677</td>
      <td>-0.056610</td>
      <td>0.074317</td>
      <td>0.390246</td>
      <td>-1.184331</td>
      <td>-0.556026</td>
      <td>-0.087052</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>0.416113</td>
      <td>-0.185352</td>
      <td>0.567087</td>
      <td>0.526671</td>
      <td>-0.041010</td>
      <td>0.647828</td>
      <td>0.692320</td>
      <td>1.214364</td>
      <td>0.799384</td>
      <td>-0.312326</td>
      <td>-1.017844</td>
      <td>0.855862</td>
      <td>0.224105</td>
      <td>-0.797736</td>
      <td>0.115550</td>
      <td>0.348469</td>
      <td>-0.094411</td>
      <td>-0.187390</td>
      <td>0.263670</td>
      <td>0.652785</td>
      <td>-0.495713</td>
      <td>-0.106478</td>
      <td>0.168376</td>
      <td>1.311213</td>
      <td>-0.357422</td>
      <td>-0.192037</td>
      <td>0.044068</td>
      <td>1.082958</td>
      <td>0.681463</td>
      <td>-0.765108</td>
      <td>-0.159615</td>
      <td>1.893053</td>
      <td>0.434868</td>
      <td>-0.396606</td>
      <td>-0.094987</td>
      <td>-0.100364</td>
      <td>0.672344</td>
      <td>0.038168</td>
      <td>0.784258</td>
      <td>-0.224761</td>
      <td>...</td>
      <td>0.940179</td>
      <td>-0.042342</td>
      <td>0.716126</td>
      <td>0.707584</td>
      <td>0.541323</td>
      <td>0.250312</td>
      <td>-0.260892</td>
      <td>-0.826828</td>
      <td>-1.501023</td>
      <td>0.483498</td>
      <td>-0.312502</td>
      <td>0.017693</td>
      <td>0.446355</td>
      <td>-0.747391</td>
      <td>0.421272</td>
      <td>0.425036</td>
      <td>0.310522</td>
      <td>-0.542533</td>
      <td>-0.448838</td>
      <td>0.063273</td>
      <td>-0.025379</td>
      <td>-0.114239</td>
      <td>-0.200580</td>
      <td>0.564702</td>
      <td>0.746154</td>
      <td>1.102437</td>
      <td>0.604666</td>
      <td>-0.088410</td>
      <td>0.745427</td>
      <td>0.209649</td>
      <td>0.149222</td>
      <td>-0.024806</td>
      <td>-0.404168</td>
      <td>-0.882391</td>
      <td>-0.659969</td>
      <td>0.671113</td>
      <td>0.536183</td>
      <td>0.068901</td>
      <td>-0.076762</td>
      <td>0.129903</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.394762</td>
      <td>-1.021393</td>
      <td>0.735113</td>
      <td>0.380467</td>
      <td>-0.359648</td>
      <td>0.816558</td>
      <td>0.347930</td>
      <td>0.109187</td>
      <td>-0.028447</td>
      <td>-0.887845</td>
      <td>-0.296250</td>
      <td>-0.125412</td>
      <td>0.398309</td>
      <td>1.366859</td>
      <td>0.633686</td>
      <td>-0.410200</td>
      <td>-1.239259</td>
      <td>-0.548409</td>
      <td>0.411239</td>
      <td>-0.529814</td>
      <td>0.019284</td>
      <td>0.442828</td>
      <td>0.591969</td>
      <td>-0.897085</td>
      <td>-0.957811</td>
      <td>-0.773226</td>
      <td>-1.892065</td>
      <td>0.042381</td>
      <td>-0.045459</td>
      <td>-0.101390</td>
      <td>0.099815</td>
      <td>0.698000</td>
      <td>-0.232203</td>
      <td>-0.593988</td>
      <td>0.059915</td>
      <td>-0.273901</td>
      <td>1.015431</td>
      <td>0.376699</td>
      <td>-0.181240</td>
      <td>-0.232990</td>
      <td>...</td>
      <td>0.687170</td>
      <td>0.000206</td>
      <td>-0.108632</td>
      <td>0.573835</td>
      <td>-0.097761</td>
      <td>-0.101637</td>
      <td>0.341578</td>
      <td>0.743979</td>
      <td>0.318078</td>
      <td>0.352176</td>
      <td>0.862573</td>
      <td>0.673650</td>
      <td>1.148569</td>
      <td>0.133291</td>
      <td>0.395562</td>
      <td>0.319928</td>
      <td>0.652743</td>
      <td>-0.456038</td>
      <td>-0.576124</td>
      <td>0.110322</td>
      <td>0.131154</td>
      <td>-0.752394</td>
      <td>-0.261754</td>
      <td>-0.359349</td>
      <td>1.294434</td>
      <td>0.367829</td>
      <td>0.588247</td>
      <td>1.129253</td>
      <td>-0.390885</td>
      <td>1.354937</td>
      <td>0.945700</td>
      <td>0.008190</td>
      <td>0.282253</td>
      <td>0.390038</td>
      <td>0.546314</td>
      <td>-0.155129</td>
      <td>0.102616</td>
      <td>1.644674</td>
      <td>1.002152</td>
      <td>0.559929</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.775295</td>
      <td>-0.274971</td>
      <td>0.404571</td>
      <td>-0.131783</td>
      <td>-0.823853</td>
      <td>-0.224765</td>
      <td>0.537730</td>
      <td>0.257963</td>
      <td>0.364162</td>
      <td>1.313161</td>
      <td>-0.063693</td>
      <td>0.039677</td>
      <td>-0.067478</td>
      <td>0.382544</td>
      <td>0.195013</td>
      <td>0.087818</td>
      <td>-0.033971</td>
      <td>-1.143077</td>
      <td>1.385779</td>
      <td>0.561902</td>
      <td>-0.479608</td>
      <td>-0.719916</td>
      <td>0.236999</td>
      <td>-1.119331</td>
      <td>-0.041839</td>
      <td>0.144674</td>
      <td>-1.094660</td>
      <td>-0.813727</td>
      <td>-1.233060</td>
      <td>-0.504492</td>
      <td>-1.410487</td>
      <td>-0.762819</td>
      <td>-1.123628</td>
      <td>-1.169880</td>
      <td>0.094442</td>
      <td>-0.914700</td>
      <td>-0.050959</td>
      <td>-0.733532</td>
      <td>-0.986273</td>
      <td>-0.749545</td>
      <td>...</td>
      <td>0.816873</td>
      <td>-0.103397</td>
      <td>0.846113</td>
      <td>0.898560</td>
      <td>-0.666539</td>
      <td>0.703133</td>
      <td>0.108395</td>
      <td>-0.685647</td>
      <td>-0.364485</td>
      <td>0.391596</td>
      <td>0.018800</td>
      <td>-0.272538</td>
      <td>-0.111768</td>
      <td>-0.886725</td>
      <td>-0.417708</td>
      <td>0.579657</td>
      <td>0.355844</td>
      <td>-0.794790</td>
      <td>-0.205483</td>
      <td>-0.352815</td>
      <td>-0.502643</td>
      <td>-0.879702</td>
      <td>0.428811</td>
      <td>0.325775</td>
      <td>0.742606</td>
      <td>-0.084627</td>
      <td>-0.200630</td>
      <td>-0.196257</td>
      <td>-0.353312</td>
      <td>0.403130</td>
      <td>-0.435320</td>
      <td>-0.494670</td>
      <td>-0.467762</td>
      <td>-0.040435</td>
      <td>-0.378629</td>
      <td>1.059024</td>
      <td>0.043977</td>
      <td>-2.190374</td>
      <td>-1.660458</td>
      <td>-0.912861</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.456509</td>
      <td>0.932146</td>
      <td>1.118342</td>
      <td>-0.483901</td>
      <td>-0.352964</td>
      <td>-0.067340</td>
      <td>0.695687</td>
      <td>0.459947</td>
      <td>0.114069</td>
      <td>0.616228</td>
      <td>0.400547</td>
      <td>1.444524</td>
      <td>-0.163893</td>
      <td>1.000310</td>
      <td>0.386616</td>
      <td>-0.219435</td>
      <td>0.557282</td>
      <td>0.219954</td>
      <td>-0.168863</td>
      <td>-0.797667</td>
      <td>-0.358204</td>
      <td>-0.325584</td>
      <td>-0.024973</td>
      <td>-0.085105</td>
      <td>-0.598909</td>
      <td>0.244852</td>
      <td>-0.278811</td>
      <td>-0.180357</td>
      <td>0.540632</td>
      <td>-0.022984</td>
      <td>-0.397679</td>
      <td>0.937251</td>
      <td>0.538337</td>
      <td>-0.577383</td>
      <td>-0.512862</td>
      <td>-0.449172</td>
      <td>-0.613547</td>
      <td>-0.372132</td>
      <td>0.442737</td>
      <td>-0.944456</td>
      <td>...</td>
      <td>1.029617</td>
      <td>0.562191</td>
      <td>0.079712</td>
      <td>0.186098</td>
      <td>-0.921210</td>
      <td>-1.468168</td>
      <td>-0.947171</td>
      <td>-1.269232</td>
      <td>-0.397887</td>
      <td>-0.887753</td>
      <td>-1.105972</td>
      <td>-1.160786</td>
      <td>-0.818287</td>
      <td>-0.982647</td>
      <td>0.049688</td>
      <td>-0.347445</td>
      <td>0.869547</td>
      <td>0.003708</td>
      <td>-0.712241</td>
      <td>-0.326352</td>
      <td>1.110403</td>
      <td>0.964719</td>
      <td>0.185676</td>
      <td>0.372068</td>
      <td>1.188825</td>
      <td>-0.308266</td>
      <td>1.314645</td>
      <td>-0.059872</td>
      <td>-0.285253</td>
      <td>-0.004324</td>
      <td>-0.109321</td>
      <td>0.025929</td>
      <td>0.234890</td>
      <td>-1.129633</td>
      <td>-0.411579</td>
      <td>-0.612068</td>
      <td>-1.060532</td>
      <td>0.314981</td>
      <td>0.349801</td>
      <td>-0.471068</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.323578</td>
      <td>0.285507</td>
      <td>0.963548</td>
      <td>0.620228</td>
      <td>1.037222</td>
      <td>0.598554</td>
      <td>0.060493</td>
      <td>0.030172</td>
      <td>-0.953941</td>
      <td>-0.081215</td>
      <td>-0.299847</td>
      <td>0.432990</td>
      <td>0.646653</td>
      <td>-0.596170</td>
      <td>-1.131229</td>
      <td>-0.714124</td>
      <td>-0.392508</td>
      <td>-0.689545</td>
      <td>0.372434</td>
      <td>0.300849</td>
      <td>0.611509</td>
      <td>-0.554899</td>
      <td>1.132516</td>
      <td>0.057426</td>
      <td>0.115697</td>
      <td>-0.491681</td>
      <td>-0.592457</td>
      <td>0.080641</td>
      <td>-0.408749</td>
      <td>-1.204809</td>
      <td>-0.455348</td>
      <td>0.484668</td>
      <td>0.216444</td>
      <td>0.764486</td>
      <td>-0.198052</td>
      <td>-1.068209</td>
      <td>-0.826061</td>
      <td>-1.211923</td>
      <td>-0.374504</td>
      <td>-0.630370</td>
      <td>...</td>
      <td>0.877241</td>
      <td>0.934516</td>
      <td>0.049261</td>
      <td>-0.712853</td>
      <td>-0.585081</td>
      <td>-0.528317</td>
      <td>-0.096647</td>
      <td>1.132101</td>
      <td>-0.294552</td>
      <td>0.626960</td>
      <td>0.404839</td>
      <td>0.292742</td>
      <td>0.208613</td>
      <td>0.109414</td>
      <td>0.600812</td>
      <td>1.364040</td>
      <td>-0.733220</td>
      <td>0.700473</td>
      <td>-0.061639</td>
      <td>-0.600216</td>
      <td>-0.093348</td>
      <td>0.694937</td>
      <td>0.704861</td>
      <td>-0.507899</td>
      <td>1.188547</td>
      <td>0.417490</td>
      <td>0.316951</td>
      <td>0.501663</td>
      <td>0.420191</td>
      <td>-0.446716</td>
      <td>-0.126254</td>
      <td>0.438442</td>
      <td>-0.462977</td>
      <td>-0.367692</td>
      <td>-0.250498</td>
      <td>0.178829</td>
      <td>-0.550434</td>
      <td>-1.602833</td>
      <td>-1.307958</td>
      <td>-0.458457</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f0ba48dcb20&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef  std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.010838   0.0392  25.786729  1.249282e-146  0.934007  1.087668
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  6.350 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d8bbf5861d671d414e1a.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>