
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.0.1 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="http://doubleml.org"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>     to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-0.489145</td>
      <td>-0.395597</td>
      <td>0.242794</td>
      <td>0.295121</td>
      <td>0.622025</td>
      <td>-0.563491</td>
      <td>-0.282403</td>
      <td>-0.129385</td>
      <td>-0.038885</td>
      <td>-0.019914</td>
      <td>-0.843020</td>
      <td>-0.194848</td>
      <td>0.555280</td>
      <td>0.226161</td>
      <td>0.056762</td>
      <td>-0.278441</td>
      <td>-0.428704</td>
      <td>-0.692703</td>
      <td>1.268363</td>
      <td>-0.089726</td>
      <td>0.215617</td>
      <td>0.182487</td>
      <td>-0.087333</td>
      <td>-0.345063</td>
      <td>0.233557</td>
      <td>-0.207879</td>
      <td>0.278286</td>
      <td>0.046034</td>
      <td>-0.111565</td>
      <td>0.482277</td>
      <td>0.325800</td>
      <td>-0.827680</td>
      <td>0.829677</td>
      <td>0.395268</td>
      <td>0.243981</td>
      <td>-0.463095</td>
      <td>-0.220285</td>
      <td>-0.165118</td>
      <td>-1.180749</td>
      <td>-0.854544</td>
      <td>...</td>
      <td>-1.121701</td>
      <td>0.244617</td>
      <td>0.336282</td>
      <td>0.810802</td>
      <td>-0.079771</td>
      <td>0.319402</td>
      <td>1.026627</td>
      <td>1.125154</td>
      <td>0.517321</td>
      <td>0.027603</td>
      <td>0.487292</td>
      <td>-0.226783</td>
      <td>-0.559416</td>
      <td>0.372886</td>
      <td>-0.177014</td>
      <td>0.433255</td>
      <td>0.474417</td>
      <td>-0.546988</td>
      <td>-0.053419</td>
      <td>1.413131</td>
      <td>0.583499</td>
      <td>0.351562</td>
      <td>-1.100203</td>
      <td>0.231540</td>
      <td>0.214604</td>
      <td>0.339918</td>
      <td>-0.525419</td>
      <td>0.104673</td>
      <td>-0.051894</td>
      <td>0.430782</td>
      <td>-0.038527</td>
      <td>0.390999</td>
      <td>-0.374785</td>
      <td>1.129886</td>
      <td>0.072406</td>
      <td>0.088393</td>
      <td>0.977541</td>
      <td>-0.030331</td>
      <td>-0.106892</td>
      <td>0.110154</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.290452</td>
      <td>-0.573687</td>
      <td>0.260793</td>
      <td>0.194107</td>
      <td>-0.480228</td>
      <td>-2.149653</td>
      <td>-0.432741</td>
      <td>0.120498</td>
      <td>0.093309</td>
      <td>0.718010</td>
      <td>0.209439</td>
      <td>0.117861</td>
      <td>0.612083</td>
      <td>0.653406</td>
      <td>1.570547</td>
      <td>1.580313</td>
      <td>-0.537180</td>
      <td>-1.154790</td>
      <td>-0.461778</td>
      <td>-0.185907</td>
      <td>0.027757</td>
      <td>-0.797578</td>
      <td>-0.864929</td>
      <td>-0.127038</td>
      <td>0.017535</td>
      <td>-0.037469</td>
      <td>0.778934</td>
      <td>1.466537</td>
      <td>-0.080731</td>
      <td>-0.301688</td>
      <td>-0.490120</td>
      <td>-0.855510</td>
      <td>0.637357</td>
      <td>-0.264996</td>
      <td>-1.041220</td>
      <td>-0.600240</td>
      <td>0.677091</td>
      <td>0.287809</td>
      <td>-0.758019</td>
      <td>-0.254435</td>
      <td>...</td>
      <td>-0.437495</td>
      <td>-0.088837</td>
      <td>-0.739976</td>
      <td>0.822177</td>
      <td>-0.777583</td>
      <td>0.483493</td>
      <td>0.137249</td>
      <td>0.413523</td>
      <td>0.132025</td>
      <td>0.831122</td>
      <td>0.125221</td>
      <td>-0.107540</td>
      <td>-1.155925</td>
      <td>-0.740615</td>
      <td>-0.010261</td>
      <td>-0.983326</td>
      <td>0.229079</td>
      <td>0.233454</td>
      <td>-1.596139</td>
      <td>0.382255</td>
      <td>0.809519</td>
      <td>1.155461</td>
      <td>-0.785846</td>
      <td>0.105848</td>
      <td>0.230666</td>
      <td>0.340011</td>
      <td>0.448912</td>
      <td>0.214142</td>
      <td>-0.244795</td>
      <td>0.698370</td>
      <td>-0.748898</td>
      <td>0.974681</td>
      <td>0.246010</td>
      <td>-0.147280</td>
      <td>-0.437194</td>
      <td>-0.204609</td>
      <td>1.520017</td>
      <td>2.650253</td>
      <td>1.511841</td>
      <td>0.394889</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.451468</td>
      <td>-0.241708</td>
      <td>0.203883</td>
      <td>0.579137</td>
      <td>0.435038</td>
      <td>-1.893681</td>
      <td>-0.056525</td>
      <td>-0.651703</td>
      <td>-0.907458</td>
      <td>0.103605</td>
      <td>0.744719</td>
      <td>1.256939</td>
      <td>0.475620</td>
      <td>-0.048636</td>
      <td>0.966426</td>
      <td>1.004287</td>
      <td>0.152034</td>
      <td>0.700772</td>
      <td>-0.339144</td>
      <td>-0.252823</td>
      <td>-0.994967</td>
      <td>-0.081092</td>
      <td>0.109659</td>
      <td>0.749252</td>
      <td>-0.021790</td>
      <td>0.218727</td>
      <td>-0.228022</td>
      <td>0.163624</td>
      <td>-0.111632</td>
      <td>-0.510643</td>
      <td>0.244301</td>
      <td>-0.567443</td>
      <td>0.591567</td>
      <td>-0.507574</td>
      <td>0.152644</td>
      <td>-0.412711</td>
      <td>0.084078</td>
      <td>-0.795174</td>
      <td>-0.281634</td>
      <td>0.802822</td>
      <td>...</td>
      <td>-0.107158</td>
      <td>0.731100</td>
      <td>-0.204117</td>
      <td>0.218233</td>
      <td>0.351893</td>
      <td>0.278500</td>
      <td>-1.367305</td>
      <td>-0.086035</td>
      <td>0.439832</td>
      <td>0.568705</td>
      <td>0.377874</td>
      <td>0.384599</td>
      <td>-0.755022</td>
      <td>0.774175</td>
      <td>1.025450</td>
      <td>-0.161540</td>
      <td>0.166358</td>
      <td>-0.254243</td>
      <td>-0.588350</td>
      <td>0.332850</td>
      <td>-0.461625</td>
      <td>-0.286214</td>
      <td>-0.006497</td>
      <td>0.032062</td>
      <td>-0.045155</td>
      <td>-0.477884</td>
      <td>-0.373185</td>
      <td>-0.542782</td>
      <td>-0.329403</td>
      <td>-0.505924</td>
      <td>0.416612</td>
      <td>-0.077163</td>
      <td>0.076810</td>
      <td>-0.228815</td>
      <td>1.149120</td>
      <td>0.840699</td>
      <td>-0.315753</td>
      <td>3.030372</td>
      <td>1.862891</td>
      <td>0.174492</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.095197</td>
      <td>-0.453587</td>
      <td>0.126784</td>
      <td>-0.007528</td>
      <td>0.641969</td>
      <td>1.014122</td>
      <td>0.019560</td>
      <td>-1.540665</td>
      <td>-0.796166</td>
      <td>0.396389</td>
      <td>0.749275</td>
      <td>0.428547</td>
      <td>1.122688</td>
      <td>-0.257497</td>
      <td>0.322971</td>
      <td>0.387993</td>
      <td>0.368737</td>
      <td>0.260518</td>
      <td>0.223332</td>
      <td>0.204638</td>
      <td>0.719869</td>
      <td>0.166560</td>
      <td>-0.384756</td>
      <td>0.681864</td>
      <td>0.602752</td>
      <td>0.538518</td>
      <td>-0.150055</td>
      <td>0.903986</td>
      <td>0.439023</td>
      <td>0.374428</td>
      <td>0.099679</td>
      <td>-0.287019</td>
      <td>-0.128411</td>
      <td>0.324692</td>
      <td>-0.480786</td>
      <td>-0.273418</td>
      <td>0.457830</td>
      <td>-0.465573</td>
      <td>-1.251911</td>
      <td>0.196773</td>
      <td>...</td>
      <td>-0.351508</td>
      <td>0.428176</td>
      <td>-0.944498</td>
      <td>-0.172036</td>
      <td>0.643764</td>
      <td>-0.890340</td>
      <td>-0.802341</td>
      <td>0.647810</td>
      <td>0.598223</td>
      <td>0.465983</td>
      <td>-0.480574</td>
      <td>0.688075</td>
      <td>-0.036096</td>
      <td>0.167508</td>
      <td>-0.601132</td>
      <td>0.239914</td>
      <td>-0.240707</td>
      <td>0.112506</td>
      <td>-0.673749</td>
      <td>-0.043295</td>
      <td>0.364030</td>
      <td>-0.188696</td>
      <td>-0.199685</td>
      <td>-0.422616</td>
      <td>0.313531</td>
      <td>1.127198</td>
      <td>-0.154877</td>
      <td>-0.732499</td>
      <td>-0.001333</td>
      <td>-0.357276</td>
      <td>-1.561363</td>
      <td>0.275060</td>
      <td>-0.327769</td>
      <td>0.949038</td>
      <td>1.470939</td>
      <td>-0.284233</td>
      <td>-0.495104</td>
      <td>1.930607</td>
      <td>1.523465</td>
      <td>0.817815</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.268959</td>
      <td>-0.274761</td>
      <td>-0.076426</td>
      <td>0.395931</td>
      <td>1.102768</td>
      <td>0.745975</td>
      <td>0.750634</td>
      <td>-0.063447</td>
      <td>0.049162</td>
      <td>0.465695</td>
      <td>0.711763</td>
      <td>-0.271592</td>
      <td>0.206373</td>
      <td>-0.251495</td>
      <td>-0.290791</td>
      <td>-0.181585</td>
      <td>-0.378891</td>
      <td>0.571148</td>
      <td>0.415881</td>
      <td>0.936391</td>
      <td>-0.497492</td>
      <td>-0.584480</td>
      <td>-0.329438</td>
      <td>0.681930</td>
      <td>1.618161</td>
      <td>0.286408</td>
      <td>-0.202415</td>
      <td>1.024381</td>
      <td>-0.929116</td>
      <td>-0.030462</td>
      <td>0.396778</td>
      <td>-0.692686</td>
      <td>-0.040783</td>
      <td>-0.345604</td>
      <td>0.793828</td>
      <td>-1.003303</td>
      <td>-0.446835</td>
      <td>-0.042520</td>
      <td>0.113122</td>
      <td>-0.422347</td>
      <td>...</td>
      <td>0.585302</td>
      <td>0.242860</td>
      <td>0.570396</td>
      <td>0.703137</td>
      <td>0.625488</td>
      <td>-0.236383</td>
      <td>-0.426712</td>
      <td>-0.005629</td>
      <td>0.045142</td>
      <td>-0.402029</td>
      <td>-0.624166</td>
      <td>-0.452623</td>
      <td>-1.238950</td>
      <td>0.461052</td>
      <td>0.449132</td>
      <td>0.893980</td>
      <td>1.293452</td>
      <td>-0.100205</td>
      <td>-0.264164</td>
      <td>0.263306</td>
      <td>0.315320</td>
      <td>0.190309</td>
      <td>-0.357172</td>
      <td>0.495339</td>
      <td>0.048034</td>
      <td>-0.848053</td>
      <td>-0.929571</td>
      <td>-0.545845</td>
      <td>-1.357869</td>
      <td>-0.380371</td>
      <td>-0.482641</td>
      <td>1.019320</td>
      <td>-0.292221</td>
      <td>0.709999</td>
      <td>-0.236187</td>
      <td>-0.730687</td>
      <td>0.261752</td>
      <td>0.558884</td>
      <td>-0.023155</td>
      <td>-1.230068</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.062425</td>
      <td>-0.120472</td>
      <td>-0.220471</td>
      <td>0.073522</td>
      <td>-0.104204</td>
      <td>-0.332641</td>
      <td>-0.320480</td>
      <td>0.165628</td>
      <td>0.893166</td>
      <td>0.807461</td>
      <td>0.409927</td>
      <td>0.868550</td>
      <td>0.265197</td>
      <td>0.541723</td>
      <td>0.743608</td>
      <td>0.464876</td>
      <td>-0.705214</td>
      <td>-0.176054</td>
      <td>-0.658461</td>
      <td>0.618856</td>
      <td>-0.456924</td>
      <td>-0.761475</td>
      <td>-0.243488</td>
      <td>0.131447</td>
      <td>0.363401</td>
      <td>0.923246</td>
      <td>0.648040</td>
      <td>0.887689</td>
      <td>0.117040</td>
      <td>0.067261</td>
      <td>0.289934</td>
      <td>-0.053934</td>
      <td>-0.168736</td>
      <td>-0.131861</td>
      <td>0.026351</td>
      <td>0.228511</td>
      <td>-0.276488</td>
      <td>0.678332</td>
      <td>-0.794014</td>
      <td>-0.417671</td>
      <td>...</td>
      <td>0.139831</td>
      <td>0.045529</td>
      <td>0.221752</td>
      <td>0.604993</td>
      <td>0.174796</td>
      <td>-0.160919</td>
      <td>0.668614</td>
      <td>-0.163964</td>
      <td>0.871826</td>
      <td>1.413061</td>
      <td>0.394723</td>
      <td>0.392074</td>
      <td>-0.739619</td>
      <td>-0.245960</td>
      <td>0.278102</td>
      <td>-0.314641</td>
      <td>-0.001564</td>
      <td>0.176438</td>
      <td>-0.462012</td>
      <td>1.477290</td>
      <td>0.158191</td>
      <td>-0.172681</td>
      <td>-0.350726</td>
      <td>-0.939566</td>
      <td>-0.383731</td>
      <td>-0.717822</td>
      <td>-0.741433</td>
      <td>-0.210440</td>
      <td>-1.188648</td>
      <td>0.098292</td>
      <td>0.325232</td>
      <td>-0.193228</td>
      <td>0.850090</td>
      <td>1.777345</td>
      <td>0.463838</td>
      <td>-0.557316</td>
      <td>0.081386</td>
      <td>-0.020538</td>
      <td>0.457042</td>
      <td>0.777793</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.930544</td>
      <td>0.153080</td>
      <td>-0.270113</td>
      <td>-0.464399</td>
      <td>0.457262</td>
      <td>0.237125</td>
      <td>0.216295</td>
      <td>0.067219</td>
      <td>-0.676891</td>
      <td>-0.071937</td>
      <td>0.091168</td>
      <td>0.661244</td>
      <td>-0.154789</td>
      <td>0.203231</td>
      <td>1.051085</td>
      <td>-0.036546</td>
      <td>-0.946569</td>
      <td>-0.737161</td>
      <td>-0.349112</td>
      <td>-0.063286</td>
      <td>-0.765642</td>
      <td>-0.879348</td>
      <td>-0.317517</td>
      <td>-0.326136</td>
      <td>1.088353</td>
      <td>0.417757</td>
      <td>0.311092</td>
      <td>-0.958525</td>
      <td>-0.237998</td>
      <td>0.439351</td>
      <td>0.066783</td>
      <td>-0.533836</td>
      <td>-0.430255</td>
      <td>0.741122</td>
      <td>0.665524</td>
      <td>-0.151512</td>
      <td>0.500113</td>
      <td>1.084616</td>
      <td>0.495691</td>
      <td>0.483485</td>
      <td>...</td>
      <td>0.250792</td>
      <td>0.286100</td>
      <td>-0.064949</td>
      <td>0.582141</td>
      <td>-0.011703</td>
      <td>-0.578189</td>
      <td>-0.046158</td>
      <td>-0.719862</td>
      <td>-0.670995</td>
      <td>-0.710056</td>
      <td>-0.433784</td>
      <td>-0.097417</td>
      <td>-0.131930</td>
      <td>0.387159</td>
      <td>-0.588659</td>
      <td>-0.818997</td>
      <td>-0.305313</td>
      <td>-1.382137</td>
      <td>-0.442984</td>
      <td>-0.205903</td>
      <td>0.186975</td>
      <td>-0.745493</td>
      <td>-0.591215</td>
      <td>-0.094853</td>
      <td>-0.859178</td>
      <td>0.239178</td>
      <td>-0.545598</td>
      <td>-1.326040</td>
      <td>0.181552</td>
      <td>-0.251768</td>
      <td>-1.476054</td>
      <td>0.220294</td>
      <td>0.301554</td>
      <td>0.291347</td>
      <td>0.730496</td>
      <td>-0.963627</td>
      <td>-0.694129</td>
      <td>-0.901460</td>
      <td>-0.537643</td>
      <td>-0.240594</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.181889</td>
      <td>0.375514</td>
      <td>0.420646</td>
      <td>1.256087</td>
      <td>0.460862</td>
      <td>-1.208178</td>
      <td>-0.031507</td>
      <td>-0.062914</td>
      <td>-0.800454</td>
      <td>0.524791</td>
      <td>0.419089</td>
      <td>0.021462</td>
      <td>-0.499086</td>
      <td>-0.126170</td>
      <td>0.252877</td>
      <td>0.073689</td>
      <td>0.706997</td>
      <td>0.717022</td>
      <td>-0.422428</td>
      <td>-0.285530</td>
      <td>-0.571310</td>
      <td>0.035720</td>
      <td>-0.890342</td>
      <td>-0.367968</td>
      <td>0.788098</td>
      <td>0.786827</td>
      <td>-0.277743</td>
      <td>0.647186</td>
      <td>0.474223</td>
      <td>0.397770</td>
      <td>-0.192180</td>
      <td>-1.017423</td>
      <td>-0.758980</td>
      <td>1.120651</td>
      <td>0.797796</td>
      <td>-0.156426</td>
      <td>-0.888969</td>
      <td>0.887211</td>
      <td>-0.306138</td>
      <td>-0.257915</td>
      <td>...</td>
      <td>-0.020486</td>
      <td>-0.322716</td>
      <td>-0.462817</td>
      <td>1.179417</td>
      <td>0.338966</td>
      <td>0.033884</td>
      <td>0.087845</td>
      <td>0.977625</td>
      <td>-0.926160</td>
      <td>0.103449</td>
      <td>-0.609848</td>
      <td>0.538245</td>
      <td>-0.058373</td>
      <td>0.643026</td>
      <td>0.579998</td>
      <td>0.219563</td>
      <td>0.281814</td>
      <td>-0.884076</td>
      <td>-0.400332</td>
      <td>-0.595709</td>
      <td>-0.242168</td>
      <td>0.464917</td>
      <td>0.498789</td>
      <td>-0.140476</td>
      <td>-0.718835</td>
      <td>-1.143382</td>
      <td>-0.919359</td>
      <td>-0.851844</td>
      <td>-0.332829</td>
      <td>0.385172</td>
      <td>-0.449045</td>
      <td>-0.366866</td>
      <td>0.412527</td>
      <td>-0.215913</td>
      <td>0.479937</td>
      <td>-0.226616</td>
      <td>-0.126185</td>
      <td>1.875545</td>
      <td>1.146389</td>
      <td>-0.097961</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.307253</td>
      <td>0.029678</td>
      <td>0.865839</td>
      <td>-0.577209</td>
      <td>0.516658</td>
      <td>-0.229964</td>
      <td>-0.037518</td>
      <td>0.984223</td>
      <td>1.350871</td>
      <td>0.509667</td>
      <td>-0.446238</td>
      <td>-0.155436</td>
      <td>0.122226</td>
      <td>-0.073010</td>
      <td>0.756869</td>
      <td>0.369844</td>
      <td>-0.336292</td>
      <td>0.660757</td>
      <td>0.258706</td>
      <td>-0.478667</td>
      <td>-0.811737</td>
      <td>0.036596</td>
      <td>-0.285008</td>
      <td>-0.517082</td>
      <td>-0.431763</td>
      <td>0.571525</td>
      <td>0.277360</td>
      <td>0.108315</td>
      <td>0.749843</td>
      <td>-0.782360</td>
      <td>0.298147</td>
      <td>1.452290</td>
      <td>-1.065929</td>
      <td>-0.807751</td>
      <td>-0.204150</td>
      <td>-1.234748</td>
      <td>-0.046783</td>
      <td>0.570701</td>
      <td>-0.458334</td>
      <td>1.128513</td>
      <td>...</td>
      <td>-0.186929</td>
      <td>-0.722161</td>
      <td>-0.021659</td>
      <td>0.027498</td>
      <td>0.116936</td>
      <td>0.436909</td>
      <td>0.606941</td>
      <td>0.558536</td>
      <td>0.221969</td>
      <td>0.225442</td>
      <td>1.370876</td>
      <td>0.633538</td>
      <td>-0.414132</td>
      <td>0.616701</td>
      <td>-0.133996</td>
      <td>-0.087342</td>
      <td>-0.221705</td>
      <td>0.010245</td>
      <td>0.401728</td>
      <td>1.935968</td>
      <td>0.004219</td>
      <td>-0.223627</td>
      <td>-0.623096</td>
      <td>0.488434</td>
      <td>-0.301899</td>
      <td>-0.428998</td>
      <td>-1.592618</td>
      <td>-0.567632</td>
      <td>0.038747</td>
      <td>0.476946</td>
      <td>-0.056126</td>
      <td>-0.524892</td>
      <td>0.056680</td>
      <td>0.497274</td>
      <td>0.979620</td>
      <td>0.013854</td>
      <td>-0.784603</td>
      <td>-1.441182</td>
      <td>-0.467266</td>
      <td>0.260160</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-0.536388</td>
      <td>-0.709563</td>
      <td>-0.082249</td>
      <td>0.590164</td>
      <td>1.455712</td>
      <td>0.600739</td>
      <td>0.089241</td>
      <td>0.515110</td>
      <td>-0.673639</td>
      <td>-0.879442</td>
      <td>-0.518905</td>
      <td>-0.034668</td>
      <td>-0.237379</td>
      <td>1.073740</td>
      <td>1.011650</td>
      <td>-0.484297</td>
      <td>-0.135790</td>
      <td>-0.759400</td>
      <td>-0.462534</td>
      <td>-0.358848</td>
      <td>-0.900640</td>
      <td>-1.242080</td>
      <td>-0.482885</td>
      <td>0.410681</td>
      <td>-0.357938</td>
      <td>0.264299</td>
      <td>-0.473773</td>
      <td>-0.493307</td>
      <td>-0.934632</td>
      <td>-0.191215</td>
      <td>1.277978</td>
      <td>-0.392127</td>
      <td>-0.764196</td>
      <td>-0.286847</td>
      <td>1.515321</td>
      <td>0.073961</td>
      <td>0.259317</td>
      <td>0.468353</td>
      <td>-0.642832</td>
      <td>-0.635970</td>
      <td>...</td>
      <td>-0.005023</td>
      <td>-0.031903</td>
      <td>-0.477214</td>
      <td>-0.066846</td>
      <td>-0.299669</td>
      <td>-0.283069</td>
      <td>-0.702780</td>
      <td>0.567121</td>
      <td>-0.123317</td>
      <td>-0.779759</td>
      <td>0.163301</td>
      <td>0.718541</td>
      <td>-0.170236</td>
      <td>-0.050189</td>
      <td>-0.208543</td>
      <td>0.554972</td>
      <td>0.661689</td>
      <td>0.342803</td>
      <td>-0.179788</td>
      <td>-0.524787</td>
      <td>-0.278312</td>
      <td>0.785115</td>
      <td>-0.704122</td>
      <td>0.537754</td>
      <td>0.084964</td>
      <td>-0.084244</td>
      <td>-1.309481</td>
      <td>-0.679065</td>
      <td>-0.375635</td>
      <td>-0.133853</td>
      <td>0.231131</td>
      <td>-0.480883</td>
      <td>0.348279</td>
      <td>0.996953</td>
      <td>1.082191</td>
      <td>-1.331822</td>
      <td>-1.157164</td>
      <td>-0.852950</td>
      <td>0.006506</td>
      <td>-0.086463</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-0.341999</td>
      <td>-0.176171</td>
      <td>0.246147</td>
      <td>0.330912</td>
      <td>0.881516</td>
      <td>-0.253516</td>
      <td>0.192773</td>
      <td>0.679259</td>
      <td>0.776439</td>
      <td>0.340793</td>
      <td>0.278608</td>
      <td>0.447135</td>
      <td>0.635693</td>
      <td>0.279599</td>
      <td>1.167189</td>
      <td>1.317937</td>
      <td>0.458083</td>
      <td>0.614928</td>
      <td>0.518018</td>
      <td>-0.976821</td>
      <td>-0.126877</td>
      <td>-0.180251</td>
      <td>0.034690</td>
      <td>-0.131165</td>
      <td>0.027335</td>
      <td>0.114463</td>
      <td>0.869662</td>
      <td>1.776172</td>
      <td>0.187618</td>
      <td>0.393557</td>
      <td>0.025403</td>
      <td>-0.050260</td>
      <td>0.313386</td>
      <td>0.743264</td>
      <td>0.308077</td>
      <td>-0.083741</td>
      <td>-0.139326</td>
      <td>0.126586</td>
      <td>-0.205442</td>
      <td>-0.064826</td>
      <td>...</td>
      <td>-0.341199</td>
      <td>-0.935062</td>
      <td>-2.009178</td>
      <td>0.108989</td>
      <td>1.006375</td>
      <td>0.297923</td>
      <td>-0.232711</td>
      <td>-0.619503</td>
      <td>0.276085</td>
      <td>0.776496</td>
      <td>0.682688</td>
      <td>0.103038</td>
      <td>-0.652958</td>
      <td>0.254950</td>
      <td>1.700521</td>
      <td>0.810157</td>
      <td>0.700174</td>
      <td>-0.637242</td>
      <td>0.303520</td>
      <td>0.164086</td>
      <td>0.153933</td>
      <td>0.180785</td>
      <td>0.427986</td>
      <td>0.778358</td>
      <td>-0.566542</td>
      <td>-0.291994</td>
      <td>-0.246981</td>
      <td>-0.262807</td>
      <td>1.203273</td>
      <td>0.359515</td>
      <td>-0.548707</td>
      <td>-0.123456</td>
      <td>-0.356013</td>
      <td>0.447435</td>
      <td>0.546722</td>
      <td>0.257749</td>
      <td>0.185564</td>
      <td>1.587611</td>
      <td>0.953048</td>
      <td>0.226360</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.249276</td>
      <td>0.149282</td>
      <td>-0.312991</td>
      <td>0.505758</td>
      <td>0.090067</td>
      <td>0.065502</td>
      <td>0.349072</td>
      <td>-0.453183</td>
      <td>-0.061059</td>
      <td>-0.523131</td>
      <td>-0.486116</td>
      <td>1.670868</td>
      <td>0.956569</td>
      <td>0.374658</td>
      <td>0.657531</td>
      <td>0.027883</td>
      <td>1.437188</td>
      <td>-0.572824</td>
      <td>0.486454</td>
      <td>-0.970071</td>
      <td>-0.690816</td>
      <td>-0.178189</td>
      <td>-1.196661</td>
      <td>1.453617</td>
      <td>-0.136806</td>
      <td>0.749629</td>
      <td>1.464480</td>
      <td>0.528037</td>
      <td>-0.222998</td>
      <td>-0.142943</td>
      <td>-0.381079</td>
      <td>-1.035401</td>
      <td>-0.277871</td>
      <td>1.115776</td>
      <td>-0.768396</td>
      <td>-1.628936</td>
      <td>-0.187977</td>
      <td>0.050808</td>
      <td>-0.508786</td>
      <td>-0.490345</td>
      <td>...</td>
      <td>0.297315</td>
      <td>-0.396608</td>
      <td>-0.714612</td>
      <td>-0.824064</td>
      <td>1.202676</td>
      <td>1.263884</td>
      <td>-0.629779</td>
      <td>0.119759</td>
      <td>0.398266</td>
      <td>-0.047809</td>
      <td>1.052428</td>
      <td>-0.130077</td>
      <td>-0.363339</td>
      <td>0.710772</td>
      <td>-0.852150</td>
      <td>-0.217550</td>
      <td>-0.524468</td>
      <td>-0.270264</td>
      <td>-0.092189</td>
      <td>0.336581</td>
      <td>0.282023</td>
      <td>0.264657</td>
      <td>-0.474354</td>
      <td>0.866120</td>
      <td>0.648599</td>
      <td>-0.268939</td>
      <td>0.508277</td>
      <td>0.084855</td>
      <td>-0.421628</td>
      <td>-0.044811</td>
      <td>-0.755219</td>
      <td>0.243534</td>
      <td>0.671467</td>
      <td>1.718857</td>
      <td>1.511684</td>
      <td>0.380446</td>
      <td>0.399637</td>
      <td>1.483773</td>
      <td>1.154091</td>
      <td>0.777415</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.002283</td>
      <td>-0.024163</td>
      <td>0.837805</td>
      <td>0.406275</td>
      <td>0.998210</td>
      <td>0.548014</td>
      <td>-0.006362</td>
      <td>0.518791</td>
      <td>0.331186</td>
      <td>-0.294310</td>
      <td>-0.091074</td>
      <td>0.964043</td>
      <td>0.158922</td>
      <td>0.312307</td>
      <td>1.608869</td>
      <td>1.443319</td>
      <td>0.183129</td>
      <td>-0.263799</td>
      <td>-0.887843</td>
      <td>-0.736893</td>
      <td>0.165083</td>
      <td>0.323224</td>
      <td>0.251091</td>
      <td>0.419843</td>
      <td>-0.321016</td>
      <td>0.554616</td>
      <td>0.848194</td>
      <td>0.677199</td>
      <td>-0.312078</td>
      <td>0.762610</td>
      <td>1.181599</td>
      <td>0.079133</td>
      <td>0.225651</td>
      <td>-0.137096</td>
      <td>0.651150</td>
      <td>-0.198379</td>
      <td>-0.681223</td>
      <td>-0.047009</td>
      <td>-0.186553</td>
      <td>0.222905</td>
      <td>...</td>
      <td>-1.054380</td>
      <td>-0.912472</td>
      <td>-1.339441</td>
      <td>-0.027103</td>
      <td>0.071880</td>
      <td>0.016635</td>
      <td>-0.174856</td>
      <td>0.493926</td>
      <td>0.494596</td>
      <td>0.288081</td>
      <td>-0.896481</td>
      <td>-0.400205</td>
      <td>-0.086610</td>
      <td>1.283655</td>
      <td>0.487141</td>
      <td>0.420747</td>
      <td>-0.063181</td>
      <td>-0.137316</td>
      <td>0.110932</td>
      <td>0.221620</td>
      <td>0.186487</td>
      <td>-0.376946</td>
      <td>-1.173856</td>
      <td>0.233965</td>
      <td>-0.335161</td>
      <td>-0.728151</td>
      <td>-0.746486</td>
      <td>0.274916</td>
      <td>-0.213538</td>
      <td>0.408436</td>
      <td>0.420624</td>
      <td>-0.325506</td>
      <td>0.314132</td>
      <td>0.810030</td>
      <td>0.413730</td>
      <td>-0.400763</td>
      <td>-0.162672</td>
      <td>-0.241298</td>
      <td>-0.502011</td>
      <td>-0.332591</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.086430</td>
      <td>-0.542841</td>
      <td>0.370335</td>
      <td>-0.043657</td>
      <td>0.184769</td>
      <td>0.268031</td>
      <td>0.210345</td>
      <td>-0.309966</td>
      <td>0.107396</td>
      <td>-0.707744</td>
      <td>1.127446</td>
      <td>0.369088</td>
      <td>0.747575</td>
      <td>-0.020550</td>
      <td>0.926084</td>
      <td>0.136925</td>
      <td>0.263245</td>
      <td>-0.161311</td>
      <td>-0.792497</td>
      <td>-0.247958</td>
      <td>0.733392</td>
      <td>0.440197</td>
      <td>0.373370</td>
      <td>0.675874</td>
      <td>-0.481742</td>
      <td>0.037309</td>
      <td>0.487014</td>
      <td>-0.266200</td>
      <td>0.154800</td>
      <td>0.559386</td>
      <td>0.446838</td>
      <td>0.324411</td>
      <td>-0.021736</td>
      <td>-0.012555</td>
      <td>0.296384</td>
      <td>-0.476935</td>
      <td>-0.876286</td>
      <td>-0.329819</td>
      <td>-0.142935</td>
      <td>-0.819917</td>
      <td>...</td>
      <td>-0.795972</td>
      <td>-0.338245</td>
      <td>0.312214</td>
      <td>-0.167845</td>
      <td>-0.313149</td>
      <td>-0.407472</td>
      <td>-0.422997</td>
      <td>0.062797</td>
      <td>0.794301</td>
      <td>0.766316</td>
      <td>0.071330</td>
      <td>0.444636</td>
      <td>-1.570588</td>
      <td>0.677572</td>
      <td>-0.674320</td>
      <td>-0.744400</td>
      <td>0.175910</td>
      <td>-0.328489</td>
      <td>-0.278056</td>
      <td>0.724033</td>
      <td>-0.382294</td>
      <td>-0.003729</td>
      <td>-1.402065</td>
      <td>-1.210976</td>
      <td>-1.918936</td>
      <td>-0.371026</td>
      <td>-1.019467</td>
      <td>-0.335196</td>
      <td>-0.918721</td>
      <td>-0.596932</td>
      <td>-0.248602</td>
      <td>-0.515550</td>
      <td>-0.626972</td>
      <td>0.757456</td>
      <td>0.871305</td>
      <td>0.192467</td>
      <td>-0.237596</td>
      <td>-0.571382</td>
      <td>-0.130162</td>
      <td>0.074468</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.224419</td>
      <td>0.355603</td>
      <td>-0.491331</td>
      <td>-1.062861</td>
      <td>1.361769</td>
      <td>-0.719718</td>
      <td>-0.014495</td>
      <td>-0.418582</td>
      <td>0.245319</td>
      <td>-0.221652</td>
      <td>0.295692</td>
      <td>0.190415</td>
      <td>0.223465</td>
      <td>0.393287</td>
      <td>1.168411</td>
      <td>0.358988</td>
      <td>-0.212132</td>
      <td>-0.705663</td>
      <td>-0.613487</td>
      <td>-1.833116</td>
      <td>0.110573</td>
      <td>0.313744</td>
      <td>-0.248679</td>
      <td>0.149070</td>
      <td>0.177447</td>
      <td>0.226285</td>
      <td>0.347207</td>
      <td>-0.054334</td>
      <td>-1.124980</td>
      <td>1.196172</td>
      <td>-0.213704</td>
      <td>0.521539</td>
      <td>-0.462005</td>
      <td>-0.066576</td>
      <td>-0.162242</td>
      <td>-0.628184</td>
      <td>0.060449</td>
      <td>-0.295212</td>
      <td>-0.955112</td>
      <td>-0.461018</td>
      <td>...</td>
      <td>0.207611</td>
      <td>0.566042</td>
      <td>-0.053695</td>
      <td>0.610222</td>
      <td>0.173294</td>
      <td>-0.235643</td>
      <td>-0.305197</td>
      <td>0.925829</td>
      <td>0.669258</td>
      <td>0.287153</td>
      <td>0.156578</td>
      <td>0.296472</td>
      <td>-0.418953</td>
      <td>-0.382351</td>
      <td>0.017341</td>
      <td>-1.910701</td>
      <td>0.515911</td>
      <td>-0.485714</td>
      <td>-0.345070</td>
      <td>1.144570</td>
      <td>0.074291</td>
      <td>-0.359652</td>
      <td>-0.377581</td>
      <td>0.773985</td>
      <td>-0.386079</td>
      <td>-0.442260</td>
      <td>-0.782643</td>
      <td>0.242344</td>
      <td>1.288987</td>
      <td>-0.454979</td>
      <td>-1.142205</td>
      <td>-0.594656</td>
      <td>0.929321</td>
      <td>0.197493</td>
      <td>0.454526</td>
      <td>-0.045945</td>
      <td>-0.635630</td>
      <td>2.450377</td>
      <td>2.283912</td>
      <td>0.939727</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-0.247222</td>
      <td>0.992686</td>
      <td>1.273408</td>
      <td>0.455741</td>
      <td>1.111355</td>
      <td>0.326531</td>
      <td>0.389286</td>
      <td>0.386748</td>
      <td>0.074031</td>
      <td>-0.511238</td>
      <td>0.518610</td>
      <td>0.480938</td>
      <td>0.321339</td>
      <td>0.318998</td>
      <td>-0.102772</td>
      <td>0.181922</td>
      <td>-1.398978</td>
      <td>-0.128813</td>
      <td>-0.151639</td>
      <td>0.077084</td>
      <td>-1.214746</td>
      <td>-0.932447</td>
      <td>-1.433628</td>
      <td>-0.191227</td>
      <td>-0.458854</td>
      <td>1.374258</td>
      <td>0.578441</td>
      <td>0.909666</td>
      <td>0.955116</td>
      <td>1.060080</td>
      <td>0.228650</td>
      <td>-0.543899</td>
      <td>0.117634</td>
      <td>-0.273069</td>
      <td>-0.110600</td>
      <td>-0.563972</td>
      <td>0.035557</td>
      <td>0.701745</td>
      <td>-0.268639</td>
      <td>-0.626026</td>
      <td>...</td>
      <td>-0.520957</td>
      <td>-1.101713</td>
      <td>-0.910179</td>
      <td>0.607604</td>
      <td>0.275626</td>
      <td>0.067023</td>
      <td>-0.441670</td>
      <td>0.154858</td>
      <td>0.680463</td>
      <td>1.042858</td>
      <td>0.123857</td>
      <td>0.314551</td>
      <td>0.587058</td>
      <td>-0.260403</td>
      <td>0.214388</td>
      <td>-0.402100</td>
      <td>-0.865459</td>
      <td>-0.723763</td>
      <td>0.054078</td>
      <td>1.106481</td>
      <td>-0.343092</td>
      <td>0.247849</td>
      <td>-0.661657</td>
      <td>-0.452669</td>
      <td>-1.015713</td>
      <td>-0.714996</td>
      <td>-0.706013</td>
      <td>-0.805715</td>
      <td>-0.437919</td>
      <td>0.650181</td>
      <td>0.281465</td>
      <td>0.561389</td>
      <td>0.956814</td>
      <td>-0.526016</td>
      <td>-0.023706</td>
      <td>0.568231</td>
      <td>0.870839</td>
      <td>2.249926</td>
      <td>2.340340</td>
      <td>1.550980</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-0.393138</td>
      <td>-0.414758</td>
      <td>-0.310664</td>
      <td>0.276882</td>
      <td>0.128064</td>
      <td>-0.438231</td>
      <td>1.302301</td>
      <td>0.621981</td>
      <td>-0.468966</td>
      <td>0.310283</td>
      <td>0.931724</td>
      <td>1.160187</td>
      <td>-0.256393</td>
      <td>-0.923389</td>
      <td>-0.220351</td>
      <td>0.238894</td>
      <td>-0.627312</td>
      <td>-0.608655</td>
      <td>-0.215119</td>
      <td>-0.854177</td>
      <td>-0.364991</td>
      <td>0.007035</td>
      <td>-0.359382</td>
      <td>-0.175045</td>
      <td>0.309764</td>
      <td>0.490052</td>
      <td>-0.144752</td>
      <td>-0.068694</td>
      <td>-1.327462</td>
      <td>-0.100057</td>
      <td>-1.013740</td>
      <td>0.210062</td>
      <td>0.432917</td>
      <td>-1.138511</td>
      <td>0.423219</td>
      <td>-0.372798</td>
      <td>0.626065</td>
      <td>0.048136</td>
      <td>0.435251</td>
      <td>0.667080</td>
      <td>...</td>
      <td>-0.395228</td>
      <td>0.053074</td>
      <td>0.117723</td>
      <td>0.881169</td>
      <td>-0.492550</td>
      <td>-0.594388</td>
      <td>-0.870455</td>
      <td>0.310122</td>
      <td>0.762778</td>
      <td>0.517025</td>
      <td>-0.992700</td>
      <td>-0.102551</td>
      <td>-0.071863</td>
      <td>0.840131</td>
      <td>0.958602</td>
      <td>0.623765</td>
      <td>0.669396</td>
      <td>0.262462</td>
      <td>0.238533</td>
      <td>0.886728</td>
      <td>-0.313458</td>
      <td>-0.814500</td>
      <td>-1.086215</td>
      <td>-1.153248</td>
      <td>0.237938</td>
      <td>-0.594483</td>
      <td>0.231155</td>
      <td>0.176271</td>
      <td>-0.233553</td>
      <td>-0.157807</td>
      <td>-0.628877</td>
      <td>0.067095</td>
      <td>0.678874</td>
      <td>0.508068</td>
      <td>0.054641</td>
      <td>0.074033</td>
      <td>-0.756374</td>
      <td>0.287322</td>
      <td>0.007852</td>
      <td>-0.565319</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.496263</td>
      <td>-0.114998</td>
      <td>-0.503485</td>
      <td>0.331410</td>
      <td>0.912629</td>
      <td>1.230778</td>
      <td>0.923636</td>
      <td>-0.514654</td>
      <td>-0.739290</td>
      <td>0.402052</td>
      <td>0.411793</td>
      <td>0.538986</td>
      <td>-0.181532</td>
      <td>0.380668</td>
      <td>1.035538</td>
      <td>0.961231</td>
      <td>0.650789</td>
      <td>-0.320677</td>
      <td>-0.226423</td>
      <td>0.343019</td>
      <td>-1.278569</td>
      <td>-0.521800</td>
      <td>-0.716229</td>
      <td>0.591039</td>
      <td>-0.679019</td>
      <td>-0.350131</td>
      <td>0.721598</td>
      <td>-0.030324</td>
      <td>-0.669018</td>
      <td>-0.021504</td>
      <td>-0.366338</td>
      <td>-1.067750</td>
      <td>0.211982</td>
      <td>-0.418126</td>
      <td>0.440952</td>
      <td>-0.371293</td>
      <td>-0.432104</td>
      <td>-0.624788</td>
      <td>0.069777</td>
      <td>0.378788</td>
      <td>...</td>
      <td>0.620405</td>
      <td>1.197792</td>
      <td>-0.441982</td>
      <td>-0.150746</td>
      <td>-0.137102</td>
      <td>-0.003267</td>
      <td>-0.461334</td>
      <td>-0.158371</td>
      <td>0.594375</td>
      <td>-0.265456</td>
      <td>0.285009</td>
      <td>0.669836</td>
      <td>-0.422803</td>
      <td>0.278071</td>
      <td>-0.557096</td>
      <td>-0.457517</td>
      <td>-0.901933</td>
      <td>-0.467787</td>
      <td>-1.174068</td>
      <td>-0.384569</td>
      <td>0.112793</td>
      <td>-0.896381</td>
      <td>-0.953827</td>
      <td>-0.089252</td>
      <td>-0.064932</td>
      <td>-0.476242</td>
      <td>0.265476</td>
      <td>-0.288393</td>
      <td>-0.603744</td>
      <td>-0.947000</td>
      <td>-0.867386</td>
      <td>0.092318</td>
      <td>0.601174</td>
      <td>0.567951</td>
      <td>0.343441</td>
      <td>-0.402595</td>
      <td>-0.141415</td>
      <td>2.191398</td>
      <td>1.828832</td>
      <td>1.364316</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.528287</td>
      <td>-0.168504</td>
      <td>-0.032394</td>
      <td>0.444107</td>
      <td>0.994327</td>
      <td>0.128632</td>
      <td>-0.099203</td>
      <td>0.352398</td>
      <td>0.556923</td>
      <td>0.410168</td>
      <td>-1.206621</td>
      <td>0.046985</td>
      <td>0.143065</td>
      <td>-0.335629</td>
      <td>0.897349</td>
      <td>-0.320871</td>
      <td>0.085042</td>
      <td>-0.340324</td>
      <td>-0.691841</td>
      <td>-1.403282</td>
      <td>-1.361654</td>
      <td>-0.208260</td>
      <td>-1.101787</td>
      <td>-0.974185</td>
      <td>0.085525</td>
      <td>1.341171</td>
      <td>0.716274</td>
      <td>0.279586</td>
      <td>0.144325</td>
      <td>0.274127</td>
      <td>-0.163959</td>
      <td>0.220991</td>
      <td>-0.416585</td>
      <td>0.147437</td>
      <td>-0.743826</td>
      <td>-0.778878</td>
      <td>-0.404513</td>
      <td>0.485770</td>
      <td>-1.069217</td>
      <td>0.159442</td>
      <td>...</td>
      <td>0.593213</td>
      <td>0.667860</td>
      <td>-0.334487</td>
      <td>0.238585</td>
      <td>0.098327</td>
      <td>0.299181</td>
      <td>-0.439489</td>
      <td>0.093231</td>
      <td>0.223387</td>
      <td>-0.219687</td>
      <td>0.051169</td>
      <td>-0.893933</td>
      <td>-0.392105</td>
      <td>-0.387853</td>
      <td>-0.989762</td>
      <td>-0.335754</td>
      <td>0.109317</td>
      <td>-0.327639</td>
      <td>0.135336</td>
      <td>0.583507</td>
      <td>0.481006</td>
      <td>-0.656291</td>
      <td>-0.622126</td>
      <td>-0.234946</td>
      <td>-0.175702</td>
      <td>-0.681989</td>
      <td>-0.770868</td>
      <td>-0.147209</td>
      <td>0.574435</td>
      <td>-0.224608</td>
      <td>-0.466332</td>
      <td>-0.852780</td>
      <td>-0.612938</td>
      <td>0.547768</td>
      <td>0.411287</td>
      <td>-0.250186</td>
      <td>-0.031343</td>
      <td>2.903790</td>
      <td>2.627280</td>
      <td>1.615739</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.087138</td>
      <td>-0.257558</td>
      <td>0.143227</td>
      <td>-0.845248</td>
      <td>-0.280474</td>
      <td>0.243162</td>
      <td>0.156184</td>
      <td>0.105318</td>
      <td>-0.300071</td>
      <td>0.470694</td>
      <td>1.081798</td>
      <td>1.235870</td>
      <td>0.373631</td>
      <td>1.026298</td>
      <td>-0.094365</td>
      <td>0.543111</td>
      <td>0.576705</td>
      <td>-0.197676</td>
      <td>0.144131</td>
      <td>-1.228446</td>
      <td>-0.291143</td>
      <td>0.320797</td>
      <td>0.705071</td>
      <td>0.756257</td>
      <td>0.839008</td>
      <td>1.069676</td>
      <td>0.149490</td>
      <td>0.413415</td>
      <td>-0.237247</td>
      <td>-0.039689</td>
      <td>0.396736</td>
      <td>-0.872694</td>
      <td>-0.220302</td>
      <td>-0.074557</td>
      <td>0.551254</td>
      <td>1.635447</td>
      <td>-0.214594</td>
      <td>-0.689737</td>
      <td>-1.583808</td>
      <td>-0.555413</td>
      <td>...</td>
      <td>-0.280035</td>
      <td>-0.022558</td>
      <td>-0.242541</td>
      <td>0.019229</td>
      <td>-0.054570</td>
      <td>0.314618</td>
      <td>0.319505</td>
      <td>0.437560</td>
      <td>0.122367</td>
      <td>0.647647</td>
      <td>-1.032804</td>
      <td>-0.713695</td>
      <td>-0.688856</td>
      <td>0.422452</td>
      <td>0.371483</td>
      <td>-0.214602</td>
      <td>-0.330746</td>
      <td>0.292759</td>
      <td>-1.456162</td>
      <td>0.355713</td>
      <td>0.671258</td>
      <td>0.442793</td>
      <td>-1.893271</td>
      <td>0.202606</td>
      <td>0.473671</td>
      <td>0.743323</td>
      <td>0.321141</td>
      <td>-0.137568</td>
      <td>-0.242235</td>
      <td>-0.070607</td>
      <td>-0.764340</td>
      <td>0.372837</td>
      <td>0.284113</td>
      <td>0.042443</td>
      <td>-0.491050</td>
      <td>-0.991518</td>
      <td>-0.562674</td>
      <td>0.459121</td>
      <td>0.872337</td>
      <td>0.778376</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.904272</td>
      <td>-0.150047</td>
      <td>-0.072260</td>
      <td>0.094144</td>
      <td>-0.455131</td>
      <td>-0.368966</td>
      <td>-0.489654</td>
      <td>0.145829</td>
      <td>-0.187522</td>
      <td>0.479767</td>
      <td>0.181747</td>
      <td>1.104805</td>
      <td>1.815664</td>
      <td>0.664684</td>
      <td>2.119741</td>
      <td>0.457231</td>
      <td>0.390578</td>
      <td>0.722238</td>
      <td>0.454608</td>
      <td>-0.794880</td>
      <td>-0.491787</td>
      <td>-1.309947</td>
      <td>-0.224390</td>
      <td>-0.043973</td>
      <td>-0.108555</td>
      <td>1.270247</td>
      <td>1.239976</td>
      <td>0.752918</td>
      <td>0.183382</td>
      <td>0.912706</td>
      <td>-0.203248</td>
      <td>0.166057</td>
      <td>0.255889</td>
      <td>0.658578</td>
      <td>1.111192</td>
      <td>-0.036359</td>
      <td>-0.491045</td>
      <td>-0.033930</td>
      <td>-0.179573</td>
      <td>0.025346</td>
      <td>...</td>
      <td>-0.229177</td>
      <td>0.308888</td>
      <td>0.175905</td>
      <td>0.676211</td>
      <td>0.526170</td>
      <td>-0.311268</td>
      <td>-0.561609</td>
      <td>-0.094874</td>
      <td>0.308310</td>
      <td>-0.446950</td>
      <td>-0.345410</td>
      <td>-0.485829</td>
      <td>-0.158328</td>
      <td>0.864903</td>
      <td>0.123123</td>
      <td>-1.122446</td>
      <td>-0.213785</td>
      <td>0.478211</td>
      <td>-1.138677</td>
      <td>1.682498</td>
      <td>0.733577</td>
      <td>0.556438</td>
      <td>-0.236074</td>
      <td>-1.450998</td>
      <td>-0.715136</td>
      <td>-0.029570</td>
      <td>-0.541358</td>
      <td>0.299844</td>
      <td>1.057554</td>
      <td>0.604855</td>
      <td>0.080258</td>
      <td>0.466888</td>
      <td>0.701862</td>
      <td>-0.051362</td>
      <td>0.776096</td>
      <td>0.134181</td>
      <td>-1.127359</td>
      <td>2.012299</td>
      <td>0.647343</td>
      <td>0.004895</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.719568</td>
      <td>-1.237282</td>
      <td>-0.301245</td>
      <td>0.812961</td>
      <td>0.965238</td>
      <td>0.328610</td>
      <td>0.810044</td>
      <td>-0.350707</td>
      <td>-0.219487</td>
      <td>0.841355</td>
      <td>0.240731</td>
      <td>0.133026</td>
      <td>-0.013006</td>
      <td>1.592561</td>
      <td>0.875891</td>
      <td>-0.921477</td>
      <td>0.139845</td>
      <td>-0.257944</td>
      <td>-0.382562</td>
      <td>-0.962511</td>
      <td>-0.202336</td>
      <td>-0.889250</td>
      <td>-0.811449</td>
      <td>0.399791</td>
      <td>-0.837619</td>
      <td>-0.557155</td>
      <td>-0.370480</td>
      <td>0.563571</td>
      <td>0.074080</td>
      <td>-0.742358</td>
      <td>0.094550</td>
      <td>-0.340968</td>
      <td>0.306949</td>
      <td>-0.094648</td>
      <td>0.231420</td>
      <td>-0.138854</td>
      <td>-0.878750</td>
      <td>0.852162</td>
      <td>-0.357302</td>
      <td>-0.528140</td>
      <td>...</td>
      <td>0.070768</td>
      <td>0.393732</td>
      <td>-0.556360</td>
      <td>-0.624368</td>
      <td>-1.035523</td>
      <td>-0.763418</td>
      <td>0.586083</td>
      <td>-0.318756</td>
      <td>0.179283</td>
      <td>0.213122</td>
      <td>0.564661</td>
      <td>1.035537</td>
      <td>-0.583139</td>
      <td>0.708151</td>
      <td>0.383817</td>
      <td>0.347991</td>
      <td>0.234393</td>
      <td>-0.017510</td>
      <td>0.435332</td>
      <td>0.369168</td>
      <td>-0.515178</td>
      <td>0.520097</td>
      <td>-0.008642</td>
      <td>-0.159468</td>
      <td>0.267868</td>
      <td>-0.632432</td>
      <td>0.222074</td>
      <td>-0.019872</td>
      <td>0.699281</td>
      <td>0.466836</td>
      <td>0.012181</td>
      <td>0.618527</td>
      <td>-0.060858</td>
      <td>-0.673836</td>
      <td>1.116682</td>
      <td>0.755976</td>
      <td>0.540188</td>
      <td>-1.116359</td>
      <td>-0.961403</td>
      <td>-0.408577</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.432654</td>
      <td>-0.890414</td>
      <td>-0.755389</td>
      <td>-0.403526</td>
      <td>-0.036625</td>
      <td>0.332534</td>
      <td>0.657320</td>
      <td>-0.136698</td>
      <td>0.206844</td>
      <td>0.347057</td>
      <td>0.967668</td>
      <td>-0.278154</td>
      <td>0.629887</td>
      <td>1.202788</td>
      <td>0.990312</td>
      <td>0.523862</td>
      <td>0.043672</td>
      <td>-0.260591</td>
      <td>0.101746</td>
      <td>0.576754</td>
      <td>-1.091018</td>
      <td>-0.155840</td>
      <td>-0.588370</td>
      <td>0.618991</td>
      <td>-0.523072</td>
      <td>-0.463207</td>
      <td>1.009175</td>
      <td>0.784496</td>
      <td>-0.445289</td>
      <td>-0.217289</td>
      <td>0.077653</td>
      <td>-0.902335</td>
      <td>-0.213781</td>
      <td>0.510099</td>
      <td>0.947742</td>
      <td>-0.382569</td>
      <td>-0.723444</td>
      <td>0.085385</td>
      <td>-1.510866</td>
      <td>-0.736842</td>
      <td>...</td>
      <td>-1.036342</td>
      <td>0.104406</td>
      <td>-0.464575</td>
      <td>-0.239511</td>
      <td>-0.008469</td>
      <td>-0.449903</td>
      <td>0.740441</td>
      <td>-1.430426</td>
      <td>0.962031</td>
      <td>0.530397</td>
      <td>-0.150393</td>
      <td>0.170144</td>
      <td>-0.431979</td>
      <td>-0.782615</td>
      <td>-0.166729</td>
      <td>0.177464</td>
      <td>0.162388</td>
      <td>-0.631558</td>
      <td>-1.496970</td>
      <td>0.242296</td>
      <td>0.136016</td>
      <td>0.320880</td>
      <td>-0.351484</td>
      <td>-0.426561</td>
      <td>0.002265</td>
      <td>-0.001484</td>
      <td>0.223273</td>
      <td>-0.313945</td>
      <td>-0.164054</td>
      <td>-0.740975</td>
      <td>-1.023205</td>
      <td>0.025966</td>
      <td>0.410213</td>
      <td>0.517945</td>
      <td>1.097076</td>
      <td>0.456174</td>
      <td>-0.605161</td>
      <td>-2.172330</td>
      <td>-0.950075</td>
      <td>0.198900</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.034291</td>
      <td>-0.105188</td>
      <td>0.556563</td>
      <td>0.546042</td>
      <td>1.655097</td>
      <td>0.437256</td>
      <td>0.413888</td>
      <td>0.630042</td>
      <td>0.289009</td>
      <td>0.591165</td>
      <td>-0.502827</td>
      <td>0.044739</td>
      <td>0.453322</td>
      <td>0.125018</td>
      <td>0.757914</td>
      <td>-0.864682</td>
      <td>-1.030776</td>
      <td>-1.217894</td>
      <td>-0.657295</td>
      <td>0.164333</td>
      <td>-0.263431</td>
      <td>0.047536</td>
      <td>-0.975745</td>
      <td>-0.406716</td>
      <td>-0.422803</td>
      <td>0.262291</td>
      <td>0.692756</td>
      <td>0.597466</td>
      <td>-0.268419</td>
      <td>-0.070942</td>
      <td>-0.486156</td>
      <td>-0.868993</td>
      <td>-0.029493</td>
      <td>-0.264618</td>
      <td>0.258361</td>
      <td>-0.730797</td>
      <td>-0.661319</td>
      <td>-0.391893</td>
      <td>0.070592</td>
      <td>0.307616</td>
      <td>...</td>
      <td>-0.253640</td>
      <td>-0.222458</td>
      <td>0.125294</td>
      <td>0.392979</td>
      <td>0.627844</td>
      <td>0.740071</td>
      <td>0.724527</td>
      <td>1.145651</td>
      <td>0.328250</td>
      <td>1.296844</td>
      <td>0.851640</td>
      <td>-0.101622</td>
      <td>0.067652</td>
      <td>0.187158</td>
      <td>0.324071</td>
      <td>-0.032447</td>
      <td>0.029369</td>
      <td>1.109398</td>
      <td>0.020501</td>
      <td>1.364229</td>
      <td>0.411303</td>
      <td>-0.827668</td>
      <td>-0.538648</td>
      <td>-0.584063</td>
      <td>-0.967943</td>
      <td>0.391964</td>
      <td>0.490520</td>
      <td>-0.323042</td>
      <td>-0.087965</td>
      <td>-0.757986</td>
      <td>-0.048064</td>
      <td>-0.378522</td>
      <td>-0.414438</td>
      <td>0.294784</td>
      <td>0.815048</td>
      <td>0.393998</td>
      <td>-0.662537</td>
      <td>0.620442</td>
      <td>-0.202663</td>
      <td>-0.151954</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-0.324272</td>
      <td>-1.251443</td>
      <td>-0.207962</td>
      <td>-0.012272</td>
      <td>0.930585</td>
      <td>0.425779</td>
      <td>0.333442</td>
      <td>-0.168705</td>
      <td>0.205978</td>
      <td>0.502043</td>
      <td>0.630958</td>
      <td>0.962286</td>
      <td>0.247186</td>
      <td>0.479593</td>
      <td>1.173152</td>
      <td>0.597692</td>
      <td>0.112840</td>
      <td>0.608996</td>
      <td>0.328927</td>
      <td>1.061944</td>
      <td>0.316238</td>
      <td>0.352417</td>
      <td>-0.446081</td>
      <td>-0.142383</td>
      <td>-0.720507</td>
      <td>0.577019</td>
      <td>0.648594</td>
      <td>0.687476</td>
      <td>0.140243</td>
      <td>-0.838665</td>
      <td>0.465838</td>
      <td>-0.609893</td>
      <td>-0.602718</td>
      <td>0.186054</td>
      <td>0.662746</td>
      <td>-0.233622</td>
      <td>-0.579816</td>
      <td>-0.564218</td>
      <td>-0.789474</td>
      <td>-0.625825</td>
      <td>...</td>
      <td>-0.756973</td>
      <td>0.297300</td>
      <td>-0.882724</td>
      <td>-0.171109</td>
      <td>0.118224</td>
      <td>-0.131370</td>
      <td>-0.631193</td>
      <td>0.240162</td>
      <td>1.346888</td>
      <td>0.669258</td>
      <td>0.391529</td>
      <td>0.548580</td>
      <td>-1.227615</td>
      <td>-0.236446</td>
      <td>-1.239676</td>
      <td>0.583562</td>
      <td>0.127255</td>
      <td>-0.405309</td>
      <td>0.465152</td>
      <td>1.213764</td>
      <td>0.881079</td>
      <td>0.167065</td>
      <td>-0.223153</td>
      <td>0.453908</td>
      <td>0.397895</td>
      <td>0.386613</td>
      <td>0.038324</td>
      <td>0.211339</td>
      <td>0.498549</td>
      <td>0.227322</td>
      <td>-0.395747</td>
      <td>0.214531</td>
      <td>0.223534</td>
      <td>0.113886</td>
      <td>0.351202</td>
      <td>1.444663</td>
      <td>-0.330669</td>
      <td>-2.249735</td>
      <td>-2.131736</td>
      <td>-1.599699</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>1.355793</td>
      <td>1.091927</td>
      <td>0.609460</td>
      <td>0.117517</td>
      <td>0.309203</td>
      <td>-0.421662</td>
      <td>-0.495508</td>
      <td>-1.042545</td>
      <td>0.240024</td>
      <td>-0.659289</td>
      <td>-1.259270</td>
      <td>-2.151098</td>
      <td>-0.496807</td>
      <td>-0.268357</td>
      <td>-0.966226</td>
      <td>-0.508772</td>
      <td>1.119476</td>
      <td>-0.017249</td>
      <td>0.238889</td>
      <td>-0.809002</td>
      <td>0.664851</td>
      <td>-0.387864</td>
      <td>-0.710594</td>
      <td>-0.971136</td>
      <td>-0.701827</td>
      <td>-0.400984</td>
      <td>0.197212</td>
      <td>-0.355033</td>
      <td>0.514228</td>
      <td>0.541308</td>
      <td>-0.631475</td>
      <td>-0.269820</td>
      <td>-0.139449</td>
      <td>-1.196477</td>
      <td>-0.036506</td>
      <td>-0.573206</td>
      <td>0.381504</td>
      <td>0.193632</td>
      <td>0.337526</td>
      <td>-0.794575</td>
      <td>...</td>
      <td>-0.672734</td>
      <td>-0.917666</td>
      <td>0.051435</td>
      <td>-0.283930</td>
      <td>0.072234</td>
      <td>-0.075423</td>
      <td>0.201140</td>
      <td>0.663505</td>
      <td>-0.072949</td>
      <td>-0.668616</td>
      <td>0.324355</td>
      <td>-0.417054</td>
      <td>-0.025463</td>
      <td>-0.371754</td>
      <td>-0.381504</td>
      <td>-0.002782</td>
      <td>-0.080884</td>
      <td>-0.700155</td>
      <td>-0.137226</td>
      <td>-0.150348</td>
      <td>0.631569</td>
      <td>-0.595938</td>
      <td>-0.182329</td>
      <td>0.232277</td>
      <td>1.078477</td>
      <td>1.482577</td>
      <td>0.707495</td>
      <td>0.223603</td>
      <td>1.324283</td>
      <td>-0.134457</td>
      <td>0.124623</td>
      <td>0.445902</td>
      <td>-0.384388</td>
      <td>-0.016960</td>
      <td>0.243978</td>
      <td>0.531207</td>
      <td>-0.715399</td>
      <td>2.735104</td>
      <td>2.084056</td>
      <td>1.571320</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.166823</td>
      <td>0.325479</td>
      <td>-0.406799</td>
      <td>1.037334</td>
      <td>0.373710</td>
      <td>-0.438532</td>
      <td>-0.764750</td>
      <td>-0.629873</td>
      <td>-0.282973</td>
      <td>-0.550812</td>
      <td>-0.635002</td>
      <td>-0.822122</td>
      <td>0.311130</td>
      <td>0.862016</td>
      <td>0.300614</td>
      <td>0.234435</td>
      <td>0.417355</td>
      <td>0.326657</td>
      <td>0.650685</td>
      <td>0.295293</td>
      <td>0.075287</td>
      <td>-0.509399</td>
      <td>0.169677</td>
      <td>-0.588510</td>
      <td>0.045270</td>
      <td>-0.232363</td>
      <td>-0.620054</td>
      <td>0.045856</td>
      <td>0.309096</td>
      <td>1.120236</td>
      <td>0.086757</td>
      <td>0.155929</td>
      <td>-0.194787</td>
      <td>-0.385700</td>
      <td>-0.327461</td>
      <td>-0.843704</td>
      <td>0.145853</td>
      <td>-0.488221</td>
      <td>0.590646</td>
      <td>-0.320837</td>
      <td>...</td>
      <td>-0.680150</td>
      <td>0.321022</td>
      <td>-0.828975</td>
      <td>-0.290273</td>
      <td>-0.460996</td>
      <td>-0.594608</td>
      <td>-0.666695</td>
      <td>1.062169</td>
      <td>0.610500</td>
      <td>-0.016273</td>
      <td>0.627125</td>
      <td>-0.452744</td>
      <td>-0.153582</td>
      <td>-0.317212</td>
      <td>-1.423081</td>
      <td>0.028946</td>
      <td>0.917800</td>
      <td>0.030044</td>
      <td>-1.155684</td>
      <td>-0.517507</td>
      <td>-0.457527</td>
      <td>-0.304608</td>
      <td>-0.876339</td>
      <td>-0.339726</td>
      <td>0.332570</td>
      <td>0.487685</td>
      <td>-0.634031</td>
      <td>-0.365852</td>
      <td>0.017168</td>
      <td>-0.690990</td>
      <td>-1.432425</td>
      <td>-0.737478</td>
      <td>-0.268978</td>
      <td>-1.101755</td>
      <td>-0.475408</td>
      <td>-0.786761</td>
      <td>0.554055</td>
      <td>1.790180</td>
      <td>1.493444</td>
      <td>1.233696</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.276572</td>
      <td>0.032858</td>
      <td>-0.195280</td>
      <td>0.184852</td>
      <td>0.310159</td>
      <td>0.207521</td>
      <td>-0.173532</td>
      <td>0.066681</td>
      <td>0.330016</td>
      <td>0.762349</td>
      <td>-0.087265</td>
      <td>-0.642415</td>
      <td>0.423841</td>
      <td>1.046427</td>
      <td>0.891624</td>
      <td>-0.037102</td>
      <td>0.344077</td>
      <td>0.284252</td>
      <td>-0.878763</td>
      <td>-0.006678</td>
      <td>0.951764</td>
      <td>0.447120</td>
      <td>0.304809</td>
      <td>0.109110</td>
      <td>-0.896123</td>
      <td>-0.748994</td>
      <td>-1.126991</td>
      <td>0.290518</td>
      <td>0.458675</td>
      <td>0.495198</td>
      <td>-1.302723</td>
      <td>-0.582750</td>
      <td>-0.865196</td>
      <td>0.287773</td>
      <td>-0.029594</td>
      <td>1.050547</td>
      <td>0.072785</td>
      <td>-0.086419</td>
      <td>0.501661</td>
      <td>0.914921</td>
      <td>...</td>
      <td>-0.338830</td>
      <td>1.553052</td>
      <td>-0.102710</td>
      <td>-0.100001</td>
      <td>0.390181</td>
      <td>-0.189952</td>
      <td>-0.439213</td>
      <td>0.335593</td>
      <td>0.366876</td>
      <td>0.022504</td>
      <td>-0.052394</td>
      <td>-0.304462</td>
      <td>-0.053208</td>
      <td>0.287271</td>
      <td>0.289506</td>
      <td>0.324474</td>
      <td>0.284133</td>
      <td>-0.123298</td>
      <td>-0.046180</td>
      <td>0.752779</td>
      <td>0.525333</td>
      <td>-0.859775</td>
      <td>0.996536</td>
      <td>0.136196</td>
      <td>-0.531974</td>
      <td>-0.167021</td>
      <td>-1.270968</td>
      <td>0.053035</td>
      <td>0.626057</td>
      <td>-0.592084</td>
      <td>-0.145038</td>
      <td>0.296338</td>
      <td>0.367094</td>
      <td>-0.028905</td>
      <td>-0.471660</td>
      <td>-0.262562</td>
      <td>-0.002404</td>
      <td>0.272478</td>
      <td>0.619436</td>
      <td>-0.504410</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.096923</td>
      <td>-0.426914</td>
      <td>0.668883</td>
      <td>-0.773367</td>
      <td>-0.343435</td>
      <td>-0.126743</td>
      <td>-0.117484</td>
      <td>-0.491009</td>
      <td>-0.204702</td>
      <td>-0.090562</td>
      <td>0.112397</td>
      <td>-0.279297</td>
      <td>1.421053</td>
      <td>0.743572</td>
      <td>-0.627969</td>
      <td>0.712131</td>
      <td>0.451984</td>
      <td>0.441234</td>
      <td>0.517319</td>
      <td>0.595803</td>
      <td>0.496601</td>
      <td>-0.090917</td>
      <td>-0.690073</td>
      <td>-0.009790</td>
      <td>-0.428031</td>
      <td>0.147252</td>
      <td>-0.403001</td>
      <td>-0.197591</td>
      <td>0.506075</td>
      <td>-0.183859</td>
      <td>-0.467856</td>
      <td>0.890735</td>
      <td>-0.722515</td>
      <td>-1.041850</td>
      <td>-0.652196</td>
      <td>-0.085741</td>
      <td>-0.577540</td>
      <td>-0.265434</td>
      <td>0.520119</td>
      <td>-0.415329</td>
      <td>...</td>
      <td>-0.500810</td>
      <td>-0.260205</td>
      <td>-0.361578</td>
      <td>0.037865</td>
      <td>0.131835</td>
      <td>-1.302839</td>
      <td>-0.881845</td>
      <td>0.308929</td>
      <td>-0.729137</td>
      <td>0.558703</td>
      <td>0.518154</td>
      <td>0.270567</td>
      <td>0.035206</td>
      <td>-0.599125</td>
      <td>-1.159735</td>
      <td>-0.855223</td>
      <td>-0.358079</td>
      <td>-1.391097</td>
      <td>-0.693132</td>
      <td>-0.436175</td>
      <td>-0.466044</td>
      <td>-0.752961</td>
      <td>-0.019169</td>
      <td>0.198250</td>
      <td>0.618644</td>
      <td>0.145832</td>
      <td>0.065676</td>
      <td>0.085705</td>
      <td>0.908683</td>
      <td>-0.233281</td>
      <td>-0.231857</td>
      <td>0.659703</td>
      <td>0.016840</td>
      <td>-0.330383</td>
      <td>-0.056514</td>
      <td>-0.528659</td>
      <td>-0.044089</td>
      <td>0.183122</td>
      <td>-0.495469</td>
      <td>-0.136854</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.002237</td>
      <td>0.916899</td>
      <td>-0.152764</td>
      <td>0.511356</td>
      <td>0.842370</td>
      <td>-0.089641</td>
      <td>1.425854</td>
      <td>-0.203120</td>
      <td>0.196665</td>
      <td>-0.082662</td>
      <td>0.192728</td>
      <td>-0.975769</td>
      <td>-0.017081</td>
      <td>0.014988</td>
      <td>-0.149627</td>
      <td>0.703301</td>
      <td>-0.490753</td>
      <td>0.368716</td>
      <td>0.383770</td>
      <td>0.311833</td>
      <td>0.061443</td>
      <td>-0.727972</td>
      <td>-0.256324</td>
      <td>-0.377674</td>
      <td>-1.661084</td>
      <td>-0.033223</td>
      <td>-0.829372</td>
      <td>0.550645</td>
      <td>-0.070264</td>
      <td>1.282177</td>
      <td>0.074952</td>
      <td>-0.461163</td>
      <td>-0.772768</td>
      <td>-1.299949</td>
      <td>-1.127621</td>
      <td>0.001058</td>
      <td>-0.910953</td>
      <td>0.024055</td>
      <td>-0.088034</td>
      <td>-0.662231</td>
      <td>...</td>
      <td>0.008379</td>
      <td>-0.312075</td>
      <td>-0.551964</td>
      <td>-0.480640</td>
      <td>-0.636823</td>
      <td>-0.879727</td>
      <td>-0.273143</td>
      <td>0.410131</td>
      <td>-0.658904</td>
      <td>-0.509266</td>
      <td>-1.211529</td>
      <td>0.257204</td>
      <td>0.367606</td>
      <td>0.067976</td>
      <td>-0.261790</td>
      <td>-0.139493</td>
      <td>-0.048391</td>
      <td>-0.578153</td>
      <td>-0.090127</td>
      <td>0.021054</td>
      <td>0.906460</td>
      <td>-0.696379</td>
      <td>-0.002606</td>
      <td>-0.091228</td>
      <td>-0.408913</td>
      <td>-0.123555</td>
      <td>-0.237758</td>
      <td>0.300238</td>
      <td>-0.302570</td>
      <td>0.705509</td>
      <td>-0.355977</td>
      <td>0.263259</td>
      <td>0.240540</td>
      <td>-1.420257</td>
      <td>-0.255726</td>
      <td>0.668259</td>
      <td>0.135215</td>
      <td>0.747977</td>
      <td>0.278138</td>
      <td>-0.246163</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7fddbc99fdf0&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef  std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.008819  0.04257  23.698146  3.767925e-124  0.925384  1.092253
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.491 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>