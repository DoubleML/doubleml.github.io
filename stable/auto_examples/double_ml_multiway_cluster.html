
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.1.1 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>     to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-0.064212</td>
      <td>0.163448</td>
      <td>-0.569046</td>
      <td>-0.968120</td>
      <td>-0.691429</td>
      <td>-0.087758</td>
      <td>-1.474605</td>
      <td>-1.336488</td>
      <td>-0.656580</td>
      <td>-0.032774</td>
      <td>0.538960</td>
      <td>-1.523677</td>
      <td>-0.552138</td>
      <td>-0.608965</td>
      <td>0.555136</td>
      <td>-1.090433</td>
      <td>0.356377</td>
      <td>0.143969</td>
      <td>0.465525</td>
      <td>0.778234</td>
      <td>0.934009</td>
      <td>-0.298191</td>
      <td>-0.155506</td>
      <td>-0.868003</td>
      <td>-0.547204</td>
      <td>0.103544</td>
      <td>-0.043993</td>
      <td>-0.075139</td>
      <td>-0.016022</td>
      <td>0.060206</td>
      <td>-0.435343</td>
      <td>1.415587</td>
      <td>0.293863</td>
      <td>0.542455</td>
      <td>-0.364421</td>
      <td>-0.357397</td>
      <td>0.268431</td>
      <td>-0.620011</td>
      <td>-0.398093</td>
      <td>-0.879258</td>
      <td>...</td>
      <td>-0.278455</td>
      <td>0.410194</td>
      <td>0.388902</td>
      <td>-0.495925</td>
      <td>-1.340205</td>
      <td>0.801124</td>
      <td>0.154203</td>
      <td>-0.473507</td>
      <td>-0.655026</td>
      <td>0.777010</td>
      <td>0.144961</td>
      <td>0.162123</td>
      <td>-0.883939</td>
      <td>0.307595</td>
      <td>-0.029860</td>
      <td>0.378890</td>
      <td>-1.307877</td>
      <td>-0.592035</td>
      <td>-0.118897</td>
      <td>0.072122</td>
      <td>0.823801</td>
      <td>0.412768</td>
      <td>-0.290691</td>
      <td>-0.904468</td>
      <td>0.143660</td>
      <td>-0.117103</td>
      <td>-1.019642</td>
      <td>0.281796</td>
      <td>0.433397</td>
      <td>0.098687</td>
      <td>0.091968</td>
      <td>0.678847</td>
      <td>2.048959</td>
      <td>1.902531</td>
      <td>0.579277</td>
      <td>-0.405062</td>
      <td>-0.549863</td>
      <td>-0.167135</td>
      <td>0.132843</td>
      <td>0.531905</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.248745</td>
      <td>1.035378</td>
      <td>1.473062</td>
      <td>0.714591</td>
      <td>0.021048</td>
      <td>0.186798</td>
      <td>-0.354502</td>
      <td>-1.006205</td>
      <td>-0.894103</td>
      <td>-0.556479</td>
      <td>-0.243317</td>
      <td>-0.812727</td>
      <td>-1.352930</td>
      <td>-0.188687</td>
      <td>-0.402793</td>
      <td>0.139129</td>
      <td>-0.109658</td>
      <td>-0.398267</td>
      <td>0.148008</td>
      <td>0.002432</td>
      <td>0.168282</td>
      <td>-0.568382</td>
      <td>0.129393</td>
      <td>-0.270354</td>
      <td>-1.124859</td>
      <td>1.524957</td>
      <td>-0.913394</td>
      <td>0.731845</td>
      <td>-0.932736</td>
      <td>-0.307765</td>
      <td>-1.479098</td>
      <td>0.656589</td>
      <td>1.207204</td>
      <td>0.679693</td>
      <td>0.091391</td>
      <td>0.085294</td>
      <td>-0.449289</td>
      <td>0.093846</td>
      <td>-0.597470</td>
      <td>-0.408434</td>
      <td>...</td>
      <td>-0.331224</td>
      <td>0.848559</td>
      <td>0.793684</td>
      <td>-0.106447</td>
      <td>0.597780</td>
      <td>0.567605</td>
      <td>0.108175</td>
      <td>0.128098</td>
      <td>0.345654</td>
      <td>-0.313495</td>
      <td>-0.716640</td>
      <td>-0.290410</td>
      <td>0.445958</td>
      <td>0.161793</td>
      <td>0.231912</td>
      <td>-0.698587</td>
      <td>-1.112140</td>
      <td>-0.273389</td>
      <td>0.075524</td>
      <td>0.174911</td>
      <td>1.005102</td>
      <td>-0.192405</td>
      <td>0.273786</td>
      <td>-0.402452</td>
      <td>-0.242205</td>
      <td>-0.366149</td>
      <td>-1.056545</td>
      <td>0.667599</td>
      <td>-0.148405</td>
      <td>0.038022</td>
      <td>-0.662865</td>
      <td>-0.799793</td>
      <td>0.586066</td>
      <td>0.139542</td>
      <td>0.187714</td>
      <td>-1.507495</td>
      <td>-0.521195</td>
      <td>1.273494</td>
      <td>0.380893</td>
      <td>-0.498207</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.283273</td>
      <td>1.150428</td>
      <td>0.083729</td>
      <td>-0.540342</td>
      <td>-1.166997</td>
      <td>-1.158457</td>
      <td>-0.917151</td>
      <td>0.207409</td>
      <td>-0.363646</td>
      <td>1.050207</td>
      <td>0.515789</td>
      <td>-0.156760</td>
      <td>0.182969</td>
      <td>-0.469222</td>
      <td>0.942218</td>
      <td>0.974400</td>
      <td>0.285202</td>
      <td>0.381780</td>
      <td>0.698714</td>
      <td>0.157452</td>
      <td>-0.186427</td>
      <td>-0.498431</td>
      <td>-0.014475</td>
      <td>-0.193947</td>
      <td>0.107834</td>
      <td>-0.383606</td>
      <td>0.609614</td>
      <td>0.601126</td>
      <td>-1.447250</td>
      <td>-0.455643</td>
      <td>0.312853</td>
      <td>0.973729</td>
      <td>-0.519591</td>
      <td>0.641476</td>
      <td>0.162770</td>
      <td>-0.858304</td>
      <td>-0.725403</td>
      <td>-0.621124</td>
      <td>-0.414713</td>
      <td>0.398586</td>
      <td>...</td>
      <td>0.078958</td>
      <td>0.104609</td>
      <td>0.403599</td>
      <td>0.578847</td>
      <td>0.980453</td>
      <td>-0.571628</td>
      <td>-0.274907</td>
      <td>0.481648</td>
      <td>0.610909</td>
      <td>0.944644</td>
      <td>0.468222</td>
      <td>-0.418939</td>
      <td>-0.065087</td>
      <td>-0.771839</td>
      <td>0.760285</td>
      <td>-0.112244</td>
      <td>-0.524731</td>
      <td>-1.022558</td>
      <td>-0.112968</td>
      <td>-0.590605</td>
      <td>-0.804984</td>
      <td>0.283000</td>
      <td>0.277683</td>
      <td>-0.708132</td>
      <td>-0.147757</td>
      <td>0.065166</td>
      <td>-0.341971</td>
      <td>-0.387833</td>
      <td>0.246817</td>
      <td>0.613887</td>
      <td>-1.073514</td>
      <td>0.214623</td>
      <td>0.514400</td>
      <td>0.507585</td>
      <td>0.144049</td>
      <td>0.332741</td>
      <td>-0.469839</td>
      <td>0.769372</td>
      <td>0.839943</td>
      <td>0.020900</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.156399</td>
      <td>1.081291</td>
      <td>-0.412547</td>
      <td>-0.955896</td>
      <td>-0.490641</td>
      <td>-0.279047</td>
      <td>-0.674535</td>
      <td>-0.510078</td>
      <td>-1.066164</td>
      <td>0.185529</td>
      <td>0.464996</td>
      <td>-1.284751</td>
      <td>0.111225</td>
      <td>-0.820657</td>
      <td>0.622694</td>
      <td>0.342541</td>
      <td>0.387954</td>
      <td>-0.209315</td>
      <td>0.336674</td>
      <td>0.844195</td>
      <td>0.950613</td>
      <td>0.396317</td>
      <td>-0.335341</td>
      <td>0.184261</td>
      <td>-0.317938</td>
      <td>0.455256</td>
      <td>-0.828630</td>
      <td>0.460591</td>
      <td>0.477386</td>
      <td>-0.112457</td>
      <td>0.301690</td>
      <td>0.533845</td>
      <td>1.396894</td>
      <td>0.903504</td>
      <td>0.779292</td>
      <td>-0.049636</td>
      <td>-0.412097</td>
      <td>0.198747</td>
      <td>0.675310</td>
      <td>-0.249814</td>
      <td>...</td>
      <td>-0.688465</td>
      <td>-0.454332</td>
      <td>-0.108604</td>
      <td>0.613325</td>
      <td>-0.029498</td>
      <td>0.173521</td>
      <td>-0.092799</td>
      <td>0.834202</td>
      <td>-0.612101</td>
      <td>0.062754</td>
      <td>0.915542</td>
      <td>0.847481</td>
      <td>0.614919</td>
      <td>-0.833623</td>
      <td>-0.582958</td>
      <td>0.626347</td>
      <td>-0.414764</td>
      <td>-0.322651</td>
      <td>-0.072688</td>
      <td>0.757673</td>
      <td>-0.431725</td>
      <td>0.464568</td>
      <td>0.871265</td>
      <td>0.074447</td>
      <td>-0.585383</td>
      <td>-1.228905</td>
      <td>-0.088101</td>
      <td>-0.055815</td>
      <td>0.616647</td>
      <td>-0.183973</td>
      <td>-0.674943</td>
      <td>0.025159</td>
      <td>1.089005</td>
      <td>0.210008</td>
      <td>0.480182</td>
      <td>0.482162</td>
      <td>0.177465</td>
      <td>0.710846</td>
      <td>0.655853</td>
      <td>0.189153</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.793367</td>
      <td>1.502235</td>
      <td>1.278188</td>
      <td>0.596214</td>
      <td>-1.088816</td>
      <td>0.385644</td>
      <td>0.480031</td>
      <td>-0.579273</td>
      <td>-0.664697</td>
      <td>0.048265</td>
      <td>-0.579993</td>
      <td>-1.455236</td>
      <td>-0.324077</td>
      <td>0.140870</td>
      <td>0.530318</td>
      <td>-0.017968</td>
      <td>-0.207353</td>
      <td>-0.071555</td>
      <td>1.723432</td>
      <td>1.072685</td>
      <td>-0.333974</td>
      <td>-1.173275</td>
      <td>0.021846</td>
      <td>0.371150</td>
      <td>0.594571</td>
      <td>0.819489</td>
      <td>0.986974</td>
      <td>-0.869318</td>
      <td>-0.174364</td>
      <td>-0.188986</td>
      <td>-0.199378</td>
      <td>-0.095678</td>
      <td>-0.119454</td>
      <td>0.354329</td>
      <td>-0.557509</td>
      <td>-0.292387</td>
      <td>-0.859062</td>
      <td>-0.535756</td>
      <td>0.969530</td>
      <td>0.239538</td>
      <td>...</td>
      <td>0.652296</td>
      <td>0.295725</td>
      <td>0.650032</td>
      <td>0.048247</td>
      <td>0.188927</td>
      <td>-0.320108</td>
      <td>-0.974564</td>
      <td>-0.248871</td>
      <td>-0.842033</td>
      <td>-0.196413</td>
      <td>-0.151190</td>
      <td>-0.021458</td>
      <td>0.105026</td>
      <td>1.049397</td>
      <td>0.724831</td>
      <td>-0.387188</td>
      <td>0.601025</td>
      <td>0.415098</td>
      <td>-0.417978</td>
      <td>0.668752</td>
      <td>0.917287</td>
      <td>1.141339</td>
      <td>0.590803</td>
      <td>-0.782609</td>
      <td>-0.139141</td>
      <td>-0.583070</td>
      <td>-0.923705</td>
      <td>-0.608070</td>
      <td>-0.269618</td>
      <td>0.555342</td>
      <td>0.164787</td>
      <td>0.242998</td>
      <td>0.915042</td>
      <td>1.369593</td>
      <td>-0.077987</td>
      <td>-0.434915</td>
      <td>-0.162262</td>
      <td>2.140028</td>
      <td>2.248245</td>
      <td>0.919630</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.939726</td>
      <td>-0.540084</td>
      <td>0.255676</td>
      <td>-0.725556</td>
      <td>0.461747</td>
      <td>0.024499</td>
      <td>0.105835</td>
      <td>0.714040</td>
      <td>-0.499299</td>
      <td>0.038256</td>
      <td>-0.132180</td>
      <td>-1.744701</td>
      <td>-0.148854</td>
      <td>0.280449</td>
      <td>1.120611</td>
      <td>-0.215542</td>
      <td>0.037027</td>
      <td>-0.486119</td>
      <td>-0.460096</td>
      <td>-0.151286</td>
      <td>0.865403</td>
      <td>-0.653304</td>
      <td>-0.888303</td>
      <td>-0.295707</td>
      <td>0.758387</td>
      <td>1.205711</td>
      <td>1.206637</td>
      <td>0.588702</td>
      <td>-0.940406</td>
      <td>-0.883028</td>
      <td>0.562856</td>
      <td>0.479646</td>
      <td>-0.038270</td>
      <td>-0.516223</td>
      <td>0.627253</td>
      <td>0.268898</td>
      <td>-0.246005</td>
      <td>-0.132504</td>
      <td>-0.489688</td>
      <td>0.583474</td>
      <td>...</td>
      <td>-0.726847</td>
      <td>0.048934</td>
      <td>0.556012</td>
      <td>-0.448978</td>
      <td>-0.650477</td>
      <td>0.585231</td>
      <td>-0.148197</td>
      <td>0.270202</td>
      <td>0.684769</td>
      <td>1.265033</td>
      <td>0.180654</td>
      <td>-0.167568</td>
      <td>-0.155789</td>
      <td>0.806998</td>
      <td>0.530950</td>
      <td>-0.414136</td>
      <td>-0.384614</td>
      <td>0.116465</td>
      <td>0.486896</td>
      <td>0.336991</td>
      <td>1.440331</td>
      <td>0.916694</td>
      <td>0.153909</td>
      <td>-0.455161</td>
      <td>0.233165</td>
      <td>-0.256377</td>
      <td>-0.070084</td>
      <td>-1.165928</td>
      <td>0.385511</td>
      <td>0.558223</td>
      <td>-0.498204</td>
      <td>0.232971</td>
      <td>-0.188711</td>
      <td>-0.010686</td>
      <td>-0.282006</td>
      <td>-0.519796</td>
      <td>-0.127537</td>
      <td>-2.159167</td>
      <td>-1.975836</td>
      <td>-1.421064</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.204738</td>
      <td>-0.835639</td>
      <td>-0.237728</td>
      <td>0.457636</td>
      <td>-0.329193</td>
      <td>-0.324765</td>
      <td>-0.339789</td>
      <td>-0.217251</td>
      <td>-0.046943</td>
      <td>0.454419</td>
      <td>0.105409</td>
      <td>-0.457294</td>
      <td>0.412980</td>
      <td>0.015463</td>
      <td>0.351069</td>
      <td>0.005478</td>
      <td>-0.362257</td>
      <td>-1.021464</td>
      <td>0.105133</td>
      <td>-0.575267</td>
      <td>0.750717</td>
      <td>-0.274652</td>
      <td>-0.468291</td>
      <td>-0.273956</td>
      <td>0.637286</td>
      <td>-0.102129</td>
      <td>-0.345979</td>
      <td>0.353387</td>
      <td>0.636067</td>
      <td>0.445594</td>
      <td>0.959961</td>
      <td>0.826090</td>
      <td>-0.272596</td>
      <td>-0.383089</td>
      <td>-0.644581</td>
      <td>0.031575</td>
      <td>-0.993695</td>
      <td>-0.011965</td>
      <td>0.050532</td>
      <td>0.082216</td>
      <td>...</td>
      <td>-0.144927</td>
      <td>-0.813735</td>
      <td>-0.457322</td>
      <td>-0.814164</td>
      <td>0.537539</td>
      <td>0.559887</td>
      <td>0.023736</td>
      <td>-1.124226</td>
      <td>-1.331605</td>
      <td>-0.590649</td>
      <td>-0.152623</td>
      <td>0.900782</td>
      <td>-0.879001</td>
      <td>-1.121983</td>
      <td>-0.924888</td>
      <td>-0.022191</td>
      <td>-0.688112</td>
      <td>-0.308331</td>
      <td>-0.565883</td>
      <td>0.052269</td>
      <td>1.080956</td>
      <td>1.059871</td>
      <td>0.799251</td>
      <td>-0.324326</td>
      <td>-0.873435</td>
      <td>-0.078878</td>
      <td>-1.029132</td>
      <td>-0.502108</td>
      <td>-0.008164</td>
      <td>0.509696</td>
      <td>0.097909</td>
      <td>0.283065</td>
      <td>0.728453</td>
      <td>0.643740</td>
      <td>0.528831</td>
      <td>0.415749</td>
      <td>-0.471483</td>
      <td>-3.285728</td>
      <td>-1.846261</td>
      <td>-1.152532</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1.302066</td>
      <td>1.078166</td>
      <td>0.794023</td>
      <td>-0.666560</td>
      <td>-0.419494</td>
      <td>0.796832</td>
      <td>-0.642053</td>
      <td>0.092374</td>
      <td>-0.216831</td>
      <td>0.399377</td>
      <td>-0.617226</td>
      <td>0.487160</td>
      <td>-0.312742</td>
      <td>-0.314723</td>
      <td>0.208330</td>
      <td>0.575187</td>
      <td>0.330713</td>
      <td>1.150286</td>
      <td>-0.038360</td>
      <td>0.070650</td>
      <td>0.461828</td>
      <td>-0.617928</td>
      <td>-0.599209</td>
      <td>-0.071998</td>
      <td>-0.224388</td>
      <td>1.481222</td>
      <td>0.681740</td>
      <td>-0.141291</td>
      <td>0.177225</td>
      <td>0.612225</td>
      <td>0.499703</td>
      <td>0.969634</td>
      <td>-0.437295</td>
      <td>0.375388</td>
      <td>0.581971</td>
      <td>-0.272314</td>
      <td>-0.207911</td>
      <td>-0.225688</td>
      <td>0.247389</td>
      <td>0.784921</td>
      <td>...</td>
      <td>-0.160458</td>
      <td>-0.021201</td>
      <td>0.407088</td>
      <td>-0.481392</td>
      <td>-0.547177</td>
      <td>0.674896</td>
      <td>0.412047</td>
      <td>-0.021094</td>
      <td>-0.683205</td>
      <td>0.448900</td>
      <td>1.471742</td>
      <td>0.275230</td>
      <td>0.058187</td>
      <td>-0.583575</td>
      <td>-0.203144</td>
      <td>-0.200548</td>
      <td>0.183563</td>
      <td>0.571419</td>
      <td>0.450001</td>
      <td>-0.415563</td>
      <td>-0.635847</td>
      <td>-0.064403</td>
      <td>0.051140</td>
      <td>-0.376793</td>
      <td>-0.551062</td>
      <td>-1.110088</td>
      <td>-1.109343</td>
      <td>0.213567</td>
      <td>-0.230471</td>
      <td>0.266775</td>
      <td>-1.205308</td>
      <td>-1.053148</td>
      <td>0.888126</td>
      <td>-0.143430</td>
      <td>0.555206</td>
      <td>0.138372</td>
      <td>0.476553</td>
      <td>0.532770</td>
      <td>-0.305358</td>
      <td>-1.196347</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.394364</td>
      <td>1.060803</td>
      <td>0.146269</td>
      <td>0.041647</td>
      <td>-0.742276</td>
      <td>0.344558</td>
      <td>-0.606222</td>
      <td>0.336968</td>
      <td>-0.493186</td>
      <td>0.298792</td>
      <td>0.059993</td>
      <td>-0.668941</td>
      <td>-0.189619</td>
      <td>-0.708171</td>
      <td>0.328005</td>
      <td>-0.283605</td>
      <td>-0.147994</td>
      <td>1.184310</td>
      <td>0.752167</td>
      <td>0.565430</td>
      <td>-0.393935</td>
      <td>-1.426935</td>
      <td>0.203856</td>
      <td>-0.712648</td>
      <td>-0.222098</td>
      <td>-0.672888</td>
      <td>0.691676</td>
      <td>0.325942</td>
      <td>-0.786948</td>
      <td>-0.247478</td>
      <td>0.231693</td>
      <td>0.358327</td>
      <td>0.115665</td>
      <td>0.374801</td>
      <td>0.260772</td>
      <td>-0.047149</td>
      <td>-0.068890</td>
      <td>-0.622312</td>
      <td>1.145757</td>
      <td>0.206298</td>
      <td>...</td>
      <td>-0.549477</td>
      <td>-0.536069</td>
      <td>-0.296831</td>
      <td>0.769828</td>
      <td>0.536649</td>
      <td>-0.013848</td>
      <td>0.424290</td>
      <td>-0.451102</td>
      <td>-0.931658</td>
      <td>0.250756</td>
      <td>0.257120</td>
      <td>0.699207</td>
      <td>-0.817914</td>
      <td>0.025937</td>
      <td>0.282517</td>
      <td>0.103364</td>
      <td>-0.763619</td>
      <td>-1.053229</td>
      <td>-0.242652</td>
      <td>0.025529</td>
      <td>0.401028</td>
      <td>0.737434</td>
      <td>-0.563449</td>
      <td>-0.526779</td>
      <td>-0.357583</td>
      <td>1.028353</td>
      <td>0.628080</td>
      <td>-0.330289</td>
      <td>-0.548700</td>
      <td>0.857905</td>
      <td>-0.018398</td>
      <td>0.059732</td>
      <td>-0.103671</td>
      <td>0.079500</td>
      <td>0.738410</td>
      <td>-0.116296</td>
      <td>-0.311856</td>
      <td>0.947294</td>
      <td>0.170103</td>
      <td>0.134283</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.957251</td>
      <td>0.162811</td>
      <td>0.191377</td>
      <td>-0.975209</td>
      <td>-0.573700</td>
      <td>-0.761743</td>
      <td>0.220099</td>
      <td>0.536274</td>
      <td>-0.929379</td>
      <td>-0.359514</td>
      <td>0.558633</td>
      <td>-1.562497</td>
      <td>-0.599359</td>
      <td>-0.127662</td>
      <td>0.150128</td>
      <td>-0.169583</td>
      <td>-0.685300</td>
      <td>0.748610</td>
      <td>1.221663</td>
      <td>0.446482</td>
      <td>0.720554</td>
      <td>-0.153901</td>
      <td>0.300261</td>
      <td>-0.282049</td>
      <td>0.002496</td>
      <td>0.049724</td>
      <td>-0.620388</td>
      <td>-0.591108</td>
      <td>-0.438561</td>
      <td>0.130609</td>
      <td>0.507233</td>
      <td>1.101212</td>
      <td>0.953135</td>
      <td>-0.659804</td>
      <td>-0.417046</td>
      <td>-0.411854</td>
      <td>-0.690743</td>
      <td>-0.282768</td>
      <td>0.793663</td>
      <td>0.536124</td>
      <td>...</td>
      <td>0.336393</td>
      <td>0.719572</td>
      <td>1.217377</td>
      <td>0.016362</td>
      <td>-0.401286</td>
      <td>0.548545</td>
      <td>0.447744</td>
      <td>-0.602166</td>
      <td>0.180537</td>
      <td>0.063749</td>
      <td>-0.305345</td>
      <td>0.137990</td>
      <td>0.361690</td>
      <td>0.591001</td>
      <td>0.415529</td>
      <td>-0.314827</td>
      <td>-0.583302</td>
      <td>-0.606499</td>
      <td>-0.908234</td>
      <td>0.538656</td>
      <td>0.043809</td>
      <td>-0.427205</td>
      <td>0.290972</td>
      <td>-0.417448</td>
      <td>0.303189</td>
      <td>-0.440633</td>
      <td>0.424835</td>
      <td>0.307935</td>
      <td>0.020605</td>
      <td>-0.312651</td>
      <td>1.124674</td>
      <td>0.451950</td>
      <td>0.951618</td>
      <td>0.141532</td>
      <td>-0.188677</td>
      <td>-0.510279</td>
      <td>-1.288092</td>
      <td>0.065189</td>
      <td>-0.675148</td>
      <td>-1.036750</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-0.757704</td>
      <td>0.573373</td>
      <td>0.525098</td>
      <td>0.034781</td>
      <td>-0.086174</td>
      <td>0.155966</td>
      <td>0.125923</td>
      <td>-0.465158</td>
      <td>-0.095593</td>
      <td>0.906513</td>
      <td>1.507275</td>
      <td>-0.983689</td>
      <td>0.364092</td>
      <td>0.121818</td>
      <td>0.465315</td>
      <td>-0.655657</td>
      <td>-0.304947</td>
      <td>-0.364256</td>
      <td>-0.439777</td>
      <td>1.108334</td>
      <td>1.856211</td>
      <td>0.339290</td>
      <td>0.131760</td>
      <td>0.733104</td>
      <td>-1.036934</td>
      <td>0.058577</td>
      <td>0.148216</td>
      <td>0.108178</td>
      <td>-0.026075</td>
      <td>-0.287148</td>
      <td>-0.212602</td>
      <td>1.741523</td>
      <td>0.176740</td>
      <td>0.030560</td>
      <td>-0.994665</td>
      <td>-0.411829</td>
      <td>-0.622148</td>
      <td>-0.104317</td>
      <td>-0.081933</td>
      <td>-0.494733</td>
      <td>...</td>
      <td>-0.078591</td>
      <td>-0.254762</td>
      <td>0.302353</td>
      <td>-0.436801</td>
      <td>-0.522153</td>
      <td>0.733458</td>
      <td>-0.841096</td>
      <td>-0.391680</td>
      <td>-0.148424</td>
      <td>0.185340</td>
      <td>0.117191</td>
      <td>-0.329558</td>
      <td>0.534387</td>
      <td>0.611843</td>
      <td>0.666887</td>
      <td>0.278233</td>
      <td>-0.095020</td>
      <td>0.685224</td>
      <td>0.338750</td>
      <td>-0.059639</td>
      <td>-0.180576</td>
      <td>0.512061</td>
      <td>1.317122</td>
      <td>0.702504</td>
      <td>0.037585</td>
      <td>0.412416</td>
      <td>0.186166</td>
      <td>0.371032</td>
      <td>1.077236</td>
      <td>0.819413</td>
      <td>0.584796</td>
      <td>-0.053327</td>
      <td>-0.190917</td>
      <td>0.210050</td>
      <td>-0.744944</td>
      <td>-0.266178</td>
      <td>0.254422</td>
      <td>-1.324489</td>
      <td>-1.249706</td>
      <td>-0.271852</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.555835</td>
      <td>-0.869834</td>
      <td>0.081551</td>
      <td>-0.187400</td>
      <td>-0.261418</td>
      <td>0.444220</td>
      <td>-0.223836</td>
      <td>-0.945809</td>
      <td>0.130945</td>
      <td>-0.332183</td>
      <td>-0.270872</td>
      <td>0.005824</td>
      <td>0.099662</td>
      <td>-0.741069</td>
      <td>0.379689</td>
      <td>-0.151957</td>
      <td>-1.190759</td>
      <td>0.468623</td>
      <td>0.802643</td>
      <td>0.431803</td>
      <td>-0.604232</td>
      <td>-0.180147</td>
      <td>0.178301</td>
      <td>0.054901</td>
      <td>-1.098613</td>
      <td>-0.081143</td>
      <td>-1.033881</td>
      <td>-0.517418</td>
      <td>-0.214215</td>
      <td>0.892410</td>
      <td>0.807994</td>
      <td>1.152199</td>
      <td>-0.152965</td>
      <td>-0.276137</td>
      <td>-1.207695</td>
      <td>-0.446448</td>
      <td>-0.055739</td>
      <td>-0.039984</td>
      <td>-0.030701</td>
      <td>0.404008</td>
      <td>...</td>
      <td>-0.269943</td>
      <td>1.153562</td>
      <td>0.453140</td>
      <td>0.613696</td>
      <td>-0.132410</td>
      <td>-0.449500</td>
      <td>-0.784759</td>
      <td>-0.161849</td>
      <td>-0.249935</td>
      <td>-0.677078</td>
      <td>-0.337725</td>
      <td>0.772412</td>
      <td>-0.170972</td>
      <td>-0.326479</td>
      <td>0.799852</td>
      <td>0.537461</td>
      <td>-0.540725</td>
      <td>-0.431947</td>
      <td>-0.210833</td>
      <td>0.119547</td>
      <td>1.130032</td>
      <td>0.316651</td>
      <td>1.149499</td>
      <td>0.777575</td>
      <td>0.045208</td>
      <td>-0.475716</td>
      <td>0.359149</td>
      <td>0.292430</td>
      <td>0.083646</td>
      <td>0.266174</td>
      <td>-0.502508</td>
      <td>0.342474</td>
      <td>1.274151</td>
      <td>0.516595</td>
      <td>0.363762</td>
      <td>0.232092</td>
      <td>0.848654</td>
      <td>-4.067016</td>
      <td>-2.661688</td>
      <td>-1.477429</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.740723</td>
      <td>0.573909</td>
      <td>-0.446706</td>
      <td>-0.372477</td>
      <td>0.307701</td>
      <td>1.029899</td>
      <td>-0.222031</td>
      <td>0.140292</td>
      <td>-0.405548</td>
      <td>-0.145885</td>
      <td>-0.826641</td>
      <td>-0.624626</td>
      <td>-0.190738</td>
      <td>-0.283236</td>
      <td>0.056772</td>
      <td>-0.347668</td>
      <td>0.107253</td>
      <td>-0.170884</td>
      <td>0.568044</td>
      <td>-0.062104</td>
      <td>0.887476</td>
      <td>0.007914</td>
      <td>-1.314536</td>
      <td>0.310954</td>
      <td>-0.044288</td>
      <td>-0.295570</td>
      <td>-0.111128</td>
      <td>-0.470710</td>
      <td>-0.386327</td>
      <td>0.344403</td>
      <td>-0.021984</td>
      <td>1.525906</td>
      <td>0.594459</td>
      <td>0.238017</td>
      <td>0.421097</td>
      <td>-0.426876</td>
      <td>0.024445</td>
      <td>-0.415514</td>
      <td>0.530408</td>
      <td>-0.112631</td>
      <td>...</td>
      <td>-0.914545</td>
      <td>0.655306</td>
      <td>0.968724</td>
      <td>-0.232443</td>
      <td>-0.390154</td>
      <td>0.256238</td>
      <td>-0.375644</td>
      <td>0.726001</td>
      <td>0.106996</td>
      <td>-0.573889</td>
      <td>0.450659</td>
      <td>0.777406</td>
      <td>-0.732650</td>
      <td>-0.701101</td>
      <td>0.115313</td>
      <td>0.226683</td>
      <td>-0.265307</td>
      <td>-0.700487</td>
      <td>-0.534561</td>
      <td>0.166077</td>
      <td>0.181966</td>
      <td>0.622577</td>
      <td>-0.220729</td>
      <td>-0.967003</td>
      <td>-0.298251</td>
      <td>0.462128</td>
      <td>0.013108</td>
      <td>0.559936</td>
      <td>-0.647004</td>
      <td>0.919614</td>
      <td>0.418274</td>
      <td>0.291834</td>
      <td>0.730295</td>
      <td>0.537529</td>
      <td>0.690751</td>
      <td>0.273823</td>
      <td>0.852324</td>
      <td>-0.982525</td>
      <td>-0.691608</td>
      <td>-0.312335</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.413032</td>
      <td>1.361715</td>
      <td>0.572903</td>
      <td>-0.141597</td>
      <td>-1.395411</td>
      <td>-0.696900</td>
      <td>-0.533621</td>
      <td>-0.085599</td>
      <td>-0.986528</td>
      <td>-0.084013</td>
      <td>-0.568424</td>
      <td>-0.368830</td>
      <td>0.376863</td>
      <td>0.679930</td>
      <td>0.362953</td>
      <td>-0.385534</td>
      <td>0.278344</td>
      <td>0.486493</td>
      <td>0.445677</td>
      <td>-0.356482</td>
      <td>0.268022</td>
      <td>-0.141455</td>
      <td>-0.458056</td>
      <td>0.074997</td>
      <td>-0.485767</td>
      <td>-0.111909</td>
      <td>-0.205063</td>
      <td>-0.522579</td>
      <td>-1.379419</td>
      <td>-0.307906</td>
      <td>0.710483</td>
      <td>1.863896</td>
      <td>0.073364</td>
      <td>0.188075</td>
      <td>-0.550234</td>
      <td>-0.152252</td>
      <td>-0.473802</td>
      <td>-0.450436</td>
      <td>-0.513979</td>
      <td>0.014759</td>
      <td>...</td>
      <td>-0.741947</td>
      <td>-0.036688</td>
      <td>0.164545</td>
      <td>0.255002</td>
      <td>0.364487</td>
      <td>0.389757</td>
      <td>0.347945</td>
      <td>-1.232644</td>
      <td>-0.080299</td>
      <td>0.696194</td>
      <td>0.461460</td>
      <td>0.716430</td>
      <td>-0.204049</td>
      <td>0.010599</td>
      <td>0.642151</td>
      <td>0.745854</td>
      <td>0.419429</td>
      <td>-0.611302</td>
      <td>0.403479</td>
      <td>0.029462</td>
      <td>-0.597418</td>
      <td>-0.406611</td>
      <td>0.065432</td>
      <td>-0.980935</td>
      <td>0.367458</td>
      <td>-0.412702</td>
      <td>-0.054287</td>
      <td>-0.240047</td>
      <td>0.161516</td>
      <td>0.676167</td>
      <td>-0.668019</td>
      <td>0.741079</td>
      <td>1.348797</td>
      <td>1.003510</td>
      <td>-0.658205</td>
      <td>-1.538501</td>
      <td>1.104465</td>
      <td>0.597262</td>
      <td>0.301692</td>
      <td>0.044723</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.528959</td>
      <td>-0.146352</td>
      <td>-0.745276</td>
      <td>0.476594</td>
      <td>-1.173146</td>
      <td>0.105767</td>
      <td>0.186773</td>
      <td>0.107781</td>
      <td>0.420344</td>
      <td>0.392011</td>
      <td>-0.412645</td>
      <td>-0.788518</td>
      <td>0.068407</td>
      <td>0.083980</td>
      <td>0.238887</td>
      <td>0.323105</td>
      <td>0.134558</td>
      <td>0.980367</td>
      <td>0.052612</td>
      <td>-0.008416</td>
      <td>-0.393618</td>
      <td>0.603069</td>
      <td>0.766880</td>
      <td>0.967031</td>
      <td>0.509239</td>
      <td>0.859533</td>
      <td>-0.379079</td>
      <td>-0.476456</td>
      <td>-0.976399</td>
      <td>0.243275</td>
      <td>-0.260234</td>
      <td>0.821418</td>
      <td>-0.205349</td>
      <td>1.278424</td>
      <td>0.256637</td>
      <td>-1.042793</td>
      <td>0.272220</td>
      <td>0.201550</td>
      <td>0.697663</td>
      <td>0.486949</td>
      <td>...</td>
      <td>-0.050799</td>
      <td>0.604436</td>
      <td>0.884667</td>
      <td>0.338261</td>
      <td>-0.423790</td>
      <td>0.476140</td>
      <td>-0.661441</td>
      <td>-0.233248</td>
      <td>-0.942125</td>
      <td>0.299895</td>
      <td>-0.306219</td>
      <td>0.282528</td>
      <td>-0.162912</td>
      <td>0.490903</td>
      <td>0.760436</td>
      <td>-0.113080</td>
      <td>0.593820</td>
      <td>0.965487</td>
      <td>-0.566943</td>
      <td>-0.119509</td>
      <td>-0.371169</td>
      <td>0.200974</td>
      <td>-0.197038</td>
      <td>-0.288662</td>
      <td>-0.674441</td>
      <td>-1.144213</td>
      <td>-0.502410</td>
      <td>-1.364314</td>
      <td>0.193336</td>
      <td>-0.571324</td>
      <td>0.589876</td>
      <td>-0.184449</td>
      <td>-0.730685</td>
      <td>0.065721</td>
      <td>0.638286</td>
      <td>0.558844</td>
      <td>0.288730</td>
      <td>1.174586</td>
      <td>0.889561</td>
      <td>-0.109368</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.247185</td>
      <td>1.627845</td>
      <td>0.121206</td>
      <td>0.289986</td>
      <td>-0.690206</td>
      <td>0.334753</td>
      <td>-0.074531</td>
      <td>-0.204643</td>
      <td>-0.483842</td>
      <td>-0.073130</td>
      <td>0.496439</td>
      <td>-0.703065</td>
      <td>0.121196</td>
      <td>-0.289403</td>
      <td>-0.081982</td>
      <td>-1.334938</td>
      <td>-0.191560</td>
      <td>-0.055818</td>
      <td>-0.319313</td>
      <td>-0.187329</td>
      <td>-0.363317</td>
      <td>0.148934</td>
      <td>0.180717</td>
      <td>-0.271954</td>
      <td>-0.336993</td>
      <td>-0.554009</td>
      <td>-0.820812</td>
      <td>-0.027412</td>
      <td>-0.156737</td>
      <td>0.208572</td>
      <td>0.408887</td>
      <td>0.555899</td>
      <td>-0.597534</td>
      <td>-1.450838</td>
      <td>0.269418</td>
      <td>-0.391564</td>
      <td>-0.135967</td>
      <td>0.308527</td>
      <td>1.054498</td>
      <td>0.089196</td>
      <td>...</td>
      <td>0.405762</td>
      <td>0.030642</td>
      <td>0.498097</td>
      <td>0.604395</td>
      <td>0.340902</td>
      <td>0.778984</td>
      <td>-0.706103</td>
      <td>-0.889666</td>
      <td>0.435837</td>
      <td>-0.291481</td>
      <td>0.270910</td>
      <td>0.056065</td>
      <td>0.056777</td>
      <td>0.233330</td>
      <td>0.483906</td>
      <td>0.738568</td>
      <td>-0.991100</td>
      <td>-0.762678</td>
      <td>-0.561441</td>
      <td>-0.281520</td>
      <td>-0.610496</td>
      <td>-0.134935</td>
      <td>0.450930</td>
      <td>-0.050372</td>
      <td>0.050312</td>
      <td>0.266665</td>
      <td>0.007593</td>
      <td>-0.901095</td>
      <td>0.209369</td>
      <td>0.386565</td>
      <td>0.346679</td>
      <td>1.110977</td>
      <td>0.219781</td>
      <td>0.278034</td>
      <td>0.633699</td>
      <td>0.757130</td>
      <td>0.652948</td>
      <td>2.002608</td>
      <td>1.527234</td>
      <td>0.955504</td>
    </tr>
    <tr>
      <th>16</th>
      <td>1.029256</td>
      <td>0.366942</td>
      <td>0.930747</td>
      <td>-0.049449</td>
      <td>-0.339819</td>
      <td>0.401714</td>
      <td>-1.003525</td>
      <td>-0.154420</td>
      <td>-0.698195</td>
      <td>-0.247934</td>
      <td>-1.087817</td>
      <td>-0.787850</td>
      <td>-0.575054</td>
      <td>-0.204534</td>
      <td>0.308678</td>
      <td>-0.519075</td>
      <td>-0.114236</td>
      <td>0.476812</td>
      <td>0.932464</td>
      <td>1.612003</td>
      <td>1.247354</td>
      <td>0.511708</td>
      <td>-0.444371</td>
      <td>-0.603564</td>
      <td>-0.347621</td>
      <td>0.335662</td>
      <td>-0.097468</td>
      <td>-0.011156</td>
      <td>-1.130293</td>
      <td>0.248041</td>
      <td>-0.575955</td>
      <td>0.453540</td>
      <td>-0.520182</td>
      <td>0.328079</td>
      <td>-0.822849</td>
      <td>-0.975053</td>
      <td>0.694570</td>
      <td>0.212175</td>
      <td>0.276555</td>
      <td>1.156107</td>
      <td>...</td>
      <td>0.307371</td>
      <td>0.108571</td>
      <td>0.159390</td>
      <td>0.765979</td>
      <td>0.293022</td>
      <td>1.200397</td>
      <td>0.400164</td>
      <td>-1.076747</td>
      <td>-0.910281</td>
      <td>0.427391</td>
      <td>0.287660</td>
      <td>0.192244</td>
      <td>0.348486</td>
      <td>0.415841</td>
      <td>0.210844</td>
      <td>-0.354237</td>
      <td>-0.068118</td>
      <td>-0.298323</td>
      <td>-0.860522</td>
      <td>0.254300</td>
      <td>0.023554</td>
      <td>0.192554</td>
      <td>0.600467</td>
      <td>-1.212869</td>
      <td>-0.611223</td>
      <td>-0.933690</td>
      <td>-0.072528</td>
      <td>-0.227080</td>
      <td>0.812530</td>
      <td>0.190943</td>
      <td>0.418083</td>
      <td>0.566474</td>
      <td>0.388958</td>
      <td>0.630810</td>
      <td>0.225667</td>
      <td>0.145518</td>
      <td>0.150581</td>
      <td>4.188775</td>
      <td>2.459654</td>
      <td>0.526940</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.616130</td>
      <td>0.266930</td>
      <td>0.208226</td>
      <td>0.437331</td>
      <td>-0.995717</td>
      <td>-0.202906</td>
      <td>-0.420462</td>
      <td>0.719748</td>
      <td>-0.499239</td>
      <td>0.539761</td>
      <td>-0.513647</td>
      <td>-0.761232</td>
      <td>-0.370272</td>
      <td>-0.277747</td>
      <td>0.693439</td>
      <td>-0.132151</td>
      <td>0.381054</td>
      <td>1.327800</td>
      <td>0.396095</td>
      <td>-0.361640</td>
      <td>-0.297032</td>
      <td>0.220192</td>
      <td>-1.188320</td>
      <td>-0.141047</td>
      <td>0.760657</td>
      <td>-0.473874</td>
      <td>0.152059</td>
      <td>-0.753167</td>
      <td>-0.826927</td>
      <td>-0.909784</td>
      <td>-0.334036</td>
      <td>-0.397248</td>
      <td>-0.048800</td>
      <td>0.884374</td>
      <td>0.436067</td>
      <td>0.669861</td>
      <td>-0.095857</td>
      <td>0.941865</td>
      <td>-0.259431</td>
      <td>-0.038748</td>
      <td>...</td>
      <td>-0.831835</td>
      <td>-1.757468</td>
      <td>-0.843230</td>
      <td>0.204094</td>
      <td>-0.148431</td>
      <td>-0.610667</td>
      <td>-0.506569</td>
      <td>-1.138911</td>
      <td>-1.165535</td>
      <td>-0.494684</td>
      <td>0.106631</td>
      <td>0.915778</td>
      <td>-0.149944</td>
      <td>-0.405121</td>
      <td>0.862002</td>
      <td>0.253166</td>
      <td>-0.689991</td>
      <td>0.291400</td>
      <td>0.068912</td>
      <td>0.112906</td>
      <td>0.662855</td>
      <td>0.534292</td>
      <td>-0.672439</td>
      <td>-0.579261</td>
      <td>-0.361949</td>
      <td>1.125133</td>
      <td>-0.330738</td>
      <td>-0.110484</td>
      <td>-0.080025</td>
      <td>0.033223</td>
      <td>-0.059524</td>
      <td>1.182763</td>
      <td>0.382017</td>
      <td>0.393372</td>
      <td>-0.105211</td>
      <td>0.439639</td>
      <td>0.032750</td>
      <td>0.887346</td>
      <td>0.289637</td>
      <td>-0.309072</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.259165</td>
      <td>-0.926495</td>
      <td>-1.127019</td>
      <td>-1.532655</td>
      <td>-0.792725</td>
      <td>0.314672</td>
      <td>0.037294</td>
      <td>1.752619</td>
      <td>-0.669348</td>
      <td>0.455924</td>
      <td>-1.113054</td>
      <td>-1.177691</td>
      <td>-0.878148</td>
      <td>0.416989</td>
      <td>1.587064</td>
      <td>0.110142</td>
      <td>-1.175948</td>
      <td>-0.081676</td>
      <td>0.955577</td>
      <td>-0.017282</td>
      <td>0.746683</td>
      <td>0.079652</td>
      <td>0.155642</td>
      <td>-0.325170</td>
      <td>-0.092784</td>
      <td>0.675263</td>
      <td>0.840081</td>
      <td>0.149521</td>
      <td>-1.357135</td>
      <td>-0.141141</td>
      <td>0.251724</td>
      <td>0.515012</td>
      <td>0.127829</td>
      <td>0.577940</td>
      <td>-0.101363</td>
      <td>-0.128464</td>
      <td>0.120631</td>
      <td>-0.715495</td>
      <td>-0.487035</td>
      <td>0.260415</td>
      <td>...</td>
      <td>-0.238211</td>
      <td>0.014424</td>
      <td>0.408372</td>
      <td>0.403661</td>
      <td>0.158673</td>
      <td>0.468516</td>
      <td>-1.155183</td>
      <td>-0.560204</td>
      <td>0.326301</td>
      <td>0.274838</td>
      <td>-0.211655</td>
      <td>-0.107847</td>
      <td>-0.570119</td>
      <td>0.041136</td>
      <td>-0.646919</td>
      <td>0.041513</td>
      <td>-0.974395</td>
      <td>0.542718</td>
      <td>-0.194681</td>
      <td>-0.444224</td>
      <td>1.052549</td>
      <td>0.729612</td>
      <td>1.191782</td>
      <td>-0.140249</td>
      <td>-0.500207</td>
      <td>0.119097</td>
      <td>0.043879</td>
      <td>-1.069049</td>
      <td>-0.454448</td>
      <td>0.980191</td>
      <td>-0.511976</td>
      <td>0.703782</td>
      <td>1.158697</td>
      <td>1.153414</td>
      <td>-0.106429</td>
      <td>-0.676147</td>
      <td>0.578518</td>
      <td>-3.199619</td>
      <td>-2.064130</td>
      <td>-1.487612</td>
    </tr>
    <tr>
      <th>19</th>
      <td>1.143554</td>
      <td>0.154623</td>
      <td>-1.188688</td>
      <td>-0.038632</td>
      <td>-0.384259</td>
      <td>0.545547</td>
      <td>0.933886</td>
      <td>0.293088</td>
      <td>-0.570760</td>
      <td>-0.159455</td>
      <td>0.248796</td>
      <td>-0.652233</td>
      <td>-0.337793</td>
      <td>0.043666</td>
      <td>0.410105</td>
      <td>-0.139360</td>
      <td>-0.430439</td>
      <td>0.240509</td>
      <td>0.411893</td>
      <td>0.643170</td>
      <td>1.230023</td>
      <td>-0.241000</td>
      <td>0.248838</td>
      <td>-0.322674</td>
      <td>0.232482</td>
      <td>0.877739</td>
      <td>0.661096</td>
      <td>-0.720777</td>
      <td>-0.601547</td>
      <td>-0.154754</td>
      <td>0.546192</td>
      <td>-0.111087</td>
      <td>1.057921</td>
      <td>1.042437</td>
      <td>-0.363204</td>
      <td>-1.277009</td>
      <td>-0.171904</td>
      <td>-0.658096</td>
      <td>-0.271230</td>
      <td>0.359757</td>
      <td>...</td>
      <td>-0.238895</td>
      <td>0.414256</td>
      <td>0.881486</td>
      <td>0.698822</td>
      <td>-0.018362</td>
      <td>-0.192792</td>
      <td>0.183134</td>
      <td>0.417539</td>
      <td>0.203703</td>
      <td>0.328486</td>
      <td>0.738221</td>
      <td>0.265647</td>
      <td>-0.558785</td>
      <td>-0.778975</td>
      <td>0.145920</td>
      <td>1.646314</td>
      <td>0.060652</td>
      <td>0.487848</td>
      <td>-0.718433</td>
      <td>-0.497322</td>
      <td>0.240689</td>
      <td>-0.054882</td>
      <td>-0.504147</td>
      <td>-1.132634</td>
      <td>-0.843786</td>
      <td>-1.993200</td>
      <td>-0.540889</td>
      <td>-1.162427</td>
      <td>-0.168663</td>
      <td>0.100344</td>
      <td>1.151035</td>
      <td>0.631220</td>
      <td>0.700403</td>
      <td>-0.019492</td>
      <td>0.338567</td>
      <td>0.162527</td>
      <td>-0.199111</td>
      <td>1.035649</td>
      <td>1.482313</td>
      <td>0.212333</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.823005</td>
      <td>-0.359975</td>
      <td>0.376327</td>
      <td>-0.640610</td>
      <td>-0.182552</td>
      <td>-0.418175</td>
      <td>-0.571091</td>
      <td>-0.539872</td>
      <td>-1.689541</td>
      <td>0.542774</td>
      <td>-0.278412</td>
      <td>-0.864067</td>
      <td>0.897583</td>
      <td>0.199526</td>
      <td>0.087961</td>
      <td>-0.812897</td>
      <td>-0.580600</td>
      <td>0.843178</td>
      <td>0.310079</td>
      <td>0.375402</td>
      <td>0.043358</td>
      <td>-0.134466</td>
      <td>-0.213831</td>
      <td>-0.770948</td>
      <td>-0.293980</td>
      <td>-0.575246</td>
      <td>-0.963693</td>
      <td>-0.961379</td>
      <td>0.564789</td>
      <td>0.202578</td>
      <td>0.659495</td>
      <td>0.939161</td>
      <td>0.105410</td>
      <td>1.024402</td>
      <td>0.353601</td>
      <td>-0.026514</td>
      <td>-0.546845</td>
      <td>-0.091341</td>
      <td>-0.253928</td>
      <td>-0.123149</td>
      <td>...</td>
      <td>1.125760</td>
      <td>1.734667</td>
      <td>0.398506</td>
      <td>-0.088433</td>
      <td>0.133995</td>
      <td>-0.533257</td>
      <td>-0.403180</td>
      <td>-0.122771</td>
      <td>0.313229</td>
      <td>0.327534</td>
      <td>-0.200526</td>
      <td>0.221784</td>
      <td>-0.481610</td>
      <td>-0.840150</td>
      <td>-0.873736</td>
      <td>-0.471967</td>
      <td>0.440352</td>
      <td>0.055426</td>
      <td>-0.349779</td>
      <td>0.430246</td>
      <td>0.224726</td>
      <td>0.550454</td>
      <td>-0.574141</td>
      <td>-0.330048</td>
      <td>-0.645875</td>
      <td>0.341924</td>
      <td>0.076463</td>
      <td>-1.630082</td>
      <td>0.467277</td>
      <td>0.167928</td>
      <td>-0.855882</td>
      <td>-0.123931</td>
      <td>1.314280</td>
      <td>0.500624</td>
      <td>0.360694</td>
      <td>0.623474</td>
      <td>1.363203</td>
      <td>0.091938</td>
      <td>-0.500384</td>
      <td>-0.402937</td>
    </tr>
    <tr>
      <th>21</th>
      <td>1.128818</td>
      <td>0.729826</td>
      <td>-0.396081</td>
      <td>-0.567590</td>
      <td>-1.118277</td>
      <td>-0.414362</td>
      <td>-0.653446</td>
      <td>0.112367</td>
      <td>0.271227</td>
      <td>-0.155333</td>
      <td>0.205480</td>
      <td>0.166249</td>
      <td>-0.729393</td>
      <td>-0.771426</td>
      <td>0.936371</td>
      <td>0.170325</td>
      <td>-0.214170</td>
      <td>0.849040</td>
      <td>0.674743</td>
      <td>-0.662932</td>
      <td>-0.019349</td>
      <td>-0.342612</td>
      <td>-0.133438</td>
      <td>0.834065</td>
      <td>-0.346835</td>
      <td>0.005332</td>
      <td>-0.511985</td>
      <td>-0.512480</td>
      <td>-0.383638</td>
      <td>0.474628</td>
      <td>-1.254165</td>
      <td>0.046554</td>
      <td>0.161116</td>
      <td>-0.201942</td>
      <td>-0.211809</td>
      <td>-0.338709</td>
      <td>1.141055</td>
      <td>0.082690</td>
      <td>0.069159</td>
      <td>0.211876</td>
      <td>...</td>
      <td>0.061880</td>
      <td>0.455098</td>
      <td>-0.481677</td>
      <td>-0.310453</td>
      <td>0.475827</td>
      <td>0.469534</td>
      <td>-0.432398</td>
      <td>-0.563385</td>
      <td>0.363566</td>
      <td>-0.327242</td>
      <td>0.690304</td>
      <td>-0.487140</td>
      <td>0.493848</td>
      <td>0.571774</td>
      <td>0.627824</td>
      <td>0.578299</td>
      <td>-0.584936</td>
      <td>-0.376960</td>
      <td>0.132536</td>
      <td>0.013649</td>
      <td>0.257136</td>
      <td>0.788878</td>
      <td>0.998250</td>
      <td>-0.535813</td>
      <td>0.221257</td>
      <td>-1.429926</td>
      <td>0.117544</td>
      <td>-0.893352</td>
      <td>0.001400</td>
      <td>-0.159038</td>
      <td>0.416286</td>
      <td>0.633086</td>
      <td>0.603996</td>
      <td>0.564248</td>
      <td>1.667060</td>
      <td>0.054404</td>
      <td>0.310795</td>
      <td>1.837727</td>
      <td>2.042083</td>
      <td>0.874902</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.888535</td>
      <td>1.064566</td>
      <td>0.601027</td>
      <td>-0.203023</td>
      <td>-0.255090</td>
      <td>-0.160840</td>
      <td>0.161321</td>
      <td>0.078744</td>
      <td>-0.464275</td>
      <td>1.282844</td>
      <td>-0.385616</td>
      <td>-0.668076</td>
      <td>-0.815653</td>
      <td>-0.589723</td>
      <td>-0.332663</td>
      <td>-0.566020</td>
      <td>0.206968</td>
      <td>0.844321</td>
      <td>0.786602</td>
      <td>0.158606</td>
      <td>0.704819</td>
      <td>-0.500582</td>
      <td>-0.360339</td>
      <td>-0.261068</td>
      <td>0.034665</td>
      <td>0.784590</td>
      <td>-0.385296</td>
      <td>-0.535550</td>
      <td>0.304264</td>
      <td>-0.729124</td>
      <td>0.315077</td>
      <td>1.059136</td>
      <td>0.293377</td>
      <td>-0.398873</td>
      <td>-0.627595</td>
      <td>-0.918363</td>
      <td>-0.141842</td>
      <td>-1.052469</td>
      <td>-0.784873</td>
      <td>0.100454</td>
      <td>...</td>
      <td>-0.220750</td>
      <td>-0.409544</td>
      <td>-0.554110</td>
      <td>-0.395064</td>
      <td>-0.490342</td>
      <td>-0.254187</td>
      <td>-0.406380</td>
      <td>0.338251</td>
      <td>0.050266</td>
      <td>0.825910</td>
      <td>-0.211730</td>
      <td>-0.670587</td>
      <td>-0.796135</td>
      <td>0.806287</td>
      <td>0.067634</td>
      <td>-0.329174</td>
      <td>-0.434809</td>
      <td>-0.496469</td>
      <td>-0.866490</td>
      <td>0.896425</td>
      <td>0.311787</td>
      <td>0.650085</td>
      <td>-0.171323</td>
      <td>-0.331833</td>
      <td>-1.264688</td>
      <td>0.520650</td>
      <td>-0.585656</td>
      <td>-0.380223</td>
      <td>0.085169</td>
      <td>-0.512652</td>
      <td>-0.195879</td>
      <td>-0.226934</td>
      <td>1.429924</td>
      <td>0.521906</td>
      <td>-0.119896</td>
      <td>-0.683838</td>
      <td>-0.165540</td>
      <td>1.918243</td>
      <td>1.111512</td>
      <td>-0.009030</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.916388</td>
      <td>-0.588723</td>
      <td>-1.342900</td>
      <td>-0.576199</td>
      <td>-1.001115</td>
      <td>0.192707</td>
      <td>0.110326</td>
      <td>0.369800</td>
      <td>0.447722</td>
      <td>-0.019239</td>
      <td>0.696756</td>
      <td>-1.084051</td>
      <td>-0.779433</td>
      <td>-0.624991</td>
      <td>-0.758384</td>
      <td>-0.668887</td>
      <td>0.765086</td>
      <td>0.392555</td>
      <td>0.444664</td>
      <td>0.136152</td>
      <td>0.752529</td>
      <td>-0.917924</td>
      <td>0.110183</td>
      <td>-0.034541</td>
      <td>-0.242141</td>
      <td>-0.036069</td>
      <td>0.094962</td>
      <td>0.470921</td>
      <td>0.394550</td>
      <td>0.791151</td>
      <td>0.292909</td>
      <td>1.066696</td>
      <td>1.053521</td>
      <td>-0.018843</td>
      <td>-0.245931</td>
      <td>1.014832</td>
      <td>0.538855</td>
      <td>-0.695383</td>
      <td>-0.979570</td>
      <td>0.923019</td>
      <td>...</td>
      <td>-0.677798</td>
      <td>0.727951</td>
      <td>-0.529506</td>
      <td>-1.169397</td>
      <td>-0.023836</td>
      <td>-0.314055</td>
      <td>-0.675064</td>
      <td>0.012457</td>
      <td>-0.187043</td>
      <td>0.306219</td>
      <td>0.468084</td>
      <td>-0.552161</td>
      <td>-0.417356</td>
      <td>-0.836084</td>
      <td>0.686018</td>
      <td>0.916540</td>
      <td>-0.273447</td>
      <td>-0.168269</td>
      <td>0.256351</td>
      <td>0.223819</td>
      <td>0.039532</td>
      <td>0.287734</td>
      <td>0.315375</td>
      <td>0.050102</td>
      <td>0.051469</td>
      <td>-0.283729</td>
      <td>-0.242036</td>
      <td>-0.314177</td>
      <td>-0.176398</td>
      <td>-0.254136</td>
      <td>-0.298408</td>
      <td>0.266460</td>
      <td>0.312009</td>
      <td>0.855529</td>
      <td>-0.461487</td>
      <td>-0.777718</td>
      <td>-0.280523</td>
      <td>-3.221915</td>
      <td>-1.849541</td>
      <td>-1.009141</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.152227</td>
      <td>-0.161538</td>
      <td>0.021959</td>
      <td>0.446549</td>
      <td>-0.627233</td>
      <td>0.655587</td>
      <td>-0.344288</td>
      <td>-0.478814</td>
      <td>-0.389226</td>
      <td>-0.582785</td>
      <td>0.123923</td>
      <td>-0.167505</td>
      <td>-0.391406</td>
      <td>-1.258726</td>
      <td>0.581425</td>
      <td>0.194952</td>
      <td>0.645996</td>
      <td>0.496831</td>
      <td>0.471086</td>
      <td>0.137124</td>
      <td>0.208375</td>
      <td>-0.214070</td>
      <td>0.188705</td>
      <td>0.623936</td>
      <td>-0.273113</td>
      <td>-0.260532</td>
      <td>0.432515</td>
      <td>0.650067</td>
      <td>0.428736</td>
      <td>0.046730</td>
      <td>-0.123068</td>
      <td>1.159396</td>
      <td>0.040705</td>
      <td>-0.748601</td>
      <td>-0.989189</td>
      <td>-0.695913</td>
      <td>-0.028032</td>
      <td>-0.589365</td>
      <td>-0.697561</td>
      <td>-0.118098</td>
      <td>...</td>
      <td>0.308668</td>
      <td>-0.659048</td>
      <td>-0.445900</td>
      <td>0.114243</td>
      <td>-0.243682</td>
      <td>0.627978</td>
      <td>0.382626</td>
      <td>0.370752</td>
      <td>0.216774</td>
      <td>-0.275359</td>
      <td>-0.289069</td>
      <td>0.228213</td>
      <td>-0.404575</td>
      <td>-0.149696</td>
      <td>0.299603</td>
      <td>0.799326</td>
      <td>1.175953</td>
      <td>-0.048965</td>
      <td>0.270814</td>
      <td>0.352485</td>
      <td>-0.343016</td>
      <td>-0.214204</td>
      <td>-0.231082</td>
      <td>-0.780368</td>
      <td>-0.381335</td>
      <td>0.050227</td>
      <td>0.112696</td>
      <td>-0.229165</td>
      <td>-0.229702</td>
      <td>0.208523</td>
      <td>-0.405233</td>
      <td>-0.367983</td>
      <td>0.385709</td>
      <td>1.270243</td>
      <td>0.094863</td>
      <td>0.351236</td>
      <td>0.530746</td>
      <td>-1.731746</td>
      <td>-0.485551</td>
      <td>-0.206396</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.142014</td>
      <td>0.843565</td>
      <td>0.128895</td>
      <td>-0.152026</td>
      <td>-1.410147</td>
      <td>-0.778795</td>
      <td>-1.312890</td>
      <td>-0.687383</td>
      <td>-0.400159</td>
      <td>-0.153749</td>
      <td>-0.070330</td>
      <td>0.157243</td>
      <td>0.315240</td>
      <td>-0.606463</td>
      <td>-0.120088</td>
      <td>-0.905229</td>
      <td>0.161407</td>
      <td>0.308625</td>
      <td>-0.102727</td>
      <td>0.345876</td>
      <td>-0.180743</td>
      <td>-0.707322</td>
      <td>0.009650</td>
      <td>1.019331</td>
      <td>0.872023</td>
      <td>0.225247</td>
      <td>-0.326535</td>
      <td>0.063028</td>
      <td>0.350075</td>
      <td>0.354009</td>
      <td>0.959804</td>
      <td>0.037036</td>
      <td>0.112167</td>
      <td>-0.236886</td>
      <td>-0.023339</td>
      <td>-0.907911</td>
      <td>-0.035329</td>
      <td>1.159707</td>
      <td>0.157408</td>
      <td>0.356104</td>
      <td>...</td>
      <td>0.304710</td>
      <td>-0.266035</td>
      <td>-0.496157</td>
      <td>-0.086360</td>
      <td>-0.034367</td>
      <td>0.763533</td>
      <td>-0.139457</td>
      <td>-1.411944</td>
      <td>-0.828188</td>
      <td>0.046892</td>
      <td>-0.402295</td>
      <td>0.262047</td>
      <td>-0.389558</td>
      <td>-0.191480</td>
      <td>-0.025282</td>
      <td>-0.771917</td>
      <td>-1.045450</td>
      <td>0.291298</td>
      <td>-0.167951</td>
      <td>-1.692292</td>
      <td>-0.152806</td>
      <td>0.412282</td>
      <td>0.191491</td>
      <td>-0.238691</td>
      <td>-0.638471</td>
      <td>-0.132121</td>
      <td>-0.232077</td>
      <td>-1.117107</td>
      <td>0.578850</td>
      <td>-0.101334</td>
      <td>-0.557061</td>
      <td>0.419605</td>
      <td>0.318089</td>
      <td>0.185353</td>
      <td>0.135644</td>
      <td>-0.031294</td>
      <td>1.209241</td>
      <td>-2.678352</td>
      <td>-2.643857</td>
      <td>-1.699264</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.095126</td>
      <td>-0.285262</td>
      <td>1.456868</td>
      <td>0.020062</td>
      <td>-0.643608</td>
      <td>-0.711426</td>
      <td>-0.716695</td>
      <td>-0.229872</td>
      <td>-1.413935</td>
      <td>-0.450528</td>
      <td>0.147509</td>
      <td>-0.801226</td>
      <td>0.022658</td>
      <td>-0.311652</td>
      <td>-0.042170</td>
      <td>-0.559032</td>
      <td>-0.379492</td>
      <td>0.035670</td>
      <td>-0.346608</td>
      <td>0.735147</td>
      <td>-0.382197</td>
      <td>-0.128252</td>
      <td>-0.562729</td>
      <td>0.042114</td>
      <td>-0.461877</td>
      <td>0.602032</td>
      <td>0.080557</td>
      <td>0.476375</td>
      <td>0.906467</td>
      <td>1.334324</td>
      <td>-0.300233</td>
      <td>0.169155</td>
      <td>0.646030</td>
      <td>0.271248</td>
      <td>0.228687</td>
      <td>0.068470</td>
      <td>-1.248902</td>
      <td>0.279113</td>
      <td>0.569900</td>
      <td>1.516295</td>
      <td>...</td>
      <td>-0.643619</td>
      <td>-0.713460</td>
      <td>-0.776991</td>
      <td>-0.492601</td>
      <td>-0.276879</td>
      <td>-0.060913</td>
      <td>0.440880</td>
      <td>0.937376</td>
      <td>0.120711</td>
      <td>-0.017871</td>
      <td>0.046659</td>
      <td>-0.031100</td>
      <td>-0.032243</td>
      <td>0.239333</td>
      <td>0.076835</td>
      <td>0.482968</td>
      <td>-0.177640</td>
      <td>-0.146347</td>
      <td>0.914036</td>
      <td>0.269928</td>
      <td>0.870362</td>
      <td>-0.283155</td>
      <td>-0.894958</td>
      <td>-0.010667</td>
      <td>-0.032634</td>
      <td>0.421215</td>
      <td>0.126595</td>
      <td>-1.174878</td>
      <td>0.372671</td>
      <td>-1.379312</td>
      <td>-1.314710</td>
      <td>-0.084343</td>
      <td>0.850382</td>
      <td>-0.584319</td>
      <td>-0.066285</td>
      <td>0.043650</td>
      <td>-0.199107</td>
      <td>0.364862</td>
      <td>0.002316</td>
      <td>0.195743</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.111401</td>
      <td>0.577870</td>
      <td>0.375062</td>
      <td>-0.045275</td>
      <td>-1.036574</td>
      <td>0.598651</td>
      <td>0.277277</td>
      <td>-0.542234</td>
      <td>-2.242442</td>
      <td>-0.486854</td>
      <td>0.149652</td>
      <td>-0.386738</td>
      <td>-0.003303</td>
      <td>-0.052374</td>
      <td>0.115524</td>
      <td>-0.121311</td>
      <td>0.718415</td>
      <td>0.475474</td>
      <td>0.339151</td>
      <td>0.378741</td>
      <td>-0.710775</td>
      <td>-0.371928</td>
      <td>0.646472</td>
      <td>0.278210</td>
      <td>0.682568</td>
      <td>0.857602</td>
      <td>-0.556458</td>
      <td>0.538820</td>
      <td>0.824855</td>
      <td>-0.470706</td>
      <td>0.159133</td>
      <td>0.249154</td>
      <td>0.086112</td>
      <td>-0.316279</td>
      <td>-0.367068</td>
      <td>-0.915931</td>
      <td>0.210989</td>
      <td>-0.801915</td>
      <td>-0.175807</td>
      <td>-0.198832</td>
      <td>...</td>
      <td>0.621099</td>
      <td>0.665846</td>
      <td>-0.356778</td>
      <td>-0.708528</td>
      <td>0.536722</td>
      <td>-0.720600</td>
      <td>-0.248914</td>
      <td>0.121421</td>
      <td>-0.259666</td>
      <td>0.195220</td>
      <td>0.562760</td>
      <td>-0.228728</td>
      <td>-0.601456</td>
      <td>-0.967635</td>
      <td>-0.174925</td>
      <td>0.249094</td>
      <td>-0.192628</td>
      <td>0.616855</td>
      <td>-0.563520</td>
      <td>-0.422417</td>
      <td>0.109918</td>
      <td>0.479657</td>
      <td>0.119237</td>
      <td>0.058830</td>
      <td>0.002514</td>
      <td>1.836737</td>
      <td>0.434820</td>
      <td>-0.180879</td>
      <td>0.231250</td>
      <td>-0.092419</td>
      <td>-0.712745</td>
      <td>1.178556</td>
      <td>1.088344</td>
      <td>-0.635551</td>
      <td>0.076863</td>
      <td>-0.306397</td>
      <td>-0.286762</td>
      <td>0.805090</td>
      <td>-0.042501</td>
      <td>-0.061753</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.154676</td>
      <td>-0.113446</td>
      <td>0.762063</td>
      <td>0.217070</td>
      <td>-1.190333</td>
      <td>0.066913</td>
      <td>0.212758</td>
      <td>-0.001826</td>
      <td>-0.794164</td>
      <td>0.718016</td>
      <td>0.676471</td>
      <td>-0.483790</td>
      <td>0.091619</td>
      <td>0.724976</td>
      <td>0.435959</td>
      <td>-0.729754</td>
      <td>0.496463</td>
      <td>-0.343106</td>
      <td>-0.554399</td>
      <td>0.170350</td>
      <td>-0.448255</td>
      <td>-0.235082</td>
      <td>-1.284518</td>
      <td>-0.323111</td>
      <td>0.727730</td>
      <td>-0.236579</td>
      <td>-0.551138</td>
      <td>-1.240547</td>
      <td>-0.689153</td>
      <td>-1.372527</td>
      <td>-0.166362</td>
      <td>-0.791727</td>
      <td>-0.158038</td>
      <td>-0.089734</td>
      <td>0.636151</td>
      <td>-0.132957</td>
      <td>-0.368287</td>
      <td>-0.188872</td>
      <td>0.380393</td>
      <td>-0.078903</td>
      <td>...</td>
      <td>-0.368559</td>
      <td>-0.472816</td>
      <td>-0.588304</td>
      <td>0.003885</td>
      <td>0.403667</td>
      <td>-1.065291</td>
      <td>0.586327</td>
      <td>-0.301290</td>
      <td>-1.579493</td>
      <td>-0.854200</td>
      <td>-0.767940</td>
      <td>-0.115850</td>
      <td>0.023940</td>
      <td>-0.081755</td>
      <td>-0.419260</td>
      <td>0.591112</td>
      <td>0.306837</td>
      <td>0.471349</td>
      <td>-0.352446</td>
      <td>0.977865</td>
      <td>0.090481</td>
      <td>-0.286906</td>
      <td>-0.048454</td>
      <td>0.345475</td>
      <td>0.602872</td>
      <td>0.374093</td>
      <td>-0.174949</td>
      <td>-0.732953</td>
      <td>0.222321</td>
      <td>-1.091393</td>
      <td>-1.022741</td>
      <td>0.231577</td>
      <td>0.975037</td>
      <td>0.188220</td>
      <td>1.356010</td>
      <td>1.293929</td>
      <td>1.120102</td>
      <td>-0.868358</td>
      <td>-0.204857</td>
      <td>0.567533</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.375636</td>
      <td>0.460490</td>
      <td>1.133930</td>
      <td>0.647796</td>
      <td>-0.100174</td>
      <td>1.229857</td>
      <td>-0.076659</td>
      <td>-0.741975</td>
      <td>-1.530895</td>
      <td>-0.096786</td>
      <td>-0.904121</td>
      <td>-0.221105</td>
      <td>-0.568002</td>
      <td>0.572817</td>
      <td>1.500420</td>
      <td>-0.267396</td>
      <td>0.614049</td>
      <td>-0.487199</td>
      <td>-0.057943</td>
      <td>1.183148</td>
      <td>-1.211542</td>
      <td>0.162350</td>
      <td>0.075498</td>
      <td>-0.600581</td>
      <td>0.179972</td>
      <td>0.492033</td>
      <td>0.212725</td>
      <td>-0.136719</td>
      <td>0.105862</td>
      <td>0.199071</td>
      <td>0.561366</td>
      <td>-0.387407</td>
      <td>0.095917</td>
      <td>0.036520</td>
      <td>0.604154</td>
      <td>0.552868</td>
      <td>-0.236304</td>
      <td>-0.340985</td>
      <td>0.324291</td>
      <td>0.839920</td>
      <td>...</td>
      <td>0.746484</td>
      <td>0.128399</td>
      <td>0.558939</td>
      <td>0.989576</td>
      <td>1.309242</td>
      <td>-0.090873</td>
      <td>0.521230</td>
      <td>-0.382863</td>
      <td>-0.504925</td>
      <td>0.466401</td>
      <td>-0.139161</td>
      <td>0.418984</td>
      <td>0.151672</td>
      <td>-0.680328</td>
      <td>0.078718</td>
      <td>-0.968838</td>
      <td>-0.121543</td>
      <td>0.455183</td>
      <td>0.097563</td>
      <td>-0.709994</td>
      <td>0.812615</td>
      <td>-0.618511</td>
      <td>-0.970780</td>
      <td>-0.823884</td>
      <td>-0.651793</td>
      <td>0.941719</td>
      <td>-0.983806</td>
      <td>-0.705007</td>
      <td>0.292189</td>
      <td>-0.914783</td>
      <td>-0.455377</td>
      <td>-0.026659</td>
      <td>1.150605</td>
      <td>0.304899</td>
      <td>-0.194672</td>
      <td>0.806482</td>
      <td>0.497899</td>
      <td>-0.722891</td>
      <td>-0.437095</td>
      <td>-0.100710</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 103 columns</p>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f69f0ac3550&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.129633  0.036591  30.872248  2.817181e-209  1.057917  1.201349
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.461 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>