

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Python: Choice of learners &#8212; DoubleML  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="../_static/design-tabs.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'examples/py_double_ml_learner';</script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Python: First Stage and Causal Estimation" href="py_double_ml_firststage.html" />
    <link rel="prev" title="Python: Sensitivity Analysis" href="py_double_ml_sensitivity.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  <div class="navbar-header-items__start">
    
      <div class="navbar-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    <p class="title logo__title">DoubleML  documentation</p>
  
</a></div>
    
  </div>
  
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../intro/install.html">
                         Install
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../intro/intro.html">
                         Getting started
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../workflow/workflow.html">
                         Workflow
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../guide/guide.html">
                         User guide
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="index.html">
                         Examples
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../api/api.html">
                         Python API
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-external" href="https://docs.doubleml.org/r/stable/">
                         R API
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../literature/literature.html">
                         Literature
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../release/release.html">
                         Release notes
                      </a>
                    </li>
                
                </div>
            </div>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
        </div>
      
      
        <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/DoubleML/doubleml-for-py" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
    </div>
  

  
    <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
    </label>
  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../intro/install.html">
                         Install
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../intro/intro.html">
                         Getting started
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../workflow/workflow.html">
                         Workflow
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../guide/guide.html">
                         User guide
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="index.html">
                         Examples
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../api/api.html">
                         Python API
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-external" href="https://docs.doubleml.org/r/stable/">
                         R API
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../literature/literature.html">
                         Literature
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../release/release.html">
                         Release notes
                      </a>
                    </li>
                
                </div>
            </div>
            
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/DoubleML/doubleml-for-py" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item"><p class="logo" style="text-align:center;"><a href="../index.html">
    <img class="logo" src="../logo.png" alt="Logo" width="65%" height="65%">
</a></p>

<script type="text/javascript">
    // Change the logo depending on the theme
    var logo = document.querySelector('img.logo');
    var observer = new MutationObserver(function(mutations) {
        const dark = document.documentElement.dataset.theme == 'dark';
        if (dark) {
            logo.src = "../logo_dark.png";
        } else {
            logo.src = "../logo.png";
        }
    });
    observer.observe(document.documentElement, {attributes: true, attributeFilter: ['data-theme']});
</script></div>
        <div class="sidebar-primary-item">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
        <div class="sidebar-primary-item"><nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="py_double_ml_basics.html">Python: Basics of Double Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="py_double_ml_pension.html">Python: Impact of 401(k) on Financial Wealth</a></li>
<li class="toctree-l1"><a class="reference internal" href="py_double_ml_sensitivity.html">Python: Sensitivity Analysis</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Python: Choice of learners</a></li>
<li class="toctree-l1"><a class="reference internal" href="py_double_ml_firststage.html">Python: First Stage and Causal Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="py_double_ml_multiway_cluster.html">Python: Cluster Robust Double Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="py_double_ml_ssm.html">Python: Sample Selection Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="py_double_ml_did.html">Python: Difference-in-Differences</a></li>
<li class="toctree-l1"><a class="reference internal" href="py_double_ml_did_pretest.html">Python: Difference-in-Differences Pre-Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="py_double_ml_basic_iv.html">Python: Basic Instrumental Variables calculation</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="py_double_ml_gate.html">Python: Group Average Treatment Effects (GATEs) for IRM models</a></li>
<li class="toctree-l1"><a class="reference internal" href="py_double_ml_gate_plr.html">Python: Group Average Treatment Effects (GATEs) for PLR models</a></li>
<li class="toctree-l1"><a class="reference internal" href="py_double_ml_cate.html">Python: Conditional Average Treatment Effects (CATEs) for IRM models</a></li>
<li class="toctree-l1"><a class="reference internal" href="py_double_ml_cate_plr.html">Python: Conditional Average Treatment Effects (CATEs) for PLR models</a></li>
<li class="toctree-l1"><a class="reference internal" href="py_double_ml_gate_sensitivity.html">Python: GATE Sensitivity Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="py_double_ml_policy_tree.html">Python: Policy Learning with Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="py_double_ml_pension_qte.html">Python: Impact of 401(k) on Financial Wealth (Quantile Effects)</a></li>
<li class="toctree-l1"><a class="reference internal" href="py_double_ml_pq.html">Python: Potential Quantiles and Quantile Treatment Effects</a></li>
<li class="toctree-l1"><a class="reference internal" href="py_double_ml_cvar.html">Python: Conditional Value at Risk of potential outcomes</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="R_double_ml_basics.html">R: Basics of Double Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="R_double_ml_pension.html">R: Impact of 401(k) on Financial Wealth</a></li>
<li class="toctree-l1"><a class="reference internal" href="R_double_ml_multiway_cluster.html">R: Cluster Robust Double Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="R_double_ml_basic_iv.html">R: Basic Instrumental Variables Calculation</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="R_double_ml_pipeline.html">R: Ensemble Learners and More with <code class="docutils literal notranslate"><span class="pre">mlr3pipelines</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="double_ml_bonus_data.html">DML: Bonus Data</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumbs">
  <ul class="bd-breadcrumbs" role="navigation" aria-label="Breadcrumb">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="index.html" class="nav-link">Examples</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Python: Choice of learners</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
      <div class="admonition note">
    <p class="admonition-title">Note</p>
    <ul class="simple">

Download Jupyter notebook:
<a class="reference external" href="https://docs.doubleml.org/stable/examples/py_double_ml_learner.ipynb">https://docs.doubleml.org/stable/examples/py_double_ml_learner.ipynb</a>.

    </ul>
    </div><section id="Python:-Choice-of-learners">
<h1>Python: Choice of learners<a class="headerlink" href="#Python:-Choice-of-learners" title="Permalink to this heading">#</a></h1>
<p>This notebooks contains some practical recommendations to choose the right learner and evaluate different learners for the corresponding nuisance components.</p>
<p>For the example, we will work with a IRM, but all of the important components are directly usable for all other models too.</p>
<p>To be able to compare the properties of different learners, we will start by setting the true treatment parameter to zero, fix some other parameters of the data generating process and generate several datasets to obtain some information about the distribution of the estimators.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_irm_data</span>

<span class="n">theta</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">n_obs</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">dim_x</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">n_rep</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">datasets</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_rep</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">make_irm_data</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="n">theta</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="n">n_obs</span><span class="p">,</span> <span class="n">dim_x</span><span class="o">=</span><span class="n">dim_x</span><span class="p">,</span>
                         <span class="n">R2_d</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">R2_y</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;DataFrame&#39;</span><span class="p">)</span>
    <span class="n">datasets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<section id="Comparing-different-learners">
<h2>Comparing different learners<a class="headerlink" href="#Comparing-different-learners" title="Permalink to this heading">#</a></h2>
<p>For simplicity, we will restrict ourselves to the comparison of two different types and evaluate a learner of linear type and a tree based estimator for each nuisance component (with default hyperparameters).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">LogisticRegressionCV</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span><span class="p">,</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">clone</span>

<span class="n">reg_learner_1</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">reg_learner_2</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">()</span>
<span class="n">class_learner_1</span> <span class="o">=</span> <span class="n">LogisticRegressionCV</span><span class="p">()</span>
<span class="n">class_learner_2</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">()</span>

<span class="n">learner_list</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;ml_g&#39;</span><span class="p">:</span> <span class="n">reg_learner_1</span><span class="p">,</span> <span class="s1">&#39;ml_m&#39;</span><span class="p">:</span> <span class="n">class_learner_1</span><span class="p">},</span>
                <span class="p">{</span><span class="s1">&#39;ml_g&#39;</span><span class="p">:</span> <span class="n">reg_learner_2</span><span class="p">,</span> <span class="s1">&#39;ml_m&#39;</span><span class="p">:</span> <span class="n">class_learner_1</span><span class="p">},</span>
                <span class="p">{</span><span class="s1">&#39;ml_g&#39;</span><span class="p">:</span> <span class="n">reg_learner_1</span><span class="p">,</span> <span class="s1">&#39;ml_m&#39;</span><span class="p">:</span> <span class="n">class_learner_2</span><span class="p">},</span>
                <span class="p">{</span><span class="s1">&#39;ml_g&#39;</span><span class="p">:</span> <span class="n">reg_learner_2</span><span class="p">,</span> <span class="s1">&#39;ml_m&#39;</span><span class="p">:</span> <span class="n">class_learner_2</span><span class="p">}]</span>
</pre></div>
</div>
</div>
<p>In all combinations, we now can try to evaluate four different IRM models. To make the comparison fair, we will apply all different models to the same cross-fitting samples (usually this should not matter, we only consider this here to get slightly cleaner comparison).</p>
<section id="Standard-approach">
<h3>Standard approach<a class="headerlink" href="#Standard-approach" title="Permalink to this heading">#</a></h3>
<p>At first, we will look at the most straightforward approach using the inbuild RMSE. The <code class="docutils literal notranslate"><span class="pre">rmses</span></code> attribute contains the out-of-sample RMSE for the nuisance functions. We will save all RMSEs and the corresponding treatment estimates for all combinations of learners over all repetitions.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">doubleml._utils_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLResampling</span>

<span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_rep</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">learner_list</span><span class="p">)),</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
<span class="n">rmses_ml_m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_rep</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">learner_list</span><span class="p">)),</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
<span class="n">rmses_ml_g0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_rep</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">learner_list</span><span class="p">)),</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
<span class="n">rmses_ml_g1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_rep</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">learner_list</span><span class="p">)),</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

<span class="n">coverage</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_rep</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">learner_list</span><span class="p">)),</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i_rep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_rep</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">Processing: </span><span class="si">{</span><span class="nb">round</span><span class="p">((</span><span class="n">i_rep</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">n_rep</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2"> %&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="n">dml_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]</span>
    <span class="c1"># define the sample splitting</span>
    <span class="n">smpls</span> <span class="o">=</span> <span class="n">DoubleMLResampling</span><span class="p">(</span><span class="n">n_folds</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_rep</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="n">n_obs</span><span class="p">,</span>
                               <span class="n">apply_cross_fitting</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">dml_data</span><span class="o">.</span><span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">i_learners</span><span class="p">,</span> <span class="n">learners</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">learner_list</span><span class="p">):</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">dml_irm</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLIRM</span><span class="p">(</span><span class="n">dml_data</span><span class="p">,</span>
                                  <span class="n">ml_g</span><span class="o">=</span><span class="n">clone</span><span class="p">(</span><span class="n">learners</span><span class="p">[</span><span class="s1">&#39;ml_g&#39;</span><span class="p">]),</span>
                                  <span class="n">ml_m</span><span class="o">=</span><span class="n">clone</span><span class="p">(</span><span class="n">learners</span><span class="p">[</span><span class="s1">&#39;ml_m&#39;</span><span class="p">]),</span>
                                  <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">dml_irm</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">(</span><span class="n">smpls</span><span class="p">)</span>
        <span class="n">dml_irm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">n_jobs_cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

        <span class="n">coefs</span><span class="p">[</span><span class="n">i_rep</span><span class="p">,</span> <span class="n">i_learners</span><span class="p">]</span> <span class="o">=</span> <span class="n">dml_irm</span><span class="o">.</span><span class="n">coef</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">rmses_ml_m</span><span class="p">[</span><span class="n">i_rep</span><span class="p">,</span> <span class="n">i_learners</span><span class="p">]</span> <span class="o">=</span> <span class="n">dml_irm</span><span class="o">.</span><span class="n">rmses</span><span class="p">[</span><span class="s1">&#39;ml_m&#39;</span><span class="p">]</span>
        <span class="n">rmses_ml_g0</span><span class="p">[</span><span class="n">i_rep</span><span class="p">,</span> <span class="n">i_learners</span><span class="p">]</span> <span class="o">=</span> <span class="n">dml_irm</span><span class="o">.</span><span class="n">rmses</span><span class="p">[</span><span class="s1">&#39;ml_g0&#39;</span><span class="p">]</span>
        <span class="n">rmses_ml_g1</span><span class="p">[</span><span class="n">i_rep</span><span class="p">,</span> <span class="n">i_learners</span><span class="p">]</span> <span class="o">=</span> <span class="n">dml_irm</span><span class="o">.</span><span class="n">rmses</span><span class="p">[</span><span class="s1">&#39;ml_g1&#39;</span><span class="p">]</span>

        <span class="n">confint</span> <span class="o">=</span> <span class="n">dml_irm</span><span class="o">.</span><span class="n">confint</span><span class="p">()</span>
        <span class="n">coverage</span><span class="p">[</span><span class="n">i_rep</span><span class="p">,</span> <span class="n">i_learners</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">confint</span><span class="p">[</span><span class="s1">&#39;2.5 %&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">theta</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">confint</span><span class="p">[</span><span class="s1">&#39;97.5 %&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">theta</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Coverage: </span><span class="si">{</span><span class="n">coverage</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Processing: 100.0 %
Coverage: [0.935 0.65  0.975 0.95 ]
</pre></div></div>
</div>
<p>Next, let us take a look at the corresponding results</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">colnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Linear + Logit&#39;</span><span class="p">,</span><span class="s1">&#39;Boost + Logit&#39;</span><span class="p">,</span> <span class="s1">&#39;Linear + Boost&#39;</span><span class="p">,</span> <span class="s1">&#39;Boost + Boost&#39;</span><span class="p">]</span>

<span class="n">df_coefs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">coefs</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">colnames</span><span class="p">)</span>
<span class="n">df_ml_m</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rmses_ml_m</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">colnames</span><span class="p">)</span>
<span class="n">df_ml_g0</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rmses_ml_g0</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">colnames</span><span class="p">)</span>
<span class="n">df_ml_g1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rmses_ml_g1</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">colnames</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Learner Comparison&#39;</span><span class="p">)</span>


<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_coefs</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_ml_m</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_ml_g0</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_ml_g1</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s1">&#39;Estimated Parameter&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s1">&#39;RMSE ml_m&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s1">&#39;RMSE ml_g0&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s1">&#39;RMSE ml_g1&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">bottom</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">right</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                    <span class="n">top</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                    <span class="n">wspace</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span>
                    <span class="n">hspace</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_py_double_ml_learner_9_0.png" src="../_images/examples_py_double_ml_learner_9_0.png" />
</div>
</div>
<p>We can now easily observe that in this setting, the linear learners are able to approximate the corresponding nuisance functions better than the boosting algorithm (as should be expected since the data is generated accordingly).</p>
<p>Let us take a look at what would have happend if a each repetition for each nuisance element, we would have selected the learner with smallest out-of-sample rmse (in our example this corresponds to minimizing the product of rmses). Remark that we cannot select different learners for <code class="docutils literal notranslate"><span class="pre">ml_g0</span></code> and <code class="docutils literal notranslate"><span class="pre">ml_g1</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">selected_learners</span> <span class="o">=</span> <span class="p">(</span><span class="n">rmses_ml_m</span> <span class="o">*</span> <span class="p">(</span><span class="n">rmses_ml_g0</span> <span class="o">+</span> <span class="n">rmses_ml_g1</span><span class="p">))</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">selected_learners</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(array([0, 2], dtype=int64), array([191,   9], dtype=int64))
</pre></div></div>
</div>
<p>Most of the time, we will use linear learners for both nuisance elements. Sometimes the tree-based estimator is chosen for the propensity score <code class="docutils literal notranslate"><span class="pre">ml_m</span></code>. Let us compare which learners, how the estimated coefficients would have performed with the selected learners.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Coverage of selected learners: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">coverage</span><span class="p">[</span><span class="n">i_rep</span><span class="p">,</span><span class="w"> </span><span class="n">selected_learners</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]]</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">i_rep</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nb">range</span><span class="p">(</span><span class="n">n_rep</span><span class="p">)]))</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">selected_coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">coefs</span><span class="p">[</span><span class="n">i_rep</span><span class="p">,</span> <span class="n">selected_learners</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]]</span> <span class="k">for</span> <span class="n">i_rep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_rep</span><span class="p">)])</span>
<span class="n">df_coefs</span><span class="p">[</span><span class="s1">&#39;Selected&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">selected_coefs</span>
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_coefs</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Coverage of selected learners: 0.94
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_py_double_ml_learner_13_1.png" src="../_images/examples_py_double_ml_learner_13_1.png" />
</div>
</div>
<p>This procedure will be generally valid as long as we do not compare a excessively large number of different learners.</p>
</section>
<section id="Custom-evaluation-metrics">
<h3>Custom evaluation metrics<a class="headerlink" href="#Custom-evaluation-metrics" title="Permalink to this heading">#</a></h3>
<p>If one wants to evaluate a learner based on some other metric/loss it is possible to use the inbuilt <code class="docutils literal notranslate"><span class="pre">evaluate_learners()</span></code> method. Without further arguments this will default to the RMSE for all nuisance components and result in the same output as the <code class="docutils literal notranslate"><span class="pre">rmses</span></code> attribute.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">dml_irm</span><span class="o">.</span><span class="n">evaluate_learners</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_irm</span><span class="o">.</span><span class="n">rmses</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;ml_g0&#39;: array([[1.02649578]]), &#39;ml_g1&#39;: array([[1.06046108]]), &#39;ml_m&#39;: array([[0.34943161]])}
{&#39;ml_g0&#39;: array([[1.02649578]]), &#39;ml_g1&#39;: array([[1.06046108]]), &#39;ml_m&#39;: array([[0.34943161]])}
</pre></div></div>
</div>
<p>To evaluate a self-defined metric, the user has to hand over a callable. In this example, we define the mean absolute deviation as an error metric.</p>
<p>Remark that the metric should be able to handle <code class="docutils literal notranslate"><span class="pre">nan</span></code> values, since e.g. in the IRM model the learner <code class="docutils literal notranslate"><span class="pre">ml_g</span></code> is used to onto two different subsamples. As a result, we have two different nuisance components for</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
g_0(x) &amp;= \mathbb{E}[Y|X=x, D=0] \\
g_1(x) &amp;= \mathbb{E}[Y|X=x, D=1]
\end{aligned}\end{split}\]</div>
<p>which are both fitted with the learner <code class="docutils literal notranslate"><span class="pre">ml_g</span></code>. Of course, we can only observe the target value for <span class="math notranslate nohighlight">\(g_0(x)\)</span> if <span class="math notranslate nohighlight">\(D=0\)</span> and vice versa, resulting in <code class="docutils literal notranslate"><span class="pre">nan</span></code> values for all other observations.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>

<span class="k">def</span> <span class="nf">mae</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="n">subset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">y_true</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="n">subset</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">subset</span><span class="p">])</span>

<span class="n">dml_irm</span><span class="o">.</span><span class="n">evaluate_learners</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="n">mae</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;ml_g0&#39;: array([[0.82261299]]),
 &#39;ml_g1&#39;: array([[0.853177]]),
 &#39;ml_m&#39;: array([[0.20148598]])}
</pre></div></div>
</div>
<p>Another option is to access the out-of-sample predictions and target values for the nuisance elements via the <code class="docutils literal notranslate"><span class="pre">nuisance_targets</span></code> and <code class="docutils literal notranslate"><span class="pre">predictions</span></code> attributes.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">dml_irm</span><span class="o">.</span><span class="n">nuisance_targets</span><span class="p">[</span><span class="s1">&#39;ml_g1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_irm</span><span class="o">.</span><span class="n">predictions</span><span class="p">[</span><span class="s1">&#39;ml_g1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(500, 1, 1)
(500, 1, 1)
</pre></div></div>
</div>
<p>For most models minimizing the RMSE for each learner should result in improved performance as the theoretical backbone of the DML Framework is build on <span class="math notranslate nohighlight">\(\ell_2\)</span>-convergence rates for the nuisance estimates (<a class="reference external" href="https://doi.org/10.1111/ectj.12097">Chernozhukov et al. (2018)</a>). But for some models (e.g. classification learners) it might be helpful to further check other error metrics (e.g. as in <a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html#">scikit-learn</a>) to gain a
overview whether the nuisance function can be approximated sufficiently well.</p>
<p>Of course, if one has some prior knowledge on functional form assumptions (e.g. linearity as in the IRM example above) using these learners will usually improve the performance of the estimator and might speed up computation time.</p>
</section>
</section>
<section id="Computation-time">
<h2>Computation time<a class="headerlink" href="#Computation-time" title="Permalink to this heading">#</a></h2>
<p>The choice of the learner has a huge impact on the computation time of the DoubleML models. As the largest part of the computation time is usually used to train the learners for the nuisance components, some clever choices of learners and hyperparameters can speed up the computation time.</p>
<p>Resourcewise, most implementations support the <code class="docutils literal notranslate"><span class="pre">n_jobs_cv</span></code> argument, which can parallelize the k-fold estimation and might speed up the calculation nearly up to <span class="math notranslate nohighlight">\(k\)</span>-times if the resources are available.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span><span class="p">,</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">perf_counter</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n_obs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="p">(</span><span class="n">make_irm_data</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="n">n_obs</span><span class="p">,</span> <span class="n">dim_x</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;DataFrame&#39;</span><span class="p">),</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

<span class="c1"># define the sample splitting</span>
<span class="n">smpls</span> <span class="o">=</span> <span class="n">DoubleMLResampling</span><span class="p">(</span><span class="n">n_folds</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_rep</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="n">n_obs</span><span class="p">,</span> <span class="n">apply_cross_fitting</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">dml_data</span><span class="o">.</span><span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_irm</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLIRM</span><span class="p">(</span><span class="n">dml_data</span><span class="p">,</span>
                          <span class="n">ml_g</span><span class="o">=</span><span class="n">RandomForestRegressor</span><span class="p">(),</span>
                          <span class="n">ml_m</span><span class="o">=</span><span class="n">RandomForestClassifier</span><span class="p">(),</span>
                          <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">dml_irm</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">(</span><span class="n">smpls</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">t_1_start</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">dml_irm</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">t_1_stop</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Time without parallelization of crossfitting: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">t_1_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_1_start</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s1"> seconds&#39;</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">t_2_start</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">dml_irm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">n_jobs_cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">t_2_stop</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Time with parallelization of crossfitting: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">t_2_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_2_start</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s1"> seconds&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Speedup of factor </span><span class="si">{</span><span class="nb">round</span><span class="p">((</span><span class="n">t_1_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_1_start</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">t_2_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_2_start</span><span class="p">),</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Time without parallelization of crossfitting: 5.7683 seconds
Time with parallelization of crossfitting: 1.1492 seconds
Speedup of factor 5.02
</pre></div></div>
</div>
<p>Other more helpful ways to improve computation time will largly depend on the implemented learner. Of course linear learners are quite fast, but if no functional form restrictions are known Boosting or Random Forest might be better default options to saveguard against wrong model assumptions. Especially Boosting performs very well as a default option for tabular data. As a general recommendation all popular Boosting frameworks (XGBoost, Lightgbm, Catboost, etc.) should improve computation time.
But this might vary heavily with the number of features in your dataset. Let us compare the computation time with Boosting and Random Forest (we increase the sample size and the number of features).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span><span class="p">,</span> <span class="n">XGBRegressor</span>
<span class="kn">from</span> <span class="nn">lightgbm</span> <span class="kn">import</span> <span class="n">LGBMClassifier</span><span class="p">,</span> <span class="n">LGBMRegressor</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n_obs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="p">(</span><span class="n">make_irm_data</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="n">n_obs</span><span class="p">,</span> <span class="n">dim_x</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;DataFrame&#39;</span><span class="p">),</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

<span class="c1"># define the sample splitting</span>
<span class="n">smpls</span> <span class="o">=</span> <span class="n">DoubleMLResampling</span><span class="p">(</span><span class="n">n_folds</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_rep</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="n">n_obs</span><span class="p">,</span> <span class="n">apply_cross_fitting</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">dml_data</span><span class="o">.</span><span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">t_1_start</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">dml_irm</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLIRM</span><span class="p">(</span><span class="n">dml_data</span><span class="p">,</span>
                          <span class="n">ml_g</span><span class="o">=</span><span class="n">RandomForestRegressor</span><span class="p">(),</span>
                          <span class="n">ml_m</span><span class="o">=</span><span class="n">RandomForestClassifier</span><span class="p">(),</span>
                          <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">dml_irm</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">(</span><span class="n">smpls</span><span class="p">)</span>
<span class="n">dml_irm</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">t_1_stop</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Time without RandomForest (Scikit-Learn): </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">t_1_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_1_start</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s1"> seconds&#39;</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">t_2_start</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">dml_irm</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLIRM</span><span class="p">(</span><span class="n">dml_data</span><span class="p">,</span>
                          <span class="n">ml_g</span><span class="o">=</span><span class="n">XGBRegressor</span><span class="p">(),</span>
                          <span class="n">ml_m</span><span class="o">=</span><span class="n">XGBClassifier</span><span class="p">(),</span>
                          <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">dml_irm</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">(</span><span class="n">smpls</span><span class="p">)</span>
<span class="n">dml_irm</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">t_2_stop</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Time with XGBoost: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">t_2_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_2_start</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s1"> seconds&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Speedup of factor </span><span class="si">{</span><span class="nb">round</span><span class="p">((</span><span class="n">t_1_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_1_start</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">t_2_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_2_start</span><span class="p">),</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">t_3_start</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">dml_irm</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLIRM</span><span class="p">(</span><span class="n">dml_data</span><span class="p">,</span>
                          <span class="n">ml_g</span><span class="o">=</span><span class="n">LGBMRegressor</span><span class="p">(),</span>
                          <span class="n">ml_m</span><span class="o">=</span><span class="n">LGBMClassifier</span><span class="p">(),</span>
                          <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">dml_irm</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">(</span><span class="n">smpls</span><span class="p">)</span>
<span class="n">dml_irm</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">t_3_stop</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Time with LightGBM: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">t_3_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_3_start</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s1"> seconds&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Speedup of factor </span><span class="si">{</span><span class="nb">round</span><span class="p">((</span><span class="n">t_1_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_1_start</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">t_3_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_3_start</span><span class="p">),</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Time without RandomForest (Scikit-Learn): 11.7578 seconds
Time with XGBoost: 0.7731 seconds
Speedup of factor 15.21
Time with LightGBM: 0.5987 seconds
Speedup of factor 19.64
</pre></div></div>
</div>
</section>
</section>


                </article>
              
              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="py_double_ml_sensitivity.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Python: Sensitivity Analysis</p>
      </div>
    </a>
    <a class="right-next"
       href="py_double_ml_firststage.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Python: First Stage and Causal Estimation</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Comparing-different-learners">Comparing different learners</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Standard-approach">Standard approach</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Custom-evaluation-metrics">Custom evaluation metrics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Computation-time">Computation time</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div class="tocsection sourcelink">
    <a href="../_sources/examples/py_double_ml_learner.ipynb.txt">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
  <p class="copyright">
    
      © Copyright 2023, Bach, P., Chernozhukov, V., Klaassen, S., Kurz, M. S., and Spindler, M..
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">
  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 6.1.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
    <div class="footer-items__end">
      
        <div class="footer-item"><p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.13.3.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>