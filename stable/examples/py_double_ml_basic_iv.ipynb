{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7806db72",
   "metadata": {},
   "source": [
    "# Python: Basic Instrumental Variables calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd1243",
   "metadata": {},
   "source": [
    "In this example we show how to use the DoubleML functionality of Instrumental Variables (IVs) in the basic setting shown in the graph below, where:\n",
    "\n",
    "- Z is the instrument\n",
    "- C is a vector of unobserved confounders\n",
    "- D is the decision or treatment variable\n",
    "- Y is the outcome\n",
    "\n",
    "So, we will first generate synthetic data using linear models compatible with the diagram, and then use the DoubleML package to estimate the causal effect from D to Y. \n",
    "\n",
    "We assume that you have basic knowledge of instrumental variables and linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4315f48e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T08:43:30.519622Z",
     "iopub.status.busy": "2025-06-19T08:43:30.519435Z",
     "iopub.status.idle": "2025-06-19T08:43:32.061800Z",
     "shell.execute_reply": "2025-06-19T08:43:32.061160Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed, normal, binomial, uniform\n",
    "from pandas import DataFrame\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import doubleml as dml\n",
    "\n",
    "seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484507f7",
   "metadata": {},
   "source": [
    "## Instrumental Variables Directed Acyclic Graph (IV - DAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d56698",
   "metadata": {},
   "source": [
    "![basic_iv_example_nb.png](../_static/basic_iv_example_nb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d235508b",
   "metadata": {},
   "source": [
    "## Data Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b96a0e6",
   "metadata": {},
   "source": [
    "This code generates `n` samples in which there is a unique binary confounder. The treatment is also a binary variable, while the outcome is a continuous linear model. \n",
    "\n",
    "The quantity we want to recover using IVs is the `decision_impact`, which is the impact of the decision variable into the outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f8b1555",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T08:43:32.064199Z",
     "iopub.status.busy": "2025-06-19T08:43:32.063853Z",
     "iopub.status.idle": "2025-06-19T08:43:32.069472Z",
     "shell.execute_reply": "2025-06-19T08:43:32.068814Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "instrument_impact = 0.7\n",
    "decision_impact = - 2\n",
    "\n",
    "confounder = binomial(1, 0.3, n)\n",
    "instrument = binomial(1, 0.5, n)\n",
    "decision = (uniform(0, 1, n) <= instrument_impact*instrument + 0.4*confounder).astype(int)\n",
    "outcome = 30 + decision_impact*decision + 10 * confounder + normal(0, 2, n)\n",
    "\n",
    "df = DataFrame({\n",
    "    'instrument': instrument,\n",
    "    'decision': decision,\n",
    "    'outcome': outcome\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ccce44",
   "metadata": {},
   "source": [
    "## Naive estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b09ac86",
   "metadata": {},
   "source": [
    "We can see that if we make a direct estimation of the impact of the `decision` into the `outcome`, though the difference of the averages of outcomes between the two decision groups, we obtain a biased estimate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d00221a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T08:43:32.071762Z",
     "iopub.status.busy": "2025-06-19T08:43:32.071552Z",
     "iopub.status.idle": "2025-06-19T08:43:32.077200Z",
     "shell.execute_reply": "2025-06-19T08:43:32.076555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1099472942084532\n"
     ]
    }
   ],
   "source": [
    "outcome_1 = df[df.decision==1].outcome.mean()\n",
    "outcome_0 = df[df.decision==0].outcome.mean()\n",
    "print(outcome_1 - outcome_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836f0dd8",
   "metadata": {},
   "source": [
    "## Using DoubleML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86679b9",
   "metadata": {},
   "source": [
    "DoubleML assumes that there is at least one observed confounder. For this reason, we create a fake variable that doesn't bring any kind of information to the model, called `obs_confounder`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57e52c0",
   "metadata": {},
   "source": [
    "To use the DoubleML we need to specify the Machine Learning methods we want to use to estimate the different relationships between variables:\n",
    "\n",
    "- `ml_g` models the functional relationship betwen the `outcome` and the pair `instrument` and observed confounders `obs_confounders`. In this case we choose a `LinearRegression` because the outcome is continuous. \n",
    "- `ml_m` models the functional relationship betwen the `obs_confounders` and the `instrument`. In this case we choose a `LogisticRegression` because the outcome is dichotomic.\n",
    "- `ml_r` models the functional relationship betwen the `decision` and the pair `instrument` and observed confounders `obs_confounders`. In this case we choose a `LogisticRegression` because the outcome is dichotomic.\n",
    "\n",
    "\n",
    "Notice that instead of using linear and logistic regression, we could use more flexible models capable of dealing with non-linearities such as random forests, boosting, ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "600b8196",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T08:43:32.079193Z",
     "iopub.status.busy": "2025-06-19T08:43:32.078974Z",
     "iopub.status.idle": "2025-06-19T08:43:32.141012Z",
     "shell.execute_reply": "2025-06-19T08:43:32.139785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              coef   std err         t     P>|t|     2.5 %    97.5 %\n",
      "decision -1.950545  0.487872 -3.998063  0.000064 -2.906757 -0.994332\n"
     ]
    }
   ],
   "source": [
    "df['obs_confounders'] = 1\n",
    "\n",
    "ml_g = LinearRegression()\n",
    "ml_m = LogisticRegression(penalty=None)\n",
    "ml_r = LogisticRegression(penalty=None)\n",
    "\n",
    "obj_dml_data = dml.DoubleMLData(\n",
    "    df, y_col='outcome', d_cols='decision', \n",
    "    z_cols='instrument', x_cols='obs_confounders'\n",
    ")\n",
    "dml_iivm_obj = dml.DoubleMLIIVM(obj_dml_data, ml_g, ml_m, ml_r)\n",
    "print(dml_iivm_obj.fit().summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecabe477",
   "metadata": {},
   "source": [
    "We can see that the causal effect is estimated without bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84ca8b9",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Ruiz de Villa, A. Causal Inference for Data Science, Manning Publications, 2024."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
