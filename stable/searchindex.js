Search.setIndex({"alltitles": {"(One-Way) Cluster Robust Double Machine Learing": [[42, "(One-Way)-Cluster-Robust-Double-Machine-Learing"], [61, "(One-Way)-Cluster-Robust-Double-Machine-Learing"]], "0. Problem Formulation": [[108, "problem-formulation"]], "1. Data-Backend": [[108, "data-backend"]], "1. Formulation of Causal Model & Identification Assumptions": [[69, "1.-Formulation-of-Causal-Model-&-Identification-Assumptions"]], "2. Causal Model": [[108, "causal-model"]], "2. Estimation of Causal Effect": [[69, "2.-Estimation-of-Causal-Effect"]], "3. ML Methods": [[108, "ml-methods"]], "3. Sensitivity Analysis": [[69, "3.-Sensitivity-Analysis"]], "4. Benchmarking Analysis": [[69, "4.-Benchmarking-Analysis"]], "4. DML Specifications": [[108, "dml-specifications"]], "5. Conclusion": [[69, "5.-Conclusion"]], "5. Estimation": [[108, "estimation"]], "6. Inference": [[108, "inference"]], "7. Sensitivity Analysis": [[108, "sensitivity-analysis"]], "A Motivating Example: Two-Way Cluster Robust DML": [[42, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"], [61, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"]], "API reference": [[0, "api-reference"]], "ATE Estimation and Sensitivity": [[58, "ATE-Estimation-and-Sensitivity"]], "ATE estimates distribution": [[70, "ATE-estimates-distribution"], [70, "id3"]], "ATTE Estimation": [[53, "ATTE-Estimation"], [53, "id2"]], "Acknowledgements": [[103, "acknowledgements"]], "Acknowledgements and Final Remarks": [[41, "Acknowledgements-and-Final-Remarks"]], "Additional Results: CATE estimates": [[64, "Additional-Results:-CATE-estimates"]], "Advanced: External Predictions": [[76, "advanced-external-predictions"]], "Advanced: Global and Local Learners, Stacked Ensembles": [[67, "Advanced:-Global-and-Local-Learners,-Stacked-Ensembles"]], "Algorithm DML1": [[71, "algorithm-dml1"]], "Algorithm DML2": [[71, "algorithm-dml2"]], "Application Results": [[42, "Application-Results"], [61, "Application-Results"]], "Application: 401(k)": [[68, "Application:-401(k)"]], "AutoML with less Computation time": [[60, "AutoML-with-less-Computation-time"]], "Average Potential Outcome (APOs)": [[47, "Average-Potential-Outcome-(APOs)"]], "Average Potential Outcomes (APOs)": [[77, "average-potential-outcomes-apos"], [79, "average-potential-outcomes-apos"], [93, "average-potential-outcomes-apos"]], "Average Potential Outcomes (APOs) for Multiple Treatment Levels": [[77, "average-potential-outcomes-apos-for-multiple-treatment-levels"]], "Benchmarking": [[93, "benchmarking"]], "Benchmarking Analysis": [[68, "Benchmarking-Analysis"]], "Binary Interactive Regression Model (IRM)": [[77, "binary-interactive-regression-model-irm"], [79, "binary-interactive-regression-model-irm"]], "CATEs for IRM models": [[75, "cates-for-irm-models"]], "CATEs for PLR models": [[75, "cates-for-plr-models"]], "CVaR Treatment Effects": [[52, "CVaR-Treatment-Effects"]], "CVaR of potential outcomes": [[75, "cvar-of-potential-outcomes"]], "CVaR treatment effects": [[75, "cvar-treatment-effects"]], "Causal Analysis with DoubleML": [[69, "Causal-Analysis-with-DoubleML"]], "Causal Contrasts": [[47, "Causal-Contrasts"]], "Causal estimation vs. lasso penalty \\lambda": [[55, "Causal-estimation-vs.-lasso-penalty-\\lambda"]], "Chernozhukov et al. (2023): Benchmarking": [[69, "Chernozhukov-et-al.-(2023):-Benchmarking"]], "Citation": [[103, "citation"]], "Cluster Robust Cross Fitting": [[42, "Cluster-Robust-Cross-Fitting"], [61, "Cluster-Robust-Cross-Fitting"]], "Cluster Robust Standard Errors": [[42, "Cluster-Robust-Standard-Errors"], [61, "Cluster-Robust-Standard-Errors"]], "Clustering and double machine learning": [[42, "Clustering-and-double-machine-learning"], [61, "Clustering-and-double-machine-learning"]], "Combined loss vs. lasso penalty \\lambda": [[55, "Combined-loss-vs.-lasso-penalty-\\lambda"]], "Compare Metrics for Nuisance Estimation": [[60, "Compare-Metrics-for-Nuisance-Estimation"]], "Comparing different learners": [[59, "Comparing-different-learners"]], "Comparison and summary": [[60, "Comparison-and-summary"]], "Comparison to AutoML with less Computation time and Untuned XGBoost Learners": [[60, "Comparison-to-AutoML-with-less-Computation-time-and-Untuned-XGBoost-Learners"]], "Comparison to did package": [[41, "Comparison-to-did-package"]], "Computation time": [[59, "Computation-time"]], "Conclusion": [[60, "Conclusion"]], "Conditional Value at Risk (CVaR)": [[52, "Conditional-Value-at-Risk-(CVaR)"]], "Conditional average treatment effects (CATEs)": [[75, "conditional-average-treatment-effects-cates"]], "Conditional value at risk (CVaR)": [[75, "conditional-value-at-risk-cvar"], [79, "conditional-value-at-risk-cvar"]], "Confidence bands and multiplier bootstrap for valid simultaneous inference": [[92, "confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference"], [102, "confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference"]], "Coverage Simulation": [[53, "Coverage-Simulation"], [53, "id3"]], "Cross-fitting with K folds": [[78, "cross-fitting-with-k-folds"]], "Cross-fitting, DML algorithms and Neyman-orthogonal score functions": [[105, "cross-fitting-dml-algorithms-and-neyman-orthogonal-score-functions"]], "Custom evaluation metrics": [[59, "Custom-evaluation-metrics"]], "DML: Bonus Data": [[45, "DML:-Bonus-Data"]], "Data": [[43, "Data"], [50, "Data"], [51, "Data"], [52, "Data"], [53, "Data"], [53, "id1"], [56, "Data"], [57, "Data"], [58, "Data"], [62, "Data"], [63, "Data"], [65, "Data"], [66, "Data"], [66, "id1"], [68, "Data"], [70, "Data"], [70, "id1"], [105, "data"]], "Data Generating Process (DGP)": [[40, "Data-Generating-Process-(DGP)"], [47, "Data-Generating-Process-(DGP)"], [49, "Data-Generating-Process-(DGP)"]], "Data Generation": [[60, "Data-Generation"]], "Data Simulation": [[39, "Data-Simulation"], [48, "Data-Simulation"]], "Data and Effect Estimation": [[68, "Data-and-Effect-Estimation"]], "Data generating process": [[72, "data-generating-process"]], "Data preprocessing": [[44, "Data-preprocessing"]], "Data-Backend for Cluster Data": [[42, "Data-Backend-for-Cluster-Data"], [61, "Data-Backend-for-Cluster-Data"]], "Dataset generators": [[0, "dataset-generators"]], "Dataset loaders": [[0, "dataset-loaders"]], "Datasets module": [[0, "datasets-module"]], "Define Helper Functions for Plotting": [[42, "Define-Helper-Functions-for-Plotting"], [61, "Define-Helper-Functions-for-Plotting"]], "Demo Example from did": [[41, "Demo-Example-from-did"]], "Details on Predictive Performance": [[41, "Details-on-Predictive-Performance"]], "Difference-in-Differences Models": [[79, "difference-in-differences-models"]], "Difference-in-Differences Models (DID)": [[77, "difference-in-differences-models-did"]], "Difference-in-Differences for Panel Data": [[93, "difference-in-differences-for-panel-data"]], "Difference-in-Differences for repeated cross-sections": [[93, "difference-in-differences-for-repeated-cross-sections"]], "Disclaimer": [[69, "Disclaimer"]], "Double Machine Learning Algorithm": [[103, "double-machine-learning-algorithm"]], "Double machine learning algorithms": [[71, "double-machine-learning-algorithms"]], "Double machine learning data class": [[0, "double-machine-learning-data-class"]], "Double machine learning literature": [[106, "double-machine-learning-literature"]], "Double machine learning models": [[0, "double-machine-learning-models"]], "Double/debiased machine learning": [[40, "Double/debiased-machine-learning"], [49, "Double/debiased-machine-learning"], [72, "double-debiased-machine-learning"]], "DoubleML": [[103, "doubleml"]], "DoubleML Object": [[68, "DoubleML-Object"]], "DoubleML Workflow": [[108, "doubleml-workflow"]], "DoubleML meets FLAML - How to tune learners automatically within DoubleML": [[60, "DoubleML-meets-FLAML---How-to-tune-learners-automatically-within-DoubleML"]], "DoubleMLData from arrays and matrices": [[73, "doublemldata-from-arrays-and-matrices"]], "DoubleMLData from dataframes": [[73, "doublemldata-from-dataframes"]], "Effect Heterogeneity": [[46, "effect-heterogeneity"]], "Empirical coverage vs. lasso penalty \\lambda": [[55, "Empirical-coverage-vs.-lasso-penalty-\\lambda"]], "Estimate DML models without sample-splitting": [[78, "estimate-dml-models-without-sample-splitting"]], "Estimate double/debiased machine learning models": [[105, "estimate-double-debiased-machine-learning-models"]], "Estimating Potential Quantiles and Quantile Treatment Effects": [[63, "Estimating-Potential-Quantiles-and-Quantile-Treatment-Effects"]], "Estimating local quantile treatment effects (LQTEs)": [[63, "Estimating-local-quantile-treatment-effects-(LQTEs)"]], "Estimating the Average Treatment Effect of 401(k) Eligibility on Net Financial Assets": [[43, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"], [62, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"]], "Estimating the treatment effect on the Conditional Value a Risk (CVaR)": [[63, "Estimating-the-treatment-effect-on-the-Conditional-Value-a-Risk-(CVaR)"]], "Estimation": [[70, "Estimation"], [70, "id2"]], "Estimation quality vs. \\lambda": [[55, "Estimation-quality-vs.-\\lambda"]], "Evaluate learners": [[76, "evaluate-learners"]], "Example: Sensitivity Analysis for Causal ML": [[69, "Example:-Sensitivity-Analysis-for-Causal-ML"]], "Examples": [[46, "examples"]], "Exploiting the Functionalities of did": [[41, "Exploiting-the-Functionalities-of-did"]], "Externally provide a sample splitting / partition": [[78, "externally-provide-a-sample-splitting-partition"]], "Flexible Covariate Adjustment in Regression Discontinuity Designs (RDD)": [[67, "Flexible-Covariate-Adjustment-in-Regression-Discontinuity-Designs-(RDD)"]], "Fuzzy RDD": [[67, "Fuzzy-RDD"]], "Fuzzy RDD Without Adjustment": [[67, "Fuzzy-RDD-Without-Adjustment"]], "Fuzzy RDD with Flexible Adjustment": [[67, "Fuzzy-RDD-with-Flexible-Adjustment"]], "Fuzzy RDD with Linear Adjustment": [[67, "Fuzzy-RDD-with-Linear-Adjustment"]], "Fuzzy Regression Discontinuity Design": [[77, "fuzzy-regression-discontinuity-design"]], "GATE Estimation and Sensitivity": [[58, "GATE-Estimation-and-Sensitivity"]], "GATET Estimation and Sensitivity": [[58, "GATET-Estimation-and-Sensitivity"]], "GATEs for IRM models": [[75, "gates-for-irm-models"]], "GATEs for PLR models": [[75, "gates-for-plr-models"]], "General Examples": [[46, "general-examples"]], "General algorithm": [[93, "general-algorithm"]], "Generate Fuzzy Data": [[67, "Generate-Fuzzy-Data"]], "Generate Sharp Data": [[67, "Generate-Sharp-Data"]], "Getting started": [[105, "getting-started"]], "Group Average Treatment Effects (GATEs)": [[56, "Group-Average-Treatment-Effects-(GATEs)"], [57, "Group-Average-Treatment-Effects-(GATEs)"]], "Group average treatment effects (GATEs)": [[75, "group-average-treatment-effects-gates"]], "Heterogeneous treatment effects": [[75, "heterogeneous-treatment-effects"]], "How to exploit more features of mlr3pipelines in DoubleML": [[44, "How-to-exploit-more-features-of-mlr3pipelines-in-DoubleML"]], "Hyperparameter tuning": [[76, "hyperparameter-tuning"], [76, "id16"]], "Hyperparameter tuning with pipelines": [[76, "hyperparameter-tuning-with-pipelines"]], "Implementation": [[93, "implementation"]], "Implementation Details": [[77, "implementation-details"]], "Implementation of the double machine learning algorithms": [[71, "implementation-of-the-double-machine-learning-algorithms"]], "Implementation of the score function and the estimate of the causal parameter": [[79, "implementation-of-the-score-function-and-the-estimate-of-the-causal-parameter"]], "Implemented Neyman orthogonal score functions": [[79, "implemented-neyman-orthogonal-score-functions"]], "Initialize DoubleMLClusterData object": [[42, "Initialize-DoubleMLClusterData-object"], [61, "Initialize-DoubleMLClusterData-object"]], "Initialize the objects of class DoubleMLPLIV": [[42, "Initialize-the-objects-of-class-DoubleMLPLIV"], [61, "Initialize-the-objects-of-class-DoubleMLPLIV"]], "Installing DoubleML": [[104, "installing-doubleml"]], "Instrumental Variables Directed Acyclic Graph (IV - DAG)": [[39, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"], [48, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"]], "Interactive IV Model (IIVM)": [[43, "Interactive-IV-Model-(IIVM)"], [62, "Interactive-IV-Model-(IIVM)"]], "Interactive IV model (IIVM)": [[77, "interactive-iv-model-iivm"], [79, "interactive-iv-model-iivm"]], "Interactive Regression Model (IRM)": [[43, "Interactive-Regression-Model-(IRM)"], [56, "Interactive-Regression-Model-(IRM)"], [62, "Interactive-Regression-Model-(IRM)"], [65, "Interactive-Regression-Model-(IRM)"]], "Interactive regression model (IRM)": [[93, "interactive-regression-model-irm"]], "Interactive regression models (IRM)": [[77, "interactive-regression-models-irm"], [79, "interactive-regression-models-irm"]], "Learners to estimate the nuisance models": [[105, "learners-to-estimate-the-nuisance-models"]], "Learners, hyperparameters and hyperparameter tuning": [[76, "learners-hyperparameters-and-hyperparameter-tuning"]], "Load Data": [[69, "Load-Data"]], "Load and Process Data": [[42, "Load-and-Process-Data"], [61, "Load-and-Process-Data"]], "Load bonus data using the dml datasets module": [[45, "Load-bonus-data-using-the-dml-datasets-module"]], "Local Average Treatment Effects of 401(k) Participation on Net Financial Assets": [[43, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"], [62, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"]], "Local Potential Quantile Estimation": [[66, "Local-Potential-Quantile-Estimation"]], "Local Potential Quantiles (LPQs)": [[66, "Local-Potential-Quantiles-(LPQs)"]], "Local Quantile Treatment Effects (LQTEs)": [[66, "Local-Quantile-Treatment-Effects-(LQTEs)"]], "Local potential quantiles (LPQs)": [[79, "local-potential-quantiles-lpqs"]], "Main Features": [[103, "main-features"]], "Minimum requirements for learners": [[76, "minimum-requirements-for-learners"], [76, "id2"]], "Missingness at Random": [[77, "missingness-at-random"], [79, "missingness-at-random"]], "Model-specific implementations": [[93, "model-specific-implementations"]], "Models": [[77, "models"]], "Motivation": [[42, "Motivation"], [61, "Motivation"]], "Multiple Average Potential Outcome Models (APOS)": [[47, "Multiple-Average-Potential-Outcome-Models-(APOS)"]], "Multiplier bootstrap and joint confidence intervals": [[102, "multiplier-bootstrap-and-joint-confidence-intervals"]], "Naive estimation": [[39, "Naive-estimation"], [48, "Naive-estimation"]], "No Clustering / Zero-Way Clustering": [[42, "No-Clustering-/-Zero-Way-Clustering"], [61, "No-Clustering-/-Zero-Way-Clustering"]], "Nonignorable Nonresponse": [[77, "nonignorable-nonresponse"], [79, "nonignorable-nonresponse"]], "One-Way Clustering with Respect to the Market": [[42, "One-Way-Clustering-with-Respect-to-the-Market"], [61, "One-Way-Clustering-with-Respect-to-the-Market"]], "One-Way Clustering with Respect to the Product": [[42, "One-Way-Clustering-with-Respect-to-the-Product"], [61, "One-Way-Clustering-with-Respect-to-the-Product"]], "One-dimensional Example": [[50, "One-dimensional-Example"], [51, "One-dimensional-Example"]], "Other models": [[0, "other-models"]], "Outcome missing at random (MAR)": [[70, "Outcome-missing-at-random-(MAR)"]], "Outcome missing under nonignorable nonresponse": [[70, "Outcome-missing-under-nonignorable-nonresponse"]], "Overcoming regularization bias by orthogonalization": [[40, "Overcoming-regularization-bias-by-orthogonalization"], [49, "Overcoming-regularization-bias-by-orthogonalization"], [72, "overcoming-regularization-bias-by-orthogonalization"]], "Panel Data": [[79, "panel-data"]], "Panel Data (Repeated Outcomes)": [[53, "Panel-Data-(Repeated-Outcomes)"]], "Panel data": [[77, "panel-data"]], "Parameter tuning": [[44, "Parameter-tuning"]], "Partialling out score": [[40, "Partialling-out-score"], [49, "Partialling-out-score"], [72, "partialling-out-score"]], "Partially Linear Regression Model (PLR)": [[43, "Partially-Linear-Regression-Model-(PLR)"], [57, "Partially-Linear-Regression-Model-(PLR)"], [62, "Partially-Linear-Regression-Model-(PLR)"]], "Partially linear IV regression model (PLIV)": [[77, "partially-linear-iv-regression-model-pliv"], [79, "partially-linear-iv-regression-model-pliv"]], "Partially linear models (PLM)": [[77, "partially-linear-models-plm"], [79, "partially-linear-models-plm"]], "Partially linear regression model (PLR)": [[77, "partially-linear-regression-model-plr"], [79, "partially-linear-regression-model-plr"], [93, "partially-linear-regression-model-plr"]], "Plot Coefficients and 95% Confidence Intervals": [[60, "Plot-Coefficients-and-95%-Confidence-Intervals"]], "Policy Learning with Trees": [[65, "Policy-Learning-with-Trees"], [75, "policy-learning-with-trees"]], "Potential Quantile Estimation": [[66, "Potential-Quantile-Estimation"]], "Potential Quantiles (PQs)": [[66, "Potential-Quantiles-(PQs)"]], "Potential quantiles (PQs)": [[75, "potential-quantiles-pqs"], [79, "potential-quantiles-pqs"]], "Python: Average Potential Outcome (APO) Models": [[47, "Python:-Average-Potential-Outcome-(APO)-Models"]], "Python: Basic Instrumental Variables calculation": [[48, "Python:-Basic-Instrumental-Variables-calculation"]], "Python: Basics of Double Machine Learning": [[49, "Python:-Basics-of-Double-Machine-Learning"]], "Python: Building the package from source": [[104, "python-building-the-package-from-source"]], "Python: Case studies": [[46, "python-case-studies"]], "Python: Choice of learners": [[59, "Python:-Choice-of-learners"]], "Python: Cluster Robust Double Machine Learning": [[61, "Python:-Cluster-Robust-Double-Machine-Learning"]], "Python: Conditional Average Treatment Effects (CATEs) for IRM models": [[50, "Python:-Conditional-Average-Treatment-Effects-(CATEs)-for-IRM-models"]], "Python: Conditional Average Treatment Effects (CATEs) for PLR models": [[51, "Python:-Conditional-Average-Treatment-Effects-(CATEs)-for-PLR-models"]], "Python: Conditional Value at Risk of potential outcomes": [[52, "Python:-Conditional-Value-at-Risk-of-potential-outcomes"]], "Python: Difference-in-Differences": [[53, "Python:-Difference-in-Differences"]], "Python: Difference-in-Differences Pre-Testing": [[54, "Python:-Difference-in-Differences-Pre-Testing"]], "Python: First Stage and Causal Estimation": [[55, "Python:-First-Stage-and-Causal-Estimation"]], "Python: GATE Sensitivity Analysis": [[58, "Python:-GATE-Sensitivity-Analysis"]], "Python: Group Average Treatment Effects (GATEs) for IRM models": [[56, "Python:-Group-Average-Treatment-Effects-(GATEs)-for-IRM-models"]], "Python: Group Average Treatment Effects (GATEs) for PLR models": [[57, "Python:-Group-Average-Treatment-Effects-(GATEs)-for-PLR-models"]], "Python: Impact of 401(k) on Financial Wealth": [[62, "Python:-Impact-of-401(k)-on-Financial-Wealth"]], "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)": [[63, "Python:-Impact-of-401(k)-on-Financial-Wealth-(Quantile-Effects)"]], "Python: Installing DoubleML": [[104, "python-installing-doubleml"]], "Python: Installing a released version from a .whl file": [[104, "python-installing-a-released-version-from-a-whl-file"]], "Python: Installing the latest release from pip or conda": [[104, "python-installing-the-latest-release-from-pip-or-conda"]], "Python: Learners and hyperparameters": [[76, "python-learners-and-hyperparameters"]], "Python: Optional Dependencies": [[104, "python-optional-dependencies"]], "Python: PLM and IRM for Multiple Treatments": [[64, "Python:-PLM-and-IRM-for-Multiple-Treatments"]], "Python: Policy Learning with Trees": [[65, "Python:-Policy-Learning-with-Trees"]], "Python: Potential Quantiles and Quantile Treatment Effects": [[66, "Python:-Potential-Quantiles-and-Quantile-Treatment-Effects"]], "Python: Sample Selection Models": [[70, "Python:-Sample-Selection-Models"]], "Python: Sensitivity Analysis": [[68, "Python:-Sensitivity-Analysis"]], "Quantile Treatment Effects (QTEs)": [[66, "Quantile-Treatment-Effects-(QTEs)"]], "Quantile treatment effects (QTEs)": [[75, "quantile-treatment-effects-qtes"]], "Quantiles": [[75, "quantiles"]], "R: Basic Instrumental Variables Calculation": [[39, "R:-Basic-Instrumental-Variables-Calculation"]], "R: Basics of Double Machine Learning": [[40, "R:-Basics-of-Double-Machine-Learning"]], "R: Case studies": [[46, "r-case-studies"]], "R: Cluster Robust Double Machine Learning": [[42, "R:-Cluster-Robust-Double-Machine-Learning"]], "R: DoubleML for Difference-in-Differences": [[41, "R:-DoubleML-for-Difference-in-Differences"]], "R: Ensemble Learners and More with mlr3pipelines": [[44, "R:-Ensemble-Learners-and-More-with-mlr3pipelines"]], "R: Impact of 401(k) on Financial Wealth": [[43, "R:-Impact-of-401(k)-on-Financial-Wealth"]], "R: Installing DoubleML": [[104, "r-installing-doubleml"]], "R: Installing the development version from GitHub": [[104, "r-installing-the-development-version-from-github"]], "R: Installing the latest release from CRAN": [[104, "r-installing-the-latest-release-from-cran"]], "R: Learners and hyperparameters": [[76, "r-learners-and-hyperparameters"]], "Ranking Treatment Effects under Treatment Propensity and Treatment Effect Heterogeneity": [[64, "Ranking-Treatment-Effects-under-Treatment-Propensity-and-Treatment-Effect-Heterogeneity"]], "Real-Data Application": [[42, "Real-Data-Application"], [61, "Real-Data-Application"]], "References": [[39, "References"], [41, "References"], [42, "References"], [44, "References"], [48, "References"], [55, "References"], [61, "References"], [64, "References"], [69, "References"], [72, "references"], [76, "references"], [78, "references"], [92, "references"], [102, "references"], [103, "references"], [105, "references"]], "Regression Discontinuity Designs (RDD)": [[77, "regression-discontinuity-designs-rdd"]], "Regularization Bias in Simple ML-Approaches": [[40, "Regularization-Bias-in-Simple-ML-Approaches"], [49, "Regularization-Bias-in-Simple-ML-Approaches"]], "Regularization bias in simple ML-approaches": [[72, "regularization-bias-in-simple-ml-approaches"]], "Release notes": [[107, "release-notes"]], "Repeated Cross-Sectional Data": [[53, "Repeated-Cross-Sectional-Data"], [79, "repeated-cross-sectional-data"]], "Repeated cross-fitting with K folds and M repetitions": [[78, "repeated-cross-fitting-with-k-folds-and-m-repetitions"]], "Repeated cross-sections": [[77, "repeated-cross-sections"]], "Sample Selection Models": [[79, "sample-selection-models"]], "Sample Selection Models (SSM)": [[77, "sample-selection-models-ssm"]], "Sample splitting to remove bias induced by overfitting": [[40, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [49, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [72, "sample-splitting-to-remove-bias-induced-by-overfitting"]], "Sample-splitting without cross-fitting": [[78, "sample-splitting-without-cross-fitting"]], "Sample-splitting, cross-fitting and repeated cross-fitting": [[78, "sample-splitting-cross-fitting-and-repeated-cross-fitting"]], "Sandbox": [[46, "sandbox"]], "Score functions": [[79, "score-functions"]], "Score mixin classes for double machine learning models": [[0, "score-mixin-classes-for-double-machine-learning-models"]], "Sensitivity Analysis": [[47, "Sensitivity-Analysis"], [68, "Sensitivity-Analysis"], [68, "id1"]], "Sensitivity Analysis with IRM": [[68, "Sensitivity-Analysis-with-IRM"]], "Sensitivity analysis": [[93, "sensitivity-analysis"]], "Set up learners based on mlr3pipelines": [[44, "Set-up-learners-based-on-mlr3pipelines"]], "Sharp RDD": [[67, "Sharp-RDD"]], "Sharp RDD Without Adjustment": [[67, "Sharp-RDD-Without-Adjustment"]], "Sharp RDD with Flexible Adjustment": [[67, "Sharp-RDD-with-Flexible-Adjustment"]], "Sharp RDD with Linear Adjustment": [[67, "Sharp-RDD-with-Linear-Adjustment"]], "Sharp Regression Discontinuity Design": [[77, "sharp-regression-discontinuity-design"]], "Simulate two-way cluster data": [[42, "Simulate-two-way-cluster-data"], [61, "Simulate-two-way-cluster-data"]], "Simulation Example": [[68, "Simulation-Example"]], "Simultaneous inference over different DoubleML models (advanced)": [[92, "simultaneous-inference-over-different-doubleml-models-advanced"]], "Single Average Potential Outcome Models (APO)": [[47, "Single-Average-Potential-Outcome-Models-(APO)"]], "Source code and maintenance": [[103, "source-code-and-maintenance"]], "Specify learner and estimate causal parameter: IRM model with Lasso as learner": [[45, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: IRM model with random forest as learner": [[45, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-random-forest-as-learner"]], "Specify learner and estimate causal parameter: PLR model with Lasso as learner": [[45, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: PLR model with random forest as learner": [[45, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-random-forest-as-learner"]], "Specifying alternative score functions via callables": [[79, "specifying-alternative-score-functions-via-callables"]], "Specifying learners and set hyperparameters": [[76, "specifying-learners-and-set-hyperparameters"], [76, "id9"]], "Standard approach": [[59, "Standard-approach"]], "Step 1: Custom API for FLAML Models within DoubleML": [[60, "Step-1:-Custom-API-for-FLAML-Models-within-DoubleML"]], "Step 1: Initialize and Train the AutoML Models:": [[60, "Step-1:-Initialize-and-Train-the-AutoML-Models:"]], "Step 2: Evaluate the Tuned Models": [[60, "Step-2:-Evaluate-the-Tuned-Models"]], "Step 2: Using the API when calling DoubleML\u2019s .fit() Method": [[60, "Step-2:-Using-the-API-when-calling-DoubleML's-.fit()-Method"]], "Step 3: Create and Fit DoubleML Model": [[60, "Step-3:-Create-and-Fit-DoubleML-Model"]], "Summary Figure": [[64, "Summary-Figure"]], "Summary of Results": [[43, "Summary-of-Results"], [62, "Summary-of-Results"]], "The Augmented Inverse Propensity Weighting Model estimates the ATE under arbitrary effect and propensity score heterogeneity": [[64, "The-Augmented-Inverse-Propensity-Weighting-Model-estimates-the-ATE-under-arbitrary-effect-and-propensity-score-heterogeneity"]], "The Data Backend: DoubleMLData": [[43, "The-Data-Backend:-DoubleMLData"], [62, "The-Data-Backend:-DoubleMLData"]], "The DoubleML package": [[43, "The-DoubleML-package"], [62, "The-DoubleML-package"]], "The Partially Linear Model performs overlap weighting": [[64, "The-Partially-Linear-Model-performs-overlap-weighting"]], "The basics of double/debiased machine learning": [[72, "the-basics-of-double-debiased-machine-learning"]], "The causal model": [[105, "the-causal-model"]], "The data-backend DoubleMLData": [[73, "the-data-backend-doublemldata"], [105, "the-data-backend-doublemldata"]], "Theory": [[93, "theory"]], "Tuning on the Folds": [[60, "Tuning-on-the-Folds"]], "Tuning on the full Sample": [[60, "Tuning-on-the-full-Sample"]], "Two-Dimensional Example": [[50, "Two-Dimensional-Example"], [51, "Two-Dimensional-Example"]], "Two-Way Clustering with Respect to Product and Market": [[42, "Two-Way-Clustering-with-Respect-to-Product-and-Market"], [61, "Two-Way-Clustering-with-Respect-to-Product-and-Market"]], "Untuned (default parameter) XGBoost": [[60, "Untuned-(default-parameter)-XGBoost"]], "Use ensemble learners based on mlr3pipelines": [[44, "Use-ensemble-learners-based-on-mlr3pipelines"]], "User guide": [[74, "user-guide"]], "Using DoubleML": [[39, "Using-DoubleML"], [48, "Using-DoubleML"]], "Using ML for DiD: Integrating DoubleML in did": [[41, "Using-ML-for-DiD:-Integrating-DoubleML-in-did"]], "Using learners from mlr3, mlr3learners and mlr3extralearners": [[44, "Using-learners-from-mlr3,-mlr3learners-and-mlr3extralearners"]], "Using pipelines to construct learners": [[76, "using-pipelines-to-construct-learners"]], "Utility classes": [[0, "utility-classes"]], "Utility classes and functions": [[0, "utility-classes-and-functions"]], "Utility functions": [[0, "utility-functions"]], "VanderWeele and Arah (2011): Benchmarking": [[69, "VanderWeele-and-Arah-(2011):-Benchmarking"]], "Variance estimation": [[92, "variance-estimation"]], "Variance estimation and confidence intervals": [[92, "variance-estimation-and-confidence-intervals"]], "Weighted Average Treatment Effects": [[75, "weighted-average-treatment-effects"]], "doubleml.DoubleMLAPO": [[1, "doubleml-doublemlapo"]], "doubleml.DoubleMLAPOS": [[2, "doubleml-doublemlapos"]], "doubleml.DoubleMLCVAR": [[3, "doubleml-doublemlcvar"]], "doubleml.DoubleMLClusterData": [[4, "doubleml-doublemlclusterdata"]], "doubleml.DoubleMLDID": [[5, "doubleml-doublemldid"]], "doubleml.DoubleMLDIDCS": [[6, "doubleml-doublemldidcs"]], "doubleml.DoubleMLData": [[7, "doubleml-doublemldata"]], "doubleml.DoubleMLIIVM": [[8, "doubleml-doublemliivm"]], "doubleml.DoubleMLIRM": [[9, "doubleml-doublemlirm"]], "doubleml.DoubleMLLPQ": [[10, "doubleml-doublemllpq"]], "doubleml.DoubleMLPLIV": [[11, "doubleml-doublemlpliv"]], "doubleml.DoubleMLPLR": [[12, "doubleml-doublemlplr"]], "doubleml.DoubleMLPQ": [[13, "doubleml-doublemlpq"]], "doubleml.DoubleMLQTE": [[14, "doubleml-doublemlqte"]], "doubleml.DoubleMLSSM": [[15, "doubleml-doublemlssm"]], "doubleml.datasets.fetch_401K": [[16, "doubleml-datasets-fetch-401k"]], "doubleml.datasets.fetch_bonus": [[17, "doubleml-datasets-fetch-bonus"]], "doubleml.datasets.make_confounded_irm_data": [[18, "doubleml-datasets-make-confounded-irm-data"]], "doubleml.datasets.make_confounded_plr_data": [[19, "doubleml-datasets-make-confounded-plr-data"]], "doubleml.datasets.make_did_SZ2020": [[20, "doubleml-datasets-make-did-sz2020"]], "doubleml.datasets.make_heterogeneous_data": [[21, "doubleml-datasets-make-heterogeneous-data"]], "doubleml.datasets.make_iivm_data": [[22, "doubleml-datasets-make-iivm-data"]], "doubleml.datasets.make_irm_data": [[23, "doubleml-datasets-make-irm-data"]], "doubleml.datasets.make_irm_data_discrete_treatments": [[24, "doubleml-datasets-make-irm-data-discrete-treatments"]], "doubleml.datasets.make_pliv_CHS2015": [[25, "doubleml-datasets-make-pliv-chs2015"]], "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021": [[26, "doubleml-datasets-make-pliv-multiway-cluster-ckms2021"]], "doubleml.datasets.make_plr_CCDDHNR2018": [[27, "doubleml-datasets-make-plr-ccddhnr2018"]], "doubleml.datasets.make_plr_turrell2018": [[28, "doubleml-datasets-make-plr-turrell2018"]], "doubleml.datasets.make_ssm_data": [[29, "doubleml-datasets-make-ssm-data"]], "doubleml.double_ml_score_mixins.LinearScoreMixin": [[30, "doubleml-double-ml-score-mixins-linearscoremixin"]], "doubleml.double_ml_score_mixins.NonLinearScoreMixin": [[31, "doubleml-double-ml-score-mixins-nonlinearscoremixin"]], "doubleml.rdd.RDFlex": [[32, "doubleml-rdd-rdflex"]], "doubleml.rdd.datasets.make_simple_rdd_data": [[33, "doubleml-rdd-datasets-make-simple-rdd-data"]], "doubleml.utils.DMLDummyClassifier": [[34, "doubleml-utils-dmldummyclassifier"]], "doubleml.utils.DMLDummyRegressor": [[35, "doubleml-utils-dmldummyregressor"]], "doubleml.utils.DoubleMLBLP": [[36, "doubleml-utils-doublemlblp"]], "doubleml.utils.DoubleMLPolicyTree": [[37, "doubleml-utils-doublemlpolicytree"]], "doubleml.utils.gain_statistics": [[38, "doubleml-utils-gain-statistics"]]}, "docnames": ["api/api", "api/generated/doubleml.DoubleMLAPO", "api/generated/doubleml.DoubleMLAPOS", "api/generated/doubleml.DoubleMLCVAR", "api/generated/doubleml.DoubleMLClusterData", "api/generated/doubleml.DoubleMLDID", "api/generated/doubleml.DoubleMLDIDCS", "api/generated/doubleml.DoubleMLData", "api/generated/doubleml.DoubleMLIIVM", "api/generated/doubleml.DoubleMLIRM", "api/generated/doubleml.DoubleMLLPQ", "api/generated/doubleml.DoubleMLPLIV", "api/generated/doubleml.DoubleMLPLR", "api/generated/doubleml.DoubleMLPQ", "api/generated/doubleml.DoubleMLQTE", "api/generated/doubleml.DoubleMLSSM", "api/generated/doubleml.datasets.fetch_401K", "api/generated/doubleml.datasets.fetch_bonus", "api/generated/doubleml.datasets.make_confounded_irm_data", "api/generated/doubleml.datasets.make_confounded_plr_data", "api/generated/doubleml.datasets.make_did_SZ2020", "api/generated/doubleml.datasets.make_heterogeneous_data", "api/generated/doubleml.datasets.make_iivm_data", "api/generated/doubleml.datasets.make_irm_data", "api/generated/doubleml.datasets.make_irm_data_discrete_treatments", "api/generated/doubleml.datasets.make_pliv_CHS2015", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018", "api/generated/doubleml.datasets.make_plr_turrell2018", "api/generated/doubleml.datasets.make_ssm_data", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin", "api/generated/doubleml.rdd.RDFlex", "api/generated/doubleml.rdd.datasets.make_simple_rdd_data", "api/generated/doubleml.utils.DMLDummyClassifier", "api/generated/doubleml.utils.DMLDummyRegressor", "api/generated/doubleml.utils.DoubleMLBLP", "api/generated/doubleml.utils.DoubleMLPolicyTree", "api/generated/doubleml.utils.gain_statistics", "examples/R_double_ml_basic_iv", "examples/R_double_ml_basics", "examples/R_double_ml_did", "examples/R_double_ml_multiway_cluster", "examples/R_double_ml_pension", "examples/R_double_ml_pipeline", "examples/double_ml_bonus_data", "examples/index", "examples/py_double_ml_apo", "examples/py_double_ml_basic_iv", "examples/py_double_ml_basics", "examples/py_double_ml_cate", "examples/py_double_ml_cate_plr", "examples/py_double_ml_cvar", "examples/py_double_ml_did", "examples/py_double_ml_did_pretest", "examples/py_double_ml_firststage", "examples/py_double_ml_gate", "examples/py_double_ml_gate_plr", "examples/py_double_ml_gate_sensitivity", "examples/py_double_ml_learner", "examples/py_double_ml_meets_flaml", "examples/py_double_ml_multiway_cluster", "examples/py_double_ml_pension", "examples/py_double_ml_pension_qte", "examples/py_double_ml_plm_irm_hetfx", "examples/py_double_ml_policy_tree", "examples/py_double_ml_pq", "examples/py_double_ml_rdflex", "examples/py_double_ml_sensitivity", "examples/py_double_ml_sensitivity_booking", "examples/py_double_ml_ssm", "guide/algorithms", "guide/basics", "guide/data_backend", "guide/guide", "guide/heterogeneity", "guide/learners", "guide/models", "guide/resampling", "guide/scores", "guide/scores/apo_score", "guide/scores/cvar_score", "guide/scores/did_score", "guide/scores/didcs_score", "guide/scores/iivm_score", "guide/scores/irm_score", "guide/scores/lpq_score", "guide/scores/mar_score", "guide/scores/nr_score", "guide/scores/pliv_score", "guide/scores/plr_score", "guide/scores/pq_score", "guide/se_confint", "guide/sensitivity", "guide/sensitivity/apo_sensitivity", "guide/sensitivity/benchmarking", "guide/sensitivity/did_cs_sensitivity", "guide/sensitivity/did_sensitivity", "guide/sensitivity/implementation", "guide/sensitivity/irm_sensitivity", "guide/sensitivity/plr_sensitivity", "guide/sensitivity/theory", "guide/sim_inf", "index", "intro/install", "intro/intro", "literature/literature", "release/release", "workflow/workflow"], "envversion": {"nbsphinx": 4, "sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["api/api.rst", "api/generated/doubleml.DoubleMLAPO.rst", "api/generated/doubleml.DoubleMLAPOS.rst", "api/generated/doubleml.DoubleMLCVAR.rst", "api/generated/doubleml.DoubleMLClusterData.rst", "api/generated/doubleml.DoubleMLDID.rst", "api/generated/doubleml.DoubleMLDIDCS.rst", "api/generated/doubleml.DoubleMLData.rst", "api/generated/doubleml.DoubleMLIIVM.rst", "api/generated/doubleml.DoubleMLIRM.rst", "api/generated/doubleml.DoubleMLLPQ.rst", "api/generated/doubleml.DoubleMLPLIV.rst", "api/generated/doubleml.DoubleMLPLR.rst", "api/generated/doubleml.DoubleMLPQ.rst", "api/generated/doubleml.DoubleMLQTE.rst", "api/generated/doubleml.DoubleMLSSM.rst", "api/generated/doubleml.datasets.fetch_401K.rst", "api/generated/doubleml.datasets.fetch_bonus.rst", "api/generated/doubleml.datasets.make_confounded_irm_data.rst", "api/generated/doubleml.datasets.make_confounded_plr_data.rst", "api/generated/doubleml.datasets.make_did_SZ2020.rst", "api/generated/doubleml.datasets.make_heterogeneous_data.rst", "api/generated/doubleml.datasets.make_iivm_data.rst", "api/generated/doubleml.datasets.make_irm_data.rst", "api/generated/doubleml.datasets.make_irm_data_discrete_treatments.rst", "api/generated/doubleml.datasets.make_pliv_CHS2015.rst", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021.rst", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018.rst", "api/generated/doubleml.datasets.make_plr_turrell2018.rst", "api/generated/doubleml.datasets.make_ssm_data.rst", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin.rst", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin.rst", "api/generated/doubleml.rdd.RDFlex.rst", "api/generated/doubleml.rdd.datasets.make_simple_rdd_data.rst", "api/generated/doubleml.utils.DMLDummyClassifier.rst", "api/generated/doubleml.utils.DMLDummyRegressor.rst", "api/generated/doubleml.utils.DoubleMLBLP.rst", "api/generated/doubleml.utils.DoubleMLPolicyTree.rst", "api/generated/doubleml.utils.gain_statistics.rst", "examples/R_double_ml_basic_iv.ipynb", "examples/R_double_ml_basics.ipynb", "examples/R_double_ml_did.ipynb", "examples/R_double_ml_multiway_cluster.ipynb", "examples/R_double_ml_pension.ipynb", "examples/R_double_ml_pipeline.ipynb", "examples/double_ml_bonus_data.ipynb", "examples/index.rst", "examples/py_double_ml_apo.ipynb", "examples/py_double_ml_basic_iv.ipynb", "examples/py_double_ml_basics.ipynb", "examples/py_double_ml_cate.ipynb", "examples/py_double_ml_cate_plr.ipynb", "examples/py_double_ml_cvar.ipynb", "examples/py_double_ml_did.ipynb", "examples/py_double_ml_did_pretest.ipynb", "examples/py_double_ml_firststage.ipynb", "examples/py_double_ml_gate.ipynb", "examples/py_double_ml_gate_plr.ipynb", "examples/py_double_ml_gate_sensitivity.ipynb", "examples/py_double_ml_learner.ipynb", "examples/py_double_ml_meets_flaml.ipynb", "examples/py_double_ml_multiway_cluster.ipynb", "examples/py_double_ml_pension.ipynb", "examples/py_double_ml_pension_qte.ipynb", "examples/py_double_ml_plm_irm_hetfx.ipynb", "examples/py_double_ml_policy_tree.ipynb", "examples/py_double_ml_pq.ipynb", "examples/py_double_ml_rdflex.ipynb", "examples/py_double_ml_sensitivity.ipynb", "examples/py_double_ml_sensitivity_booking.ipynb", "examples/py_double_ml_ssm.ipynb", "guide/algorithms.rst", "guide/basics.rst", "guide/data_backend.rst", "guide/guide.rst", "guide/heterogeneity.rst", "guide/learners.rst", "guide/models.rst", "guide/resampling.rst", "guide/scores.rst", "guide/scores/apo_score.rst", "guide/scores/cvar_score.rst", "guide/scores/did_score.rst", "guide/scores/didcs_score.rst", "guide/scores/iivm_score.rst", "guide/scores/irm_score.rst", "guide/scores/lpq_score.rst", "guide/scores/mar_score.rst", "guide/scores/nr_score.rst", "guide/scores/pliv_score.rst", "guide/scores/plr_score.rst", "guide/scores/pq_score.rst", "guide/se_confint.rst", "guide/sensitivity.rst", "guide/sensitivity/apo_sensitivity.rst", "guide/sensitivity/benchmarking.rst", "guide/sensitivity/did_cs_sensitivity.rst", "guide/sensitivity/did_sensitivity.rst", "guide/sensitivity/implementation.rst", "guide/sensitivity/irm_sensitivity.rst", "guide/sensitivity/plr_sensitivity.rst", "guide/sensitivity/theory.rst", "guide/sim_inf.rst", "index.rst", "intro/install.rst", "intro/intro.rst", "literature/literature.rst", "release/release.rst", "workflow/workflow.rst"], "indexentries": {"aggregate_over_splits() (doubleml.rdd.rdflex method)": [[32, "doubleml.rdd.RDFlex.aggregate_over_splits", false]], "bootstrap() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.bootstrap", false]], "bootstrap() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.bootstrap", false]], "bootstrap() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.bootstrap", false]], "bootstrap() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.bootstrap", false]], "bootstrap() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.bootstrap", false]], "bootstrap() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.bootstrap", false]], "bootstrap() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.bootstrap", false]], "bootstrap() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.bootstrap", false]], "bootstrap() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.bootstrap", false]], "bootstrap() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.bootstrap", false]], "bootstrap() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.bootstrap", false]], "bootstrap() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.bootstrap", false]], "bootstrap() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.bootstrap", false]], "capo() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.capo", false]], "cate() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.cate", false]], "cate() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.cate", false]], "causal_contrast() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.causal_contrast", false]], "confint() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.confint", false]], "confint() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.confint", false]], "confint() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.confint", false]], "confint() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.confint", false]], "confint() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.confint", false]], "confint() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.confint", false]], "confint() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.confint", false]], "confint() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.confint", false]], "confint() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.confint", false]], "confint() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.confint", false]], "confint() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.confint", false]], "confint() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.confint", false]], "confint() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.confint", false]], "confint() (doubleml.rdd.rdflex method)": [[32, "doubleml.rdd.RDFlex.confint", false]], "confint() (doubleml.utils.doublemlblp method)": [[36, "doubleml.utils.DoubleMLBLP.confint", false]], "construct_framework() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.construct_framework", false]], "construct_framework() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.construct_framework", false]], "construct_framework() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.construct_framework", false]], "construct_framework() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.construct_framework", false]], "construct_framework() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.construct_framework", false]], "construct_framework() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.construct_framework", false]], "construct_framework() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.construct_framework", false]], "construct_framework() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.construct_framework", false]], "construct_framework() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.construct_framework", false]], "construct_framework() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.construct_framework", false]], "construct_framework() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.construct_framework", false]], "dmldummyclassifier (class in doubleml.utils)": [[34, "doubleml.utils.DMLDummyClassifier", false]], "dmldummyregressor (class in doubleml.utils)": [[35, "doubleml.utils.DMLDummyRegressor", false]], "doublemlapo (class in doubleml)": [[1, "doubleml.DoubleMLAPO", false]], "doublemlapos (class in doubleml)": [[2, "doubleml.DoubleMLAPOS", false]], "doublemlblp (class in doubleml.utils)": [[36, "doubleml.utils.DoubleMLBLP", false]], "doublemlclusterdata (class in doubleml)": [[4, "doubleml.DoubleMLClusterData", false]], "doublemlcvar (class in doubleml)": [[3, "doubleml.DoubleMLCVAR", false]], "doublemldata (class in doubleml)": [[7, "doubleml.DoubleMLData", false]], "doublemldid (class in doubleml)": [[5, "doubleml.DoubleMLDID", false]], "doublemldidcs (class in doubleml)": [[6, "doubleml.DoubleMLDIDCS", false]], "doublemliivm (class in doubleml)": [[8, "doubleml.DoubleMLIIVM", false]], "doublemlirm (class in doubleml)": [[9, "doubleml.DoubleMLIRM", false]], "doublemllpq (class in doubleml)": [[10, "doubleml.DoubleMLLPQ", false]], "doublemlpliv (class in doubleml)": [[11, "doubleml.DoubleMLPLIV", false]], "doublemlplr (class in doubleml)": [[12, "doubleml.DoubleMLPLR", false]], "doublemlpolicytree (class in doubleml.utils)": [[37, "doubleml.utils.DoubleMLPolicyTree", false]], "doublemlpq (class in doubleml)": [[13, "doubleml.DoubleMLPQ", false]], "doublemlqte (class in doubleml)": [[14, "doubleml.DoubleMLQTE", false]], "doublemlssm (class in doubleml)": [[15, "doubleml.DoubleMLSSM", false]], "draw_sample_splitting() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.draw_sample_splitting", false]], "evaluate_learners() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.evaluate_learners", false]], "fetch_401k() (in module doubleml.datasets)": [[16, "doubleml.datasets.fetch_401K", false]], "fetch_bonus() (in module doubleml.datasets)": [[17, "doubleml.datasets.fetch_bonus", false]], "fit() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.fit", false]], "fit() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.fit", false]], "fit() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.fit", false]], "fit() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.fit", false]], "fit() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.fit", false]], "fit() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.fit", false]], "fit() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.fit", false]], "fit() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.fit", false]], "fit() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.fit", false]], "fit() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.fit", false]], "fit() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.fit", false]], "fit() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.fit", false]], "fit() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.fit", false]], "fit() (doubleml.rdd.rdflex method)": [[32, "doubleml.rdd.RDFlex.fit", false]], "fit() (doubleml.utils.dmldummyclassifier method)": [[34, "doubleml.utils.DMLDummyClassifier.fit", false]], "fit() (doubleml.utils.dmldummyregressor method)": [[35, "doubleml.utils.DMLDummyRegressor.fit", false]], "fit() (doubleml.utils.doublemlblp method)": [[36, "doubleml.utils.DoubleMLBLP.fit", false]], "fit() (doubleml.utils.doublemlpolicytree method)": [[37, "doubleml.utils.DoubleMLPolicyTree.fit", false]], "from_arrays() (doubleml.doublemlclusterdata class method)": [[4, "doubleml.DoubleMLClusterData.from_arrays", false]], "from_arrays() (doubleml.doublemldata class method)": [[7, "doubleml.DoubleMLData.from_arrays", false]], "gain_statistics() (in module doubleml.utils)": [[38, "doubleml.utils.gain_statistics", false]], "gapo() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.gapo", false]], "gate() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.gate", false]], "gate() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.gate", false]], "get_metadata_routing() (doubleml.utils.dmldummyclassifier method)": [[34, "doubleml.utils.DMLDummyClassifier.get_metadata_routing", false]], "get_metadata_routing() (doubleml.utils.dmldummyregressor method)": [[35, "doubleml.utils.DMLDummyRegressor.get_metadata_routing", false]], "get_params() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.get_params", false]], "get_params() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.get_params", false]], "get_params() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.get_params", false]], "get_params() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.get_params", false]], "get_params() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.get_params", false]], "get_params() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.get_params", false]], "get_params() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.get_params", false]], "get_params() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.get_params", false]], "get_params() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.get_params", false]], "get_params() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.get_params", false]], "get_params() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.get_params", false]], "get_params() (doubleml.utils.dmldummyclassifier method)": [[34, "doubleml.utils.DMLDummyClassifier.get_params", false]], "get_params() (doubleml.utils.dmldummyregressor method)": [[35, "doubleml.utils.DMLDummyRegressor.get_params", false]], "linearscoremixin (class in doubleml.double_ml_score_mixins)": [[30, "doubleml.double_ml_score_mixins.LinearScoreMixin", false]], "make_confounded_irm_data() (in module doubleml.datasets)": [[18, "doubleml.datasets.make_confounded_irm_data", false]], "make_confounded_plr_data() (in module doubleml.datasets)": [[19, "doubleml.datasets.make_confounded_plr_data", false]], "make_did_sz2020() (in module doubleml.datasets)": [[20, "doubleml.datasets.make_did_SZ2020", false]], "make_heterogeneous_data() (in module doubleml.datasets)": [[21, "doubleml.datasets.make_heterogeneous_data", false]], "make_iivm_data() (in module doubleml.datasets)": [[22, "doubleml.datasets.make_iivm_data", false]], "make_irm_data() (in module doubleml.datasets)": [[23, "doubleml.datasets.make_irm_data", false]], "make_irm_data_discrete_treatments() (in module doubleml.datasets)": [[24, "doubleml.datasets.make_irm_data_discrete_treatments", false]], "make_pliv_chs2015() (in module doubleml.datasets)": [[25, "doubleml.datasets.make_pliv_CHS2015", false]], "make_pliv_multiway_cluster_ckms2021() (in module doubleml.datasets)": [[26, "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", false]], "make_plr_ccddhnr2018() (in module doubleml.datasets)": [[27, "doubleml.datasets.make_plr_CCDDHNR2018", false]], "make_plr_turrell2018() (in module doubleml.datasets)": [[28, "doubleml.datasets.make_plr_turrell2018", false]], "make_simple_rdd_data() (in module doubleml.rdd.datasets)": [[33, "doubleml.rdd.datasets.make_simple_rdd_data", false]], "make_ssm_data() (in module doubleml.datasets)": [[29, "doubleml.datasets.make_ssm_data", false]], "nonlinearscoremixin (class in doubleml.double_ml_score_mixins)": [[31, "doubleml.double_ml_score_mixins.NonLinearScoreMixin", false]], "p_adjust() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.p_adjust", false]], "p_adjust() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.p_adjust", false]], "p_adjust() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.p_adjust", false]], "p_adjust() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.p_adjust", false]], "p_adjust() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.p_adjust", false]], "p_adjust() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.p_adjust", false]], "p_adjust() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.p_adjust", false]], "p_adjust() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.p_adjust", false]], "p_adjust() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.p_adjust", false]], "p_adjust() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.p_adjust", false]], "p_adjust() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.p_adjust", false]], "p_adjust() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.p_adjust", false]], "plot_tree() (doubleml.utils.doublemlpolicytree method)": [[37, "doubleml.utils.DoubleMLPolicyTree.plot_tree", false]], "policy_tree() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.policy_tree", false]], "predict() (doubleml.utils.dmldummyclassifier method)": [[34, "doubleml.utils.DMLDummyClassifier.predict", false]], "predict() (doubleml.utils.dmldummyregressor method)": [[35, "doubleml.utils.DMLDummyRegressor.predict", false]], "predict() (doubleml.utils.doublemlpolicytree method)": [[37, "doubleml.utils.DoubleMLPolicyTree.predict", false]], "predict_proba() (doubleml.utils.dmldummyclassifier method)": [[34, "doubleml.utils.DMLDummyClassifier.predict_proba", false]], "rdflex (class in doubleml.rdd)": [[32, "doubleml.rdd.RDFlex", false]], "sensitivity_analysis() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.sensitivity_analysis", false]], "sensitivity_benchmark() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.sensitivity_benchmark", false]], "sensitivity_plot() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.sensitivity_plot", false]], "set_ml_nuisance_params() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.set_ml_nuisance_params", false]], "set_params() (doubleml.utils.dmldummyclassifier method)": [[34, "doubleml.utils.DMLDummyClassifier.set_params", false]], "set_params() (doubleml.utils.dmldummyregressor method)": [[35, "doubleml.utils.DMLDummyRegressor.set_params", false]], "set_sample_splitting() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.set_sample_splitting", false]], "set_x_d() (doubleml.doublemlclusterdata method)": [[4, "doubleml.DoubleMLClusterData.set_x_d", false]], "set_x_d() (doubleml.doublemldata method)": [[7, "doubleml.DoubleMLData.set_x_d", false]], "tune() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.tune", false]], "tune() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.tune", false]], "tune() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.tune", false]], "tune() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.tune", false]], "tune() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.tune", false]], "tune() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.tune", false]], "tune() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.tune", false]], "tune() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.tune", false]], "tune() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.tune", false]], "tune() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.tune", false]], "tune() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.tune", false]]}, "objects": {"doubleml": [[1, 0, 1, "", "DoubleMLAPO"], [2, 0, 1, "", "DoubleMLAPOS"], [3, 0, 1, "", "DoubleMLCVAR"], [4, 0, 1, "", "DoubleMLClusterData"], [5, 0, 1, "", "DoubleMLDID"], [6, 0, 1, "", "DoubleMLDIDCS"], [7, 0, 1, "", "DoubleMLData"], [8, 0, 1, "", "DoubleMLIIVM"], [9, 0, 1, "", "DoubleMLIRM"], [10, 0, 1, "", "DoubleMLLPQ"], [11, 0, 1, "", "DoubleMLPLIV"], [12, 0, 1, "", "DoubleMLPLR"], [13, 0, 1, "", "DoubleMLPQ"], [14, 0, 1, "", "DoubleMLQTE"], [15, 0, 1, "", "DoubleMLSSM"]], "doubleml.DoubleMLAPO": [[1, 1, 1, "", "bootstrap"], [1, 1, 1, "", "capo"], [1, 1, 1, "", "confint"], [1, 1, 1, "", "construct_framework"], [1, 1, 1, "", "draw_sample_splitting"], [1, 1, 1, "", "evaluate_learners"], [1, 1, 1, "", "fit"], [1, 1, 1, "", "gapo"], [1, 1, 1, "", "get_params"], [1, 1, 1, "", "p_adjust"], [1, 1, 1, "", "sensitivity_analysis"], [1, 1, 1, "", "sensitivity_benchmark"], [1, 1, 1, "", "sensitivity_plot"], [1, 1, 1, "", "set_ml_nuisance_params"], [1, 1, 1, "", "set_sample_splitting"], [1, 1, 1, "", "tune"]], "doubleml.DoubleMLAPOS": [[2, 1, 1, "", "bootstrap"], [2, 1, 1, "", "causal_contrast"], [2, 1, 1, "", "confint"], [2, 1, 1, "", "draw_sample_splitting"], [2, 1, 1, "", "fit"], [2, 1, 1, "", "sensitivity_analysis"], [2, 1, 1, "", "sensitivity_benchmark"], [2, 1, 1, "", "sensitivity_plot"], [2, 1, 1, "", "set_sample_splitting"]], "doubleml.DoubleMLCVAR": [[3, 1, 1, "", "bootstrap"], [3, 1, 1, "", "confint"], [3, 1, 1, "", "construct_framework"], [3, 1, 1, "", "draw_sample_splitting"], [3, 1, 1, "", "evaluate_learners"], [3, 1, 1, "", "fit"], [3, 1, 1, "", "get_params"], [3, 1, 1, "", "p_adjust"], [3, 1, 1, "", "sensitivity_analysis"], [3, 1, 1, "", "sensitivity_benchmark"], [3, 1, 1, "", "sensitivity_plot"], [3, 1, 1, "", "set_ml_nuisance_params"], [3, 1, 1, "", "set_sample_splitting"], [3, 1, 1, "", "tune"]], "doubleml.DoubleMLClusterData": [[4, 1, 1, "", "from_arrays"], [4, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLDID": [[5, 1, 1, "", "bootstrap"], [5, 1, 1, "", "confint"], [5, 1, 1, "", "construct_framework"], [5, 1, 1, "", "draw_sample_splitting"], [5, 1, 1, "", "evaluate_learners"], [5, 1, 1, "", "fit"], [5, 1, 1, "", "get_params"], [5, 1, 1, "", "p_adjust"], [5, 1, 1, "", "sensitivity_analysis"], [5, 1, 1, "", "sensitivity_benchmark"], [5, 1, 1, "", "sensitivity_plot"], [5, 1, 1, "", "set_ml_nuisance_params"], [5, 1, 1, "", "set_sample_splitting"], [5, 1, 1, "", "tune"]], "doubleml.DoubleMLDIDCS": [[6, 1, 1, "", "bootstrap"], [6, 1, 1, "", "confint"], [6, 1, 1, "", "construct_framework"], [6, 1, 1, "", "draw_sample_splitting"], [6, 1, 1, "", "evaluate_learners"], [6, 1, 1, "", "fit"], [6, 1, 1, "", "get_params"], [6, 1, 1, "", "p_adjust"], [6, 1, 1, "", "sensitivity_analysis"], [6, 1, 1, "", "sensitivity_benchmark"], [6, 1, 1, "", "sensitivity_plot"], [6, 1, 1, "", "set_ml_nuisance_params"], [6, 1, 1, "", "set_sample_splitting"], [6, 1, 1, "", "tune"]], "doubleml.DoubleMLData": [[7, 1, 1, "", "from_arrays"], [7, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLIIVM": [[8, 1, 1, "", "bootstrap"], [8, 1, 1, "", "confint"], [8, 1, 1, "", "construct_framework"], [8, 1, 1, "", "draw_sample_splitting"], [8, 1, 1, "", "evaluate_learners"], [8, 1, 1, "", "fit"], [8, 1, 1, "", "get_params"], [8, 1, 1, "", "p_adjust"], [8, 1, 1, "", "sensitivity_analysis"], [8, 1, 1, "", "sensitivity_benchmark"], [8, 1, 1, "", "sensitivity_plot"], [8, 1, 1, "", "set_ml_nuisance_params"], [8, 1, 1, "", "set_sample_splitting"], [8, 1, 1, "", "tune"]], "doubleml.DoubleMLIRM": [[9, 1, 1, "", "bootstrap"], [9, 1, 1, "", "cate"], [9, 1, 1, "", "confint"], [9, 1, 1, "", "construct_framework"], [9, 1, 1, "", "draw_sample_splitting"], [9, 1, 1, "", "evaluate_learners"], [9, 1, 1, "", "fit"], [9, 1, 1, "", "gate"], [9, 1, 1, "", "get_params"], [9, 1, 1, "", "p_adjust"], [9, 1, 1, "", "policy_tree"], [9, 1, 1, "", "sensitivity_analysis"], [9, 1, 1, "", "sensitivity_benchmark"], [9, 1, 1, "", "sensitivity_plot"], [9, 1, 1, "", "set_ml_nuisance_params"], [9, 1, 1, "", "set_sample_splitting"], [9, 1, 1, "", "tune"]], "doubleml.DoubleMLLPQ": [[10, 1, 1, "", "bootstrap"], [10, 1, 1, "", "confint"], [10, 1, 1, "", "construct_framework"], [10, 1, 1, "", "draw_sample_splitting"], [10, 1, 1, "", "evaluate_learners"], [10, 1, 1, "", "fit"], [10, 1, 1, "", "get_params"], [10, 1, 1, "", "p_adjust"], [10, 1, 1, "", "sensitivity_analysis"], [10, 1, 1, "", "sensitivity_benchmark"], [10, 1, 1, "", "sensitivity_plot"], [10, 1, 1, "", "set_ml_nuisance_params"], [10, 1, 1, "", "set_sample_splitting"], [10, 1, 1, "", "tune"]], "doubleml.DoubleMLPLIV": [[11, 1, 1, "", "bootstrap"], [11, 1, 1, "", "confint"], [11, 1, 1, "", "construct_framework"], [11, 1, 1, "", "draw_sample_splitting"], [11, 1, 1, "", "evaluate_learners"], [11, 1, 1, "", "fit"], [11, 1, 1, "", "get_params"], [11, 1, 1, "", "p_adjust"], [11, 1, 1, "", "sensitivity_analysis"], [11, 1, 1, "", "sensitivity_benchmark"], [11, 1, 1, "", "sensitivity_plot"], [11, 1, 1, "", "set_ml_nuisance_params"], [11, 1, 1, "", "set_sample_splitting"], [11, 1, 1, "", "tune"]], "doubleml.DoubleMLPLR": [[12, 1, 1, "", "bootstrap"], [12, 1, 1, "", "cate"], [12, 1, 1, "", "confint"], [12, 1, 1, "", "construct_framework"], [12, 1, 1, "", "draw_sample_splitting"], [12, 1, 1, "", "evaluate_learners"], [12, 1, 1, "", "fit"], [12, 1, 1, "", "gate"], [12, 1, 1, "", "get_params"], [12, 1, 1, "", "p_adjust"], [12, 1, 1, "", "sensitivity_analysis"], [12, 1, 1, "", "sensitivity_benchmark"], [12, 1, 1, "", "sensitivity_plot"], [12, 1, 1, "", "set_ml_nuisance_params"], [12, 1, 1, "", "set_sample_splitting"], [12, 1, 1, "", "tune"]], "doubleml.DoubleMLPQ": [[13, 1, 1, "", "bootstrap"], [13, 1, 1, "", "confint"], [13, 1, 1, "", "construct_framework"], [13, 1, 1, "", "draw_sample_splitting"], [13, 1, 1, "", "evaluate_learners"], [13, 1, 1, "", "fit"], [13, 1, 1, "", "get_params"], [13, 1, 1, "", "p_adjust"], [13, 1, 1, "", "sensitivity_analysis"], [13, 1, 1, "", "sensitivity_benchmark"], [13, 1, 1, "", "sensitivity_plot"], [13, 1, 1, "", "set_ml_nuisance_params"], [13, 1, 1, "", "set_sample_splitting"], [13, 1, 1, "", "tune"]], "doubleml.DoubleMLQTE": [[14, 1, 1, "", "bootstrap"], [14, 1, 1, "", "confint"], [14, 1, 1, "", "draw_sample_splitting"], [14, 1, 1, "", "fit"], [14, 1, 1, "", "p_adjust"], [14, 1, 1, "", "set_sample_splitting"]], "doubleml.DoubleMLSSM": [[15, 1, 1, "", "bootstrap"], [15, 1, 1, "", "confint"], [15, 1, 1, "", "construct_framework"], [15, 1, 1, "", "draw_sample_splitting"], [15, 1, 1, "", "evaluate_learners"], [15, 1, 1, "", "fit"], [15, 1, 1, "", "get_params"], [15, 1, 1, "", "p_adjust"], [15, 1, 1, "", "sensitivity_analysis"], [15, 1, 1, "", "sensitivity_benchmark"], [15, 1, 1, "", "sensitivity_plot"], [15, 1, 1, "", "set_ml_nuisance_params"], [15, 1, 1, "", "set_sample_splitting"], [15, 1, 1, "", "tune"]], "doubleml.datasets": [[16, 2, 1, "", "fetch_401K"], [17, 2, 1, "", "fetch_bonus"], [18, 2, 1, "", "make_confounded_irm_data"], [19, 2, 1, "", "make_confounded_plr_data"], [20, 2, 1, "", "make_did_SZ2020"], [21, 2, 1, "", "make_heterogeneous_data"], [22, 2, 1, "", "make_iivm_data"], [23, 2, 1, "", "make_irm_data"], [24, 2, 1, "", "make_irm_data_discrete_treatments"], [25, 2, 1, "", "make_pliv_CHS2015"], [26, 2, 1, "", "make_pliv_multiway_cluster_CKMS2021"], [27, 2, 1, "", "make_plr_CCDDHNR2018"], [28, 2, 1, "", "make_plr_turrell2018"], [29, 2, 1, "", "make_ssm_data"]], "doubleml.double_ml_score_mixins": [[30, 0, 1, "", "LinearScoreMixin"], [31, 0, 1, "", "NonLinearScoreMixin"]], "doubleml.rdd": [[32, 0, 1, "", "RDFlex"]], "doubleml.rdd.RDFlex": [[32, 1, 1, "", "aggregate_over_splits"], [32, 1, 1, "", "confint"], [32, 1, 1, "", "fit"]], "doubleml.rdd.datasets": [[33, 2, 1, "", "make_simple_rdd_data"]], "doubleml.utils": [[34, 0, 1, "", "DMLDummyClassifier"], [35, 0, 1, "", "DMLDummyRegressor"], [36, 0, 1, "", "DoubleMLBLP"], [37, 0, 1, "", "DoubleMLPolicyTree"], [38, 2, 1, "", "gain_statistics"]], "doubleml.utils.DMLDummyClassifier": [[34, 1, 1, "", "fit"], [34, 1, 1, "", "get_metadata_routing"], [34, 1, 1, "", "get_params"], [34, 1, 1, "", "predict"], [34, 1, 1, "", "predict_proba"], [34, 1, 1, "", "set_params"]], "doubleml.utils.DMLDummyRegressor": [[35, 1, 1, "", "fit"], [35, 1, 1, "", "get_metadata_routing"], [35, 1, 1, "", "get_params"], [35, 1, 1, "", "predict"], [35, 1, 1, "", "set_params"]], "doubleml.utils.DoubleMLBLP": [[36, 1, 1, "", "confint"], [36, 1, 1, "", "fit"]], "doubleml.utils.DoubleMLPolicyTree": [[37, 1, 1, "", "fit"], [37, 1, 1, "", "plot_tree"], [37, 1, 1, "", "predict"]]}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function"}, "terms": {"": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 22, 23, 25, 26, 27, 28, 29, 32, 36, 39, 41, 42, 43, 44, 45, 47, 53, 56, 57, 58, 61, 62, 63, 67, 68, 69, 70, 71, 73, 76, 77, 79, 87, 88, 92, 93, 95, 102, 103, 105, 106, 107, 108], "0": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 95, 96, 97, 98, 99, 102, 104, 105, 107], "00": [57, 62, 63, 78], "000": [64, 92, 102, 108], "000000": [45, 47, 62, 63, 73, 75, 105], "0000000": [92, 102], "0000000000000010000100": [44, 73, 105], "000000e": [57, 62, 63], "00000591": 66, "000006": [47, 66], "000017": 66, "000025": 61, "000034": 62, "000039": 61, "000064": 48, "000067": 61, "000091": [61, 75], "0001": [45, 62], "000135": 77, "000219": [13, 75], "000242": [14, 75], "000327": 78, "000341": 61, "000442": 61, "00047580260495": 39, "000488": 61, "000494": 58, "0005": 45, "000522": 61, "0005a80b528f": 44, "000670": 61, "000743": 68, "000915799": [92, 102], "0009157990": [92, 102], "000943": [50, 51], "001": [39, 41, 42, 43, 44, 49, 64, 76, 77, 78, 79, 92, 105, 108], "001051": 61, "001234": 63, "00133": 44, "00138944": [71, 79], "001403": 67, "0014578": 78, "001494": 77, "0016": [43, 62], "001714": 75, "0018": [43, 62], "0019": 45, "002169338": [92, 102], "0021693380": [92, 102], "0021693381": [92, 102], "002277": 50, "002290": 54, "0023": 41, "002388": 60, "002436": 58, "002539": 77, "0026": 45, "002779": 68, "0028": [41, 43, 62], "002821": 69, "0028213335041910427": 69, "002847233": 78, "002983": 61, "003": [18, 19, 20], "003111": 47, "003134": 66, "003187": 50, "003214777": 78, "003220": 47, "003328": 66, "0034": 55, "003404": 47, "003415": 47, "003427": 61, "003607": 51, "003779": 58, "003836": 66, "003924": 58, "003944": 50, "003975": 50, "00409412": [71, 79], "0042": [43, 62], "004253": 47, "004392": 58, "004526": 47, "004688": 8, "0047": [43, 62], "004846": 69, "005064573": 78, "005321203": 78, "005339": [50, 51], "005857": 61, "005e": 77, "006055": 47, "006267": 51, "006425": 63, "0068101213851626": 60, "006922": 45, "006958": [50, 51], "00715206": 78, "007210e": 63, "00728": 105, "0073": 45, "007332": 52, "007332393760465": 52, "007659": 75, "00778625": 78, "0078540263583833": 60, "008": 69, "008023": 63, "008223": [50, 51], "008266e": 63, "008487": 45, "0084871742256079": 60, "008642": 75, "008883698": 79, "00888458890362062": 71, "008884589": 71, "008dbd": 64, "008e80": 64, "009": [64, 69], "009122": 66, "009255": 50, "009329847": 79, "009428": 52, "00944171905420782": 69, "00950122695463054": 71, "009501226954630540": 71, "009501227": 71, "009645422": 42, "009656": 66, "00972": 45, "009790": 63, "009837": 64, "009904": 75, "009986": 66, "01": [1, 2, 3, 5, 6, 8, 9, 10, 13, 14, 15, 37, 39, 42, 43, 44, 50, 51, 62, 63, 64, 65, 66, 67, 76, 77, 78, 79, 92, 105, 108], "010": 64, "010063": 64, "010213": 68, "010269": 61, "010450": 42, "010940": 61, "011131": 66, "0112": 41, "01128": 45, "011598": 66, "0118095": 42, "011823": 68, "011988e": 66, "012067": 64, "01219": 44, "01274": 69, "012780": 63, "012831": 69, "013034": 69, "013128": 50, "013162": 64, "013313": 60, "01351638": 42, "013593": 68, "013617": 63, "013677": 67, "013712": 50, "01398951": 42, "013990": [92, 102], "014": 67, "01403089": 42, "014080": [50, 51], "014432": 54, "0145163": 78, "014637": 61, "014681": 68, "014873e": 50, "015": 44, "015038": 52, "015552": 50, "015565": 66, "0156853566737638": 60, "015698": 66, "01574297": 66, "015743": 66, "015831": 50, "016011": 51, "016044": 64, "016154": 61, "016200": [50, 51], "016315": 56, "016429": 75, "01643": 106, "017": [44, 64], "017140": 50, "017393e": 92, "01772": 95, "017777e": 51, "017800092": [92, 102], "0178000920": [92, 102], "018": 44, "018023": 65, "018148": 66, "018508": 50, "018602": 77, "019": 64, "01903": [44, 76, 103, 105], "01916030e": 78, "01925597": 42, "019439633": [92, 102], "0194396330": [92, 102], "0194396331": [92, 102], "019596": 52, "019660": [14, 75], "01990373": 70, "019974": 63, "02": [50, 51, 62, 63, 66, 75, 77, 78], "02016117": 105, "020166": 66, "020271": 61, "020360838": [92, 102], "0203608380": [92, 102], "0203608381": [92, 102], "02052929": [71, 79], "02079162e": 78, "020819": 75, "02092": 105, "021269": [56, 57], "02163217": 42, "021690": 57, "021823": 60, "021866": 65, "021926": 52, "022181": 50, "022295e": 50, "02247976": 42, "022768": 45, "022783": 68, "022915": 61, "022954": 75, "022969": 63, "023020e": [62, 63], "023052": 51, "023256": 66, "023537": 60, "023563": [92, 102], "023955": 63, "024346": 50, "024355": 54, "024364": 93, "024401": [56, 57], "024604": 61, "024782": 66, "024926": 54, "025": [50, 51, 56, 57, 64], "025077": [51, 92, 102], "02528067": 59, "0253": 44, "025300e": 51, "025443": 45, "025496": 50, "0257": 41, "025813114": [92, 102], "0258131140": [92, 102], "02584": 44, "025958": 75, "026669": 63, "026723": 52, "026822": 60, "027": [39, 64], "02791": 45, "028": 64, "0281": 44, "028520": [50, 51], "02897287": 53, "02900983": 66, "029010": 66, "029022": 51, "029209": 108, "029364": [93, 98], "029831": 66, "029910e": [62, 63], "02e": 43, "03": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 47, 50, 51, 52, 58, 62, 63, 66, 67, 68, 69, 78, 93, 98, 108], "030087": 75, "0301": 44, "03018": [10, 75], "030346": 105, "0307": 44, "030934": 66, "030962": 66, "031007": 60, "03113": 70, "031134": 76, "031156": 51, "03123698": 78, "031269": 45, "031639": 66, "031820": 51, "03191": 106, "03220": 107, "0323": 41, "03244552": 76, "0325": 105, "03258": 60, "032580": 60, "032738": 60, "032941": 50, "032953": 68, "033265": 60, "033442": 64, "033756": 52, "033946": [56, 57], "034065": 51, "03411": 105, "0341895": 78, "034226": 63, "034690": 52, "034812763": [92, 102], "0348127630": [92, 102], "0348127631": [92, 102], "034836": 62, "03489": [26, 42, 61], "035119185": [92, 102], "0351191850": [92, 102], "0351191851": [92, 102], "035264": 51, "03536": 105, "03538": 44, "03539": 44, "035391": 45, "0354": 44, "035411": 105, "035441": 51, "03545": 44, "035545": 45, "035572": 45, "035730": 66, "03574": 45, "035762": 66, "035785": 51, "0359": 44, "036129015": [92, 102], "0361290150": [92, 102], "0361290151": [92, 102], "036143": 66, "036147": 66, "036240": 47, "036729": 61, "0368": 41, "036945": 63, "03698487": 66, "036985": 66, "037008": [56, 57], "0374": 44, "037504": 51, "037509": 70, "037747": [50, 51], "038845": 50, "039036": 50, "039141": 47, "03917696": [79, 92], "03920960e": 78, "039310e": 52, "039991e": 50, "04": [19, 32, 43, 47, 50, 51, 62, 63, 66, 67, 68, 78, 108], "040079": 51, "040112": [92, 102], "040139": [50, 51], "04023376": 78, "040533": [79, 92], "04053339": 92, "040562": 50, "040688": 50, "0408": 50, "040912": 51, "040919": 51, "041": 64, "04107": 12, "041147": 52, "041284": 52, "041387": 52, "04142491": 78, "041459": 63, "041491e": 52, "04165": 77, "0418": 41, "041831": 52, "041925": 50, "042034": 69, "042249": 51, "042265": 52, "042437": 64, "0425": 76, "0428": 70, "042822e": 63, "042844e": 66, "043": 39, "043108": 63, "0433": 41, "0434e374": 44, "04387": 76, "043998": 51, "044": 64, "044113": 52, "04415": 44, "04424": 44, "04444978": [92, 102], "044449780": [92, 102], "0445": 76, "04465": 42, "044704": 51, "04478968": 78, "04486": 105, "04487585": [93, 98], "04491": 77, "04497975": [93, 98], "04501612": 92, "04502": [76, 79, 92], "045144": 61, "045313": 50, "045379": 105, "04552": 61, "045553": 52, "045624": 54, "04563": 76, "045638": 50, "04571669": 78, "045754": 66, "04586": 76, "045932": 66, "045993": 76, "046": 64, "046127687": 78, "04625": 76, "046405": 75, "04644564": 78, "046527": 52, "04653976": 66, "046540": 66, "046587": 51, "0466028": 42, "046728": 68, "04682310e": 78, "046922": 76, "047194": 8, "047652e": 51, "047724": 50, "047954": 61, "048220": 60, "048308": 57, "04854487": 78, "048699": 70, "048723": 76, "048853": 51, "049": 64, "049264": 47, "049502": 64, "04973": 51, "05": [32, 39, 41, 42, 43, 44, 50, 51, 52, 55, 59, 61, 62, 63, 64, 66, 67, 69, 76, 77, 78, 79, 92, 105, 108], "05039": 68, "050494e": 51, "050538": 51, "050856": [75, 76], "051": 44, "051651": 67, "051867e": 52, "052": 67, "052000e": 63, "05200782": 78, "052298": 66, "052380": 50, "052488": 57, "052502": 66, "052745": 52, "053": [44, 64, 77], "053049": 51, "0533": 41, "053331": 52, "053342": 63, "053389": [92, 102], "053436": 9, "053541": 66, "053558": 52, "05362122": 78, "053849e": 50, "054": [44, 67], "054068": 61, "054162": 61, "054348": 92, "054370": 52, "054529": [92, 102], "054677988": 78, "054771e": 66, "055165": 68, "055171": 51, "055338e": 62, "055439": [60, 63], "055493": 69, "055680": [92, 102], "05596702": 78, "056": [64, 67], "05624559": 78, "056499": 57, "056745": 50, "056764": 50, "057095": 66, "057274": 47, "0576": [43, 62], "057762": 66, "057792": 50, "057962": 52, "058": 39, "058042": [92, 102], "058276": 63, "058375": 47, "058463": 66, "058508": 70, "058595": 50, "0590": 41, "059128": 50, "059384": 66, "05960305": 78, "059627": 63, "059630": 54, "059685": 66, "06": [18, 19, 20, 47, 50, 51, 52, 62, 63, 66, 75, 76, 108], "06008533": 77, "060201": 66, "060212": [62, 63], "060417": 50, "060581": 59, "060845": [92, 102], "060933": 50, "0611": 41, "06111111": 44, "0615": 41, "062": [67, 77], "062414": 63, "062507": 66, "0628": 41, "062964": [92, 102], "062988": 50, "063017": 47, "0632": 41, "063234e": 51, "0635": 41, "063593": 51, "0636": 41, "063685": 47, "063700": 50, "0638": 41, "063881": 77, "064": 64, "0640": 41, "064161": 63, "064175": 47, "064213": 51, "06428": 62, "064280": 62, "0645": 41, "0646222": 43, "0647": 41, "064848369": 78, "0649": 41, "065": 69, "0653": 41, "065356": [56, 57], "065368": 60, "0654": 41, "065451": 63, "0655": 41, "065725": 52, "0659": 41, "065969": 77, "065988452": 78, "0662": 41, "066464": 68, "06685974": 78, "066889": 66, "0669": 41, "06692492": 78, "06694255": 77, "067046e": 50, "0671": 41, "067240": 66, "06724028": 66, "0673": 41, "0675": 41, "067528": 69, "067721": [92, 102], "068073": 51, "06827": 68, "06834315": 53, "068377": 63, "068514": 50, "068934": 47, "06895837": 42, "069443": 47, "0695854": 42, "069600": 63, "069882e": 50, "07": [50, 51, 63, 66, 67, 69, 78], "070020": 66, "070196": 52, "0701961897676835": 52, "0702127": 42, "0704": 41, "070497": 69, "070534": 15, "070552": 50, "070574e": 63, "0707": 41, "070751": 50, "07085301": 77, "070884": 66, "0711": 41, "071285": 92, "07136": [42, 61], "071362": 50, "071488e": 52, "0716": 41, "07168291": 42, "071777": 76, "071782": [14, 75], "0719": 41, "07202564": [56, 57], "07222222": 44, "072293": 65, "0727": 77, "073": 67, "073013": 66, "073207": 61, "073275": 50, "07347676": 42, "07350015": [26, 29, 42, 61], "073520": 52, "0736": 41, "07366": [44, 76], "073694": 51, "0739130271918385": 60, "073929": 60, "074": 39, "0743": 41, "074304": 92, "07436521": 78, "074426": 66, "07456127": 42, "074617": 51, "07479278": 68, "074927": 47, "075261": 54, "075384": 66, "07538443": 66, "07544271e": 78, "07561": 105, "07564554e": 78, "0758": 69, "075809": 47, "075869": 76, "075942": 60, "076019": 62, "076156": 92, "076179312": [92, 102], "0761793120": [92, 102], "076322": 66, "076347": 52, "0765": 44, "076559": [75, 76], "076596": 50, "076684": 105, "07685043": 78, "07689": 44, "07691847": 78, "076953": [56, 57], "076971": 45, "077144e": 51, "077161": 63, "07727773e": 78, "077319": 66, "077502": [93, 98], "077555": 50, "077702": 47, "0777777777777778": 76, "07777778": [44, 76], "077840": 63, "077883": 66, "077923e": 50, "07796": 77, "078": 108, "078017": 50, "078024924": 78, "078096": 92, "078207": 45, "07828372": [92, 102], "078474": [92, 102], "078709": 51, "078810": 66, "079085": 45, "07915": 44, "07919896": 78, "07942v3": 106, "079458e": 62, "079500e": 50, "07961": 68, "07978296": 78, "08": [52, 63, 66, 69, 77], "08005229": 78, "08027069": 78, "08031571": 78, "080854": 63, "08091581": 78, "080947": 45, "081": 44, "081100": 66, "081230": [50, 51], "081396": 57, "081488": 61, "08154161": 78, "081589": 64, "08181827e": 78, "08191204": 77, "0820": 41, "082263": 11, "082297": 78, "082400e": 50, "082574": 9, "082804": 54, "082858": 51, "082934": 63, "082973": 61, "083": 64, "083258": [92, 102], "083318": 92, "08333333": 44, "08333617": 78, "0835771416": 42, "083706": 69, "083750": 63, "083949": 69, "084": 42, "084156": 51, "084184": 52, "0841842065698133": 52, "084212": 58, "084269": 63, "084323": 50, "084337": 77, "084633": 56, "0853505": 42, "085395": 50, "085566": 52, "085671": 50, "08569257": 78, "085965": 63, "08602774e": 78, "0862": 103, "086264": 52, "08664208": 78, "086679": 76, "086889": 56, "08715073": 78, "0872": 41, "087222": 51, "087561": 50, "087634": 50, "087745": 51, "087947": 66, "088048": 66, "08810528": 78, "0882514": 78, "088282": 57, "088357": 66, "08848": 76, "088482": [14, 75], "088504e": 11, "08888889": 44, "08924608": 78, "0894": 41, "08968939": 42, "089964": 60, "08e": 43, "09": [50, 51, 52, 62, 63, 66, 75], "09000000000000001": 76, "090025": 63, "09015": 41, "090255": 66, "09031157": 78, "09036": 78, "090436": 51, "091": 64, "09106911": 78, "091179e": 50, "091263": 60, "091391": [92, 102], "091406": 93, "091535": 50, "0916": 41, "091824": 51, "09182421": 78, "091992": 65, "092229": 69, "092247": 66, "092263": 77, "092365": [92, 102], "09242707": 78, "092919": 95, "092935": 50, "093": 39, "093043": 66, "09310496": [92, 102], "093153": 66, "09335": 78, "093474": 66, "09347419": 66, "093746": 92, "093950": 61, "094026": 61, "094118": 66, "09428332": 78, "094378e": 50, "094381": 61, "09444444": 44, "094581e": 51, "094829": 77, "094999": 66, "095104": 47, "095475": 75, "095654": 50, "095781": 3, "095785": 47, "09603": 103, "096245": 75, "096337": 61, "096418": 47, "096550": 56, "096616": 75, "096688": 51, "096741": 53, "09682314": 77, "096915": 69, "097": 67, "097157": 69, "09719253": 78, "097468": 52, "09779675": [92, 102], "097796750": [92, 102], "098": 43, "098256": 66, "09830758": 68, "098308": 68, "098317": 63, "098319": 66, "0986": 41, "098712": 66, "09879814e": 78, "099": 67, "099001": 51, "09914": 78, "099307": 51, "099647": 65, "099670": 63, "099731": [50, 51], "09980311": [92, 102], "09988": 106, "0_": 25, "0ff823b17d45": 44, "0x1747bdd4520": 45, "0x1747bdd6b90": 45, "0x2920d7b7150": 65, "0x7f224ec26cf0": 69, "0x7f9c7e93dd30": 93, "0x7f9c7ece6030": 77, "0x7f9c7ed15370": 77, "0x7f9c7ee95a00": 77, "0x7f9c7f0c0950": 76, "0x7f9c7f0c1820": 76, "0x7f9c7f2285c0": 108, "0x7f9c7f2ccd40": 77, "0x7f9c7f2fe270": 98, "0x7f9c7fcb19a0": 92, "0x7f9c7fcb1e50": 92, "0x7f9c7ff5ecf0": 76, "0x7f9c854657c0": 92, "0x7f9c85467950": 92, "1": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107], "10": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 26, 27, 29, 39, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 103, 105, 106, 108], "100": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 26, 28, 29, 42, 44, 50, 51, 53, 55, 58, 59, 61, 64, 69, 70, 71, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 105, 107], "1000": [8, 10, 40, 48, 49, 53, 54, 56, 57, 58, 59, 60, 62, 63, 67, 68, 69, 72, 75, 77], "10000": [39, 50, 51, 54, 62, 63, 66], "100000e": 63, "100044": 57, "1000925": 78, "100154": 60, "100356": 52, "10038": 68, "100385": 60, "10039862": [70, 77], "100517": 92, "100715": 50, "10079785": 77, "100807": [50, 51], "100858": 68, "10089588": 66, "100896": 66, "10092": 63, "100923": 66, "100_000": 64, "101": [18, 19, 20, 41, 67, 75, 77, 106, 107], "1011704": 78, "10126": 63, "10127930": [92, 102], "101279300": [92, 102], "1015": [43, 62], "1016": [18, 19, 20, 41], "1016010": 43, "1018": 63, "102": [73, 75, 77, 105, 107], "10235": 63, "10258": 63, "102616": 52, "102775": 52, "10299": 62, "103": [50, 61, 67, 70, 75, 77, 107], "1030204": 78, "10307": 92, "1031": 63, "103189": 63, "10348": 62, "103497": 66, "1038": 63, "103806": 52, "103951906910721": 52, "103952": 52, "10396": 62, "104": [43, 62, 70, 75, 77, 107], "10406": 63, "104087": 50, "1041": 41, "10414": 63, "1045303": 42, "104787": 61, "104849": 50, "105": [25, 42, 61, 75, 77, 107], "1050": 69, "105318": 66, "1054": 44, "1055": 41, "10578593": 78, "106": [44, 75, 77, 107], "10607": [45, 73, 105], "10618": 63, "1062131": 78, "10637173e": 78, "106391": 92, "106595": 77, "106691": 75, "106746": 66, "107": [44, 69, 75, 77, 107], "107073": 52, "107295": 92, "1073": 63, "107413": 50, "10747": [45, 73, 105], "107872": 75, "10799": 63, "108": [75, 77, 103, 106, 107], "1080": [26, 29, 41, 42, 61], "10824": [45, 73, 105], "108257e": 63, "108259": 47, "10831": [45, 73, 105], "10878571": 66, "108786": 66, "109": [50, 75, 77], "109005": 66, "10903": 62, "109069": [92, 102], "109079e": 66, "109273": 61, "10928": 63, "1093": 55, "109454": 63, "109470": 51, "1096": 41, "10967": 62, "109811": 58, "109861": 105, "1099472942084532": 48, "10e": [52, 66], "11": [12, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 105, 108], "110": [75, 77, 107], "1101": 63, "11019365749799062": 69, "110194": 69, "110359": 61, "110365": 69, "110681": 68, "1107": 63, "11071087": [70, 77], "110717": [92, 102], "1109": 63, "110902": 52, "110902411746278": 52, "111": [51, 75, 77, 107], "1111": [16, 17, 27, 40, 42, 49, 55, 61, 69, 72, 77, 93, 98, 103], "111164": 65, "11120": 63, "1118": 43, "11199615e": 78, "112": [44, 75, 77, 107], "1120": 62, "11208236": [71, 79], "1121800": 78, "1122": 63, "112216": 52, "1127779": 78, "1129": 63, "113": [16, 75, 77, 78, 107], "113207": 66, "113270": 52, "113415": 63, "11375": 63, "113780": 61, "114": [75, 77, 107], "11409": 62, "11414": 62, "1144500": 42, "11447": 68, "114530": 56, "1145370": 42, "114570": 51, "11458": 63, "114647": 52, "1147": 41, "1148": 63, "114834": 63, "11488": 63, "11495": 63, "115": [75, 77, 107], "11500": [62, 108], "115060e": 66, "1151610541568202": 60, "115296e": 63, "115297e": 62, "1155142425200442": 60, "11552911": 68, "11559": 63, "115636": 51, "11570": 62, "115792e": 63, "115972": 50, "116": [75, 77, 107], "116027": 52, "11617": 63, "116274": 52, "116569": 63, "1166": 106, "1167": 62, "11673": 63, "11675": 63, "117": [50, 75, 77], "1170": 68, "11700": 108, "117072": 56, "117112": 51, "117242": 66, "11724226": 66, "117366": 66, "11743": 108, "11750": 63, "1176": 41, "1177": [41, 62], "117710": 52, "11778369": 78, "11792": 43, "11796": 63, "118": [75, 77], "11802": 63, "1182": 43, "11823404": 69, "118255": 66, "1186": 43, "118601": 61, "11861": 43, "1187339840850312": 61, "11879": 63, "118799": 63, "118938e": 77, "118952": 61, "119": [69, 75, 77, 107], "11932": 63, "11935": 68, "119669": 77, "119766": 66, "1198": [42, 61], "12": [15, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 56, 57, 58, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 103, 105, 106, 107, 108], "120": [53, 60, 70, 75, 77, 107], "12002": 62, "1202": 106, "120468": 66, "12046836": 66, "120567": [56, 57], "120721": 61, "12097": [16, 17, 27, 42, 55, 61, 72, 103], "121": [63, 75, 77, 107], "1210": 63, "12101": 63, "12105472": [92, 102], "121054720": [92, 102], "1211": 63, "1213405": 42, "121399": 63, "1214": [92, 102], "121584e": 66, "121711": 63, "121774": 58, "121824": 51, "12196389e": 78, "122": [18, 19, 20, 41, 67, 73, 75, 77, 106, 107], "12214": 43, "12223182e": 78, "122324220": 78, "122408": 52, "122777": 92, "122932": 64, "123": [32, 43, 44, 62, 64, 69, 75, 77, 107, 108], "1230": 63, "123192": 69, "12323": 63, "1234": [39, 40, 41, 45, 48, 49, 67, 72, 76, 78, 92, 102], "123457026": 78, "12348": 69, "1238": 63, "123917": 63, "124": [75, 77], "12410": 63, "124306": 60, "1243823": 78, "124480": 60, "124805": 62, "124825": 51, "125": [75, 107], "12500": 62, "125065": 92, "12539340": [92, 102], "1255": 63, "12579": 63, "1258": 42, "126": [75, 107], "12606": 63, "12612": 63, "126777": 92, "126802": 63, "12689": 63, "127": [18, 64, 75, 107], "127006": 63, "12705095": [79, 92], "12707800": 42, "1272404618426184": 60, "12752825": [92, 102], "127563": 68, "1277": 64, "127778": 63, "128": [43, 75, 107], "12802": 43, "12814": 63, "128300e": 51, "128312": 66, "128408": 61, "1285": 41, "12861": 63, "128651": 51, "129": [61, 75, 107], "12945": 106, "1295": [41, 63], "129514": 63, "12955": 62, "129606": 50, "129798": 50, "1298": 63, "12980769e": 78, "12983057": 77, "13": [19, 20, 22, 24, 40, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 63, 66, 67, 68, 69, 71, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 105, 108], "130": [44, 56, 61, 75, 107], "130122": 68, "13034980e": 78, "130370": 52, "130526": 75, "1306": 68, "130829": 66, "13091": 63, "1309844442144665": 60, "131": [75, 107], "13102231": 77, "131024": 60, "13119": 68, "1312": 108, "131211": 63, "1313": [43, 108], "13137893e": 78, "1318": 41, "132": [44, 50, 61, 75, 107], "13208": 108, "1321": [62, 108], "1324": [43, 62], "132454": 54, "1325": 43, "132671": 52, "13288": 62, "132903": 63, "132907542": 78, "132982": 50, "133": [44, 73, 75, 106, 107], "13300": 63, "133202": 63, "133421": 63, "13356": 63, "133596": 66, "13398": 69, "133f5a": 64, "134": [61, 70, 75, 107], "1340371": 41, "1341": 43, "134146": 63, "1342": 63, "134211": 66, "1343": 62, "134542": 50, "134567": 63, "1346035": 43, "134687": 63, "13474": 63, "134765": 63, "134784e": 50, "1348": 62, "1349": 68, "13490": 63, "135": [44, 75, 77, 107], "13505272": 42, "135142": 51, "135329": 58, "135344": 47, "135352": 5, "135379": 92, "135665": 51, "135707": 76, "135755": 75, "135856": 66, "13585644": 66, "135871": 61, "136": [45, 61, 69, 75, 107], "1360": 43, "13602": 69, "136089": 61, "1361": 63, "136102": 50, "136178": 77, "1362430723104844": 60, "13642": 63, "136442": 61, "1366": 64, "136836": 61, "137": [18, 44, 45, 75, 107], "1371": 63, "137213": 51, "137396": 66, "137529": 77, "1378": 63, "137809": 77, "138": [75, 107], "1380": 62, "138068": 56, "13809": 63, "138264": 69, "138378": 52, "1386": 41, "13868238": [92, 102], "138682380": [92, 102], "138698": [92, 102], "1387": 41, "138851": 56, "13893": 63, "138953": 47, "139": [69, 75, 105], "1390": 62, "139117e": 50, "139491": [92, 102], "13956": 68, "139582e": 12, "1398": 63, "1399": 41, "139921": 75, "14": [40, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 56, 57, 58, 60, 61, 62, 63, 66, 67, 68, 69, 71, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 105, 106, 108], "140": [53, 63, 70, 75, 107], "1400": 63, "14000073": 78, "140073": 50, "140081": 60, "1401": 41, "140770": [50, 51], "140833": 52, "140861": 42, "140926": 66, "141": [63, 75, 107], "141002": 51, "141098e": 63, "14114": 68, "1411881": 78, "14129666": 78, "141384": 58, "14141": 63, "141460": 47, "141530": 64, "141546": [92, 102], "141820": 52, "142": [75, 107], "14200098": [92, 102], "142119": 50, "142270": 54, "142382": 50, "1424": 76, "14268": 77, "14281403493938022": 76, "14289": 63, "143": [73, 75, 107], "143342": 51, "143495": 75, "1435": 63, "143534": 50, "14368145": [92, 102], "144": [75, 107], "14400": 62, "14405": 63, "14406": 63, "144084": 52, "1441": 41, "144137": 53, "144241": 56, "1443": 63, "144500e": 63, "144669": 66, "1447": 63, "144800": 52, "144861": 62, "144908": 65, "145": [75, 107], "145027": 47, "145245": 66, "14532650": [92, 102], "145625": 66, "145748": 92, "14587": 63, "146": [75, 107], "146037": 66, "146087": 105, "146142808990006": 52, "146143": 52, "14625": 63, "146435": 51, "1465": 43, "146641": 92, "14667": 63, "1468115": 42, "146916272941465154596367828389949799": 78, "14691627294146515459636782838994979925111424262830313740424358606175859698172123333949505256576264667172747690939537101213192034363844474865737879808691": 78, "1469162729414651545963678283899497992511142426283031374042435860617585969881518222532354553556869707781848788921001721233339495052565762646671727476909395": 78, "14691627294146515459636782838994979925111424262830313740424358606175859698815182225323545535568697077818487889210037101213192034363844474865737879808691": 78, "1469162729414651545963678283899497998151822253235455355686970778184878892100172123333949505256576264667172747690939537101213192034363844474865737879808691": 78, "146973": 52, "1469734445741286": 52, "147": [75, 107], "147015e": 63, "14702": 45, "147121": 66, "14744": 63, "14772": 63, "1479": 63, "14790924": [92, 102], "147909240": [92, 102], "147927": 45, "14798": 63, "148": [75, 107], "14803": 63, "148134": [50, 51], "148161": 66, "148443": 75, "14845": 45, "1485": 63, "148750e": [62, 63], "148790": 63, "148802": 63, "149": [64, 75, 78, 107], "1492": 39, "149215e": 51, "149228": 69, "149285": 66, "149472": 69, "149714": 61, "14984": 63, "149858": [13, 75], "149882": 77, "149898": 66, "14992160": 78, "15": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 17, 40, 42, 43, 44, 47, 49, 50, 51, 52, 53, 56, 58, 59, 60, 61, 62, 63, 66, 67, 68, 69, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 105, 108], "150": [25, 44, 69, 75, 107], "15000": [43, 62], "150000": 43, "15000000000000002": [52, 63, 66, 76], "150000e": 63, "15016319": 78, "1502": 42, "150200": 61, "150334": 63, "150408": 42, "150614": 45, "150719e": 62, "151": [75, 107], "151047e": 56, "151063": 50, "15113": 63, "151636": 52, "151819": 66, "15194": 62, "152": [75, 107], "152034": 63, "152148": [50, 51], "152353": 51, "15285": 63, "152896": 60, "152926": 54, "153": [69, 75, 107], "1530959776797396": 52, "153096": 52, "153119": 52, "153314": 51, "15347": 63, "15354": 68, "153587": 61, "153633": 45, "153639": 78, "153935": 51, "154": 75, "15430": 108, "154421": 92, "1545": 63, "154557": 66, "154758": 92, "154828": 52, "154890": 60, "155": [75, 107], "155000": 62, "155025": 66, "155120": 66, "155160": 47, "155174": 47, "155516": 65, "15556": 63, "1557093": 42, "156": [75, 107], "1560": 63, "156021": 66, "156169": 51, "156202": [50, 51], "156317": [50, 51], "1564": [92, 102], "156545": 92, "156684": 51, "1569": 63, "156969": 52, "157": [51, 75, 107], "157091": 92, "157154": 50, "1576": 63, "157733": 60, "1577657": 42, "157e": 77, "158": [62, 75, 107], "158007": 66, "15815035": 43, "158178": 52, "1582": 63, "1586": 63, "158697": [92, 102], "1589": 63, "15891559": 66, "158916": 66, "159": 107, "15916": 41, "159386": 68, "1596": 44, "159633e": 51, "159841": 50, "159959": 63, "16": [3, 39, 40, 42, 43, 44, 47, 50, 51, 52, 57, 58, 61, 62, 63, 66, 67, 68, 69, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 105, 108], "160": [53, 70, 107], "1604": 43, "160932": 52, "161": [39, 44, 106, 107], "161049": 51, "161141": 61, "161198": 65, "161236": 66, "161243": 66, "161269": 50, "161288": [51, 60], "161543": 63, "1619": 43, "162": 107, "16201": 63, "16211": 62, "162153": 66, "1622": 63, "16241": 63, "162436": 69, "162593": 60, "1626685": 42, "162683": 69, "162710": 52, "162784": 77, "1628": 62, "162930": 63, "163": [63, 107], "163194": 66, "163566": 63, "163577": 47, "163816": 47, "163895": 52, "164": [47, 67, 107], "164034": 92, "164608": 66, "164617": 62, "164698": 58, "1648": 41, "164801": 66, "164805": 52, "164864": 61, "165": 107, "16500": 62, "165178": 66, "16536299": [92, 102], "165362990": [92, 102], "16539906e": 78, "1654": 63, "165419": 66, "165549": 105, "165707": 47, "16587": 62, "16587686": 78, "16590": 63, "16597": 63, "166": 107, "1661": 62, "166238": 60, "166375": 75, "167": [43, 62, 107], "16725": 63, "167547": 66, "167581e": 50, "1676": 63, "167765": 63, "167993": 92, "168": 107, "16803512": [92, 102], "168089": 60, "168092": 92, "1681": 41, "168195": 68, "1683": 62, "168614": 66, "168931": 66, "169": [44, 107], "1691": [41, 63], "16910": 63, "169117": 69, "169196": 66, "169230e": 52, "16951": 63, "1698331": 78, "16984": 63, "17": [40, 42, 43, 44, 50, 51, 58, 61, 62, 63, 66, 67, 68, 69, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 105, 108], "170": 107, "1704": 63, "170709e": 51, "17083": 63, "171": 107, "1712": 106, "1714": 43, "171575": 66, "171815": 76, "171833": 51, "171848e": 50, "171942": 63, "172": [67, 107], "172022": [92, 102], "172083": 51, "1721233339495052565762646671727476909395": 78, "1724": 78, "1726092": 78, "172628": 60, "172793": 66, "173": 107, "173504": 57, "17372": 63, "1738": 63, "17385178": 76, "173969": 92, "173e": 67, "174": 107, "174106": 68, "174185": 66, "174499": [92, 102], "174516e": 66, "17453": 63, "1746": 63, "174743": 75, "174835": 51, "174940": 75, "17499": 63, "175": 107, "1751": 62, "175176": 66, "17522": 63, "175284": 52, "175369": 51, "175635027": 42, "17576": 63, "175894": 69, "175931": 77, "176183": 64, "176495": 66, "17655394": 66, "176554": 66, "176929": [92, 102], "177": [106, 107], "177007": 66, "17700723": 66, "177043": [50, 51], "1773": 63, "1774": 41, "177463": 65, "177496": 66, "177611": 66, "177740": 50, "177751": 66, "17778": 63, "177830": 51, "17799": 63, "177995": 66, "178": [58, 107], "178169": 56, "178218": 51, "17823": 44, "178704": 92, "178763": 66, "178934": 92, "179": [56, 107], "179026": 51, "1795850": 42, "179588e": 66, "179777": 51, "1798913180930109556": 64, "18": [40, 42, 43, 44, 45, 50, 51, 58, 59, 61, 62, 63, 66, 67, 68, 69, 73, 75, 76, 77, 78, 92, 102, 105, 108], "180": [53, 64, 70, 107], "180143": 47, "18015": 63, "180176e": 63, "180190": 77, "180262": 51, "1803": 41, "18030": 63, "180575": [56, 57], "1807": [41, 63], "1809": 106, "180951": 66, "181": 107, "1812": 63, "1814": 41, "18141": 63, "181446": 92, "182": 107, "1820": 41, "182427": 51, "182633": 66, "182849": 66, "183": [44, 77, 107], "183339": 50, "183373": 77, "183526": 52, "183553": 67, "18356413": 77, "18368": 63, "183855": 76, "183888": 61, "184": [44, 106, 107], "184247": 50, "184347": 51, "185": [43, 44], "18500": 63, "185130": 67, "1853561": 78, "1855": 63, "185585": 75, "185984": 50, "186": [63, 107], "18604": 63, "1862": 41, "186237": 51, "18631": 63, "18637": 103, "186589": 47, "18666": 63, "186735": 66, "18678094e": 78, "186836": 66, "187": 107, "187153": 92, "187664": 50, "187690": 66, "1876913": 78, "18789": 63, "188": [39, 107], "188175": 66, "1881752": 66, "188223": 66, "188400": 51, "1887": 77, "18888149e": 78, "188882": 51, "188991": 92, "189": [44, 67, 107], "189195": 63, "189248": 50, "189293": 63, "1895815": [26, 42, 61], "189737": 66, "189927": 63, "189998": 66, "19": [39, 40, 42, 43, 44, 50, 51, 60, 61, 62, 63, 66, 67, 68, 69, 75, 76, 77, 78, 92, 105, 108], "190": [44, 107], "19000": 63, "190096": 92, "19031969": 66, "190320": 66, "19033538": 42, "190381": 77, "190648": 8, "19073905e": 78, "190809": 66, "190869": 75, "190892": 69, "1909": [26, 42, 61], "190915": 52, "190921": 57, "190976": 67, "190982": 66, "191": [44, 106, 107], "191192": 50, "1912": 106, "191223": 51, "1912705": 72, "191294": 51, "191320e": 62, "191397": 75, "191606": 62, "191716": 63, "1918": 41, "192": 107, "1922": 63, "192240": 92, "192505": 65, "192526": 68, "19252647": 68, "192539": [14, 75], "192587": 66, "192952": 47, "193": 107, "193060": 66, "193253": 50, "193285": 50, "193308": [14, 75], "193341": 51, "19374710e": 78, "19382": 63, "193849": 67, "19385": 63, "193f0d909729": 44, "194": [59, 63, 107], "194092": 50, "1941": 43, "19413": [62, 63], "194303": 51, "194601": 53, "195": 107, "19508": 69, "19508031003642462": 69, "19509680e": 78, "195377": 66, "195396": 66, "195547": 63, "195564": 61, "19559": [43, 62], "195761": 66, "195781": 50, "1959": 106, "196": 107, "196189": 66, "196437": 63, "196478e": 51, "19680840": [92, 102], "196e": 32, "197": 107, "1970": 63, "197000e": 63, "19705": 63, "197225": [45, 73, 105], "1972250000001000100001": [44, 73, 105], "1974": 63, "197424": 76, "197484": 92, "19756": 63, "19758": 63, "197600": 54, "197711": 63, "197920": 50, "19793": 63, "19794": 63, "198": 107, "198218": 61, "19824": 63, "198351": 66, "198503": 67, "198549": 45, "198687": 43, "1988": [40, 49, 72, 77], "198953": 75, "199": 107, "1990": [43, 62, 63], "1991": [43, 62, 63, 108], "199281e": 66, "199282e": 63, "199412": 51, "199458": 92, "1995": [42, 61], "1998": 64, "19983954": 70, "199893": 56, "1999": [64, 70], "1_": [52, 66], "1e": [1, 3, 5, 6, 8, 9, 10, 13, 14, 15, 63], "1f77b4": 54, "1x_4x_3": 54, "2": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 32, 33, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 92, 93, 94, 95, 98, 99, 100, 101, 102, 104, 105, 106, 107], "20": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 22, 23, 24, 26, 27, 28, 40, 42, 43, 44, 50, 51, 52, 53, 56, 58, 59, 61, 62, 63, 66, 68, 69, 70, 71, 72, 75, 76, 77, 78, 79, 92, 93, 98, 105, 108], "200": [21, 24, 25, 41, 52, 53, 55, 59, 65, 66, 70, 72, 76, 107], "2000": [15, 17, 43, 47, 50, 51, 52, 62, 63, 66, 70, 77], "20000": [43, 62], "20000000000000004": [52, 63, 66], "200000e": 63, "200049": 50, "200065": 47, "20010": 63, "200110": 63, "2003": [16, 106], "200303": 105, "2005": 53, "20055": 63, "2006": 63, "20073763": 59, "20074": 63, "201": [44, 63, 107], "2010": [42, 61], "2011": [42, 61, 103, 105], "2013": [55, 92, 102, 106], "2014": [92, 102, 106], "2015": [25, 106], "201528": [50, 51], "20158": 63, "2016": 64, "2017": [23, 106], "201768": 61, "201788e": 63, "201796": 58, "2018": [16, 17, 27, 28, 40, 42, 43, 49, 53, 55, 59, 61, 62, 63, 68, 72, 78, 92, 102, 103, 106, 107], "2019": [21, 44, 50, 51, 52, 56, 57, 63, 66, 68, 76, 79, 81, 86, 91, 103, 105, 106], "201e": 67, "202": 107, "2020": [5, 6, 18, 19, 20, 22, 24, 41, 44, 53, 69, 76, 77, 93, 95, 106], "2020435": 42, "2021": [26, 41, 42, 44, 50, 51, 61, 106, 107], "20219609": 42, "2022": [68, 69, 77, 93, 95, 101, 103, 106], "2023": [29, 70, 77, 79, 87, 88, 106], "2024": [39, 48, 64, 67, 69, 77, 103, 106], "202603": 51, "202650e": 52, "20269": 63, "20274": 63, "202846": 51, "203": [43, 50, 62, 107], "203284": 52, "20329": 63, "2036": 63, "203828": 63, "203893": 75, "204": 107, "204007": 66, "20400735": 66, "204362": 69, "204455": 51, "204482": 66, "204626": 47, "204653": 75, "204794": 66, "205": [67, 68, 107], "205187": 52, "205224": 68, "205938": 61, "206": 107, "2061": 63, "206253": [62, 63], "2064": 63, "206614": 66, "207": [67, 77, 107], "207222": 62, "2075": 41, "207834": 51, "20783816": 42, "207840": 57, "207912": 92, "208": [47, 107], "208034e": 63, "2080787": 42, "20823898": 42, "2086": 63, "209": 47, "209014": 66, "209219e": 68, "209257": 5, "209546e": 63, "209894": 66, "21": [16, 17, 27, 40, 42, 43, 44, 50, 51, 55, 61, 62, 63, 66, 68, 69, 72, 75, 76, 77, 78, 92, 103, 105, 106, 108], "210": [19, 20, 24, 47, 64], "2103": [63, 103], "2103034": 42, "210319": [50, 51], "210323": 66, "2104": 107, "2107": 106, "21078": 63, "211": [47, 67, 107], "21105": [44, 76, 103, 105], "2112": 69, "21142": 63, "211534": 52, "21155656": 66, "211557": 66, "212": [47, 107], "2122": 63, "21257396e": 78, "212844": 61, "212863": 50, "213": [47, 64, 67, 106, 107], "213026": 63, "213070": 51, "213135": 51, "2134272": 78, "21361": 63, "213743e": 51, "2139": 22, "214458": 60, "214764": 68, "215": 47, "215069": 66, "215342": 66, "2155": 63, "21550": 63, "21562": 63, "21573": 63, "215967": 92, "216": 47, "216207": 76, "21624417": 42, "2163": 63, "216344": 66, "21669513e": 78, "216761": 65, "217": [47, 67, 106], "217118": 64, "21716": 63, "2171802": [42, 61], "217244": [10, 75], "218": 47, "21804": [43, 62], "218176": 47, "218383": 47, "218767": 63, "2189": 63, "218938": 63, "219": [18, 19, 20, 39, 41, 47, 106], "2191274": 42, "2197237644227434": 60, "21997": 62, "22": [40, 42, 43, 44, 50, 51, 60, 61, 62, 66, 67, 68, 69, 75, 76, 77, 78, 92, 105, 108], "220": [32, 47, 107], "220088": 63, "220398": 50, "220407": 60, "220772": 66, "221": [47, 107], "2213": 61, "2214": 61, "221419": 63, "2215": 61, "2216": 61, "2217": [42, 61], "222": 107, "2222": [40, 42, 49, 77], "22222": 63, "22272803e": 78, "222843": 66, "222882": [51, 60], "223": [64, 67, 107], "223158": 60, "22336235": 42, "223485956098176": [56, 57], "223617": 60, "22375856": 42, "22390": 62, "223928": 60, "224": [67, 107], "224897": [50, 51], "225": [41, 70, 107], "225034": 53, "22505965": 42, "22507006e": 78, "225175": 66, "225222": 66, "22522221": 66, "22528": 63, "225350": 51, "225427": 47, "225459760731946": 52, "225460": 52, "225574": 61, "2256": 63, "22562": 63, "225670": 60, "225776": 69, "226": 107, "2264": 41, "226524": 66, "226598": 61, "226938": 57, "226969": 47, "227": [63, 107], "2271071": 29, "2276": 41, "2279": 63, "227931e": 62, "228035": 63, "2281": 63, "228214": 77, "228404": 60, "228597e": 51, "228630": 51, "228648": 43, "229": [43, 107], "22925": 63, "22937": 63, "229443": 66, "229452": 77, "229472": 62, "2295": 63, "229759": 76, "2298": 41, "229961": [50, 51], "229994": [50, 51], "23": [6, 39, 42, 43, 44, 50, 51, 53, 59, 61, 62, 63, 66, 68, 69, 73, 75, 76, 77, 78, 92, 103, 105, 106, 108], "230": [41, 64], "230009": [56, 57], "2307": [42, 61, 72], "2308": 68, "230842": 50, "230956": 54, "231": [16, 107], "23113": 77, "231153": 51, "231310": 66, "231430": 92, "231467": 77, "231986": 66, "231e": 67, "232134": [50, 51], "232157": 51, "2328": 63, "232868e": 51, "232959": [56, 57], "232e": 77, "233": 23, "233029": 50, "233154": 108, "2335": 41, "233705": 51, "234": 106, "234137": 69, "234153": 69, "234205": 63, "234431": 60, "234534": 52, "234605": 45, "234798": 63, "234910": 61, "235": 107, "235291": 50, "2359": 108, "23590": 63, "236008": 52, "236015e": 50, "2362093": 78, "236309": 63, "236884": 60, "23690345e": 78, "237": 44, "237115": 51, "237200e": 50, "237252": 63, "237341": 50, "237461": 68, "23748": 63, "23751359e": 78, "237896": 66, "23789633": 66, "238": [42, 61, 107], "23805443": 78, "238101": 66, "238225": 92, "238251": 52, "238529": 9, "23856": 63, "23865373": 78, "238794": 66, "239": 107, "239243": 50, "239267": 60, "239313": 51, "23958915": 78, "23965": 63, "23e": 43, "24": [42, 43, 44, 50, 51, 59, 60, 61, 62, 63, 66, 68, 69, 70, 75, 76, 77, 78, 92, 105, 106, 107, 108], "240127": [50, 51], "240146": 51, "240295": 68, "240532": [50, 51], "2407": 41, "24080030a4d": 44, "240813": 58, "241049": 66, "241064": 51, "241596": 77, "2416": 41, "241609": 63, "241645": 51, "241678": 50, "241827": 51, "241962": 69, "24199": 63, "241e": 67, "242": 106, "242000": 63, "242124": [62, 63], "242139": 92, "242158": [62, 63], "2424596822": 57, "242710": 64, "242815": 92, "242902": 66, "243": 39, "2430561": 41, "243246": 66, "24372106": 78, "2438": 63, "2439": 63, "243e": 67, "244": [32, 63], "244090": 63, "2443286": 78, "244455": 66, "244622": 92, "24469564": 105, "245": [106, 107], "245062": 66, "2451": 41, "24510393": 43, "245370": 61, "245512": 66, "245531": 50, "245720": 54, "246": 107, "246624": 75, "246731": 62, "2467506": 42, "246753": 66, "246879": 66, "247": [67, 107], "247020": 52, "247057e": 66, "2471": 63, "2472": 63, "247617": 75, "247717": 63, "24774": [62, 63], "247826": 61, "247977": 50, "248171": 66, "248638": 52, "249": [42, 61, 64, 107], "2491": 63, "24917": 63, "249986": 60, "25": [14, 15, 18, 19, 20, 24, 25, 26, 27, 42, 43, 44, 50, 51, 52, 54, 55, 59, 60, 61, 62, 63, 66, 69, 70, 75, 76, 77, 78, 92, 105, 108], "250": [64, 107], "2500": 63, "25000000000000006": [52, 63, 66], "250073": 63, "250210": 52, "2503": 63, "250354": 66, "250425": 52, "251": [63, 68], "251101": [75, 76], "25111424262830313740424358606175859698": 78, "251114242628303137404243586061758596988151822253235455355686970778184878892100172123333949505256576264667172747690939537101213192034363844474865737879808691": 78, "251412": 51, "251480": 51, "251953": 63, "252133": 63, "252253": 68, "25240463": 77, "252524": 66, "252601": 92, "253026": [50, 51], "2532": 63, "253437": 65, "253724": 66, "25374": 63, "254": [63, 107], "25401679": 42, "254035": 60, "254038": 57, "254083": 51, "2543": 63, "254324": 52, "254400": 92, "255": [63, 107], "255034e": 51, "255995": 50, "256": [63, 76], "256002": 77, "256416": 66, "256567": 61, "25672": 63, "256944": 66, "256983": 12, "256992": 63, "257019": 51, "257207": 42, "257377": 54, "257523": 50, "258083": 51, "258158": [50, 51], "2583": 63, "258522": 50, "258541e": 15, "258951": 66, "259164": 51, "259395": 58, "2594": [43, 62], "259828": [50, 51], "259875": 51, "25x_3": 54, "26": [42, 43, 44, 45, 50, 51, 53, 59, 61, 62, 63, 70, 73, 75, 76, 77, 78, 92, 105], "26016": 63, "260161": [13, 75], "260211": [50, 51], "260356": 62, "260360": 66, "261": 67, "2610": 63, "2613": 63, "261520": 47, "261624": [62, 63], "261685": 63, "26175": 63, "261777": 63, "261903": 61, "2619317": 42, "262423e": 63, "262621": 61, "262829": 78, "263": [16, 63, 107], "2633": 63, "263942e": 51, "263974e": 66, "264": [106, 107], "264086": 54, "264274e": 63, "264884": 63, "265": 107, "2651": 77, "265119": 65, "2652": [44, 62, 63], "265547": 63, "265744": 60, "2658": 57, "265929": 67, "266": 107, "266147": 67, "266686": 50, "266922": 92, "267": [39, 64], "2670691": 42, "267500": 61, "267581": 63, "267950": 66, "268": 107, "268055": 63, "268343": 60, "2686065": 78, "268628e": 51, "268942": 66, "268943": 50, "268998": 43, "269043": 66, "26957766": 78, "269977": 63, "26bd56a6": 44, "26e": 43, "27": [19, 20, 24, 40, 42, 43, 44, 45, 50, 51, 53, 59, 61, 62, 63, 70, 73, 75, 76, 77, 78, 92, 105, 106], "270": 107, "2700": 44, "270644": [50, 51], "271": 107, "271004": [62, 63], "271083": 63, "272296": 63, "272332e": 50, "272408": 51, "272662": 63, "272953570": 78, "273": 44, "273299": 51, "273356": 52, "2735": 78, "27371": [43, 62], "27372": [43, 62], "274": [44, 63], "2740991": 41, "274247e": 62, "274267": 61, "27429763": 77, "274793": 66, "274825": [14, 75], "27487": 63, "2754": 41, "275596": 92, "276": [44, 107], "276148": 66, "276189e": 61, "2764": 63, "2766091": 43, "27713": 63, "277299": 45, "27751": 63, "277512": 51, "277561e": 61, "277968": 66, "278": [68, 107], "2780": 42, "278000": 61, "278035": 47, "278391": 63, "278434": 56, "278522": 47, "2786": [92, 102], "278804": 51, "279": 107, "27951256e": 78, "27986": 63, "279933e": 51, "28": [42, 43, 44, 50, 51, 55, 58, 59, 61, 62, 70, 75, 76, 77, 78, 92, 105, 107], "280196": 57, "280454dd": 44, "280514": 92, "280963": 65, "281": [67, 107], "281024": 66, "28111364": 43, "2815": 63, "2818": 41, "2819": [92, 102], "282": [67, 106, 107], "282200": 57, "2825": [103, 105], "28251": 63, "282870": 63, "2830": [103, 105], "283041": 50, "283207": 50, "28326": 63, "28330449": 78, "283386": 50, "2836": 41, "2836059": 42, "28382": 63, "283974": 66, "283992": 50, "283994": 66, "283e": 67, "284": 107, "28425026": 68, "284271": 58, "284397": 108, "28452": [43, 62], "2849": 63, "284987": 63, "285": [67, 77, 107], "285e": 67, "286": 107, "286027": 75, "286203": 50, "286371": 50, "2865": [41, 63], "286507": 52, "286563e": 63, "286593": 63, "287041": 66, "287196": 50, "287815": 68, "287926": 66, "288": 64, "288006": 62, "288976": 63, "289": 106, "289357": 51, "289440": [50, 51], "29": [12, 42, 43, 44, 50, 51, 59, 61, 62, 68, 70, 75, 76, 77, 78, 92, 105], "290": 77, "29034596": 78, "290565": 51, "290736e": 51, "290987": 62, "291": [63, 67], "2910": 63, "291008": 50, "291011": 77, "291071": 66, "29107127": 66, "291405": 66, "291406": 66, "291434": 51, "291500e": [62, 63], "291517": [50, 51], "291963": 66, "292": 65, "292028": 52, "292047": 92, "292105": 66, "29216514": 78, "292178": 62, "292302995303554": 52, "292303": 52, "2925": 44, "2927": 63, "292997": 66, "29299726": 66, "293218": 66, "293617e": 63, "294067": [50, 51], "294449": 50, "295": 106, "29512483": 78, "295307": 50, "295481": 66, "29548121": 66, "295837": [45, 73, 105], "2958370000000100000100": [44, 73, 105], "2958370001000010011100": [44, 73, 105], "2958371000000010010100": [44, 73, 105], "296228": 63, "296729": 61, "29678199": [71, 79], "296901": 50, "297287": [50, 51], "2973": 63, "297349": [56, 57], "297682": 66, "297687": 63, "297749": 63, "29784405": 68, "298": [23, 44], "298076": 50, "298120": 52, "298228e": 63, "299": [44, 67], "299537": 57, "299712": 56, "2999": 47, "2_": [29, 70, 93, 95, 101], "2_x": [29, 70], "2d": [79, 86], "2dx_5": [52, 66], "2e": [39, 41, 42, 43, 44, 76, 77, 79, 92, 105], "2f": 58, "2m": [93, 98, 101], "2n_t": 54, "2x": 66, "2x_0": [21, 50, 51, 56, 57], "2x_4": 54, "3": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 27, 32, 33, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 103, 104, 105, 106, 107], "30": [21, 39, 40, 42, 44, 47, 48, 49, 50, 51, 52, 53, 59, 61, 62, 63, 64, 66, 67, 70, 75, 76, 77, 78, 92, 105], "300": [40, 49, 52, 63, 66, 72, 106], "3000": 47, "30000000000000004": [52, 63, 66], "300031": 50, "30031116e": 78, "300892e": 51, "30093956": 68, "301": 44, "301366": 92, "301371": 66, "3016": 62, "301737": 50, "30189": 63, "302149": 50, "302357": 66, "302382": 60, "302571": 75, "302648": 61, "303007": 50, "303324": 61, "303489": 66, "303613": 66, "30361321": 66, "30383": 63, "303835": 61, "303f00f0bd62": 44, "304130": 66, "304159": 66, "304201": 54, "305133": 75, "30527": 63, "305341": 66, "305612": 61, "305775": 66, "305b": 44, "306297": 50, "30645": 63, "30672815": 42, "306915": 61, "306963": 66, "307407": 66, "308": 63, "3085402": 78, "308568": 51, "3086445": 78, "308774": 50, "30917769": [56, 57], "309539": 60, "309772": 61, "309823e": 63, "30982972": 66, "309830": 66, "31": [42, 43, 44, 47, 50, 51, 59, 61, 62, 63, 70, 75, 76, 77, 78, 92, 105, 108], "310000e": 63, "310145": 60, "310761": 65, "311": 67, "311253": 63, "311321": 51, "311667": 51, "311712": 56, "3120": 63, "312652": 67, "313": 77, "313056": 92, "313209": 52, "313324": 63, "31337878": 63, "313535": 66, "31378": 44, "314": 78, "3141": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 42, 44, 45, 61, 71, 73, 75, 76, 79, 92, 102, 105], "314247": 69, "314341": 50, "3146": 15, "314625": 51, "314651": 56, "31476": [62, 63], "315031": 69, "315036": 50, "3151": 63, "315155": 51, "315223": 47, "315290": [56, 57], "315310": 50, "315769e": 50, "316": 44, "316193": 66, "31632": 63, "316407": 77, "316540": 61, "316717": [50, 51], "316826": 50, "316863": 51, "317394": 54, "317487": 66, "317607": 66, "318": 44, "318000e": 63, "318438": 63, "318552": 63, "318584": 92, "318753": [56, 57], "319": 44, "319100": [56, 57], "319759": 66, "319850": 66, "31989820": 78, "32": [42, 43, 44, 50, 51, 59, 60, 61, 62, 63, 70, 75, 76, 77, 78, 79, 92, 105], "320": 63, "320314": 62, "320633": 52, "321686": 92, "322186e": 50, "32236455588136": 53, "322404": 68, "322751": 51, "323": 64, "3234": 63, "323622": 62, "323679": 61, "324": [43, 63], "324476": 47, "324518": 65, "32458367": 42, "3245837": 66, "325056": 66, "325090": 63, "325486": 50, "325599": 50, "326": 67, "326148": 51, "326721": 51, "326740": 66, "326871": 69, "3268714482135234": 69, "3271597": 78, "327257": 50, "327803": 75, "328471": 50, "329339": 53, "329371600": 78, "32950022e": 78, "33": [42, 43, 44, 50, 51, 56, 59, 60, 61, 62, 63, 70, 75, 76, 77, 78, 92, 105, 106], "3300": [43, 62], "330068": 50, "330100": 50, "330143": 66, "33014346": 66, "330163": 51, "330285": [50, 51], "3304269": 42, "33049044": 78, "330615": 66, "330731": [14, 75], "331365": 56, "331521": 66, "331602": 63, "33175566": 66, "331756": 66, "332502": 51, "332782": [14, 75], "3329": 63, "332996": 61, "3333": [40, 42, 49, 75, 76, 77], "3333333": 44, "33335939e": 78, "3335": 63, "333575": 62, "333655": 50, "333704": 51, "333955": 51, "334": 43, "334649": 58, "334750": 52, "33500": 63, "335176": 63, "33543": 78, "335446": 47, "335609e": 66, "335846": 66, "335853": 63, "336382": 51, "336461": 63, "336612": 54, "337": 64, "337380": 66, "3376": 41, "337619": 53, "338": 68, "33849": 63, "3386": 78, "338603": 50, "338775": 52, "338908": 52, "339269": 68, "33928": 63, "339443": 51, "339570": 66, "339875": [56, 57], "34": [40, 41, 42, 43, 44, 50, 51, 57, 59, 61, 62, 63, 68, 70, 75, 76, 77, 78, 92, 108], "340": [43, 63], "340029": 51, "3400642": 78, "340274": 68, "341336": [10, 75], "341472": 60, "341755e": 50, "3420": 63, "342362": 47, "342467": 75, "342632": 60, "342675": 42, "34287815": 68, "342989": 63, "342992": 61, "343": [63, 67], "343685": 50, "343828": 50, "344212": 108, "344305": 58, "344505": [62, 63], "344640": 66, "34475": 62, "344753": 47, "344787": [50, 51], "344834": 54, "3448768": 78, "345065e": 63, "345381": 52, "3453813031813522": 52, "3454": 63, "345852": 51, "345903": 66, "345989": 50, "346206": 66, "346238": 68, "346269": 51, "346678": 65, "346964": 50, "347310": [14, 75], "347696": 52, "34769649731686": 52, "347929": 63, "348": 67, "348319": 51, "34858240261807": 53, "348617": 66, "348622": 67, "348700": 51, "348980e": 51, "349": 108, "3492131": 41, "349383": 61, "34943627": 59, "3495114": 78, "349638": 51, "34967621": 42, "349772": 57, "34e": 78, "35": [43, 44, 50, 51, 52, 61, 62, 63, 64, 66, 75, 76, 77, 78, 92, 93, 98, 108], "3500000000000001": [52, 63, 66], "350165": 76, "350208": 50, "350518": 66, "350712": [56, 57], "35077502": [93, 98], "351003": 78, "351220": 51, "351629": 63, "351766": 65, "352": [43, 61], "352250e": 62, "352259e": 63, "3522697": 42, "352813": [75, 76], "35292": 63, "352990": 63, "352998": 63, "353": 39, "353105": 15, "353412": 66, "35341202": 66, "35365143": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "353748e": 66, "3538": 41, "354": 63, "354188": 54, "354371": 66, "354688": 11, "355065": 47, "355209": 66, "355651": 51, "356136e": 63, "356167": 57, "356183": 63, "35620768e": 78, "3564": 63, "3565": 63, "3568": 77, "357": 63, "357170": 50, "35731523": 77, "358158": [62, 108], "3582207": 78, "358289": 61, "358395": 68, "358799": 92, "358977": 62, "359": [67, 108], "359100": 63, "359161e": 50, "35924100": 78, "3593": 68, "359307": 51, "35th": 106, "36": [43, 44, 50, 51, 61, 62, 75, 76, 77, 78, 92], "360004": 66, "360065": 92, "360249": 58, "360475": [50, 51], "360572": 51, "360655": 63, "360683": 52, "360801": 52, "361": 67, "361518": 52, "361518457569366": 52, "361521": 11, "3619201": 22, "362157": 50, "36231307e": 78, "363276": 42, "364221": 50, "3643": [92, 102], "364595": 42, "3647": 44, "364800": 66, "36501": 63, "365551": 51, "36557195e": 78, "36566025e": 78, "366": [63, 108], "36616": 63, "366310": [50, 77], "366529": 65, "366718627": 42, "366950": 50, "367": [32, 67], "367181": 50, "367323": 66, "367398": 60, "3674277": 78, "367571": 52, "367625": 66, "368152": 61, "3682": [43, 62, 63], "368324": 61, "368499": 52, "3684990272106954": 52, "369556": 52, "3696": 68, "369796": 66, "369869": 62, "369981": 61, "37": [43, 50, 51, 61, 62, 63, 75, 76, 77, 78, 92, 108], "3702770": 42, "370736": 61, "3707775": 42, "370908": 50, "3710": 63, "37101213192034363844474865737879808691": 78, "3711353": 78, "371357": [62, 63], "371429": 52, "371850e": 51, "372": 106, "37200": [62, 63], "372097": 52, "3722": 63, "37231324": 70, "3724": 63, "3724028": 78, "372427": 51, "3727679": 42, "373218e": 60, "3736704": 78, "3738573": 42, "374364": 66, "37436439": 66, "3745": 63, "374821e": 63, "374862": 50, "37490": 78, "374917e": 50, "375081": 63, "375274": 50, "375465": 66, "375621": 60, "375844": 60, "376": 108, "376760": 51, "376806": 51, "377060": 63, "377195": 47, "377311": 66, "377669": 51, "378": 39, "378351": 8, "378588": 50, "378596": 61, "378688": 66, "378727": 50, "378834": 66, "3788859": 42, "379": 106, "379038": 66, "37939": 63, "379614": 66, "379626": 50, "379981e": 51, "38": [44, 50, 51, 62, 75, 76, 77, 78, 92], "3800694": 42, "380837": [62, 63], "381": 67, "381072": 66, "381603": 50, "381685e": [62, 63], "381689": 66, "3817": 63, "381826": 12, "382286": 63, "382582e": 3, "382684": 75, "382872": 52, "383297": 66, "383531": 60, "384": 63, "384223": 77, "384443": 51, "384677": 47, "384777": 63, "384865": 51, "384928": 50, "385013": 47, "3851": 63, "385160": 51, "385240": 92, "385615": 47, "385917": 61, "386": [44, 63], "386102": 52, "386502": 63, "386831": 47, "386988": 53, "387": 44, "3871": 41, "387426": 66, "387780": 66, "388026": 50, "388071": 66, "388185": 47, "38818693": 78, "388216e": 76, "3882638": 78, "388668": 66, "38866808": 66, "388871": 63, "389": 44, "389126": 77, "389164": 60, "38922": 77, "389566": 65, "38973512e": 78, "389755": 50, "38990574": 78, "39": [39, 41, 42, 43, 44, 45, 47, 50, 51, 53, 57, 58, 59, 61, 62, 63, 68, 69, 70, 75, 76, 77, 78, 92, 108], "39010121e": 78, "390379": 66, "391377": 69, "392128": 51, "392242": 58, "39236801": 59, "392400": 63, "392623": 51, "392752": 53, "392833": 68, "392864e": [62, 63], "392917": 50, "393060": 75, "393604": 52, "393654": 47, "3939186": 78, "394226": 51, "39425708": 42, "395076e": 63, "395136": 61, "395268": 75, "395569": 50, "395603": 50, "3958": 77, "395889": 63, "396": [32, 77], "39611477": 43, "396173": 56, "39621961e": 78, "396300": 56, "3964": 63, "396531": 63, "396985": 61, "396992": [50, 51], "397140": 52, "397155": 51, "397179": 47, "39727": 63, "397313": 41, "397536": 60, "397578": 58, "397811": 68, "398": [73, 105], "3985": 63, "3987093": 78, "398770": 66, "398999": 75, "399": 43, "399056": 66, "399223": 54, "399343e": 50, "399355": 54, "399692": 66, "399858": 69, "3cd0": 44, "3dx_1": [52, 66], "3e1c": 44, "3ec2": 44, "3f5d93": 64, "3x_": 66, "3x_4": [52, 66], "4": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 19, 20, 24, 29, 32, 33, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 105, 107], "40": [42, 50, 51, 52, 53, 60, 62, 63, 66, 70, 73, 75, 76, 77, 78, 92, 93, 98, 108], "400": 61, "4000000000000001": 76, "40000000000000013": [52, 63, 66], "40029364": [93, 98], "400823": 66, "400855956463958": 52, "400856": 52, "401": [16, 108], "401247": [79, 92], "40127723e": 78, "401690e": 51, "401931": [56, 57], "402077": 63, "402113": 92, "402301e": 76, "402571": 64, "402902": 63, "403": 67, "403425": 66, "403626490670169": 71, "4036264906701690": 71, "403626491": 71, "403715": 3, "403771948": 79, "4039": 41, "404267": 50, "404300": 47, "404318": 41, "404411": 50, "40452": 63, "404550": 65, "405050": 51, "405203": 54, "405374": 63, "40583": 41, "405890": [14, 75], "406": 62, "406285": 66, "406446": 52, "4065173": 78, "40676": 41, "407": [39, 67], "407558": 50, "407565": 50, "408476": [93, 98], "40847623": [93, 98], "408479": 61, "408509": 51, "408539": 66, "408565": 66, "4088207": 78, "409": 64, "409154": 41, "4093": 68, "409328": 63, "409395": 66, "409746": 52, "409848": [50, 51], "41": [47, 50, 51, 62, 63, 75, 76, 77, 78, 92, 102, 108], "410100": 50, "410393": 52, "410667": 75, "410681": 54, "410682": 50, "410795": 61, "41093655": 78, "411146e": 51, "411190": [50, 51], "411291": 65, "411295": 66, "411304": [50, 51], "411447": 63, "411582": 66, "411768": 51, "412004": 56, "412127": 66, "412304": 69, "412477": 54, "412653": 61, "412714": 52, "412726": 51, "412941e": 51, "413247e": 50, "41336": 76, "41341040": 42, "413608": 66, "414": 67, "414073": 9, "4142456": 78, "414533": 51, "41525168e": 78, "415375": 50, "41566": 77, "415812": 108, "415988": 63, "416052": 47, "416132": 51, "4166": 63, "4166667": 44, "416757": 66, "416899": 50, "416919": 51, "416e": 67, "417640": 50, "417736": 60, "417767": [56, 57], "417822": 62, "417834": 47, "41798768e": 78, "418": 32, "418056": 66, "41805621": 66, "41836": 62, "418360": 62, "418741": 47, "418806e": 52, "41918406e": 78, "419371": 66, "4197069": 78, "419871": 47, "41989983e": 78, "4199952": 42, "41e5": 44, "42": [5, 6, 24, 39, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 63, 65, 66, 68, 69, 70, 75, 76, 77, 78, 92, 102, 106, 108], "4200": 63, "420316e": 63, "420608e": 68, "42073312": 42, "420967": 52, "421083": 41, "4211349413": 42, "421163": 50, "421200": 69, "421234": 75, "421297e": 51, "421357": [56, 57], "421576e": 63, "421596540": 78, "421793": 68, "421919": 63, "422007": 68, "422266": 63, "422293e": 75, "422325": 52, "422561": 47, "422591": 51, "42338": 63, "4235839": [56, 57], "42388745": 70, "423921e": 75, "423951": 41, "424108": 52, "424127": 78, "42412729": 42, "424292": 50, "424328": 66, "424651": 77, "424717": 52, "424748": 69, "425": 61, "425103": 41, "425208": 63, "425493": 41, "42550": 63, "426055": 41, "426540": 61, "426540301": 42, "426736": 63, "427": 63, "427486": [50, 51], "42755087": 68, "427551": 68, "427573": 61, "427725": 66, "428": [92, 102, 108], "428046": 65, "42811700": 108, "428255": 66, "428411": [62, 63], "428467": 66, "4284675": 66, "428771": [14, 75], "4290": 41, "429057": 51, "429230": 50, "429705": 50, "42ba": 44, "43": [39, 43, 47, 50, 51, 75, 76, 77, 78, 92], "430298e": [62, 63], "430595": 51, "430608": 50, "43093681": 78, "431": 39, "431061e": 50, "4311947070055128": 76, "431253": 60, "431306": 66, "431701914": 103, "431998": 47, "432125e": 62, "432300e": 66, "43231359e": 78, "4326052": 78, "432707": 67, "43294": 44, "432f": 44, "433": [44, 67], "433221": 52, "4336": 63, "43374433": 70, "433750": 50, "433753": 60, "4339": 41, "434121": 60, "434519": 75, "434535": 66, "43453524": 66, "435": 44, "43503345": 77, "43511": 63, "435401": 61, "4357": 63, "435927": 63, "435967": 61, "43597565": 66, "435976": 66, "436": [44, 63], "436016": 60, "43627032": 53, "436327": 63, "436394": 60, "436764": 67, "436806": 63, "436817": 60, "437767": 62, "437924": 63, "438": 61, "438219": 66, "438289": 63, "438569": 63, "438578e": 63, "438709": 62, "43883": 57, "438834": 51, "4389": 63, "438960": 61, "439401e": 51, "439541": [62, 63], "439675": 67, "439699": 47, "43989": 75, "439958": 60, "43f0": 44, "44": [47, 50, 51, 53, 75, 76, 77, 78, 92], "440320": 63, "440364": 75, "440605": 76, "440747": 50, "440a": 44, "441153": 66, "441209": 66, "441219": 56, "44124313": 77, "441282": 50, "4416552": 42, "441676": 47, "441849": 50, "443016": 52, "443032": 62, "44312177": 43, "443686": 66, "4437": 63, "443701": 58, "443e": 67, "444046": 63, "4444": [40, 42, 49, 77], "444500": [62, 63], "444850": 63, "4449272": 63, "445": 67, "445476": 50, "44563945e": 78, "446166": 64, "4461928741399595": 52, "446193": 52, "4462": 44, "44647451": 68, "44713577e": 78, "447492": 63, "447624": [50, 51], "447706": 52, "447849": 53, "448": 63, "448252": 51, "448456e": 51, "448569": 50, "448587": 52, "448745": 66, "448842": 51, "4489": 63, "44890536": 78, "448923": 58, "449107": 6, "449150": [14, 75], "44950": 63, "44fa97767be8": 44, "45": [47, 50, 51, 52, 56, 58, 60, 62, 63, 66, 75, 76, 77, 78, 92], "4500": 62, "45000000000000007": [52, 63, 66, 76], "450031": 60, "450152": 61, "450812e": 51, "450870601": 42, "451312e": 50, "452": 44, "452091": 63, "452114": 75, "452488701": 42, "452489": 61, "452623": 51, "453": 44, "453279": 50, "4535": 63, "4539": 44, "454081": 63, "454397": 66, "454406": 47, "45467447": 78, "455": 44, "45500": 63, "455078": 52, "455091": 51, "455107": 52, "455120": 66, "4552": 44, "455293": 52, "4552b8af": 44, "455448": 68, "455672": 63, "455981": 93, "456370": 61, "456458e": 50, "456552": 75, "4566031": 92, "45660310": 92, "4567": 68, "456892": 52, "457088": 66, "457667": 63, "457775e": 64, "458114": 63, "458307": 95, "458420": 63, "4584447": 42, "458784": 50, "458855": 43, "4592": 42, "459200": 61, "459383": 52, "459418": 51, "459436": 60, "45957837": 78, "459760": 63, "459812": 52, "46": [47, 50, 51, 58, 59, 75, 76, 77, 78, 92, 102], "460": [39, 63], "4601": 63, "460207": [50, 51], "460218": 52, "460289": 66, "460535": 75, "4610": 108, "461227e": 50, "461629": 69, "461646": 47, "462321": 12, "462451": 52, "462567": 51, "462979": 50, "463": 39, "463325": 66, "4634": 63, "463418": 69, "463668": 63, "463766": 57, "463857": 63, "463903": 51, "463b": 44, "464": 77, "464076": 52, "464284": 61, "46448227": 78, "464668": [10, 75], "465": 47, "46507214": 68, "465424": 60, "465649": 69, "465730": 69, "4659651": 71, "465965114589023": 71, "4659651145890230": 71, "466047": 66, "46618738": 78, "466440": 52, "466756": 66, "467": 63, "46709481": 78, "46722576e": 78, "467613": 61, "467613401": 42, "467681": [50, 51], "467770": 52, "468072": 51, "468075": 66, "46807543": 66, "46811985": 66, "468120": 66, "468406": 63, "468907": 47, "468919": 63, "468d": 44, "469": 44, "469474": 69, "469825": 52, "469895": 51, "469905": 51, "47": [43, 47, 50, 51, 53, 62, 68, 75, 76, 77, 78, 92, 107], "470055": 51, "470904": 50, "471": 47, "471435": 67, "471622": 50, "472": 63, "47222159": 70, "472255": 63, "472699": 51, "472891": 66, "472e": 44, "473099": 52, "47319": 77, "47419634": 105, "474214": [56, 57], "474731": 75, "474846": 62, "475304": 63, "475517": 60, "475569": 50, "475e": 67, "476856": 52, "477130": [50, 51], "477150": 66, "477247": 51, "477357": 67, "477474": 61, "47759584": 78, "47761563": 53, "478032": 63, "478059": 51, "478064": 51, "4781": 63, "47857478": 78, "479655": 60, "47966100e": 78, "479722": 51, "479744": 64, "4798500": 78, "479860": 63, "479876": [56, 57], "479882": 51, "479928": 66, "47be": 44, "48": [44, 47, 50, 51, 57, 62, 63, 64, 75, 76, 77, 78, 92], "480": 47, "480133e": 66, "48029755": 68, "480579": 51, "48069071": [71, 79, 92], "480691": [79, 92], "480800e": 66, "481172": 66, "481218": 63, "481399": [62, 63], "481705": 77, "481761e": 63, "482": [44, 47], "482012": 56, "482038": 52, "48208358": 66, "482084": 66, "482179": 50, "482461": [93, 98], "48246134": [93, 98], "482483": 66, "482616": 60, "482790": 54, "482898e": 51, "48296": 68, "483": [67, 77], "48315": 68, "483186": 54, "483192": [62, 63], "48331": 68, "4835": 63, "483711": 66, "483717": 52, "48390784": 77, "48404": 42, "484303": 51, "4845": 63, "484640": 66, "4849": 44, "485": [44, 63], "485197": 50, "48550": 69, "485617": [62, 63], "485747": 64, "485812e": 63, "48583": [62, 63], "485871": 57, "486": [25, 63], "486178e": 50, "486202": 52, "486532": 66, "48661": 63, "487": [47, 63], "487467": 63, "487641e": 66, "487793": 51, "487872": 48, "488394": 50, "488460": 63, "488485": 63, "48873663": 53, "488811": 66, "488909": [62, 63], "488982e": 52, "4895498": 66, "489550": 66, "489699": 52, "489951": 51, "49": [44, 47, 50, 51, 75, 76, 77, 78, 92], "490000e": 63, "490070931": 42, "49040": 78, "490488e": 62, "490504e": 63, "490700": 66, "490941": 63, "491034": 50, "491245": 61, "49135": 15, "4915707": 77, "492": 63, "4923156": 71, "49231564722955": 71, "492315647229550": 71, "492417e": 77, "492656": 51, "49270769e": 78, "493": [67, 77, 106], "493102e": 60, "493144": 69, "493219": 66, "493313": 63, "493325": 5, "493426": 67, "494": 67, "494089": 51, "494129": 66, "494324": 61, "494324401": 42, "495": 65, "495108": 60, "49530782": 42, "495657": 52, "495752": 66, "49596416e": 78, "496": 65, "49650883": 68, "496551": 66, "496714": 69, "496777": 108, "49693": 76, "497": 65, "497168": 60, "497298": 75, "497422": 51, "497655": 6, "497674": 53, "497964": 75, "497995": 64, "498": 65, "498286": 60, "498921": 66, "498979": 63, "498982": 64, "498992": 50, "498f": 44, "499": [63, 65, 73, 105], "499000e": [62, 63], "499776": 63, "49d4": 44, "4a53": 44, "4b8f": 44, "4dba": 44, "4dd2": 44, "4e": [42, 43], "4ecd": 44, "4fee": 44, "4x": 66, "4x_0": [21, 50, 51, 56, 57], "4x_1": [21, 50, 51], "5": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 104, 105, 107], "50": [14, 42, 44, 52, 54, 57, 59, 60, 62, 63, 64, 66, 75, 76, 77, 78, 92], "500": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 22, 23, 27, 36, 40, 44, 45, 49, 50, 51, 56, 57, 59, 62, 65, 67, 68, 72, 73, 75, 76, 77, 79, 92, 93, 98, 102, 105, 108], "5000": [33, 50, 51, 52, 66], "50000": 61, "500000": [62, 63], "5000000000000001": [52, 63, 66], "500084": 66, "500267": 58, "5003517412": 42, "500517": 66, "50093148e": 78, "501018": 64, "501021": 63, "501047e": 50, "501983": 66, "502005": 64, "502016": 60, "502084": 77, "502205": 50, "502494": 52, "5025850": 42, "502595": 51, "502612": 66, "502901": 51, "502995": 66, "503": 32, "503374": 60, "503504": 76, "503511": 63, "503700": 47, "50398782e": 78, "504286": 61, "5042861": 42, "504548e": 51, "5050973": 42, "505264": 50, "505353": 51, "506050": 50, "506644": 50, "506659": 63, "506687": 63, "50672034": 42, "506900e": 66, "506903": 52, "507": 67, "50768b": 64, "508153": 65, "508433": 50, "508459": 61, "5085": 63, "508947": 77, "509059": 63, "509196": 66, "509461": 66, "50967": 69, "5097": 69, "5098": [45, 73, 105], "509853": 66, "5099": [44, 45, 73, 105], "509951": 52, "509958": 61, "51": [41, 43, 44, 56, 60, 75, 76, 77, 78, 92, 107], "510000e": [62, 63], "510121": 50, "510385": 61, "510555": 47, "51079110": 42, "510982": 62, "511022": 75, "511257": 60, "511293": 62, "511515": 63, "511540": 63, "5115547": 71, "5115547181877": 71, "51155471818770": 71, "511665": 50, "511668": 69, "5116683753999614": 69, "511862": 66, "512": 61, "512108": 66, "512149": 66, "51214922": 66, "51243406e": 78, "512519": 61, "512572": 66, "512672": [77, 93, 98], "5131": 62, "513992": 66, "514": 44, "514173": 51, "514545": 63, "515031": 50, "515338e": 50, "515358": 52, "5154": 63, "5154789948092002": 61, "5155": 44, "515672": 51, "515950": 77, "516": 44, "516125": 52, "516222": 66, "516242": 51, "516255": 66, "516256": 66, "516528": 66, "516797": 51, "516945": 47, "517": [44, 61], "517279": 51, "5175": 63, "517753": 50, "518175": 61, "518375": 51, "518446": 63, "518478": 47, "518782": 63, "518846": 61, "51966955": 42, "519710": 66, "52": [41, 44, 58, 60, 67, 75, 76, 77, 78, 92], "520": 63, "520415": 50, "520641": 68, "520930": 52, "521002": 52, "521085": 75, "521233": 47, "521611": 51, "521632": 50, "521788": 50, "522753": 11, "522835": 54, "523030": 69, "523163": 52, "5232": 59, "52343523e": 78, "523794e": 66, "523807": 65, "523977545": 42, "52424539": 42, "524657": 66, "524934": [50, 51], "5250": 63, "525064": 47, "52510803": 43, "5251546891842586": 69, "5255": 44, "525722": 50, "52590": [43, 62], "526": 61, "526102": 77, "526532": 63, "526769": [50, 51], "526984": 51, "527226": 50, "52732": 76, "527452": 51, "527540": 50, "528381e": 70, "528580": 66, "528763": 51, "528937": [56, 57], "528996901": 42, "528997": 61, "529": 61, "529405": 41, "529782": 41, "5299600": 78, "53": [41, 44, 47, 73, 75, 76, 77, 78, 92, 103, 106], "530793": 50, "530940": 66, "53094017": 66, "531": 44, "531223": 52, "531594": 63, "53209683": 77, "532266": 52, "53257": 76, "532738": 66, "53273833": 66, "532751": 56, "5329": 63, "533": 67, "533489": 54, "533900": 66, "5346": 44, "535179": 66, "535318": 66, "535609": 63, "535718e": 63, "53606675": 66, "536067": 66, "536082": 47, "536143": 63, "536219": 47, "536746": 66, "536778e": 51, "536798e": [62, 63], "537240": 66, "53724023": 66, "53791422": 77, "538": 44, "538013": 63, "538105": 51, "5382": 68, "538937": [62, 63], "539455": 66, "539475": 66, "53947541": 66, "539491": [56, 57], "539767": 52, "54": [41, 43, 44, 53, 67, 72, 75, 76, 77, 78, 92, 107], "540240": 63, "540542": 62, "5408": 41, "541": 67, "541159": 66, "54163": 68, "5416844": 71, "541684435562712": 71, "541821": 63, "541990": 63, "542": 67, "542136": 50, "542159": 51, "542170": 51, "542333": 63, "542446": 57, "542451": 66, "542560": 69, "542584": 52, "5425843074324594": 52, "542647": 66, "542671": 61, "542816": 12, "542883": [93, 98], "5428834": [93, 98], "542919": 75, "542989": 66, "543": [61, 63], "543075": 52, "543136": 52, "543358": 75, "543380": 61, "5434231": 71, "543423145188043": 71, "54350456": 78, "5436005": 42, "543691": 51, "543764": 57, "54378": 68, "543832": 66, "544097": 66, "544383": 69, "544555": 61, "544669": 56, "54483": [79, 92], "5448331": [79, 92], "54517706e": 78, "545492": 47, "54550506": 67, "545605e": 66, "545919": 63, "546266": 47, "546294": 63, "5467606094959261": 52, "546761": 52, "546953": 51, "547039": 50, "54716": 68, "547324": 51, "547431": 65, "5476": 63, "5479": 63, "547909": 63, "549109e": 63, "549645": 75, "55": [43, 44, 52, 62, 63, 66, 75, 76, 77, 78, 92], "5500000000000002": [52, 63, 66], "550242": 60, "551317": 51, "551586928482123": 52, "551587": 52, "551686": 52, "55176": 76, "5518": 63, "552": 63, "552058": 68, "552508": 63, "552694e": 50, "552727": 61, "552776": 66, "553004": 47, "55307": 76, "553522": 51, "553878": [13, 75], "553916": 63, "554076": 52, "554793e": 78, "555": 61, "555137": 51, "555150": 63, "555445": 65, "555498": 66, "5555": [40, 49], "555536": 50, "555949e": 63, "555954": 63, "556191": [50, 51], "556792": 66, "5574dcd4": 44, "557595": 61, "557731": 65, "557999": 61, "558134": [50, 51], "5584": 61, "5585": 61, "55863386": 77, "558634": 64, "558655": 52, "5589": 61, "559": 108, "5590": 61, "559144": 52, "559186": 52, "5592": 61, "559394": 66, "559522": 66, "559592e": 50, "559680": 63, "55dc37e31fb1": 44, "55e": [43, 78], "56": [44, 72, 75, 76, 77, 78, 92, 103, 106], "560135": [79, 92], "56018481": 66, "560185": 66, "5602727": 53, "560530": 51, "560689": 41, "560723": 58, "561348": 51, "5616": 62, "561711": 63, "561785": 77, "562013": 66, "56223": 68, "562288": 69, "562452": 60, "562518": 63, "5625561": 41, "562712": [50, 51], "563067": 67, "563374e": 52, "563503": 66, "563528": 63, "563673": 63, "56387280e": 78, "56390147e": 78, "564045": 66, "564073": 63, "5641": 63, "564142": 52, "564232": [50, 51], "564451": 51, "564577": 63, "565": 77, "565066": 52, "565373": 50, "566": 69, "566024": 66, "566091": 63, "566388": 50, "567004": 68, "567215": 60, "567343": 63, "567364": 51, "567529": 66, "567695": 50, "567945": [56, 57], "568111": 75, "568923": 64, "569315e": 51, "569444": 47, "569540": 51, "569590": 60, "56965663": 66, "569657": 66, "569911": 42, "5699994715": 42, "57": [44, 67, 75, 76, 77, 78, 92, 108], "570038": 52, "5700384030890744": 52, "570111": 65, "5702": 63, "570486": 41, "570562": 41, "570722": 105, "570936": 50, "571707": 75, "571778": 41, "5718": 63, "572153": 75, "5722": 62, "572408e": 51, "57245066": 66, "572451": 66, "572991": 51, "573700": 54, "574": 44, "5748": 76, "57496671": 42, "575": 17, "57525547": 78, "57572422": 68, "57576659": 78, "575810": 50, "57585824": 68, "57592948e": 78, "57599221": 68, "575e": 67, "576": 44, "5763996": 42, "57643609": 68, "577": 44, "5770": 62, "57715074": 42, "577271": 61, "577273": 50, "577647": 47, "5776971": 68, "57775704": 68, "577807": [50, 51], "577813": 50, "577e": 67, "578081": 63, "578307": 66, "578523": 61, "578557": 51, "578846e": 52, "57914935": 43, "579213": 69, "579238": 52, "579322e": 62, "579875e": 50, "57e": 43, "58": [18, 43, 62, 69, 75, 76, 77, 78, 92, 107], "5800": 63, "58000": 62, "5804": 44, "580414": 69, "580853": 50, "580922": 56, "581655": 63, "581827": 60, "581849": 51, "581896": 47, "582146": 51, "58240136": 78, "58241568": 78, "582761": 52, "583034": 56, "583195": [50, 51], "583201": 51, "5833333": 44, "583404": 62, "583534": 66, "583692": 60, "584012": 63, "584057e": 50, "584742": 57, "584849": 52, "584928": 50, "584942e": 61, "5852": 63, "585426": 78, "585793": 52, "586362": 66, "5864": 41, "5866": 63, "586719": 52, "586719493648897": 52, "586794": 50, "5868472": 42, "586921": 60, "587": 78, "587135": 51, "587292": 63, "588": 63, "588000": 75, "58812": 76, "588233": 50, "588364": 75, "588854": 50, "589147e": 60, "589248": 68, "589440": 52, "589958": 51, "59": [51, 75, 76, 77, 78, 92], "590320": 54, "5905": 62, "590736": 66, "590813": 66, "590904": 51, "590911": 52, "590991": 52, "591080": 54, "591411": 56, "591441": 3, "591741": 62, "591782": 66, "591788": 62, "59199423e": 78, "592186": 51, "592681e": 52, "593": 78, "59307502e": 78, "593648": 76, "593981": 75, "594": 17, "594241": 75, "594316e": 66, "595353": 52, "596": 63, "596069e": 63, "5962": 62, "596270": [56, 57], "5964": 59, "596460": 51, "59675337": 78, "596758": 50, "597": 43, "597098": 63, "597923": 63, "598178": 63, "59854797": 77, "5985730": 43, "59861": 63, "598761e": 51, "599208": 47, "599297": 77, "5cb31a99b9cc": 44, "5d": [52, 66], "5x_2": 54, "5x_3": 54, "5z_i": 66, "6": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 24, 25, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 103, 105, 106, 107], "60": [42, 52, 53, 63, 64, 66, 70, 75, 76, 77, 78, 92, 106], "600": 61, "6000": 63, "6000000000000002": [52, 63, 66], "600000e": 63, "600195": 50, "600254": 65, "600694": 77, "600776": 47, "600934": 75, "601": 43, "601061": 52, "601598": 61, "601783e": 51, "601984": 51, "602079": 57, "602168": 52, "602386e": 50, "602492": 50, "602587": 66, "602625529": 78, "602628": 52, "6029": 63, "604016": 63, "604111": 63, "604227": 62, "604603": 6, "604825": 63, "604841": [62, 63], "605": 63, "605195": 57, "606034": 66, "606129": 66, "606342": 52, "606759": 63, "6068": 42, "606800": 61, "606954": 52, "607264": 50, "6075": 108, "607600": 63, "607900e": 51, "608": [55, 67], "608392": 66, "60857": 41, "608818": 68, "609": 67, "609522": 60, "609575": 77, "61": [75, 76, 77, 78, 92, 107], "611": 108, "6110": 63, "611269": 61, "61170069": 67, "611859": 57, "612": [64, 67], "612792": 63, "613244": 51, "6133": 43, "613314": 52, "613408": 66, "613498": 63, "613574": 58, "613622": 51, "613691": 77, "614": 67, "61404894": 77, "614188": 61, "614201": 47, "614678": 63, "6149707": 78, "615": 47, "615498": 3, "615863": [56, 57], "616617": 51, "61669761": [93, 98], "616698": [93, 98], "616828": 63, "617": 61, "617283": 63, "6173": 44, "61771229": 67, "617877": 66, "618069": 62, "61810738": 43, "618574": 51, "618662098": 78, "618776": 53, "618881": 51, "619": 67, "6190870": 78, "619128": 51, "619177": 62, "619351": [50, 51], "619390": [50, 51], "619454": 54, "619613": 62, "619903": 51, "61e": [43, 108], "62": [3, 57, 58, 75, 76, 77, 78, 92], "620156": 66, "620874e": 77, "620995": 70, "621094": 63, "621318": 66, "62131806": 66, "621490": 66, "6215": 62, "621902": 47, "622": [63, 67], "622153": 63, "622272": 47, "6224": 42, "622750": 47, "623024": 52, "623173": 50, "623197": 62, "624": 61, "6240": 68, "62403053": 53, "6243811": 42, "624535": 76, "624764": 51, "624798": 62, "624818": 51, "624919": 63, "624988": 63, "625": [42, 61], "625159": 58, "625183": 47, "625477": 66, "625766": 56, "625767": 50, "625891": [56, 57], "626433": 66, "6266": 63, "626633": 51, "627505": [56, 57], "627560": 66, "627564": 52, "627588e": 63, "628": 67, "628069": 61, "629346": 63, "629549": 51, "629595": 15, "629740": 50, "629e": 67, "63": [42, 61, 75, 76, 77, 78, 92, 106, 107], "630150e": 66, "630880": 67, "630914": 58, "631083": 51, "63117637": 77, "631333": 66, "63141": 64, "6318": [62, 108], "632058": 61, "63245862e": 78, "632747e": 66, "632958": 65, "6330631": 92, "633433": 61, "634": 67, "63407762": 108, "634078": [62, 108], "634577": 92, "63499": 63, "635": 32, "635000e": [62, 63], "635199": [62, 63], "635768": 50, "63593298": 77, "636048": 77, "636453": [10, 75], "636575": 52, "637326": 66, "6379": 62, "638264": 66, "638461": 60, "638488": 58, "639135": 61, "63916605": 43, "639345": 63, "639580": 51, "639603": 51, "64": [57, 62, 63, 64, 67, 75, 76, 77, 78, 92, 105], "640": 63, "640334": 47, "640900": 63, "641528": 66, "641547": 66, "64154727": 66, "64197957": 66, "641980": 66, "642": 67, "6420": 63, "642016": 66, "64215574": 78, "642329": 47, "64269": 68, "642735": 62, "643133": 63, "64340": 68, "643512": 52, "643752": 66, "644113": 75, "644182": 75, "644371": 51, "644665": 52, "64476745e": 78, "644799": 54, "644985": 50, "645": 63, "645583": 47, "64579": 41, "6458": 42, "645800": 61, "646117": 51, "646937": 54, "647002": 63, "647004": 77, "647010": 63, "647196": 54, "64723": 68, "647254e": 50, "647689": 69, "647873": 66, "64797": 68, "648355": 50, "648690": 51, "648769": 51, "649": 106, "649158": 66, "649514": 50, "649738": 50, "65": [52, 58, 63, 66, 67, 75, 76, 77, 78, 92], "650": [55, 77], "6500000000000001": [52, 63, 66], "650000e": 63, "650234": 47, "650810": 63, "650867": 52, "651127": 51, "652071": 63, "6522": 106, "652312": 56, "652349": 66, "652350": 61, "652450e": [62, 63], "6527": 55, "652778": 61, "6528": 63, "6530": 63, "653820": 75, "653846": 52, "653901": [50, 51], "653991": 75, "654070e": 77, "654755": 54, "655284": 66, "6553": 108, "6554": 106, "655422": 63, "655547": 50, "65557405e": 78, "657": 44, "658": 61, "658267": 66, "658592": 51, "6586": 41, "658702": 51, "659": 44, "659245": [50, 51], "659339": 51, "659361": 47, "6593871": 41, "659423": [50, 51], "659473": 69, "659636": 52, "659735": 50, "659755": 67, "6598": 59, "659835": 51, "66": [47, 59, 64, 75, 76, 77, 78, 92, 105, 107], "660": [44, 77], "660073": 51, "660320": 57, "660479": 77, "6607402": 67, "660776": 66, "66133": 77, "661369": 65, "661388": 50, "6625": 63, "662975": 60, "663081975281988": 52, "663082": 52, "663182": 52, "6634357241067617": 69, "663529": 66, "663533": 63, "663765": 51, "664103e": 63, "664147": 63, "664276": [75, 76], "664362351": 78, "664409": 51, "664797": 50, "664824": 63, "664850": 61, "665264": 66, "66601815": 77, "666104": 66, "666307": 54, "6666667": 44, "667": 61, "667492e": 63, "667536": 66, "667614": 52, "667614205604159": 52, "667981": 50, "667985": 58, "668337": 63, "668452": 58, "668584": 54, "668981": 56, "669579": 51, "66989604": 53, "67": [39, 44, 62, 69, 75, 76, 77, 78, 92, 105], "670785": 47, "670867": [14, 75], "671224": 51, "671271": [50, 51], "67136": 63, "6716717587835648": 52, "671672": 52, "671690": 50, "6722": 44, "672234": [50, 51], "672368": 52, "6723684718264447": 52, "672384": [50, 51], "67245350": 42, "672511": 50, "673092": [50, 51], "673302": 61, "673330": 51, "67410934": 42, "6745349414": 42, "674552": 63, "67456": 69, "674609": 52, "674747": 60, "674949e": 68, "675233": 51, "675293": 65, "675625": 75, "675775": 60, "676": 39, "676405": 52, "6765": [43, 62], "676534": 92, "676641": 50, "676756": 66, "676807": 62, "677123": 50, "677614": 66, "677980": 52, "678": 67, "678117": 63, "678826": 52, "67936506": 77, "6795": 62, "679539": 61, "679789e": 50, "67ad635a": 44, "68": [44, 47, 68, 75, 76, 77, 78, 92], "680": 63, "6810775": 68, "681176": 61, "681246": 51, "681448": 63, "681521": 50, "681562": 63, "681817dcfcda": 44, "682": 77, "682122": 60, "682269": 63, "682875": 52, "683487": 51, "683581": 77, "683687": 51, "683942": 66, "683984": 11, "684": 108, "68410364": 43, "68411700": [43, 108], "684128": 51, "684142": 50, "684502": 66, "685104": 5, "685107": 66, "68554404e": 78, "68562150e": 78, "685807": 66, "686270": 51, "686627": 50, "687345": 66, "687612": 51, "687647": 66, "687697": 47, "687854": 54, "687871": 61, "6878711": 42, "688": 106, "6881643": 78, "688641": 60, "688747": 63, "688887": 77, "688918": 63, "688956": 50, "689088": [50, 51], "689188": 54, "689392": 66, "689600": 60, "689932": 50, "69": [58, 64, 75, 76, 77, 78, 92, 107], "690334": 52, "6903344145051182": 52, "691097": 50, "691136": 75, "691157": 53, "69140475e": 78, "691423": 50, "691511": 62, "691848e": 51, "691911": 75, "692297": 51, "692460": 60, "692579": 51, "692725": 66, "692907": 63, "692959": 50, "693316": 63, "693497e": 63, "693690": 63, "693796": 61, "694154": 52, "694561": 67, "694845e": 63, "694919": 61, "6950": 63, "695045": 50, "69508862": 77, "695581": 58, "69562150e": 78, "695711": 60, "695928": 50, "696011": [13, 75], "696289": [56, 57], "696770": 75, "69684828": 77, "696966": 51, "697": 61, "697000": 52, "697420": [56, 57], "697545": 66, "697616": 51, "697693": 50, "698223": 54, "698244": 54, "69840389e": 78, "698509": 50, "698651": 47, "698694": 61, "698751": 60, "699035": 66, "699082": 52, "69921": 44, "699259e": 66, "699333": 52, "699543": 47, "699616": 60, "699697": 51, "6_design_1a": 55, "6_r2d_0": 55, "6_r2y_0": 55, "6b": [92, 102], "6cea": 44, "7": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 19, 20, 24, 27, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 105, 106, 107], "70": [43, 52, 56, 62, 63, 66, 75, 76, 77, 78, 92, 107], "700": [50, 51, 55, 61], "7000000000000002": [52, 63, 66], "700015": 66, "700102": 66, "700458": 50, "701078": 66, "701088": 62, "701106": 58, "701265": 56, "701413": 63, "701672e": 52, "701841e": 57, "701866": 66, "7018663": 66, "701966": 63, "702489": 63, "703049": 50, "703772": 63, "703942": 75, "7040": 63, "704814": 50, "705090": 51, "705354": 50, "705581": 63, "7055958": 71, "705595810371231": 71, "7055958103712310": 71, "705794": 51, "70583": 68, "706056": 63, "706077": 51, "706122": 51, "706231": 75, "706430": 50, "706645": 52, "706657": 52, "706862": 6, "707125": 51, "707197": 75, "707441": 51, "707738": 51, "707868": 66, "707963e": 62, "708190": 61, "708235": 50, "708459": 66, "708472": 51, "708821": 47, "708837": 47, "709026": 54, "709596": 50, "709606": [14, 75], "71": [75, 76, 77, 78, 92, 107], "710059": 47, "710319": 51, "710515": 50, "710586e": 61, "711024": 63, "711328": 63, "711383e": 50, "711518": 63, "711638": 77, "712064": 50, "712082": 63, "712095": 47, "712157": 65, "712268": 50, "712372e": 51, "712503": 68, "712592": 62, "712774": 56, "7128877": 78, "712960": 52, "713": 63, "713407": 63, "713457": 50, "713986": 63, "713993": 51, "714240": 61, "714250": 51, "714534e": 51, "714651": 66, "71465114": 66, "715013": 63, "715180e": 63, "7154": 63, "715407": 52, "7155": 63, "7158581": 42, "716": 39, "716013e": 50, "7161": 63, "716387": 50, "716427e": 51, "716456": 66, "716595e": 63, "716762": 52, "716793": 52, "716799": 61, "7167991": 42, "716801": 60, "717": 63, "717130": 63, "717185": 66, "717860": 75, "718686": 69, "719552": 51, "71957094": 78, "72": [75, 76, 77, 78, 92, 107], "720559": 50, "720571": 66, "720573": 50, "720589": 67, "720664": 61, "721018": 50, "721071": 66, "721245": 51, "7215093d9089": 44, "72155839e": 78, "721609": 63, "722316": 66, "722634": 66, "722848": 52, "722881": 66, "7229": 63, "723": 44, "723314": 66, "723345e": 66, "723657": 50, "723846": 47, "7239": 63, "7241399": 42, "724338": 66, "724767": [56, 57], "724918": 69, "725": 44, "725061": 50, "725080": 47, "725087": 63, "725166": 66, "72524727": 78, "72528105": 78, "725565": 50, "725802": 6, "725820": 60, "725919": 50, "726": [44, 67], "726658": 60, "7268131": 42, "727159e": 51, "727543": 54, "727693": 63, "727704": 63, "727976": 52, "7282094": 77, "728294": 65, "728622904": 78, "728710": 66, "728734": 47, "72875815e": 78, "728852": 63, "728e": 67, "729867": 50, "73": [43, 47, 75, 76, 77, 78, 92], "730023": 63, "7308": 41, "730809": 50, "731174": 50, "731317": 52, "732": 67, "732067": 50, "732137": 50, "732150": 51, "732405": 62, "732586": 62, "7326": 63, "732638": 66, "73285": [10, 75], "732918": 56, "733": 63, "733047": 51, "733644": 50, "734278": 47, "734635": 50, "734770": 51, "734948": 66, "735369e": 75, "7357": 63, "735848": 75, "735941": 9, "735964": 54, "736082": [50, 51], "736084": 66, "73608412": 66, "736823": 51, "737052": 63, "7375615": 43, "73764317e": 78, "737951": [50, 51], "738065": 51, "738223": 63, "738315": 63, "738659e": 63, "738793": 75, "738876": 51, "739": 63, "739063": 50, "7395359436844482": 52, "739536": 52, "739595": 67, "739720": 63, "739817": 58, "74": [18, 43, 51, 62, 75, 76, 77, 78, 92, 107], "740": [61, 62], "740180e": 66, "740367": 50, "740417": 62, "740505": 47, "740785": 50, "740869": 52, "741104": 52, "741329": 64, "741380": 67, "741523": 47, "741702": 66, "7418": 41, "74189": 44, "742128": 66, "742375": 50, "742407": 65, "742411": 50, "742907": 66, "7432": 41, "743247": 63, "743341": 51, "743609": 50, "7437": 63, "74402577": 66, "744026": 66, "744236": 68, "74461783e": 78, "745": 63, "745022": 47, "745444": 50, "745714": 62, "745881": 50, "746361": 66, "746843": 57, "7470": 63, "747646": 63, "747945": 42, "747961": 63, "748084": 51, "748377": 62, "748513": 63, "748880": 63, "74938952": 77, "749443": 63, "749854893": 79, "75": [14, 18, 20, 44, 47, 52, 54, 62, 63, 66, 75, 76, 77, 78, 92, 102, 107], "75000": 69, "7500000000000002": [52, 63, 66], "750000e": 63, "750597": 51, "750701": 47, "751013": 63, "751261": 63, "751633": 63, "75171": 62, "751710": [52, 62], "751712655588833": 71, "7517126555888330": 71, "751712656": 71, "752015": 8, "752283": 63, "7533": 62, "753323": 50, "753393": 50, "753523": 66, "753866": 51, "754": 39, "754469": 50, "754499": 51, "754678": 60, "7548": 69, "754870": 61, "755": 62, "755688": 50, "755701e": 50, "755910": 63, "7559417564883749": 52, "755942": 52, "7560824": 42, "756200": 47, "756805": 61, "756867e": 63, "756905": 6, "756969": 52, "757": [67, 106], "757151": [50, 51], "757183": 52, "757411": 66, "757819": 61, "757917e": 66, "758391": 63, "75882468": 78, "758831": 51, "75887": 44, "759006": 53, "759054": 51, "759833": 51, "76": [75, 76, 77, 78, 92, 106, 107], "760104": 66, "7603": 41, "760386": 77, "760778": 61, "760915": 54, "761": [42, 61], "761429": 51, "761714": 52, "762284": 66, "76228406": 66, "762748": 63, "76368792": 78, "763691": 63, "764093": [50, 51], "76419024e": 78, "764315": 66, "76444177e": 78, "764478": 65, "7646": 63, "764798": 66, "764953": 62, "765": 62, "765202": 63, "765363": [50, 51], "765500e": [62, 63], "765710e": 70, "765792": 66, "765864": 68, "76591188": 42, "765960": 50, "7660": 41, "7663": 63, "766499": 66, "76686310": 78, "766940": 47, "76702611e": 78, "767125": 64, "767188": [56, 57], "767247": 75, "767349": 75, "767435": 69, "767549": 51, "767616": 47, "768071": 66, "768273": [56, 57], "768763": 51, "768798": 47, "769361": 66, "769805": 66, "77": [67, 75, 76, 77, 78, 92], "770556": 63, "770944": [56, 57], "7710": 68, "771157": 92, "771390e": 63, "7714": 64, "7716982": 43, "771741": 63, "771965": 63, "772104": 50, "77227783e": 78, "772396": 51, "772788056": 78, "772791": 63, "77289874e": 78, "773": 44, "773177": 52, "7733904": 78, "773488": 66, "77348822": 66, "773769": 60, "77401500e": 78, "774271e": 63, "775": [44, 63], "775191": [50, 51], "775285": 50, "775770": 64, "775969": 68, "776254e": 50, "7763": 62, "776728e": 61, "776887": 62, "7776071": 42, "777718": 60, "777728": 75, "777e": 67, "778": 64, "778400": 50, "7786": 41, "778852": 75, "779": 67, "779108": 50, "779167": 3, "779517": [50, 51], "779682": 52, "7799": 59, "779912": 63, "78": [67, 75, 76, 77, 78, 92, 107], "780": 44, "780068": 60, "780338": 50, "780458": 66, "780857": 62, "781": 63, "781233": 63, "781530": 66, "781681": 66, "782": 44, "782050": 66, "782117": 47, "782555": 63, "782646": 75, "783": 44, "783276": 77, "7833": 41, "7838": 41, "784": [92, 102], "784238": 61, "784405": 68, "784483": 61, "784624": 52, "784792": 60, "785": 44, "785038": 51, "785153": 51, "785815": 47, "785911": 66, "785e": 32, "786": 44, "786090": 60, "786237": 50, "786563": 60, "786744": 52, "78711285e": 78, "78777": 68, "788": 106, "78818": 44, "788868": 51, "789032": 50, "789039": 51, "789330": 51, "789671": 52, "789671060840732": 52, "79": [47, 75, 76, 77, 78, 107], "790039e": 50, "790115": 63, "790261": 75, "790723": [56, 57], "79122": 62, "791220": 62, "791241": 66, "791297": [14, 75], "792922": 64, "792939": 52, "793": 39, "793316": 75, "79338596e": 78, "793570": 66, "793598": 51, "793735": 66, "793818": [50, 51], "794": 77, "794366": 63, "79458848e": 78, "794805": 56, "795": 67, "795647": 66, "7957": 63, "795932": 76, "796014": 51, "796203": 77, "796384": 51, "796444": 63, "796596e": 50, "796e": 67, "797086": 50, "797157": 47, "797280": 66, "797737": 92, "797868": 51, "79792890e": 78, "797965": 92, "798071": 5, "798309": 62, "798783": [56, 57], "799": 64, "799403": 66, "799421": 64, "7999": 70, "7b428990": 44, "7x": 66, "8": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 105, 107, 108], "80": [52, 53, 63, 66, 70, 75, 76, 77, 78, 107], "800": 61, "8000": [29, 70], "8000000000000002": [52, 63, 66], "800143": 50, "800272": 75, "800326e": 50, "800351": 50, "801623": 63, "802": 67, "802289": 63, "803112": 60, "803300": 50, "803492e": 66, "803563": 63, "803902e": 63, "804": 63, "804219": 66, "804284": 68, "804316": 66, "804484": 66, "8048": 43, "804828": 66, "804889": 63, "805007": 61, "805153e": [62, 63], "805293": 51, "8055563": 42, "805774": 50, "8059": 62, "806218e": 63, "806531": 63, "806554": 50, "80696592e": 78, "80714504e": 78, "807879": 66, "808": [43, 92, 102], "808246": 62, "808284": 63, "808640": 63, "809": 64, "809125": 50, "8095": 64, "809913": [50, 51], "80a8": 44, "81": [42, 50, 55, 58, 59, 75, 76, 77, 78, 107], "810044": 62, "810134": 66, "8102": [41, 62], "810306": 47, "810322": 50, "810363": 63, "810382": [62, 63], "810419": 51, "810707": 63, "810895": 51, "811011": 51, "811155": 58, "811398": 75, "811513": 51, "8116912": [92, 102], "811696": 50, "811825": 61, "811901": 66, "81190107": 66, "812": 67, "8132463": 42, "813293": 66, "813342": [92, 102], "81337648": 78, "813682": 63, "814136": 52, "814246e": 51, "814351": 52, "814913": 61, "8151822253235455355686970778184878892100": 78, "8152": 63, "815213e": 51, "815224": [92, 102], "815226": 77, "81568484": 66, "815685": 66, "81568684": 78, "815993": 66, "816176": 69, "816318": 61, "816373": 50, "816645": 47, "816752": 63, "816982": 50, "817119": 50, "817291": 63, "8173602": 59, "817628": 77, "81827267": 66, "818273": 66, "818289": 66, "81828926": 66, "818313": 47, "818380": [50, 51], "81856": 44, "819507": 60, "82": [69, 75, 76, 77, 78, 107], "8202": 43, "820366": 61, "8209": 43, "820963": 47, "821": 106, "8210": 43, "821021": 52, "821457": 63, "821566": 66, "821855": 75, "821970": 60, "821995": 51, "8221": 41, "822289": [62, 108], "82228913": 108, "822482": 52, "8227": 63, "822822": 52, "823071": 64, "823247": 66, "823273": [50, 51], "824350": [50, 51], "824657": 60, "824701": 52, "824750": 52, "824889": 52, "824961e": 63, "8250": 41, "825587": 51, "825617": 61, "825801": 47, "825862": 66, "825980": 52, "8259803249536914": 52, "8260": 62, "826065": [50, 51], "826426": 77, "826467e": 50, "826492": 66, "826519": [14, 75], "82666866e": 78, "82684324": 68, "827375": 53, "827381": 66, "827445": 47, "827735": 66, "827938162750831": [56, 57], "828058": 63, "828157": 47, "828778e": 50, "828912": 50, "828915": [56, 57], "829162": 75, "829543": 52, "829730e": 51, "82985": 58, "83": [75, 76, 77, 78, 107], "830263": 60, "830301": 65, "830442": 50, "830467": 50, "830755e": 58, "831": 67, "831019": 52, "831190": 51, "831278": 50, "8315931": 78, "831741": 50, "832078": 47, "832086": 66, "8326928": 68, "832693": 68, "832875": 66, "83287529": 66, "833024": 61, "833227e": 76, "833464": 63, "833907": 61, "835": 67, "8350": 63, "835035": 60, "835596": 63, "835822": 47, "835935": 51, "836234": 77, "83785159": 78, "838114": 66, "838235": 64, "838457": 63, "83905": 5, "8391089": 78, "84": [44, 58, 67, 75, 76, 77, 78, 107], "840041": 63, "840303": 66, "84030318": 66, "840673": 50, "840718": 77, "840836": 66, "840995e": 62, "841": [42, 61], "841132": 62, "8415": 43, "841847": 63, "842132": 77, "842405": 52, "842589": 47, "842625": 61, "842746": 66, "8428": 62, "842853": 66, "843730": 61, "843796": 50, "8440": 63, "844107e": 51, "844308": 66, "844549": [56, 57], "844667": 92, "844707": 66, "844889": 61, "845241": 67, "845534": 60, "846388": 52, "847029": 51, "847555": 50, "847595": [13, 75], "847948": 52, "847962": 50, "847966": 63, "848688e": 60, "848757e": 62, "848868": 52, "849245": 47, "84930915e": 78, "849747": 68, "8497f641": 44, "8499": 63, "85": [23, 52, 58, 63, 66, 70, 75, 76, 77, 78], "8500000000000002": [52, 63, 66], "850038": 47, "850321": 61, "850439": 51, "850575": [50, 51], "850794": 66, "851": 106, "851198": 63, "8513": 44, "851366": 61, "852": 63, "85265193": 59, "85280376": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "85397773": 77, "855035": 50, "855780": 66, "855862": 51, "856404": 57, "8571": 41, "857161": 66, "857294": 47, "857544": 61, "857765": 63, "858212e": 51, "859": 63, "85911521e": 78, "85912862": 92, "859129": [79, 92], "85974356": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "85c5": 44, "85e": 43, "86": [75, 76, 77, 78, 107], "860663": [92, 102], "860804": 66, "860992": 63, "861519": 50, "862043": [56, 57], "862359": 52, "863772": 62, "863982270": 79, "864": 67, "8640921": 78, "86415573": 43, "86424193e": 78, "8644": 44, "864741e": 63, "865074": 47, "865313": 63, "865562": [50, 51], "865854": 63, "865860": [62, 63], "865914": 51, "866102": [50, 51], "866179899731091": 71, "866179900": 71, "866579": 63, "866798": 63, "867201": 60, "867565": 66, "8679": 63, "868": 44, "8685788": 66, "868579": 66, "8688": 62, "869": [44, 67, 108], "869020": 52, "869195": 51, "869398": 51, "869477": 50, "869586": 58, "87": [43, 50, 58, 61, 75, 76, 77, 78, 107], "8700": 43, "870099": [56, 57], "870142": 77, "870260": 66, "870332": 66, "870857": 66, "871": 44, "871545e": 50, "871923": 51, "872": [64, 67], "872132": 51, "872222": 63, "872727": 50, "872768": 66, "872852": 66, "87290240e": 78, "872994": 63, "87312285": 78, "873198": 63, "873677": [56, 57], "87384812361": 41, "87384812362": 41, "87430335": [92, 102], "874303353": [92, 102], "874702": [56, 57], "8750": 63, "8759": 63, "876": 67, "876083": 63, "87623301": 41, "876431e": 52, "876549": 63, "87674597e": 78, "8768": 41, "8771": 63, "877153": 63, "877455": 65, "877833": [50, 51], "878281": 66, "878289": 63, "878402": 50, "878746": 47, "878847e": 63, "878968e": 50, "879": 77, "879049": 63, "879058": 60, "879103": 52, "879509": 50, "87e": 43, "88": [43, 58, 67, 75, 77, 78], "880106": 61, "880579": 66, "880591": 65, "880808e": 63, "880880e": 63, "880886": 62, "8810": 62, "881201": 63, "88125046e": 78, "881465": 54, "881581": 9, "88173062": 42, "881937": 47, "882475": 52, "883485": 51, "883622": 66, "883914": 52, "883953": 60, "884132": 66, "8843": 68, "8845": 41, "884996": 52, "8850": 43, "885065": 66, "885832": 67, "885956": 50, "885978": [56, 57], "886041": 51, "886086": [50, 51], "886266": 63, "88629": 41, "886314": 51, "88664": 44, "887197": 47, "887345": 63, "887556": 52, "887648": 51, "887680": 50, "888146": 61, "8881461": 42, "888445": 51, "888775": 57, "888804": 63, "889": 39, "889293": 66, "8893": 62, "889300": 62, "889326": 51, "889638": 47, "889733": 66, "889792": 51, "88988263e": 78, "889913": [50, 51], "889963": 66, "88ad": 44, "89": [43, 51, 75, 77, 78, 106, 107], "890": [42, 61], "890229": 47, "89027368": [92, 102], "890273683": [92, 102], "890318": 50, "89035917": 58, "890372": [45, 73, 105], "8903720000100010000010": [44, 73, 105], "8904": 39, "890454": 76, "8909": [42, 62, 108], "891697": 62, "891752": 51, "891997": 50, "892": 44, "892648": 66, "892796": [50, 51], "893": 44, "8932105": 42, "893649": [50, 51], "893851": 66, "894": 44, "894307e": 63, "894448": 51, "89449": 62, "894490": 62, "895106": [50, 51], "895308": 63, "895333": 66, "895690": [50, 51], "895768e": 52, "896023": 66, "897220": 66, "897240": 63, "8974": 62, "897451": 50, "897495e": 51, "898722": 66, "899460": 66, "899662e": 50, "899716": 51, "8bdee1a1d83d": 44, "8da924c": 44, "8e3aa840": 44, "9": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 104, 105, 107, 108], "90": [25, 43, 52, 53, 63, 66, 70, 75, 77, 78, 107], "9000000000000002": [52, 63, 66], "900000e": 63, "900021": 76, "901013": 51, "901148": 66, "90136": 62, "901360": 62, "901526": 58, "901683": 63, "901705": 50, "902": [92, 102], "902573": 52, "903056e": 66, "903135": 75, "903339": 52, "903351e": 52, "903406": 77, "903418": 61, "903674": 50, "903681": 66, "903767": [50, 51], "904156": 52, "9041560442482157": 52, "904315": 50, "904396": 50, "905": 39, "905042": 51, "905494": 52, "905858": 69, "905951": 68, "9061": 63, "906716732639898": [56, 57], "906757": 48, "907115": 66, "907176": 66, "9073": 63, "907491": 52, "907801": 61, "90794478": [92, 102], "907944783": [92, 102], "907961": 63, "908024": 69, "908663": 51, "908767": 60, "909304": [50, 51], "90963122e": 78, "909942e": 75, "909975": 63, "909997": [62, 108], "91": [75, 77, 78, 107], "910000e": 63, "9102": 62, "910895": 51, "9109": 44, "91102953": 66, "911030": 66, "911277": 51, "911662": 56, "912230": [50, 51], "9126": [43, 108], "9127": [43, 108], "912903": 50, "913": 44, "91315015": 42, "913280": 69, "913371": 51, "913415e": 50, "913485": 63, "913774": 52, "914": 64, "9142": 63, "91438767e": 78, "9145": 41, "915": [43, 44, 62, 63], "915000e": [62, 63], "915057e": 62, "915260e": 50, "915488": [56, 57], "9158080176561963": 60, "916236": 41, "916528": 56, "9166667": 44, "916914": 66, "916930": 50, "917": 44, "917000": 51, "917066": 63, "917248": 66, "91724807": 66, "917436": 66, "918": 67, "918227": 52, "919432": 66, "9197": 63, "919969": 50, "91e": 43, "92": [75, 76, 77, 78, 107], "920052": 51, "920335": 63, "920337": 57, "920645": 63, "9209": 41, "921": 39, "9210": 63, "921061": 69, "921256e": 51, "921372": 52, "921913": 61, "921956": [50, 51], "921e4f0d": 44, "922160": 63, "922251": 50, "9223": 63, "922996": 61, "923074e": 52, "923517": 70, "923607": 66, "92369755": 42, "923804": 52, "923943": 108, "923977": 63, "924002": 66, "9243": 63, "924396": [56, 57], "92463": 62, "924630": 62, "924634": 54, "9248": 44, "924821": 52, "924843": 61, "924921": 75, "925": 53, "925248": [56, 57], "925660": 50, "925736": 52, "925957": 56, "925995": 51, "926227": 51, "926493": 62, "926621": 52, "926901": 60, "927": 40, "927074": 66, "927232": 63, "9274": 63, "927950": 63, "92827999": 77, "92881435e": 78, "928947": 61, "92905": 42, "929643": 50, "92972925e": 92, "929729e": [79, 92], "93": [43, 75, 76, 77, 78, 107], "9304028": 42, "931": [64, 72], "931479": 66, "931978": 105, "932027": 52, "932404e": 63, "9325": 41, "9327": 41, "932973": 66, "933259": 47, "933322": 51, "933671": 51, "933857": 51, "933996": 52, "934058": 50, "934068": 47, "934243": 51, "934433": [50, 51], "9345": 44, "934500": 51, "934511": [92, 102], "934549": 63, "93458": 68, "934963": 51, "934992": 52, "935": [32, 59, 77], "935591": 66, "935730": 66, "935764": 51, "935989": 61, "9359891": 42, "93648": 70, "936494": 50, "936739": 66, "937": 39, "937116": 61, "937586": 63, "938": [92, 102], "938975": [75, 76], "939068": [56, 57], "9392": 63, "939250": 50, "939458": 50, "9395": 63, "93958082416": 108, "94": [53, 59, 75, 77, 78, 107, 108], "940354721701296": 52, "940355": 52, "940373": 63, "940450": 47, "941440": 50, "941724": 63, "941788": 56, "942139": 57, "94225699": 78, "942312": 66, "942460e": 66, "942489": 63, "9425": 41, "942550": 63, "942661": 61, "942823": 63, "94309994e": 78, "943938": 66, "943949e": 66, "944149": 75, "944253e": 66, "944266": [56, 57], "944280": 63, "94441007e": 78, "944839": 47, "945881": 50, "94629": 70, "946297": 52, "946406": 57, "946433": 66, "946533": 50, "94658029": 78, "946658": 63, "946968": 52, "947": 78, "947440": 65, "947466": 76, "947613": 51, "9480": 63, "948112": 67, "948154e": 56, "948785e": 50, "948868": 63, "94906344": 42, "949241": [92, 102], "949456": 66, "949866": 51, "95": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 36, 41, 43, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63, 66, 67, 68, 69, 70, 75, 77, 78, 92, 93, 98, 107, 108], "9500": 63, "950158": 50, "950545": 48, "95062986e": 78, "951502": 66, "951532": 61, "951920": 65, "952": [43, 67, 108], "9523": 41, "952839": 66, "9534": 63, "953683": 61, "953704": 50, "95372559e": 78, "954": [92, 102], "95401167e": 78, "954536": 75, "955005e": 63, "9551": 63, "9552": 41, "955541": [14, 75], "95559917": 76, "955701": 50, "955e": 77, "956": 64, "956047": 42, "9561": 41, "956574": 63, "956724": 52, "9567242535070148": 52, "956877": 51, "956892": 63, "957229": 57, "957375": 61, "957745": 52, "9579": 43, "957996": 52, "958": [92, 102], "9580": 43, "958105": 75, "958541": 63, "959132": 51, "959384": 51, "95e": 43, "96": [43, 50, 51, 64, 75, 77, 78, 107], "9605": 63, "960808": 52, "960834": 51, "9609": 41, "961": 64, "961539": 63, "961962": 52, "962": 39, "962364": 47, "962373": 51, "962523": 47, "962954": 51, "963": 64, "963055": 63, "963427e": 51, "964025e": 66, "964065e": 51, "964261e": 61, "964318": 63, "9647": 41, "965341": 51, "965531": 77, "965696": 50, "965774": 63, "96582": 76, "966015": 66, "966097": 15, "966320": 47, "966659": 52, "9666592590622916": 52, "967092": 51, "967467": 68, "968127": 47, "968134e": 66, "968258e": 50, "968577": 53, "969141": 77, "9699": 62, "969925e": 51, "97": [3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 45, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 75, 76, 77, 78, 79, 92, 102, 105, 107, 108], "970065": 66, "970150": 51, "971058": [56, 57], "97135560": 78, "972509": 51, "972745": 50, "972748": 52, "97276281": 66, "972763": 66, "97314470": 42, "973156": 75, "973229": 51, "973241": 66, "973331": 63, "973741": 51, "973890": 51, "974202": 52, "974213": 51, "97441062": [56, 57], "974414": 52, "974487": 50, "97470872": 68, "9748910611": 42, "975": [50, 51, 56, 57, 59, 64], "975289": 47, "9753": 44, "975447": 53, "975450": 51, "975461": 61, "975592": 47, "976088": 66, "976548e": 51, "976562": 66, "977202": 51, "977280": [50, 51], "977295": 63, "977507": 51, "977820": 50, "978303": 60, "9787": 63, "978977": 66, "978997": 47, "979": 67, "979475": 50, "979702": 50, "979857": 50, "979971e": 50, "98": [50, 51, 63, 75, 77, 78, 107], "980026": 63, "9802393": 42, "980440": 51, "980643e": 52, "981104": 65, "981403": 51, "981438": 50, "981672": 52, "981715": 50, "982": 64, "982019e": 51, "982353e": 63, "982417": 52, "982720": 50, "982797": 65, "983": 64, "983192": 66, "983253": 50, "983759": 108, "98393441": 68, "984024": 65, "984083": [56, 57], "984551": 8, "984562": 66, "984866": [92, 102], "984872": [50, 51], "984914": 64, "984937": 52, "98505871e": 78, "985207": [50, 51], "985654": 51, "986383": 63, "986417": 50, "9870004": 44, "987220": 63, "987307": 60, "9875": 41, "987726": 51, "9880384": 44, "988421": [50, 51], "988463": 66, "988541": 50, "988709": 63, "988780": 63, "989937": 64, "99": [43, 47, 50, 51, 64, 75, 77, 78, 107], "990163": 64, "990210": 63, "990903": 50, "991": 44, "9914": [62, 63, 68], "991444e": 56, "9915": [43, 62, 63, 68], "991512": 43, "991963": [50, 51], "991977": 63, "991988": 50, "992": [64, 67], "99232145": 68, "992582": [50, 51], "993201": 51, "993575": 63, "994": 67, "994168239": 42, "994208": 47, "994214": 63, "994332": 48, "994377": 50, "9944": [59, 77], "994851": 63, "994937": 57, "995": 108, "995015": 63, "9951": 41, "995248": 66, "99549118e": 78, "99571372e": 78, "9961392": 42, "996313": 50, "996892": 60, "996934": 61, "9970": 63, "997034": 70, "997494": 70, "997571": 61, "997621": 52, "997934": [56, 57], "998063": 48, "99864670889": 108, "998766": 63, "9989": 62, "999": [53, 54, 58, 68, 108], "999207": 66, "9995": [50, 51, 54], "9996": [50, 51, 54], "9996553": 43, "9997": [50, 51, 54], "9998": [50, 51, 54], "9999": [50, 51, 54], "99c8": 44, "A": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 23, 24, 28, 32, 34, 35, 36, 39, 40, 41, 43, 44, 48, 49, 55, 57, 64, 65, 67, 68, 69, 72, 73, 75, 76, 77, 92, 93, 94, 95, 99, 100, 101, 102, 103, 105, 106, 108], "ATE": [9, 15, 18, 43, 45, 47, 62, 68, 69, 75, 77, 79, 85, 93, 99], "ATEs": [47, 64], "And": [64, 70, 93, 96], "As": [40, 41, 42, 43, 44, 47, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 62, 63, 64, 66, 69, 70, 71, 76, 77, 78, 79, 81, 92, 93, 95, 101, 102, 108], "At": [18, 19, 20, 42, 47, 53, 54, 58, 59, 61, 63, 66, 108], "Being": 108, "But": 59, "By": [41, 42, 61, 67, 69, 76, 77, 93, 98], "For": [1, 5, 6, 8, 9, 12, 20, 30, 31, 39, 41, 42, 44, 47, 48, 53, 58, 59, 60, 61, 63, 65, 67, 68, 69, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 99, 101, 102, 104, 105, 108], "ITE": [24, 47], "ITEs": 47, "If": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 40, 42, 49, 50, 51, 53, 59, 61, 63, 67, 72, 73, 75, 76, 77, 79, 80, 82, 83, 85, 92, 93, 95, 96, 97, 98, 100, 101, 103, 108], "In": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108], "It": [41, 42, 43, 50, 51, 55, 56, 57, 61, 62, 63, 67, 69, 76, 78, 103, 107], "No": [22, 39, 41, 43, 44, 45, 47, 53, 58, 62, 63, 67, 68, 70, 73, 76, 77, 79, 92, 105, 106], "Of": [59, 92, 108], "On": [40, 49, 60, 64, 72, 106], "One": [43, 62, 63, 69, 75, 92], "Or": 32, "Such": [69, 76], "That": [32, 108], "The": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 39, 40, 41, 42, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 85, 88, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 106, 107, 108], "Then": [20, 52, 66, 77, 92, 93, 101, 102, 103, 104], "There": [43, 62, 69, 77, 104, 108], "These": [43, 44, 46, 60, 62, 65, 67, 68, 75, 77, 108], "To": [31, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 56, 57, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76, 77, 78, 92, 93, 95, 98, 101, 102, 104, 105, 108], "With": [23, 50, 51, 76, 106], "_": [40, 42, 49, 50, 51, 52, 54, 55, 56, 57, 61, 62, 63, 65, 66, 67, 71, 72, 75, 77, 78, 79, 92, 93, 95, 98, 102], "_0": [40, 42, 49, 55, 61, 71, 72, 78, 79, 87, 88, 92, 93, 101], "_1": [18, 19, 20, 24, 64, 70, 79, 87, 88], "_2": [18, 19, 20, 24, 64], "_3": [18, 19, 20, 24], "_4": [18, 19, 20, 24], "_5": [18, 24], "__init__": 60, "__version__": 104, "_all_coef": 78, "_all_s": 78, "_compute_scor": 31, "_compute_score_deriv": 31, "_coordinate_desc": 61, "_d": [67, 77], "_est_causal_pars_and_s": 107, "_estimator_typ": 60, "_h": [67, 77], "_i": [40, 49, 66, 70, 72], "_id": 78, "_j": [18, 19, 20, 24, 26, 42, 61, 92, 102], "_l": 76, "_m": [76, 78], "_n": [79, 82, 83, 85, 92, 93, 98, 100, 102], "_n_folds_per_clust": 61, "_rmse": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "_x": 33, "_y": [67, 77], "a0": 60, "a09a": 44, "a09b": 44, "a1": 60, "a3d9": 44, "a4a147": 64, "a5e6": 44, "a5e7": 44, "a6ba": 44, "a79359d2da46": 44, "a840": 44, "a_": 70, "a_0": 27, "a_1": 27, "a_j": 77, "ab": [41, 103], "ab71": 44, "abadi": [16, 53], "abb0fd28": 44, "abdt": [45, 73, 105], "abl": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 49, 59, 63, 64, 76, 93, 95, 101], "about": [43, 59, 62, 77, 103, 105, 108], "abov": [40, 43, 47, 49, 50, 51, 56, 57, 59, 60, 62, 64, 65, 66, 67, 69, 72, 75, 76, 77, 104], "absolut": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 59, 76], "abstract": [31, 41, 42, 61, 79, 103, 107], "acc": [2, 41], "accept": [75, 76], "access": [34, 35, 41, 43, 56, 57, 58, 59, 68, 76, 93, 98, 108], "accord": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 40, 43, 47, 49, 52, 53, 62, 66, 67, 69, 70, 76, 77, 92, 93, 94, 96, 97, 99, 102, 108], "accordingli": [53, 59, 60, 62, 67, 70], "account": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 42, 43, 61, 62, 63, 68, 69, 93, 98, 101, 108], "accumul": [43, 62, 63, 68], "accuraci": [41, 77], "acemoglu": 106, "achiev": [42, 61, 65, 69, 77, 92, 102], "acic_2024_post": 64, "acknowledg": [43, 44, 62], "acm": 106, "acov": 106, "across": [43, 62, 64, 108], "action": 107, "activ": [4, 7, 104, 107], "actual": [32, 58, 69], "acycl": [70, 108], "ad": [4, 7, 16, 17, 31, 58, 73, 76, 77, 92, 93, 95, 107], "adapt": [8, 62, 107], "add": [41, 42, 45, 47, 53, 54, 56, 57, 58, 64, 66, 67, 68, 69, 70, 76, 77, 106, 107], "add_trac": 69, "addit": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 20, 24, 26, 27, 28, 33, 36, 55, 69, 76, 77, 79, 86, 93, 94, 99, 101, 106, 107], "addition": [18, 19, 47, 52, 63, 68, 76, 77, 78, 92, 93, 98, 105], "address": 69, "adel": 106, "adj": [67, 69], "adj_coef_bench": 69, "adj_est": 69, "adj_vanderweelearah": 69, "adjust": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 37, 42, 54, 61, 63, 68, 69, 75, 77, 92, 93, 98, 102, 106, 107, 108], "adopt": [53, 77], "advanc": [60, 74, 78, 106], "advantag": [40, 41, 43, 47, 49, 62, 63, 72, 104], "advers": [93, 95], "adversari": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 68, 93, 98, 101], "ae": [40, 42, 43], "ae56": 44, "ae89": 44, "aesthet": 40, "aeturrel": 28, "afd9e4": 64, "affect": [47, 55, 77, 107, 108], "after": [41, 43, 44, 53, 55, 62, 63, 69, 70, 75, 76, 93, 96, 98, 104, 108], "after_stat": 40, "ag": [43, 62, 63, 65, 68, 108], "again": [40, 41, 42, 43, 47, 49, 53, 58, 60, 61, 62, 67, 68, 69, 70, 72, 93, 96], "against": [53, 58, 59, 65, 76], "agebra": 75, "agegt54": [44, 45, 73, 105], "agelt35": [44, 45, 73, 105], "agg": 41, "aggreg": [41, 71, 78, 107], "aggregate_over_split": 32, "aggt": 41, "aim": 67, "aipw": 64, "aipw_est_1": 64, "aipw_est_2": 64, "aipw_obj_1": 64, "aipw_obj_2": 64, "air": [42, 61], "al": [16, 17, 21, 23, 26, 27, 40, 42, 43, 44, 49, 50, 51, 52, 53, 55, 56, 57, 59, 61, 62, 63, 66, 68, 72, 77, 78, 79, 81, 86, 91, 92, 93, 95, 101, 102, 103, 105, 107], "alexandr": [55, 106], "algebra": 77, "algorithm": [39, 41, 42, 44, 47, 49, 52, 53, 59, 61, 63, 66, 68, 70, 74, 76, 77, 78, 79, 92, 107, 108], "align": [40, 42, 49, 52, 54, 59, 61, 62, 64, 65, 66, 70, 107], "all": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 38, 40, 41, 42, 43, 47, 49, 53, 58, 59, 60, 61, 62, 63, 65, 67, 69, 70, 72, 73, 75, 76, 77, 78, 92, 93, 101, 102, 103, 104, 107], "all_coef": 78, "all_dml1_coef": 71, "all_s": 78, "all_smpl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "all_smpls_clust": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "all_z_col": [42, 61], "allow": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 31, 43, 47, 62, 63, 67, 75, 76, 77, 78, 79, 92, 102, 103, 107, 108], "almqvist": 106, "along": 76, "alpha": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 25, 27, 40, 42, 43, 45, 47, 49, 50, 51, 52, 55, 59, 60, 61, 62, 63, 66, 71, 72, 75, 76, 77, 78, 79, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102], "alpha_": [26, 42, 61, 76], "alpha_0": [93, 101], "alpha_ml_l": 55, "alpha_ml_m": 55, "alpha_x": [8, 22, 77], "alreadi": [20, 53, 70, 76, 77], "also": [1, 5, 6, 8, 9, 12, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 53, 56, 57, 58, 59, 60, 61, 62, 63, 65, 67, 68, 69, 72, 75, 76, 77, 78, 79, 92, 93, 95, 104, 105, 107, 108], "alter": [42, 61], "altern": [41, 43, 44, 62, 65, 74, 76, 92, 102, 103, 105], "although": 69, "alwai": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 41, 67, 107], "always_tak": [8, 43, 62], "amamb": 61, "american": [25, 64], "amgrem": 61, "amhorn": 61, "amit": [69, 106], "amjavl": 61, "ammata": 61, "among": [43, 55, 62, 63, 68, 69], "amount": [43, 60, 62, 63, 108], "amp": [39, 42, 44, 53, 61, 63, 68, 70], "an": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 24, 34, 35, 40, 41, 42, 43, 44, 47, 49, 50, 51, 55, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 92, 93, 95, 98, 102, 103, 105, 106, 107, 108], "analog": [30, 31, 42, 61, 63, 68, 75, 77, 79, 82, 83, 92, 93, 98, 102], "analys": 108, "analysi": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 33, 40, 42, 43, 49, 61, 62, 63, 72, 74, 75, 95, 98, 101, 103, 107], "analyt": [64, 66], "analyz": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 43, 62, 63, 68, 108], "ancillari": 69, "andrea": 106, "angl": 43, "angrist": 64, "ani": [39, 40, 41, 44, 48, 49, 53, 69, 70, 72, 77, 104, 108], "anna": [5, 6, 18, 19, 20, 24, 41, 53, 77, 106], "annal": [92, 102, 106], "anneal": 76, "annot": 40, "annual": 106, "anoth": [40, 41, 42, 43, 49, 59, 60, 61, 72, 76, 77], "anticip": 41, "anymor": [42, 61], "aos1161": [92, 102], "aos1230": [92, 102], "aos1671": [92, 102], "ap": [43, 62], "ape_e401_uncond": 43, "ape_p401_uncond": 43, "api": [73, 103, 107], "apo": [1, 2, 80, 94], "apoorva": 107, "apoorva__l": 64, "apoorval": 64, "app": 107, "appeal": 69, "append": [49, 59, 72], "appendix": [23, 29, 68, 70, 93, 95], "appli": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 39, 40, 42, 43, 44, 49, 53, 54, 59, 61, 62, 63, 67, 69, 70, 72, 77, 78, 79, 92, 102, 103, 105, 107, 108], "applic": [40, 49, 53, 64, 69, 72, 75, 78, 106, 108], "apply_along_axi": 65, "apply_cross_fit": [40, 78], "apply_crossfit": 107, "appreci": 103, "approach": [1, 3, 5, 6, 8, 9, 10, 13, 14, 15, 41, 42, 47, 61, 67, 68, 69, 74, 76, 78, 92, 93, 95, 102, 104, 106, 108], "appropri": [43, 55, 62, 77, 78, 108], "approx": 75, "approxim": [40, 49, 50, 51, 52, 59, 66, 69, 72, 75, 77, 92, 102, 107, 108], "apt": 104, "ar": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 30, 31, 32, 34, 35, 36, 37, 40, 41, 42, 43, 44, 46, 47, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108], "arang": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 49, 52, 54, 63, 65, 66, 68, 69, 76], "architectur": [79, 106], "arellano": 106, "arg": [60, 67, 75, 77], "argmin": 59, "argu": [40, 43, 49, 62, 63, 68, 72, 108], "argument": [1, 9, 12, 20, 26, 27, 28, 32, 33, 36, 43, 50, 51, 53, 58, 59, 62, 63, 71, 75, 76, 77, 107, 108], "aris": [40, 41, 42, 49, 61, 69, 72, 108], "aronow": 64, "around": [41, 43, 62, 63, 67, 77, 79], "arr": 65, "arrai": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 22, 23, 25, 26, 27, 28, 29, 36, 37, 47, 49, 50, 51, 52, 53, 59, 61, 64, 65, 68, 69, 70, 71, 72, 74, 75, 76, 78, 92, 93, 98, 102, 105, 107, 108], "arrang": 42, "array_lik": 14, "articl": [28, 103], "arxiv": [26, 41, 42, 61, 69, 103, 106, 107], "as_learn": [44, 76], "asarrai": [50, 51], "aspect": [43, 62, 63], "assert": 76, "assess": 41, "asset": [63, 68, 108], "assign": [4, 7, 43, 57, 62, 67, 75, 76, 77, 108], "assmput": 77, "associ": [43, 55, 62, 77, 92, 102, 106], "assum": [39, 42, 48, 53, 61, 64, 65, 69, 77, 79, 82, 83, 92, 93, 101, 108], "assumpt": [41, 42, 43, 53, 54, 59, 61, 62, 64, 67, 70, 77, 92, 108], "assur": 107, "astyp": [48, 62, 67, 69], "asymptot": [30, 31, 40, 42, 49, 61, 72, 78, 92, 106], "ate": 47, "ate_estim": 70, "ates": 47, "athei": 106, "att": [9, 18, 41, 54, 58, 65, 69, 75, 77, 79, 85, 93, 99, 107], "att_gt": 41, "attach": 41, "atte_estim": 53, "attempt": [34, 35], "attenu": [43, 62], "attr": 43, "attribut": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 32, 36, 37, 59, 60, 71, 76, 78, 79, 92], "attributeerror": [34, 35], "attrict": 77, "attrit": [15, 70, 77], "au": [44, 76, 103, 105], "auc": 41, "author": [41, 69, 103], "auto_ml": 60, "autodoubleml": 60, "autom": 60, "automat": [40, 49, 58, 72, 75, 93, 98], "automl": 107, "automl_l": 60, "automl_l_lesstim": 60, "automl_m": 60, "automl_m_lesstim": 60, "automobil": [42, 61], "autos": 55, "autosklearn": 60, "auxiliari": [40, 49, 72], "avail": [22, 41, 43, 44, 47, 53, 55, 59, 62, 63, 64, 65, 67, 69, 72, 75, 76, 77, 93, 101, 103, 104, 107, 108], "avaiv": 37, "aver": 47, "averag": [1, 2, 8, 9, 12, 18, 19, 20, 39, 41, 44, 48, 53, 54, 58, 63, 64, 65, 67, 68, 69, 70, 74, 80, 85, 92, 94, 99, 106, 107, 108], "average_it": 47, "avoid": [40, 41, 49, 67, 77, 78, 104, 107], "awai": 68, "ax": [47, 49, 50, 51, 52, 54, 56, 57, 59, 60, 61, 62, 63, 64, 66, 67], "ax1": [47, 52, 63, 66], "ax2": [47, 52, 63, 66], "axhlin": [54, 60, 67], "axi": [42, 43, 47, 55, 59, 61, 62, 64, 65, 67], "axvlin": [47, 49], "b": [5, 6, 28, 40, 42, 44, 49, 50, 51, 61, 64, 66, 67, 69, 72, 75, 76, 92, 93, 101, 102, 103, 105, 106], "b208": 44, "b371": 44, "b5d34a6f42b": 44, "b5d7": 44, "b_": 77, "b_0": 27, "b_1": 27, "b_j": 28, "bach": [69, 103, 106, 107], "backbon": 59, "backend": [4, 7, 41, 63, 68, 69, 74, 107], "backward": 107, "bad": 64, "balanc": [43, 62, 63], "band": [41, 74, 108], "bandwidth": [10, 13, 14, 32, 67, 77], "bar": [58, 60, 62, 75, 77, 79, 80, 85, 93, 94], "base": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 21, 24, 33, 37, 40, 41, 42, 43, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 92, 93, 95, 98, 102, 103, 105, 106, 107, 108], "base_estim": 67, "baselin": [24, 43, 60, 62], "basi": [1, 9, 12, 36, 50, 51, 75], "basic": [41, 42, 43, 53, 61, 62, 63, 64, 67, 68, 69, 74, 76], "batch": 44, "battocchi": 106, "bay": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 92, 102], "bb2913dc": 44, "bbotk": [44, 76, 107], "bbox_inch": 49, "bbox_to_anchor": 49, "bcallaway11": 41, "bd929a9e": 44, "bde4": 44, "becam": [43, 62, 63], "becaus": [39, 40, 41, 42, 48, 49, 57, 58, 61, 64, 69, 72, 108], "becker": [44, 76], "becom": [42, 57, 60, 61, 75, 78], "bee": 54, "been": [42, 43, 60, 61, 62, 63, 68, 69, 75, 76, 107], "befor": [41, 43, 47, 54, 58, 62, 66, 69, 77, 108], "begin": [22, 25, 26, 40, 42, 43, 44, 49, 52, 54, 59, 61, 62, 64, 65, 66, 70, 71, 73, 76, 78, 92, 102, 105, 108], "behav": 57, "behavior": [43, 64, 76], "behaviour": 57, "behind": 77, "being": [24, 29, 30, 31, 33, 42, 61, 67, 69, 77, 78, 79, 81, 92, 93, 98, 102, 103], "belloni": [23, 55, 92, 102, 106], "below": [39, 43, 48, 62, 64, 77, 104, 105], "bench_x1": 69, "bench_x2": 69, "benchmark": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 47, 58, 95, 107], "benchmark_dict": [38, 68], "benchmark_inc": 68, "benchmark_pira": 68, "benchmark_result": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "benchmark_twoearn": 68, "benchmarking_set": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 47, 58, 68, 69, 93, 95], "benchmarking_vari": 58, "benefit": [40, 43, 49, 62, 72], "bernoulli": 22, "berri": [42, 61], "besid": 105, "best": [1, 9, 12, 36, 50, 51, 56, 57, 60, 104], "best_loss": 60, "beta": [15, 22, 23, 25, 29, 43, 62, 65, 67, 70, 77], "beta_": 70, "beta_0": [21, 65, 70, 75], "beta_a": [18, 19, 69], "beta_j": [22, 23, 25, 29], "better": [41, 47, 59, 69], "between": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 39, 47, 48, 52, 54, 55, 60, 64, 66, 68, 69, 70, 77, 79, 82, 83, 85, 89, 90, 92, 93, 101, 102, 105, 107], "betwen": [39, 48], "beyond": 106, "bia": [29, 39, 48, 55, 67, 69, 70, 74, 77, 78, 79, 87, 88, 93, 101, 106, 107], "bias": [39, 43, 48, 62, 63, 68, 108], "bias_bench": 69, "bibtex": 103, "big": [55, 71, 78, 79, 83, 86, 92, 93, 96, 97, 99, 100, 101], "bigg": [42, 61, 79, 84, 85, 93, 99], "bilia": 17, "bin": [40, 47, 49, 104], "binari": [1, 3, 5, 6, 8, 9, 10, 12, 13, 15, 21, 33, 39, 41, 43, 44, 48, 53, 58, 59, 62, 64, 65, 69, 75, 76, 93, 94, 99, 107, 108], "binary_outcom": 33, "binary_treat": [21, 50, 56, 58], "bind": 107, "binder": [44, 76, 103, 105, 107], "binomi": [48, 64, 65, 66], "bischl": [44, 76, 103, 105], "black": [40, 44, 45, 73, 105], "blob": 41, "blog": 28, "blondel": [103, 105], "blp": [36, 42, 61], "blp_data": [42, 61], "blp_model": [56, 57], "blue": [40, 42, 61], "bodori": 106, "bond": [43, 62, 63], "bonferroni": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 92, 102], "bonu": [17, 44, 73, 105], "book": [44, 69, 76], "bool": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 21, 24, 32, 33, 34, 35, 36, 58, 67], "boolean": [29, 56, 57, 73, 78], "boost": [39, 43, 48, 53, 59, 62], "boost_class": [43, 62], "boost_summari": 62, "boostrap": [52, 107], "bootstrap": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 36, 47, 50, 51, 52, 56, 57, 63, 66, 74, 75, 78, 79, 103, 105, 107, 108], "both": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 19, 21, 41, 43, 44, 53, 54, 59, 60, 62, 63, 65, 67, 68, 69, 73, 76, 77, 92, 93, 95, 98, 100, 101, 107, 108], "bottom": [42, 43, 59, 61, 62, 63], "bound": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 24, 43, 47, 58, 62, 68, 69, 93, 95, 98, 101, 108], "branch": 44, "brantli": 41, "break": [40, 107], "breviti": 108, "brew": 104, "brewer": 42, "bridg": 69, "brief": 72, "bring": [39, 48], "brucher": [103, 105], "bsd": 107, "budget": [60, 76], "bug": [103, 107], "build": [42, 59, 61, 65], "build_design_matric": [50, 51], "build_sim_dataset": 41, "built": [37, 60, 76, 103], "bureau": [69, 78, 106], "busi": [26, 29, 42, 61, 69, 106], "b\u00fchlmann": 106, "c": [16, 17, 19, 20, 23, 25, 27, 39, 40, 41, 42, 43, 44, 45, 48, 49, 54, 55, 56, 57, 61, 62, 64, 67, 72, 73, 76, 77, 103, 104, 105, 106, 108], "c1": [16, 17, 27, 42, 55, 61, 72, 103, 106], "c68": [16, 17, 27, 42, 55, 61, 72, 103, 106], "c895": 44, "c_": [92, 102], "c_d": [23, 93, 99, 100, 101], "c_y": [23, 93, 101], "ca1af7be64b2": 44, "caac5a95": 44, "calcualt": 65, "calcul": [1, 9, 12, 41, 43, 47, 50, 51, 52, 56, 57, 59, 60, 62, 66, 68, 93, 98, 101], "calibr": [59, 60, 69], "call": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 39, 41, 42, 43, 44, 48, 50, 51, 52, 53, 56, 57, 61, 62, 63, 65, 66, 67, 68, 69, 70, 73, 76, 78, 79, 92, 93, 98, 101, 102, 105, 107, 108], "callabl": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 40, 49, 50, 51, 59, 74, 76, 103], "callawai": 41, "camera": 55, "cameron": [42, 61], "can": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 21, 32, 37, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 82, 83, 85, 89, 90, 92, 93, 94, 95, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108], "candid": 69, "cannot": [59, 67, 69, 77, 108], "capabl": [4, 7, 39, 48], "capo": 1, "capsiz": [47, 60, 64, 67], "capthick": [47, 67], "cardin": [42, 61], "care": 76, "carlo": [18, 19, 21, 24, 50, 51, 56, 57, 69, 106], "casalicchio": [44, 76, 103, 105], "case": [1, 4, 7, 8, 9, 17, 21, 32, 39, 42, 43, 48, 50, 51, 52, 55, 57, 58, 60, 61, 65, 66, 67, 68, 69, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 105, 107, 108], "cat": [40, 107], "catboost": 59, "cate": [9, 12, 36, 74, 107], "cate_obj": 75, "cattaneo": [77, 106], "caus": [40, 49, 67, 72], "causal": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 22, 23, 25, 26, 27, 28, 29, 32, 39, 40, 42, 43, 44, 48, 49, 61, 62, 64, 68, 70, 71, 72, 73, 74, 77, 78, 92, 93, 98, 102, 106], "causal_contrast": [2, 47, 77], "causal_contrast_model": [47, 77], "causaldml": 106, "causalweight": 106, "caution": 92, "caveat": [57, 69], "cbind": 42, "cc": 62, "ccp_alpha": [9, 37, 62], "cd": 104, "cd_fast": 61, "cda85647": 44, "cdf": 75, "cdid": [42, 61], "cdot": [18, 19, 20, 24, 33, 42, 52, 54, 58, 61, 64, 66, 67, 69, 75, 77, 79, 80, 85, 86, 87, 88, 92, 93, 94, 102], "cdot1": 58, "cell": 60, "center": 55, "central": [78, 107], "certain": [57, 77], "cexcol": 42, "cexrow": 42, "cf_d": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 38, 47, 58, 68, 69, 93, 94, 95, 98, 99, 100, 101, 108], "cf_y": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 38, 47, 58, 68, 69, 93, 94, 95, 98, 99, 100, 101, 108], "chad": 69, "chain": 57, "chainedassignmenterror": 57, "challeng": [42, 61, 93, 95], "chang": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 43, 53, 57, 63, 68, 69, 70, 77, 79, 85, 92, 93, 94, 95, 96, 97, 98, 99, 104, 106, 107], "channel": 108, "chapter": [30, 31, 44, 76, 93, 101], "charact": [43, 44, 76, 107], "characterist": [68, 108], "chart": 60, "check": [34, 35, 40, 43, 49, 59, 60, 62, 63, 71, 72, 103, 104, 107], "check_data": 107, "check_scor": 107, "checkmat": 107, "chernozhukov": [16, 17, 23, 25, 27, 40, 42, 43, 49, 55, 59, 61, 62, 63, 68, 72, 78, 92, 93, 95, 101, 102, 103, 106, 107], "chetverikov": [16, 17, 27, 42, 55, 61, 72, 92, 102, 103, 106], "chiang": [26, 42, 61, 106], "chieh": 106, "choic": [1, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 43, 55, 62, 65, 75, 76, 93, 95, 98, 101, 107], "choos": [39, 43, 48, 49, 55, 59, 62, 63, 71, 78, 79, 82, 83, 85, 89, 90, 92, 102, 105, 108], "chosen": [1, 19, 24, 59, 76, 77], "chou": 64, "chr": 43, "christian": [55, 106], "christoph": 106, "chunk": 76, "ci": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 32, 47, 50, 51, 52, 53, 54, 56, 57, 58, 60, 62, 63, 66, 67, 68, 69, 75, 77, 93, 98, 107, 108], "ci_at": 47, "ci_cvar": [52, 63], "ci_cvar_0": 52, "ci_cvar_1": 52, "ci_joint": 47, "ci_joint_cvar": 52, "ci_joint_lqt": 66, "ci_joint_qt": 66, "ci_length": 53, "ci_low": 47, "ci_lpq_0": 66, "ci_lpq_1": 66, "ci_lqt": [63, 66], "ci_pointwis": 47, "ci_pq_0": [63, 66], "ci_pq_1": [63, 66], "ci_qt": [63, 66], "ci_upp": 47, "cinelli": [69, 93, 95, 106], "circumv": 108, "citat": 107, "claim": 44, "clash": 41, "class": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 30, 31, 32, 34, 35, 36, 37, 43, 44, 45, 47, 53, 58, 60, 62, 63, 68, 70, 71, 73, 75, 76, 78, 79, 92, 103, 105, 107], "class_estim": 67, "class_learn": 63, "class_learner_1": 59, "class_learner_2": 59, "classes_": 60, "classic": [41, 42, 61, 108], "classif": [9, 39, 41, 43, 44, 59, 60, 65, 68, 75, 76, 77, 108], "classifavg": 44, "classifi": [1, 3, 5, 6, 8, 9, 10, 12, 13, 14, 15, 32, 34, 44, 47, 60, 67, 76, 107], "classmethod": [4, 7], "claudia": [106, 107], "claus": 107, "clean": 107, "cleaner": 59, "cleanup": 107, "clear": [42, 61], "clearli": 67, "clever": 59, "clone": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 39, 40, 44, 49, 59, 61, 63, 71, 76, 77, 78, 79, 92, 93, 98, 102, 104, 105], "close": [41, 43, 62, 69, 93, 95], "cluster": [1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 26, 106, 107], "cluster_col": [4, 42, 61], "cluster_var": [4, 26], "cluster_var_i": [4, 42, 61], "cluster_var_j": [4, 42, 61], "cmap": 61, "cmd": 107, "co": [28, 54], "codaci": 107, "code": [1, 9, 12, 28, 39, 41, 42, 43, 44, 48, 55, 62, 72, 75, 76, 77, 78, 79, 92, 104, 105, 107, 108], "codecov": 107, "coef": [3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 78, 79, 92, 105, 108], "coef_": 69, "coef_df": 42, "coef_valu": 60, "coeffici": [18, 19, 21, 36, 43, 56, 57, 59, 62, 64, 65, 67, 69, 70, 75, 92, 93, 98, 102, 108], "coefs_t": 65, "coefs_w": 65, "coffici": [93, 98], "cofid": 36, "coincid": [54, 63], "col": [40, 42, 57, 62], "collect": [44, 53, 61, 70], "colnam": [42, 59], "color": [43, 47, 49, 50, 51, 52, 54, 60, 61, 62, 63, 64, 66, 67, 69], "color_palett": [47, 49, 61, 62, 63], "colorbar": 61, "colorblind": 47, "colorramppalett": 42, "colorscal": [50, 51], "colour": [40, 42], "column": [4, 7, 45, 47, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 67, 68, 69, 70, 73, 75, 76, 77, 78, 105, 107, 108], "column_stack": [47, 54, 56, 57, 67, 68, 69, 77], "colv": 42, "com": [28, 41, 43, 44, 55, 62, 64, 69, 76, 104], "comb": 55, "combin": [41, 42, 44, 47, 53, 59, 60, 61, 69, 76, 78, 93, 98, 107], "combind": 63, "combined_loss": 55, "come": [71, 76, 79, 93, 95, 103, 108], "command": [104, 107], "comment": 73, "common": [59, 68, 69, 75, 77, 106], "companion": 106, "compar": [40, 42, 49, 50, 51, 52, 54, 56, 57, 61, 64, 66, 67, 69, 72, 76, 77, 93, 95], "comparevers": 43, "comparison": [47, 59, 64], "compat": [39, 41, 48, 107], "complement": 69, "complet": [60, 72, 93, 98, 104], "complex": [9, 41, 60], "compli": [67, 77], "complianc": [66, 67, 77, 79, 86], "complic": [44, 108], "complier": [43, 62, 63, 66, 67, 75, 77], "compon": [41, 43, 55, 59, 60, 62, 65, 75, 76, 78, 79, 80, 82, 83, 84, 85, 86, 89, 90, 107], "compont": 41, "composit": 106, "compris": [92, 102], "comput": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 36, 38, 40, 41, 43, 44, 49, 62, 63, 68, 69, 78, 79, 93, 94, 95, 96, 97, 98, 99, 103, 106, 107, 108], "computation": [93, 95], "concat": [60, 61, 62, 65, 92], "concaten": [54, 62, 92], "concentr": 92, "concern": 69, "conclud": [67, 69, 108], "cond": 77, "conda": [61, 106, 107], "condit": [1, 3, 9, 12, 18, 19, 21, 30, 31, 40, 42, 43, 47, 49, 53, 54, 58, 61, 62, 65, 67, 69, 70, 72, 74, 77, 92, 93, 94, 99, 101, 102, 105, 106, 107, 108], "conduct": [75, 77, 108], "conf": [41, 66], "confer": 106, "confid": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 36, 41, 42, 43, 47, 50, 51, 52, 53, 56, 57, 61, 63, 66, 67, 68, 70, 74, 75, 78, 79, 93, 98, 105, 106, 108], "confidenceband": 52, "confidenti": 69, "config": 64, "configur": [44, 60], "confint": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 36, 43, 47, 50, 51, 52, 53, 54, 56, 57, 59, 63, 65, 66, 67, 68, 70, 75, 78, 92, 102, 103, 105, 108], "conflict": 104, "confound": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 21, 38, 39, 43, 48, 58, 62, 66, 68, 69, 73, 77, 92, 93, 95, 98, 100, 101, 102, 105, 106, 107, 108], "congress": 106, "connect": [43, 62, 63], "consequ": [18, 19, 42, 58, 61, 68, 75, 77, 93, 94, 95, 99, 101], "conserv": [68, 69, 93, 101], "consid": [3, 8, 9, 10, 13, 33, 40, 42, 43, 49, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 78, 79, 92, 93, 95, 102, 103, 108], "consider": [69, 77], "consist": [11, 12, 43, 53, 60, 62, 63, 64, 69, 72, 73, 77, 105, 107], "consol": [40, 107], "constant": [23, 55, 65, 75, 77, 92, 102], "constrained_layout": 49, "construct": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 36, 44, 50, 51, 52, 54, 63, 68, 71, 75, 79, 81, 88, 92, 102, 107, 108], "construct_framework": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "construct_iv": 61, "constructiv": 42, "constructor": 44, "consum": [42, 61], "cont": 24, "cont_d": 47, "contain": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 24, 33, 34, 35, 40, 42, 43, 47, 49, 50, 51, 56, 57, 59, 61, 62, 72, 75, 76, 92, 93, 95, 98, 107], "context": [69, 77, 108], "contin": [24, 60], "continu": [24, 39, 44, 47, 48, 55, 64, 67, 77, 93, 101, 107, 108], "contour": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 55, 58, 68, 69, 93, 98], "contour_plot": 69, "contours_z": [50, 51], "contrast": [2, 52, 53, 77], "contribut": [104, 107], "contributor": 107, "control": [25, 33, 41, 55, 63, 65, 67, 69, 108], "convent": [32, 43, 62, 63, 67, 77], "converg": [40, 49, 59, 61, 72], "convergencewarn": 61, "convers": 61, "convert": [52, 61, 66], "convex": 64, "cooper": 107, "coor": [44, 76, 103, 105], "coordin": 69, "copi": [57, 60, 62, 65, 69], "cor": [93, 101], "core": [45, 47, 52, 53, 58, 61, 62, 63, 66, 68, 70, 73, 76, 105, 107], "cores_us": [52, 63, 66], "correct": [58, 69, 75, 92, 102, 107], "correctli": [53, 64, 68, 93, 101], "correl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 42, 55, 61, 68, 70, 77, 93, 95, 101], "correpond": 77, "correspond": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 24, 30, 31, 40, 42, 43, 44, 47, 49, 50, 51, 53, 54, 55, 59, 61, 62, 63, 65, 66, 68, 69, 72, 75, 76, 77, 78, 92, 93, 95, 98, 99, 101, 102, 107, 108], "cosh": 28, "coul": 42, "could": [39, 44, 48, 50, 51, 60, 69, 107, 108], "counfound": [18, 19, 66, 68, 75, 93, 101], "count": [47, 62, 63], "countour": [93, 98], "coupl": [43, 62, 63], "cournapeau": [103, 105], "cours": [43, 59, 62, 69, 92, 108], "cov": [15, 18, 33, 67], "cov_nam": [67, 77], "cov_typ": [1, 9, 12, 36, 107], "covari": [4, 5, 6, 7, 9, 11, 12, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 68, 69, 70, 72, 73, 75, 76, 77, 79, 82, 83, 92, 93, 95, 105, 106, 107], "cover": [41, 55, 68], "coverag": [59, 67, 75, 107], "cp": [43, 44, 76], "cpu": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "cpu_count": [52, 63, 66], "cran": [44, 106, 107], "creat": [21, 39, 42, 44, 47, 48, 49, 50, 51, 52, 56, 57, 61, 63, 65, 66, 69, 76, 93, 95, 98, 101, 104, 107], "create_synthetic_group_data": 65, "critic": [69, 108], "cross": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 20, 39, 40, 41, 43, 44, 49, 59, 60, 62, 63, 67, 69, 72, 74, 76, 82, 83, 88, 92, 96, 98, 107, 108], "cross_sectional_data": [6, 20, 53, 77], "crossfit": [59, 77], "crosstab": 64, "crucial": [55, 77, 108], "csail": [103, 105], "csv": 55, "cumul": 77, "current": [37, 41, 57, 79, 93, 101, 103, 104, 108], "custom": [40, 41, 49, 69, 76], "custom_measur": 41, "cut": 65, "cutoff": [32, 33, 67, 77], "cv": [44, 62, 76, 78], "cv_glmnet": [42, 43, 44, 76, 92, 102, 105], "cvar": [3, 14, 74, 81, 107], "cvar_0": 52, "cvar_1": 52, "d": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 108], "d0": [52, 66, 92], "d0_true": 66, "d0cdb0ea4795": 44, "d1": [52, 64, 66, 92, 102], "d10": [92, 102], "d1_true": 66, "d2": [64, 92, 102], "d21ee5775b5f": 44, "d3": [92, 102], "d4": [92, 102], "d5": [92, 102], "d5a0c70f1d98": 44, "d6": [92, 102], "d7": [92, 102], "d8": [92, 102], "d9": [92, 102], "d_": [24, 26, 42, 47, 54, 61, 77, 92, 102], "d_0": 77, "d_1": [64, 92, 102], "d_2": 64, "d_col": [4, 7, 39, 40, 42, 43, 44, 48, 50, 51, 56, 57, 61, 62, 63, 65, 67, 68, 71, 72, 73, 76, 77, 78, 79, 105, 107, 108], "d_i": [21, 22, 23, 25, 27, 28, 29, 40, 47, 49, 52, 53, 64, 66, 67, 70, 72, 77], "d_j": [47, 77, 92, 102], "d_k": [77, 92, 102], "d_l": 77, "d_w": 65, "da1440": 64, "dag": [69, 70, 108], "dark": [40, 49], "darkblu": 42, "darkr": 42, "dash": 47, "dat": 73, "data": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 36, 41, 54, 55, 59, 64, 71, 74, 75, 76, 78, 92, 97, 98, 102, 106, 107], "data_apo": 47, "data_cvar": 63, "data_dict": [32, 50, 51, 56, 57, 58, 67, 77], "data_dml": 68, "data_dml_bas": [43, 50, 51, 56, 57, 62, 63, 65], "data_dml_base_iv": [43, 62, 63], "data_dml_flex": [43, 62], "data_dml_flex_iv": 43, "data_dml_iv_flex": 62, "data_dml_new": 65, "data_fram": 108, "data_lqt": 63, "data_pq": 63, "data_qt": 63, "data_transf": [42, 61, 62], "datafram": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 32, 36, 37, 42, 45, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 75, 76, 77, 79, 92, 93, 95, 98, 105, 108], "dataset": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 32, 40, 41, 47, 49, 50, 51, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 92, 93, 98, 105, 108], "datatyp": 107, "db": [43, 62, 63, 68, 108], "dbl": [41, 42, 43, 44, 73, 92, 102, 105, 108], "dc13a11076b3": 44, "ddc9": 44, "de": [39, 48, 106], "deal": [39, 48], "debias": [16, 17, 26, 27, 42, 55, 61, 74, 76, 78, 103, 106, 107], "debt": [43, 62, 63], "decai": 70, "decid": [43, 62], "decis": [9, 39, 43, 48, 62, 63, 75, 77, 106, 108], "decision_effect": 39, "decision_impact": [39, 48], "decisiontreeclassifi": [9, 37, 62], "decisiontreeregressor": 62, "declar": 108, "decreas": 67, "deep": [34, 35, 60], "deeper": 9, "def": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 49, 52, 59, 60, 61, 64, 65, 66, 69, 76, 79], "default": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 24, 26, 27, 28, 32, 33, 34, 35, 36, 37, 41, 42, 53, 56, 57, 59, 61, 65, 67, 68, 69, 70, 71, 75, 76, 77, 78, 92, 93, 94, 98, 102, 105, 108], "default_convert": 61, "defier": [67, 77], "defin": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 40, 43, 44, 47, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 62, 63, 65, 66, 67, 68, 69, 75, 76, 77, 79, 82, 83, 93, 95, 98, 101], "definit": [28, 56, 57, 93, 94, 99], "defint": 93, "degre": [33, 43, 50, 51, 61, 62, 67, 75, 93, 95], "dekel": 106, "delete_origin": 44, "deliber": 64, "delta": [25, 41, 53, 69, 77], "delta_bench": 69, "delta_i": 41, "delta_j": 25, "delta_theta": [38, 47, 58, 68, 69, 93, 95], "delta_v": 69, "demand": [42, 61, 93, 95], "demir": [16, 17, 27, 42, 55, 61, 72, 78, 103, 106], "demo": 69, "demonstr": [40, 41, 42, 49, 61, 67, 69, 73, 77, 92, 102, 103, 105], "deni": 106, "denomin": [93, 94, 95, 99], "denot": [11, 42, 43, 53, 54, 61, 62, 67, 69, 70, 75, 77, 79, 93, 95, 98, 99, 101], "dens_net_tfa": 43, "densiti": [10, 13, 14, 40, 47, 49], "dep": 45, "dep1": [44, 45, 73, 105], "dep2": [44, 45, 73, 105], "depend": [1, 3, 9, 10, 14, 21, 44, 50, 51, 53, 56, 57, 58, 59, 60, 65, 67, 71, 75, 76, 77, 79, 86, 91, 93, 94, 95, 101, 105, 106], "deprec": [71, 78], "depreci": 107, "depth": [9, 37, 43, 44, 65, 71, 75, 76, 77, 78, 79, 92, 105, 108], "deriv": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 31, 77, 92], "describ": [41, 42, 61, 62, 63, 69, 76, 78, 104, 107], "descript": [43, 45, 68, 76, 78, 93, 95], "deserv": 77, "design": [32, 33, 47, 60, 74, 106, 107], "design_info": [50, 51], "design_matrix": [50, 51, 75], "desir": [19, 44, 65, 77, 104], "detail": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 30, 31, 40, 43, 44, 47, 49, 53, 54, 55, 60, 63, 67, 68, 69, 72, 73, 75, 76, 79, 81, 85, 86, 87, 88, 91, 92, 93, 95, 101, 102, 103, 104, 105, 107, 108], "determin": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 43, 52, 62, 63, 66, 67, 68, 77, 92, 93, 101, 102], "determinist": [65, 67, 75, 77], "deutsch": 103, "dev": [104, 107], "develop": [41, 42, 44, 61, 69, 77, 107], "deviat": [59, 77, 93, 101], "dezeur": 106, "df": [4, 7, 39, 40, 42, 47, 48, 50, 51, 52, 54, 57, 61, 64, 66, 67, 68, 69, 70, 72, 75, 77], "df_agg": 55, "df_apo": 47, "df_apo_ci": 47, "df_apos_ci": 47, "df_ate": 47, "df_bench": 69, "df_binari": 69, "df_bonu": [44, 73, 105], "df_cate": [50, 51], "df_ci": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 36], "df_coef": 59, "df_cvar": 63, "df_fuzzi": 67, "df_lqte": 63, "df_ml_g0": 59, "df_ml_g1": 59, "df_ml_m": 59, "df_pa": [53, 70], "df_plot": 42, "df_pq": 63, "df_qte": 63, "df_result": 55, "df_sharp": 67, "df_sort": 47, "df_summari": 62, "df_wide": 61, "dfg": 103, "dgp": [20, 42, 52, 54, 55, 61, 64, 65, 66, 69, 70], "dgp1": 20, "dgp2": 20, "dgp3": 20, "dgp4": 20, "dgp5": 20, "dgp6": 20, "dgp_dict": 69, "dgp_tpye": 53, "dgp_type": [20, 53], "diagon": 69, "diagram": [39, 48, 77], "dichotom": [39, 48], "dict": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 34, 35, 36, 37, 38, 50, 51, 55, 60, 69, 76], "dict_kei": [93, 98], "dictionari": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 21, 24, 33, 38, 50, 51, 56, 57, 68, 75, 76, 93, 98], "dictonari": [43, 62], "did": [4, 7, 40, 53, 54, 61, 74, 107, 108], "diff": 62, "differ": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 21, 39, 40, 42, 43, 44, 47, 48, 49, 52, 56, 57, 58, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 74, 75, 76, 78, 82, 83, 104, 105, 106, 107, 108], "differenti": 77, "difficult": 69, "dillon": 106, "dim": [33, 43], "dim_x": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 22, 23, 25, 26, 27, 28, 29, 33, 40, 42, 44, 49, 59, 60, 61, 72, 75, 76, 77, 93, 98], "dim_z": [11, 25, 77], "dimens": [21, 26, 42, 61, 65, 78], "dimension": [11, 12, 21, 23, 55, 75, 77, 78, 92, 93, 98, 102, 105, 106], "direct": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 49, 54, 70, 72, 77, 108], "directli": [32, 40, 41, 43, 47, 49, 59, 68, 72, 93, 98, 105, 108], "discontinu": [32, 33, 74, 106, 107], "discret": [2, 24, 47, 61, 77, 107], "discretis": 63, "discuss": [22, 42, 43, 61, 62, 106, 107, 108], "disjoint": [42, 56, 57, 61], "displai": [42, 47, 61, 69, 75, 76, 93, 98], "displot": 62, "disproportion": [43, 62], "dist": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "distr": 76, "distribut": [33, 40, 47, 49, 53, 59, 69, 72, 77, 93, 99, 104, 106, 107], "diverg": [32, 40, 49, 72], "divid": 77, "dmatrix": [50, 51, 75], "dml": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 30, 31, 32, 39, 40, 44, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 92, 93, 98, 102, 104], "dml1": [74, 105, 107, 108], "dml2": [39, 42, 44, 45, 53, 61, 63, 74, 77, 79, 92, 105, 107, 108], "dml_apo_obj": 77, "dml_apos_obj": 77, "dml_base": 61, "dml_combin": 92, "dml_cv_predict": 107, "dml_cvar": [52, 63], "dml_cvar_0": 52, "dml_cvar_1": 52, "dml_cvar_obj": [3, 75], "dml_data": [41, 42, 45, 47, 53, 54, 58, 59, 61, 64, 68, 69, 70, 75, 76, 77, 92, 102, 108], "dml_data_bench": 69, "dml_data_bonu": [44, 105], "dml_data_df": 108, "dml_data_fuzzi": 67, "dml_data_lasso": 45, "dml_data_sharp": 67, "dml_data_sim": [44, 105], "dml_df": [42, 61], "dml_did": [53, 54], "dml_did_obj": [5, 6, 77], "dml_iivm_boost": [43, 62], "dml_iivm_forest": [43, 62], "dml_iivm_lasso": [43, 62], "dml_iivm_obj": [8, 48, 77], "dml_iivm_tre": [43, 62], "dml_irm": [50, 56, 59, 65], "dml_irm_at": 58, "dml_irm_boost": [43, 62], "dml_irm_forest": [43, 62], "dml_irm_gat": 58, "dml_irm_gatet": 58, "dml_irm_lasso": [43, 45, 62], "dml_irm_new": 65, "dml_irm_obj": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 68, 75, 76, 77], "dml_irm_obj_ext": 76, "dml_irm_rf": 45, "dml_irm_tre": [43, 62], "dml_long": 38, "dml_lpq_0": 66, "dml_lpq_1": 66, "dml_lpq_obj": [10, 75], "dml_lqte": [63, 66], "dml_obj": [41, 47, 68, 69], "dml_obj_bench": 69, "dml_pliv": [42, 61], "dml_pliv_obj": [11, 42, 61, 77], "dml_plr": [51, 57, 92, 102], "dml_plr_1": 92, "dml_plr_2": 92, "dml_plr_boost": [43, 62], "dml_plr_forest": [43, 62, 108], "dml_plr_lasso": [43, 45, 62], "dml_plr_no_split": 78, "dml_plr_obj": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 68, 71, 75, 76, 77, 78, 79, 92, 93, 95, 98], "dml_plr_obj_extern": 78, "dml_plr_obj_intern": 78, "dml_plr_obj_onfold": 60, "dml_plr_obj_untun": 60, "dml_plr_rf": 45, "dml_plr_tree": [43, 62, 108], "dml_pq_0": [63, 66], "dml_pq_1": [63, 66], "dml_pq_obj": [13, 75], "dml_procedur": [45, 71, 105, 107, 108], "dml_qte": [63, 66], "dml_qte_obj": [14, 75], "dml_short": 38, "dml_ssm": [70, 77], "dml_tune": 107, "dmldummyclassifi": 76, "dmldummyregressor": 76, "dmlmt": 106, "dnorm": 40, "do": [41, 42, 43, 44, 59, 61, 62, 63, 64, 69, 75, 76, 93, 101, 105, 108], "doabl": 79, "doc": [39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 103, 107], "doccument": 107, "docu": 107, "document": [46, 50, 51, 54, 56, 57, 60, 69, 103, 107], "doe": [2, 14, 41, 42, 43, 47, 61, 62, 64, 68, 69, 93, 101, 108], "doesn": [39, 48], "doi": [16, 17, 18, 19, 20, 22, 26, 27, 29, 41, 42, 44, 55, 61, 69, 72, 76, 78, 92, 102, 103, 105, 107], "domain": 65, "don": [41, 60], "done": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 60, 63, 76, 78, 93, 95], "dosag": 47, "dot": [15, 54, 65, 73, 75, 76, 77, 92, 102, 105], "doubl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 26, 27, 28, 29, 32, 43, 55, 62, 64, 74, 76, 78, 79, 92, 93, 95, 102, 107], "double_ml_bonus_data": 45, "double_ml_data_from_data_fram": [40, 72, 73, 108], "double_ml_data_from_matrix": [41, 44, 73, 76, 92, 102, 105], "double_ml_irm": [45, 65], "doubleiivm": 103, "doubleml": [40, 42, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 93, 98, 102, 105, 106, 107], "doubleml2022python": 103, "doubleml2024r": 103, "doubleml_did_eval_linear": 41, "doubleml_did_eval_rf": 41, "doubleml_did_linear": 41, "doubleml_did_rf": 41, "doubleml_framework": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "doublemlapo": [47, 77, 79, 80, 107], "doublemlblp": [1, 9, 12, 50, 51, 75, 107], "doublemlclusterdata": 26, "doublemlcvar": [52, 75, 79, 81, 107], "doublemldata": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 25, 27, 28, 29, 32, 39, 42, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 92, 93, 98, 102, 107, 108], "doublemldid": [53, 54, 77, 79, 82, 107], "doublemldidc": [53, 77, 79, 83, 107], "doublemlframework": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 78, 92, 107], "doublemlframwork": 2, "doublemlidid": 77, "doublemlididc": 77, "doublemliivm": [39, 43, 48, 62, 76, 77, 78, 79, 84, 107], "doublemlirm": [1, 3, 5, 6, 8, 10, 11, 12, 13, 15, 41, 43, 45, 47, 50, 56, 58, 59, 62, 64, 65, 68, 69, 75, 76, 77, 78, 79, 85, 103, 107], "doublemllpq": [66, 75, 79, 86, 107], "doublemlpliv": [76, 77, 78, 79, 89, 103, 107], "doublemlplr": [1, 2, 3, 5, 6, 8, 9, 10, 11, 13, 14, 15, 40, 43, 44, 45, 49, 51, 57, 60, 62, 64, 68, 71, 72, 75, 76, 77, 78, 79, 90, 92, 93, 98, 102, 103, 105, 107, 108], "doublemlpolicytre": [9, 75], "doublemlpq": [63, 66, 75, 79, 91, 107], "doublemlqt": [52, 63, 66, 75, 92, 107], "doublemlresampl": 59, "doublemlsmm": 107, "doublemlssm": [70, 77, 79, 87, 88], "doubli": [18, 19, 20, 41, 106], "down": 69, "download": [39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 104, 105], "downward": 69, "dpg_dict": 68, "dpi": [40, 49, 64], "dramat": 41, "draw": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 69, 78, 107], "draw_sample_split": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 59, 78], "drawn": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 21, 33, 43, 62, 63, 65, 78], "drive": [40, 49, 72], "driven": [69, 108], "drop": [41, 60, 61, 64, 73, 76, 79, 82, 83, 92, 102], "dt": [79, 83, 93, 96], "dt_bonu": 73, "dta": 41, "dtype": [45, 47, 53, 56, 57, 58, 59, 61, 62, 63, 68, 70, 73, 75, 105], "dualiti": 61, "dubourg": [103, 105], "duchesnai": [103, 105], "due": [40, 41, 49, 50, 51, 58, 68, 69, 72, 77, 93, 95, 107, 108], "duflo": [16, 17, 27, 42, 55, 61, 72, 78, 103, 106], "dummi": [1, 9, 12, 34, 35, 36, 60, 69, 75, 76, 77, 107], "dummyclassifi": 34, "dummyregressor": 35, "duplic": 107, "durabl": [44, 45, 73, 105], "durat": 17, "dure": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 41, 42, 43, 44, 60, 61, 62, 76, 78, 105, 107, 108], "dx": 22, "dynam": [41, 106], "e": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 24, 27, 29, 30, 31, 32, 40, 41, 42, 43, 47, 49, 50, 51, 53, 55, 58, 59, 60, 61, 62, 63, 64, 67, 68, 69, 70, 72, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108], "e20ea26": 44, "e401": [43, 62, 63, 68, 108], "e4016553": 108, "e45228": 64, "e57c": 44, "each": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 24, 42, 44, 47, 54, 56, 57, 59, 60, 61, 63, 64, 65, 68, 69, 71, 73, 76, 77, 78, 92, 93, 98, 102, 108], "earlier": 108, "earn": [43, 62, 63], "earner": [43, 62, 68], "easi": [44, 79], "easier": 60, "easili": [44, 59, 60, 63, 107], "ec973f": 64, "ecolor": [47, 54, 62, 64], "econ": 106, "econml": 106, "econom": [25, 26, 28, 29, 42, 55, 61, 64, 69, 78, 106], "econometr": [16, 17, 18, 19, 20, 27, 28, 41, 42, 55, 61, 72, 103, 106], "econometrica": [23, 42, 61, 64, 72, 106], "ecosystem": [103, 108], "ectj": [16, 17, 27, 42, 55, 61, 72, 103], "ed": 106, "edge_color": 49, "edgecolor": 49, "edit": [104, 106], "edu": [103, 105], "educ": [43, 62, 63, 68, 108], "ee97bda7": 44, "effect": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 24, 33, 39, 40, 41, 42, 44, 47, 48, 49, 53, 54, 55, 58, 61, 65, 67, 70, 72, 74, 76, 77, 78, 79, 85, 92, 93, 95, 105, 106, 107, 108], "effici": [77, 106], "effort": 79, "eight": [42, 61], "either": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 21, 44, 54, 55, 65, 67, 75, 76, 77, 108], "eleanor": 106, "element": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 42, 50, 51, 52, 53, 59, 61, 63, 66, 68, 70, 79, 80, 82, 83, 93, 98, 100, 101, 107], "element_text": [42, 43], "elementari": 106, "elif": [56, 57, 65], "elig": [63, 68, 108], "eligibl": [43, 62, 68], "ell": [40, 42, 49, 55, 61, 72, 79, 89, 90, 105], "ell_0": [8, 11, 12, 40, 49, 55, 60, 72, 77], "ell_2": 59, "els": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 36, 41, 42, 43, 54, 56, 57, 61, 65, 69], "em": 106, "emphas": [42, 61], "empir": [30, 31, 40, 42, 49, 61, 64, 69, 72, 77, 78, 79, 92, 102], "emploi": [42, 55, 61, 69, 79, 84], "employ": [43, 62, 63], "employe": 108, "empti": 61, "emul": [93, 95], "enabl": [47, 65, 68, 75, 93, 95, 107], "encapsul": [34, 35], "encod": 64, "end": [22, 25, 26, 40, 41, 42, 43, 49, 52, 54, 55, 59, 61, 62, 64, 65, 66, 70, 71, 73, 76, 78, 92, 102, 105, 108], "endogen": [43, 62, 63, 108], "enet_coordinate_descent_gram": 61, "engin": [44, 106], "enrol": [43, 62, 63], "ensembl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 45, 47, 49, 50, 51, 56, 57, 58, 59, 62, 65, 68, 69, 71, 75, 76, 77, 78, 79, 92, 93, 98, 105, 108], "ensemble_learner_pipelin": 76, "ensemble_pipe_classif": 44, "ensemble_pipe_regr": 44, "ensur": [42, 57, 60, 61, 65], "entir": [40, 43, 49, 62, 72, 93, 95], "entri": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 40, 42, 45, 47, 49, 53, 58, 61, 62, 63, 68, 70, 72, 73, 76, 103, 105, 107], "enumer": [47, 52, 54, 56, 57, 59, 61, 62, 63, 66, 71, 76, 78], "env": [61, 104], "environ": 104, "ep": 64, "epanechnikov": 32, "epsilon": [43, 52, 53, 54, 62, 66, 75, 77], "epsilon_": [42, 54, 61], "epsilon_0": 33, "epsilon_1": 33, "epsilon_i": [21, 52, 64, 65, 66], "epsilon_sampl": 65, "epsilon_tru": [52, 66], "eqnarrai": 43, "equal": [1, 9, 42, 61, 64, 70, 75, 76, 77, 93, 99], "equat": [33, 42, 43, 61, 62, 69, 71, 92, 102, 108], "equilibrium": [42, 61], "equival": [55, 78], "err": [3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 45, 47, 48, 50, 51, 52, 53, 56, 57, 58, 60, 61, 62, 63, 64, 66, 68, 69, 70, 75, 76, 77, 78, 79, 92, 105, 108], "error": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 39, 40, 41, 43, 44, 49, 54, 55, 56, 57, 59, 60, 62, 67, 69, 72, 76, 77, 78, 79, 92, 93, 98, 102, 105, 107, 108], "errorbar": [47, 54, 56, 57, 60, 62, 64, 67], "erstellt": [42, 43, 44], "esim": 67, "especi": [59, 60], "essenti": 69, "est": 67, "est_method": 41, "esther": [78, 106], "estim": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 30, 31, 32, 34, 35, 36, 37, 40, 41, 42, 44, 47, 49, 50, 51, 52, 54, 56, 57, 59, 61, 65, 67, 71, 72, 74, 75, 76, 77, 81, 82, 83, 86, 88, 91, 93, 95, 98, 102, 103, 106, 107], "estimatior": [4, 7], "estimator_list": 60, "et": [16, 17, 21, 23, 26, 27, 40, 42, 43, 44, 49, 50, 51, 52, 53, 55, 56, 57, 59, 61, 62, 63, 66, 68, 72, 77, 78, 79, 81, 86, 91, 92, 93, 95, 101, 102, 103, 105, 107], "eta": [30, 31, 40, 42, 43, 54, 60, 61, 62, 66, 67, 71, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 101, 102, 105, 108], "eta1": 64, "eta2": 64, "eta_": [92, 93, 101, 102], "eta_0": [32, 71, 77, 79, 92], "eta_d": [67, 77], "eta_i": [21, 54, 65, 66, 67, 77], "eta_sampl": 65, "eta_tru": 66, "etc": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 42, 59, 60, 61, 107], "ev": [40, 49, 72], "eval": [44, 76], "eval_metr": [43, 62, 108], "eval_pr": 41, "eval_predict": 41, "evalu": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 23, 31, 41, 44, 50, 51, 52, 54, 58, 63, 66, 68, 71, 106, 107], "evaluate_learn": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 59, 60, 76, 107], "evalut": 76, "even": [43, 44, 62, 64, 67, 76, 77, 108], "eventu": [42, 61], "everi": [42, 61], "everyth": 103, "evid": [58, 60], "exact": 69, "exactli": [67, 69, 77], "exampl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 21, 32, 39, 40, 43, 44, 45, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 70, 71, 72, 75, 76, 77, 78, 79, 92, 93, 98, 102, 103, 105, 107, 108], "example_attgt": 41, "example_attgt_dml_eval_linear": 41, "example_attgt_dml_eval_rf": 41, "example_attgt_dml_linear": 41, "example_attgt_dml_rf": 41, "except": [55, 69, 107], "excess": 59, "exclud": 38, "exclus": [1, 9, 12, 56, 57, 75], "execut": [44, 108], "exemplarili": 105, "exemplatori": 65, "exhaust": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 76], "exhibit": [42, 61], "exist": [77, 93, 101], "exogen": [43, 62, 63, 77, 108], "exp": [18, 19, 20, 21, 23, 24, 27, 40, 49, 50, 51, 54, 56, 57, 64, 65, 72], "expect": [18, 19, 41, 47, 53, 58, 59, 60, 67, 69, 70, 75, 77, 78, 92, 93, 94, 105], "experi": [17, 22, 23, 40, 43, 49, 62, 69, 72, 73, 78, 105, 106], "experiment": [5, 6, 20, 79, 82, 83, 93, 96, 97], "expertis": 69, "explain": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 68, 93, 95, 100, 101], "explan": [42, 53, 61, 68, 93, 100, 103, 108], "explanatori": [69, 92, 102], "explicit": 69, "explicitli": [58, 108], "exploit": [40, 49, 72, 77, 108], "explor": 60, "exponenti": [92, 102], "export": [60, 107], "exposur": 54, "express": [42, 55, 67, 93, 101], "extend": [69, 76, 103, 107], "extendend": [93, 101], "extens": [76, 79, 103, 106, 107], "extent": 55, "extern": [40, 49, 60, 74, 93, 95, 107], "external_predict": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 49, 76], "externalptr": 43, "extra": 44, "extract": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 60], "extralearn": 44, "extrem": [43, 62], "ey": 55, "f": [43, 44, 47, 49, 52, 53, 54, 55, 59, 61, 62, 63, 65, 66, 68, 69, 70, 76, 93, 101, 103, 105], "f00584a57972": 44, "f1718fdeb9b0": 44, "f2e7": 44, "f3d24993": 44, "f6ebc": 64, "f_": [18, 20, 54, 75], "f_loc": [52, 66], "f_p": 54, "f_scale": [52, 66], "f_x": 77, "face_color": 49, "facet_wrap": 43, "facilit": 60, "fact": [43, 62, 63], "factor": [33, 40, 41, 42, 43, 44, 49, 59, 72, 76, 108], "faculti": 106, "fail": 107, "fair": 59, "fake": [39, 48], "fals": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 24, 32, 33, 36, 40, 43, 44, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 70, 73, 76, 77, 78, 79, 82, 83, 92, 93, 96, 97, 102, 108], "famili": [43, 62, 76], "fanci": 41, "far": [43, 62], "farbmach": 22, "fast": [59, 65, 76], "faster": 55, "fb5c25fa": 44, "fc9e": 44, "fd8a": 44, "featur": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 37, 41, 45, 58, 59, 62, 65, 75, 76, 77], "featureless": [44, 76], "features_bas": [43, 62, 63, 68], "features_flex": 43, "featureunion": 44, "februari": 69, "femal": [44, 45, 73, 105], "fern\u00e1ndez": [23, 78, 106], "fetch": [43, 61, 62, 63, 73], "fetch_401k": [43, 62, 63, 68, 108], "fetch_bonu": [44, 45, 73, 105], "few": [43, 62, 63], "ff7f0e": 54, "field": [42, 61, 76, 108], "fifteenth": 106, "fifth": 42, "fig": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 47, 50, 51, 52, 54, 55, 59, 60, 63, 64, 66, 67, 69], "fig_al": 49, "fig_dml": 49, "fig_non_orth": 49, "fig_orth_nosplit": 49, "fig_po_al": 49, "fig_po_dml": 49, "fig_po_nosplit": 49, "figsiz": [45, 47, 50, 51, 52, 54, 56, 57, 59, 60, 61, 62, 63, 64, 66, 67], "figur": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 27, 40, 42, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 60, 61, 62, 63, 66, 69, 72], "figure_format": 64, "file": [16, 17, 55, 64, 106, 107], "filenam": 40, "fill": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 42, 43, 53, 59, 62, 70], "fill_between": [50, 51, 52, 63, 66], "fill_valu": 59, "filter": 44, "filterwarn": 49, "final": [40, 44, 47, 49, 50, 51, 52, 54, 56, 57, 58, 63, 66, 67, 70, 72, 77, 108], "final_estim": 67, "financi": [16, 68, 108], "find": [43, 54, 62, 69, 75, 76, 108], "finish": 44, "finit": [40, 43], "firm": [42, 61, 68], "firmid": 61, "first": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 26, 32, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 69, 70, 72, 75, 77, 78, 92, 93, 98, 102, 104, 105, 107, 108], "fit": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 82, 83, 88, 92, 93, 95, 98, 102, 103, 107, 108], "fit_arg": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "fit_transform": [61, 62], "five": 61, "fix": [54, 59, 62, 107], "flag": [20, 78, 104], "flake8": 107, "flamlclassifierdoubleml": 60, "flamlregressordoubleml": 60, "flatten": [60, 64], "flexibl": [32, 39, 41, 43, 44, 48, 53, 62, 77, 103, 106, 107, 108], "flexibli": [43, 62, 68], "float": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 32, 33, 36], "float32": [63, 68], "float64": [45, 47, 53, 57, 58, 61, 62, 68, 70, 73, 76, 105], "floor": 44, "floor_divid": 61, "flt": 44, "flush": 40, "fmt": [47, 54, 56, 57, 60, 62, 64, 67], "focu": [42, 43, 61, 62, 63, 69, 75, 77, 108], "focus": [63, 68, 69, 108], "fold": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 39, 42, 43, 44, 53, 59, 61, 62, 63, 68, 70, 71, 74, 76, 77, 79, 82, 83, 92, 105, 108], "follow": [18, 19, 20, 21, 24, 40, 42, 43, 49, 50, 51, 52, 53, 54, 56, 57, 60, 61, 62, 63, 66, 67, 68, 69, 70, 72, 73, 75, 76, 77, 78, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 108], "font_scal": [61, 62, 63], "fontsiz": [52, 63, 66], "force_all_x_finit": [4, 7], "forest": [22, 39, 40, 41, 43, 44, 48, 49, 53, 58, 59, 62, 68, 72, 76, 105, 108], "forest_summari": 62, "forg": [104, 106, 107], "form": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 21, 36, 43, 50, 51, 52, 53, 54, 56, 57, 58, 59, 62, 66, 67, 68, 70, 75, 77, 79, 80, 85, 93, 94, 95, 98, 99, 100, 101, 104, 105], "format": [49, 58, 93, 98], "formula": [42, 43, 61, 62, 67, 69, 107], "formula_flex": 43, "forschungsgemeinschaft": 103, "forthcom": [69, 106], "forum": 107, "forward": [9, 37], "found": [50, 51, 55, 56, 57, 60, 72, 73, 76, 77, 105], "foundat": [103, 106], "four": [43, 59, 62, 107], "fourth": [42, 61], "frac": [8, 18, 19, 20, 22, 23, 25, 27, 28, 29, 31, 40, 42, 44, 49, 54, 55, 58, 61, 64, 67, 71, 72, 75, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102], "fraction": 44, "frame": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 36, 39, 40, 42, 43, 45, 47, 50, 51, 53, 56, 57, 58, 61, 62, 63, 64, 65, 68, 70, 72, 73, 105, 108], "framework": [31, 40, 42, 44, 49, 59, 60, 61, 64, 69, 72, 76, 92, 102, 103, 105, 107, 108], "freez": 104, "fribourg": 106, "friendli": 47, "from": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 36, 39, 40, 42, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 92, 93, 98, 102, 105, 107, 108], "from_arrai": [4, 7, 15, 32, 49, 52, 53, 54, 66, 72, 73, 76, 92, 102, 105], "from_product": 61, "front": 47, "fr\u00e9chet": [93, 101], "fs_kernel": [32, 77], "fs_specif": [32, 77], "fsize": [43, 62, 63, 68, 108], "full": [47, 49, 52, 53, 54, 56, 57, 59, 62, 63, 66, 67, 70, 72, 77], "fulli": [9, 43, 46, 60, 62, 77], "fun": 40, "func": 41, "function": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 27, 28, 30, 31, 32, 39, 40, 43, 44, 48, 49, 50, 51, 52, 53, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 96, 97, 101, 102, 103, 106, 107, 108], "fund": [43, 62, 63, 103], "further": [18, 19, 20, 21, 24, 26, 42, 44, 47, 50, 51, 52, 53, 54, 58, 59, 61, 63, 65, 66, 67, 68, 69, 70, 76, 77, 79, 81, 86, 87, 88, 91, 92, 93, 95, 98, 100, 101, 102, 103, 105, 107, 108], "furthermor": [49, 79, 80, 85], "futurewarn": 57, "fuzzi": [32, 33], "g": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 32, 40, 41, 44, 45, 49, 50, 51, 53, 54, 55, 58, 59, 63, 64, 65, 68, 70, 72, 75, 76, 77, 79, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 108], "g_": [33, 47, 79, 81, 82, 83, 86, 91, 92, 102], "g_0": [1, 5, 6, 8, 9, 11, 12, 13, 27, 28, 32, 33, 40, 42, 43, 49, 59, 61, 62, 72, 75, 76, 77, 79, 80, 87, 88, 93, 94, 99, 101, 105, 108], "g_1": [33, 59], "g_all": [40, 43], "g_all_po": 40, "g_ci": 43, "g_d": [79, 81, 91], "g_dml": 40, "g_dml_po": 40, "g_hat": [11, 12, 40, 49, 79], "g_hat0": [8, 9], "g_hat1": [8, 9], "g_k": 75, "g_nonorth": 40, "g_nosplit": 40, "g_nosplit_po": 40, "g_x": 54, "gain": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 38, 59, 93, 95, 99, 107], "gain_statist": 107, "galleri": [72, 75, 76, 77, 103, 107], "gama": 60, "gamma": [25, 28, 29, 42, 61, 64, 65, 67, 69, 77, 79, 81, 86], "gamma_0": [21, 65, 70, 79, 81, 86], "gamma_a": [18, 19, 69], "gamma_bench": 69, "gamma_v": 69, "gap": [61, 69], "gapo": 1, "gate": [1, 9, 12, 36, 64, 65, 74, 107], "gate_obj": 75, "gatet": 75, "gaussian": [10, 13, 14, 40, 49, 72, 75, 76, 92, 102, 106], "ge": [18, 20, 21, 58, 65, 75], "geer": 106, "gelbach": [42, 61], "gener": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 39, 41, 42, 43, 44, 45, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 85, 92, 94, 95, 96, 97, 99, 101, 102, 106, 107, 108], "generate_treat": 66, "geom_bar": 43, "geom_dens": 43, "geom_errorbar": 43, "geom_funct": 40, "geom_histogram": 40, "geom_hlin": 43, "geom_point": 43, "geom_til": 42, "geom_vlin": 40, "geq": [67, 77], "german": 103, "get": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 34, 35, 44, 47, 59, 64, 68, 69, 93, 95, 103, 104], "get_dummi": 64, "get_feature_names_out": [61, 62], "get_legend_handles_label": 47, "get_level_valu": 60, "get_logg": [40, 41, 42, 43, 44, 71, 76, 77, 78, 79, 92, 102, 105], "get_metadata_rout": [34, 35], "get_param": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 34, 35, 60, 76], "ggdid": 41, "ggplot": [40, 42, 43], "ggplot2": [40, 42, 43], "ggsave": 40, "ggtitl": 43, "gh": 107, "git": 104, "github": [41, 43, 55, 60, 62, 64, 103, 106, 107], "githubusercont": 55, "give": [43, 62], "given": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 23, 27, 28, 31, 32, 33, 40, 42, 47, 49, 54, 56, 57, 61, 63, 64, 67, 69, 70, 72, 75, 79, 80, 92, 93, 94, 98, 99, 100, 101, 102, 105, 107], "glmnet": [43, 44, 76, 107], "global": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 76, 77], "globalclassifi": 67, "globallearn": 67, "globalregressor": 67, "glrn": 44, "glrn_lasso": 44, "gname": 41, "go": [50, 51, 55, 60, 67, 69], "goal": [47, 56, 57, 77], "goe": 77, "goldman": 106, "good": [55, 93, 95, 108], "gradient": [43, 62], "gradientboostingclassifi": 59, "gradientboostingregressor": 59, "gradual": 69, "gramfort": [103, 105], "graph": [44, 70, 108], "graph_ensemble_classif": 44, "graph_ensemble_regr": 44, "graph_obj": 67, "graph_object": [50, 51, 55, 69], "graphlearn": [44, 76], "grasp": [47, 93, 95], "great": [54, 108], "greater": 108, "green": [40, 50, 51, 52, 66], "greg": 106, "grei": [43, 47], "grenand": 106, "grey50": 42, "grid": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 42, 44, 47, 50, 51, 52, 55, 63, 64, 66, 69, 76, 93, 98], "grid_arrai": [50, 51], "grid_bound": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 69], "grid_search": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 44, 76], "grid_siz": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 50, 51], "gridextra": 42, "gridsearchcv": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 76], "grisel": [103, 105], "grob": 42, "group": [1, 9, 12, 39, 41, 47, 48, 58, 63, 64, 65, 69, 74], "group_0": 75, "group_1": [56, 57, 75], "group_2": [56, 57, 75], "group_3": [56, 57], "group_effect": 65, "group_ind": 58, "group_treat": 58, "groupbi": [55, 62], "gruber": 22, "gt": [39, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 105], "guarante": [42, 61], "guber": 22, "guess": [68, 93, 95], "guid": [30, 31, 34, 35, 40, 41, 42, 44, 47, 49, 54, 58, 61, 67, 68, 76, 103, 105, 107], "guidelin": 107, "gunion": [44, 76], "gxidclusterperiodytreat": 41, "h": [18, 19, 20, 22, 26, 41, 42, 61, 67, 77, 106], "h20": 60, "h_0": [47, 58, 68, 69, 93, 98, 108], "h_f": [32, 77], "ha": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 20, 36, 37, 40, 41, 42, 43, 49, 55, 59, 60, 61, 62, 63, 64, 67, 68, 69, 75, 76, 77, 93, 94, 95, 98, 99, 100, 101, 108], "half": [40, 49, 64, 72, 78], "hand": [32, 59, 60, 64, 108], "handbook": 64, "handl": [41, 47, 59, 76, 107], "hansen": [16, 17, 23, 25, 27, 42, 55, 61, 72, 103, 106], "happend": 59, "hard": [68, 93, 95], "harold": 106, "hat": [40, 42, 49, 55, 58, 61, 64, 67, 71, 72, 75, 77, 78, 79, 92, 93, 95, 98, 100, 102], "have": [1, 2, 9, 12, 14, 21, 24, 36, 37, 39, 40, 41, 42, 43, 44, 47, 48, 50, 51, 53, 54, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 73, 75, 76, 77, 92, 93, 94, 95, 101, 104, 105, 107, 108], "hazlett": [69, 93, 95], "hc": [41, 106], "hc0": [36, 107], "hdm": [42, 61], "he": 70, "head": [41, 42, 44, 45, 50, 51, 56, 57, 60, 61, 62, 64, 67, 69, 73, 75, 105], "heat": [42, 61], "heatmap": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 42, 61, 69], "heavili": 59, "hei": 106, "height": [40, 42, 55, 60], "help": [41, 43, 52, 59, 63, 65, 69, 78, 108], "helper": 107, "henc": [41, 43, 44, 62, 69, 76, 79, 108], "here": [10, 13, 14, 41, 42, 43, 44, 50, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 69, 70, 73, 76, 77, 104], "heterogen": [9, 21, 43, 58, 62, 63, 65, 74, 77, 78, 106, 107, 108], "heteroskedast": [56, 57], "heurist": [40, 49, 72], "high": [11, 12, 23, 43, 54, 55, 62, 63, 71, 77, 92, 102, 103, 105, 106], "higher": [41, 43, 55, 62, 63, 64, 67, 107, 108], "highli": [43, 62, 103], "highlight": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 53, 60, 69, 107], "highlightcolor": [50, 51], "hint": 60, "hispan": 45, "hist": 47, "hist_e401": 43, "hist_p401": 43, "histogram": 47, "histplot": 49, "hjust": 43, "hline": [73, 92, 102, 105, 108], "hold": [29, 42, 43, 60, 61, 62, 70, 75, 76, 77], "holdout": [76, 78], "holm": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "home": [43, 62], "homogen": 77, "hopefulli": 63, "horizont": [42, 54, 61], "hostedtoolcach": [62, 69], "hot": 64, "hotstart_backward": [44, 76], "hotstart_forward": [44, 76], "household": [43, 62, 63, 68], "how": [34, 35, 39, 41, 42, 43, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 76, 77, 103, 104], "howev": [40, 43, 49, 60, 62, 67, 69, 70, 72, 77, 108], "hown": [43, 62, 63, 68, 108], "hpwt": [42, 61], "hpwt0": 42, "hpwtairmpdspac": 42, "href": 103, "hspace": 59, "hstack": [15, 54], "html": [44, 57, 103, 105, 107], "http": [22, 28, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 76, 103, 104, 105, 107], "huber": [29, 70, 77, 79, 87, 88, 106], "hue": 62, "huge": 59, "hugo": 106, "husd": [44, 45, 73, 105], "hyperparamet": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 43, 44, 45, 55, 59, 60, 62, 74, 105], "hypothes": [92, 102, 106], "hypothesi": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 43, 62, 68, 93, 98, 106], "hypothet": 69, "i": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 88, 91, 92, 93, 94, 95, 98, 99, 101, 102, 103, 104, 105, 107, 108], "i0": [53, 54, 77], "i03": 103, "i1": [53, 77], "i_": [25, 61, 65], "i_1": [42, 61], "i_2": [42, 61], "i_3": [42, 61], "i_4": 54, "i_est": 49, "i_fold": 42, "i_k": [42, 61, 71, 78, 92, 102], "i_learn": 59, "i_level": 47, "i_rep": [40, 49, 53, 59, 70, 72], "i_split": 61, "i_train": 49, "icp": 106, "id": [41, 42, 44, 61], "id_var": 61, "idea": [43, 44, 62, 63, 69, 76, 77, 93, 95, 108], "ident": [18, 19, 20, 21, 24, 25, 37, 44, 47, 60, 67, 76, 77, 93, 98], "identfi": 69, "identif": [67, 77, 108], "identifi": [42, 43, 53, 58, 61, 62, 63, 67, 69, 75, 77, 93, 101, 107], "identifii": 75, "idnam": 41, "idx_tau": [52, 63, 66], "idx_treat": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 47, 93, 98], "ieee": 106, "ifels": 41, "ignor": [49, 67], "ii": [42, 61], "iid": 77, "iivm": [8, 22, 30, 31, 63, 71, 75, 84, 103, 107], "iivm_summari": 62, "iivmglmnet": 43, "iivmrang": 43, "iivmrpart": 43, "iivmxgboost11861": 43, "ij": [26, 42, 47, 61, 70], "ilia": 106, "illustr": [40, 42, 43, 44, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 65, 66, 68, 69, 70, 72, 76, 108], "iloc": [47, 53, 54, 59, 61, 64], "immedi": 104, "immun": [78, 106], "impact": [39, 48, 59, 64, 68], "implement": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 30, 31, 32, 40, 41, 42, 43, 44, 49, 53, 55, 59, 61, 62, 64, 67, 68, 69, 70, 72, 74, 75, 76, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 102, 103, 105, 106, 107, 108], "impli": [18, 19, 42, 43, 61, 62, 63, 67, 75, 77, 93, 94, 96, 97, 99], "implment": 54, "import": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 32, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 104, 105, 107, 108], "importlib": 55, "impos": 69, "improv": [53, 59, 65, 77, 107], "in_sample_norm": [5, 6, 53, 79, 82, 83, 93, 96, 97], "inbuild": 59, "inbuilt": 59, "inc": [43, 62, 63, 68, 108], "includ": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 41, 43, 47, 54, 56, 57, 62, 67, 68, 69, 75, 77, 92, 93, 94, 98, 99, 101, 102, 104, 107, 108], "include_bia": [61, 62], "include_scenario": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 69], "incom": [43, 62, 63, 65, 68, 108], "incorpor": [44, 68, 93, 98], "increas": [58, 59, 61, 69, 108], "increment": 107, "ind": 62, "independ": [5, 6, 18, 19, 20, 21, 33, 42, 44, 54, 58, 61, 65, 77, 79, 82, 83, 107], "index": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 42, 45, 49, 54, 55, 56, 57, 60, 61, 62, 64, 65, 72, 73, 78, 79, 82, 83, 105], "index_col": 55, "india": [78, 106], "indic": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 24, 29, 32, 36, 42, 43, 54, 58, 61, 62, 63, 67, 69, 70, 71, 73, 75, 77, 78], "individu": [1, 9, 41, 43, 47, 54, 56, 57, 58, 60, 62, 63, 67, 68, 75, 77, 108], "individual_df": 54, "induc": [74, 78], "industri": [42, 61], "inf": [4, 7, 41], "inf_model": 79, "infer": [23, 25, 39, 40, 42, 48, 49, 55, 61, 72, 74, 77, 78, 103, 105, 106, 107], "inferenti": 108, "infinit": [4, 7, 107], "influenc": 77, "info": [39, 44, 45, 47, 53, 58, 60, 61, 62, 63, 68, 70, 73, 105, 107, 108], "inform": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 35, 36, 39, 44, 48, 50, 51, 59, 67, 68, 69, 77, 93, 95, 106], "infti": [40, 49, 72], "inher": 69, "inherit": [64, 107], "initi": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 32, 43, 44, 52, 53, 62, 63, 66, 67, 68, 69, 70, 73, 75, 76, 77, 78, 105, 107, 108], "inlin": [45, 64], "inlinebackend": 64, "inner": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 76], "innermost": 76, "input": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 44, 68, 71, 92, 93, 95, 98, 102], "insensit": 77, "insight": [55, 69], "insignific": 68, "inspect": 105, "inspir": [18, 22, 23, 29, 69], "instal": [43, 60, 67, 77, 107], "install_github": 104, "instanc": [43, 44, 62, 76], "instanti": [42, 43, 61, 62, 76, 78], "instead": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 39, 41, 43, 47, 48, 57, 58, 60, 62, 63, 75, 76, 77, 93, 96, 97, 99, 100, 107], "instruct": [104, 107], "instrument": [4, 7, 8, 11, 16, 22, 25, 42, 43, 44, 45, 47, 53, 58, 61, 62, 63, 66, 68, 70, 73, 76, 77, 79, 86, 92, 105, 108], "instrument_effect": 39, "instrument_impact": 48, "insuffienct": 60, "int": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 21, 24, 32, 33, 36, 37, 41, 42, 43, 48, 52, 53, 65, 66, 69, 70], "int64": [45, 59, 61, 73, 105], "int8": [62, 63, 68], "integ": [20, 44, 76], "integr": [60, 69, 93, 101, 107], "intend": [32, 44, 69, 108], "intent": [77, 108], "inter": 76, "interact": [1, 2, 8, 9, 18, 22, 23, 24, 32, 33, 47, 69, 74, 76, 94, 99, 103, 107, 108], "interchang": 92, "interest": [8, 9, 11, 12, 18, 19, 40, 43, 49, 53, 55, 62, 63, 67, 70, 72, 75, 77, 79, 92, 102, 105, 108], "interfac": [41, 43, 44, 73, 76, 78, 105], "intermedi": [57, 69], "intern": [41, 43, 44, 47, 60, 63, 76, 106], "internet": [43, 62, 63], "interpret": [56, 57, 69, 75, 93, 94, 95, 99, 100, 101, 104, 108], "intersect": [69, 93, 98, 107], "interv": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 36, 41, 42, 43, 47, 50, 51, 52, 53, 56, 57, 61, 63, 66, 67, 68, 70, 74, 75, 78, 79, 93, 98, 105, 106, 108], "intial": 67, "introduc": [40, 49, 72, 73, 92, 102, 107, 108], "introduct": [40, 42, 44, 49, 61, 63, 68, 76, 77, 93, 95], "introductori": [41, 69], "intrument": 70, "intspecifi": 32, "intuit": 69, "inuidur1": [44, 45, 73, 105], "inuidur1femaleblackothracedep1dep2q2q3q4q5q6agelt35agegt54durablelusdhusdtg": [44, 73, 105], "inuidur2": [45, 73, 105], "inv_sigmoid": 64, "invalid": [40, 49, 72], "invari": 77, "invers": [1, 3, 8, 9, 10, 13, 14, 15, 70, 93, 94, 99], "invert_yaxi": 61, "investig": [55, 60, 69], "involv": [75, 76, 79, 108], "io": [64, 107], "ipw_norm": 107, "ipykernel_12747": 57, "ipynb": [39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70], "ira": [43, 62, 63], "irm": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 23, 24, 30, 31, 36, 37, 59, 69, 71, 74, 76, 85, 94, 99, 103, 107, 108], "irm_summari": 62, "irmglmnet": 43, "irmrang": 43, "irmrpart": 43, "irmxgboost8047": 43, "irrespect": 69, "is_classifi": [1, 5, 6, 8, 9, 12], "is_gat": [1, 9, 12, 36], "isnan": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 59, 76], "isoton": 69, "isotonicregress": 69, "issn": 55, "issu": [62, 69, 103, 106, 107], "ite": [47, 56, 57, 58], "item": [8, 62, 71, 76, 78], "iter": [32, 39, 53, 61, 67, 70, 76, 92, 102, 108], "itertool": 55, "its": [34, 35, 69, 71, 75, 76, 77, 78, 79, 92], "iv": [8, 11, 12, 22, 25, 26, 40, 42, 49, 61, 72, 73, 89, 90, 93, 100, 103, 107, 108], "iv_2": 39, "iv_var": [42, 61], "iv\u00e1n": [78, 106], "j": [16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 40, 41, 42, 44, 47, 49, 55, 61, 64, 70, 72, 76, 77, 92, 102, 103, 105], "j_": [42, 61], "j_0": 92, "j_1": [42, 61], "j_2": [42, 61], "j_3": [42, 61], "j_k": [42, 61], "jame": 106, "janni": [43, 62], "javanmard": 106, "jbe": [42, 61], "jeconom": [18, 19, 20, 41], "jerzi": 106, "jia": 69, "jk": 77, "jmlr": [44, 103, 105, 107], "job": [43, 62, 63], "joint": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 36, 47, 50, 51, 52, 56, 57, 63, 66, 77, 92, 107, 108], "jointli": [66, 75], "joss": [44, 76, 103, 105], "journal": [16, 17, 18, 19, 20, 26, 27, 29, 41, 42, 44, 55, 61, 64, 69, 72, 76, 103, 105, 106, 107], "jss": 103, "jump": [65, 67, 77], "jun": [41, 106], "jupyt": [39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70], "juraj": 106, "just": [41, 44, 47, 52, 53, 54, 56, 57, 58, 65, 66, 77, 79, 82, 83, 93, 95], "justif": [78, 93, 95], "k": [16, 19, 20, 22, 23, 25, 26, 27, 29, 40, 42, 44, 49, 59, 60, 61, 67, 71, 72, 74, 75, 77, 92, 102, 108], "k_h": [67, 77], "kaggl": [43, 62], "kallu": [52, 63, 66, 68, 79, 81, 86, 91, 106], "kappa": 77, "kato": [26, 42, 61, 92, 102, 106], "kb": [47, 53, 58, 61, 62, 63, 68, 73, 105], "kde": [10, 13, 14, 62], "kdeplot": [53, 59, 70], "kdeunivari": [10, 13, 14], "kecsk\u00e9sov\u00e1": 107, "keep": [41, 57, 69, 108], "kei": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 32, 37, 42, 43, 50, 51, 56, 57, 60, 61, 62, 63, 67, 69, 76, 77, 79, 93, 98, 107], "keith": 106, "kengo": 106, "kernel": [10, 13, 14, 32, 67, 77], "kernel_regress": 67, "kernelreg": 67, "keyword": [1, 9, 12, 20, 26, 27, 28, 33, 36], "kf": 78, "kfold": [61, 78], "kind": [39, 48, 62], "kj": [19, 20, 22, 23, 25, 26, 27, 29, 40, 42, 49, 61, 72], "klaassen": [22, 69, 103, 106], "klaa\u00dfen": 22, "knau": 106, "know": [53, 65], "knowledg": [39, 48, 59, 64, 65], "known": [58, 59, 67, 69, 76, 77], "kohei": 106, "kotthof": 44, "kotthoff": [44, 76, 103, 105], "krueger": 64, "kueck": [43, 62], "kurz": [103, 106, 107], "kwarg": [1, 9, 12, 18, 19, 20, 24, 26, 27, 28, 32, 33, 34, 36, 60, 77], "l": [42, 44, 45, 50, 51, 61, 69, 70, 76, 93, 100, 103, 105], "l1": [62, 70, 77], "l_hat": [11, 12, 40, 49, 79], "label": [47, 49, 50, 51, 52, 54, 56, 57, 60, 63, 64, 66, 67], "labor": 64, "laffer": 106, "laff\u00e9r": [29, 70, 77, 79, 87, 88], "lal": [64, 107], "lambda": [42, 43, 44, 62, 64, 65, 76, 79, 83, 92, 102, 105], "lambda_": 55, "lambda_0": [79, 83], "lambda_t": 20, "land": 65, "lang": [44, 76, 103, 105], "langl": [21, 65], "lappli": 78, "larg": [40, 49, 58, 59, 60, 64, 69, 77], "larger": [9, 41, 67, 69, 93, 98], "largest": 59, "largli": 59, "lasso": [42, 43, 44, 62, 70, 76, 105, 106], "lasso_class": [43, 62], "lasso_pip": [44, 76], "lasso_summari": 62, "lassocv": [15, 55, 61, 62, 70, 76, 77, 92, 102, 105], "last": [20, 44, 104], "late": [8, 39, 43, 62, 77, 79, 84], "latent": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 68, 93, 100, 101], "later": [43, 44, 67, 69, 76, 108], "latter": 77, "layout": 55, "lbrace": [8, 9, 22, 23, 29, 42, 61, 71, 77, 78, 79, 80, 92, 93, 94, 102], "ldot": [11, 12, 42, 61, 70, 71, 77, 78, 92, 102, 105], "le": [20, 53, 65, 75, 77, 79, 86, 91], "lead": [41, 69, 77], "leadsto": 92, "lear": [44, 76, 103, 105], "learn": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 26, 27, 28, 29, 32, 39, 43, 44, 45, 47, 48, 52, 55, 59, 60, 62, 63, 64, 66, 67, 69, 73, 74, 76, 78, 79, 92, 93, 95, 102, 107, 108], "learner": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 39, 40, 41, 42, 43, 49, 50, 51, 53, 55, 61, 62, 63, 68, 69, 70, 71, 72, 74, 77, 78, 79, 92, 93, 98, 102, 107, 108], "learner_class": [15, 107], "learner_cv": 44, "learner_forest_classif": 44, "learner_forest_regr": 44, "learner_l": 68, "learner_lasso": 44, "learner_list": 59, "learner_m": 68, "learner_nam": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 76], "learner_param_v": 44, "learner_rf": 92, "learnerclassif": 44, "learnerregr": 44, "learnerregrcvglmnet": 44, "learnerregrrang": [44, 76], "learning_r": [49, 52, 63, 66, 67, 69, 72], "least": [39, 43, 48, 62, 63, 68, 77, 78], "leav": [69, 70], "left": [22, 23, 25, 26, 29, 40, 42, 47, 49, 59, 61, 62, 63, 64, 66, 67, 72, 77, 79, 82, 83, 92, 93, 94, 96, 97, 99, 102], "legend": [43, 47, 49, 50, 51, 52, 54, 56, 57, 59, 63, 64, 66], "len": [47, 52, 59, 60, 61, 63, 66], "length": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 40, 44, 53, 76], "leq": [42, 61], "less": [41, 43, 62, 63, 67, 69], "lester": 106, "let": [18, 19, 20, 24, 40, 41, 43, 44, 47, 49, 52, 53, 56, 57, 59, 62, 63, 66, 69, 70, 71, 72, 76, 77, 93, 95, 101, 108], "level": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 24, 32, 36, 42, 43, 47, 50, 51, 52, 53, 54, 56, 57, 58, 61, 62, 63, 66, 68, 69, 70, 76, 79, 80, 93, 94, 98, 108], "level_0": [44, 61], "level_1": 61, "level_bound": 47, "levinsohn": [42, 61], "lewi": 106, "lgbmclassifi": [52, 53, 54, 59, 63, 66, 67, 69], "lgbmregressor": [49, 52, 53, 54, 59, 63, 67, 69, 72], "lgr": [40, 41, 42, 43, 44, 71, 76, 77, 78, 79, 92, 102, 105], "lib": [61, 62, 69], "liblinear": [62, 70, 77], "librari": [39, 40, 41, 42, 43, 44, 71, 72, 73, 76, 77, 78, 79, 92, 102, 104, 105, 108], "licens": 107, "lie": 106, "lightgbm": [49, 52, 53, 54, 59, 63, 66, 67, 69], "like": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 41, 43, 44, 55, 57, 62, 63, 69, 76, 78, 105, 108], "lim": 64, "lim_": [67, 77], "limegreen": [50, 51], "limit": [64, 77, 106], "limits_": 75, "lin": [67, 69, 77], "line": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 47, 54, 69], "linear": [1, 9, 11, 12, 18, 19, 24, 25, 26, 27, 28, 30, 31, 36, 39, 40, 41, 42, 44, 47, 48, 49, 50, 51, 53, 54, 55, 56, 59, 60, 61, 68, 69, 71, 72, 74, 75, 76, 78, 80, 82, 83, 84, 85, 89, 90, 92, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108], "linear_model": [1, 9, 12, 15, 36, 45, 47, 48, 55, 59, 61, 62, 67, 69, 70, 76, 77, 92, 102, 105], "linearli": [67, 77], "linearregress": [39, 47, 48, 59, 67, 69], "linearscoremixin": 79, "lineplot": 47, "linestyl": [47, 54, 60, 67], "linewidth": 54, "link": [69, 107], "linspac": [50, 51, 69], "lint": 107, "linux": 104, "list": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 40, 41, 42, 43, 44, 49, 50, 51, 61, 63, 65, 72, 76, 78, 79, 104, 107], "listedcolormap": 61, "literatur": [69, 77], "littl": 58, "ll": [44, 92, 102, 108], "lllllllllllllllll": [73, 105], "lm": [39, 41, 69], "ln_alpha_ml_l": 55, "ln_alpha_ml_m": 55, "load": [39, 41, 43, 44, 55, 62, 63, 73, 104, 105], "loc": [47, 49, 52, 54, 55, 57, 61, 64, 66, 68, 69], "local": [8, 10, 75, 77, 106, 107], "localconvert": 61, "locat": [52, 66, 77], "log": [42, 55, 59, 61, 64, 68, 76, 77], "log_odd": 65, "log_p": [42, 61], "log_reg": [39, 41], "logarithm": 55, "logic": [8, 44, 76], "logical_not": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 59, 76], "logist": [18, 33, 39, 41, 43, 47, 48, 62, 69, 70, 108], "logisticregress": [39, 45, 47, 48, 67, 69], "logisticregressioncv": [15, 59, 62, 70, 77], "logit": [59, 64], "loglik": 44, "logloss": [43, 62, 108], "logo": 107, "logspac": 62, "long": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 40, 49, 59, 68, 69, 93, 95, 101, 106], "look": [41, 43, 44, 52, 53, 54, 59, 62, 63, 66, 67, 68], "loop": 47, "loss": [59, 60, 67, 68, 76, 77], "loss_ml_g0": 59, "loss_ml_g1": 59, "loss_ml_m": 59, "low": [54, 58, 75, 106], "lower": [43, 44, 47, 52, 54, 55, 58, 63, 64, 66, 67, 68, 69, 76, 93, 98, 101, 108], "lower_bound": [50, 51], "lpq": [10, 14, 63, 75, 86, 107], "lpq_0": 66, "lpq_1": 66, "lqte": 75, "lr": 67, "lrn": [39, 40, 41, 42, 43, 44, 71, 76, 77, 78, 79, 92, 102, 105, 108], "lrn_0": 44, "lt": [39, 41, 42, 43, 44, 45, 47, 53, 58, 61, 62, 63, 65, 68, 69, 70, 73, 105], "lucien": 107, "luka": 106, "luk\u00e1\u0161": 29, "lusd": [44, 45, 73, 105], "lvert": 55, "m": [15, 16, 17, 18, 25, 26, 27, 40, 42, 44, 45, 49, 55, 58, 61, 64, 72, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 96, 97, 99, 100, 101, 103, 104, 105, 106, 107], "m_": [47, 77, 79, 80, 86, 92, 102], "m_0": [1, 3, 5, 6, 8, 9, 11, 12, 13, 27, 28, 32, 40, 42, 43, 49, 55, 58, 60, 61, 62, 72, 75, 76, 77, 79, 81, 82, 83, 86, 87, 88, 91, 105, 108], "m_hat": [8, 9, 11, 12, 40, 49, 79], "m_i": [67, 77], "ma": [26, 42, 61, 106], "mac": 104, "machin": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 26, 27, 28, 29, 32, 39, 43, 44, 45, 47, 48, 52, 53, 55, 60, 62, 63, 64, 66, 67, 68, 69, 70, 74, 76, 77, 78, 79, 92, 93, 95, 102, 107, 108], "machineri": [55, 106], "mackei": 106, "maco": 104, "made": [77, 108], "mae": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 59, 76], "maggi": 106, "magnitud": [93, 95], "mai": [53, 70], "main": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 55, 63, 69, 77, 92, 93, 95, 102, 106, 108], "mainli": 69, "maintain": [41, 103, 107], "mainten": 107, "major": [44, 69, 107], "make": [39, 47, 48, 59, 60, 69, 75, 76, 107, 108], "make_confounded_irm_data": [69, 107], "make_confounded_plr_data": 68, "make_did_sz2020": [5, 6, 53, 77], "make_heterogeneous_data": [50, 51, 56, 57, 58], "make_iivm_data": [8, 10, 75, 77], "make_irm_data": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 59, 75, 76, 77], "make_irm_data_discrete_treat": 47, "make_pipelin": 62, "make_pliv_chs2015": [11, 77], "make_pliv_multiway_cluster_ckms2021": [4, 42, 61], "make_plr_ccddhnr2018": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 40, 49, 60, 71, 72, 75, 76, 77, 78, 79, 92, 93, 98], "make_simple_rdd_data": [32, 67, 77], "make_spd_matrix": 28, "make_ssm_data": [70, 77], "malt": [103, 106], "maltekurz": 103, "man": [39, 48], "manag": [76, 104], "mani": [25, 30, 31, 40, 41, 42, 44, 49, 53, 60, 61, 72, 79, 92, 102, 108], "manili": 36, "manipul": [43, 44, 67, 77], "manual": [43, 60, 68, 108], "mao": 106, "map": [8, 34, 35, 41, 42, 61, 75, 77], "mapsto": [71, 75], "mar": [29, 77], "margin": [50, 51, 69], "marit": [43, 62], "marker": [47, 69], "markers": 64, "market": 64, "markettwo": 42, "markov": [28, 106], "marr": [43, 62, 63, 68, 108], "marshal": 76, "martin": [29, 69, 103, 106, 107], "masatoshi": 106, "master": 41, "mat": 42, "match": [76, 93, 100], "math": 15, "mathbb": [8, 9, 11, 12, 18, 19, 20, 24, 30, 31, 42, 47, 53, 54, 58, 59, 60, 61, 64, 67, 70, 75, 77, 79, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 105, 108], "mathcal": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 40, 42, 49, 52, 54, 61, 65, 66, 70, 72], "mathop": 75, "mathrm": [18, 19, 67, 77], "matia": 106, "matplotlib": [45, 47, 49, 50, 51, 52, 53, 54, 56, 57, 59, 60, 61, 62, 63, 64, 66, 67, 69, 70], "matric": [65, 74, 107], "matrix": [18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 40, 42, 43, 44, 49, 61, 70, 72, 73, 76, 92, 102, 105, 107, 108], "matt": 106, "matter": [59, 64], "max": [43, 44, 62, 63, 71, 75, 76, 77, 78, 79, 81, 92, 105, 108], "max_depth": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 45, 62, 68, 71, 75, 76, 77, 78, 79, 92, 93, 98, 105, 108], "max_featur": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 45, 62, 68, 71, 75, 76, 77, 78, 79, 92, 93, 98, 105, 108], "max_it": [61, 62, 69], "maxim": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 65, 75, 77], "maxima": [92, 102], "maximum": [75, 76], "mb": [45, 70, 73, 105], "mb706": 107, "mea": 22, "mean": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 39, 40, 42, 43, 47, 48, 49, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 66, 68, 69, 72, 76, 77, 92, 108], "mean_absolute_error": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 59, 76], "meant": [75, 107], "measir": 68, "measur": [41, 44, 55, 60, 68, 69, 76, 77, 93, 94, 95, 99, 100, 101], "measure_col": 55, "measure_func": 41, "measure_pr": 41, "measures_r": 41, "mechan": [34, 35, 69], "median": [69, 78], "melt": 42, "membership": 69, "memori": [45, 47, 53, 58, 61, 62, 63, 68, 70, 73, 105], "mention": [58, 75], "merg": [43, 62], "mert": [78, 106], "meshgrid": [50, 51, 69], "messag": [40, 41, 42, 43, 44, 105, 107], "meta": [76, 105], "metadata": [34, 35], "metadatarequest": [34, 35], "method": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 56, 57, 59, 61, 62, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 78, 79, 92, 93, 95, 98, 102, 103, 105, 107], "methodolog": 106, "methodologi": 69, "metric": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 76], "michael": 106, "michaela": 107, "michel": [103, 105], "michela": [29, 106], "mid": [43, 62, 64, 67, 77], "mid_point": 47, "might": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 42, 52, 59, 61, 65, 67, 68, 69, 76, 77], "mild": [40, 49, 72], "militari": 64, "miller": [42, 61], "mimic": 69, "min": [42, 43, 44, 52, 61, 62, 63, 66, 67, 71, 76, 77, 78, 79, 92, 102, 105, 108], "min_": 75, "min_samples_leaf": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 58, 62, 68, 71, 75, 76, 77, 78, 79, 92, 93, 98, 108], "min_samples_split": 62, "minim": [9, 37, 43, 59, 62, 67, 77], "minor": [40, 49, 72, 79, 107], "minsplit": 43, "minut": 60, "miruna": 106, "mislead": 107, "miss": [4, 7, 15, 44, 76, 77, 79, 87, 107], "missing": [29, 70], "misspecif": 53, "misspecifi": 53, "mit": [103, 105], "mixin": [30, 31, 79], "ml": [28, 42, 43, 44, 55, 60, 61, 62, 67, 71, 74, 76, 77, 78, 103, 106, 107], "ml_g": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 39, 40, 41, 43, 45, 47, 48, 49, 50, 52, 53, 54, 56, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 75, 76, 77, 107], "ml_g0": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 43, 45, 53, 59, 62, 68, 76, 77], "ml_g1": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 43, 45, 53, 59, 62, 68, 76, 77], "ml_g_d0": [70, 77], "ml_g_d0_t0": [53, 77], "ml_g_d0_t1": [53, 77], "ml_g_d1": [70, 77], "ml_g_d1_t0": [53, 77], "ml_g_d1_t1": [53, 77], "ml_g_sim": 15, "ml_l": [11, 12, 40, 42, 43, 44, 45, 49, 51, 57, 60, 61, 62, 64, 68, 71, 72, 76, 77, 78, 79, 92, 93, 98, 102, 105, 107, 108], "ml_l_bonu": 105, "ml_l_forest": 44, "ml_l_forest_pip": 44, "ml_l_lasso": 44, "ml_l_lasso_pip": 44, "ml_l_rf": 108, "ml_l_sim": 105, "ml_l_tune": 76, "ml_l_xgb": 108, "ml_m": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 78, 79, 92, 93, 98, 102, 105, 107, 108], "ml_m_bench_control": 69, "ml_m_bench_treat": 69, "ml_m_bonu": 105, "ml_m_forest": 44, "ml_m_forest_pip": 44, "ml_m_lasso": 44, "ml_m_lasso_pip": 44, "ml_m_rf": 108, "ml_m_sim": [15, 105], "ml_m_tune": 76, "ml_m_xgb": 108, "ml_pi": [15, 70, 77], "ml_pi_sim": 15, "ml_r": [8, 11, 39, 42, 43, 48, 61, 62, 77, 107], "ml_r0": 77, "ml_r1": [43, 62, 77], "mlr": [44, 76], "mlr3": [39, 40, 41, 42, 43, 71, 76, 77, 78, 79, 92, 102, 103, 105, 107, 108], "mlr3book": [44, 76], "mlr3extralearn": [43, 76], "mlr3filter": 44, "mlr3learner": [39, 40, 41, 42, 43, 71, 76, 77, 78, 79, 92, 102, 105, 108], "mlr3measur": 41, "mlr3pipelin": [76, 107], "mlr3tune": [44, 76, 107], "mlr3vers": 43, "mlrmeasur": 41, "mode": [69, 104], "model": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 40, 41, 42, 44, 48, 49, 52, 53, 54, 55, 58, 59, 61, 63, 66, 68, 71, 72, 73, 74, 76, 80, 82, 83, 84, 85, 89, 90, 94, 95, 98, 99, 100, 101, 102, 103, 106, 107], "model_data": [43, 62], "model_label": 60, "model_select": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 49, 61, 76, 78], "modelmlestimatelowerupp": 43, "modern": [44, 76, 103, 105], "modul": [67, 77, 104], "moment": [30, 31, 42, 61, 79, 92, 93, 95, 101, 102, 105], "monoton": 77, "mont": [18, 19, 21, 24, 50, 51, 56, 57], "montanari": 106, "more": [9, 36, 39, 41, 43, 47, 48, 50, 51, 55, 59, 60, 62, 63, 67, 68, 69, 71, 75, 76, 77, 79, 85, 92, 93, 95, 98, 101, 105, 108], "moreov": [43, 44, 55, 76, 92, 102, 108], "mortgag": [43, 62, 63], "most": [43, 52, 59, 62, 63, 66, 69, 75, 76, 77, 93, 98, 104], "motiv": [69, 72], "motivation_example_bch": 55, "mp": 41, "mpd": [42, 61], "mpg": 61, "mse": [44, 55, 76], "mserd": 67, "msr": [44, 76], "mtry": [43, 44, 71, 76, 77, 78, 79, 92, 108], "mu": 54, "mu_": 54, "mu_0": 77, "mu_mean": 54, "much": [43, 44, 62, 67, 69, 108], "muld": [45, 73, 105], "multi": [41, 42, 50, 51, 61], "multiclass": [44, 60], "multiindex": 61, "multipl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 24, 41, 42, 43, 53, 61, 62, 68, 69, 70, 73, 76, 78, 92, 93, 95, 102, 107, 108], "multipletest": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "multipli": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 49, 74, 75, 79, 108], "multiprocess": [52, 63, 66], "multitest": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "multivariate_norm": 15, "multiwai": [26, 42, 61, 106], "music": 106, "must": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 76, 77], "mutat": 44, "mutual": [1, 9, 12, 43, 56, 57, 62, 63, 75], "my_sampl": 78, "my_task": 78, "n": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 33, 39, 40, 42, 44, 47, 48, 49, 52, 54, 55, 58, 61, 64, 65, 66, 67, 70, 71, 72, 75, 76, 77, 78, 92, 102, 103, 104], "n_": [24, 54], "n_coef": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 93, 98], "n_complier": 66, "n_core": [52, 63, 66], "n_estim": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 45, 49, 50, 51, 52, 53, 54, 56, 57, 58, 62, 63, 65, 66, 67, 68, 69, 71, 72, 75, 76, 77, 78, 79, 92, 93, 98, 105, 108], "n_eval": [44, 76], "n_fold": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 40, 41, 42, 43, 45, 49, 50, 51, 52, 53, 56, 57, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72, 76, 78, 105, 108], "n_folds_per_clust": [42, 61], "n_folds_tun": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "n_iter": [32, 67, 77], "n_iter_randomized_search": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 76], "n_job": 62, "n_jobs_cv": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 59], "n_jobs_model": [2, 14, 52, 63, 66], "n_level": [24, 47], "n_ob": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 33, 36, 37, 40, 44, 47, 49, 50, 51, 53, 54, 56, 57, 58, 59, 60, 67, 68, 69, 70, 72, 73, 75, 76, 77, 78, 92, 93, 98, 102, 105], "n_rep": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 40, 41, 42, 45, 47, 49, 53, 58, 59, 61, 67, 68, 69, 70, 72, 76, 78, 93, 98, 105, 108], "n_rep_boot": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 36, 47, 50, 51, 52, 56, 57, 63, 66, 92, 102], "n_sampl": 65, "n_split": 78, "n_t": 54, "n_time_period": 54, "n_true": [52, 66], "n_var": [40, 44, 49, 72, 73, 76, 92, 102, 105], "n_w": 65, "n_x": [21, 50, 51, 56, 57, 58], "na": [4, 7, 40, 42, 72, 107], "na_real_": [42, 107], "naiv": [40, 49, 72], "name": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 34, 35, 40, 41, 42, 56, 57, 58, 60, 61, 67, 68, 69, 76, 104, 107], "namespac": 41, "nan": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 47, 49, 52, 53, 54, 56, 57, 59, 60, 62, 63, 66, 70, 72, 76], "nanmean": 49, "narita": 106, "nathan": 106, "nation": [69, 78, 106], "nativ": 41, "natt": 65, "natur": 69, "ncol": [42, 43, 44, 67, 73, 76, 92, 102, 105], "ncoverag": 59, "ndarrai": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 20, 22, 23, 25, 26, 27, 28, 29, 73], "nearli": 59, "necess": [42, 61], "necessari": [41, 42, 60, 61, 67, 77, 104], "need": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 31, 39, 40, 41, 43, 48, 49, 60, 63, 70, 76, 78, 93, 101, 107, 108], "neighborhood": [67, 92], "neither": [4, 7, 42, 61, 73], "neng": 106, "neq": [67, 77], "nest": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 76, 79, 88, 93, 98], "net": [63, 68, 108], "net_tfa": [43, 62, 63, 68, 108], "never": [8, 41, 42, 57, 61, 107], "never_tak": [8, 43, 62], "new": [39, 40, 41, 42, 43, 44, 50, 51, 60, 62, 65, 71, 72, 73, 75, 76, 77, 78, 79, 92, 102, 103, 105, 106, 107, 108], "new_data": [50, 51, 65], "newei": [16, 17, 27, 42, 55, 61, 69, 72, 103, 106], "newest": 107, "next": [41, 43, 44, 50, 51, 52, 58, 59, 62, 63, 65, 66, 69, 107], "neyman": [42, 61, 71, 74, 93, 101, 103, 106], "nfold": [42, 43], "nh": 77, "nice": 41, "nifa": [62, 63, 68], "nil": 69, "nine": [42, 61], "nn": 67, "noack": [67, 77, 106, 107], "node": [43, 44, 71, 77, 78, 79, 92, 105, 108], "nois": [33, 64, 65], "non": [20, 26, 27, 28, 32, 39, 40, 43, 48, 49, 54, 62, 63, 65, 67, 76, 78, 79, 92], "non_orth_scor": [40, 49, 79], "nondur": 45, "none": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 24, 32, 36, 42, 43, 45, 47, 48, 53, 58, 62, 63, 68, 69, 70, 73, 76, 77, 79, 92, 104, 105], "nonignor": [15, 88], "nonlinear": [31, 43, 62, 67, 77, 79, 86, 91, 107], "nonlinearscoremixin": 79, "nonparametr": [10, 13, 14, 67, 69, 93, 94, 95, 99, 100, 101, 106], "nop": 44, "nor": [4, 7, 42, 61, 73], "norm": 49, "normal": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 20, 40, 48, 49, 52, 53, 54, 58, 63, 64, 65, 66, 67, 70, 72, 73, 76, 77, 79, 82, 83, 92, 102, 105], "normalize_ipw": [1, 2, 3, 8, 9, 10, 13, 14, 15, 63, 70], "notat": [42, 53, 61, 70, 77], "note": [4, 7, 8, 9, 11, 12, 15, 30, 31, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 78, 79, 103, 105], "notebook": [39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 75, 76, 77, 108], "notic": [39, 48], "now": [41, 42, 43, 50, 51, 59, 61, 62, 65, 69, 70, 105, 107], "np": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 22, 23, 25, 26, 27, 28, 29, 32, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 105, 108], "nround": [40, 43, 108], "nrow": [41, 42, 44, 67, 73, 76, 92, 102, 105], "nu": [8, 20, 28, 70, 77, 93, 95, 98, 100, 101], "nu2": [93, 98], "nu_0": [93, 101], "nu_i": 70, "nuis_g0": 39, "nuis_g1": 39, "nuis_l": 108, "nuis_m": [39, 108], "nuis_r0": 39, "nuis_r1": 39, "nuis_rmse_ml_l": 55, "nuis_rmse_ml_m": 55, "nuisanc": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 27, 28, 32, 40, 41, 42, 43, 44, 49, 50, 51, 52, 53, 55, 58, 59, 61, 62, 63, 66, 68, 69, 70, 71, 72, 76, 77, 78, 79, 80, 82, 83, 86, 92, 93, 101, 103, 107, 108], "nuisance_el": [93, 94, 96, 97, 99, 100], "nuisance_loss": [59, 76, 107], "nuisance_target": 59, "null": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 68, 76, 93, 98, 107], "null_hypothesi": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 68, 93, 98], "num": [43, 44, 71, 76, 77, 78, 79, 92, 105], "num_leav": [52, 54, 63, 66], "number": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 36, 37, 40, 42, 49, 50, 51, 52, 54, 55, 56, 57, 59, 61, 63, 65, 66, 67, 69, 78, 92, 102, 103, 105, 108], "numer": [31, 39, 44, 64, 76, 79, 93, 94, 99, 107], "numeric_onli": 55, "numpi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 32, 36, 37, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 105], "ny": 106, "o": [47, 54, 56, 57, 60, 62, 64, 67, 92, 103, 105], "ob": [41, 43, 54, 67], "obei": 79, "obj_dml_data": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 39, 40, 42, 48, 49, 52, 60, 61, 66, 71, 72, 75, 76, 77, 78, 79, 92, 93, 98, 107], "obj_dml_data_bonu": 73, "obj_dml_data_bonus_df": 73, "obj_dml_data_from_arrai": [4, 7], "obj_dml_data_from_df": [4, 7], "obj_dml_data_sim": 73, "obj_dml_plr": [40, 49, 72], "obj_dml_plr_bonu": [44, 105], "obj_dml_plr_bonus_pip": 44, "obj_dml_plr_bonus_pipe2": 44, "obj_dml_plr_bonus_pipe3": 44, "obj_dml_plr_bonus_pipe_ensembl": 44, "obj_dml_plr_fullsampl": 60, "obj_dml_plr_lesstim": 60, "obj_dml_plr_nonorth": [40, 49], "obj_dml_plr_orth_nosplit": [40, 49], "obj_dml_plr_sim": [44, 105], "obj_dml_plr_sim_pip": 44, "obj_dml_plr_sim_pipe_ensembl": 44, "obj_dml_plr_sim_pipe_tun": 44, "obj_dml_sim": 15, "object": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 32, 34, 35, 36, 37, 39, 43, 44, 45, 47, 50, 51, 52, 53, 57, 58, 60, 62, 63, 66, 67, 70, 73, 75, 76, 77, 78, 79, 92, 103, 105, 106, 107, 108], "obs_confound": [39, 48], "observ": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 62, 63, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 82, 83, 92, 93, 95, 96, 97, 105, 106, 108], "obtain": [19, 39, 40, 41, 42, 48, 49, 50, 51, 52, 53, 55, 59, 61, 66, 69, 70, 71, 72, 75, 76, 78, 79, 92, 93, 95, 98, 102, 104, 105], "occur": [60, 107], "off": [65, 106], "offer": [41, 43, 62, 63, 69, 108], "offici": 104, "often": 66, "oka": 106, "ol": [1, 9, 12, 36], "olma": [67, 77, 106, 107], "omega": [58, 75, 79, 80, 85, 93, 94, 99], "omega_": [26, 42, 61], "omega_1": [26, 42, 61], "omega_2": [26, 42, 61], "omega_epsilon": [42, 61], "omega_v": [26, 42, 61], "omega_x": [26, 42, 61], "omit": [68, 69, 93, 95, 101, 106, 107, 108], "ommit": 69, "onc": [41, 60, 69, 77, 108], "one": [11, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 59, 61, 63, 64, 67, 68, 69, 72, 75, 76, 77, 78, 79, 82, 83, 85, 89, 90, 92, 93, 94, 95, 98, 99, 100, 102, 105, 107], "ones": [44, 52, 54, 60, 66, 68, 75], "ones_lik": [47, 66], "onli": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 36, 41, 42, 43, 50, 51, 56, 57, 58, 59, 60, 61, 62, 63, 67, 71, 75, 76, 77, 79, 81, 86, 91, 92, 93, 94, 95, 99, 101, 107], "onlin": 108, "onto": 59, "oo": 60, "oob_error": [44, 76], "oop": 107, "opac": [50, 51], "open": [44, 76, 103, 105], "oper": 44, "opposit": [65, 67, 77], "oprescu": [21, 50, 51, 56, 57, 106], "opt": [62, 69], "optim": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 32, 44, 50, 51, 60, 65, 75, 76, 106], "option": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 39, 40, 42, 43, 47, 50, 51, 56, 57, 58, 59, 61, 62, 63, 70, 76, 77, 78, 79, 81, 86, 91, 92, 102, 107], "oracl": [24, 33, 47], "oracle_valu": [18, 19, 24, 33, 47], "orang": 40, "orcal": [18, 19], "order": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 42, 43, 44, 61, 62, 67, 76, 77, 78, 79], "org": [22, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 76, 103, 104, 107], "orient": [44, 76, 79, 103, 105, 106, 107], "origin": [37, 41, 44, 57, 65, 68, 69, 75], "orign": [43, 62], "orth_sign": [36, 37], "orthogon": [36, 37, 42, 43, 61, 62, 71, 74, 77, 92, 93, 101, 102, 103, 106], "orthongon": [93, 101], "osx": 104, "other": [4, 7, 11, 12, 40, 42, 43, 44, 47, 49, 53, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 75, 76, 77, 78, 79, 85, 92, 93, 101, 103, 104, 105, 106, 107, 108], "other_ind": 61, "otherwis": [1, 5, 6, 8, 9, 12, 43, 62, 63, 65, 77], "othrac": [44, 45, 73, 105], "our": [40, 41, 43, 44, 49, 50, 51, 52, 53, 59, 60, 62, 63, 66, 67, 68, 69, 72, 77, 103, 105, 107, 108], "ourselv": 59, "out": [11, 12, 42, 44, 45, 53, 55, 59, 60, 61, 63, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 89, 90, 92, 93, 95, 98, 100, 103, 105, 107, 108], "outcom": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 24, 33, 39, 41, 42, 43, 44, 45, 48, 54, 55, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 73, 76, 80, 92, 94, 95, 98, 100, 101, 105, 107, 108], "outcome_0": 48, "outcome_1": 48, "outer": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 76], "output": [41, 59, 71, 92, 102, 108], "outshr": 61, "outsid": 40, "over": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 47, 49, 55, 59, 72, 74, 76, 93, 98, 102], "overal": [65, 69], "overcom": [74, 79], "overfit": [60, 74, 78], "overlap": [53, 69, 77], "overrid": [76, 107], "overridden": 77, "overst": [43, 62, 63], "overview": [59, 92, 93, 98, 106], "overwrit": 107, "ownership": [43, 62], "p": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 32, 33, 40, 41, 42, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 88, 91, 92, 93, 94, 99, 102, 103, 104, 105, 107], "p401": [43, 62, 63], "p_0": [79, 82, 83], "p_1": [92, 102], "p_adjust": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 78, 92, 102, 103, 105], "p_dbl": [44, 76], "p_int": 76, "p_n": 25, "p_val": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "p_x": [26, 42, 61], "p_x0": 64, "p_x1": 64, "packag": [39, 40, 42, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 78, 79, 92, 93, 95, 103, 105, 106, 107, 108], "packagedata": 61, "packagevers": 43, "page": [69, 103, 106], "pair": [39, 48], "pake": [42, 61], "paket": [42, 43, 44], "pal": 42, "palett": 47, "panda": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 36, 37, 45, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 75, 77, 93, 95, 105], "pandas2ri": 61, "panel": [5, 20, 97, 106, 107], "paper": [22, 25, 44, 60, 64, 67, 68, 69, 93, 101, 103, 105, 106, 107], "par": 45, "par_grid": [44, 76], "paradox": [44, 76, 107], "parallel": [41, 47, 52, 53, 54, 59, 66, 77], "param": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 34, 35, 60, 76], "param_grid": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 76], "param_nam": 41, "param_set": [44, 76], "param_v": 44, "paramet": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 47, 49, 50, 51, 52, 53, 55, 58, 59, 61, 62, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 86, 91, 92, 93, 95, 98, 99, 101, 102, 103, 105, 106, 107, 108], "parametr": [41, 69, 72, 76, 108], "params_exact": 76, "params_nam": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41], "parenttoc": 103, "part": [28, 40, 42, 43, 44, 49, 59, 60, 61, 62, 72, 76, 78, 93, 101, 107, 108], "parti": 28, "partial": [11, 12, 19, 25, 26, 27, 28, 31, 42, 44, 45, 55, 60, 61, 68, 71, 74, 76, 78, 89, 90, 92, 94, 98, 99, 100, 101, 102, 103, 105, 107, 108], "partial_": [79, 92], "partiallli": 68, "particip": [16, 63, 68, 108], "particular": [77, 103], "particularli": 60, "partion": [42, 61], "partit": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 42, 61, 71, 74], "partli": 108, "pass": [1, 9, 12, 36, 41, 44, 60, 76, 108], "passo": [103, 105], "past": 42, "paste0": 42, "pastel": 49, "path": [76, 77], "path_to_r": 55, "patsi": [50, 51, 75], "pattern": 69, "paul": 106, "pd": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 32, 36, 47, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 77], "pdf": [49, 64], "pedregosa": [103, 105], "pedregosa11a": [103, 105], "pedro": [41, 106], "penal": 70, "penalti": [43, 44, 48, 62, 69, 70, 76, 77], "pennsylvania": [17, 73, 105], "pension": [43, 62, 63, 108], "peopl": [43, 62, 63], "pep8": 107, "per": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 42, 61], "percent": 76, "percentag": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19], "perf_count": 59, "perfectli": [67, 77], "perform": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 37, 40, 42, 44, 49, 53, 55, 57, 58, 59, 60, 61, 63, 68, 69, 70, 72, 76, 77, 78, 79, 92, 102, 103, 105, 106, 108], "perfrom": 58, "perhap": 108, "period": [5, 41, 53, 54, 77], "perp": 77, "perrot": [103, 105], "person": 108, "pessimist": 69, "peter": 106, "pfister": [44, 76, 103, 105], "phi": [42, 61, 75, 92], "philipp": [69, 103, 106], "philippbach": [103, 107], "pi": [15, 23, 25, 28, 75, 77, 79, 87, 88], "pi_": [26, 42, 61], "pi_0": [79, 87, 88], "pi_i": [70, 77], "pick": [67, 108], "pip": [67, 77], "pip3": 104, "pipe": 44, "pipe_forest_classif": 44, "pipe_forest_regr": 44, "pipe_lasso": 44, "pipelin": [44, 62, 107], "pipeop": 44, "pira": [43, 62, 63, 68, 108], "pivot": [55, 61, 106], "plai": [60, 108], "plan": [16, 43, 62, 63, 108], "plausibl": 69, "pleas": [34, 35, 41, 47, 60, 69, 78, 104], "plim": 64, "pliv": [11, 30, 31, 42, 61, 71, 75, 89, 103, 107], "plm": [74, 76, 92, 93, 98, 108], "plot": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 37, 40, 41, 43, 44, 47, 49, 50, 51, 52, 54, 55, 56, 57, 58, 62, 63, 64, 66, 67, 68, 69, 70, 75, 93, 98], "plot_tre": [37, 65, 75], "plotli": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 50, 51, 55, 67, 69], "plr": [12, 30, 31, 44, 60, 64, 68, 71, 76, 78, 90, 92, 98, 99, 100, 101, 102, 103, 105, 107, 108], "plr_est": 64, "plr_est1": 64, "plr_est2": 64, "plr_obj": 64, "plr_obj_1": 64, "plr_obj_2": 64, "plr_summari": 62, "plrglmnet": 43, "plrranger": 43, "plrrpart": 43, "plrxgboost8700": 43, "plt": [45, 47, 49, 50, 51, 52, 53, 54, 56, 57, 59, 60, 61, 62, 63, 64, 66, 67, 69, 70], "plt_smpl": [42, 61], "plt_smpls_cluster": [42, 61], "plug": [58, 93, 94, 96, 97, 98, 99], "pm": [32, 42, 61, 92, 93, 98, 101, 102], "pmatrix": 70, "po": [44, 76], "point": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 42, 56, 57, 61, 69, 75, 77, 108], "pointwis": [36, 52, 56, 57, 66], "poli": [43, 61, 62], "polici": [9, 11, 12, 37, 74, 77, 105, 106, 107], "policy_tre": [9, 65, 75], "policy_tree_2": 65, "policy_tree_obj": 75, "policytre": 65, "polit": 64, "poly_dict": 62, "polynomi": [16, 17, 33, 43, 45, 62, 67], "polynomial_featur": [16, 17, 43, 45], "polynomialfeatur": [61, 62], "popul": [69, 79], "popular": [59, 77, 93, 95], "porport": 68, "posit": [28, 43, 64, 69, 108], "posixct": [44, 76], "possibl": [4, 7, 41, 44, 50, 51, 56, 57, 58, 59, 60, 65, 67, 68, 69, 76, 77, 92, 93, 95, 107, 108], "possibli": [93, 95], "post": [25, 28, 77, 92, 102, 106], "postdoubl": 106, "poster": 64, "potenti": [1, 2, 3, 10, 13, 15, 18, 24, 33, 53, 64, 67, 70, 80, 81, 92, 94, 104, 107, 108], "potential_level": 47, "power": [44, 60, 69, 76, 106], "pp": 41, "pq": [10, 13, 14, 63, 91, 107], "pq_0": [63, 66], "pq_1": [63, 66], "pr": [15, 39, 42, 43, 44, 76, 77, 78, 79, 92, 105, 108], "practic": [59, 69, 106], "pre": [41, 53, 70, 76, 77], "precis": [41, 77, 93, 99, 108], "pred": [41, 60], "pred_df": 65, "pred_dict": 76, "pred_treat": 65, "predict": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 32, 34, 35, 36, 37, 40, 42, 43, 44, 49, 52, 55, 59, 60, 61, 62, 65, 69, 72, 75, 78, 93, 95, 98, 99, 107, 108], "predict_proba": [1, 3, 5, 6, 8, 9, 10, 12, 13, 14, 15, 32, 34, 60, 76], "predictor": [1, 9, 12, 36, 37, 50, 51, 56, 57, 69, 71], "prefer": [43, 62, 63, 108], "preliminari": [3, 40, 49, 67, 79, 81, 86, 88, 91], "prepar": [41, 42, 61, 107], "preprint": 106, "preprocess": [43, 61, 62, 63, 76], "presenc": [43, 62, 63], "present": [41, 69, 76, 108], "prespecifi": 68, "pretest": 41, "pretreat": [5, 6, 41, 53], "prettenhof": [103, 105], "preval": 69, "prevent": [78, 107], "previou": [54, 58, 64, 104, 108], "previous": [76, 108], "price": [42, 61], "priliminari": [10, 14], "primari": 47, "principl": [93, 95], "print": [32, 40, 41, 42, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 104, 105, 107, 108], "print_detail": 41, "prior": [59, 77], "privat": 107, "prob": 44, "probabilit": 58, "probabl": [1, 3, 8, 9, 10, 13, 14, 15, 20, 24, 40, 41, 47, 49, 53, 58, 64, 66, 67, 69, 70, 72, 77, 79, 82, 83, 86, 106], "problem": [43, 62, 63, 75, 76], "procedur": [40, 42, 43, 49, 59, 61, 62, 68, 69, 76, 92, 102, 104, 107], "proceed": [25, 106], "process": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 41, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 65, 66, 69, 70, 74, 92, 93, 95, 102, 106, 107], "produc": 64, "product": [50, 51, 55, 59, 69, 93, 101], "producton": 42, "program": [23, 43, 62, 63, 106, 108], "progress": 46, "project": [44, 50, 51, 75, 103, 107], "project_z": [50, 51], "prone": 79, "pronounc": 67, "propens": [10, 14, 18, 19, 43, 53, 58, 59, 62, 63, 69, 70, 75, 77, 93, 94], "properli": [60, 108], "properti": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 43, 44, 59, 62, 63, 64, 68, 76, 77, 93, 98, 105, 107], "proport": [68, 93, 95, 100, 101], "propos": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 42, 44, 61, 67, 93, 95, 106, 107], "provid": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 32, 41, 42, 43, 44, 50, 51, 56, 57, 60, 61, 62, 67, 69, 71, 72, 73, 74, 76, 92, 102, 103, 105, 107, 108], "prune": [9, 37], "ps911c": 61, "ps944": 61, "pscore1": 64, "pscore2": 64, "psi": [30, 31, 40, 41, 42, 61, 71, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 101, 105], "psi_": [92, 93, 98, 100, 101, 102], "psi_a": [8, 9, 11, 12, 30, 40, 42, 49, 61, 78, 79, 80, 82, 83, 84, 85, 89, 90, 92], "psi_b": [8, 9, 11, 12, 30, 40, 49, 75, 78, 79, 80, 82, 83, 84, 85, 89, 90], "psi_el": [78, 79], "psi_j": [92, 102], "psi_nu2": [93, 98], "psi_sigma2": [93, 98], "public": [39, 48, 107], "publish": [69, 107], "pull": [43, 107], "purchas": 69, "pure": 69, "purp": [50, 51], "purpos": [40, 49, 58, 68, 69, 93, 95, 105], "pval": [92, 102], "px": [55, 67], "py": [57, 61, 62, 69, 103, 104, 107], "py3": 104, "py_al": 49, "py_dml": 49, "py_dml_nosplit": 49, "py_dml_po": 49, "py_dml_po_nosplit": 49, "py_double_ml_apo": 47, "py_double_ml_bas": 49, "py_double_ml_basic_iv": 48, "py_double_ml_c": 50, "py_double_ml_cate_plr": 51, "py_double_ml_cvar": 52, "py_double_ml_did": 53, "py_double_ml_did_pretest": 54, "py_double_ml_firststag": 55, "py_double_ml_g": 56, "py_double_ml_gate_plr": 57, "py_double_ml_gate_sensit": 58, "py_double_ml_learn": 59, "py_double_ml_meets_flaml": 60, "py_double_ml_multiway_clust": 61, "py_double_ml_pens": 62, "py_double_ml_pension_qt": 63, "py_double_ml_plm_irm_hetfx": 64, "py_double_ml_policy_tre": 65, "py_double_ml_pq": 66, "py_double_ml_rdflex": 67, "py_double_ml_sensit": 68, "py_double_ml_sensitivity_book": 69, "py_double_ml_ssm": 70, "py_non_orthogon": 49, "py_po_al": 49, "pydata": 57, "pypi": [106, 107], "pyplot": [45, 47, 49, 50, 51, 52, 53, 54, 56, 57, 59, 60, 61, 62, 63, 64, 66, 67, 69, 70], "pyproject": 107, "python": [28, 41, 60, 69, 71, 72, 73, 74, 75, 77, 78, 79, 92, 93, 95, 98, 102, 103, 105, 106, 107, 108], "python3": [62, 69, 104], "q": [44, 52, 66, 67, 76, 103, 105], "q2": [44, 45, 73, 105], "q3": [44, 45, 73, 105], "q4": [44, 45, 73, 105], "q5": [44, 45, 73, 105], "q6": [44, 45, 73, 105], "q_i": [67, 77], "qquad": 23, "qte": [52, 63, 107], "quad": [20, 43, 53, 62, 65, 67, 70, 75, 77, 79, 86, 92, 93, 96, 102], "quadrat": 70, "qualiti": [68, 71, 107], "quanitl": 63, "quant": 52, "quantifi": 69, "quantil": [2, 3, 10, 13, 14, 24, 47, 52, 68, 74, 76, 81, 86, 91, 106, 107], "quantiti": [39, 48, 69], "queri": 62, "question": [69, 108], "quick": 63, "quit": [59, 65, 68, 93, 95], "r": [8, 22, 49, 50, 51, 54, 55, 61, 64, 67, 69, 71, 72, 73, 74, 77, 78, 79, 84, 89, 92, 93, 94, 95, 99, 100, 101, 102, 103, 105, 106, 107, 108], "r2_d": [23, 59], "r2_y": [23, 59], "r6": [44, 107], "r_0": [8, 11, 43, 62, 77], "r_all": 40, "r_d": 23, "r_df": 61, "r_dml": 40, "r_dml_nosplit": 40, "r_dml_po": 40, "r_dml_po_nosplit": 40, "r_double_ml_bas": 40, "r_double_ml_basic_iv": 39, "r_double_ml_did": 41, "r_double_ml_multiway_clust": 42, "r_double_ml_pens": 43, "r_double_ml_pipelin": 44, "r_hat": 11, "r_hat0": 8, "r_hat1": 8, "r_non_orthogon": 40, "r_po_al": 40, "r_y": 23, "rais": [4, 7, 34, 35, 76], "randint": 64, "randn": 15, "random": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 24, 28, 29, 32, 33, 39, 40, 41, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 76, 78, 87, 92, 93, 98, 101, 102, 105, 106, 108], "random_search": 76, "random_st": [24, 49, 58, 65], "randomforest": [43, 59, 62], "randomforest_class": [43, 50, 62, 65], "randomforest_reg": [50, 65], "randomforestclassifi": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 45, 47, 50, 51, 56, 57, 58, 59, 62, 65, 67, 68, 69, 75, 76, 77, 108], "randomforestregressor": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 45, 47, 49, 50, 51, 56, 57, 58, 59, 62, 65, 67, 68, 69, 71, 75, 76, 77, 78, 79, 92, 93, 98, 105, 108], "randomized_search": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 76], "randomizedsearchcv": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 76], "randomli": [40, 42, 49, 61, 72, 78, 108], "rang": [40, 47, 49, 52, 53, 54, 56, 57, 59, 60, 61, 63, 65, 66, 67, 69, 70, 72, 76, 77], "rangeindex": [45, 47, 53, 58, 61, 62, 63, 68, 70, 73, 105], "ranger": [41, 43, 44, 71, 76, 77, 78, 79, 92, 105, 108], "rangl": [21, 65], "rank": 107, "rate": [55, 59, 77], "rather": [67, 69, 77], "ratio": [76, 78, 93, 95], "ravel": [50, 51], "raw": [43, 55, 62], "raw_res_manual_lasso_r_100_n_100_p_200_rho_0": 55, "rbind": 43, "rbindlist": 43, "rbinom": 39, "rbrace": [8, 9, 22, 23, 29, 42, 61, 71, 77, 78, 79, 80, 92, 93, 94, 102], "rcolorbrew": 42, "rcparam": [45, 50, 51, 52, 54, 56, 57, 61, 62, 63, 66], "rd": [77, 107], "rdbu": 42, "rdbu_r": 61, "rdbwselect": 77, "rdd": [4, 7, 74, 104], "rdflex": [67, 77, 107], "rdflex_fuzzi": 67, "rdflex_fuzzy_stack": 67, "rdflex_obj": [32, 77], "rdflex_sharp": 67, "rdflex_sharp_stack": 67, "rdrobust": [32, 67, 77, 104, 107], "rdrobust_fuzzi": 67, "rdrobust_fuzzy_noadj": 67, "rdrobust_sharp": 67, "rdrobust_sharp_noadj": 67, "rdt044": 55, "re": [61, 69, 104], "read": 104, "read_csv": 55, "readabl": 107, "readili": 103, "real": [43, 62, 63, 68, 93, 95], "realat": 77, "realiz": [67, 77], "reason": [4, 7, 39, 48, 68, 69, 93, 95, 108], "recal": [45, 93, 101], "receiv": [47, 67, 77], "recent": [60, 77], "recogn": [43, 62, 63], "recommend": [44, 59, 67, 69, 71, 78, 104, 106, 107], "recov": [39, 41, 48, 64], "recsi": 106, "red": [42, 56, 57, 60, 61], "reduc": [43, 58, 60, 62, 67, 68, 69, 77, 107], "redund": 107, "reemploy": [17, 73, 105], "refactor": 107, "refer": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 43, 47, 54, 58, 60, 62, 63, 67, 68, 73, 74, 75, 77, 93, 95, 98, 106, 107], "reference_level": [2, 47, 77], "refin": 107, "refit": [93, 95], "reflect": [65, 69, 75], "reg": [20, 43, 62, 108], "reg_estim": 67, "reg_learn": 63, "reg_learner_1": 59, "reg_learner_2": 59, "regard": [69, 103], "regener": 107, "region": [42, 52, 61, 92, 102, 106], "regr": [39, 40, 41, 42, 43, 44, 71, 76, 77, 78, 79, 92, 102, 105, 108], "regravg": [44, 76], "regress": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 22, 23, 24, 25, 26, 27, 28, 32, 33, 36, 39, 41, 42, 44, 47, 48, 55, 60, 61, 64, 68, 69, 70, 71, 72, 74, 75, 76, 78, 92, 94, 95, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108], "regressor": [35, 40, 43, 47, 49, 52, 59, 60, 62, 72], "regular": [25, 74, 76, 79, 92, 102, 106], "reich": [44, 76], "reinforc": 106, "reject": [43, 62], "rel": [43, 62, 93, 94, 95, 99], "relat": [69, 108], "relationship": [39, 48, 55, 69, 92, 102], "releas": 62, "relev": [4, 5, 6, 7, 21, 36, 52, 65, 66, 77, 93, 108], "reli": [50, 51, 53, 54, 58, 75, 76, 77, 93, 95, 108], "reload": 43, "remain": [41, 92, 102, 108], "remark": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 47, 49, 50, 51, 52, 54, 56, 57, 58, 59, 63, 68, 75, 76, 77, 79, 82, 83, 86, 91, 92, 93, 99], "remot": 104, "remov": [43, 62, 69, 74, 78, 107], "renam": [62, 107], "render": [68, 69], "reorgan": 107, "rep": [40, 72, 76, 92, 102], "repeat": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 39, 40, 42, 43, 44, 49, 58, 61, 62, 63, 64, 67, 68, 70, 72, 74, 76, 92, 96, 105, 107, 108], "repeatedkfold": 61, "repet": 68, "repetit": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 36, 50, 51, 55, 56, 57, 58, 59, 74, 76, 92, 105, 108], "repetiton": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32], "replac": [65, 69, 107], "replic": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 40, 43, 49, 55, 69], "repo": 107, "report": [43, 60, 62, 103, 107], "repositori": [55, 67, 107], "repr": [40, 42], "repres": [64, 69, 77], "represent": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 68, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 105, 107], "reproduc": 24, "request": 107, "requir": [11, 12, 39, 43, 44, 47, 58, 62, 63, 68, 77, 92, 93, 95, 98, 102, 104, 107, 108], "requirenamespac": 41, "res_df": 61, "res_dict": [18, 19, 21, 24, 33], "resampl": [39, 42, 44, 53, 61, 63, 68, 70, 76, 77, 78, 79, 92, 103, 105, 108], "research": [42, 44, 61, 64, 69, 78, 103, 105, 106, 108], "resembl": 70, "reset": 41, "reset_index": [55, 61, 62], "reshap": [49, 50, 51, 54], "reshape2": 42, "residu": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 68, 93, 95, 100, 101], "resolut": [44, 76], "resourc": 59, "resourcewis": 59, "respect": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 43, 47, 62, 63, 67, 75, 77, 78, 93, 101, 108], "respons": [16, 44, 76], "rest": 77, "restart": 104, "restrict": 59, "restructur": 107, "restud": 55, "result": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 39, 40, 41, 44, 47, 49, 50, 51, 53, 54, 55, 58, 59, 65, 67, 68, 69, 70, 72, 76, 78, 79, 82, 83, 93, 95, 98, 105, 107], "result_iivm": 43, "result_irm": 43, "result_plr": 43, "retina": 64, "retir": [43, 62, 63, 68], "return": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 44, 49, 52, 57, 59, 60, 61, 64, 65, 66, 68, 69, 70, 71, 76, 79, 93, 95, 107], "return_count": [47, 59], "return_tune_r": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "return_typ": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 40, 43, 44, 49, 53, 59, 60, 62, 63, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 92, 93, 98, 105, 108], "rev": 42, "reveal": 58, "review": [25, 55, 106], "revist": [42, 61], "rf": 67, "rho": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 47, 58, 67, 68, 69, 93, 95, 98, 101, 108], "rho_val": 69, "richter": [44, 76, 103, 105], "riesz": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 68, 93, 95, 96, 97, 98, 100, 101], "riesz_rep": [93, 98], "right": [22, 23, 25, 26, 29, 40, 42, 49, 59, 61, 62, 63, 64, 66, 67, 69, 72, 77, 79, 82, 83, 92, 93, 94, 96, 97, 99, 102], "rightarrow_": [40, 49, 72], "risk": [3, 74, 107], "ritov": 106, "rival": 61, "rival_ind": 61, "rmd": 41, "rmse": [41, 53, 59, 60, 63, 68, 70, 76, 77, 79, 92, 105, 107], "rmse_dml_ml_l_fullsampl": 60, "rmse_dml_ml_l_lesstim": 60, "rmse_dml_ml_l_onfold": 60, "rmse_dml_ml_l_untun": 60, "rmse_dml_ml_m_fullsampl": 60, "rmse_dml_ml_m_lesstim": 60, "rmse_dml_ml_m_onfold": 60, "rmse_dml_ml_m_untun": 60, "rmse_oos_ml_l": 60, "rmse_oos_ml_m": 60, "rmse_oos_onfolds_ml_l": 60, "rmse_oos_onfolds_ml_m": 60, "rnorm": [39, 44, 73, 76, 92, 102, 105], "robin": [16, 17, 27, 42, 55, 61, 72, 103, 106], "robinson": [40, 49, 72], "robject": 61, "robu": [56, 57], "robust": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 26, 32, 41, 47, 58, 67, 68, 69, 77, 93, 98, 106, 108], "roc\u00edo": 106, "role": [4, 7, 40, 49, 60, 72, 108], "romano": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 92, 102], "root": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 31, 55, 72, 76, 79, 106], "rotat": [60, 67], "roth": [67, 77, 106], "rough": [69, 108], "roughli": 69, "round": [43, 47, 59, 64, 69], "rout": [34, 35], "row": [40, 43, 45, 50, 51, 54, 60, 61, 65, 73, 78, 105, 108], "row_index": 57, "rownam": 42, "rowv": 42, "roxygen2": 107, "royal": [69, 106], "rpart": [43, 44, 76], "rpart_cv": 44, "rprocess": 59, "rpy2": 61, "rpy2pi": 61, "rsmp": [44, 76, 78], "rsmp_tune": [44, 76], "rssb": 69, "rtype": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "ruben": 106, "ruiz": [39, 48], "rule": [41, 75], "run": [41, 67, 77, 104, 107], "runif": 39, "runtime_learn": 44, "rv": [47, 58, 68, 69, 93, 98, 108], "rva": [47, 58, 68, 69, 93, 98, 108], "rvert": 55, "rvert_": 55, "s1": 60, "s2": 60, "s_": [26, 42, 61, 77], "s_1": 27, "s_2": 27, "s_col": [4, 7, 67, 70, 77], "s_i": [29, 67, 70, 77], "s_x": [26, 42, 61], "safeguard": [53, 76], "sake": [43, 62, 69, 108], "same": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 24, 36, 40, 42, 49, 50, 51, 58, 59, 61, 63, 65, 67, 68, 69, 70, 76, 79, 82, 83, 92, 93, 99, 107], "samii": 64, "sampl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 26, 29, 32, 39, 41, 42, 44, 48, 53, 56, 57, 59, 61, 63, 65, 68, 74, 76, 92, 102, 105, 106, 107], "sample_weight": [32, 67], "sant": [5, 6, 18, 19, 20, 24, 41, 53, 77, 106], "sara": 106, "sasaki": [26, 42, 61, 106], "satisfi": [70, 76, 79, 92], "save": [40, 43, 49, 56, 57, 59, 60, 62, 63, 76, 93, 98, 108], "savefig": 49, "saveguard": 59, "saver": [43, 62, 63], "scalar": 77, "scale": [40, 42, 52, 54, 64, 66, 69, 92, 93, 101], "scale_color_manu": 40, "scale_fill_manu": [40, 42], "scatter": [47, 54, 56, 57, 64, 67, 69], "scatterplot": 47, "scenario": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 47, 58, 68, 69, 77, 93, 98, 108], "scene": [50, 51, 55], "scene_camera": 55, "schaefer": 64, "schedul": 107, "scheme": [42, 61, 76, 78, 103], "schneider": 44, "schratz": [44, 76, 103, 105], "scienc": [28, 39, 48, 64, 106], "scikit": [59, 62, 76, 103, 105, 107, 108], "scipi": 49, "score": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 30, 31, 32, 33, 39, 41, 42, 43, 44, 45, 50, 51, 52, 53, 55, 58, 59, 60, 61, 62, 63, 66, 67, 68, 69, 70, 71, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 96, 97, 98, 99, 100, 101, 103, 107, 108], "scoring_method": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "script": 104, "sd": 39, "se": [40, 42, 49, 68, 72, 76, 78, 92, 93, 98, 106, 108], "se_df": 42, "se_dml": [40, 49, 72], "se_dml_po": [40, 49, 72], "se_nonorth": [40, 49], "se_orth_nosplit": [40, 49], "se_orth_po_nosplit": [40, 49], "seaborn": [45, 47, 49, 53, 59, 61, 62, 63, 69, 70], "search": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 31, 76, 79], "search_mod": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 76], "searchabl": 43, "second": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 26, 40, 42, 44, 49, 59, 60, 61, 71, 72, 78, 92, 93, 95, 101, 102, 105], "secondari": 47, "section": [6, 20, 41, 42, 43, 44, 58, 60, 61, 63, 69, 96, 107], "secur": 64, "see": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 23, 29, 30, 31, 36, 39, 41, 42, 43, 44, 47, 48, 50, 51, 53, 57, 60, 61, 63, 64, 65, 67, 68, 69, 76, 77, 78, 79, 81, 85, 86, 87, 88, 91, 93, 95, 98, 101, 104, 105, 107], "seed": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 24, 32, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 92, 93, 98, 102, 105, 108], "seek": 64, "seem": [41, 43, 58, 62, 63, 108], "seen": [56, 57], "sel_cols_chiang": 61, "select": [4, 7, 15, 24, 25, 29, 55, 59, 67, 69, 71, 74, 76, 106, 107, 108], "selected_coef": 59, "selected_featur": [44, 76], "selected_learn": 59, "self": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 36, 37, 59, 60, 108], "selfref": 43, "semenova": [50, 51, 106], "semi": 72, "semiparametr": 16, "sens": [68, 69], "sensemakr": [93, 95], "sensit": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 74, 75, 95, 98, 101, 107], "sensitivity_analysi": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 47, 58, 68, 69, 93, 98, 108], "sensitivity_benchmark": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 47, 58, 68, 69, 93, 95], "sensitivity_el": [93, 98], "sensitivity_param": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 68, 69, 93, 95, 98], "sensitivity_plot": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 47, 58, 68, 69, 93, 98], "sensitivity_summari": [47, 58, 68, 69, 93, 98, 108], "sensitvity_benchmark": 47, "sensiv": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "senstiv": [93, 100], "sep": 40, "separ": [64, 68, 76, 77, 107], "seper": [60, 67, 68, 78, 92, 93, 95], "seq_len": [40, 72], "sequenti": 17, "seri": [57, 69, 106], "serv": [73, 105, 107], "serverless": [106, 107], "servic": 64, "set": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 26, 27, 28, 37, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 75, 77, 78, 79, 80, 82, 83, 85, 92, 93, 94, 95, 99, 100, 102, 104, 105, 107, 108], "set_as_param": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "set_fold_specif": 76, "set_index": 62, "set_ml_nuisance_param": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 43, 45, 62, 76, 107], "set_param": [34, 35, 60, 76], "set_sample_split": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 59, 78, 107], "set_styl": [62, 63], "set_text": 59, "set_threshold": [40, 41, 42, 43, 44, 71, 76, 77, 78, 79, 92, 102, 105], "set_tick": 61, "set_ticklabel": 61, "set_titl": [47, 60, 61, 67], "set_x_d": [4, 7], "set_xlabel": [47, 49, 60, 61, 67], "set_xlim": 49, "set_xtick": 64, "set_xticklabel": 64, "set_ylabel": [47, 60, 61, 64, 67], "set_ylim": [52, 60, 61, 66], "setdiff": 107, "setdiff1d": 61, "setminu": [42, 61, 92, 102], "settings_l": 60, "settings_m": 60, "setup": [104, 107], "seven": [42, 61], "sever": [38, 43, 44, 59, 60, 62, 63, 68, 69, 72, 76, 108], "shape": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 36, 37, 47, 50, 51, 54, 56, 57, 59, 61, 62, 65, 67, 68, 69, 76, 77], "share": [42, 43, 61, 62], "sharma": [69, 106], "sharp": 32, "shock": [42, 61], "short": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 68, 69, 93, 95, 106, 107, 108], "shortcut": 43, "shortli": [42, 44, 61, 76], "shota": 106, "should": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 31, 43, 47, 56, 57, 59, 62, 67, 68, 70, 73, 75, 76, 77, 92, 93, 95, 103], "show": [39, 40, 42, 45, 47, 48, 49, 50, 51, 53, 55, 58, 59, 60, 61, 64, 67, 69, 70, 72, 93, 100, 104], "showcas": 65, "showlabel": 69, "showlegend": 69, "shown": [39, 48, 64, 105], "showscal": [50, 51, 55], "shrink": 67, "shuffl": 78, "side": [67, 77, 93, 98], "sigma": [15, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 40, 42, 49, 61, 70, 72, 75, 78, 92, 93, 95, 98, 100, 101, 102], "sigma2": [93, 98], "sigma_": [19, 20, 22, 23, 25, 26, 27, 29, 40, 42, 49, 61, 72], "sigma_0": [93, 101], "sigma_j": [92, 102], "sigmoid": 64, "sign": 69, "signal": [36, 37], "signatur": [8, 9, 10, 11, 12, 13, 14, 79], "signif": [39, 41, 42, 43, 44, 76, 77, 78, 79, 92, 105, 108], "signific": [39, 42, 43, 44, 47, 58, 62, 65, 67, 68, 69, 76, 77, 78, 79, 92, 93, 98, 105, 108], "silverman": [10, 13, 14], "sim": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 40, 41, 42, 49, 52, 54, 61, 65, 66, 70, 72, 77], "similar": [19, 24, 41, 44, 50, 51, 58, 60, 63, 67, 68, 69, 77], "similarli": 60, "simpl": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 21, 41, 44, 50, 51, 56, 57, 58, 65, 69, 74, 77, 93, 95], "simplest": 75, "simpli": [44, 53, 108], "simplic": [43, 59, 62, 65, 69], "simplif": [93, 96], "simplifi": [64, 69, 75, 93, 100], "simul": [18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 40, 44, 49, 50, 51, 52, 55, 56, 57, 66, 67, 69, 70, 72, 76, 92, 102, 105], "simul_data": 15, "simulaten": 77, "simulation_run": 55, "simult": 41, "simultan": [74, 108], "sin": [21, 24, 28, 50, 51, 54, 56, 57], "sinc": [18, 19, 43, 47, 53, 54, 56, 57, 58, 59, 60, 62, 64, 70, 76, 77, 93, 98, 99, 104, 107], "singl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 53, 56, 57, 63, 64, 76, 92, 102], "single_learner_pipelin": 76, "singleton": 78, "sinh": 28, "sipp": [43, 62, 63], "site": [61, 62, 69], "situat": [42, 61], "six": 42, "sixth": 61, "size": [15, 40, 42, 43, 44, 49, 52, 54, 55, 58, 59, 60, 62, 64, 65, 66, 69, 71, 73, 76, 77, 78, 79, 92, 102, 105, 108], "sizeabl": 69, "skill": 106, "sklearn": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 28, 32, 37, 45, 47, 48, 49, 50, 51, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 67, 68, 69, 70, 71, 75, 76, 77, 78, 79, 92, 93, 98, 102, 105, 108], "skotara": 69, "slide": 64, "slightli": [54, 56, 57, 58, 59, 75, 79, 82, 83, 93, 95], "sligthli": [5, 6], "slow": [40, 49, 72], "slower": [40, 49, 72], "small": [21, 53, 54, 65, 70, 77, 93, 95, 99], "smaller": [43, 53, 56, 57, 58, 60, 62, 67, 69, 77, 108], "smallest": 59, "smpl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 40, 42, 49, 59, 61, 78, 79], "smpls_cluster": [42, 61], "smsg": 62, "sn": [45, 47, 49, 53, 59, 61, 62, 63, 69, 70], "so": [39, 43, 44, 48, 53, 60, 62, 64, 69, 70, 76, 92, 108], "social": [64, 106], "societi": [42, 61, 69, 106], "softwar": [44, 76, 103, 105, 106, 107], "solari": 107, "sole": 69, "solut": [71, 75, 79], "solv": [30, 42, 61, 75, 76, 92, 102], "solver": [62, 70, 77], "some": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 43, 44, 45, 53, 54, 59, 60, 62, 63, 67, 68, 70, 75, 76, 77, 104, 107], "sometim": 59, "sonabend": [44, 76], "sophist": 76, "sort": [62, 77], "sort_valu": 47, "sourc": [44, 76, 105, 107], "sourcefileload": 55, "sp": 41, "space": [42, 61, 76], "spars": [55, 76, 92, 102, 105, 106], "sparsiti": 106, "spec": 106, "special": [42, 61, 77], "specif": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 31, 32, 42, 43, 47, 59, 61, 62, 69, 73, 74, 75, 76, 77, 78, 79, 85, 92, 98, 101, 103, 105], "specifi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 32, 39, 42, 43, 44, 47, 48, 50, 51, 52, 53, 56, 57, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 77, 80, 85, 104, 105, 107, 108], "specifii": 63, "speed": [2, 14, 59], "speedup": 59, "spefici": 8, "spindler": [25, 69, 103, 106, 107], "spine": [62, 63], "spline": [50, 51, 75], "spline_basi": [50, 51, 75], "spline_grid": [50, 51], "split": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 39, 42, 44, 53, 59, 61, 63, 65, 68, 70, 74, 75, 76, 77, 79, 92, 105, 107], "split_sampl": 59, "sponsor": [43, 62, 63], "sprintf": 40, "sq_error": 55, "sqrt": [18, 19, 20, 23, 24, 40, 42, 44, 45, 49, 52, 61, 66, 72, 78, 92, 93, 95, 102, 105], "squar": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 43, 55, 62, 76, 77, 93, 101, 106], "squarederror": [43, 62, 108], "squeez": [52, 53, 66, 70], "src": 62, "ssm": [4, 7, 29, 74], "ssrn": 22, "stabil": 58, "stabl": [39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 103], "stack": [44, 76], "stackingclassifi": 67, "stackingregressor": 67, "stacklrn": 44, "stackrel": 77, "stage": [32, 50, 51, 56, 57, 65, 67, 76, 77, 107, 108], "standard": [20, 41, 44, 52, 56, 57, 67, 77, 78, 79, 92, 93, 98, 101, 102, 107, 108], "standard_norm": [73, 76, 92, 102, 105], "standardscal": 62, "star": 77, "start": [41, 43, 44, 50, 51, 55, 58, 59, 60, 61, 62, 66, 69, 77, 103, 108], "stat": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 49, 67, 73, 76, 77, 92, 102, 103, 106], "stat_bin": 40, "stat_dens": 43, "state": 108, "stationar": 53, "stationari": 77, "statist": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 26, 29, 38, 42, 61, 68, 69, 92, 93, 98, 102, 103, 105, 106, 107, 108], "statsmodel": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 36, 67], "statu": [41, 43, 53, 62, 64, 67, 70], "std": [3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 39, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 56, 57, 58, 60, 61, 62, 63, 64, 66, 68, 69, 70, 75, 76, 77, 78, 79, 92, 105, 108], "stefan": 106, "step": [40, 43, 44, 49, 56, 57, 58, 62, 65, 72, 76, 77, 92, 102, 103, 108], "stepdown": [92, 102], "stick": [43, 62], "still": [50, 51, 53, 56, 57, 58, 63, 67, 68, 70, 76], "stochast": [11, 12, 77, 105], "stock": [43, 62, 63], "store": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 71, 76, 78, 79, 92, 93, 98, 107], "store_model": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 60], "store_predict": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 41, 62, 65], "stori": [69, 106], "str": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 32, 36, 43, 47, 56, 57, 66, 67, 75, 77, 107], "straightforward": [56, 57, 59, 75], "strategi": [64, 69, 77, 108], "stratifi": 59, "stratum": 64, "strength": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 68, 69, 93, 95, 98, 100], "strictli": 77, "string": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 75, 92, 93, 98, 105, 107], "string_label": 64, "strong": [70, 93, 95], "stronger": [92, 108], "structur": [16, 17, 27, 42, 43, 55, 61, 62, 70, 72, 76, 103, 106, 108], "student": 106, "studi": [29, 42, 43, 55, 60, 61, 62, 63, 68, 105, 108], "style": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 60, 107], "styler": 107, "styliz": 69, "sub": [42, 61], "subclass": 107, "subfold": 76, "subgroup": [8, 43, 62, 107], "subject": [42, 61], "submiss": 107, "subobject": [34, 35], "subplot": [42, 47, 49, 50, 51, 52, 54, 56, 57, 59, 60, 61, 62, 63, 64, 66, 67], "subplots_adjust": 59, "subpopul": 77, "subsampl": [44, 59], "subscript": [93, 95], "subsequ": [42, 61], "subset": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 42, 59, 61, 65, 71, 75, 76, 93, 95], "subseteq": 75, "substanti": [43, 62, 64], "substract": 92, "subtract": 92, "sudo": 104, "suffic": 69, "suffici": [59, 60, 69], "suggest": [42, 43, 61, 62, 69, 107], "suitabl": [50, 51, 70], "sum": [42, 43, 61, 62, 63, 66, 67, 75, 92, 102], "sum_": [33, 40, 42, 49, 61, 67, 71, 72, 75, 77, 92, 102], "sum_i": 64, "sum_oth": 61, "sum_riv": 61, "summar": [41, 47, 64, 69, 71, 93, 98], "summari": [3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 39, 41, 42, 44, 45, 47, 48, 50, 51, 52, 53, 56, 57, 58, 61, 63, 66, 68, 69, 70, 72, 73, 75, 76, 77, 78, 79, 92, 93, 105, 107, 108], "summary_result": 43, "suppli": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 50, 51, 56, 57, 58, 65, 75, 93, 94, 95, 98], "support": [8, 21, 32, 41, 42, 59, 61, 65, 67, 76, 77, 108], "support_s": [21, 50, 51, 56, 57, 65], "support_t": 65, "support_w": 65, "suppos": 69, "suppress": [41, 43, 44], "suppresswarn": 40, "suprema": [92, 102], "suptitl": [52, 59, 60, 63, 66], "supxlabel": [52, 63, 66], "supylabel": [52, 63, 66], "sure": [47, 76, 107], "surfac": [50, 51, 55], "surpress": [42, 105], "survei": [43, 62, 63, 108], "susan": 106, "sven": [69, 103, 106], "svenk": 61, "svenklaassen": 103, "svg": [40, 49], "switch": [40, 49, 69, 72], "symbol": 69, "symmetr": 28, "syntax": [67, 77], "synthet": [21, 33, 39, 48, 50, 51, 52, 56, 57, 60, 65, 66], "syrgkani": [69, 106], "system": 106, "szita": 106, "t": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 24, 32, 39, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 83, 92, 93, 96, 102, 105, 108], "t_1_start": 59, "t_1_stop": 59, "t_2_start": 59, "t_2_stop": 59, "t_3_start": 59, "t_3_stop": 59, "t_col": [4, 6, 7, 77], "t_df": 65, "t_diff": 54, "t_dml": 40, "t_i": [53, 65, 67, 77], "t_idx": 54, "t_nonorth": 40, "t_orth_nosplit": 40, "t_sigmoid": 65, "t_stat": 92, "tabl": [40, 42, 43, 44, 47, 71, 73, 76, 77, 78, 79, 92, 102, 105, 108], "tabular": [59, 73, 92, 102, 105, 108], "taddi": 106, "take": [8, 9, 11, 12, 18, 19, 21, 50, 51, 52, 53, 54, 55, 56, 57, 59, 63, 66, 67, 68, 70, 71, 75, 76, 77, 79, 80, 85, 93, 94, 99, 100, 105], "taken": [43, 62, 63, 108], "taker": [8, 107], "talk": 108, "target": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 30, 31, 39, 42, 43, 44, 50, 51, 59, 61, 75, 76, 77, 78, 79, 86, 91, 92, 93, 99, 101, 102, 103, 105, 107, 108], "task": [39, 60, 73, 78, 108], "task_typ": 107, "tau": [33, 52, 54, 63, 64, 66, 67, 75, 77, 79, 81, 86, 91], "tau_": [64, 67, 77], "tau_0": [67, 77], "tau_1": 64, "tau_2": 64, "tau_vec": [52, 63, 66], "tax": [43, 62, 63], "te": [41, 50, 51, 65], "techniqu": [40, 49, 72, 78, 108], "templat": 107, "temporari": 62, "ten": 60, "tend": [43, 62, 63, 77], "tensor": [50, 51], "tenth": 106, "term": [40, 42, 43, 44, 49, 54, 55, 61, 62, 64, 69, 72, 77, 103, 108], "termin": [44, 76], "terminatorev": 44, "test": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 22, 39, 40, 41, 42, 43, 44, 49, 58, 61, 69, 72, 76, 77, 78, 79, 92, 102, 105, 106, 107, 108], "test_id": [42, 78], "test_ind": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "test_set": 78, "test_siz": 49, "text": [18, 19, 20, 22, 24, 32, 33, 42, 43, 52, 55, 64, 65, 66, 67, 69, 75, 77, 78], "textbf": [71, 76, 108], "textposit": 69, "textrm": [93, 94, 95, 99, 100, 101], "tg": [44, 45, 73, 105], "th": [42, 61], "than": [9, 40, 41, 43, 49, 55, 59, 62, 63, 64, 67, 68, 69, 72, 77, 93, 98, 108], "thank": [41, 43, 44, 62, 107], "thatw": 54, "thei": [41, 43, 54, 56, 57, 62, 64, 77, 93, 101], "them": [43, 44, 50, 51, 52, 58, 60, 62, 66, 77], "theme": [42, 43], "theme_minim": [40, 43], "theorem": [93, 101], "theoret": [59, 69, 78, 106], "theori": [75, 106], "therebi": [42, 44, 61, 108], "therefor": [47, 64, 67, 68, 78, 79, 93, 100], "theta": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 22, 23, 24, 26, 28, 29, 30, 31, 40, 42, 44, 47, 49, 53, 54, 55, 58, 59, 61, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 98, 100, 101, 102, 105, 108], "theta_": [47, 67, 69, 75, 77, 92, 93, 101, 102], "theta_0": [8, 9, 11, 12, 21, 40, 42, 43, 47, 49, 50, 51, 55, 56, 57, 61, 62, 69, 70, 72, 75, 77, 79, 86, 91, 92, 93, 94, 99, 101, 105], "theta_dml": [40, 49, 72], "theta_dml_po": [40, 49, 72], "theta_initi": 49, "theta_nonorth": [40, 49], "theta_orth_nosplit": [40, 49], "theta_orth_po_nosplit": [40, 49], "theta_resc": 40, "theta_t": 54, "thi": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 31, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 75, 76, 77, 78, 79, 81, 82, 83, 86, 91, 92, 93, 94, 95, 98, 99, 103, 104, 105, 106, 107, 108], "think": 44, "third": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 40, 49, 61, 72, 78], "thirion": [103, 105], "this_df": [55, 62], "this_split_ind": 61, "those": [41, 43, 62, 63], "though": [39, 48, 64], "thread": [64, 76], "three": [42, 44, 56, 57, 104, 107], "threshold": [1, 3, 5, 6, 8, 9, 10, 13, 14, 15, 67, 69, 77], "through": [41, 52, 56, 57, 66, 67, 76, 77], "throughout": 58, "thu": [60, 67, 75, 77], "tibbl": 41, "tick_param": 67, "tight": 49, "tight_layout": [60, 61, 67], "tighter": 67, "tild": [18, 19, 20, 24, 42, 61, 64, 71, 75, 78, 79, 86, 87, 88, 91, 92, 93, 100, 101, 102], "time": [4, 5, 7, 25, 26, 40, 41, 42, 43, 49, 53, 54, 55, 56, 57, 61, 62, 63, 67, 68, 69, 70, 77, 107, 108], "time_budget": 60, "time_df": 54, "time_period": 54, "titiunik": [77, 106], "titl": [42, 43, 47, 50, 51, 52, 55, 56, 57, 59, 60, 61, 62, 63, 64, 66, 67, 69, 103], "tmp": 57, "tname": 41, "tnr": [44, 76], "to_fram": 65, "to_numpi": [52, 58, 63, 66], "todo": [42, 45], "toeplitz": 55, "togeth": [56, 57, 92], "toler": 61, "tomasz": [106, 107], "toml": 107, "too": 59, "tool": [41, 44, 68, 108], "top": [42, 59, 61, 62, 63, 67, 69, 77, 103], "total": [43, 60, 62], "tpot": 60, "tracker": 103, "tradit": [92, 102], "train": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 40, 42, 44, 49, 50, 51, 52, 56, 57, 59, 61, 65, 66, 71, 72, 78], "train_id": [42, 78], "train_ind": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "train_set": 78, "train_test_split": 49, "transact": 106, "transform": [18, 19, 33, 64, 69, 108], "translat": 55, "transpos": 54, "treament": 65, "treat": [9, 20, 41, 47, 53, 54, 58, 65, 67, 69, 75, 77, 92, 108], "treat1_param": 64, "treat2_param": 64, "treat_var": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 76], "treatment": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 27, 32, 39, 41, 42, 44, 45, 47, 48, 53, 54, 55, 58, 59, 60, 61, 65, 67, 68, 69, 70, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 85, 86, 91, 92, 93, 94, 98, 100, 102, 103, 105, 106, 107, 108], "treatment_df": 54, "treatment_effect": [21, 50, 51], "treatment_level": [1, 2, 47, 77], "treatment_var": [4, 7], "tree": [9, 37, 43, 44, 53, 54, 59, 62, 71, 74, 76, 77, 78, 79, 92, 105, 107], "tree_param": [9, 37], "tree_summari": 62, "trees_class": [43, 62], "trend": [41, 53, 54, 61, 77, 106], "tri": [55, 93, 95], "triangular": [32, 67, 77], "trim": [1, 3, 5, 6, 8, 9, 10, 13, 14, 15, 43, 62, 63, 69], "trimming_rul": [1, 2, 3, 5, 6, 8, 9, 10, 13, 14, 15, 63], "trimming_threshold": [1, 2, 3, 5, 6, 8, 9, 10, 13, 14, 15, 43, 50, 62, 63, 65, 66, 69], "trm": [44, 76], "true": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 24, 29, 32, 33, 34, 35, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 76, 77, 78, 79, 80, 81, 86, 87, 88, 91, 92, 93, 96, 97, 101, 102, 105, 108], "true_effect": [50, 51, 54, 56, 57], "true_gatet_effect": 58, "true_group_effect": 58, "true_tau": 67, "truncat": [1, 2, 3, 5, 6, 8, 9, 10, 13, 14, 15, 63], "try": [59, 68], "tune": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 55, 67, 74, 77, 103, 105, 107], "tune_on_fold": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 76], "tune_r": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "tune_set": [44, 76], "tuned_model": 60, "tuner": 76, "tunergridsearch": 44, "tupl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "turn": 69, "turrel": 28, "tutori": 43, "tw": [62, 63], "twice": 77, "twinx": 47, "two": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 39, 40, 43, 44, 48, 49, 52, 53, 59, 60, 62, 63, 64, 65, 66, 68, 69, 71, 72, 75, 76, 77, 78, 79, 86, 92, 102, 108], "twoclass": 44, "twoearn": [43, 62, 63, 68, 108], "type": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 21, 24, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 49, 59, 60, 61, 67, 69, 72, 76, 77, 79, 89, 90, 92, 93, 100, 102, 107, 108], "typic": [57, 77, 103], "u": [8, 9, 10, 13, 14, 18, 19, 20, 21, 23, 29, 40, 41, 42, 43, 47, 49, 52, 53, 54, 56, 57, 59, 61, 62, 63, 65, 66, 68, 69, 72, 77, 93, 95, 104, 108], "u_hat": [40, 49, 79], "u_i": [22, 25, 28, 29], "u_t": 20, "uehara": 106, "uhash": 44, "ulf": 106, "unambigu": 69, "uncertainti": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 56, 57, 67, 68, 93, 98, 108], "uncondit": [43, 62, 108], "unconfounded": [69, 106], "under": [15, 40, 43, 49, 53, 62, 65, 67, 69, 72, 77, 92, 106], "underbrac": [40, 49, 54, 72, 75], "underfit": 60, "underli": [18, 24, 43, 44, 47, 56, 57, 64, 65, 77, 93, 95, 108], "underlin": [42, 61], "underset": [67, 77], "understand": 69, "undesir": 76, "unevenli": 78, "uniform": [20, 32, 33, 48, 50, 51, 52, 54, 65, 66, 92], "uniformli": [52, 63, 92, 102], "uniqu": [39, 47, 48, 59, 67, 79, 93, 101], "unique_label": 60, "unit": [40, 41, 53, 54, 58, 67, 70, 77, 79, 82, 83, 107], "univari": [21, 50, 51], "univers": 106, "unknown": 77, "unlik": [43, 62, 63, 69], "unobserv": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 39, 43, 48, 62, 63, 68, 69, 77, 93, 95, 101, 108], "unpen": 41, "unstabl": [93, 95], "unter": [42, 43, 44], "untest": 69, "until": [77, 107], "untreat": [69, 77], "up": [2, 14, 43, 55, 59, 60, 62, 63, 68, 69, 76, 77, 78, 93, 95, 104, 107, 108], "upcom": 107, "updat": [42, 57, 61, 106, 107], "update_layout": [50, 51, 55, 67, 69], "update_trac": [50, 51], "upload": 107, "upon": [79, 107], "upper": [43, 44, 47, 49, 52, 54, 58, 63, 66, 67, 68, 69, 76, 93, 98, 101, 108], "upper_bound": [50, 51], "upsilon": 70, "upsilon_i": 70, "upward": [43, 62, 63, 69], "upweight": 64, "url": [55, 103, 106], "us": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 36, 40, 42, 43, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 77, 78, 79, 82, 83, 92, 93, 95, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108], "usa": 106, "usabl": 59, "usag": [41, 45, 47, 53, 58, 61, 62, 63, 68, 70, 73, 105, 107], "use_label_encod": [62, 108], "use_other_treat_as_covari": [4, 7, 73], "usecolormap": [50, 51], "user": [30, 31, 34, 35, 40, 41, 42, 43, 44, 47, 49, 58, 59, 61, 62, 67, 68, 75, 76, 77, 79, 92, 102, 103, 104, 105, 107, 108], "user_guid": 57, "userwarn": [62, 69], "usual": [42, 50, 51, 53, 59, 61, 67, 68, 69, 75, 76, 78, 93, 101], "util": [31, 59, 60, 64, 67, 76, 77, 107], "v": [8, 9, 11, 12, 16, 17, 23, 25, 26, 27, 29, 40, 42, 43, 47, 49, 58, 61, 62, 64, 67, 71, 72, 75, 77, 92, 102, 103, 105, 106, 107, 108], "v108": 103, "v12": [103, 105], "v22": 44, "v23": 103, "v_": [26, 42, 61, 77], "v_i": [22, 23, 27, 28, 29, 40, 49, 72, 77], "v_j": [92, 102], "val": [23, 78, 106], "val_list": 55, "valid": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 22, 40, 41, 42, 43, 49, 52, 53, 59, 60, 61, 62, 63, 66, 72, 74, 75, 76, 78, 79, 81, 86, 91, 93, 95, 106, 108], "valu": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 47, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 71, 74, 76, 77, 78, 81, 86, 87, 88, 91, 92, 93, 95, 98, 101, 102, 105, 107, 108], "value_count": 62, "van": 106, "vanderpla": [103, 105], "vanish": [40, 49, 72], "var": [18, 19, 20, 24, 42, 61, 64, 67, 93, 94, 95, 99, 100, 101], "var_ep": 69, "varepsilon": [8, 18, 19, 26, 42, 61, 70, 75, 77], "varepsilon_": [26, 42, 61], "varepsilon_0": 20, "varepsilon_1": 20, "varepsilon_d": [19, 24], "varepsilon_i": [24, 25, 52, 66, 70], "vari": [43, 54, 59, 62, 64, 69], "variabl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 32, 42, 43, 44, 45, 47, 53, 55, 58, 60, 61, 62, 63, 67, 68, 69, 70, 73, 75, 76, 77, 78, 79, 92, 93, 95, 98, 101, 102, 105, 106, 107, 108], "varianc": [30, 31, 42, 44, 61, 67, 68, 69, 74, 77, 78, 93, 95, 98, 99, 100, 101, 105], "variant": 41, "variat": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 68, 93, 95, 101], "variou": [41, 60, 69, 76, 108], "varoquaux": [103, 105], "vasili": [69, 106], "vector": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 21, 22, 23, 25, 26, 28, 29, 39, 42, 43, 48, 53, 56, 57, 58, 61, 62, 65, 70, 77, 92, 102, 105, 107], "venv": 104, "verbos": [43, 49, 54, 59, 60, 67, 69], "veri": [41, 42, 44, 58, 59, 61, 69, 79, 103], "verifi": 64, "versa": [59, 64, 93, 98], "version": [18, 42, 43, 44, 62, 69, 71, 75, 92, 93, 94, 96, 97, 99, 102, 107], "versoin": 69, "versu": 57, "vertic": [42, 47, 61], "via": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 31, 41, 52, 53, 54, 55, 56, 57, 58, 59, 67, 68, 70, 71, 73, 74, 75, 76, 77, 78, 81, 88, 92, 93, 95, 98, 101, 102, 103, 104, 105, 106, 107, 108], "viabl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "vice": [59, 64, 93, 98], "victor": [55, 69, 78, 103, 106], "view": 57, "vignett": [41, 107], "villa": [39, 48], "violet": [52, 63, 66], "vira": 106, "virtual": 104, "virtualenv": 104, "visibl": [63, 67, 69], "visit": [103, 108], "visual": [42, 58, 60, 61, 67], "vol": 41, "volum": [69, 103], "voluntari": 64, "vv740": 61, "vv760g": 61, "w": [16, 17, 18, 19, 20, 27, 30, 31, 42, 55, 61, 64, 65, 71, 72, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 105], "w24678": 78, "w30302": 106, "w_": [20, 42, 61, 65, 77], "w_1": [20, 65], "w_2": [20, 65], "w_3": 20, "w_4": 20, "w_df": 65, "w_i": [29, 53, 65, 67, 71, 75, 77, 78, 79, 92, 102], "wa": [42, 54, 60, 61, 69, 107], "wager": 106, "wai": [43, 59, 60, 62, 69, 76, 79, 104], "wander": 28, "wang": 106, "want": [39, 42, 43, 44, 48, 52, 53, 59, 61, 66, 67, 76, 77, 103, 104, 106], "warn": [39, 40, 41, 42, 43, 44, 49, 62, 69, 71, 76, 77, 78, 79, 92, 102, 105, 107], "wayon": 42, "we": [9, 37, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 84, 92, 93, 95, 101, 102, 104, 105, 107, 108], "weak": [93, 95, 106], "wealth": [16, 68], "websit": [43, 44, 76, 103], "wedg": [42, 61], "week": 107, "wei": [92, 102], "weight": [1, 2, 3, 8, 9, 10, 13, 14, 15, 42, 43, 44, 47, 58, 61, 62, 67, 70, 74, 76, 77, 79, 80, 85, 92, 93, 94, 99, 102, 107], "weights_bar": [1, 9], "weiss": [103, 105], "well": [4, 7, 40, 42, 49, 55, 59, 60, 61, 71, 72, 73, 78, 104, 105], "were": [43, 62, 63, 70, 108], "what": [41, 55, 59], "when": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 34, 35, 43, 53, 57, 62, 64, 77, 79, 92, 102, 103, 104, 105, 107], "whenev": [43, 62], "whera": [93, 99], "where": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 36, 37, 39, 40, 42, 43, 47, 48, 49, 52, 53, 54, 58, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 98, 99, 101, 104, 105, 107, 108], "wherea": [21, 47, 53, 69, 70, 79, 85, 93, 94, 108], "whether": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 24, 29, 32, 36, 43, 54, 59, 62, 63, 67, 69, 73, 76, 77, 93, 95, 107], "which": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 21, 31, 39, 40, 41, 43, 44, 46, 47, 48, 49, 53, 55, 57, 58, 59, 60, 62, 63, 65, 67, 68, 69, 70, 72, 73, 75, 76, 77, 79, 92, 93, 94, 95, 98, 99, 101, 102, 104, 107, 108], "while": [39, 48, 77], "white": [42, 56, 57, 61, 69], "whitegrid": [62, 63], "whitnei": [69, 106], "who": [41, 43, 62, 69], "whole": [40, 49, 53, 67, 72, 76, 93, 95], "whom": 77, "widehat": 77, "width": [40, 42, 50, 51, 55], "wiki": 107, "wiksel": 106, "wild": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 92, 102], "window": 104, "wise": [56, 57], "wish": 104, "within": [32, 42, 56, 57, 61, 65, 67], "without": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 24, 32, 39, 40, 48, 49, 59, 60, 69, 72, 74, 76, 77, 93, 95, 104, 107], "wolf": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 92, 102], "won": 69, "word": [32, 67, 77, 107, 108], "work": [34, 35, 46, 47, 57, 58, 59, 64, 68, 76, 77, 92, 104, 106], "workflow": [103, 107], "workspac": 62, "world": 106, "worri": 69, "would": [41, 43, 44, 50, 51, 55, 59, 62, 63, 67, 68, 69, 75, 76, 93, 101, 108], "wrapper": [41, 67, 76], "write": [40, 41, 49, 53, 57, 70, 72, 93, 101], "written": [77, 79, 93, 94, 99], "wrong": [59, 64], "wspace": 59, "wurd": [42, 43, 44], "www": [103, 104], "x": [1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 40, 41, 42, 43, 44, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 102, 105, 108], "x0": [47, 64, 67], "x1": [42, 44, 47, 53, 60, 61, 64, 67, 68, 69, 70, 73, 75, 76, 77, 79, 92, 93, 95, 105], "x10": [42, 44, 60, 61, 70, 73, 76, 77, 79, 92, 105], "x100": [42, 44, 61, 70, 73, 77, 105], "x11": [42, 44, 61, 70, 73, 76, 77, 79, 92, 105], "x12": [42, 44, 61, 70, 73, 76, 77, 79, 92, 105], "x13": [42, 44, 61, 70, 73, 76, 77, 79, 92, 105], "x14": [42, 44, 61, 70, 73, 76, 77, 79, 92, 105], "x15": [42, 44, 61, 70, 73, 76, 77, 79, 92, 105], "x16": [42, 44, 61, 70, 73, 76, 77, 79, 92, 105], "x17": [42, 44, 61, 70, 73, 76, 77, 79, 92, 105], "x18": [42, 44, 61, 70, 73, 76, 77, 79, 92, 105], "x19": [42, 44, 61, 70, 73, 76, 77, 79, 92, 105], "x1x2x3x4x5x6x7x8x9x10": 42, "x2": [42, 44, 47, 53, 60, 61, 67, 68, 69, 70, 73, 75, 76, 77, 79, 92, 105], "x20": [42, 44, 61, 70, 73, 76, 77, 79, 92, 105], "x21": [42, 44, 61, 70, 73, 77, 105], "x22": [42, 44, 61, 70, 73, 77, 105], "x23": [42, 44, 61, 70, 73, 77, 105], "x24": [42, 44, 61, 70, 73, 77, 105], "x25": [42, 44, 61, 70, 73, 77, 105], "x26": [42, 44, 61, 70, 73, 77, 105], "x27": [42, 44, 61, 70, 73, 77, 105], "x28": [42, 44, 61, 70, 73, 77, 105], "x29": [42, 44, 61, 70, 73, 77, 105], "x2_dummi": 69, "x2_preds_control": 69, "x2_preds_treat": 69, "x3": [42, 44, 47, 53, 60, 61, 68, 69, 70, 73, 75, 76, 77, 79, 92, 105], "x30": [42, 44, 61, 70, 73, 77, 105], "x31": [42, 44, 61, 70, 73, 77, 105], "x32": [42, 44, 61, 70, 73, 77, 105], "x33": [42, 44, 61, 70, 73, 77, 105], "x34": [42, 44, 61, 70, 73, 77, 105], "x35": [42, 44, 61, 70, 73, 77, 105], "x36": [42, 44, 61, 70, 73, 77, 105], "x37": [42, 44, 61, 70, 73, 77, 105], "x38": [42, 44, 61, 70, 73, 77, 105], "x39": [42, 44, 61, 70, 73, 77, 105], "x4": [42, 44, 47, 53, 60, 61, 68, 69, 70, 73, 76, 77, 79, 92, 105], "x40": [42, 44, 61, 70, 73, 77, 105], "x41": [42, 44, 61, 70, 73, 77, 105], "x42": [42, 44, 61, 70, 73, 77, 105], "x43": [42, 44, 60, 61, 70, 73, 77, 105], "x44": [42, 44, 60, 61, 70, 73, 77, 105], "x45": [42, 44, 60, 61, 70, 73, 77, 105], "x46": [42, 44, 60, 61, 70, 73, 77, 105], "x47": [42, 44, 60, 61, 70, 73, 77, 105], "x48": [42, 44, 60, 61, 70, 73, 77, 105], "x49": [42, 44, 60, 61, 70, 73, 77, 105], "x5": [42, 44, 60, 61, 69, 70, 73, 76, 77, 79, 92, 105], "x50": [42, 44, 60, 61, 70, 73, 77, 105], "x51": [42, 44, 61, 70, 73, 77, 105], "x52": [42, 44, 61, 70, 73, 77, 105], "x53": [42, 44, 61, 70, 73, 77, 105], "x54": [42, 44, 61, 70, 73, 77, 105], "x55": [42, 44, 61, 70, 73, 77, 105], "x56": [42, 44, 61, 70, 73, 77, 105], "x57": [42, 44, 61, 70, 73, 77, 105], "x58": [42, 44, 61, 70, 73, 77, 105], "x59": [42, 44, 61, 70, 73, 77, 105], "x6": [42, 44, 60, 61, 70, 73, 76, 77, 79, 92, 105], "x60": [42, 44, 61, 70, 73, 77, 105], "x61": [42, 44, 61, 70, 73, 77, 105], "x62": [42, 44, 61, 70, 73, 77, 105], "x63": [42, 44, 61, 70, 73, 77, 105], "x64": [42, 44, 61, 62, 69, 70, 73, 77, 105], "x65": [42, 44, 61, 70, 73, 77, 105], "x66": [42, 44, 61, 70, 73, 77, 105], "x67": [42, 44, 61, 70, 73, 77, 105], "x68": [42, 44, 61, 70, 73, 77, 105], "x69": [42, 44, 61, 70, 73, 77, 105], "x7": [42, 44, 60, 61, 70, 73, 76, 77, 79, 92, 105], "x70": [42, 44, 61, 70, 73, 77, 105], "x71": [42, 44, 61, 70, 73, 77, 105], "x72": [42, 44, 61, 70, 73, 77, 105], "x73": [42, 44, 61, 70, 73, 77, 105], "x74": [42, 44, 61, 70, 73, 77, 105], "x75": [42, 44, 61, 70, 73, 77, 105], "x76": [42, 44, 61, 70, 73, 77, 105], "x77": [42, 44, 61, 70, 73, 77, 105], "x78": [42, 44, 61, 70, 73, 77, 105], "x79": [42, 44, 61, 70, 73, 77, 105], "x8": [42, 44, 60, 61, 70, 73, 76, 77, 79, 92, 105], "x80": [42, 44, 61, 70, 73, 77, 105], "x81": [42, 44, 61, 70, 73, 77, 105], "x82": [42, 44, 61, 70, 73, 77, 105], "x83": [42, 44, 61, 70, 73, 77, 105], "x84": [42, 44, 61, 70, 73, 77, 105], "x85": [42, 44, 61, 70, 73, 77, 105], "x86": [42, 44, 61, 70, 73, 77, 105], "x87": [42, 44, 61, 70, 73, 77, 105], "x88": [42, 44, 61, 70, 73, 77, 105], "x89": [42, 44, 61, 70, 73, 77, 105], "x9": [42, 44, 60, 61, 70, 73, 76, 77, 79, 92, 105], "x90": [42, 44, 61, 70, 73, 77, 105], "x91": [42, 44, 61, 70, 73, 77, 105], "x92": [42, 44, 61, 70, 73, 77, 105], "x93": [42, 44, 61, 70, 73, 77, 105], "x94": [42, 44, 61, 70, 73, 77, 105], "x95": [42, 44, 61, 70, 73, 77, 105], "x96": [42, 44, 61, 70, 73, 77, 105], "x96x97x98x99x100ydcluster_var_icluster_var_jz": 42, "x97": [42, 44, 61, 70, 73, 77, 105], "x98": [42, 44, 61, 70, 73, 77, 105], "x99": [42, 44, 61, 70, 73, 77, 105], "x_": [26, 27, 40, 42, 49, 54, 61, 69, 72], "x_0": [50, 51, 54, 56, 57, 58], "x_1": [11, 12, 18, 19, 20, 24, 50, 51, 52, 54, 56, 57, 58, 66, 69, 77, 93, 95, 105], "x_1x_3": [52, 66], "x_2": [18, 19, 20, 24, 50, 51, 52, 54, 56, 57, 58, 66, 69, 93, 95], "x_3": [18, 19, 20, 24, 50, 51, 54, 56, 57, 58, 93, 95], "x_4": [18, 19, 20, 24, 50, 51, 52, 56, 57, 58, 66], "x_5": [18, 19, 24, 50, 51, 56, 57], "x_6": [50, 51, 56, 57], "x_7": [50, 51, 56, 57], "x_8": [50, 51, 56, 57], "x_9": [50, 51, 56, 57], "x_binary_control": 69, "x_binary_tr": 69, "x_col": [4, 7, 39, 42, 43, 44, 48, 55, 61, 62, 63, 65, 67, 68, 69, 73, 76, 77, 105, 107, 108], "x_cols_bench": 69, "x_cols_binari": 69, "x_cols_poli": 61, "x_conf": 66, "x_conf_tru": 66, "x_df": 54, "x_domain": 44, "x_i": [21, 22, 23, 25, 27, 28, 29, 33, 40, 49, 52, 53, 56, 57, 64, 66, 67, 70, 72, 75, 77], "x_p": [11, 12, 77, 105], "x_train": 60, "x_true": [52, 66], "x_var": 44, "xaxis_titl": [50, 51, 55, 67, 69], "xformla": 41, "xgb": 60, "xgb_untuned_l": 60, "xgb_untuned_m": 60, "xgbclassifi": [59, 62, 64, 108], "xgboost": [40, 43, 59, 62, 64, 108], "xgbregressor": [59, 60, 62, 64, 108], "xi": [20, 24, 77], "xi_": [92, 102], "xi_0": [26, 42, 61], "xi_i": 70, "xiaoji": 106, "xintercept": 40, "xlab": [40, 42, 43], "xlabel": [47, 50, 51, 52, 54, 56, 57, 60, 62, 63, 66], "xlim": [40, 43], "xtick": [47, 60], "xval": [44, 76], "xx": 49, "y": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 98, 99, 100, 101, 102, 105, 108], "y0": [41, 47, 52, 66], "y0_cvar": 52, "y0_quant": [52, 66], "y1": [41, 52, 66], "y1_cvar": 52, "y1_quant": [52, 66], "y_": [26, 42, 53, 54, 61, 70, 77], "y_0": [5, 20, 33, 79, 82], "y_1": [5, 20, 33, 79, 82], "y_col": [4, 7, 39, 40, 42, 43, 44, 48, 50, 51, 55, 56, 57, 61, 62, 63, 65, 67, 68, 71, 72, 73, 76, 77, 78, 79, 105, 107, 108], "y_df": [54, 65], "y_diff": 54, "y_i": [21, 22, 23, 25, 27, 28, 29, 40, 49, 52, 53, 64, 65, 66, 67, 70, 72, 77], "y_pred": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 59, 76], "y_train": 60, "y_true": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 59, 76], "ya": 106, "yasui": 106, "yata": 106, "yaxis_titl": [50, 51, 55, 67, 69], "year": 103, "yerr": [47, 54, 56, 57, 60, 62, 64, 67], "yet": [42, 46], "yggvpl": 61, "yield": 77, "yintercept": 43, "ylab": [40, 42, 43], "ylabel": [47, 50, 51, 52, 54, 56, 57, 60, 62, 63, 66], "ylim": 62, "ymax": 43, "ymin": 43, "yname": 41, "york": 106, "you": [39, 40, 48, 54, 57, 61, 68, 77, 103, 104, 108], "your": [59, 104], "ython": 103, "yukun": 106, "yusuk": 106, "yuya": 106, "yy": 49, "z": [4, 7, 8, 10, 11, 15, 18, 19, 20, 22, 24, 25, 26, 29, 39, 42, 43, 48, 50, 51, 55, 61, 62, 66, 69, 70, 75, 77, 79, 84, 86, 88, 89, 92, 102, 107], "z1": [11, 77], "z2": 77, "z3": 77, "z4": 77, "z_": [26, 42, 61], "z_1": [18, 19, 24], "z_2": [18, 19, 24], "z_3": [18, 19, 24], "z_4": [18, 19, 24], "z_5": 18, "z_col": [4, 7, 8, 10, 11, 39, 42, 43, 48, 61, 62, 63, 70, 73, 75, 77, 107], "z_i": [25, 29, 66, 70, 77], "z_j": [18, 19, 20, 24], "z_true": 66, "zadik": 106, "zaxis_titl": [50, 51, 55], "zero": [20, 33, 52, 53, 54, 59, 65, 66, 68, 69, 77, 92], "zeros_lik": 66, "zeta": [8, 11, 12, 43, 62, 75, 77, 105], "zeta_": [26, 42, 61], "zeta_0": [26, 42, 61], "zeta_i": [23, 25, 27, 40, 49, 72], "zeta_j": [92, 102], "zhang": 106, "zhao": [5, 6, 18, 19, 20, 24, 41, 53, 77, 106], "zimmert": [53, 106], "zip": [50, 51], "zorder": 47, "\u03c4_x0": 64, "\u03c4_x1": 64, "\u2139": 40}, "titles": ["API reference", "doubleml.DoubleMLAPO", "doubleml.DoubleMLAPOS", "doubleml.DoubleMLCVAR", "doubleml.DoubleMLClusterData", "doubleml.DoubleMLDID", "doubleml.DoubleMLDIDCS", "doubleml.DoubleMLData", "doubleml.DoubleMLIIVM", "doubleml.DoubleMLIRM", "doubleml.DoubleMLLPQ", "doubleml.DoubleMLPLIV", "doubleml.DoubleMLPLR", "doubleml.DoubleMLPQ", "doubleml.DoubleMLQTE", "doubleml.DoubleMLSSM", "doubleml.datasets.fetch_401K", "doubleml.datasets.fetch_bonus", "doubleml.datasets.make_confounded_irm_data", "doubleml.datasets.make_confounded_plr_data", "doubleml.datasets.make_did_SZ2020", "doubleml.datasets.make_heterogeneous_data", "doubleml.datasets.make_iivm_data", "doubleml.datasets.make_irm_data", "doubleml.datasets.make_irm_data_discrete_treatments", "doubleml.datasets.make_pliv_CHS2015", "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "doubleml.datasets.make_plr_CCDDHNR2018", "doubleml.datasets.make_plr_turrell2018", "doubleml.datasets.make_ssm_data", "doubleml.double_ml_score_mixins.LinearScoreMixin", "doubleml.double_ml_score_mixins.NonLinearScoreMixin", "doubleml.rdd.RDFlex", "doubleml.rdd.datasets.make_simple_rdd_data", "doubleml.utils.DMLDummyClassifier", "doubleml.utils.DMLDummyRegressor", "doubleml.utils.DoubleMLBLP", "doubleml.utils.DoubleMLPolicyTree", "doubleml.utils.gain_statistics", "R: Basic Instrumental Variables Calculation", "R: Basics of Double Machine Learning", "R: DoubleML for Difference-in-Differences", "R: Cluster Robust Double Machine Learning", "R: Impact of 401(k) on Financial Wealth", "R: Ensemble Learners and More with <code class=\"docutils literal notranslate\"><span class=\"pre\">mlr3pipelines</span></code>", "DML: Bonus Data", "Examples", "Python: Average Potential Outcome (APO) Models", "Python: Basic Instrumental Variables calculation", "Python: Basics of Double Machine Learning", "Python: Conditional Average Treatment Effects (CATEs) for IRM models", "Python: Conditional Average Treatment Effects (CATEs) for PLR models", "Python: Conditional Value at Risk of potential outcomes", "Python: Difference-in-Differences", "Python: Difference-in-Differences Pre-Testing", "Python: First Stage and Causal Estimation", "Python: Group Average Treatment Effects (GATEs) for IRM models", "Python: Group Average Treatment Effects (GATEs) for PLR models", "Python: GATE Sensitivity Analysis", "Python: Choice of learners", "DoubleML meets FLAML - How to tune learners automatically within <code class=\"docutils literal notranslate\"><span class=\"pre\">DoubleML</span></code>", "Python: Cluster Robust Double Machine Learning", "Python: Impact of 401(k) on Financial Wealth", "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)", "Python: PLM and IRM for Multiple Treatments", "Python: Policy Learning with Trees", "Python: Potential Quantiles and Quantile Treatment Effects", "Flexible Covariate Adjustment in Regression Discontinuity Designs (RDD)", "Python: Sensitivity Analysis", "Example: Sensitivity Analysis for Causal ML", "Python: Sample Selection Models", "<span class=\"section-number\">6. </span>Double machine learning algorithms", "<span class=\"section-number\">1. </span>The basics of double/debiased machine learning", "<span class=\"section-number\">2. </span>The data-backend DoubleMLData", "User guide", "<span class=\"section-number\">4. </span>Heterogeneous treatment effects", "<span class=\"section-number\">7. </span>Learners, hyperparameters and hyperparameter tuning", "<span class=\"section-number\">3. </span>Models", "<span class=\"section-number\">9. </span>Sample-splitting, cross-fitting and repeated cross-fitting", "<span class=\"section-number\">5. </span>Score functions", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "<span class=\"section-number\">8. </span>Variance estimation and confidence intervals", "<span class=\"section-number\">10. </span>Sensitivity analysis", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "Confidence bands and multiplier bootstrap for valid simultaneous inference", "DoubleML", "Installing DoubleML", "Getting started", "Double machine learning literature", "Release notes", "DoubleML Workflow"], "titleterms": {"": 60, "0": 108, "1": [60, 69, 108], "2": [60, 69, 108], "2011": 69, "2023": 69, "3": [60, 69, 108], "4": [69, 108], "401": [43, 62, 63, 68], "5": [69, 108], "6": 108, "7": 108, "95": 60, "A": [42, 61], "ATE": [58, 64, 70], "No": [42, 61], "One": [42, 50, 51, 61], "The": [43, 62, 64, 72, 73, 105], "acknowledg": [41, 103], "acycl": [39, 48], "addit": 64, "adjust": 67, "advanc": [67, 76, 92], "al": 69, "algorithm": [71, 93, 103, 105], "altern": 79, "analysi": [47, 58, 68, 69, 93, 108], "api": [0, 60], "apo": [47, 77, 79, 93], "applic": [42, 61, 68], "approach": [40, 49, 59, 72], "arah": 69, "arbitrari": 64, "arrai": 73, "asset": [43, 62], "assumpt": 69, "att": 53, "augment": 64, "automat": 60, "automl": 60, "averag": [43, 47, 50, 51, 56, 57, 62, 75, 77, 79, 93], "backend": [42, 43, 61, 62, 73, 105, 108], "band": [92, 102], "base": 44, "basic": [39, 40, 48, 49, 72], "benchmark": [68, 69, 93], "bia": [40, 49, 72], "binari": [77, 79], "bonu": 45, "bootstrap": [92, 102], "build": 104, "calcul": [39, 48], "call": 60, "callabl": 79, "case": 46, "cate": [50, 51, 64, 75], "causal": [45, 47, 55, 69, 79, 105, 108], "chernozhukov": 69, "choic": 59, "citat": 103, "class": [0, 42, 61], "cluster": [42, 61], "code": 103, "coeffici": 60, "combin": 55, "compar": [59, 60], "comparison": [41, 60], "comput": [59, 60], "conclus": [60, 69], "conda": 104, "condit": [50, 51, 52, 63, 75, 79], "confid": [60, 92, 102], "construct": 76, "contrast": 47, "covari": 67, "coverag": [53, 55], "cran": 104, "creat": 60, "cross": [42, 53, 61, 77, 78, 79, 93, 105], "custom": [59, 60], "cvar": [52, 63, 75, 79], "dag": [39, 48], "data": [0, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 77, 79, 93, 105, 108], "datafram": 73, "dataset": [0, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 45], "debias": [40, 49, 72, 105], "default": 60, "defin": [42, 61], "demo": 41, "depend": 104, "design": [67, 77], "detail": [41, 77], "develop": 104, "dgp": [40, 47, 49], "did": [41, 77], "differ": [41, 53, 54, 59, 77, 79, 92, 93], "dimension": [50, 51], "direct": [39, 48], "disclaim": 69, "discontinu": [67, 77], "distribut": 70, "dml": [42, 45, 61, 78, 105, 108], "dml1": 71, "dml2": 71, "dmldummyclassifi": 34, "dmldummyregressor": 35, "doubl": [0, 40, 42, 49, 61, 71, 72, 103, 105, 106], "double_ml_score_mixin": [30, 31], "doubleml": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 48, 60, 62, 68, 69, 92, 103, 104, 108], "doublemlapo": [1, 2], "doublemlblp": 36, "doublemlclusterdata": [4, 42, 61], "doublemlcvar": 3, "doublemldata": [7, 43, 62, 73, 105], "doublemldid": 5, "doublemldidc": 6, "doublemliivm": 8, "doublemlirm": 9, "doublemllpq": 10, "doublemlpliv": [11, 42, 61], "doublemlplr": 12, "doublemlpolicytre": 37, "doublemlpq": 13, "doublemlqt": 14, "doublemlssm": 15, "effect": [43, 46, 50, 51, 52, 56, 57, 62, 63, 64, 66, 68, 69, 75], "elig": [43, 62], "empir": 55, "ensembl": [44, 67], "error": [42, 61], "estim": [39, 43, 45, 48, 53, 55, 58, 60, 62, 63, 64, 66, 68, 69, 70, 78, 79, 92, 105, 108], "et": 69, "evalu": [59, 60, 76], "exampl": [41, 42, 46, 50, 51, 61, 68, 69], "exploit": [41, 44], "extern": [76, 78], "featur": [44, 103], "fetch_401k": 16, "fetch_bonu": 17, "figur": 64, "file": 104, "final": 41, "financi": [43, 62, 63], "first": 55, "fit": [42, 60, 61, 78, 105], "flaml": 60, "flexibl": 67, "fold": [60, 78], "forest": 45, "formul": [69, 108], "from": [41, 44, 73, 104], "full": 60, "function": [0, 41, 42, 61, 79, 105], "fuzzi": [67, 77], "gain_statist": 38, "gate": [56, 57, 58, 75], "gatet": 58, "gener": [0, 40, 46, 47, 49, 60, 67, 72, 93], "get": 105, "github": 104, "global": 67, "graph": [39, 48], "group": [56, 57, 75], "guid": 74, "helper": [42, 61], "heterogen": [46, 64, 75], "how": [44, 60], "hyperparamet": 76, "identif": 69, "iivm": [43, 62, 77, 79], "impact": [43, 62, 63], "implement": [71, 77, 79, 93], "induc": [40, 49, 72], "infer": [92, 102, 108], "initi": [42, 60, 61], "instal": 104, "instrument": [39, 48], "integr": 41, "interact": [43, 56, 62, 65, 77, 79, 93], "interv": [60, 92, 102], "invers": 64, "irm": [43, 45, 50, 56, 62, 64, 65, 68, 75, 77, 79, 93], "iv": [39, 43, 48, 62, 77, 79], "joint": 102, "k": [43, 62, 63, 68, 78], "lambda": 55, "lasso": [45, 55], "latest": 104, "lear": [42, 61], "learn": [0, 40, 42, 49, 61, 65, 71, 72, 75, 103, 105, 106], "learner": [44, 45, 59, 60, 67, 76, 105], "less": 60, "level": 77, "linear": [43, 57, 62, 64, 67, 77, 79, 93], "linearscoremixin": 30, "literatur": 106, "load": [42, 45, 61, 69], "loader": 0, "local": [43, 62, 63, 66, 67, 79], "loss": 55, "lpq": [66, 79], "lqte": [63, 66], "m": 78, "machin": [0, 40, 42, 49, 61, 71, 72, 103, 105, 106], "main": 103, "mainten": 103, "make_confounded_irm_data": 18, "make_confounded_plr_data": 19, "make_did_sz2020": 20, "make_heterogeneous_data": 21, "make_iivm_data": 22, "make_irm_data": 23, "make_irm_data_discrete_treat": 24, "make_pliv_chs2015": 25, "make_pliv_multiway_cluster_ckms2021": 26, "make_plr_ccddhnr2018": 27, "make_plr_turrell2018": 28, "make_simple_rdd_data": 33, "make_ssm_data": 29, "mar": 70, "market": [42, 61], "matric": 73, "meet": 60, "method": [60, 108], "metric": [59, 60], "minimum": 76, "miss": 70, "missing": [77, 79], "mixin": 0, "ml": [40, 41, 49, 69, 72, 108], "mlr3": 44, "mlr3extralearn": 44, "mlr3learner": 44, "mlr3pipelin": 44, "model": [0, 43, 45, 47, 50, 51, 56, 57, 60, 62, 64, 65, 69, 70, 75, 77, 78, 79, 92, 93, 105, 108], "modul": [0, 45], "more": 44, "motiv": [42, 61], "multipl": [47, 64, 77], "multipli": [92, 102], "naiv": [39, 48], "net": [43, 62], "neyman": [79, 105], "nonignor": [70, 77, 79], "nonlinearscoremixin": 31, "nonrespons": [70, 77, 79], "note": 107, "nuisanc": [60, 105], "object": [42, 61, 68], "option": 104, "orthogon": [40, 49, 72, 79, 105], "other": 0, "out": [40, 49, 72], "outcom": [47, 52, 53, 70, 75, 77, 79, 93], "over": 92, "overcom": [40, 49, 72], "overfit": [40, 49, 72], "overlap": 64, "packag": [41, 43, 62, 104], "panel": [53, 77, 79, 93], "paramet": [44, 45, 60, 79], "partial": [40, 43, 49, 57, 62, 64, 72, 77, 79, 93], "particip": [43, 62], "partit": 78, "penalti": 55, "perform": [41, 64], "pip": 104, "pipelin": 76, "pliv": [77, 79], "plm": [64, 77, 79], "plot": [42, 60, 61], "plr": [43, 45, 51, 57, 62, 75, 77, 79, 93], "polici": [65, 75], "potenti": [47, 52, 63, 66, 75, 77, 79, 93], "pq": [66, 75, 79], "pre": 54, "predict": [41, 76], "preprocess": 44, "problem": 108, "process": [40, 42, 47, 49, 61, 72], "product": [42, 61], "propens": 64, "provid": 78, "python": [46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 68, 70, 76, 104], "qte": [66, 75], "qualiti": 55, "quantil": [63, 66, 75, 79], "r": [39, 40, 41, 42, 43, 44, 46, 76, 104], "random": [45, 70, 77, 79], "rank": 64, "rdd": [32, 33, 67, 77], "rdflex": 32, "real": [42, 61], "refer": [0, 39, 41, 42, 44, 48, 55, 61, 64, 69, 72, 76, 78, 92, 102, 103, 105], "regress": [43, 56, 57, 62, 65, 67, 77, 79, 93], "regular": [40, 49, 72], "releas": [104, 107], "remark": 41, "remov": [40, 49, 72], "repeat": [53, 77, 78, 79, 93], "repetit": 78, "requir": 76, "respect": [42, 61], "result": [42, 43, 61, 62, 64], "risk": [52, 63, 75, 79], "robust": [42, 61], "sampl": [40, 49, 60, 70, 72, 77, 78, 79], "sandbox": 46, "score": [0, 40, 49, 64, 72, 79, 105], "section": [53, 77, 79, 93], "select": [70, 77, 79], "sensit": [47, 58, 68, 69, 93, 108], "set": [44, 76], "sharp": [67, 77], "simpl": [40, 49, 72], "simul": [39, 42, 48, 53, 61, 68], "simultan": [92, 102], "singl": 47, "sourc": [103, 104], "specif": [93, 108], "specifi": [45, 76, 79], "split": [40, 49, 72, 78], "ssm": 77, "stack": 67, "stage": 55, "standard": [42, 59, 61], "start": 105, "step": 60, "studi": 46, "summari": [43, 60, 62, 64], "test": 54, "theori": 93, "time": [59, 60], "train": 60, "treatment": [43, 50, 51, 52, 56, 57, 62, 63, 64, 66, 75, 77], "tree": [65, 75], "tune": [44, 60, 76], "two": [42, 50, 51, 61], "under": [64, 70], "untun": 60, "up": 44, "us": [39, 41, 44, 45, 48, 60, 76], "user": 74, "util": [0, 34, 35, 36, 37, 38], "v": 55, "valid": [92, 102], "valu": [52, 63, 75, 79], "vanderweel": 69, "variabl": [39, 48], "varianc": 92, "version": 104, "via": 79, "wai": [42, 61], "wealth": [43, 62, 63], "weight": [64, 75], "when": 60, "whl": 104, "within": 60, "without": [67, 78], "workflow": 108, "xgboost": 60, "zero": [42, 61]}})