Search.setIndex({"docnames": ["api/api", "api/generated/doubleml.DoubleMLBLP", "api/generated/doubleml.DoubleMLCVAR", "api/generated/doubleml.DoubleMLClusterData", "api/generated/doubleml.DoubleMLDID", "api/generated/doubleml.DoubleMLDIDCS", "api/generated/doubleml.DoubleMLData", "api/generated/doubleml.DoubleMLIIVM", "api/generated/doubleml.DoubleMLIRM", "api/generated/doubleml.DoubleMLLPQ", "api/generated/doubleml.DoubleMLPLIV", "api/generated/doubleml.DoubleMLPLR", "api/generated/doubleml.DoubleMLPQ", "api/generated/doubleml.DoubleMLQTE", "api/generated/doubleml.datasets.fetch_401K", "api/generated/doubleml.datasets.fetch_bonus", "api/generated/doubleml.datasets.make_confounded_irm_data", "api/generated/doubleml.datasets.make_confounded_plr_data", "api/generated/doubleml.datasets.make_did_SZ2020", "api/generated/doubleml.datasets.make_heterogeneous_data", "api/generated/doubleml.datasets.make_iivm_data", "api/generated/doubleml.datasets.make_irm_data", "api/generated/doubleml.datasets.make_pliv_CHS2015", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018", "api/generated/doubleml.datasets.make_plr_turrell2018", "api/generated/doubleml.datasets.make_ssm_data", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin", "api/generated/doubleml.utils.DMLDummyClassifier", "api/generated/doubleml.utils.DMLDummyRegressor", "api/generated/doubleml.utils.gain_statistics", "examples/R_double_ml_basic_iv", "examples/R_double_ml_basics", "examples/R_double_ml_multiway_cluster", "examples/R_double_ml_pension", "examples/R_double_ml_pipeline", "examples/double_ml_bonus_data", "examples/index", "examples/py_double_ml_basic_iv", "examples/py_double_ml_basics", "examples/py_double_ml_cate", "examples/py_double_ml_cate_plr", "examples/py_double_ml_cvar", "examples/py_double_ml_did", "examples/py_double_ml_did_pretest", "examples/py_double_ml_firststage", "examples/py_double_ml_gate", "examples/py_double_ml_gate_plr", "examples/py_double_ml_gate_sensitivity", "examples/py_double_ml_learner", "examples/py_double_ml_multiway_cluster", "examples/py_double_ml_pension", "examples/py_double_ml_pension_qte", "examples/py_double_ml_policy_tree", "examples/py_double_ml_pq", "examples/py_double_ml_sensitivity", "examples/py_double_ml_ssm", "guide/algorithms", "guide/basics", "guide/data_backend", "guide/guide", "guide/heterogeneity", "guide/learners", "guide/models", "guide/resampling", "guide/scores", "guide/se_confint", "guide/sensitivity", "guide/sim_inf", "index", "intro/install", "intro/intro", "literature/literature", "release/release", "workflow/workflow"], "filenames": ["api/api.rst", "api/generated/doubleml.DoubleMLBLP.rst", "api/generated/doubleml.DoubleMLCVAR.rst", "api/generated/doubleml.DoubleMLClusterData.rst", "api/generated/doubleml.DoubleMLDID.rst", "api/generated/doubleml.DoubleMLDIDCS.rst", "api/generated/doubleml.DoubleMLData.rst", "api/generated/doubleml.DoubleMLIIVM.rst", "api/generated/doubleml.DoubleMLIRM.rst", "api/generated/doubleml.DoubleMLLPQ.rst", "api/generated/doubleml.DoubleMLPLIV.rst", "api/generated/doubleml.DoubleMLPLR.rst", "api/generated/doubleml.DoubleMLPQ.rst", "api/generated/doubleml.DoubleMLQTE.rst", "api/generated/doubleml.datasets.fetch_401K.rst", "api/generated/doubleml.datasets.fetch_bonus.rst", "api/generated/doubleml.datasets.make_confounded_irm_data.rst", "api/generated/doubleml.datasets.make_confounded_plr_data.rst", "api/generated/doubleml.datasets.make_did_SZ2020.rst", "api/generated/doubleml.datasets.make_heterogeneous_data.rst", "api/generated/doubleml.datasets.make_iivm_data.rst", "api/generated/doubleml.datasets.make_irm_data.rst", "api/generated/doubleml.datasets.make_pliv_CHS2015.rst", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021.rst", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018.rst", "api/generated/doubleml.datasets.make_plr_turrell2018.rst", "api/generated/doubleml.datasets.make_ssm_data.rst", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin.rst", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin.rst", "api/generated/doubleml.utils.DMLDummyClassifier.rst", "api/generated/doubleml.utils.DMLDummyRegressor.rst", "api/generated/doubleml.utils.gain_statistics.rst", "examples/R_double_ml_basic_iv.ipynb", "examples/R_double_ml_basics.ipynb", "examples/R_double_ml_multiway_cluster.ipynb", "examples/R_double_ml_pension.ipynb", "examples/R_double_ml_pipeline.ipynb", "examples/double_ml_bonus_data.ipynb", "examples/index.rst", "examples/py_double_ml_basic_iv.ipynb", "examples/py_double_ml_basics.ipynb", "examples/py_double_ml_cate.ipynb", "examples/py_double_ml_cate_plr.ipynb", "examples/py_double_ml_cvar.ipynb", "examples/py_double_ml_did.ipynb", "examples/py_double_ml_did_pretest.ipynb", "examples/py_double_ml_firststage.ipynb", "examples/py_double_ml_gate.ipynb", "examples/py_double_ml_gate_plr.ipynb", "examples/py_double_ml_gate_sensitivity.ipynb", "examples/py_double_ml_learner.ipynb", "examples/py_double_ml_multiway_cluster.ipynb", "examples/py_double_ml_pension.ipynb", "examples/py_double_ml_pension_qte.ipynb", "examples/py_double_ml_policy_tree.ipynb", "examples/py_double_ml_pq.ipynb", "examples/py_double_ml_sensitivity.ipynb", "examples/py_double_ml_ssm.ipynb", "guide/algorithms.rst", "guide/basics.rst", "guide/data_backend.rst", "guide/guide.rst", "guide/heterogeneity.rst", "guide/learners.rst", "guide/models.rst", "guide/resampling.rst", "guide/scores.rst", "guide/se_confint.rst", "guide/sensitivity.rst", "guide/sim_inf.rst", "index.rst", "intro/install.rst", "intro/intro.rst", "literature/literature.rst", "release/release.rst", "workflow/workflow.rst"], "titles": ["API reference", "doubleml.DoubleMLBLP", "doubleml.DoubleMLCVAR", "doubleml.DoubleMLClusterData", "doubleml.DoubleMLDID", "doubleml.DoubleMLDIDCS", "doubleml.DoubleMLData", "doubleml.DoubleMLIIVM", "doubleml.DoubleMLIRM", "doubleml.DoubleMLLPQ", "doubleml.DoubleMLPLIV", "doubleml.DoubleMLPLR", "doubleml.DoubleMLPQ", "doubleml.DoubleMLQTE", "doubleml.datasets.fetch_401K", "doubleml.datasets.fetch_bonus", "doubleml.datasets.make_confounded_irm_data", "doubleml.datasets.make_confounded_plr_data", "doubleml.datasets.make_did_SZ2020", "doubleml.datasets.make_heterogeneous_data", "doubleml.datasets.make_iivm_data", "doubleml.datasets.make_irm_data", "doubleml.datasets.make_pliv_CHS2015", "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "doubleml.datasets.make_plr_CCDDHNR2018", "doubleml.datasets.make_plr_turrell2018", "doubleml.datasets.make_ssm_data", "doubleml.double_ml_score_mixins.LinearScoreMixin", "doubleml.double_ml_score_mixins.NonLinearScoreMixin", "doubleml.utils.DMLDummyClassifier", "doubleml.utils.DMLDummyRegressor", "doubleml.utils.gain_statistics", "R: Basic Instrumental Variables Calculation", "R: Basics of Double Machine Learning", "R: Cluster Robust Double Machine Learning", "R: Impact of 401(k) on Financial Wealth", "R: Ensemble Learners and More with <code class=\"docutils literal notranslate\"><span class=\"pre\">mlr3pipelines</span></code>", "DML: Bonus Data", "Examples", "Python: Basic Instrumental Variables calculation", "Python: Basics of Double Machine Learning", "Python: Conditional Average Treatment Effects (CATEs) for IRM models", "Python: Conditional Average Treatment Effects (CATEs) for PLR models", "Python: Conditional Value at Risk of potential outcomes", "Python: Difference-in-Differences", "Python: Difference-in-Differences Pre-Testing", "Python: First Stage and Causal Estimation", "Python: Group Average Treatment Effects (GATEs) for IRM models", "Python: Group Average Treatment Effects (GATEs) for PLR models", "Python: GATE Sensitivity Analysis", "Python: Choice of learners", "Python: Cluster Robust Double Machine Learning", "Python: Impact of 401(k) on Financial Wealth", "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)", "Python: Policy Learning with Trees", "Python: Potential Quantiles and Quantile Treatment Effects", "Python: Sensitivity Analysis", "Python: Sample Selection Models", "<span class=\"section-number\">6. </span>Double machine learning algorithms", "<span class=\"section-number\">1. </span>The basics of double/debiased machine learning", "<span class=\"section-number\">2. </span>The data-backend DoubleMLData", "User guide", "<span class=\"section-number\">4. </span>Heterogeneous treatment effects", "<span class=\"section-number\">7. </span>Learners, hyperparameters and hyperparameter tuning", "<span class=\"section-number\">3. </span>Models", "<span class=\"section-number\">9. </span>Sample-splitting, cross-fitting and repeated cross-fitting", "<span class=\"section-number\">5. </span>Score functions", "<span class=\"section-number\">8. </span>Variance estimation and confidence intervals", "<span class=\"section-number\">10. </span>Sensitivity analysis", "Confidence bands and multiplier bootstrap for valid simultaneous inference", "DoubleML", "Installing DoubleML", "Getting started", "Double machine learning literature", "Release notes", "DoubleML Workflow"], "terms": {"class": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 27, 28, 29, 30, 35, 36, 37, 44, 49, 52, 53, 56, 57, 58, 60, 62, 63, 65, 66, 67, 70, 72, 74], "orth_sign": 1, "basi": [1, 8, 11, 41, 42, 62], "is_gat": [1, 8, 11], "fals": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 33, 35, 36, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 60, 63, 64, 65, 66, 67, 68, 69, 75], "best": [1, 8, 11, 41, 42, 47, 48, 71], "linear": [1, 8, 10, 11, 17, 22, 23, 24, 25, 27, 28, 32, 33, 34, 36, 39, 40, 41, 42, 44, 45, 46, 47, 50, 51, 56, 58, 59, 61, 62, 63, 65, 67, 69, 70, 72, 73, 74, 75], "predictor": [1, 8, 11, 41, 42, 47, 48, 58], "blp": [1, 34, 51], "orthogon": [1, 34, 35, 51, 52, 58, 61, 67, 68, 69, 70, 73], "signal": 1, "manili": 1, "us": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 33, 34, 35, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 62, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75], "cate": [1, 8, 11, 61, 74], "gate": [1, 8, 11, 54, 61, 74], "estim": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 27, 28, 29, 30, 33, 34, 36, 40, 41, 42, 43, 45, 47, 48, 50, 51, 54, 58, 59, 61, 62, 63, 64, 68, 69, 70, 73, 74], "irm": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 21, 27, 28, 50, 58, 61, 63, 70, 74, 75], "model": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 36, 39, 40, 43, 44, 45, 46, 49, 50, 51, 53, 55, 56, 58, 59, 60, 61, 63, 69, 70, 73, 74], "paramet": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 40, 41, 42, 43, 44, 46, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 75], "numpi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72], "arrai": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 20, 21, 22, 23, 24, 25, 26, 40, 41, 42, 43, 44, 50, 51, 54, 56, 57, 58, 59, 61, 62, 63, 65, 67, 68, 69, 72, 74, 75], "The": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 34, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75], "predict": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 29, 30, 33, 34, 35, 36, 40, 43, 46, 50, 51, 52, 54, 59, 62, 65, 68, 74, 75], "ha": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 18, 33, 34, 35, 40, 46, 50, 51, 52, 53, 56, 62, 63, 64, 68, 75], "shape": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 41, 42, 45, 47, 48, 50, 51, 52, 54, 56, 63], "n_ob": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 33, 36, 40, 41, 42, 44, 45, 47, 48, 49, 50, 56, 57, 59, 60, 62, 63, 64, 65, 67, 68, 69, 72], "where": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 32, 33, 34, 35, 39, 40, 43, 44, 45, 49, 51, 52, 54, 55, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 71, 72, 74, 75], "i": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75], "number": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 53, 54, 55, 65, 67, 69, 70, 72, 75], "observ": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 72, 73, 75], "panda": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 62, 68, 72], "datafram": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 34, 37, 39, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 64, 66, 67, 68, 72, 75], "have": [1, 8, 11, 13, 19, 32, 33, 34, 35, 36, 39, 41, 42, 44, 45, 49, 50, 51, 52, 53, 54, 56, 57, 60, 62, 63, 67, 68, 71, 72, 74, 75], "d": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75], "bool": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 29, 30, 49], "indic": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 19, 26, 34, 35, 45, 49, 51, 52, 53, 57, 58, 60, 62, 64, 65], "whether": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 19, 26, 35, 45, 50, 52, 53, 60, 63, 68, 74], "construct": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 41, 42, 43, 45, 53, 56, 58, 62, 66, 67, 69, 74, 75], "dummi": [1, 8, 11, 29, 30, 62, 63, 64, 74], "default": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 23, 24, 25, 29, 30, 34, 44, 47, 48, 50, 51, 54, 56, 57, 58, 62, 63, 65, 67, 68, 69, 72, 75], "method": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 47, 48, 50, 51, 52, 54, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74], "attribut": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 50, 58, 63, 65, 66, 67], "confint": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 41, 42, 43, 44, 45, 47, 48, 50, 53, 54, 55, 56, 57, 62, 65, 67, 69, 70, 72, 75], "none": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 34, 35, 37, 39, 44, 49, 52, 53, 56, 57, 60, 63, 64, 66, 67, 71, 72], "joint": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 41, 42, 43, 47, 48, 53, 55, 64, 67, 74, 75], "level": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 55, 56, 57, 63, 68, 75], "0": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74], "95": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 62, 64, 65, 67, 68, 74, 75], "n_rep_boot": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 41, 42, 43, 47, 48, 53, 55, 67, 69], "500": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, 21, 24, 33, 36, 37, 40, 41, 42, 47, 48, 50, 52, 54, 56, 59, 60, 62, 63, 64, 66, 67, 68, 69, 72, 75], "confid": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 41, 42, 43, 44, 47, 48, 51, 53, 55, 56, 57, 61, 62, 65, 66, 68, 72, 73, 75], "interv": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 41, 42, 43, 44, 47, 48, 51, 53, 55, 56, 57, 61, 62, 65, 66, 68, 72, 73, 75], "same": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 34, 40, 41, 42, 49, 50, 51, 53, 54, 56, 57, 63, 66, 67, 68, 74], "form": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 19, 35, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 55, 56, 57, 62, 64, 68, 71, 72], "from": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72, 74, 75], "If": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 33, 34, 40, 41, 42, 44, 50, 51, 53, 59, 60, 62, 63, 64, 66, 67, 68, 70, 75], "pass": [1, 36, 63, 75], "ar": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 24, 25, 27, 28, 29, 30, 33, 34, 35, 36, 38, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75], "return": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 33, 34, 36, 40, 43, 50, 51, 54, 55, 56, 57, 58, 63, 66, 68, 74], "els": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 45, 47, 48, 51, 54], "coeffici": [1, 16, 17, 19, 35, 47, 48, 50, 52, 54, 57, 62, 67, 68, 69, 75], "pointwis": [1, 43, 47, 48, 55], "cofid": 1, "comput": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 31, 33, 35, 36, 40, 52, 53, 56, 65, 66, 68, 70, 73, 74, 75], "float": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17], "int": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 34, 35, 39, 43, 44, 54, 55, 57], "bootstrap": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 41, 42, 43, 47, 48, 53, 55, 61, 62, 65, 66, 70, 72, 74, 75], "repetit": [1, 41, 42, 46, 47, 48, 49, 50, 61, 63, 67, 72, 75], "onli": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 34, 35, 41, 42, 47, 48, 49, 50, 51, 52, 53, 58, 62, 63, 64, 66, 67, 68, 74], "relev": [1, 3, 4, 5, 6, 19, 43, 54, 55, 68, 75], "df_ci": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "A": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 21, 25, 29, 30, 32, 33, 35, 36, 39, 40, 46, 54, 56, 59, 60, 62, 63, 64, 67, 68, 69, 70, 72, 73, 75], "data": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 45, 46, 50, 58, 61, 62, 63, 65, 67, 69, 73, 74], "frame": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 37, 41, 42, 44, 47, 48, 49, 51, 52, 53, 54, 56, 57, 59, 60, 72, 75], "": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 20, 21, 22, 23, 24, 25, 26, 32, 34, 35, 36, 37, 44, 47, 48, 49, 51, 52, 53, 56, 57, 58, 60, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75], "type": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 29, 30, 31, 33, 34, 35, 36, 40, 50, 51, 59, 63, 66, 67, 68, 69, 74, 75], "pd": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 62], "fit": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 29, 30, 32, 33, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 74, 75], "self": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 50, 75], "object": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30, 32, 35, 36, 37, 41, 42, 43, 44, 49, 52, 53, 55, 57, 60, 62, 63, 64, 65, 66, 67, 70, 72, 73, 74, 75], "obj_dml_data": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 39, 40, 43, 51, 55, 58, 59, 62, 63, 64, 65, 66, 67, 68, 74], "ml_g": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 35, 37, 39, 40, 41, 43, 44, 45, 47, 49, 50, 52, 53, 54, 55, 56, 57, 59, 62, 63, 64, 74], "ml_m": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 72, 74, 75], "treatment": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 32, 34, 36, 37, 39, 44, 45, 46, 49, 50, 51, 54, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75], "1": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74], "quantil": [2, 9, 12, 13, 43, 56, 61, 73, 74], "5": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74], "n_fold": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 34, 35, 37, 40, 41, 42, 43, 44, 47, 48, 50, 51, 52, 53, 54, 55, 56, 59, 63, 65, 72, 75], "n_rep": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 34, 37, 40, 44, 49, 50, 51, 56, 57, 59, 63, 65, 68, 72, 75], "score": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 27, 28, 32, 34, 35, 36, 37, 41, 42, 43, 44, 46, 49, 50, 51, 52, 53, 55, 56, 57, 58, 61, 62, 63, 64, 65, 67, 68, 70, 74, 75], "cvar": [2, 13, 61, 74], "normalize_ipw": [2, 7, 8, 9, 12, 13, 53, 57], "true": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 26, 29, 30, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 63, 64, 65, 66, 67, 68, 69, 72, 75], "trimming_rul": [2, 4, 5, 7, 8, 9, 12, 13, 53], "truncat": [2, 4, 5, 7, 8, 9, 12, 13, 53], "trimming_threshold": [2, 4, 5, 7, 8, 9, 12, 13, 35, 41, 52, 53, 54, 55], "01": [2, 4, 5, 7, 8, 9, 12, 13, 32, 34, 35, 36, 41, 42, 52, 53, 54, 55, 63, 64, 65, 66, 67, 72, 75], "draw_sample_split": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 50, 65], "doubl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 23, 24, 25, 26, 35, 46, 52, 61, 63, 65, 66, 67, 68, 69, 74], "machin": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 23, 24, 25, 26, 32, 35, 36, 37, 39, 43, 44, 46, 52, 53, 55, 56, 57, 61, 63, 64, 65, 66, 67, 68, 69, 74, 75], "learn": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 23, 24, 25, 26, 32, 35, 36, 37, 39, 43, 46, 50, 52, 53, 55, 60, 61, 63, 65, 66, 67, 68, 69, 74, 75], "condit": [2, 8, 11, 16, 17, 19, 27, 28, 33, 34, 35, 40, 44, 45, 49, 51, 52, 54, 57, 59, 61, 64, 67, 68, 69, 72, 73, 74, 75], "valu": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 58, 61, 63, 64, 65, 67, 68, 69, 72, 74, 75], "risk": [2, 61, 74], "potenti": [2, 9, 12, 16, 44, 57, 64, 67, 71, 74, 75], "outcom": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 18, 32, 34, 35, 36, 37, 39, 45, 46, 49, 51, 52, 53, 54, 55, 56, 60, 63, 64, 66, 67, 68, 72, 74, 75], "doublemldata": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 24, 25, 26, 32, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 74, 75], "provid": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 41, 42, 47, 48, 51, 52, 58, 59, 60, 61, 63, 67, 69, 70, 72, 74, 75], "specifi": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 32, 34, 35, 36, 39, 41, 42, 43, 44, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 72, 74, 75], "variabl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 34, 35, 36, 37, 44, 46, 49, 51, 52, 53, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75], "causal": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 39, 40, 51, 52, 56, 57, 58, 59, 60, 61, 64, 65, 67, 68, 69, 73], "implement": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 27, 28, 33, 34, 35, 36, 40, 44, 46, 50, 51, 52, 56, 57, 59, 61, 62, 63, 64, 65, 67, 69, 70, 72, 73, 74, 75], "learner": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 40, 41, 42, 44, 46, 51, 52, 53, 56, 57, 58, 59, 61, 64, 65, 66, 67, 68, 69, 74, 75], "e": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 24, 26, 27, 28, 33, 34, 35, 40, 41, 42, 44, 46, 49, 50, 51, 52, 53, 56, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75], "g": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 33, 36, 37, 40, 41, 42, 44, 45, 46, 49, 50, 53, 54, 56, 57, 59, 62, 63, 64, 66, 67, 68, 70, 71, 72, 75], "sklearn": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 25, 37, 39, 40, 41, 42, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 62, 63, 64, 65, 66, 67, 68, 69, 72, 75], "ensembl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 37, 40, 41, 42, 47, 48, 49, 50, 52, 54, 56, 58, 62, 63, 64, 65, 66, 67, 68, 72, 75], "randomforestregressor": [2, 4, 5, 7, 8, 9, 10, 11, 12, 37, 40, 41, 42, 47, 48, 49, 50, 52, 54, 56, 58, 62, 63, 64, 65, 66, 67, 68, 72, 75], "nuisanc": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 24, 25, 33, 34, 35, 36, 40, 41, 42, 43, 44, 46, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 63, 65, 66, 67, 68, 70, 74, 75], "element": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 41, 42, 43, 44, 50, 51, 53, 55, 56, 57, 66, 68, 74], "which": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 28, 32, 33, 35, 36, 38, 39, 40, 44, 46, 49, 50, 52, 53, 54, 56, 57, 59, 60, 62, 63, 64, 66, 67, 68, 69, 71, 74, 75], "depend": [2, 8, 9, 13, 19, 36, 41, 42, 44, 47, 48, 49, 50, 54, 58, 62, 63, 66, 68, 72, 73], "preliminari": [2, 33, 40, 66], "classifi": [2, 4, 5, 7, 8, 9, 11, 12, 13, 29, 36, 63, 74], "predict_proba": [2, 4, 5, 7, 8, 9, 11, 12, 13, 29, 63], "randomforestclassifi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 37, 41, 42, 47, 48, 49, 50, 52, 54, 56, 62, 63, 64, 75], "function": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 24, 25, 27, 28, 32, 33, 35, 36, 39, 40, 41, 42, 43, 44, 50, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 67, 68, 69, 70, 73, 74, 75], "m_0": [2, 4, 5, 7, 8, 10, 11, 12, 24, 25, 33, 34, 35, 40, 46, 49, 51, 52, 59, 62, 63, 64, 66, 72, 75], "x": [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 75], "binari": [2, 4, 5, 7, 8, 9, 11, 12, 19, 32, 35, 36, 39, 44, 49, 52, 54, 62, 63, 64, 74, 75], "either": [2, 4, 5, 7, 8, 9, 10, 11, 12, 19, 36, 45, 46, 54, 62, 63, 75], "determin": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 35, 43, 52, 53, 55, 56, 64, 67, 68, 69], "consid": [2, 7, 8, 9, 12, 33, 34, 35, 40, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75], "between": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 39, 43, 45, 46, 55, 56, 57, 66, 67, 68, 69, 72, 74], "fold": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 34, 35, 36, 44, 50, 51, 52, 53, 56, 57, 58, 61, 63, 64, 66, 67, 72, 75], "repetiton": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "sampl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 23, 26, 32, 34, 36, 39, 44, 47, 48, 50, 51, 53, 54, 56, 61, 63, 66, 67, 69, 72, 73, 74], "split": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 34, 36, 44, 50, 51, 53, 54, 56, 57, 61, 62, 63, 64, 66, 67, 72, 74], "str": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 35, 47, 48, 55, 62, 74], "choic": [2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 35, 46, 52, 54, 62, 63, 68, 74], "invers": [2, 7, 8, 9, 12, 13, 57, 68], "probabl": [2, 7, 8, 9, 12, 13, 18, 33, 40, 44, 49, 55, 57, 59, 64, 66, 73], "weight": [2, 7, 8, 9, 12, 13, 34, 35, 36, 49, 51, 52, 57, 61, 63, 67, 68, 69, 74], "normal": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 33, 39, 40, 43, 44, 45, 49, 53, 54, 55, 57, 59, 60, 63, 66, 67, 69, 72], "trim": [2, 4, 5, 7, 8, 9, 12, 13, 35, 52, 53], "approach": [2, 4, 5, 7, 8, 9, 12, 13, 34, 51, 56, 61, 63, 65, 67, 68, 69, 71, 73, 75], "threshold": [2, 4, 5, 7, 8, 9, 12, 13, 64], "1e": [2, 4, 5, 7, 8, 9, 12, 13, 53], "2": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 26, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74], "should": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 28, 35, 47, 48, 50, 52, 56, 57, 60, 62, 63, 67, 68, 70], "drawn": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 19, 35, 52, 53, 54, 65], "dure": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 51, 52, 63, 65, 72, 74, 75], "initi": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 35, 36, 43, 44, 52, 53, 55, 56, 57, 60, 62, 63, 65, 72, 74, 75], "exampl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 32, 33, 35, 36, 37, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75], "import": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75], "np": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 20, 21, 22, 23, 24, 25, 26, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 75], "dml": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 27, 28, 32, 33, 36, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 71], "dataset": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 33, 40, 41, 42, 44, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 72, 75], "make_irm_data": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 50, 62, 63, 64], "random": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 19, 25, 26, 32, 33, 35, 36, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 62, 63, 65, 67, 68, 69, 72, 73, 75], "seed": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 75], "3141": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 36, 37, 51, 58, 60, 62, 63, 66, 67, 69, 72], "n_estim": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 52, 53, 54, 55, 56, 58, 59, 62, 63, 64, 65, 66, 67, 68, 72, 75], "100": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 23, 25, 26, 34, 36, 40, 41, 42, 44, 46, 49, 50, 51, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 74], "max_featur": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 37, 40, 52, 56, 58, 62, 63, 64, 65, 66, 67, 68, 72, 75], "20": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, 21, 23, 24, 25, 33, 34, 35, 36, 41, 42, 43, 44, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 72, 75], "max_depth": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 37, 40, 52, 56, 58, 62, 63, 64, 65, 66, 67, 68, 72, 75], "10": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 23, 24, 26, 32, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75], "min_samples_leaf": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 40, 49, 52, 56, 58, 62, 63, 64, 65, 66, 67, 68, 75], "theta": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 23, 25, 26, 27, 28, 33, 34, 36, 40, 44, 45, 46, 49, 50, 51, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 75], "dim_x": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 20, 21, 22, 23, 24, 25, 26, 33, 34, 36, 40, 50, 51, 59, 62, 63, 64, 68], "return_typ": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 33, 35, 36, 40, 44, 50, 52, 53, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 72, 75], "y": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 75], "dml_cvar_obj": [2, 62], "summari": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 34, 36, 37, 39, 41, 42, 43, 44, 47, 48, 49, 51, 53, 55, 56, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 72, 74, 75], "coef": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 72, 75], "std": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 34, 35, 36, 37, 39, 41, 42, 43, 44, 47, 48, 49, 51, 52, 53, 55, 56, 57, 62, 63, 64, 65, 66, 67, 72, 75], "err": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 37, 39, 41, 42, 43, 44, 47, 48, 49, 51, 52, 53, 55, 56, 57, 62, 63, 64, 65, 66, 67, 72, 75], "t": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 32, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 62, 63, 64, 65, 66, 67, 68, 69, 72, 75], "p": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 21, 33, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74], "97": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 37, 39, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 62, 63, 64, 65, 66, 67, 69, 72, 74, 75], "591441": 2, "095781": 2, "16": [2, 32, 33, 34, 35, 36, 41, 42, 43, 49, 51, 52, 53, 55, 56, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 75], "615498": 2, "382582e": 2, "62": [2, 49, 62, 63, 64, 65, 67], "403715": 2, "779167": 2, "multipli": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 40, 61, 62, 66, 75], "bay": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 67, 69], "wild": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 67, 69], "replic": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 33, 35, 40, 46], "construct_framework": [2, 4, 5, 7, 8, 9, 10, 11, 12], "doublemlframework": [2, 4, 5, 7, 8, 9, 10, 11, 12, 65, 67, 74], "can": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75], "doubleml_framework": [2, 4, 5, 7, 8, 9, 10, 11, 12], "draw": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 65, 74], "accord": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 35, 40, 43, 44, 52, 55, 57, 63, 67, 68, 69, 75], "evaluate_learn": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 63, 74], "metric": [2, 4, 5, 7, 8, 9, 10, 11, 12, 63], "_rmse": [2, 4, 5, 7, 8, 9, 10, 11, 12], "evalu": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 21, 28, 36, 41, 42, 43, 45, 49, 53, 55, 56, 58, 73, 74], "cross": [2, 4, 5, 7, 8, 9, 10, 11, 12, 18, 32, 33, 35, 36, 40, 50, 52, 53, 59, 61, 63, 67, 74, 75], "valid": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 20, 33, 34, 35, 40, 43, 44, 50, 51, 52, 53, 55, 59, 61, 62, 63, 65, 66, 68, 73, 75], "list": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 33, 34, 35, 36, 40, 41, 42, 51, 53, 54, 59, 63, 65, 66, 71, 74], "string": [2, 4, 5, 7, 8, 9, 10, 11, 12, 62, 67, 68, 72, 74], "correspond": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 27, 28, 33, 34, 35, 36, 40, 41, 42, 44, 45, 46, 50, 51, 52, 53, 54, 55, 56, 59, 62, 63, 64, 65, 67, 68, 69, 74, 75], "callabl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 40, 41, 42, 50, 61, 63, 70], "input": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 56, 58, 67, 68, 69], "y_pred": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 63], "y_true": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 63], "n": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 36, 39, 40, 43, 45, 46, 49, 51, 54, 55, 57, 58, 59, 62, 63, 65, 67, 69, 70, 71], "remark": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 40, 41, 42, 43, 45, 47, 48, 49, 50, 53, 56, 62, 63, 64, 66, 67, 68], "some": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 36, 37, 44, 45, 50, 52, 53, 56, 57, 62, 63, 64, 74], "like": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 36, 46, 52, 53, 63, 65, 72, 75], "abl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 40, 50, 53, 63, 68], "all": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 31, 33, 34, 35, 40, 44, 49, 50, 51, 52, 53, 54, 57, 59, 60, 62, 63, 64, 65, 67, 68, 69, 70, 71, 74], "might": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 43, 50, 51, 54, 56, 63], "contain": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 33, 34, 35, 40, 41, 42, 47, 48, 50, 51, 52, 59, 62, 63, 67, 68, 74], "nan": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 40, 43, 44, 45, 47, 48, 50, 52, 53, 55, 57, 59, 63], "target": [2, 4, 5, 7, 8, 9, 10, 11, 12, 27, 28, 32, 34, 35, 36, 41, 42, 50, 51, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75], "vector": [2, 4, 5, 7, 8, 9, 10, 11, 12, 19, 20, 21, 22, 23, 25, 26, 32, 34, 35, 39, 44, 47, 48, 49, 51, 52, 54, 57, 64, 67, 69, 72, 74], "root": [2, 4, 5, 7, 8, 9, 10, 11, 12, 28, 46, 59, 63, 66, 73], "mean": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 39, 40, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 59, 63, 67, 75], "squar": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 46, 52, 63, 68, 73], "error": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 32, 33, 35, 36, 40, 45, 46, 47, 48, 50, 52, 59, 63, 64, 65, 66, 67, 68, 69, 72, 74, 75], "dist": [2, 4, 5, 7, 8, 9, 10, 11, 12], "dictionari": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 19, 31, 41, 42, 47, 48, 56, 62, 63, 68], "each": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 36, 45, 47, 48, 50, 51, 53, 54, 56, 58, 60, 63, 65, 67, 68, 69, 75], "dict": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 31, 41, 42, 46, 63], "mean_absolute_error": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 63], "dml_irm_obj": [2, 4, 5, 7, 8, 9, 10, 11, 12, 56, 62, 63, 64], "doublemlirm": [2, 4, 5, 7, 9, 10, 11, 12, 35, 37, 41, 47, 49, 50, 52, 54, 56, 62, 63, 64, 65, 66, 70, 74], "def": [2, 4, 5, 7, 8, 9, 10, 11, 12, 40, 43, 50, 51, 54, 55, 63, 66], "mae": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 63], "subset": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 50, 51, 54, 58, 62, 63, 68], "logical_not": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 63], "isnan": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 63], "ml_g0": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 37, 44, 50, 52, 56, 63, 64], "85974356": [2, 4, 5, 7, 8, 9, 10, 11, 12], "ml_g1": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 37, 44, 50, 52, 56, 63, 64], "85280376": [2, 4, 5, 7, 8, 9, 10, 11, 12], "35365143": [2, 4, 5, 7, 8, 9, 10, 11, 12], "n_jobs_cv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 50], "store_predict": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 52, 54], "external_predict": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 40, 63], "store_model": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "cpu": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "store": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 58, 63, 65, 66, 67, 68, 74], "thi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75], "allow": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 28, 35, 52, 53, 62, 63, 65, 66, 67, 69, 70, 74, 75], "analyz": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 52, 53, 56, 75], "extract": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "inform": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 29, 30, 32, 36, 39, 41, 42, 50, 56, 68, 73], "specif": [2, 4, 5, 7, 8, 9, 10, 11, 12, 28, 34, 35, 51, 52, 60, 61, 62, 63, 65, 66, 67, 70, 72], "suppli": [2, 4, 5, 7, 8, 9, 10, 11, 12, 41, 42, 47, 48, 49, 54, 62, 68], "instead": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 35, 39, 49, 52, 53, 62, 63, 68, 74], "nest": [2, 4, 5, 7, 8, 9, 10, 11, 12, 63, 66, 68], "kei": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 41, 42, 47, 48, 51, 52, 53, 63, 66, 68, 74], "refer": [2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 35, 45, 49, 52, 53, 56, 60, 61, 62, 64, 68, 73, 74], "get_param": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 63], "get": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 36, 50, 56, 68, 70, 71], "hyperparamet": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 36, 37, 46, 50, 52, 61, 72], "see": [2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 21, 26, 27, 28, 32, 34, 35, 36, 39, 41, 42, 44, 51, 53, 54, 56, 63, 64, 65, 66, 68, 71, 72, 74], "params_nam": [2, 4, 5, 7, 8, 9, 10, 11, 12], "param": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 63], "p_adjust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 65, 67, 69, 70, 72], "romano": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 67, 69], "wolf": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 67, 69], "multipl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 34, 35, 44, 51, 52, 56, 57, 60, 63, 64, 65, 67, 68, 69, 74, 75], "test": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 20, 32, 33, 34, 35, 36, 40, 49, 51, 59, 63, 64, 65, 66, 67, 69, 72, 73, 74, 75], "adjust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 45, 51, 53, 56, 62, 67, 68, 69, 75], "bonferroni": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 67, 69], "holm": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "etc": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 50, 51, 74], "In": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75], "addit": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 23, 24, 25, 46, 63, 64, 66, 68, 73], "statsmodel": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "stat": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 40, 60, 63, 67, 69, 70, 73], "multitest": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "multipletest": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "appli": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 32, 33, 34, 35, 36, 40, 44, 45, 50, 51, 52, 53, 57, 59, 64, 65, 66, 67, 69, 70, 72, 74, 75], "p_val": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "sensitivity_analysi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 49, 56, 68, 75], "cf_y": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 31, 49, 56, 68, 75], "03": [2, 4, 5, 7, 8, 9, 10, 11, 12, 41, 42, 43, 49, 52, 53, 55, 56, 65, 68, 75], "cf_d": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 31, 49, 56, 68, 75], "rho": [2, 4, 5, 7, 8, 9, 10, 11, 12, 31, 49, 56, 68, 75], "null_hypothesi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 56, 68], "perform": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 34, 36, 40, 44, 46, 49, 50, 51, 53, 56, 57, 59, 63, 64, 65, 66, 67, 69, 70, 72, 73, 75], "sensit": [2, 4, 5, 7, 8, 9, 10, 11, 12, 31, 61, 62, 74], "analysi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 34, 35, 40, 51, 52, 53, 59, 61, 62, 70, 74], "account": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 51, 52, 53, 56, 68, 75], "unobserv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 35, 39, 52, 53, 56, 64, 68, 75], "confound": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 19, 31, 32, 35, 39, 49, 52, 55, 56, 60, 64, 67, 68, 69, 72, 73, 74, 75], "scenario": [2, 4, 5, 7, 8, 9, 10, 11, 12, 49, 56, 68, 75], "properti": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 36, 50, 52, 53, 56, 63, 68, 72], "sensitivity_param": [2, 4, 5, 7, 8, 9, 10, 11, 12, 56, 68], "percentag": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17], "residu": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 56, 68], "variat": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 56, 68], "explain": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 56, 68], "latent": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 56, 68], "gain": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 31, 50, 68, 74], "riesz": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 56, 68], "represent": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 56, 67, 68, 72, 74], "gener": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 69, 73, 74, 75], "correl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 46, 51, 56, 57, 64, 68], "differ": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 32, 33, 34, 35, 36, 39, 40, 43, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 61, 62, 63, 65, 71, 72, 73, 74, 75], "short": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 56, 68, 73, 74, 75], "long": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 33, 40, 50, 56, 68, 73], "main": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 46, 53, 67, 68, 69, 73, 75], "regress": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 20, 21, 22, 23, 24, 25, 32, 34, 36, 39, 46, 51, 56, 57, 58, 59, 61, 62, 63, 65, 67, 69, 70, 72, 73, 74, 75], "absolut": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 63], "adversari": [2, 4, 5, 7, 8, 9, 10, 11, 12, 56, 68], "strength": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 56, 68], "maxim": [2, 4, 5, 7, 8, 9, 10, 11, 12, 54, 62], "ndarrai": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 20, 21, 22, 23, 24, 25, 26, 60], "null": [2, 4, 5, 7, 8, 9, 10, 11, 12, 56, 68, 74], "hypothesi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 52, 56, 68, 73], "effect": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 32, 33, 34, 36, 39, 40, 44, 45, 46, 49, 51, 54, 57, 59, 61, 63, 64, 65, 66, 67, 68, 72, 73, 74, 75], "robust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 23, 49, 56, 68, 73, 75], "singl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 44, 47, 48, 53, 63, 67, 69], "n_coef": [2, 4, 5, 7, 8, 9, 10, 11, 12, 68], "sensitivity_benchmark": [2, 4, 5, 7, 8, 9, 10, 11, 12, 49, 56, 68], "benchmarking_set": [2, 4, 5, 7, 8, 9, 10, 11, 12, 49, 56, 68], "fit_arg": [2, 4, 5, 7, 8, 9, 10, 11, 12], "benchmark": [2, 4, 5, 7, 8, 9, 10, 11, 12, 31, 49, 74], "given": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 21, 24, 25, 28, 33, 34, 40, 45, 47, 48, 51, 53, 57, 59, 62, 67, 68, 69, 72, 74], "set": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 18, 19, 23, 24, 25, 32, 33, 34, 35, 37, 39, 40, 41, 42, 44, 47, 48, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 62, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75], "featur": [2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 37, 49, 50, 52, 54, 62, 63], "chang": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 44, 53, 56, 57, 67, 68, 71, 73, 74], "benchmark_result": [2, 4, 5, 7, 8, 9, 10, 11, 12], "result": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 33, 36, 40, 41, 42, 44, 45, 46, 49, 50, 54, 56, 57, 59, 63, 65, 66, 68, 72, 74], "rtype": [2, 4, 5, 7, 8, 9, 10, 11, 12], "sensitivity_plot": [2, 4, 5, 7, 8, 9, 10, 11, 12, 49, 56, 68], "idx_treat": [2, 4, 5, 7, 8, 9, 10, 11, 12, 68], "include_scenario": [2, 4, 5, 7, 8, 9, 10, 11, 12], "fill": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 34, 35, 44, 50, 52, 57], "grid_bound": [2, 4, 5, 7, 8, 9, 10, 11, 12], "15": [2, 4, 5, 7, 8, 9, 10, 11, 12, 15, 33, 34, 35, 36, 41, 42, 43, 44, 47, 49, 50, 51, 52, 53, 55, 56, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 75], "grid_siz": [2, 4, 5, 7, 8, 9, 10, 11, 12, 41, 42], "contour": [2, 4, 5, 7, 8, 9, 10, 11, 12, 46, 49, 56, 68], "plot": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 35, 36, 40, 41, 42, 43, 45, 46, 47, 48, 49, 52, 53, 55, 56, 57, 62, 68], "sensiv": [2, 4, 5, 7, 8, 9, 10, 11, 12], "respect": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 52, 53, 62, 64, 65, 68, 75], "index": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 34, 37, 40, 45, 46, 47, 48, 51, 52, 54, 59, 60, 65, 66, 72], "bound": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 49, 52, 56, 68, 75], "ci": [2, 4, 5, 7, 8, 9, 10, 11, 12, 41, 42, 43, 44, 45, 47, 48, 49, 52, 53, 55, 56, 62, 68, 74, 75], "includ": [2, 4, 5, 7, 8, 9, 10, 11, 12, 31, 35, 45, 47, 48, 52, 56, 62, 64, 67, 68, 69, 74, 75], "statist": [2, 4, 5, 7, 8, 9, 10, 11, 12, 23, 26, 31, 34, 51, 56, 67, 68, 69, 70, 72, 73, 74, 75], "uncertainti": [2, 4, 5, 7, 8, 9, 10, 11, 12, 47, 48, 56, 68, 75], "highlight": [2, 4, 5, 7, 8, 9, 10, 11, 12, 44, 74], "call": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 34, 35, 36, 39, 41, 42, 43, 44, 47, 48, 51, 52, 53, 54, 55, 56, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 75], "name": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 33, 34, 47, 48, 49, 51, 56, 63, 71, 74], "heatmap": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 51], "style": [2, 4, 5, 7, 8, 9, 10, 11, 12, 74], "line": [2, 4, 5, 7, 8, 9, 10, 11, 12, 45], "tupl": [2, 4, 5, 7, 8, 9, 10, 11, 12], "grid": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 36, 41, 42, 43, 46, 53, 55, 63, 68], "two": [2, 4, 5, 7, 8, 9, 10, 11, 12, 18, 19, 32, 33, 35, 36, 39, 40, 43, 44, 50, 52, 53, 54, 55, 56, 58, 59, 62, 63, 64, 65, 66, 67, 69, 75], "point": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 47, 48, 51, 62, 75], "fig": [2, 4, 5, 7, 8, 9, 10, 11, 12, 41, 42, 43, 45, 46, 50, 53, 55], "plotli": [2, 4, 5, 7, 8, 9, 10, 11, 12, 41, 42, 46], "figur": [2, 4, 5, 7, 8, 9, 10, 11, 12, 24, 33, 34, 37, 40, 41, 42, 43, 45, 46, 47, 48, 51, 52, 53, 55, 59], "set_ml_nuisance_param": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 37, 52, 63, 74], "treat_var": [2, 4, 5, 7, 8, 9, 10, 11, 12, 63], "outer": [2, 4, 5, 7, 8, 9, 10, 11, 12, 63], "need": [2, 4, 5, 7, 8, 9, 10, 11, 12, 28, 32, 33, 35, 39, 40, 53, 57, 63, 65, 68, 74, 75], "length": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 36, 44, 63], "inner": [2, 4, 5, 7, 8, 9, 10, 11, 12, 63], "set_sample_split": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 65], "all_smpl": [2, 4, 5, 7, 8, 9, 10, 11, 12], "deriv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 28, 67], "partit": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 51, 58, 61], "an": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 18, 29, 30, 33, 34, 35, 36, 40, 41, 42, 46, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "entri": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 37, 40, 44, 49, 51, 52, 53, 56, 57, 59, 60, 63, 70, 72, 74], "per": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 51], "repeat": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 33, 34, 35, 36, 40, 49, 51, 52, 53, 56, 57, 59, 61, 63, 67, 72, 74, 75], "train_ind": [2, 4, 5, 7, 8, 9, 10, 11, 12], "test_ind": [2, 4, 5, 7, 8, 9, 10, 11, 12], "must": [2, 4, 5, 7, 8, 9, 10, 11, 12, 63, 64], "alwai": [2, 4, 5, 7, 8, 9, 10, 11, 12, 74], "viabl": [2, 4, 5, 7, 8, 9, 10, 11, 12], "option": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 33, 34, 35, 41, 42, 47, 48, 49, 50, 51, 52, 53, 57, 63, 65, 66, 67, 69, 74], "arang": [2, 4, 5, 7, 8, 9, 10, 11, 12, 40, 43, 45, 53, 54, 55, 56, 63], "make_plr_ccddhnr2018": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 33, 40, 58, 59, 62, 63, 64, 65, 66, 67, 68], "base": [2, 4, 5, 7, 8, 9, 10, 11, 12, 19, 33, 34, 35, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75], "clone": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 33, 36, 40, 50, 51, 53, 58, 63, 64, 65, 66, 67, 68, 69, 71, 72], "alpha": [2, 4, 5, 7, 8, 9, 10, 11, 12, 22, 24, 33, 34, 35, 37, 40, 41, 42, 43, 46, 50, 51, 52, 53, 55, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69], "dml_plr_obj": [2, 4, 5, 7, 8, 9, 10, 11, 12, 56, 58, 62, 63, 64, 65, 66, 67, 68], "doublemlplr": [2, 4, 5, 7, 8, 9, 10, 12, 33, 35, 36, 37, 40, 42, 48, 52, 56, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75], "simpl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 19, 36, 41, 42, 47, 48, 49, 54, 61, 68], "without": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 33, 39, 40, 50, 59, 61, 63, 68, 71, 74], "smpl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 34, 40, 50, 51, 65, 66], "3": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 24, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74], "4": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 26, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 74], "6": [2, 4, 5, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 22, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74], "7": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 24, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74], "8": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 74, 75], "9": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 75], "tune": [2, 4, 5, 7, 8, 9, 10, 11, 12, 46, 61, 70, 74], "param_grid": [2, 4, 5, 7, 8, 9, 10, 11, 12, 63], "tune_on_fold": [2, 4, 5, 7, 8, 9, 10, 11, 12, 63], "scoring_method": [2, 4, 5, 7, 8, 9, 10, 11, 12], "n_folds_tun": [2, 4, 5, 7, 8, 9, 10, 11, 12], "search_mod": [2, 4, 5, 7, 8, 9, 10, 11, 12, 63], "grid_search": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 63], "n_iter_randomized_search": [2, 4, 5, 7, 8, 9, 10, 11, 12, 63], "set_as_param": [2, 4, 5, 7, 8, 9, 10, 11, 12], "return_tune_r": [2, 4, 5, 7, 8, 9, 10, 11, 12], "exhaust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 63], "search": [2, 4, 5, 7, 8, 9, 10, 11, 12, 28, 63, 66], "over": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 40, 46, 50, 59, 61, 63, 68, 69], "model_select": [2, 4, 5, 7, 8, 9, 10, 11, 12, 40, 51, 63, 65], "gridsearchcv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 63], "via": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 28, 43, 44, 45, 46, 47, 48, 49, 50, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75], "randomizedsearchcv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 63], "learner_nam": [2, 4, 5, 7, 8, 9, 10, 11, 12, 63], "done": [2, 4, 5, 7, 8, 9, 10, 11, 12, 53, 63, 65, 68], "global": [2, 4, 5, 7, 8, 9, 10, 11, 12, 63], "randomized_search": [2, 4, 5, 7, 8, 9, 10, 11, 12, 63], "optim": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 41, 42, 54, 62, 63, 73], "order": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 36, 51, 52, 63, 65, 66], "when": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 35, 44, 52, 64, 66, 67, 69, 70, 71, 72, 74], "detail": [2, 4, 5, 7, 8, 9, 10, 11, 12, 27, 28, 33, 35, 36, 40, 44, 45, 46, 53, 56, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 72, 74, 75], "tune_r": [2, 4, 5, 7, 8, 9, 10, 11, 12], "propos": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 36, 51, 68, 73], "y_col": [3, 6, 32, 33, 34, 35, 36, 39, 41, 42, 46, 47, 48, 51, 52, 53, 54, 56, 58, 59, 60, 63, 64, 65, 66, 72, 74, 75], "d_col": [3, 6, 32, 33, 34, 35, 36, 39, 41, 42, 47, 48, 51, 52, 53, 54, 56, 58, 59, 60, 63, 64, 65, 66, 72, 74, 75], "cluster_col": [3, 34, 51], "x_col": [3, 6, 32, 34, 35, 36, 39, 46, 51, 52, 53, 54, 56, 60, 63, 72, 74, 75], "z_col": [3, 6, 7, 9, 10, 32, 34, 35, 39, 51, 52, 53, 57, 60, 62, 64, 74], "t_col": [3, 5, 6, 64], "s_col": [3, 6, 57, 64], "use_other_treat_as_covari": [3, 6, 60], "force_all_x_finit": [3, 6], "backend": [3, 6, 53, 56, 61, 74], "cluster": [3, 23, 73, 74], "well": [3, 6, 33, 34, 40, 46, 50, 51, 58, 59, 60, 65, 72], "covari": [3, 4, 5, 6, 8, 10, 11, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 56, 57, 59, 60, 62, 63, 64, 66, 67, 68, 72, 74], "column": [3, 6, 37, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 60, 62, 63, 65, 72, 74, 75], "neither": [3, 6, 34, 51, 60], "nor": [3, 6, 34, 51, 60], "instrument": [3, 6, 7, 10, 14, 20, 22, 34, 35, 36, 37, 44, 49, 51, 52, 53, 55, 56, 57, 60, 63, 64, 66, 67, 72, 75], "time": [3, 4, 6, 22, 23, 33, 34, 35, 40, 44, 45, 46, 47, 48, 51, 52, 53, 56, 57, 64, 74, 75], "did": [3, 6, 33, 44, 45, 51, 61, 74, 75], "select": [3, 6, 22, 26, 46, 50, 58, 61, 63, 73, 74, 75], "ssm": [3, 6, 26, 61], "estimatior": [3, 6], "case": [3, 6, 7, 8, 15, 19, 32, 34, 35, 39, 41, 42, 43, 46, 49, 51, 54, 55, 56, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 74, 75], "other": [3, 6, 10, 11, 33, 34, 35, 36, 40, 44, 50, 51, 52, 53, 55, 56, 57, 59, 60, 62, 63, 64, 65, 67, 68, 70, 71, 72, 73, 74, 75], "ad": [3, 6, 14, 15, 28, 49, 60, 63, 67, 68, 74], "rais": [3, 6, 29, 30, 63], "infinit": [3, 6, 74], "miss": [3, 6, 36, 63, 64, 66, 74], "possibl": [3, 6, 36, 41, 42, 47, 48, 49, 50, 54, 56, 63, 67, 68, 74, 75], "na": [3, 6, 33, 34, 59, 74], "inf": [3, 6], "note": [3, 6, 7, 8, 10, 11, 27, 28, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 65, 66, 70, 72], "reason": [3, 6, 32, 39, 56, 68, 75], "capabl": [3, 6, 32, 39], "make_pliv_multiway_cluster_ckms2021": [3, 34, 51], "df": [3, 6, 32, 33, 34, 39, 41, 42, 43, 45, 51, 55, 56, 57, 59, 62, 64], "obj_dml_data_from_df": [3, 6], "cluster_var_i": [3, 34, 51], "cluster_var_j": [3, 34, 51], "z": [3, 6, 7, 9, 10, 16, 17, 18, 20, 22, 23, 26, 32, 34, 35, 39, 41, 42, 46, 51, 52, 55, 57, 62, 64, 66, 67, 69, 74], "cluster_var": [3, 23], "obj_dml_data_from_arrai": [3, 6], "from_arrai": [3, 6, 40, 43, 44, 45, 55, 59, 60, 63, 67, 69, 72], "classmethod": [3, 6], "set_x_d": [3, 6], "treatment_var": [3, 6], "assign": [3, 6, 35, 52, 62, 63, 64, 75], "role": [3, 6, 33, 40, 59, 75], "activ": [3, 6, 71, 74], "in_sample_norm": [4, 5, 44, 66, 68], "panel": [4, 18, 73, 74], "period": [4, 44, 45, 64], "g_0": [4, 5, 7, 8, 10, 11, 12, 24, 25, 33, 34, 35, 40, 50, 51, 52, 59, 62, 63, 64, 66, 68, 72, 75], "y_1": [4, 18, 66], "y_0": [4, 18, 66], "For": [4, 5, 7, 8, 11, 18, 27, 28, 32, 34, 36, 39, 44, 49, 50, 51, 53, 54, 56, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 75], "also": [4, 5, 7, 8, 11, 32, 33, 34, 35, 36, 39, 40, 41, 42, 44, 47, 48, 49, 51, 52, 53, 54, 56, 59, 62, 63, 65, 66, 67, 68, 71, 72, 74, 75], "is_classifi": [4, 5, 7, 8, 11], "otherwis": [4, 5, 7, 8, 11, 35, 52, 53, 54, 64], "experiment": [4, 5, 18, 66, 68], "b": [4, 5, 25, 33, 34, 36, 40, 41, 42, 51, 55, 59, 62, 63, 67, 68, 69, 70, 72, 73], "independ": [4, 5, 16, 17, 18, 19, 34, 36, 45, 49, 51, 54, 64, 66, 74], "pretreat": [4, 5, 44], "sligthli": [4, 5], "sant": [4, 5, 16, 17, 18, 44, 64, 73], "anna": [4, 5, 16, 17, 18, 44, 64, 73], "zhao": [4, 5, 16, 17, 18, 44, 64, 73], "2020": [4, 5, 16, 17, 18, 20, 36, 44, 63, 64, 68, 73], "make_did_sz2020": [4, 5, 44, 64], "42": [4, 5, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 53, 54, 55, 56, 57, 62, 63, 64, 65, 67, 69, 73], "dml_did_obj": [4, 5, 64], "685104": 4, "798071": 4, "493325": 4, "135352": 4, "209257": 4, "83905": 4, "section": [5, 18, 34, 35, 36, 49, 51, 53, 74], "cross_sectional_data": [5, 18, 44, 64], "604603": 5, "725802": 5, "756905": 5, "449107": 5, "23": [5, 34, 35, 36, 41, 42, 44, 51, 52, 53, 55, 56, 60, 62, 63, 64, 65, 67, 70, 72, 73, 75], "706862": 5, "497655": 5, "ml_r": [7, 10, 32, 34, 35, 39, 51, 52, 64, 74], "late": [7, 32, 35, 52, 64, 66], "subgroup": [7, 35, 52, 74], "interact": [7, 8, 16, 20, 21, 61, 63, 70, 74, 75], "iv": [7, 10, 11, 20, 22, 23, 33, 34, 40, 51, 59, 60, 61, 68, 70, 74, 75], "r_0": [7, 10, 35, 52, 64], "signatur": [7, 8, 9, 10, 11, 12, 13, 66], "psi_a": [7, 8, 10, 11, 27, 33, 34, 40, 51, 65, 66, 67], "psi_b": [7, 8, 10, 11, 27, 33, 40, 62, 65, 66], "g_hat0": [7, 8], "g_hat1": [7, 8], "m_hat": [7, 8, 10, 11, 33, 40, 66], "r_hat0": 7, "r_hat1": 7, "adapt": [7, 52, 74], "taker": [7, 74], "never": [7, 34, 51, 74], "take": [7, 8, 10, 11, 16, 17, 19, 41, 42, 43, 44, 45, 46, 47, 48, 50, 53, 55, 56, 57, 58, 62, 63, 64, 68, 72], "logic": [7, 36, 63], "item": [7, 52, 58, 63, 65], "always_tak": [7, 35, 52], "spefici": 7, "never_tak": [7, 35, 52], "make_iivm_data": [7, 9, 62, 64], "1000": [7, 9, 33, 39, 40, 44, 45, 47, 48, 49, 50, 52, 53, 56, 59, 62, 64], "alpha_x": [7, 20, 64], "dml_iivm_obj": [7, 39, 64], "378351": 7, "190648": 7, "984551": 7, "047194": 7, "004688": 7, "752015": 7, "iivm": [7, 20, 27, 28, 53, 58, 61, 62, 70, 74], "ell_0": [7, 10, 11, 33, 40, 46, 59, 64], "zeta": [7, 10, 11, 35, 52, 62, 64, 72], "mathbb": [7, 8, 10, 11, 16, 17, 18, 27, 28, 34, 44, 45, 49, 50, 51, 57, 62, 64, 66, 67, 68, 69, 72, 75], "v": [7, 8, 10, 11, 14, 15, 21, 22, 23, 24, 26, 33, 34, 35, 40, 49, 51, 52, 58, 59, 62, 64, 67, 69, 70, 72, 73, 74, 75], "lbrace": [7, 8, 20, 21, 26, 34, 51, 58, 64, 65, 67, 69], "rbrace": [7, 8, 20, 21, 26, 34, 51, 58, 64, 65, 67, 69], "map": [7, 29, 30, 34, 51, 62, 64], "support": [7, 19, 34, 50, 51, 54, 63, 64, 75], "r": [7, 20, 40, 41, 42, 45, 46, 51, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75], "varepsilon": [7, 16, 17, 23, 34, 51, 57, 62, 64], "nu": [7, 18, 25, 57, 64, 68], "u": [7, 8, 9, 12, 13, 16, 17, 18, 19, 21, 26, 33, 34, 35, 40, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 55, 56, 59, 64, 68, 71, 75], "interest": [7, 8, 10, 11, 16, 17, 33, 35, 40, 44, 46, 52, 53, 57, 59, 62, 64, 66, 67, 69, 72, 75], "local": [7, 9, 62, 64, 73, 74], "averag": [7, 8, 11, 16, 17, 18, 32, 36, 39, 44, 45, 49, 53, 54, 56, 57, 61, 64, 67, 68, 73, 75], "theta_0": [7, 8, 10, 11, 19, 33, 34, 35, 40, 41, 42, 46, 47, 48, 51, 52, 57, 59, 62, 64, 66, 67, 68, 72], "frac": [7, 16, 17, 18, 20, 21, 22, 24, 25, 26, 28, 33, 34, 36, 40, 45, 46, 49, 51, 58, 59, 62, 64, 66, 67, 68, 69], "ATE": [8, 35, 37, 52, 56, 62, 64, 66, 68], "att": [8, 45, 49, 54, 62, 64, 66, 68, 74], "individu": [8, 35, 45, 47, 48, 49, 52, 53, 56, 62, 75], "equal": [8, 34, 51, 57, 62, 63, 68], "weights_bar": 8, "414073": 8, "238529": 8, "735941": 8, "082574": 8, "053436": 8, "881581": 8, "we": [8, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75], "fulli": [8, 35, 38, 52, 64], "heterogen": [8, 19, 35, 49, 52, 53, 54, 61, 64, 65, 73, 74, 75], "treat": [8, 18, 44, 45, 49, 54, 62, 64, 67, 75], "calcul": [8, 11, 35, 41, 42, 43, 47, 48, 50, 52, 55, 56, 68], "doublemlblp": [8, 11, 41, 42, 62, 74], "group": [8, 11, 32, 39, 49, 53, 54, 61], "mutual": [8, 11, 35, 47, 48, 52, 53, 62], "exclus": [8, 11, 47, 48, 62], "code": [8, 11, 25, 32, 34, 35, 36, 39, 46, 52, 59, 62, 63, 64, 65, 66, 67, 71, 72, 74, 75], "policy_tre": [8, 54, 62], "depth": [8, 35, 36, 54, 58, 62, 63, 64, 65, 66, 67, 72, 75], "tree_param": 8, "decis": [8, 32, 35, 39, 52, 53, 62, 73, 75], "tree": [8, 35, 36, 44, 45, 50, 52, 58, 61, 63, 64, 65, 66, 67, 72, 74], "polici": [8, 10, 11, 61, 64, 72, 73, 74], "classif": [8, 32, 35, 36, 50, 54, 62, 63, 64, 75], "larger": [8, 68], "than": [8, 33, 35, 40, 46, 50, 52, 53, 56, 59, 68, 75], "deeper": 8, "more": [8, 32, 35, 39, 41, 42, 46, 50, 52, 53, 56, 58, 62, 63, 64, 66, 67, 68, 72, 75], "complex": 8, "forward": 8, "decisiontreeclassifi": [8, 52], "minim": [8, 35, 50, 52], "prune": 8, "ccp_alpha": [8, 52], "doublemlpolicytre": [8, 62], "lpq": [9, 13, 53, 62, 74], "kde": [9, 12, 13, 52], "priliminari": [9, 13], "propens": [9, 13, 16, 17, 35, 44, 49, 50, 52, 53, 57, 62], "pq": [9, 12, 13, 53, 74], "kernel": [9, 12, 13], "densiti": [9, 12, 13, 33, 40], "here": [9, 12, 13, 34, 35, 36, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 60, 63, 71], "nonparametr": [9, 12, 13, 68, 73], "kdeunivari": [9, 12, 13], "gaussian": [9, 12, 13, 33, 40, 59, 62, 63, 67, 69, 73], "silverman": [9, 12, 13], "bandwidth": [9, 12, 13], "dml_lpq_obj": [9, 62], "217244": 9, "636453": 9, "341336": 9, "73285": 9, "03018": 9, "464668": 9, "ml_l": [10, 11, 33, 34, 35, 36, 37, 40, 42, 48, 51, 52, 56, 58, 59, 63, 64, 65, 66, 67, 68, 69, 72, 74, 75], "partial": [10, 11, 17, 22, 23, 24, 25, 28, 34, 36, 37, 46, 51, 56, 58, 61, 63, 65, 67, 69, 70, 72, 74, 75], "out": [10, 11, 34, 36, 37, 44, 46, 50, 51, 53, 56, 57, 58, 60, 61, 62, 63, 64, 66, 67, 68, 70, 72, 74, 75], "requir": [10, 11, 32, 35, 36, 49, 52, 53, 56, 64, 67, 68, 69, 71, 74, 75], "l_hat": [10, 11, 33, 40, 66], "r_hat": 10, "g_hat": [10, 11, 33, 40, 66], "make_pliv_chs2015": [10, 64], "dim_z": [10, 22, 64], "z1": [10, 64], "dml_pliv_obj": [10, 34, 51, 64], "522753": 10, "082263": 10, "354688": 10, "088504e": 10, "361521": 10, "683984": 10, "pliv": [10, 27, 28, 34, 51, 58, 61, 62, 70, 74], "denot": [10, 34, 35, 44, 45, 51, 52, 57, 62, 64, 66, 68], "one": [10, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 50, 51, 53, 56, 59, 62, 63, 64, 65, 66, 67, 68, 69, 72, 74], "high": [10, 11, 21, 35, 45, 46, 52, 53, 58, 64, 67, 69, 70, 72, 73], "dimension": [10, 11, 19, 21, 46, 62, 64, 65, 67, 68, 69, 72, 73], "x_1": [10, 11, 16, 17, 18, 41, 42, 43, 45, 47, 48, 49, 55, 64, 68, 72], "ldot": [10, 11, 34, 51, 57, 58, 64, 65, 67, 69, 72], "x_p": [10, 11, 64, 72], "consist": [10, 11, 35, 44, 52, 53, 59, 60, 64, 72, 74], "stochast": [10, 11, 64, 72], "462321": 11, "04107": 11, "11": [11, 34, 35, 36, 37, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 75], "256983": 11, "139582e": 11, "29": [11, 34, 35, 36, 41, 42, 51, 52, 56, 57, 62, 63, 64, 65, 67, 72], "381826": 11, "542816": 11, "plr": [11, 27, 28, 36, 56, 58, 61, 63, 65, 67, 69, 70, 72, 74, 75], "dml_pq_obj": [12, 62], "553878": [12, 62], "149858": [12, 62], "696011": [12, 62], "000219": [12, 62], "260161": [12, 62], "847595": [12, 62], "array_lik": 13, "dml_qte_obj": [13, 62], "25": [13, 16, 17, 18, 22, 23, 24, 34, 35, 36, 41, 42, 43, 45, 46, 51, 52, 53, 55, 57, 62, 63, 64, 65, 67, 72, 75], "75": [13, 18, 36, 41, 43, 45, 52, 53, 55, 62, 63, 64, 65, 67, 69, 74], "274825": [13, 62], "347310": [13, 62], "791297": [13, 62], "428771": [13, 62], "405890": [13, 62], "955541": [13, 62], "50": [13, 34, 36, 43, 45, 48, 50, 52, 53, 55, 62, 63, 64, 65, 67], "449150": [13, 62], "192539": [13, 62], "332782": [13, 62], "019660": [13, 62], "071782": [13, 62], "826519": [13, 62], "709606": [13, 62], "193308": [13, 62], "670867": [13, 62], "000242": [13, 62], "330731": [13, 62], "088482": [13, 62], "n_jobs_model": [13, 43, 53, 55], "doe": [13, 34, 35, 51, 52, 56, 68, 75], "speed": [13, 50], "up": [13, 35, 46, 50, 52, 53, 56, 63, 64, 65, 68, 71, 74, 75], "polynomial_featur": [14, 15, 35, 37], "financi": [14, 56, 75], "wealth": [14, 56], "401": [14, 75], "k": [14, 17, 18, 20, 21, 22, 23, 24, 26, 33, 34, 36, 40, 50, 51, 58, 59, 61, 62, 67, 69, 75], "plan": [14, 35, 52, 53, 75], "particip": [14, 53, 56, 75], "polynomi": [14, 15, 35, 37, 52], "file": [14, 15, 46, 73, 74], "chernozhukov": [14, 15, 21, 22, 24, 33, 34, 35, 40, 46, 50, 51, 52, 53, 56, 59, 65, 67, 68, 69, 70, 73, 74], "et": [14, 15, 19, 21, 23, 24, 33, 34, 35, 36, 40, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 55, 56, 59, 64, 65, 66, 67, 68, 69, 70, 72, 74], "al": [14, 15, 19, 21, 23, 24, 33, 34, 35, 36, 40, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 55, 56, 59, 64, 65, 66, 67, 68, 69, 70, 72, 74], "2018": [14, 15, 24, 25, 33, 34, 35, 40, 44, 46, 50, 51, 52, 53, 56, 59, 65, 67, 69, 70, 73, 74], "abadi": [14, 44], "2003": [14, 73], "semiparametr": 14, "respons": [14, 36, 63], "journal": [14, 15, 16, 17, 18, 23, 24, 26, 34, 36, 46, 51, 59, 63, 70, 72, 73, 74], "econometr": [14, 15, 16, 17, 18, 24, 25, 34, 46, 51, 59, 70, 73], "113": [14, 62, 74], "231": [14, 74], "263": [14, 53], "chetverikov": [14, 15, 24, 34, 46, 51, 59, 67, 69, 70, 73], "demir": [14, 15, 24, 34, 46, 51, 59, 65, 70, 73], "m": [14, 15, 16, 22, 23, 24, 33, 34, 36, 37, 40, 46, 49, 51, 59, 61, 62, 63, 66, 68, 70, 71, 72, 73, 74], "duflo": [14, 15, 24, 34, 46, 51, 59, 65, 70, 73], "hansen": [14, 15, 21, 22, 24, 34, 46, 51, 59, 70, 73], "c": [14, 15, 17, 18, 21, 22, 24, 32, 33, 34, 35, 36, 37, 39, 40, 45, 46, 47, 48, 51, 52, 59, 60, 63, 70, 71, 72, 73, 75], "newei": [14, 15, 24, 34, 46, 51, 59, 70, 73], "w": [14, 15, 16, 17, 18, 24, 27, 28, 34, 46, 51, 54, 58, 59, 66, 67, 68, 69, 70, 72], "robin": [14, 15, 24, 34, 46, 51, 59, 70, 73], "j": [14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 33, 34, 36, 40, 46, 51, 57, 59, 63, 67, 69, 70, 72], "debias": [14, 15, 23, 24, 34, 46, 51, 61, 63, 65, 70, 73, 74], "structur": [14, 15, 24, 34, 35, 46, 51, 52, 57, 59, 63, 70, 73, 75], "21": [14, 15, 24, 33, 34, 35, 36, 41, 42, 46, 50, 51, 52, 53, 55, 56, 59, 62, 63, 64, 65, 67, 70, 72, 73, 75], "c1": [14, 15, 24, 34, 46, 51, 59, 70, 73], "c68": [14, 15, 24, 34, 46, 51, 59, 70, 73], "doi": [14, 15, 16, 17, 18, 20, 23, 24, 26, 34, 36, 46, 51, 59, 63, 65, 67, 69, 70, 72, 74], "1111": [14, 15, 24, 33, 34, 40, 46, 51, 59, 64, 68, 70], "ectj": [14, 15, 24, 34, 46, 51, 59, 70], "12097": [14, 15, 24, 34, 46, 51, 59, 70], "pennsylvania": [15, 60, 72], "reemploy": [15, 60, 72], "bonu": [15, 36, 60, 72], "experi": [15, 20, 21, 33, 35, 40, 52, 59, 60, 65, 72, 73], "bilia": 15, "2000": [15, 35, 41, 42, 43, 52, 53, 55, 57, 64], "sequenti": 15, "durat": 15, "575": 15, "594": 15, "04": [16, 17, 35, 41, 42, 52, 53, 55, 56, 65, 75], "counfound": [16, 17, 55, 56, 62, 68], "process": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 41, 42, 43, 44, 45, 46, 47, 48, 50, 54, 55, 57, 61, 67, 68, 69, 73], "defin": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 35, 36, 40, 41, 42, 43, 44, 46, 47, 48, 50, 52, 53, 54, 55, 56, 62, 63, 64, 66, 68], "follow": [16, 17, 18, 19, 33, 34, 35, 40, 41, 42, 43, 44, 45, 47, 48, 51, 52, 53, 55, 56, 57, 59, 60, 62, 63, 64, 65, 68, 71, 72, 75], "similar": [16, 17, 36, 41, 42, 49, 53, 56], "mont": [16, 17, 19, 41, 42, 47, 48], "carlo": [16, 17, 19, 41, 42, 47, 48, 73], "simul": [16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 33, 36, 40, 41, 42, 43, 46, 47, 48, 55, 57, 59, 63, 67, 69, 72], "let": [16, 17, 18, 33, 35, 36, 40, 43, 44, 47, 48, 50, 52, 53, 55, 57, 58, 59, 63, 64, 68, 75], "x_2": [16, 17, 18, 41, 42, 43, 45, 47, 48, 49, 55, 68], "x_3": [16, 17, 18, 41, 42, 45, 47, 48, 49, 68], "x_4": [16, 17, 18, 41, 42, 43, 47, 48, 49, 55], "x_5": [16, 17, 41, 42, 47, 48], "sim": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 40, 43, 45, 51, 54, 55, 57, 59], "mathcal": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 40, 43, 45, 51, 54, 55, 57, 59], "sigma": [16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 33, 34, 40, 51, 57, 59, 62, 65, 67, 68, 69], "ident": [16, 17, 18, 19, 22, 36, 63, 68], "matrix": [16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 33, 34, 35, 36, 40, 51, 57, 59, 60, 63, 67, 69, 72, 74, 75], "further": [16, 17, 18, 19, 23, 34, 36, 41, 42, 43, 44, 45, 49, 50, 51, 53, 54, 55, 56, 57, 63, 64, 66, 67, 68, 69, 70, 72, 74, 75], "z_j": [16, 17, 18], "tild": [16, 17, 18, 34, 51, 58, 62, 65, 66, 67, 68, 69], "_j": [16, 17, 18, 23, 34, 51, 67, 69], "sqrt": [16, 17, 18, 21, 33, 34, 36, 37, 40, 43, 51, 55, 59, 65, 67, 68, 69, 72], "text": [16, 17, 18, 20, 34, 35, 43, 46, 54, 55, 62, 65], "var": [16, 17, 18, 34, 51, 68], "_1": [16, 17, 18, 57, 66], "exp": [16, 17, 18, 19, 21, 24, 33, 40, 41, 42, 45, 47, 48, 54, 59], "cdot": [16, 17, 18, 34, 43, 45, 49, 51, 55, 62, 64, 66, 67, 69], "_2": [16, 17, 18], "_3": [16, 17, 18], "_4": [16, 17, 18], "_5": 16, "addition": [16, 17, 43, 53, 56, 63, 64, 65, 67, 68, 72], "At": [16, 17, 18, 34, 44, 45, 49, 50, 51, 53, 55, 75], "first": [16, 17, 18, 23, 32, 33, 34, 35, 36, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 59, 62, 65, 67, 68, 69, 71, 72, 74, 75], "gamma_a": [16, 17], "ge": [16, 18, 19, 49, 54, 62], "sinc": [16, 17, 35, 44, 45, 47, 48, 49, 50, 52, 57, 63, 64, 68, 74], "z_5": 16, "beta_a": [16, 17], "210": [16, 17, 18], "27": [16, 17, 18, 33, 34, 35, 36, 37, 41, 42, 44, 51, 52, 53, 57, 60, 62, 63, 64, 65, 67, 72, 73], "z_1": [16, 17], "13": [16, 17, 18, 20, 33, 34, 35, 36, 37, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 75], "z_2": [16, 17], "z_3": [16, 17], "z_4": [16, 17], "impli": [16, 17, 34, 35, 51, 52, 53, 62, 68], "expect": [16, 17, 44, 49, 50, 57, 62, 65, 67, 72], "mathrm": [16, 17], "cov": 16, "consequ": [16, 17, 34, 49, 51, 56, 62, 64, 68], "both": [16, 17, 19, 35, 36, 44, 45, 50, 52, 53, 54, 56, 60, 63, 67, 68, 74, 75], "chosen": [16, 17, 50, 63], "obtain": [16, 17, 32, 33, 34, 39, 40, 41, 42, 43, 44, 46, 50, 51, 55, 57, 58, 59, 62, 63, 65, 66, 67, 68, 69, 71, 72], "desir": [16, 17, 36, 54], "orcal": [16, 17], "transform": [16, 17, 75], "res_dict": [16, 17, 19], "oracle_valu": [16, 17], "h": [16, 17, 18, 20, 23, 34, 51, 73], "doubli": [16, 17, 18, 73], "219": [16, 17, 18, 73], "101": [16, 17, 18, 62, 73, 74], "122": [16, 17, 18, 60, 62, 73, 74], "1016": [16, 17, 18], "jeconom": [16, 17, 18], "06": [16, 17, 18, 41, 42, 43, 52, 53, 55, 62, 65, 66, 67], "003": [16, 17, 18], "kwarg": [17, 18, 23, 24, 25, 29], "sigma_": [17, 18, 20, 21, 22, 23, 24, 26, 33, 34, 40, 51, 59], "kj": [17, 18, 20, 21, 22, 23, 24, 26, 33, 34, 40, 51, 59], "varepsilon_d": 17, "dgp_type": [18, 44], "w_1": [18, 54], "w_2": [18, 54], "w_3": 18, "w_4": 18, "f_": [18, 45, 62], "reg": [18, 35, 52, 75], "w_": [18, 34, 51, 54], "varepsilon_0": 18, "varepsilon_1": 18, "standard": [18, 36, 43, 47, 48, 65, 66, 67, 68, 69, 74, 75], "uniform": [18, 39, 41, 42, 43, 45, 54, 55, 67], "dgp1": 18, "quad": [18, 35, 44, 52, 54, 57, 62, 64, 66, 67, 68, 69], "dgp2": 18, "dgp3": 18, "dgp4": 18, "dgp5": 18, "dgp6": 18, "last": [18, 36, 71], "alreadi": [18, 44, 57, 63, 64], "flag": [18, 65, 71], "Then": [18, 43, 55, 67, 68, 69, 70, 71], "u_t": 18, "le": [18, 44, 54, 62, 64, 66], "lambda_t": 18, "zero": [18, 43, 44, 45, 50, 54, 55, 56, 67], "dgp": [18, 34, 43, 45, 46, 51, 54, 55, 57], "integ": [18, 36, 63], "keyword": [18, 23, 24, 25], "argument": [18, 23, 24, 25, 35, 41, 42, 44, 49, 50, 52, 53, 58, 62, 63, 64, 75], "non": [18, 23, 24, 25, 32, 33, 35, 39, 40, 45, 52, 53, 54, 63, 65, 66, 67], "xi": [18, 64], "200": [19, 22, 40, 43, 44, 46, 50, 54, 55, 57, 59, 63, 74], "30": [19, 32, 33, 34, 36, 39, 40, 41, 42, 43, 44, 51, 52, 53, 55, 57, 62, 63, 64, 65, 67, 72], "support_s": [19, 41, 42, 47, 48, 54], "n_x": [19, 41, 42, 47, 48, 49], "binary_treat": [19, 41, 47, 49], "creat": [19, 32, 34, 36, 39, 40, 41, 42, 43, 47, 48, 51, 53, 54, 55, 63, 68, 71], "synthet": [19, 32, 39, 41, 42, 43, 47, 48, 54, 55], "oprescu": [19, 41, 42, 47, 48, 73], "2019": [19, 36, 41, 42, 43, 47, 48, 53, 55, 56, 63, 66, 70, 72, 73], "y_i": [19, 20, 21, 22, 24, 25, 26, 33, 40, 43, 44, 54, 55, 57, 59, 64], "x_i": [19, 20, 21, 22, 24, 25, 26, 33, 40, 43, 44, 47, 48, 55, 57, 59, 62, 64], "d_i": [19, 20, 21, 22, 24, 25, 26, 33, 40, 43, 44, 55, 57, 59, 64], "langl": [19, 54], "gamma_0": [19, 54, 57, 66], "rangl": [19, 54], "epsilon_i": [19, 43, 54, 55], "beta_0": [19, 54, 57, 62], "eta_i": [19, 45, 54, 55], "small": [19, 44, 45, 54, 57, 68], "dimens": [19, 23, 34, 51, 54, 65], "univari": [19, 41, 42], "2x_0": [19, 41, 42, 47, 48], "sin": [19, 25, 41, 42, 45, 47, 48], "4x_0": [19, 41, 42, 47, 48], "wherea": [19, 44, 57, 68, 75], "4x_1": [19, 41, 42], "treatment_effect": [19, 41, 42], "left": [20, 21, 22, 23, 26, 33, 34, 40, 50, 51, 52, 53, 55, 59, 66, 67, 68, 69], "v_i": [20, 21, 24, 25, 26, 33, 40, 59, 64], "right": [20, 21, 22, 23, 26, 33, 34, 40, 50, 51, 52, 53, 55, 59, 66, 67, 68, 69], "beta": [20, 21, 22, 26, 35, 52, 54, 57], "u_i": [20, 22, 25, 26], "bernoulli": 20, "begin": [20, 22, 23, 33, 34, 35, 36, 40, 43, 45, 50, 51, 52, 54, 55, 57, 58, 60, 63, 65, 67, 69, 72, 75], "end": [20, 22, 23, 33, 34, 35, 40, 43, 45, 46, 50, 51, 52, 54, 55, 57, 58, 60, 63, 65, 67, 69, 72, 75], "beta_j": [20, 21, 22, 26], "inspir": [20, 21, 26], "farbmach": 20, "gruber": 20, "klaassen": [20, 70, 73], "guber": 20, "klaa\u00dfen": 20, "forest": [20, 32, 33, 35, 36, 39, 40, 44, 49, 50, 52, 56, 59, 63, 72, 75], "mea": 20, "discuss": [20, 34, 35, 51, 52, 73, 74, 75], "paper": [20, 22, 36, 56, 68, 70, 72, 73, 74], "No": [20, 32, 35, 36, 37, 44, 49, 52, 53, 56, 57, 60, 63, 64, 66, 67, 72, 73], "avail": [20, 35, 36, 44, 46, 50, 52, 53, 54, 59, 62, 63, 64, 68, 70, 71, 74, 75], "ssrn": 20, "http": [20, 25, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 63, 70, 71, 72, 74], "dx": 20, "org": [20, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 63, 70, 71, 74], "2139": 20, "3619201": 20, "r2_d": [21, 50], "r2_y": [21, 50], "c_d": [21, 68], "c_y": [21, 68], "zeta_i": [21, 22, 24, 33, 40, 59], "constant": [21, 46, 54, 62, 67, 69], "r_y": 21, "qquad": 21, "pi": [21, 22, 25, 62, 64, 66], "r_d": 21, "appendix": [21, 26, 56, 57, 68], "belloni": [21, 46, 67, 69, 73], "2017": [21, 73], "fern\u00e1ndez": [21, 65, 73], "val": [21, 65, 73], "program": [21, 35, 52, 53, 73, 75], "infer": [21, 22, 32, 33, 34, 39, 40, 46, 51, 59, 61, 65, 70, 72, 73, 74], "With": [21, 41, 42, 63, 73], "econometrica": [21, 34, 51, 59, 73], "85": [21, 43, 49, 53, 55, 57, 62, 63, 64, 65], "233": 21, "298": [21, 36], "150": [22, 36, 41, 42, 62, 74], "spindler": [22, 70, 73, 74], "2015": [22, 73], "z_i": [22, 26, 55, 57, 64], "gamma": [22, 25, 26, 34, 51, 54, 66], "delta": [22, 44, 64], "varepsilon_i": [22, 43, 55, 57], "i_": [22, 51, 54], "p_n": 22, "delta_j": 22, "0_": 22, "post": [22, 25, 64, 67, 69, 73], "regular": [22, 61, 63, 66, 67, 69, 73], "mani": [22, 27, 28, 33, 34, 36, 40, 44, 51, 59, 66, 67, 69, 75], "control": [22, 46, 53, 54, 75], "american": 22, "econom": [22, 23, 25, 26, 34, 46, 51, 65, 73], "review": [22, 46, 73], "proceed": [22, 73], "105": [22, 34, 41, 51, 62, 74], "486": [22, 53], "90": [22, 35, 43, 44, 53, 55, 57, 62, 64, 65, 74], "doublemlclusterdata": 23, "multiwai": [23, 34, 51, 73], "chiang": [23, 34, 51, 73], "2021": [23, 34, 36, 41, 42, 51, 73, 74], "z_": [23, 34, 51], "ij": [23, 34, 51, 57], "x_": [23, 24, 33, 34, 40, 45, 51, 59], "xi_0": [23, 34, 51], "v_": [23, 34, 51], "d_": [23, 34, 45, 51, 64, 67, 69], "pi_": [23, 34, 51], "y_": [23, 34, 44, 45, 51, 57, 64], "zeta_0": [23, 34, 51], "varepsilon_": [23, 34, 51], "omega_1": [23, 34, 51], "omega_2": [23, 34, 51], "alpha_": [23, 34, 51, 63], "p_x": [23, 34, 51], "s_x": [23, 34, 51], "s_": [23, 34, 51, 64], "second": [23, 33, 34, 36, 40, 50, 51, 58, 59, 65, 67, 68, 69, 72], "omega_x": [23, 34, 51], "omega_": [23, 34, 51], "omega_v": [23, 34, 51], "zeta_": [23, 34, 51], "kato": [23, 34, 51, 67, 69, 73], "ma": [23, 34, 51, 73], "sasaki": [23, 34, 51, 73], "busi": [23, 26, 34, 51, 73], "1080": [23, 26, 34, 51], "07350015": [23, 26, 34, 51], "1895815": [23, 34, 51], "arxiv": [23, 34, 51, 70, 73, 74], "1909": [23, 34, 51], "03489": [23, 34, 51], "s_1": 24, "s_2": 24, "a_0": 24, "a_1": 24, "b_0": 24, "b_1": 24, "blog": 25, "articl": [25, 70], "turrel": 25, "symmetr": 25, "posit": [25, 35, 75], "definit": [25, 47, 48, 68], "make_spd_matrix": 25, "b_j": 25, "sinh": 25, "cosh": 25, "co": [25, 45], "python": [25, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75], "part": [25, 33, 34, 35, 36, 40, 50, 51, 52, 59, 63, 65, 68, 74, 75], "markov": [25, 73], "wander": 25, "scienc": [25, 32, 39, 73], "aeturrel": 25, "com": [25, 35, 36, 46, 52, 63, 71], "parti": 25, "ml": [25, 34, 35, 36, 46, 51, 52, 58, 61, 63, 65, 70, 73, 74], "8000": [26, 57], "mar": [26, 64], "s_i": [26, 57, 64], "w_i": [26, 44, 54, 58, 62, 65, 66, 67, 69], "being": [26, 27, 28, 34, 51, 65, 66, 67, 68, 69, 70], "2_x": [26, 57], "2_": [26, 57, 68], "studi": [26, 34, 35, 46, 51, 52, 53, 56, 72, 75], "bia": [26, 32, 39, 46, 57, 61, 64, 65, 66, 68, 73, 74], "huber": [26, 57, 64, 66, 73], "laff\u00e9r": [26, 57, 64, 66], "2023": [26, 57, 64, 66, 73], "boolean": [26, 47, 48, 60, 65], "missing": [26, 57], "hold": [26, 34, 35, 51, 52, 57, 62, 63], "michela": [26, 73], "martin": [26, 70, 73], "luk\u00e1\u0161": 26, "2271071": 26, "mixin": [27, 28, 66], "psi": [27, 28, 33, 34, 51, 58, 66, 67, 68, 72], "eta": [27, 28, 33, 34, 35, 45, 51, 52, 55, 58, 62, 65, 66, 67, 68, 69, 72, 75], "empir": [27, 28, 33, 34, 40, 51, 59, 65, 66, 67, 69], "analog": [27, 28, 34, 51, 53, 56, 62, 64, 66, 67, 68, 69], "moment": [27, 28, 34, 51, 66, 67, 68, 69, 72], "solv": [27, 34, 51, 62, 63, 67, 69], "asymptot": [27, 28, 33, 34, 40, 51, 59, 65, 67, 73], "varianc": [27, 28, 34, 36, 51, 56, 61, 65, 68, 72], "chapter": [27, 28, 36, 63, 68], "user": [27, 28, 29, 30, 33, 34, 35, 36, 40, 49, 50, 51, 52, 56, 62, 63, 66, 67, 69, 70, 71, 72, 74, 75], "guid": [27, 28, 29, 30, 33, 34, 36, 40, 45, 49, 51, 56, 63, 70, 72, 74], "nonlinear": [28, 35, 52, 66, 74], "framework": [28, 33, 34, 36, 40, 50, 51, 59, 63, 67, 69, 70, 72, 74, 75], "numer": [28, 32, 36, 63, 66, 68, 74], "To": [28, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 62, 63, 65, 67, 68, 69, 71, 72, 75], "util": [28, 63, 74], "abstract": [28, 34, 51, 66, 70, 74], "_compute_scor": 28, "_compute_score_deriv": 28, "attributeerror": [29, 30], "attempt": [29, 30], "access": [29, 30, 35, 47, 48, 49, 50, 56, 63, 68, 75], "its": [29, 30, 58, 62, 63, 64, 65, 66, 67], "set_param": [29, 30, 63], "dummyclassifi": 29, "get_metadata_rout": [29, 30], "metadata": [29, 30], "rout": [29, 30], "pleas": [29, 30, 65], "check": [29, 30, 33, 35, 40, 50, 52, 53, 58, 59, 70, 71, 74], "how": [29, 30, 32, 34, 35, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 63, 70, 71], "mechan": [29, 30], "work": [29, 30, 38, 49, 50, 56, 63, 67, 71, 73], "metadatarequest": [29, 30], "encapsul": [29, 30], "deep": [29, 30], "subobject": [29, 30], "regressor": [30, 33, 35, 40, 43, 52, 59], "dummyregressor": 30, "dml_long": 31, "dml_short": 31, "exclud": 31, "sever": [31, 35, 36, 50, 52, 53, 56, 59, 63, 75], "benchmark_dict": [31, 56], "delta_theta": [31, 49, 56, 68], "download": [32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 71, 72], "jupyt": [32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "notebook": [32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 62, 63, 75], "doc": [32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 70, 74], "stabl": [32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58], "r_double_ml_basic_iv": 32, "ipynb": [32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "show": [32, 33, 34, 37, 39, 40, 41, 42, 44, 46, 49, 50, 51, 57, 59, 63, 68, 71], "shown": [32, 39, 72], "below": [32, 35, 39, 52, 71, 72], "so": [32, 35, 36, 39, 44, 52, 57, 63, 67, 75], "compat": [32, 39, 74], "diagram": [32, 39, 64], "packag": [32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75], "assum": [32, 34, 39, 44, 51, 54, 64, 66, 67, 68, 75], "you": [32, 33, 39, 45, 51, 56, 70, 71, 75], "knowledg": [32, 39, 50, 54], "librari": [32, 33, 34, 35, 36, 58, 59, 60, 63, 64, 65, 66, 67, 69, 71, 72, 75], "mlr3learner": [32, 33, 34, 35, 58, 63, 64, 65, 66, 67, 69, 72, 75], "1234": [32, 33, 37, 39, 40, 59, 63, 65, 67, 69], "warn": [32, 33, 34, 35, 36, 40, 58, 63, 64, 65, 66, 67, 69, 72, 74], "load": [32, 35, 36, 46, 52, 53, 60, 71, 72], "mlr3": [32, 33, 34, 35, 58, 63, 64, 65, 66, 67, 69, 70, 72, 74, 75], "uniqu": [32, 39, 50, 66, 68], "while": [32, 39], "continu": [32, 36, 39, 46, 68, 74, 75], "quantiti": [32, 39], "want": [32, 34, 35, 36, 39, 43, 44, 50, 51, 55, 63, 70, 71, 73], "recov": [32, 39], "decision_impact": [32, 39], "impact": [32, 39, 50, 56], "10000": [32, 41, 42, 45, 52, 53, 55], "decision_effect": 32, "instrument_effect": 32, "rbinom": 32, "runif": 32, "rnorm": [32, 36, 60, 63, 67, 69, 72], "sd": 32, "make": [32, 39, 50, 62, 63, 74, 75], "though": [32, 39], "bias": [32, 35, 39, 52, 53, 56, 75], "00047580260495": 32, "least": [32, 35, 39, 52, 53, 56, 65], "fake": [32, 39], "doesn": [32, 39], "bring": [32, 39], "ani": [32, 33, 36, 39, 40, 44, 57, 59, 71, 75], "kind": [32, 39, 52], "obs_confound": [32, 39], "relationship": [32, 39, 46, 67, 69], "betwen": [32, 39], "pair": [32, 39], "choos": [32, 35, 39, 40, 46, 50, 52, 53, 58, 65, 66, 67, 69, 72, 75], "linearregress": [32, 39, 50], "becaus": [32, 33, 34, 39, 40, 49, 51, 59, 75], "logisticregress": [32, 37, 39], "dichotom": [32, 39], "notic": [32, 39], "logist": [32, 35, 39, 52, 57, 75], "could": [32, 36, 39, 41, 42, 74, 75], "flexibl": [32, 35, 36, 39, 44, 52, 70, 75], "deal": [32, 39], "boost": [32, 35, 39, 44, 50, 52], "new": [32, 33, 34, 35, 36, 41, 42, 52, 54, 58, 59, 60, 62, 63, 64, 65, 66, 67, 69, 70, 72, 73, 74, 75], "lrn": [32, 33, 34, 35, 36, 58, 63, 64, 65, 66, 67, 69, 72, 75], "regr": [32, 33, 34, 35, 36, 58, 63, 64, 65, 66, 67, 69, 72, 75], "lm": 32, "log_reg": 32, "iv_2": 32, "doublemliivm": [32, 35, 39, 52, 63, 64, 65, 66, 74], "info": [32, 36, 37, 44, 49, 51, 52, 53, 56, 57, 60, 72, 74, 75], "08": [32, 41, 42, 43, 53, 55, 64, 75], "00": [32, 52, 53, 65, 75], "45": [32, 41, 42, 43, 47, 49, 52, 53, 55, 62, 63, 64, 65, 67], "871": [32, 36], "39": [32, 34, 35, 36, 37, 41, 42, 44, 49, 50, 51, 52, 53, 56, 57, 62, 63, 64, 65, 67], "task": [32, 60, 65, 75], "nuis_m": [32, 75], "iter": [32, 44, 51, 57, 63, 67, 69, 75], "46": [32, 41, 42, 49, 62, 63, 64, 65, 67, 69], "015": [32, 36], "053": [32, 36], "089": 32, "126": [32, 62, 74], "266": 32, "nuis_g0": 32, "291": [32, 53], "310": 32, "328": 32, "346": 32, "460": [32, 53], "nuis_g1": 32, "478": 32, "496": [32, 54], "514": [32, 36], "551": 32, "661": 32, "nuis_r0": 32, "696": 32, "726": [32, 36], "768": 32, "799": 32, "922": 32, "nuis_r1": 32, "951": 32, "986": 32, "47": [32, 35, 41, 42, 44, 52, 56, 62, 63, 64, 65, 67, 74], "016": 32, "046": 32, "amp": [32, 34, 36, 44, 51, 53, 56, 57], "algorithm": [32, 34, 36, 40, 43, 44, 50, 51, 53, 55, 56, 57, 61, 63, 64, 65, 66, 67, 74, 75], "dml2": [32, 34, 36, 37, 44, 51, 53, 61, 64, 66, 67, 72, 74, 75], "resampl": [32, 34, 36, 44, 51, 53, 56, 57, 63, 64, 65, 66, 67, 70, 72, 75], "signific": [32, 34, 35, 36, 49, 52, 54, 56, 63, 64, 65, 66, 67, 68, 72, 75], "pr": [32, 34, 35, 36, 63, 64, 65, 66, 67, 72, 75], "gt": [32, 34, 35, 36, 37, 39, 41, 42, 43, 44, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 60, 72], "8904": 32, "1492": [32, 50], "12": [32, 33, 34, 35, 36, 37, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 55, 56, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75], "67": [32, 36, 41, 52, 62, 63, 64, 65, 67, 72], "lt": [32, 34, 35, 36, 37, 44, 49, 51, 52, 53, 54, 56, 57, 60, 72], "2e": [32, 34, 35, 36, 63, 64, 66, 67, 72], "signif": [32, 34, 35, 36, 63, 64, 65, 66, 67, 72, 75], "001": [32, 34, 35, 36, 40, 63, 64, 65, 66, 67, 72, 75], "05": [32, 34, 35, 36, 41, 42, 43, 46, 51, 52, 53, 55, 63, 64, 65, 66, 67, 72, 75], "ruiz": [32, 39], "de": [32, 39, 73], "villa": [32, 39], "man": [32, 39], "public": [32, 39, 74], "2024": [32, 39, 70, 73], "doubleml": [33, 34, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 72, 73, 74], "r_double_ml_bas": 33, "due": [33, 40, 41, 42, 49, 56, 59, 64, 68, 74, 75], "larg": [33, 40, 49, 50], "introduct": [33, 34, 36, 40, 51, 53, 56, 63, 64, 68], "tabl": [33, 34, 35, 36, 58, 60, 63, 64, 65, 66, 67, 69, 72, 75], "ggplot2": [33, 34, 35], "lgr": [33, 34, 35, 36, 58, 63, 64, 65, 66, 67, 69, 72], "get_logg": [33, 34, 35, 36, 58, 63, 64, 65, 66, 67, 69, 72], "set_threshold": [33, 34, 35, 36, 58, 63, 64, 65, 66, 67, 69, 72], "repr": [33, 34], "width": [33, 34, 41, 42, 46], "height": [33, 34, 46], "align": [33, 34, 40, 43, 45, 50, 51, 52, 54, 55, 57, 74], "our": [33, 35, 36, 40, 41, 42, 43, 44, 50, 52, 53, 55, 56, 59, 70, 72, 74, 75], "size": [33, 34, 35, 36, 40, 43, 45, 46, 49, 50, 52, 54, 55, 58, 60, 63, 64, 65, 66, 67, 69, 72, 75], "compar": [33, 34, 40, 41, 42, 43, 45, 47, 48, 51, 55, 59, 63, 68], "n_var": [33, 36, 40, 59, 60, 63, 67, 69, 72], "i_rep": [33, 40, 44, 50, 57, 59], "seq_len": [33, 59], "naiv": [33, 40, 59], "direct": [33, 40, 45, 57, 59, 75], "applic": [33, 40, 44, 59, 62, 65, 73, 75], "invalid": [33, 40, 59], "introduc": [33, 40, 59, 60, 67, 69, 74, 75], "aris": [33, 34, 40, 51, 59, 75], "randomli": [33, 34, 40, 51, 59, 65, 75], "On": [33, 40, 59, 73], "auxiliari": [33, 40, 59], "hat": [33, 34, 40, 46, 49, 51, 58, 59, 62, 65, 66, 67, 68, 69], "_0": [33, 34, 40, 46, 51, 58, 59, 65, 66, 67, 68], "final": [33, 36, 40, 41, 42, 43, 45, 47, 48, 49, 53, 55, 57, 59, 64, 75], "half": [33, 40, 59, 65], "sum_": [33, 34, 40, 51, 58, 59, 62, 67, 69], "As": [33, 34, 35, 36, 40, 41, 42, 43, 44, 46, 49, 50, 51, 52, 53, 55, 57, 58, 63, 65, 66, 67, 68, 69, 75], "custom": [33, 40, 63], "14": [33, 34, 35, 36, 37, 41, 42, 43, 44, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 75], "non_orth_scor": [33, 40, 66], "u_hat": [33, 40, 66], "directli": [33, 35, 40, 50, 56, 59, 68, 72, 75], "procedur": [33, 34, 35, 40, 50, 51, 52, 56, 63, 67, 69, 74], "xgboost": [33, 35, 50, 52, 75], "nround": [33, 35, 75], "300": [33, 40, 43, 53, 55, 59, 73], "theta_nonorth": [33, 40], "rep": [33, 59, 63, 67, 69], "se_nonorth": [33, 40], "cat": [33, 74], "sprintf": 33, "sep": 33, "flush": 33, "consol": [33, 74], "double_ml_data_from_data_fram": [33, 59, 60, 75], "obj_dml_plr_nonorth": [33, 40], "apply_cross_fit": [33, 50, 65], "se": [33, 34, 40, 56, 59, 63, 65, 67, 68, 73, 75], "g_nonorth": 33, "ggplot": [33, 34, 35], "theta_resc": 33, "geom_histogram": 33, "ae": [33, 34, 35], "after_stat": 33, "colour": [33, 34], "bin": [33, 40, 71], "geom_vlin": 33, "xintercept": 33, "col": [33, 34, 52], "black": [33, 36, 37, 60, 72], "suppresswarn": 33, "geom_funct": 33, "fun": 33, "dnorm": 33, "scale_color_manu": 33, "break": 33, "dark": [33, 40], "blue": [33, 34, 51], "scale_fill_manu": [33, 34], "xlim": [33, 35], "xlab": [33, 34, 35], "ylab": [33, 34, 35], "theme_minim": [33, 35], "messag": [33, 34, 35, 36, 72, 74], "34": [33, 34, 35, 36, 41, 42, 51, 52, 53, 56, 57, 62, 63, 64, 65, 67, 75], "aesthet": 33, "row": [33, 35, 37, 41, 42, 45, 51, 54, 60, 65, 72, 75], "\u2139": 33, "annot": 33, "caus": [33, 40, 59], "slow": [33, 40, 59], "converg": [33, 40, 50, 51, 59], "rightarrow_": [33, 40, 59], "infti": [33, 40, 59], "slower": [33, 40, 59], "drive": [33, 40, 59], "factor": [33, 34, 35, 36, 40, 50, 59, 63, 75], "techniqu": [33, 40, 59, 65, 75], "heurist": [33, 40, 59], "illustr": [33, 34, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 59, 63, 75], "underbrac": [33, 40, 45, 59, 62], "_": [33, 34, 40, 41, 42, 43, 45, 46, 47, 48, 51, 52, 53, 54, 55, 58, 59, 62, 65, 66, 67, 68, 69], "approxim": [33, 40, 41, 42, 43, 50, 55, 59, 62, 67, 69, 74, 75], "under": [33, 35, 40, 44, 52, 54, 59, 64, 67, 73], "mild": [33, 40, 59], "howev": [33, 35, 40, 52, 57, 59, 75], "diverg": [33, 40, 59], "_i": [33, 40, 55, 57, 59], "distribut": [33, 40, 44, 50, 59, 64, 68, 71, 73, 74], "again": [33, 34, 35, 40, 44, 49, 51, 52, 56, 57, 59, 68], "extern": [33, 40, 61, 68, 74], "avoid": [33, 40, 65, 71, 74], "demonstr": [33, 34, 40, 51, 60, 67, 69, 70, 72], "purpos": [33, 40, 49, 56, 68, 72], "2222": [33, 34, 40, 64], "theta_orth_nosplit": [33, 40], "se_orth_nosplit": [33, 40], "obj_dml_plr_orth_nosplit": [33, 40], "g_nosplit": 33, "orang": 33, "927": 33, "finit": [33, 35], "outsid": 33, "scale": [33, 34, 43, 45, 55, 67, 68], "rang": [33, 40, 43, 44, 45, 47, 48, 50, 51, 53, 54, 55, 57, 59, 63], "stat_bin": 33, "whole": [33, 40, 44, 59, 63, 68], "anoth": [33, 34, 35, 40, 50, 51, 59, 63], "train": [33, 34, 36, 40, 41, 42, 43, 47, 48, 50, 51, 54, 55, 58, 59, 65], "exploit": [33, 40, 59, 75], "benefit": [33, 35, 40, 52, 59], "switch": [33, 40, 59], "entir": [33, 35, 40, 52, 59, 68], "17": [33, 34, 35, 36, 41, 42, 49, 51, 52, 53, 55, 56, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 75], "3333": [33, 34, 40, 62, 63, 64], "theta_dml": [33, 40, 59], "se_dml": [33, 40, 59], "obj_dml_plr": [33, 40, 59], "g_dml": 33, "green": [33, 41, 42, 43, 55], "step": [33, 35, 36, 40, 47, 48, 49, 52, 54, 59, 63, 67, 69, 70, 75], "write": [33, 40, 44, 57, 59, 68], "argu": [33, 35, 40, 52, 53, 56, 59, 75], "term": [33, 34, 35, 36, 40, 45, 46, 51, 52, 59, 70, 75], "ev": [33, 40, 59], "vanish": [33, 40, 59], "third": [33, 40, 51, 59, 65], "18": [33, 34, 35, 36, 37, 41, 42, 49, 51, 52, 53, 55, 56, 60, 62, 63, 64, 65, 67, 68, 69, 72, 75], "g_all": [33, 35], "t_nonorth": 33, "t_orth_nosplit": 33, "t_dml": 33, "print": [33, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75], "robinson": [33, 40, 59], "1988": [33, 40, 59], "ell": [33, 34, 40, 46, 51, 59, 66, 72], "minor": [33, 40, 59, 66, 74], "advantag": [33, 35, 40, 52, 53, 59, 71], "abov": [33, 35, 40, 41, 42, 47, 48, 50, 52, 54, 55, 59, 62, 63, 64, 71], "19": [33, 34, 35, 36, 41, 42, 50, 51, 52, 53, 55, 56, 62, 63, 64, 65, 67, 72, 75], "4444": [33, 34, 40, 64], "theta_orth_po_nosplit": [33, 40], "se_orth_po_nosplit": [33, 40], "g_nosplit_po": 33, "automat": [33, 40, 49, 59, 62, 68], "5555": [33, 40], "theta_dml_po": [33, 40, 59], "se_dml_po": [33, 40, 59], "g_dml_po": 33, "g_all_po": 33, "22": [33, 34, 35, 36, 41, 42, 51, 52, 55, 56, 62, 63, 64, 65, 67, 72, 75], "save": [33, 35, 40, 47, 48, 50, 52, 53, 63, 68, 75], "ggsave": 33, "filenam": 33, "r_non_orthogon": 33, "svg": [33, 40], "dpi": [33, 40], "unit": [33, 44, 45, 49, 57, 64, 66, 74], "r_dml_nosplit": 33, "r_dml": 33, "r_all": 33, "r_dml_po_nosplit": 33, "r_dml_po": 33, "r_po_al": 33, "r_double_ml_multiway_clust": 34, "exhibit": [34, 51], "usual": [34, 41, 42, 44, 50, 51, 56, 62, 63, 65, 68], "assumpt": [34, 35, 44, 45, 50, 51, 52, 57, 64, 67, 75], "anymor": [34, 51], "research": [34, 36, 51, 65, 70, 72, 73, 75], "shortli": [34, 36, 51, 63], "emphas": [34, 51], "been": [34, 35, 51, 52, 53, 56, 62, 63, 74], "within": [34, 47, 48, 51, 54], "region": [34, 43, 51, 67, 69, 73], "ii": [34, 51], "industri": [34, 51], "share": [34, 35, 51, 52], "subject": [34, 51], "shock": [34, 51], "cameron": [34, 51], "2011": [34, 51, 70, 72], "challeng": [34, 51, 68], "necessari": [34, 51], "formula": [34, 35, 51, 52, 74], "scheme": [34, 51, 63, 65, 70], "classic": [34, 51, 75], "suggest": [34, 35, 51, 52, 74], "wa": [34, 45, 51, 74], "emploi": [34, 46, 51, 66], "build": [34, 50, 51, 54], "eventu": [34, 51], "necess": [34, 51], "explan": [34, 44, 51, 56, 68, 70, 75], "achiev": [34, 51, 54, 67, 69], "multi": [34, 41, 42, 51], "develop": [34, 36, 51, 64, 74], "updat": [34, 51, 73, 74], "ensur": [34, 51, 54], "disjoint": [34, 47, 48, 51], "situat": [34, 51], "therebi": [34, 36, 51, 75], "do": [34, 35, 36, 50, 51, 52, 53, 62, 63, 68, 72, 75], "hdm": [34, 51], "surpress": [34, 72], "reshape2": 34, "gridextra": 34, "paket": [34, 35, 36], "wurd": [34, 35, 36], "unter": [34, 35, 36], "version": [34, 35, 36, 52, 58, 62, 67, 68, 69, 74], "erstellt": [34, 35, 36], "equat": [34, 35, 51, 52, 58, 67, 69, 75], "epsilon_": [34, 45, 51], "describ": [34, 51, 52, 53, 63, 65, 71, 74], "th": [34, 51], "special": [34, 51], "instanti": [34, 35, 51, 52, 63, 65], "subsequ": [34, 51], "x1": [34, 36, 44, 51, 56, 57, 60, 62, 63, 64, 66, 67, 68, 72], "x2": [34, 36, 44, 51, 56, 57, 60, 62, 63, 64, 66, 67, 72], "x3": [34, 36, 44, 51, 56, 57, 60, 62, 63, 64, 66, 67, 72], "x4": [34, 36, 44, 51, 56, 57, 60, 63, 64, 66, 67, 72], "x5": [34, 36, 51, 57, 60, 63, 64, 66, 67, 72], "x6": [34, 36, 51, 57, 60, 63, 64, 66, 67, 72], "x7": [34, 36, 51, 57, 60, 63, 64, 66, 67, 72], "x8": [34, 36, 51, 57, 60, 63, 64, 66, 67, 72], "x9": [34, 36, 51, 57, 60, 63, 64, 66, 67, 72], "x10": [34, 36, 51, 57, 60, 63, 64, 66, 67, 72], "x11": [34, 36, 51, 57, 60, 63, 64, 66, 67, 72], "x12": [34, 36, 51, 57, 60, 63, 64, 66, 67, 72], "x13": [34, 36, 51, 57, 60, 63, 64, 66, 67, 72], "x14": [34, 36, 51, 57, 60, 63, 64, 66, 67, 72], "x15": [34, 36, 51, 57, 60, 63, 64, 66, 67, 72], "x16": [34, 36, 51, 57, 60, 63, 64, 66, 67, 72], "x17": [34, 36, 51, 57, 60, 63, 64, 66, 67, 72], "x18": [34, 36, 51, 57, 60, 63, 64, 66, 67, 72], "x19": [34, 36, 51, 57, 60, 63, 64, 66, 67, 72], "x20": [34, 36, 51, 57, 60, 63, 64, 66, 67, 72], "x21": [34, 36, 51, 57, 60, 64, 72], "x22": [34, 36, 51, 57, 60, 64, 72], "x23": [34, 36, 51, 57, 60, 64, 72], "x24": [34, 36, 51, 57, 60, 64, 72], "x25": [34, 36, 51, 57, 60, 64, 72], "x26": [34, 36, 51, 57, 60, 64, 72], "x27": [34, 36, 51, 57, 60, 64, 72], "x28": [34, 36, 51, 57, 60, 64, 72], "x29": [34, 36, 51, 57, 60, 64, 72], "x30": [34, 36, 51, 57, 60, 64, 72], "x31": [34, 36, 51, 57, 60, 64, 72], "x32": [34, 36, 51, 57, 60, 64, 72], "x33": [34, 36, 51, 57, 60, 64, 72], "x34": [34, 36, 51, 57, 60, 64, 72], "x35": [34, 36, 51, 57, 60, 64, 72], "x36": [34, 36, 51, 57, 60, 64, 72], "x37": [34, 36, 51, 57, 60, 64, 72], "x38": [34, 36, 51, 57, 60, 64, 72], "x39": [34, 36, 51, 57, 60, 64, 72], "x40": [34, 36, 51, 57, 60, 64, 72], "x41": [34, 36, 51, 57, 60, 64, 72], "x42": [34, 36, 51, 57, 60, 64, 72], "x43": [34, 36, 51, 57, 60, 64, 72], "x44": [34, 36, 51, 57, 60, 64, 72], "x45": [34, 36, 51, 57, 60, 64, 72], "x46": [34, 36, 51, 57, 60, 64, 72], "x47": [34, 36, 51, 57, 60, 64, 72], "x48": [34, 36, 51, 57, 60, 64, 72], "x49": [34, 36, 51, 57, 60, 64, 72], "x50": [34, 36, 51, 57, 60, 64, 72], "x51": [34, 36, 51, 57, 60, 64, 72], "x52": [34, 36, 51, 57, 60, 64, 72], "x53": [34, 36, 51, 57, 60, 64, 72], "x54": [34, 36, 51, 57, 60, 64, 72], "x55": [34, 36, 51, 57, 60, 64, 72], "x56": [34, 36, 51, 57, 60, 64, 72], "x57": [34, 36, 51, 57, 60, 64, 72], "x58": [34, 36, 51, 57, 60, 64, 72], "x59": [34, 36, 51, 57, 60, 64, 72], "x60": [34, 36, 51, 57, 60, 64, 72], "x61": [34, 36, 51, 57, 60, 64, 72], "x62": [34, 36, 51, 57, 60, 64, 72], "x63": [34, 36, 51, 57, 60, 64, 72], "x64": [34, 36, 51, 57, 60, 64, 72], "x65": [34, 36, 51, 57, 60, 64, 72], "x66": [34, 36, 51, 57, 60, 64, 72], "x67": [34, 36, 51, 57, 60, 64, 72], "x68": [34, 36, 51, 57, 60, 64, 72], "x69": [34, 36, 51, 57, 60, 64, 72], "x70": [34, 36, 51, 57, 60, 64, 72], "x71": [34, 36, 51, 57, 60, 64, 72], "x72": [34, 36, 51, 57, 60, 64, 72], "x73": [34, 36, 51, 57, 60, 64, 72], "x74": [34, 36, 51, 57, 60, 64, 72], "x75": [34, 36, 51, 57, 60, 64, 72], "x76": [34, 36, 51, 57, 60, 64, 72], "x77": [34, 36, 51, 57, 60, 64, 72], "x78": [34, 36, 51, 57, 60, 64, 72], "x79": [34, 36, 51, 57, 60, 64, 72], "x80": [34, 36, 51, 57, 60, 64, 72], "x81": [34, 36, 51, 57, 60, 64, 72], "x82": [34, 36, 51, 57, 60, 64, 72], "x83": [34, 36, 51, 57, 60, 64, 72], "x84": [34, 36, 51, 57, 60, 64, 72], "x85": [34, 36, 51, 57, 60, 64, 72], "x86": [34, 36, 51, 57, 60, 64, 72], "x87": [34, 36, 51, 57, 60, 64, 72], "x88": [34, 36, 51, 57, 60, 64, 72], "x89": [34, 36, 51, 57, 60, 64, 72], "x90": [34, 36, 51, 57, 60, 64, 72], "x91": [34, 36, 51, 57, 60, 64, 72], "x92": [34, 36, 51, 57, 60, 64, 72], "x93": [34, 36, 51, 57, 60, 64, 72], "x94": [34, 36, 51, 57, 60, 64, 72], "x95": [34, 36, 51, 57, 60, 64, 72], "x96": [34, 36, 51, 57, 60, 64, 72], "x97": [34, 36, 51, 57, 60, 64, 72], "x98": [34, 36, 51, 57, 60, 64, 72], "x99": [34, 36, 51, 57, 60, 64, 72], "x100": [34, 36, 51, 57, 60, 64, 72], "625": [34, 51], "head": [34, 36, 37, 41, 42, 47, 48, 51, 52, 60, 62, 72], "x1x2x3x4x5x6x7x8x9x10": 34, "x96x97x98x99x100ydcluster_var_icluster_var_jz": 34, "dbl": [34, 35, 36, 60, 67, 69, 72, 75], "3707775": 34, "994168239": 34, "1045303": 34, "1145370": 34, "41341040": 34, "01925597": 34, "7776071": 34, "2467506": 34, "07456127": 34, "1795850": 34, "5763996": 34, "49530782": 34, "25401679": 34, "06895837": 34, "34967621": 34, "150408": 34, "9748910611": 34, "3522697": 34, "1577657": 34, "490070931": 34, "0702127": 34, "8932105": 34, "02163217": 34, "08968939": 34, "5025850": 34, "5436005": 34, "51966955": 34, "0118095": 34, "6243811": 34, "07168291": 34, "57715074": 34, "20823898": 34, "01403089": 34, "364595": 34, "5003517412": 34, "1626685": 34, "4416552": 34, "366718627": 34, "1557093": 34, "3702770": 34, "32458367": 34, "07347676": 34, "2619317": 34, "2836059": 34, "94906344": 34, "3304269": 34, "2080787": 34, "76591188": 34, "01351638": 34, "30672815": 34, "22336235": 34, "010450": 34, "4211349413": 34, "2020435": 34, "1144500": 34, "009645422": 34, "2103034": 34, "7560824": 34, "02247976": 34, "13505272": 34, "3800694": 34, "3727679": 34, "42412729": 34, "8055563": 34, "9304028": 34, "20783816": 34, "39425708": 34, "91315015": 34, "67245350": 34, "342675": 34, "6745349414": 34, "8132463": 34, "5050973": 34, "523977545": 34, "4584447": 34, "0853505": 34, "92369755": 34, "21624417": 34, "9961392": 34, "2191274": 34, "67410934": 34, "3788859": 34, "0695854": 34, "22505965": 34, "42073312": 34, "22375856": 34, "50672034": 34, "140861": 34, "5699994715": 34, "1213405": 34, "1468115": 34, "175635027": 34, "0466028": 34, "4199952": 34, "19033538": 34, "88173062": 34, "5868472": 34, "2670691": 34, "57496671": 34, "9802393": 34, "3738573": 34, "20219609": 34, "52424539": 34, "12707800": 34, "01398951": 34, "363276": 34, "0835771416": 34, "7241399": 34, "l": [34, 36, 37, 41, 42, 51, 57, 63, 68, 70, 72], "cv_glmnet": [34, 35, 36, 63, 67, 69, 72], "nfold": [34, 35], "lambda": [34, 35, 36, 52, 54, 63, 66, 67, 69, 72], "min": [34, 35, 36, 43, 51, 52, 53, 55, 58, 63, 64, 65, 66, 67, 69, 72, 75], "yet": [34, 38], "i_1": [34, 51], "i_k": [34, 51, 58, 65, 67, 69], "j_1": [34, 51], "j_k": [34, 51], "basic": [34, 35, 44, 51, 52, 53, 56, 61, 63], "setminu": [34, 51, 67, 69], "j_": [34, 51], "neyman": [34, 51, 58, 61, 68, 70, 73], "cardin": [34, 51], "visual": [34, 49, 51], "heat": [34, 51], "horizont": [34, 45, 51], "axi": [34, 35, 46, 50, 51, 52, 54], "vertic": [34, 51], "field": [34, 51, 63, 75], "red": [34, 47, 48, 51], "white": [34, 47, 48, 51], "displai": [34, 51, 62, 68], "veri": [34, 36, 49, 50, 51, 66, 70], "bottom": [34, 35, 50, 51, 52, 53], "fourth": [34, 51], "fifth": 34, "nine": [34, 51], "three": [34, 36, 47, 48, 71, 74], "six": 34, "seven": [34, 51], "eight": [34, 51], "plt_smpl": [34, 51], "becom": [34, 51, 62, 65], "clear": [34, 51], "identifi": [34, 35, 44, 49, 51, 52, 53, 62, 64, 68, 74], "partion": [34, 51], "i_2": [34, 51], "i_3": [34, 51], "j_2": [34, 51], "j_3": [34, 51], "By": [34, 51, 63, 68], "everi": [34, 51], "combin": [34, 36, 44, 50, 51, 63, 65, 68, 74], "leq": [34, 51], "now": [34, 35, 41, 42, 50, 51, 52, 54, 57, 72, 74], "focu": [34, 35, 51, 52, 53, 62, 64, 75], "top": [34, 50, 51, 52, 53, 70], "sub": [34, 51], "guarante": [34, 51], "plt_smpls_cluster": [34, 51], "smpls_cluster": [34, 51], "arrang": 34, "grob": 34, "ncol": [34, 35, 36, 60, 63, 67, 69, 72], "nrow": [34, 36, 60, 63, 67, 69, 72], "It": [34, 35, 41, 42, 46, 47, 48, 51, 52, 53, 63, 65, 70, 74], "notat": [34, 44, 51, 57, 64], "wedg": [34, 51], "underlin": [34, 51], "bigg": [34, 51, 66, 68], "pm": [34, 51, 67, 68, 69], "phi": [34, 51, 62, 67], "8909": [34, 52, 75], "1258": 34, "084": 34, "4e": [34, 35], "prepar": [34, 51, 74], "alter": [34, 51], "omega_epsilon": [34, 51], "92905": 34, "04465": 34, "81": [34, 46, 49, 62, 63, 64, 65, 74], "revist": [34, 51], "consum": [34, 51], "demand": [34, 51, 68], "automobil": [34, 51], "berri": [34, 51], "levinsohn": [34, 51], "pake": [34, 51], "1995": [34, 51], "blp_data": [34, 51], "price": [34, 51], "761": [34, 51], "log_p": [34, 51], "log": [34, 46, 51], "hpwt": [34, 51], "air": [34, 51], "mpd": [34, 51], "space": [34, 51, 63], "hpwtairmpdspac": 34, "528996901": 34, "8881461": 34, "1502": 34, "494324401": 34, "9359891": 34, "2780": 34, "467613401": 34, "7167991": 34, "4592": 34, "40": [34, 41, 42, 43, 44, 48, 52, 53, 55, 57, 60, 62, 63, 64, 65, 67, 68, 75], "426540301": 34, "6878711": 34, "6068": 34, "452488701": 34, "5042861": 34, "6458": 34, "60": [34, 43, 44, 53, 55, 57, 62, 63, 64, 65, 67, 73], "450870601": 34, "7268131": 34, "6224": 34, "iv_var": [34, 51], "constructiv": 34, "firm": [34, 51, 56], "id": [34, 36, 51], "cdid": [34, 51], "paste0": 34, "data_transf": [34, 51, 52], "all_z_col": [34, 51], "sum": [34, 35, 51, 52, 53, 55, 62, 67, 69], "dml_df": [34, 51], "cbind": 34, "dml_data": [34, 37, 44, 45, 49, 50, 51, 56, 57, 62, 63, 64, 67, 69, 75], "2217": [34, 51], "lasso": [34, 35, 36, 52, 57, 63, 72, 73], "24": [34, 35, 36, 41, 42, 48, 51, 52, 53, 55, 56, 57, 62, 63, 64, 65, 67, 72, 73, 74, 75], "coef_df": 34, "na_real_": [34, 74], "colnam": [34, 50], "rownam": 34, "se_df": 34, "dml_pliv": [34, 51], "26": [34, 35, 36, 37, 41, 42, 44, 51, 52, 53, 57, 60, 62, 63, 64, 65, 67, 72], "28": [34, 35, 36, 41, 42, 46, 49, 51, 52, 57, 62, 63, 64, 65, 67, 72, 74], "31": [34, 35, 36, 41, 42, 51, 52, 53, 57, 62, 63, 64, 65, 67, 72, 75], "wayon": 34, "producton": 34, "markettwo": 34, "956047": 34, "747945": 34, "569911": 34, "257207": 34, "32": [34, 35, 36, 41, 42, 51, 52, 53, 57, 62, 63, 64, 65, 66, 67, 72], "hpwt0": 34, "51079110": 34, "97314470": 34, "7158581": 34, "48404": 34, "equilibrium": [34, 51], "societi": [34, 51, 73], "63": [34, 51, 62, 63, 64, 65, 67, 73, 74], "841": [34, 51], "890": [34, 51], "2307": [34, 51, 59], "2171802": [34, 51], "gelbach": [34, 51], "miller": [34, 51], "238": [34, 51, 74], "249": [34, 51], "1198": [34, 51], "jbe": [34, 51], "2010": [34, 51], "07136": [34, 51], "33": [34, 35, 36, 41, 42, 47, 51, 52, 53, 57, 62, 63, 64, 65, 67, 72, 73], "rcolorbrew": 34, "coul": 34, "rev": 34, "colorramppalett": 34, "brewer": 34, "pal": 34, "rdbu": 34, "i_fold": 34, "train_id": [34, 65], "test_id": [34, 65], "rowv": 34, "colv": 34, "cexrow": 34, "cexcol": 34, "n_folds_per_clust": [34, 51], "mat": 34, "df_plot": 34, "melt": 34, "geom_til": 34, "grey50": 34, "darkblu": 34, "darkr": 34, "theme": [34, 35], "element_text": [34, 35], "todo": [34, 37], "add": [34, 37, 44, 45, 47, 48, 49, 55, 56, 57, 63, 73, 74], "subplot": [34, 40, 41, 42, 43, 45, 47, 48, 50, 51, 52, 53, 55], "titl": [34, 35, 41, 42, 43, 46, 47, 48, 50, 51, 52, 53, 55, 70], "express": [34, 46, 68], "past": 34, "r_double_ml_pens": 35, "real": [35, 52, 53, 56, 68], "accumul": [35, 52, 53, 56], "among": [35, 46, 52, 53, 56], "pension": [35, 52, 53, 75], "sponsor": [35, 52, 53], "employ": [35, 52, 53], "problem": [35, 52, 53, 62, 63], "saver": [35, 52, 53], "coupl": [35, 52, 53], "fact": [35, 52, 53], "enrol": [35, 52, 53], "recogn": [35, 52, 53], "peopl": [35, 52, 53], "higher": [35, 46, 52, 53, 74, 75], "prefer": [35, 52, 53, 75], "seem": [35, 49, 52, 53, 75], "those": [35, 52, 53], "would": [35, 36, 41, 42, 46, 50, 52, 53, 56, 62, 63, 68, 75], "most": [35, 43, 50, 52, 53, 55, 62, 63, 68, 71], "tax": [35, 52, 53], "retir": [35, 52, 53, 56], "tend": [35, 52, 53], "amount": [35, 52, 53, 75], "presenc": [35, 52, 53], "convent": [35, 52, 53], "endogen": [35, 52, 53, 75], "upward": [35, 52, 53], "overst": [35, 52, 53], "One": [35, 52, 53, 62, 67], "taken": [35, 52, 53, 75], "exogen": [35, 52, 53, 75], "after": [35, 36, 44, 46, 52, 53, 57, 62, 63, 68, 71, 75], "few": [35, 52, 53], "incom": [35, 52, 53, 54, 56, 75], "idea": [35, 36, 52, 53, 63, 68, 75], "around": [35, 52, 53, 66], "becam": [35, 52, 53], "were": [35, 52, 53, 57, 75], "unlik": [35, 52, 53], "offer": [35, 52, 53, 75], "aspect": [35, 52, 53], "job": [35, 52, 53], "preprocess": [35, 51, 52, 53, 63], "fetch": [35, 51, 52, 53, 60], "fetch_401k": [35, 52, 53, 56, 75], "internet": [35, 52, 53], "connect": [35, 52, 53], "start": [35, 36, 41, 42, 46, 49, 50, 51, 52, 55, 64, 70, 75], "baselin": [35, 52], "reload": 35, "later": [35, 36, 63, 75], "tutori": 35, "suppress": [35, 36], "dim": 35, "991512": 35, "9915": [35, 52, 53, 56], "ob": [35, 45], "net_tfa": [35, 52, 53, 56, 75], "num": [35, 36, 58, 63, 64, 65, 66, 67, 72], "1015": [35, 52], "15000": [35, 52], "ag": [35, 52, 53, 54, 56, 75], "36": [35, 36, 41, 42, 51, 52, 62, 63, 64, 65, 67], "37": [35, 41, 42, 51, 52, 53, 62, 63, 64, 65, 67], "58": [35, 52, 62, 63, 64, 65, 67, 74, 75], "54": [35, 36, 44, 59, 62, 63, 64, 65, 67, 74], "43": [35, 41, 42, 62, 63, 64, 65, 67], "inc": [35, 52, 53, 56, 75], "6765": [35, 52], "28452": [35, 52], "3300": [35, 52], "52590": [35, 52], "21804": [35, 52], "educ": [35, 52, 53, 56, 75], "fsize": [35, 52, 53, 56, 75], "marr": [35, 52, 53, 56, 75], "twoearn": [35, 52, 53, 56, 75], "db": [35, 52, 53, 56, 75], "pira": [35, 52, 53, 56, 75], "hown": [35, 52, 53, 56, 75], "p401": [35, 52, 53], "e401": [35, 52, 53, 56, 75], "attr": 35, "intern": [35, 36, 53, 63, 73], "selfref": 35, "externalptr": 35, "descript": [35, 37, 56, 63, 65, 68], "help": [35, 43, 50, 53, 54, 65, 75], "915": [35, 36, 52, 53], "household": [35, 52, 53, 56], "1991": [35, 52, 53, 75], "survei": [35, 52, 53, 75], "sipp": [35, 52, 53], "1990": [35, 52, 53, 64], "ira": [35, 52, 53], "balanc": [35, 52, 53], "bond": [35, 52, 53], "earn": [35, 52, 53], "stock": [35, 52, 53], "fund": [35, 52, 53, 70], "less": [35, 52, 53], "mortgag": [35, 52, 53], "debt": [35, 52, 53], "3682": [35, 52, 53], "hist_e401": 35, "geom_bar": 35, "ggtitl": 35, "legend": [35, 40, 41, 42, 43, 45, 47, 48, 50, 53, 55], "hjust": 35, "hist_p401": 35, "highli": [35, 52, 70], "associ": [35, 46, 52, 64, 67, 69, 73], "dens_net_tfa": 35, "color": [35, 40, 41, 42, 43, 45, 51, 52, 53, 55], "geom_dens": 35, "20000": [35, 52], "150000": 35, "facet_wrap": 35, "remov": [35, 52, 61, 65, 74], "340": [35, 53], "stat_dens": 35, "uncondit": [35, 52, 75], "ap": [35, 52], "wai": [35, 50, 52, 63, 66, 71], "about": [35, 50, 52, 70, 72, 75], "19559": [35, 52], "ape_e401_uncond": 35, "round": [35, 50], "2594": [35, 52], "decid": [35, 52], "27372": [35, 52], "ape_p401_uncond": 35, "27371": [35, 52], "thei": [35, 45, 47, 48, 52, 68], "look": [35, 36, 43, 44, 45, 50, 52, 53, 55, 56], "total": [35, 52], "give": [35, 52], "f": [35, 36, 40, 43, 44, 45, 46, 50, 51, 52, 53, 54, 55, 56, 57, 63, 68, 70, 72], "epsilon": [35, 43, 44, 45, 52, 55, 62, 64], "dictonari": [35, 52], "raw": [35, 46, 52], "marit": [35, 52], "statu": [35, 44, 52, 57], "earner": [35, 52, 56], "home": [35, 52], "ownership": [35, 52], "famili": [35, 52, 63], "degre": [35, 41, 42, 51, 52, 62, 68], "whenev": [35, 52], "There": [35, 52, 71, 75], "cours": [35, 50, 52, 67, 75], "even": [35, 36, 52, 63, 75], "flexibli": [35, 52, 56], "sake": [35, 52, 75], "simplic": [35, 50, 52, 54], "stick": [35, 52], "who": [35, 52], "vari": [35, 45, 50, 52], "manipul": [35, 36], "formula_flex": 35, "orign": [35, 52], "report": [35, 52, 70, 74], "instanc": [35, 36, 52, 63], "manual": [35, 56, 75], "interfac": [35, 36, 60, 63, 65, 72], "shortcut": 35, "data_dml_bas": [35, 41, 42, 47, 48, 52, 53, 54], "data_dml_flex": [35, 52], "features_bas": [35, 52, 53, 56], "poli": [35, 51, 52], "features_flex": 35, "model_data": [35, 52], "eqnarrai": 35, "mid": [35, 52], "compon": [35, 46, 50, 52, 54, 62, 63, 65, 66, 74], "penalti": [35, 36, 39, 52, 57, 63, 64], "glmnet": [35, 36, 63, 74], "underli": [35, 36, 47, 48, 54, 68, 75], "instal": [35, 74], "moreov": [35, 36, 46, 63, 67, 69, 75], "123": [35, 36, 52, 62, 74, 75], "lasso_class": [35, 52], "dml_plr_lasso": [35, 37, 52], "6133": 35, "1465": 35, "185": [35, 36], "85e": 35, "9580": 35, "1325": 35, "229": [35, 74], "87e": 35, "altern": [35, 36, 52, 54, 61, 63, 67, 69, 70, 71, 72], "ranger": [35, 36, 58, 63, 64, 65, 66, 67, 72, 75], "websit": [35, 36, 63, 70], "mlr3extralearn": [35, 63], "searchabl": 35, "mlr3vers": 35, "randomforest": [35, 50, 52], "max": [35, 36, 52, 53, 58, 62, 63, 64, 65, 66, 67, 72, 75], "mtry": [35, 36, 58, 63, 64, 65, 66, 67, 75], "node": [35, 36, 58, 64, 65, 66, 67, 72, 75], "randomforest_class": [35, 41, 52, 54], "dml_plr_forest": [35, 52, 75], "9127": [35, 75], "1313": [35, 75], "952": [35, 75], "61e": [35, 75], "rpart": [35, 36, 63], "cp": [35, 36, 63], "0047": [35, 52], "minsplit": 35, "203": [35, 52], "trees_class": [35, 52], "0042": [35, 52], "104": [35, 52, 57, 62, 74], "dml_plr_tree": [35, 52, 75], "8210": 35, "1324": [35, 52], "55e": 35, "extrem": [35, 52], "gradient": [35, 52], "squarederror": [35, 52, 75], "35": [35, 36, 41, 42, 43, 51, 52, 53, 55, 62, 63, 64, 65, 67, 68, 75], "boost_class": [35, 52], "eval_metr": [35, 52, 75], "logloss": [35, 52, 75], "dml_plr_boost": [35, 52], "8700": 35, "1360": 35, "399": 35, "57e": 35, "rbind": 35, "result_plr": 35, "lower": [35, 36, 43, 45, 46, 49, 53, 55, 56, 63, 68, 75], "upper": [35, 36, 40, 43, 45, 49, 53, 55, 56, 63, 68, 75], "modelmlestimatelowerupp": 35, "chr": 35, "plrglmnet": 35, "9579": 35, "7716982": 35, "44312177": 35, "plrranger": 35, "9126": [35, 75], "9996553": 35, "68411700": [35, 75], "plrrpart": 35, "8209": 35, "7375615": 35, "52510803": 35, "plrxgboost8700": 35, "1346035": 35, "28111364": 35, "99": [35, 41, 42, 62, 64, 65, 74], "g_ci": 35, "geom_point": 35, "geom_errorbar": 35, "ymin": 35, "ymax": 35, "geom_hlin": 35, "yintercept": 35, "grei": 35, "angl": 35, "next": [35, 36, 41, 42, 43, 49, 50, 52, 53, 54, 55, 74], "reduc": [35, 49, 52, 56, 74], "disproportion": [35, 52], "close": [35, 52, 68], "dml_irm_lasso": [35, 37, 52], "8850": 35, "1341": 35, "601": 35, "08e": 35, "dml_irm_forest": [35, 52], "8202": 35, "1118": 35, "334": 35, "23e": 35, "dml_irm_tre": [35, 52], "0016": [35, 52], "74": [35, 52, 62, 63, 64, 65, 67, 74], "0018": [35, 52], "70": [35, 43, 47, 52, 53, 55, 62, 63, 64, 65, 67, 74], "0028": [35, 52], "167": [35, 52, 74], "8415": 35, "1186": 35, "098": 35, "26e": 35, "dml_irm_boost": [35, 52], "comparevers": 35, "charact": [35, 36, 63, 74], "packagevers": 35, "behavior": [35, 63], "github": [35, 46, 52, 70, 73, 74], "pull": [35, 74], "89": [35, 42, 62, 64, 65, 73, 74], "verbos": [35, 45], "8048": 35, "1182": 35, "808": [35, 67, 69], "91e": 35, "result_irm": 35, "irmglmnet": 35, "0646222": 35, "39611477": 35, "73": [35, 62, 63, 64, 65, 67], "irmrang": 35, "1016010": 35, "24510393": 35, "96": [35, 41, 42, 49, 62, 64, 65, 74], "irmrpart": 35, "2766091": 35, "61810738": 35, "93": [35, 62, 63, 64, 65, 74], "irmxgboost8047": 35, "5985730": 35, "68410364": 35, "51": [35, 36, 47, 62, 63, 64, 65, 67, 74], "These": [35, 36, 38, 52, 54, 56, 62, 75], "substanti": [35, 52], "attenu": [35, 52], "rel": [35, 52, 68], "much": [35, 36, 52, 75], "smaller": [35, 44, 47, 48, 49, 52, 75], "eligibl": [35, 52, 56], "appropri": [35, 46, 52, 65, 75], "complier": [35, 52, 53, 55, 62], "befor": [35, 45, 49, 52, 55, 64, 75], "data_dml_base_iv": [35, 52, 53], "data_dml_flex_iv": 35, "dml_iivm_lasso": [35, 52], "12802": 35, "1941": 35, "597": 35, "dml_iivm_forest": [35, 52], "ml_r1": [35, 52, 64], "11792": 35, "1604": 35, "352": [35, 51], "95e": 35, "dml_iivm_tre": [35, 52], "0576": [35, 52], "55": [35, 36, 43, 48, 52, 53, 55, 62, 63, 64, 65, 67], "12214": 35, "1714": 35, "128": [35, 62, 74], "02e": 35, "dml_iivm_boost": [35, 52], "11861": 35, "1619": 35, "324": [35, 53], "result_iivm": 35, "iivmglmnet": 35, "268998": 35, "63916605": 35, "88": [35, 49, 62, 64, 65], "iivmrang": 35, "228648": 35, "57914935": 35, "87": [35, 48, 49, 51, 62, 63, 64, 65, 74], "iivmrpart": 35, "458855": 35, "86415573": 35, "iivmxgboost11861": 35, "198687": 35, "15815035": 35, "merg": [35, 52], "far": [35, 52], "them": [35, 36, 41, 42, 43, 49, 52, 55], "summary_result": 35, "rbindlist": 35, "four": [35, 50, 52, 74], "find": [35, 45, 52, 62, 63, 75], "across": [35, 52, 75], "henc": [35, 36, 52, 63, 66, 75], "reject": [35, 52], "acknowledg": [35, 36, 52], "thank": [35, 36, 52], "janni": [35, 52], "kueck": [35, 52], "kaggl": [35, 52], "r_double_ml_pipelin": 36, "power": [36, 63, 73], "tool": [36, 56, 75], "binder": [36, 63, 70, 72], "engin": [36, 73], "stack": [36, 63], "subsampl": [36, 50], "pipelin": [36, 52, 74], "incorpor": [36, 56, 68], "oper": 36, "easili": [36, 50, 53, 74], "mlr3book": [36, 63], "becker": [36, 63], "intend": [36, 75], "major": [36, 74], "ones": [36, 43, 45, 55, 56, 62], "claim": 36, "dml_data_sim": [36, 72], "double_ml_data_from_matrix": [36, 60, 63, 67, 69, 72], "df_bonu": [36, 60, 72], "fetch_bonu": [36, 37, 60, 72], "x_var": 36, "femal": [36, 37, 60, 72], "othrac": [36, 37, 60, 72], "dep1": [36, 37, 60, 72], "dep2": [36, 37, 60, 72], "q2": [36, 37, 60, 72], "q3": [36, 37, 60, 72], "q4": [36, 37, 60, 72], "q5": [36, 37, 60, 72], "q6": [36, 37, 60, 72], "agelt35": [36, 37, 60, 72], "agegt54": [36, 37, 60, 72], "durabl": [36, 37, 60, 72], "lusd": [36, 37, 60, 72], "husd": [36, 37, 60, 72], "dml_data_bonu": [36, 72], "inuidur1": [36, 37, 60, 72], "tg": [36, 37, 60, 72], "inuidur1femaleblackothracedep1dep2q2q3q4q5q6agelt35agegt54durablelusdhusdtg": [36, 60, 72], "8903720000100010000010": [36, 60, 72], "0000000000000010000100": [36, 60, 72], "2958370000000100000100": [36, 60, 72], "1972250000001000100001": [36, 60, 72], "2958370001000010011100": [36, 60, 72], "2958371000000010010100": [36, 60, 72], "5099": [36, 37, 60, 72], "learnerregr": 36, "learnerclassif": 36, "think": 36, "lang": [36, 63, 70, 72], "sonabend": [36, 63], "schratz": [36, 63, 70, 72], "learner_lasso": 36, "ml_l_lasso": 36, "ml_m_lasso": 36, "learnerregrcvglmnet": 36, "r6": [36, 74], "learner_forest_regr": 36, "floor": 36, "learner_forest_classif": 36, "ml_l_forest": 36, "ml_m_forest": 36, "learnerregrrang": [36, 63], "obj_dml_plr_sim": [36, 72], "01219": 36, "04415": [36, 63], "68": [36, 56, 62, 63, 64, 65, 67], "obj_dml_plr_bonu": [36, 72], "0765": 36, "0354": 36, "161": [36, 48, 73, 74], "0307": 36, "ll": [36, 67, 69, 75], "pipeop": 36, "constructor": 36, "po": [36, 63], "pipe_lasso": 36, "ml_l_lasso_pip": 36, "as_learn": [36, 63], "ml_m_lasso_pip": 36, "graphlearn": [36, 63], "pipe_forest_regr": 36, "pipe_forest_classif": 36, "ml_l_forest_pip": 36, "ml_m_forest_pip": 36, "obj_dml_plr_sim_pip": 36, "obj_dml_plr_bonus_pip": 36, "complic": [36, 75], "branch": 36, "pipe": 36, "graph_ensemble_regr": 36, "gunion": [36, 63], "regravg": [36, 63], "graph": [36, 57, 75], "graph_ensemble_classif": 36, "classifavg": 36, "ensemble_pipe_regr": 36, "ensemble_pipe_classif": 36, "obj_dml_plr_sim_pipe_ensembl": 36, "88664": 36, "02584": 36, "obj_dml_plr_bonus_pipe_ensembl": 36, "07689": 36, "03545": 36, "169": [36, 74], "0301": 36, "simpli": [36, 44, 75], "lrn_0": 36, "learner_cv": 36, "rpart_cv": 36, "origin": [36, 54, 56, 62], "level_0": [36, 51], "nop": 36, "featureunion": 36, "html": [36, 70, 72, 74], "stacklrn": 36, "07915": 36, "03538": 36, "237": 36, "0253": 36, "just": [36, 43, 44, 45, 47, 48, 49, 54, 55, 66, 68], "mutat": 36, "filter": 36, "mlr3filter": 36, "flt": 36, "param_v": 36, "collect": [36, 44, 51, 57], "glrn": 36, "delete_origin": 36, "xval": [36, 63], "prob": 36, "posixct": [36, 63], "featureless": [36, 63], "hotstart_backward": [36, 63], "hotstart_forward": [36, 63], "loglik": [36, 63], "multiclass": 36, "oob_error": [36, 63], "selected_featur": [36, 63], "twoclass": 36, "obj_dml_plr_bonus_pipe2": 36, "07366": [36, 63], "03539": 36, "081": 36, "0374": 36, "param_set": [36, 63], "obj_dml_plr_bonus_pipe3": 36, "lasso_pip": [36, 63], "glrn_lasso": 36, "fraction": 36, "paradox": [36, 63], "par_grid": [36, 63], "p_dbl": [36, 63], "mlr3tune": [36, 63, 74], "tune_set": [36, 63], "termin": [36, 63], "trm": [36, 63], "eval": [36, 63], "n_eval": [36, 63], "tnr": [36, 63], "resolut": [36, 63], "rsmp_tune": [36, 63], "rsmp": [36, 63, 65], "cv": [36, 52, 63, 65], "measur": [36, 46, 56, 63, 64, 68], "msr": [36, 63], "mse": [36, 46, 63], "execut": [36, 75], "obj_dml_plr_sim_pipe_tun": 36, "57": [36, 62, 63, 64, 65, 67, 75], "48": [36, 41, 42, 52, 53, 62, 63, 64, 65, 67], "469": 36, "bbotk": [36, 63, 74], "tunergridsearch": 36, "terminatorev": 36, "485": [36, 53], "configur": 36, "49": [36, 41, 42, 62, 63, 64, 65, 67], "133": [36, 60, 62, 73, 74], "batch": 36, "135": [36, 62, 74], "07222222": 36, "6666667": 36, "107": [36, 62, 74], "2925": 36, "runtime_learn": 36, "uhash": 36, "38": [36, 41, 42, 52, 62, 63, 64, 65, 67], "5574dcd4": 36, "fc9e": 36, "463b": 36, "9345": 36, "d21ee5775b5f": 36, "137": [36, 37, 62, 74], "516": 36, "106": [36, 62, 74], "2652": [36, 52, 53], "8497f641": 36, "2700": 36, "4a53": 36, "ae89": 36, "5cb31a99b9cc": 36, "517": [36, 51], "892": 36, "893": 36, "4166667": 36, "482": 36, "9753": 36, "f3d24993": 36, "a09b": 36, "432f": 36, "ab71": 36, "44fa97767be8": 36, "894": 36, "273": 36, "274": [36, 53], "09444444": 36, "112": [36, 62, 74], "1054": 36, "bb2913dc": 36, "3cd0": 36, "4b8f": 36, "a09a": 36, "303f00f0bd62": 36, "276": 36, "657": 36, "659": 36, "08333333": 36, "9166667": 36, "81856": 36, "8da924c": 36, "f2e7": 36, "4dd2": 36, "a840": 36, "b5d34a6f42b": 36, "660": 36, "051": 36, "08888889": 36, "74189": 36, "0434e374": 36, "ddc9": 36, "468d": 36, "b208": 36, "dc13a11076b3": 36, "054": 36, "433": 36, "435": 36, "07777778": [36, 63], "5833333": 36, "201": [36, 53, 74], "8513": 36, "280454dd": 36, "5804": 36, "498f": 36, "80a8": 36, "24080030a4d": 36, "436": [36, 53], "868": 36, "869": 36, "3333333": 36, "531": 36, "5255": 36, "7b428990": 36, "305b": 36, "47be": 36, "bde4": 36, "7215093d9089": 36, "52": [36, 49, 62, 63, 64, 65, 67], "316": 36, "318": 36, "06111111": 36, "17823": 36, "bd929a9e": 36, "3e1c": 36, "4fee": 36, "ae56": 36, "f00584a57972": 36, "319": 36, "773": 36, "775": [36, 53], "538": 36, "991": 36, "e20ea26": 36, "a6ba": 36, "4539": 36, "a3d9": 36, "0005a80b528f": 36, "780": 36, "finish": 36, "782": 36, "learner_param_v": 36, "x_domain": 36, "53": [36, 60, 62, 63, 64, 65, 67, 70, 73], "299": 36, "6173": 36, "67ad635a": 36, "5346": 36, "41e5": 36, "b5d7": 36, "a79359d2da46": 36, "301": 36, "723": 36, "725": 36, "5155": 36, "921e4f0d": 36, "e57c": 36, "4552": 36, "a5e6": 36, "8bdee1a1d83d": 36, "130": [36, 47, 51, 62, 74], "132": [36, 51, 62, 74], "9870004": 36, "26bd56a6": 36, "fd8a": 36, "4dba": 36, "9109": 36, "0ff823b17d45": 36, "574": 36, "576": 36, "75887": 36, "fb5c25fa": 36, "1596": 36, "49d4": 36, "b371": 36, "d0cdb0ea4795": 36, "577": 36, "017": 36, "6722": 36, "ee97bda7": 36, "6cea": 36, "440a": 36, "9248": 36, "d5a0c70f1d98": 36, "018": 36, "452": 36, "453": 36, "78818": 36, "8e3aa840": 36, "c895": 36, "472e": 36, "85c5": 36, "681817dcfcda": 36, "455": 36, "913": 36, "69921": 36, "4552b8af": 36, "3647": 36, "43f0": 36, "a5e7": 36, "55dc37e31fb1": 36, "917": 36, "56": [36, 59, 62, 63, 64, 65, 67, 70, 73, 75], "386": [36, 53], "387": 36, "9880384": 36, "abb0fd28": 36, "0359": 36, "4ecd": 36, "8644": 36, "f1718fdeb9b0": 36, "389": 36, "783": 36, "785": 36, "43294": 36, "cda85647": 36, "3ec2": 36, "4849": 36, "88ad": 36, "193f0d909729": 36, "786": 36, "183": [36, 74], "31378": 36, "caac5a95": 36, "4462": 36, "42ba": 36, "99c8": 36, "ca1af7be64b2": 36, "189": 36, "190": [36, 74], "191": [36, 50, 73, 74], "00133": 36, "04424": 36, "84": [36, 62, 63, 64, 65, 74], "bischl": [36, 63, 70, 72], "pfister": [36, 63, 70, 72], "reich": [36, 63], "richter": [36, 63, 70, 72], "book": [36, 63], "mlr": [36, 63], "schneider": 36, "kotthof": 36, "184": [36, 73], "jmlr": [36, 70, 72, 74], "v22": 36, "0281": 36, "coor": [36, 63, 70, 72], "au": [36, 63, 70, 72], "q": [36, 43, 55, 63, 70, 72], "casalicchio": [36, 63, 70, 72], "kotthoff": [36, 63, 70, 72], "modern": [36, 63, 70, 72], "orient": [36, 63, 66, 70, 72, 73, 74], "lear": [36, 63, 70, 72], "open": [36, 63, 70, 72], "sourc": [36, 63, 72, 74], "softwar": [36, 63, 70, 72, 73, 74], "21105": [36, 63, 70, 72], "joss": [36, 63, 70, 72], "01903": [36, 63, 70, 72], "recommend": [36, 50, 58, 65, 71, 73, 74], "cran": [36, 73, 74], "project": [36, 41, 42, 62, 70, 74], "extralearn": 36, "extra": 36, "easi": [36, 66], "double_ml_bonus_data": 37, "matplotlib": [37, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 55, 57], "inlin": 37, "linear_model": [37, 39, 46, 50, 51, 52, 57, 63, 64, 67, 69, 72], "pyplot": [37, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 55, 57], "plt": [37, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 55, 57], "seaborn": [37, 40, 44, 50, 51, 52, 53, 57], "sn": [37, 40, 44, 50, 51, 52, 53, 57], "rcparam": [37, 41, 42, 43, 45, 47, 48, 51, 52, 53, 55], "figsiz": [37, 41, 42, 43, 45, 47, 48, 50, 51, 52, 53, 55], "abdt": [37, 60, 72], "inuidur2": [37, 60, 72], "hispan": 37, "dep": 37, "recal": [37, 68], "nondur": 37, "muld": [37, 60, 72], "10824": [37, 60, 72], "890372": [37, 60, 72], "000000": [37, 52, 53, 60, 62, 72], "10747": [37, 60, 72], "295837": [37, 60, 72], "10607": [37, 60, 72], "197225": [37, 60, 72], "10831": [37, 60, 72], "dml_plr_rf": 37, "dml_procedur": [37, 58, 72, 74, 75], "par": 37, "079085": 37, "035391": 37, "234605": 37, "025443": 37, "14845": 37, "00972": 37, "dml_data_lasso": 37, "core": [37, 43, 44, 49, 51, 52, 53, 55, 56, 57, 60, 63, 72, 74], "rangeindex": [37, 44, 49, 51, 52, 53, 56, 57, 60, 72], "5098": [37, 60, 72], "dtype": [37, 44, 47, 48, 49, 50, 51, 52, 53, 56, 57, 60, 62, 72], "float64": [37, 44, 49, 51, 52, 56, 57, 60, 72], "136": [37, 51, 62, 74], "int64": [37, 50, 51, 60, 72], "memori": [37, 44, 49, 51, 52, 53, 56, 57, 60, 72], "usag": [37, 44, 49, 51, 52, 53, 56, 57, 60, 72, 74], "mb": [37, 57, 60, 72], "0005": 37, "0026": 37, "078207": 37, "035572": 37, "198549": 37, "02791": 37, "147927": 37, "008487": 37, "dml_irm_rf": 37, "double_ml_irm": [37, 54], "0x1747bdd6b90": 37, "076971": 37, "03574": 37, "153633": 37, "031269": 37, "14702": 37, "006922": 37, "0019": 37, "0073": 37, "0001": [37, 52], "0x1747bdd4520": 37, "080947": 37, "035545": 37, "277299": 37, "022768": 37, "150614": 37, "01128": 37, "progress": 38, "document": [38, 41, 42, 45, 47, 48, 70, 74], "py_double_ml_basic_iv": 39, "binomi": [39, 54, 55], "instrument_impact": 39, "astyp": [39, 52], "outcome_1": 39, "outcome_0": 39, "1099472942084532": 39, "950545": 39, "487872": 39, "998062": 39, "000064": 39, "906757": 39, "994332": 39, "py_double_ml_bas": 40, "scipi": 40, "lightgbm": [40, 43, 44, 45, 50, 53, 55], "lgbmregressor": [40, 43, 44, 45, 50, 53, 59], "train_test_split": 40, "face_color": 40, "color_palett": [40, 51, 52, 53], "pastel": 40, "edge_color": 40, "filterwarn": 40, "ignor": 40, "append": [40, 50, 59], "furthermor": 40, "learning_r": [40, 43, 53, 55, 59], "full": [40, 43, 44, 45, 47, 48, 50, 52, 53, 55, 57, 59], "i_train": 40, "i_est": 40, "test_siz": 40, "random_st": [40, 49, 54], "theta_initi": 40, "nanmean": 40, "reshap": [40, 41, 42, 45], "fig_non_orth": 40, "ax": [40, 41, 42, 43, 45, 47, 48, 50, 51, 52, 53, 55], "constrained_layout": 40, "histplot": 40, "edgecolor": 40, "label": [40, 41, 42, 43, 45, 47, 48, 53, 55], "axvlin": 40, "xx": 40, "yy": 40, "norm": 40, "pdf": 40, "loc": [40, 43, 45, 46, 51, 55, 56], "bbox_to_anchor": 40, "set_xlim": 40, "set_xlabel": [40, 51], "fig_orth_nosplit": 40, "fig_dml": 40, "fig_al": 40, "fig_po_nosplit": 40, "fig_po_dml": 40, "fig_po_al": 40, "savefig": 40, "py_non_orthogon": 40, "bbox_inch": 40, "tight": 40, "format": [40, 49, 68], "py_dml_nosplit": 40, "py_dml": 40, "py_al": 40, "py_dml_po_nosplit": 40, "py_dml_po": 40, "py_po_al": 40, "py_double_ml_c": 41, "spline": [41, 42, 62], "make_heterogeneous_data": [41, 42, 47, 48, 49], "found": [41, 42, 46, 47, 48, 59, 60, 63, 64, 72], "x_0": [41, 42, 45, 47, 48, 49], "data_dict": [41, 42, 47, 48, 49], "803300": 41, "259828": [41, 42], "886086": [41, 42], "895690": [41, 42], "297287": [41, 42], "229994": [41, 42], "411304": [41, 42], "655547": 41, "824350": [41, 42], "396992": [41, 42], "156317": [41, 42], "737951": [41, 42], "360475": [41, 42], "671271": [41, 42], "878402": 41, "988421": [41, 42], "977280": [41, 42], "793818": [41, 42], "659423": [41, 42], "577807": [41, 42], "866102": [41, 42], "941440": 41, "427486": [41, 42], "330285": [41, 42], "564232": [41, 42], "850575": [41, 42], "201528": [41, 42], "934433": [41, 42], "703049": 41, "016200": [41, 42], "818380": [41, 42], "040139": [41, 42], "889913": [41, 42], "991963": [41, 42], "294067": [41, 42], "x_6": [41, 42, 47, 48], "x_7": [41, 42, 47, 48], "x_8": [41, 42, 47, 48], "x_9": [41, 42, 47, 48], "240532": [41, 42], "672384": [41, 42], "826065": [41, 42], "673092": [41, 42], "270644": [41, 42], "081230": [41, 42], "992582": [41, 42], "156202": [41, 42], "289440": [41, 42], "467681": [41, 42], "619390": [41, 42], "411190": [41, 42], "689088": [41, 42], "823273": [41, 42], "556191": [41, 42], "779517": [41, 42], "210319": [41, 42], "765363": [41, 42], "253026": [41, 42], "865562": [41, 42], "stage": [41, 42, 47, 48, 54, 63, 74, 75], "randomforest_reg": [41, 54], "dml_irm": [41, 47, 50, 54], "475569": 41, "0408": 41, "109": [41, 62], "695045": 41, "395603": 41, "555536": 41, "reli": [41, 42, 44, 45, 49, 62, 63, 64, 68, 75], "semenova": [41, 42, 73], "patsi": [41, 42, 62], "suitabl": [41, 42, 57], "design_matrix": [41, 42, 62], "dmatrix": [41, 42, 62], "spline_basi": [41, 42, 62], "025": [41, 42, 47, 48], "975": [41, 42, 47, 48, 50], "691423": 41, "160438": 41, "309605": 41, "715075e": 41, "376780": 41, "006066": 41, "303007": 41, "267099": 41, "622301": 41, "314071e": 41, "779185": 41, "826829": 41, "904315": 41, "171709": 41, "561819": 41, "047375e": 41, "567568": 41, "241063": 41, "755688": 41, "205656": 41, "124465": 41, "235501e": 41, "352365": 41, "159011": 41, "745881": 41, "208922": 41, "929552": 41, "128273e": 41, "336153": 41, "155610": 41, "314341": 41, "224546": 41, "213635": 41, "278303e": 41, "873972": 41, "754710": 41, "new_data": [41, 42, 54], "linspac": [41, 42], "spline_grid": [41, 42], "build_design_matric": [41, 42], "design_info": [41, 42], "df_cate": [41, 42], "070552": 41, "333655": 41, "596758": 41, "185984": 41, "453279": 41, "720573": 41, "298076": 41, "570936": 41, "843796": 41, "407558": 41, "686627": 41, "965696": 41, "515031": 41, "800351": 41, "085671": 41, "417640": 41, "704814": 41, "991988": 41, "424292": 41, "705354": 41, "986417": 41, "433750": 41, "708235": 41, "982720": 41, "98": [41, 42, 53, 62, 64, 65, 74], "445476": 41, "713457": 41, "981438": 41, "458784": 41, "721018": 41, "983253": 41, "true_effect": [41, 42, 45, 47, 48], "fill_between": [41, 42, 43, 53, 55], "xlabel": [41, 42, 43, 45, 47, 48, 52, 53, 55], "ylabel": [41, 42, 43, 45, 47, 48, 52, 53, 55], "still": [41, 42, 44, 47, 48, 49, 53, 56, 57, 63], "5000": [41, 42, 43, 55], "286203": 41, "014080": [41, 42], "006958": [41, 42], "240127": [41, 42], "100807": [41, 42], "260211": [41, 42], "177043": [41, 42], "416899": 41, "152148": [41, 42], "912230": [41, 42], "892796": [41, 42], "653901": [41, 42], "672234": [41, 42], "005339": [41, 42], "087634": 41, "344787": [41, 42], "893649": [41, 42], "291517": [41, 42], "562712": [41, 42], "099731": [41, 42], "921956": [41, 42], "508433": 41, "619351": [41, 42], "232134": [41, 42], "000943": [41, 42], "757151": [41, 42], "985207": [41, 42], "809913": [41, 42], "567695": 41, "477130": [41, 42], "447624": [41, 42], "775191": [41, 42], "526769": [41, 42], "316717": [41, 42], "258158": [41, 42], "028520": [41, 42], "909304": [41, 42], "008223": [41, 42], "736082": [41, 42], "984872": [41, 42], "877833": [41, 42], "895106": [41, 42], "659245": [41, 42], "140770": [41, 42], "224897": [41, 42], "558134": [41, 42], "764093": [41, 42], "460207": [41, 42], "903767": [41, 42], "409848": [41, 42], "524934": [41, 42], "037747": [41, 42], "583195": [41, 42], "229961": [41, 42], "148134": [41, 42], "547052": 41, "038845": 41, "117": [41, 62], "057529": 41, "470918": 41, "623186": 41, "tensor": [41, 42], "product": [41, 42, 46, 50, 68], "te": [41, 42, 54], "805766": 41, "105942": 41, "484022": 41, "169759e": 41, "144": [41, 42, 62, 74], "598073": 41, "013459": 41, "115489": 41, "865279": 41, "289167": 41, "974002e": 41, "811818": 41, "580841": 41, "462857": 41, "856112": 41, "540650": 41, "887734e": 41, "215502": 41, "141215": 41, "309252": 41, "755712": 41, "055729": 41, "257106e": 41, "827721": 41, "790783": 41, "575588": 41, "763215": 41, "754162": 41, "507876e": 41, "920652": 41, "071827": 41, "338149": 41, "960068": 41, "476991": 41, "114339e": 41, "220309": 41, "455990": 41, "994680": 41, "033218": 41, "834103": 41, "377947e": 41, "020245": 41, "969116": 41, "404342": 41, "003959": 41, "379085": 41, "943864e": 41, "372547": 41, "436136": 41, "644977": 41, "908615": 41, "911000": 41, "618824e": 41, "426265": 41, "863689": 41, "753215": 41, "930412": 41, "033929": 41, "567809e": 41, "929195": 41, "577234": 41, "018440": 41, "787391": 41, "023419": 41, "813172e": 41, "562076": 41, "525197": 41, "577967": 41, "827434": 41, "907062": 41, "657037e": 41, "02": [41, 42, 50, 52, 53, 55, 62, 65, 75], "044169": 41, "200104": 41, "071240": 41, "027323": 41, "042749": 41, "971154e": 41, "085250": 41, "942769": 41, "289879": 41, "135389": 41, "016822": 41, "376796e": 41, "515746": 41, "064012": 41, "607495": 41, "040439": 41, "506150": 41, "223720e": 41, "647216": 41, "567774": 41, "241651": 41, "762233": 41, "317030": 41, "512342e": 41, "252663": 41, "735965": 41, "085470": 41, "774248": 41, "401967": 41, "609878e": 41, "432399": 41, "603340": 41, "742340": 41, "665550": 41, "622929": 41, "980483e": 41, "437567": 41, "047113": 41, "384833": 41, "673582": 41, "055922": 41, "984237e": 41, "064313": 41, "705353": 41, "505902": 41, "842439": 41, "787550": 41, "390974e": 41, "157455": 41, "145652": 41, "315927": 41, "896752": 41, "582572": 41, "835149e": 41, "073960": 41, "557895": 41, "806172": 41, "779345": 41, "600679": 41, "204979e": 41, "334034": 41, "278310": 41, "945878": 41, "772286": 41, "519633": 41, "177894e": 41, "431855": 41, "459902": 41, "189109": 41, "805957": 41, "716160": 41, "627347e": 41, "609075": 41, "769142": 41, "375128": 41, "693628": 41, "307597": 41, "080755e": 41, "015309": 41, "734947": 41, "134494": 41, "666861": 41, "200809": 41, "379084e": 41, "827151": 41, "441837": 41, "709543": 41, "876075": 41, "951366": 41, "106987e": 41, "007953": 41, "427038": 41, "232706": 41, "945411": 41, "303883": 41, "923340e": 41, "086130": 41, "620719": 41, "378910": 41, "907697": 41, "519131": 41, "287934e": 41, "158399": 41, "400578": 41, "060585": 41, "983891": 41, "127070": 41, "734540e": 41, "131723": 41, "989447": 41, "063691": 41, "973256": 41, "175357": 41, "026318e": 41, "155678": 41, "971704": 41, "076531": 41, "840625": 41, "228586": 41, "625914e": 41, "428533": 41, "724529": 41, "840627": 41, "818586": 41, "691784": 41, "781283e": 41, "235836": 41, "445417": 41, "585250": 41, "056947": 41, "445961": 41, "448125e": 41, "513166": 41, "657334": 41, "848004": 41, "182386": 41, "562945": 41, "181294e": 41, "166004": 41, "469996": 41, "429441": 41, "156561": 41, "371309": 41, "104233e": 41, "696813": 41, "837930": 41, "038915": 41, "978549": 41, "193219": 41, "274986e": 41, "120526": 41, "957305": 41, "187746": 41, "021007": 41, "081010": 41, "892380e": 41, "07": [41, 42, 53, 55, 65], "186120": 41, "189372": 41, "151029": 41, "833112": 41, "583517": 41, "216029e": 41, "517761": 41, "784298": 41, "733851": 41, "913280": 41, "373259": 41, "941512e": 41, "943417": 41, "524285": 41, "381220": 41, "148943": 41, "072531": 41, "826764e": 41, "128782": 41, "633658": 41, "41": [41, 42, 52, 53, 62, 63, 64, 65, 67, 69, 75], "441293": 41, "263665": 41, "514613": 41, "443368e": 41, "963949": 41, "918636": 41, "731904": 41, "166072": 41, "485246": 41, "375424e": 41, "554115": 41, "017923": 41, "068584": 41, "937852": 41, "735793": 41, "353723e": 41, "229978": 41, "907189": 41, "44": [41, 42, 44, 62, 63, 64, 65, 67], "734608": 41, "133198": 41, "295637": 41, "889032e": 41, "513038": 41, "956177": 41, "197947": 41, "814406": 41, "294060": 41, "189538e": 41, "601351": 41, "794544": 41, "367100": 41, "825135": 41, "504509": 41, "563902e": 41, "749469": 41, "984731": 41, "925833": 41, "023154": 41, "791732": 41, "396516e": 41, "09": [41, 43, 52, 53, 55, 62], "919998": 41, "931669": 41, "301554": 41, "049953": 41, "239631": 41, "151705e": 41, "756818": 41, "359927": 41, "237434": 41, "039654": 41, "190237": 41, "340104e": 41, "800748": 41, "275616": 41, "meshgrid": [41, 42], "ravel": [41, 42], "671843": 41, "379763": 41, "087683": 41, "681670": 41, "367085": 41, "052500": 41, "698653": 41, "357300": 41, "015947": 41, "720696": 41, "350332": 41, "979968": 41, "745574": 41, "346106": 41, "946637": 41, "9995": [41, 42, 45], "716422": 41, "506686": 41, "296950": 41, "9996": [41, 42, 45], "831783": 41, "661438": 41, "491093": 41, "9997": [41, 42, 45], "939298": 41, "811754": 41, "684210": 41, "9998": [41, 42, 45], "041979": 41, "955766": 41, "869554": 41, "9999": [41, 42, 45], "142442": 41, "091607": 41, "040771": 41, "graph_object": [41, 42, 46], "go": [41, 42, 46], "grid_arrai": [41, 42], "zip": [41, 42], "asarrai": [41, 42], "lower_bound": [41, 42], "upper_bound": [41, 42], "surfac": [41, 42, 46], "showscal": [41, 42, 46], "opac": [41, 42], "colorscal": [41, 42], "purp": [41, 42], "update_trac": [41, 42], "contours_z": [41, 42], "usecolormap": [41, 42], "highlightcolor": [41, 42], "limegreen": [41, 42], "project_z": [41, 42], "update_layout": [41, 42, 46], "scene": [41, 42, 46], "xaxis_titl": [41, 42, 46], "yaxis_titl": [41, 42, 46], "zaxis_titl": [41, 42, 46], "700": [41, 42, 46, 51], "margin": [41, 42], "py_double_ml_cate_plr": 42, "564451": 42, "241064": 42, "114570": 42, "040912": 42, "901013": 42, "392623": 42, "315155": 42, "551317": 42, "314625": 42, "683487": 42, "dml_plr": [42, 48, 67, 69], "377669": 42, "043998": 42, "497422": 42, "291434": 42, "463903": 42, "239313": 42, "141729": 42, "744228": 42, "675733e": 42, "961360": 42, "517266": 42, "581849": 42, "237292": 42, "666259": 42, "385877e": 42, "116483": 42, "047215": 42, "178218": 42, "150136": 42, "829619": 42, "742758e": 42, "883778": 42, "472657": 42, "040919": 42, "182692": 42, "118721": [42, 48], "950131e": 42, "682631": 42, "399207": 42, "272408": 42, "186795": 42, "518682": 42, "025783e": 42, "64": [42, 50, 52, 53, 62, 63, 64, 65, 67, 72], "906073": 42, "638742": 42, "796384": 42, "194232": 42, "545602": 42, "614185e": 42, "78": [42, 62, 63, 64, 65, 67, 74], "415465": 42, "177304": 42, "199412": 42, "429057": 42, "658702": 42, "289357": 42, "521611": 42, "753866": 42, "376806": 42, "613622": 42, "850439": 42, "462567": 42, "705090": 42, "947613": 42, "547324": 42, "796014": 42, "044704": 42, "494089": 42, "734770": 42, "975450": 42, "502901": 42, "738065": 42, "973229": 42, "514173": 42, "743341": 42, "972509": 42, "527452": 42, "750597": 42, "973741": 42, "542159": 42, "759833": 42, "977507": 42, "359307": 42, "479722": 42, "578557": 42, "587135": 42, "479882": 42, "172083": 42, "468072": 42, "480579": 42, "949866": 42, "974213": 42, "469885": 42, "049733": 42, "877289": 42, "37241": 42, "567361": 42, "785155": 42, "103184": 42, "992177": 42, "032420e": 42, "582869": 42, "987440": 42, "327397": 42, "865496": 42, "844496": 42, "223160e": 42, "024153": 42, "630641": 42, "070172": 42, "886948": 42, "461500": 42, "417145e": 42, "331360": 42, "808984": 42, "732388": 42, "768296": 42, "254844": 42, "418666e": 42, "226187": 42, "238590": 42, "016240": 42, "772250": 42, "610866": 42, "058565e": 42, "502289": 42, "530192": 42, "887451": 42, "929517": 42, "182226": 42, "936604e": 42, "709717": 42, "065185": 42, "447955": 42, "011405": 42, "386520": 42, "515881e": 42, "430757": 42, "465152": 42, "346739": 42, "916634": 42, "014906": 42, "363906e": 42, "143749": 42, "549729": 42, "628925": 42, "909099": 42, "691811": 42, "890885e": 42, "411162": 42, "153312": 42, "215756": 42, "962994": 42, "224047": 42, "227300e": 42, "103651": 42, "672139": 42, "906596": 42, "826349": 42, "307254": 42, "108175e": 42, "286586": 42, "526606": 42, "571864": 42, "826176": 42, "692182": 42, "888556e": 42, "047807": 42, "191535": 42, "869982": 42, "044030": 42, "833293": 42, "047199e": 42, "916743": 42, "176779": 42, "231931": 42, "127681": 42, "092446": 42, "746902e": 42, "442685": 42, "978824": 42, "163689": 42, "955649": 42, "264103": 42, "361088e": 42, "037185": 42, "290192": 42, "083059": 42, "788372": 42, "105355": 42, "160981e": 42, "462499": 42, "628617": 42, "891456": 42, "795531": 42, "634624": 42, "812119e": 42, "331863": 42, "451049": 42, "899296": 42, "682343": 42, "783492": 42, "398116e": 42, "561602": 42, "236991": 42, "679876": 42, "666883": 42, "018509": 42, "943705e": 42, "372489": 42, "987263": 42, "994036": 42, "845023": 42, "359741": 42, "832630e": 42, "650656": 42, "337416": 42, "966054": 42, "842814": 42, "332726": 42, "970240e": 42, "618343": 42, "313765": 42, "126810": 42, "734967": 42, "614956": 42, "073389e": 42, "567672": 42, "685948": 42, "162227": 42, "780091": 42, "207959": 42, "352696e": 42, "367097": 42, "691551": 42, "427678": 42, "796196": 42, "561040": 42, "822525e": 42, "866781": 42, "988575": 42, "310201": 42, "692187": 42, "337539": 42, "514763e": 42, "953208": 42, "667194": 42, "344909": 42, "656470": 42, "095295": 42, "611423e": 42, "057937": 42, "631882": 42, "030830": 42, "860246": 42, "035839": 42, "714121e": 42, "655633": 42, "717294": 42, "185413": 42, "951078": 42, "246389": 42, "126806e": 42, "049947": 42, "679121": 42, "139663": 42, "892272": 42, "277260": 42, "015705e": 42, "888912": 42, "609586": 42, "554896": 42, "996408": 42, "574920": 42, "607761e": 42, "601494": 42, "508298": 42, "414995": 42, "972671": 42, "454751": 42, "458016e": 42, "491872": 42, "321862": 42, "391627": 42, "858471": 42, "610228": 42, "669156e": 42, "708645": 42, "074610": 42, "911582": 42, "815494": 42, "570329": 42, "599180e": 42, "312852": 42, "510312": 42, "227797": 42, "040103": 42, "141899": 42, "225023e": 42, "188733": 42, "266860": 42, "200374": 42, "133278": 42, "176809": 42, "596657e": 42, "021354": 42, "422102": 42, "053614": 42, "048277": 42, "005092": 42, "149018e": 42, "001473": 42, "108702": 42, "565352": 42, "027969": 42, "386724": 42, "849992e": 42, "550078": 42, "580627": 42, "124503": 42, "050382": 42, "878706": 42, "101333e": 42, "065289": 42, "183716": 42, "072994": 42, "836451": 42, "455961": 42, "600258e": 42, "433180": 42, "712808": 42, "940895": 42, "907147": 42, "548985": 42, "380716e": 42, "162484": 42, "719306": 42, "310847": 42, "114559": 42, "867761": 42, "112495e": 42, "125818": 42, "495877": 42, "631615": 42, "254564": 42, "300543": 42, "934756e": 42, "827888": 42, "091117": 42, "770954": 42, "095776": 42, "703569": 42, "817344e": 42, "919159": 42, "377252": 42, "383033": 42, "996913": 42, "408991": 42, "348457e": 42, "428642": 42, "337425": 42, "245953": 42, "161076": 42, "240721": 42, "718746e": 42, "969729": 42, "522178": 42, "040651": 42, "825869": 42, "735989": 42, "345933e": 42, "421582": 42, "659721": 42, "017732": 42, "868965": 42, "075962": 42, "337631e": 42, "314175": 42, "721290": 42, "653178": 42, "041086": 42, "469543": 42, "013681e": 42, "612188": 42, "694168": 42, "487801": 42, "956192": 42, "601779": 42, "301769e": 42, "613241": 42, "362362": 42, "652448": 42, "821852": 42, "444167": 42, "016003e": 42, "041253": 42, "263642": 42, "333516": 42, "035184": 42, "736852": 42, "349439": 42, "035353": 42, "721268": 42, "376551": 42, "042153": 42, "707755": 42, "412508": 42, "055069": 42, "697630": 42, "454862": 42, "073587": 42, "692311": 42, "543515": 42, "251205": 42, "958896": 42, "582029": 42, "332346": 42, "082662": 42, "619083": 42, "416029": 42, "212975": 42, "659377": 42, "502548": 42, "345718": 42, "707256": 42, "592195": 42, "477133": 42, "py_double_ml_cvar": 43, "kallu": [43, 53, 55, 56, 66, 73], "multiprocess": [43, 53, 55], "lgbmclassifi": [43, 44, 45, 50, 53, 55], "locat": [43, 55], "5d": [43, 55], "2dx_5": [43, 55], "x_1x_3": [43, 55], "3x_4": [43, 55], "3dx_1": [43, 55], "1_": [43, 55], "f_loc": [43, 55], "f_scale": [43, 55], "through": [43, 47, 48, 55, 63], "tau_vec": [43, 53, 55], "n_true": [43, 55], "10e": [43, 55], "x_true": [43, 55], "epsilon_tru": [43, 55], "d1": [43, 55, 67, 69], "d0": [43, 55, 67], "y1": [43, 55], "y0": [43, 55], "y1_quant": [43, 55], "y0_quant": [43, 55], "y1_cvar": 43, "quant": 43, "y0_cvar": 43, "5467606094959261": 43, "7559417564883749": 43, "9567242535070148": 43, "1530959776797396": 43, "34769649731686": 43, "5425843074324594": 43, "7395359436844482": 43, "940354721701296": 43, "1469734445741286": 43, "361518457569366": 43, "586719493648897": 43, "8259803249536914": 43, "0841842065698133": 43, "3684990272106954": 43, "6903344145051182": 43, "0701961897676835": 43, "551586928482123": 43, "110902411746278": 43, "3453813031813522": 43, "5700384030890744": 43, "789671060840732": 43, "007332393760465": 43, "225459760731946": 43, "4461928741399595": 43, "6716717587835648": 43, "9041560442482157": 43, "146142808990006": 43, "400855956463958": 43, "6723684718264447": 43, "9666592590622916": 43, "292302995303554": 43, "663081975281988": 43, "103951906910721": 43, "667614205604159": 43, "convert": [43, 51, 55], "contrast": [43, 44], "doublemlcvar": [43, 62, 66, 74], "num_leav": [43, 45, 53, 55], "cvar_0": 43, "len": [43, 50, 51, 53, 55], "cvar_1": 43, "ci_cvar_0": 43, "ci_cvar_1": 43, "idx_tau": [43, 53, 55], "tau": [43, 45, 53, 55, 62, 66], "enumer": [43, 45, 47, 48, 50, 51, 52, 53, 55, 58, 63, 65], "dml_cvar_0": 43, "dml_cvar_1": 43, "to_numpi": [43, 49, 53, 55], "squeez": [43, 44, 55, 57], "15000000000000002": [43, 53, 55, 63], "20000000000000004": [43, 53, 55], "25000000000000006": [43, 53, 55], "30000000000000004": [43, 53, 55], "3500000000000001": [43, 53, 55], "40000000000000013": [43, 53, 55], "45000000000000007": [43, 53, 55, 63], "5000000000000001": [43, 53, 55], "5500000000000002": [43, 53, 55], "6000000000000002": [43, 53, 55], "6500000000000001": [43, 53, 55], "7000000000000002": [43, 53, 55], "7500000000000002": [43, 53, 55], "8000000000000002": [43, 53, 55], "8500000000000002": [43, 53, 55], "9000000000000002": [43, 53, 55], "546761": 43, "110902": 43, "360683": 43, "057962": 43, "755942": 43, "345381": 43, "590911": 43, "273356": 43, "956724": 43, "570038": 43, "829543": 43, "489699": 43, "153096": 43, "789671": 43, "015038": 43, "697000": 43, "347696": 43, "007332": 43, "203284": 43, "925736": 43, "542584": 43, "225460": 43, "502494": 43, "144084": 43, "739536": 43, "446193": 43, "678826": 43, "338775": 43, "940355": 43, "671672": 43, "822482": 43, "559144": 43, "146973": 43, "904156": 43, "153119": 43, "824701": 43, "361518": 43, "146143": 43, "156969": 43, "041831": 43, "586719": 43, "400856": 43, "495657": 43, "298120": 43, "65": [43, 49, 50, 53, 55, 62, 63, 64, 65, 67], "825980": 43, "672368": 43, "653846": 43, "582761": 43, "084184": 43, "966659": 43, "847948": 43, "842405": 43, "368499": 43, "292303": 43, "076347": 43, "163895": 43, "80": [43, 44, 53, 55, 57, 62, 63, 64, 65, 74], "690334": 43, "663082": 43, "523163": 43, "543075": 43, "070196": 43, "103952": 43, "869020": 43, "913774": 43, "551587": 43, "667614": 43, "372097": 43, "482038": 43, "162710": 43, "558655": 43, "957745": 43, "360801": 43, "821021": 43, "175284": 43, "606342": 43, "052745": 43, "393604": 43, "824889": 43, "205187": 43, "601061": 43, "009428": 43, "397140": 43, "824750": 43, "292028": 43, "712960": 43, "041147": 43, "455078": 43, "902573": 43, "234534": 43, "579238": 43, "065725": 43, "455107": 43, "883914": 43, "422325": 43, "715407": 43, "907491": 43, "406446": 43, "932027": 43, "250210": 43, "741104": 43, "183526": 43, "382872": 43, "924821": 43, "466440": 43, "554076": 43, "141820": 43, "722848": 43, "727976": 43, "424717": 43, "041284": 43, "140833": 43, "905494": 43, "409746": 43, "483717": 43, "254324": 43, "773177": 43, "921372": 43, "822822": 43, "313209": 43, "158178": 43, "371429": 43, "585793": 43, "792939": 43, "026723": 43, "247020": 43, "443016": 43, "663182": 43, "933996": 43, "151636": 43, "412714": 43, "699082": 43, "961962": 43, "286507": 43, "676405": 43, "054370": 43, "650867": 43, "ax1": [43, 53, 55], "ax2": [43, 53, 55], "violet": [43, 53, 55], "set_ylim": [43, 51, 55], "suptitl": [43, 50, 53, 55], "fontsiz": [43, 53, 55], "supxlabel": [43, 53, 55], "supylabel": [43, 53, 55], "doublemlqt": [43, 53, 55, 62, 67, 74], "parallel": [43, 44, 45, 50, 55, 64], "n_core": [43, 53, 55], "cpu_count": [43, 53, 55], "cores_us": [43, 53, 55], "dml_cvar": [43, 53], "627564": 43, "103806": 43, "045553": 43, "488982e": 43, "424108": 43, "831019": 43, "677980": 43, "102616": 43, "606954": 43, "923074e": 43, "476856": 43, "879103": 43, "706645": 43, "100356": 43, "041387": 43, "903351e": 43, "509951": 43, "903339": 43, "716793": 43, "102775": 43, "974414": 43, "071488e": 43, "515358": 43, "918227": 43, "716762": 43, "107073": 43, "694154": 43, "169230e": 43, "506903": 43, "926621": 43, "740869": 43, "112216": 43, "602168": [43, 64], "051867e": 43, "520930": 43, "960808": 43, "756969": 43, "114647": 43, "602628": 43, "039310e": 43, "532266": 43, "981672": 43, "751710": [43, 52], "117710": 43, "386102": 43, "701672e": 43, "521002": 43, "982417": 43, "779682": 43, "122408": 43, "369556": 43, "895768e": 43, "539767": 43, "019596": 43, "786744": 43, "130370": 43, "034690": 43, "592681e": 43, "531223": 43, "042265": 43, "814351": 43, "138378": 43, "884996": 43, "980643e": 43, "543136": 43, "085566": 43, "848868": 43, "144800": 43, "862359": 43, "563374e": 43, "565066": 43, "132671": 43, "946968": 43, "154828": 43, "116274": 43, "578846e": 43, "643512": 43, "250425": 43, "997621": 43, "164805": 43, "053331": 43, "418806e": 43, "674609": 43, "320633": 43, "073520": 43, "190915": 43, "623024": 43, "876431e": 43, "699333": 43, "447706": 43, "053558": 43, "236008": 43, "464076": 43, "041491e": 43, "590991": 43, "516125": 43, "097468": 43, "338908": 43, "238251": 43, "202650e": 43, "433221": 43, "761714": 43, "confidenceband": 43, "uniformli": [43, 53, 67, 69], "boostrap": [43, 74], "ci_cvar": [43, 53], "ci_joint_cvar": 43, "367571": 43, "887556": 43, "420967": 43, "934992": 43, "455293": 43, "957996": 43, "459383": 43, "974202": 43, "448587": 43, "984937": 43, "459812": 43, "021926": 43, "469825": 43, "044113": 43, "456892": 43, "046527": 43, "473099": 43, "086264": 43, "460218": 43, "113270": 43, "467770": 43, "160932": 43, "486202": 43, "211534": 43, "559186": 43, "334750": 43, "584849": 43, "410393": 43, "595353": 43, "551686": 43, "462451": 43, "644665": 43, "248638": 43, "946297": 43, "564142": 43, "589440": 43, "613314": 43, "636575": 43, "659636": 43, "682875": 43, "706657": 43, "731317": 43, "757183": 43, "784624": 43, "814136": 43, "846388": 43, "882475": 43, "923804": 43, "972748": 43, "033756": 43, "116027": 43, "qte": [43, 53, 74], "py_double_ml_did": 44, "trend": [44, 45, 51, 64, 73], "zimmert": [44, 73], "adopt": [44, 64], "pre": [44, 57, 63, 64], "2005": 44, "i1": [44, 64], "stationar": 44, "i0": [44, 45, 64], "overlap": [44, 64], "dgp_tpye": 44, "misspecifi": 44, "accordingli": [44, 50, 52, 57], "999": [44, 45, 49, 56, 75], "kb": [44, 49, 51, 52, 53, 56, 60, 72], "doublemldid": [44, 45, 64, 66, 74], "improv": [44, 50, 54, 74], "dml_did": [44, 45], "rmse": [44, 50, 53, 56, 57, 63, 64, 66, 67, 72, 74], "43627032": 44, "66989604": 44, "48873663": 44, "386988": 44, "827375": 44, "759006": 44, "447849": 44, "194601": 44, "968577": 44, "618776": 44, "392752": 44, "mai": [44, 57], "atte_estim": 44, "ci_length": 44, "iloc": [44, 45, 50, 51], "120": [44, 57, 62, 74], "140": [44, 53, 57, 62, 74], "160": [44, 57, 74], "180": [44, 57], "925": 44, "32236455588136": 44, "know": [44, 54], "correctli": [44, 56, 68], "safeguard": [44, 63], "against": [44, 49, 50, 54, 63], "misspecif": 44, "df_pa": [44, 57], "kdeplot": [44, 50, 57], "t_i": [44, 54, 64], "doublemldidc": [44, 64, 66, 74], "ml_g_d0_t0": [44, 64], "02897287": 44, "ml_g_d0_t1": [44, 64], "5602727": 44, "ml_g_d1_t0": [44, 64], "62403053": 44, "ml_g_d1_t1": [44, 64], "06834315": 44, "47761563": 44, "096741": 44, "225034": 44, "975447": 44, "329339": 44, "144137": 44, "337619": 44, "497674": 44, "691157": 44, "94": [44, 50, 62, 64, 65, 74, 75], "34858240261807": 44, "py_double_ml_did_pretest": 45, "implment": 45, "great": [45, 75], "slightli": [45, 47, 48, 49, 50, 62, 66, 68], "n_": 45, "2n_t": 45, "n_t": 45, "theta_t": 45, "mu_": 45, "fix": [45, 50, 52, 74], "i_4": 45, "dot": [45, 54, 60, 62, 63, 67, 69, 72], "bee": 45, "coincid": [45, 53], "5x_2": 45, "25x_3": 45, "1x_4x_3": 45, "5x_3": 45, "2x_4": 45, "n_time_period": 45, "time_period": 45, "mu_mean": 45, "concaten": [45, 52, 67], "mu": 45, "f_p": 45, "low": [45, 49, 62, 73], "g_x": 45, "y_df": [45, 54], "hstack": 45, "treatment_df": 45, "x_df": 45, "transpos": 45, "time_df": 45, "individual_df": 45, "column_stack": [45, 47, 48, 56], "354188": 45, "399355": 45, "317394": 45, "522835": 45, "257377": 45, "045624": 45, "924634": 45, "197600": 45, "573700": 45, "668584": 45, "014432": 45, "059630": 45, "075261": 45, "024355": 45, "399223": 45, "002290": 45, "646937": 45, "689188": 45, "142270": 45, "647196": 45, "024926": 45, "698223": 45, "735964": 45, "727543": 45, "483186": 45, "412477": 45, "152926": 45, "405203": 45, "654755": 45, "590320": 45, "881465": 45, "410681": 45, "698244": 45, "132454": 45, "760915": 45, "591080": 45, "082804": 45, "533489": 45, "344834": 45, "482790": 45, "709026": 45, "619454": 45, "666307": 45, "304201": 45, "264086": 45, "230956": 45, "336612": 45, "687854": 45, "245720": 45, "644799": 45, "thatw": 45, "previou": [45, 49, 71, 75], "t_idx": 45, "t_diff": 45, "y_diff": 45, "errorbar": [45, 47, 48, 52], "fmt": [45, 47, 48, 52], "o": [45, 47, 48, 52, 67, 70, 72], "yerr": [45, 47, 48, 52], "1f77b4": 45, "ecolor": [45, 52], "linestyl": 45, "linewidth": 45, "axhlin": 45, "scatter": [45, 47, 48], "ff7f0e": 45, "exposur": 45, "py_double_ml_firststag": 46, "insight": 46, "2013": [46, 67, 69, 73], "spars": [46, 63, 67, 69, 72, 73], "toeplitz": 46, "repositori": [46, 74], "equival": [46, 65], "what": [46, 50], "extent": 46, "affect": [46, 64, 74, 75], "investig": 46, "translat": 46, "itertool": 46, "importlib": 46, "machineri": [46, 73], "sourcefileload": 46, "lassocv": [46, 51, 52, 57, 63, 64, 67, 69, 72], "px": 46, "path_to_r": 46, "githubusercont": 46, "motivation_example_bch": 46, "simulation_run": 46, "raw_res_manual_lasso_r_100_n_100_p_200_rho_0": 46, "6_r2d_0": 46, "6_r2y_0": 46, "6_design_1a": 46, "csv": 46, "df_result": 46, "read_csv": 46, "index_col": 46, "lambda_": 46, "df_agg": 46, "groupbi": [46, 52], "alpha_ml_l": 46, "alpha_ml_m": 46, "numeric_onli": 46, "reset_index": [46, 51, 52], "logarithm": 46, "ln_alpha_ml_l": 46, "ln_alpha_ml_m": 46, "measure_col": 46, "sq_error": 46, "camera": 46, "center": 46, "ey": 46, "layout": 46, "autos": 46, "this_df": [46, 52], "val_list": 46, "pivot": [46, 51, 73], "scene_camera": 46, "cover": [46, 56], "comb": 46, "lvert": 46, "rvert_": 46, "big": [46, 58, 65, 66, 67, 68], "rvert": 46, "tri": [46, 68], "rate": [46, 50], "except": [46, 74], "faster": 46, "combined_loss": 46, "nuis_rmse_ml_l": 46, "nuis_rmse_ml_m": 46, "crucial": [46, 75], "good": [46, 68, 75], "alexandr": [46, 73], "victor": [46, 65, 70, 73], "christian": [46, 73], "608": 46, "650": 46, "issn": 46, "0034": 46, "6527": 46, "1093": 46, "restud": 46, "rdt044": 46, "url": [46, 70, 73], "py_double_ml_g": 47, "114530": 47, "925248": [47, 48], "180575": [47, 48], "567945": [47, 48], "915488": [47, 48], "033946": [47, 48], "697420": [47, 48], "580922": 47, "474214": [47, 48], "862043": [47, 48], "844549": [47, 48], "319100": [47, 48], "828915": [47, 48], "037008": [47, 48], "278434": 47, "696289": [47, 48], "339875": [47, 48], "724767": [47, 48], "065356": [47, 48], "315290": [47, 48], "539491": [47, 48], "794805": 47, "615863": [47, 48], "232959": [47, 48], "024401": [47, 48], "870099": [47, 48], "021269": [47, 48], "874702": [47, 48], "178169": 47, "350712": [47, 48], "767188": [47, 48], "401931": [47, 48], "479876": [47, 48], "627505": [47, 48], "873677": [47, 48], "297349": [47, 48], "924396": [47, 48], "971058": [47, 48], "944266": [47, 48], "596270": [47, 48], "230009": [47, 48], "120567": [47, 48], "076953": [47, 48], "790723": [47, 48], "318753": [47, 48], "625891": [47, 48], "885978": [47, 48], "528937": [47, 48], "939068": [47, 48], "798783": [47, 48], "997934": [47, 48], "984083": [47, 48], "768273": [47, 48], "417767": [47, 48], "421357": [47, 48], "ite": [47, 48, 49], "770944": [47, 48], "4235839": [47, 48], "07202564": [47, 48], "30917769": [47, 48], "97441062": [47, 48], "goal": [47, 48], "906716732639898": [47, 48], "223485956098176": [47, 48], "827938162750831": [47, 48], "482012": 47, "086889": 47, "583034": 47, "311712": 47, "652312": 47, "straightforward": [47, 48, 50, 62], "interpret": [47, 48, 62, 68, 71, 75], "701265": 47, "016315": 47, "331365": 47, "096550": 47, "314651": 47, "532751": 47, "412004": 47, "668981": 47, "925957": 47, "wise": [47, 48], "441219": 47, "591411": 47, "916528": 47, "712774": 47, "199893": 47, "138068": 47, "togeth": [47, 48, 67], "elif": [47, 48, 54], "group_1": [47, 48, 62], "group_2": [47, 48, 62], "group_3": [47, 48], "seen": [47, 48], "blp_model": [47, 48], "144241": 47, "911662": 47, "948154e": 47, "732918": 47, "299712": 47, "117072": 47, "396300": 47, "151047e": 47, "179": [47, 74], "084633": 47, "544669": 47, "138851": 47, "625766": 47, "991444e": 47, "396173": 47, "941788": 47, "heteroskedast": [47, 48], "robu": [47, 48], "py_double_ml_gate_plr": 48, "543764": 48, "605195": 48, "463766": 48, "056499": 48, "946406": 48, "920337": 48, "994937": 48, "356167": 48, "254038": 48, "190921": 48, "43883": 48, "088282": 48, "280196": 48, "2658": 48, "611859": 48, "602079": 48, "942139": 48, "282200": 48, "888775": 48, "048308": 48, "207840": 48, "660320": 48, "856404": 48, "052488": 48, "299537": 48, "584742": 48, "746843": 48, "349772": 48, "485871": 48, "226938": 48, "120456": 48, "425072": 48, "751482e": 48, "705474": 48, "178805": 48, "091046": 48, "447999": 48, "593754e": 48, "215": 48, "869425": 48, "227190": 48, "905998": 48, "381623e": 48, "623147": 48, "089661": 48, "py_double_ml_gate_sensit": 49, "perfrom": 49, "known": [49, 50, 63], "2f": 49, "mention": [49, 62], "throughout": 49, "increas": [49, 50, 51, 75], "stabil": 49, "explicitli": [49, 75], "dml_irm_at": 49, "448923": 49, "084212": 49, "82985": 49, "284271": 49, "613574": 49, "sensitivity_summari": [49, 56, 68, 75], "259118": 49, "397578": 49, "500267": 49, "638888": 49, "h_0": [49, 56, 68, 75], "rv": [49, 56, 68, 75], "rva": [49, 56, 68, 75], "695581": 49, "635296": 49, "reveal": 49, "benchmarking_vari": 49, "004392": 49, "003779": 49, "true_group_effect": 49, "correct": [49, 62, 67, 69, 74], "probabilit": 49, "omega": [49, 62, 68], "89035917": 49, "dml_irm_gat": 49, "739817": 49, "201796": 49, "443701": 49, "830755e": 49, "178": [49, 74], "344305": 49, "135329": 49, "334785": 49, "668452": 49, "811155": 49, "141384": 49, "164698": 49, "100614": 49, "littl": 49, "evid": 49, "000494": 49, "group_treat": 49, "true_gatet_effect": 49, "69": [49, 62, 63, 64, 65, 67, 74], "cdot1": 49, "bar": [49, 52, 62], "plug": [49, 68], "actual": 49, "nbsphinx": 49, "math": 49, "group_ind": 49, "dml_irm_gatet": 49, "630914": 49, "121774": 49, "240813": 49, "392242": 49, "869586": 49, "400164": 49, "600438": 49, "661391": 49, "861755": 49, "989372": 49, "408014": 49, "002436": 49, "py_double_ml_learn": 50, "practic": [50, 73], "usabl": 50, "too": 50, "restrict": 50, "ourselv": 50, "comparison": 50, "logisticregressioncv": [50, 52, 57, 64], "gradientboostingregressor": 50, "gradientboostingclassifi": 50, "reg_learner_1": 50, "reg_learner_2": 50, "class_learner_1": 50, "class_learner_2": 50, "learner_list": 50, "try": [50, 56], "fair": 50, "matter": 50, "cleaner": 50, "inbuild": 50, "_utils_resampl": 50, "doublemlresampl": 50, "fill_valu": 50, "rmses_ml_m": 50, "rmses_ml_g0": 50, "rmses_ml_g1": 50, "coverag": [50, 62, 74], "rprocess": 50, "stratifi": 50, "split_sampl": 50, "i_learn": 50, "ncoverag": 50, "935": 50, "logit": 50, "df_coef": 50, "df_ml_m": 50, "df_ml_g0": 50, "df_ml_g1": 50, "set_text": 50, "subplots_adjust": 50, "wspace": 50, "hspace": 50, "better": 50, "happend": 50, "smallest": 50, "cannot": [50, 75], "selected_learn": 50, "argmin": 50, "return_count": 50, "sometim": 50, "selected_coef": 50, "excess": 50, "loss": 50, "inbuilt": 50, "output": [50, 58, 67, 69, 75], "02649578": 50, "06046108": 50, "34943161": 50, "hand": [50, 75], "deviat": [50, 68], "handl": [50, 63, 74], "onto": 50, "g_1": 50, "Of": [50, 67, 75], "vice": [50, 68], "versa": [50, 68], "82261299": 50, "853177": 50, "20148598": 50, "nuisance_target": 50, "theoret": [50, 65, 73], "backbon": 50, "ell_2": 50, "But": 50, "scikit": [50, 52, 63, 70, 72, 74, 75], "overview": [50, 67, 68, 73], "suffici": 50, "prior": [50, 64], "huge": 50, "largest": 50, "clever": 50, "resourcewis": 50, "nearli": 50, "resourc": 50, "perf_count": 50, "t_1_start": 50, "t_1_stop": 50, "crossfit": 50, "t_2_start": 50, "t_2_stop": 50, "speedup": 50, "7683": 50, "largli": 50, "quit": [50, 54, 56, 68], "fast": [50, 54, 63], "saveguard": 50, "wrong": 50, "especi": 50, "tabular": [50, 60, 67, 69, 72, 75], "popular": [50, 68], "catboost": 50, "heavili": 50, "your": [50, 71], "xgbclassifi": [50, 52, 75], "xgbregressor": [50, 52, 75], "t_3_start": 50, "t_3_stop": 50, "7578": 50, "7731": 50, "5987": 50, "py_double_ml_multiway_clust": 51, "listedcolormap": 51, "kfold": [51, 65], "repeatedkfold": 51, "624": 51, "103": [51, 57, 62, 74], "512": 51, "261903": 51, "195564": 51, "118952": 51, "508459": 51, "082973": 51, "303835": 51, "760778": 51, "542671": 51, "110359": 51, "679539": 51, "491245": 51, "309772": 51, "010940": 51, "003427": 51, "412653": 51, "784238": 51, "073207": 51, "370736": 51, "005857": 51, "833907": 51, "226598": 51, "544555": 51, "183888": 51, "694919": 51, "205938": 51, "996934": 51, "136836": 51, "601598": 51, "201768": 51, "234910": 51, "212844": 51, "427573": 51, "303324": 51, "247826": 51, "552727": 51, "036729": 51, "673302": 51, "024604": 51, "094381": 51, "922996": 51, "054068": 51, "014637": 51, "611269": 51, "323679": 51, "557999": 51, "698694": 51, "342992": 51, "136089": 51, "096337": 51, "714240": 51, "094026": 51, "435401": 51, "149714": 51, "164864": 51, "756805": 51, "010269": 51, "396985": 51, "161141": 51, "614188": 51, "256567": 51, "113780": 51, "104787": 51, "109273": 51, "410795": 51, "128408": 51, "633433": 51, "816318": 51, "002983": 51, "942661": 51, "477474": 51, "543380": 51, "720664": 51, "332996": 51, "851366": 51, "302648": 51, "628069": 51, "632058": 51, "509958": 51, "456370": 51, "557595": 51, "081488": 51, "438960": 51, "054162": 51, "518175": 51, "510385": 51, "681176": 51, "020271": 51, "708190": 51, "805007": 51, "850321": 51, "empti": 51, "sixth": 51, "five": 51, "_n_folds_per_clust": 51, "135871": 51, "118601": 51, "577271": 51, "964261e": 51, "903418": 51, "368324": 51, "951532": 51, "047954": 51, "842625": 51, "276189e": 51, "857544": 51, "04552": 51, "polynomialfeatur": [51, 52], "rpy2": 51, "robject": 51, "packagedata": 51, "pandas2ri": 51, "default_convert": 51, "convers": 51, "r_df": 51, "localconvert": 51, "rpy2pi": 51, "amgrem": 51, "129": [51, 62, 74], "825617": 51, "888146": 51, "amhorn": 51, "245370": 51, "935989": 51, "amjavl": 51, "652778": 51, "716799": 51, "ammata": 51, "134": [51, 57, 62, 74], "921913": 51, "687871": 51, "amamb": 51, "833024": 51, "504286": 51, "2213": 51, "vv740": 51, "526": 51, "5584": 51, "378596": 51, "639135": 51, "2214": 51, "vv760g": 51, "529": 51, "5585": 51, "225574": 51, "136442": 51, "2215": 51, "yggvpl": 51, "555": 51, "5589": 51, "368152": 51, "518846": 51, "2216": 51, "ps911c": 51, "425": 51, "5590": 51, "997571": 51, "016154": 51, "ps944": 51, "438": 51, "5592": 51, "296729": 51, "267500": 51, "mpg": 51, "outshr": 51, "697": 51, "150200": 51, "528997": 51, "001051": 51, "880106": 51, "820366": 51, "740": 51, "278000": 51, "494324": 51, "000670": 51, "369981": 51, "543": [51, 53], "459200": 51, "467613": 51, "000341": 51, "306915": 51, "606800": 51, "426540": 51, "000522": 51, "120721": 51, "645800": 51, "452489": 51, "000442": 51, "045144": 51, "305612": 51, "385917": 51, "000488": 51, "907801": 51, "022915": 51, "435967": 51, "000091": [51, 62], "652350": 51, "800": 51, "843730": 51, "358289": 51, "000067": 51, "957375": 51, "400": 51, "093950": 51, "814913": 51, "000039": 51, "512519": 51, "600": 51, "153587": 51, "693796": 51, "000025": 51, "953683": 51, "construct_iv": 51, "firmid": 51, "id_var": 51, "sum_oth": 51, "sum_riv": 51, "rival": 51, "other_ind": 51, "rival_ind": 51, "concat": [51, 52, 54, 67], "include_bia": [51, 52], "fit_transform": [51, 52], "x_cols_poli": 51, "get_feature_names_out": [51, 52], "sel_cols_chiang": 51, "setdiff1d": 51, "658": 51, "max_it": [51, 52], "50000": 51, "res_df": 51, "re": [51, 71], "drop": [51, 60, 63, 66, 67, 69], "svenk": 51, "conda": [51, 73, 74], "env": [51, 71], "dml_base": 51, "lib": 51, "site": 51, "_coordinate_desc": 51, "py": [51, 67, 70, 71, 74], "617": 51, "convergencewarn": 51, "dualiti": 51, "gap": 51, "5154789948092002": 51, "toler": 51, "1187339840850312": 51, "cd_fast": 51, "enet_coordinate_descent_gram": 51, "450152": 51, "262621": 51, "316540": 51, "584942e": 51, "924843": 51, "975461": 51, "757819": 51, "928947": 51, "198218": 51, "710586e": 51, "578523": 51, "937116": 51, "811825": 51, "784483": 51, "408479": 51, "277561e": 51, "349383": 51, "274267": 51, "754870": 51, "464284": 51, "395136": 51, "776728e": 51, "664850": 51, "844889": 51, "discret": 51, "rdbu_r": 51, "cmap": 51, "font_scal": [51, 52, 53], "i_split": 51, "this_split_ind": 51, "invert_yaxi": 51, "set_ylabel": 51, "colorbar": 51, "set_tick": 51, "667": 51, "set_ticklabel": 51, "multiindex": 51, "from_product": 51, "df_wide": 51, "level_1": 51, "floor_divid": 51, "set_titl": 51, "tight_layout": 51, "py_double_ml_pens": 52, "decisiontreeregressor": 52, "standardscal": 52, "make_pipelin": 52, "set_styl": [52, 53], "whitegrid": [52, 53], "spine": [52, 53], "temporari": 52, "issu": [52, 70, 73, 74], "21997": 52, "releas": 52, "nifa": [52, 53, 56], "tw": [52, 53], "4500": 52, "6215": 52, "22390": 52, "155000": 52, "58000": 52, "count": [52, 53], "915000e": [52, 53], "392864e": [52, 53], "805153e": [52, 53], "381685e": [52, 53], "060212": [52, 53], "37200": [52, 53], "623197": 52, "490488e": 52, "352250e": 52, "115297e": 52, "344505": [52, 53], "24774": [52, 53], "288006": 52, "000000e": [52, 53], "023020e": [52, 53], "291500e": [52, 53], "19413": [52, 53], "635000e": [52, 53], "499000e": [52, 53], "510000e": [52, 53], "31476": [52, 53], "765500e": [52, 53], "652450e": [52, 53], "148750e": [52, 53], "48583": [52, 53], "500000": [52, 53], "430298e": [52, 53], "536798e": [52, 53], "029910e": [52, 53], "242124": [52, 53], "865860": [52, 53], "206253": [52, 53], "271004": [52, 53], "604841": [52, 53], "380837": [52, 53], "538937": [52, 53], "810382": [52, 53], "444500": [52, 53], "488909": [52, 53], "485617": [52, 53], "371357": [52, 53], "261624": [52, 53], "242158": [52, 53], "635199": [52, 53], "483192": [52, 53], "439541": [52, 53], "428411": [52, 53], "481399": [52, 53], "value_count": 52, "displot": 52, "hue": 52, "diff": 52, "34475": 52, "583404": 52, "9914": [52, 53, 56], "int8": [52, 53, 56], "406": 52, "copi": [52, 54], "poly_dict": 52, "sort": 52, "755": 52, "logspac": 52, "l1": [52, 57, 64], "solver": [52, 57, 64], "liblinear": [52, 57, 64], "5722": 52, "474846": 52, "1380": 52, "619177": 52, "144861": 52, "000034": 52, "3016": 52, "510982": 52, "8428": 52, "438709": 52, "lasso_summari": 52, "8974": 52, "79122": 52, "323622": 52, "776887": 52, "227931e": 52, "6379": 52, "164617": 52, "11570": 52, "417822": 52, "forest_summari": 52, "634078": [52, 75], "1321": [52, 75], "822289": [52, 75], "740417": 52, "579322e": 52, "6318": [52, 75], "909997": [52, 75], "11500": [52, 75], "358158": [52, 75], "min_samples_split": 52, "tree_summari": 52, "8260": 52, "06428": 52, "1348": 52, "624798": 52, "124805": 52, "079458e": 52, "5616": 52, "808246": 52, "10903": 52, "320314": 52, "n_job": 52, "use_label_encod": [52, 75], "boost_summari": 52, "8688": 52, "511293": 52, "1390": 52, "8893": 52, "246731": 52, "191320e": 52, "5962": 52, "41836": 52, "11414": 52, "604227": 52, "plr_summari": 52, "791220": 52, "064280": 52, "418360": 52, "ylim": 52, "12500": 52, "7763": 52, "891697": 52, "1343": 52, "034836": 52, "780857": 52, "432125e": 52, "5131": 52, "591788": 52, "10396": 52, "191606": 52, "8102": 52, "443032": 52, "1120": 52, "75171": 52, "229472": 52, "848757e": 52, "5905": 52, "810044": 52, "10299": 52, "076019": 52, "8059": 52, "691511": 52, "1167": 52, "841132": 52, "90136": 52, "150719e": 52, "5770": 52, "764953": 52, "10348": 52, "618069": 52, "9102": 52, "642735": 52, "1177": 52, "207222": 52, "732405": 52, "055338e": 52, "6795": 52, "358977": 52, "11409": 52, "926493": 52, "irm_summari": 52, "data_dml_iv_flex": 52, "765": 52, "12955": 52, "591741": 52, "1661": 52, "333575": 52, "798309": 52, "274247e": 52, "9699": 52, "437767": 52, "16211": 52, "745714": 52, "12002": 52, "712592": 52, "1628": 52, "619613": 52, "369869": 52, "707963e": 52, "8810": 52, "676807": 52, "15194": 52, "748377": 52, "10967": 52, "290987": 52, "1751": 52, "863772": 52, "260356": 52, "840995e": 52, "7533": 52, "701088": 52, "14400": 52, "880886": 52, "13288": 52, "732586": 52, "1683": 52, "292178": 52, "89449": 52, "915057e": 52, "9989": 52, "540542": 52, "16587": 52, "92463": 52, "iivm_summari": 52, "924630": 52, "16500": 52, "df_summari": 52, "renam": [52, 74], "set_index": 52, "889300": 52, "901360": 52, "894490": 52, "ind": 52, "queri": 52, "py_double_ml_pension_qt": 53, "elig": [53, 56, 75], "asset": [53, 56, 75], "focus": [53, 56, 75], "621094": 53, "490504e": 53, "352259e": 53, "115296e": 53, "251953": 53, "net": [53, 56, 75], "discretis": 53, "quanitl": 53, "class_learn": 53, "reg_learn": 53, "doublemlpq": [53, 55, 62, 66, 74], "specifii": 53, "pq_0": [53, 55], "pq_1": [53, 55], "ci_pq_0": [53, 55], "ci_pq_1": [53, 55], "dml_pq_0": [53, 55], "dml_pq_1": [53, 55], "hopefulli": 53, "31337878": 53, "4449272": 53, "63499": 53, "1855": 53, "668337": 53, "218938": 53, "264274e": 53, "256": [53, 63], "59861": 53, "956892": 53, "67136": 53, "043108": 53, "data_pq": 53, "df_pq": 53, "150000e": 53, "4200": 53, "5518": 53, "552508": 53, "4781": 53, "447492": 53, "197000e": 53, "3420": 53, "763691": 53, "2973": 53, "236309": 53, "900000e": 53, "733": 53, "2061": 53, "872222": 53, "1738": 53, "127778": 53, "910000e": 53, "1129": 53, "758391": 53, "852": 53, "241609": 53, "310000e": 53, "467": 53, "454081": 53, "194": [53, 74], "545919": 53, "880808e": 53, "411447": 53, "262423e": 53, "1586": 53, "141": [53, 62, 74], "518446": 53, "490000e": 53, "2927": 53, "781233": 53, "218767": 53, "5250": 53, "354": 53, "965774": 53, "645": 53, "034226": 53, "200000e": 53, "6530": 53, "1038": 53, "506687": 53, "1361": 53, "493313": 53, "318000e": 53, "2103": [53, 70], "647002": 53, "2532": 53, "352998": 53, "100000e": 53, "13300": 53, "3710": 53, "041459": 53, "4489": 53, "958541": 53, "750000e": 53, "18500": 53, "6029": 53, "711024": 53, "7470": 53, "288976": 53, "052000e": 53, "24199": 53, "9551": 53, "134146": 53, "11488": 53, "865854": 53, "650000e": 53, "33500": 53, "14984": 53, "664147": 53, "18015": 53, "335853": 53, "600000e": 53, "45500": 53, "23748": 53, "752283": 53, "28251": 53, "247717": 53, "144500e": 53, "37939": 53, "488460": 53, "44950": 53, "511540": 53, "4835": 53, "847966": 53, "3564": 53, "152034": 53, "2439": 53, "318552": 53, "1560": 53, "681448": 53, "1238": 53, "098317": 53, "227": [53, 74], "901683": 53, "472": 53, "478032": 53, "343": 53, "083750": 53, "745": 53, "552": 53, "392400": 53, "1447": 53, "607600": 53, "1107": 53, "286593": 53, "2064": 53, "713407": 53, "2036": 53, "542333": 53, "3817": 53, "457667": 53, "4389": 53, "402902": 53, "6110": 53, "597098": 53, "5702": 53, "335176": 53, "7357": 53, "664824": 53, "8440": 53, "555150": 53, "11559": 53, "444850": 53, "11932": 53, "311253": 53, "14667": 53, "688747": 53, "16725": 53, "272296": 53, "20274": 53, "727704": 53, "22222": 53, "986383": 53, "26175": 53, "013617": 53, "30383": 53, "148802": 53, "36616": 53, "851198": 53, "42338": 53, "762748": 53, "48661": 53, "237252": 53, "visibl": 53, "dml_qte": [53, 55], "1210": 53, "438569": 53, "487467": 53, "286563e": 53, "597923": 53, "1230": 53, "748513": 53, "663533": 53, "108257e": 53, "713": 53, "062414": 53, "1211": 53, "251": [53, 56], "948868": 53, "806531": 53, "535718e": 53, "717": 53, "189293": 53, "244": 53, "841847": 53, "084269": 53, "421576e": 53, "520": 53, "118799": 53, "622": 53, "255": 53, "252133": 53, "436806": 53, "481761e": 53, "121": [53, 62, 74], "715013": 53, "1031": 53, "813682": 53, "751633": 53, "756867e": 53, "492": 53, "375081": 53, "2006": 53, "320": 53, "163566": 53, "265547": 53, "715180e": 53, "1378": 53, "490941": 53, "3329": 53, "427": 53, "336461": 53, "790115": 53, "694845e": 53, "2491": 53, "435927": 53, "4601": 53, "448": 53, "109454": 53, "267581": 53, "864741e": 53, "3722": 53, "721609": 53, "6000": 53, "588": 53, "816752": 53, "189927": 53, "199282e": 53, "4845": 53, "940373": 53, "7040": 53, "605": 53, "739720": 53, "622153": 53, "180176e": 53, "5852": 53, "771965": 53, "9223": 53, "804": 53, "541821": 53, "463668": 53, "008266e": 53, "7646": 53, "127006": 53, "10928": 53, "859": 53, "705581": 53, "711328": 53, "115792e": 53, "9243": 53, "008023": 53, "12410": 53, "1018": 53, "114834": 53, "189195": 53, "549109e": 53, "10414": 53, "531594": 53, "16590": 53, "1589": 53, "396531": 53, "437924": 53, "664103e": 53, "13474": 53, "840041": 53, "19382": 53, "1622": 53, "701413": 53, "944280": 53, "955005e": 53, "16201": 53, "563673": 53, "21550": 53, "2279": 53, "055439": 53, "455672": 53, "209546e": 53, "17083": 53, "133421": 53, "2163": 53, "402077": 53, "1746": 53, "937586": 53, "1704": 53, "810707": 53, "1479": 53, "881201": 53, "1122": 53, "284987": 53, "1569": 53, "624919": 53, "2633": 53, "509059": 53, "4166": 53, "564073": 53, "5479": 53, "278391": 53, "7154": 53, "059627": 53, "8227": 53, "228035": 53, "10799": 53, "872994": 53, "12612": 53, "991977": 53, "14405": 53, "468406": 53, "19705": 53, "159959": 53, "22562": 53, "436327": 53, "26016": 53, "866579": 53, "quick": 53, "combind": 53, "ci_qt": [53, 55], "data_qt": 53, "df_qte": 53, "163": [53, 74], "857765": 53, "2583": 53, "090025": 53, "1974": 53, "909975": 53, "499": [53, 54, 60, 72], "415988": 53, "1922": 53, "584012": 53, "308": 53, "488485": 53, "1691": 53, "511515": 53, "913485": 53, "1342": 53, "254": 53, "838457": 53, "1807": 53, "161543": 53, "1101": 53, "755910": 53, "2910": 53, "244090": 53, "2122": 53, "065451": 53, "4535": 53, "934549": 53, "3335": 53, "395889": 53, "5866": 53, "604111": 53, "4336": 53, "993575": 53, "7663": 53, "006425": 53, "5329": 53, "197711": 53, "8750": 53, "802289": 53, "6950": 53, "717130": 53, "11495": 53, "282870": 53, "8499": 53, "917066": 53, "13356": 53, "082934": 53, "9534": 53, "518782": 53, "15285": 53, "481218": 53, "12101": 53, "036945": 53, "21078": 53, "963055": 53, "14798": 53, "973331": 53, "23965": 53, "026669": 53, "15113": 53, "220088": 53, "27986": 53, "779912": 53, "9073": 53, "195547": 53, "1298": 53, "264884": 53, "988709": 53, "774271e": 53, "6528": 53, "643133": 53, "10126": 53, "150334": 53, "1371": 53, "682269": 53, "382286": 53, "555949e": 53, "7437": 53, "702489": 53, "14587": 53, "388871": 53, "1485": 53, "887345": 53, "817291": 53, "485812e": 53, "11675": 53, "103189": 53, "16910": 53, "113415": 53, "1582": 53, "022969": 53, "688918": 53, "147015e": 53, "13809": 53, "405374": 53, "14744": 53, "693690": 53, "1676": 53, "606759": 53, "794366": 53, "438578e": 53, "11458": 53, "604825": 53, "16241": 53, "221419": 53, "1812": 53, "325090": 53, "961539": 53, "201788e": 53, "12689": 53, "129514": 53, "18666": 53, "064161": 53, "1970": 53, "604016": 53, "472255": 53, "738659e": 53, "14803": 53, "751261": 53, "12861": 53, "546294": 53, "2086": 53, "920645": 53, "162930": 53, "141098e": 53, "8771": 53, "256992": 53, "13642": 53, "272662": 53, "2295": 53, "693316": 53, "942550": 53, "806218e": 53, "9142": 53, "796444": 53, "14772": 53, "077161": 53, "2543": 53, "121399": 53, "808640": 53, "298228e": 53, "9787": 53, "650810": 53, "15556": 53, "468919": 53, "2849": 53, "994851": 53, "458420": 53, "803902e": 53, "9970": 53, "581655": 53, "16597": 53, "988780": 53, "3234": 53, "712082": 53, "131211": 53, "878847e": 53, "10258": 53, "069600": 53, "17576": 53, "743247": 53, "3745": 53, "384777": 53, "692907": 53, "693497e": 53, "10235": 53, "923977": 53, "18789": 53, "942489": 53, "4437": 53, "655422": 53, "234205": 53, "293617e": 53, "10092": 53, "297687": 53, "19794": 53, "747646": 53, "5476": 53, "213026": 53, "614678": 53, "007210e": 53, "9061": 53, "567343": 53, "19824": 53, "888804": 53, "7155": 53, "563528": 53, "770556": 53, "596069e": 53, "5800": 53, "242000": 53, "20055": 53, "810363": 53, "10406": 53, "538013": 53, "927232": 53, "395076e": 53, "629346": 53, "11617": 53, "747961": 53, "12814": 53, "598178": 53, "17499": 53, "674552": 53, "20010": 53, "821457": 53, "18030": 53, "782555": 53, "19793": 53, "313324": 53, "22528": 53, "377060": 53, "16951": 53, "835596": 53, "18141": 53, "748880": 53, "19756": 53, "503511": 53, "21142": 53, "356183": 53, "22937": 53, "907961": 53, "24917": 53, "562518": 53, "27487": 53, "587292": 53, "30527": 53, "927950": 53, "33849": 53, "535609": 53, "40452": 53, "250073": 53, "data_cvar": 53, "df_cvar": 53, "6266": 53, "876549": 53, "11879": 53, "514545": 53, "7161": 53, "132903": 53, "13091": 53, "167765": 53, "11375": 53, "506659": 53, "17799": 53, "271083": 53, "13490": 53, "425208": 53, "20329": 53, "801623": 53, "11120": 53, "553916": 53, "18368": 53, "833464": 53, "12323": 53, "713986": 53, "20158": 53, "728852": 53, "14406": 53, "422266": 53, "22925": 53, "706056": 53, "8350": 53, "475304": 53, "17372": 53, "617283": 53, "8679": 53, "920335": 53, "18604": 53, "624988": 53, "9274": 53, "886266": 53, "20269": 53, "268055": 53, "9395": 53, "942823": 53, "21716": 53, "995015": 53, "9605": 53, "860992": 53, "23590": 53, "116569": 53, "9480": 53, "749443": 53, "25672": 53, "737052": 53, "9197": 53, "541990": 53, "28382": 53, "342989": 53, "7957": 53, "409328": 53, "31632": 53, "085965": 53, "4357": 53, "479860": 53, "35292": 53, "297749": 53, "2438": 53, "879049": 53, "42550": 53, "499776": 53, "float32": [53, 56], "dml_lqte": [53, 55], "2610": 53, "487": 53, "701966": 53, "351629": 53, "716595e": 53, "1654": 53, "121711": 53, "1773": 53, "357": 53, "148790": 53, "964318": 53, "894307e": 53, "1073": 53, "001234": 53, "1398": 53, "526532": 53, "616828": 53, "982353e": 53, "640": 53, "421919": 53, "1435": 53, "384": 53, "956574": 53, "727693": 53, "932404e": 53, "680": 53, "498979": 53, "1400": 53, "977295": 53, "203828": 53, "356136e": 53, "540240": 53, "2500": 53, "877153": 53, "134765": 53, "824961e": 53, "1545": 53, "738315": 53, "3985": 53, "596": 53, "725087": 53, "678117": 53, "420316e": 53, "2815": 53, "440320": 53, "5175": 53, "739": 53, "897240": 53, "994214": 53, "667492e": 53, "3724": 53, "828058": 53, "7239": 53, "751013": 53, "331602": 53, "042822e": 53, "5718": 53, "555954": 53, "9500": 53, "1109": 53, "023955": 53, "566091": 53, "070574e": 53, "7326": 53, "352990": 53, "11750": 53, "1295": 53, "711518": 53, "068377": 53, "208034e": 53, "9210": 53, "452091": 53, "14625": 53, "1443": 53, "080854": 53, "134567": 53, "880880e": 53, "11796": 53, "613498": 53, "16984": 53, "1576": 53, "564577": 53, "772791": 53, "627588e": 53, "13893": 53, "990210": 53, "19758": 53, "2865": 53, "426736": 53, "895308": 53, "374821e": 53, "14141": 53, "866798": 53, "23856": 53, "2281": 53, "099670": 53, "458114": 53, "345065e": 53, "19385": 53, "126802": 53, "27751": 53, "3151": 53, "771741": 53, "804889": 53, "309823e": 53, "21573": 53, "640900": 53, "30645": 53, "4634": 53, "200110": 53, "612792": 53, "771390e": 53, "21562": 53, "134687": 53, "3565": 53, "878289": 53, "2472": 53, "998766": 53, "2155": 53, "578081": 53, "2189": 53, "501021": 53, "2256": 53, "459760": 53, "3454": 53, "261685": 53, "5154": 53, "559680": 53, "6625": 53, "171942": 53, "8759": 53, "444046": 53, "11673": 53, "647010": 53, "14289": 53, "547909": 53, "17453": 53, "386502": 53, "20074": 53, "009790": 53, "25374": 53, "133202": 53, "28326": 53, "873198": 53, "33928": 53, "359100": 53, "39727": 53, "865313": 53, "ci_lqt": [53, 55], "data_lqt": 53, "df_lqte": 53, "1255": 53, "980026": 53, "3964": 53, "019974": 53, "781": 53, "438289": 53, "2764": 53, "561711": 53, "876083": 53, "2471": 53, "123917": 53, "366": 53, "234798": 53, "2503": 53, "765202": 53, "186": [53, 74], "808284": 53, "2613": 53, "191716": 53, "1148": 53, "269977": 53, "3851": 53, "730023": 53, "2328": 53, "296228": 53, "5641": 53, "703772": 53, "3120": 53, "803563": 53, "7229": 53, "196437": 53, "5085": 53, "261777": 53, "9392": 53, "738223": 53, "6420": 53, "987220": 53, "12579": 53, "012780": 53, "8152": 53, "681562": 53, "15347": 53, "318438": 53, "10618": 53, "536143": 53, "18631": 53, "463857": 53, "12606": 53, "941724": 53, "21361": 53, "058276": 53, "11802": 53, "639345": 53, "27713": 53, "360655": 53, "17522": 53, "922160": 53, "30189": 53, "077840": 53, "19000": 53, "652071": 53, "36501": 53, "347929": 53, "17778": 53, "946658": 53, "43511": 53, "053342": 53, "py_double_ml_policy_tre": 54, "determinist": [54, 62], "enabl": [54, 56, 62, 68, 74], "cut": 54, "off": [54, 73], "opposit": 54, "group_effect": 54, "d_w": 54, "land": 54, "create_synthetic_group_data": 54, "n_sampl": 54, "n_w": 54, "support_w": 54, "replac": [54, 74], "coefs_w": 54, "nois": 54, "epsilon_sampl": 54, "matric": [54, 61, 74], "support_t": 54, "coefs_t": 54, "eta_sampl": 54, "apply_along_axi": 54, "arr": 54, "log_odd": 54, "t_sigmoid": 54, "t_df": 54, "w_df": 54, "calcualt": 54, "0x2920d7b7150": 54, "domain": 54, "428046": 54, "742407": 54, "600254": 54, "947440": 54, "265119": 54, "091992": 54, "346678": 54, "880591": 54, "508153": 54, "099647": 54, "495": 54, "072293": 54, "951920": 54, "144908": 54, "280963": 54, "497": 54, "877455": 54, "404550": 54, "498": 54, "981104": 54, "830301": 54, "555445": 54, "021866": 54, "plot_tre": [54, 62], "reflect": [54, 62], "exemplatori": 54, "292": 54, "jump": 54, "policy_tree_2": 54, "policytre": 54, "pred_df": 54, "pred_treat": 54, "155516": 54, "570111": 54, "216761": 54, "389566": 54, "764478": 54, "111164": 54, "411291": 54, "984024": 54, "324518": 54, "675293": 54, "728294": 54, "018023": 54, "632958": 54, "557731": 54, "161198": 54, "661369": 54, "351766": 54, "523807": 54, "366529": 54, "310761": 54, "overal": 54, "treament": 54, "showcas": 54, "data_dml_new": 54, "dml_irm_new": 54, "to_fram": 54, "natt": 54, "192505": 54, "177463": 54, "547431": 54, "712157": 54, "982797": 54, "253437": 54, "py_double_ml_pq": 55, "analyt": 55, "33014346": 55, "71465114": 55, "21155656": 55, "77348822": 55, "37436439": 55, "00000591": 55, "64197957": 55, "29548121": 55, "04653976": 55, "38866808": 55, "73608412": 55, "09347419": 55, "46811985": 55, "8685788": 55, "30982972": 55, "81568484": 55, "43597565": 55, "23789633": 55, "53947541": 55, "97276281": 55, "48208358": 55, "03698487": 55, "62131806": 55, "22522221": 55, "15891559": 55, "53724023": 55, "91724807": 55, "30361321": 55, "7018663": 55, "12046836": 55, "56965663": 55, "06724028": 55, "64154727": 55, "35341202": 55, "330143": 55, "237896": 55, "408565": 55, "128312": 55, "813293": 55, "714651": 55, "539475": 55, "855780": 55, "495752": 55, "245512": 55, "211557": 55, "972763": 55, "345903": 55, "978977": 55, "638264": 55, "773488": 55, "482084": 55, "924002": 55, "533900": 55, "189737": 55, "374364": 55, "036985": 55, "482483": 55, "148161": 55, "683942": 55, "000006": 55, "621318": 55, "246879": 55, "700102": 55, "509196": 55, "641980": 55, "225222": 55, "932973": 55, "291406": 55, "244455": 55, "295481": 55, "158916": 55, "665264": 55, "145245": 55, "949456": 55, "046540": 55, "537240": 55, "077319": 55, "496551": 55, "411582": 55, "388668": 55, "917248": 55, "378834": 55, "760104": 55, "070020": 55, "736084": 55, "303613": 55, "479928": 55, "216344": 55, "168614": 55, "093474": 55, "701866": 55, "059384": 55, "655284": 55, "677614": 55, "468120": 55, "120468": 55, "544097": 55, "036147": 55, "215342": 55, "868579": 55, "569657": 55, "700015": 55, "493219": 55, "400823": 55, "309830": 55, "067240": 55, "187690": 55, "988463": 55, "872768": 55, "815685": 55, "641547": 55, "631333": 55, "542647": 55, "226524": 55, "435976": 55, "353412": 55, "113207": 55, "243246": 55, "753523": 55, "003836": 55, "448745": 55, "807879": 55, "466047": 55, "687345": 55, "304159": 55, "053541": 55, "177496": 55, "780458": 55, "658267": 55, "684502": 55, "383297": 55, "281024": 55, "319759": 55, "976562": 55, "984562": 55, "844707": 55, "555498": 55, "621490": 55, "428255": 55, "154557": 55, "381072": 55, "015698": 55, "274793": 55, "256944": 55, "367625": 55, "625477": 55, "687647": 55, "627560": 55, "892648": 55, "791241": 55, "088048": 55, "344640": 55, "441153": 55, "524657": 55, "785911": 55, "872852": 55, "907115": 55, "165178": 55, "999207": 55, "360004": 55, "626433": 55, "502612": 55, "857161": 55, "119766": 55, "036143": 55, "408539": 55, "676756": 55, "472891": 55, "098712": 55, "387780": 55, "267950": 55, "231986": 55, "155025": 55, "480800e": 55, "186735": 55, "722634": 55, "293218": 55, "190982": 55, "535318": 55, "247057e": 55, "081100": 55, "667536": 55, "388071": 55, "167547": 55, "316193": 55, "054771e": 55, "059685": 55, "716456": 55, "406285": 55, "161243": 55, "519710": 55, "174516e": 55, "090255": 55, "722316": 55, "466756": 55, "151819": 55, "074426": 55, "109079e": 55, "169196": 55, "764315": 55, "606129": 55, "149285": 55, "060201": 55, "903056e": 55, "313535": 55, "898722": 55, "708459": 55, "158007": 55, "483711": 55, "335609e": 55, "398770": 55, "018148": 55, "725166": 55, "156021": 55, "647873": 55, "353748e": 55, "419371": 55, "030962": 55, "509461": 55, "164608": 55, "094999": 55, "968134e": 55, "186836": 55, "832086": 55, "488811": 55, "161236": 55, "031639": 55, "432300e": 55, "172793": 55, "804828": 55, "542989": 55, "162153": 55, "348617": 55, "121584e": 55, "225175": 55, "860804": 55, "699035": 55, "190809": 55, "663529": 55, "487641e": 55, "325056": 55, "073013": 55, "516528": 55, "195377": 55, "643752": 55, "199281e": 55, "133596": 55, "899460": 55, "685107": 55, "245062": 55, "795647": 55, "179588e": 55, "204794": 55, "165419": 55, "893851": 55, "222843": 55, "011131": 55, "042844e": 55, "457088": 55, "330615": 55, "896023": 55, "209894": 55, "268942": 55, "964025e": 55, "484640": 55, "307407": 55, "229443": 55, "177995": 55, "907176": 55, "943949e": 55, "880579": 55, "578307": 55, "jointli": [55, 62], "ci_joint_qt": 55, "399692": 55, "935591": 55, "256416": 55, "842853": 55, "094118": 55, "870260": 55, "057762": 55, "870332": 55, "029831": 55, "903681": 55, "176495": 55, "035762": 55, "253724": 55, "163194": 55, "276148": 55, "174185": 55, "035730": 55, "983192": 55, "024782": 55, "952839": 55, "076322": 55, "009656": 55, "149898": 55, "248171": 55, "045754": 55, "078810": 55, "020166": 55, "390379": 55, "252524": 55, "535179": 55, "291963": 55, "500084": 55, "717185": 55, "741702": 55, "092247": 55, "175176": 55, "238794": 55, "291405": 55, "337380": 55, "378688": 55, "416757": 55, "454397": 55, "490700": 55, "528580": 55, "567529": 55, "608392": 55, "652349": 55, "701078": 55, "757411": 55, "825862": 55, "917436": 55, "conf": 55, "5z_i": 55, "3x_": 55, "7x": 55, "2x": 55, "4x": 55, "x_conf": 55, "generate_treat": 55, "x_conf_tru": 55, "z_true": 55, "eta_tru": 55, "d1_true": 55, "ones_lik": 55, "d0_true": 55, "zeros_lik": 55, "complianc": [55, 66], "n_complier": 55, "3245837": 55, "07538443": 55, "53606675": 55, "10878571": 55, "74402577": 55, "41805621": 55, "11724226": 55, "83287529": 55, "56018481": 55, "29299726": 55, "02900983": 55, "76228406": 55, "4895498": 55, "20400735": 55, "10089588": 55, "43453524": 55, "81827267": 55, "29107127": 55, "19031969": 55, "53273833": 55, "01574297": 55, "57245066": 55, "17700723": 55, "81190107": 55, "46807543": 55, "13585644": 55, "1881752": 55, "51214922": 55, "84030318": 55, "17655394": 55, "53094017": 55, "91102953": 55, "33175566": 55, "81828926": 55, "4284675": 55, "doublemllpq": [55, 62, 66, 74], "lpq_0": 55, "lpq_1": 55, "ci_lpq_0": 55, "ci_lpq_1": 55, "dml_lpq_0": 55, "dml_lpq_1": 55, "075384": 55, "190320": 55, "231310": 55, "306963": 55, "976088": 55, "536067": 55, "532738": 55, "188223": 55, "826492": 55, "009122": 55, "108786": 55, "015743": 55, "641528": 55, "935730": 55, "164801": 55, "744026": 55, "572451": 55, "387426": 55, "590813": 55, "838114": 55, "418056": 55, "177007": 55, "927074": 55, "878281": 55, "301371": 55, "117242": 55, "811901": 55, "799403": 55, "583534": 55, "155120": 55, "832875": 55, "468075": 55, "564045": 55, "134211": 55, "923607": 55, "560185": 55, "135856": 55, "412127": 55, "023256": 55, "765792": 55, "292997": 55, "188175": 55, "144669": 55, "317487": 55, "566024": 55, "029010": 55, "512149": 55, "970065": 55, "516255": 55, "441209": 55, "762284": 55, "840303": 55, "649158": 55, "793570": 55, "180951": 55, "489550": 55, "176554": 55, "355209": 55, "556792": 55, "919432": 55, "204007": 55, "530940": 55, "077883": 55, "742907": 55, "742128": 55, "100896": 55, "911030": 55, "354371": 55, "995248": 55, "379614": 55, "434535": 55, "331756": 55, "692725": 55, "562013": 55, "009986": 55, "818273": 55, "818289": 55, "842746": 55, "720571": 55, "146037": 55, "291071": 55, "428467": 55, "196189": 55, "946433": 55, "145625": 55, "486532": 55, "867565": 55, "746361": 55, "367323": 55, "883622": 55, "769361": 55, "118255": 55, "724338": 55, "147121": 55, "936739": 55, "377311": 55, "804316": 55, "552776": 55, "563503": 55, "193060": 55, "443686": 55, "182633": 55, "015565": 55, "204482": 55, "728710": 55, "460289": 55, "058463": 55, "559522": 55, "606034": 55, "723314": 55, "260360": 55, "895333": 55, "498921": 55, "098319": 55, "130829": 55, "117366": 55, "070884": 55, "516256": 55, "209014": 55, "793735": 55, "319850": 55, "586362": 55, "973241": 55, "512572": 55, "088357": 55, "168931": 55, "821566": 55, "375465": 55, "685807": 55, "438219": 55, "539455": 55, "827735": 55, "613408": 55, "246753": 55, "889733": 55, "003134": 55, "often": 55, "103497": 55, "463325": 55, "381689": 55, "723345e": 55, "195396": 55, "011598": 55, "052502": 55, "590736": 55, "781681": 55, "480133e": 55, "105318": 55, "210323": 55, "707868": 55, "411295": 55, "721071": 55, "523794e": 55, "098256": 55, "513992": 55, "931479": 55, "427725": 55, "177751": 55, "942460e": 55, "093153": 55, "769805": 55, "182849": 55, "326740": 55, "620156": 55, "944253e": 55, "542451": 55, "823247": 55, "220772": 55, "297682": 55, "100923": 55, "115060e": 55, "637326": 55, "804219": 55, "369796": 55, "292105": 55, "689392": 55, "740180e": 55, "797280": 55, "942312": 55, "403425": 55, "287041": 55, "889293": 55, "011988e": 55, "840836": 55, "966015": 55, "500517": 55, "283974": 55, "283994": 55, "263974e": 55, "943938": 55, "057095": 55, "642016": 55, "304130": 55, "399056": 55, "699259e": 55, "045932": 55, "238101": 55, "502995": 55, "350518": 55, "287926": 55, "803492e": 55, "815993": 55, "189998": 55, "901148": 55, "335846": 55, "660776": 55, "506900e": 55, "242902": 55, "559394": 55, "827381": 55, "331521": 55, "512108": 55, "545605e": 55, "177611": 55, "477150": 55, "844308": 55, "339570": 55, "431306": 55, "594316e": 55, "178763": 55, "509853": 55, "916914": 55, "305775": 55, "269043": 55, "632747e": 55, "317607": 55, "516222": 55, "087947": 55, "346206": 55, "030934": 55, "630150e": 55, "409395": 55, "766499": 55, "250354": 55, "536746": 55, "192587": 55, "757917e": 55, "198351": 55, "302357": 55, "ci_joint_lqt": 55, "206614": 55, "413608": 55, "617877": 55, "722881": 55, "455120": 55, "870857": 55, "277968": 55, "140926": 55, "258951": 55, "106746": 55, "379038": 55, "062507": 55, "543832": 55, "195761": 55, "591782": 55, "215069": 55, "697545": 55, "303489": 55, "782050": 55, "501983": 55, "511862": 55, "494129": 55, "951502": 55, "850794": 55, "889963": 55, "764798": 55, "884132": 55, "804484": 55, "052298": 55, "781530": 55, "109005": 55, "066889": 55, "732638": 55, "768071": 55, "885065": 55, "003328": 55, "093043": 55, "171575": 55, "241049": 55, "305341": 55, "364800": 55, "424328": 55, "481172": 55, "541159": 55, "602587": 55, "666104": 55, "734948": 55, "810134": 55, "897220": 55, "000017": 55, "137396": 55, "py_double_ml_sensit": 56, "partiallli": 56, "2022": [56, 64, 68, 70, 73], "qualiti": [56, 58, 74], "make_confounded_plr_data": 56, "proport": [56, 68], "measir": 56, "porport": 56, "dpg_dict": 56, "dml_obj": 56, "82684324": 56, "11552911": 56, "130122": 56, "455448": 56, "06827": 56, "209219e": 56, "237461": 56, "022783": 56, "conserv": [56, 68], "098308": 56, "832693": 56, "427551": 56, "192526": 56, "287815": 56, "784405": 56, "8326928": 56, "42755087": 56, "44647451": 56, "46507214": 56, "09830758": 56, "19252647": 56, "34287815": 56, "29784405": 56, "awai": 56, "prespecifi": 56, "397811": 56, "100858": 56, "159386": 56, "967467": 56, "520641": 56, "168195": 56, "data_dml": 56, "learner_l": 56, "learner_m": 56, "54163": 56, "99232145": 56, "54716": 56, "48029755": 56, "54378": 56, "6810775": 56, "44435333": 56, "44408333": 56, "44482929": 56, "8843": 56, "744236": 56, "1349": 56, "765864": 56, "552058": 56, "674949e": 56, "6240": 56, "066464": 56, "11447": 56, "422007": 56, "2258": 56, "287384": 56, "4567": 56, "712503": 56, "13119": 56, "775969": 56, "15375": 56, "33527": 56, "014681": 56, "162587": 56, "sens": 56, "characterist": [56, 75], "render": 56, "insignific": 56, "hard": [56, 68], "common": [56, 62, 64, 73], "guess": [56, 68], "omit": [56, 68, 73, 74, 75], "separ": [56, 63, 74], "seper": [56, 65, 67, 68], "repet": 56, "therefor": [56, 65, 66, 68], "benchmark_inc": 56, "benchmark_pira": 56, "benchmark_twoearn": 56, "13956": 56, "046728": 56, "358395": 56, "3696": 56, "252253": 56, "05039": 56, "002779": 56, "214764": 56, "338": 56, "70583": 56, "011823": 56, "000743": 56, "804284": 56, "278": 56, "905951": 56, "48296": 56, "97470872": 56, "48331": 56, "30093956": 56, "48315": 56, "49650883": 56, "64723": 56, "28425026": 56, "64340": 56, "98393441": 56, "64797": 56, "07479278": 56, "44427868": 56, "44414044": 56, "4448089": 56, "7710": 56, "567004": 56, "1170": 56, "174106": 56, "589248": 56, "420608e": 56, "5382": 56, "346238": 56, "10038": 56, "78777": 56, "1306": 56, "608818": 56, "3593": 56, "56223": 56, "11935": 56, "392833": 56, "14114": 56, "64269": 56, "240295": 56, "339273": 56, "110681": 56, "4093": 56, "849747": 56, "055165": 56, "010213": 56, "07961": 56, "205": 56, "322404": 56, "013593": 56, "127563": 56, "032953": 56, "421793": 56, "py_double_ml_ssm": 57, "attrit": [57, 64], "upsilon_i": 57, "xi_i": 57, "nu_i": 57, "a_": 57, "upsilon": 57, "pmatrix": 57, "resembl": 57, "quadrat": 57, "decai": 57, "beta_": 57, "make_ssm_data": [57, 64], "1999": 57, "doublemlssm": [57, 64, 66], "penal": 57, "ml_pi": [57, 64], "satisfi": [57, 63, 66, 67], "dml_ssm": [57, 64], "ml_g_d0": [57, 64], "10039862": [57, 64], "ml_g_d1": [57, 64], "11071087": [57, 64], "42388745": [57, 64], "47222159": [57, 64], "997494": 57, "03113": 57, "0428": 57, "765710e": 57, "225": [57, 74], "93648": 57, "058508": 57, "94629": 57, "048699": 57, "ate_estim": 57, "strong": [57, 68], "acycl": [57, 75], "dag": [57, 75], "leav": 57, "intrument": 57, "7999": 57, "he": 57, "pi_i": [57, 64], "01990373": 57, "19983954": 57, "37231324": 57, "43374433": 57, "923517": 57, "037509": 57, "620995": 57, "528381e": 57, "997034": 57, "And": [57, 68], "come": [58, 63, 66, 68, 70, 75], "deprec": [58, 65], "summar": [58, 68], "eta_0": [58, 66, 67], "mapsto": [58, 62], "solut": [58, 62, 66], "aggreg": [58, 65, 74], "48025158": [58, 66, 67], "54287532563466": 58, "textbf": [58, 63, 75], "5428753": 58, "01128689": [58, 66], "0036984": [58, 66], "00136267": [58, 66], "11932146": [58, 66], "29951284": [58, 66], "all_dml1_coef": 58, "0007846231543724570": 58, "7831243849103790": 58, "00902031947837708": 58, "4035699755140420": 58, "867033752141195": 58, "000784623154372457": 58, "783124384910379": 58, "403569975514042": 58, "0007846232": 58, "7831243849": 58, "0090203195": 58, "4035699755": 58, "8670337521": 58, "7086950268607550": 58, "5093396933893620": 58, "4652126999576090": 58, "4958502164268730": 58, "535278991538703": 58, "708695026860755": 58, "509339693389362": 58, "465212699957609": 58, "495850216426873": 58, "708695": 58, "5093397": 58, "4652127": 58, "4958502": 58, "535279": 58, "brief": 59, "motiv": 59, "complet": [59, 68, 71], "galleri": [59, 62, 63, 64, 70, 74], "semi": 59, "parametr": [59, 63, 75], "931": 59, "1912705": 59, "dt_bonu": 60, "lllllllllllllllll": [60, 72], "hline": [60, 67, 69, 72, 75], "143": [60, 62, 74], "serv": [60, 72, 74], "api": [60, 70, 74], "obj_dml_data_bonu": 60, "dat": 60, "obj_dml_data_bonus_df": 60, "comment": 60, "standard_norm": [60, 63, 67, 69, 72], "obj_dml_data_sim": 60, "102": [60, 62, 72, 74], "398": [60, 72], "overcom": [61, 66], "induc": [61, 65], "overfit": [61, 65], "dml1": [61, 72, 74, 75], "band": [61, 75], "simultan": [61, 75], "advanc": [61, 65, 73], "theta_": [62, 67, 68, 69], "g_k": 62, "gate_obj": 62, "group_0": 62, "287186": 62, "692300": 62, "097415": 62, "925119": 62, "098433": 62, "728253": 62, "136062": 62, "572424": 62, "008785": 62, "498119": 62, "644565": 62, "791012": 62, "247555": 62, "395402": 62, "543248": 62, "451385": 62, "593896": 62, "736407": 62, "191397": 62, "782646": 62, "025958": 62, "342467": 62, "653991": 62, "460535": 62, "511022": 62, "456552": 62, "543358": 62, "046405": 62, "778852": 62, "174743": 62, "cate_obj": 62, "142292": 62, "646079": 62, "149866": 62, "492968": 62, "698898": 62, "095172": 62, "143246": 62, "929154": 62, "284938": 62, "025685": 62, "014572": 62, "003459": 62, "564720": 62, "125526": 62, "815772": 62, "59": [62, 63, 64, 65, 67, 75], "61": [62, 63, 64, 65, 67, 74], "66": [62, 63, 64, 65, 67, 72, 74], "71": [62, 63, 64, 65, 67, 74], "72": [62, 63, 64, 65, 67, 74], "391971": 62, "548740": 62, "705509": 62, "433640": 62, "600482": 62, "767324": 62, "381653": 62, "587828": 62, "794002": 62, "438942": 62, "570852": 62, "702763": 62, "419818": 62, "592956": 62, "766095": 62, "theori": [62, 73], "agebra": 62, "subseteq": 62, "arg": 62, "min_": 62, "approx": 62, "meant": [62, 74], "simplest": 62, "76": [62, 63, 64, 65, 67, 73, 74], "77": [62, 63, 64, 65, 67], "79": [62, 63, 64, 65, 74], "82": [62, 63, 64, 65, 74], "83": [62, 63, 64, 65, 74], "86": [62, 63, 64, 65, 74], "054636": [62, 63, 64], "660914": [62, 63, 64], "082667": [62, 63, 64], "934116": [62, 63, 64], "240732": [62, 63, 64], "350004": [62, 63, 64], "involv": [62, 63, 66, 75], "identifii": 62, "gatet": 62, "simplifi": [62, 68], "accept": [62, 63], "conduct": [62, 64, 75], "91": [62, 63, 64, 65, 74], "92": [62, 64, 65, 74], "108": [62, 70, 73, 74], "327341": 62, "548862": 62, "5964": 62, "550908": 62, "748408": 62, "403091": 62, "lqte": 62, "110": [62, 74], "111": [62, 74], "114": [62, 65, 74], "115": [62, 74], "116": [62, 74], "118": 62, "119": [62, 74], "cdf": 62, "124": 62, "125": [62, 74], "127": [62, 74], "585192": 62, "096897": 62, "359623": 62, "714182e": 62, "395278": 62, "775106": 62, "131": [62, 74], "138": [62, 74], "139": [62, 72], "473428": 62, "244647": 62, "935145": 62, "297245e": 62, "006072": 62, "952927": 62, "694323": 62, "142952": 62, "857027": 62, "191614e": 62, "414142": 62, "974505": 62, "001638": 62, "165765": 62, "042534": 62, "517128e": 62, "676745": 62, "326530": 62, "mathop": 62, "limits_": 62, "thu": 62, "rule": 62, "maximum": [62, 63], "142": [62, 74], "145": [62, 74], "146": [62, 74], "147": [62, 74], "148": [62, 74], "149": [62, 74], "151": [62, 74], "152": [62, 74], "153": [62, 74], "154": 62, "155": [62, 74], "156": [62, 74], "305133": 62, "497298": 62, "811398": 62, "696770": 62, "717860": 62, "030087": 62, "903135": 62, "174940": 62, "185585": 62, "095475": 62, "653820": 62, "800272": 62, "198953": 62, "203893": 62, "204653": 62, "157": [62, 74], "policy_tree_obj": 62, "158": [62, 74], "Such": 63, "variou": [63, 75], "meta": [63, 72], "doublemlpliv": [63, 64, 65, 66, 70, 74], "506368": 63, "046011": 63, "005397": 63, "599252e": 63, "416188": 63, "596547": 63, "52259": 63, "04767": 63, "962742": 63, "772317e": 63, "429159": 63, "616021": 63, "031134": 63, "071777": 63, "229759": 63, "890454": 63, "171815": 63, "4000000000000001": 63, "09000000000000001": 63, "96582": 63, "086679": 63, "216207": 63, "388216e": 63, "795932": 63, "135707": 63, "sophist": 63, "along": 63, "path": [63, 64], "ml_l_tune": 63, "ml_m_tune": 63, "4311947070055128": 63, "14281403493938022": 63, "048723": 63, "075869": 63, "183855": 63, "900021": 63, "197424": 63, "plm": [63, 67, 68, 75], "0x7f9c6047a610": 63, "17559653": 63, "03262702": 63, "evalut": 63, "95690813": 63, "extens": [63, 66, 70, 73, 74], "care": 63, "inter": 63, "0x7f9c60a32760": 63, "pred_dict": 63, "dmldummyregressor": 63, "dmldummyclassifi": 63, "dml_irm_obj_ext": 63, "0x7f9c5a529880": 63, "undesir": 63, "extend": [63, 70, 74], "sure": [63, 74], "mlr3pipelin": [63, 74], "57505": 63, "04458": 63, "set_fold_specif": 63, "58765": 63, "04532": 63, "innermost": 63, "overrid": [63, 74], "previous": [63, 75], "assert": 63, "thread": 63, "_l": 63, "_m": [63, 65], "5249": 63, "0459": 63, "params_exact": 63, "49098": 63, "single_learner_pipelin": 63, "ensemble_learner_pipelin": 63, "distr": 63, "marshal": 63, "55173": 63, "04631": 63, "manag": [63, 71], "budget": 63, "tuner": 63, "wrapper": 63, "anneal": 63, "holdout": [63, 65], "ratio": [63, 65, 68], "percent": 63, "match": [63, 68], "subfold": 63, "paramset": 63, "paramdbl": 63, "0777777777777778": 63, "0425": 63, "1424": 63, "built": [63, 70], "08848": 63, "chunk": 63, "paramint": 63, "random_search": 63, "55348": 63, "04559": 63, "present": [63, 75], "18346131": 64, "0600811": 64, "514216": [64, 68], "044875": 64, "458956": 64, "120543e": 64, "426263": 64, "47659": 64, "04166": 64, "48355347": 64, "53188141": 64, "25181913": 64, "481267": 64, "084945": 64, "66564": 64, "464764e": 64, "314778": 64, "647756": 64, "66184": 64, "07786": 64, "09392932": 64, "12503777": 64, "41702876": 64, "6695": 64, "2097": 64, "192": [64, 74], "00141": 64, "12996326": 64, "13192169": 64, "50173922": 64, "ml_r0": 64, "50003363": 64, "3622318": 64, "38853": 64, "231437": 64, "678769": 64, "093197": 64, "065079": 64, "842139": 64, "3569": 64, "793": 64, "073": 64, "untreat": 64, "receiv": 64, "until": [64, 74], "cond": 64, "exist": [64, 68], "recent": 64, "literatur": 64, "roth": 64, "iid": 64, "doublemlidid": 64, "z2": 64, "z3": 64, "z4": 64, "27429763": 64, "35731523": 64, "48584006": 64, "840718": 64, "760386": 64, "613691": 64, "106595": 64, "291011": 64, "609575": 64, "stationari": 64, "invari": 64, "doublemlididc": 64, "4915707": 64, "85397773": 64, "74938952": 64, "7282094": 64, "49203859": 64, "9944": 64, "561785": 64, "660479": 64, "508947": 64, "815226": 64, "826426": 64, "subpopul": 64, "realiz": 64, "perp": 64, "assmput": 64, "made": [64, 75], "context": [64, 75], "correpond": 64, "0x7f9c5a4efa30": 64, "965531": 64, "065969": 64, "636048": 64, "654070e": 64, "836234": 64, "094829": 64, "attrict": 64, "realat": 64, "identif": [64, 75], "neq": 64, "unknown": 64, "scalar": 64, "strictli": 64, "monoton": 64, "cumul": 64, "homogen": 64, "0x7f9c60de7d30": 64, "92827999": 64, "10079785": 64, "37743524": 64, "45143571": 64, "14268": 64, "183373": 64, "231467": 64, "620874e": 64, "783276": 64, "502084": 64, "central": [65, 74], "251638454647506668697273787981848993100711131415171824273551536067858690929596389101920222333394855565871747582919814122530314042444952646570767780879799": 65, "621262829323436374143545759616263838894711131415171824273551536067858690929596389101920222333394855565871747582919814122530314042444952646570767780879799": 65, "621262829323436374143545759616263838894251638454647506668697273787981848993100389101920222333394855565871747582919814122530314042444952646570767780879799": 65, "62126282932343637414354575961626383889425163845464750666869727378798184899310071113141517182427355153606785869092959614122530314042444952646570767780879799": 65, "6212628293234363741435457596162638388942516384546475066686972737879818489931007111314151718242735515360678586909295963891019202223333948555658717475829198": 65, "621262829323436374143545759616263838894": 65, "251638454647506668697273787981848993100": 65, "711131415171824273551536067858690929596": 65, "3891019202223333948555658717475829198": 65, "14122530314042444952646570767780879799": 65, "_id": 65, "psi_el": [65, 66], "81676552e": 65, "56414991e": 65, "18956777e": 65, "92738338e": 65, "83772121e": 65, "40976446": 65, "1688736": 65, "06896522": 65, "00804723": 65, "61077157": 65, "05660173": 65, "71282884": 65, "03199446": 65, "03741200": 65, "75116589": 65, "31664348": 65, "49450893": 65, "03713702": 65, "02888635": 65, "56265968": 65, "singleton": 65, "75490070e": 65, "41046758e": 65, "30057541e": 65, "84698342e": 65, "43985220e": 65, "48134201e": 65, "76481851e": 65, "35664442e": 65, "73792324e": 65, "59224373e": 65, "94576968e": 65, "58969994e": 65, "55676843e": 65, "49426619e": 65, "37648108e": 65, "50168661e": 65, "22543208e": 65, "22021494e": 65, "85400337e": 65, "51688163e": 65, "86109800e": 65, "06587889e": 65, "14026461e": 65, "15093765e": 65, "15055603e": 65, "40346195e": 65, "36994549e": 65, "70372751e": 65, "58359745e": 65, "55802542e": 65, "75087861e": 65, "04862071e": 65, "44349653e": 65, "90481011e": 65, "65583829e": 65, "46873669e": 65, "86709699e": 65, "64509433e": 65, "44940659e": 65, "90090862e": 65, "30174871e": 65, "17270587e": 65, "72245056e": 65, "77260527e": 65, "06534446e": 65, "18323415e": 65, "84307870e": 65, "86429142e": 65, "98316935e": 65, "27227828e": 65, "28378624": 65, "24084412": 65, "1018566": 65, "40081686": 65, "43963575": 65, "3872246": 65, "02147332": 65, "13683567": 65, "29446732": 65, "37594642": 65, "01968693": 65, "4900045": 65, "33823902": 65, "39842187": 65, "12067512": 65, "10956349": 65, "82152436": 65, "40255781": 65, "08036685": 65, "00298768": 65, "03132564": 65, "06366163": 65, "01874402": 65, "00511567": 65, "04258852": 65, "00332808": 65, "05211249": 65, "00557391": 65, "10301607": 65, "03437452": 65, "01397145": 65, "02567156": 65, "04625777": 65, "05247536": 65, "0972051": 65, "00396731": 65, "03634815": 65, "13911694": 65, "00847932": 65, "02628082": 65, "58456203": 65, "83112225": 65, "89529699": 65, "71005405": 65, "97301552": 65, "97344746": 65, "65843094": 65, "24245294": 65, "80014581": 65, "1556604": 65, "06547148": 65, "05144261": 65, "04356419": 65, "1176960": 65, "0002741582": 65, "01860714": 65, "14522580": 65, "04817087": 65, "79660931": 65, "3687492": 65, "2781441438": 65, "19504698": 65, "22014064": 65, "02594509": 65, "20907519": 65, "3103751": 65, "1140585409": 65, "70661468": 65, "31457723": 65, "16414924": 65, "04442090": 65, "1761613": 65, "5322927154": 65, "16642137": 65, "64342303": 65, "72804480": 65, "04820660": 65, "4772708": 65, "7874741997": 65, "14096924": 65, "15295711": 65, "2068054": 65, "12138623": 65, "00573154": 65, "71404629": 65, "6348454": 65, "04552211": 65, "42045737": 65, "09528739": 65, "8577317": 65, "24878606": 65, "06345646": 65, "00369015": 65, "4536280": 65, "33566284": 65, "11829941": 65, "85498280": 65, "2698901": 65, "14627563": 65, "65091944": 65, "4527243": 65, "34102760": 65, "3152684": 65, "50792096": 65, "02460591": 65, "20099611": 65, "7114062": 65, "41134085": 65, "1608098": 65, "12088788": 65, "11151604": 65, "95045930": 65, "7691131": 65, "10039761": 65, "5109568": 65, "09260140": 65, "06386615": 65, "21650328": 65, "3191498": 65, "03515763": 65, "1150055": 65, "08831552": 65, "11473770": 65, "01059602": 65, "3369922": 65, "46434509": 65, "1070822": 65, "65952233": 65, "77480282": 65, "97020291": 65, "82561855": 65, "93282273": 65, "55716289": 65, "11500276": 65, "60333028": 65, "40956854": 65, "39182104": 65, "31227847": 65, "04499133": 65, "52804584": 65, "75516040": 65, "05286799": 65, "01426441": 65, "07996184": 65, "01840774": 65, "05939763": 65, "35717774": 65, "61328725": 65, "58040032": 65, "42545202": 65, "median": 65, "45939615": 65, "08026436": 65, "4367802": 65, "09072822": 65, "_all_coef": 65, "_all_s": 65, "45359775": 65, "40424675": 65, "47058888": 65, "47592974": 65, "40950183": 65, "48226638": 65, "46588939": 65, "39593046": 65, "44972133": 65, "46519454": 65, "07988863": 65, "07959541": 65, "08098413": 65, "08746582": 65, "08206336": 65, "07636116": 65, "07433834": 65, "08038611": 65, "08434861": 65, "07689183": 65, "all_coef": 65, "all_s": 65, "4017782": 65, "4201019": 65, "4256505": 65, "4479099": 65, "3964469": 65, "4609432": 65, "4613562": 65, "4756171": 65, "4775664": 65, "4109954": 65, "09135138": 65, "09950102": 65, "08915834": 65, "08527342": 65, "08999468": 65, "09576608": 65, "09133383": 65, "08923286": 65, "08854817": 65, "09311103": 65, "prevent": [65, 74], "314": 65, "dml_plr_obj_intern": 65, "422609": 65, "083002": 65, "091553": 65, "551434e": 65, "259928": 65, "58529": 65, "43680": 65, "09335": 65, "679": 65, "88e": 65, "dml_plr_obj_extern": 65, "kf": 65, "n_split": 65, "shuffl": 65, "my_task": 65, "my_sampl": 65, "lappli": 65, "train_set": 65, "test_set": 65, "2955": 65, "1357": 65, "177": [65, 73, 74], "0295": 65, "unevenli": 65, "3273": 65, "2069": 65, "582": 65, "justif": [65, 68], "dml_plr_no_split": 65, "40673": 65, "08883": 65, "579": 65, "68e": 65, "mert": [65, 73], "esther": [65, 73], "iv\u00e1n": [65, 73], "immun": [65, 73], "india": [65, 73], "nation": [65, 73], "bureau": [65, 73], "3386": 65, "w24678": 65, "upon": [66, 74], "popul": 66, "obei": 66, "partial_": [66, 67], "written": [66, 68], "_n": [66, 67, 68, 69], "architectur": [66, 73], "doabl": 66, "effort": 66, "linearscoremixin": 66, "nonlinearscoremixin": 66, "current": [66, 68, 70, 75], "12638786": [66, 67], "03968828": [66, 67], "480252": [66, 67], "040533": [66, 67], "848422": [66, 67], "192817e": [66, 67], "400808": [66, 67], "559695": [66, 67], "54440": [66, 67], "04512": [66, 67], "5443965": [66, 67], "0009695237": 66, "7811465543": 66, "0090193584": 66, "4037269089": 66, "8646627426": 66, "g_": [66, 67, 69], "p_0": 66, "dt": [66, 68], "lambda_0": 66, "g_d": 66, "2d": 66, "m_": [66, 67, 69], "pi_0": 66, "inf_model": 66, "prone": 66, "concentr": 67, "neighborhood": 67, "leadsto": 67, "j_0": 67, "interchang": 67, "04053296": 67, "04512331": 67, "t_stat": 67, "pval": [67, 69], "84842177": 67, "19281722e": 67, "06464": 67, "623681e": 67, "45595650": 67, "6328366": 67, "4559565": 67, "p_1": [67, 69], "d_1": [67, 69], "psi_j": [67, 69], "eta_": [67, 68, 69], "d_j": [67, 69], "d_k": [67, 69], "zeta_j": [67, 69], "compris": [67, 69], "remain": [67, 69, 75], "explanatori": [67, 69], "v_j": [67, 69], "2014": [67, 69, 73], "tradit": [67, 69], "xi_": [67, 69], "exponenti": [67, 69], "psi_": [67, 68, 69], "c_": [67, 69], "sigma_j": [67, 69], "hypothes": [67, 69, 73], "stepdown": [67, 69], "813342": [67, 69], "055680": [67, 69], "d2": [67, 69], "815224": [67, 69], "083258": [67, 69], "d3": [67, 69], "860663": [67, 69], "109069": [67, 69], "d4": [67, 69], "141546": [67, 69], "091391": [67, 69], "d5": [67, 69], "060845": [67, 69], "176929": [67, 69], "d6": [67, 69], "158697": [67, 69], "078474": [67, 69], "d7": [67, 69], "172022": [67, 69], "062964": [67, 69], "d8": [67, 69], "067721": [67, 69], "174499": [67, 69], "d9": [67, 69], "092365": [67, 69], "139491": [67, 69], "d10": [67, 69], "110717": [67, 69], "138698": [67, 69], "934511": [67, 69], "000": [67, 69, 75], "949241": [67, 69], "984866": [67, 69], "025077": [67, 69], "902": [67, 69], "058042": [67, 69], "784": [67, 69], "040112": [67, 69], "054529": [67, 69], "053389": [67, 69], "023563": [67, 69], "013990": [67, 69], "890273683": [67, 69], "14532650": [67, 69], "907944783": [67, 69], "14368145": [67, 69], "874303353": [67, 69], "12752825": [67, 69], "147909240": [67, 69], "07828372": [67, 69], "097796750": [67, 69], "16803512": [67, 69], "121054720": [67, 69], "12539340": [67, 69], "165362990": [67, 69], "09310496": [67, 69], "101279300": [67, 69], "14200098": [67, 69], "138682380": [67, 69], "09980311": [67, 69], "044449780": [67, 69], "19680840": [67, 69], "89027368": [67, 69], "90794478": [67, 69], "87430335": [67, 69], "14790924": [67, 69], "09779675": [67, 69], "12105472": [67, 69], "16536299": [67, 69], "10127930": [67, 69], "13868238": [67, 69], "04444978": [67, 69], "0178000920": [67, 69], "0258131140": [67, 69], "0009157990": [67, 69], "0348127630": [67, 69], "938": [67, 69], "0351191850": [67, 69], "0021693380": [67, 69], "958": [67, 69], "0361290150": [67, 69], "0203608380": [67, 69], "954": [67, 69], "0194396330": [67, 69], "0761793120": [67, 69], "428": [67, 69, 75], "017800092": [67, 69], "025813114": [67, 69], "000915799": [67, 69], "034812763": [67, 69], "035119185": [67, 69], "002169338": [67, 69], "036129015": [67, 69], "020360838": [67, 69], "019439633": [67, 69], "076179312": [67, 69], "0000000": [67, 69], "0348127631": [67, 69], "0351191851": [67, 69], "0021693381": [67, 69], "0361290151": [67, 69], "0203608381": [67, 69], "0194396331": [67, 69], "8116912": [67, 69], "stronger": [67, 75], "dml_plr_1": 67, "learner_rf": 67, "dml_plr_2": 67, "0x7f9c605fbca0": 67, "0x7f9c6088bf70": 67, "dml_combin": 67, "797737": 67, "071285": 67, "797965": 67, "100517": 67, "844667": 67, "125065": 67, "156545": 67, "106391": 67, "076156": 67, "192240": 67, "173969": 67, "093746": 67, "187153": 67, "078096": 67, "083318": 67, "190096": 67, "107295": 67, "154421": 67, "126777": 67, "154758": 67, "634577": 67, "054348": 67, "676534": 67, "178704": 67, "771157": 67, "215967": 67, "360065": 67, "157091": 67, "167993": 67, "358799": 67, "402113": 67, "199458": 67, "313056": 67, "238225": 67, "266922": 67, "318584": 67, "181446": 67, "385240": 67, "280514": 67, "321686": 67, "subtract": 67, "caution": 67, "0x7f9c59b050a0": 67, "0x7f9c5a9b1370": 67, "074304": 67, "254400": 67, "145748": 67, "188991": 67, "164034": 67, "146641": 67, "122777": 67, "275596": 67, "242815": 67, "168092": 67, "178934": 67, "301366": 67, "242139": 67, "207912": 67, "197484": 67, "252601": 67, "292047": 67, "135379": 67, "244622": 67, "231430": 67, "substract": 67, "wei": [67, 69], "annal": [67, 69, 73], "6b": [67, 69], "3643": [67, 69], "1214": [67, 69], "aos1671": [67, 69], "maxima": [67, 69], "2786": [67, 69], "2819": [67, 69], "aos1161": [67, 69], "suprema": [67, 69], "1564": [67, 69], "aos1230": [67, 69], "defint": 68, "integr": [68, 74], "alpha_0": 68, "fr\u00e9chet": 68, "theorem": 68, "sigma_0": 68, "nu_0": 68, "2m": 68, "extendend": 68, "textrm": 68, "cor": 68, "orthongon": 68, "sensitivity_el": 68, "0x7f9c50ffc400": 68, "dict_kei": 68, "sigma2": 68, "nu2": 68, "psi_sigma2": 68, "psi_nu2": 68, "side": 68, "410112": 68, "484032": 68, "544399": 68, "618163": 68, "147026": 68, "207071": 68, "48403222": 68, "54439924": 68, "04494057": 68, "04484505": 68, "41011156": 68, "61816278": 68, "40147026": 68, "35207071": 68, "coffici": 68, "intersect": [68, 74], "countour": 68, "grasp": 68, "magnitud": 68, "possibli": 68, "principl": 68, "emul": 68, "refit": 68, "computation": 68, "026842": 68, "45688": 68, "97978": 68, "089075": 68, "weak": [68, 73], "unstabl": 68, "denomin": 68, "sensemakr": 68, "cinelli": [68, 73], "hazlett": 68, "subscript": 68, "advers": 68, "nuisance_el": 68, "senstiv": 68, "precis": [68, 75], "whera": 68, "simplif": 68, "pedregosa": [70, 72], "ecosystem": [70, 75], "workflow": 70, "typic": 70, "everyth": 70, "visit": [70, 75], "doubleiivm": 70, "particular": 70, "readili": 70, "regard": 70, "maintain": [70, 74], "maltekurz": 70, "philippbach": [70, 74], "svenklaassen": 70, "bug": [70, 74], "tracker": 70, "appreci": 70, "bach": [70, 73, 74], "kurz": [70, 73, 74], "www": [70, 71], "v23": 70, "0862": 70, "18637": 70, "jss": 70, "v108": 70, "i03": 70, "09603": 70, "bibtex": 70, "doubleml2022python": 70, "ython": 70, "author": 70, "philipp": [70, 73], "malt": [70, 73], "year": 70, "volum": 70, "page": [70, 73], "doubleml2024r": 70, "sven": [70, 73], "href": 70, "ab": 70, "deutsch": 70, "forschungsgemeinschaft": 70, "dfg": 70, "german": 70, "foundat": [70, 73], "431701914": 70, "varoquaux": [70, 72], "gramfort": [70, 72], "michel": [70, 72], "thirion": [70, 72], "grisel": [70, 72], "blondel": [70, 72], "prettenhof": [70, 72], "weiss": [70, 72], "dubourg": [70, 72], "vanderpla": [70, 72], "passo": [70, 72], "cournapeau": [70, 72], "brucher": [70, 72], "perrot": [70, 72], "duchesnai": [70, 72], "2825": [70, 72], "2830": [70, 72], "csail": [70, 72], "mit": [70, 72], "edu": [70, 72], "v12": [70, 72], "pedregosa11a": [70, 72], "offici": 71, "wish": 71, "contribut": [71, 74], "linux": 71, "virtual": 71, "environ": 71, "python3": 71, "sudo": 71, "apt": 71, "conflict": 71, "virtualenv": 71, "setup": 71, "venv": 71, "run": [71, 74], "freez": 71, "__version__": 71, "pip3": 71, "forg": [71, 73, 74], "maco": 71, "brew": 71, "mac": 71, "osx": 71, "window": 71, "script": 71, "py3": 71, "git": 71, "cd": 71, "edit": [71, 73], "mode": 71, "immedi": 71, "restart": 71, "setuptool": 71, "command": [71, 74], "remot": 71, "install_github": 71, "exemplarili": 72, "ml_l_bonu": 72, "ml_m_bonu": 72, "ml_l_sim": 72, "ml_m_sim": 72, "inspect": 72, "besid": 72, "200303": 72, "47419634": 72, "076684": 72, "035411": 72, "165549": 72, "030346": 72, "146087": 72, "00728": 72, "24469564": 72, "02016117": 72, "02092": 72, "045379": 72, "570722": 72, "931978": 72, "109861": 72, "07561": 72, "03536": 72, "0325": 72, "03411": 72, "04486": 72, "deni": 73, "whitnei": 73, "jame": 73, "pypi": [73, 74], "keith": 73, "battocchi": 73, "eleanor": 73, "dillon": 73, "maggi": 73, "hei": 73, "greg": 73, "lewi": 73, "paul": 73, "oka": 73, "miruna": 73, "vasili": 73, "syrgkani": 73, "econml": 73, "hugo": 73, "bodori": 73, "causalweight": 73, "493": 73, "faculti": 73, "social": 73, "univers": 73, "fribourg": 73, "michael": 73, "knau": 73, "unconfounded": 73, "preprint": 73, "03191": 73, "econ": 73, "em": 73, "causaldml": 73, "music": 73, "student": 73, "skill": 73, "royal": 73, "282": 73, "dmlmt": 73, "serverless": [73, 74], "companion": 73, "acm": 73, "spec": 73, "confer": 73, "icp": 73, "york": 73, "ny": 73, "usa": 73, "juraj": 73, "szita": 73, "postdoubl": 73, "methodolog": 73, "susan": 73, "athei": 73, "stefan": 73, "wager": 73, "luka": 73, "laffer": 73, "neng": 73, "chieh": 73, "harold": 73, "kengo": 73, "yukun": 73, "yuya": 73, "forthcom": 73, "nathan": 73, "xiaoji": 73, "mao": 73, "masatoshi": 73, "uehara": 73, "effici": 73, "beyond": 73, "1912": 73, "12945": 73, "reinforc": 73, "yusuk": 73, "narita": 73, "shota": 73, "yasui": 73, "kohei": 73, "yata": 73, "system": 73, "recsi": 73, "fifteenth": 73, "372": 73, "379": 73, "lester": 73, "mackei": 73, "ilia": 73, "zadik": 73, "limit": 73, "35th": 73, "pedro": 73, "hc": 73, "jun": 73, "amit": 73, "sharma": 73, "stori": 73, "w30302": 73, "vira": 73, "264": 73, "289": 73, "matt": 73, "goldman": 73, "taddi": 73, "dynam": 73, "1712": 73, "09988": 73, "1809": 73, "01643": 73, "sparsiti": 73, "acemoglu": 73, "arellano": 73, "dekel": 73, "ed": 73, "tenth": 73, "world": 73, "congress": 73, "245": 73, "295": 73, "lie": 73, "wang": 73, "757": 73, "788": 73, "elementari": 73, "annual": 73, "649": 73, "688": 73, "adel": 73, "javanmard": 73, "andrea": 73, "montanari": 73, "design": 73, "ieee": 73, "transact": 73, "6522": 73, "6554": 73, "jerzi": 73, "composit": 73, "ulf": 73, "grenand": 73, "almqvist": 73, "wiksel": 73, "213": [73, 74], "234": 73, "1959": 73, "sara": 73, "van": 73, "geer": 73, "peter": 73, "b\u00fchlmann": 73, "ya": 73, "acov": 73, "ritov": 73, "ruben": 73, "dezeur": 73, "1166": 73, "1202": 73, "zhang": 73, "seri": 73, "217": 73, "242": 73, "doublemlsmm": 74, "michaela": 74, "kecsk\u00e9sov\u00e1": 74, "235": 74, "171": 74, "apply_crossfit": 74, "166": 74, "restructur": 74, "readabl": 74, "226": 74, "lucien": 74, "239": 74, "gain_statist": 74, "mainten": 74, "162": 74, "164": 74, "165": 74, "168": 74, "246": 74, "220": 74, "221": 74, "159": 74, "222": 74, "223": 74, "224": 74, "211": 74, "212": 74, "208": 74, "202": 74, "206": 74, "199": 74, "182": 74, "188": 74, "ipw_norm": 74, "173": 74, "refactor": 74, "docu": 74, "195": 74, "196": 74, "licens": 74, "bsd": 74, "claus": 74, "198": 74, "174": 74, "181": 74, "fail": 74, "172": 74, "overwrit": 74, "depreci": 74, "170": 74, "publish": 74, "citat": 74, "guidelin": 74, "templat": 74, "request": 74, "forum": 74, "clean": 74, "dev": 74, "action": 74, "assur": 74, "duplic": 74, "datatyp": 74, "occur": 74, "setdiff": 74, "2104": 74, "03220": 74, "export": 74, "logo": 74, "repo": 74, "upload": 74, "codecov": 74, "app": 74, "io": 74, "gh": 74, "lint": 74, "flake8": 74, "pep8": 74, "codaci": 74, "redund": 74, "schedul": 74, "week": 74, "privat": 74, "_est_causal_pars_and_s": 74, "instruct": 74, "submiss": 74, "inherit": 74, "helper": 74, "link": 74, "regener": 74, "rd": 74, "newest": 74, "roxygen2": 74, "task_typ": 74, "learner_class": 74, "solari": 74, "upcom": 74, "checkmat": 74, "backward": 74, "styler": 74, "wiki": 74, "bind": 74, "oop": 74, "mislead": 74, "cleanup": 74, "reorgan": 74, "vignett": 74, "subclass": 74, "check_scor": 74, "check_data": 74, "refin": 74, "dml_cv_predict": 74, "dml_tune": 74, "cmd": 74, "rough": 75, "analys": 75, "onlin": 75, "state": 75, "channel": 75, "critic": 75, "inferenti": 75, "question": 75, "employe": 75, "properli": 75, "strategi": 75, "person": 75, "circumv": 75, "word": 75, "onc": 75, "earlier": 75, "relat": 75, "breviti": 75, "intent": 75, "talk": 75, "That": 75, "plai": 75, "pick": 75, "perhap": 75, "greater": 75, "driven": 75, "declar": 75, "data_fram": 75, "dml_data_df": 75, "keep": 75, "ml_l_rf": 75, "ml_m_rf": 75, "ml_l_xgb": 75, "ml_m_xgb": 75, "0x7f9c59d0d070": 75, "63407762": 75, "82228913": 75, "218": 75, "nuis_l": 75, "069": 75, "187": 75, "451": 75, "403": 75, "361": 75, "99864670889": 75, "1312": 75, "93958082416": 75, "partli": 75, "conclud": 75, "Being": 75, "559": 75, "6075": 75, "923943": 75, "11743": 75, "344212": 75, "e4016553": 75, "6553": 75, "684": 75, "11700": 75, "42811700": 75, "611": 75, "359": 75, "2359": 75, "496777": 75, "4610": 75, "983759": 75, "13208": 75, "284397": 75, "15430": 75, "415812": 75, "029209": 75, "233154": 75}, "objects": {"doubleml": [[1, 0, 1, "", "DoubleMLBLP"], [2, 0, 1, "", "DoubleMLCVAR"], [3, 0, 1, "", "DoubleMLClusterData"], [4, 0, 1, "", "DoubleMLDID"], [5, 0, 1, "", "DoubleMLDIDCS"], [6, 0, 1, "", "DoubleMLData"], [7, 0, 1, "", "DoubleMLIIVM"], [8, 0, 1, "", "DoubleMLIRM"], [9, 0, 1, "", "DoubleMLLPQ"], [10, 0, 1, "", "DoubleMLPLIV"], [11, 0, 1, "", "DoubleMLPLR"], [12, 0, 1, "", "DoubleMLPQ"], [13, 0, 1, "", "DoubleMLQTE"]], "doubleml.DoubleMLBLP": [[1, 1, 1, "", "confint"], [1, 1, 1, "", "fit"]], "doubleml.DoubleMLCVAR": [[2, 1, 1, "", "bootstrap"], [2, 1, 1, "", "confint"], [2, 1, 1, "", "construct_framework"], [2, 1, 1, "", "draw_sample_splitting"], [2, 1, 1, "", "evaluate_learners"], [2, 1, 1, "", "fit"], [2, 1, 1, "", "get_params"], [2, 1, 1, "", "p_adjust"], [2, 1, 1, "", "sensitivity_analysis"], [2, 1, 1, "", "sensitivity_benchmark"], [2, 1, 1, "", "sensitivity_plot"], [2, 1, 1, "", "set_ml_nuisance_params"], [2, 1, 1, "", "set_sample_splitting"], [2, 1, 1, "", "tune"]], "doubleml.DoubleMLClusterData": [[3, 1, 1, "", "from_arrays"], [3, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLDID": [[4, 1, 1, "", "bootstrap"], [4, 1, 1, "", "confint"], [4, 1, 1, "", "construct_framework"], [4, 1, 1, "", "draw_sample_splitting"], [4, 1, 1, "", "evaluate_learners"], [4, 1, 1, "", "fit"], [4, 1, 1, "", "get_params"], [4, 1, 1, "", "p_adjust"], [4, 1, 1, "", "sensitivity_analysis"], [4, 1, 1, "", "sensitivity_benchmark"], [4, 1, 1, "", "sensitivity_plot"], [4, 1, 1, "", "set_ml_nuisance_params"], [4, 1, 1, "", "set_sample_splitting"], [4, 1, 1, "", "tune"]], "doubleml.DoubleMLDIDCS": [[5, 1, 1, "", "bootstrap"], [5, 1, 1, "", "confint"], [5, 1, 1, "", "construct_framework"], [5, 1, 1, "", "draw_sample_splitting"], [5, 1, 1, "", "evaluate_learners"], [5, 1, 1, "", "fit"], [5, 1, 1, "", "get_params"], [5, 1, 1, "", "p_adjust"], [5, 1, 1, "", "sensitivity_analysis"], [5, 1, 1, "", "sensitivity_benchmark"], [5, 1, 1, "", "sensitivity_plot"], [5, 1, 1, "", "set_ml_nuisance_params"], [5, 1, 1, "", "set_sample_splitting"], [5, 1, 1, "", "tune"]], "doubleml.DoubleMLData": [[6, 1, 1, "", "from_arrays"], [6, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLIIVM": [[7, 1, 1, "", "bootstrap"], [7, 1, 1, "", "confint"], [7, 1, 1, "", "construct_framework"], [7, 1, 1, "", "draw_sample_splitting"], [7, 1, 1, "", "evaluate_learners"], [7, 1, 1, "", "fit"], [7, 1, 1, "", "get_params"], [7, 1, 1, "", "p_adjust"], [7, 1, 1, "", "sensitivity_analysis"], [7, 1, 1, "", "sensitivity_benchmark"], [7, 1, 1, "", "sensitivity_plot"], [7, 1, 1, "", "set_ml_nuisance_params"], [7, 1, 1, "", "set_sample_splitting"], [7, 1, 1, "", "tune"]], "doubleml.DoubleMLIRM": [[8, 1, 1, "", "bootstrap"], [8, 1, 1, "", "cate"], [8, 1, 1, "", "confint"], [8, 1, 1, "", "construct_framework"], [8, 1, 1, "", "draw_sample_splitting"], [8, 1, 1, "", "evaluate_learners"], [8, 1, 1, "", "fit"], [8, 1, 1, "", "gate"], [8, 1, 1, "", "get_params"], [8, 1, 1, "", "p_adjust"], [8, 1, 1, "", "policy_tree"], [8, 1, 1, "", "sensitivity_analysis"], [8, 1, 1, "", "sensitivity_benchmark"], [8, 1, 1, "", "sensitivity_plot"], [8, 1, 1, "", "set_ml_nuisance_params"], [8, 1, 1, "", "set_sample_splitting"], [8, 1, 1, "", "tune"]], "doubleml.DoubleMLLPQ": [[9, 1, 1, "", "bootstrap"], [9, 1, 1, "", "confint"], [9, 1, 1, "", "construct_framework"], [9, 1, 1, "", "draw_sample_splitting"], [9, 1, 1, "", "evaluate_learners"], [9, 1, 1, "", "fit"], [9, 1, 1, "", "get_params"], [9, 1, 1, "", "p_adjust"], [9, 1, 1, "", "sensitivity_analysis"], [9, 1, 1, "", "sensitivity_benchmark"], [9, 1, 1, "", "sensitivity_plot"], [9, 1, 1, "", "set_ml_nuisance_params"], [9, 1, 1, "", "set_sample_splitting"], [9, 1, 1, "", "tune"]], "doubleml.DoubleMLPLIV": [[10, 1, 1, "", "bootstrap"], [10, 1, 1, "", "confint"], [10, 1, 1, "", "construct_framework"], [10, 1, 1, "", "draw_sample_splitting"], [10, 1, 1, "", "evaluate_learners"], [10, 1, 1, "", "fit"], [10, 1, 1, "", "get_params"], [10, 1, 1, "", "p_adjust"], [10, 1, 1, "", "sensitivity_analysis"], [10, 1, 1, "", "sensitivity_benchmark"], [10, 1, 1, "", "sensitivity_plot"], [10, 1, 1, "", "set_ml_nuisance_params"], [10, 1, 1, "", "set_sample_splitting"], [10, 1, 1, "", "tune"]], "doubleml.DoubleMLPLR": [[11, 1, 1, "", "bootstrap"], [11, 1, 1, "", "cate"], [11, 1, 1, "", "confint"], [11, 1, 1, "", "construct_framework"], [11, 1, 1, "", "draw_sample_splitting"], [11, 1, 1, "", "evaluate_learners"], [11, 1, 1, "", "fit"], [11, 1, 1, "", "gate"], [11, 1, 1, "", "get_params"], [11, 1, 1, "", "p_adjust"], [11, 1, 1, "", "sensitivity_analysis"], [11, 1, 1, "", "sensitivity_benchmark"], [11, 1, 1, "", "sensitivity_plot"], [11, 1, 1, "", "set_ml_nuisance_params"], [11, 1, 1, "", "set_sample_splitting"], [11, 1, 1, "", "tune"]], "doubleml.DoubleMLPQ": [[12, 1, 1, "", "bootstrap"], [12, 1, 1, "", "confint"], [12, 1, 1, "", "construct_framework"], [12, 1, 1, "", "draw_sample_splitting"], [12, 1, 1, "", "evaluate_learners"], [12, 1, 1, "", "fit"], [12, 1, 1, "", "get_params"], [12, 1, 1, "", "p_adjust"], [12, 1, 1, "", "sensitivity_analysis"], [12, 1, 1, "", "sensitivity_benchmark"], [12, 1, 1, "", "sensitivity_plot"], [12, 1, 1, "", "set_ml_nuisance_params"], [12, 1, 1, "", "set_sample_splitting"], [12, 1, 1, "", "tune"]], "doubleml.DoubleMLQTE": [[13, 1, 1, "", "bootstrap"], [13, 1, 1, "", "confint"], [13, 1, 1, "", "draw_sample_splitting"], [13, 1, 1, "", "fit"], [13, 1, 1, "", "p_adjust"]], "doubleml.datasets": [[14, 2, 1, "", "fetch_401K"], [15, 2, 1, "", "fetch_bonus"], [16, 2, 1, "", "make_confounded_irm_data"], [17, 2, 1, "", "make_confounded_plr_data"], [18, 2, 1, "", "make_did_SZ2020"], [19, 2, 1, "", "make_heterogeneous_data"], [20, 2, 1, "", "make_iivm_data"], [21, 2, 1, "", "make_irm_data"], [22, 2, 1, "", "make_pliv_CHS2015"], [23, 2, 1, "", "make_pliv_multiway_cluster_CKMS2021"], [24, 2, 1, "", "make_plr_CCDDHNR2018"], [25, 2, 1, "", "make_plr_turrell2018"], [26, 2, 1, "", "make_ssm_data"]], "doubleml.double_ml_score_mixins": [[27, 0, 1, "", "LinearScoreMixin"], [28, 0, 1, "", "NonLinearScoreMixin"]], "doubleml.utils": [[29, 0, 1, "", "DMLDummyClassifier"], [30, 0, 1, "", "DMLDummyRegressor"], [31, 2, 1, "", "gain_statistics"]], "doubleml.utils.DMLDummyClassifier": [[29, 1, 1, "", "fit"], [29, 1, 1, "", "get_metadata_routing"], [29, 1, 1, "", "get_params"], [29, 1, 1, "", "predict"], [29, 1, 1, "", "predict_proba"], [29, 1, 1, "", "set_params"]], "doubleml.utils.DMLDummyRegressor": [[30, 1, 1, "", "fit"], [30, 1, 1, "", "get_metadata_routing"], [30, 1, 1, "", "get_params"], [30, 1, 1, "", "predict"], [30, 1, 1, "", "set_params"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"]}, "titleterms": {"api": 0, "refer": [0, 32, 34, 36, 39, 46, 51, 59, 63, 65, 67, 69, 70, 72], "doubl": [0, 33, 34, 40, 51, 58, 59, 70, 72, 73], "machin": [0, 33, 34, 40, 51, 58, 59, 70, 72, 73], "learn": [0, 33, 34, 40, 51, 54, 58, 59, 62, 70, 72, 73], "data": [0, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 59, 60, 64, 66, 68, 72, 75], "class": [0, 34, 51], "model": [0, 35, 37, 41, 42, 47, 48, 52, 54, 57, 62, 64, 65, 66, 67, 68, 72, 75], "dataset": [0, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 37], "modul": [0, 37], "loader": 0, "gener": [0, 33, 38, 40, 59, 68], "util": [0, 29, 30, 31], "function": [0, 34, 51, 66, 72], "score": [0, 33, 40, 59, 66, 72], "mixin": 0, "doubleml": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 39, 52, 56, 67, 70, 71, 75], "doublemlblp": 1, "doublemlcvar": 2, "doublemlclusterdata": [3, 34, 51], "doublemldid": 4, "doublemldidc": 5, "doublemldata": [6, 35, 52, 60, 72], "doublemliivm": 7, "doublemlirm": 8, "doublemllpq": 9, "doublemlpliv": [10, 34, 51], "doublemlplr": 11, "doublemlpq": 12, "doublemlqt": 13, "fetch_401k": 14, "fetch_bonu": 15, "make_confounded_irm_data": 16, "make_confounded_plr_data": 17, "make_did_sz2020": 18, "make_heterogeneous_data": 19, "make_iivm_data": 20, "make_irm_data": 21, "make_pliv_chs2015": 22, "make_pliv_multiway_cluster_ckms2021": 23, "make_plr_ccddhnr2018": 24, "make_plr_turrell2018": 25, "make_ssm_data": 26, "double_ml_score_mixin": [27, 28], "linearscoremixin": 27, "nonlinearscoremixin": 28, "dmldummyclassifi": 29, "dmldummyregressor": 30, "gain_statist": 31, "r": [32, 33, 34, 35, 36, 38, 63, 71], "basic": [32, 33, 39, 40, 59], "instrument": [32, 39], "variabl": [32, 39], "calcul": [32, 39], "direct": [32, 39], "acycl": [32, 39], "graph": [32, 39], "iv": [32, 35, 39, 52, 64, 66], "dag": [32, 39], "simul": [32, 34, 39, 44, 51, 56], "naiv": [32, 39], "estim": [32, 35, 37, 39, 44, 46, 49, 52, 53, 55, 56, 57, 65, 66, 67, 72, 75], "us": [32, 36, 37, 39, 63], "process": [33, 34, 40, 51, 59], "dgp": [33, 40], "regular": [33, 40, 59], "bia": [33, 40, 59], "simpl": [33, 40, 59], "ml": [33, 40, 59, 75], "approach": [33, 40, 50, 59], "overcom": [33, 40, 59], "orthogon": [33, 40, 59, 66, 72], "sampl": [33, 40, 57, 59, 64, 65], "split": [33, 40, 59, 65], "remov": [33, 40, 59], "induc": [33, 40, 59], "overfit": [33, 40, 59], "debias": [33, 40, 59, 72], "partial": [33, 35, 40, 48, 52, 59, 64, 66, 68], "out": [33, 40, 59], "cluster": [34, 51], "robust": [34, 51], "motiv": [34, 51], "A": [34, 51], "exampl": [34, 38, 41, 42, 51, 56], "two": [34, 41, 42, 51], "wai": [34, 51], "dml": [34, 37, 51, 65, 72, 75], "backend": [34, 35, 51, 52, 60, 72, 75], "initi": [34, 51], "object": [34, 51, 56], "cross": [34, 44, 51, 64, 65, 66, 68, 72], "fit": [34, 51, 65, 72], "standard": [34, 50, 51], "error": [34, 51], "One": [34, 41, 42, 51], "lear": [34, 51], "real": [34, 51], "applic": [34, 51, 56], "load": [34, 37, 51], "respect": [34, 51], "product": [34, 51], "market": [34, 51], "No": [34, 51], "zero": [34, 51], "result": [34, 35, 51, 52], "defin": [34, 51], "helper": [34, 51], "plot": [34, 51], "impact": [35, 52, 53], "401": [35, 52, 53, 56], "k": [35, 52, 53, 56, 65], "financi": [35, 52, 53], "wealth": [35, 52, 53], "The": [35, 52, 59, 60, 72], "packag": [35, 52, 71], "averag": [35, 41, 42, 47, 48, 52, 62], "treatment": [35, 41, 42, 43, 47, 48, 52, 53, 55, 62], "effect": [35, 38, 41, 42, 43, 47, 48, 52, 53, 55, 56, 62], "elig": [35, 52], "net": [35, 52], "asset": [35, 52], "linear": [35, 48, 52, 64, 66, 68], "regress": [35, 47, 48, 52, 54, 64, 66, 68], "plr": [35, 37, 42, 48, 52, 62, 64, 66, 68], "interact": [35, 47, 52, 54, 64, 66, 68], "irm": [35, 37, 41, 47, 52, 54, 56, 62, 64, 66, 68], "local": [35, 52, 53, 55, 66], "particip": [35, 52], "iivm": [35, 52, 64, 66], "summari": [35, 52], "ensembl": 36, "learner": [36, 37, 50, 63, 72], "more": 36, "mlr3pipelin": 36, "from": [36, 60, 71], "mlr3": 36, "mlr3learner": 36, "mlr3extralearn": 36, "set": [36, 63], "up": 36, "base": 36, "how": 36, "exploit": 36, "featur": [36, 70], "preprocess": 36, "paramet": [36, 37, 66], "tune": [36, 63], "bonu": 37, "specifi": [37, 63, 66], "causal": [37, 46, 66, 72, 75], "random": [37, 57, 64, 66], "forest": 37, "lasso": [37, 46], "python": [38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 63, 71], "case": 38, "studi": 38, "heterogen": [38, 62], "sandbox": 38, "condit": [41, 42, 43, 53, 62, 66], "cate": [41, 42, 62], "dimension": [41, 42], "valu": [43, 53, 62, 66], "risk": [43, 53, 62, 66], "potenti": [43, 53, 55, 62, 66], "outcom": [43, 44, 57, 62], "cvar": [43, 53, 62, 66], "differ": [44, 45, 50, 64, 66, 67, 68], "panel": [44, 64, 66, 68], "repeat": [44, 64, 65, 66, 68], "att": 44, "coverag": [44, 46], "section": [44, 64, 66, 68], "pre": 45, "test": 45, "first": 46, "stage": 46, "v": 46, "penalti": 46, "lambda": 46, "qualiti": 46, "empir": 46, "combin": 46, "loss": 46, "group": [47, 48, 62], "gate": [47, 48, 49, 62], "sensit": [49, 56, 68, 75], "analysi": [49, 56, 68, 75], "ATE": [49, 57], "gatet": 49, "choic": 50, "compar": 50, "custom": 50, "evalu": [50, 63], "metric": 50, "comput": 50, "time": 50, "quantil": [53, 55, 62, 66], "lqte": [53, 55], "polici": [54, 62], "tree": [54, 62], "pq": [55, 62, 66], "qte": [55, 62], "lpq": [55, 66], "benchmark": [56, 68], "select": [57, 64], "miss": 57, "mar": 57, "distribut": 57, "under": 57, "nonignor": [57, 64, 66], "nonrespons": [57, 64, 66], "algorithm": [58, 68, 70, 72], "dml1": 58, "dml2": 58, "implement": [58, 66, 68], "datafram": 60, "arrai": 60, "matric": 60, "user": 61, "guid": 61, "weight": 62, "hyperparamet": 63, "minimum": 63, "requir": 63, "advanc": [63, 67], "extern": [63, 65], "predict": 63, "pipelin": 63, "construct": 63, "pliv": [64, 66], "did": 64, "ssm": 64, "missing": [64, 66], "fold": 65, "m": 65, "repetit": 65, "provid": 65, "partit": 65, "without": 65, "neyman": [66, 72], "altern": 66, "via": 66, "callabl": 66, "varianc": 67, "confid": [67, 69], "interv": [67, 69], "band": [67, 69], "multipli": [67, 69], "bootstrap": [67, 69], "valid": [67, 69], "simultan": [67, 69], "infer": [67, 69, 75], "over": 67, "theori": 68, "specif": [68, 75], "joint": 69, "main": 70, "sourc": [70, 71], "code": 70, "mainten": 70, "citat": 70, "acknowledg": 70, "instal": 71, "latest": 71, "releas": [71, 74], "pip": 71, "conda": 71, "version": 71, "whl": 71, "file": 71, "build": 71, "cran": 71, "develop": 71, "github": 71, "get": 72, "start": 72, "nuisanc": 72, "literatur": 73, "note": 74, "workflow": 75, "0": 75, "problem": 75, "formul": 75, "1": 75, "2": 75, "3": 75, "method": 75, "4": 75, "5": 75, "6": 75, "7": 75}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "nbsphinx": 4, "sphinx": 57}, "alltitles": {"API reference": [[0, "api-reference"]], "Double machine learning data class": [[0, "double-machine-learning-data-class"]], "Double machine learning models": [[0, "double-machine-learning-models"]], "Datasets module": [[0, "datasets-module"]], "Dataset loaders": [[0, "dataset-loaders"]], "Dataset generators": [[0, "dataset-generators"]], "Utility classes and functions": [[0, "utility-classes-and-functions"]], "Utility classes": [[0, "utility-classes"]], "Utility functions": [[0, "utility-functions"]], "Score mixin classes for double machine learning models": [[0, "score-mixin-classes-for-double-machine-learning-models"]], "doubleml.DoubleMLBLP": [[1, "doubleml-doublemlblp"]], "doubleml.DoubleMLCVAR": [[2, "doubleml-doublemlcvar"]], "doubleml.DoubleMLClusterData": [[3, "doubleml-doublemlclusterdata"]], "doubleml.DoubleMLDID": [[4, "doubleml-doublemldid"]], "doubleml.DoubleMLDIDCS": [[5, "doubleml-doublemldidcs"]], "doubleml.DoubleMLData": [[6, "doubleml-doublemldata"]], "doubleml.DoubleMLIIVM": [[7, "doubleml-doublemliivm"]], "doubleml.DoubleMLIRM": [[8, "doubleml-doublemlirm"]], "doubleml.DoubleMLLPQ": [[9, "doubleml-doublemllpq"]], "doubleml.DoubleMLPLIV": [[10, "doubleml-doublemlpliv"]], "doubleml.DoubleMLPLR": [[11, "doubleml-doublemlplr"]], "doubleml.DoubleMLPQ": [[12, "doubleml-doublemlpq"]], "doubleml.DoubleMLQTE": [[13, "doubleml-doublemlqte"]], "doubleml.datasets.fetch_401K": [[14, "doubleml-datasets-fetch-401k"]], "doubleml.datasets.fetch_bonus": [[15, "doubleml-datasets-fetch-bonus"]], "doubleml.datasets.make_confounded_irm_data": [[16, "doubleml-datasets-make-confounded-irm-data"]], "doubleml.datasets.make_confounded_plr_data": [[17, "doubleml-datasets-make-confounded-plr-data"]], "doubleml.datasets.make_did_SZ2020": [[18, "doubleml-datasets-make-did-sz2020"]], "doubleml.datasets.make_heterogeneous_data": [[19, "doubleml-datasets-make-heterogeneous-data"]], "doubleml.datasets.make_iivm_data": [[20, "doubleml-datasets-make-iivm-data"]], "doubleml.datasets.make_irm_data": [[21, "doubleml-datasets-make-irm-data"]], "doubleml.datasets.make_pliv_CHS2015": [[22, "doubleml-datasets-make-pliv-chs2015"]], "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021": [[23, "doubleml-datasets-make-pliv-multiway-cluster-ckms2021"]], "doubleml.datasets.make_plr_CCDDHNR2018": [[24, "doubleml-datasets-make-plr-ccddhnr2018"]], "doubleml.datasets.make_plr_turrell2018": [[25, "doubleml-datasets-make-plr-turrell2018"]], "doubleml.datasets.make_ssm_data": [[26, "doubleml-datasets-make-ssm-data"]], "doubleml.double_ml_score_mixins.LinearScoreMixin": [[27, "doubleml-double-ml-score-mixins-linearscoremixin"]], "doubleml.double_ml_score_mixins.NonLinearScoreMixin": [[28, "doubleml-double-ml-score-mixins-nonlinearscoremixin"]], "doubleml.utils.DMLDummyClassifier": [[29, "doubleml-utils-dmldummyclassifier"]], "doubleml.utils.DMLDummyRegressor": [[30, "doubleml-utils-dmldummyregressor"]], "doubleml.utils.gain_statistics": [[31, "doubleml-utils-gain-statistics"]], "R: Basic Instrumental Variables Calculation": [[32, "R:-Basic-Instrumental-Variables-Calculation"]], "Instrumental Variables Directed Acyclic Graph (IV - DAG)": [[32, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"], [39, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"]], "Data Simulation": [[32, "Data-Simulation"], [39, "Data-Simulation"]], "Naive estimation": [[32, "Naive-estimation"], [39, "Naive-estimation"]], "Using DoubleML": [[32, "Using-DoubleML"], [39, "Using-DoubleML"]], "References": [[32, "References"], [34, "References"], [36, "References"], [39, "References"], [46, "References"], [51, "References"], [59, "references"], [63, "references"], [65, "references"], [67, "references"], [69, "references"], [70, "references"], [72, "references"]], "R: Basics of Double Machine Learning": [[33, "R:-Basics-of-Double-Machine-Learning"]], "Data Generating Process (DGP)": [[33, "Data-Generating-Process-(DGP)"], [40, "Data-Generating-Process-(DGP)"]], "Regularization Bias in Simple ML-Approaches": [[33, "Regularization-Bias-in-Simple-ML-Approaches"], [40, "Regularization-Bias-in-Simple-ML-Approaches"]], "Overcoming regularization bias by orthogonalization": [[33, "Overcoming-regularization-bias-by-orthogonalization"], [40, "Overcoming-regularization-bias-by-orthogonalization"], [59, "overcoming-regularization-bias-by-orthogonalization"]], "Sample splitting to remove bias induced by overfitting": [[33, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [40, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [59, "sample-splitting-to-remove-bias-induced-by-overfitting"]], "Double/debiased machine learning": [[33, "Double/debiased-machine-learning"], [40, "Double/debiased-machine-learning"], [59, "double-debiased-machine-learning"]], "Partialling out score": [[33, "Partialling-out-score"], [40, "Partialling-out-score"], [59, "partialling-out-score"]], "R: Cluster Robust Double Machine Learning": [[34, "R:-Cluster-Robust-Double-Machine-Learning"]], "Motivation": [[34, "Motivation"], [51, "Motivation"]], "Clustering and double machine learning": [[34, "Clustering-and-double-machine-learning"], [51, "Clustering-and-double-machine-learning"]], "A Motivating Example: Two-Way Cluster Robust DML": [[34, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"], [51, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"]], "Simulate two-way cluster data": [[34, "Simulate-two-way-cluster-data"], [51, "Simulate-two-way-cluster-data"]], "Data-Backend for Cluster Data": [[34, "Data-Backend-for-Cluster-Data"], [51, "Data-Backend-for-Cluster-Data"]], "Initialize the objects of class DoubleMLPLIV": [[34, "Initialize-the-objects-of-class-DoubleMLPLIV"], [51, "Initialize-the-objects-of-class-DoubleMLPLIV"]], "Cluster Robust Cross Fitting": [[34, "Cluster-Robust-Cross-Fitting"], [51, "Cluster-Robust-Cross-Fitting"]], "Cluster Robust Standard Errors": [[34, "Cluster-Robust-Standard-Errors"], [51, "Cluster-Robust-Standard-Errors"]], "(One-Way) Cluster Robust Double Machine Learing": [[34, "(One-Way)-Cluster-Robust-Double-Machine-Learing"], [51, "(One-Way)-Cluster-Robust-Double-Machine-Learing"]], "Real-Data Application": [[34, "Real-Data-Application"], [51, "Real-Data-Application"]], "Load and Process Data": [[34, "Load-and-Process-Data"], [51, "Load-and-Process-Data"]], "Initialize DoubleMLClusterData object": [[34, "Initialize-DoubleMLClusterData-object"], [51, "Initialize-DoubleMLClusterData-object"]], "Two-Way Clustering with Respect to Product and Market": [[34, "Two-Way-Clustering-with-Respect-to-Product-and-Market"], [51, "Two-Way-Clustering-with-Respect-to-Product-and-Market"]], "One-Way Clustering with Respect to the Product": [[34, "One-Way-Clustering-with-Respect-to-the-Product"], [51, "One-Way-Clustering-with-Respect-to-the-Product"]], "One-Way Clustering with Respect to the Market": [[34, "One-Way-Clustering-with-Respect-to-the-Market"], [51, "One-Way-Clustering-with-Respect-to-the-Market"]], "No Clustering / Zero-Way Clustering": [[34, "No-Clustering-/-Zero-Way-Clustering"], [51, "No-Clustering-/-Zero-Way-Clustering"]], "Application Results": [[34, "Application-Results"], [51, "Application-Results"]], "Define Helper Functions for Plotting": [[34, "Define-Helper-Functions-for-Plotting"], [51, "Define-Helper-Functions-for-Plotting"]], "R: Impact of 401(k) on Financial Wealth": [[35, "R:-Impact-of-401(k)-on-Financial-Wealth"]], "Data": [[35, "Data"], [41, "Data"], [42, "Data"], [43, "Data"], [44, "Data"], [44, "id1"], [47, "Data"], [48, "Data"], [49, "Data"], [52, "Data"], [53, "Data"], [54, "Data"], [55, "Data"], [55, "id1"], [56, "Data"], [57, "Data"], [57, "id1"], [72, "data"]], "The DoubleML package": [[35, "The-DoubleML-package"], [52, "The-DoubleML-package"]], "Estimating the Average Treatment Effect of 401(k) Eligibility on Net Financial Assets": [[35, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"], [52, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"]], "The Data Backend: DoubleMLData": [[35, "The-Data-Backend:-DoubleMLData"], [52, "The-Data-Backend:-DoubleMLData"]], "Partially Linear Regression Model (PLR)": [[35, "Partially-Linear-Regression-Model-(PLR)"], [48, "Partially-Linear-Regression-Model-(PLR)"], [52, "Partially-Linear-Regression-Model-(PLR)"]], "Interactive Regression Model (IRM)": [[35, "Interactive-Regression-Model-(IRM)"], [47, "Interactive-Regression-Model-(IRM)"], [52, "Interactive-Regression-Model-(IRM)"], [54, "Interactive-Regression-Model-(IRM)"]], "Local Average Treatment Effects of 401(k) Participation on Net Financial Assets": [[35, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"], [52, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"]], "Interactive IV Model (IIVM)": [[35, "Interactive-IV-Model-(IIVM)"], [52, "Interactive-IV-Model-(IIVM)"]], "Summary of Results": [[35, "Summary-of-Results"], [52, "Summary-of-Results"]], "R: Ensemble Learners and More with mlr3pipelines": [[36, "R:-Ensemble-Learners-and-More-with-mlr3pipelines"]], "Using learners from mlr3, mlr3learners and mlr3extralearners": [[36, "Using-learners-from-mlr3,-mlr3learners-and-mlr3extralearners"]], "Set up learners based on mlr3pipelines": [[36, "Set-up-learners-based-on-mlr3pipelines"]], "Use ensemble learners based on mlr3pipelines": [[36, "Use-ensemble-learners-based-on-mlr3pipelines"]], "How to exploit more features of mlr3pipelines in DoubleML": [[36, "How-to-exploit-more-features-of-mlr3pipelines-in-DoubleML"]], "Data preprocessing": [[36, "Data-preprocessing"]], "Parameter tuning": [[36, "Parameter-tuning"]], "DML: Bonus Data": [[37, "DML:-Bonus-Data"]], "Load bonus data using the dml datasets module": [[37, "Load-bonus-data-using-the-dml-datasets-module"]], "Specify learner and estimate causal parameter: PLR model with random forest as learner": [[37, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-random-forest-as-learner"]], "Specify learner and estimate causal parameter: PLR model with Lasso as learner": [[37, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: IRM model with random forest as learner": [[37, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-random-forest-as-learner"]], "Specify learner and estimate causal parameter: IRM model with Lasso as learner": [[37, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-Lasso-as-learner"]], "Examples": [[38, "examples"]], "Python: Case studies": [[38, "python-case-studies"]], "General Examples": [[38, "general-examples"]], "Effect Heterogeneity": [[38, "effect-heterogeneity"]], "R: Case studies": [[38, "r-case-studies"]], "Sandbox": [[38, "sandbox"]], "Python: Basic Instrumental Variables calculation": [[39, "Python:-Basic-Instrumental-Variables-calculation"]], "Python: Basics of Double Machine Learning": [[40, "Python:-Basics-of-Double-Machine-Learning"]], "Python: Conditional Average Treatment Effects (CATEs) for IRM models": [[41, "Python:-Conditional-Average-Treatment-Effects-(CATEs)-for-IRM-models"]], "One-dimensional Example": [[41, "One-dimensional-Example"], [42, "One-dimensional-Example"]], "Two-Dimensional Example": [[41, "Two-Dimensional-Example"], [42, "Two-Dimensional-Example"]], "Python: Conditional Average Treatment Effects (CATEs) for PLR models": [[42, "Python:-Conditional-Average-Treatment-Effects-(CATEs)-for-PLR-models"]], "Python: Conditional Value at Risk of potential outcomes": [[43, "Python:-Conditional-Value-at-Risk-of-potential-outcomes"]], "Conditional Value at Risk (CVaR)": [[43, "Conditional-Value-at-Risk-(CVaR)"]], "CVaR Treatment Effects": [[43, "CVaR-Treatment-Effects"]], "Python: Difference-in-Differences": [[44, "Python:-Difference-in-Differences"]], "Panel Data (Repeated Outcomes)": [[44, "Panel-Data-(Repeated-Outcomes)"]], "ATTE Estimation": [[44, "ATTE-Estimation"], [44, "id2"]], "Coverage Simulation": [[44, "Coverage-Simulation"], [44, "id3"]], "Repeated Cross-Sectional Data": [[44, "Repeated-Cross-Sectional-Data"]], "Python: Difference-in-Differences Pre-Testing": [[45, "Python:-Difference-in-Differences-Pre-Testing"]], "Python: First Stage and Causal Estimation": [[46, "Python:-First-Stage-and-Causal-Estimation"]], "Causal estimation vs. lasso penalty \\lambda": [[46, "Causal-estimation-vs.-lasso-penalty-\\lambda"]], "Estimation quality vs. \\lambda": [[46, "Estimation-quality-vs.-\\lambda"]], "Empirical coverage vs. lasso penalty \\lambda": [[46, "Empirical-coverage-vs.-lasso-penalty-\\lambda"]], "Combined loss vs. lasso penalty \\lambda": [[46, "Combined-loss-vs.-lasso-penalty-\\lambda"]], "Python: Group Average Treatment Effects (GATEs) for IRM models": [[47, "Python:-Group-Average-Treatment-Effects-(GATEs)-for-IRM-models"]], "Group Average Treatment Effects (GATEs)": [[47, "Group-Average-Treatment-Effects-(GATEs)"], [48, "Group-Average-Treatment-Effects-(GATEs)"]], "Python: Group Average Treatment Effects (GATEs) for PLR models": [[48, "Python:-Group-Average-Treatment-Effects-(GATEs)-for-PLR-models"]], "Python: GATE Sensitivity Analysis": [[49, "Python:-GATE-Sensitivity-Analysis"]], "ATE Estimation and Sensitivity": [[49, "ATE-Estimation-and-Sensitivity"]], "GATE Estimation and Sensitivity": [[49, "GATE-Estimation-and-Sensitivity"]], "GATET Estimation and Sensitivity": [[49, "GATET-Estimation-and-Sensitivity"]], "Python: Choice of learners": [[50, "Python:-Choice-of-learners"]], "Comparing different learners": [[50, "Comparing-different-learners"]], "Standard approach": [[50, "Standard-approach"]], "Custom evaluation metrics": [[50, "Custom-evaluation-metrics"]], "Computation time": [[50, "Computation-time"]], "Python: Cluster Robust Double Machine Learning": [[51, "Python:-Cluster-Robust-Double-Machine-Learning"]], "Python: Impact of 401(k) on Financial Wealth": [[52, "Python:-Impact-of-401(k)-on-Financial-Wealth"]], "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)": [[53, "Python:-Impact-of-401(k)-on-Financial-Wealth-(Quantile-Effects)"]], "Estimating Potential Quantiles and Quantile Treatment Effects": [[53, "Estimating-Potential-Quantiles-and-Quantile-Treatment-Effects"]], "Estimating the treatment effect on the Conditional Value a Risk (CVaR)": [[53, "Estimating-the-treatment-effect-on-the-Conditional-Value-a-Risk-(CVaR)"]], "Estimating local quantile treatment effects (LQTEs)": [[53, "Estimating-local-quantile-treatment-effects-(LQTEs)"]], "Python: Policy Learning with Trees": [[54, "Python:-Policy-Learning-with-Trees"]], "Policy Learning with Trees": [[54, "Policy-Learning-with-Trees"], [62, "policy-learning-with-trees"]], "Python: Potential Quantiles and Quantile Treatment Effects": [[55, "Python:-Potential-Quantiles-and-Quantile-Treatment-Effects"]], "Potential Quantiles (PQs)": [[55, "Potential-Quantiles-(PQs)"]], "Potential Quantile Estimation": [[55, "Potential-Quantile-Estimation"]], "Quantile Treatment Effects (QTEs)": [[55, "Quantile-Treatment-Effects-(QTEs)"]], "Local Potential Quantiles (LPQs)": [[55, "Local-Potential-Quantiles-(LPQs)"]], "Local Potential Quantile Estimation": [[55, "Local-Potential-Quantile-Estimation"]], "Local Quantile Treatment Effects (LQTEs)": [[55, "Local-Quantile-Treatment-Effects-(LQTEs)"]], "Python: Sensitivity Analysis": [[56, "Python:-Sensitivity-Analysis"]], "Simulation Example": [[56, "Simulation-Example"]], "DoubleML Object": [[56, "DoubleML-Object"]], "Sensitivity Analysis": [[56, "Sensitivity-Analysis"], [56, "id1"]], "Application: 401(k)": [[56, "Application:-401(k)"]], "Data and Effect Estimation": [[56, "Data-and-Effect-Estimation"]], "Benchmarking Analysis": [[56, "Benchmarking-Analysis"]], "Sensitivity Analysis with IRM": [[56, "Sensitivity-Analysis-with-IRM"]], "Python: Sample Selection Models": [[57, "Python:-Sample-Selection-Models"]], "Outcome missing at random (MAR)": [[57, "Outcome-missing-at-random-(MAR)"]], "Estimation": [[57, "Estimation"], [57, "id2"]], "ATE estimates distribution": [[57, "ATE-estimates-distribution"], [57, "id3"]], "Outcome missing under nonignorable nonresponse": [[57, "Outcome-missing-under-nonignorable-nonresponse"]], "Double machine learning algorithms": [[58, "double-machine-learning-algorithms"]], "Algorithm DML1": [[58, "algorithm-dml1"]], "Algorithm DML2": [[58, "algorithm-dml2"]], "Implementation of the double machine learning algorithms": [[58, "implementation-of-the-double-machine-learning-algorithms"]], "The basics of double/debiased machine learning": [[59, "the-basics-of-double-debiased-machine-learning"]], "Data generating process": [[59, "data-generating-process"]], "Regularization bias in simple ML-approaches": [[59, "regularization-bias-in-simple-ml-approaches"]], "The data-backend DoubleMLData": [[60, "the-data-backend-doublemldata"], [72, "the-data-backend-doublemldata"]], "DoubleMLData from dataframes": [[60, "doublemldata-from-dataframes"]], "DoubleMLData from arrays and matrices": [[60, "doublemldata-from-arrays-and-matrices"]], "User guide": [[61, "user-guide"]], "Heterogeneous treatment effects": [[62, "heterogeneous-treatment-effects"]], "Group average treatment effects (GATEs)": [[62, "group-average-treatment-effects-gates"]], "GATEs for IRM models": [[62, "gates-for-irm-models"]], "GATEs for PLR models": [[62, "gates-for-plr-models"]], "Conditional average treatment effects (CATEs)": [[62, "conditional-average-treatment-effects-cates"]], "CATEs for IRM models": [[62, "cates-for-irm-models"]], "CATEs for PLR models": [[62, "cates-for-plr-models"]], "Weighted Average Treatment Effects": [[62, "weighted-average-treatment-effects"]], "Quantiles": [[62, "quantiles"]], "Potential quantiles (PQs)": [[62, "potential-quantiles-pqs"], [66, "potential-quantiles-pqs"]], "Quantile treatment effects (QTEs)": [[62, "quantile-treatment-effects-qtes"]], "Conditional value at risk (CVaR)": [[62, "conditional-value-at-risk-cvar"], [66, "conditional-value-at-risk-cvar"]], "CVaR of potential outcomes": [[62, "cvar-of-potential-outcomes"]], "CVaR treatment effects": [[62, "cvar-treatment-effects"]], "Learners, hyperparameters and hyperparameter tuning": [[63, "learners-hyperparameters-and-hyperparameter-tuning"]], "Python: Learners and hyperparameters": [[63, "python-learners-and-hyperparameters"]], "Minimum requirements for learners": [[63, "minimum-requirements-for-learners"], [63, "id3"]], "Specifying learners and set hyperparameters": [[63, "specifying-learners-and-set-hyperparameters"], [63, "id10"]], "Hyperparameter tuning": [[63, "hyperparameter-tuning"], [63, "id17"]], "Evaluate learners": [[63, "evaluate-learners"]], "Advanced: External Predictions": [[63, "advanced-external-predictions"]], "R: Learners and hyperparameters": [[63, "r-learners-and-hyperparameters"]], "Using pipelines to construct learners": [[63, "using-pipelines-to-construct-learners"]], "Hyperparameter tuning with pipelines": [[63, "hyperparameter-tuning-with-pipelines"]], "Models": [[64, "models"]], "Partially linear regression model (PLR)": [[64, "partially-linear-regression-model-plr"], [66, "partially-linear-regression-model-plr"], [68, "partially-linear-regression-model-plr"]], "Partially linear IV regression model (PLIV)": [[64, "partially-linear-iv-regression-model-pliv"], [66, "partially-linear-iv-regression-model-pliv"]], "Interactive regression model (IRM)": [[64, "interactive-regression-model-irm"], [66, "interactive-regression-model-irm"], [68, "interactive-regression-model-irm"]], "Interactive IV model (IIVM)": [[64, "interactive-iv-model-iivm"], [66, "interactive-iv-model-iivm"]], "Difference-in-Differences Models (DID)": [[64, "difference-in-differences-models-did"]], "Panel data": [[64, "panel-data"]], "Repeated cross-sections": [[64, "repeated-cross-sections"]], "Sample Selection Models (SSM)": [[64, "sample-selection-models-ssm"]], "Missingness at Random": [[64, "missingness-at-random"], [66, "missingness-at-random"]], "Nonignorable Nonresponse": [[64, "nonignorable-nonresponse"], [66, "nonignorable-nonresponse"]], "Sample-splitting, cross-fitting and repeated cross-fitting": [[65, "sample-splitting-cross-fitting-and-repeated-cross-fitting"]], "Cross-fitting with K folds": [[65, "cross-fitting-with-k-folds"]], "Repeated cross-fitting with K folds and M repetitions": [[65, "repeated-cross-fitting-with-k-folds-and-m-repetitions"]], "Externally provide a sample splitting / partition": [[65, "externally-provide-a-sample-splitting-partition"]], "Sample-splitting without cross-fitting": [[65, "sample-splitting-without-cross-fitting"]], "Estimate DML models without sample-splitting": [[65, "estimate-dml-models-without-sample-splitting"]], "Score functions": [[66, "score-functions"]], "Implementation of the score function and the estimate of the causal parameter": [[66, "implementation-of-the-score-function-and-the-estimate-of-the-causal-parameter"]], "Implemented Neyman orthogonal score functions": [[66, "implemented-neyman-orthogonal-score-functions"]], "Difference-in-Differences for Panel Data": [[66, "difference-in-differences-for-panel-data"], [68, "difference-in-differences-for-panel-data"]], "Difference-in-Differences for repeated cross-sections": [[66, "difference-in-differences-for-repeated-cross-sections"], [68, "difference-in-differences-for-repeated-cross-sections"]], "Local potential quantiles (LPQs)": [[66, "local-potential-quantiles-lpqs"]], "Specifying alternative score functions via callables": [[66, "specifying-alternative-score-functions-via-callables"]], "Variance estimation and confidence intervals": [[67, "variance-estimation-and-confidence-intervals"]], "Variance estimation": [[67, "variance-estimation"]], "Confidence bands and multiplier bootstrap for valid simultaneous inference": [[67, "confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference"], [69, "confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference"]], "Simultaneous inference over different DoubleML models (advanced)": [[67, "simultaneous-inference-over-different-doubleml-models-advanced"]], "Sensitivity analysis": [[68, "sensitivity-analysis"]], "General algorithm": [[68, "general-algorithm"]], "Theory": [[68, "theory"]], "Implementation": [[68, "implementation"]], "Benchmarking": [[68, "benchmarking"]], "Model-specific implementations": [[68, "model-specific-implementations"]], "Multiplier bootstrap and joint confidence intervals": [[69, "multiplier-bootstrap-and-joint-confidence-intervals"]], "DoubleML": [[70, "doubleml"]], "Double Machine Learning Algorithm": [[70, "double-machine-learning-algorithm"]], "Main Features": [[70, "main-features"]], "Source code and maintenance": [[70, "source-code-and-maintenance"]], "Citation": [[70, "citation"]], "Acknowledgements": [[70, "acknowledgements"]], "Installing DoubleML": [[71, "installing-doubleml"]], "Python: Installing DoubleML": [[71, "python-installing-doubleml"]], "Python: Installing the latest release from pip or conda": [[71, "python-installing-the-latest-release-from-pip-or-conda"]], "Python: Installing a released version from a .whl file": [[71, "python-installing-a-released-version-from-a-whl-file"]], "Python: Building the package from source": [[71, "python-building-the-package-from-source"]], "R: Installing DoubleML": [[71, "r-installing-doubleml"]], "R: Installing the latest release from CRAN": [[71, "r-installing-the-latest-release-from-cran"]], "R: Installing the development version from GitHub": [[71, "r-installing-the-development-version-from-github"]], "Getting started": [[72, "getting-started"]], "The causal model": [[72, "the-causal-model"]], "Learners to estimate the nuisance models": [[72, "learners-to-estimate-the-nuisance-models"]], "Cross-fitting, DML algorithms and Neyman-orthogonal score functions": [[72, "cross-fitting-dml-algorithms-and-neyman-orthogonal-score-functions"]], "Estimate double/debiased machine learning models": [[72, "estimate-double-debiased-machine-learning-models"]], "Double machine learning literature": [[73, "double-machine-learning-literature"]], "Release notes": [[74, "release-notes"]], "DoubleML Workflow": [[75, "doubleml-workflow"]], "0. Problem Formulation": [[75, "problem-formulation"]], "1. Data-Backend": [[75, "data-backend"]], "2. Causal Model": [[75, "causal-model"]], "3. ML Methods": [[75, "ml-methods"]], "4. DML Specifications": [[75, "dml-specifications"]], "5. Estimation": [[75, "estimation"]], "6. Inference": [[75, "inference"]], "7. Sensitivity Analysis": [[75, "sensitivity-analysis"]]}, "indexentries": {"doublemlblp (class in doubleml)": [[1, "doubleml.DoubleMLBLP"]], "confint() (doubleml.doublemlblp method)": [[1, "doubleml.DoubleMLBLP.confint"]], "fit() (doubleml.doublemlblp method)": [[1, "doubleml.DoubleMLBLP.fit"]], "doublemlcvar (class in doubleml)": [[2, "doubleml.DoubleMLCVAR"]], "bootstrap() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.bootstrap"]], "confint() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.confint"]], "construct_framework() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.construct_framework"]], "draw_sample_splitting() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.draw_sample_splitting"]], "evaluate_learners() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.evaluate_learners"]], "fit() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.fit"]], "get_params() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.get_params"]], "p_adjust() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.p_adjust"]], "sensitivity_analysis() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.sensitivity_analysis"]], "sensitivity_benchmark() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.sensitivity_benchmark"]], "sensitivity_plot() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.sensitivity_plot"]], "set_ml_nuisance_params() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.set_ml_nuisance_params"]], "set_sample_splitting() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.set_sample_splitting"]], "tune() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.tune"]], "doublemlclusterdata (class in doubleml)": [[3, "doubleml.DoubleMLClusterData"]], "from_arrays() (doubleml.doublemlclusterdata class method)": [[3, "doubleml.DoubleMLClusterData.from_arrays"]], "set_x_d() (doubleml.doublemlclusterdata method)": [[3, "doubleml.DoubleMLClusterData.set_x_d"]], "doublemldid (class in doubleml)": [[4, "doubleml.DoubleMLDID"]], "bootstrap() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.bootstrap"]], "confint() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.confint"]], "construct_framework() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.construct_framework"]], "draw_sample_splitting() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.draw_sample_splitting"]], "evaluate_learners() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.evaluate_learners"]], "fit() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.fit"]], "get_params() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.get_params"]], "p_adjust() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.p_adjust"]], "sensitivity_analysis() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.sensitivity_analysis"]], "sensitivity_benchmark() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.sensitivity_benchmark"]], "sensitivity_plot() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.sensitivity_plot"]], "set_ml_nuisance_params() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.set_ml_nuisance_params"]], "set_sample_splitting() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.set_sample_splitting"]], "tune() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.tune"]], "doublemldidcs (class in doubleml)": [[5, "doubleml.DoubleMLDIDCS"]], "bootstrap() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.bootstrap"]], "confint() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.confint"]], "construct_framework() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.construct_framework"]], "draw_sample_splitting() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.draw_sample_splitting"]], "evaluate_learners() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.evaluate_learners"]], "fit() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.fit"]], "get_params() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.get_params"]], "p_adjust() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.p_adjust"]], "sensitivity_analysis() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.sensitivity_analysis"]], "sensitivity_benchmark() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.sensitivity_benchmark"]], "sensitivity_plot() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.sensitivity_plot"]], "set_ml_nuisance_params() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.set_ml_nuisance_params"]], "set_sample_splitting() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.set_sample_splitting"]], "tune() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.tune"]], "doublemldata (class in doubleml)": [[6, "doubleml.DoubleMLData"]], "from_arrays() (doubleml.doublemldata class method)": [[6, "doubleml.DoubleMLData.from_arrays"]], "set_x_d() (doubleml.doublemldata method)": [[6, "doubleml.DoubleMLData.set_x_d"]], "doublemliivm (class in doubleml)": [[7, "doubleml.DoubleMLIIVM"]], "bootstrap() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.bootstrap"]], "confint() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.confint"]], "construct_framework() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.construct_framework"]], "draw_sample_splitting() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.draw_sample_splitting"]], "evaluate_learners() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.evaluate_learners"]], "fit() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.fit"]], "get_params() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.get_params"]], "p_adjust() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.p_adjust"]], "sensitivity_analysis() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.sensitivity_analysis"]], "sensitivity_benchmark() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.sensitivity_benchmark"]], "sensitivity_plot() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.sensitivity_plot"]], "set_ml_nuisance_params() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.set_ml_nuisance_params"]], "set_sample_splitting() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.set_sample_splitting"]], "tune() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.tune"]], "doublemlirm (class in doubleml)": [[8, "doubleml.DoubleMLIRM"]], "bootstrap() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.bootstrap"]], "cate() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.cate"]], "confint() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.confint"]], "construct_framework() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.construct_framework"]], "draw_sample_splitting() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.draw_sample_splitting"]], "evaluate_learners() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.evaluate_learners"]], "fit() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.fit"]], "gate() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.gate"]], "get_params() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.get_params"]], "p_adjust() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.p_adjust"]], "policy_tree() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.policy_tree"]], "sensitivity_analysis() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.sensitivity_analysis"]], "sensitivity_benchmark() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.sensitivity_benchmark"]], "sensitivity_plot() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.sensitivity_plot"]], "set_ml_nuisance_params() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.set_ml_nuisance_params"]], "set_sample_splitting() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.set_sample_splitting"]], "tune() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.tune"]], "doublemllpq (class in doubleml)": [[9, "doubleml.DoubleMLLPQ"]], "bootstrap() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.bootstrap"]], "confint() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.confint"]], "construct_framework() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.construct_framework"]], "draw_sample_splitting() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.draw_sample_splitting"]], "evaluate_learners() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.evaluate_learners"]], "fit() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.fit"]], "get_params() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.get_params"]], "p_adjust() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.p_adjust"]], "sensitivity_analysis() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.sensitivity_analysis"]], "sensitivity_benchmark() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.sensitivity_benchmark"]], "sensitivity_plot() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.sensitivity_plot"]], "set_ml_nuisance_params() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.set_ml_nuisance_params"]], "set_sample_splitting() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.set_sample_splitting"]], "tune() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.tune"]], "doublemlpliv (class in doubleml)": [[10, "doubleml.DoubleMLPLIV"]], "bootstrap() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.bootstrap"]], "confint() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.confint"]], "construct_framework() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.construct_framework"]], "draw_sample_splitting() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.draw_sample_splitting"]], "evaluate_learners() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.evaluate_learners"]], "fit() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.fit"]], "get_params() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.get_params"]], "p_adjust() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.p_adjust"]], "sensitivity_analysis() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.sensitivity_analysis"]], "sensitivity_benchmark() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.sensitivity_benchmark"]], "sensitivity_plot() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.sensitivity_plot"]], "set_ml_nuisance_params() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.set_ml_nuisance_params"]], "set_sample_splitting() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.set_sample_splitting"]], "tune() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.tune"]], "doublemlplr (class in doubleml)": [[11, "doubleml.DoubleMLPLR"]], "bootstrap() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.bootstrap"]], "cate() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.cate"]], "confint() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.confint"]], "construct_framework() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.construct_framework"]], "draw_sample_splitting() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.draw_sample_splitting"]], "evaluate_learners() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.evaluate_learners"]], "fit() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.fit"]], "gate() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.gate"]], "get_params() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.get_params"]], "p_adjust() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.p_adjust"]], "sensitivity_analysis() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.sensitivity_analysis"]], "sensitivity_benchmark() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.sensitivity_benchmark"]], "sensitivity_plot() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.sensitivity_plot"]], "set_ml_nuisance_params() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.set_ml_nuisance_params"]], "set_sample_splitting() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.set_sample_splitting"]], "tune() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.tune"]], "doublemlpq (class in doubleml)": [[12, "doubleml.DoubleMLPQ"]], "bootstrap() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.bootstrap"]], "confint() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.confint"]], "construct_framework() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.construct_framework"]], "draw_sample_splitting() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.draw_sample_splitting"]], "evaluate_learners() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.evaluate_learners"]], "fit() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.fit"]], "get_params() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.get_params"]], "p_adjust() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.p_adjust"]], "sensitivity_analysis() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.sensitivity_analysis"]], "sensitivity_benchmark() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.sensitivity_benchmark"]], "sensitivity_plot() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.sensitivity_plot"]], "set_ml_nuisance_params() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.set_ml_nuisance_params"]], "set_sample_splitting() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.set_sample_splitting"]], "tune() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.tune"]], "doublemlqte (class in doubleml)": [[13, "doubleml.DoubleMLQTE"]], "bootstrap() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.bootstrap"]], "confint() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.confint"]], "draw_sample_splitting() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.draw_sample_splitting"]], "fit() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.fit"]], "p_adjust() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.p_adjust"]], "fetch_401k() (in module doubleml.datasets)": [[14, "doubleml.datasets.fetch_401K"]], "fetch_bonus() (in module doubleml.datasets)": [[15, "doubleml.datasets.fetch_bonus"]], "make_confounded_irm_data() (in module doubleml.datasets)": [[16, "doubleml.datasets.make_confounded_irm_data"]], "make_confounded_plr_data() (in module doubleml.datasets)": [[17, "doubleml.datasets.make_confounded_plr_data"]], "make_did_sz2020() (in module doubleml.datasets)": [[18, "doubleml.datasets.make_did_SZ2020"]], "make_heterogeneous_data() (in module doubleml.datasets)": [[19, "doubleml.datasets.make_heterogeneous_data"]], "make_iivm_data() (in module doubleml.datasets)": [[20, "doubleml.datasets.make_iivm_data"]], "make_irm_data() (in module doubleml.datasets)": [[21, "doubleml.datasets.make_irm_data"]], "make_pliv_chs2015() (in module doubleml.datasets)": [[22, "doubleml.datasets.make_pliv_CHS2015"]], "make_pliv_multiway_cluster_ckms2021() (in module doubleml.datasets)": [[23, "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021"]], "make_plr_ccddhnr2018() (in module doubleml.datasets)": [[24, "doubleml.datasets.make_plr_CCDDHNR2018"]], "make_plr_turrell2018() (in module doubleml.datasets)": [[25, "doubleml.datasets.make_plr_turrell2018"]], "make_ssm_data() (in module doubleml.datasets)": [[26, "doubleml.datasets.make_ssm_data"]], "linearscoremixin (class in doubleml.double_ml_score_mixins)": [[27, "doubleml.double_ml_score_mixins.LinearScoreMixin"]], "nonlinearscoremixin (class in doubleml.double_ml_score_mixins)": [[28, "doubleml.double_ml_score_mixins.NonLinearScoreMixin"]], "dmldummyclassifier (class in doubleml.utils)": [[29, "doubleml.utils.DMLDummyClassifier"]], "fit() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.fit"]], "get_metadata_routing() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.get_metadata_routing"]], "get_params() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.get_params"]], "predict() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.predict"]], "predict_proba() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.predict_proba"]], "set_params() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.set_params"]], "dmldummyregressor (class in doubleml.utils)": [[30, "doubleml.utils.DMLDummyRegressor"]], "fit() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.fit"]], "get_metadata_routing() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.get_metadata_routing"]], "get_params() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.get_params"]], "predict() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.predict"]], "set_params() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.set_params"]], "gain_statistics() (in module doubleml.utils)": [[31, "doubleml.utils.gain_statistics"]]}})