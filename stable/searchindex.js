Search.setIndex({"alltitles": {"(One-Way) Cluster Robust Double Machine Learing": [[50, "(One-Way)-Cluster-Robust-Double-Machine-Learing"], [69, "(One-Way)-Cluster-Robust-Double-Machine-Learing"]], "0. Problem Formulation": [[115, "problem-formulation"]], "1. Data-Backend": [[115, "data-backend"]], "1. Formulation of Causal Model & Identification Assumptions": [[77, "1.-Formulation-of-Causal-Model-&-Identification-Assumptions"]], "2. Causal Model": [[115, "causal-model"]], "2. Estimation of Causal Effect": [[77, "2.-Estimation-of-Causal-Effect"]], "3. ML Methods": [[115, "ml-methods"]], "3. Sensitivity Analysis": [[77, "3.-Sensitivity-Analysis"]], "4. Benchmarking Analysis": [[77, "4.-Benchmarking-Analysis"]], "4. DML Specifications": [[115, "dml-specifications"]], "5. Conclusion": [[77, "5.-Conclusion"]], "5. Estimation": [[115, "estimation"]], "6. Inference": [[115, "inference"]], "7. Sensitivity Analysis": [[115, "sensitivity-analysis"]], "A Motivating Example: Two-Way Cluster Robust DML": [[50, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"], [69, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"]], "API Reference": [[0, null]], "ATE Estimation and Sensitivity": [[66, "ATE-Estimation-and-Sensitivity"]], "ATE estimates distribution": [[78, "ATE-estimates-distribution"], [78, "id3"]], "ATTE Estimation": [[61, "ATTE-Estimation"], [61, "id2"]], "Acknowledgements": [[110, "acknowledgements"]], "Acknowledgements and Final Remarks": [[49, "Acknowledgements-and-Final-Remarks"]], "Additional Results: CATE estimates": [[72, "Additional-Results:-CATE-estimates"]], "Advanced: External Predictions": [[84, "advanced-external-predictions"]], "Advanced: Global and Local Learners, Stacked Ensembles": [[75, "Advanced:-Global-and-Local-Learners,-Stacked-Ensembles"]], "Algorithm DML1": [[79, "algorithm-dml1"]], "Algorithm DML2": [[79, "algorithm-dml2"]], "Application Results": [[50, "Application-Results"], [69, "Application-Results"]], "Application: 401(k)": [[76, "Application:-401(k)"]], "AutoML with less Computation time": [[68, "AutoML-with-less-Computation-time"]], "Average Potential Outcome (APOs)": [[55, "Average-Potential-Outcome-(APOs)"]], "Average Potential Outcomes (APOs)": [[85, "average-potential-outcomes-apos"], [87, "average-potential-outcomes-apos"], [101, "average-potential-outcomes-apos"]], "Average Potential Outcomes (APOs) for Multiple Treatment Levels": [[85, "average-potential-outcomes-apos-for-multiple-treatment-levels"]], "Benchmarking": [[101, "benchmarking"]], "Benchmarking Analysis": [[76, "Benchmarking-Analysis"]], "Binary Interactive Regression Model (IRM)": [[85, "binary-interactive-regression-model-irm"], [87, "binary-interactive-regression-model-irm"]], "CATEs for IRM models": [[83, "cates-for-irm-models"]], "CATEs for PLR models": [[83, "cates-for-plr-models"]], "CVaR Treatment Effects": [[60, "CVaR-Treatment-Effects"]], "CVaR of potential outcomes": [[83, "cvar-of-potential-outcomes"]], "CVaR treatment effects": [[83, "cvar-treatment-effects"]], "Causal Analysis with DoubleML": [[77, "Causal-Analysis-with-DoubleML"]], "Causal Contrasts": [[55, "Causal-Contrasts"]], "Causal estimation vs. lasso penalty \\lambda": [[63, "Causal-estimation-vs.-lasso-penalty-\\lambda"]], "Chernozhukov et al. (2023): Benchmarking": [[77, "Chernozhukov-et-al.-(2023):-Benchmarking"]], "Citation": [[110, "citation"]], "Cluster Robust Cross Fitting": [[50, "Cluster-Robust-Cross-Fitting"], [69, "Cluster-Robust-Cross-Fitting"]], "Cluster Robust Standard Errors": [[50, "Cluster-Robust-Standard-Errors"], [69, "Cluster-Robust-Standard-Errors"]], "Clustering and double machine learning": [[50, "Clustering-and-double-machine-learning"], [69, "Clustering-and-double-machine-learning"]], "Combined loss vs. lasso penalty \\lambda": [[63, "Combined-loss-vs.-lasso-penalty-\\lambda"]], "Compare Metrics for Nuisance Estimation": [[68, "Compare-Metrics-for-Nuisance-Estimation"]], "Comparing different learners": [[67, "Comparing-different-learners"]], "Comparison and summary": [[68, "Comparison-and-summary"]], "Comparison to AutoML with less Computation time and Untuned XGBoost Learners": [[68, "Comparison-to-AutoML-with-less-Computation-time-and-Untuned-XGBoost-Learners"]], "Comparison to did package": [[49, "Comparison-to-did-package"]], "Computation time": [[67, "Computation-time"]], "Conclusion": [[68, "Conclusion"]], "Conditional Value at Risk (CVaR)": [[60, "Conditional-Value-at-Risk-(CVaR)"]], "Conditional average treatment effects (CATEs)": [[83, "conditional-average-treatment-effects-cates"]], "Conditional value at risk (CVaR)": [[83, "conditional-value-at-risk-cvar"], [87, "conditional-value-at-risk-cvar"]], "Confidence bands and multiplier bootstrap for valid simultaneous inference": [[100, "confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference"]], "Coverage Simulation": [[61, "Coverage-Simulation"], [61, "id3"]], "Cross-fitting with K folds": [[86, "cross-fitting-with-k-folds"]], "Cross-fitting, DML algorithms and Neyman-orthogonal score functions": [[112, "cross-fitting-dml-algorithms-and-neyman-orthogonal-score-functions"]], "Custom evaluation metrics": [[67, "Custom-evaluation-metrics"]], "DML: Bonus Data": [[53, null]], "Data": [[51, "Data"], [58, "Data"], [59, "Data"], [60, "Data"], [61, "Data"], [61, "id1"], [64, "Data"], [65, "Data"], [66, "Data"], [70, "Data"], [71, "Data"], [73, "Data"], [74, "Data"], [74, "id1"], [76, "Data"], [78, "Data"], [78, "id1"], [112, "data"]], "Data Generating Process (DGP)": [[48, "Data-Generating-Process-(DGP)"], [55, "Data-Generating-Process-(DGP)"], [57, "Data-Generating-Process-(DGP)"]], "Data Generation": [[68, "Data-Generation"]], "Data Simulation": [[47, "Data-Simulation"], [56, "Data-Simulation"]], "Data and Effect Estimation": [[76, "Data-and-Effect-Estimation"]], "Data generating process": [[80, "data-generating-process"]], "Data preprocessing": [[52, "Data-preprocessing"]], "Data-Backend for Cluster Data": [[50, "Data-Backend-for-Cluster-Data"], [69, "Data-Backend-for-Cluster-Data"]], "Dataset Generators": [[2, "dataset-generators"]], "Dataset Loaders": [[2, "dataset-loaders"]], "Datasets": [[2, null]], "Define Helper Functions for Plotting": [[50, "Define-Helper-Functions-for-Plotting"], [69, "Define-Helper-Functions-for-Plotting"]], "Demo Example from did": [[49, "Demo-Example-from-did"]], "Details on Predictive Performance": [[49, "Details-on-Predictive-Performance"]], "Difference-in-Differences Models": [[87, "difference-in-differences-models"]], "Difference-in-Differences Models (DID)": [[85, "difference-in-differences-models-did"]], "Difference-in-Differences for Panel Data": [[101, "difference-in-differences-for-panel-data"]], "Difference-in-Differences for repeated cross-sections": [[101, "difference-in-differences-for-repeated-cross-sections"]], "Disclaimer": [[77, "Disclaimer"]], "Double Machine Learning Algorithm": [[110, "double-machine-learning-algorithm"]], "Double Machine Learning Literature": [[113, null]], "Double machine learning algorithms": [[79, null]], "Double/debiased machine learning": [[48, "Double/debiased-machine-learning"], [57, "Double/debiased-machine-learning"], [80, "double-debiased-machine-learning"]], "DoubleML": [[110, null]], "DoubleML Data Class": [[1, null]], "DoubleML Models": [[3, null]], "DoubleML Object": [[76, "DoubleML-Object"]], "DoubleML Workflow": [[115, null]], "DoubleML meets FLAML - How to tune learners automatically within DoubleML": [[68, null]], "DoubleMLData from arrays and matrices": [[81, "doublemldata-from-arrays-and-matrices"]], "DoubleMLData from dataframes": [[81, "doublemldata-from-dataframes"]], "Effect Heterogeneity": [[54, "effect-heterogeneity"]], "Empirical coverage vs. lasso penalty \\lambda": [[63, "Empirical-coverage-vs.-lasso-penalty-\\lambda"]], "Estimate DML models without sample-splitting": [[86, "estimate-dml-models-without-sample-splitting"]], "Estimate double/debiased machine learning models": [[112, "estimate-double-debiased-machine-learning-models"]], "Estimating Potential Quantiles and Quantile Treatment Effects": [[71, "Estimating-Potential-Quantiles-and-Quantile-Treatment-Effects"]], "Estimating local quantile treatment effects (LQTEs)": [[71, "Estimating-local-quantile-treatment-effects-(LQTEs)"]], "Estimating the Average Treatment Effect of 401(k) Eligibility on Net Financial Assets": [[51, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"], [70, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"]], "Estimating the treatment effect on the Conditional Value a Risk (CVaR)": [[71, "Estimating-the-treatment-effect-on-the-Conditional-Value-a-Risk-(CVaR)"]], "Estimation": [[78, "Estimation"], [78, "id2"]], "Estimation quality vs. \\lambda": [[63, "Estimation-quality-vs.-\\lambda"]], "Evaluate learners": [[84, "evaluate-learners"]], "Example: Sensitivity Analysis for Causal ML": [[77, null]], "Examples": [[54, null]], "Exploiting the Functionalities of did": [[49, "Exploiting-the-Functionalities-of-did"]], "Externally provide a sample splitting / partition": [[86, "externally-provide-a-sample-splitting-partition"]], "Flexible Covariate Adjustment in Regression Discontinuity Designs (RDD)": [[75, null]], "Fuzzy RDD": [[75, "Fuzzy-RDD"]], "Fuzzy RDD Without Adjustment": [[75, "Fuzzy-RDD-Without-Adjustment"]], "Fuzzy RDD with Flexible Adjustment": [[75, "Fuzzy-RDD-with-Flexible-Adjustment"]], "Fuzzy RDD with Linear Adjustment": [[75, "Fuzzy-RDD-with-Linear-Adjustment"]], "Fuzzy Regression Discontinuity Design": [[85, "fuzzy-regression-discontinuity-design"]], "GATE Estimation and Sensitivity": [[66, "GATE-Estimation-and-Sensitivity"]], "GATET Estimation and Sensitivity": [[66, "GATET-Estimation-and-Sensitivity"]], "GATEs for IRM models": [[83, "gates-for-irm-models"]], "GATEs for PLR models": [[83, "gates-for-plr-models"]], "General Examples": [[54, "general-examples"]], "General algorithm": [[101, "general-algorithm"]], "Generate Fuzzy Data": [[75, "Generate-Fuzzy-Data"]], "Generate Sharp Data": [[75, "Generate-Sharp-Data"]], "Getting Started": [[112, null]], "Group Average Treatment Effects (GATEs)": [[64, "Group-Average-Treatment-Effects-(GATEs)"], [65, "Group-Average-Treatment-Effects-(GATEs)"]], "Group average treatment effects (GATEs)": [[83, "group-average-treatment-effects-gates"]], "Heterogeneous treatment effects": [[83, null]], "How to exploit more features of mlr3pipelines in DoubleML": [[52, "How-to-exploit-more-features-of-mlr3pipelines-in-DoubleML"]], "Hyperparameter tuning": [[84, "hyperparameter-tuning"], [84, "id16"]], "Hyperparameter tuning with pipelines": [[84, "hyperparameter-tuning-with-pipelines"]], "Implementation": [[101, "implementation"]], "Implementation Details": [[85, "implementation-details"]], "Implementation of the double machine learning algorithms": [[79, "implementation-of-the-double-machine-learning-algorithms"]], "Implementation of the score function and the estimate of the causal parameter": [[87, "implementation-of-the-score-function-and-the-estimate-of-the-causal-parameter"]], "Implemented Neyman orthogonal score functions": [[87, "implemented-neyman-orthogonal-score-functions"]], "Initialize DoubleMLClusterData object": [[50, "Initialize-DoubleMLClusterData-object"], [69, "Initialize-DoubleMLClusterData-object"]], "Initialize the objects of class DoubleMLPLIV": [[50, "Initialize-the-objects-of-class-DoubleMLPLIV"], [69, "Initialize-the-objects-of-class-DoubleMLPLIV"]], "Installing DoubleML": [[111, null]], "Instrumental Variables Directed Acyclic Graph (IV - DAG)": [[47, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"], [56, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"]], "Interactive IV Model (IIVM)": [[51, "Interactive-IV-Model-(IIVM)"], [70, "Interactive-IV-Model-(IIVM)"]], "Interactive IV model (IIVM)": [[85, "interactive-iv-model-iivm"], [87, "interactive-iv-model-iivm"]], "Interactive Regression Model (IRM)": [[51, "Interactive-Regression-Model-(IRM)"], [64, "Interactive-Regression-Model-(IRM)"], [70, "Interactive-Regression-Model-(IRM)"], [73, "Interactive-Regression-Model-(IRM)"]], "Interactive regression model (IRM)": [[101, "interactive-regression-model-irm"]], "Interactive regression models (IRM)": [[85, "interactive-regression-models-irm"], [87, "interactive-regression-models-irm"]], "Learners to estimate the nuisance models": [[112, "learners-to-estimate-the-nuisance-models"]], "Learners, hyperparameters and hyperparameter tuning": [[84, null]], "Load Data": [[77, "Load-Data"]], "Load and Process Data": [[50, "Load-and-Process-Data"], [69, "Load-and-Process-Data"]], "Load bonus data using the dml datasets module": [[53, "Load-bonus-data-using-the-dml-datasets-module"]], "Local Average Treatment Effects of 401(k) Participation on Net Financial Assets": [[51, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"], [70, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"]], "Local Potential Quantile Estimation": [[74, "Local-Potential-Quantile-Estimation"]], "Local Potential Quantiles (LPQs)": [[74, "Local-Potential-Quantiles-(LPQs)"]], "Local Quantile Treatment Effects (LQTEs)": [[74, "Local-Quantile-Treatment-Effects-(LQTEs)"]], "Local potential quantiles (LPQs)": [[87, "local-potential-quantiles-lpqs"]], "Main Features": [[110, "main-features"]], "Minimum requirements for learners": [[84, "minimum-requirements-for-learners"], [84, "id2"]], "Missingness at Random": [[85, "missingness-at-random"], [87, "missingness-at-random"]], "Model-specific implementations": [[101, "model-specific-implementations"]], "Models": [[85, null]], "Motivation": [[50, "Motivation"], [69, "Motivation"]], "Multiple Average Potential Outcome Models (APOS)": [[55, "Multiple-Average-Potential-Outcome-Models-(APOS)"]], "Naive estimation": [[47, "Naive-estimation"], [56, "Naive-estimation"]], "No Clustering / Zero-Way Clustering": [[50, "No-Clustering-/-Zero-Way-Clustering"], [69, "No-Clustering-/-Zero-Way-Clustering"]], "Nonignorable Nonresponse": [[85, "nonignorable-nonresponse"], [87, "nonignorable-nonresponse"]], "One-Way Clustering with Respect to the Market": [[50, "One-Way-Clustering-with-Respect-to-the-Market"], [69, "One-Way-Clustering-with-Respect-to-the-Market"]], "One-Way Clustering with Respect to the Product": [[50, "One-Way-Clustering-with-Respect-to-the-Product"], [69, "One-Way-Clustering-with-Respect-to-the-Product"]], "One-dimensional Example": [[58, "One-dimensional-Example"], [59, "One-dimensional-Example"]], "Other models": [[45, null]], "Outcome missing at random (MAR)": [[78, "Outcome-missing-at-random-(MAR)"]], "Outcome missing under nonignorable nonresponse": [[78, "Outcome-missing-under-nonignorable-nonresponse"]], "Overcoming regularization bias by orthogonalization": [[48, "Overcoming-regularization-bias-by-orthogonalization"], [57, "Overcoming-regularization-bias-by-orthogonalization"], [80, "overcoming-regularization-bias-by-orthogonalization"]], "Panel Data": [[87, "panel-data"]], "Panel Data (Repeated Outcomes)": [[61, "Panel-Data-(Repeated-Outcomes)"]], "Panel data": [[85, "panel-data"]], "Parameter tuning": [[52, "Parameter-tuning"]], "Partialling out score": [[48, "Partialling-out-score"], [57, "Partialling-out-score"], [80, "partialling-out-score"]], "Partially Linear Regression Model (PLR)": [[51, "Partially-Linear-Regression-Model-(PLR)"], [65, "Partially-Linear-Regression-Model-(PLR)"], [70, "Partially-Linear-Regression-Model-(PLR)"]], "Partially linear IV regression model (PLIV)": [[85, "partially-linear-iv-regression-model-pliv"], [87, "partially-linear-iv-regression-model-pliv"]], "Partially linear models (PLM)": [[85, "partially-linear-models-plm"], [87, "partially-linear-models-plm"]], "Partially linear regression model (PLR)": [[85, "partially-linear-regression-model-plr"], [87, "partially-linear-regression-model-plr"], [101, "partially-linear-regression-model-plr"]], "Plot Coefficients and 95% Confidence Intervals": [[68, "Plot-Coefficients-and-95%-Confidence-Intervals"]], "Policy Learning with Trees": [[73, "Policy-Learning-with-Trees"], [83, "policy-learning-with-trees"]], "Potential Quantile Estimation": [[74, "Potential-Quantile-Estimation"]], "Potential Quantiles (PQs)": [[74, "Potential-Quantiles-(PQs)"]], "Potential quantiles (PQs)": [[83, "potential-quantiles-pqs"], [87, "potential-quantiles-pqs"]], "Python: Average Potential Outcome (APO) Models": [[55, null]], "Python: Basic Instrumental Variables calculation": [[56, null]], "Python: Basics of Double Machine Learning": [[57, null]], "Python: Building the package from source": [[111, "python-building-the-package-from-source"]], "Python: Case studies": [[54, "python-case-studies"]], "Python: Choice of learners": [[67, null]], "Python: Cluster Robust Double Machine Learning": [[69, null]], "Python: Conditional Average Treatment Effects (CATEs) for IRM models": [[58, null]], "Python: Conditional Average Treatment Effects (CATEs) for PLR models": [[59, null]], "Python: Conditional Value at Risk of potential outcomes": [[60, null]], "Python: Difference-in-Differences": [[61, null]], "Python: Difference-in-Differences Pre-Testing": [[62, null]], "Python: First Stage and Causal Estimation": [[63, null]], "Python: GATE Sensitivity Analysis": [[66, null]], "Python: Group Average Treatment Effects (GATEs) for IRM models": [[64, null]], "Python: Group Average Treatment Effects (GATEs) for PLR models": [[65, null]], "Python: Impact of 401(k) on Financial Wealth": [[70, null]], "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)": [[71, null]], "Python: Installing DoubleML": [[111, "python-installing-doubleml"]], "Python: Installing a released version from a .whl file": [[111, "python-installing-a-released-version-from-a-whl-file"]], "Python: Installing the latest release from pip or conda": [[111, "python-installing-the-latest-release-from-pip-or-conda"]], "Python: Learners and hyperparameters": [[84, "python-learners-and-hyperparameters"]], "Python: Optional Dependencies": [[111, "python-optional-dependencies"]], "Python: PLM and IRM for Multiple Treatments": [[72, null]], "Python: Policy Learning with Trees": [[73, null]], "Python: Potential Quantiles and Quantile Treatment Effects": [[74, null]], "Python: Sample Selection Models": [[78, null]], "Python: Sensitivity Analysis": [[76, null]], "Quantile Treatment Effects (QTEs)": [[74, "Quantile-Treatment-Effects-(QTEs)"]], "Quantile treatment effects (QTEs)": [[83, "quantile-treatment-effects-qtes"]], "Quantiles": [[83, "quantiles"]], "R: Basic Instrumental Variables Calculation": [[47, null]], "R: Basics of Double Machine Learning": [[48, null]], "R: Case studies": [[54, "r-case-studies"]], "R: Cluster Robust Double Machine Learning": [[50, null]], "R: DoubleML for Difference-in-Differences": [[49, null]], "R: Ensemble Learners and More with mlr3pipelines": [[52, null]], "R: Impact of 401(k) on Financial Wealth": [[51, null]], "R: Installing DoubleML": [[111, "r-installing-doubleml"]], "R: Installing the development version from GitHub": [[111, "r-installing-the-development-version-from-github"]], "R: Installing the latest release from CRAN": [[111, "r-installing-the-latest-release-from-cran"]], "R: Learners and hyperparameters": [[84, "r-learners-and-hyperparameters"]], "Ranking Treatment Effects under Treatment Propensity and Treatment Effect Heterogeneity": [[72, "Ranking-Treatment-Effects-under-Treatment-Propensity-and-Treatment-Effect-Heterogeneity"]], "Real-Data Application": [[50, "Real-Data-Application"], [69, "Real-Data-Application"]], "References": [[47, "References"], [49, "References"], [50, "References"], [52, "References"], [56, "References"], [63, "References"], [69, "References"], [72, "References"], [77, "References"], [80, "references"], [84, "references"], [86, "references"], [100, "references"], [110, "references"], [112, "references"]], "Regression Discontinuity Designs (RDD)": [[85, "regression-discontinuity-designs-rdd"]], "Regularization Bias in Simple ML-Approaches": [[48, "Regularization-Bias-in-Simple-ML-Approaches"], [57, "Regularization-Bias-in-Simple-ML-Approaches"]], "Regularization bias in simple ML-approaches": [[80, "regularization-bias-in-simple-ml-approaches"]], "Release Notes": [[114, null]], "Repeated Cross-Sectional Data": [[61, "Repeated-Cross-Sectional-Data"], [87, "repeated-cross-sectional-data"]], "Repeated cross-fitting with K folds and M repetitions": [[86, "repeated-cross-fitting-with-k-folds-and-m-repetitions"]], "Repeated cross-sections": [[85, "repeated-cross-sections"]], "Sample Selection Models": [[87, "sample-selection-models"]], "Sample Selection Models (SSM)": [[85, "sample-selection-models-ssm"]], "Sample splitting to remove bias induced by overfitting": [[48, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [57, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [80, "sample-splitting-to-remove-bias-induced-by-overfitting"]], "Sample-splitting without cross-fitting": [[86, "sample-splitting-without-cross-fitting"]], "Sample-splitting, cross-fitting and repeated cross-fitting": [[86, null]], "Sandbox": [[54, "sandbox"]], "Score Mixin Classes for DoubleML Models": [[44, null]], "Score functions": [[87, null]], "Sensitivity Analysis": [[55, "Sensitivity-Analysis"], [76, "Sensitivity-Analysis"], [76, "id1"]], "Sensitivity Analysis with IRM": [[76, "Sensitivity-Analysis-with-IRM"]], "Sensitivity analysis": [[101, null]], "Set up learners based on mlr3pipelines": [[52, "Set-up-learners-based-on-mlr3pipelines"]], "Sharp RDD": [[75, "Sharp-RDD"]], "Sharp RDD Without Adjustment": [[75, "Sharp-RDD-Without-Adjustment"]], "Sharp RDD with Flexible Adjustment": [[75, "Sharp-RDD-with-Flexible-Adjustment"]], "Sharp RDD with Linear Adjustment": [[75, "Sharp-RDD-with-Linear-Adjustment"]], "Sharp Regression Discontinuity Design": [[85, "sharp-regression-discontinuity-design"]], "Simulate two-way cluster data": [[50, "Simulate-two-way-cluster-data"], [69, "Simulate-two-way-cluster-data"]], "Simulation Example": [[76, "Simulation-Example"]], "Simultaneous inference over different DoubleML models (advanced)": [[100, "simultaneous-inference-over-different-doubleml-models-advanced"]], "Single Average Potential Outcome Models (APO)": [[55, "Single-Average-Potential-Outcome-Models-(APO)"]], "Source code and maintenance": [[110, "source-code-and-maintenance"]], "Specify learner and estimate causal parameter: IRM model with Lasso as learner": [[53, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: IRM model with random forest as learner": [[53, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-random-forest-as-learner"]], "Specify learner and estimate causal parameter: PLR model with Lasso as learner": [[53, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: PLR model with random forest as learner": [[53, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-random-forest-as-learner"]], "Specifying alternative score functions via callables": [[87, "specifying-alternative-score-functions-via-callables"]], "Specifying learners and set hyperparameters": [[84, "specifying-learners-and-set-hyperparameters"], [84, "id9"]], "Standard approach": [[67, "Standard-approach"]], "Step 1: Custom API for FLAML Models within DoubleML": [[68, "Step-1:-Custom-API-for-FLAML-Models-within-DoubleML"]], "Step 1: Initialize and Train the AutoML Models:": [[68, "Step-1:-Initialize-and-Train-the-AutoML-Models:"]], "Step 2: Evaluate the Tuned Models": [[68, "Step-2:-Evaluate-the-Tuned-Models"]], "Step 2: Using the API when calling DoubleML\u2019s .fit() Method": [[68, "Step-2:-Using-the-API-when-calling-DoubleML's-.fit()-Method"]], "Step 3: Create and Fit DoubleML Model": [[68, "Step-3:-Create-and-Fit-DoubleML-Model"]], "Summary Figure": [[72, "Summary-Figure"]], "Summary of Results": [[51, "Summary-of-Results"], [70, "Summary-of-Results"]], "The Augmented Inverse Propensity Weighting Model estimates the ATE under arbitrary effect and propensity score heterogeneity": [[72, "The-Augmented-Inverse-Propensity-Weighting-Model-estimates-the-ATE-under-arbitrary-effect-and-propensity-score-heterogeneity"]], "The Data Backend: DoubleMLData": [[51, "The-Data-Backend:-DoubleMLData"], [70, "The-Data-Backend:-DoubleMLData"]], "The DoubleML package": [[51, "The-DoubleML-package"], [70, "The-DoubleML-package"]], "The Partially Linear Model performs overlap weighting": [[72, "The-Partially-Linear-Model-performs-overlap-weighting"]], "The basics of double/debiased machine learning": [[80, null]], "The causal model": [[112, "the-causal-model"]], "The data-backend DoubleMLData": [[81, null], [112, "the-data-backend-doublemldata"]], "Theory": [[101, "theory"]], "Tuning on the Folds": [[68, "Tuning-on-the-Folds"]], "Tuning on the full Sample": [[68, "Tuning-on-the-full-Sample"]], "Two-Dimensional Example": [[58, "Two-Dimensional-Example"], [59, "Two-Dimensional-Example"]], "Two-Way Clustering with Respect to Product and Market": [[50, "Two-Way-Clustering-with-Respect-to-Product-and-Market"], [69, "Two-Way-Clustering-with-Respect-to-Product-and-Market"]], "Untuned (default parameter) XGBoost": [[68, "Untuned-(default-parameter)-XGBoost"]], "Use ensemble learners based on mlr3pipelines": [[52, "Use-ensemble-learners-based-on-mlr3pipelines"]], "User Guide": [[82, null]], "Using DoubleML": [[47, "Using-DoubleML"], [56, "Using-DoubleML"]], "Using ML for DiD: Integrating DoubleML in did": [[49, "Using-ML-for-DiD:-Integrating-DoubleML-in-did"]], "Using learners from mlr3, mlr3learners and mlr3extralearners": [[52, "Using-learners-from-mlr3,-mlr3learners-and-mlr3extralearners"]], "Using pipelines to construct learners": [[84, "using-pipelines-to-construct-learners"]], "Utility Classes": [[46, "utility-classes"]], "Utility Classes and Functions": [[46, null]], "Utility Functions": [[46, "utility-functions"]], "VanderWeele and Arah (2011): Benchmarking": [[77, "VanderWeele-and-Arah-(2011):-Benchmarking"]], "Variance estimation": [[100, "variance-estimation"]], "Variance estimation and confidence intervals": [[100, null]], "Weighted Average Treatment Effects": [[83, "weighted-average-treatment-effects"]], "doubleml.DoubleMLAPO": [[4, null]], "doubleml.DoubleMLAPOS": [[5, null]], "doubleml.DoubleMLCVAR": [[6, null]], "doubleml.DoubleMLClusterData": [[7, null]], "doubleml.DoubleMLDID": [[8, null]], "doubleml.DoubleMLDIDCS": [[9, null]], "doubleml.DoubleMLData": [[10, null]], "doubleml.DoubleMLIIVM": [[11, null]], "doubleml.DoubleMLIRM": [[12, null]], "doubleml.DoubleMLLPQ": [[13, null]], "doubleml.DoubleMLPLIV": [[14, null]], "doubleml.DoubleMLPLR": [[15, null]], "doubleml.DoubleMLPQ": [[16, null]], "doubleml.DoubleMLQTE": [[17, null]], "doubleml.DoubleMLSSM": [[18, null]], "doubleml.datasets.fetch_401K": [[19, null]], "doubleml.datasets.fetch_bonus": [[20, null]], "doubleml.datasets.make_confounded_irm_data": [[21, null]], "doubleml.datasets.make_confounded_plr_data": [[22, null]], "doubleml.datasets.make_did_SZ2020": [[23, null]], "doubleml.datasets.make_heterogeneous_data": [[24, null]], "doubleml.datasets.make_iivm_data": [[25, null]], "doubleml.datasets.make_irm_data": [[26, null]], "doubleml.datasets.make_irm_data_discrete_treatments": [[27, null]], "doubleml.datasets.make_pliv_CHS2015": [[28, null]], "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021": [[29, null]], "doubleml.datasets.make_plr_CCDDHNR2018": [[30, null]], "doubleml.datasets.make_plr_turrell2018": [[31, null]], "doubleml.datasets.make_ssm_data": [[32, null]], "doubleml.double_ml_score_mixins.LinearScoreMixin": [[33, null]], "doubleml.double_ml_score_mixins.NonLinearScoreMixin": [[34, null]], "doubleml.rdd.RDFlex": [[35, null]], "doubleml.rdd.datasets.make_simple_rdd_data": [[36, null]], "doubleml.utils.DMLDummyClassifier": [[37, null]], "doubleml.utils.DMLDummyRegressor": [[38, null]], "doubleml.utils.DoubleMLBLP": [[39, null]], "doubleml.utils.DoubleMLPolicyTree": [[40, null]], "doubleml.utils.GlobalClassifier": [[41, null]], "doubleml.utils.GlobalRegressor": [[42, null]], "doubleml.utils.gain_statistics": [[43, null]]}, "docnames": ["api/api", "api/data_class", "api/datasets", "api/dml_models", "api/generated/doubleml.DoubleMLAPO", "api/generated/doubleml.DoubleMLAPOS", "api/generated/doubleml.DoubleMLCVAR", "api/generated/doubleml.DoubleMLClusterData", "api/generated/doubleml.DoubleMLDID", "api/generated/doubleml.DoubleMLDIDCS", "api/generated/doubleml.DoubleMLData", "api/generated/doubleml.DoubleMLIIVM", "api/generated/doubleml.DoubleMLIRM", "api/generated/doubleml.DoubleMLLPQ", "api/generated/doubleml.DoubleMLPLIV", "api/generated/doubleml.DoubleMLPLR", "api/generated/doubleml.DoubleMLPQ", "api/generated/doubleml.DoubleMLQTE", "api/generated/doubleml.DoubleMLSSM", "api/generated/doubleml.datasets.fetch_401K", "api/generated/doubleml.datasets.fetch_bonus", "api/generated/doubleml.datasets.make_confounded_irm_data", "api/generated/doubleml.datasets.make_confounded_plr_data", "api/generated/doubleml.datasets.make_did_SZ2020", "api/generated/doubleml.datasets.make_heterogeneous_data", "api/generated/doubleml.datasets.make_iivm_data", "api/generated/doubleml.datasets.make_irm_data", "api/generated/doubleml.datasets.make_irm_data_discrete_treatments", "api/generated/doubleml.datasets.make_pliv_CHS2015", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018", "api/generated/doubleml.datasets.make_plr_turrell2018", "api/generated/doubleml.datasets.make_ssm_data", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin", "api/generated/doubleml.rdd.RDFlex", "api/generated/doubleml.rdd.datasets.make_simple_rdd_data", "api/generated/doubleml.utils.DMLDummyClassifier", "api/generated/doubleml.utils.DMLDummyRegressor", "api/generated/doubleml.utils.DoubleMLBLP", "api/generated/doubleml.utils.DoubleMLPolicyTree", "api/generated/doubleml.utils.GlobalClassifier", "api/generated/doubleml.utils.GlobalRegressor", "api/generated/doubleml.utils.gain_statistics", "api/mixins", "api/other_models", "api/utility", "examples/R_double_ml_basic_iv", "examples/R_double_ml_basics", "examples/R_double_ml_did", "examples/R_double_ml_multiway_cluster", "examples/R_double_ml_pension", "examples/R_double_ml_pipeline", "examples/double_ml_bonus_data", "examples/index", "examples/py_double_ml_apo", "examples/py_double_ml_basic_iv", "examples/py_double_ml_basics", "examples/py_double_ml_cate", "examples/py_double_ml_cate_plr", "examples/py_double_ml_cvar", "examples/py_double_ml_did", "examples/py_double_ml_did_pretest", "examples/py_double_ml_firststage", "examples/py_double_ml_gate", "examples/py_double_ml_gate_plr", "examples/py_double_ml_gate_sensitivity", "examples/py_double_ml_learner", "examples/py_double_ml_meets_flaml", "examples/py_double_ml_multiway_cluster", "examples/py_double_ml_pension", "examples/py_double_ml_pension_qte", "examples/py_double_ml_plm_irm_hetfx", "examples/py_double_ml_policy_tree", "examples/py_double_ml_pq", "examples/py_double_ml_rdflex", "examples/py_double_ml_sensitivity", "examples/py_double_ml_sensitivity_booking", "examples/py_double_ml_ssm", "guide/algorithms", "guide/basics", "guide/data_backend", "guide/guide", "guide/heterogeneity", "guide/learners", "guide/models", "guide/resampling", "guide/scores", "guide/scores/apo_score", "guide/scores/cvar_score", "guide/scores/did_score", "guide/scores/didcs_score", "guide/scores/iivm_score", "guide/scores/irm_score", "guide/scores/lpq_score", "guide/scores/mar_score", "guide/scores/nr_score", "guide/scores/pliv_score", "guide/scores/plr_score", "guide/scores/pq_score", "guide/se_confint", "guide/sensitivity", "guide/sensitivity/apo_sensitivity", "guide/sensitivity/benchmarking", "guide/sensitivity/did_cs_sensitivity", "guide/sensitivity/did_sensitivity", "guide/sensitivity/implementation", "guide/sensitivity/irm_sensitivity", "guide/sensitivity/plr_sensitivity", "guide/sensitivity/theory", "index", "intro/install", "intro/intro", "literature/literature", "release/release", "workflow/workflow"], "envversion": {"nbsphinx": 4, "sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["api/api.rst", "api/data_class.rst", "api/datasets.rst", "api/dml_models.rst", "api/generated/doubleml.DoubleMLAPO.rst", "api/generated/doubleml.DoubleMLAPOS.rst", "api/generated/doubleml.DoubleMLCVAR.rst", "api/generated/doubleml.DoubleMLClusterData.rst", "api/generated/doubleml.DoubleMLDID.rst", "api/generated/doubleml.DoubleMLDIDCS.rst", "api/generated/doubleml.DoubleMLData.rst", "api/generated/doubleml.DoubleMLIIVM.rst", "api/generated/doubleml.DoubleMLIRM.rst", "api/generated/doubleml.DoubleMLLPQ.rst", "api/generated/doubleml.DoubleMLPLIV.rst", "api/generated/doubleml.DoubleMLPLR.rst", "api/generated/doubleml.DoubleMLPQ.rst", "api/generated/doubleml.DoubleMLQTE.rst", "api/generated/doubleml.DoubleMLSSM.rst", "api/generated/doubleml.datasets.fetch_401K.rst", "api/generated/doubleml.datasets.fetch_bonus.rst", "api/generated/doubleml.datasets.make_confounded_irm_data.rst", "api/generated/doubleml.datasets.make_confounded_plr_data.rst", "api/generated/doubleml.datasets.make_did_SZ2020.rst", "api/generated/doubleml.datasets.make_heterogeneous_data.rst", "api/generated/doubleml.datasets.make_iivm_data.rst", "api/generated/doubleml.datasets.make_irm_data.rst", "api/generated/doubleml.datasets.make_irm_data_discrete_treatments.rst", "api/generated/doubleml.datasets.make_pliv_CHS2015.rst", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021.rst", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018.rst", "api/generated/doubleml.datasets.make_plr_turrell2018.rst", "api/generated/doubleml.datasets.make_ssm_data.rst", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin.rst", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin.rst", "api/generated/doubleml.rdd.RDFlex.rst", "api/generated/doubleml.rdd.datasets.make_simple_rdd_data.rst", "api/generated/doubleml.utils.DMLDummyClassifier.rst", "api/generated/doubleml.utils.DMLDummyRegressor.rst", "api/generated/doubleml.utils.DoubleMLBLP.rst", "api/generated/doubleml.utils.DoubleMLPolicyTree.rst", "api/generated/doubleml.utils.GlobalClassifier.rst", "api/generated/doubleml.utils.GlobalRegressor.rst", "api/generated/doubleml.utils.gain_statistics.rst", "api/mixins.rst", "api/other_models.rst", "api/utility.rst", "examples/R_double_ml_basic_iv.ipynb", "examples/R_double_ml_basics.ipynb", "examples/R_double_ml_did.ipynb", "examples/R_double_ml_multiway_cluster.ipynb", "examples/R_double_ml_pension.ipynb", "examples/R_double_ml_pipeline.ipynb", "examples/double_ml_bonus_data.ipynb", "examples/index.rst", "examples/py_double_ml_apo.ipynb", "examples/py_double_ml_basic_iv.ipynb", "examples/py_double_ml_basics.ipynb", "examples/py_double_ml_cate.ipynb", "examples/py_double_ml_cate_plr.ipynb", "examples/py_double_ml_cvar.ipynb", "examples/py_double_ml_did.ipynb", "examples/py_double_ml_did_pretest.ipynb", "examples/py_double_ml_firststage.ipynb", "examples/py_double_ml_gate.ipynb", "examples/py_double_ml_gate_plr.ipynb", "examples/py_double_ml_gate_sensitivity.ipynb", "examples/py_double_ml_learner.ipynb", "examples/py_double_ml_meets_flaml.ipynb", "examples/py_double_ml_multiway_cluster.ipynb", "examples/py_double_ml_pension.ipynb", "examples/py_double_ml_pension_qte.ipynb", "examples/py_double_ml_plm_irm_hetfx.ipynb", "examples/py_double_ml_policy_tree.ipynb", "examples/py_double_ml_pq.ipynb", "examples/py_double_ml_rdflex.ipynb", "examples/py_double_ml_sensitivity.ipynb", "examples/py_double_ml_sensitivity_booking.ipynb", "examples/py_double_ml_ssm.ipynb", "guide/algorithms.rst", "guide/basics.rst", "guide/data_backend.rst", "guide/guide.rst", "guide/heterogeneity.rst", "guide/learners.rst", "guide/models.rst", "guide/resampling.rst", "guide/scores.rst", "guide/scores/apo_score.rst", "guide/scores/cvar_score.rst", "guide/scores/did_score.rst", "guide/scores/didcs_score.rst", "guide/scores/iivm_score.rst", "guide/scores/irm_score.rst", "guide/scores/lpq_score.rst", "guide/scores/mar_score.rst", "guide/scores/nr_score.rst", "guide/scores/pliv_score.rst", "guide/scores/plr_score.rst", "guide/scores/pq_score.rst", "guide/se_confint.rst", "guide/sensitivity.rst", "guide/sensitivity/apo_sensitivity.rst", "guide/sensitivity/benchmarking.rst", "guide/sensitivity/did_cs_sensitivity.rst", "guide/sensitivity/did_sensitivity.rst", "guide/sensitivity/implementation.rst", "guide/sensitivity/irm_sensitivity.rst", "guide/sensitivity/plr_sensitivity.rst", "guide/sensitivity/theory.rst", "index.rst", "intro/install.rst", "intro/intro.rst", "literature/literature.rst", "release/release.rst", "workflow/workflow.rst"], "indexentries": {"aggregate_over_splits() (doubleml.rdd.rdflex method)": [[35, "doubleml.rdd.RDFlex.aggregate_over_splits", false]], "bootstrap() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.bootstrap", false]], "bootstrap() (doubleml.doublemlapos method)": [[5, "doubleml.DoubleMLAPOS.bootstrap", false]], "bootstrap() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.bootstrap", false]], "bootstrap() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.bootstrap", false]], "bootstrap() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.bootstrap", false]], "bootstrap() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.bootstrap", false]], "bootstrap() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.bootstrap", false]], "bootstrap() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.bootstrap", false]], "bootstrap() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.bootstrap", false]], "bootstrap() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.bootstrap", false]], "bootstrap() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.bootstrap", false]], "bootstrap() (doubleml.doublemlqte method)": [[17, "doubleml.DoubleMLQTE.bootstrap", false]], "bootstrap() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.bootstrap", false]], "capo() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.capo", false]], "cate() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.cate", false]], "cate() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.cate", false]], "causal_contrast() (doubleml.doublemlapos method)": [[5, "doubleml.DoubleMLAPOS.causal_contrast", false]], "confint() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.confint", false]], "confint() (doubleml.doublemlapos method)": [[5, "doubleml.DoubleMLAPOS.confint", false]], "confint() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.confint", false]], "confint() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.confint", false]], "confint() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.confint", false]], "confint() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.confint", false]], "confint() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.confint", false]], "confint() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.confint", false]], "confint() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.confint", false]], "confint() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.confint", false]], "confint() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.confint", false]], "confint() (doubleml.doublemlqte method)": [[17, "doubleml.DoubleMLQTE.confint", false]], "confint() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.confint", false]], "confint() (doubleml.rdd.rdflex method)": [[35, "doubleml.rdd.RDFlex.confint", false]], "confint() (doubleml.utils.doublemlblp method)": [[39, "doubleml.utils.DoubleMLBLP.confint", false]], "construct_framework() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.construct_framework", false]], "construct_framework() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.construct_framework", false]], "construct_framework() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.construct_framework", false]], "construct_framework() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.construct_framework", false]], "construct_framework() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.construct_framework", false]], "construct_framework() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.construct_framework", false]], "construct_framework() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.construct_framework", false]], "construct_framework() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.construct_framework", false]], "construct_framework() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.construct_framework", false]], "construct_framework() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.construct_framework", false]], "construct_framework() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.construct_framework", false]], "dmldummyclassifier (class in doubleml.utils)": [[37, "doubleml.utils.DMLDummyClassifier", false]], "dmldummyregressor (class in doubleml.utils)": [[38, "doubleml.utils.DMLDummyRegressor", false]], "doublemlapo (class in doubleml)": [[4, "doubleml.DoubleMLAPO", false]], "doublemlapos (class in doubleml)": [[5, "doubleml.DoubleMLAPOS", false]], "doublemlblp (class in doubleml.utils)": [[39, "doubleml.utils.DoubleMLBLP", false]], "doublemlclusterdata (class in doubleml)": [[7, "doubleml.DoubleMLClusterData", false]], "doublemlcvar (class in doubleml)": [[6, "doubleml.DoubleMLCVAR", false]], "doublemldata (class in doubleml)": [[10, "doubleml.DoubleMLData", false]], "doublemldid (class in doubleml)": [[8, "doubleml.DoubleMLDID", false]], "doublemldidcs (class in doubleml)": [[9, "doubleml.DoubleMLDIDCS", false]], "doublemliivm (class in doubleml)": [[11, "doubleml.DoubleMLIIVM", false]], "doublemlirm (class in doubleml)": [[12, "doubleml.DoubleMLIRM", false]], "doublemllpq (class in doubleml)": [[13, "doubleml.DoubleMLLPQ", false]], "doublemlpliv (class in doubleml)": [[14, "doubleml.DoubleMLPLIV", false]], "doublemlplr (class in doubleml)": [[15, "doubleml.DoubleMLPLR", false]], "doublemlpolicytree (class in doubleml.utils)": [[40, "doubleml.utils.DoubleMLPolicyTree", false]], "doublemlpq (class in doubleml)": [[16, "doubleml.DoubleMLPQ", false]], "doublemlqte (class in doubleml)": [[17, "doubleml.DoubleMLQTE", false]], "doublemlssm (class in doubleml)": [[18, "doubleml.DoubleMLSSM", false]], "draw_sample_splitting() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlapos method)": [[5, "doubleml.DoubleMLAPOS.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlqte method)": [[17, "doubleml.DoubleMLQTE.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.draw_sample_splitting", false]], "evaluate_learners() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.evaluate_learners", false]], "fetch_401k() (in module doubleml.datasets)": [[19, "doubleml.datasets.fetch_401K", false]], "fetch_bonus() (in module doubleml.datasets)": [[20, "doubleml.datasets.fetch_bonus", false]], "fit() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.fit", false]], "fit() (doubleml.doublemlapos method)": [[5, "doubleml.DoubleMLAPOS.fit", false]], "fit() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.fit", false]], "fit() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.fit", false]], "fit() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.fit", false]], "fit() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.fit", false]], "fit() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.fit", false]], "fit() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.fit", false]], "fit() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.fit", false]], "fit() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.fit", false]], "fit() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.fit", false]], "fit() (doubleml.doublemlqte method)": [[17, "doubleml.DoubleMLQTE.fit", false]], "fit() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.fit", false]], "fit() (doubleml.rdd.rdflex method)": [[35, "doubleml.rdd.RDFlex.fit", false]], "fit() (doubleml.utils.dmldummyclassifier method)": [[37, "doubleml.utils.DMLDummyClassifier.fit", false]], "fit() (doubleml.utils.dmldummyregressor method)": [[38, "doubleml.utils.DMLDummyRegressor.fit", false]], "fit() (doubleml.utils.doublemlblp method)": [[39, "doubleml.utils.DoubleMLBLP.fit", false]], "fit() (doubleml.utils.doublemlpolicytree method)": [[40, "doubleml.utils.DoubleMLPolicyTree.fit", false]], "fit() (doubleml.utils.globalclassifier method)": [[41, "doubleml.utils.GlobalClassifier.fit", false]], "fit() (doubleml.utils.globalregressor method)": [[42, "doubleml.utils.GlobalRegressor.fit", false]], "from_arrays() (doubleml.doublemlclusterdata class method)": [[7, "doubleml.DoubleMLClusterData.from_arrays", false]], "from_arrays() (doubleml.doublemldata class method)": [[10, "doubleml.DoubleMLData.from_arrays", false]], "gain_statistics() (in module doubleml.utils)": [[43, "doubleml.utils.gain_statistics", false]], "gapo() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.gapo", false]], "gate() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.gate", false]], "gate() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.gate", false]], "get_metadata_routing() (doubleml.utils.dmldummyclassifier method)": [[37, "doubleml.utils.DMLDummyClassifier.get_metadata_routing", false]], "get_metadata_routing() (doubleml.utils.dmldummyregressor method)": [[38, "doubleml.utils.DMLDummyRegressor.get_metadata_routing", false]], "get_metadata_routing() (doubleml.utils.globalclassifier method)": [[41, "doubleml.utils.GlobalClassifier.get_metadata_routing", false]], "get_metadata_routing() (doubleml.utils.globalregressor method)": [[42, "doubleml.utils.GlobalRegressor.get_metadata_routing", false]], "get_params() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.get_params", false]], "get_params() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.get_params", false]], "get_params() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.get_params", false]], "get_params() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.get_params", false]], "get_params() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.get_params", false]], "get_params() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.get_params", false]], "get_params() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.get_params", false]], "get_params() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.get_params", false]], "get_params() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.get_params", false]], "get_params() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.get_params", false]], "get_params() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.get_params", false]], "get_params() (doubleml.utils.dmldummyclassifier method)": [[37, "doubleml.utils.DMLDummyClassifier.get_params", false]], "get_params() (doubleml.utils.dmldummyregressor method)": [[38, "doubleml.utils.DMLDummyRegressor.get_params", false]], "get_params() (doubleml.utils.globalclassifier method)": [[41, "doubleml.utils.GlobalClassifier.get_params", false]], "get_params() (doubleml.utils.globalregressor method)": [[42, "doubleml.utils.GlobalRegressor.get_params", false]], "globalclassifier (class in doubleml.utils)": [[41, "doubleml.utils.GlobalClassifier", false]], "globalregressor (class in doubleml.utils)": [[42, "doubleml.utils.GlobalRegressor", false]], "linearscoremixin (class in doubleml.double_ml_score_mixins)": [[33, "doubleml.double_ml_score_mixins.LinearScoreMixin", false]], "make_confounded_irm_data() (in module doubleml.datasets)": [[21, "doubleml.datasets.make_confounded_irm_data", false]], "make_confounded_plr_data() (in module doubleml.datasets)": [[22, "doubleml.datasets.make_confounded_plr_data", false]], "make_did_sz2020() (in module doubleml.datasets)": [[23, "doubleml.datasets.make_did_SZ2020", false]], "make_heterogeneous_data() (in module doubleml.datasets)": [[24, "doubleml.datasets.make_heterogeneous_data", false]], "make_iivm_data() (in module doubleml.datasets)": [[25, "doubleml.datasets.make_iivm_data", false]], "make_irm_data() (in module doubleml.datasets)": [[26, "doubleml.datasets.make_irm_data", false]], "make_irm_data_discrete_treatments() (in module doubleml.datasets)": [[27, "doubleml.datasets.make_irm_data_discrete_treatments", false]], "make_pliv_chs2015() (in module doubleml.datasets)": [[28, "doubleml.datasets.make_pliv_CHS2015", false]], "make_pliv_multiway_cluster_ckms2021() (in module doubleml.datasets)": [[29, "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", false]], "make_plr_ccddhnr2018() (in module doubleml.datasets)": [[30, "doubleml.datasets.make_plr_CCDDHNR2018", false]], "make_plr_turrell2018() (in module doubleml.datasets)": [[31, "doubleml.datasets.make_plr_turrell2018", false]], "make_simple_rdd_data() (in module doubleml.rdd.datasets)": [[36, "doubleml.rdd.datasets.make_simple_rdd_data", false]], "make_ssm_data() (in module doubleml.datasets)": [[32, "doubleml.datasets.make_ssm_data", false]], "nonlinearscoremixin (class in doubleml.double_ml_score_mixins)": [[34, "doubleml.double_ml_score_mixins.NonLinearScoreMixin", false]], "p_adjust() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.p_adjust", false]], "p_adjust() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.p_adjust", false]], "p_adjust() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.p_adjust", false]], "p_adjust() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.p_adjust", false]], "p_adjust() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.p_adjust", false]], "p_adjust() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.p_adjust", false]], "p_adjust() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.p_adjust", false]], "p_adjust() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.p_adjust", false]], "p_adjust() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.p_adjust", false]], "p_adjust() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.p_adjust", false]], "p_adjust() (doubleml.doublemlqte method)": [[17, "doubleml.DoubleMLQTE.p_adjust", false]], "p_adjust() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.p_adjust", false]], "plot_tree() (doubleml.utils.doublemlpolicytree method)": [[40, "doubleml.utils.DoubleMLPolicyTree.plot_tree", false]], "policy_tree() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.policy_tree", false]], "predict() (doubleml.utils.dmldummyclassifier method)": [[37, "doubleml.utils.DMLDummyClassifier.predict", false]], "predict() (doubleml.utils.dmldummyregressor method)": [[38, "doubleml.utils.DMLDummyRegressor.predict", false]], "predict() (doubleml.utils.doublemlpolicytree method)": [[40, "doubleml.utils.DoubleMLPolicyTree.predict", false]], "predict() (doubleml.utils.globalclassifier method)": [[41, "doubleml.utils.GlobalClassifier.predict", false]], "predict() (doubleml.utils.globalregressor method)": [[42, "doubleml.utils.GlobalRegressor.predict", false]], "predict_proba() (doubleml.utils.dmldummyclassifier method)": [[37, "doubleml.utils.DMLDummyClassifier.predict_proba", false]], "predict_proba() (doubleml.utils.globalclassifier method)": [[41, "doubleml.utils.GlobalClassifier.predict_proba", false]], "rdflex (class in doubleml.rdd)": [[35, "doubleml.rdd.RDFlex", false]], "score() (doubleml.utils.globalclassifier method)": [[41, "doubleml.utils.GlobalClassifier.score", false]], "score() (doubleml.utils.globalregressor method)": [[42, "doubleml.utils.GlobalRegressor.score", false]], "sensitivity_analysis() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlapos method)": [[5, "doubleml.DoubleMLAPOS.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.sensitivity_analysis", false]], "sensitivity_benchmark() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlapos method)": [[5, "doubleml.DoubleMLAPOS.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.sensitivity_benchmark", false]], "sensitivity_plot() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlapos method)": [[5, "doubleml.DoubleMLAPOS.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.sensitivity_plot", false]], "set_fit_request() (doubleml.utils.globalclassifier method)": [[41, "doubleml.utils.GlobalClassifier.set_fit_request", false]], "set_fit_request() (doubleml.utils.globalregressor method)": [[42, "doubleml.utils.GlobalRegressor.set_fit_request", false]], "set_ml_nuisance_params() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.set_ml_nuisance_params", false]], "set_params() (doubleml.utils.dmldummyclassifier method)": [[37, "doubleml.utils.DMLDummyClassifier.set_params", false]], "set_params() (doubleml.utils.dmldummyregressor method)": [[38, "doubleml.utils.DMLDummyRegressor.set_params", false]], "set_params() (doubleml.utils.globalclassifier method)": [[41, "doubleml.utils.GlobalClassifier.set_params", false]], "set_params() (doubleml.utils.globalregressor method)": [[42, "doubleml.utils.GlobalRegressor.set_params", false]], "set_sample_splitting() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlapos method)": [[5, "doubleml.DoubleMLAPOS.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlqte method)": [[17, "doubleml.DoubleMLQTE.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.set_sample_splitting", false]], "set_score_request() (doubleml.utils.globalclassifier method)": [[41, "doubleml.utils.GlobalClassifier.set_score_request", false]], "set_score_request() (doubleml.utils.globalregressor method)": [[42, "doubleml.utils.GlobalRegressor.set_score_request", false]], "set_x_d() (doubleml.doublemlclusterdata method)": [[7, "doubleml.DoubleMLClusterData.set_x_d", false]], "set_x_d() (doubleml.doublemldata method)": [[10, "doubleml.DoubleMLData.set_x_d", false]], "tune() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.tune", false]], "tune() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.tune", false]], "tune() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.tune", false]], "tune() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.tune", false]], "tune() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.tune", false]], "tune() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.tune", false]], "tune() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.tune", false]], "tune() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.tune", false]], "tune() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.tune", false]], "tune() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.tune", false]], "tune() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.tune", false]]}, "objects": {"doubleml": [[4, 0, 1, "", "DoubleMLAPO"], [5, 0, 1, "", "DoubleMLAPOS"], [6, 0, 1, "", "DoubleMLCVAR"], [7, 0, 1, "", "DoubleMLClusterData"], [8, 0, 1, "", "DoubleMLDID"], [9, 0, 1, "", "DoubleMLDIDCS"], [10, 0, 1, "", "DoubleMLData"], [11, 0, 1, "", "DoubleMLIIVM"], [12, 0, 1, "", "DoubleMLIRM"], [13, 0, 1, "", "DoubleMLLPQ"], [14, 0, 1, "", "DoubleMLPLIV"], [15, 0, 1, "", "DoubleMLPLR"], [16, 0, 1, "", "DoubleMLPQ"], [17, 0, 1, "", "DoubleMLQTE"], [18, 0, 1, "", "DoubleMLSSM"]], "doubleml.DoubleMLAPO": [[4, 1, 1, "", "bootstrap"], [4, 1, 1, "", "capo"], [4, 1, 1, "", "confint"], [4, 1, 1, "", "construct_framework"], [4, 1, 1, "", "draw_sample_splitting"], [4, 1, 1, "", "evaluate_learners"], [4, 1, 1, "", "fit"], [4, 1, 1, "", "gapo"], [4, 1, 1, "", "get_params"], [4, 1, 1, "", "p_adjust"], [4, 1, 1, "", "sensitivity_analysis"], [4, 1, 1, "", "sensitivity_benchmark"], [4, 1, 1, "", "sensitivity_plot"], [4, 1, 1, "", "set_ml_nuisance_params"], [4, 1, 1, "", "set_sample_splitting"], [4, 1, 1, "", "tune"]], "doubleml.DoubleMLAPOS": [[5, 1, 1, "", "bootstrap"], [5, 1, 1, "", "causal_contrast"], [5, 1, 1, "", "confint"], [5, 1, 1, "", "draw_sample_splitting"], [5, 1, 1, "", "fit"], [5, 1, 1, "", "sensitivity_analysis"], [5, 1, 1, "", "sensitivity_benchmark"], [5, 1, 1, "", "sensitivity_plot"], [5, 1, 1, "", "set_sample_splitting"]], "doubleml.DoubleMLCVAR": [[6, 1, 1, "", "bootstrap"], [6, 1, 1, "", "confint"], [6, 1, 1, "", "construct_framework"], [6, 1, 1, "", "draw_sample_splitting"], [6, 1, 1, "", "evaluate_learners"], [6, 1, 1, "", "fit"], [6, 1, 1, "", "get_params"], [6, 1, 1, "", "p_adjust"], [6, 1, 1, "", "sensitivity_analysis"], [6, 1, 1, "", "sensitivity_benchmark"], [6, 1, 1, "", "sensitivity_plot"], [6, 1, 1, "", "set_ml_nuisance_params"], [6, 1, 1, "", "set_sample_splitting"], [6, 1, 1, "", "tune"]], "doubleml.DoubleMLClusterData": [[7, 1, 1, "", "from_arrays"], [7, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLDID": [[8, 1, 1, "", "bootstrap"], [8, 1, 1, "", "confint"], [8, 1, 1, "", "construct_framework"], [8, 1, 1, "", "draw_sample_splitting"], [8, 1, 1, "", "evaluate_learners"], [8, 1, 1, "", "fit"], [8, 1, 1, "", "get_params"], [8, 1, 1, "", "p_adjust"], [8, 1, 1, "", "sensitivity_analysis"], [8, 1, 1, "", "sensitivity_benchmark"], [8, 1, 1, "", "sensitivity_plot"], [8, 1, 1, "", "set_ml_nuisance_params"], [8, 1, 1, "", "set_sample_splitting"], [8, 1, 1, "", "tune"]], "doubleml.DoubleMLDIDCS": [[9, 1, 1, "", "bootstrap"], [9, 1, 1, "", "confint"], [9, 1, 1, "", "construct_framework"], [9, 1, 1, "", "draw_sample_splitting"], [9, 1, 1, "", "evaluate_learners"], [9, 1, 1, "", "fit"], [9, 1, 1, "", "get_params"], [9, 1, 1, "", "p_adjust"], [9, 1, 1, "", "sensitivity_analysis"], [9, 1, 1, "", "sensitivity_benchmark"], [9, 1, 1, "", "sensitivity_plot"], [9, 1, 1, "", "set_ml_nuisance_params"], [9, 1, 1, "", "set_sample_splitting"], [9, 1, 1, "", "tune"]], "doubleml.DoubleMLData": [[10, 1, 1, "", "from_arrays"], [10, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLIIVM": [[11, 1, 1, "", "bootstrap"], [11, 1, 1, "", "confint"], [11, 1, 1, "", "construct_framework"], [11, 1, 1, "", "draw_sample_splitting"], [11, 1, 1, "", "evaluate_learners"], [11, 1, 1, "", "fit"], [11, 1, 1, "", "get_params"], [11, 1, 1, "", "p_adjust"], [11, 1, 1, "", "sensitivity_analysis"], [11, 1, 1, "", "sensitivity_benchmark"], [11, 1, 1, "", "sensitivity_plot"], [11, 1, 1, "", "set_ml_nuisance_params"], [11, 1, 1, "", "set_sample_splitting"], [11, 1, 1, "", "tune"]], "doubleml.DoubleMLIRM": [[12, 1, 1, "", "bootstrap"], [12, 1, 1, "", "cate"], [12, 1, 1, "", "confint"], [12, 1, 1, "", "construct_framework"], [12, 1, 1, "", "draw_sample_splitting"], [12, 1, 1, "", "evaluate_learners"], [12, 1, 1, "", "fit"], [12, 1, 1, "", "gate"], [12, 1, 1, "", "get_params"], [12, 1, 1, "", "p_adjust"], [12, 1, 1, "", "policy_tree"], [12, 1, 1, "", "sensitivity_analysis"], [12, 1, 1, "", "sensitivity_benchmark"], [12, 1, 1, "", "sensitivity_plot"], [12, 1, 1, "", "set_ml_nuisance_params"], [12, 1, 1, "", "set_sample_splitting"], [12, 1, 1, "", "tune"]], "doubleml.DoubleMLLPQ": [[13, 1, 1, "", "bootstrap"], [13, 1, 1, "", "confint"], [13, 1, 1, "", "construct_framework"], [13, 1, 1, "", "draw_sample_splitting"], [13, 1, 1, "", "evaluate_learners"], [13, 1, 1, "", "fit"], [13, 1, 1, "", "get_params"], [13, 1, 1, "", "p_adjust"], [13, 1, 1, "", "sensitivity_analysis"], [13, 1, 1, "", "sensitivity_benchmark"], [13, 1, 1, "", "sensitivity_plot"], [13, 1, 1, "", "set_ml_nuisance_params"], [13, 1, 1, "", "set_sample_splitting"], [13, 1, 1, "", "tune"]], "doubleml.DoubleMLPLIV": [[14, 1, 1, "", "bootstrap"], [14, 1, 1, "", "confint"], [14, 1, 1, "", "construct_framework"], [14, 1, 1, "", "draw_sample_splitting"], [14, 1, 1, "", "evaluate_learners"], [14, 1, 1, "", "fit"], [14, 1, 1, "", "get_params"], [14, 1, 1, "", "p_adjust"], [14, 1, 1, "", "sensitivity_analysis"], [14, 1, 1, "", "sensitivity_benchmark"], [14, 1, 1, "", "sensitivity_plot"], [14, 1, 1, "", "set_ml_nuisance_params"], [14, 1, 1, "", "set_sample_splitting"], [14, 1, 1, "", "tune"]], "doubleml.DoubleMLPLR": [[15, 1, 1, "", "bootstrap"], [15, 1, 1, "", "cate"], [15, 1, 1, "", "confint"], [15, 1, 1, "", "construct_framework"], [15, 1, 1, "", "draw_sample_splitting"], [15, 1, 1, "", "evaluate_learners"], [15, 1, 1, "", "fit"], [15, 1, 1, "", "gate"], [15, 1, 1, "", "get_params"], [15, 1, 1, "", "p_adjust"], [15, 1, 1, "", "sensitivity_analysis"], [15, 1, 1, "", "sensitivity_benchmark"], [15, 1, 1, "", "sensitivity_plot"], [15, 1, 1, "", "set_ml_nuisance_params"], [15, 1, 1, "", "set_sample_splitting"], [15, 1, 1, "", "tune"]], "doubleml.DoubleMLPQ": [[16, 1, 1, "", "bootstrap"], [16, 1, 1, "", "confint"], [16, 1, 1, "", "construct_framework"], [16, 1, 1, "", "draw_sample_splitting"], [16, 1, 1, "", "evaluate_learners"], [16, 1, 1, "", "fit"], [16, 1, 1, "", "get_params"], [16, 1, 1, "", "p_adjust"], [16, 1, 1, "", "sensitivity_analysis"], [16, 1, 1, "", "sensitivity_benchmark"], [16, 1, 1, "", "sensitivity_plot"], [16, 1, 1, "", "set_ml_nuisance_params"], [16, 1, 1, "", "set_sample_splitting"], [16, 1, 1, "", "tune"]], "doubleml.DoubleMLQTE": [[17, 1, 1, "", "bootstrap"], [17, 1, 1, "", "confint"], [17, 1, 1, "", "draw_sample_splitting"], [17, 1, 1, "", "fit"], [17, 1, 1, "", "p_adjust"], [17, 1, 1, "", "set_sample_splitting"]], "doubleml.DoubleMLSSM": [[18, 1, 1, "", "bootstrap"], [18, 1, 1, "", "confint"], [18, 1, 1, "", "construct_framework"], [18, 1, 1, "", "draw_sample_splitting"], [18, 1, 1, "", "evaluate_learners"], [18, 1, 1, "", "fit"], [18, 1, 1, "", "get_params"], [18, 1, 1, "", "p_adjust"], [18, 1, 1, "", "sensitivity_analysis"], [18, 1, 1, "", "sensitivity_benchmark"], [18, 1, 1, "", "sensitivity_plot"], [18, 1, 1, "", "set_ml_nuisance_params"], [18, 1, 1, "", "set_sample_splitting"], [18, 1, 1, "", "tune"]], "doubleml.datasets": [[19, 2, 1, "", "fetch_401K"], [20, 2, 1, "", "fetch_bonus"], [21, 2, 1, "", "make_confounded_irm_data"], [22, 2, 1, "", "make_confounded_plr_data"], [23, 2, 1, "", "make_did_SZ2020"], [24, 2, 1, "", "make_heterogeneous_data"], [25, 2, 1, "", "make_iivm_data"], [26, 2, 1, "", "make_irm_data"], [27, 2, 1, "", "make_irm_data_discrete_treatments"], [28, 2, 1, "", "make_pliv_CHS2015"], [29, 2, 1, "", "make_pliv_multiway_cluster_CKMS2021"], [30, 2, 1, "", "make_plr_CCDDHNR2018"], [31, 2, 1, "", "make_plr_turrell2018"], [32, 2, 1, "", "make_ssm_data"]], "doubleml.double_ml_score_mixins": [[33, 0, 1, "", "LinearScoreMixin"], [34, 0, 1, "", "NonLinearScoreMixin"]], "doubleml.rdd": [[35, 0, 1, "", "RDFlex"]], "doubleml.rdd.RDFlex": [[35, 1, 1, "", "aggregate_over_splits"], [35, 1, 1, "", "confint"], [35, 1, 1, "", "fit"]], "doubleml.rdd.datasets": [[36, 2, 1, "", "make_simple_rdd_data"]], "doubleml.utils": [[37, 0, 1, "", "DMLDummyClassifier"], [38, 0, 1, "", "DMLDummyRegressor"], [39, 0, 1, "", "DoubleMLBLP"], [40, 0, 1, "", "DoubleMLPolicyTree"], [41, 0, 1, "", "GlobalClassifier"], [42, 0, 1, "", "GlobalRegressor"], [43, 2, 1, "", "gain_statistics"]], "doubleml.utils.DMLDummyClassifier": [[37, 1, 1, "", "fit"], [37, 1, 1, "", "get_metadata_routing"], [37, 1, 1, "", "get_params"], [37, 1, 1, "", "predict"], [37, 1, 1, "", "predict_proba"], [37, 1, 1, "", "set_params"]], "doubleml.utils.DMLDummyRegressor": [[38, 1, 1, "", "fit"], [38, 1, 1, "", "get_metadata_routing"], [38, 1, 1, "", "get_params"], [38, 1, 1, "", "predict"], [38, 1, 1, "", "set_params"]], "doubleml.utils.DoubleMLBLP": [[39, 1, 1, "", "confint"], [39, 1, 1, "", "fit"]], "doubleml.utils.DoubleMLPolicyTree": [[40, 1, 1, "", "fit"], [40, 1, 1, "", "plot_tree"], [40, 1, 1, "", "predict"]], "doubleml.utils.GlobalClassifier": [[41, 1, 1, "", "fit"], [41, 1, 1, "", "get_metadata_routing"], [41, 1, 1, "", "get_params"], [41, 1, 1, "", "predict"], [41, 1, 1, "", "predict_proba"], [41, 1, 1, "", "score"], [41, 1, 1, "", "set_fit_request"], [41, 1, 1, "", "set_params"], [41, 1, 1, "", "set_score_request"]], "doubleml.utils.GlobalRegressor": [[42, 1, 1, "", "fit"], [42, 1, 1, "", "get_metadata_routing"], [42, 1, 1, "", "get_params"], [42, 1, 1, "", "predict"], [42, 1, 1, "", "score"], [42, 1, 1, "", "set_fit_request"], [42, 1, 1, "", "set_params"], [42, 1, 1, "", "set_score_request"]]}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function"}, "terms": {"": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 25, 26, 28, 29, 30, 31, 32, 35, 39, 41, 42, 47, 49, 50, 51, 52, 53, 55, 61, 64, 65, 66, 69, 70, 71, 75, 76, 77, 78, 79, 81, 84, 85, 87, 95, 96, 100, 101, 103, 110, 112, 113, 114, 115], "0": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 42, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 99, 100, 101, 103, 104, 105, 106, 107, 111, 112, 114], "00": [65, 70, 71, 86], "000": [72, 100, 115], "000000": [53, 55, 70, 71, 81, 83, 112], "0000000": 100, "0000000000000010000100": [52, 81, 112], "000000e": [65, 70, 71], "00000591": 74, "000006": [55, 74], "000017": 74, "000025": 69, "000034": 70, "000039": 69, "000064": 56, "000067": 69, "000091": [69, 83], "0001": [53, 70], "000135": 85, "0001367709": 86, "000219": [16, 83], "000242": [17, 83], "000341": 69, "0004080233": 86, "000442": 69, "00047580260495": 47, "000488": 69, "000494": 66, "0005": 53, "000522": 69, "0005a80b528f": 52, "000670": 69, "0007324152": 86, "000743": 76, "000746221": 86, "000915799": 100, "0009157990": 100, "000943": [58, 59], "001": [47, 49, 50, 51, 52, 57, 84, 85, 86, 87, 100, 112, 115], "001051": 69, "001147571": 86, "001234": 71, "00133": 52, "00138944": [79, 87], "001403": 75, "001494": 85, "0016": [51, 70], "001714": 83, "0018": [51, 70], "0019": 53, "002169338": 100, "0021693380": 100, "0021693381": 100, "002277": 58, "002290": 62, "0023": 49, "002388": 68, "002436": 66, "002539": 85, "0026": 53, "002779": 76, "0028": [49, 51, 70], "002821": 77, "0028213335041910427": 77, "002983": 69, "003": [21, 22, 23], "003111": 55, "003134": 74, "003187": 58, "003220": 55, "003328": 74, "0034": 63, "003404": 55, "003415": 55, "003427": 69, "003607": 59, "003746812": 86, "003779": 66, "003836": 74, "003924": 66, "003944": 58, "003975": 58, "004078968": 86, "00409412": [79, 87], "0042": [51, 70], "004253": 55, "004392": 66, "004526": 55, "004688": 11, "0047": [51, 70], "004803234": 86, "004846": 77, "005": 115, "005339": [58, 59], "005857": 69, "005e": 85, "006055": 55, "006249325": 86, "006267": 59, "006425": 71, "0068101213851626": 68, "006922": 53, "006952006": 86, "006958": [58, 59], "007210e": 71, "007223385": 86, "00728": 112, "0073": 53, "007332": 60, "007332393760465": 60, "007659": 83, "00778625": 86, "0078540263583833": 68, "008": 77, "008023": 71, "008223": [58, 59], "008266e": 71, "00832547": 86, "008487": 53, "0084871742256079": 68, "008642": 83, "008883698": 87, "00888458890362062": 79, "008884589": 79, "008dbd": 72, "008e80": 72, "009": [72, 77], "009122": 74, "009255": 58, "009329847": 87, "009378": 72, "009428": 60, "00944171905420782": 77, "00950122695463054": 79, "009501226954630540": 79, "009501227": 79, "009645422": 50, "009656": 74, "00972": 53, "009790": 71, "009904": 83, "009986": 74, "01": [4, 5, 6, 8, 9, 11, 12, 13, 16, 17, 18, 40, 47, 50, 51, 52, 58, 59, 70, 71, 72, 73, 74, 75, 84, 85, 86, 87, 100, 112, 115], "010": [47, 72], "010213": 76, "010242": 72, "010269": 69, "010298485": 86, "010384402": 86, "010450": 50, "01084909": 86, "010940": 69, "011131": 74, "0112": 49, "01128": 53, "011598": 74, "0118095": 50, "011823": 76, "011957": 72, "011988e": 74, "01219": 52, "01274": 77, "012780": 71, "012831": 77, "013034": 77, "013128": 58, "013174": 72, "013313": 68, "01351638": 50, "013593": 76, "013617": 71, "013677": 75, "013712": 58, "01398951": 50, "013990": 100, "014": [72, 75], "01402613": 86, "01403089": 50, "014080": [58, 59], "014432": 62, "014637": 69, "014681": 76, "014873e": 58, "015": 52, "015038": 60, "015552": 58, "015565": 74, "0156853566737638": 68, "015698": 74, "01574297": 74, "015743": 74, "015831": 58, "016": 72, "016011": 59, "01612752": 86, "016154": 69, "016200": [58, 59], "016315": 64, "016429": 83, "01643": 113, "017": [52, 72], "017140": 58, "017393e": 100, "01772": 103, "017777e": 59, "017800092": 100, "0178000920": 100, "018": 52, "018023": 73, "018148": 74, "018508": 58, "018602": 85, "01882264": 86, "01903": [52, 84, 110, 112], "01916030e": 86, "01925597": 50, "019439633": 100, "0194396330": 100, "0194396331": 100, "019596": 60, "0196": 72, "019660": [17, 83], "01990373": 78, "019974": 71, "02": [58, 59, 70, 71, 74, 83, 85, 86], "02016117": 112, "020166": 74, "020271": 69, "020360838": 100, "0203608380": 100, "0203608381": 100, "02052929": [79, 87], "02079162e": 86, "020819": 83, "02092": 112, "021269": [64, 65], "02163217": 50, "021690": 65, "021823": 68, "021866": 73, "021926": 60, "02196338": 86, "022": 115, "022181": 58, "0222737222": 86, "022295e": 58, "02247976": 50, "02276342": 86, "022768": 53, "022783": 76, "022915": 69, "022954": 83, "022969": 71, "023020e": [70, 71], "023052": 59, "023256": 74, "023537": 68, "023563": 100, "023955": 71, "024": 72, "02428944": 86, "024346": 58, "024355": 62, "024364": 101, "024401": [64, 65], "024604": 69, "024782": 74, "024926": 62, "025": [58, 59, 64, 65, 72], "025077": [59, 100], "02528067": 67, "0253": 52, "025300e": 59, "025443": 53, "025496": 58, "0257": 49, "025813114": 100, "0258131140": 100, "02584": 52, "025958": 83, "026669": 71, "026723": 60, "026822": 68, "027": 47, "02791": 53, "028": 72, "0281": 52, "0284": 86, "028520": [58, 59], "02897287": 61, "02900983": 74, "029010": 74, "029022": 59, "029209": 115, "029364": [101, 106], "029831": 74, "029910e": [70, 71], "02e": 51, "03": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 55, 58, 59, 60, 66, 70, 71, 74, 75, 76, 77, 86, 101, 106, 115], "030087": 83, "0301": 52, "03018": 13, "030346": 112, "0307": 52, "030934": 74, "030962": 74, "031007": 68, "03113": 78, "031134": 84, "031156": 59, "031269": 53, "031639": 74, "031820": 59, "03191": 113, "032": 72, "03220": 114, "0323": 49, "03244552": 84, "0325": 112, "03258": 68, "032580": 68, "032738": 68, "032941": 58, "032953": 76, "033265": 68, "033756": 60, "033946": [64, 65], "03403": 72, "034065": 59, "03411": 112, "034226": 71, "034690": 60, "034812763": 100, "0348127630": 100, "0348127631": 100, "034846": 70, "03489": [29, 50, 69], "035119185": 100, "0351191850": 100, "0351191851": 100, "03522851": 86, "035264": 59, "03536": 112, "03538": 52, "03539": 52, "035391": 53, "0354": 52, "035411": 112, "035441": 59, "03545": 52, "035545": 53, "035572": 53, "035730": 74, "03574": 53, "035762": 74, "035785": 59, "0359": 52, "036129015": 100, "0361290150": 100, "0361290151": 100, "036143": 74, "036147": 74, "036240": 55, "036729": 69, "0368": 49, "036945": 71, "03698487": 74, "036985": 74, "037008": [64, 65], "0374": 52, "037504": 59, "037509": 78, "037747": [58, 59], "038675079": 86, "038845": 58, "039036": 58, "039141": 55, "03917696": [87, 100], "03920768": 86, "03920960e": 86, "039310e": 60, "039991e": 58, "04": [22, 35, 51, 55, 58, 59, 70, 71, 74, 75, 76, 86, 115], "040079": 59, "040112": 100, "040139": [58, 59], "040533": [87, 100], "04053339": 100, "040562": 58, "040688": 58, "040733": 72, "0408": 58, "040912": 59, "040919": 59, "04107": 15, "041147": 60, "041284": 60, "041387": 60, "041459": 71, "041491e": 60, "04165": 85, "0418": 49, "041831": 60, "041925": 58, "042034": 77, "042249": 59, "042265": 60, "0425": 84, "0428": 78, "042822e": 71, "042844e": 74, "043": 72, "043108": 71, "0433": 49, "0434e374": 52, "04387": 84, "043998": 59, "044113": 60, "04415": 52, "04424": 52, "04444978": 100, "044449780": 100, "0445": 84, "04465": 50, "044704": 59, "04486": 112, "04487585": [101, 106], "04491": 85, "04497975": [101, 106], "04501612": 100, "04502": [84, 87, 100], "04512493": 86, "045144": 69, "045313": 58, "045379": 112, "04552": 69, "045553": 60, "045624": 62, "04563": 84, "045638": 58, "045754": 74, "04586": 84, "045932": 74, "045993": 84, "04625": 84, "046405": 83, "046527": 60, "04653976": 74, "046540": 74, "046587": 59, "0466028": 50, "046728": 76, "04682310e": 86, "046922": 84, "047098": 72, "047194": 11, "047652e": 59, "047724": 58, "047954": 69, "048": 72, "04813674": 86, "048220": 68, "048308": 65, "048699": 78, "048723": 84, "048853": 59, "049": 47, "049264": 55, "04973": 59, "05": [35, 47, 49, 50, 51, 52, 58, 59, 60, 63, 67, 69, 70, 71, 72, 74, 75, 77, 84, 85, 86, 87, 100, 112, 115], "05039": 76, "050494e": 59, "050538": 59, "05076852": 86, "050856": [83, 84], "051": 52, "051651": 75, "051867e": 60, "05194009": 86, "052": 75, "052000e": 71, "052298": 74, "052380": 58, "05243409": 86, "052488": 65, "052502": 74, "052745": 60, "053": [52, 85], "053049": 59, "0533": 49, "053331": 60, "053342": 71, "053389": 100, "053436": 12, "053541": 74, "053558": 60, "053849e": 58, "054": [52, 75], "054068": 69, "054162": 69, "054348": 100, "054370": 60, "054521945": 86, "054529": 100, "0546": 86, "054771e": 74, "055165": 76, "055171": 59, "055338e": 70, "055439": [68, 71], "055493": 77, "055680": 100, "056": 75, "056499": 65, "056745": 58, "056764": 58, "05682862": 86, "057095": 74, "057274": 55, "0576": [51, 70], "057762": 74, "057792": 58, "057962": 60, "058042": 100, "058276": 71, "058375": 55, "058463": 74, "058508": 78, "058595": 58, "0590": 49, "059128": 58, "059384": 74, "059627": 71, "059630": 62, "059685": 74, "06": [21, 22, 23, 55, 58, 59, 60, 70, 71, 74, 83, 84, 115], "06008533": 85, "060201": 74, "060212": [70, 71], "060417": 58, "060581": 67, "060845": 100, "060933": 58, "0611": 49, "06111111": 52, "0615": 49, "062": [75, 85], "062414": 71, "062507": 74, "0628": 49, "062964": 100, "062988": 58, "063017": 55, "0632": 49, "063234e": 59, "0635": 49, "063593": 59, "0636": 49, "063685": 55, "063700": 58, "06373550": 86, "0638": 49, "063881": 85, "0640": 49, "064161": 71, "064175": 55, "064213": 59, "06428": 70, "064280": 70, "0645": 49, "0646222": 51, "0647": 49, "0649": 49, "065": [72, 77], "0653": 49, "065356": [64, 65], "065368": 68, "0654": 49, "065451": 71, "0655": 49, "065725": 60, "0659": 49, "065969": 85, "066": 72, "0662": 49, "066464": 76, "066889": 74, "0669": 49, "06692492": 86, "06694255": 85, "067046e": 58, "0671": 49, "067240": 74, "06724028": 74, "0673": 49, "0675": 49, "067528": 77, "067721": 100, "068073": 59, "06827": 76, "06834315": 61, "068377": 71, "068514": 58, "068934": 55, "06895837": 50, "069": 72, "069443": 55, "0695854": 50, "069600": 71, "069882e": 58, "07": [47, 58, 59, 71, 74, 75, 77, 86, 115], "070020": 74, "070196": 60, "0701961897676835": 60, "0702127": 50, "0704": 49, "070497": 77, "070534": 18, "070552": 58, "070574e": 71, "0707": 49, "070751": 58, "07085301": 85, "070884": 74, "0711": 49, "071285": 100, "07136": [50, 69], "071362": 58, "071488e": 60, "0716": 49, "07168291": 50, "071777": 84, "071782": [17, 83], "0719": 49, "07202564": [64, 65], "07222222": 52, "072293": 73, "0725668429": 86, "0727": 85, "073": 75, "073013": 74, "073207": 69, "073275": 58, "07347676": 50, "07350015": [29, 32, 50, 69], "073520": 60, "0736": 49, "07366": [52, 84], "073694": 59, "0739130271918385": 68, "073929": 68, "0743": 49, "074304": 100, "07436521": 86, "074426": 74, "07456127": 50, "074617": 59, "07479278": 76, "074927": 55, "075261": 62, "075384": 74, "07538443": 74, "07544271e": 86, "07561": 112, "07564554e": 86, "0758": 77, "075809": 55, "075869": 84, "075942": 68, "076019": 70, "076156": 100, "076179312": 100, "0761793120": 100, "076322": 74, "076347": 60, "0765": 52, "076559": [83, 84], "076596": 58, "076684": 112, "07685043": 86, "07689": 52, "07691847": 86, "076953": [64, 65], "076971": 53, "077": 72, "077144e": 59, "077161": 71, "07727773e": 86, "077319": 74, "077502": [101, 106], "077555": 58, "077702": 55, "0777777777777778": 84, "07777778": [52, 84], "077840": 71, "077883": 74, "077923e": 58, "07796": 85, "078017": 58, "078096": 100, "078207": 53, "07828372": 100, "078474": 100, "078709": 59, "078810": 74, "079": 72, "079085": 53, "07915": 52, "07919896": 86, "07942v3": 113, "079458e": 70, "079500e": 58, "07961": 76, "07978296": 86, "08": [60, 71, 74, 77, 85], "08005229": 86, "08031571": 86, "080854": 71, "08091581": 86, "080947": 53, "081": 52, "081100": 74, "081230": [58, 59], "081396": 65, "081488": 69, "08154161": 86, "08181827e": 86, "08191204": 85, "0820": 49, "082263": 14, "082297": 86, "082400e": 58, "082574": 12, "082804": 62, "082858": 59, "082934": 71, "082973": 69, "083258": 100, "08331688": 86, "083318": 100, "08333333": 52, "08333617": 86, "0835771416": 50, "083706": 77, "083750": 71, "083949": 77, "084": 50, "084156": 59, "084184": 60, "0841842065698133": 60, "084212": 66, "084269": 71, "084323": 58, "084337": 85, "084633": 64, "0853505": 50, "085395": 58, "085566": 60, "085671": 58, "085965": 71, "08602774e": 86, "0862": 110, "086264": 60, "086298": 72, "08664208": 86, "086679": 84, "086889": 64, "0872": 49, "087222": 59, "087561": 58, "087634": 58, "087745": 59, "087947": 74, "088048": 74, "088282": 65, "088357": 74, "08847859": 86, "08848": 84, "088482": [17, 83], "088504e": 14, "08869835": 86, "08888889": 52, "0894": 49, "08968939": 50, "089964": 68, "08e": 51, "09": [58, 59, 60, 70, 71, 74, 83, 115], "09000000000000001": 84, "090025": 71, "09015": 49, "090255": 74, "090436": 59, "091179e": 58, "091263": 68, "091391": 100, "091406": 101, "091535": 58, "0916": 49, "091824": 59, "0919393": 86, "091992": 73, "092229": 77, "092247": 74, "092263": 85, "092365": 100, "092919": 103, "092935": 58, "093043": 74, "09310496": 100, "093153": 74, "093474": 74, "09347419": 74, "093746": 100, "093950": 69, "094026": 69, "094118": 74, "094378e": 58, "094381": 69, "09444444": 52, "094581e": 59, "094829": 85, "094999": 74, "095104": 55, "095475": 83, "095654": 58, "095781": 6, "095785": 55, "09603": 110, "096173130": 86, "096245": 83, "096337": 69, "096418": 55, "096550": 64, "096616": 83, "096688": 59, "096741": 61, "09682314": 85, "096915": 77, "097": 75, "097104752": 86, "097157": 77, "097468": 60, "09779675": 100, "097796750": 100, "098": 51, "098256": 74, "09830758": 76, "098308": 76, "098317": 71, "098319": 74, "09846777": 86, "0986": 49, "09869993": 86, "098712": 74, "09879814e": 86, "099": 75, "099001": 59, "099307": 59, "099647": 73, "099670": 71, "099731": [58, 59], "09980311": 100, "09988": 113, "0_": 28, "0ff823b17d45": 52, "0x1747bdd4520": 53, "0x1747bdd6b90": 53, "0x2920d7b7150": 73, "0x7f5cd5393140": 106, "0x7f5cd583ebd0": 115, "0x7f5cd5e92990": 85, "0x7f5cd5f96390": 85, "0x7f5cd5f97020": 85, "0x7f5cd6471700": 85, "0x7f5cd64765a0": 84, "0x7f5cd64774a0": 84, "0x7f5cd64ad280": 84, "0x7f5cd7c95fa0": 101, "0x7f5cdc8cc590": 100, "0x7f5cdc8cf4a0": 100, "0x7f5cdcf0a1e0": 100, "0x7f5cdf892e70": 100, "0x7f8f2362f950": 77, "1": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 41, 42, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114], "10": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 29, 30, 32, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 100, 101, 106, 110, 112, 113, 115], "100": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 29, 31, 32, 50, 52, 58, 59, 61, 63, 66, 67, 69, 72, 77, 78, 79, 81, 83, 84, 85, 86, 87, 100, 101, 106, 112, 114], "1000": [11, 13, 48, 56, 57, 61, 62, 64, 65, 66, 67, 68, 70, 71, 75, 76, 77, 80, 85], "10000": [47, 58, 59, 62, 70, 71, 74], "100000e": 71, "100044": 65, "100154": 68, "100356": 60, "10038": 76, "100385": 68, "10039862": [78, 85], "100517": 100, "100715": 58, "10079785": 85, "100807": [58, 59], "100858": 76, "10089588": 74, "100896": 74, "10092": 71, "100923": 74, "100_000": 72, "101": [21, 22, 23, 49, 75, 83, 85, 113, 114], "10126": 71, "10127930": 100, "101279300": 100, "1015": [51, 70], "1016": [21, 22, 23, 49], "1016010": 51, "1018": 71, "102": [81, 83, 85, 112, 114], "10235": 71, "10258": 71, "102616": 60, "102775": 60, "10299": 70, "103": [58, 69, 75, 78, 83, 85, 114], "10307": 100, "1031": 71, "103189": 71, "10348": 70, "103497": 74, "1038": 71, "103806": 60, "103951906910721": 60, "103952": 60, "10396": 70, "104": [51, 70, 78, 83, 85, 114], "10406": 71, "104087": 58, "1041": 49, "10414": 71, "1045303": 50, "104787": 69, "104849": 58, "105": [28, 50, 69, 83, 85, 114], "1050": 77, "105318": 74, "1054": 52, "1055": 49, "106": [52, 83, 85, 114], "10607": [53, 81, 112], "10618": 71, "10637173e": 86, "106391": 100, "106595": 85, "106691": 83, "106746": 74, "107": [52, 77, 83, 85, 114], "107073": 60, "107295": 100, "1073": 71, "107413": 58, "10747": [53, 81, 112], "107872": 83, "10799": 71, "108": [83, 85, 110, 113, 114], "1080": [29, 32, 49, 50, 69], "10824": [53, 81, 112], "108257e": 71, "108259": 55, "10831": [53, 81, 112], "1084234": 86, "10878571": 74, "108786": 74, "109": [58, 83, 85], "109005": 74, "10903": 70, "109069": 100, "109079e": 74, "109273": 69, "10928": 71, "1093": 63, "109454": 71, "109470": 59, "1096": 49, "10967": 70, "109811": 66, "109861": 112, "1099472942084532": 56, "10e": [60, 74], "11": [15, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 81, 83, 84, 85, 86, 87, 100, 101, 106, 112, 115], "110": [83, 85, 114], "1101": 71, "11019365749799062": 77, "110194": 77, "110359": 69, "110365": 77, "110681": 76, "1107": 71, "11071087": [78, 85], "110717": 100, "1108484": 86, "1109": 71, "110902": 60, "110902411746278": 60, "111": [59, 83, 85, 114], "1111": [19, 20, 30, 48, 50, 57, 63, 69, 77, 80, 85, 86, 101, 106, 110], "111164": 73, "11120": 71, "1118": 51, "11199615e": 86, "112": [52, 72, 83, 85, 114], "1120": 70, "11208236": [79, 87], "1122": 71, "112216": 60, "1129": 71, "113": [19, 83, 85, 114], "113207": 74, "113270": 60, "1132944094": 86, "113415": 71, "11375": 71, "113780": 69, "114": [83, 85, 114], "11409": 70, "11414": 70, "1144500": 50, "11447": 76, "114530": 64, "1145370": 50, "114570": 59, "11458": 71, "114647": 60, "1147": 49, "1148": 71, "114834": 71, "11488": 71, "11495": 71, "115": [83, 85, 114], "11500": [70, 115], "115060e": 74, "1151610541568202": 68, "115296e": 71, "115297e": 70, "1155142425200442": 68, "11552911": 76, "11559": 71, "115636": 59, "11570": 70, "115792e": 71, "115931221": 86, "115972": 58, "116": [83, 85, 114], "116027": 60, "11617": 71, "116274": 60, "116569": 71, "1166": 113, "1167": 70, "11673": 71, "11675": 71, "117": [58, 83, 85], "1170": 76, "11700": 115, "117072": 64, "117112": 59, "117242": 74, "11724226": 74, "117366": 74, "11743": 115, "11750": 71, "1176": 49, "1177": [49, 70], "117710": 60, "11792": 51, "11796": 71, "118": [72, 83, 85], "11802": 71, "1182": 51, "11823404": 77, "11825327": 86, "118255": 74, "1186": 51, "118601": 69, "11861": 51, "1187339840850312": 69, "11879": 71, "118799": 71, "118938e": 85, "118952": 69, "119": [77, 83, 85, 114], "1190236": 86, "1193": 86, "11932": 71, "11935": 76, "119669": 85, "119766": 74, "1198": [50, 69], "12": [18, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 81, 83, 84, 85, 86, 87, 100, 101, 106, 110, 112, 113, 114, 115], "120": [61, 68, 78, 83, 85, 114], "12002": 70, "1202": 113, "120468": 74, "12046836": 74, "120567": [64, 65], "120721": 69, "12097": [19, 20, 30, 50, 63, 69, 80, 110], "121": [71, 83, 85, 114], "1210": 71, "12101": 71, "12105472": 100, "121054720": 100, "1211": 71, "1213405": 50, "121399": 71, "1214": 100, "121584e": 74, "121711": 71, "12171951": 86, "121774": 66, "121824": 59, "12196389e": 86, "122": [21, 22, 23, 49, 75, 81, 83, 85, 113, 114], "12214": 51, "12223182e": 86, "1222426": 86, "122408": 60, "122777": 100, "123": [35, 47, 51, 52, 70, 77, 83, 85, 114, 115], "1230": 71, "123192": 77, "12323": 71, "1234": [47, 48, 49, 53, 56, 57, 75, 80, 84, 86, 100], "12348": 77, "1238": 71, "123917": 71, "124": [83, 85], "12410": 71, "124306": 68, "124480": 68, "124805": 70, "124825": 59, "125": [83, 114], "12500": 70, "125065": 100, "12539340": 100, "1255": 71, "12579": 71, "1258": 50, "126": [83, 114], "12606": 71, "12612": 71, "126777": 100, "126802": 71, "12689": 71, "127": [21, 83, 114], "127006": 71, "12705095": [87, 100], "12707800": 50, "1272404618426184": 68, "12752825": 100, "127563": 76, "1277": 72, "127778": 71, "127889": 83, "128": [51, 83, 114], "12802": 51, "12814": 71, "128300e": 59, "128312": 74, "128408": 69, "1284587": 86, "1285": 49, "12861": 71, "128651": 59, "1289984": 86, "129": [69, 83, 114], "12945": 113, "1294771": 86, "1295": [49, 71], "1295022": 86, "129514": 71, "12955": 70, "129606": 58, "129798": 58, "1298": 71, "12980769e": 86, "12983057": 85, "13": [22, 23, 25, 27, 48, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 81, 83, 84, 85, 86, 87, 100, 101, 106, 112, 115], "130": [52, 64, 69, 83, 114], "130122": 76, "130270e": 72, "13034980e": 86, "130370": 60, "130526": 83, "1306": 76, "130829": 74, "13091": 71, "1309844442144665": 68, "131": [83, 114], "13102231": 85, "131024": 68, "13119": 76, "1312": 115, "131211": 71, "1313": [51, 115], "13137893e": 86, "1317746": 86, "1318": 49, "132": [52, 58, 69, 83, 114], "13208": 115, "1321": [70, 115], "1322911": 86, "1324": [51, 70], "132454": 62, "1325": 51, "1325603": 86, "132671": 60, "13288": 70, "132903": 71, "132982": 58, "133": [52, 81, 83, 113, 114], "13300": 71, "133202": 71, "133421": 71, "133485194": 86, "13356": 71, "133596": 74, "13398": 77, "133f5a": 72, "134": [69, 78, 83, 114], "1340371": 49, "1341": 51, "134146": 71, "1342": 71, "134211": 74, "1343": 70, "134542": 58, "134567": 71, "1346035": 51, "134687": 71, "13474": 71, "134765": 71, "134784e": 58, "1348": 70, "1349": 76, "13490": 71, "135": [52, 83, 85, 114], "13505272": 50, "135142": 59, "135329": 66, "135344": 55, "135352": 8, "135379": 100, "135665": 59, "135707": 84, "135755": 83, "135856": 74, "13585644": 74, "135871": 69, "136": [53, 69, 77, 83, 86, 114], "1360": 51, "13602": 77, "136089": 69, "1361": 71, "136102": 58, "136178": 85, "1362430723104844": 68, "13642": 71, "136442": 69, "1366": 72, "136836": 69, "137": [21, 52, 53, 83, 114], "1371": 71, "137213": 59, "137396": 74, "137529": 85, "1378": 71, "137809": 85, "138": [83, 114], "1380": 70, "138068": 64, "13809": 71, "138264": 77, "138378": 60, "1386": 49, "13868238": 100, "138682380": 100, "138698": 100, "1387": 49, "138851": 64, "13893": 71, "138953": 55, "139": [77, 83, 112], "1390": 70, "139117e": 58, "139491": 100, "13956": 76, "139582e": 15, "1398": 71, "1399": 49, "139921": 83, "14": [48, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 79, 81, 83, 84, 85, 86, 87, 100, 101, 106, 112, 113, 115], "140": [61, 71, 78, 83, 114], "1400": 71, "14000073": 86, "140073": 58, "140081": 68, "1401": 49, "140770": [58, 59], "140833": 60, "140861": 50, "140926": 74, "141": [71, 83, 114], "141002": 59, "141098e": 71, "14114": 76, "141384": 66, "14141": 71, "141460": 55, "141546": 100, "141820": 60, "142": [83, 114], "14200098": 100, "142119": 58, "142270": 62, "142382": 58, "1424": 84, "14268": 85, "14281403493938022": 84, "142816195": 86, "14289": 71, "143": [81, 83, 114], "143342": 59, "143495": 83, "1435": 71, "143534": 58, "14368145": 100, "144": [83, 114], "14400": 70, "14405": 71, "14406": 71, "144084": 60, "1441": 49, "144137": 61, "144241": 64, "1443": 71, "144500e": 71, "144669": 74, "1447": 71, "144800": 60, "144908": 73, "144971": 70, "145": [83, 114], "145027": 55, "145245": 74, "14532650": 100, "145625": 74, "145748": 100, "14587": 71, "146": [83, 114], "146037": 74, "146087": 112, "146142808990006": 60, "146143": 60, "14625": 71, "146435": 59, "1465": 51, "146641": 100, "14667": 71, "1468115": 50, "146973": 60, "1469734445741286": 60, "147": [83, 114], "147015e": 71, "14702": 53, "147121": 74, "14744": 71, "14772": 71, "1479": 71, "14790924": 100, "147909240": 100, "147927": 53, "14798": 71, "148": [83, 114], "14803": 71, "148134": [58, 59], "148161": 74, "148443": 83, "14845": 53, "1485": 71, "148750e": [70, 71], "148790": 71, "148802": 71, "149": [72, 83, 114], "1492": 47, "149215e": 59, "149228": 77, "149285": 74, "149472": 77, "149714": 69, "14984": 71, "149858": [16, 83], "149882": 85, "149898": 74, "15": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 20, 48, 50, 51, 52, 55, 57, 58, 59, 60, 61, 64, 66, 67, 68, 69, 70, 71, 74, 75, 76, 77, 81, 83, 84, 85, 86, 87, 100, 101, 106, 112, 115], "150": [28, 52, 72, 77, 83, 114], "15000": [51, 70], "150000": 51, "15000000000000002": [60, 71, 74, 84], "150000e": 71, "1502": 50, "150200": 69, "150334": 71, "150408": 50, "150614": 53, "150719e": 70, "151": [83, 114], "151047e": 64, "151063": 58, "15113": 71, "151636": 60, "151819": 74, "1519222332384043465358616977828385878990": 86, "15194": 70, "152": [47, 83, 114], "152034": 71, "152148": [58, 59], "152353": 59, "15285": 71, "152896": 68, "152926": 62, "153": [77, 83, 114], "1530959776797396": 60, "153096": 60, "153119": 60, "153314": 59, "15347": 71, "15354": 76, "153587": 69, "153633": 53, "153639": 86, "153935": 59, "154": 83, "15430": 115, "154421": 100, "1545": 71, "154557": 74, "154758": 100, "154828": 60, "154890": 68, "155": [83, 114], "155000": 70, "155025": 74, "155120": 74, "155160": 55, "155174": 55, "155516": 73, "15556": 71, "1557093": 50, "156": [83, 114], "1560": 71, "156021": 74, "156169": 59, "156202": [58, 59], "156317": [58, 59], "1564": 100, "156545": 100, "156684": 59, "1569": 71, "156969": 60, "157": [59, 83, 114], "157091": 100, "157154": 58, "1576": 71, "157733": 68, "1577657": 50, "157e": 85, "158": [70, 83, 114], "158007": 74, "1581202": 86, "1581214202128314145475152607078799194": 86, "15812142021283141454751526070787991942346132433343536545962636466889295987161825294448495556576772737584869697991519222332384043465358616977828385878990": 86, "158121420212831414547515260707879919423461324333435365459626364668892959891011172627303739425065687174768081931001519222332384043465358616977828385878990": 86, "15812142021283141454751526070787991942346132433343536545962636466889295989101117262730373942506568717476808193100716182529444849555657677273758486969799": 86, "158121420212831414547515260707879919491011172627303739425065687174768081931007161825294448495556576772737584869697991519222332384043465358616977828385878990": 86, "15815035": 51, "158178": 60, "1582": 71, "1586": 71, "158697": 100, "1589": 71, "15891559": 74, "158916": 74, "159": 114, "15916": 49, "159386": 76, "1596": 52, "159633e": 59, "159841": 58, "159959": 71, "16": [6, 47, 48, 50, 51, 52, 55, 58, 59, 60, 65, 66, 69, 70, 71, 74, 75, 76, 77, 81, 83, 84, 85, 86, 87, 100, 101, 106, 112, 115], "160": [61, 78, 114], "1604": 51, "160932": 60, "161": [52, 113, 114], "161049": 59, "161141": 69, "1611558611": 86, "161198": 73, "161236": 74, "161243": 74, "161269": 58, "161288": [59, 68], "161543": 71, "1619": 51, "162": 114, "16201": 71, "16211": 70, "162153": 74, "1622": 71, "16241": 71, "162436": 77, "162593": 68, "1626685": 50, "162683": 77, "162710": 60, "162784": 85, "1628": 70, "162930": 71, "163": [71, 114], "163194": 74, "163566": 71, "163577": 55, "1637779": 86, "163816": 55, "163895": 60, "164": [55, 75, 114], "164034": 100, "164467": 70, "164608": 74, "164698": 66, "1648": 49, "164801": 74, "164805": 60, "164864": 69, "165": 114, "16500": 70, "165178": 74, "16536299": 100, "165362990": 100, "16539906e": 86, "1654": 71, "165419": 74, "165549": 112, "165707": 55, "16587": 70, "16590": 71, "16597": 71, "166": 114, "1661": 70, "166238": 68, "166375": 83, "167": [51, 70, 114], "16725": 71, "167547": 74, "167581e": 58, "1676": 71, "167765": 71, "167993": 100, "168": 114, "16803512": 100, "168089": 68, "168092": 100, "1681": 49, "168195": 76, "1683": 70, "168614": 74, "168931": 74, "169": [52, 114], "1691": [49, 71], "16910": 71, "169117": 77, "169196": 74, "169230e": 60, "16951": 71, "16984": 71, "17": [48, 50, 51, 52, 58, 59, 66, 69, 70, 71, 74, 75, 76, 77, 81, 83, 84, 85, 86, 87, 100, 101, 106, 112, 115], "170": 114, "1704": 71, "170709e": 59, "17083": 71, "171": 114, "1712": 113, "1714": 51, "171575": 74, "171815": 84, "171833": 59, "171848e": 58, "171942": 71, "172": [75, 114], "172022": 100, "172083": 59, "172210835": 86, "172628": 68, "172793": 74, "1729": 86, "173": 114, "173504": 65, "17372": 71, "1738": 71, "17385178": 84, "173969": 100, "173e": 75, "174": 114, "174106": 76, "174185": 74, "174499": 100, "174516e": 74, "17453": 71, "1746": 71, "174743": 83, "174835": 59, "174940": 83, "17499": 71, "175": 114, "1751": 70, "175176": 74, "17522": 71, "175284": 60, "175369": 59, "175635027": 50, "17576": 71, "175894": 77, "175931": 85, "176260455": 86, "176495": 74, "17655394": 74, "176554": 74, "176929": 100, "177": [113, 114], "177007": 74, "17700723": 74, "177043": [58, 59], "1773": 71, "1774": 49, "177463": 73, "177496": 74, "177611": 74, "177740": 58, "177751": 74, "17778": 71, "177830": 59, "17799": 71, "177995": 74, "178": [66, 114], "178169": 64, "178218": 59, "17823": 52, "178704": 100, "178763": 74, "178934": 100, "179": [64, 114], "179026": 59, "1795850": 50, "179588e": 74, "179777": 59, "1798913180930109556": 72, "18": [48, 50, 51, 52, 53, 58, 59, 66, 67, 69, 70, 71, 74, 75, 76, 77, 81, 83, 84, 85, 86, 100, 112, 115], "180": [61, 78, 114], "180143": 55, "18015": 71, "180176e": 71, "180190": 85, "180262": 59, "1803": 49, "18030": 71, "180575": [64, 65], "1807": [49, 71], "1809": 113, "180951": 74, "181": 114, "1812": 71, "1814": 49, "18141": 71, "181446": 100, "182": 114, "1820": 49, "182427": 59, "182633": 74, "182849": 74, "183": [52, 85, 114], "183339": 58, "183373": 85, "183526": 60, "183553": 75, "18356413": 85, "18368": 71, "183855": 84, "183888": 69, "184": [52, 113, 114], "184247": 58, "184347": 59, "185": [47, 51, 52], "18500": 71, "185130": 75, "18527081": 86, "1855": 71, "185585": 83, "185984": 58, "186": [71, 114], "18604": 71, "1862": 49, "186237": 59, "18631": 71, "18637": 110, "186589": 55, "18666": 71, "186735": 74, "18678094e": 86, "186836": 74, "187": 114, "187153": 100, "187664": 58, "187690": 74, "18789": 71, "188": 114, "188175": 74, "1881752": 74, "188223": 74, "188400": 59, "1887": 85, "1887826": 86, "18888149e": 86, "188882": 59, "188991": 100, "189": [52, 75, 114], "189195": 71, "189248": 58, "189293": 71, "1895815": [29, 50, 69], "189737": 74, "189927": 71, "189998": 74, "19": [48, 50, 51, 52, 58, 59, 68, 69, 70, 71, 74, 75, 76, 77, 83, 84, 85, 86, 100, 112, 115], "190": [52, 114], "19000": 71, "190096": 100, "19031969": 74, "190320": 74, "19033538": 50, "190381": 85, "190648": 11, "19073905e": 86, "190809": 74, "190869": 83, "190892": 77, "1909": [29, 50, 69], "190915": 60, "190921": 65, "190976": 75, "190982": 74, "191": [52, 86, 113, 114], "191192": 58, "1912": 113, "191223": 59, "1912705": 80, "191294": 59, "191319e": 70, "191397": 83, "191534": 70, "191716": 71, "1918": 49, "192": 114, "1922": 71, "192240": 100, "192505": 73, "192526": 76, "19252647": 76, "192539": [17, 83], "192587": 74, "192952": 55, "193": 114, "193060": 74, "193253": 58, "193285": 58, "193308": [17, 83], "193341": 59, "19374710e": 86, "19382": 71, "193849": 75, "19385": 71, "193f0d909729": 52, "194": [67, 71, 114], "194092": 58, "1941": 51, "19413": [70, 71], "194303": 59, "194601": 61, "195": 114, "19508": 77, "19508031003642462": 77, "19509680e": 86, "195377": 74, "195396": 74, "195547": 71, "195564": 69, "19559": [51, 70], "195761": 74, "195781": 58, "1959": 113, "196": 114, "196189": 74, "196437": 71, "196478e": 59, "19680840": 100, "196e": 35, "197": 114, "1970": 71, "197000e": 71, "19705": 71, "197225": [53, 81, 112], "1972250000001000100001": [52, 81, 112], "1974": 71, "197424": 84, "197484": 100, "19756": 71, "19758": 71, "197600": 62, "197711": 71, "197920": 58, "19793": 71, "19794": 71, "198": 114, "198218": 69, "19824": 71, "198351": 74, "198503": 75, "198549": 53, "198687": 51, "1988": [48, 57, 80, 85], "198953": 83, "199": 114, "1990": [51, 70, 71], "1991": [51, 70, 71, 115], "199281e": 74, "199282e": 71, "199412": 59, "199458": 100, "1995": [50, 69], "1998": 72, "19983954": 78, "199893": 64, "1999": [72, 78], "1_": [60, 74], "1e": [4, 6, 8, 9, 11, 12, 13, 16, 17, 18, 71], "1f77b4": 62, "1x_4x_3": 62, "2": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 35, 36, 40, 42, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 100, 101, 102, 103, 106, 107, 108, 109, 111, 112, 113, 114], "20": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 29, 30, 31, 47, 48, 50, 51, 52, 58, 59, 60, 61, 64, 66, 67, 69, 70, 71, 74, 76, 77, 78, 79, 80, 83, 84, 85, 86, 87, 100, 101, 106, 112, 115], "200": [24, 27, 28, 49, 60, 61, 63, 67, 73, 74, 78, 80, 84, 114], "2000": [18, 20, 51, 55, 58, 59, 60, 70, 71, 74, 78, 83, 85], "20000": [51, 70], "20000000000000004": [60, 71, 74], "200000e": 71, "200049": 58, "200065": 55, "20010": 71, "200110": 71, "2003": [19, 113], "200303": 112, "2005": 61, "20055": 71, "2006": 71, "20073763": 67, "20074": 71, "201": [52, 71, 114], "2010": [50, 69], "2011": [50, 69, 110, 112], "2013": [63, 100, 113], "2014": [100, 113], "2015": [28, 113], "201528": [58, 59], "20158": 71, "2016": 72, "2017": [26, 113], "201768": 69, "201788e": 71, "201796": 66, "2018": [19, 20, 30, 31, 48, 50, 51, 57, 61, 63, 67, 69, 70, 71, 76, 80, 86, 100, 110, 113, 114], "2019": [24, 52, 58, 59, 60, 64, 65, 71, 74, 76, 84, 87, 89, 94, 99, 110, 112, 113], "201e": 75, "202": 114, "2020": [8, 9, 21, 22, 23, 25, 27, 49, 52, 61, 77, 84, 85, 101, 103, 113], "2020435": 50, "2021": [29, 49, 50, 52, 58, 59, 69, 113, 114], "20219609": 50, "2022": [76, 77, 85, 101, 103, 109, 110, 113], "2023": [32, 78, 85, 87, 95, 96, 113], "2024": [47, 56, 72, 75, 77, 85, 110, 113], "202603": 59, "202650e": 60, "20269": 71, "20274": 71, "202846": 59, "203": [51, 58, 70, 114], "203284": 60, "20329": 71, "2036": 71, "203828": 71, "203893": 83, "204": 114, "204007": 74, "20400735": 74, "204362": 77, "204455": 59, "204482": 74, "204626": 55, "204653": 83, "204794": 74, "205": [75, 76, 114], "205187": 60, "205224": 76, "205938": 69, "206": 114, "2061": 71, "206253": [70, 71], "2064": 71, "206614": 74, "207": [75, 85, 114], "207155948": 86, "207222": 70, "2075": 49, "207834": 59, "20783816": 50, "207840": 65, "207912": 100, "208": [55, 114], "208034e": 71, "2080787": 50, "20823898": 50, "2086": 71, "209": [55, 72], "209014": 74, "209219e": 76, "209257": 8, "209546e": 71, "209894": 74, "21": [19, 20, 30, 47, 48, 50, 51, 52, 58, 59, 63, 69, 70, 71, 74, 76, 77, 80, 83, 84, 85, 86, 100, 110, 112, 113, 115], "210": [22, 23, 27, 55], "2103": [71, 110], "2103034": 50, "210319": [58, 59], "210323": 74, "2104": 114, "2107": 113, "21078": 71, "211": [47, 55, 75, 114], "21105": [52, 84, 110, 112], "2112": 77, "21142": 71, "211534": 60, "21155656": 74, "211557": 74, "212": [55, 114], "2122": 71, "21257396e": 86, "212844": 69, "212863": 58, "213": [55, 75, 113, 114], "213026": 71, "213070": 59, "213135": 59, "21361": 71, "213743e": 59, "2139": 25, "214": 72, "214458": 68, "214764": 76, "215": 55, "215069": 74, "215342": 74, "2155": 71, "21550": 71, "21562": 71, "2157": 86, "21573": 71, "215967": 100, "216": 55, "216207": 84, "21624417": 50, "2163": 71, "216344": 74, "21669513e": 86, "216761": 73, "217": [55, 75, 113], "21716": 71, "2171802": [50, 69], "217244": 13, "218": 55, "21804": [51, 70], "218176": 55, "218383": 55, "218767": 71, "2189": 71, "218938": 71, "219": [21, 22, 23, 49, 55, 113], "2191274": 50, "2197237644227434": 68, "22": [48, 50, 51, 52, 58, 59, 68, 69, 70, 74, 75, 76, 77, 83, 84, 85, 86, 100, 112, 115], "220": [35, 55, 114], "220088": 71, "220398": 58, "220407": 68, "220772": 74, "221": [55, 114], "2213": 69, "2214": 69, "221419": 71, "2215": 69, "2216": 69, "2217": [50, 69], "222": 114, "2222": [48, 50, 57, 85], "22222": 71, "22272803e": 86, "222843": 74, "222882": [59, 68], "223": [72, 75, 114], "223158": 68, "22336235": 50, "223485956098176": [64, 65], "223617": 68, "22375856": 50, "22390": 70, "223928": 68, "224": [75, 114], "224897": [58, 59], "225": [49, 78, 114], "225034": 61, "22505965": 50, "22507006e": 86, "225175": 74, "225222": 74, "22522221": 74, "22528": 71, "225350": 59, "225427": 55, "225459760731946": 60, "225460": 60, "225574": 69, "2256": 71, "22562": 71, "225670": 68, "225776": 77, "226": 114, "2264": 49, "226524": 74, "226598": 69, "226938": 65, "226969": 55, "227": [71, 114], "2271071": 32, "2276": 49, "2279": 71, "227932e": 70, "228035": 71, "2281": 71, "228214": 85, "228404": 68, "228597e": 59, "228630": 59, "228648": 51, "229": [51, 114], "22925": 71, "22937": 71, "229443": 74, "229452": 85, "229472": 70, "2295": 71, "229759": 84, "2298": 49, "229961": [58, 59], "229994": [58, 59], "23": [9, 42, 50, 51, 52, 58, 59, 61, 67, 69, 70, 71, 74, 76, 77, 81, 83, 84, 85, 86, 100, 110, 112, 113, 115], "230": 49, "230009": [64, 65], "23040741": 86, "2307": [50, 69, 80], "2308": 76, "230842": 58, "230956": 62, "231": [19, 114], "23113": 85, "231153": 59, "231310": 74, "231430": 100, "231467": 85, "231986": 74, "231e": 75, "232": 72, "232134": [58, 59], "232157": 59, "2328": 71, "232868e": 59, "232959": [64, 65], "232e": 85, "233": 26, "233029": 58, "233154": 115, "2335": 49, "233705": 59, "234": 113, "234137": 77, "234153": 77, "234205": 71, "234431": 68, "234534": 60, "234605": 53, "234613243334353654596263646688929598": 86, "23461324333435365459626364668892959891011172627303739425065687174768081931007161825294448495556576772737584869697991519222332384043465358616977828385878990": 86, "234798": 71, "234910": 69, "235": 114, "235291": 58, "2359": 115, "23590": 71, "236008": 60, "236015e": 58, "236309": 71, "236884": 68, "23690345e": 86, "237": 52, "237115": 59, "237200e": 58, "237252": 71, "237341": 58, "237461": 76, "23748": 71, "23751359e": 86, "237896": 74, "23789633": 74, "238": [50, 69, 114], "238101": 74, "238225": 100, "238251": 60, "238529": 12, "23856": 71, "238794": 74, "239": 114, "239243": 58, "239267": 68, "239313": 59, "23965": 71, "23e": 51, "24": [50, 51, 52, 58, 59, 67, 68, 69, 70, 71, 74, 76, 77, 78, 83, 84, 85, 86, 100, 112, 113, 114, 115], "240": 47, "240127": [58, 59], "240146": 59, "240295": 76, "240532": [58, 59], "2407": 49, "24080030a4d": 52, "240813": 66, "241049": 74, "241064": 59, "241596": 85, "2416": 49, "241609": 71, "241645": 59, "241678": 58, "241827": 59, "241962": 77, "24199": 71, "241e": 75, "242": 113, "242000": 71, "242124": [70, 71], "242139": 100, "242158": [70, 71], "2424596822": 65, "242815": 100, "242902": 74, "2430561": 49, "243246": 74, "2438": 71, "2439": 71, "243e": 75, "244": [35, 71], "244090": 71, "244455": 74, "244622": 100, "24469564": 112, "245": [113, 114], "245062": 74, "2451": 49, "24510393": 51, "245370": 69, "245512": 74, "245531": 58, "245720": 62, "246": 114, "24631207": 86, "246624": 83, "246731": 70, "2467506": 50, "246753": 74, "246879": 74, "247": [75, 114], "247020": 60, "247057e": 74, "2471": 71, "2472": 71, "247617": 83, "247717": 71, "24774": [70, 71], "247826": 69, "247977": 58, "248171": 74, "248638": 60, "2488659690": 86, "249": [50, 69, 72, 114], "2491": 71, "24917": 71, "24979946": 86, "249986": 68, "25": [17, 18, 21, 22, 23, 27, 28, 29, 30, 50, 51, 52, 58, 59, 60, 62, 63, 67, 68, 69, 70, 71, 74, 77, 78, 83, 84, 85, 86, 100, 112, 115], "250": [72, 114], "2500": 71, "25000000000000006": [60, 71, 74], "250073": 71, "250210": 60, "2503": 71, "250354": 74, "250425": 60, "251": [70, 71, 76], "251101": [83, 84], "251412": 59, "251480": 59, "251953": 71, "252133": 71, "252253": 76, "25240463": 85, "252524": 74, "252601": 100, "253026": [58, 59], "2532": 71, "253437": 73, "253724": 74, "25374": 71, "254": [71, 114], "25401679": 50, "254035": 68, "254038": 65, "254083": 59, "2543": 71, "254324": 60, "254400": 100, "255": [71, 114], "255034e": 59, "2552736": 86, "255995": 58, "256": [71, 84], "256002": 85, "256416": 74, "256567": 69, "25672": 71, "256944": 74, "256983": 15, "256992": 71, "257019": 59, "257207": 50, "257377": 62, "257523": 58, "258083": 59, "258158": [58, 59], "2583": 71, "258522": 58, "258541e": 18, "258951": 74, "259164": 59, "259367": 83, "259395": 66, "2594": [51, 70], "259828": [58, 59], "259875": 59, "25x_3": 62, "26": [50, 51, 52, 53, 58, 59, 61, 67, 69, 70, 71, 78, 81, 83, 84, 85, 86, 100, 112], "26016": 71, "260161": [16, 83], "260211": [58, 59], "260356": 70, "260360": 74, "261": 75, "2610": 71, "2613": 71, "261520": 55, "261624": [70, 71], "261685": 71, "26175": 71, "261777": 71, "261889": 72, "261903": 69, "2619317": 50, "262423e": 71, "262621": 69, "262829": 86, "263": [19, 71, 114], "2633": 71, "263942e": 59, "263974e": 74, "264": [113, 114], "264086": 62, "264274e": 71, "264884": 71, "265": 114, "2651": 85, "265119": 73, "2652": [52, 70, 71], "265547": 71, "265744": 68, "2658": 65, "265929": 75, "266": 114, "266147": 75, "266686": 58, "266922": 100, "267": 72, "2670691": 50, "267500": 69, "267581": 71, "267950": 74, "268": 114, "268055": 71, "268343": 68, "268628e": 59, "268942": 74, "268943": 58, "268998": 51, "269043": 74, "269977": 71, "26bd56a6": 52, "26e": 51, "27": [22, 23, 27, 48, 50, 51, 52, 53, 58, 59, 61, 67, 69, 70, 71, 78, 81, 83, 84, 85, 86, 100, 112, 113], "270": 114, "2700": 52, "27024328": 86, "270644": [58, 59], "271": 114, "271004": [70, 71], "271083": 71, "272296": 71, "272332e": 58, "272408": 59, "272662": 71, "273": 52, "273299": 59, "273356": 60, "27371": [51, 70], "27372": [51, 70], "274": [52, 71], "2740991": 49, "274251e": 70, "274267": 69, "27429763": 85, "2746288": 86, "274793": 74, "274825": [17, 83], "27487": 71, "2754": 49, "275596": 100, "276": [52, 114], "276148": 74, "276189e": 69, "2764": 71, "2766091": 51, "27713": 71, "277299": 53, "27751": 71, "277512": 59, "277561e": 69, "277968": 74, "278": [76, 114], "2780": 50, "278000": 69, "278035": 55, "278391": 71, "278434": 64, "278522": 55, "2786": 100, "278804": 59, "279": 114, "27951256e": 86, "27986": 71, "279933e": 59, "28": [50, 51, 52, 58, 59, 63, 66, 67, 69, 70, 78, 83, 84, 85, 86, 100, 112, 114], "280196": 65, "280454dd": 52, "280514": 100, "280963": 73, "281": [75, 114], "281024": 74, "28111364": 51, "2815": 71, "2818": 49, "2819": 100, "282": [75, 113, 114], "282200": 65, "2825": [110, 112], "28251": 71, "282870": 71, "2830": [110, 112], "283041": 58, "283207": 58, "28326": 71, "283386": 58, "2836": 49, "2836059": 50, "28382": 71, "283974": 74, "283992": 58, "283994": 74, "283e": 75, "284": 114, "28425026": 76, "284271": 66, "284397": 115, "28452": [51, 70], "2849": 71, "284987": 71, "285": [75, 85, 114], "285e": 75, "286": 114, "286027": 83, "286203": 58, "286371": 58, "2865": [49, 71], "286507": 60, "286563e": 71, "286593": 71, "287041": 74, "287196": 58, "287815": 76, "287926": 74, "288": 72, "288976": 71, "289": 113, "289062": 70, "289357": 59, "289440": [58, 59], "29": [15, 50, 51, 52, 58, 59, 67, 69, 70, 76, 78, 83, 84, 85, 86, 100, 112], "290": 85, "290565": 59, "290736e": 59, "290987": 70, "291": [71, 75], "2910": 71, "291008": 58, "291011": 85, "291071": 74, "29107127": 74, "291405": 74, "291406": 74, "291434": 59, "291500e": [70, 71], "291517": [58, 59], "291963": 74, "292": 73, "292028": 60, "292047": 100, "292105": 74, "29214524": 86, "292178": 70, "292302995303554": 60, "292303": 60, "2925": 52, "2927": 71, "292997": 74, "29299726": 74, "293218": 74, "293617e": 71, "294067": [58, 59], "294449": 58, "295": 113, "295307": 58, "295481": 74, "29548121": 74, "295837": [53, 81, 112], "2958370000000100000100": [52, 81, 112], "2958370001000010011100": [52, 81, 112], "2958371000000010010100": [52, 81, 112], "296228": 71, "296729": 69, "29678199": [79, 87], "296901": 58, "297287": [58, 59], "2973": 71, "297349": [64, 65], "297682": 74, "297687": 71, "297749": 71, "29784405": 76, "298": [26, 52], "298076": 58, "298120": 60, "298228e": 71, "299": [52, 72, 75], "299537": 65, "299712": 64, "2999": 55, "2_": [32, 78, 101, 103, 109], "2_x": [32, 78], "2d": [87, 94], "2dx_5": [60, 74], "2e": [47, 49, 50, 51, 52, 84, 85, 87, 100, 112], "2f": 66, "2m": [101, 106, 109], "2n_t": 62, "2x": 74, "2x_0": [24, 58, 59, 64, 65], "2x_4": 62, "3": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 30, 35, 36, 41, 42, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 100, 101, 106, 110, 111, 112, 113, 114], "30": [24, 47, 48, 50, 52, 55, 56, 57, 58, 59, 60, 61, 67, 69, 70, 71, 74, 75, 78, 83, 84, 85, 86, 100, 112], "300": [48, 57, 60, 71, 74, 80, 113], "3000": 55, "30000000000000004": [60, 71, 74], "300031": 58, "30031116e": 86, "300892e": 59, "30093956": 76, "301": 52, "301366": 100, "301371": 74, "3016": 70, "301737": 58, "30189": 71, "302149": 58, "302357": 74, "302382": 68, "302571": 83, "302648": 69, "303007": 58, "303324": 69, "303489": 74, "303613": 74, "30361321": 74, "30383": 71, "303835": 69, "303f00f0bd62": 52, "304130": 74, "304159": 74, "304201": 62, "305133": 83, "30527": 71, "305341": 74, "305612": 69, "305775": 74, "305b": 52, "306297": 58, "30645": 71, "30672815": 50, "306915": 69, "306963": 74, "307407": 74, "308": 71, "308568": 59, "308774": 58, "30917769": [64, 65], "309539": 68, "309772": 69, "309823e": 71, "30982972": 74, "309830": 74, "31": [50, 51, 52, 55, 58, 59, 67, 69, 70, 71, 78, 83, 84, 85, 86, 100, 112, 115], "310000e": 71, "310145": 68, "310761": 73, "31080800": 86, "311": 75, "311253": 71, "311321": 59, "311667": 59, "311712": 64, "3120": 71, "312652": 75, "313": 85, "313056": 100, "313209": 60, "313324": 71, "31337878": 71, "313535": 74, "31378": 52, "314": 86, "3141": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 50, 52, 53, 69, 79, 81, 83, 84, 87, 100, 112], "314247": 77, "314341": 58, "3146": 18, "3146191": 86, "314625": 59, "314651": 64, "31476": [70, 71], "315031": 77, "315036": 58, "3151": 71, "315155": 59, "315223": 55, "315290": [64, 65], "315310": 58, "315769e": 58, "316": 52, "316193": 74, "31632": 71, "316407": 85, "316540": 69, "316717": [58, 59], "316826": 58, "316863": 59, "317394": 62, "317487": 74, "317607": 74, "318": 52, "318000e": 71, "318438": 71, "318552": 71, "318584": 100, "318753": [64, 65], "319": 52, "319100": [64, 65], "319759": 74, "319850": 74, "32": [50, 51, 52, 58, 59, 67, 68, 69, 70, 71, 78, 83, 84, 85, 86, 87, 100, 112], "320": 71, "320314": 70, "320633": 60, "321686": 100, "322": 72, "322186e": 58, "32236455588136": 61, "322404": 76, "322751": 59, "3234": 71, "323636": 70, "323679": 69, "324": [51, 71], "324476": 55, "324518": 73, "32458367": 50, "3245837": 74, "325056": 74, "325090": 71, "325486": 58, "325599": 58, "326": 75, "326148": 59, "326721": 59, "326740": 74, "326871": 77, "3268714482135234": 77, "327257": 58, "327803": 83, "328471": 58, "329339": 61, "32950022e": 86, "33": [50, 51, 52, 58, 59, 64, 67, 68, 69, 70, 71, 78, 83, 84, 85, 86, 100, 112, 113], "3300": [51, 70], "330068": 58, "330100": 58, "330143": 74, "33014346": 74, "330163": 59, "330285": [58, 59], "3304269": 50, "330615": 74, "330731": [17, 83], "33084646": 86, "331365": 64, "331521": 74, "331602": 71, "33175566": 74, "331756": 74, "3323": 86, "332502": 59, "332782": [17, 83], "3329": 71, "332996": 69, "3333": [48, 50, 57, 83, 84, 85], "3333333": 52, "33335939e": 86, "3335": 71, "333581": 70, "333655": 58, "333704": 59, "333955": 59, "334": 51, "334649": 66, "334750": 60, "335": [47, 86], "33500": 71, "335176": 71, "335446": 55, "335609e": 74, "335846": 74, "335853": 71, "336": 72, "336382": 59, "336461": 71, "336612": 62, "337380": 74, "3376": 49, "337619": 61, "338": 76, "33849": 71, "3386": 86, "338603": 58, "338775": 60, "338908": 60, "339077577": 86, "339269": 76, "33928": 71, "339443": 59, "339570": 74, "339875": [64, 65], "34": [48, 49, 50, 51, 52, 58, 59, 65, 67, 69, 70, 71, 76, 78, 83, 84, 85, 86, 100, 115], "340": [51, 71], "340029": 59, "340274": 76, "341336": 13, "341472": 68, "341755e": 58, "3420": 71, "342362": 55, "342467": 83, "342632": 68, "342675": 50, "34287815": 76, "342989": 71, "342992": 69, "343": [47, 71, 75], "343685": 58, "34375": 70, "343828": 58, "344212": 115, "344305": 66, "344505": [70, 71], "344640": 74, "344753": 55, "344787": [58, 59], "344834": 62, "345065e": 71, "345381": 60, "3453813031813522": 60, "3454": 71, "345852": 59, "345903": 74, "345989": 58, "346107": 70, "346206": 74, "346238": 76, "346269": 59, "346678": 73, "346964": 58, "347310": [17, 83], "347696": 60, "34769649731686": 60, "347929": 71, "348": 75, "348319": 59, "34858240261807": 61, "348617": 74, "348622": 75, "348700": 59, "348980e": 59, "3491472145": 86, "3492131": 49, "349383": 69, "34943627": 67, "349638": 59, "34967621": 50, "349772": 65, "35": [51, 52, 58, 59, 60, 69, 70, 71, 74, 83, 84, 85, 86, 100, 101, 106, 115], "3500000000000001": [60, 71, 74], "350165": 84, "350208": 58, "350518": 74, "350712": [64, 65], "35077502": [101, 106], "351220": 59, "351629": 71, "351766": 73, "352": [51, 69], "352250e": 70, "352259e": 71, "3522697": 50, "352813": [83, 84], "35292": 71, "352990": 71, "352998": 71, "353105": 18, "353412": 74, "35341202": 74, "35349": 72, "35365143": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "353748e": 74, "3538": 49, "354": 71, "354188": 62, "354226492": 86, "354371": 74, "354688": 14, "355065": 55, "355209": 74, "355651": 59, "356136e": 71, "356167": 65, "356183": 71, "35620768e": 86, "3564": 71, "3565": 71, "3568": 85, "357": 71, "357170": 58, "35731523": 85, "358158": [70, 115], "358289": 69, "358395": 76, "358799": 100, "358977": 70, "359": [75, 115], "359100": 71, "359161e": 58, "3593": 76, "359307": 59, "35th": 113, "36": [51, 52, 58, 59, 69, 70, 83, 84, 85, 86, 100], "360004": 74, "360065": 100, "360249": 66, "360475": [58, 59], "360572": 59, "360655": 71, "360683": 60, "360801": 60, "361": 75, "36112819": 86, "361518": 60, "361518457569366": 60, "361521": 14, "3619201": 25, "362": 47, "362157": 58, "36231307e": 86, "363276": 50, "364221": 58, "3643": 100, "364595": 50, "3647": 52, "364800": 74, "36501": 71, "365551": 59, "36557195e": 86, "36566025e": 86, "366": 71, "36616": 71, "366310": [58, 85], "366529": 73, "366718627": 50, "366950": 58, "367": [35, 75], "367181": 58, "367323": 74, "367336237": 86, "367398": 68, "367571": 60, "367625": 74, "368152": 69, "3682": [51, 70, 71], "368324": 69, "368499": 60, "3684990272106954": 60, "368565735": 86, "369556": 60, "3696": 76, "369796": 74, "369869": 70, "369981": 69, "37": [51, 58, 59, 69, 70, 71, 83, 84, 85, 86, 100], "3702770": 50, "37043700": 86, "370736": 69, "3707775": 50, "370908": 58, "3710": 71, "371357": [70, 71], "371429": 60, "371850e": 59, "372": 113, "37200": [70, 71], "372097": 60, "3722": 71, "37231324": 78, "3724": 71, "372427": 59, "3727679": 50, "373218e": 68, "3738573": 50, "374364": 74, "37436439": 74, "3745": 71, "374821e": 71, "374862": 58, "374917e": 58, "375081": 71, "375274": 58, "375465": 74, "375621": 68, "375844": 68, "376760": 59, "376806": 59, "377060": 71, "377195": 55, "377311": 74, "377669": 59, "37791452": 86, "378351": 11, "378588": 58, "378596": 69, "378688": 74, "378727": 58, "378834": 74, "3788859": 50, "379": 113, "379038": 74, "37939": 71, "379614": 74, "379626": 58, "379981e": 59, "38": [52, 58, 59, 70, 72, 83, 84, 85, 86, 100], "3800694": 50, "38061749": 86, "380837": [70, 71], "381": 75, "381072": 74, "381603": 58, "381685e": [70, 71], "381689": 74, "3817": 71, "381826": 15, "382286": 71, "382582e": 6, "382684": 83, "382872": 60, "383297": 74, "383531": 68, "384": 71, "384223": 85, "384443": 59, "384677": 55, "384777": 71, "384865": 59, "384928": 58, "385013": 55, "3851": 71, "385160": 59, "385240": 100, "385615": 55, "38571651": 86, "385917": 69, "386": [52, 71], "386102": 60, "386502": 71, "386831": 55, "386988": 61, "387": 52, "3871": 49, "387426": 74, "387780": 74, "388026": 58, "388071": 74, "388185": 55, "38818693": 86, "388216e": 84, "388668": 74, "38866808": 74, "388871": 71, "389": 52, "389126": 85, "389164": 68, "38922": 85, "389566": 73, "38973512e": 86, "389755": 58, "38990574": 86, "39": [47, 49, 50, 51, 52, 53, 55, 58, 59, 61, 65, 66, 67, 69, 70, 71, 76, 77, 78, 83, 84, 85, 86, 100], "39010121e": 86, "390379": 74, "391377": 77, "392": 47, "392128": 59, "392242": 66, "39236801": 67, "392400": 71, "392623": 59, "392752": 61, "392833": 76, "392864e": [70, 71], "392917": 58, "393060": 83, "393604": 60, "393654": 55, "394226": 59, "39425708": 50, "395076e": 71, "395136": 69, "395268": 83, "395569": 58, "395603": 58, "3958": 85, "395889": 71, "396": [35, 85], "39611477": 51, "396173": 64, "39621961e": 86, "396300": 64, "3964": 71, "396531": 71, "396985": 69, "396992": [58, 59], "397140": 60, "397155": 59, "397179": 55, "39727": 71, "397313": 49, "397536": 68, "397578": 66, "397811": 76, "398": [81, 112], "3985": 71, "398770": 74, "398999": 83, "399": 51, "399056": 74, "399223": 62, "399343e": 58, "399355": 62, "399692": 74, "399858": 77, "3cd0": 52, "3dx_1": [60, 74], "3e1c": 52, "3ec2": 52, "3f5d93": 72, "3x_": 74, "3x_4": [60, 74], "4": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 22, 23, 27, 32, 35, 36, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 100, 101, 106, 112, 114], "40": [50, 58, 59, 60, 61, 68, 70, 71, 72, 74, 78, 81, 83, 84, 85, 86, 100, 101, 106], "400": 69, "4000000000000001": 84, "40000000000000013": [60, 71, 74], "400211562": 86, "40029364": [101, 106], "400823": 74, "400855956463958": 60, "400856": 60, "400894": 72, "401": [19, 115], "401247": [87, 100], "40127723e": 86, "401690e": 59, "401931": [64, 65], "402077": 71, "402113": 100, "402301e": 84, "402902": 71, "403": 75, "403425": 74, "403626490670169": 79, "4036264906701690": 79, "403626491": 79, "403715": 6, "403771948": 87, "4039": 49, "404267": 58, "404300": 55, "404318": 49, "404411": 58, "40452": 71, "404550": 73, "405050": 59, "405203": 62, "405374": 71, "40583": 49, "405890": [17, 83], "406285": 74, "406446": 60, "4065173": 86, "40676": 49, "40682190": 86, "407": 75, "407558": 58, "407565": 58, "408476": [101, 106], "40847623": [101, 106], "408479": 69, "408509": 59, "408539": 74, "408565": 74, "409154": 49, "4093": 76, "409328": 71, "409395": 74, "409746": 60, "409848": [58, 59], "41": [55, 58, 59, 70, 71, 83, 84, 85, 86, 100], "410100": 58, "410393": 60, "410667": 83, "410681": 62, "410682": 58, "410795": 69, "41093655": 86, "411146e": 59, "411190": [58, 59], "411291": 73, "411295": 74, "411304": [58, 59], "411447": 71, "411582": 74, "411768": 59, "412004": 64, "412127": 74, "412304": 77, "412477": 62, "412653": 69, "412714": 60, "412726": 59, "412941e": 59, "413247e": 58, "41336": 84, "41341040": 50, "413608": 74, "414": 75, "414073": 12, "414533": 59, "41525168e": 86, "415375": 58, "41566": 85, "415812": 115, "415988": 71, "416052": 55, "416132": 59, "4166": 71, "4166667": 52, "416757": 74, "416899": 58, "416919": 59, "416e": 75, "417640": 58, "417727": 70, "417736": 68, "417767": [64, 65], "417834": 55, "41798768e": 86, "418": [35, 47], "418056": 74, "41805621": 74, "418438": 70, "418741": 55, "418806e": 60, "41918406e": 86, "41932857": 86, "419371": 74, "419871": 55, "41989983e": 86, "4199952": 50, "41e5": 52, "42": [8, 9, 27, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 71, 73, 74, 76, 77, 78, 83, 84, 85, 86, 100, 113], "4200": 71, "420316e": 71, "420608e": 76, "42073312": 50, "420967": 60, "421083": 49, "4211349413": 50, "421163": 58, "421200": 77, "421234": 83, "421297e": 59, "421357": [64, 65], "421576e": 71, "421793": 76, "421919": 71, "422007": 76, "422266": 71, "422293e": 83, "422325": 60, "422561": 55, "422591": 59, "42338": 71, "4235839": [64, 65], "42388745": 78, "423921e": 83, "423951": 49, "424108": 60, "424127": 86, "42412729": 50, "424292": 58, "424328": 74, "424651": 85, "424717": 60, "424748": 77, "425": 69, "425103": 49, "425208": 71, "425493": 49, "42550": 71, "426055": 49, "426540": 69, "426540301": 50, "426736": 71, "427": 71, "427486": [58, 59], "42755087": 76, "427551": 76, "427573": 69, "427725": 74, "428": [100, 115], "428046": 73, "42811700": 115, "428255": 74, "428411": [70, 71], "428467": 74, "4284675": 74, "428771": [17, 83], "4290": 49, "429057": 59, "429230": 58, "429705": 58, "42ba": 52, "43": [51, 55, 58, 59, 83, 84, 85, 86, 100], "430298e": [70, 71], "430595": 59, "430608": 58, "431061e": 58, "4311947070055128": 84, "431253": 68, "431306": 74, "431701914": 110, "431998": 55, "432130e": 70, "432300e": 74, "43231359e": 86, "432707": 75, "43294": 52, "43297420": 86, "432f": 52, "433": [52, 75], "433221": 60, "4336": 71, "43374433": 78, "433750": 58, "433753": 68, "4339": 49, "434121": 68, "434519": 83, "434535": 74, "43453524": 74, "435": 52, "43503345": 85, "43511": 71, "435401": 69, "4357": 71, "435927": 71, "435967": 69, "43597565": 74, "435976": 74, "436": [52, 71], "436016": 68, "43627032": 61, "436327": 71, "436394": 68, "436764": 75, "436806": 71, "436817": 68, "437667": 70, "437924": 71, "438": 69, "438219": 74, "438289": 71, "438569": 71, "438578e": 71, "43883": 65, "438834": 59, "4389": 71, "438960": 69, "439401e": 59, "439541": [70, 71], "439675": 75, "439699": 55, "43989": 83, "439958": 68, "43f0": 52, "44": [55, 58, 59, 61, 83, 84, 85, 86, 100], "440320": 71, "440364": 83, "440605": 84, "440747": 58, "440a": 52, "441153": 74, "441209": 74, "441219": 64, "44124313": 85, "441282": 58, "4416552": 50, "441676": 55, "441849": 58, "443016": 60, "443032": 70, "44312177": 51, "443686": 74, "4437": 71, "443701": 66, "443e": 75, "444046": 71, "4444": [48, 50, 57, 85], "444500": [70, 71], "444850": 71, "4449272": 71, "445": 75, "445476": 58, "44563945e": 86, "4461928741399595": 60, "446193": 60, "4462": 52, "44647451": 76, "44713577e": 86, "447492": 71, "447624": [58, 59], "447706": 60, "447849": 61, "448": [47, 71], "448252": 59, "448456e": 59, "448569": 58, "448587": 60, "448745": 74, "448842": 59, "4489": 71, "44890536": 86, "448923": 66, "449107": 9, "449150": [17, 83], "44950": 71, "44972962": 86, "44fa97767be8": 52, "45": [55, 58, 59, 60, 64, 66, 68, 71, 74, 83, 84, 85, 86, 100], "4500": 70, "45000000000000007": [60, 71, 74, 84], "450031": 68, "450152": 69, "450812e": 59, "450870601": 50, "451312e": 58, "452": 52, "452091": 71, "452114": 83, "452488701": 50, "452489": 69, "452623": 59, "453": 52, "453279": 58, "4535": 71, "4539": 52, "454081": 71, "454397": 74, "454406": 55, "45467447": 86, "455": 52, "45500": 71, "455078": 60, "455091": 59, "455107": 60, "455120": 74, "4552": 52, "455293": 60, "4552b8af": 52, "455448": 76, "455672": 71, "455981": 101, "456370": 69, "456458e": 58, "456552": 83, "4566031": 100, "45660310": 100, "4567": 76, "456892": 60, "457088": 74, "457667": 71, "458114": 71, "458307": 103, "458420": 71, "4584447": 50, "458784": 58, "458855": 51, "4592": 50, "459200": 69, "459383": 60, "459418": 59, "459436": 68, "45957837": 86, "4596": 86, "459760": 71, "459812": 60, "46": [55, 58, 59, 66, 67, 72, 83, 84, 85, 86, 100], "460": 71, "4601": 71, "460207": [58, 59], "460218": 60, "460289": 74, "460535": 83, "460744": 70, "461": 72, "4610": 115, "461227e": 58, "461629": 77, "461646": 55, "462321": 15, "462451": 60, "462567": 59, "462979": 58, "463325": 74, "4634": 71, "463418": 77, "463668": 71, "463766": 65, "463857": 71, "463903": 59, "463b": 52, "464": 85, "464076": 60, "464097": 72, "464284": 69, "46448227": 86, "464668": 13, "465": 55, "46507214": 76, "465424": 68, "465649": 77, "465730": 77, "4659651": 79, "465965114589023": 79, "4659651145890230": 79, "466047": 74, "46618738": 86, "466440": 60, "466756": 74, "467": 71, "46709481": 86, "46722576e": 86, "467613": 69, "467613401": 50, "467681": [58, 59], "467770": 60, "468072": 59, "468075": 74, "46807543": 74, "46811985": 74, "468120": 74, "468406": 71, "468907": 55, "468919": 71, "468d": 52, "469": 52, "469474": 77, "469825": 60, "469895": 59, "469905": 59, "46e": 86, "47": [51, 55, 58, 59, 61, 70, 76, 83, 84, 85, 86, 100, 114], "470055": 59, "470904": 58, "471": 55, "471435": 75, "471622": 58, "472": 71, "47222159": 78, "472255": 71, "472699": 59, "4727": 86, "472891": 74, "472e": 52, "473099": 60, "47319": 85, "47419634": 112, "474214": [64, 65], "474731": 83, "475304": 71, "475517": 68, "475569": 58, "4756464": 86, "4757738": 86, "475e": 75, "476856": 60, "477130": [58, 59], "477150": 74, "477247": 59, "477357": 75, "477474": 69, "47759584": 86, "47761563": 61, "478032": 71, "478059": 59, "478064": 59, "4781": 71, "47857478": 86, "479655": 68, "47966100e": 86, "479722": 59, "479860": 71, "479876": [64, 65], "479882": 59, "479928": 74, "47be": 52, "48": [52, 55, 58, 59, 65, 70, 71, 83, 84, 85, 86, 100], "480": [55, 115], "480133e": 74, "48029755": 76, "480579": 59, "48069071": [79, 87, 100], "480691": [87, 100], "480800e": 74, "481172": 74, "481218": 71, "481279": 86, "481399": [70, 71], "481705": 85, "481761e": 71, "482": [52, 55], "482012": 64, "482038": 60, "48208358": 74, "482084": 74, "482179": 58, "482461": [101, 106], "48246134": [101, 106], "482483": 74, "482616": 68, "482790": 62, "482898e": 59, "48296": 76, "483": [75, 85], "48315": 76, "483186": 62, "483192": [70, 71], "48331": 76, "4835": 71, "483711": 74, "483717": 60, "48390784": 85, "48404": 50, "48426988": 86, "484303": 59, "4845": 71, "484640": 74, "4849": 52, "485": [52, 71], "485197": 58, "48550": 77, "485617": [70, 71], "485812e": 71, "48583": [70, 71], "485871": 65, "486": [28, 71], "486178e": 58, "486202": 60, "486532": 74, "48661": 71, "487": [55, 71], "487467": 71, "487641e": 74, "487793": 59, "487872": 56, "4880104": 86, "488394": 58, "488460": 71, "488485": 71, "48873663": 61, "488811": 74, "488909": [70, 71], "488982e": 60, "4895498": 74, "489550": 74, "489699": 60, "489951": 59, "49": [52, 55, 58, 59, 70, 83, 84, 85, 86, 100], "490000e": 71, "490070931": 50, "490488e": 70, "490504e": 71, "490700": 74, "490941": 71, "491034": 58, "491245": 69, "49135": 18, "4915707": 85, "49157710": 86, "492": 71, "4923156": 79, "49231564722955": 79, "492315647229550": 79, "492417e": 85, "492656": 59, "49270769e": 86, "493": [75, 85, 113], "493102e": 68, "493144": 77, "493219": 74, "493313": 71, "493325": 8, "493426": 75, "494": 75, "494089": 59, "494129": 74, "494324": 69, "494324401": 50, "495": 73, "495108": 68, "49530782": 50, "495657": 60, "495752": 74, "49596416e": 86, "496": 73, "49650883": 76, "496551": 74, "496714": 77, "496777": 115, "49693": 84, "497": 73, "497168": 68, "497298": 83, "497422": 59, "497655": 9, "497674": 61, "49767983": 86, "497964": 83, "498": 73, "498286": 68, "498610": 72, "498730": 72, "498921": 74, "498979": 71, "498992": 58, "498f": 52, "499": [71, 73, 81, 112], "499000e": [70, 71], "499776": 71, "49d4": 52, "4a53": 52, "4b8f": 52, "4dba": 52, "4dd2": 52, "4e": [50, 51], "4ecd": 52, "4fee": 52, "4x": 74, "4x_0": [24, 58, 59, 64, 65], "4x_1": [24, 58, 59], "5": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 100, 101, 106, 111, 112, 114], "50": [17, 50, 52, 60, 62, 65, 67, 68, 70, 71, 72, 74, 83, 84, 85, 86, 100], "500": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 25, 26, 30, 39, 48, 52, 53, 57, 58, 59, 64, 65, 67, 70, 73, 75, 76, 80, 81, 83, 84, 85, 87, 100, 101, 106, 112, 115], "5000": [36, 58, 59, 60, 74], "50000": 69, "500000": [70, 71], "5000000000000001": [60, 71, 74], "500084": 74, "500267": 66, "5003517412": 50, "5005153": 86, "500517": 74, "50093148e": 86, "501021": 71, "501047e": 58, "501270": 72, "501390": 72, "501983": 74, "502016": 68, "502084": 85, "502205": 58, "502494": 60, "5025850": 50, "502595": 59, "502612": 74, "502901": 59, "502995": 74, "503": 35, "503374": 68, "503504": 84, "503511": 71, "503700": 55, "50398782e": 86, "504286": 69, "5042861": 50, "504548e": 59, "5050973": 50, "505264": 58, "505353": 59, "5055006": 86, "506050": 58, "50660517": 86, "506644": 58, "506659": 71, "506687": 71, "50672034": 50, "506900e": 74, "506903": 60, "507": 75, "50768b": 72, "508153": 73, "508433": 58, "508459": 69, "5085": 71, "508947": 85, "509059": 71, "509196": 74, "509461": 74, "50967": 77, "5097": 77, "5098": [53, 81, 112], "509853": 74, "5099": [52, 53, 81, 112], "509951": 60, "509958": 69, "51": [49, 51, 52, 64, 68, 83, 84, 85, 86, 100, 114, 115], "510000e": [70, 71], "510121": 58, "510385": 69, "5104859": 86, "510555": 55, "51079110": 50, "511022": 83, "511257": 68, "511391": 70, "511515": 71, "511540": 71, "5115547": 79, "5115547181877": 79, "51155471818770": 79, "511665": 58, "511668": 77, "5116683753999614": 77, "511862": 74, "512": 69, "512108": 74, "512149": 74, "51214922": 74, "51243406e": 86, "512519": 69, "512572": 74, "512672": [85, 101, 106], "5131": 70, "513624": 83, "513992": 74, "514": 52, "514173": 59, "514545": 71, "515031": 58, "515338e": 58, "515358": 60, "5154": 71, "5154789948092002": 69, "5155": 52, "515672": 59, "515950": 85, "516": 52, "516125": 60, "516222": 74, "516242": 59, "516255": 74, "516256": 74, "516528": 74, "516784": 72, "516797": 59, "516945": 55, "517": [52, 69], "5170": 86, "517279": 59, "5175": 71, "5176528": 86, "517753": 58, "518175": 69, "518375": 59, "518446": 71, "518478": 55, "518782": 71, "518846": 69, "51966955": 50, "519710": 74, "52": [49, 52, 66, 68, 75, 83, 84, 85, 86, 100], "520": 71, "520415": 58, "520641": 76, "520930": 60, "521002": 60, "521085": 83, "521233": 55, "5214051": 86, "521611": 59, "521632": 58, "521788": 58, "522753": 14, "522835": 62, "523030": 77, "523163": 60, "5232": 67, "52343523e": 86, "5234575": 86, "523794e": 74, "523807": 73, "523977545": 50, "52424539": 50, "524657": 74, "524934": [58, 59], "5250": 71, "525064": 55, "52510803": 51, "5251546891842586": 77, "5255": 52, "525722": 58, "52590": [51, 70], "526": 69, "526102": 85, "526532": 71, "526769": [58, 59], "526984": 59, "527226": 58, "52732": 84, "527452": 59, "527540": 58, "528381e": 78, "528580": 74, "5287429": 86, "528763": 59, "528937": [64, 65], "528996901": 50, "528997": 69, "529": 69, "529405": 49, "529782": 49, "53": [49, 52, 55, 81, 83, 84, 85, 86, 100, 110, 113], "5307877": 86, "530793": 58, "530940": 74, "53094017": 74, "531": 52, "531223": 60, "531594": 71, "53209683": 85, "532266": 60, "53257": 84, "532738": 74, "53273833": 74, "532751": 64, "5329": 71, "533": 75, "533489": 62, "533900": 74, "5346": 52, "535179": 74, "535318": 74, "535609": 71, "535718e": 71, "53606675": 74, "536067": 74, "536082": 55, "536143": 71, "536219": 55, "536746": 74, "536778e": 59, "536798e": [70, 71], "537240": 74, "53724023": 74, "53791422": 85, "538": 52, "538013": 71, "538105": 59, "5382": 76, "538292545": 86, "538937": [70, 71], "539455": 74, "539475": 74, "53947541": 74, "539491": [64, 65], "539767": 60, "54": [49, 51, 52, 61, 75, 80, 83, 84, 85, 86, 100, 114], "540240": 71, "540542": 70, "5408": 49, "541": 75, "541159": 74, "54163": 76, "5416844": 79, "541684435562712": 79, "541821": 71, "541990": 71, "542": 75, "542136": 58, "542159": 59, "542170": 59, "542333": 71, "542446": 65, "542451": 74, "542560": 77, "542584": 60, "5425843074324594": 60, "542647": 74, "542671": 69, "542816": 15, "542883": [101, 106], "5428834": [101, 106], "542919": 83, "542989": 74, "543": [69, 71], "543075": 60, "543136": 60, "543358": 83, "543380": 69, "5434231": 79, "543423145188043": 79, "5436005": 50, "543691": 59, "543764": 65, "54378": 76, "543832": 74, "543933": 72, "544097": 74, "544383": 77, "544555": 69, "544669": 64, "54483": [87, 100], "5448331": [87, 100], "54517706e": 86, "545492": 55, "54550506": 75, "545605e": 74, "545919": 71, "546266": 55, "546294": 71, "5467606094959261": 60, "546761": 60, "546953": 59, "547039": 58, "54716": 76, "547324": 59, "547431": 73, "5476": 71, "5479": 71, "547909": 71, "549109e": 71, "549645": 83, "54e": 86, "55": [51, 52, 60, 70, 71, 74, 83, 84, 85, 86, 100], "5500000000000002": [60, 71, 74], "550242": 68, "551317": 59, "551586928482123": 60, "551587": 60, "551686": 60, "55176": 84, "5518": 71, "552": 71, "552058": 76, "552508": 71, "552694e": 58, "552727": 69, "552776": 74, "553004": 55, "55307": 84, "553522": 59, "553878": [16, 83], "553916": 71, "554076": 60, "554793e": 86, "55498112": 86, "555": 69, "555137": 59, "555150": 71, "555445": 73, "555498": 74, "5555": [48, 57], "555536": 58, "555949e": 71, "555954": 71, "556191": [58, 59], "556792": 74, "557": 115, "5574dcd4": 52, "557595": 69, "557731": 73, "557999": 69, "558134": [58, 59], "5584": 69, "5585": 69, "55863386": 85, "558655": 60, "5589": 69, "559": 115, "5590": 69, "559144": 60, "559186": 60, "5592": 69, "559394": 74, "559522": 74, "559592e": 58, "559680": 71, "55dc37e31fb1": 52, "55e": 51, "56": [52, 80, 83, 84, 85, 86, 100, 110, 113], "560135": [87, 100], "56018481": 74, "560185": 74, "5602727": 61, "560530": 59, "560689": 49, "560723": 66, "561348": 59, "5616": 70, "561711": 71, "561785": 85, "562013": 74, "56223": 76, "562288": 77, "562452": 68, "562518": 71, "5625561": 49, "562712": [58, 59], "563067": 75, "563374e": 60, "563503": 74, "563528": 71, "563673": 71, "56387280e": 86, "56390147e": 86, "564045": 74, "564073": 71, "5641": 71, "564142": 60, "564232": [58, 59], "564451": 59, "564577": 71, "564647": 72, "565": 85, "565066": 60, "565373": 58, "566": 77, "566024": 74, "566091": 71, "566388": 58, "567004": 76, "567215": 68, "567343": 71, "567364": 59, "567529": 74, "567695": 58, "567945": [64, 65], "568111": 83, "569315e": 59, "569444": 55, "569540": 59, "569590": 68, "56965663": 74, "569657": 74, "569911": 50, "5699994715": 50, "57": [52, 75, 83, 84, 85, 86, 100, 115], "570038": 60, "5700384030890744": 60, "570111": 73, "5702": 71, "570486": 49, "570562": 49, "570722": 112, "570936": 58, "571707": 83, "571778": 49, "5718": 71, "572153": 83, "5722": 70, "572408e": 59, "57245066": 74, "572451": 74, "572991": 59, "573700": 62, "574": 52, "5748": 84, "57496671": 50, "575": 20, "575381": 70, "57572422": 76, "575810": 58, "57585824": 76, "57592948e": 86, "575952": 72, "57599221": 76, "575e": 75, "576": 52, "5763996": 50, "57643609": 76, "577": 52, "5770": 70, "57715074": 50, "577271": 69, "577273": 58, "577647": 55, "5776971": 76, "57775704": 76, "577807": [58, 59], "577813": 58, "577e": 75, "578081": 71, "578307": 74, "578523": 69, "578557": 59, "578846e": 60, "579125": 70, "57914935": 51, "579213": 77, "579238": 60, "579322e": 70, "579875e": 58, "57e": 51, "58": [21, 51, 70, 77, 83, 84, 85, 86, 100, 114], "5800": 71, "58000": 70, "5804": 52, "580414": 77, "580853": 58, "580922": 64, "581655": 71, "581827": 68, "581849": 59, "581896": 55, "582031": 70, "582146": 59, "58241568": 86, "582761": 60, "583034": 64, "583195": [58, 59], "583201": 59, "5833333": 52, "583534": 74, "583692": 68, "584012": 71, "584057e": 58, "584742": 65, "584849": 60, "584928": 58, "584942e": 69, "5852": 71, "585426": 86, "585793": 60, "586362": 74, "5864": 49, "5866": 71, "586719": 60, "586719493648897": 60, "586794": 58, "5868472": 50, "586921": 68, "587135": 59, "587292": 71, "588": 71, "588000": 83, "58812": 84, "588233": 58, "588364": 83, "588854": 58, "589147e": 68, "589248": 76, "589440": 60, "589958": 59, "59": [59, 83, 84, 85, 86, 100], "590320": 62, "5905": 70, "590736": 74, "590813": 74, "590904": 59, "590911": 60, "590991": 60, "591080": 62, "591411": 64, "591441": 6, "591652": 70, "591678": 70, "591782": 74, "59199423e": 86, "592186": 59, "592681e": 60, "59307502e": 86, "593648": 84, "593683": 72, "593981": 83, "594": 20, "594241": 83, "594316e": 74, "595353": 60, "596": [47, 71], "596069e": 71, "5962": 70, "596270": [64, 65], "5964": 67, "596460": 59, "596758": 58, "597": 51, "597098": 71, "59771072": 86, "597923": 71, "598178": 71, "59854797": 85, "5985730": 51, "59861": 71, "598761e": 59, "599208": 55, "599297": 85, "5cb31a99b9cc": 52, "5d": [60, 74], "5x_2": 62, "5x_3": 62, "5z_i": 74, "6": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 27, 28, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 83, 84, 85, 86, 87, 100, 101, 106, 110, 112, 113, 114], "60": [50, 60, 61, 71, 72, 74, 78, 83, 84, 85, 86, 100, 113], "600": 69, "6000": 71, "6000000000000002": [60, 71, 74], "600000e": 71, "600195": 58, "600254": 73, "600694": 85, "600776": 55, "600934": 83, "601": 51, "601061": 60, "601598": 69, "601783e": 59, "601984": 59, "602079": 65, "602168": 60, "602386e": 58, "602492": 58, "602587": 74, "602628": 60, "6029": 71, "604016": 71, "604111": 71, "604343": 70, "604603": 9, "604825": 71, "604841": [70, 71], "605": 71, "605195": 65, "606034": 74, "606129": 74, "606342": 60, "606759": 71, "6068": 50, "606800": 69, "606954": 60, "607264": 58, "6075": 115, "607600": 71, "607900e": 59, "608": [63, 75], "608392": 74, "60857": 49, "608818": 76, "609": 75, "609522": 68, "609575": 85, "61": [83, 84, 85, 86, 100, 114], "611": 115, "6110": 71, "611269": 69, "61170069": 75, "611859": 65, "612": 75, "612792": 71, "613244": 59, "6133": 51, "613314": 60, "613408": 74, "613498": 71, "613574": 66, "613622": 59, "613691": 85, "614": 75, "61404894": 85, "614188": 69, "614201": 55, "614678": 71, "615": 55, "615498": 6, "615863": [64, 65], "616617": 59, "61669761": [101, 106], "616698": [101, 106], "616828": 71, "617": 69, "61728": 83, "617283": 71, "6173": 52, "61771229": 75, "617877": 74, "618069": 70, "61810738": 51, "618574": 59, "618776": 61, "618881": 59, "619": 75, "619128": 59, "619351": [58, 59], "619390": [58, 59], "619454": 62, "619613": 70, "619903": 59, "61e": [51, 115], "62": [6, 65, 66, 72, 83, 84, 85, 86, 100], "620156": 74, "620874e": 85, "620995": 78, "621094": [70, 71], "621318": 74, "62131806": 74, "621490": 74, "6215": 70, "621902": 55, "622": [71, 75], "622153": 71, "622272": 55, "6224": 50, "622750": 55, "623024": 60, "623173": 58, "62377": 72, "624": 69, "6240": 76, "62403053": 61, "6243811": 50, "624535": 84, "624764": 59, "624798": 70, "624818": 59, "624919": 71, "624988": 71, "625": [50, 69], "625159": 66, "625183": 55, "625477": 74, "625766": 64, "625767": 58, "625891": [64, 65], "626433": 74, "6266": 71, "626633": 59, "627505": [64, 65], "627560": 74, "627564": 60, "627588e": 71, "628": 75, "628069": 69, "629346": 71, "629549": 59, "629595": 18, "6296844": 86, "629740": 58, "629e": 75, "63": [50, 69, 83, 84, 85, 86, 100, 113, 114], "630150e": 74, "630880": 75, "630914": 66, "631083": 59, "63117637": 85, "631333": 74, "6318": [70, 115], "632058": 69, "63245862e": 86, "632747e": 74, "632958": 73, "6330631": 100, "633433": 69, "634": 75, "63407762": 115, "634078": [70, 115], "634577": 100, "63499": 71, "635": 35, "635000e": [70, 71], "635199": [70, 71], "635768": 58, "63588711": 86, "63593298": 85, "636048": 85, "636453": 13, "636575": 60, "637326": 74, "637424619": 86, "6379": 70, "638": 47, "638264": 74, "638461": 68, "638488": 66, "639": 70, "639135": 69, "63916605": 51, "639345": 71, "639580": 59, "639603": 59, "64": [65, 70, 71, 75, 83, 84, 85, 86, 100, 112], "640": 71, "640334": 55, "64075242": 86, "640900": 71, "641528": 74, "641547": 74, "64154727": 74, "64197957": 74, "641980": 74, "642": 75, "6420": 71, "642016": 74, "642329": 55, "64269": 76, "642735": 70, "643133": 71, "64340": 76, "643512": 60, "643752": 74, "644113": 83, "644182": 83, "644371": 59, "644665": 60, "64476745e": 86, "644799": 62, "644985": 58, "645": 71, "64541329": 86, "645583": 55, "64579": 49, "6458": 50, "645800": 69, "646117": 59, "646937": 62, "647002": 71, "647004": 85, "647010": 71, "647196": 62, "64723": 76, "647254e": 58, "647689": 77, "647873": 74, "64797": 76, "648": 70, "648355": 58, "648690": 59, "648769": 59, "649": 113, "649158": 74, "649514": 58, "649738": 58, "65": [60, 66, 71, 74, 75, 83, 84, 85, 86, 100], "650": [63, 85], "6500000000000001": [60, 71, 74], "650000e": 71, "650234": 55, "650810": 71, "650867": 60, "651127": 59, "652071": 71, "6522": 113, "652312": 64, "652349": 74, "652350": 69, "652450e": [70, 71], "6527": 63, "652778": 69, "6528": 71, "6530": 71, "653820": 83, "653846": 60, "653901": [58, 59], "653991": 83, "654070e": 85, "654755": 62, "655284": 74, "6553": 115, "6554": 113, "655422": 71, "655547": 58, "65557405e": 86, "657": 52, "658": 69, "658267": 74, "658592": 59, "6586": 49, "658702": 59, "659": 52, "659245": [58, 59], "659339": 59, "659361": 55, "6593871": 49, "659423": [58, 59], "659473": 77, "659636": 60, "659735": 58, "659755": 75, "6598": 67, "659835": 59, "66": [55, 67, 72, 83, 84, 85, 86, 100, 112, 114], "660": [52, 85], "660073": 59, "660320": 65, "660479": 85, "6607402": 75, "660776": 74, "66080817": 86, "66133": 85, "661369": 73, "661388": 58, "6625": 71, "662975": 68, "663081975281988": 60, "663082": 60, "663182": 60, "6634357241067617": 77, "663529": 74, "663533": 71, "663765": 59, "663848392": 86, "664103e": 71, "664147": 71, "664276": [83, 84], "664409": 59, "664797": 58, "664824": 71, "664850": 69, "665264": 74, "66601815": 85, "666104": 74, "666307": 62, "6666667": 52, "667": 69, "667492e": 71, "667536": 74, "667614": 60, "667614205604159": 60, "667981": 58, "667985": 66, "668337": 71, "668452": 66, "668584": 62, "668981": 64, "669579": 59, "66989604": 61, "67": [47, 52, 70, 77, 83, 84, 85, 86, 100, 112], "670785": 55, "670867": [17, 83], "671": 72, "671224": 59, "671271": [58, 59], "67136": 71, "6716717587835648": 60, "671672": 60, "671690": 58, "6722": 52, "672234": [58, 59], "672368": 60, "6723684718264447": 60, "672384": [58, 59], "67245350": 50, "672511": 58, "673092": [58, 59], "673302": 69, "673330": 59, "67410934": 50, "6745349414": 50, "674552": 71, "67456": 77, "674609": 60, "674747": 68, "674949e": 76, "675233": 59, "675293": 73, "675625": 83, "675775": 68, "676405": 60, "6765": [51, 70], "676534": 100, "676641": 58, "676756": 74, "676807": 70, "677123": 58, "677614": 74, "677980": 60, "678": 75, "678117": 71, "678826": 60, "679": 47, "67936506": 85, "6795": 70, "679539": 69, "679789e": 58, "67ad635a": 52, "68": [52, 55, 72, 76, 83, 84, 85, 86, 100], "680": 71, "6810775": 76, "681176": 69, "681246": 59, "681448": 71, "681521": 58, "681562": 71, "681817dcfcda": 52, "682": 85, "682122": 68, "682269": 71, "68279187": 86, "682875": 60, "683487": 59, "683581": 85, "683687": 59, "683942": 74, "683984": 14, "684": 115, "68410364": 51, "68411700": [51, 115], "684128": 59, "684142": 58, "684502": 74, "685104": 8, "685107": 74, "68554404e": 86, "68562150e": 86, "685807": 74, "686270": 59, "686627": 58, "687345": 74, "687612": 59, "687647": 74, "687697": 55, "687854": 62, "687871": 69, "6878711": 50, "688": 113, "688641": 68, "688747": 71, "688887": 85, "688918": 71, "688956": 58, "689088": [58, 59], "689188": 62, "689392": 74, "689600": 68, "689932": 58, "69": [66, 83, 84, 85, 86, 100, 114], "690334": 60, "6903344145051182": 60, "691097": 58, "691136": 83, "691157": 61, "69140475e": 86, "691423": 58, "691511": 70, "691848e": 59, "691911": 83, "692": 115, "692297": 59, "692460": 68, "692579": 59, "692725": 74, "692907": 71, "692959": 58, "693316": 71, "693497e": 71, "693690": 71, "693796": 69, "694154": 60, "694561": 75, "694845e": 71, "694919": 69, "6950": 71, "695045": 58, "69508862": 85, "695581": 66, "69562150e": 86, "695711": 68, "695928": 58, "696011": [16, 83], "696224": 83, "696289": [64, 65], "696770": 83, "69684828": 85, "696966": 59, "697": 69, "697000": 60, "697390184": 86, "697420": [64, 65], "697545": 74, "697616": 59, "697693": 58, "698223": 62, "698244": 62, "698376": 72, "69840389e": 86, "698509": 58, "698651": 55, "698694": 69, "698751": 68, "699035": 74, "699082": 60, "69921": 52, "699259e": 74, "699333": 60, "699543": 55, "699616": 68, "699697": 59, "6_design_1a": 63, "6_r2d_0": 63, "6_r2y_0": 63, "6b": 100, "6cea": 52, "7": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 22, 23, 27, 30, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 100, 101, 106, 112, 113, 114], "70": [51, 60, 64, 70, 71, 74, 83, 84, 85, 86, 100, 114], "700": [58, 59, 63, 69], "7000000000000002": [60, 71, 74], "700015": 74, "700102": 74, "700458": 58, "701078": 74, "701088": 70, "701106": 66, "701265": 64, "701413": 71, "701672e": 60, "701841e": 65, "701866": 74, "7018663": 74, "701966": 71, "702489": 71, "703049": 58, "703772": 71, "703942": 83, "7040": 71, "704814": 58, "705090": 59, "705354": 58, "705581": 71, "7055958": 79, "705595810371231": 79, "7055958103712310": 79, "705794": 59, "70583": 76, "706056": 71, "706077": 59, "706122": 59, "706231": 83, "706430": 58, "706645": 60, "706657": 60, "706862": 9, "707125": 59, "707197": 83, "707441": 59, "707738": 59, "707868": 74, "707963e": 70, "708190": 69, "708235": 58, "708459": 74, "708472": 59, "708821": 55, "708837": 55, "709026": 62, "709596": 58, "709606": [17, 83], "71": [83, 84, 85, 86, 100, 114], "710059": 55, "710319": 59, "710515": 58, "710586e": 69, "711024": 71, "711328": 71, "711354773": 86, "711383e": 58, "711518": 71, "711638": 85, "712064": 58, "712082": 71, "712095": 55, "712157": 73, "712268": 58, "712372e": 59, "712503": 76, "712592": 70, "712774": 64, "712960": 60, "713": 71, "713407": 71, "713457": 58, "713986": 71, "713993": 59, "714189": 72, "714240": 69, "714250": 59, "714534e": 59, "714651": 74, "71465114": 74, "715013": 71, "715180e": 71, "7154": 71, "715407": 60, "7155": 71, "7158581": 50, "716013e": 58, "7161": 71, "716182529444849555657677273758486969799": 86, "716387": 58, "716427e": 59, "716456": 74, "716595e": 71, "716762": 60, "716793": 60, "716799": 69, "7167991": 50, "716801": 68, "717": 71, "717130": 71, "717185": 74, "717860": 83, "71825722": 86, "718686": 77, "719": [47, 72], "719552": 59, "72": [83, 84, 85, 86, 100, 114], "720559": 58, "720571": 74, "720573": 58, "720589": 75, "720664": 69, "721018": 58, "721071": 74, "721245": 59, "7215093d9089": 52, "72155839e": 86, "721609": 71, "722316": 74, "722634": 74, "722848": 60, "722881": 74, "7229": 71, "723": 52, "723314": 74, "723345e": 74, "723657": 58, "723846": 55, "7239": 71, "7241399": 50, "724338": 74, "724767": [64, 65], "724918": 77, "725": 52, "725061": 58, "725080": 55, "725087": 71, "725166": 74, "725565": 58, "725802": 9, "725820": 68, "725919": 58, "726": [52, 75], "726658": 68, "7268131": 50, "727159e": 59, "727543": 62, "727693": 71, "727704": 71, "727976": 60, "7282094": 85, "728294": 73, "728710": 74, "728734": 55, "72875815e": 86, "728852": 71, "728e": 75, "72956153": 86, "729867": 58, "73": [51, 55, 83, 84, 85, 86, 100], "730023": 71, "7308": 49, "730809": 58, "731174": 58, "731317": 60, "732": 75, "732067": 58, "732137": 58, "732150": 59, "732405": 70, "732586": 70, "7326": 71, "732638": 74, "73285": 13, "732918": 64, "733": 71, "733047": 59, "733644": 58, "734278": 55, "734635": 58, "734770": 59, "734948": 74, "735369e": 83, "7357": 71, "735848": 83, "735941": 12, "735964": 62, "736082": [58, 59], "736084": 74, "73608412": 74, "736823": 59, "737052": 71, "7375615": 51, "73764317e": 86, "737951": [58, 59], "738051": 72, "738065": 59, "738223": 71, "738315": 71, "738659e": 71, "738793": 83, "738876": 59, "739": 71, "739063": 58, "7395359436844482": 60, "739536": 60, "739595": 75, "739720": 71, "739817": 66, "74": [21, 51, 59, 70, 83, 84, 85, 86, 100, 114], "740": [69, 70], "740180e": 74, "740367": 58, "740417": 70, "740505": 55, "740785": 58, "740869": 60, "741104": 60, "741380": 75, "741523": 55, "741702": 74, "7418": 49, "74189": 52, "742128": 74, "742375": 58, "742407": 73, "742411": 58, "742907": 74, "7432": 49, "743247": 71, "743341": 59, "743609": 58, "7437": 71, "74402577": 74, "744026": 74, "744236": 76, "74461783e": 86, "745": 71, "745022": 55, "745444": 58, "745638": 70, "745881": 58, "746361": 74, "746843": 65, "7470": 71, "747646": 71, "747945": 50, "747961": 71, "748084": 59, "748377": 70, "748513": 71, "748880": 71, "74938952": 85, "749443": 71, "749854893": 87, "75": [17, 21, 23, 52, 55, 60, 62, 70, 71, 74, 83, 84, 85, 86, 100, 114], "75000": 77, "7500000000000002": [60, 71, 74], "750000e": 71, "750597": 59, "750701": 55, "751013": 71, "751261": 71, "751633": 71, "75171": 70, "751710": [60, 70], "751712655588833": 79, "7517126555888330": 79, "751712656": 79, "752015": 11, "752283": 71, "7533": 70, "753323": 58, "753393": 58, "753523": 74, "753866": 59, "754469": 58, "754499": 59, "754678": 68, "7548": 77, "754870": 69, "755688": 58, "755701e": 58, "755910": 71, "7559417564883749": 60, "755942": 60, "7560824": 50, "756200": 55, "756805": 69, "756867e": 71, "756905": 9, "756969": 60, "757": [75, 113], "757151": [58, 59], "757183": 60, "757411": 74, "757819": 69, "757917e": 74, "758391": 71, "758831": 59, "75887": 52, "759006": 61, "759054": 59, "759833": 59, "76": [83, 84, 85, 86, 100, 113, 114], "760104": 74, "7603": 49, "760386": 85, "760778": 69, "760915": 62, "761": [50, 69], "761429": 59, "761714": 60, "762284": 74, "76228406": 74, "762748": 71, "763691": 71, "763871": 72, "764093": [58, 59], "76419024e": 86, "764315": 74, "76444177e": 86, "764478": 73, "7646": 71, "764798": 74, "764953": 70, "765202": 71, "765363": [58, 59], "765500e": [70, 71], "765710e": 78, "765792": 74, "765864": 76, "76591188": 50, "765960": 58, "7660": 49, "7663": 71, "766499": 74, "766940": 55, "76702611e": 86, "767188": [64, 65], "767247": 83, "767349": 83, "767435": 77, "767549": 59, "767616": 55, "768071": 74, "768273": [64, 65], "768763": 59, "768798": 55, "769361": 74, "769805": 74, "77": [75, 83, 84, 85, 86, 100], "770556": 71, "770944": [64, 65], "7710": 76, "771157": 100, "771390e": 71, "7714": 72, "7716982": 51, "771741": 71, "771965": 71, "772104": 58, "77227783e": 86, "772396": 59, "772791": 71, "77289874e": 86, "773": 52, "773177": 60, "773488": 74, "77348822": 74, "773769": 68, "77401500e": 86, "774271e": 71, "775": [52, 71], "775191": [58, 59], "775285": 58, "7756353": 86, "775969": 76, "776254e": 58, "7763": 70, "776728e": 69, "776887": 70, "7776071": 50, "777718": 68, "777728": 83, "777e": 75, "778400": 58, "778468": 72, "7786": 49, "778852": 83, "779": 75, "779108": 58, "779167": 6, "779517": [58, 59], "779682": 60, "7799": 67, "779912": 71, "78": [75, 83, 84, 85, 86, 100, 114], "780": 52, "780068": 68, "780338": 58, "780458": 74, "780856": 70, "781": 71, "781233": 71, "781530": 74, "781681": 74, "782": 52, "782050": 74, "782117": 55, "782555": 71, "782646": 83, "783": 52, "783276": 85, "7833": 49, "7838": 49, "784": 100, "784238": 69, "784405": 76, "784483": 69, "784624": 60, "784792": 68, "785": 52, "785038": 59, "785153": 59, "785815": 55, "785911": 74, "785e": 35, "786": 52, "786090": 68, "786237": 58, "786563": 68, "786744": 60, "78711285e": 86, "78777": 76, "788": 113, "78818": 52, "788868": 59, "789032": 58, "789039": 59, "789330": 59, "789671": 60, "789671060840732": 60, "789691": 72, "79": [55, 83, 84, 85, 86, 114], "790039e": 58, "790115": 71, "790261": 83, "790723": [64, 65], "791097": 70, "791241": 74, "791297": [17, 83], "792939": 60, "793316": 83, "79338596e": 86, "793570": 74, "793598": 59, "793735": 74, "793818": [58, 59], "794": 85, "794366": 71, "79458848e": 86, "794805": 64, "795": 75, "795647": 74, "7957": 71, "795932": 84, "796014": 59, "796203": 85, "796384": 59, "796444": 71, "796596e": 58, "796e": 75, "797086": 58, "797157": 55, "797280": 74, "797737": 100, "797868": 59, "79792890e": 86, "797965": 100, "798071": 8, "798308": 70, "798783": [64, 65], "799403": 74, "7999": 78, "7b428990": 52, "7x": 74, "8": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 40, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 83, 84, 85, 86, 87, 100, 101, 106, 112, 114, 115], "80": [60, 61, 71, 74, 78, 83, 84, 85, 86, 114], "800": 69, "8000": [32, 78], "8000000000000002": [60, 71, 74], "800143": 58, "800160": 72, "800272": 83, "800326e": 58, "800351": 58, "80152351": 86, "801623": 71, "801903": 72, "802": 75, "802289": 71, "803112": 68, "803300": 58, "803492e": 74, "803563": 71, "803902e": 71, "804": 71, "804219": 74, "804284": 76, "804316": 74, "804484": 74, "8048": 51, "804828": 74, "804889": 71, "805007": 69, "805153e": [70, 71], "805293": 59, "8055563": 50, "805774": 58, "8059": 70, "806218e": 71, "806531": 71, "806554": 58, "80696592e": 86, "80714504e": 86, "807879": 74, "808": [51, 100], "808246": 70, "808284": 71, "808640": 71, "809125": 58, "8095": 72, "809913": [58, 59], "80a8": 52, "81": [50, 58, 63, 66, 67, 83, 84, 85, 86, 114], "810044": 70, "810134": 74, "8102": [49, 70], "810306": 55, "810322": 58, "810363": 71, "810382": [70, 71], "810419": 59, "810707": 71, "810895": 59, "811011": 59, "811155": 66, "811398": 83, "811513": 59, "8116912": 100, "811696": 58, "811825": 69, "811901": 74, "81190107": 74, "812": 75, "8132463": 50, "813293": 74, "813342": 100, "813682": 71, "814136": 60, "814246e": 59, "814351": 60, "814913": 69, "8152": 71, "815213e": 59, "815224": 100, "815226": 85, "81568484": 74, "815685": 74, "815993": 74, "816176": 77, "816318": 69, "816373": 58, "816645": 55, "816752": 71, "816982": 58, "817119": 58, "817291": 71, "8173602": 67, "817628": 85, "81827267": 74, "818273": 74, "818289": 74, "81828926": 74, "818313": 55, "818380": [58, 59], "81856": 52, "819507": 68, "82": [77, 83, 84, 85, 86, 114], "8202": 51, "820366": 69, "8209": 51, "820963": 55, "821": 113, "8210": 51, "821021": 60, "821457": 71, "821566": 74, "821855": 83, "821970": 68, "821995": 59, "822": 47, "8221": 49, "822289": [70, 115], "82228913": 115, "822482": 60, "8227": 71, "822822": 60, "823247": 74, "823273": [58, 59], "824350": [58, 59], "824657": 68, "824701": 60, "824750": 60, "824889": 60, "824961e": 71, "8250": 49, "825339": 72, "825587": 59, "825617": 69, "825801": 55, "825862": 74, "825980": 60, "8259803249536914": 60, "8260": 70, "826065": [58, 59], "826426": 85, "826467e": 58, "826492": 74, "826519": [17, 83], "82666866e": 86, "82684324": 76, "827375": 61, "827381": 74, "827445": 55, "827735": 74, "827938162750831": [64, 65], "828058": 71, "828157": 55, "828778e": 58, "828912": 58, "828915": [64, 65], "829162": 83, "829543": 60, "829730e": 59, "82985": 66, "83": [83, 84, 85, 86, 114], "830263": 68, "830301": 73, "830442": 58, "830467": 58, "830755e": 66, "831": 75, "831019": 60, "831190": 59, "831278": 58, "831741": 58, "832078": 55, "832086": 74, "8326928": 76, "832693": 76, "832875": 74, "83287529": 74, "833024": 69, "833227e": 84, "833464": 71, "833907": 69, "835": 75, "8350": 71, "835035": 68, "835596": 71, "835822": 55, "835935": 59, "836234": 85, "838114": 74, "838235": 72, "838457": 71, "83905": 8, "84": [52, 66, 75, 83, 84, 85, 86, 114], "840": 47, "840041": 71, "840303": 74, "84030318": 74, "840581044": 86, "840673": 58, "840718": 85, "840836": 74, "840995e": 70, "841": [50, 69], "841132": 70, "8415": 51, "841847": 71, "842132": 85, "842405": 60, "842589": 55, "842625": 69, "842746": 74, "8428": 70, "842853": 74, "843730": 69, "843796": 58, "8440": 71, "844107e": 59, "844308": 74, "844549": [64, 65], "844667": 100, "844707": 74, "844889": 69, "845241": 75, "845534": 68, "846388": 60, "847029": 59, "847555": 58, "847595": [16, 83], "847948": 60, "847962": 58, "847966": 71, "848688e": 68, "848757e": 70, "848868": 60, "849245": 55, "84930915e": 86, "849747": 76, "8497f641": 52, "8499": 71, "85": [26, 60, 66, 71, 74, 78, 83, 84, 85, 86], "850": 72, "8500000000000002": [60, 71, 74], "850038": 55, "850321": 69, "850439": 59, "850575": [58, 59], "850794": 74, "851": 113, "851198": 71, "8513": 52, "851366": 69, "852": 71, "85265193": 67, "85280376": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "85397773": 85, "855035": 58, "855780": 74, "855862": 59, "856404": 65, "8571": 49, "857161": 74, "857294": 55, "857544": 69, "857765": 71, "858": [47, 72], "858212e": 59, "859": 71, "85911521e": 86, "85912862": 100, "859129": [87, 100], "85974356": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "85c5": 52, "85e": 51, "86": [83, 84, 85, 86, 114], "860663": 100, "860804": 74, "860992": 71, "861519": 58, "862043": [64, 65], "862359": 60, "863772": 70, "863982270": 87, "864": 75, "86415573": 51, "86424193e": 86, "8644": 52, "864741e": 71, "865074": 55, "865313": 71, "865562": [58, 59], "865854": 71, "865860": [70, 71], "865914": 59, "866102": [58, 59], "866179899731091": 79, "866179900": 79, "866247151": 86, "866579": 71, "866798": 71, "867201": 68, "867565": 74, "8679": 71, "868": 52, "8685788": 74, "868579": 74, "8688": 70, "869": [52, 75], "869020": 60, "869195": 59, "869398": 59, "869477": 58, "869586": 66, "87": [51, 58, 66, 69, 83, 84, 85, 86, 114], "8700": 51, "870099": [64, 65], "870142": 85, "870260": 74, "870332": 74, "870857": 74, "871": 52, "871545e": 58, "871923": 59, "872": 75, "872132": 59, "872222": 71, "872727": 58, "872768": 74, "872852": 74, "87290240e": 86, "872994": 71, "873198": 71, "873677": [64, 65], "87384812361": 49, "87384812362": 49, "87430335": 100, "874303353": 100, "874702": [64, 65], "875": 47, "8750": 71, "8759": 71, "876": 75, "876083": 71, "87623301": 49, "876431e": 60, "876549": 71, "87674597e": 86, "8768": 49, "8771": 71, "877153": 71, "877455": 73, "877833": [58, 59], "878281": 74, "878289": 71, "878402": 58, "878746": 55, "878847e": 71, "878968e": 58, "879": 85, "879049": 71, "879058": 68, "879103": 60, "879509": 58, "87e": 51, "88": [51, 66, 75, 83, 85, 86], "880106": 69, "880579": 74, "880591": 73, "880808e": 71, "880880e": 71, "880886": 70, "8810": 70, "881201": 71, "88125046e": 86, "881465": 62, "881581": 12, "88173062": 50, "881937": 55, "882475": 60, "883485": 59, "883622": 74, "883914": 60, "883953": 68, "884132": 74, "8843": 76, "8845": 49, "884996": 60, "8850": 51, "885065": 74, "885832": 75, "885956": 58, "885978": [64, 65], "886041": 59, "886086": [58, 59], "886266": 71, "88629": 49, "886314": 59, "88664": 52, "887197": 55, "887345": 71, "887556": 60, "887648": 59, "887680": 58, "888146": 69, "8881461": 50, "888445": 59, "888775": 65, "888804": 71, "889293": 74, "889309": 70, "889326": 59, "889638": 55, "889733": 74, "889792": 59, "88988263e": 86, "889913": [58, 59], "889963": 74, "88ad": 52, "89": [51, 59, 83, 85, 86, 113, 114], "890": [50, 69], "890229": 55, "89027368": 100, "890273683": 100, "890318": 58, "89035917": 66, "890372": [53, 81, 112], "8903720000100010000010": [52, 81, 112], "8904": 47, "890454": 84, "8909": [50, 70, 115], "891453534": 86, "891606": 70, "891752": 59, "891997": 58, "892": 52, "892648": 74, "892796": [58, 59], "893": 52, "8932105": 50, "893649": [58, 59], "893851": 74, "894": 52, "894307e": 71, "894448": 59, "89449": 70, "894490": 70, "8946806718": 86, "895106": [58, 59], "895308": 71, "895333": 74, "895690": [58, 59], "895768e": 60, "896023": 74, "897220": 74, "897240": 71, "8974": 70, "897451": 58, "897495e": 59, "898722": 74, "899460": 74, "899662e": 58, "899716": 59, "8bdee1a1d83d": 52, "8da924c": 52, "8e3aa840": 52, "9": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 81, 83, 84, 85, 86, 87, 100, 101, 106, 111, 112, 114, 115], "90": [28, 51, 60, 61, 71, 74, 78, 83, 85, 86, 114], "900": 72, "9000000000000002": [60, 71, 74], "900000e": 71, "900021": 84, "901013": 59, "901148": 74, "90136": 70, "901360": 70, "901526": 66, "901683": 71, "901705": 58, "902": 100, "902573": 60, "903056e": 74, "903135": 83, "903339": 60, "903351e": 60, "903406": 85, "903418": 69, "903674": 58, "903681": 74, "903767": [58, 59], "904156": 60, "9041560442482157": 60, "904315": 58, "904396": 58, "905042": 59, "905494": 60, "905858": 77, "905951": 76, "906072": 83, "9061": 71, "906716732639898": [64, 65], "906757": 56, "907": 47, "907115": 74, "907176": 74, "9073": 71, "907491": 60, "907801": 69, "90794478": 100, "907944783": 100, "907961": 71, "908024": 77, "908663": 59, "908767": 68, "909304": [58, 59], "90963122e": 86, "909942e": 83, "909975": 71, "909997": [70, 115], "91": [83, 85, 86, 114], "910000e": 71, "9101117262730373942506568717476808193100": 86, "9102": 70, "910895": 59, "9109": 52, "91102953": 74, "911030": 74, "911277": 59, "911662": 64, "912230": [58, 59], "9126": [51, 115], "9127": [51, 115], "912903": 58, "913": 52, "91315015": 50, "913280": 77, "913371": 59, "913415e": 58, "913485": 71, "913774": 60, "9142": 71, "91438767e": 86, "9145": 49, "915": [51, 52, 70, 71], "915000e": [70, 71], "915057e": 70, "915260e": 58, "915488": [64, 65], "9158080176561963": 68, "916236": 49, "916528": 64, "9166667": 52, "916914": 74, "916930": 58, "917": 52, "917000": 59, "917066": 71, "917248": 74, "91724807": 74, "917436": 74, "918": 75, "918227": 60, "919432": 74, "9197": 71, "919969": 58, "91e": 51, "92": [83, 84, 85, 86, 114], "920052": 59, "920335": 71, "920337": 65, "920645": 71, "9209": 49, "921": 72, "9210": 71, "921061": 77, "921256e": 59, "921372": 60, "921913": 69, "921956": [58, 59], "921e4f0d": 52, "922": 86, "922160": 71, "922251": 58, "9223": 71, "922996": 69, "923074e": 60, "923517": 78, "923607": 74, "92369755": 50, "923804": 60, "923943": 115, "923977": 71, "924002": 74, "9243": 71, "924396": [64, 65], "92463": 70, "924630": 70, "924634": 62, "9248": 52, "924821": 60, "924843": 69, "924921": 83, "925": 61, "925248": [64, 65], "925660": 58, "925736": 60, "925957": 64, "925995": 59, "926227": 59, "926493": 70, "926621": 60, "926901": 68, "927": [48, 72], "927074": 74, "927232": 71, "9274": 71, "927950": 71, "92827999": 85, "92881435e": 86, "928947": 69, "929": 72, "92905": 50, "929643": 58, "92972925e": 100, "929729e": [87, 100], "93": [51, 83, 84, 85, 86, 114], "9304028": 50, "931": 80, "931479": 74, "931978": 112, "932027": 60, "932404e": 71, "9325": 49, "9327": 49, "932973": 74, "933259": 55, "933322": 59, "933671": 59, "933857": 59, "933996": 60, "934058": 58, "934068": 55, "934243": 59, "934433": [58, 59], "9345": 52, "934500": 59, "934511": 100, "934549": 71, "93458": 76, "934963": 59, "934992": 60, "935": [35, 67, 85], "935591": 74, "935730": 74, "935764": 59, "935989": 69, "9359891": 50, "93648": 78, "936494": 58, "936739": 74, "937116": 69, "937586": 71, "938": 100, "938975": [83, 84], "939068": [64, 65], "9392": 71, "939250": 58, "939458": 58, "9395": 71, "93958082416": 115, "94": [61, 67, 83, 85, 86, 114, 115], "940354721701296": 60, "940355": 60, "940373": 71, "940450": 55, "941440": 58, "941724": 71, "941788": 64, "942139": 65, "942249683": 86, "942312": 74, "942460e": 74, "942489": 71, "9425": 49, "942550": 71, "942661": 69, "942823": 71, "94309994e": 86, "943938": 74, "943949e": 74, "944149": 83, "944253e": 74, "944266": [64, 65], "944280": 71, "94441007e": 86, "944839": 55, "945881": 58, "94629": 78, "946297": 60, "946406": 65, "946433": 74, "946533": 58, "946658": 71, "946968": 60, "947440": 73, "947466": 84, "947613": 59, "9480": 71, "948112": 75, "948154e": 64, "948785e": 58, "948868": 71, "94906344": 50, "949241": 100, "949456": 74, "949866": 59, "95": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 39, 49, 51, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 70, 71, 74, 75, 76, 77, 78, 83, 85, 86, 100, 101, 106, 114, 115], "9500": 71, "950158": 58, "950545": 56, "95062986e": 86, "951502": 74, "951532": 69, "951920": 73, "952": [51, 75, 115], "9523": 49, "952839": 74, "9534": 71, "953683": 69, "953704": 58, "95372559e": 86, "954": 100, "95401167e": 86, "954536": 83, "955005e": 71, "9551": 71, "9552": 49, "955541": [17, 83], "95559917": 84, "955701": 58, "955e": 85, "956047": 50, "9561": 49, "956574": 71, "956724": 60, "9567242535070148": 60, "956877": 59, "956892": 71, "957012925": 86, "957229": 65, "957375": 69, "957745": 60, "9579": 51, "957996": 60, "958": 100, "9580": 51, "958105": 83, "958541": 71, "959132": 59, "959384": 59, "95e": 51, "96": [51, 58, 59, 72, 83, 85, 86, 114], "9605": 71, "960808": 60, "960834": 59, "9609": 49, "961539": 71, "961962": 60, "962364": 55, "962373": 59, "962523": 55, "962954": 59, "963055": 71, "963427e": 59, "964025e": 74, "964065e": 59, "964261e": 69, "964318": 71, "9647": 49, "965341": 59, "965531": 85, "965696": 58, "965774": 71, "96582": 84, "966015": 74, "966097": 18, "966320": 55, "966659": 60, "9666592590622916": 60, "967092": 59, "967467": 76, "968127": 55, "968134e": 74, "968258e": 58, "968577": 61, "969141": 85, "9699": 70, "969925e": 59, "97": [6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 53, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 83, 84, 85, 86, 87, 100, 112, 114, 115], "970065": 74, "970150": 59, "971058": [64, 65], "972509": 59, "972745": 58, "972748": 60, "97276281": 74, "972763": 74, "97314470": 50, "973156": 83, "973229": 59, "973241": 74, "973331": 71, "973741": 59, "973890": 59, "974202": 60, "974213": 59, "97441062": [64, 65], "974414": 60, "974487": 58, "97470872": 76, "9748910611": 50, "975": [47, 58, 59, 64, 65, 67, 72], "975289": 55, "9753": 52, "975447": 61, "975450": 59, "975461": 69, "975592": 55, "976088": 74, "976548e": 59, "976562": 74, "977202": 59, "977280": [58, 59], "977295": 71, "977507": 59, "977820": 58, "978303": 68, "9787": 71, "978977": 74, "978997": 55, "979": [72, 75], "979475": 58, "979702": 58, "979857": 58, "979971e": 58, "98": [58, 59, 71, 83, 85, 86, 114], "980026": 71, "9802393": 50, "980440": 59, "980643e": 60, "981104": 73, "981403": 59, "981438": 58, "981672": 60, "981715": 58, "982": 72, "982019e": 59, "982353e": 71, "982417": 60, "982720": 58, "982797": 73, "983192": 74, "983253": 58, "983759": 115, "98393441": 76, "984": 72, "984024": 73, "984083": [64, 65], "984551": 11, "984562": 74, "984866": 100, "984872": [58, 59], "984937": 60, "985": 72, "98505871e": 86, "985207": [58, 59], "985654": 59, "986383": 71, "986417": 58, "9870004": 52, "987220": 71, "987307": 68, "9875": 49, "987726": 59, "9880384": 52, "988421": [58, 59], "988463": 74, "988541": 58, "988709": 71, "988780": 71, "989758": 72, "99": [51, 55, 58, 59, 72, 83, 85, 86, 114], "990210": 71, "990622": 72, "990903": 58, "991": 52, "9914": [70, 71, 76], "991444e": 64, "9915": [51, 70, 71, 76], "991512": 51, "991963": [58, 59], "991977": 71, "991988": 58, "992": 75, "99232145": 76, "992582": [58, 59], "993": [47, 72], "993201": 59, "993575": 71, "994": 75, "994168239": 50, "994208": 55, "994214": 71, "994332": 56, "994377": 58, "9944": [67, 85], "994851": 71, "994937": 65, "995": 115, "995015": 71, "9951": 49, "995248": 74, "99549118e": 86, "99571372e": 86, "996": 72, "9961392": 50, "996313": 58, "996892": 68, "996934": 69, "997": 72, "9970": 71, "997034": 78, "997494": 78, "997571": 69, "997621": 60, "997934": [64, 65], "998063": 56, "99864670889": 115, "998766": 71, "9989": 70, "999": [61, 62, 66, 76, 115], "999207": 74, "9995": [58, 59, 62], "9996": [58, 59, 62], "9996553": 51, "9997": [58, 59, 62], "9998": [58, 59, 62], "9999": [58, 59, 62], "99c8": 52, "A": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 26, 27, 31, 35, 37, 38, 39, 41, 42, 47, 48, 49, 51, 52, 56, 57, 63, 65, 72, 73, 75, 76, 77, 80, 81, 83, 84, 85, 100, 101, 102, 103, 107, 108, 109, 110, 112, 113, 115], "ATE": [12, 18, 21, 51, 53, 55, 70, 76, 77, 83, 85, 87, 93, 101, 107], "ATEs": [55, 72], "And": [72, 78, 101, 104], "As": [48, 49, 50, 51, 52, 55, 57, 58, 59, 60, 61, 63, 66, 67, 68, 69, 70, 71, 72, 74, 77, 78, 79, 84, 85, 86, 87, 89, 100, 101, 103, 109, 115], "At": [21, 22, 23, 50, 55, 61, 62, 66, 67, 69, 71, 74, 115], "Being": 115, "But": 67, "By": [49, 50, 69, 75, 77, 84, 85, 101, 106], "For": [4, 8, 9, 11, 12, 15, 23, 33, 34, 42, 47, 49, 50, 52, 55, 56, 61, 66, 67, 68, 69, 71, 73, 75, 76, 77, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 107, 109, 111, 112, 115], "ITE": [27, 55], "ITEs": 55, "If": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 41, 42, 48, 50, 57, 58, 59, 61, 67, 69, 71, 75, 80, 81, 83, 84, 85, 87, 88, 90, 91, 93, 100, 101, 103, 104, 105, 106, 108, 109, 110, 115], "In": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 41, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], "It": [49, 50, 51, 58, 59, 63, 64, 65, 69, 70, 71, 75, 77, 84, 86, 110, 114], "No": [25, 47, 49, 51, 52, 53, 55, 61, 66, 70, 71, 75, 76, 78, 81, 84, 85, 87, 100, 112, 113], "Of": [67, 100, 115], "On": [48, 57, 68, 72, 80, 113], "One": [51, 70, 71, 77, 83, 100], "Or": 35, "Such": [77, 84], "That": [35, 115], "The": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 47, 48, 49, 50, 52, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 93, 96, 100, 101, 102, 103, 104, 105, 106, 107, 109, 110, 111, 113, 114, 115], "Then": [23, 60, 74, 85, 100, 101, 109, 110, 111], "There": [51, 70, 77, 85, 111, 115], "These": [51, 52, 54, 68, 70, 73, 75, 76, 83, 85, 115], "To": [34, 47, 48, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 64, 65, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 100, 101, 103, 106, 109, 111, 112, 115], "With": [26, 58, 59, 84, 113], "_": [48, 50, 57, 58, 59, 60, 62, 63, 64, 65, 69, 70, 71, 73, 74, 75, 79, 80, 83, 85, 86, 87, 100, 101, 103, 106], "_0": [48, 50, 57, 63, 69, 79, 80, 86, 87, 95, 96, 100, 101, 109], "_1": [21, 22, 23, 27, 72, 78, 87, 95, 96], "_2": [21, 22, 23, 27, 72], "_3": [21, 22, 23, 27], "_4": [21, 22, 23, 27], "_5": [21, 27], "__": [41, 42], "__init__": 68, "__version__": 111, "_all_coef": 86, "_all_s": 86, "_compute_scor": 34, "_compute_score_deriv": 34, "_coordinate_desc": 69, "_d": [75, 85], "_est_causal_pars_and_s": 114, "_estimator_typ": 68, "_h": [75, 85], "_i": [48, 57, 74, 78, 80], "_id": 86, "_j": [21, 22, 23, 27, 29, 50, 69, 100], "_l": 84, "_m": [84, 86], "_n": [87, 90, 91, 93, 100, 101, 106, 108], "_n_folds_per_clust": 69, "_rmse": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "_x": 36, "_y": [75, 85], "a0": 68, "a09a": 52, "a09b": 52, "a1": 68, "a3d9": 52, "a4a147": 72, "a5e6": 52, "a5e7": 52, "a6ba": 52, "a79359d2da46": 52, "a840": 52, "a_": 78, "a_0": 30, "a_1": 30, "a_j": 85, "ab": [49, 110], "ab71": 52, "abadi": [19, 61], "abb0fd28": 52, "abdt": [53, 81, 112], "abl": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 48, 57, 67, 71, 72, 84, 101, 103, 109], "about": [51, 67, 70, 85, 110, 112, 115], "abov": [48, 51, 55, 57, 58, 59, 64, 65, 67, 68, 70, 72, 73, 74, 75, 77, 80, 83, 84, 85, 111], "absolut": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 67, 84], "abstract": [34, 49, 50, 69, 87, 110, 114], "acc": [5, 49], "accept": [83, 84], "access": [37, 38, 49, 51, 64, 65, 66, 67, 76, 84, 101, 106, 115], "accord": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 48, 51, 55, 57, 60, 61, 70, 74, 75, 77, 78, 84, 85, 100, 101, 102, 104, 105, 107, 115], "accordingli": [61, 67, 68, 70, 75, 78], "account": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 50, 51, 69, 70, 71, 76, 77, 101, 106, 109, 115], "accumul": [51, 70, 71, 76], "accuraci": [41, 49, 85], "acemoglu": 113, "achiev": [50, 69, 73, 77, 85, 100], "acic_2024_post": 72, "acknowledg": [51, 52, 70], "acm": 113, "acov": 113, "across": [51, 70, 72, 115], "action": 114, "activ": [7, 10, 111, 114], "actual": [35, 66, 77], "acycl": [78, 115], "ad": [7, 10, 19, 20, 34, 41, 42, 66, 81, 84, 85, 100, 101, 103, 114], "adapt": [11, 70, 114], "add": [49, 50, 53, 55, 61, 62, 64, 65, 66, 72, 74, 75, 76, 77, 78, 84, 85, 113, 114], "add_trac": 77, "addit": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 23, 27, 29, 30, 31, 36, 39, 63, 77, 84, 85, 87, 94, 101, 102, 107, 109, 113, 114], "addition": [21, 22, 55, 60, 71, 76, 84, 85, 86, 100, 101, 106, 112], "address": 77, "adel": 113, "adj": [75, 77], "adj_coef_bench": 77, "adj_est": 77, "adj_vanderweelearah": 77, "adjust": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 40, 50, 62, 69, 71, 76, 77, 83, 85, 100, 101, 106, 113, 114, 115], "adopt": [61, 85], "advanc": [68, 82, 86, 113], "advantag": [48, 49, 51, 55, 57, 70, 71, 80, 111], "advers": [101, 103], "adversari": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 76, 101, 106, 109], "ae": [48, 50, 51], "ae56": 52, "ae89": 52, "aesthet": 48, "aeturrel": 31, "afd9e4": 72, "affect": [55, 63, 85, 114, 115], "after": [49, 51, 52, 61, 63, 70, 71, 77, 78, 83, 84, 101, 104, 106, 111, 115], "after_stat": 48, "ag": [51, 70, 71, 73, 76, 115], "again": [48, 49, 50, 51, 55, 57, 61, 66, 68, 69, 70, 75, 76, 77, 78, 80, 101, 104], "against": [61, 66, 67, 73, 84], "agebra": 83, "agegt54": [52, 53, 81, 112], "agelt35": [52, 53, 81, 112], "agg": 49, "aggreg": [49, 79, 86, 114], "aggregate_over_split": 35, "aggt": 49, "aim": 75, "aipw": 72, "aipw_est_1": 72, "aipw_est_2": 72, "aipw_obj_1": 72, "aipw_obj_2": 72, "air": [50, 69], "al": [19, 20, 24, 26, 29, 30, 48, 50, 51, 52, 57, 58, 59, 60, 61, 63, 64, 65, 67, 69, 70, 71, 74, 76, 80, 85, 86, 87, 89, 94, 99, 100, 101, 103, 109, 110, 112, 114], "alexandr": [63, 113], "algebra": 85, "algorithm": [47, 49, 50, 52, 55, 57, 60, 61, 67, 69, 71, 74, 76, 78, 82, 84, 85, 86, 87, 100, 114, 115], "alia": [41, 42], "align": [48, 50, 57, 60, 62, 67, 69, 70, 72, 73, 74, 78, 114], "all": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 41, 42, 43, 48, 49, 50, 51, 55, 57, 61, 66, 67, 68, 69, 70, 71, 73, 75, 77, 78, 80, 81, 83, 84, 85, 86, 100, 101, 109, 110, 111, 114], "all_coef": 86, "all_dml1_coef": 79, "all_s": 86, "all_smpl": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "all_smpls_clust": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "all_z_col": [50, 69], "allow": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 34, 41, 42, 51, 55, 70, 71, 75, 83, 84, 85, 86, 87, 100, 110, 114, 115], "almqvist": 113, "along": 84, "alpha": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 28, 30, 48, 50, 51, 53, 55, 57, 58, 59, 60, 63, 67, 68, 69, 70, 71, 74, 79, 80, 83, 84, 85, 86, 87, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109], "alpha_": [29, 50, 69, 84], "alpha_0": [101, 109], "alpha_ml_l": 63, "alpha_ml_m": 63, "alpha_x": [11, 25, 85], "alreadi": [23, 61, 78, 84, 85], "also": [4, 8, 9, 11, 12, 15, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 61, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 80, 83, 84, 85, 86, 87, 100, 101, 103, 111, 112, 114, 115], "alter": [50, 69], "altern": [49, 51, 52, 70, 73, 82, 84, 100, 110, 112], "although": 77, "alwai": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 42, 49, 75, 114], "always_tak": [11, 51, 70], "amamb": 69, "american": [28, 72], "amgrem": 69, "amhorn": 69, "amit": [77, 113], "amjavl": 69, "ammata": 69, "among": [51, 63, 70, 71, 76, 77], "amount": [51, 68, 70, 71, 115], "amp": [47, 50, 52, 61, 69, 71, 76, 78], "an": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 27, 37, 38, 41, 42, 48, 49, 50, 51, 52, 55, 57, 58, 59, 63, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 100, 101, 103, 106, 110, 112, 113, 114, 115], "analog": [33, 34, 50, 69, 71, 76, 83, 85, 87, 90, 91, 100, 101, 106], "analys": 115, "analysi": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 36, 48, 50, 51, 57, 69, 70, 71, 80, 82, 83, 103, 106, 109, 110, 114], "analyt": [72, 74], "analyz": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 51, 70, 71, 76, 115], "ancillari": 77, "andrea": 113, "angl": 51, "angrist": 72, "ani": [47, 48, 49, 52, 56, 57, 61, 77, 78, 80, 85, 111, 115], "anna": [8, 9, 21, 22, 23, 27, 49, 61, 85, 113], "annal": [100, 113], "anneal": 84, "annot": 48, "annual": 113, "anoth": [48, 49, 50, 51, 57, 67, 68, 69, 80, 84, 85], "anticip": 49, "anymor": [50, 69], "aos1161": 100, "aos1230": 100, "aos1671": 100, "ap": [51, 70], "ape_e401_uncond": 51, "ape_p401_uncond": 51, "api": [81, 110, 114], "apo": [4, 5, 88, 102], "apoorva": 114, "apoorva__l": 72, "apoorval": 72, "app": 114, "appeal": 77, "append": [57, 67, 80], "appendix": [26, 32, 76, 78, 101, 103], "appli": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 47, 48, 50, 51, 52, 57, 61, 62, 67, 69, 70, 71, 75, 77, 78, 80, 85, 86, 87, 100, 110, 112, 114, 115], "applic": [48, 57, 61, 72, 77, 80, 83, 86, 113, 115], "apply_along_axi": 73, "apply_cross_fit": [48, 86], "apply_crossfit": 114, "appreci": 110, "approach": [4, 6, 8, 9, 11, 12, 13, 16, 17, 18, 49, 50, 55, 69, 75, 76, 77, 82, 84, 86, 100, 101, 103, 111, 113, 115], "appropri": [51, 63, 70, 85, 86, 115], "approx": 83, "approxim": [48, 57, 58, 59, 60, 67, 74, 77, 80, 83, 85, 100, 114, 115], "apt": 111, "ar": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 48, 49, 50, 51, 52, 54, 55, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115], "arang": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 57, 60, 62, 71, 73, 74, 76, 77, 84], "arbitrarili": 42, "architectur": [87, 113], "arellano": 113, "arg": [68, 75, 83, 85], "argmin": 67, "argu": [48, 51, 57, 70, 71, 76, 80, 115], "argument": [4, 12, 15, 23, 29, 30, 31, 35, 36, 39, 51, 58, 59, 61, 66, 67, 70, 71, 79, 83, 84, 85, 114, 115], "aris": [48, 49, 50, 57, 69, 77, 80, 115], "aronow": 72, "around": [49, 51, 70, 71, 75, 85, 87], "arr": 73, "arrai": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 25, 26, 28, 29, 30, 31, 32, 39, 40, 41, 42, 55, 57, 58, 59, 60, 61, 67, 69, 72, 73, 76, 77, 78, 79, 80, 82, 83, 84, 86, 100, 101, 106, 112, 114, 115], "arrang": 50, "array_lik": 17, "articl": [31, 110], "arxiv": [29, 49, 50, 69, 77, 110, 113, 114], "as_learn": [52, 84], "asarrai": [58, 59], "aspect": [51, 70, 71], "assert": 84, "assess": 49, "asset": [71, 76, 115], "assign": [7, 10, 51, 65, 70, 75, 83, 84, 85, 115], "assmput": 85, "associ": [51, 63, 70, 85, 100, 113], "assum": [47, 50, 56, 61, 69, 72, 73, 77, 85, 87, 90, 91, 100, 101, 109, 115], "assumpt": [49, 50, 51, 61, 62, 67, 69, 70, 72, 75, 78, 85, 100, 115], "assur": 114, "astyp": [56, 75, 77], "asymptot": [33, 34, 48, 50, 57, 69, 80, 86, 100, 113], "ate": 55, "ate_estim": 78, "ates": 55, "athei": 113, "att": [12, 21, 49, 62, 66, 73, 77, 83, 85, 87, 93, 101, 107, 114], "att_gt": 49, "attach": 49, "atte_estim": 61, "attempt": [37, 38], "attenu": [51, 70], "attr": 51, "attribut": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 35, 39, 40, 41, 42, 67, 68, 79, 84, 86, 87, 100], "attributeerror": [37, 38], "attrict": 85, "attrit": [18, 78, 85], "au": [52, 84, 110, 112], "auc": 49, "author": [49, 77, 110], "auto_ml": 68, "autodoubleml": 68, "autom": 68, "automat": [48, 57, 66, 80, 83, 101, 106], "automl": 114, "automl_l": 68, "automl_l_lesstim": 68, "automl_m": 68, "automl_m_lesstim": 68, "automobil": [50, 69], "autos": 63, "autosklearn": 68, "auxiliari": [48, 57, 80], "avail": [25, 49, 51, 52, 55, 61, 63, 67, 70, 71, 72, 73, 75, 77, 80, 83, 84, 85, 101, 109, 110, 111, 114, 115], "avaiv": 40, "aver": 55, "averag": [4, 5, 11, 12, 15, 21, 22, 23, 47, 49, 52, 56, 61, 62, 66, 71, 72, 73, 75, 76, 77, 78, 82, 88, 93, 100, 102, 107, 113, 114, 115], "average_it": 55, "avoid": [48, 49, 57, 75, 85, 86, 111, 114], "awai": 76, "ax": [55, 57, 58, 59, 60, 62, 64, 65, 67, 68, 69, 70, 71, 72, 74, 75], "ax1": [55, 60, 71, 74], "ax2": [55, 60, 71, 74], "axhlin": [62, 68, 75], "axi": [50, 51, 55, 63, 67, 69, 70, 72, 73, 75], "axvlin": [55, 57], "b": [8, 9, 31, 48, 50, 52, 57, 58, 59, 69, 72, 74, 75, 77, 80, 83, 84, 100, 101, 109, 110, 112, 113], "b208": 52, "b371": 52, "b5d34a6f42b": 52, "b5d7": 52, "b_": 85, "b_0": 30, "b_1": 30, "b_j": 31, "bach": [77, 110, 113, 114], "backbon": 67, "backend": [7, 10, 49, 71, 76, 77, 82, 114], "backward": 114, "bad": 72, "balanc": [51, 70, 71], "band": [49, 82, 115], "bandwidth": [13, 16, 17, 35, 75, 85], "bar": [66, 68, 70, 83, 85, 87, 88, 93, 101, 102], "base": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 24, 27, 36, 40, 48, 49, 50, 51, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 100, 101, 103, 106, 110, 112, 113, 114, 115], "base_estim": [41, 42, 75], "baselin": [27, 51, 68, 70], "basi": [4, 12, 15, 39, 58, 59, 83], "basic": [49, 50, 51, 61, 69, 70, 71, 72, 75, 76, 77, 82, 84], "batch": 52, "battocchi": 113, "bay": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 100], "bb2913dc": 52, "bbotk": [52, 84, 114], "bbox_inch": 57, "bbox_to_anchor": 57, "bcallaway11": 49, "bd929a9e": 52, "bde4": 52, "becam": [51, 70, 71], "becaus": [42, 47, 48, 49, 50, 56, 57, 65, 66, 69, 72, 77, 80, 115], "becker": [52, 84], "becom": [50, 65, 68, 69, 83, 86], "bee": 62, "been": [50, 51, 68, 69, 70, 71, 76, 77, 83, 84, 114], "befor": [49, 51, 55, 62, 66, 70, 74, 77, 85, 115], "begin": [25, 28, 29, 48, 50, 51, 52, 57, 60, 62, 67, 69, 70, 72, 73, 74, 78, 79, 81, 84, 86, 100, 112, 115], "behav": 65, "behavior": [51, 72, 84], "behaviour": 65, "behind": 85, "being": [27, 32, 33, 34, 36, 41, 42, 50, 69, 75, 77, 85, 86, 87, 89, 100, 101, 106, 110], "belloni": [26, 63, 100, 113], "below": [47, 51, 56, 70, 72, 85, 111, 112], "bench_x1": 77, "bench_x2": 77, "benchmark": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 43, 55, 66, 103, 114], "benchmark_dict": [43, 76], "benchmark_inc": 76, "benchmark_pira": 76, "benchmark_result": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "benchmark_twoearn": 76, "benchmarking_set": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 55, 66, 76, 77, 101, 103], "benchmarking_vari": 66, "benefit": [48, 51, 57, 70, 80], "bernoulli": 25, "berri": [50, 69], "besid": 112, "best": [4, 12, 15, 39, 42, 58, 59, 64, 65, 68, 111], "best_loss": 68, "beta": [18, 25, 26, 28, 32, 51, 70, 73, 75, 78, 85], "beta_": 78, "beta_0": [24, 73, 78, 83], "beta_a": [21, 22, 77], "beta_j": [25, 26, 28, 32], "better": [49, 55, 67, 77], "between": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 47, 55, 56, 60, 62, 63, 68, 72, 74, 76, 77, 78, 85, 87, 90, 91, 93, 97, 98, 100, 101, 109, 112, 114], "betwen": [47, 56], "beyond": 113, "bia": [32, 47, 56, 63, 75, 77, 78, 82, 85, 86, 87, 95, 96, 101, 109, 113, 114], "bias": [47, 51, 56, 70, 71, 76, 115], "bias_bench": 77, "bibtex": 110, "big": [63, 79, 86, 87, 91, 94, 100, 101, 104, 105, 107, 108, 109], "bigg": [50, 69, 87, 92, 93, 101, 107], "bilia": 20, "bin": [48, 55, 57, 111], "binari": [4, 6, 8, 9, 11, 12, 13, 15, 16, 18, 24, 36, 47, 49, 51, 52, 56, 61, 66, 67, 70, 72, 73, 77, 83, 84, 101, 102, 107, 114, 115], "binary_outcom": 36, "binary_treat": [24, 58, 64, 66], "bind": 114, "binder": [52, 84, 110, 112, 114], "binomi": [56, 72, 73, 74], "bischl": [52, 84, 110, 112], "black": [48, 52, 53, 81, 112], "blob": 49, "blog": 31, "blondel": [110, 112], "blp": [39, 50, 69], "blp_data": [50, 69], "blp_model": [64, 65], "blue": [48, 50, 69], "bodori": 113, "bond": [51, 70, 71], "bonferroni": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 100], "bonu": [20, 52, 81, 112], "book": [52, 77, 84], "bool": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 24, 27, 35, 36, 37, 38, 39, 41, 42, 66, 75], "boolean": [32, 64, 65, 81, 86], "boost": [47, 51, 56, 61, 67, 70], "boost_class": [51, 70], "boost_summari": 70, "boostrap": [60, 114], "bootstrap": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 39, 55, 58, 59, 60, 64, 65, 71, 74, 82, 83, 86, 87, 110, 112, 114, 115], "both": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 22, 24, 49, 51, 52, 61, 62, 67, 68, 70, 71, 73, 75, 76, 77, 81, 84, 85, 100, 101, 103, 106, 108, 109, 114, 115], "bottom": [50, 51, 67, 69, 70, 71], "bound": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 27, 51, 55, 66, 70, 76, 77, 101, 103, 106, 109, 115], "branch": 52, "brantli": 49, "break": [48, 114], "breviti": 115, "brew": 111, "brewer": 50, "bridg": 77, "brief": 80, "bring": [47, 56], "brucher": [110, 112], "bsd": 114, "budget": [68, 84], "bug": [110, 114], "build": [50, 67, 69, 73], "build_design_matric": [58, 59], "build_sim_dataset": 49, "built": [40, 68, 84, 110], "bureau": [77, 86, 113], "busi": [29, 32, 50, 69, 77, 113], "b\u00fchlmann": 113, "c": [19, 20, 22, 23, 26, 28, 30, 47, 48, 49, 50, 51, 52, 53, 56, 57, 62, 63, 64, 65, 69, 70, 72, 75, 80, 81, 84, 85, 110, 111, 112, 113, 115], "c1": [19, 20, 30, 50, 63, 69, 80, 110, 113], "c68": [19, 20, 30, 50, 63, 69, 80, 110, 113], "c895": 52, "c_": 100, "c_d": [26, 101, 107, 108, 109], "c_y": [26, 101, 109], "ca1af7be64b2": 52, "caac5a95": 52, "calcualt": 73, "calcul": [4, 12, 15, 49, 51, 55, 58, 59, 60, 64, 65, 67, 68, 70, 74, 76, 101, 106, 109], "calibr": [67, 68, 77], "call": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 41, 42, 47, 49, 50, 51, 52, 56, 58, 59, 60, 61, 64, 65, 69, 70, 71, 73, 74, 75, 76, 77, 78, 81, 84, 86, 87, 100, 101, 106, 109, 112, 114, 115], "callabl": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 48, 57, 58, 59, 67, 82, 84, 110], "callawai": 49, "camera": 63, "cameron": [50, 69], "can": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 24, 35, 40, 42, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 90, 91, 93, 97, 98, 100, 101, 102, 103, 106, 107, 108, 109, 110, 111, 112, 114, 115], "candid": 77, "cannot": [67, 75, 77, 85, 115], "capabl": [7, 10, 47, 56], "capo": 4, "capsiz": [55, 68, 72, 75], "capthick": [55, 75], "cardin": [50, 69], "care": 84, "carlo": [21, 22, 24, 27, 58, 59, 64, 65, 77, 113], "casalicchio": [52, 84, 110, 112], "case": [4, 7, 10, 11, 12, 20, 24, 35, 47, 50, 51, 56, 58, 59, 60, 63, 65, 66, 68, 69, 73, 74, 75, 76, 77, 81, 83, 84, 85, 86, 87, 100, 101, 106, 112, 114, 115], "cat": [48, 114], "catboost": 67, "cate": [12, 15, 39, 82, 114], "cate_obj": 83, "cattaneo": [85, 113], "caus": [48, 57, 75, 80], "causal": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 25, 26, 28, 29, 30, 31, 32, 35, 47, 48, 50, 51, 52, 56, 57, 69, 70, 72, 76, 78, 79, 80, 81, 82, 85, 86, 100, 101, 106, 113], "causal_contrast": [5, 55, 85], "causal_contrast_model": [55, 85], "causaldml": 113, "causalweight": 113, "caution": 100, "caveat": [65, 77], "cbind": 50, "cc": 70, "ccp_alpha": [12, 40, 70], "cd": 111, "cd_fast": 69, "cda85647": 52, "cdf": 83, "cdid": [50, 69], "cdot": [21, 22, 23, 27, 36, 50, 60, 62, 66, 69, 72, 74, 75, 77, 83, 85, 87, 88, 93, 94, 95, 96, 100, 101, 102], "cdot1": 66, "cell": 68, "center": 63, "central": [86, 114], "certain": [65, 85], "cexcol": 50, "cexrow": 50, "cf_d": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 43, 55, 66, 76, 77, 101, 102, 103, 106, 107, 108, 109, 115], "cf_y": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 43, 55, 66, 76, 77, 101, 102, 103, 106, 107, 108, 109, 115], "chad": 77, "chain": 65, "chainedassignmenterror": 65, "challeng": [50, 69, 101, 103], "chang": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 41, 42, 51, 61, 65, 71, 76, 77, 78, 85, 87, 93, 100, 101, 102, 103, 104, 105, 106, 107, 111, 113, 114], "channel": 115, "chapter": [33, 34, 52, 84, 101, 109], "charact": [51, 52, 84, 114], "characterist": [76, 115], "chart": 68, "check": [37, 38, 41, 42, 48, 51, 57, 67, 68, 70, 71, 79, 80, 110, 111, 114], "check_data": 114, "check_scor": 114, "checkmat": 114, "chernozhukov": [19, 20, 26, 28, 30, 48, 50, 51, 57, 63, 67, 69, 70, 71, 76, 80, 86, 100, 101, 103, 109, 110, 113, 114], "chetverikov": [19, 20, 30, 50, 63, 69, 80, 100, 110, 113], "chiang": [29, 50, 69, 113], "chieh": 113, "choic": [4, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 51, 63, 70, 73, 83, 84, 101, 103, 106, 109, 114], "choos": [47, 51, 56, 57, 63, 67, 70, 71, 79, 86, 87, 90, 91, 93, 97, 98, 100, 112, 115], "chosen": [4, 22, 27, 67, 84, 85], "chou": 72, "chr": 51, "christian": [63, 113], "christoph": 113, "chunk": 84, "ci": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 35, 55, 58, 59, 60, 61, 62, 64, 65, 66, 68, 70, 71, 74, 75, 76, 77, 83, 85, 101, 106, 114, 115], "ci_at": 55, "ci_cvar": [60, 71], "ci_cvar_0": 60, "ci_cvar_1": 60, "ci_joint": 55, "ci_joint_cvar": 60, "ci_joint_lqt": 74, "ci_joint_qt": 74, "ci_length": 61, "ci_low": 55, "ci_lpq_0": 74, "ci_lpq_1": 74, "ci_lqt": [71, 74], "ci_pointwis": 55, "ci_pq_0": [71, 74], "ci_pq_1": [71, 74], "ci_qt": [71, 74], "ci_upp": 55, "cinelli": [77, 101, 103, 113], "circumv": 115, "citat": 114, "claim": 52, "clash": 49, "class": [0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 33, 34, 35, 37, 38, 39, 40, 41, 42, 51, 52, 53, 55, 61, 66, 68, 70, 71, 76, 78, 79, 81, 83, 84, 86, 87, 100, 110, 112, 114], "class_estim": 75, "class_learn": 71, "class_learner_1": 67, "class_learner_2": 67, "classes_": 68, "classic": [49, 50, 69, 115], "classif": [12, 41, 47, 49, 51, 52, 67, 68, 73, 76, 83, 84, 85, 115], "classifavg": 52, "classifi": [4, 6, 8, 9, 11, 12, 13, 15, 16, 17, 18, 35, 37, 41, 52, 55, 68, 75, 84, 114], "classmethod": [7, 10], "claudia": [113, 114], "claus": 114, "clean": 114, "cleaner": 67, "cleanup": 114, "clear": [50, 69], "clearli": 75, "clever": 67, "clone": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 47, 48, 52, 57, 67, 69, 71, 79, 84, 85, 86, 87, 100, 101, 106, 111, 112], "close": [49, 51, 70, 77, 101, 103], "cluster": [4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 29, 113, 114], "cluster_col": [7, 50, 69], "cluster_var": [7, 29], "cluster_var_i": [7, 50, 69], "cluster_var_j": [7, 50, 69], "cmap": 69, "cmd": 114, "co": [31, 62], "codaci": 114, "code": [4, 12, 15, 31, 47, 49, 50, 51, 52, 56, 63, 70, 80, 83, 84, 85, 86, 87, 100, 111, 112, 114, 115], "codecov": 114, "coef": [6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 87, 100, 112, 115], "coef_": 77, "coef_df": 50, "coef_valu": 68, "coeffici": [21, 22, 24, 39, 42, 51, 64, 65, 67, 70, 72, 73, 75, 77, 78, 83, 100, 101, 106, 115], "coefs_t": 73, "coefs_w": 73, "coffici": [101, 106], "cofid": 39, "coincid": [62, 71], "col": [48, 50, 65, 70], "collect": [52, 61, 69, 78], "colnam": [50, 67], "color": [51, 55, 57, 58, 59, 60, 62, 68, 69, 70, 71, 72, 74, 75, 77], "color_palett": [55, 57, 69, 70, 71], "colorbar": 69, "colorblind": 55, "colorramppalett": 50, "colorscal": [58, 59], "colour": [48, 50], "column": [7, 10, 53, 55, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 78, 81, 83, 84, 85, 86, 112, 114, 115], "column_stack": [55, 62, 64, 65, 75, 76, 77, 85], "colv": 50, "com": [31, 49, 51, 52, 63, 72, 77, 84, 111], "comb": 63, "combin": [49, 50, 52, 55, 61, 67, 68, 69, 77, 84, 86, 101, 106, 114], "combind": 71, "combined_loss": 63, "come": [79, 84, 87, 101, 103, 110, 115], "command": [111, 114], "comment": 81, "common": [67, 76, 77, 83, 85, 113], "companion": 113, "compar": [48, 50, 57, 58, 59, 60, 62, 64, 65, 69, 72, 74, 75, 77, 80, 84, 85, 101, 103], "comparevers": 51, "comparison": [55, 67, 72], "compat": [47, 49, 56, 114], "complement": 77, "complet": [68, 80, 101, 106, 111], "complex": [12, 49, 68], "compli": [75, 85], "complianc": [74, 75, 85, 87, 94], "complic": [52, 115], "complier": [51, 70, 71, 74, 75, 83, 85], "compon": [41, 42, 49, 51, 63, 67, 68, 70, 73, 83, 84, 86, 87, 88, 90, 91, 92, 93, 94, 97, 98, 114], "compont": 49, "composit": 113, "compris": 100, "comput": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 39, 43, 48, 49, 51, 52, 57, 70, 71, 76, 77, 86, 87, 101, 102, 103, 104, 105, 106, 107, 110, 113, 114, 115], "computation": [101, 103], "concat": [68, 69, 70, 73, 100], "concaten": [62, 70, 100], "concentr": 100, "concern": 77, "conclud": [75, 77, 115], "cond": 85, "conda": [69, 113, 114], "condit": [4, 6, 12, 15, 21, 22, 24, 33, 34, 48, 50, 51, 55, 57, 61, 62, 66, 69, 70, 73, 75, 77, 78, 80, 82, 85, 100, 101, 102, 107, 109, 112, 113, 114, 115], "conduct": [83, 85, 115], "conf": [49, 74], "confer": 113, "confid": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 39, 49, 50, 51, 55, 58, 59, 60, 61, 64, 65, 69, 71, 74, 75, 76, 78, 82, 83, 86, 87, 101, 106, 112, 113, 115], "confidenceband": 60, "confidenti": 77, "config": 72, "configur": [52, 68], "confint": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 39, 51, 55, 58, 59, 60, 61, 62, 64, 65, 67, 71, 73, 74, 75, 76, 78, 83, 86, 100, 110, 112, 115], "conflict": 111, "confound": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 24, 43, 47, 51, 56, 66, 70, 74, 76, 77, 81, 85, 100, 101, 103, 106, 108, 109, 112, 113, 114, 115], "congress": 113, "connect": [51, 70, 71], "consequ": [21, 22, 50, 66, 69, 76, 83, 85, 101, 102, 103, 107, 109], "conserv": [76, 77, 101, 109], "consid": [6, 11, 12, 13, 16, 36, 48, 50, 51, 57, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 87, 100, 101, 103, 110, 115], "consider": [77, 85], "consist": [14, 15, 42, 51, 61, 68, 70, 71, 72, 77, 80, 81, 85, 112, 114], "consol": [48, 114], "constant": [26, 42, 63, 73, 83, 85, 100], "constrained_layout": 57, "construct": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 39, 52, 58, 59, 60, 62, 71, 76, 79, 83, 87, 89, 96, 100, 114, 115], "construct_framework": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "construct_iv": 69, "constructiv": 50, "constructor": 52, "consum": [50, 69], "cont": 27, "cont_d": 55, "contain": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 27, 36, 37, 38, 41, 42, 48, 50, 51, 55, 57, 58, 59, 64, 65, 67, 69, 70, 80, 83, 84, 100, 101, 103, 106, 114], "context": [77, 85, 115], "contin": [27, 68], "continu": [27, 47, 52, 55, 56, 63, 72, 75, 85, 101, 109, 114, 115], "contour": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 63, 66, 76, 77, 101, 106], "contour_plot": 77, "contours_z": [58, 59], "contrast": [5, 60, 61, 85], "contribut": [111, 114], "contributor": 114, "control": [28, 36, 49, 63, 71, 73, 75, 77, 115], "convent": [35, 51, 70, 71, 75, 85], "converg": [48, 57, 67, 69, 80], "convergencewarn": 69, "convers": 69, "convert": [60, 69, 74], "convex": 72, "cooper": 114, "coor": [52, 84, 110, 112], "coordin": 77, "copi": [65, 68, 70, 73, 77], "cor": [101, 109], "core": [53, 55, 60, 61, 66, 69, 70, 71, 74, 76, 78, 81, 84, 112, 114], "cores_us": [60, 71, 74], "correct": [66, 77, 83, 100, 114], "correctli": [41, 61, 72, 76, 101, 109], "correl": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 50, 63, 69, 76, 78, 85, 101, 103, 109], "correpond": 85, "correspond": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 27, 33, 34, 48, 50, 51, 52, 55, 57, 58, 59, 61, 62, 63, 67, 69, 70, 71, 73, 74, 76, 77, 80, 83, 84, 85, 86, 100, 101, 103, 106, 107, 109, 114, 115], "cosh": 31, "coul": 50, "could": [47, 52, 56, 58, 59, 68, 77, 114, 115], "counfound": [21, 22, 74, 76, 83, 101, 109], "count": [55, 70, 71], "countour": [101, 106], "coupl": [51, 70, 71], "cournapeau": [110, 112], "cours": [51, 67, 70, 77, 100, 115], "cov": [18, 21, 36, 75], "cov_nam": [75, 85], "cov_typ": [4, 12, 15, 39, 114], "covari": [7, 8, 9, 10, 12, 14, 15, 21, 22, 24, 25, 26, 28, 29, 30, 31, 32, 35, 36, 39, 40, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 76, 77, 78, 80, 81, 83, 84, 85, 87, 90, 91, 100, 101, 103, 112, 113, 114], "cover": [49, 63, 76], "coverag": [67, 75, 83, 114], "cp": [51, 52, 84], "cpu": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "cpu_count": [60, 71, 74], "cran": [52, 113, 114], "creat": [24, 47, 50, 52, 55, 56, 57, 58, 59, 60, 64, 65, 69, 71, 73, 74, 77, 84, 101, 103, 106, 109, 111, 114], "create_synthetic_group_data": 73, "critic": [77, 115], "cross": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 23, 47, 48, 49, 51, 52, 57, 67, 68, 70, 71, 75, 77, 80, 82, 84, 90, 91, 96, 100, 104, 106, 114, 115], "cross_sectional_data": [9, 23, 61, 85], "crossfit": [67, 85], "crosstab": 72, "crucial": [63, 85, 115], "csail": [110, 112], "csv": 63, "cumul": 85, "current": [40, 49, 65, 87, 101, 109, 110, 111, 115], "custom": [48, 49, 57, 77, 84], "custom_measur": 49, "cut": 73, "cutoff": [35, 36, 75, 85], "cv": [52, 70, 84, 86], "cv_glmnet": [50, 51, 52, 84, 100, 112], "cvar": [6, 17, 82, 89, 114], "cvar_0": 60, "cvar_1": 60, "d": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 39, 40, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 115], "d0": [60, 74, 100], "d0_true": 74, "d0cdb0ea4795": 52, "d1": [60, 72, 74, 100], "d10": 100, "d1_true": 74, "d2": [72, 100], "d21ee5775b5f": 52, "d3": 100, "d4": 100, "d5": 100, "d5a0c70f1d98": 52, "d6": 100, "d7": 100, "d8": 100, "d9": 100, "d_": [27, 29, 50, 55, 62, 69, 85, 100], "d_0": 85, "d_1": [72, 100], "d_2": 72, "d_col": [7, 10, 47, 48, 50, 51, 52, 56, 58, 59, 64, 65, 69, 70, 71, 73, 75, 76, 79, 80, 81, 84, 85, 86, 87, 112, 114, 115], "d_i": [24, 25, 26, 28, 30, 31, 32, 48, 55, 57, 60, 61, 72, 74, 75, 78, 80, 85], "d_j": [55, 85, 100], "d_k": [85, 100], "d_l": 85, "d_w": 73, "da1440": 72, "dag": [77, 78, 115], "dark": [48, 57], "darkblu": 50, "darkr": 50, "dash": 55, "dat": 81, "data": [0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 39, 41, 42, 49, 62, 63, 67, 72, 79, 82, 83, 84, 86, 100, 105, 106, 113, 114], "data_apo": 55, "data_cvar": 71, "data_dict": [35, 58, 59, 64, 65, 66, 75, 85], "data_dml": 76, "data_dml_bas": [51, 58, 59, 64, 65, 70, 71, 73], "data_dml_base_iv": [51, 70, 71], "data_dml_flex": [51, 70], "data_dml_flex_iv": 51, "data_dml_iv_flex": 70, "data_dml_new": 73, "data_fram": 115, "data_lqt": 71, "data_pq": 71, "data_qt": 71, "data_transf": [50, 69, 70], "datafram": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 25, 26, 28, 29, 30, 31, 32, 35, 39, 40, 50, 53, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 87, 100, 101, 103, 106, 112, 115], "dataset": [0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 35, 48, 49, 55, 57, 58, 59, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 100, 101, 106, 112, 115], "datatyp": 114, "db": [51, 70, 71, 76, 115], "dbl": [49, 50, 51, 52, 81, 100, 112, 115], "dc13a11076b3": 52, "ddc9": 52, "de": [47, 56, 113], "deal": [47, 56], "debias": [19, 20, 29, 30, 50, 63, 69, 82, 84, 86, 110, 113, 114], "debt": [51, 70, 71], "decai": 78, "decid": [51, 70], "decis": [12, 47, 51, 56, 70, 71, 83, 85, 113, 115], "decision_effect": 47, "decision_impact": [47, 56], "decisiontreeclassifi": [12, 40, 70], "decisiontreeregressor": 70, "declar": 115, "decreas": 75, "deep": [37, 38, 41, 42, 68], "deeper": 12, "def": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 57, 60, 67, 68, 69, 72, 73, 74, 77, 84, 87], "default": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 27, 29, 30, 31, 35, 36, 37, 38, 39, 40, 41, 42, 49, 50, 61, 64, 65, 67, 69, 73, 75, 76, 77, 78, 79, 83, 84, 85, 86, 100, 101, 102, 106, 112, 115], "default_convert": 69, "defier": [75, 85], "defin": [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 42, 48, 51, 52, 55, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 70, 71, 73, 74, 75, 76, 77, 83, 84, 85, 87, 90, 91, 101, 103, 106, 109], "definit": [31, 64, 65, 101, 102, 107], "defint": 101, "degre": [36, 51, 58, 59, 69, 70, 75, 83, 101, 103], "dekel": 113, "delete_origin": 52, "deliber": 72, "delta": [28, 49, 61, 77, 85], "delta_bench": 77, "delta_i": 49, "delta_j": 28, "delta_theta": [43, 55, 66, 76, 77, 101, 103], "delta_v": 77, "demand": [50, 69, 101, 103], "demir": [19, 20, 30, 50, 63, 69, 80, 86, 110, 113], "demo": 77, "demonstr": [48, 49, 50, 57, 69, 75, 77, 81, 85, 100, 110, 112], "deni": 113, "denomin": [101, 102, 103, 107], "denot": [14, 50, 51, 61, 62, 69, 70, 75, 77, 78, 83, 85, 87, 101, 103, 106, 107, 109], "dens_net_tfa": 51, "densiti": [13, 16, 17, 48, 55, 57], "dep": 53, "dep1": [52, 53, 81, 112], "dep2": [52, 53, 81, 112], "depend": [4, 6, 12, 13, 17, 24, 52, 58, 59, 61, 64, 65, 66, 67, 68, 73, 75, 79, 83, 84, 85, 87, 94, 99, 101, 102, 103, 109, 112, 113], "deprec": [79, 86], "depreci": 114, "depth": [12, 40, 51, 52, 73, 79, 83, 84, 85, 86, 87, 100, 112, 115], "deriv": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 34, 85, 100], "describ": [49, 50, 69, 70, 71, 77, 84, 86, 111, 114], "descript": [51, 53, 76, 84, 86, 101, 103], "deserv": 85, "design": [35, 36, 55, 68, 82, 113, 114], "design_info": [58, 59], "design_matrix": [58, 59, 83], "desir": [22, 52, 73, 85, 111], "detail": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 33, 34, 48, 51, 52, 55, 57, 61, 62, 63, 68, 71, 75, 76, 77, 80, 81, 83, 84, 87, 89, 93, 94, 95, 96, 99, 100, 101, 103, 109, 110, 111, 112, 114, 115], "determin": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 42, 51, 60, 70, 71, 74, 75, 76, 85, 100, 101, 109], "determinist": [73, 75, 83, 85], "deutsch": 110, "dev": [111, 114], "develop": [49, 50, 52, 69, 77, 85, 114], "deviat": [67, 85, 101, 109], "dezeur": 113, "df": [7, 10, 47, 48, 50, 55, 56, 58, 59, 60, 62, 65, 69, 72, 74, 75, 76, 77, 78, 80, 83, 85], "df_agg": 63, "df_apo": 55, "df_apo_ci": 55, "df_apos_ci": 55, "df_ate": 55, "df_bench": 77, "df_binari": 77, "df_bonu": [52, 81, 112], "df_cate": [58, 59], "df_ci": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 39], "df_coef": 67, "df_cvar": 71, "df_fuzzi": 75, "df_lqte": 71, "df_ml_g0": 67, "df_ml_g1": 67, "df_ml_m": 67, "df_pa": [61, 78], "df_plot": 50, "df_pq": 71, "df_qte": 71, "df_result": 63, "df_sharp": 75, "df_sort": 55, "df_summari": 70, "df_wide": 69, "dfg": 110, "dgp": [23, 50, 60, 62, 63, 69, 72, 73, 74, 77, 78], "dgp1": 23, "dgp2": 23, "dgp3": 23, "dgp4": 23, "dgp5": 23, "dgp6": 23, "dgp_dict": 77, "dgp_tpye": 61, "dgp_type": [23, 61], "diagon": 77, "diagram": [47, 56, 85], "dichotom": [47, 56], "dict": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 37, 38, 39, 40, 41, 42, 43, 58, 59, 63, 68, 77, 84], "dict_kei": [101, 106], "dictionari": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 24, 27, 36, 43, 58, 59, 64, 65, 76, 83, 84, 101, 106], "dictonari": [51, 70], "did": [7, 10, 48, 61, 62, 69, 82, 114, 115], "diff": 70, "differ": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 24, 47, 48, 50, 51, 52, 55, 56, 57, 60, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 82, 83, 84, 86, 90, 91, 111, 112, 113, 114, 115], "differenti": 85, "difficult": 77, "dillon": 113, "dim": [36, 51], "dim_x": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 25, 26, 28, 29, 30, 31, 32, 36, 48, 50, 52, 57, 67, 68, 69, 80, 83, 84, 85, 101, 106], "dim_z": [14, 28, 85], "dimens": [24, 29, 50, 69, 73, 86], "dimension": [14, 15, 24, 26, 63, 83, 85, 86, 100, 101, 106, 112, 113], "direct": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 48, 57, 62, 78, 80, 85, 115], "directli": [35, 48, 49, 51, 55, 57, 67, 76, 80, 101, 106, 112, 115], "discontinu": [35, 36, 82, 113, 114], "discret": [5, 27, 55, 69, 85, 114], "discretis": 71, "discuss": [25, 50, 51, 69, 70, 113, 114, 115], "disjoint": [50, 64, 65, 69], "displai": [50, 55, 69, 77, 83, 84, 101, 106], "displot": 70, "disproportion": [51, 70], "disregard": 42, "dist": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "distr": 84, "distribut": [36, 48, 55, 57, 61, 67, 77, 80, 85, 101, 107, 111, 113, 114], "diverg": [35, 48, 57, 80], "divid": 85, "dmatrix": [58, 59, 83], "dml": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 33, 34, 35, 47, 48, 52, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 87, 100, 101, 106, 111], "dml1": [82, 112, 114, 115], "dml2": [47, 50, 52, 53, 61, 69, 71, 82, 85, 87, 100, 112, 114, 115], "dml_apo_obj": 85, "dml_apos_obj": 85, "dml_base": 69, "dml_combin": 100, "dml_cv_predict": 114, "dml_cvar": [60, 71], "dml_cvar_0": 60, "dml_cvar_1": 60, "dml_cvar_obj": [6, 83], "dml_data": [49, 50, 53, 55, 61, 62, 66, 67, 69, 72, 76, 77, 78, 83, 84, 85, 100, 115], "dml_data_bench": 77, "dml_data_bonu": [52, 112], "dml_data_df": 115, "dml_data_fuzzi": 75, "dml_data_lasso": 53, "dml_data_sharp": 75, "dml_data_sim": [52, 112], "dml_df": [50, 69], "dml_did": [61, 62], "dml_did_obj": [8, 9, 85], "dml_iivm_boost": [51, 70], "dml_iivm_forest": [51, 70], "dml_iivm_lasso": [51, 70], "dml_iivm_obj": [11, 56, 85], "dml_iivm_tre": [51, 70], "dml_irm": [58, 64, 67, 73], "dml_irm_at": 66, "dml_irm_boost": [51, 70], "dml_irm_forest": [51, 70], "dml_irm_gat": 66, "dml_irm_gatet": 66, "dml_irm_lasso": [51, 53, 70], "dml_irm_new": 73, "dml_irm_obj": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 76, 83, 84, 85], "dml_irm_obj_ext": 84, "dml_irm_rf": 53, "dml_irm_tre": [51, 70], "dml_long": 43, "dml_lpq_0": 74, "dml_lpq_1": 74, "dml_lpq_obj": [13, 83], "dml_lqte": [71, 74], "dml_obj": [49, 55, 76, 77], "dml_obj_bench": 77, "dml_pliv": [50, 69], "dml_pliv_obj": [14, 50, 69, 85], "dml_plr": [59, 65, 100], "dml_plr_1": 100, "dml_plr_2": 100, "dml_plr_boost": [51, 70], "dml_plr_forest": [51, 70, 115], "dml_plr_lasso": [51, 53, 70], "dml_plr_no_split": 86, "dml_plr_obj": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 76, 79, 83, 84, 85, 86, 87, 100, 101, 103, 106], "dml_plr_obj_extern": 86, "dml_plr_obj_intern": 86, "dml_plr_obj_onfold": 68, "dml_plr_obj_untun": 68, "dml_plr_rf": 53, "dml_plr_tree": [51, 70, 115], "dml_pq_0": [71, 74], "dml_pq_1": [71, 74], "dml_pq_obj": [16, 83], "dml_procedur": [53, 79, 112, 114, 115], "dml_qte": [71, 74], "dml_qte_obj": [17, 83], "dml_short": 43, "dml_ssm": [78, 85], "dml_tune": 114, "dmldummyclassifi": 84, "dmldummyregressor": 84, "dmlmt": 113, "dnorm": 48, "do": [49, 50, 51, 52, 67, 69, 70, 71, 72, 77, 83, 84, 101, 109, 112, 115], "doabl": 87, "doc": [47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 110, 114], "doccument": 114, "docu": 114, "document": [54, 58, 59, 62, 64, 65, 68, 77, 110, 114], "doe": [5, 17, 49, 50, 51, 55, 69, 70, 72, 76, 77, 101, 109, 115], "doesn": [47, 56], "doi": [19, 20, 21, 22, 23, 25, 29, 30, 32, 49, 50, 52, 63, 69, 77, 80, 84, 86, 100, 110, 112, 114], "domain": 73, "don": [49, 68], "done": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 68, 71, 84, 86, 101, 103], "dosag": 55, "dot": [18, 62, 73, 81, 83, 84, 85, 100, 112], "doubl": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 29, 30, 31, 32, 35, 51, 63, 70, 72, 82, 84, 86, 87, 100, 101, 103, 114], "double_ml_bonus_data": 53, "double_ml_data_from_data_fram": [48, 80, 81, 115], "double_ml_data_from_matrix": [49, 52, 81, 84, 100, 112], "double_ml_irm": [53, 73], "double_ml_score_mixin": 0, "doubleiivm": 110, "doubleml": [0, 48, 50, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 101, 106, 112, 113, 114], "doubleml2022python": 110, "doubleml2024r": 110, "doubleml_did_eval_linear": 49, "doubleml_did_eval_rf": 49, "doubleml_did_linear": 49, "doubleml_did_rf": 49, "doubleml_framework": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "doublemlapo": [0, 55, 85, 87, 88, 114], "doublemlblp": [4, 12, 15, 58, 59, 83, 114], "doublemlclusterdata": [0, 29], "doublemlcvar": [0, 60, 83, 87, 89, 114], "doublemldata": [0, 4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 25, 26, 28, 30, 31, 32, 35, 47, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 100, 101, 106, 114, 115], "doublemldid": [0, 61, 62, 85, 87, 90, 114], "doublemldidc": [0, 61, 85, 87, 91, 114], "doublemlframework": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 86, 100, 114], "doublemlframwork": 5, "doublemlidid": 85, "doublemlididc": 85, "doublemliivm": [0, 47, 51, 56, 70, 84, 85, 86, 87, 92, 114], "doublemlirm": [0, 4, 6, 8, 9, 11, 13, 14, 15, 16, 18, 49, 51, 53, 55, 58, 64, 66, 67, 70, 72, 73, 76, 77, 83, 84, 85, 86, 87, 93, 110, 114], "doublemllpq": [0, 74, 83, 87, 94, 114], "doublemlpliv": [0, 84, 85, 86, 87, 97, 110, 114], "doublemlplr": [0, 4, 5, 6, 8, 9, 11, 12, 13, 14, 16, 17, 18, 48, 51, 52, 53, 57, 59, 65, 68, 70, 72, 76, 79, 80, 83, 84, 85, 86, 87, 98, 100, 101, 106, 110, 112, 114, 115], "doublemlpolicytre": [12, 83], "doublemlpq": [0, 71, 74, 83, 87, 99, 114], "doublemlqt": [0, 60, 71, 74, 83, 100, 114], "doublemlresampl": 67, "doublemlsmm": 114, "doublemlssm": [0, 78, 85, 87, 95, 96], "doubli": [21, 22, 23, 49, 113], "down": 77, "download": [47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 111, 112], "downward": 77, "dpg_dict": 76, "dpi": [48, 57, 72], "dramat": 49, "draw": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 77, 86, 114], "draw_sample_split": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 67, 86], "drawn": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 24, 36, 51, 70, 71, 73, 86], "drive": [48, 57, 80], "driven": [77, 115], "drop": [49, 68, 69, 72, 81, 84, 87, 90, 91, 100], "dt": [87, 91, 101, 104], "dt_bonu": 81, "dta": 49, "dtype": [53, 55, 61, 64, 65, 66, 67, 69, 70, 71, 76, 78, 81, 83, 112], "dualiti": 69, "dubourg": [110, 112], "duchesnai": [110, 112], "due": [48, 49, 57, 58, 59, 66, 76, 77, 80, 85, 101, 103, 114, 115], "duflo": [19, 20, 30, 50, 63, 69, 80, 86, 110, 113], "dummi": [4, 12, 15, 37, 38, 39, 68, 77, 83, 84, 85, 114], "dummyclassifi": 37, "dummyregressor": 38, "duplic": 114, "durabl": [52, 53, 81, 112], "durat": 20, "dure": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 49, 50, 51, 52, 68, 69, 70, 84, 86, 112, 114, 115], "dx": 25, "dynam": [49, 113], "e": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 27, 30, 32, 33, 34, 35, 41, 42, 48, 49, 50, 51, 55, 57, 58, 59, 61, 63, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 78, 80, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115], "e20ea26": 52, "e401": [51, 70, 71, 76, 115], "e4016553": 115, "e45228": 72, "e57c": 52, "each": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 27, 41, 42, 50, 52, 55, 62, 64, 65, 67, 68, 69, 71, 72, 73, 76, 77, 79, 81, 84, 85, 86, 100, 101, 106, 115], "earlier": 115, "earn": [51, 70, 71], "earner": [51, 70, 76], "easi": [52, 87], "easier": 68, "easili": [52, 67, 68, 71, 114], "ec973f": 72, "ecolor": [55, 62, 70, 72], "econ": 113, "econml": 113, "econom": [28, 29, 31, 32, 50, 63, 69, 72, 77, 86, 113], "econometr": [19, 20, 21, 22, 23, 30, 31, 49, 50, 63, 69, 80, 110, 113], "econometrica": [26, 50, 69, 72, 80, 113], "ecosystem": [110, 115], "ectj": [19, 20, 30, 50, 63, 69, 80, 110], "ed": 113, "edge_color": 57, "edgecolor": 57, "edit": [111, 113], "edu": [110, 112], "educ": [51, 70, 71, 76, 115], "ee97bda7": 52, "effect": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 27, 36, 41, 42, 47, 48, 49, 50, 52, 55, 56, 57, 61, 62, 63, 66, 69, 73, 75, 78, 80, 82, 84, 85, 86, 87, 93, 100, 101, 103, 112, 113, 114, 115], "effici": [85, 113], "effort": 87, "eight": [50, 69], "either": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 24, 52, 62, 63, 73, 75, 83, 84, 85, 115], "eleanor": 113, "element": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 50, 58, 59, 60, 61, 67, 69, 71, 74, 76, 78, 87, 88, 90, 91, 101, 106, 108, 109, 114], "element_text": [50, 51], "elementari": 113, "elif": [64, 65, 73], "elig": [71, 76, 115], "eligibl": [51, 70, 76], "ell": [48, 50, 57, 63, 69, 80, 87, 97, 98, 112], "ell_0": [11, 14, 15, 48, 57, 63, 68, 80, 85], "ell_2": 67, "els": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 39, 49, 50, 51, 62, 64, 65, 69, 73, 77], "em": 113, "emphas": [50, 69], "empir": [33, 34, 48, 50, 57, 69, 72, 77, 80, 85, 86, 87, 100], "emploi": [50, 63, 69, 77, 87, 92], "employ": [51, 70, 71], "employe": 115, "empti": 69, "emul": [101, 103], "enabl": [55, 73, 76, 83, 101, 103, 114], "enable_metadata_rout": [41, 42], "encapsul": [37, 38, 41, 42], "encod": 72, "end": [25, 28, 29, 48, 49, 50, 51, 57, 60, 62, 63, 67, 69, 70, 72, 73, 74, 78, 79, 81, 84, 86, 100, 112, 115], "endogen": [51, 70, 71, 115], "enet_coordinate_descent_gram": 69, "engin": [52, 113], "enrol": [51, 70, 71], "ensembl": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 53, 55, 57, 58, 59, 64, 65, 66, 67, 70, 73, 76, 77, 79, 83, 84, 85, 86, 87, 100, 101, 106, 112, 115], "ensemble_learner_pipelin": 84, "ensemble_pipe_classif": 52, "ensemble_pipe_regr": 52, "ensur": [41, 42, 50, 65, 68, 69, 73], "entir": [48, 51, 57, 70, 80, 101, 103], "entri": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 48, 50, 53, 55, 57, 61, 66, 69, 70, 71, 76, 78, 80, 81, 84, 110, 112, 114], "enumer": [55, 60, 62, 64, 65, 67, 69, 70, 71, 74, 79, 84, 86], "env": [69, 111], "environ": 111, "ep": 72, "epanechnikov": 35, "epsilon": [51, 60, 61, 62, 70, 74, 83, 85], "epsilon_": [50, 62, 69], "epsilon_0": 36, "epsilon_1": 36, "epsilon_i": [24, 60, 72, 73, 74], "epsilon_sampl": 73, "epsilon_tru": [60, 74], "eqnarrai": 51, "equal": [4, 12, 50, 69, 72, 78, 83, 84, 85, 101, 107], "equat": [36, 50, 51, 69, 70, 77, 79, 100, 115], "equilibrium": [50, 69], "equival": [63, 86], "err": [6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 53, 55, 56, 58, 59, 60, 61, 64, 65, 66, 68, 69, 70, 71, 72, 74, 76, 77, 78, 83, 84, 85, 86, 87, 100, 112, 115], "error": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 41, 42, 47, 48, 49, 51, 52, 57, 62, 63, 64, 65, 67, 68, 70, 75, 77, 80, 84, 85, 86, 87, 100, 101, 106, 112, 114, 115], "errorbar": [55, 62, 64, 65, 68, 70, 72, 75], "erstellt": [50, 51, 52], "esim": 75, "especi": [67, 68], "essenti": 77, "est": 75, "est_method": 49, "esther": [86, 113], "estim": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 33, 34, 35, 37, 38, 39, 40, 41, 42, 48, 49, 50, 52, 55, 57, 58, 59, 60, 62, 64, 65, 67, 69, 73, 75, 79, 80, 82, 83, 84, 85, 89, 90, 91, 94, 96, 99, 101, 103, 106, 110, 113, 114], "estimatior": [7, 10], "estimator_list": 68, "et": [19, 20, 24, 26, 29, 30, 48, 50, 51, 52, 57, 58, 59, 60, 61, 63, 64, 65, 67, 69, 70, 71, 74, 76, 80, 85, 86, 87, 89, 94, 99, 100, 101, 103, 109, 110, 112, 114], "eta": [33, 34, 48, 50, 51, 62, 68, 69, 70, 74, 75, 79, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 109, 112, 115], "eta1": 72, "eta2": 72, "eta_": [100, 101, 109], "eta_0": [35, 79, 85, 87, 100], "eta_d": [75, 85], "eta_i": [24, 62, 73, 74, 75, 85], "eta_sampl": 73, "eta_tru": 74, "etc": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 50, 67, 68, 69, 114], "ev": [48, 57, 80], "eval": [52, 84], "eval_metr": [51, 70, 115], "eval_pr": 49, "eval_predict": 49, "evalu": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 26, 34, 49, 52, 58, 59, 60, 62, 66, 71, 74, 76, 79, 113, 114], "evaluate_learn": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 67, 68, 84, 114], "evalut": 84, "even": [51, 52, 70, 72, 75, 84, 85, 115], "eventu": [50, 69], "everi": [50, 69], "everyth": 110, "evid": [66, 68], "exact": 77, "exactli": [75, 77, 85], "exampl": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 24, 35, 47, 48, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 78, 79, 80, 83, 84, 85, 86, 87, 100, 101, 106, 110, 112, 114, 115], "example_attgt": 49, "example_attgt_dml_eval_linear": 49, "example_attgt_dml_eval_rf": 49, "example_attgt_dml_linear": 49, "example_attgt_dml_rf": 49, "except": [42, 63, 77, 114], "excess": 67, "exclud": 43, "exclus": [4, 12, 15, 64, 65, 83], "execut": [52, 115], "exemplarili": 112, "exemplatori": 73, "exhaust": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 84], "exhibit": [50, 69], "exist": [41, 42, 85, 101, 109], "exogen": [51, 70, 71, 85, 115], "exp": [21, 22, 23, 24, 26, 27, 30, 48, 57, 58, 59, 62, 64, 65, 72, 73, 80], "expect": [21, 22, 42, 49, 55, 61, 66, 67, 68, 75, 77, 78, 83, 85, 86, 100, 101, 102, 112], "experi": [20, 25, 26, 48, 51, 57, 70, 77, 80, 81, 86, 112, 113], "experiment": [8, 9, 23, 87, 90, 91, 101, 104, 105], "expertis": 77, "explain": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 22, 76, 101, 103, 108, 109], "explan": [50, 61, 69, 76, 101, 108, 110, 115], "explanatori": [77, 100], "explicit": 77, "explicitli": [66, 115], "exploit": [48, 57, 80, 85, 115], "explor": 68, "exponenti": 100, "export": [68, 114], "exposur": 62, "express": [50, 63, 75, 101, 109], "extend": [77, 84, 110, 114], "extendend": [101, 109], "extens": [84, 87, 110, 113, 114], "extent": 63, "extern": [48, 57, 68, 82, 101, 103, 114], "external_predict": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 57, 84], "externalptr": 51, "extra": 52, "extract": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 68], "extralearn": 52, "extrem": [51, 70], "ey": 63, "f": [51, 52, 55, 57, 60, 61, 62, 63, 67, 69, 70, 71, 73, 74, 76, 77, 78, 84, 101, 109, 110, 112], "f00584a57972": 52, "f1718fdeb9b0": 52, "f2e7": 52, "f3d24993": 52, "f6ebc": 72, "f_": [21, 23, 62, 83], "f_loc": [60, 74], "f_p": 62, "f_scale": [60, 74], "f_x": 85, "face_color": 57, "facet_wrap": 51, "facilit": 68, "fact": [51, 70, 71], "factor": [36, 48, 49, 50, 51, 52, 57, 67, 80, 84, 115], "faculti": 113, "fail": 114, "fair": 67, "fake": [47, 56], "fals": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 35, 36, 39, 41, 42, 48, 51, 52, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 77, 78, 81, 84, 85, 86, 87, 90, 91, 100, 101, 104, 105, 115], "famili": [51, 70, 84], "fanci": 49, "far": [51, 70], "farbmach": 25, "fast": [67, 73, 84], "faster": 63, "fb5c25fa": 52, "fc9e": 52, "fd8a": 52, "featur": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 40, 42, 49, 53, 66, 67, 70, 73, 83, 84, 85], "featureless": [52, 84], "features_bas": [51, 70, 71, 76], "features_flex": 51, "featureunion": 52, "februari": 77, "femal": [52, 53, 81, 112], "fern\u00e1ndez": [26, 86, 113], "fetch": [51, 69, 70, 71, 81], "fetch_401k": [51, 70, 71, 76, 115], "fetch_bonu": [52, 53, 81, 112], "few": [51, 70, 71], "ff7f0e": 62, "field": [50, 69, 84, 115], "fifteenth": 113, "fifth": 50, "fig": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 55, 58, 59, 60, 62, 63, 67, 68, 71, 72, 74, 75, 77], "fig_al": 57, "fig_dml": 57, "fig_non_orth": 57, "fig_orth_nosplit": 57, "fig_po_al": 57, "fig_po_dml": 57, "fig_po_nosplit": 57, "figsiz": [53, 55, 58, 59, 60, 62, 64, 65, 67, 68, 69, 70, 71, 72, 74, 75], "figur": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 30, 48, 50, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 68, 69, 70, 71, 74, 77, 80], "figure_format": 72, "file": [19, 20, 63, 72, 113, 114], "filenam": 48, "fill": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 48, 50, 51, 61, 67, 70, 78], "fill_between": [58, 59, 60, 71, 74], "fill_valu": 67, "filter": 52, "filterwarn": 57, "final": [48, 52, 55, 57, 58, 59, 60, 62, 64, 65, 66, 71, 74, 75, 78, 80, 85, 115], "final_estim": 75, "financi": [19, 76, 115], "find": [51, 62, 70, 77, 83, 84, 115], "finish": 52, "finit": [48, 51], "firm": [50, 69, 76], "firmid": 69, "first": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 29, 35, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 77, 78, 80, 83, 85, 86, 100, 101, 106, 111, 112, 114, 115], "fit": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 37, 38, 39, 40, 41, 42, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 87, 90, 91, 96, 100, 101, 103, 106, 110, 114, 115], "fit_arg": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "fit_transform": [69, 70], "five": 69, "fix": [62, 67, 114], "flag": [23, 86, 111], "flake8": 114, "flamlclassifierdoubleml": 68, "flamlregressordoubleml": 68, "flatten": [68, 72], "flexibl": [35, 47, 49, 51, 52, 56, 61, 70, 85, 110, 113, 114, 115], "flexibli": [51, 70, 76], "float": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 35, 36, 39, 41, 42], "float32": [70, 71, 76], "float64": [53, 55, 61, 65, 66, 69, 70, 76, 78, 81, 84, 112], "floor": 52, "floor_divid": 69, "flt": 52, "flush": 48, "fmt": [55, 62, 64, 65, 68, 70, 72, 75], "focu": [50, 51, 69, 70, 71, 77, 83, 85, 115], "focus": [71, 76, 77, 115], "fold": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 47, 50, 51, 52, 61, 67, 69, 70, 71, 76, 78, 79, 82, 84, 85, 87, 90, 91, 100, 112, 115], "follow": [21, 22, 23, 24, 27, 48, 50, 51, 57, 58, 59, 60, 61, 62, 64, 65, 68, 69, 70, 71, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 115], "font_scal": [69, 70, 71], "fontsiz": [60, 71, 74], "force_all_x_finit": [7, 10], "forest": [25, 47, 48, 49, 51, 52, 56, 57, 61, 66, 67, 70, 76, 80, 84, 112, 115], "forest_summari": 70, "forg": [111, 113, 114], "form": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 24, 39, 41, 42, 51, 58, 59, 60, 61, 62, 64, 65, 66, 67, 70, 74, 75, 76, 78, 83, 85, 87, 88, 93, 101, 102, 103, 106, 107, 108, 109, 111, 112], "format": [57, 66, 101, 106], "formula": [50, 51, 69, 70, 75, 77, 114], "formula_flex": 51, "forschungsgemeinschaft": 110, "forthcom": [77, 113], "forum": 114, "forward": [12, 40], "found": [58, 59, 63, 64, 65, 68, 80, 81, 84, 85, 112], "foundat": [110, 113], "four": [51, 67, 70, 114], "fourth": [50, 69], "frac": [11, 21, 22, 23, 25, 26, 28, 30, 31, 32, 34, 42, 48, 50, 52, 57, 62, 63, 66, 69, 72, 75, 79, 80, 83, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109], "fraction": 52, "frame": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 39, 47, 48, 50, 51, 53, 55, 58, 59, 61, 64, 65, 66, 69, 70, 71, 72, 73, 76, 78, 80, 81, 112, 115], "framework": [34, 48, 50, 52, 57, 67, 68, 69, 72, 77, 80, 84, 100, 110, 112, 114, 115], "freez": 111, "fribourg": 113, "friendli": 55, "from": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 39, 42, 47, 48, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 100, 101, 106, 112, 114, 115], "from_arrai": [7, 10, 18, 35, 57, 60, 61, 62, 74, 80, 81, 84, 100, 112], "from_product": 69, "front": 55, "fr\u00e9chet": [101, 109], "fs_kernel": [35, 85], "fs_specif": [35, 85], "fsize": [51, 70, 71, 76, 115], "full": [55, 57, 60, 61, 62, 64, 65, 67, 70, 71, 74, 75, 78, 80, 85], "fulli": [12, 51, 54, 68, 70, 85], "fun": 48, "func": 49, "function": [0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 30, 31, 33, 34, 35, 47, 48, 51, 52, 56, 57, 58, 59, 60, 61, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 109, 110, 113, 114, 115], "fund": [51, 70, 71, 110], "further": [21, 22, 23, 24, 27, 29, 50, 52, 55, 58, 59, 60, 61, 62, 66, 67, 69, 71, 73, 74, 75, 76, 77, 78, 84, 85, 87, 89, 94, 95, 96, 99, 100, 101, 103, 106, 108, 109, 110, 112, 114, 115], "furthermor": [57, 87, 88, 93], "futurewarn": 65, "fuzzi": [35, 36], "g": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 35, 41, 42, 48, 49, 52, 53, 57, 58, 59, 61, 62, 63, 66, 67, 71, 72, 73, 76, 78, 80, 83, 84, 85, 87, 88, 90, 91, 92, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 115], "g_": [36, 55, 87, 89, 90, 91, 94, 99, 100], "g_0": [4, 8, 9, 11, 12, 14, 15, 16, 30, 31, 35, 36, 48, 50, 51, 57, 67, 69, 70, 80, 83, 84, 85, 87, 88, 95, 96, 101, 102, 107, 109, 112, 115], "g_1": [36, 67], "g_all": [48, 51], "g_all_po": 48, "g_ci": 51, "g_d": [87, 89, 99], "g_dml": 48, "g_dml_po": 48, "g_hat": [14, 15, 48, 57, 87], "g_hat0": [11, 12], "g_hat1": [11, 12], "g_k": 83, "g_nonorth": 48, "g_nosplit": 48, "g_nosplit_po": 48, "g_x": 62, "gain": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 22, 43, 67, 101, 103, 107, 114], "gain_statist": 114, "galleri": [80, 83, 84, 85, 110, 114], "gama": 68, "gamma": [28, 31, 32, 50, 69, 72, 73, 75, 77, 85, 87, 89, 94], "gamma_0": [24, 73, 78, 87, 89, 94], "gamma_a": [21, 22, 77], "gamma_bench": 77, "gamma_v": 77, "gap": [69, 77], "gapo": 4, "gate": [4, 12, 15, 39, 72, 73, 82, 114], "gate_obj": 83, "gatet": 83, "gaussian": [13, 16, 17, 48, 57, 80, 83, 84, 100, 113], "ge": [21, 23, 24, 66, 73, 83], "geer": 113, "gelbach": [50, 69], "gener": [0, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 42, 47, 49, 50, 51, 52, 53, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 93, 100, 102, 103, 104, 105, 107, 109, 113, 114, 115], "generate_treat": 74, "geom_bar": 51, "geom_dens": 51, "geom_errorbar": 51, "geom_funct": 48, "geom_histogram": 48, "geom_hlin": 51, "geom_point": 51, "geom_til": 50, "geom_vlin": 48, "geq": [75, 85], "german": 110, "get": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 37, 38, 41, 42, 52, 55, 67, 72, 76, 77, 101, 103, 110, 111], "get_dummi": 72, "get_feature_names_out": [69, 70], "get_legend_handles_label": 55, "get_level_valu": 68, "get_logg": [48, 49, 50, 51, 52, 79, 84, 85, 86, 87, 100, 112], "get_metadata_rout": [37, 38, 41, 42], "get_param": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 37, 38, 41, 42, 68, 84], "ggdid": 49, "ggplot": [48, 50, 51], "ggplot2": [48, 50, 51], "ggsave": 48, "ggtitl": 51, "gh": 114, "git": 111, "github": [49, 51, 63, 68, 72, 110, 113, 114], "githubusercont": 63, "give": [51, 70], "given": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 26, 30, 31, 34, 35, 36, 41, 42, 48, 50, 55, 57, 62, 64, 65, 69, 71, 72, 75, 77, 78, 80, 83, 87, 88, 100, 101, 102, 106, 107, 108, 109, 112, 114], "glmnet": [51, 52, 84, 114], "global": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 41, 42, 84, 85], "globalclassifi": 75, "globallearn": 75, "globalregressor": 75, "glrn": 52, "glrn_lasso": 52, "gname": 49, "go": [58, 59, 63, 68, 75, 77], "goal": [55, 64, 65, 85], "goe": 85, "goldman": 113, "good": [63, 101, 103, 115], "gradient": [51, 70], "gradientboostingclassifi": 67, "gradientboostingregressor": 67, "gradual": 77, "gramfort": [110, 112], "graph": [52, 78, 115], "graph_ensemble_classif": 52, "graph_ensemble_regr": 52, "graph_obj": 75, "graph_object": [58, 59, 63, 77], "graphlearn": [52, 84], "grasp": [55, 101, 103], "great": [62, 115], "greater": 115, "green": [48, 58, 59, 60, 74], "greg": 113, "grei": [51, 55], "grenand": 113, "grey50": 50, "grid": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 50, 52, 55, 58, 59, 60, 63, 71, 72, 74, 77, 84, 101, 106], "grid_arrai": [58, 59], "grid_bound": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 77], "grid_search": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 52, 84], "grid_siz": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 58, 59], "gridextra": 50, "gridsearchcv": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 84], "grisel": [110, 112], "grob": 50, "group": [4, 12, 15, 47, 49, 55, 56, 66, 71, 72, 73, 77, 82], "group_0": 83, "group_1": [64, 65, 83], "group_2": [64, 65, 83], "group_3": [64, 65], "group_effect": 73, "group_ind": 66, "group_treat": 66, "groupbi": [63, 70], "gruber": 25, "gt": [47, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 112], "guarante": [50, 69], "guber": 25, "guess": [76, 101, 103], "guid": [33, 34, 37, 38, 41, 42, 48, 49, 50, 52, 55, 57, 62, 66, 69, 75, 76, 84, 110, 112, 114], "guidelin": 114, "gunion": [52, 84], "gxidclusterperiodytreat": 49, "h": [21, 22, 23, 25, 29, 49, 50, 69, 75, 85, 113], "h20": 68, "h_0": [55, 66, 76, 77, 101, 106, 115], "h_f": [35, 85], "ha": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 23, 39, 40, 41, 42, 48, 49, 50, 51, 57, 63, 67, 68, 69, 70, 71, 72, 75, 76, 77, 83, 84, 85, 101, 102, 103, 106, 107, 108, 109, 115], "half": [48, 57, 72, 80, 86], "hand": [35, 67, 68, 72, 115], "handbook": 72, "handl": [49, 55, 67, 84, 114], "hansen": [19, 20, 26, 28, 30, 50, 63, 69, 80, 110, 113], "happend": 67, "hard": [76, 101, 103], "harold": 113, "harsh": 41, "hat": [48, 50, 57, 63, 66, 69, 72, 75, 79, 80, 83, 85, 86, 87, 100, 101, 103, 106, 108], "have": [4, 5, 12, 15, 17, 24, 27, 39, 40, 41, 42, 47, 48, 49, 50, 51, 52, 55, 56, 58, 59, 61, 62, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 81, 83, 84, 85, 100, 101, 102, 103, 109, 111, 112, 114, 115], "hazlett": [77, 101, 103], "hc": [49, 113], "hc0": [39, 114], "hdm": [50, 69], "he": 78, "head": [49, 50, 52, 53, 58, 59, 64, 65, 68, 69, 70, 72, 75, 77, 81, 83, 112], "heat": [50, 69], "heatmap": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 50, 69, 77], "heavili": 67, "hei": 113, "height": [48, 50, 63, 68], "help": [49, 51, 60, 67, 71, 73, 77, 86, 115], "helper": 114, "henc": [49, 51, 52, 70, 77, 84, 87, 115], "here": [13, 16, 17, 49, 50, 51, 52, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 77, 78, 81, 84, 85, 111], "heterogen": [12, 24, 51, 66, 70, 71, 73, 82, 85, 86, 113, 114, 115], "heteroskedast": [64, 65], "heurist": [48, 57, 80], "high": [14, 15, 26, 51, 62, 63, 70, 71, 79, 85, 100, 110, 112, 113], "higher": [49, 51, 63, 70, 71, 72, 75, 114, 115], "highli": [51, 70, 110], "highlight": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 61, 68, 77, 114], "highlightcolor": [58, 59], "hint": 68, "hispan": 53, "hist": 55, "hist_e401": 51, "hist_p401": 51, "histogram": 55, "histplot": 57, "hjust": 51, "hline": [81, 100, 112, 115], "hold": [32, 50, 51, 68, 69, 70, 78, 83, 84, 85], "holdout": [84, 86], "holm": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "home": [51, 70], "homogen": 85, "hopefulli": 71, "horizont": [50, 62, 69], "hostedtoolcach": [70, 77], "hot": 72, "hotstart_backward": [52, 84], "hotstart_forward": [52, 84], "household": [51, 70, 71, 76], "how": [37, 38, 41, 42, 47, 49, 50, 51, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 80, 84, 85, 110, 111], "howev": [48, 51, 57, 68, 70, 75, 77, 78, 80, 85, 115], "hown": [51, 70, 71, 76, 115], "hpwt": [50, 69], "hpwt0": 50, "hpwtairmpdspac": 50, "href": 110, "hspace": 67, "hstack": [18, 62], "html": [52, 65, 110, 112, 114], "http": [25, 31, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 84, 110, 111, 112, 114], "huber": [32, 78, 85, 87, 95, 96, 113], "hue": 70, "huge": 67, "hugo": 113, "husd": [52, 53, 81, 112], "hyperparamet": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 51, 52, 53, 63, 67, 68, 70, 82, 112], "hypothes": [100, 113], "hypothesi": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 51, 70, 76, 101, 106, 113], "hypothet": 77, "i": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 94, 96, 99, 100, 101, 102, 103, 106, 107, 109, 110, 111, 112, 114, 115], "i0": [61, 62, 85], "i03": 110, "i1": [61, 85], "i_": [28, 69, 73], "i_1": [50, 69], "i_2": [50, 69], "i_3": [50, 69], "i_4": 62, "i_est": 57, "i_fold": 50, "i_k": [50, 69, 79, 86, 100], "i_learn": 67, "i_level": 55, "i_rep": [48, 57, 61, 67, 78, 80], "i_split": 69, "i_train": 57, "icp": 113, "id": [49, 50, 52, 69], "id_var": 69, "idea": [51, 52, 70, 71, 77, 84, 85, 101, 103, 115], "ident": [21, 22, 23, 24, 27, 28, 40, 52, 55, 68, 75, 84, 85, 101, 106], "identfi": 77, "identif": [75, 85, 115], "identifi": [50, 51, 61, 66, 69, 70, 71, 75, 77, 83, 85, 101, 109, 114], "identifii": 83, "idnam": 49, "idx_tau": [60, 71, 74], "idx_treat": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 55, 101, 106], "ieee": 113, "ifels": 49, "ignor": [41, 42, 57, 75], "ii": [50, 69], "iid": 85, "iivm": [11, 25, 33, 34, 71, 79, 83, 92, 110, 114], "iivm_summari": 70, "iivmglmnet": 51, "iivmrang": 51, "iivmrpart": 51, "iivmxgboost11861": 51, "ij": [29, 50, 55, 69, 78], "ilia": 113, "illustr": [48, 50, 51, 52, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 73, 74, 76, 77, 78, 80, 84, 115], "iloc": [55, 61, 62, 67, 69, 72], "immedi": 111, "immun": [86, 113], "impact": [47, 56, 67, 72, 76], "implement": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 33, 34, 35, 41, 42, 48, 49, 50, 51, 52, 57, 61, 63, 67, 69, 70, 72, 75, 76, 77, 78, 80, 82, 83, 84, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 110, 112, 113, 114, 115], "impli": [21, 22, 50, 51, 69, 70, 71, 75, 83, 85, 101, 102, 104, 105, 107], "implment": 62, "import": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 35, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 100, 101, 106, 111, 112, 114, 115], "importlib": 63, "impos": 77, "improv": [61, 67, 73, 85, 114], "in_sample_norm": [8, 9, 61, 87, 90, 91, 101, 104, 105], "inbuild": 67, "inbuilt": 67, "inc": [51, 70, 71, 76, 115], "includ": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 43, 49, 51, 55, 62, 64, 65, 70, 75, 76, 77, 83, 85, 100, 101, 102, 106, 107, 109, 111, 114, 115], "include_bia": [69, 70], "include_scenario": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 77], "incom": [51, 70, 71, 73, 76, 115], "incorpor": [52, 76, 101, 106], "increas": [66, 67, 69, 77, 115], "increment": 114, "ind": 70, "independ": [8, 9, 21, 22, 23, 24, 36, 50, 52, 62, 66, 69, 73, 85, 87, 90, 91, 114], "index": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 48, 50, 53, 57, 62, 63, 64, 65, 68, 69, 70, 72, 73, 80, 81, 86, 87, 90, 91, 112], "index_col": 63, "india": [86, 113], "indic": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 27, 32, 35, 39, 50, 51, 62, 66, 69, 70, 71, 75, 77, 78, 79, 81, 83, 85, 86], "individu": [4, 12, 41, 42, 49, 51, 55, 62, 64, 65, 66, 68, 70, 71, 75, 76, 83, 85, 115], "individual_df": 62, "induc": [82, 86], "industri": [50, 69], "inf": [7, 10, 49], "inf_model": 87, "infer": [26, 28, 47, 48, 50, 56, 57, 63, 69, 80, 82, 85, 86, 110, 112, 113, 114], "inferenti": 115, "infinit": [7, 10, 114], "influenc": [42, 85], "info": [47, 52, 53, 55, 61, 66, 68, 69, 70, 71, 76, 78, 81, 112, 114, 115], "inform": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 37, 38, 39, 41, 42, 47, 52, 56, 58, 59, 67, 75, 76, 77, 85, 101, 103, 113], "infti": [48, 57, 80], "inher": 77, "inherit": [72, 114], "initi": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 35, 51, 52, 60, 61, 70, 71, 74, 75, 76, 77, 78, 81, 83, 84, 85, 86, 112, 114, 115], "inlin": [53, 72], "inlinebackend": 72, "inner": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 84], "innermost": 84, "input": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 42, 52, 76, 79, 100, 101, 103, 106], "insensit": 85, "insid": [41, 42], "insight": [63, 77], "insignific": 76, "inspect": 112, "inspir": [21, 25, 26, 32, 77], "instal": [51, 68, 75, 85, 114], "install_github": 111, "instanc": [41, 42, 51, 52, 70, 84], "instanti": [50, 51, 69, 70, 84, 86], "instead": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 41, 42, 47, 49, 51, 55, 56, 65, 66, 68, 70, 71, 83, 84, 85, 101, 104, 105, 107, 108, 114], "instruct": [111, 114], "instrument": [7, 10, 11, 14, 19, 25, 28, 50, 51, 52, 53, 55, 61, 66, 69, 70, 71, 74, 76, 78, 81, 84, 85, 87, 94, 100, 112, 115], "instrument_effect": 47, "instrument_impact": 56, "insuffienct": 68, "int": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 24, 27, 35, 36, 39, 40, 49, 50, 51, 56, 60, 61, 73, 74, 77, 78], "int64": [53, 67, 69, 81, 112], "int8": [70, 71, 76], "integ": [23, 52, 84], "integr": [68, 77, 101, 109, 114], "intend": [35, 52, 77, 115], "intent": [85, 115], "inter": 84, "interact": [4, 5, 11, 12, 21, 25, 26, 27, 35, 36, 55, 77, 82, 84, 102, 107, 110, 114, 115], "interchang": 100, "interest": [11, 12, 14, 15, 21, 22, 48, 51, 57, 61, 63, 70, 71, 75, 78, 80, 83, 85, 87, 100, 112, 115], "interfac": [49, 51, 52, 81, 84, 86, 112], "intermedi": [65, 77], "intern": [49, 51, 52, 55, 68, 71, 84, 113], "internet": [51, 70, 71], "interpret": [64, 65, 77, 83, 101, 102, 103, 107, 108, 109, 111, 115], "intersect": [77, 101, 106, 114], "interv": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 39, 49, 50, 51, 55, 58, 59, 60, 61, 64, 65, 69, 71, 74, 75, 76, 78, 82, 83, 86, 87, 101, 106, 112, 113, 115], "intial": 75, "introduc": [48, 57, 80, 81, 100, 114, 115], "introduct": [48, 50, 52, 57, 69, 71, 76, 84, 85, 101, 103], "introductori": [49, 77], "intrument": 78, "intspecifi": 35, "intuit": 77, "inuidur1": [52, 53, 81, 112], "inuidur1femaleblackothracedep1dep2q2q3q4q5q6agelt35agegt54durablelusdhusdtg": [52, 81, 112], "inuidur2": [53, 81, 112], "inv_sigmoid": 72, "invalid": [48, 57, 80], "invari": 85, "invers": [4, 6, 11, 12, 13, 16, 17, 18, 78, 101, 102, 107], "invert_yaxi": 69, "investig": [63, 68, 77], "involv": [83, 84, 87, 115], "io": [72, 114], "ipw_norm": 114, "ipykernel_45212": 65, "ipynb": [47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78], "ira": [51, 70, 71], "irm": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 26, 27, 33, 34, 39, 40, 67, 77, 79, 82, 84, 93, 102, 107, 110, 114, 115], "irm_summari": 70, "irmglmnet": 51, "irmrang": 51, "irmrpart": 51, "irmxgboost8047": 51, "irrespect": 77, "is_classifi": [4, 8, 9, 11, 12, 15], "is_gat": [4, 12, 15, 39], "isnan": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 67, 84], "isoton": 77, "isotonicregress": 77, "issn": 63, "issu": [77, 110, 113, 114], "ite": [55, 64, 65, 66], "item": [11, 70, 79, 84, 86], "iter": [35, 47, 61, 69, 75, 78, 84, 100, 115], "itertool": 63, "its": [37, 38, 77, 79, 83, 84, 85, 86, 87, 100], "iv": [11, 14, 15, 25, 28, 29, 48, 50, 57, 69, 80, 81, 97, 98, 101, 108, 110, 114, 115], "iv_2": 47, "iv_var": [50, 69], "iv\u00e1n": [86, 113], "j": [19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 48, 49, 50, 52, 55, 57, 63, 69, 72, 78, 80, 84, 85, 100, 110, 112], "j_": [50, 69], "j_0": 100, "j_1": [50, 69], "j_2": [50, 69], "j_3": [50, 69], "j_k": [50, 69], "jame": 113, "janni": [51, 70], "javanmard": 113, "jbe": [50, 69], "jeconom": [21, 22, 23, 49], "jerzi": 113, "jia": 77, "jk": 85, "jmlr": [52, 110, 112, 114], "job": [51, 70, 71], "joint": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 39, 55, 58, 59, 60, 64, 65, 71, 74, 85, 100, 114, 115], "jointli": [74, 83], "joss": [52, 84, 110, 112], "journal": [19, 20, 21, 22, 23, 29, 30, 32, 49, 50, 52, 63, 69, 72, 77, 80, 84, 110, 112, 113, 114], "jss": 110, "jump": [73, 75, 85], "jun": [49, 113], "jupyt": [47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78], "juraj": 113, "just": [49, 52, 55, 60, 61, 62, 64, 65, 66, 73, 74, 85, 87, 90, 91, 101, 103], "justif": [86, 101, 103], "k": [19, 22, 23, 25, 26, 28, 29, 30, 32, 48, 50, 52, 57, 67, 68, 69, 75, 79, 80, 82, 83, 85, 100, 115], "k_h": [75, 85], "kaggl": [51, 70], "kallu": [60, 71, 74, 76, 87, 89, 94, 99, 113], "kappa": 85, "kato": [29, 50, 69, 100, 113], "kb": [55, 61, 66, 69, 70, 71, 76, 81, 112], "kde": [13, 16, 17, 70], "kdeplot": [61, 67, 78], "kdeunivari": [13, 16, 17], "kecsk\u00e9sov\u00e1": 114, "keep": [42, 49, 65, 77, 115], "kei": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 35, 40, 50, 51, 58, 59, 64, 65, 68, 69, 70, 71, 75, 77, 84, 85, 87, 101, 106, 114], "keith": 113, "kengo": 113, "kernel": [13, 16, 17, 35, 42, 75, 85], "kernel_regress": 75, "kernelreg": 75, "keyword": [4, 12, 15, 23, 29, 30, 31, 36, 39], "kf": 86, "kfold": [69, 86], "kind": [47, 56, 70], "kj": [22, 23, 25, 26, 28, 29, 30, 32, 48, 50, 57, 69, 80], "klaassen": [25, 77, 110, 113], "klaa\u00dfen": 25, "knau": 113, "know": [61, 73], "knowledg": [47, 56, 67, 72, 73], "known": [66, 67, 75, 77, 84, 85], "kohei": 113, "kotthof": 52, "kotthoff": [52, 84, 110, 112], "krueger": 72, "kueck": [51, 70], "kurz": [110, 113, 114], "kwarg": [4, 12, 15, 21, 22, 23, 27, 29, 30, 31, 35, 36, 37, 39, 68, 85], "l": [50, 52, 53, 58, 59, 69, 77, 78, 84, 101, 108, 110, 112], "l1": [70, 78, 85], "l_hat": [14, 15, 48, 57, 87], "label": [41, 55, 57, 58, 59, 60, 62, 64, 65, 68, 71, 72, 74, 75], "labor": 72, "laffer": 113, "laff\u00e9r": [32, 78, 85, 87, 95, 96], "lal": [72, 114], "lambda": [50, 51, 52, 70, 72, 73, 84, 87, 91, 100, 112], "lambda_": 63, "lambda_0": [87, 91], "lambda_t": 23, "land": 73, "lang": [52, 84, 110, 112], "langl": [24, 73], "lappli": 86, "larg": [48, 57, 66, 67, 68, 72, 77, 85], "larger": [12, 49, 75, 77, 101, 106], "largest": 67, "largli": 67, "lasso": [50, 51, 52, 70, 78, 84, 112, 113], "lasso_class": [51, 70], "lasso_pip": [52, 84], "lasso_summari": 70, "lassocv": [18, 63, 69, 70, 78, 84, 85, 100, 112], "last": [23, 52, 111], "late": [11, 47, 51, 70, 85, 87, 92], "latent": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 22, 76, 101, 108, 109], "later": [51, 52, 75, 77, 84, 115], "latter": [41, 42, 85], "layout": 63, "lbrace": [11, 12, 25, 26, 32, 50, 69, 79, 85, 86, 87, 88, 100, 101, 102], "ldot": [14, 15, 50, 69, 78, 79, 85, 86, 100, 112], "le": [23, 61, 73, 83, 85, 87, 94, 99], "lead": [49, 77, 85], "leadsto": 100, "lear": [52, 84, 110, 112], "learn": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 29, 30, 31, 32, 35, 47, 51, 52, 53, 55, 56, 60, 63, 67, 68, 70, 71, 72, 74, 75, 77, 81, 82, 84, 86, 87, 100, 101, 103, 114, 115], "learner": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 47, 48, 49, 50, 51, 57, 58, 59, 61, 63, 69, 70, 71, 76, 77, 78, 79, 80, 82, 85, 86, 87, 100, 101, 106, 114, 115], "learner_class": [18, 114], "learner_cv": 52, "learner_forest_classif": 52, "learner_forest_regr": 52, "learner_l": 76, "learner_lasso": 52, "learner_list": 67, "learner_m": 76, "learner_nam": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 84], "learner_param_v": 52, "learner_rf": 100, "learnerclassif": 52, "learnerregr": 52, "learnerregrcvglmnet": 52, "learnerregrrang": [52, 84], "learning_r": [57, 60, 71, 74, 75, 77, 80], "least": [47, 51, 56, 70, 71, 76, 85, 86], "leav": [77, 78], "left": [25, 26, 28, 29, 32, 48, 50, 55, 57, 67, 69, 70, 71, 72, 74, 75, 80, 85, 87, 90, 91, 100, 101, 102, 104, 105, 107], "legend": [51, 55, 57, 58, 59, 60, 62, 64, 65, 67, 71, 72, 74], "len": [55, 60, 67, 68, 69, 71, 74], "length": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 48, 52, 61, 84], "leq": [50, 69], "less": [49, 51, 70, 71, 75, 77], "lester": 113, "let": [21, 22, 23, 27, 48, 49, 51, 52, 55, 57, 60, 61, 64, 65, 67, 70, 71, 74, 77, 78, 79, 80, 84, 85, 101, 103, 109, 115], "level": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 27, 35, 39, 50, 51, 55, 58, 59, 60, 61, 62, 64, 65, 66, 69, 70, 71, 74, 76, 77, 78, 84, 87, 88, 101, 102, 106, 115], "level_0": [52, 69], "level_1": 69, "level_bound": 55, "levinsohn": [50, 69], "lewi": 113, "lgbmclassifi": [60, 61, 62, 67, 71, 74, 75, 77], "lgbmregressor": [57, 60, 61, 62, 67, 71, 75, 77, 80], "lgr": [48, 49, 50, 51, 52, 79, 84, 85, 86, 87, 100, 112], "lib": [69, 70, 77], "liblinear": [70, 78, 85], "librari": [47, 48, 49, 50, 51, 52, 79, 80, 81, 84, 85, 86, 87, 100, 111, 112, 115], "licens": 114, "lie": 113, "lightgbm": [57, 60, 61, 62, 67, 71, 74, 75, 77], "like": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 41, 42, 49, 51, 52, 63, 65, 70, 71, 77, 84, 86, 112, 115], "lim": 72, "lim_": [75, 85], "limegreen": [58, 59], "limit": [72, 85, 113], "limits_": 83, "lin": [75, 77, 85], "line": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 55, 62, 77], "linear": [4, 12, 14, 15, 21, 22, 27, 28, 29, 30, 31, 33, 34, 39, 47, 48, 49, 50, 52, 55, 56, 57, 58, 59, 61, 62, 63, 64, 67, 68, 69, 76, 77, 79, 80, 82, 83, 84, 86, 88, 90, 91, 92, 93, 97, 98, 100, 106, 107, 108, 109, 110, 112, 113, 114, 115], "linear_model": [4, 12, 15, 18, 39, 53, 55, 56, 63, 67, 69, 70, 75, 77, 78, 84, 85, 100, 112], "linearli": [75, 85], "linearregress": [47, 55, 56, 67, 75, 77], "linearscoremixin": [0, 87], "lineplot": 55, "linestyl": [55, 62, 68, 75], "linewidth": 62, "link": [77, 114], "linspac": [58, 59, 77], "lint": 114, "linux": 111, "list": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 42, 48, 49, 50, 51, 52, 57, 58, 59, 69, 71, 73, 80, 84, 86, 87, 111, 114], "listedcolormap": 69, "literatur": [77, 85], "littl": 66, "ll": [52, 100, 115], "lllllllllllllllll": [81, 112], "lm": [47, 49, 77], "ln_alpha_ml_l": 63, "ln_alpha_ml_m": 63, "load": [47, 49, 51, 52, 63, 70, 71, 81, 111, 112], "loader": 0, "loc": [55, 57, 60, 62, 63, 65, 69, 72, 74, 76, 77], "local": [11, 13, 83, 85, 113, 114], "localconvert": 69, "locat": [60, 74, 85], "log": [50, 63, 67, 69, 72, 76, 84, 85], "log_odd": 73, "log_p": [50, 69], "log_reg": [47, 49], "logarithm": 63, "logic": [11, 52, 84], "logical_not": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 67, 84], "logist": [21, 36, 47, 49, 51, 55, 56, 70, 77, 78, 115], "logisticregress": [47, 53, 55, 56, 75, 77], "logisticregressioncv": [18, 67, 70, 78, 85], "logit": [67, 72], "loglik": 52, "logloss": [51, 70, 115], "logo": 114, "logspac": 70, "long": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 48, 57, 67, 76, 77, 101, 103, 109, 113], "look": [49, 51, 52, 60, 61, 62, 67, 70, 71, 74, 75, 76], "loop": 55, "loss": [67, 68, 75, 76, 84, 85], "loss_ml_g0": 67, "loss_ml_g1": 67, "loss_ml_m": 67, "low": [62, 66, 83, 113], "lower": [51, 52, 55, 60, 62, 63, 66, 71, 72, 74, 75, 76, 77, 84, 101, 106, 109, 115], "lower_bound": [58, 59], "lpq": [13, 17, 71, 83, 94, 114], "lpq_0": 74, "lpq_1": 74, "lqte": 83, "lr": 75, "lrn": [47, 48, 49, 50, 51, 52, 79, 84, 85, 86, 87, 100, 112, 115], "lrn_0": 52, "lt": [47, 49, 50, 51, 52, 53, 55, 61, 66, 69, 70, 71, 73, 76, 77, 78, 81, 112], "lucien": 114, "luka": 113, "luk\u00e1\u0161": 32, "lusd": [52, 53, 81, 112], "lvert": 63, "m": [18, 19, 20, 21, 28, 29, 30, 48, 50, 52, 53, 57, 63, 66, 69, 72, 80, 82, 83, 84, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114], "m_": [55, 85, 87, 88, 94, 100], "m_0": [4, 6, 8, 9, 11, 12, 14, 15, 16, 30, 31, 35, 48, 50, 51, 57, 63, 66, 68, 69, 70, 80, 83, 84, 85, 87, 89, 90, 91, 94, 95, 96, 99, 112, 115], "m_hat": [11, 12, 14, 15, 48, 57, 87], "m_i": [75, 85], "ma": [29, 50, 69, 113], "mac": 111, "machin": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 29, 30, 31, 32, 35, 47, 51, 52, 53, 55, 56, 60, 61, 63, 68, 70, 71, 72, 74, 75, 76, 77, 78, 82, 84, 85, 86, 87, 100, 101, 103, 114, 115], "machineri": [63, 113], "mackei": 113, "maco": 111, "made": [85, 115], "mae": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 67, 84], "maggi": 113, "magnitud": [101, 103], "mai": [42, 61, 78], "main": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 63, 71, 77, 85, 100, 101, 103, 113, 115], "mainli": 77, "maintain": [49, 110, 114], "mainten": 114, "major": [52, 77, 114], "make": [47, 55, 56, 67, 68, 77, 83, 84, 114, 115], "make_confounded_irm_data": [77, 114], "make_confounded_plr_data": 76, "make_did_sz2020": [8, 9, 61, 85], "make_heterogeneous_data": [58, 59, 64, 65, 66], "make_iivm_data": [11, 13, 83, 85], "make_irm_data": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 67, 83, 84, 85], "make_irm_data_discrete_treat": 55, "make_pipelin": 70, "make_pliv_chs2015": [14, 85], "make_pliv_multiway_cluster_ckms2021": [7, 50, 69], "make_plr_ccddhnr2018": [4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 48, 57, 68, 79, 80, 83, 84, 85, 86, 87, 100, 101, 106], "make_simple_rdd_data": [35, 75, 85], "make_spd_matrix": 31, "make_ssm_data": [78, 85], "malt": [110, 113], "maltekurz": 110, "man": [47, 56], "manag": [84, 111], "mani": [28, 33, 34, 48, 49, 50, 52, 57, 61, 68, 69, 80, 87, 100, 115], "manili": 39, "manipul": [51, 52, 75, 85], "manual": [51, 68, 76, 115], "mao": 113, "map": [11, 37, 38, 41, 42, 49, 50, 69, 83, 85], "mapsto": [79, 83], "mar": [32, 85], "margin": [58, 59, 77], "marit": [51, 70], "marker": [55, 77], "markers": 72, "market": 72, "markettwo": 50, "markov": [31, 113], "marr": [51, 70, 71, 76, 115], "marshal": 84, "martin": [32, 77, 110, 113, 114], "masatoshi": 113, "master": 49, "mat": 50, "match": [84, 101, 108], "math": 18, "mathbb": [11, 12, 14, 15, 21, 22, 23, 27, 33, 34, 50, 55, 61, 62, 66, 67, 68, 69, 72, 75, 78, 83, 85, 87, 88, 89, 90, 91, 93, 94, 95, 96, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 112, 115], "mathcal": [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 48, 50, 57, 60, 62, 69, 73, 74, 78, 80], "mathop": 83, "mathrm": [21, 22, 75, 85], "matia": 113, "matplotlib": [53, 55, 57, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 71, 72, 74, 75, 77, 78], "matric": [73, 82, 114], "matrix": [21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 42, 48, 50, 51, 52, 57, 69, 78, 80, 81, 84, 100, 112, 114, 115], "matt": 113, "matter": [67, 72], "max": [51, 52, 70, 71, 79, 83, 84, 85, 86, 87, 89, 100, 112, 115], "max_depth": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 53, 70, 76, 79, 83, 84, 85, 86, 87, 100, 101, 106, 112, 115], "max_featur": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 53, 70, 76, 79, 83, 84, 85, 86, 87, 100, 101, 106, 112, 115], "max_it": [69, 70, 77], "maxim": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 73, 83, 85], "maxima": 100, "maximum": [83, 84], "mb": [53, 78, 81, 112], "mb706": 114, "mea": 25, "mean": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 41, 42, 47, 48, 50, 51, 55, 56, 57, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 76, 77, 80, 84, 85, 100, 115], "mean_absolute_error": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 67, 84], "meant": [83, 114], "measir": 76, "measur": [49, 52, 63, 68, 76, 77, 84, 85, 101, 102, 103, 107, 108, 109], "measure_col": 63, "measure_func": 49, "measure_pr": 49, "measures_r": 49, "mechan": [37, 38, 41, 42, 77], "median": [77, 86], "melt": 50, "membership": 77, "memori": [53, 55, 61, 66, 69, 70, 71, 76, 78, 81, 112], "mention": [66, 83], "merg": [51, 70], "mert": [86, 113], "meshgrid": [58, 59, 77], "messag": [48, 49, 50, 51, 52, 112, 114], "meta": [41, 42, 84, 112], "metadata": [37, 38, 41, 42], "metadata_rout": [41, 42], "metadatarequest": [37, 38, 41, 42], "method": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 33, 34, 35, 37, 38, 39, 40, 41, 42, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 64, 65, 67, 69, 70, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 87, 100, 101, 103, 106, 110, 112, 114], "methodolog": 113, "methodologi": 77, "metric": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 41, 84], "michael": 113, "michaela": 114, "michel": [110, 112], "michela": [32, 113], "mid": [51, 70, 72, 75, 85], "mid_point": 55, "might": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 50, 60, 67, 69, 73, 75, 76, 77, 84, 85], "mild": [48, 57, 80], "militari": 72, "miller": [50, 69], "mimic": 77, "min": [50, 51, 52, 60, 69, 70, 71, 74, 75, 79, 84, 85, 86, 87, 100, 112, 115], "min_": 83, "min_samples_leaf": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 40, 66, 70, 76, 79, 83, 84, 85, 86, 87, 100, 101, 106, 115], "min_samples_split": 70, "minim": [12, 40, 51, 67, 70, 75, 85], "minor": [48, 57, 80, 87, 114], "minsplit": 51, "minut": 68, "miruna": 113, "mislead": 114, "miss": [7, 10, 18, 52, 84, 85, 87, 95, 114], "missing": [32, 78], "misspecif": 61, "misspecifi": 61, "mit": [110, 112], "mixin": [0, 33, 34, 87], "ml": [31, 50, 51, 52, 63, 68, 69, 70, 75, 79, 82, 84, 85, 86, 110, 113, 114], "ml_g": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 47, 48, 49, 51, 53, 55, 56, 57, 58, 60, 61, 62, 64, 66, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 83, 84, 85, 114], "ml_g0": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 49, 51, 53, 61, 67, 70, 76, 84, 85], "ml_g1": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 49, 51, 53, 61, 67, 70, 76, 84, 85], "ml_g_d0": [78, 85], "ml_g_d0_t0": [61, 85], "ml_g_d0_t1": [61, 85], "ml_g_d1": [78, 85], "ml_g_d1_t0": [61, 85], "ml_g_d1_t1": [61, 85], "ml_g_sim": 18, "ml_l": [14, 15, 48, 50, 51, 52, 53, 57, 59, 65, 68, 69, 70, 72, 76, 79, 80, 84, 85, 86, 87, 100, 101, 106, 112, 114, 115], "ml_l_bonu": 112, "ml_l_forest": 52, "ml_l_forest_pip": 52, "ml_l_lasso": 52, "ml_l_lasso_pip": 52, "ml_l_rf": 115, "ml_l_sim": 112, "ml_l_tune": 84, "ml_l_xgb": 115, "ml_m": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 87, 100, 101, 106, 112, 114, 115], "ml_m_bench_control": 77, "ml_m_bench_treat": 77, "ml_m_bonu": 112, "ml_m_forest": 52, "ml_m_forest_pip": 52, "ml_m_lasso": 52, "ml_m_lasso_pip": 52, "ml_m_rf": 115, "ml_m_sim": [18, 112], "ml_m_tune": 84, "ml_m_xgb": 115, "ml_pi": [18, 78, 85], "ml_pi_sim": 18, "ml_r": [11, 14, 47, 50, 51, 56, 69, 70, 85, 114], "ml_r0": 85, "ml_r1": [51, 70, 85], "mlr": [52, 84], "mlr3": [47, 48, 49, 50, 51, 79, 84, 85, 86, 87, 100, 110, 112, 114, 115], "mlr3book": [52, 84], "mlr3extralearn": [51, 84], "mlr3filter": 52, "mlr3learner": [47, 48, 49, 50, 51, 79, 84, 85, 86, 87, 100, 112, 115], "mlr3measur": 49, "mlr3pipelin": [84, 114], "mlr3tune": [52, 84, 114], "mlr3vers": 51, "mlrmeasur": 49, "mode": [77, 111], "model": [0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 40, 42, 43, 47, 48, 49, 50, 52, 56, 57, 60, 61, 62, 63, 66, 67, 69, 71, 74, 76, 79, 80, 81, 82, 84, 88, 90, 91, 92, 93, 97, 98, 102, 103, 106, 107, 108, 109, 110, 113, 114], "model_data": [51, 70], "model_label": 68, "model_select": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 57, 69, 84, 86], "modelmlestimatelowerupp": 51, "modern": [52, 84, 110, 112], "modul": [75, 85, 111], "moment": [33, 34, 50, 69, 87, 100, 101, 103, 109, 112], "monoton": 85, "mont": [21, 22, 24, 27, 58, 59, 64, 65], "montanari": 113, "more": [12, 39, 47, 49, 51, 55, 56, 58, 59, 63, 67, 68, 70, 71, 75, 76, 77, 79, 83, 84, 85, 87, 93, 100, 101, 103, 106, 109, 112, 115], "moreov": [51, 52, 63, 84, 100, 115], "mortgag": [51, 70, 71], "most": [51, 60, 67, 70, 71, 74, 77, 83, 84, 85, 101, 106, 111], "motiv": [77, 80], "motivation_example_bch": 63, "mp": 49, "mpd": [50, 69], "mpg": 69, "mse": [52, 63, 84], "mserd": 75, "msr": [52, 84], "mtry": [51, 52, 79, 84, 85, 86, 87, 100, 115], "mu": 62, "mu_": 62, "mu_0": 85, "mu_mean": 62, "much": [51, 52, 70, 75, 77, 115], "muld": [53, 81, 112], "multi": [41, 49, 50, 58, 59, 69], "multiclass": [52, 68], "multiindex": 69, "multioutput": 42, "multioutputregressor": 42, "multipl": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 27, 49, 50, 51, 61, 69, 70, 76, 77, 78, 81, 84, 86, 100, 101, 103, 114, 115], "multipletest": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "multipli": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 57, 82, 83, 87, 115], "multiprocess": [60, 71, 74], "multitest": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "multivariate_norm": 18, "multiwai": [29, 50, 69, 113], "music": 113, "must": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 84, 85], "mutat": 52, "mutual": [4, 12, 15, 51, 64, 65, 70, 71, 83], "my_sampl": 86, "my_task": 86, "n": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 36, 47, 48, 50, 52, 55, 56, 57, 60, 62, 63, 66, 69, 72, 73, 74, 75, 78, 79, 80, 83, 84, 85, 86, 100, 110, 111], "n_": [27, 62], "n_coef": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 101, 106], "n_complier": 74, "n_core": [60, 71, 74], "n_estim": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 53, 57, 58, 59, 60, 61, 62, 64, 65, 66, 70, 71, 73, 74, 75, 76, 77, 79, 80, 83, 84, 85, 86, 87, 100, 101, 106, 112, 115], "n_eval": [52, 84], "n_featur": [41, 42], "n_fold": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 48, 49, 50, 51, 53, 57, 58, 59, 60, 61, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 80, 84, 86, 112, 115], "n_folds_per_clust": [50, 69], "n_folds_tun": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "n_iter": [35, 75, 85], "n_iter_randomized_search": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 84], "n_job": 70, "n_jobs_cv": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 67], "n_jobs_model": [5, 17, 60, 71, 74], "n_level": [27, 55], "n_ob": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 36, 39, 40, 48, 52, 55, 57, 58, 59, 61, 62, 64, 65, 66, 67, 68, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 100, 101, 106, 112], "n_output": [41, 42], "n_rep": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 48, 49, 50, 53, 55, 57, 61, 66, 67, 69, 75, 76, 77, 78, 80, 84, 86, 101, 106, 112, 115], "n_rep_boot": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 39, 55, 58, 59, 60, 64, 65, 71, 74, 100], "n_sampl": [41, 42, 73], "n_samples_fit": 42, "n_split": 86, "n_t": 62, "n_target": [41, 42], "n_time_period": 62, "n_true": [60, 74], "n_var": [48, 52, 57, 80, 81, 84, 100, 112], "n_w": 73, "n_x": [24, 58, 59, 64, 65, 66], "na": [7, 10, 48, 50, 80, 114], "na_real_": [50, 114], "naiv": [48, 57, 80], "name": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 37, 38, 41, 42, 48, 49, 50, 64, 65, 66, 68, 69, 75, 76, 77, 84, 111, 114], "namespac": 49, "nan": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 55, 57, 60, 61, 62, 64, 65, 67, 68, 70, 71, 74, 78, 80, 84], "nanmean": 57, "narita": 113, "nathan": 113, "nation": [77, 86, 113], "nativ": 49, "natt": 73, "natur": 77, "ncol": [50, 51, 52, 75, 81, 84, 100, 112], "ncoverag": 67, "ndarrai": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 23, 25, 26, 28, 29, 30, 31, 32, 81], "nearli": 67, "necess": [50, 69], "necessari": [49, 50, 68, 69, 75, 85, 111], "need": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 34, 47, 48, 49, 51, 56, 57, 68, 71, 78, 84, 86, 101, 109, 114, 115], "neg": 42, "neighborhood": [75, 100], "neither": [7, 10, 50, 69, 81], "neng": 113, "neq": [75, 85], "nest": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 41, 42, 84, 87, 96, 101, 106], "net": [71, 76, 115], "net_tfa": [51, 70, 71, 76, 115], "never": [11, 49, 50, 65, 69, 114], "never_tak": [11, 51, 70], "new": [47, 48, 49, 50, 51, 52, 58, 59, 68, 70, 73, 79, 80, 81, 83, 84, 85, 86, 87, 100, 110, 112, 113, 114, 115], "new_data": [58, 59, 73], "newei": [19, 20, 30, 50, 63, 69, 77, 80, 110, 113], "newest": 114, "next": [49, 51, 52, 58, 59, 60, 66, 67, 70, 71, 73, 74, 77, 114], "neyman": [50, 69, 79, 82, 101, 109, 110, 113], "nfold": [50, 51], "nh": 85, "nice": 49, "nifa": [70, 71, 76], "nil": 77, "nine": [50, 69], "nn": 75, "noack": [75, 85, 113, 114], "node": [51, 52, 79, 85, 86, 87, 100, 112, 115], "nois": [36, 72, 73], "non": [23, 29, 30, 31, 35, 47, 48, 51, 56, 57, 62, 70, 71, 73, 75, 84, 86, 87, 100], "non_orth_scor": [48, 57, 87], "nondur": 53, "none": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 27, 35, 39, 41, 42, 50, 51, 53, 55, 56, 61, 66, 70, 71, 76, 77, 78, 81, 84, 85, 87, 100, 111, 112], "nonignor": [18, 96], "nonlinear": [34, 51, 70, 75, 85, 87, 94, 99, 114], "nonlinearscoremixin": [0, 87], "nonparametr": [13, 16, 17, 75, 77, 101, 102, 103, 107, 108, 109, 113], "nop": 52, "nor": [7, 10, 50, 69, 81], "norm": 57, "normal": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 23, 48, 56, 57, 60, 61, 62, 66, 71, 72, 73, 74, 75, 78, 80, 81, 84, 85, 87, 90, 91, 100, 112], "normalize_ipw": [4, 5, 6, 11, 12, 13, 16, 17, 18, 71, 78], "notat": [50, 61, 69, 78, 85], "note": [7, 10, 11, 12, 14, 15, 18, 33, 34, 40, 41, 42, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 86, 87, 110, 112], "notebook": [47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 83, 84, 85, 115], "notic": [47, 56], "now": [49, 50, 51, 58, 59, 67, 69, 70, 73, 77, 78, 112, 114], "np": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 25, 26, 28, 29, 30, 31, 32, 35, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 100, 101, 106, 112, 115], "nround": [48, 51, 115], "nrow": [49, 50, 52, 75, 81, 84, 100, 112], "nu": [11, 23, 31, 78, 85, 101, 103, 106, 108, 109], "nu2": [101, 106], "nu_0": [101, 109], "nu_i": 78, "nuis_g0": 47, "nuis_g1": 47, "nuis_l": 115, "nuis_m": [47, 115], "nuis_r0": 47, "nuis_r1": 47, "nuis_rmse_ml_l": 63, "nuis_rmse_ml_m": 63, "nuisanc": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 30, 31, 35, 48, 49, 50, 51, 52, 57, 58, 59, 60, 61, 63, 66, 67, 69, 70, 71, 74, 76, 77, 78, 79, 80, 84, 85, 86, 87, 88, 90, 91, 94, 100, 101, 109, 110, 114, 115], "nuisance_el": [101, 102, 104, 105, 107, 108], "nuisance_loss": [67, 84, 114], "nuisance_target": 67, "null": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 49, 76, 84, 101, 106, 114], "null_hypothesi": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 76, 101, 106], "num": [51, 52, 79, 84, 85, 86, 87, 100, 112], "num_leav": [60, 62, 71, 74], "number": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 39, 40, 42, 48, 50, 57, 58, 59, 60, 62, 63, 64, 65, 67, 69, 71, 73, 74, 75, 77, 86, 100, 110, 112, 115], "numer": [34, 47, 52, 72, 84, 87, 101, 102, 107, 114], "numeric_onli": 63, "numpi": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 35, 39, 40, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 100, 101, 106, 112], "ny": 113, "o": [55, 62, 64, 65, 68, 70, 72, 75, 100, 110, 112], "ob": [49, 51, 62, 75], "obei": 87, "obj_dml_data": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 47, 48, 50, 56, 57, 60, 68, 69, 74, 79, 80, 83, 84, 85, 86, 87, 100, 101, 106, 114], "obj_dml_data_bonu": 81, "obj_dml_data_bonus_df": 81, "obj_dml_data_from_arrai": [7, 10], "obj_dml_data_from_df": [7, 10], "obj_dml_data_sim": 81, "obj_dml_plr": [48, 57, 80], "obj_dml_plr_bonu": [52, 112], "obj_dml_plr_bonus_pip": 52, "obj_dml_plr_bonus_pipe2": 52, "obj_dml_plr_bonus_pipe3": 52, "obj_dml_plr_bonus_pipe_ensembl": 52, "obj_dml_plr_fullsampl": 68, "obj_dml_plr_lesstim": 68, "obj_dml_plr_nonorth": [48, 57], "obj_dml_plr_orth_nosplit": [48, 57], "obj_dml_plr_sim": [52, 112], "obj_dml_plr_sim_pip": 52, "obj_dml_plr_sim_pipe_ensembl": 52, "obj_dml_plr_sim_pipe_tun": 52, "obj_dml_sim": 18, "object": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 25, 26, 28, 29, 30, 31, 32, 35, 37, 38, 39, 40, 41, 42, 47, 51, 52, 53, 55, 58, 59, 60, 61, 65, 66, 68, 70, 71, 74, 75, 78, 81, 83, 84, 85, 86, 87, 100, 110, 112, 113, 114, 115], "obs_confound": [47, 56], "observ": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 39, 40, 43, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 63, 66, 67, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 90, 91, 100, 101, 103, 104, 105, 112, 113, 115], "obtain": [22, 47, 48, 49, 50, 56, 57, 58, 59, 60, 61, 63, 67, 69, 74, 77, 78, 79, 80, 83, 84, 86, 87, 100, 101, 103, 106, 111, 112], "occur": [68, 114], "off": [73, 113], "offer": [49, 51, 70, 71, 77, 115], "offici": 111, "often": 74, "oka": 113, "ol": [4, 12, 15, 39], "olma": [75, 85, 113, 114], "omega": [66, 83, 87, 88, 93, 101, 102, 107], "omega_": [29, 50, 69], "omega_1": [29, 50, 69], "omega_2": [29, 50, 69], "omega_epsilon": [50, 69], "omega_v": [29, 50, 69], "omega_x": [29, 50, 69], "omit": [76, 77, 101, 103, 109, 113, 114, 115], "ommit": 77, "onc": [49, 68, 77, 85, 115], "one": [14, 43, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 67, 69, 71, 72, 75, 76, 77, 80, 83, 84, 85, 86, 87, 90, 91, 93, 97, 98, 100, 101, 102, 103, 106, 107, 108, 112, 114], "ones": [52, 60, 62, 68, 74, 76, 83], "ones_lik": [55, 74], "onli": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 39, 41, 42, 49, 50, 51, 58, 59, 64, 65, 66, 67, 68, 69, 70, 71, 75, 79, 83, 84, 85, 87, 89, 94, 99, 100, 101, 102, 103, 107, 109, 114], "onlin": 115, "onto": 67, "oo": 68, "oob_error": [52, 84], "oop": 114, "opac": [58, 59], "open": [52, 84, 110, 112], "oper": 52, "opposit": [73, 75, 85], "oprescu": [24, 58, 59, 64, 65, 113], "opt": [70, 77], "optim": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 35, 52, 58, 59, 68, 73, 83, 84, 113], "option": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 41, 42, 47, 48, 50, 51, 55, 58, 59, 64, 65, 66, 67, 69, 70, 71, 78, 84, 85, 86, 87, 89, 94, 99, 100, 114], "oracl": [27, 36, 55], "oracle_valu": [21, 22, 27, 36, 55], "orang": 48, "orcal": [21, 22], "order": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 41, 49, 50, 51, 52, 69, 70, 75, 84, 85, 86, 87], "org": [25, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 84, 110, 111, 114], "orient": [52, 84, 87, 110, 112, 113, 114], "origin": [40, 41, 42, 49, 52, 65, 73, 76, 77, 83], "orign": [51, 70], "orth_sign": [39, 40], "orthogon": [39, 40, 50, 51, 69, 70, 79, 82, 85, 100, 101, 109, 110, 113], "orthongon": [101, 109], "osx": 111, "other": [0, 7, 10, 14, 15, 41, 42, 48, 50, 51, 52, 55, 57, 61, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 93, 100, 101, 109, 110, 111, 112, 113, 114, 115], "other_ind": 69, "otherwis": [4, 8, 9, 11, 12, 15, 41, 42, 51, 70, 71, 73, 85], "othrac": [52, 53, 81, 112], "our": [48, 49, 51, 52, 57, 58, 59, 60, 61, 67, 68, 70, 71, 74, 75, 76, 77, 80, 85, 110, 112, 114, 115], "ourselv": 67, "out": [14, 15, 50, 52, 53, 61, 63, 67, 68, 69, 71, 76, 77, 78, 79, 81, 82, 83, 84, 85, 87, 97, 98, 100, 101, 103, 106, 108, 110, 112, 114, 115], "outcom": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 27, 36, 47, 49, 50, 51, 52, 53, 56, 62, 63, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 81, 84, 88, 100, 102, 103, 106, 108, 109, 112, 114, 115], "outcome_0": 56, "outcome_1": 56, "outer": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 84], "output": [49, 67, 79, 100, 115], "outshr": 69, "outsid": 48, "over": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 48, 55, 57, 63, 67, 80, 82, 84, 101, 106], "overal": [73, 77], "overcom": [82, 87], "overfit": [68, 82, 86], "overlap": [61, 77, 85], "overrid": [84, 114], "overridden": 85, "overst": [51, 70, 71], "overview": [67, 100, 101, 106, 113], "overwrit": 114, "ownership": [51, 70], "p": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 35, 36, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 83, 84, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 99, 100, 101, 102, 107, 110, 111, 112, 114], "p401": [51, 70, 71], "p_0": [87, 90, 91], "p_1": 100, "p_adjust": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 86, 100, 110, 112], "p_dbl": [52, 84], "p_int": 84, "p_n": 28, "p_val": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "p_x": [29, 50, 69], "p_x0": 72, "p_x1": 72, "packag": [47, 48, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 68, 69, 71, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 87, 100, 101, 103, 110, 112, 113, 114, 115], "packagedata": 69, "packagevers": 51, "page": [77, 110, 113], "pair": [47, 56], "pake": [50, 69], "paket": [50, 51, 52], "pal": 50, "palett": 55, "panda": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 39, 40, 53, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 83, 85, 101, 103, 112], "pandas2ri": 69, "panel": [8, 23, 105, 113, 114], "paper": [25, 28, 52, 68, 72, 75, 76, 77, 101, 109, 110, 112, 113, 114], "par": 53, "par_grid": [52, 84], "paradox": [52, 84, 114], "parallel": [49, 55, 60, 61, 62, 67, 74, 85], "param": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 37, 38, 41, 42, 68, 84], "param_grid": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 84], "param_nam": 49, "param_set": [52, 84], "param_v": 52, "paramet": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 48, 49, 50, 51, 55, 57, 58, 59, 60, 61, 63, 66, 67, 69, 70, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 94, 99, 100, 101, 103, 106, 107, 109, 110, 112, 113, 114, 115], "parametr": [49, 77, 80, 84, 115], "params_exact": 84, "params_nam": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 49], "parenttoc": 110, "part": [31, 48, 50, 51, 52, 57, 67, 68, 69, 70, 80, 84, 86, 101, 109, 114, 115], "parti": 31, "partial": [14, 15, 22, 28, 29, 30, 31, 34, 50, 52, 53, 63, 68, 69, 76, 79, 82, 84, 86, 97, 98, 100, 102, 106, 107, 108, 109, 110, 112, 114, 115], "partial_": [87, 100], "partiallli": 76, "particip": [19, 71, 76, 115], "particular": [85, 110], "particularli": 68, "partion": [50, 69], "partit": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 50, 69, 79, 82], "partli": 115, "pass": [4, 12, 15, 39, 41, 42, 49, 52, 68, 84, 115], "passo": [110, 112], "past": 50, "paste0": 50, "pastel": 57, "path": [84, 85], "path_to_r": 63, "patsi": [58, 59, 83], "pattern": 77, "paul": 113, "pd": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 25, 26, 28, 29, 30, 31, 32, 35, 39, 55, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 83, 85], "pdf": [57, 72], "pedregosa": [110, 112], "pedregosa11a": [110, 112], "pedro": [49, 113], "penal": 78, "penalti": [51, 52, 56, 70, 77, 78, 84, 85], "pennsylvania": [20, 81, 112], "pension": [51, 70, 71, 115], "peopl": [51, 70, 71], "pep8": 114, "per": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 50, 69], "percent": 84, "percentag": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 22], "perf_count": 67, "perfectli": [75, 85], "perform": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 40, 48, 50, 52, 57, 61, 63, 65, 66, 67, 68, 69, 71, 76, 77, 78, 80, 84, 85, 86, 87, 100, 110, 112, 113, 115], "perfrom": 66, "perhap": 115, "period": [8, 49, 61, 62, 85], "perp": 85, "perrot": [110, 112], "person": 115, "pessimist": 77, "peter": 113, "pfister": [52, 84, 110, 112], "phi": [50, 69, 83, 100], "philipp": [77, 110, 113], "philippbach": [110, 114], "pi": [18, 26, 28, 31, 83, 85, 87, 95, 96], "pi_": [29, 50, 69], "pi_0": [87, 95, 96], "pi_i": [78, 85], "pick": [75, 115], "pip": [75, 85], "pip3": 111, "pipe": 52, "pipe_forest_classif": 52, "pipe_forest_regr": 52, "pipe_lasso": 52, "pipelin": [41, 42, 52, 70, 114], "pipeop": 52, "pira": [51, 70, 71, 76, 115], "pivot": [63, 69, 113], "plai": [68, 115], "plan": [19, 51, 70, 71, 115], "plausibl": 77, "pleas": [37, 38, 41, 42, 49, 55, 68, 77, 86, 111], "plim": 72, "pliv": [14, 33, 34, 50, 69, 79, 83, 97, 110, 114], "plm": [82, 84, 100, 101, 106, 115], "plot": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 40, 48, 49, 51, 52, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 70, 71, 72, 74, 75, 76, 77, 78, 83, 101, 106], "plot_tre": [40, 73, 83], "plotli": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 58, 59, 63, 75, 77], "plr": [15, 33, 34, 52, 68, 72, 76, 79, 84, 86, 98, 100, 106, 107, 108, 109, 110, 112, 114, 115], "plr_est": 72, "plr_est1": 72, "plr_est2": 72, "plr_obj": 72, "plr_obj_1": 72, "plr_obj_2": 72, "plr_summari": 70, "plrglmnet": 51, "plrranger": 51, "plrrpart": 51, "plrxgboost8700": 51, "plt": [53, 55, 57, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 71, 72, 74, 75, 77, 78], "plt_smpl": [50, 69], "plt_smpls_cluster": [50, 69], "plug": [66, 101, 102, 104, 105, 106, 107], "pm": [35, 50, 69, 100, 101, 106, 109], "pmatrix": 78, "po": [52, 84], "point": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 49, 50, 64, 65, 69, 77, 83, 85, 115], "pointwis": [39, 60, 64, 65, 74], "poli": [51, 69, 70], "polici": [12, 14, 15, 40, 82, 85, 112, 113, 114], "policy_tre": [12, 73, 83], "policy_tree_2": 73, "policy_tree_obj": 83, "policytre": 73, "polit": 72, "poly_dict": 70, "polynomi": [19, 20, 36, 51, 53, 70, 75], "polynomial_featur": [19, 20, 51, 53], "polynomialfeatur": [69, 70], "popul": [77, 87], "popular": [67, 85, 101, 103], "porport": 76, "posit": [31, 51, 72, 77, 115], "posixct": [52, 84], "possibl": [7, 10, 41, 42, 49, 52, 58, 59, 64, 65, 66, 67, 68, 73, 75, 76, 77, 84, 85, 100, 101, 103, 114, 115], "possibli": [101, 103], "post": [28, 31, 85, 100, 113], "postdoubl": 113, "poster": 72, "potenti": [4, 5, 6, 13, 16, 18, 21, 27, 36, 61, 72, 75, 78, 88, 89, 100, 102, 111, 114, 115], "potential_level": 55, "power": [52, 68, 77, 84, 113], "pp": 49, "pq": [13, 16, 17, 71, 99, 114], "pq_0": [71, 74], "pq_1": [71, 74], "pr": [18, 47, 50, 51, 52, 84, 85, 86, 87, 100, 112, 115], "practic": [67, 77, 113], "pre": [49, 61, 78, 84, 85], "precis": [49, 85, 101, 107, 115], "precomput": 42, "pred": [49, 68], "pred_df": 73, "pred_dict": 84, "pred_treat": 73, "predict": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 35, 37, 38, 39, 40, 41, 42, 48, 50, 51, 52, 57, 60, 63, 67, 68, 69, 70, 73, 77, 80, 83, 86, 101, 103, 106, 107, 114, 115], "predict_proba": [4, 6, 8, 9, 11, 12, 13, 15, 16, 17, 18, 35, 37, 41, 42, 68, 84], "predictor": [4, 12, 15, 39, 40, 58, 59, 64, 65, 77, 79], "prefer": [51, 70, 71, 115], "preliminari": [6, 48, 57, 75, 87, 89, 94, 96, 99], "prepar": [49, 50, 69, 114], "preprint": 113, "preprocess": [51, 69, 70, 71, 84], "presenc": [51, 70, 71], "present": [49, 77, 84, 115], "prespecifi": 76, "pretest": 49, "pretreat": [8, 9, 49, 61], "prettenhof": [110, 112], "preval": 77, "prevent": [86, 114], "previou": [62, 66, 72, 111, 115], "previous": [84, 115], "price": [50, 69], "priliminari": [13, 17], "primari": 55, "principl": [101, 103], "print": [35, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 83, 84, 85, 86, 87, 100, 101, 106, 111, 112, 114, 115], "print_detail": 49, "prior": [67, 85], "privat": 114, "prob": 52, "probabilit": 66, "probabl": [4, 6, 11, 12, 13, 16, 17, 18, 23, 27, 41, 48, 49, 55, 57, 61, 66, 72, 74, 75, 77, 78, 80, 85, 87, 90, 91, 94, 113], "problem": [51, 70, 71, 83, 84], "procedur": [48, 50, 51, 57, 67, 69, 70, 76, 77, 84, 100, 111, 114], "proceed": [28, 113], "process": [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 49, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 73, 74, 77, 78, 82, 100, 101, 103, 113, 114], "produc": 72, "product": [58, 59, 63, 67, 77, 101, 109], "producton": 50, "program": [26, 51, 70, 71, 113, 115], "progress": 54, "project": [52, 58, 59, 83, 110, 114], "project_z": [58, 59], "prone": 87, "pronounc": 75, "propens": [13, 17, 21, 22, 51, 61, 66, 67, 70, 71, 77, 78, 83, 85, 101, 102], "properli": [68, 115], "properti": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 51, 52, 67, 70, 71, 72, 76, 84, 85, 101, 106, 112, 114], "proport": [76, 101, 103, 108, 109], "propos": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 50, 52, 69, 75, 101, 103, 113, 114], "provid": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 35, 41, 42, 49, 50, 51, 52, 58, 59, 64, 65, 68, 69, 70, 75, 77, 79, 80, 81, 82, 84, 100, 110, 112, 114, 115], "prune": [12, 40], "ps911c": 69, "ps944": 69, "pscore1": 72, "pscore2": 72, "psi": [33, 34, 48, 49, 50, 69, 79, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 109, 112], "psi_": [100, 101, 106, 108, 109], "psi_a": [11, 12, 14, 15, 33, 48, 50, 57, 69, 86, 87, 88, 90, 91, 92, 93, 97, 98, 100], "psi_b": [11, 12, 14, 15, 33, 48, 57, 83, 86, 87, 88, 90, 91, 92, 93, 97, 98], "psi_el": [86, 87], "psi_j": 100, "psi_nu2": [101, 106], "psi_sigma2": [101, 106], "public": [47, 56, 114], "publish": [77, 114], "pull": [51, 114], "purchas": 77, "pure": 77, "purp": [58, 59], "purpos": [48, 57, 66, 76, 77, 101, 103, 112], "pval": 100, "px": [63, 75], "py": [65, 69, 70, 77, 110, 111, 114], "py3": 111, "py_al": 57, "py_dml": 57, "py_dml_nosplit": 57, "py_dml_po": 57, "py_dml_po_nosplit": 57, "py_double_ml_apo": 55, "py_double_ml_bas": 57, "py_double_ml_basic_iv": 56, "py_double_ml_c": 58, "py_double_ml_cate_plr": 59, "py_double_ml_cvar": 60, "py_double_ml_did": 61, "py_double_ml_did_pretest": 62, "py_double_ml_firststag": 63, "py_double_ml_g": 64, "py_double_ml_gate_plr": 65, "py_double_ml_gate_sensit": 66, "py_double_ml_learn": 67, "py_double_ml_meets_flaml": 68, "py_double_ml_multiway_clust": 69, "py_double_ml_pens": 70, "py_double_ml_pension_qt": 71, "py_double_ml_plm_irm_hetfx": 72, "py_double_ml_policy_tre": 73, "py_double_ml_pq": 74, "py_double_ml_rdflex": 75, "py_double_ml_sensit": 76, "py_double_ml_sensitivity_book": 77, "py_double_ml_ssm": 78, "py_non_orthogon": 57, "py_po_al": 57, "pydata": 65, "pypi": [113, 114], "pyplot": [53, 55, 57, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 71, 72, 74, 75, 77, 78], "pyproject": 114, "python": [31, 49, 68, 77, 79, 80, 81, 82, 83, 85, 86, 87, 100, 101, 103, 106, 110, 112, 113, 114, 115], "python3": [70, 77, 111], "q": [52, 60, 74, 75, 84, 110, 112], "q2": [52, 53, 81, 112], "q3": [52, 53, 81, 112], "q4": [52, 53, 81, 112], "q5": [52, 53, 81, 112], "q6": [52, 53, 81, 112], "q_i": [75, 85], "qquad": 26, "qte": [60, 71, 114], "quad": [23, 51, 61, 70, 73, 75, 78, 83, 85, 87, 94, 100, 101, 104], "quadrat": 78, "qualiti": [76, 79, 114], "quanitl": 71, "quant": 60, "quantifi": 77, "quantil": [5, 6, 13, 16, 17, 27, 55, 60, 76, 82, 84, 89, 94, 99, 113, 114], "quantiti": [47, 56, 77], "queri": 70, "question": [77, 115], "quick": 71, "quit": [67, 73, 76, 101, 103], "r": [11, 25, 41, 42, 57, 58, 59, 62, 63, 69, 72, 75, 77, 79, 80, 81, 82, 85, 86, 87, 92, 97, 100, 101, 102, 103, 107, 108, 109, 110, 112, 113, 114, 115], "r2_d": [26, 67], "r2_score": 42, "r2_y": [26, 67], "r6": [52, 114], "r_0": [11, 14, 51, 70, 85], "r_all": 48, "r_d": 26, "r_df": 69, "r_dml": 48, "r_dml_nosplit": 48, "r_dml_po": 48, "r_dml_po_nosplit": 48, "r_double_ml_bas": 48, "r_double_ml_basic_iv": 47, "r_double_ml_did": 49, "r_double_ml_multiway_clust": 50, "r_double_ml_pens": 51, "r_double_ml_pipelin": 52, "r_hat": 14, "r_hat0": 11, "r_hat1": 11, "r_non_orthogon": 48, "r_po_al": 48, "r_y": 26, "rais": [7, 10, 37, 38, 41, 42, 84], "randint": 72, "randn": 18, "random": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 27, 31, 32, 35, 36, 47, 48, 49, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 83, 84, 86, 95, 100, 101, 106, 109, 112, 113, 115], "random_search": 84, "random_st": [27, 57, 66, 73], "randomforest": [51, 67, 70], "randomforest_class": [51, 58, 70, 73], "randomforest_reg": [58, 73], "randomforestclassifi": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 53, 55, 58, 59, 64, 65, 66, 67, 70, 73, 75, 76, 77, 83, 84, 85, 115], "randomforestregressor": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 53, 55, 57, 58, 59, 64, 65, 66, 67, 70, 73, 75, 76, 77, 79, 83, 84, 85, 86, 87, 100, 101, 106, 112, 115], "randomized_search": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 84], "randomizedsearchcv": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 84], "randomli": [48, 50, 57, 69, 80, 86, 115], "rang": [48, 55, 57, 60, 61, 62, 64, 65, 67, 68, 69, 71, 73, 74, 75, 77, 78, 80, 84, 85], "rangeindex": [53, 55, 61, 66, 69, 70, 71, 76, 78, 81, 112], "ranger": [49, 51, 52, 79, 84, 85, 86, 87, 100, 112, 115], "rangl": [24, 73], "rank": 114, "rate": [63, 67, 85], "rather": [75, 77, 85], "ratio": [84, 86, 101, 103], "ravel": [58, 59], "raw": [51, 63, 70], "raw_res_manual_lasso_r_100_n_100_p_200_rho_0": 63, "rbind": 51, "rbindlist": 51, "rbinom": 47, "rbrace": [11, 12, 25, 26, 32, 50, 69, 79, 85, 86, 87, 88, 100, 101, 102], "rcolorbrew": 50, "rcparam": [53, 58, 59, 60, 62, 64, 65, 69, 70, 71, 74], "rd": [85, 114], "rdbu": 50, "rdbu_r": 69, "rdbwselect": 85, "rdd": [0, 7, 10, 82, 111], "rdflex": [0, 75, 85, 114], "rdflex_fuzzi": 75, "rdflex_fuzzy_stack": 75, "rdflex_obj": [35, 85], "rdflex_sharp": 75, "rdflex_sharp_stack": 75, "rdrobust": [35, 75, 85, 111, 114], "rdrobust_fuzzi": 75, "rdrobust_fuzzy_noadj": 75, "rdrobust_sharp": 75, "rdrobust_sharp_noadj": 75, "rdt044": 63, "re": [69, 77, 111], "read": 111, "read_csv": 63, "readabl": 114, "readili": 110, "real": [51, 70, 71, 76, 101, 103], "realat": 85, "realiz": [75, 85], "reason": [7, 10, 47, 56, 76, 77, 101, 103, 115], "recal": [53, 101, 109], "receiv": [55, 75, 85], "recent": [68, 85], "recogn": [51, 70, 71], "recommend": [52, 67, 75, 77, 79, 86, 111, 113, 114], "recov": [47, 49, 56, 72], "recsi": 113, "red": [50, 64, 65, 68, 69], "reduc": [51, 66, 68, 70, 75, 76, 77, 85, 114], "redund": 114, "reemploy": [20, 81, 112], "refactor": 114, "refer": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 51, 55, 62, 66, 68, 70, 71, 75, 76, 81, 82, 83, 85, 101, 103, 106, 113, 114], "reference_level": [5, 55, 85], "refin": 114, "refit": [101, 103], "reflect": [73, 77, 83], "reg": [23, 51, 70, 115], "reg_estim": 75, "reg_learn": 71, "reg_learner_1": 67, "reg_learner_2": 67, "regard": [77, 110], "regener": 114, "region": [50, 60, 69, 100, 113], "regr": [47, 48, 49, 50, 51, 52, 79, 84, 85, 86, 87, 100, 112, 115], "regravg": [52, 84], "regress": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 25, 26, 27, 28, 29, 30, 31, 35, 36, 39, 47, 49, 50, 52, 55, 56, 63, 68, 69, 72, 76, 77, 78, 79, 80, 82, 83, 84, 86, 100, 102, 103, 106, 107, 108, 109, 110, 112, 113, 114, 115], "regressor": [38, 42, 48, 51, 55, 57, 60, 67, 68, 70, 80], "regular": [28, 82, 84, 87, 100, 113], "reich": [52, 84], "reinforc": 113, "reject": [51, 70], "rel": [51, 70, 101, 102, 103, 107], "relat": [77, 115], "relationship": [47, 56, 63, 77, 100], "relev": [7, 8, 9, 10, 24, 39, 41, 42, 60, 73, 74, 85, 101, 115], "reli": [58, 59, 61, 62, 66, 83, 84, 85, 101, 103, 115], "reload": 51, "remain": [49, 100, 115], "remark": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 48, 55, 57, 58, 59, 60, 62, 64, 65, 66, 67, 71, 76, 83, 84, 85, 87, 90, 91, 94, 99, 100, 101, 107], "remot": 111, "remov": [51, 77, 82, 86, 114], "renam": [70, 114], "render": [76, 77], "reorgan": 114, "rep": [48, 80, 84, 100], "repeat": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 47, 48, 50, 51, 52, 57, 66, 69, 70, 71, 72, 75, 76, 78, 80, 82, 84, 100, 104, 112, 114, 115], "repeatedkfold": 69, "repet": 76, "repetit": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 39, 58, 59, 63, 64, 65, 66, 67, 82, 84, 100, 112, 115], "repetiton": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35], "replac": [73, 77, 114], "replic": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 48, 51, 57, 63, 77], "repo": 114, "report": [51, 68, 70, 110, 114], "repositori": [63, 75, 114], "repr": [48, 50], "repres": [72, 77, 85], "represent": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 22, 76, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 112, 114], "reproduc": 27, "request": [41, 42, 114], "requir": [14, 15, 41, 47, 51, 52, 55, 66, 70, 71, 76, 85, 100, 101, 103, 106, 111, 114, 115], "requirenamespac": 49, "res_df": 69, "res_dict": [21, 22, 24, 27, 36], "resampl": [47, 50, 52, 61, 69, 71, 76, 78, 84, 85, 86, 87, 100, 110, 112, 115], "research": [50, 52, 69, 72, 77, 86, 110, 112, 113, 115], "resembl": 78, "reset": 49, "reset_index": [63, 69, 70], "reshap": [57, 58, 59, 62], "reshape2": 50, "residu": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 22, 42, 76, 101, 103, 108, 109], "resolut": [52, 84], "resourc": 67, "resourcewis": 67, "respect": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 51, 55, 70, 71, 75, 83, 85, 86, 101, 109, 115], "respons": [19, 52, 84], "rest": 85, "restart": 111, "restrict": 67, "restructur": 114, "restud": 63, "result": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 47, 48, 49, 52, 55, 57, 58, 59, 61, 62, 63, 66, 67, 73, 75, 76, 77, 78, 80, 84, 86, 87, 90, 91, 101, 103, 106, 112, 114], "result_iivm": 51, "result_irm": 51, "result_plr": 51, "retain": [41, 42], "retina": 72, "retir": [51, 70, 71, 76], "return": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 48, 49, 50, 52, 57, 60, 65, 67, 68, 69, 72, 73, 74, 76, 77, 78, 79, 84, 87, 101, 103, 114], "return_count": [55, 67], "return_tune_r": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "return_typ": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 25, 26, 28, 29, 30, 31, 32, 48, 51, 52, 57, 61, 67, 68, 70, 71, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 100, 101, 106, 112, 115], "rev": 50, "reveal": 66, "review": [28, 63, 113], "revist": [50, 69], "rf": 75, "rho": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 43, 55, 66, 75, 76, 77, 101, 103, 106, 109, 115], "rho_val": 77, "richter": [52, 84, 110, 112], "riesz": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 22, 76, 101, 103, 104, 105, 106, 108, 109], "riesz_rep": [101, 106], "right": [25, 26, 28, 29, 32, 48, 50, 57, 67, 69, 70, 71, 72, 74, 75, 77, 80, 85, 87, 90, 91, 100, 101, 102, 104, 105, 107], "rightarrow_": [48, 57, 80], "risk": [6, 82, 114], "ritov": 113, "rival": 69, "rival_ind": 69, "rmd": 49, "rmse": [49, 61, 67, 68, 71, 76, 78, 84, 85, 87, 100, 112, 114], "rmse_dml_ml_l_fullsampl": 68, "rmse_dml_ml_l_lesstim": 68, "rmse_dml_ml_l_onfold": 68, "rmse_dml_ml_l_untun": 68, "rmse_dml_ml_m_fullsampl": 68, "rmse_dml_ml_m_lesstim": 68, "rmse_dml_ml_m_onfold": 68, "rmse_dml_ml_m_untun": 68, "rmse_oos_ml_l": 68, "rmse_oos_ml_m": 68, "rmse_oos_onfolds_ml_l": 68, "rmse_oos_onfolds_ml_m": 68, "rnorm": [47, 52, 81, 84, 100, 112], "robin": [19, 20, 30, 50, 63, 69, 80, 110, 113], "robinson": [48, 57, 80], "robject": 69, "robu": [64, 65], "robust": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 29, 35, 49, 55, 66, 75, 76, 77, 85, 101, 106, 113, 115], "roc\u00edo": 113, "role": [7, 10, 48, 57, 68, 80, 115], "romano": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 100], "root": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 34, 63, 80, 84, 87, 113], "rotat": [68, 75], "roth": [75, 85, 113], "rough": [77, 115], "roughli": 77, "round": [51, 55, 67, 72, 77], "rout": [37, 38, 41, 42], "row": [48, 51, 53, 58, 59, 62, 68, 69, 73, 81, 86, 112, 115], "row_index": 65, "rownam": 50, "rowv": 50, "roxygen2": 114, "royal": [77, 113], "rpart": [51, 52, 84], "rpart_cv": 52, "rprocess": 67, "rpy2": 69, "rpy2pi": 69, "rsmp": [52, 84, 86], "rsmp_tune": [52, 84], "rssb": 77, "rtype": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "ruben": 113, "ruiz": [47, 56], "rule": [49, 83], "run": [49, 75, 85, 111, 114], "runif": 47, "runtime_learn": 52, "rv": [55, 66, 76, 77, 101, 106, 115], "rva": [55, 66, 76, 77, 101, 106, 115], "rvert": 63, "rvert_": 63, "s1": 68, "s2": 68, "s_": [29, 50, 69, 85], "s_1": 30, "s_2": 30, "s_col": [7, 10, 75, 78, 85], "s_i": [32, 75, 78, 85], "s_x": [29, 50, 69], "safeguard": [61, 84], "sake": [51, 70, 77, 115], "same": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 27, 39, 48, 50, 57, 58, 59, 66, 67, 69, 71, 73, 75, 76, 77, 78, 84, 87, 90, 91, 100, 101, 107, 114], "samii": 72, "sampl": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 29, 32, 35, 41, 42, 47, 49, 50, 52, 56, 61, 64, 65, 67, 69, 71, 73, 76, 82, 84, 100, 112, 113, 114], "sample_weight": [35, 41, 42, 75], "sant": [8, 9, 21, 22, 23, 27, 49, 61, 85, 113], "sara": 113, "sasaki": [29, 50, 69, 113], "satisfi": [78, 84, 87, 100], "save": [48, 51, 57, 64, 65, 67, 68, 70, 71, 84, 101, 106, 115], "savefig": 57, "saveguard": 67, "saver": [51, 70, 71], "scalar": 85, "scale": [48, 50, 60, 62, 72, 74, 77, 100, 101, 109], "scale_color_manu": 48, "scale_fill_manu": [48, 50], "scatter": [55, 62, 64, 65, 72, 75, 77], "scatterplot": 55, "scenario": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 55, 66, 76, 77, 85, 101, 106, 115], "scene": [58, 59, 63], "scene_camera": 63, "schaefer": 72, "schedul": 114, "scheme": [50, 69, 84, 86, 110], "schneider": 52, "schratz": [52, 84, 110, 112], "scienc": [31, 47, 56, 72, 113], "scikit": [67, 70, 84, 110, 112, 114, 115], "scipi": 57, "score": [0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 33, 34, 35, 36, 41, 42, 47, 49, 50, 51, 52, 53, 58, 59, 60, 61, 63, 66, 67, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 109, 110, 114, 115], "scoring_method": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "script": 111, "sd": 47, "se": [48, 50, 57, 76, 80, 84, 86, 100, 101, 106, 113, 115], "se_df": 50, "se_dml": [48, 57, 80], "se_dml_po": [48, 57, 80], "se_nonorth": [48, 57], "se_orth_nosplit": [48, 57], "se_orth_po_nosplit": [48, 57], "seaborn": [53, 55, 57, 61, 67, 69, 70, 71, 77, 78], "search": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 34, 84, 87], "search_mod": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 84], "searchabl": 51, "second": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 29, 48, 50, 52, 57, 67, 68, 69, 79, 80, 86, 100, 101, 103, 109, 112], "secondari": 55, "section": [9, 23, 49, 50, 51, 52, 66, 68, 69, 71, 77, 104, 114], "secur": 72, "see": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 26, 32, 33, 34, 39, 41, 42, 47, 49, 50, 51, 52, 55, 56, 58, 59, 61, 65, 68, 69, 71, 72, 73, 75, 76, 77, 84, 85, 86, 87, 89, 93, 94, 95, 96, 99, 101, 103, 106, 109, 111, 112, 114], "seed": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 27, 35, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 100, 101, 106, 112, 115], "seek": 72, "seem": [49, 51, 66, 70, 71, 115], "seen": [64, 65], "sel_cols_chiang": 69, "select": [7, 10, 18, 27, 28, 32, 63, 67, 75, 77, 79, 82, 84, 113, 114, 115], "selected_coef": 67, "selected_featur": [52, 84], "selected_learn": 67, "self": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 39, 40, 41, 42, 67, 68, 115], "selfref": 51, "semenova": [58, 59, 113], "semi": 80, "semiparametr": 19, "sens": [76, 77], "sensemakr": [101, 103], "sensit": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 43, 82, 83, 103, 106, 109, 114], "sensitivity_analysi": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 55, 66, 76, 77, 101, 106, 115], "sensitivity_benchmark": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 55, 66, 76, 77, 101, 103], "sensitivity_el": [101, 106], "sensitivity_param": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 76, 77, 101, 103, 106], "sensitivity_plot": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 55, 66, 76, 77, 101, 106], "sensitivity_summari": [55, 66, 76, 77, 101, 106, 115], "sensitvity_benchmark": 55, "sensiv": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "senstiv": [101, 108], "sep": 48, "separ": [72, 76, 84, 85, 114], "seper": [68, 75, 76, 86, 100, 101, 103], "seq_len": [48, 80], "sequenti": 20, "seri": [65, 77, 113], "serv": [81, 112, 114], "serverless": [113, 114], "servic": 72, "set": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 29, 30, 31, 40, 41, 42, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 78, 79, 80, 81, 83, 85, 86, 87, 88, 90, 91, 93, 100, 101, 102, 103, 107, 108, 111, 112, 114, 115], "set_as_param": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "set_config": [41, 42], "set_fit_request": [41, 42], "set_fold_specif": 84, "set_index": 70, "set_ml_nuisance_param": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 51, 53, 70, 84, 114], "set_param": [37, 38, 41, 42, 68, 84], "set_sample_split": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 67, 86, 114], "set_score_request": [41, 42], "set_styl": [70, 71], "set_text": 67, "set_threshold": [48, 49, 50, 51, 52, 79, 84, 85, 86, 87, 100, 112], "set_tick": 69, "set_ticklabel": 69, "set_titl": [55, 68, 69, 75], "set_x_d": [7, 10], "set_xlabel": [55, 57, 68, 69, 75], "set_xlim": 57, "set_xtick": 72, "set_xticklabel": 72, "set_ylabel": [55, 68, 69, 72, 75], "set_ylim": [60, 68, 69, 74], "setdiff": 114, "setdiff1d": 69, "setminu": [50, 69, 100], "settings_l": 68, "settings_m": 68, "setup": [111, 114], "seven": [50, 69], "sever": [43, 51, 52, 67, 68, 70, 71, 76, 77, 80, 84, 115], "shape": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 39, 40, 41, 42, 55, 58, 59, 62, 64, 65, 67, 69, 70, 73, 75, 76, 77, 84, 85], "share": [50, 51, 69, 70], "sharma": [77, 113], "sharp": 35, "shock": [50, 69], "short": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 76, 77, 101, 103, 113, 114, 115], "shortcut": 51, "shortli": [50, 52, 69, 84], "shota": 113, "should": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 34, 41, 42, 51, 55, 64, 65, 67, 70, 75, 76, 78, 81, 83, 84, 85, 100, 101, 103, 110], "show": [47, 48, 50, 53, 55, 56, 57, 58, 59, 61, 63, 66, 67, 68, 69, 72, 75, 77, 78, 80, 101, 108, 111], "showcas": 73, "showlabel": 77, "showlegend": 77, "shown": [47, 56, 72, 112], "showscal": [58, 59, 63], "shrink": 75, "shuffl": 86, "side": [75, 85, 101, 106], "sigma": [18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 48, 50, 57, 69, 78, 80, 83, 86, 100, 101, 103, 106, 108, 109], "sigma2": [101, 106], "sigma_": [22, 23, 25, 26, 28, 29, 30, 32, 48, 50, 57, 69, 80], "sigma_0": [101, 109], "sigma_j": 100, "sigmoid": 72, "sign": 77, "signal": [39, 40], "signatur": [11, 12, 13, 14, 15, 16, 17, 87], "signif": [47, 49, 50, 51, 52, 84, 85, 86, 87, 100, 112, 115], "signific": [47, 50, 51, 52, 55, 66, 70, 73, 75, 76, 77, 84, 85, 86, 87, 100, 101, 106, 112, 115], "silverman": [13, 16, 17], "sim": [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 48, 49, 50, 57, 60, 62, 69, 73, 74, 78, 80, 85], "similar": [22, 27, 49, 52, 58, 59, 66, 68, 71, 75, 76, 77, 85], "similarli": 68, "simpl": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 24, 41, 42, 49, 52, 58, 59, 64, 65, 66, 73, 77, 82, 85, 101, 103], "simplest": 83, "simpli": [52, 61, 115], "simplic": [51, 67, 70, 73, 77], "simplif": [101, 104], "simplifi": [72, 77, 83, 101, 108], "simul": [21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 48, 52, 57, 58, 59, 60, 63, 64, 65, 74, 75, 77, 78, 80, 84, 100, 112], "simul_data": 18, "simulaten": 85, "simulation_run": 63, "simult": 49, "simultan": [82, 115], "sin": [24, 27, 31, 58, 59, 62, 64, 65], "sinc": [21, 22, 41, 51, 55, 61, 62, 64, 65, 66, 67, 68, 70, 72, 78, 84, 85, 101, 106, 107, 111, 114], "singl": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 61, 64, 65, 71, 72, 84, 100], "single_learner_pipelin": 84, "singleton": 86, "sinh": 31, "sipp": [51, 70, 71], "site": [69, 70, 77], "situat": [50, 69], "six": 50, "sixth": 69, "size": [18, 48, 50, 51, 52, 57, 60, 62, 63, 66, 67, 68, 70, 72, 73, 74, 77, 79, 81, 84, 85, 86, 87, 100, 112, 115], "sizeabl": 77, "skill": 113, "sklearn": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 31, 35, 40, 41, 42, 53, 55, 56, 57, 58, 59, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 78, 79, 83, 84, 85, 86, 87, 100, 101, 106, 112, 115], "skotara": 77, "slide": 72, "slightli": [62, 64, 65, 66, 67, 83, 87, 90, 91, 101, 103], "sligthli": [8, 9], "slow": [48, 57, 80], "slower": [48, 57, 80], "small": [24, 61, 62, 73, 78, 85, 101, 103, 107], "smaller": [51, 61, 64, 65, 66, 68, 70, 75, 77, 85, 115], "smallest": 67, "smpl": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 48, 50, 57, 67, 69, 86, 87], "smpls_cluster": [50, 69], "smsg": 70, "sn": [53, 55, 57, 61, 67, 69, 70, 71, 77, 78], "so": [41, 42, 47, 51, 52, 56, 61, 68, 70, 72, 77, 78, 84, 100, 115], "social": [72, 113], "societi": [50, 69, 77, 113], "softwar": [52, 84, 110, 112, 113, 114], "solari": 114, "sole": 77, "solut": [79, 83, 87], "solv": [33, 50, 69, 83, 84, 100], "solver": [70, 78, 85], "some": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 41, 42, 51, 52, 53, 61, 62, 67, 68, 70, 71, 75, 76, 78, 83, 84, 85, 111, 114], "sometim": 67, "sonabend": [52, 84], "sophist": 84, "sort": [70, 85], "sort_valu": 55, "sourc": [52, 84, 112, 114], "sourcefileload": 63, "sp": 49, "space": [50, 69, 84], "spars": [63, 84, 100, 112, 113], "sparsiti": 113, "spec": 113, "special": [50, 69, 85], "specif": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 34, 35, 50, 51, 55, 67, 69, 70, 77, 81, 82, 83, 84, 85, 86, 87, 93, 100, 106, 109, 110, 112], "specifi": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 35, 47, 50, 51, 52, 55, 56, 58, 59, 60, 61, 64, 65, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 85, 88, 93, 111, 112, 114, 115], "specifii": 71, "speed": [5, 17, 67], "speedup": 67, "spefici": 11, "spindler": [28, 77, 110, 113, 114], "spine": [70, 71], "spline": [58, 59, 83], "spline_basi": [58, 59, 83], "spline_grid": [58, 59], "split": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 47, 50, 52, 61, 67, 69, 71, 73, 76, 78, 82, 83, 84, 85, 87, 100, 112, 114], "split_sampl": 67, "sponsor": [51, 70, 71], "sprintf": 48, "sq_error": 63, "sqrt": [21, 22, 23, 26, 27, 48, 50, 52, 53, 57, 60, 69, 74, 80, 86, 100, 101, 103, 112], "squar": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 42, 51, 63, 70, 84, 85, 101, 109, 113], "squarederror": [51, 70, 115], "squeez": [60, 61, 74, 78], "src": 70, "ssm": [7, 10, 32, 82], "ssrn": 25, "stabil": 66, "stabl": [47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 110], "stack": [52, 84], "stackingclassifi": 75, "stackingregressor": 75, "stacklrn": 52, "stackrel": 85, "stage": [35, 58, 59, 64, 65, 73, 75, 84, 85, 114, 115], "standard": [23, 49, 52, 60, 64, 65, 75, 85, 86, 87, 100, 101, 106, 109, 114, 115], "standard_norm": [81, 84, 100, 112], "standardscal": 70, "star": 85, "start": [49, 51, 52, 58, 59, 63, 66, 67, 68, 69, 70, 74, 77, 85, 110, 115], "stat": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 57, 75, 81, 84, 85, 100, 110, 113], "stat_bin": 48, "stat_dens": 51, "state": 115, "stationar": 61, "stationari": 85, "statist": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 29, 32, 43, 50, 69, 76, 77, 100, 101, 106, 110, 112, 113, 114, 115], "statsmodel": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 39, 75], "statu": [49, 51, 61, 70, 72, 75, 78], "std": [6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 47, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 64, 65, 66, 68, 69, 70, 71, 72, 74, 76, 77, 78, 83, 84, 85, 86, 87, 100, 112, 115], "stefan": 113, "step": [48, 51, 52, 57, 64, 65, 66, 70, 73, 80, 84, 85, 100, 110, 115], "stepdown": 100, "stick": [51, 70], "still": [58, 59, 61, 64, 65, 66, 71, 75, 76, 78, 84], "stochast": [14, 15, 85, 112], "stock": [51, 70, 71], "store": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 79, 84, 86, 87, 100, 101, 106, 114], "store_model": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 68], "store_predict": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 49, 70, 73], "stori": [77, 113], "str": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 35, 39, 41, 42, 51, 55, 64, 65, 74, 75, 83, 85, 114], "straightforward": [64, 65, 67, 83], "strategi": [72, 77, 85, 115], "stratifi": 67, "stratum": 72, "strength": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 76, 77, 101, 103, 106, 108], "strictli": 85, "string": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 83, 100, 101, 106, 112, 114], "string_label": 72, "strong": [78, 101, 103], "stronger": [100, 115], "structur": [19, 20, 30, 50, 51, 63, 69, 70, 78, 80, 84, 110, 113, 115], "student": 113, "studi": [32, 50, 51, 63, 68, 69, 70, 71, 76, 112, 115], "style": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 68, 114], "styler": 114, "styliz": 77, "sub": [41, 42, 50, 69], "subclass": 114, "subfold": 84, "subgroup": [11, 51, 70, 114], "subject": [50, 69], "submiss": 114, "subobject": [37, 38, 41, 42], "subplot": [50, 55, 57, 58, 59, 60, 62, 64, 65, 67, 68, 69, 70, 71, 72, 74, 75], "subplots_adjust": 67, "subpopul": 85, "subsampl": [52, 67], "subscript": [101, 103], "subsequ": [50, 69], "subset": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 41, 50, 67, 69, 73, 79, 83, 84, 101, 103], "subseteq": 83, "substanti": [51, 70, 72], "substract": 100, "subtract": 100, "sudo": 111, "suffic": 77, "suffici": [67, 68, 77], "suggest": [50, 51, 69, 70, 77, 114], "suitabl": [58, 59, 78], "sum": [42, 50, 51, 69, 70, 71, 74, 75, 83, 100], "sum_": [36, 48, 50, 57, 69, 75, 79, 80, 83, 85, 100], "sum_i": 72, "sum_oth": 69, "sum_riv": 69, "summar": [49, 55, 72, 77, 79, 101, 106], "summari": [6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 47, 49, 50, 52, 53, 55, 56, 58, 59, 60, 61, 64, 65, 66, 69, 71, 74, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 100, 101, 112, 114, 115], "summary_result": 51, "suppli": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 58, 59, 64, 65, 66, 73, 83, 101, 102, 103, 106], "support": [11, 24, 35, 49, 50, 67, 69, 73, 75, 84, 85, 115], "support_s": [24, 58, 59, 64, 65, 73], "support_t": 73, "support_w": 73, "suppos": 77, "suppress": [49, 51, 52], "suppresswarn": 48, "suprema": 100, "suptitl": [60, 67, 68, 71, 74], "supxlabel": [60, 71, 74], "supylabel": [60, 71, 74], "sure": [55, 84, 114], "surfac": [58, 59, 63], "surpress": [50, 112], "survei": [51, 70, 71, 115], "susan": 113, "sven": [77, 110, 113], "svenk": 69, "svenklaassen": [110, 114], "svg": [48, 57], "switch": [48, 57, 77, 80], "symbol": 77, "symmetr": 31, "syntax": [75, 85], "synthet": [24, 36, 47, 56, 58, 59, 60, 64, 65, 68, 73, 74], "syrgkani": [77, 113], "system": 113, "szita": 113, "t": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 27, 35, 41, 42, 47, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 83, 84, 85, 86, 87, 91, 100, 101, 104, 112, 115], "t_1_start": 67, "t_1_stop": 67, "t_2_start": 67, "t_2_stop": 67, "t_3_start": 67, "t_3_stop": 67, "t_col": [7, 9, 10, 85], "t_df": 73, "t_diff": 62, "t_dml": 48, "t_i": [61, 73, 75, 85], "t_idx": 62, "t_nonorth": 48, "t_orth_nosplit": 48, "t_sigmoid": 73, "t_stat": 100, "tabl": [48, 50, 51, 52, 55, 79, 81, 84, 85, 86, 87, 100, 112, 115], "tabular": [67, 81, 100, 112, 115], "taddi": 113, "take": [11, 12, 14, 15, 21, 22, 24, 58, 59, 60, 61, 62, 63, 64, 65, 67, 71, 74, 75, 76, 78, 79, 83, 84, 85, 87, 88, 93, 101, 102, 107, 108, 112], "taken": [51, 70, 71, 115], "taker": [11, 114], "talk": 115, "target": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 33, 34, 41, 42, 47, 50, 51, 52, 58, 59, 67, 69, 83, 84, 85, 86, 87, 94, 99, 100, 101, 107, 109, 110, 112, 114, 115], "task": [47, 68, 81, 86, 115], "task_typ": 114, "tau": [36, 60, 62, 71, 72, 74, 75, 83, 85, 87, 89, 94, 99], "tau_": [72, 75, 85], "tau_0": [75, 85], "tau_1": 72, "tau_2": 72, "tau_vec": [60, 71, 74], "tax": [51, 70, 71], "te": [49, 58, 59, 73], "techniqu": [48, 57, 80, 86, 115], "templat": 114, "ten": 68, "tend": [51, 70, 71, 85], "tensor": [58, 59], "tenth": 113, "term": [48, 50, 51, 52, 57, 62, 63, 69, 70, 72, 77, 80, 85, 110, 115], "termin": [52, 84], "terminatorev": 52, "test": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 25, 41, 42, 47, 48, 49, 50, 51, 52, 57, 66, 69, 77, 80, 84, 85, 86, 87, 100, 112, 113, 114, 115], "test_id": [50, 86], "test_ind": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "test_set": 86, "test_siz": 57, "text": [21, 22, 23, 25, 27, 35, 36, 50, 51, 60, 63, 72, 73, 74, 75, 77, 83, 85, 86], "textbf": [79, 84, 115], "textposit": 77, "textrm": [101, 102, 103, 107, 108, 109], "tg": [52, 53, 81, 112], "th": [50, 69], "than": [12, 48, 49, 51, 57, 63, 67, 70, 71, 72, 75, 76, 77, 80, 85, 101, 106, 115], "thank": [49, 51, 52, 70, 114], "thatw": 62, "thei": [49, 51, 62, 64, 65, 70, 72, 85, 101, 109], "them": [51, 52, 58, 59, 60, 66, 68, 70, 74, 85], "theme": [50, 51], "theme_minim": [48, 51], "theorem": [101, 109], "theoret": [67, 77, 86, 113], "theori": [83, 113], "therebi": [50, 52, 69, 115], "therefor": [55, 72, 75, 76, 86, 87, 101, 108], "theta": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 25, 26, 27, 29, 31, 32, 33, 34, 48, 50, 52, 55, 57, 61, 62, 63, 66, 67, 69, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 106, 108, 109, 112, 115], "theta_": [55, 75, 77, 83, 85, 100, 101, 109], "theta_0": [11, 12, 14, 15, 24, 48, 50, 51, 55, 57, 58, 59, 63, 64, 65, 69, 70, 77, 78, 80, 83, 85, 87, 94, 99, 100, 101, 102, 107, 109, 112], "theta_dml": [48, 57, 80], "theta_dml_po": [48, 57, 80], "theta_initi": 57, "theta_nonorth": [48, 57], "theta_orth_nosplit": [48, 57], "theta_orth_po_nosplit": [48, 57], "theta_resc": 48, "theta_t": 62, "thi": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 34, 37, 38, 40, 41, 42, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 83, 84, 85, 86, 87, 89, 90, 91, 94, 99, 100, 101, 102, 103, 106, 107, 110, 111, 112, 113, 114, 115], "think": 52, "third": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 48, 57, 69, 80, 86], "thirion": [110, 112], "this_df": [63, 70], "this_split_ind": 69, "those": [49, 51, 70, 71], "though": [47, 56, 72], "thread": [72, 84], "three": [50, 52, 64, 65, 111, 114], "threshold": [4, 6, 8, 9, 11, 12, 13, 16, 17, 18, 75, 77, 85], "through": [49, 60, 64, 65, 74, 75, 84, 85], "throughout": 66, "thu": [68, 75, 83, 85], "tibbl": 49, "tick_param": 75, "tight": 57, "tight_layout": [68, 69, 75], "tighter": 75, "tild": [21, 22, 23, 27, 50, 69, 72, 79, 83, 86, 87, 94, 95, 96, 99, 100, 101, 108, 109], "time": [7, 8, 10, 28, 29, 48, 49, 50, 51, 57, 61, 62, 63, 64, 65, 69, 70, 71, 75, 76, 77, 78, 85, 114, 115], "time_budget": 68, "time_df": 62, "time_period": 62, "titiunik": [85, 113], "titl": [50, 51, 55, 58, 59, 60, 63, 64, 65, 67, 68, 69, 70, 71, 72, 74, 75, 77, 110], "tmp": 65, "tname": 49, "tnr": [52, 84], "to_fram": 73, "to_numpi": [60, 66, 71, 74], "todo": [50, 53], "toeplitz": 63, "togeth": [64, 65, 100], "toler": 69, "tomasz": [113, 114], "toml": 114, "too": 67, "tool": [49, 52, 76, 115], "top": [50, 67, 69, 70, 71, 75, 77, 85, 110], "total": [42, 51, 68, 70], "tpot": 68, "tracker": 110, "tradit": 100, "train": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 41, 42, 48, 50, 52, 57, 58, 59, 60, 64, 65, 67, 69, 73, 74, 79, 80, 86], "train_id": [50, 86], "train_ind": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "train_set": 86, "train_test_split": 57, "transact": 113, "transform": [21, 22, 36, 72, 77, 115], "translat": 63, "transpos": 62, "treament": 73, "treat": [12, 23, 49, 55, 61, 62, 66, 73, 75, 77, 83, 85, 100, 115], "treat1_param": 72, "treat2_param": 72, "treat_var": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 84], "treatment": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 30, 35, 47, 49, 50, 52, 53, 55, 56, 61, 62, 63, 66, 67, 68, 69, 73, 75, 76, 77, 78, 80, 81, 82, 84, 86, 87, 88, 89, 90, 91, 93, 94, 99, 100, 101, 102, 106, 108, 110, 112, 113, 114, 115], "treatment_df": 62, "treatment_effect": [24, 58, 59], "treatment_level": [4, 5, 55, 85], "treatment_var": [7, 10], "tree": [12, 40, 51, 52, 61, 62, 67, 70, 79, 82, 84, 85, 86, 87, 100, 112, 114], "tree_param": [12, 40], "tree_summari": 70, "trees_class": [51, 70], "trend": [49, 61, 62, 69, 85, 113], "tri": [63, 101, 103], "triangular": [35, 75, 85], "trim": [4, 6, 8, 9, 11, 12, 13, 16, 17, 18, 51, 70, 71, 77], "trimming_rul": [4, 5, 6, 8, 9, 11, 12, 13, 16, 17, 18, 71], "trimming_threshold": [4, 5, 6, 8, 9, 11, 12, 13, 16, 17, 18, 51, 58, 70, 71, 73, 74, 77], "trm": [52, 84], "true": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 27, 32, 35, 36, 37, 38, 41, 42, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 84, 85, 86, 87, 88, 89, 94, 95, 96, 99, 100, 101, 104, 105, 109, 112, 115], "true_effect": [58, 59, 62, 64, 65], "true_gatet_effect": 66, "true_group_effect": 66, "true_tau": 75, "truncat": [4, 5, 6, 8, 9, 11, 12, 13, 16, 17, 18, 71], "try": [67, 76], "tune": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 63, 75, 82, 85, 110, 112, 114], "tune_on_fold": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 84], "tune_r": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "tune_set": [52, 84], "tuned_model": 68, "tuner": 84, "tunergridsearch": 52, "tupl": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "turn": 77, "turrel": 31, "tutori": 51, "tw": [70, 71], "twice": 85, "twinx": 55, "two": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 47, 48, 51, 52, 56, 57, 60, 61, 67, 68, 70, 71, 72, 73, 74, 76, 77, 79, 80, 83, 84, 85, 86, 87, 94, 100, 115], "twoclass": 52, "twoearn": [51, 70, 71, 76, 115], "type": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 24, 27, 35, 36, 37, 38, 39, 40, 41, 42, 43, 48, 49, 50, 51, 52, 57, 67, 68, 69, 75, 77, 80, 84, 85, 87, 97, 98, 100, 101, 108, 114, 115], "typic": [65, 85, 110], "u": [11, 12, 13, 16, 17, 21, 22, 23, 24, 26, 32, 42, 48, 49, 50, 51, 55, 57, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 74, 76, 77, 80, 85, 101, 103, 111, 115], "u_hat": [48, 57, 87], "u_i": [25, 28, 31, 32], "u_t": 23, "uehara": 113, "uhash": 52, "ulf": 113, "unambigu": 77, "uncertainti": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 64, 65, 75, 76, 101, 106, 115], "unchang": [41, 42], "uncondit": [51, 70, 115], "unconfounded": [77, 113], "under": [18, 48, 51, 57, 61, 70, 73, 75, 77, 80, 85, 100, 113], "underbrac": [48, 57, 62, 80, 83], "underfit": 68, "underli": [21, 27, 51, 52, 55, 64, 65, 72, 73, 85, 101, 103, 115], "underlin": [50, 69], "underset": [75, 85], "understand": 77, "undesir": 84, "unevenli": 86, "uniform": [23, 35, 36, 56, 58, 59, 60, 62, 73, 74, 100], "uniform_averag": 42, "uniformli": [60, 71, 100], "uniqu": [47, 55, 56, 67, 75, 87, 101, 109], "unique_label": 68, "unit": [48, 49, 61, 62, 66, 75, 78, 85, 87, 90, 91, 114], "univari": [24, 58, 59], "univers": 113, "unknown": 85, "unlik": [51, 70, 71, 77], "unobserv": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 47, 51, 56, 70, 71, 76, 77, 85, 101, 103, 109, 115], "unpen": 49, "unstabl": [101, 103], "unter": [50, 51, 52], "untest": 77, "until": [85, 114], "untreat": [77, 85], "up": [5, 17, 51, 63, 67, 68, 70, 71, 76, 77, 84, 85, 86, 101, 103, 111, 114, 115], "upcom": 114, "updat": [41, 42, 50, 65, 69, 113, 114], "update_layout": [58, 59, 63, 75, 77], "update_trac": [58, 59], "upload": 114, "upon": [87, 114], "upper": [51, 52, 55, 57, 60, 62, 66, 71, 74, 75, 76, 77, 84, 101, 106, 109, 115], "upper_bound": [58, 59], "upsilon": 78, "upsilon_i": 78, "upward": [51, 70, 71, 77], "upweight": 72, "url": [63, 110, 113], "us": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 39, 41, 42, 48, 50, 51, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 85, 86, 87, 90, 91, 100, 101, 103, 106, 107, 108, 109, 110, 111, 112, 114, 115], "usa": 113, "usabl": 67, "usag": [49, 53, 55, 61, 66, 69, 70, 71, 76, 78, 81, 112, 114], "use_label_encod": [70, 115], "use_other_treat_as_covari": [7, 10, 81], "usecolormap": [58, 59], "user": [33, 34, 37, 38, 41, 42, 48, 49, 50, 51, 52, 55, 57, 66, 67, 69, 70, 75, 76, 83, 84, 85, 87, 100, 110, 111, 112, 114, 115], "user_guid": 65, "userwarn": [70, 77], "usual": [50, 58, 59, 61, 67, 69, 75, 76, 77, 83, 84, 86, 101, 109], "util": [0, 34, 67, 68, 72, 75, 84, 85, 114], "v": [11, 12, 14, 15, 19, 20, 26, 28, 29, 30, 32, 42, 48, 50, 51, 55, 57, 66, 69, 70, 72, 75, 79, 80, 83, 85, 100, 110, 112, 113, 114, 115], "v108": 110, "v12": [110, 112], "v22": 52, "v23": 110, "v_": [29, 50, 69, 85], "v_i": [25, 26, 30, 31, 32, 48, 57, 80, 85], "v_j": 100, "val": [26, 86, 113], "val_list": 63, "valid": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 25, 48, 49, 50, 51, 57, 60, 61, 67, 68, 69, 70, 71, 74, 80, 82, 83, 84, 86, 87, 89, 94, 99, 101, 103, 113, 115], "valu": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 41, 42, 43, 47, 48, 49, 50, 51, 52, 55, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76, 77, 79, 82, 84, 85, 86, 89, 94, 95, 96, 99, 100, 101, 103, 106, 109, 112, 114, 115], "value_count": 70, "van": 113, "vanderpla": [110, 112], "vanish": [48, 57, 80], "var": [21, 22, 23, 27, 50, 69, 72, 75, 101, 102, 103, 107, 108, 109], "var_ep": 77, "varepsilon": [11, 21, 22, 29, 50, 69, 78, 83, 85], "varepsilon_": [29, 50, 69], "varepsilon_0": 23, "varepsilon_1": 23, "varepsilon_d": [22, 27], "varepsilon_i": [27, 28, 60, 74, 78], "vari": [51, 62, 67, 70, 72, 77], "variabl": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 35, 50, 51, 52, 53, 55, 61, 63, 66, 68, 69, 70, 71, 75, 76, 77, 78, 81, 83, 84, 85, 86, 87, 100, 101, 103, 106, 109, 112, 113, 114, 115], "varianc": [33, 34, 50, 52, 69, 75, 76, 77, 82, 85, 86, 101, 103, 106, 107, 108, 109, 112], "variant": 49, "variat": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 22, 76, 101, 103, 109], "variou": [49, 68, 77, 84, 115], "varoquaux": [110, 112], "vasili": [77, 113], "vector": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 24, 25, 26, 28, 29, 31, 32, 47, 50, 51, 56, 61, 64, 65, 66, 69, 70, 73, 78, 85, 100, 112, 114], "venv": 111, "verbos": [51, 57, 62, 67, 68, 75, 77], "veri": [49, 50, 52, 66, 67, 69, 77, 87, 110], "verifi": 72, "versa": [67, 72, 101, 106], "version": [21, 41, 42, 50, 51, 52, 77, 79, 83, 100, 101, 102, 104, 105, 107, 114], "versoin": 77, "versu": 65, "vertic": [50, 55, 69], "via": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 34, 49, 60, 61, 62, 63, 64, 65, 66, 67, 75, 76, 78, 79, 81, 82, 83, 84, 85, 86, 89, 96, 100, 101, 103, 106, 109, 110, 111, 112, 113, 114, 115], "viabl": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "vice": [67, 72, 101, 106], "victor": [63, 77, 86, 110, 113], "view": 65, "vignett": [49, 114], "villa": [47, 56], "violet": [60, 71, 74], "vira": 113, "virtual": 111, "virtualenv": 111, "visibl": [71, 75, 77], "visit": [110, 115], "visual": [50, 66, 68, 69, 75], "vol": 49, "volum": [77, 110], "voluntari": 72, "vv740": 69, "vv760g": 69, "w": [19, 20, 21, 22, 23, 30, 33, 34, 41, 42, 50, 63, 69, 72, 73, 79, 80, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 112], "w24678": 86, "w30302": 113, "w_": [23, 50, 69, 73, 85], "w_1": [23, 73], "w_2": [23, 73], "w_3": 23, "w_4": 23, "w_df": 73, "w_i": [32, 61, 73, 75, 79, 83, 85, 86, 87, 100], "wa": [50, 62, 68, 69, 77, 114], "wager": 113, "wai": [51, 67, 68, 70, 77, 84, 87, 111], "wander": 31, "wang": 113, "want": [47, 50, 51, 52, 56, 60, 61, 67, 69, 74, 75, 84, 85, 110, 111, 113], "warn": [47, 48, 49, 50, 51, 52, 57, 70, 77, 79, 84, 85, 86, 87, 100, 112, 114], "wayon": 50, "we": [12, 40, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 92, 100, 101, 103, 109, 111, 112, 114, 115], "weak": [101, 103, 113], "wealth": [19, 76], "websit": [51, 52, 84, 110], "wedg": [50, 69], "week": 114, "wei": 100, "weight": [4, 5, 6, 11, 12, 13, 16, 17, 18, 41, 42, 50, 51, 52, 55, 66, 69, 70, 75, 78, 82, 84, 85, 87, 88, 93, 100, 101, 102, 107, 114], "weights_bar": [4, 12], "weiss": [110, 112], "well": [7, 10, 41, 42, 48, 50, 57, 63, 67, 68, 69, 79, 80, 81, 86, 111, 112], "were": [51, 70, 71, 78, 115], "what": [49, 63, 67], "when": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 37, 38, 41, 42, 51, 61, 65, 70, 72, 85, 87, 100, 110, 111, 112, 114], "whenev": [51, 70], "whera": [101, 107], "where": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 39, 40, 42, 47, 48, 50, 51, 55, 56, 57, 60, 61, 62, 66, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 107, 109, 111, 112, 114, 115], "wherea": [24, 55, 61, 77, 78, 87, 93, 101, 102, 115], "whether": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 27, 32, 35, 39, 51, 62, 67, 70, 71, 75, 77, 81, 84, 85, 101, 103, 114], "which": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 24, 34, 41, 47, 48, 49, 51, 52, 54, 55, 56, 57, 61, 63, 65, 66, 67, 68, 70, 71, 73, 75, 76, 77, 78, 80, 81, 83, 84, 85, 87, 100, 101, 102, 103, 106, 107, 109, 111, 114, 115], "while": [47, 56, 85], "white": [50, 64, 65, 69, 77], "whitegrid": [70, 71], "whitnei": [77, 113], "who": [49, 51, 70, 77], "whole": [48, 57, 61, 75, 80, 84, 101, 103], "whom": 85, "widehat": 85, "width": [48, 50, 58, 59, 63], "wiki": 114, "wiksel": 113, "wild": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 100], "window": 111, "wise": [64, 65], "wish": 111, "within": [35, 50, 64, 65, 69, 73, 75], "without": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 27, 35, 47, 48, 56, 57, 67, 68, 77, 80, 82, 84, 85, 101, 103, 111, 114], "wolf": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 100], "won": 77, "word": [35, 75, 85, 114, 115], "work": [37, 38, 41, 42, 54, 55, 65, 66, 67, 72, 76, 84, 85, 100, 111, 113], "workflow": [110, 114], "workspac": 70, "world": 113, "worri": 77, "wors": 42, "would": [42, 49, 51, 52, 58, 59, 63, 67, 70, 71, 75, 76, 77, 83, 84, 101, 109, 115], "wrapper": [49, 75, 84], "write": [48, 49, 57, 61, 65, 78, 80, 101, 109], "written": [85, 87, 101, 102, 107], "wrong": [67, 72], "wspace": 67, "wurd": [50, 51, 52], "www": [110, 111], "x": [4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 41, 42, 48, 49, 50, 51, 52, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 107, 108, 109, 112, 115], "x0": [55, 72, 75], "x1": [50, 52, 55, 61, 68, 69, 72, 75, 76, 77, 78, 81, 83, 84, 85, 87, 100, 101, 103, 112], "x10": [50, 52, 68, 69, 78, 81, 84, 85, 87, 100, 112], "x100": [50, 52, 69, 78, 81, 85, 112], "x11": [50, 52, 69, 78, 81, 84, 85, 87, 100, 112], "x12": [50, 52, 69, 78, 81, 84, 85, 87, 100, 112], "x13": [50, 52, 69, 78, 81, 84, 85, 87, 100, 112], "x14": [50, 52, 69, 78, 81, 84, 85, 87, 100, 112], "x15": [50, 52, 69, 78, 81, 84, 85, 87, 100, 112], "x16": [50, 52, 69, 78, 81, 84, 85, 87, 100, 112], "x17": [50, 52, 69, 78, 81, 84, 85, 87, 100, 112], "x18": [50, 52, 69, 78, 81, 84, 85, 87, 100, 112], "x19": [50, 52, 69, 78, 81, 84, 85, 87, 100, 112], "x1x2x3x4x5x6x7x8x9x10": 50, "x2": [50, 52, 55, 61, 68, 69, 75, 76, 77, 78, 81, 83, 84, 85, 87, 100, 112], "x20": [50, 52, 69, 78, 81, 84, 85, 87, 100, 112], "x21": [50, 52, 69, 78, 81, 85, 112], "x22": [50, 52, 69, 78, 81, 85, 112], "x23": [50, 52, 69, 78, 81, 85, 112], "x24": [50, 52, 69, 78, 81, 85, 112], "x25": [50, 52, 69, 78, 81, 85, 112], "x26": [50, 52, 69, 78, 81, 85, 112], "x27": [50, 52, 69, 78, 81, 85, 112], "x28": [50, 52, 69, 78, 81, 85, 112], "x29": [50, 52, 69, 78, 81, 85, 112], "x2_dummi": 77, "x2_preds_control": 77, "x2_preds_treat": 77, "x3": [50, 52, 55, 61, 68, 69, 76, 77, 78, 81, 83, 84, 85, 87, 100, 112], "x30": [50, 52, 69, 78, 81, 85, 112], "x31": [50, 52, 69, 78, 81, 85, 112], "x32": [50, 52, 69, 78, 81, 85, 112], "x33": [50, 52, 69, 78, 81, 85, 112], "x34": [50, 52, 69, 78, 81, 85, 112], "x35": [50, 52, 69, 78, 81, 85, 112], "x36": [50, 52, 69, 78, 81, 85, 112], "x37": [50, 52, 69, 78, 81, 85, 112], "x38": [50, 52, 69, 78, 81, 85, 112], "x39": [50, 52, 69, 78, 81, 85, 112], "x4": [50, 52, 55, 61, 68, 69, 76, 77, 78, 81, 84, 85, 87, 100, 112], "x40": [50, 52, 69, 78, 81, 85, 112], "x41": [50, 52, 69, 78, 81, 85, 112], "x42": [50, 52, 69, 78, 81, 85, 112], "x43": [50, 52, 68, 69, 78, 81, 85, 112], "x44": [50, 52, 68, 69, 78, 81, 85, 112], "x45": [50, 52, 68, 69, 78, 81, 85, 112], "x46": [50, 52, 68, 69, 78, 81, 85, 112], "x47": [50, 52, 68, 69, 78, 81, 85, 112], "x48": [50, 52, 68, 69, 78, 81, 85, 112], "x49": [50, 52, 68, 69, 78, 81, 85, 112], "x5": [50, 52, 68, 69, 77, 78, 81, 84, 85, 87, 100, 112], "x50": [50, 52, 68, 69, 78, 81, 85, 112], "x51": [50, 52, 69, 78, 81, 85, 112], "x52": [50, 52, 69, 78, 81, 85, 112], "x53": [50, 52, 69, 78, 81, 85, 112], "x54": [50, 52, 69, 78, 81, 85, 112], "x55": [50, 52, 69, 78, 81, 85, 112], "x56": [50, 52, 69, 78, 81, 85, 112], "x57": [50, 52, 69, 78, 81, 85, 112], "x58": [50, 52, 69, 78, 81, 85, 112], "x59": [50, 52, 69, 78, 81, 85, 112], "x6": [50, 52, 68, 69, 78, 81, 84, 85, 87, 100, 112], "x60": [50, 52, 69, 78, 81, 85, 112], "x61": [50, 52, 69, 78, 81, 85, 112], "x62": [50, 52, 69, 78, 81, 85, 112], "x63": [50, 52, 69, 78, 81, 85, 112], "x64": [50, 52, 69, 70, 77, 78, 81, 85, 112], "x65": [50, 52, 69, 78, 81, 85, 112], "x66": [50, 52, 69, 78, 81, 85, 112], "x67": [50, 52, 69, 78, 81, 85, 112], "x68": [50, 52, 69, 78, 81, 85, 112], "x69": [50, 52, 69, 78, 81, 85, 112], "x7": [50, 52, 68, 69, 78, 81, 84, 85, 87, 100, 112], "x70": [50, 52, 69, 78, 81, 85, 112], "x71": [50, 52, 69, 78, 81, 85, 112], "x72": [50, 52, 69, 78, 81, 85, 112], "x73": [50, 52, 69, 78, 81, 85, 112], "x74": [50, 52, 69, 78, 81, 85, 112], "x75": [50, 52, 69, 78, 81, 85, 112], "x76": [50, 52, 69, 78, 81, 85, 112], "x77": [50, 52, 69, 78, 81, 85, 112], "x78": [50, 52, 69, 78, 81, 85, 112], "x79": [50, 52, 69, 78, 81, 85, 112], "x8": [50, 52, 68, 69, 78, 81, 84, 85, 87, 100, 112], "x80": [50, 52, 69, 78, 81, 85, 112], "x81": [50, 52, 69, 78, 81, 85, 112], "x82": [50, 52, 69, 78, 81, 85, 112], "x83": [50, 52, 69, 78, 81, 85, 112], "x84": [50, 52, 69, 78, 81, 85, 112], "x85": [50, 52, 69, 78, 81, 85, 112], "x86": [50, 52, 69, 78, 81, 85, 112], "x87": [50, 52, 69, 78, 81, 85, 112], "x88": [50, 52, 69, 78, 81, 85, 112], "x89": [50, 52, 69, 78, 81, 85, 112], "x9": [50, 52, 68, 69, 78, 81, 84, 85, 87, 100, 112], "x90": [50, 52, 69, 78, 81, 85, 112], "x91": [50, 52, 69, 78, 81, 85, 112], "x92": [50, 52, 69, 78, 81, 85, 112], "x93": [50, 52, 69, 78, 81, 85, 112], "x94": [50, 52, 69, 78, 81, 85, 112], "x95": [50, 52, 69, 78, 81, 85, 112], "x96": [50, 52, 69, 78, 81, 85, 112], "x96x97x98x99x100ydcluster_var_icluster_var_jz": 50, "x97": [50, 52, 69, 78, 81, 85, 112], "x98": [50, 52, 69, 78, 81, 85, 112], "x99": [50, 52, 69, 78, 81, 85, 112], "x_": [29, 30, 48, 50, 57, 62, 69, 77, 80], "x_0": [58, 59, 62, 64, 65, 66], "x_1": [14, 15, 21, 22, 23, 27, 58, 59, 60, 62, 64, 65, 66, 74, 77, 85, 101, 103, 112], "x_1x_3": [60, 74], "x_2": [21, 22, 23, 27, 58, 59, 60, 62, 64, 65, 66, 74, 77, 101, 103], "x_3": [21, 22, 23, 27, 58, 59, 62, 64, 65, 66, 101, 103], "x_4": [21, 22, 23, 27, 58, 59, 60, 64, 65, 66, 74], "x_5": [21, 22, 27, 58, 59, 64, 65], "x_6": [58, 59, 64, 65], "x_7": [58, 59, 64, 65], "x_8": [58, 59, 64, 65], "x_9": [58, 59, 64, 65], "x_binary_control": 77, "x_binary_tr": 77, "x_col": [7, 10, 47, 50, 51, 52, 56, 63, 69, 70, 71, 73, 75, 76, 77, 81, 84, 85, 112, 114, 115], "x_cols_bench": 77, "x_cols_binari": 77, "x_cols_poli": 69, "x_conf": 74, "x_conf_tru": 74, "x_df": 62, "x_domain": 52, "x_i": [24, 25, 26, 28, 30, 31, 32, 36, 48, 57, 60, 61, 64, 65, 72, 74, 75, 78, 80, 83, 85], "x_p": [14, 15, 85, 112], "x_train": 68, "x_true": [60, 74], "x_var": 52, "xaxis_titl": [58, 59, 63, 75, 77], "xformla": 49, "xgb": 68, "xgb_untuned_l": 68, "xgb_untuned_m": 68, "xgbclassifi": [67, 70, 72, 115], "xgboost": [48, 51, 67, 70, 72, 115], "xgbregressor": [67, 68, 70, 72, 115], "xi": [23, 27, 85], "xi_": 100, "xi_0": [29, 50, 69], "xi_i": 78, "xiaoji": 113, "xintercept": 48, "xlab": [48, 50, 51], "xlabel": [55, 58, 59, 60, 62, 64, 65, 68, 70, 71, 74], "xlim": [48, 51], "xtick": [55, 68], "xval": [52, 84], "xx": 57, "y": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 41, 42, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 107, 108, 109, 112, 115], "y0": [49, 55, 60, 74], "y0_cvar": 60, "y0_quant": [60, 74], "y1": [49, 60, 74], "y1_cvar": 60, "y1_quant": [60, 74], "y_": [29, 50, 61, 62, 69, 78, 85], "y_0": [8, 23, 36, 87, 90], "y_1": [8, 23, 36, 87, 90], "y_col": [7, 10, 47, 48, 50, 51, 52, 56, 58, 59, 63, 64, 65, 69, 70, 71, 73, 75, 76, 79, 80, 81, 84, 85, 86, 87, 112, 114, 115], "y_df": [62, 73], "y_diff": 62, "y_i": [24, 25, 26, 28, 30, 31, 32, 48, 57, 60, 61, 72, 73, 74, 75, 78, 80, 85], "y_pred": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 42, 67, 84], "y_train": 68, "y_true": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 42, 67, 84], "ya": 113, "yasui": 113, "yata": 113, "yaxis_titl": [58, 59, 63, 75, 77], "year": 110, "yerr": [55, 62, 64, 65, 68, 70, 72, 75], "yet": [50, 54], "yggvpl": 69, "yield": 85, "yintercept": 51, "ylab": [48, 50, 51], "ylabel": [55, 58, 59, 60, 62, 64, 65, 68, 70, 71, 74], "ylim": 70, "ymax": 51, "ymin": 51, "yname": 49, "york": 113, "you": [41, 42, 47, 48, 56, 62, 65, 69, 76, 85, 110, 111, 115], "your": [67, 111], "ython": 110, "yukun": 113, "yusuk": 113, "yuya": 113, "yy": 57, "z": [7, 10, 11, 13, 14, 18, 21, 22, 23, 25, 27, 28, 29, 32, 47, 50, 51, 56, 58, 59, 63, 69, 70, 74, 77, 78, 83, 85, 87, 92, 94, 96, 97, 100, 114], "z1": [14, 85], "z2": 85, "z3": 85, "z4": 85, "z_": [29, 50, 69], "z_1": [21, 22, 27], "z_2": [21, 22, 27], "z_3": [21, 22, 27], "z_4": [21, 22, 27], "z_5": 21, "z_col": [7, 10, 11, 13, 14, 47, 50, 51, 56, 69, 70, 71, 78, 81, 83, 85, 114], "z_i": [28, 32, 74, 78, 85], "z_j": [21, 22, 23, 27], "z_true": 74, "zadik": 113, "zaxis_titl": [58, 59, 63], "zero": [23, 36, 60, 61, 62, 67, 73, 74, 76, 77, 85, 100], "zeros_lik": 74, "zeta": [11, 14, 15, 51, 70, 83, 85, 112], "zeta_": [29, 50, 69], "zeta_0": [29, 50, 69], "zeta_i": [26, 28, 30, 48, 57, 80], "zeta_j": 100, "zhang": 113, "zhao": [8, 9, 21, 22, 23, 27, 49, 61, 85, 113], "zimmert": [61, 113], "zip": [58, 59], "zorder": 55, "\u03c4_x0": 72, "\u03c4_x1": 72, "\u2139": 48}, "titles": ["API Reference", "<span class=\"section-number\">1. </span>DoubleML Data Class", "<span class=\"section-number\">4. </span>Datasets", "<span class=\"section-number\">2. </span>DoubleML Models", "<span class=\"section-number\">2.4. </span>doubleml.DoubleMLAPO", "<span class=\"section-number\">2.5. </span>doubleml.DoubleMLAPOS", "<span class=\"section-number\">2.12. </span>doubleml.DoubleMLCVAR", "<span class=\"section-number\">1.2. </span>doubleml.DoubleMLClusterData", "<span class=\"section-number\">2.7. </span>doubleml.DoubleMLDID", "<span class=\"section-number\">2.8. </span>doubleml.DoubleMLDIDCS", "<span class=\"section-number\">1.1. </span>doubleml.DoubleMLData", "<span class=\"section-number\">2.6. </span>doubleml.DoubleMLIIVM", "<span class=\"section-number\">2.3. </span>doubleml.DoubleMLIRM", "<span class=\"section-number\">2.11. </span>doubleml.DoubleMLLPQ", "<span class=\"section-number\">2.2. </span>doubleml.DoubleMLPLIV", "<span class=\"section-number\">2.1. </span>doubleml.DoubleMLPLR", "<span class=\"section-number\">2.10. </span>doubleml.DoubleMLPQ", "<span class=\"section-number\">2.13. </span>doubleml.DoubleMLQTE", "<span class=\"section-number\">2.9. </span>doubleml.DoubleMLSSM", "<span class=\"section-number\">4.1.1. </span>doubleml.datasets.fetch_401K", "<span class=\"section-number\">4.1.2. </span>doubleml.datasets.fetch_bonus", "<span class=\"section-number\">4.2.10. </span>doubleml.datasets.make_confounded_irm_data", "<span class=\"section-number\">4.2.9. </span>doubleml.datasets.make_confounded_plr_data", "<span class=\"section-number\">4.2.7. </span>doubleml.datasets.make_did_SZ2020", "<span class=\"section-number\">4.2.11. </span>doubleml.datasets.make_heterogeneous_data", "<span class=\"section-number\">4.2.4. </span>doubleml.datasets.make_iivm_data", "<span class=\"section-number\">4.2.3. </span>doubleml.datasets.make_irm_data", "<span class=\"section-number\">4.2.12. </span>doubleml.datasets.make_irm_data_discrete_treatments", "<span class=\"section-number\">4.2.2. </span>doubleml.datasets.make_pliv_CHS2015", "<span class=\"section-number\">4.2.6. </span>doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "<span class=\"section-number\">4.2.1. </span>doubleml.datasets.make_plr_CCDDHNR2018", "<span class=\"section-number\">4.2.5. </span>doubleml.datasets.make_plr_turrell2018", "<span class=\"section-number\">4.2.8. </span>doubleml.datasets.make_ssm_data", "<span class=\"section-number\">6.1. </span>doubleml.double_ml_score_mixins.LinearScoreMixin", "<span class=\"section-number\">6.2. </span>doubleml.double_ml_score_mixins.NonLinearScoreMixin", "<span class=\"section-number\">3.1. </span>doubleml.rdd.RDFlex", "<span class=\"section-number\">4.2.13. </span>doubleml.rdd.datasets.make_simple_rdd_data", "<span class=\"section-number\">5.1.2. </span>doubleml.utils.DMLDummyClassifier", "<span class=\"section-number\">5.1.1. </span>doubleml.utils.DMLDummyRegressor", "<span class=\"section-number\">5.1.3. </span>doubleml.utils.DoubleMLBLP", "<span class=\"section-number\">5.1.4. </span>doubleml.utils.DoubleMLPolicyTree", "<span class=\"section-number\">5.1.6. </span>doubleml.utils.GlobalClassifier", "<span class=\"section-number\">5.1.5. </span>doubleml.utils.GlobalRegressor", "<span class=\"section-number\">5.2.1. </span>doubleml.utils.gain_statistics", "<span class=\"section-number\">6. </span>Score Mixin Classes for DoubleML Models", "<span class=\"section-number\">3. </span>Other models", "<span class=\"section-number\">5. </span>Utility Classes and Functions", "R: Basic Instrumental Variables Calculation", "R: Basics of Double Machine Learning", "R: DoubleML for Difference-in-Differences", "R: Cluster Robust Double Machine Learning", "R: Impact of 401(k) on Financial Wealth", "R: Ensemble Learners and More with <code class=\"docutils literal notranslate\"><span class=\"pre\">mlr3pipelines</span></code>", "DML: Bonus Data", "Examples", "Python: Average Potential Outcome (APO) Models", "Python: Basic Instrumental Variables calculation", "Python: Basics of Double Machine Learning", "Python: Conditional Average Treatment Effects (CATEs) for IRM models", "Python: Conditional Average Treatment Effects (CATEs) for PLR models", "Python: Conditional Value at Risk of potential outcomes", "Python: Difference-in-Differences", "Python: Difference-in-Differences Pre-Testing", "Python: First Stage and Causal Estimation", "Python: Group Average Treatment Effects (GATEs) for IRM models", "Python: Group Average Treatment Effects (GATEs) for PLR models", "Python: GATE Sensitivity Analysis", "Python: Choice of learners", "DoubleML meets FLAML - How to tune learners automatically within <code class=\"docutils literal notranslate\"><span class=\"pre\">DoubleML</span></code>", "Python: Cluster Robust Double Machine Learning", "Python: Impact of 401(k) on Financial Wealth", "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)", "Python: PLM and IRM for Multiple Treatments", "Python: Policy Learning with Trees", "Python: Potential Quantiles and Quantile Treatment Effects", "Flexible Covariate Adjustment in Regression Discontinuity Designs (RDD)", "Python: Sensitivity Analysis", "Example: Sensitivity Analysis for Causal ML", "Python: Sample Selection Models", "<span class=\"section-number\">6. </span>Double machine learning algorithms", "<span class=\"section-number\">1. </span>The basics of double/debiased machine learning", "<span class=\"section-number\">2. </span>The data-backend DoubleMLData", "User Guide", "<span class=\"section-number\">4. </span>Heterogeneous treatment effects", "<span class=\"section-number\">7. </span>Learners, hyperparameters and hyperparameter tuning", "<span class=\"section-number\">3. </span>Models", "<span class=\"section-number\">9. </span>Sample-splitting, cross-fitting and repeated cross-fitting", "<span class=\"section-number\">5. </span>Score functions", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "<span class=\"section-number\">8. </span>Variance estimation and confidence intervals", "<span class=\"section-number\">10. </span>Sensitivity analysis", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "DoubleML", "Installing DoubleML", "Getting Started", "Double Machine Learning Literature", "Release Notes", "DoubleML Workflow"], "titleterms": {"": 68, "0": 115, "1": [68, 77, 115], "2": [68, 77, 115], "2011": 77, "2023": 77, "3": [68, 77, 115], "4": [77, 115], "401": [51, 70, 71, 76], "5": [77, 115], "6": 115, "7": 115, "95": 68, "A": [50, 69], "ATE": [66, 72, 78], "No": [50, 69], "One": [50, 58, 59, 69], "The": [51, 70, 72, 80, 81, 112], "acknowledg": [49, 110], "acycl": [47, 56], "addit": 72, "adjust": 75, "advanc": [75, 84, 100], "al": 77, "algorithm": [79, 101, 110, 112], "altern": 87, "analysi": [55, 66, 76, 77, 101, 115], "api": [0, 68], "apo": [55, 85, 87, 101], "applic": [50, 69, 76], "approach": [48, 57, 67, 80], "arah": 77, "arbitrari": 72, "arrai": 81, "asset": [51, 70], "assumpt": 77, "att": 61, "augment": 72, "automat": 68, "automl": 68, "averag": [51, 55, 58, 59, 64, 65, 70, 83, 85, 87, 101], "backend": [50, 51, 69, 70, 81, 112, 115], "band": 100, "base": 52, "basic": [47, 48, 56, 57, 80], "benchmark": [76, 77, 101], "bia": [48, 57, 80], "binari": [85, 87], "bonu": 53, "bootstrap": 100, "build": 111, "calcul": [47, 56], "call": 68, "callabl": 87, "case": 54, "cate": [58, 59, 72, 83], "causal": [53, 55, 63, 77, 87, 112, 115], "chernozhukov": 77, "choic": 67, "citat": 110, "class": [1, 44, 46, 50, 69], "cluster": [50, 69], "code": 110, "coeffici": 68, "combin": 63, "compar": [67, 68], "comparison": [49, 68], "comput": [67, 68], "conclus": [68, 77], "conda": 111, "condit": [58, 59, 60, 71, 83, 87], "confid": [68, 100], "construct": 84, "contrast": 55, "covari": 75, "coverag": [61, 63], "cran": 111, "creat": 68, "cross": [50, 61, 69, 85, 86, 87, 101, 112], "custom": [67, 68], "cvar": [60, 71, 83, 87], "dag": [47, 56], "data": [1, 47, 48, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 80, 81, 85, 87, 101, 112, 115], "datafram": 81, "dataset": [2, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 53], "debias": [48, 57, 80, 112], "default": 68, "defin": [50, 69], "demo": 49, "depend": 111, "design": [75, 85], "detail": [49, 85], "develop": 111, "dgp": [48, 55, 57], "did": [49, 85], "differ": [49, 61, 62, 67, 85, 87, 100, 101], "dimension": [58, 59], "direct": [47, 56], "disclaim": 77, "discontinu": [75, 85], "distribut": 78, "dml": [50, 53, 69, 86, 112, 115], "dml1": 79, "dml2": 79, "dmldummyclassifi": 37, "dmldummyregressor": 38, "doubl": [48, 50, 57, 69, 79, 80, 110, 112, 113], "double_ml_score_mixin": [33, 34], "doubleml": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 49, 51, 52, 56, 68, 70, 76, 77, 100, 110, 111, 115], "doublemlapo": [4, 5], "doublemlblp": 39, "doublemlclusterdata": [7, 50, 69], "doublemlcvar": 6, "doublemldata": [10, 51, 70, 81, 112], "doublemldid": 8, "doublemldidc": 9, "doublemliivm": 11, "doublemlirm": 12, "doublemllpq": 13, "doublemlpliv": [14, 50, 69], "doublemlplr": 15, "doublemlpolicytre": 40, "doublemlpq": 16, "doublemlqt": 17, "doublemlssm": 18, "effect": [51, 54, 58, 59, 60, 64, 65, 70, 71, 72, 74, 76, 77, 83], "elig": [51, 70], "empir": 63, "ensembl": [52, 75], "error": [50, 69], "estim": [47, 51, 53, 56, 61, 63, 66, 68, 70, 71, 72, 74, 76, 77, 78, 86, 87, 100, 112, 115], "et": 77, "evalu": [67, 68, 84], "exampl": [49, 50, 54, 58, 59, 69, 76, 77], "exploit": [49, 52], "extern": [84, 86], "featur": [52, 110], "fetch_401k": 19, "fetch_bonu": 20, "figur": 72, "file": 111, "final": 49, "financi": [51, 70, 71], "first": 63, "fit": [50, 68, 69, 86, 112], "flaml": 68, "flexibl": 75, "fold": [68, 86], "forest": 53, "formul": [77, 115], "from": [49, 52, 81, 111], "full": 68, "function": [46, 49, 50, 69, 87, 112], "fuzzi": [75, 85], "gain_statist": 43, "gate": [64, 65, 66, 83], "gatet": 66, "gener": [2, 48, 54, 55, 57, 68, 75, 80, 101], "get": 112, "github": 111, "global": 75, "globalclassifi": 41, "globalregressor": 42, "graph": [47, 56], "group": [64, 65, 83], "guid": 82, "helper": [50, 69], "heterogen": [54, 72, 83], "how": [52, 68], "hyperparamet": 84, "identif": 77, "iivm": [51, 70, 85, 87], "impact": [51, 70, 71], "implement": [79, 85, 87, 101], "induc": [48, 57, 80], "infer": [100, 115], "initi": [50, 68, 69], "instal": 111, "instrument": [47, 56], "integr": 49, "interact": [51, 64, 70, 73, 85, 87, 101], "interv": [68, 100], "invers": 72, "irm": [51, 53, 58, 64, 70, 72, 73, 76, 83, 85, 87, 101], "iv": [47, 51, 56, 70, 85, 87], "k": [51, 70, 71, 76, 86], "lambda": 63, "lasso": [53, 63], "latest": 111, "lear": [50, 69], "learn": [48, 50, 57, 69, 73, 79, 80, 83, 110, 112, 113], "learner": [52, 53, 67, 68, 75, 84, 112], "less": 68, "level": 85, "linear": [51, 65, 70, 72, 75, 85, 87, 101], "linearscoremixin": 33, "literatur": 113, "load": [50, 53, 69, 77], "loader": 2, "local": [51, 70, 71, 74, 75, 87], "loss": 63, "lpq": [74, 87], "lqte": [71, 74], "m": 86, "machin": [48, 50, 57, 69, 79, 80, 110, 112, 113], "main": 110, "mainten": 110, "make_confounded_irm_data": 21, "make_confounded_plr_data": 22, "make_did_sz2020": 23, "make_heterogeneous_data": 24, "make_iivm_data": 25, "make_irm_data": 26, "make_irm_data_discrete_treat": 27, "make_pliv_chs2015": 28, "make_pliv_multiway_cluster_ckms2021": 29, "make_plr_ccddhnr2018": 30, "make_plr_turrell2018": 31, "make_simple_rdd_data": 36, "make_ssm_data": 32, "mar": 78, "market": [50, 69], "matric": 81, "meet": 68, "method": [68, 115], "metric": [67, 68], "minimum": 84, "miss": 78, "missing": [85, 87], "mixin": 44, "ml": [48, 49, 57, 77, 80, 115], "mlr3": 52, "mlr3extralearn": 52, "mlr3learner": 52, "mlr3pipelin": 52, "model": [3, 44, 45, 51, 53, 55, 58, 59, 64, 65, 68, 70, 72, 73, 77, 78, 83, 85, 86, 87, 100, 101, 112, 115], "modul": 53, "more": 52, "motiv": [50, 69], "multipl": [55, 72, 85], "multipli": 100, "naiv": [47, 56], "net": [51, 70], "neyman": [87, 112], "nonignor": [78, 85, 87], "nonlinearscoremixin": 34, "nonrespons": [78, 85, 87], "note": 114, "nuisanc": [68, 112], "object": [50, 69, 76], "option": 111, "orthogon": [48, 57, 80, 87, 112], "other": 45, "out": [48, 57, 80], "outcom": [55, 60, 61, 78, 83, 85, 87, 101], "over": 100, "overcom": [48, 57, 80], "overfit": [48, 57, 80], "overlap": 72, "packag": [49, 51, 70, 111], "panel": [61, 85, 87, 101], "paramet": [52, 53, 68, 87], "partial": [48, 51, 57, 65, 70, 72, 80, 85, 87, 101], "particip": [51, 70], "partit": 86, "penalti": 63, "perform": [49, 72], "pip": 111, "pipelin": 84, "pliv": [85, 87], "plm": [72, 85, 87], "plot": [50, 68, 69], "plr": [51, 53, 59, 65, 70, 83, 85, 87, 101], "polici": [73, 83], "potenti": [55, 60, 71, 74, 83, 85, 87, 101], "pq": [74, 83, 87], "pre": 62, "predict": [49, 84], "preprocess": 52, "problem": 115, "process": [48, 50, 55, 57, 69, 80], "product": [50, 69], "propens": 72, "provid": 86, "python": [54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76, 78, 84, 111], "qte": [74, 83], "qualiti": 63, "quantil": [71, 74, 83, 87], "r": [47, 48, 49, 50, 51, 52, 54, 84, 111], "random": [53, 78, 85, 87], "rank": 72, "rdd": [35, 36, 75, 85], "rdflex": 35, "real": [50, 69], "refer": [0, 47, 49, 50, 52, 56, 63, 69, 72, 77, 80, 84, 86, 100, 110, 112], "regress": [51, 64, 65, 70, 73, 75, 85, 87, 101], "regular": [48, 57, 80], "releas": [111, 114], "remark": 49, "remov": [48, 57, 80], "repeat": [61, 85, 86, 87, 101], "repetit": 86, "requir": 84, "respect": [50, 69], "result": [50, 51, 69, 70, 72], "risk": [60, 71, 83, 87], "robust": [50, 69], "sampl": [48, 57, 68, 78, 80, 85, 86, 87], "sandbox": 54, "score": [44, 48, 57, 72, 80, 87, 112], "section": [61, 85, 87, 101], "select": [78, 85, 87], "sensit": [55, 66, 76, 77, 101, 115], "set": [52, 84], "sharp": [75, 85], "simpl": [48, 57, 80], "simul": [47, 50, 56, 61, 69, 76], "simultan": 100, "singl": 55, "sourc": [110, 111], "specif": [101, 115], "specifi": [53, 84, 87], "split": [48, 57, 80, 86], "ssm": 85, "stack": 75, "stage": 63, "standard": [50, 67, 69], "start": 112, "step": 68, "studi": 54, "summari": [51, 68, 70, 72], "test": 62, "theori": 101, "time": [67, 68], "train": 68, "treatment": [51, 58, 59, 60, 64, 65, 70, 71, 72, 74, 83, 85], "tree": [73, 83], "tune": [52, 68, 84], "two": [50, 58, 59, 69], "under": [72, 78], "untun": 68, "up": 52, "us": [47, 49, 52, 53, 56, 68, 84], "user": 82, "util": [37, 38, 39, 40, 41, 42, 43, 46], "v": 63, "valid": 100, "valu": [60, 71, 83, 87], "vanderweel": 77, "variabl": [47, 56], "varianc": 100, "version": 111, "via": 87, "wai": [50, 69], "wealth": [51, 70, 71], "weight": [72, 83], "when": 68, "whl": 111, "within": 68, "without": [75, 86], "workflow": 115, "xgboost": 68, "zero": [50, 69]}})