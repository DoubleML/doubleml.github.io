Search.setIndex({"alltitles": {"(One-Way) Cluster Robust Double Machine Learing": [[40, "(One-Way)-Cluster-Robust-Double-Machine-Learing"], [58, "(One-Way)-Cluster-Robust-Double-Machine-Learing"]], "0. Problem Formulation": [[104, "problem-formulation"]], "1. Data-Backend": [[104, "data-backend"]], "1. Formulation of Causal Model & Identification Assumptions": [[65, "1.-Formulation-of-Causal-Model-&-Identification-Assumptions"]], "2. Causal Model": [[104, "causal-model"]], "2. Estimation of Causal Effect": [[65, "2.-Estimation-of-Causal-Effect"]], "3. ML Methods": [[104, "ml-methods"]], "3. Sensitivity Analysis": [[65, "3.-Sensitivity-Analysis"]], "4. Benchmarking Analysis": [[65, "4.-Benchmarking-Analysis"]], "4. DML Specifications": [[104, "dml-specifications"]], "5. Conclusion": [[65, "5.-Conclusion"]], "5. Estimation": [[104, "estimation"]], "6. Inference": [[104, "inference"]], "7. Sensitivity Analysis": [[104, "sensitivity-analysis"]], "A Motivating Example: Two-Way Cluster Robust DML": [[40, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"], [58, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"]], "API reference": [[0, "api-reference"]], "ATE Estimation and Sensitivity": [[56, "ATE-Estimation-and-Sensitivity"]], "ATE estimates distribution": [[66, "ATE-estimates-distribution"], [66, "id3"]], "ATTE Estimation": [[51, "ATTE-Estimation"], [51, "id2"]], "Acknowledgements": [[99, "acknowledgements"]], "Acknowledgements and Final Remarks": [[39, "Acknowledgements-and-Final-Remarks"]], "Additional Results: CATE estimates": [[61, "Additional-Results:-CATE-estimates"]], "Advanced: External Predictions": [[72, "advanced-external-predictions"]], "Algorithm DML1": [[67, "algorithm-dml1"]], "Algorithm DML2": [[67, "algorithm-dml2"]], "Application Results": [[40, "Application-Results"], [58, "Application-Results"]], "Application: 401(k)": [[64, "Application:-401(k)"]], "Average Potential Outcome (APOs)": [[45, "Average-Potential-Outcome-(APOs)"]], "Average Potential Outcomes (APOs)": [[73, "average-potential-outcomes-apos"], [75, "average-potential-outcomes-apos"], [89, "average-potential-outcomes-apos"]], "Average Potential Outcomes (APOs) for Multiple Treatment Levels": [[73, "average-potential-outcomes-apos-for-multiple-treatment-levels"]], "Benchmarking": [[89, "benchmarking"]], "Benchmarking Analysis": [[64, "Benchmarking-Analysis"]], "Binary Interactive Regression Model (IRM)": [[73, "binary-interactive-regression-model-irm"], [75, "binary-interactive-regression-model-irm"]], "CATEs for IRM models": [[71, "cates-for-irm-models"]], "CATEs for PLR models": [[71, "cates-for-plr-models"]], "CVaR Treatment Effects": [[50, "CVaR-Treatment-Effects"]], "CVaR of potential outcomes": [[71, "cvar-of-potential-outcomes"]], "CVaR treatment effects": [[71, "cvar-treatment-effects"]], "Causal Analysis with DoubleML": [[65, "Causal-Analysis-with-DoubleML"]], "Causal Contrasts": [[45, "Causal-Contrasts"]], "Causal estimation vs. lasso penalty \\lambda": [[53, "Causal-estimation-vs.-lasso-penalty-\\lambda"]], "Chernozhukov et al. (2023): Benchmarking": [[65, "Chernozhukov-et-al.-(2023):-Benchmarking"]], "Citation": [[99, "citation"]], "Cluster Robust Cross Fitting": [[40, "Cluster-Robust-Cross-Fitting"], [58, "Cluster-Robust-Cross-Fitting"]], "Cluster Robust Standard Errors": [[40, "Cluster-Robust-Standard-Errors"], [58, "Cluster-Robust-Standard-Errors"]], "Clustering and double machine learning": [[40, "Clustering-and-double-machine-learning"], [58, "Clustering-and-double-machine-learning"]], "Combined loss vs. lasso penalty \\lambda": [[53, "Combined-loss-vs.-lasso-penalty-\\lambda"]], "Comparing different learners": [[57, "Comparing-different-learners"]], "Comparison to did package": [[39, "Comparison-to-did-package"]], "Computation time": [[57, "Computation-time"]], "Conditional Value at Risk (CVaR)": [[50, "Conditional-Value-at-Risk-(CVaR)"]], "Conditional average treatment effects (CATEs)": [[71, "conditional-average-treatment-effects-cates"]], "Conditional value at risk (CVaR)": [[71, "conditional-value-at-risk-cvar"], [75, "conditional-value-at-risk-cvar"]], "Confidence bands and multiplier bootstrap for valid simultaneous inference": [[88, "confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference"], [98, "confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference"]], "Coverage Simulation": [[51, "Coverage-Simulation"], [51, "id3"]], "Cross-fitting with K folds": [[74, "cross-fitting-with-k-folds"]], "Cross-fitting, DML algorithms and Neyman-orthogonal score functions": [[101, "cross-fitting-dml-algorithms-and-neyman-orthogonal-score-functions"]], "Custom evaluation metrics": [[57, "Custom-evaluation-metrics"]], "DML: Bonus Data": [[43, "DML:-Bonus-Data"]], "Data": [[41, "Data"], [48, "Data"], [49, "Data"], [50, "Data"], [51, "Data"], [51, "id1"], [54, "Data"], [55, "Data"], [56, "Data"], [59, "Data"], [60, "Data"], [62, "Data"], [63, "Data"], [63, "id1"], [64, "Data"], [66, "Data"], [66, "id1"], [101, "data"]], "Data Generating Process (DGP)": [[38, "Data-Generating-Process-(DGP)"], [45, "Data-Generating-Process-(DGP)"], [47, "Data-Generating-Process-(DGP)"]], "Data Simulation": [[37, "Data-Simulation"], [46, "Data-Simulation"]], "Data and Effect Estimation": [[64, "Data-and-Effect-Estimation"]], "Data generating process": [[68, "data-generating-process"]], "Data preprocessing": [[42, "Data-preprocessing"]], "Data-Backend for Cluster Data": [[40, "Data-Backend-for-Cluster-Data"], [58, "Data-Backend-for-Cluster-Data"]], "Dataset generators": [[0, "dataset-generators"]], "Dataset loaders": [[0, "dataset-loaders"]], "Datasets module": [[0, "datasets-module"]], "Define Helper Functions for Plotting": [[40, "Define-Helper-Functions-for-Plotting"], [58, "Define-Helper-Functions-for-Plotting"]], "Demo Example from did": [[39, "Demo-Example-from-did"]], "Details on Predictive Performance": [[39, "Details-on-Predictive-Performance"]], "Difference-in-Differences Models": [[75, "difference-in-differences-models"]], "Difference-in-Differences Models (DID)": [[73, "difference-in-differences-models-did"]], "Difference-in-Differences for Panel Data": [[89, "difference-in-differences-for-panel-data"]], "Difference-in-Differences for repeated cross-sections": [[89, "difference-in-differences-for-repeated-cross-sections"]], "Disclaimer": [[65, "Disclaimer"]], "Double Machine Learning Algorithm": [[99, "double-machine-learning-algorithm"]], "Double machine learning algorithms": [[67, "double-machine-learning-algorithms"]], "Double machine learning data class": [[0, "double-machine-learning-data-class"]], "Double machine learning literature": [[102, "double-machine-learning-literature"]], "Double machine learning models": [[0, "double-machine-learning-models"]], "Double/debiased machine learning": [[38, "Double/debiased-machine-learning"], [47, "Double/debiased-machine-learning"], [68, "double-debiased-machine-learning"]], "DoubleML": [[99, "doubleml"]], "DoubleML Object": [[64, "DoubleML-Object"]], "DoubleML Workflow": [[104, "doubleml-workflow"]], "DoubleMLData from arrays and matrices": [[69, "doublemldata-from-arrays-and-matrices"]], "DoubleMLData from dataframes": [[69, "doublemldata-from-dataframes"]], "Effect Heterogeneity": [[44, "effect-heterogeneity"]], "Empirical coverage vs. lasso penalty \\lambda": [[53, "Empirical-coverage-vs.-lasso-penalty-\\lambda"]], "Estimate DML models without sample-splitting": [[74, "estimate-dml-models-without-sample-splitting"]], "Estimate double/debiased machine learning models": [[101, "estimate-double-debiased-machine-learning-models"]], "Estimating Potential Quantiles and Quantile Treatment Effects": [[60, "Estimating-Potential-Quantiles-and-Quantile-Treatment-Effects"]], "Estimating local quantile treatment effects (LQTEs)": [[60, "Estimating-local-quantile-treatment-effects-(LQTEs)"]], "Estimating the Average Treatment Effect of 401(k) Eligibility on Net Financial Assets": [[41, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"], [59, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"]], "Estimating the treatment effect on the Conditional Value a Risk (CVaR)": [[60, "Estimating-the-treatment-effect-on-the-Conditional-Value-a-Risk-(CVaR)"]], "Estimation": [[66, "Estimation"], [66, "id2"]], "Estimation quality vs. \\lambda": [[53, "Estimation-quality-vs.-\\lambda"]], "Evaluate learners": [[72, "evaluate-learners"]], "Example: Sensitivity Analysis for Causal ML": [[65, "Example:-Sensitivity-Analysis-for-Causal-ML"]], "Examples": [[44, "examples"]], "Exploiting the Functionalities of did": [[39, "Exploiting-the-Functionalities-of-did"]], "Externally provide a sample splitting / partition": [[74, "externally-provide-a-sample-splitting-partition"]], "GATE Estimation and Sensitivity": [[56, "GATE-Estimation-and-Sensitivity"]], "GATET Estimation and Sensitivity": [[56, "GATET-Estimation-and-Sensitivity"]], "GATEs for IRM models": [[71, "gates-for-irm-models"]], "GATEs for PLR models": [[71, "gates-for-plr-models"]], "General Examples": [[44, "general-examples"]], "General algorithm": [[89, "general-algorithm"]], "Getting started": [[101, "getting-started"]], "Group Average Treatment Effects (GATEs)": [[54, "Group-Average-Treatment-Effects-(GATEs)"], [55, "Group-Average-Treatment-Effects-(GATEs)"]], "Group average treatment effects (GATEs)": [[71, "group-average-treatment-effects-gates"]], "Heterogeneous treatment effects": [[71, "heterogeneous-treatment-effects"]], "How to exploit more features of mlr3pipelines in DoubleML": [[42, "How-to-exploit-more-features-of-mlr3pipelines-in-DoubleML"]], "Hyperparameter tuning": [[72, "hyperparameter-tuning"], [72, "id16"]], "Hyperparameter tuning with pipelines": [[72, "hyperparameter-tuning-with-pipelines"]], "Implementation": [[89, "implementation"]], "Implementation of the double machine learning algorithms": [[67, "implementation-of-the-double-machine-learning-algorithms"]], "Implementation of the score function and the estimate of the causal parameter": [[75, "implementation-of-the-score-function-and-the-estimate-of-the-causal-parameter"]], "Implemented Neyman orthogonal score functions": [[75, "implemented-neyman-orthogonal-score-functions"]], "Initialize DoubleMLClusterData object": [[40, "Initialize-DoubleMLClusterData-object"], [58, "Initialize-DoubleMLClusterData-object"]], "Initialize the objects of class DoubleMLPLIV": [[40, "Initialize-the-objects-of-class-DoubleMLPLIV"], [58, "Initialize-the-objects-of-class-DoubleMLPLIV"]], "Installing DoubleML": [[100, "installing-doubleml"]], "Instrumental Variables Directed Acyclic Graph (IV - DAG)": [[37, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"], [46, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"]], "Interactive IV Model (IIVM)": [[41, "Interactive-IV-Model-(IIVM)"], [59, "Interactive-IV-Model-(IIVM)"]], "Interactive IV model (IIVM)": [[73, "interactive-iv-model-iivm"], [75, "interactive-iv-model-iivm"]], "Interactive Regression Model (IRM)": [[41, "Interactive-Regression-Model-(IRM)"], [54, "Interactive-Regression-Model-(IRM)"], [59, "Interactive-Regression-Model-(IRM)"], [62, "Interactive-Regression-Model-(IRM)"]], "Interactive regression model (IRM)": [[89, "interactive-regression-model-irm"]], "Interactive regression models (IRM)": [[73, "interactive-regression-models-irm"], [75, "interactive-regression-models-irm"]], "Learners to estimate the nuisance models": [[101, "learners-to-estimate-the-nuisance-models"]], "Learners, hyperparameters and hyperparameter tuning": [[72, "learners-hyperparameters-and-hyperparameter-tuning"]], "Load Data": [[65, "Load-Data"]], "Load and Process Data": [[40, "Load-and-Process-Data"], [58, "Load-and-Process-Data"]], "Load bonus data using the dml datasets module": [[43, "Load-bonus-data-using-the-dml-datasets-module"]], "Local Average Treatment Effects of 401(k) Participation on Net Financial Assets": [[41, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"], [59, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"]], "Local Potential Quantile Estimation": [[63, "Local-Potential-Quantile-Estimation"]], "Local Potential Quantiles (LPQs)": [[63, "Local-Potential-Quantiles-(LPQs)"]], "Local Quantile Treatment Effects (LQTEs)": [[63, "Local-Quantile-Treatment-Effects-(LQTEs)"]], "Local potential quantiles (LPQs)": [[75, "local-potential-quantiles-lpqs"]], "Main Features": [[99, "main-features"]], "Minimum requirements for learners": [[72, "minimum-requirements-for-learners"], [72, "id2"]], "Missingness at Random": [[73, "missingness-at-random"], [75, "missingness-at-random"]], "Model-specific implementations": [[89, "model-specific-implementations"]], "Models": [[73, "models"]], "Motivation": [[40, "Motivation"], [58, "Motivation"]], "Multiple Average Potential Outcome Models (APOS)": [[45, "Multiple-Average-Potential-Outcome-Models-(APOS)"]], "Multiplier bootstrap and joint confidence intervals": [[98, "multiplier-bootstrap-and-joint-confidence-intervals"]], "Naive estimation": [[37, "Naive-estimation"], [46, "Naive-estimation"]], "No Clustering / Zero-Way Clustering": [[40, "No-Clustering-/-Zero-Way-Clustering"], [58, "No-Clustering-/-Zero-Way-Clustering"]], "Nonignorable Nonresponse": [[73, "nonignorable-nonresponse"], [75, "nonignorable-nonresponse"]], "One-Way Clustering with Respect to the Market": [[40, "One-Way-Clustering-with-Respect-to-the-Market"], [58, "One-Way-Clustering-with-Respect-to-the-Market"]], "One-Way Clustering with Respect to the Product": [[40, "One-Way-Clustering-with-Respect-to-the-Product"], [58, "One-Way-Clustering-with-Respect-to-the-Product"]], "One-dimensional Example": [[48, "One-dimensional-Example"], [49, "One-dimensional-Example"]], "Outcome missing at random (MAR)": [[66, "Outcome-missing-at-random-(MAR)"]], "Outcome missing under nonignorable nonresponse": [[66, "Outcome-missing-under-nonignorable-nonresponse"]], "Overcoming regularization bias by orthogonalization": [[38, "Overcoming-regularization-bias-by-orthogonalization"], [47, "Overcoming-regularization-bias-by-orthogonalization"], [68, "overcoming-regularization-bias-by-orthogonalization"]], "Panel Data": [[75, "panel-data"]], "Panel Data (Repeated Outcomes)": [[51, "Panel-Data-(Repeated-Outcomes)"]], "Panel data": [[73, "panel-data"]], "Parameter tuning": [[42, "Parameter-tuning"]], "Partialling out score": [[38, "Partialling-out-score"], [47, "Partialling-out-score"], [68, "partialling-out-score"]], "Partially Linear Regression Model (PLR)": [[41, "Partially-Linear-Regression-Model-(PLR)"], [55, "Partially-Linear-Regression-Model-(PLR)"], [59, "Partially-Linear-Regression-Model-(PLR)"]], "Partially linear IV regression model (PLIV)": [[73, "partially-linear-iv-regression-model-pliv"], [75, "partially-linear-iv-regression-model-pliv"]], "Partially linear models (PLM)": [[73, "partially-linear-models-plm"], [75, "partially-linear-models-plm"]], "Partially linear regression model (PLR)": [[73, "partially-linear-regression-model-plr"], [75, "partially-linear-regression-model-plr"], [89, "partially-linear-regression-model-plr"]], "Policy Learning with Trees": [[62, "Policy-Learning-with-Trees"], [71, "policy-learning-with-trees"]], "Potential Quantile Estimation": [[63, "Potential-Quantile-Estimation"]], "Potential Quantiles (PQs)": [[63, "Potential-Quantiles-(PQs)"]], "Potential quantiles (PQs)": [[71, "potential-quantiles-pqs"], [75, "potential-quantiles-pqs"]], "Python: Average Potential Outcome (APO) Models": [[45, "Python:-Average-Potential-Outcome-(APO)-Models"]], "Python: Basic Instrumental Variables calculation": [[46, "Python:-Basic-Instrumental-Variables-calculation"]], "Python: Basics of Double Machine Learning": [[47, "Python:-Basics-of-Double-Machine-Learning"]], "Python: Building the package from source": [[100, "python-building-the-package-from-source"]], "Python: Case studies": [[44, "python-case-studies"]], "Python: Choice of learners": [[57, "Python:-Choice-of-learners"]], "Python: Cluster Robust Double Machine Learning": [[58, "Python:-Cluster-Robust-Double-Machine-Learning"]], "Python: Conditional Average Treatment Effects (CATEs) for IRM models": [[48, "Python:-Conditional-Average-Treatment-Effects-(CATEs)-for-IRM-models"]], "Python: Conditional Average Treatment Effects (CATEs) for PLR models": [[49, "Python:-Conditional-Average-Treatment-Effects-(CATEs)-for-PLR-models"]], "Python: Conditional Value at Risk of potential outcomes": [[50, "Python:-Conditional-Value-at-Risk-of-potential-outcomes"]], "Python: Difference-in-Differences": [[51, "Python:-Difference-in-Differences"]], "Python: Difference-in-Differences Pre-Testing": [[52, "Python:-Difference-in-Differences-Pre-Testing"]], "Python: First Stage and Causal Estimation": [[53, "Python:-First-Stage-and-Causal-Estimation"]], "Python: GATE Sensitivity Analysis": [[56, "Python:-GATE-Sensitivity-Analysis"]], "Python: Group Average Treatment Effects (GATEs) for IRM models": [[54, "Python:-Group-Average-Treatment-Effects-(GATEs)-for-IRM-models"]], "Python: Group Average Treatment Effects (GATEs) for PLR models": [[55, "Python:-Group-Average-Treatment-Effects-(GATEs)-for-PLR-models"]], "Python: Impact of 401(k) on Financial Wealth": [[59, "Python:-Impact-of-401(k)-on-Financial-Wealth"]], "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)": [[60, "Python:-Impact-of-401(k)-on-Financial-Wealth-(Quantile-Effects)"]], "Python: Installing DoubleML": [[100, "python-installing-doubleml"]], "Python: Installing a released version from a .whl file": [[100, "python-installing-a-released-version-from-a-whl-file"]], "Python: Installing the latest release from pip or conda": [[100, "python-installing-the-latest-release-from-pip-or-conda"]], "Python: Learners and hyperparameters": [[72, "python-learners-and-hyperparameters"]], "Python: PLM and IRM for Multiple Treatments": [[61, "Python:-PLM-and-IRM-for-Multiple-Treatments"]], "Python: Policy Learning with Trees": [[62, "Python:-Policy-Learning-with-Trees"]], "Python: Potential Quantiles and Quantile Treatment Effects": [[63, "Python:-Potential-Quantiles-and-Quantile-Treatment-Effects"]], "Python: Sample Selection Models": [[66, "Python:-Sample-Selection-Models"]], "Python: Sensitivity Analysis": [[64, "Python:-Sensitivity-Analysis"]], "Quantile Treatment Effects (QTEs)": [[63, "Quantile-Treatment-Effects-(QTEs)"]], "Quantile treatment effects (QTEs)": [[71, "quantile-treatment-effects-qtes"]], "Quantiles": [[71, "quantiles"]], "R: Basic Instrumental Variables Calculation": [[37, "R:-Basic-Instrumental-Variables-Calculation"]], "R: Basics of Double Machine Learning": [[38, "R:-Basics-of-Double-Machine-Learning"]], "R: Case studies": [[44, "r-case-studies"]], "R: Cluster Robust Double Machine Learning": [[40, "R:-Cluster-Robust-Double-Machine-Learning"]], "R: DoubleML for Difference-in-Differences": [[39, "R:-DoubleML-for-Difference-in-Differences"]], "R: Ensemble Learners and More with mlr3pipelines": [[42, "R:-Ensemble-Learners-and-More-with-mlr3pipelines"]], "R: Impact of 401(k) on Financial Wealth": [[41, "R:-Impact-of-401(k)-on-Financial-Wealth"]], "R: Installing DoubleML": [[100, "r-installing-doubleml"]], "R: Installing the development version from GitHub": [[100, "r-installing-the-development-version-from-github"]], "R: Installing the latest release from CRAN": [[100, "r-installing-the-latest-release-from-cran"]], "R: Learners and hyperparameters": [[72, "r-learners-and-hyperparameters"]], "Ranking Treatment Effects under Treatment Propensity and Treatment Effect Heterogeneity": [[61, "Ranking-Treatment-Effects-under-Treatment-Propensity-and-Treatment-Effect-Heterogeneity"]], "Real-Data Application": [[40, "Real-Data-Application"], [58, "Real-Data-Application"]], "References": [[37, "References"], [39, "References"], [40, "References"], [42, "References"], [46, "References"], [53, "References"], [58, "References"], [61, "References"], [65, "References"], [68, "references"], [72, "references"], [74, "references"], [88, "references"], [98, "references"], [99, "references"], [101, "references"]], "Regularization Bias in Simple ML-Approaches": [[38, "Regularization-Bias-in-Simple-ML-Approaches"], [47, "Regularization-Bias-in-Simple-ML-Approaches"]], "Regularization bias in simple ML-approaches": [[68, "regularization-bias-in-simple-ml-approaches"]], "Release notes": [[103, "release-notes"]], "Repeated Cross-Sectional Data": [[51, "Repeated-Cross-Sectional-Data"], [75, "repeated-cross-sectional-data"]], "Repeated cross-fitting with K folds and M repetitions": [[74, "repeated-cross-fitting-with-k-folds-and-m-repetitions"]], "Repeated cross-sections": [[73, "repeated-cross-sections"]], "Sample Selection Models": [[75, "sample-selection-models"]], "Sample Selection Models (SSM)": [[73, "sample-selection-models-ssm"]], "Sample splitting to remove bias induced by overfitting": [[38, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [47, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [68, "sample-splitting-to-remove-bias-induced-by-overfitting"]], "Sample-splitting without cross-fitting": [[74, "sample-splitting-without-cross-fitting"]], "Sample-splitting, cross-fitting and repeated cross-fitting": [[74, "sample-splitting-cross-fitting-and-repeated-cross-fitting"]], "Sandbox": [[44, "sandbox"]], "Score functions": [[75, "score-functions"]], "Score mixin classes for double machine learning models": [[0, "score-mixin-classes-for-double-machine-learning-models"]], "Sensitivity Analysis": [[45, "Sensitivity-Analysis"], [64, "Sensitivity-Analysis"], [64, "id1"]], "Sensitivity Analysis with IRM": [[64, "Sensitivity-Analysis-with-IRM"]], "Sensitivity analysis": [[89, "sensitivity-analysis"]], "Set up learners based on mlr3pipelines": [[42, "Set-up-learners-based-on-mlr3pipelines"]], "Simulate two-way cluster data": [[40, "Simulate-two-way-cluster-data"], [58, "Simulate-two-way-cluster-data"]], "Simulation Example": [[64, "Simulation-Example"]], "Simultaneous inference over different DoubleML models (advanced)": [[88, "simultaneous-inference-over-different-doubleml-models-advanced"]], "Single Average Potential Outcome Models (APO)": [[45, "Single-Average-Potential-Outcome-Models-(APO)"]], "Source code and maintenance": [[99, "source-code-and-maintenance"]], "Specify learner and estimate causal parameter: IRM model with Lasso as learner": [[43, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: IRM model with random forest as learner": [[43, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-random-forest-as-learner"]], "Specify learner and estimate causal parameter: PLR model with Lasso as learner": [[43, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: PLR model with random forest as learner": [[43, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-random-forest-as-learner"]], "Specifying alternative score functions via callables": [[75, "specifying-alternative-score-functions-via-callables"]], "Specifying learners and set hyperparameters": [[72, "specifying-learners-and-set-hyperparameters"], [72, "id9"]], "Standard approach": [[57, "Standard-approach"]], "Summary Figure": [[61, "Summary-Figure"]], "Summary of Results": [[41, "Summary-of-Results"], [59, "Summary-of-Results"]], "The Augmented Inverse Propensity Weighting Model estimates the ATE under arbitrary effect and propensity score heterogeneity": [[61, "The-Augmented-Inverse-Propensity-Weighting-Model-estimates-the-ATE-under-arbitrary-effect-and-propensity-score-heterogeneity"]], "The Data Backend: DoubleMLData": [[41, "The-Data-Backend:-DoubleMLData"], [59, "The-Data-Backend:-DoubleMLData"]], "The DoubleML package": [[41, "The-DoubleML-package"], [59, "The-DoubleML-package"]], "The Partially Linear Model performs overlap weighting": [[61, "The-Partially-Linear-Model-performs-overlap-weighting"]], "The basics of double/debiased machine learning": [[68, "the-basics-of-double-debiased-machine-learning"]], "The causal model": [[101, "the-causal-model"]], "The data-backend DoubleMLData": [[69, "the-data-backend-doublemldata"], [101, "the-data-backend-doublemldata"]], "Theory": [[89, "theory"]], "Two-Dimensional Example": [[48, "Two-Dimensional-Example"], [49, "Two-Dimensional-Example"]], "Two-Way Clustering with Respect to Product and Market": [[40, "Two-Way-Clustering-with-Respect-to-Product-and-Market"], [58, "Two-Way-Clustering-with-Respect-to-Product-and-Market"]], "Use ensemble learners based on mlr3pipelines": [[42, "Use-ensemble-learners-based-on-mlr3pipelines"]], "User guide": [[70, "user-guide"]], "Using DoubleML": [[37, "Using-DoubleML"], [46, "Using-DoubleML"]], "Using ML for DiD: Integrating DoubleML in did": [[39, "Using-ML-for-DiD:-Integrating-DoubleML-in-did"]], "Using learners from mlr3, mlr3learners and mlr3extralearners": [[42, "Using-learners-from-mlr3,-mlr3learners-and-mlr3extralearners"]], "Using pipelines to construct learners": [[72, "using-pipelines-to-construct-learners"]], "Utility classes": [[0, "utility-classes"]], "Utility classes and functions": [[0, "utility-classes-and-functions"]], "Utility functions": [[0, "utility-functions"]], "VanderWeele and Arah (2011): Benchmarking": [[65, "VanderWeele-and-Arah-(2011):-Benchmarking"]], "Variance estimation": [[88, "variance-estimation"]], "Variance estimation and confidence intervals": [[88, "variance-estimation-and-confidence-intervals"]], "Weighted Average Treatment Effects": [[71, "weighted-average-treatment-effects"]], "doubleml.DoubleMLAPO": [[1, "doubleml-doublemlapo"]], "doubleml.DoubleMLAPOS": [[2, "doubleml-doublemlapos"]], "doubleml.DoubleMLCVAR": [[3, "doubleml-doublemlcvar"]], "doubleml.DoubleMLClusterData": [[4, "doubleml-doublemlclusterdata"]], "doubleml.DoubleMLDID": [[5, "doubleml-doublemldid"]], "doubleml.DoubleMLDIDCS": [[6, "doubleml-doublemldidcs"]], "doubleml.DoubleMLData": [[7, "doubleml-doublemldata"]], "doubleml.DoubleMLIIVM": [[8, "doubleml-doublemliivm"]], "doubleml.DoubleMLIRM": [[9, "doubleml-doublemlirm"]], "doubleml.DoubleMLLPQ": [[10, "doubleml-doublemllpq"]], "doubleml.DoubleMLPLIV": [[11, "doubleml-doublemlpliv"]], "doubleml.DoubleMLPLR": [[12, "doubleml-doublemlplr"]], "doubleml.DoubleMLPQ": [[13, "doubleml-doublemlpq"]], "doubleml.DoubleMLQTE": [[14, "doubleml-doublemlqte"]], "doubleml.DoubleMLSSM": [[15, "doubleml-doublemlssm"]], "doubleml.datasets.fetch_401K": [[16, "doubleml-datasets-fetch-401k"]], "doubleml.datasets.fetch_bonus": [[17, "doubleml-datasets-fetch-bonus"]], "doubleml.datasets.make_confounded_irm_data": [[18, "doubleml-datasets-make-confounded-irm-data"]], "doubleml.datasets.make_confounded_plr_data": [[19, "doubleml-datasets-make-confounded-plr-data"]], "doubleml.datasets.make_did_SZ2020": [[20, "doubleml-datasets-make-did-sz2020"]], "doubleml.datasets.make_heterogeneous_data": [[21, "doubleml-datasets-make-heterogeneous-data"]], "doubleml.datasets.make_iivm_data": [[22, "doubleml-datasets-make-iivm-data"]], "doubleml.datasets.make_irm_data": [[23, "doubleml-datasets-make-irm-data"]], "doubleml.datasets.make_irm_data_discrete_treatments": [[24, "doubleml-datasets-make-irm-data-discrete-treatments"]], "doubleml.datasets.make_pliv_CHS2015": [[25, "doubleml-datasets-make-pliv-chs2015"]], "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021": [[26, "doubleml-datasets-make-pliv-multiway-cluster-ckms2021"]], "doubleml.datasets.make_plr_CCDDHNR2018": [[27, "doubleml-datasets-make-plr-ccddhnr2018"]], "doubleml.datasets.make_plr_turrell2018": [[28, "doubleml-datasets-make-plr-turrell2018"]], "doubleml.datasets.make_ssm_data": [[29, "doubleml-datasets-make-ssm-data"]], "doubleml.double_ml_score_mixins.LinearScoreMixin": [[30, "doubleml-double-ml-score-mixins-linearscoremixin"]], "doubleml.double_ml_score_mixins.NonLinearScoreMixin": [[31, "doubleml-double-ml-score-mixins-nonlinearscoremixin"]], "doubleml.utils.DMLDummyClassifier": [[32, "doubleml-utils-dmldummyclassifier"]], "doubleml.utils.DMLDummyRegressor": [[33, "doubleml-utils-dmldummyregressor"]], "doubleml.utils.DoubleMLBLP": [[34, "doubleml-utils-doublemlblp"]], "doubleml.utils.DoubleMLPolicyTree": [[35, "doubleml-utils-doublemlpolicytree"]], "doubleml.utils.gain_statistics": [[36, "doubleml-utils-gain-statistics"]]}, "docnames": ["api/api", "api/generated/doubleml.DoubleMLAPO", "api/generated/doubleml.DoubleMLAPOS", "api/generated/doubleml.DoubleMLCVAR", "api/generated/doubleml.DoubleMLClusterData", "api/generated/doubleml.DoubleMLDID", "api/generated/doubleml.DoubleMLDIDCS", "api/generated/doubleml.DoubleMLData", "api/generated/doubleml.DoubleMLIIVM", "api/generated/doubleml.DoubleMLIRM", "api/generated/doubleml.DoubleMLLPQ", "api/generated/doubleml.DoubleMLPLIV", "api/generated/doubleml.DoubleMLPLR", "api/generated/doubleml.DoubleMLPQ", "api/generated/doubleml.DoubleMLQTE", "api/generated/doubleml.DoubleMLSSM", "api/generated/doubleml.datasets.fetch_401K", "api/generated/doubleml.datasets.fetch_bonus", "api/generated/doubleml.datasets.make_confounded_irm_data", "api/generated/doubleml.datasets.make_confounded_plr_data", "api/generated/doubleml.datasets.make_did_SZ2020", "api/generated/doubleml.datasets.make_heterogeneous_data", "api/generated/doubleml.datasets.make_iivm_data", "api/generated/doubleml.datasets.make_irm_data", "api/generated/doubleml.datasets.make_irm_data_discrete_treatments", "api/generated/doubleml.datasets.make_pliv_CHS2015", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018", "api/generated/doubleml.datasets.make_plr_turrell2018", "api/generated/doubleml.datasets.make_ssm_data", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin", "api/generated/doubleml.utils.DMLDummyClassifier", "api/generated/doubleml.utils.DMLDummyRegressor", "api/generated/doubleml.utils.DoubleMLBLP", "api/generated/doubleml.utils.DoubleMLPolicyTree", "api/generated/doubleml.utils.gain_statistics", "examples/R_double_ml_basic_iv", "examples/R_double_ml_basics", "examples/R_double_ml_did", "examples/R_double_ml_multiway_cluster", "examples/R_double_ml_pension", "examples/R_double_ml_pipeline", "examples/double_ml_bonus_data", "examples/index", "examples/py_double_ml_apo", "examples/py_double_ml_basic_iv", "examples/py_double_ml_basics", "examples/py_double_ml_cate", "examples/py_double_ml_cate_plr", "examples/py_double_ml_cvar", "examples/py_double_ml_did", "examples/py_double_ml_did_pretest", "examples/py_double_ml_firststage", "examples/py_double_ml_gate", "examples/py_double_ml_gate_plr", "examples/py_double_ml_gate_sensitivity", "examples/py_double_ml_learner", "examples/py_double_ml_multiway_cluster", "examples/py_double_ml_pension", "examples/py_double_ml_pension_qte", "examples/py_double_ml_plm_irm_hetfx", "examples/py_double_ml_policy_tree", "examples/py_double_ml_pq", "examples/py_double_ml_sensitivity", "examples/py_double_ml_sensitivity_booking", "examples/py_double_ml_ssm", "guide/algorithms", "guide/basics", "guide/data_backend", "guide/guide", "guide/heterogeneity", "guide/learners", "guide/models", "guide/resampling", "guide/scores", "guide/scores/apo_score", "guide/scores/cvar_score", "guide/scores/did_score", "guide/scores/didcs_score", "guide/scores/iivm_score", "guide/scores/irm_score", "guide/scores/lpq_score", "guide/scores/mar_score", "guide/scores/nr_score", "guide/scores/pliv_score", "guide/scores/plr_score", "guide/scores/pq_score", "guide/se_confint", "guide/sensitivity", "guide/sensitivity/apo_sensitivity", "guide/sensitivity/benchmarking", "guide/sensitivity/did_cs_sensitivity", "guide/sensitivity/did_sensitivity", "guide/sensitivity/implementation", "guide/sensitivity/irm_sensitivity", "guide/sensitivity/plr_sensitivity", "guide/sensitivity/theory", "guide/sim_inf", "index", "intro/install", "intro/intro", "literature/literature", "release/release", "workflow/workflow"], "envversion": {"nbsphinx": 4, "sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["api/api.rst", "api/generated/doubleml.DoubleMLAPO.rst", "api/generated/doubleml.DoubleMLAPOS.rst", "api/generated/doubleml.DoubleMLCVAR.rst", "api/generated/doubleml.DoubleMLClusterData.rst", "api/generated/doubleml.DoubleMLDID.rst", "api/generated/doubleml.DoubleMLDIDCS.rst", "api/generated/doubleml.DoubleMLData.rst", "api/generated/doubleml.DoubleMLIIVM.rst", "api/generated/doubleml.DoubleMLIRM.rst", "api/generated/doubleml.DoubleMLLPQ.rst", "api/generated/doubleml.DoubleMLPLIV.rst", "api/generated/doubleml.DoubleMLPLR.rst", "api/generated/doubleml.DoubleMLPQ.rst", "api/generated/doubleml.DoubleMLQTE.rst", "api/generated/doubleml.DoubleMLSSM.rst", "api/generated/doubleml.datasets.fetch_401K.rst", "api/generated/doubleml.datasets.fetch_bonus.rst", "api/generated/doubleml.datasets.make_confounded_irm_data.rst", "api/generated/doubleml.datasets.make_confounded_plr_data.rst", "api/generated/doubleml.datasets.make_did_SZ2020.rst", "api/generated/doubleml.datasets.make_heterogeneous_data.rst", "api/generated/doubleml.datasets.make_iivm_data.rst", "api/generated/doubleml.datasets.make_irm_data.rst", "api/generated/doubleml.datasets.make_irm_data_discrete_treatments.rst", "api/generated/doubleml.datasets.make_pliv_CHS2015.rst", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021.rst", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018.rst", "api/generated/doubleml.datasets.make_plr_turrell2018.rst", "api/generated/doubleml.datasets.make_ssm_data.rst", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin.rst", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin.rst", "api/generated/doubleml.utils.DMLDummyClassifier.rst", "api/generated/doubleml.utils.DMLDummyRegressor.rst", "api/generated/doubleml.utils.DoubleMLBLP.rst", "api/generated/doubleml.utils.DoubleMLPolicyTree.rst", "api/generated/doubleml.utils.gain_statistics.rst", "examples/R_double_ml_basic_iv.ipynb", "examples/R_double_ml_basics.ipynb", "examples/R_double_ml_did.ipynb", "examples/R_double_ml_multiway_cluster.ipynb", "examples/R_double_ml_pension.ipynb", "examples/R_double_ml_pipeline.ipynb", "examples/double_ml_bonus_data.ipynb", "examples/index.rst", "examples/py_double_ml_apo.ipynb", "examples/py_double_ml_basic_iv.ipynb", "examples/py_double_ml_basics.ipynb", "examples/py_double_ml_cate.ipynb", "examples/py_double_ml_cate_plr.ipynb", "examples/py_double_ml_cvar.ipynb", "examples/py_double_ml_did.ipynb", "examples/py_double_ml_did_pretest.ipynb", "examples/py_double_ml_firststage.ipynb", "examples/py_double_ml_gate.ipynb", "examples/py_double_ml_gate_plr.ipynb", "examples/py_double_ml_gate_sensitivity.ipynb", "examples/py_double_ml_learner.ipynb", "examples/py_double_ml_multiway_cluster.ipynb", "examples/py_double_ml_pension.ipynb", "examples/py_double_ml_pension_qte.ipynb", "examples/py_double_ml_plm_irm_hetfx.ipynb", "examples/py_double_ml_policy_tree.ipynb", "examples/py_double_ml_pq.ipynb", "examples/py_double_ml_sensitivity.ipynb", "examples/py_double_ml_sensitivity_booking.ipynb", "examples/py_double_ml_ssm.ipynb", "guide/algorithms.rst", "guide/basics.rst", "guide/data_backend.rst", "guide/guide.rst", "guide/heterogeneity.rst", "guide/learners.rst", "guide/models.rst", "guide/resampling.rst", "guide/scores.rst", "guide/scores/apo_score.rst", "guide/scores/cvar_score.rst", "guide/scores/did_score.rst", "guide/scores/didcs_score.rst", "guide/scores/iivm_score.rst", "guide/scores/irm_score.rst", "guide/scores/lpq_score.rst", "guide/scores/mar_score.rst", "guide/scores/nr_score.rst", "guide/scores/pliv_score.rst", "guide/scores/plr_score.rst", "guide/scores/pq_score.rst", "guide/se_confint.rst", "guide/sensitivity.rst", "guide/sensitivity/apo_sensitivity.rst", "guide/sensitivity/benchmarking.rst", "guide/sensitivity/did_cs_sensitivity.rst", "guide/sensitivity/did_sensitivity.rst", "guide/sensitivity/implementation.rst", "guide/sensitivity/irm_sensitivity.rst", "guide/sensitivity/plr_sensitivity.rst", "guide/sensitivity/theory.rst", "guide/sim_inf.rst", "index.rst", "intro/install.rst", "intro/intro.rst", "literature/literature.rst", "release/release.rst", "workflow/workflow.rst"], "indexentries": {"bootstrap() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.bootstrap", false]], "bootstrap() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.bootstrap", false]], "bootstrap() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.bootstrap", false]], "bootstrap() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.bootstrap", false]], "bootstrap() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.bootstrap", false]], "bootstrap() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.bootstrap", false]], "bootstrap() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.bootstrap", false]], "bootstrap() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.bootstrap", false]], "bootstrap() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.bootstrap", false]], "bootstrap() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.bootstrap", false]], "bootstrap() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.bootstrap", false]], "bootstrap() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.bootstrap", false]], "bootstrap() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.bootstrap", false]], "capo() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.capo", false]], "cate() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.cate", false]], "cate() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.cate", false]], "causal_contrast() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.causal_contrast", false]], "confint() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.confint", false]], "confint() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.confint", false]], "confint() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.confint", false]], "confint() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.confint", false]], "confint() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.confint", false]], "confint() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.confint", false]], "confint() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.confint", false]], "confint() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.confint", false]], "confint() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.confint", false]], "confint() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.confint", false]], "confint() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.confint", false]], "confint() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.confint", false]], "confint() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.confint", false]], "confint() (doubleml.utils.doublemlblp method)": [[34, "doubleml.utils.DoubleMLBLP.confint", false]], "construct_framework() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.construct_framework", false]], "construct_framework() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.construct_framework", false]], "construct_framework() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.construct_framework", false]], "construct_framework() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.construct_framework", false]], "construct_framework() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.construct_framework", false]], "construct_framework() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.construct_framework", false]], "construct_framework() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.construct_framework", false]], "construct_framework() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.construct_framework", false]], "construct_framework() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.construct_framework", false]], "construct_framework() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.construct_framework", false]], "construct_framework() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.construct_framework", false]], "dmldummyclassifier (class in doubleml.utils)": [[32, "doubleml.utils.DMLDummyClassifier", false]], "dmldummyregressor (class in doubleml.utils)": [[33, "doubleml.utils.DMLDummyRegressor", false]], "doublemlapo (class in doubleml)": [[1, "doubleml.DoubleMLAPO", false]], "doublemlapos (class in doubleml)": [[2, "doubleml.DoubleMLAPOS", false]], "doublemlblp (class in doubleml.utils)": [[34, "doubleml.utils.DoubleMLBLP", false]], "doublemlclusterdata (class in doubleml)": [[4, "doubleml.DoubleMLClusterData", false]], "doublemlcvar (class in doubleml)": [[3, "doubleml.DoubleMLCVAR", false]], "doublemldata (class in doubleml)": [[7, "doubleml.DoubleMLData", false]], "doublemldid (class in doubleml)": [[5, "doubleml.DoubleMLDID", false]], "doublemldidcs (class in doubleml)": [[6, "doubleml.DoubleMLDIDCS", false]], "doublemliivm (class in doubleml)": [[8, "doubleml.DoubleMLIIVM", false]], "doublemlirm (class in doubleml)": [[9, "doubleml.DoubleMLIRM", false]], "doublemllpq (class in doubleml)": [[10, "doubleml.DoubleMLLPQ", false]], "doublemlpliv (class in doubleml)": [[11, "doubleml.DoubleMLPLIV", false]], "doublemlplr (class in doubleml)": [[12, "doubleml.DoubleMLPLR", false]], "doublemlpolicytree (class in doubleml.utils)": [[35, "doubleml.utils.DoubleMLPolicyTree", false]], "doublemlpq (class in doubleml)": [[13, "doubleml.DoubleMLPQ", false]], "doublemlqte (class in doubleml)": [[14, "doubleml.DoubleMLQTE", false]], "doublemlssm (class in doubleml)": [[15, "doubleml.DoubleMLSSM", false]], "draw_sample_splitting() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.draw_sample_splitting", false]], "evaluate_learners() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.evaluate_learners", false]], "fetch_401k() (in module doubleml.datasets)": [[16, "doubleml.datasets.fetch_401K", false]], "fetch_bonus() (in module doubleml.datasets)": [[17, "doubleml.datasets.fetch_bonus", false]], "fit() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.fit", false]], "fit() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.fit", false]], "fit() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.fit", false]], "fit() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.fit", false]], "fit() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.fit", false]], "fit() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.fit", false]], "fit() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.fit", false]], "fit() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.fit", false]], "fit() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.fit", false]], "fit() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.fit", false]], "fit() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.fit", false]], "fit() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.fit", false]], "fit() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.fit", false]], "fit() (doubleml.utils.dmldummyclassifier method)": [[32, "doubleml.utils.DMLDummyClassifier.fit", false]], "fit() (doubleml.utils.dmldummyregressor method)": [[33, "doubleml.utils.DMLDummyRegressor.fit", false]], "fit() (doubleml.utils.doublemlblp method)": [[34, "doubleml.utils.DoubleMLBLP.fit", false]], "fit() (doubleml.utils.doublemlpolicytree method)": [[35, "doubleml.utils.DoubleMLPolicyTree.fit", false]], "from_arrays() (doubleml.doublemlclusterdata class method)": [[4, "doubleml.DoubleMLClusterData.from_arrays", false]], "from_arrays() (doubleml.doublemldata class method)": [[7, "doubleml.DoubleMLData.from_arrays", false]], "gain_statistics() (in module doubleml.utils)": [[36, "doubleml.utils.gain_statistics", false]], "gapo() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.gapo", false]], "gate() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.gate", false]], "gate() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.gate", false]], "get_metadata_routing() (doubleml.utils.dmldummyclassifier method)": [[32, "doubleml.utils.DMLDummyClassifier.get_metadata_routing", false]], "get_metadata_routing() (doubleml.utils.dmldummyregressor method)": [[33, "doubleml.utils.DMLDummyRegressor.get_metadata_routing", false]], "get_params() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.get_params", false]], "get_params() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.get_params", false]], "get_params() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.get_params", false]], "get_params() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.get_params", false]], "get_params() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.get_params", false]], "get_params() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.get_params", false]], "get_params() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.get_params", false]], "get_params() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.get_params", false]], "get_params() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.get_params", false]], "get_params() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.get_params", false]], "get_params() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.get_params", false]], "get_params() (doubleml.utils.dmldummyclassifier method)": [[32, "doubleml.utils.DMLDummyClassifier.get_params", false]], "get_params() (doubleml.utils.dmldummyregressor method)": [[33, "doubleml.utils.DMLDummyRegressor.get_params", false]], "linearscoremixin (class in doubleml.double_ml_score_mixins)": [[30, "doubleml.double_ml_score_mixins.LinearScoreMixin", false]], "make_confounded_irm_data() (in module doubleml.datasets)": [[18, "doubleml.datasets.make_confounded_irm_data", false]], "make_confounded_plr_data() (in module doubleml.datasets)": [[19, "doubleml.datasets.make_confounded_plr_data", false]], "make_did_sz2020() (in module doubleml.datasets)": [[20, "doubleml.datasets.make_did_SZ2020", false]], "make_heterogeneous_data() (in module doubleml.datasets)": [[21, "doubleml.datasets.make_heterogeneous_data", false]], "make_iivm_data() (in module doubleml.datasets)": [[22, "doubleml.datasets.make_iivm_data", false]], "make_irm_data() (in module doubleml.datasets)": [[23, "doubleml.datasets.make_irm_data", false]], "make_irm_data_discrete_treatments() (in module doubleml.datasets)": [[24, "doubleml.datasets.make_irm_data_discrete_treatments", false]], "make_pliv_chs2015() (in module doubleml.datasets)": [[25, "doubleml.datasets.make_pliv_CHS2015", false]], "make_pliv_multiway_cluster_ckms2021() (in module doubleml.datasets)": [[26, "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", false]], "make_plr_ccddhnr2018() (in module doubleml.datasets)": [[27, "doubleml.datasets.make_plr_CCDDHNR2018", false]], "make_plr_turrell2018() (in module doubleml.datasets)": [[28, "doubleml.datasets.make_plr_turrell2018", false]], "make_ssm_data() (in module doubleml.datasets)": [[29, "doubleml.datasets.make_ssm_data", false]], "nonlinearscoremixin (class in doubleml.double_ml_score_mixins)": [[31, "doubleml.double_ml_score_mixins.NonLinearScoreMixin", false]], "p_adjust() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.p_adjust", false]], "p_adjust() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.p_adjust", false]], "p_adjust() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.p_adjust", false]], "p_adjust() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.p_adjust", false]], "p_adjust() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.p_adjust", false]], "p_adjust() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.p_adjust", false]], "p_adjust() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.p_adjust", false]], "p_adjust() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.p_adjust", false]], "p_adjust() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.p_adjust", false]], "p_adjust() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.p_adjust", false]], "p_adjust() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.p_adjust", false]], "p_adjust() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.p_adjust", false]], "plot_tree() (doubleml.utils.doublemlpolicytree method)": [[35, "doubleml.utils.DoubleMLPolicyTree.plot_tree", false]], "policy_tree() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.policy_tree", false]], "predict() (doubleml.utils.dmldummyclassifier method)": [[32, "doubleml.utils.DMLDummyClassifier.predict", false]], "predict() (doubleml.utils.dmldummyregressor method)": [[33, "doubleml.utils.DMLDummyRegressor.predict", false]], "predict() (doubleml.utils.doublemlpolicytree method)": [[35, "doubleml.utils.DoubleMLPolicyTree.predict", false]], "predict_proba() (doubleml.utils.dmldummyclassifier method)": [[32, "doubleml.utils.DMLDummyClassifier.predict_proba", false]], "sensitivity_analysis() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.sensitivity_analysis", false]], "sensitivity_benchmark() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.sensitivity_benchmark", false]], "sensitivity_plot() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.sensitivity_plot", false]], "set_ml_nuisance_params() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.set_ml_nuisance_params", false]], "set_params() (doubleml.utils.dmldummyclassifier method)": [[32, "doubleml.utils.DMLDummyClassifier.set_params", false]], "set_params() (doubleml.utils.dmldummyregressor method)": [[33, "doubleml.utils.DMLDummyRegressor.set_params", false]], "set_sample_splitting() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.set_sample_splitting", false]], "set_x_d() (doubleml.doublemlclusterdata method)": [[4, "doubleml.DoubleMLClusterData.set_x_d", false]], "set_x_d() (doubleml.doublemldata method)": [[7, "doubleml.DoubleMLData.set_x_d", false]], "tune() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.tune", false]], "tune() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.tune", false]], "tune() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.tune", false]], "tune() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.tune", false]], "tune() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.tune", false]], "tune() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.tune", false]], "tune() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.tune", false]], "tune() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.tune", false]], "tune() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.tune", false]], "tune() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.tune", false]], "tune() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.tune", false]]}, "objects": {"doubleml": [[1, 0, 1, "", "DoubleMLAPO"], [2, 0, 1, "", "DoubleMLAPOS"], [3, 0, 1, "", "DoubleMLCVAR"], [4, 0, 1, "", "DoubleMLClusterData"], [5, 0, 1, "", "DoubleMLDID"], [6, 0, 1, "", "DoubleMLDIDCS"], [7, 0, 1, "", "DoubleMLData"], [8, 0, 1, "", "DoubleMLIIVM"], [9, 0, 1, "", "DoubleMLIRM"], [10, 0, 1, "", "DoubleMLLPQ"], [11, 0, 1, "", "DoubleMLPLIV"], [12, 0, 1, "", "DoubleMLPLR"], [13, 0, 1, "", "DoubleMLPQ"], [14, 0, 1, "", "DoubleMLQTE"], [15, 0, 1, "", "DoubleMLSSM"]], "doubleml.DoubleMLAPO": [[1, 1, 1, "", "bootstrap"], [1, 1, 1, "", "capo"], [1, 1, 1, "", "confint"], [1, 1, 1, "", "construct_framework"], [1, 1, 1, "", "draw_sample_splitting"], [1, 1, 1, "", "evaluate_learners"], [1, 1, 1, "", "fit"], [1, 1, 1, "", "gapo"], [1, 1, 1, "", "get_params"], [1, 1, 1, "", "p_adjust"], [1, 1, 1, "", "sensitivity_analysis"], [1, 1, 1, "", "sensitivity_benchmark"], [1, 1, 1, "", "sensitivity_plot"], [1, 1, 1, "", "set_ml_nuisance_params"], [1, 1, 1, "", "set_sample_splitting"], [1, 1, 1, "", "tune"]], "doubleml.DoubleMLAPOS": [[2, 1, 1, "", "bootstrap"], [2, 1, 1, "", "causal_contrast"], [2, 1, 1, "", "confint"], [2, 1, 1, "", "draw_sample_splitting"], [2, 1, 1, "", "fit"], [2, 1, 1, "", "sensitivity_analysis"], [2, 1, 1, "", "sensitivity_benchmark"], [2, 1, 1, "", "sensitivity_plot"], [2, 1, 1, "", "set_sample_splitting"]], "doubleml.DoubleMLCVAR": [[3, 1, 1, "", "bootstrap"], [3, 1, 1, "", "confint"], [3, 1, 1, "", "construct_framework"], [3, 1, 1, "", "draw_sample_splitting"], [3, 1, 1, "", "evaluate_learners"], [3, 1, 1, "", "fit"], [3, 1, 1, "", "get_params"], [3, 1, 1, "", "p_adjust"], [3, 1, 1, "", "sensitivity_analysis"], [3, 1, 1, "", "sensitivity_benchmark"], [3, 1, 1, "", "sensitivity_plot"], [3, 1, 1, "", "set_ml_nuisance_params"], [3, 1, 1, "", "set_sample_splitting"], [3, 1, 1, "", "tune"]], "doubleml.DoubleMLClusterData": [[4, 1, 1, "", "from_arrays"], [4, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLDID": [[5, 1, 1, "", "bootstrap"], [5, 1, 1, "", "confint"], [5, 1, 1, "", "construct_framework"], [5, 1, 1, "", "draw_sample_splitting"], [5, 1, 1, "", "evaluate_learners"], [5, 1, 1, "", "fit"], [5, 1, 1, "", "get_params"], [5, 1, 1, "", "p_adjust"], [5, 1, 1, "", "sensitivity_analysis"], [5, 1, 1, "", "sensitivity_benchmark"], [5, 1, 1, "", "sensitivity_plot"], [5, 1, 1, "", "set_ml_nuisance_params"], [5, 1, 1, "", "set_sample_splitting"], [5, 1, 1, "", "tune"]], "doubleml.DoubleMLDIDCS": [[6, 1, 1, "", "bootstrap"], [6, 1, 1, "", "confint"], [6, 1, 1, "", "construct_framework"], [6, 1, 1, "", "draw_sample_splitting"], [6, 1, 1, "", "evaluate_learners"], [6, 1, 1, "", "fit"], [6, 1, 1, "", "get_params"], [6, 1, 1, "", "p_adjust"], [6, 1, 1, "", "sensitivity_analysis"], [6, 1, 1, "", "sensitivity_benchmark"], [6, 1, 1, "", "sensitivity_plot"], [6, 1, 1, "", "set_ml_nuisance_params"], [6, 1, 1, "", "set_sample_splitting"], [6, 1, 1, "", "tune"]], "doubleml.DoubleMLData": [[7, 1, 1, "", "from_arrays"], [7, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLIIVM": [[8, 1, 1, "", "bootstrap"], [8, 1, 1, "", "confint"], [8, 1, 1, "", "construct_framework"], [8, 1, 1, "", "draw_sample_splitting"], [8, 1, 1, "", "evaluate_learners"], [8, 1, 1, "", "fit"], [8, 1, 1, "", "get_params"], [8, 1, 1, "", "p_adjust"], [8, 1, 1, "", "sensitivity_analysis"], [8, 1, 1, "", "sensitivity_benchmark"], [8, 1, 1, "", "sensitivity_plot"], [8, 1, 1, "", "set_ml_nuisance_params"], [8, 1, 1, "", "set_sample_splitting"], [8, 1, 1, "", "tune"]], "doubleml.DoubleMLIRM": [[9, 1, 1, "", "bootstrap"], [9, 1, 1, "", "cate"], [9, 1, 1, "", "confint"], [9, 1, 1, "", "construct_framework"], [9, 1, 1, "", "draw_sample_splitting"], [9, 1, 1, "", "evaluate_learners"], [9, 1, 1, "", "fit"], [9, 1, 1, "", "gate"], [9, 1, 1, "", "get_params"], [9, 1, 1, "", "p_adjust"], [9, 1, 1, "", "policy_tree"], [9, 1, 1, "", "sensitivity_analysis"], [9, 1, 1, "", "sensitivity_benchmark"], [9, 1, 1, "", "sensitivity_plot"], [9, 1, 1, "", "set_ml_nuisance_params"], [9, 1, 1, "", "set_sample_splitting"], [9, 1, 1, "", "tune"]], "doubleml.DoubleMLLPQ": [[10, 1, 1, "", "bootstrap"], [10, 1, 1, "", "confint"], [10, 1, 1, "", "construct_framework"], [10, 1, 1, "", "draw_sample_splitting"], [10, 1, 1, "", "evaluate_learners"], [10, 1, 1, "", "fit"], [10, 1, 1, "", "get_params"], [10, 1, 1, "", "p_adjust"], [10, 1, 1, "", "sensitivity_analysis"], [10, 1, 1, "", "sensitivity_benchmark"], [10, 1, 1, "", "sensitivity_plot"], [10, 1, 1, "", "set_ml_nuisance_params"], [10, 1, 1, "", "set_sample_splitting"], [10, 1, 1, "", "tune"]], "doubleml.DoubleMLPLIV": [[11, 1, 1, "", "bootstrap"], [11, 1, 1, "", "confint"], [11, 1, 1, "", "construct_framework"], [11, 1, 1, "", "draw_sample_splitting"], [11, 1, 1, "", "evaluate_learners"], [11, 1, 1, "", "fit"], [11, 1, 1, "", "get_params"], [11, 1, 1, "", "p_adjust"], [11, 1, 1, "", "sensitivity_analysis"], [11, 1, 1, "", "sensitivity_benchmark"], [11, 1, 1, "", "sensitivity_plot"], [11, 1, 1, "", "set_ml_nuisance_params"], [11, 1, 1, "", "set_sample_splitting"], [11, 1, 1, "", "tune"]], "doubleml.DoubleMLPLR": [[12, 1, 1, "", "bootstrap"], [12, 1, 1, "", "cate"], [12, 1, 1, "", "confint"], [12, 1, 1, "", "construct_framework"], [12, 1, 1, "", "draw_sample_splitting"], [12, 1, 1, "", "evaluate_learners"], [12, 1, 1, "", "fit"], [12, 1, 1, "", "gate"], [12, 1, 1, "", "get_params"], [12, 1, 1, "", "p_adjust"], [12, 1, 1, "", "sensitivity_analysis"], [12, 1, 1, "", "sensitivity_benchmark"], [12, 1, 1, "", "sensitivity_plot"], [12, 1, 1, "", "set_ml_nuisance_params"], [12, 1, 1, "", "set_sample_splitting"], [12, 1, 1, "", "tune"]], "doubleml.DoubleMLPQ": [[13, 1, 1, "", "bootstrap"], [13, 1, 1, "", "confint"], [13, 1, 1, "", "construct_framework"], [13, 1, 1, "", "draw_sample_splitting"], [13, 1, 1, "", "evaluate_learners"], [13, 1, 1, "", "fit"], [13, 1, 1, "", "get_params"], [13, 1, 1, "", "p_adjust"], [13, 1, 1, "", "sensitivity_analysis"], [13, 1, 1, "", "sensitivity_benchmark"], [13, 1, 1, "", "sensitivity_plot"], [13, 1, 1, "", "set_ml_nuisance_params"], [13, 1, 1, "", "set_sample_splitting"], [13, 1, 1, "", "tune"]], "doubleml.DoubleMLQTE": [[14, 1, 1, "", "bootstrap"], [14, 1, 1, "", "confint"], [14, 1, 1, "", "draw_sample_splitting"], [14, 1, 1, "", "fit"], [14, 1, 1, "", "p_adjust"], [14, 1, 1, "", "set_sample_splitting"]], "doubleml.DoubleMLSSM": [[15, 1, 1, "", "bootstrap"], [15, 1, 1, "", "confint"], [15, 1, 1, "", "construct_framework"], [15, 1, 1, "", "draw_sample_splitting"], [15, 1, 1, "", "evaluate_learners"], [15, 1, 1, "", "fit"], [15, 1, 1, "", "get_params"], [15, 1, 1, "", "p_adjust"], [15, 1, 1, "", "sensitivity_analysis"], [15, 1, 1, "", "sensitivity_benchmark"], [15, 1, 1, "", "sensitivity_plot"], [15, 1, 1, "", "set_ml_nuisance_params"], [15, 1, 1, "", "set_sample_splitting"], [15, 1, 1, "", "tune"]], "doubleml.datasets": [[16, 2, 1, "", "fetch_401K"], [17, 2, 1, "", "fetch_bonus"], [18, 2, 1, "", "make_confounded_irm_data"], [19, 2, 1, "", "make_confounded_plr_data"], [20, 2, 1, "", "make_did_SZ2020"], [21, 2, 1, "", "make_heterogeneous_data"], [22, 2, 1, "", "make_iivm_data"], [23, 2, 1, "", "make_irm_data"], [24, 2, 1, "", "make_irm_data_discrete_treatments"], [25, 2, 1, "", "make_pliv_CHS2015"], [26, 2, 1, "", "make_pliv_multiway_cluster_CKMS2021"], [27, 2, 1, "", "make_plr_CCDDHNR2018"], [28, 2, 1, "", "make_plr_turrell2018"], [29, 2, 1, "", "make_ssm_data"]], "doubleml.double_ml_score_mixins": [[30, 0, 1, "", "LinearScoreMixin"], [31, 0, 1, "", "NonLinearScoreMixin"]], "doubleml.utils": [[32, 0, 1, "", "DMLDummyClassifier"], [33, 0, 1, "", "DMLDummyRegressor"], [34, 0, 1, "", "DoubleMLBLP"], [35, 0, 1, "", "DoubleMLPolicyTree"], [36, 2, 1, "", "gain_statistics"]], "doubleml.utils.DMLDummyClassifier": [[32, 1, 1, "", "fit"], [32, 1, 1, "", "get_metadata_routing"], [32, 1, 1, "", "get_params"], [32, 1, 1, "", "predict"], [32, 1, 1, "", "predict_proba"], [32, 1, 1, "", "set_params"]], "doubleml.utils.DMLDummyRegressor": [[33, 1, 1, "", "fit"], [33, 1, 1, "", "get_metadata_routing"], [33, 1, 1, "", "get_params"], [33, 1, 1, "", "predict"], [33, 1, 1, "", "set_params"]], "doubleml.utils.DoubleMLBLP": [[34, 1, 1, "", "confint"], [34, 1, 1, "", "fit"]], "doubleml.utils.DoubleMLPolicyTree": [[35, 1, 1, "", "fit"], [35, 1, 1, "", "plot_tree"], [35, 1, 1, "", "predict"]]}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function"}, "terms": {"": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 22, 23, 25, 26, 27, 28, 29, 34, 37, 39, 40, 41, 42, 43, 45, 51, 54, 55, 56, 58, 59, 60, 64, 65, 66, 67, 69, 72, 73, 75, 83, 84, 88, 89, 91, 98, 99, 101, 102, 103, 104], "0": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 88, 89, 91, 92, 93, 94, 95, 98, 100, 101, 103], "00": [59, 60, 74], "000": [61, 88, 98, 104], "000000": [43, 45, 59, 60, 69, 71, 101], "0000000": [88, 98], "0000000000000010000100": [42, 69, 101], "000000e": [59, 60], "00000591": 63, "000006": [45, 63], "000017": 63, "000025": 58, "000034": 59, "000039": 58, "000064": 46, "000067": 58, "000091": [58, 71], "0001": [43, 59], "000135": 73, "000219": [13, 71], "000242": [14, 71], "000341": 58, "000442": 58, "00047580260495": 37, "000488": 58, "000494": 56, "0005": 43, "000522": 58, "0005a80b528f": 42, "000670": 58, "000743": 64, "000915799": [88, 98], "0009157990": [88, 98], "000943": [48, 49], "001": [37, 39, 40, 41, 42, 47, 72, 73, 74, 75, 88, 101, 104], "001051": 58, "001234": 60, "0012892": 74, "00133": 42, "00138944": [67, 75], "001494": 73, "0016": [41, 59], "001714": 71, "0018": [41, 59], "0019": 43, "002110": 49, "002169338": [88, 98], "0021693380": [88, 98], "0021693381": [88, 98], "002290": 52, "0023": 39, "002436": 56, "002539": 73, "0026": 43, "002779": 64, "0028": [39, 41, 59], "002821": 65, "0028213335041910427": 65, "002983": 58, "003": [18, 19, 20], "003111": 45, "003134": 63, "003220": 45, "003328": 63, "0034": 53, "003404": 45, "003415": 45, "003427": 58, "003779": 56, "003836": 63, "003924": 56, "003965": 48, "00409412": [67, 75], "0042": [41, 59], "004253": 45, "004392": 56, "004526": 45, "004645": 49, "004688": 8, "0047": [41, 59], "004846": 65, "005339": [48, 49], "005854453": 74, "005857": 58, "006055": 45, "006066": 48, "006425": 60, "00667": 74, "006922": 43, "006958": [48, 49], "007": 61, "007210e": 60, "00728": 101, "0073": 43, "007332": 50, "007332393760465": 50, "007659": 71, "00778625": 74, "007909": 48, "008": 65, "008023": 60, "008223": [48, 49], "008266e": 60, "008487": 43, "008642": 71, "008883698": 75, "00888458890362062": 67, "008884589": 67, "008dbd": 61, "008e80": 61, "009": [61, 65], "009122": 63, "009329847": 75, "009415": 61, "009428": 50, "00944171905420782": 65, "00950122695463054": 67, "009501226954630540": 67, "009501227": 67, "009645422": 40, "009656": 63, "00972": 43, "009790": 60, "009904": 71, "009986": 63, "01": [1, 2, 3, 5, 6, 8, 9, 10, 13, 14, 15, 35, 37, 40, 41, 42, 48, 49, 59, 60, 61, 62, 63, 72, 73, 74, 75, 88, 101, 104], "0101174": 74, "010213": 64, "010269": 58, "010450": 40, "010940": 58, "011131": 63, "011169": 61, "0112": 39, "01128": 43, "011511": 49, "011598": 63, "0116165": 74, "01167": 61, "0118095": 40, "011823": 64, "011962": 61, "011988e": 63, "01219": 42, "01274": 65, "012780": 60, "012831": 65, "013033": 61, "013034": 65, "013469": 48, "01351638": 40, "013593": 64, "013617": 60, "01398951": 40, "013990": [88, 98], "014": 61, "01403089": 40, "014080": [48, 49], "014432": 52, "014637": 58, "014681": 64, "015": 42, "015035": 48, "015038": 50, "015548": 49, "015565": 63, "015698": 63, "01574297": 63, "015743": 63, "015831": 48, "016011": 49, "016154": 58, "016200": [48, 49], "016315": 54, "016429": 71, "01643": 102, "017": 42, "0170884": 74, "017393e": 88, "01772": 91, "017800092": [88, 98], "0178000920": [88, 98], "017805": 48, "018": 42, "018023": 62, "018099": 48, "018148": 63, "018508": 48, "018602": 73, "019008": 49, "01903": [42, 72, 99, 101], "01916030e": 74, "01925597": 40, "019439633": [88, 98], "0194396330": [88, 98], "0194396331": [88, 98], "019596": 50, "019660": [14, 71], "01990373": 66, "019953": 48, "019974": 60, "02": [48, 49, 59, 60, 63, 71, 74], "02016117": 101, "020166": 63, "020271": 58, "020360838": [88, 98], "0203608380": [88, 98], "0203608381": [88, 98], "020387": 49, "02052929": [67, 75], "02079162e": 74, "020819": 71, "02092": 101, "021013": 48, "021269": [54, 55], "02163217": 40, "021866": 62, "021926": 50, "022": 61, "02247976": 40, "022768": 43, "022783": 64, "022915": 58, "022954": 71, "022969": 60, "022991": 49, "023020e": [59, 60], "023160": 48, "023256": 63, "023505": 48, "023563": [88, 98], "023955": 60, "024355": 52, "024364": 89, "024401": [54, 55], "024604": 58, "024782": 63, "024926": 52, "025": [48, 49, 54, 55, 61], "025077": [88, 98], "02528067": 57, "0253": 42, "025443": 43, "0257": 39, "025708e": 49, "025783e": 49, "025813114": [88, 98], "0258131140": [88, 98], "02584": 42, "025958": 71, "026518e": 48, "026669": 60, "026723": 50, "027329": 48, "02791": 43, "028001": 49, "0281": 42, "028520": [48, 49], "02897287": 51, "029": 74, "02900983": 63, "029010": 63, "029022": 49, "029209": 104, "029364": [89, 94], "029831": 63, "029910e": [59, 60], "02e": 41, "03": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 48, 49, 50, 56, 59, 60, 63, 64, 65, 74, 89, 94, 104], "030087": 71, "0301": 42, "03018": [10, 71], "030346": 101, "0307": 42, "030934": 63, "030962": 63, "03113": 66, "031134": 72, "031156": 49, "031269": 43, "031639": 63, "031820": 49, "03191": 102, "032": 61, "03220": 103, "0323": 39, "03244552": 72, "0325": 101, "03257115": 74, "032638": 61, "032953": 64, "033224": 48, "033737": 49, "033756": 50, "033946": [54, 55], "034097": 48, "03411": 101, "034226": 60, "034690": 50, "034812763": [88, 98], "0348127630": [88, 98], "0348127631": [88, 98], "034836": 59, "03489": [26, 40, 58], "035088": 49, "035119185": [88, 98], "0351191850": [88, 98], "0351191851": [88, 98], "035264": 49, "03536": 101, "03538": 42, "03539": 42, "035391": 43, "0354": 42, "035411": 101, "035441": 49, "03545": 42, "035545": 43, "035572": 43, "035730": 63, "03574": 43, "035762": 63, "0359": 42, "036129015": [88, 98], "0361290150": [88, 98], "0361290151": [88, 98], "036143": 63, "036147": 63, "036240": 45, "036729": 58, "0368": 39, "036874e": 49, "036945": 60, "03698487": 63, "036985": 63, "037008": [54, 55], "0374": 42, "037509": 66, "037747": [48, 49], "038845": 48, "039036": 48, "039102": 61, "039141": 45, "03917696": [75, 88], "03920960e": 74, "039310e": 50, "039660": 48, "039897": 49, "04": [19, 41, 45, 48, 49, 59, 60, 63, 64, 74, 104], "040112": [88, 98], "040139": [48, 49], "040141": 49, "040445": 48, "040533": [75, 88], "04053339": 88, "040688": 48, "0408": 48, "040912": 49, "040919": 49, "04107": 12, "041112": 49, "041147": 50, "041284": 50, "041387": 50, "041459": 60, "041491e": 50, "04165": 73, "0418": 39, "041831": 50, "04183522": 74, "041925": 48, "042034": 65, "042249": 49, "042265": 50, "042266": 48, "0425": 72, "0426246": 74, "0428": 66, "042822e": 60, "042844e": 63, "043108": 60, "0433": 39, "0434e374": 42, "04387": 72, "043998": 49, "044": 61, "0440569": 74, "044062": 49, "044113": 50, "04415": 42, "04424": 42, "044334": 48, "04444978": [88, 98], "044449780": [88, 98], "0445": 72, "04465": 40, "044704": 49, "04486": 101, "04487585": [89, 94], "04491": 73, "04497975": [89, 94], "045": 61, "04501612": 88, "04502": [72, 75, 88], "045144": 58, "045379": 101, "04552": 58, "045553": 50, "045624": 52, "04563": 72, "045754": 63, "04586": 72, "045932": 63, "045993": 72, "04625": 72, "046405": 71, "046527": 50, "04653976": 63, "046540": 63, "0466028": 40, "046728": 64, "046757": 49, "04682310e": 74, "046922": 72, "047156": 48, "047194": 8, "047215": 49, "047375e": 48, "047954": 58, "048308": 55, "048326": 49, "048699": 66, "048723": 72, "049264": 45, "04955445": 74, "04973": 49, "049959": 48, "05": [37, 39, 40, 41, 42, 48, 49, 50, 53, 57, 58, 59, 60, 61, 63, 65, 72, 73, 74, 75, 88, 101, 104], "05039": 64, "050399": 49, "050538": 49, "050843": 49, "050856": [71, 72], "051": [42, 74], "051578e": 49, "051867e": 50, "052000e": 60, "052298": 63, "0523": 61, "052380": 48, "052488": 55, "052502": 63, "052745": 50, "053": 42, "05316864": 74, "0533": 39, "053331": 50, "053342": 60, "053389": [88, 98], "053436": 9, "053541": 63, "053558": 50, "054": [42, 61], "054068": 58, "054162": 58, "054348": 88, "054370": 50, "054529": [88, 98], "054771e": 63, "055078": 48, "055165": 64, "055171": 49, "055338e": 59, "055439": 60, "055493": 65, "055680": [88, 98], "056052": 48, "056389": 49, "056499": 55, "056745": 48, "056953": 48, "057095": 63, "057274": 45, "0576": [41, 59], "057762": 63, "057962": 50, "058042": [88, 98], "058276": 60, "058375": 45, "058463": 63, "058508": 66, "0590": 39, "059187": 49, "059384": 63, "059627": 60, "059630": 52, "059685": 63, "06": [18, 19, 20, 45, 48, 49, 50, 59, 60, 63, 71, 72], "06008533": 73, "060201": 63, "060212": [59, 60], "060417": 48, "060581": 57, "060845": [88, 98], "0611": 39, "06111111": 42, "0615": 39, "062414": 60, "062507": 63, "0628": 39, "062964": [88, 98], "063017": 45, "0632": 39, "0635": 39, "0636": 39, "063618": 49, "063685": 45, "063700": 48, "0638": 39, "063881": 73, "0640": 39, "064161": 60, "064175": 45, "06428": 59, "064280": 59, "064400": 48, "0645": 39, "0646222": 41, "0647": 39, "0649": 39, "06491032": 74, "065": 65, "065128": 48, "0653": 39, "065356": [54, 55], "0654": 39, "065451": 60, "0655": 39, "065725": 50, "0659": 39, "065969": 73, "0662": 39, "066464": 64, "066689e": 49, "066889": 63, "0669": 39, "06692492": 74, "06694255": 73, "0671": 39, "067233e": 74, "067240": 63, "06724028": 63, "0673": 39, "0675": 39, "067528": 65, "067721": [88, 98], "068073": 49, "06827": 64, "06834315": 51, "068377": 60, "068514": 48, "068934": 45, "06895837": 40, "069443": 45, "0695854": 40, "069600": 60, "07": [48, 49, 60, 63, 65, 74], "070020": 63, "070196": 50, "0701961897676835": 50, "0702127": 40, "0704": 39, "070497": 65, "070534": 15, "070552": 48, "070574e": 60, "0707": 39, "070751": 48, "07085301": 73, "070884": 63, "071": 37, "0711": 39, "071285": 88, "07136": [40, 58], "071488e": 50, "0716": 39, "07168291": 40, "071777": 72, "071782": [14, 71], "0719": 39, "07202564": [54, 55], "072058": 48, "07222222": 42, "072293": 62, "0727": 73, "07277916": 74, "072852": 48, "073013": 63, "073207": 58, "073352": 48, "07347676": 40, "07350015": [26, 29, 40, 58], "073520": 50, "0736": 39, "07366": [42, 72], "073694": 49, "0743": 39, "074304": 88, "07436521": 74, "074426": 63, "07456127": 40, "074601141": 74, "074617": 49, "07479278": 64, "074927": 45, "075261": 52, "075384": 63, "07538443": 63, "07544271e": 74, "07561": 101, "07564554e": 74, "0758": 65, "075809": 45, "075869": 72, "076019": 59, "076156": 88, "076179312": [88, 98], "0761793120": [88, 98], "076322": 63, "076347": 50, "0765": 42, "076559": [71, 72], "076596": 48, "0766474": 74, "076684": 101, "07685043": 74, "07689": 42, "07691847": 74, "076953": [54, 55], "076971": 43, "077161": 60, "07727773e": 74, "077319": 63, "077502": [89, 94], "077702": 45, "0777777777777778": 72, "07777778": [42, 72], "077840": 60, "077883": 63, "07796": 73, "078096": 88, "078207": 43, "07828372": [88, 98], "078474": [88, 98], "078810": 63, "079085": 43, "07915": 42, "07919896": 74, "079458e": 59, "07961": 64, "07978296": 74, "08": [48, 49, 50, 60, 63, 65, 73], "08005229": 74, "08031571": 74, "080351": 49, "080854": 60, "080900": 48, "08091581": 74, "080947": 43, "081": 42, "08102679": 74, "081100": 63, "081230": [48, 49], "081488": 58, "08154161": 74, "08181827e": 74, "08191204": 73, "0820": 39, "08220133": 74, "082263": 11, "082297": 74, "0824301": 74, "082574": 9, "082804": 52, "082858": 49, "082934": 60, "082973": 58, "083258": [88, 98], "083318": 88, "08333333": 42, "08333617": 74, "0835771416": 40, "083706": 65, "083750": 60, "083949": 65, "084": 40, "084156": 49, "084184": 50, "0841842065698133": 50, "084212": 56, "084269": 60, "084337": 73, "084633": 54, "084771": 48, "08482782": 74, "0853505": 40, "085395": 48, "085566": 50, "085671": 48, "085965": 60, "08602774e": 74, "086109": 49, "0862": 99, "086264": 50, "086464": 48, "08664208": 74, "086679": 72, "086889": 54, "087": 74, "0872": 39, "08745354": 74, "087491e": 49, "087561": 48, "087634": 48, "08776184": 74, "087947": 63, "088048": 63, "08807789": 74, "088282": 55, "088357": 63, "08848": 72, "088482": [14, 71], "088504e": 11, "088696e": 49, "08870946": 74, "08888889": 42, "089064e": 48, "0892368": 74, "0894": 39, "089661": 55, "08968939": 40, "089825": 49, "08e": 41, "09": [37, 48, 50, 59, 60, 63, 71], "090": 61, "09000000000000001": 72, "090025": 60, "09015": 39, "090255": 63, "09085": 74, "09103": 74, "091046": 55, "09124997": 74, "09134063": 74, "091391": [88, 98], "091406": 89, "091535": 48, "0916": 39, "091611": 49, "091992": 62, "092229": 65, "092247": 63, "092263": 73, "09233029": 74, "092365": [88, 98], "092919": 91, "093043": 63, "09310496": [88, 98], "09311549": 74, "093153": 63, "09341787": 74, "093474": 63, "09347419": 63, "093746": 88, "093950": 58, "094026": 58, "094118": 63, "094381": 58, "09444444": 42, "094829": 73, "094999": 63, "095": 61, "095104": 45, "095475": 71, "095781": 3, "095785": 45, "095835": 49, "096": 61, "09603": 99, "096245": 71, "096337": 58, "096418": 45, "096550": 54, "096616": 71, "096741": 51, "09682314": 73, "096915": 65, "096934": 49, "097157": 65, "097468": 50, "09779675": [88, 98], "097796750": [88, 98], "098": 41, "098256": 63, "09830758": 64, "098308": 64, "098317": 60, "098319": 63, "0986": 39, "098712": 63, "09879814e": 74, "099647": 62, "099670": 60, "099731": [48, 49], "09980311": [88, 98], "09988": 102, "09e": 74, "0_": 25, "0ff823b17d45": 42, "0x1747bdd4520": 43, "0x1747bdd6b90": 43, "0x2920d7b7150": 62, "0x7f6307105460": 65, "0x7fe30ec5a4b0": 104, "0x7fe30f175580": 88, "0x7fe30f175970": 88, "0x7fe30f176e10": 88, "0x7fe30f177380": 88, "0x7fe30f205af0": 72, "0x7fe30f33a690": 72, "0x7fe30f670fe0": 73, "0x7fe30f989280": 72, "0x7fe314f1f320": 73, "0x7fe3152da570": 94, "0x7fe3162a3680": 89, "1": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "10": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 26, 27, 29, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 99, 101, 102, 104], "100": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 26, 28, 29, 40, 42, 48, 49, 51, 53, 56, 57, 58, 61, 65, 66, 67, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 101, 103], "1000": [8, 10, 38, 46, 47, 51, 52, 54, 55, 56, 57, 59, 60, 64, 65, 68, 71, 73], "10000": [37, 48, 49, 52, 59, 60, 63], "100000e": 60, "100356": 50, "10038": 64, "10039862": [66, 73], "100517": 88, "10079785": 73, "100807": [48, 49], "100858": 64, "10089588": 63, "100896": 63, "10092": 60, "100923": 63, "100_000": 61, "101": [18, 19, 20, 39, 71, 73, 102, 103], "101076": 49, "10126": 60, "10127930": [88, 98], "101279300": [88, 98], "1015": [41, 59], "1016": [18, 19, 20, 39], "1016010": 41, "1018": 60, "1018162": 74, "102": [37, 69, 71, 73, 101, 103], "1021147": 74, "10235": 60, "102553e": 48, "10258": 60, "102616": 50, "102775": 50, "1027765": 74, "10299": 59, "103": [58, 66, 71, 73, 103], "10307": 88, "1031": 60, "103186": 49, "103189": 60, "10348": 59, "103497": 63, "1038": 60, "103806": 50, "103951906910721": 50, "103952": 50, "10396": 59, "104": [41, 59, 66, 71, 73, 103], "10406": 60, "1041": 39, "10414": 60, "1042696": 74, "1045303": 40, "104787": 58, "105": [25, 40, 48, 58, 71, 73, 103], "1050": 65, "105318": 63, "1054": 42, "1055": 39, "105722": 49, "105751e": 48, "105942": 48, "106": [42, 61, 71, 73, 103], "10607": [43, 69, 101], "10618": 60, "10637173e": 74, "106391": 88, "106401e": 48, "106595": 73, "106691": 71, "106743": 49, "106746": 63, "107": [42, 65, 71, 73, 103], "107073": 50, "107295": 88, "1073": 60, "10747": [43, 69, 101], "107872": 71, "10799": 60, "108": [71, 73, 99, 102, 103], "1080": [26, 29, 39, 40, 58], "10824": [43, 69, 101], "108257e": 60, "108259": 45, "10831": [43, 69, 101], "10878571": 63, "108786": 63, "109": [48, 71, 73], "109005": 63, "10903": 59, "109063": 61, "109069": [88, 98], "109079e": 63, "109273": 58, "10928": 60, "1093": 53, "109454": 60, "1096": 39, "10967": 59, "109811": 56, "109861": 101, "1099472942084532": 46, "10e": [50, 63], "11": [12, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 101, 104], "110": [71, 73, 103], "1101": 60, "11019365749799062": 65, "110194": 65, "110359": 58, "110365": 65, "110681": 64, "1107": 60, "11071087": [66, 73], "110717": [88, 98], "1109": 60, "110902": 50, "110902411746278": 50, "111": [71, 73, 103], "1111": [16, 17, 27, 38, 40, 47, 53, 58, 65, 68, 73, 89, 94, 99], "111164": 62, "11120": 60, "1114151820212630333440425256626771889096": 74, "1118": 41, "11199615e": 74, "112": [42, 71, 73, 103], "1120": 59, "1120514": 74, "11208236": [67, 75], "1121617192224363748515558597476778295100": 74, "1122": 60, "112216": 50, "1129": 60, "113": [16, 71, 73, 103], "113207": 63, "113270": 50, "113415": 60, "1135": 74, "11375": 60, "113780": 58, "114": [71, 73, 103], "11409": 59, "11414": 59, "1144500": 40, "11447": 64, "114530": 54, "1145370": 40, "114570": 49, "11458": 60, "114591": 49, "114647": 50, "1147": 39, "1148": 60, "114834": 60, "11488": 60, "11495": 60, "115": [71, 73, 103], "11500": [59, 104], "115060e": 63, "115296e": 60, "115297e": 59, "11552911": 64, "11559": 60, "115636": 49, "11570": 59, "115792e": 60, "115972": 48, "116": [71, 73, 103], "116027": 50, "11617": 60, "11627": 61, "116274": 50, "116483": 49, "116569": 60, "1166": 102, "1167": 59, "11673": 60, "11675": 60, "117": [48, 71, 73], "1170": 64, "11700": 104, "117072": 54, "117242": 63, "11724226": 63, "117366": 63, "11743": 104, "11750": 60, "1176": 39, "1177": [39, 59], "117710": 50, "11792": 41, "11796": 60, "118": [71, 73], "11802": 60, "1182": 41, "11823404": 65, "118255": 63, "1186": 41, "118601": 58, "11861": 41, "118721": [49, 55], "1187339840850312": 58, "11879": 60, "118799": 60, "118938e": 73, "118952": 58, "119": [65, 71, 73, 103], "11932": 60, "119348e": 49, "11935": 64, "119669": 73, "119766": 63, "1198": [40, 58], "12": [15, 37, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 99, 101, 102, 103, 104], "120": [37, 51, 66, 71, 73, 103], "12002": 59, "1202": 102, "120456": 55, "120468": 63, "12046836": 63, "120567": [54, 55], "120636": 48, "120721": 58, "12097": [16, 17, 27, 40, 53, 58, 68, 99], "121": [60, 61, 71, 73, 103], "1210": 60, "12101": 60, "12105472": [88, 98], "121054720": [88, 98], "1211": 60, "1213405": 40, "121399": 60, "1214": [88, 98], "121584e": 63, "121711": 60, "121774": 56, "12196389e": 74, "122": [18, 19, 20, 39, 69, 71, 73, 102, 103], "12214": 41, "12223182e": 74, "122408": 50, "122777": 88, "123": [41, 42, 59, 65, 71, 73, 103, 104], "1230": 60, "123192": 65, "12323": 60, "1234": [37, 38, 39, 43, 46, 47, 68, 72, 74, 88, 98], "12348": 65, "1238": 60, "123806e": 49, "123917": 60, "124": [71, 73], "12410": 60, "124465": 48, "124805": 59, "125": [71, 103], "12500": 59, "125065": 88, "12539340": [88, 98], "1255": 60, "12579": 60, "1258": 40, "126": [71, 103], "12606": 60, "12612": 60, "126777": 88, "126802": 60, "126875": 48, "12689": 60, "127": [18, 71, 103], "127006": 60, "12705095": [75, 88], "12707800": 40, "12752825": [88, 98], "127563": 64, "1277": 61, "127778": 60, "127831": 49, "128": [41, 71, 103], "12802": 41, "12814": 60, "128273e": 48, "128312": 63, "128408": 58, "1285": 39, "12861": 60, "128651": 49, "129": [37, 58, 71, 103], "129152": 48, "12945": 102, "1295": [39, 60], "129514": 60, "12955": 59, "1298": 60, "12980769e": 74, "12983057": 73, "13": [19, 20, 22, 24, 38, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 63, 64, 65, 67, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 101, 104], "130": [42, 54, 58, 71, 103], "130122": 64, "13034980e": 74, "130370": 50, "130526": 71, "1306": 64, "130829": 63, "13091": 60, "131": [71, 103], "13102231": 73, "13119": 64, "1312": 104, "131211": 60, "1313": [41, 104], "13137893e": 74, "131544": 48, "131771": 49, "1318": 39, "132": [42, 58, 71, 103], "13208": 104, "1321": [59, 104], "1324": [41, 59], "132454": 52, "1325": 41, "132671": 50, "13288": 59, "132903": 60, "133": [42, 69, 71, 102, 103], "13300": 60, "133202": 60, "133204": 48, "133343": 49, "133421": 60, "13356": 60, "133596": 63, "13398": 65, "133f5a": 61, "134": [58, 66, 71, 103], "1340371": 39, "1341": 41, "134146": 60, "1342": 60, "134211": 63, "1343": 59, "134542": 48, "134567": 60, "1346035": 41, "134687": 60, "13474": 60, "134765": 60, "1348": 59, "1349": 64, "13490": 60, "135": [42, 61, 71, 73, 103], "13505272": 40, "135329": 56, "135344": 45, "135352": 5, "135379": 88, "135396": 48, "135707": 72, "135755": 71, "135856": 63, "13585644": 63, "135871": 58, "136": [43, 58, 65, 71, 103], "1360": 41, "13602": 65, "136089": 58, "1361": 60, "136178": 73, "13642": 60, "136442": 58, "1366": 61, "136836": 58, "137": [18, 42, 43, 71, 103], "1371": 60, "137213": 49, "137396": 63, "137529": 73, "1378": 60, "137809": 73, "138": [71, 103], "1380": 59, "138068": 54, "13809": 60, "138264": 65, "138378": 50, "1386": 39, "13868238": [88, 98], "138682380": [88, 98], "138698": [88, 98], "1387": 39, "138851": 54, "13893": 60, "138953": 45, "139": [65, 71, 101], "1390": 59, "139491": [88, 98], "13956": 64, "139582e": 12, "1398": 60, "1399": 39, "139921": 71, "14": [38, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 54, 55, 56, 58, 59, 60, 63, 64, 65, 67, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 101, 104], "140": [51, 60, 66, 71, 103], "1400": 60, "14000073": 74, "1401": 39, "140770": [48, 49], "140833": 50, "140861": 40, "1408926": 74, "140926": 63, "141": [60, 71, 103], "141098e": 60, "14114": 64, "141347": 48, "141384": 56, "14141": 60, "141460": 45, "141546": [88, 98], "141729": 49, "141820": 50, "142": [71, 103], "14200098": [88, 98], "142270": 52, "142382": 48, "1424": 72, "142624": 49, "14268": 73, "14281403493938022": 72, "14289": 60, "143": [61, 69, 71, 103], "143495": 71, "1435": 60, "14368145": [88, 98], "1439282": 74, "144": [48, 49, 71, 103], "14400": 59, "14405": 60, "14406": 60, "144084": 50, "1441": 39, "144137": 51, "144241": 54, "1443": 60, "144500e": 60, "144669": 63, "1447": 60, "144800": 50, "144861": 59, "144908": 62, "145": [71, 103], "145027": 45, "145245": 63, "14532650": [88, 98], "1455008": 74, "145513": 48, "145625": 63, "145748": 88, "14587": 60, "146": [71, 103], "146037": 63, "146046": 49, "146087": 101, "146142808990006": 50, "146143": 50, "14625": 60, "1465": 41, "146641": 88, "14667": 60, "1468115": 40, "146973": 50, "1469734445741286": 50, "147": [71, 103], "147015e": 60, "14702": 43, "147121": 63, "14744": 60, "14772": 60, "1479": 60, "14790924": [88, 98], "147909240": [88, 98], "147927": 43, "14798": 60, "148": [71, 103], "14803": 60, "148134": [48, 49], "148161": 63, "148443": 71, "14845": 43, "1485": 60, "148750e": [59, 60], "148790": 60, "148802": 60, "148950": 48, "149": [71, 103], "1490324": 74, "1492": 37, "149228": 65, "149285": 63, "149472": 65, "149671e": 49, "149714": 58, "14984": 60, "149858": [13, 71], "149882": 73, "149898": 63, "149973e": 49, "15": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 17, 38, 40, 41, 42, 45, 47, 48, 49, 50, 51, 54, 56, 57, 58, 59, 60, 63, 64, 65, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 101, 104], "150": [25, 42, 48, 49, 61, 65, 71, 103], "15000": [41, 59], "150000": 41, "15000000000000002": [50, 60, 63, 72], "150000e": 60, "150136": 49, "1502": 40, "150200": 58, "150334": 60, "150408": 40, "150614": 43, "150719e": 59, "151": [71, 103], "151047e": 54, "151063": 48, "151087e": 48, "15113": 60, "151636": 50, "151819": 63, "15194": 59, "152": [71, 103], "152034": 60, "152148": [48, 49], "152772": 49, "15285": 60, "152926": 52, "153": [65, 71, 103], "1530959776797396": 50, "153096": 50, "153119": 50, "1532415": 74, "15347": 60, "1534794": 74, "15354": 64, "153587": 58, "153633": 43, "153639": 74, "154": 71, "15430": 104, "154421": 88, "1545": 60, "154557": 63, "154758": 88, "154811": 49, "154828": 50, "155": [37, 71, 103], "155000": 59, "155025": 63, "155120": 63, "155160": 45, "155174": 45, "155516": 62, "15556": 60, "155610": 48, "155676": 48, "1557093": 40, "156": [71, 103], "1560": 60, "156021": 63, "156202": [48, 49], "156317": [48, 49], "1564": [88, 98], "156545": 88, "156567": 48, "1569": 60, "156969": 50, "157": [71, 103], "157091": 88, "1576": 60, "157613": 48, "1577657": 40, "158": [59, 71, 103], "158007": 63, "158087": 48, "15815035": 41, "158178": 50, "1582": 60, "1586": 60, "158697": [88, 98], "1589": 60, "15891559": 63, "158916": 63, "159": 103, "159011": 48, "15916": 39, "159202e": 49, "159386": 64, "1596": 42, "159959": 60, "16": [3, 37, 38, 40, 41, 42, 45, 48, 49, 50, 56, 58, 59, 60, 63, 64, 65, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 101, 104], "160": [51, 66, 103], "1602574": 74, "1604": 41, "160438": 48, "160932": 50, "161": [42, 55, 102, 103], "161049": 49, "161088": 49, "161141": 58, "161198": 62, "161236": 63, "161243": 63, "161288": 49, "161543": 60, "1619": 41, "162": 103, "16201": 60, "16211": 59, "162153": 63, "1622": 60, "16241": 60, "162436": 65, "1626685": 40, "162683": 65, "162710": 50, "1627630": 74, "162784": 73, "1628": 59, "162930": 60, "163": [60, 103], "163194": 63, "163393e": 49, "163566": 60, "163577": 45, "1637463": 74, "163816": 45, "163895": 50, "164": [45, 103], "164034": 88, "164608": 63, "164617": 59, "164698": 56, "1648": 39, "164801": 63, "164805": 50, "164864": 58, "165": 103, "16500": 59, "165178": 63, "16536299": [88, 98], "165362990": [88, 98], "16539906e": 74, "1654": 60, "165419": 63, "165549": 101, "165569": 48, "165707": 45, "16587": 59, "16590": 60, "16597": 60, "166": 103, "166079": 48, "1661": 59, "166375": 71, "167": [41, 59, 103], "16725": 60, "1673488": 74, "167547": 63, "1676": 60, "167765": 60, "167993": 88, "168": 103, "16803512": [88, 98], "168092": 88, "1681": 39, "168195": 64, "16824883": 74, "1683": 59, "168614": 63, "168931": 63, "169": [42, 103], "1691": [39, 60], "16910": 60, "169117": 65, "169196": 63, "169230e": 50, "16951": 60, "16984": 60, "17": [38, 40, 41, 42, 48, 49, 56, 58, 59, 60, 63, 64, 65, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 101, 104], "170": 103, "1704": 60, "17083": 60, "171": 103, "1712": 102, "1714": 41, "171575": 63, "171709": 48, "171815": 72, "171868e": 48, "171942": 60, "172": 103, "172022": [88, 98], "172083": 49, "172793": 63, "173": 103, "17372": 60, "1738": 60, "17385178": 72, "173969": 88, "174": 103, "174106": 64, "174185": 63, "174499": [88, 98], "174516e": 63, "17453": 60, "1746": 60, "174743": 71, "174884": 49, "174901": 49, "174940": 71, "17499": 60, "175": 103, "1751": 59, "175176": 63, "17522": 60, "175284": 50, "175342": 48, "175635027": 40, "17576": 60, "175894": 65, "175931": 73, "176495": 63, "17655394": 63, "176554": 63, "176929": [88, 98], "177": [102, 103], "177007": 63, "17700723": 63, "177043": [48, 49], "1773": 60, "177304": 49, "1774": 39, "177463": 62, "177496": 63, "177611": 63, "177751": 63, "17778": 60, "177933e": 48, "17799": 60, "177995": 63, "178": [56, 103], "178169": 54, "178218": 49, "17823": 42, "178704": 88, "178763": 63, "178805": 55, "178934": 88, "178980": 49, "179": [54, 103], "1795850": 40, "179588e": 63, "1798913180930109556": 61, "18": [38, 40, 41, 42, 43, 48, 49, 56, 57, 58, 59, 60, 63, 64, 65, 69, 71, 72, 73, 74, 88, 98, 101, 104], "180": [51, 66, 103], "180143": 45, "18015": 60, "180176e": 60, "180190": 73, "1803": 39, "18030": 60, "180348": 49, "180575": [54, 55], "1807": [39, 60], "1809": 102, "180951": 63, "181": [61, 103], "1812": 60, "1814": 39, "18141": 60, "181446": 88, "182": 103, "1820": 39, "182208e": 48, "182393": 48, "182633": 63, "182692": 49, "182849": 63, "183": [42, 103], "183373": 73, "183526": 50, "18356413": 73, "18368": 60, "183855": 72, "183888": 58, "184": [42, 102, 103], "185": [37, 41, 42], "18500": 60, "1855": 60, "185585": 71, "185984": 48, "186": [60, 103], "186027": 48, "18604": 60, "1862": 39, "186237": 49, "18631": 60, "18637": 99, "186589": 45, "18666": 60, "186735": 63, "18678094e": 74, "186795": 49, "186836": 63, "187": 103, "187153": 88, "187664": 48, "187690": 63, "18789": 60, "188": 103, "188175": 63, "1881752": 63, "188223": 63, "1887": 73, "18888149e": 74, "188991": 88, "189": [42, 103], "189195": 60, "189248": 48, "189293": 60, "189302": 48, "189493": 49, "1895815": [26, 40, 58], "189737": 63, "189927": 60, "189998": 63, "19": [38, 40, 41, 42, 48, 49, 58, 59, 60, 63, 64, 65, 71, 72, 73, 74, 88, 101, 104], "190": [42, 103], "19000": 60, "190096": 88, "1901311": 74, "190140": 48, "19031969": 63, "190320": 63, "19033538": 40, "190381": 73, "190648": 8, "19073905e": 74, "190809": 63, "190869": 71, "190892": 65, "1909": [26, 40, 58], "190915": 50, "190921": 55, "190982": 63, "191": [42, 102, 103], "1912": 102, "1912705": 68, "191320e": 59, "191397": 71, "191606": 59, "191716": 60, "1918": 39, "192": 103, "1922": 60, "192240": 88, "192505": 62, "192526": 64, "19252647": 64, "192539": [14, 71], "192587": 63, "192739": 49, "192952": 45, "193": 103, "193060": 63, "193069e": 48, "193300": 48, "193308": [14, 71], "19374710e": 74, "19382": 60, "19385": 60, "193f0d909729": 42, "194": [57, 60, 103], "1941": 41, "19413": [59, 60], "194232": 49, "194601": 51, "195": 103, "19508": 65, "19508031003642462": 65, "19509680e": 74, "195377": 63, "195396": 63, "195547": 60, "195564": 58, "19559": [41, 59], "195761": 63, "1959": 102, "196": 103, "196189": 63, "196437": 60, "19680840": [88, 98], "197": 103, "1970": 60, "197000e": 60, "19705": 60, "197225": [43, 69, 101], "1972250000001000100001": [42, 69, 101], "1974": 60, "197424": 72, "197484": 88, "19756": 60, "19758": 60, "197600": 52, "197711": 60, "197920": 48, "19793": 60, "19794": 60, "198": 103, "198218": 58, "19824": 60, "198351": 63, "19849902": 74, "198549": 43, "198687": 41, "1988": [38, 47, 68, 73], "198953": 71, "199": 103, "1990": [41, 59, 60], "1991": [41, 59, 60, 104], "199206e": 48, "1992591": 74, "199281e": 63, "199282e": 60, "199412": 49, "199458": 88, "1995": [40, 58], "1998": 61, "19983954": 66, "19984945": 74, "199893": 54, "1999": [61, 66], "199959": 48, "1_": [50, 63], "1e": [1, 3, 5, 6, 8, 9, 10, 13, 14, 15, 60], "1f77b4": 52, "1x_4x_3": 52, "2": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 88, 89, 90, 91, 94, 95, 96, 97, 98, 101, 102, 103], "20": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 22, 23, 24, 26, 27, 28, 38, 40, 41, 42, 48, 49, 50, 51, 54, 56, 57, 58, 59, 60, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 88, 89, 94, 101, 104], "200": [21, 24, 25, 39, 50, 51, 53, 57, 62, 63, 66, 68, 72, 103], "2000": [15, 17, 41, 45, 48, 49, 50, 59, 60, 63, 66, 73], "20000": [41, 59], "20000000000000004": [50, 60, 63], "200000e": 60, "200065": 45, "20010": 60, "200110": 60, "2003": [16, 102], "200303": 101, "2005": 51, "20055": 60, "2006": 60, "20073763": 57, "20074": 60, "200863": 48, "201": [42, 60, 103], "2010": [40, 58], "2011": [40, 58, 99, 101], "2013": [53, 88, 98, 102], "2014": [88, 98, 102], "2015": [25, 102], "201528": [48, 49], "20158": 60, "2016": 61, "2017": [23, 102], "201768": 58, "201788e": 60, "201796": 56, "2018": [16, 17, 27, 28, 38, 40, 41, 47, 51, 53, 57, 58, 59, 60, 64, 68, 74, 88, 98, 99, 102, 103], "2019": [21, 42, 48, 49, 50, 54, 55, 60, 63, 64, 72, 75, 77, 82, 87, 99, 101, 102], "202": 103, "2020": [5, 6, 18, 19, 20, 22, 24, 39, 42, 51, 65, 72, 73, 89, 91, 102], "2020435": 40, "2021": [26, 39, 40, 42, 48, 49, 58, 102, 103], "20219609": 40, "2022": [64, 65, 73, 89, 91, 97, 99, 102], "2023": [29, 66, 73, 75, 83, 84, 102], "2024": [37, 46, 61, 65, 99, 102], "202650e": 50, "20269": 60, "20274": 60, "202846": 49, "203": [41, 59], "203284": 50, "20329": 60, "2036": 60, "203828": 60, "203893": 71, "204007": 63, "20400735": 63, "204362": 65, "204482": 63, "204626": 45, "204653": 71, "204794": 63, "205": 64, "205187": 50, "205224": 64, "205656": 48, "205938": 58, "206": 103, "2061": 60, "206253": [59, 60], "2064": 60, "206614": 63, "206748": 49, "207222": 59, "2075": 39, "20783816": 40, "207840": 55, "207912": 88, "208": [45, 103], "208034e": 60, "2080787": 40, "20823898": 40, "2086": 60, "208922": 48, "209": 45, "209014": 63, "209219e": 64, "209257": 5, "209546e": 60, "20984635": 74, "209894": 63, "21": [16, 17, 27, 38, 40, 41, 42, 48, 49, 53, 58, 59, 60, 63, 64, 65, 68, 71, 72, 73, 74, 88, 99, 101, 102, 104], "210": [19, 20, 24, 45], "2103": [60, 99], "2103034": 40, "210319": [48, 49], "210323": 63, "2104": 103, "21078": 60, "211": [45, 103], "21105": [42, 72, 99, 101], "2112": 65, "21142": 60, "211534": 50, "21155656": 63, "211557": 63, "212": [45, 61, 103], "2122": 60, "21257396e": 74, "212844": 58, "213": [45, 102, 103], "213026": 60, "213070": 49, "213135": 49, "21361": 60, "213635": 48, "2139": 22, "214764": 64, "215": [45, 55], "215069": 63, "215342": 63, "215389": 48, "2155": 60, "21550": 60, "21562": 60, "21573": 60, "215967": 88, "216": 45, "216130e": 48, "216207": 72, "21624417": 40, "2163": 60, "216344": 63, "21669513e": 74, "216761": 62, "217": [45, 102], "21716": 60, "2171802": [40, 58], "217244": [10, 71], "218": 45, "21804": [41, 59], "218176": 45, "2183155": 74, "218383": 45, "218767": 60, "2189": 60, "218938": 60, "219": [18, 19, 20, 39, 45, 102], "2191274": 40, "219196e": 49, "21997": 59, "22": [38, 40, 41, 42, 48, 49, 58, 59, 63, 64, 65, 71, 72, 73, 74, 88, 101, 104], "220": [45, 103], "220088": 60, "220772": 63, "220773": 48, "221": [45, 103], "221245": 49, "2213": 58, "2214": 58, "221419": 60, "2215": 58, "2216": 58, "2217": [40, 58], "222": 103, "2222": [38, 40, 47, 73], "22222": 60, "22272803e": 74, "222843": 63, "223": 103, "22336235": 40, "223485956098176": [54, 55], "22375856": 40, "22390": 59, "224": [61, 103], "224539e": 48, "224546": 48, "224897": [48, 49], "225": [39, 66, 103], "225034": 51, "22505965": 40, "22507006e": 74, "225175": 63, "225222": 63, "22522221": 63, "22528": 60, "225427": 45, "225459760731946": 50, "225460": 50, "225574": 58, "2256": 60, "22562": 60, "225776": 65, "226": 103, "2264": 39, "226524": 63, "226598": 58, "226776": 49, "226938": 55, "226969": 45, "227": [60, 103], "2271071": 29, "227190": 55, "2276": 39, "2279": 60, "227931e": 59, "228035": 60, "2281": 60, "228214": 73, "228621": 48, "228630": 49, "228648": 41, "229": [41, 103], "22925": 60, "22937": 60, "229443": 63, "229452": 73, "229472": 59, "2295": 60, "229759": 72, "2298": 39, "229897": 48, "229961": [48, 49], "229994": [48, 49], "23": [6, 40, 41, 42, 48, 49, 51, 57, 58, 59, 60, 63, 64, 65, 69, 71, 72, 73, 74, 88, 99, 101, 102, 104], "230": 39, "230009": [54, 55], "23032209": 74, "2307": [40, 58, 68], "2308": 64, "230956": 52, "231": [16, 103], "2310794": 74, "23113": 73, "231153": 49, "231310": 63, "231330e": 49, "231430": 88, "231467": 73, "231986": 63, "232134": [48, 49], "2328": 60, "232959": [54, 55], "233": 23, "233029": 48, "2330860": 74, "233154": 104, "2335": 39, "234": 102, "234137": 65, "234153": 65, "234205": 60, "234534": 50, "234605": 43, "234798": 60, "234812e": 49, "234910": 58, "235": 103, "235501e": 48, "235873": 48, "2358815": 74, "2359": 104, "23590": 60, "236008": 50, "236309": 60, "23690345e": 74, "237": 42, "237252": 60, "237292": 49, "237341": 48, "237430": 49, "237461": 64, "23748": 60, "23751359e": 74, "23789104550535469707275788081838689": 74, "237891045505354697072757880818386894623273539414344476061687384879192939911141518202126303334404252566267718890961121617192224363748515558597476778295100": 74, "23789104550535469707275788081838689462327353941434447606168738487919293995132528293132384649576364656679859497981114151820212630333440425256626771889096": 74, "23789104550535469707275788081838689462327353941434447606168738487919293995132528293132384649576364656679859497981121617192224363748515558597476778295100": 74, "2378910455053546970727578808183868951325282931323846495763646566798594979811141518202126303334404252566267718890961121617192224363748515558597476778295100": 74, "237896": 63, "23789633": 63, "238": [40, 58, 103], "238101": 63, "238225": 88, "238251": 50, "238529": 9, "23856": 60, "238794": 63, "239": 103, "239313": 49, "239317": 49, "23965": 60, "239799": 48, "23e": 41, "24": [40, 41, 42, 48, 49, 55, 57, 58, 59, 60, 63, 64, 65, 66, 71, 72, 73, 74, 88, 101, 102, 103, 104], "240127": [48, 49], "240295": 64, "240532": [48, 49], "2407": 39, "24080030a4d": 42, "240813": 56, "241049": 63, "241063": 48, "241064": 49, "241596": 73, "2416": 39, "241609": 60, "241678": 48, "241962": 65, "24199": 60, "242": 102, "242000": 60, "242124": [59, 60], "242139": 88, "242158": [59, 60], "2424596822": 55, "242815": 88, "242902": 63, "2430561": 39, "243246": 63, "2438": 60, "2438070": 74, "2439": 60, "244": 60, "244090": 60, "244455": 63, "244622": 88, "24469564": 101, "245": [102, 103], "245062": 63, "2451": 39, "24510393": 41, "245370": 58, "245416": 49, "245512": 63, "245720": 52, "246": 103, "246624": 71, "246731": 59, "2467506": 40, "246753": 63, "246879": 63, "247": 103, "247020": 50, "247057e": 63, "2471": 60, "2472": 60, "247207": 49, "247617": 71, "247717": 60, "24774": [59, 60], "247826": 58, "248171": 63, "248638": 50, "249": [40, 58, 61, 103], "2491": 60, "249109e": 49, "24917": 60, "25": [14, 15, 18, 19, 20, 24, 25, 26, 27, 40, 41, 42, 48, 49, 50, 52, 53, 57, 58, 59, 60, 63, 65, 66, 71, 72, 73, 74, 88, 101, 104], "250": [61, 103], "2500": 60, "25000000000000006": [50, 60, 63], "250073": 60, "250210": 50, "2503": 60, "250354": 63, "250425": 50, "251": [60, 64], "251101": [71, 72], "251412": 49, "251480": 49, "251953": 60, "252133": 60, "252253": 64, "25240463": 73, "252524": 63, "252601": 88, "252644": 48, "253026": [48, 49], "2532": 60, "253437": 62, "253724": 63, "25374": 60, "254": [60, 103], "25401679": 40, "254038": 55, "2543": 60, "254324": 50, "254400": 88, "254551": 49, "255": [60, 103], "25547627": 74, "255598": 49, "256": [60, 72], "256002": 73, "256416": 63, "256567": 58, "25672": 60, "256944": 63, "256983": 12, "256992": 60, "257207": 40, "257377": 52, "258158": [48, 49], "2583": 60, "258541e": 15, "258951": 63, "259395": 56, "2594": [41, 59], "2595812": 74, "259828": [48, 49], "25x_3": 52, "26": [40, 41, 42, 43, 48, 49, 51, 57, 58, 59, 60, 66, 69, 71, 72, 73, 74, 88, 101], "26016": 60, "260161": [13, 71], "260211": [48, 49], "260356": 59, "260360": 63, "260687": 49, "2610": 60, "2613": 60, "261520": 45, "261624": [59, 60], "261685": 60, "26175": 60, "261777": 60, "261903": 58, "2619317": 40, "262000e": 48, "262357": 49, "262423e": 60, "262621": 58, "262829": 74, "263": [16, 60, 103], "2633": 60, "263672": 48, "263974e": 63, "264": [102, 103], "264086": 52, "264274e": 60, "2646": 74, "264884": 60, "265": 103, "2651": 73, "265119": 62, "2652": [42, 59, 60], "265495961": 74, "265547": 60, "2658": 55, "266": 103, "266922": 88, "267": 61, "2670691": 40, "267099": 48, "267500": 58, "267581": 60, "267767": 49, "267950": 63, "268055": 60, "2687955": 74, "268942": 63, "268998": 41, "269043": 63, "269977": 60, "26bd56a6": 42, "26e": 41, "27": [19, 20, 24, 38, 40, 41, 42, 43, 48, 49, 51, 57, 58, 59, 60, 66, 69, 71, 72, 73, 74, 88, 101, 102], "2700": 42, "270644": [48, 49], "270694e": 48, "271004": [59, 60], "271083": 60, "272296": 60, "272408": 49, "272662": 60, "273": 42, "273356": 50, "27371": [41, 59], "27372": [41, 59], "274": [42, 60], "2740991": 39, "274247e": 59, "274267": 58, "27429763": 73, "27437786": 74, "274430": 49, "274793": 63, "274825": [14, 71], "27487": 60, "2754": 39, "275535": 48, "275596": 88, "276": 42, "276148": 63, "276189e": 58, "2764": 60, "2766091": 41, "27713": 60, "277299": 43, "27751": 60, "277561e": 58, "277968": 63, "278": 64, "2780": 40, "278000": 58, "278035": 45, "278303e": 48, "278391": 60, "278434": 54, "278522": 45, "2786": [88, 98], "278683": 48, "27951256e": 74, "27986": 60, "28": [40, 41, 42, 48, 49, 53, 56, 57, 58, 59, 66, 71, 72, 73, 74, 88, 101, 103], "280196": 55, "280454dd": 42, "280514": 88, "280963": 62, "281024": 63, "28111364": 41, "2815": 60, "2818": 39, "2819": [88, 98], "282": 102, "282200": 55, "2825": [99, 101], "28251": 60, "282870": 60, "2830": [99, 101], "28326": 60, "2836": 39, "2836059": 40, "28382": 60, "283974": 63, "283994": 63, "28425026": 64, "284271": 56, "284397": 104, "28452": [41, 59], "2849": 60, "284949": 49, "284987": 60, "286027": 71, "286203": 48, "2865": [39, 60], "286507": 50, "286563e": 60, "286593": 60, "287011": 49, "287041": 63, "287815": 64, "287926": 63, "288": 61, "288006": 59, "2883725": 74, "288850e": 48, "288976": 60, "289": 102, "289357": 49, "289440": [48, 49], "289718": 48, "29": [12, 40, 41, 42, 48, 49, 57, 58, 59, 64, 66, 71, 72, 73, 74, 88, 101], "290987": 59, "291": 60, "2910": 60, "291008": 48, "291011": 73, "291071": 63, "29107127": 63, "291405": 63, "291406": 63, "291434": 49, "291500e": [59, 60], "291517": [48, 49], "291963": 63, "292": 62, "292028": 50, "292047": 88, "292105": 63, "292178": 59, "292302995303554": 50, "292303": 50, "2925": 42, "2927": 60, "292997": 63, "29299726": 63, "293218": 63, "2934042": 74, "293617e": 60, "293960": 48, "294067": [48, 49], "295": 102, "295481": 63, "29548121": 63, "295642": 48, "295837": [43, 69, 101], "2958370000000100000100": [42, 69, 101], "2958370001000010011100": [42, 69, 101], "2958371000000010010100": [42, 69, 101], "296228": 60, "296585": 49, "296729": 58, "29678199": [67, 75], "296901": 48, "297287": [48, 49], "2973": 60, "297349": [54, 55], "297682": 63, "297687": 60, "297749": 60, "297779e": 49, "29784405": 64, "298": [23, 42, 61, 104], "29806933": 74, "298076": 48, "298120": 50, "298228e": 60, "299": 42, "2991927": 74, "299537": 55, "299712": 54, "2999": 45, "2_": [29, 66, 89, 91, 97], "2_x": [29, 66], "2d": [75, 82], "2dx_5": [50, 63], "2e": [37, 39, 40, 41, 42, 72, 73, 75, 88, 101], "2f": 56, "2m": [89, 94, 97], "2n_t": 52, "2x": 63, "2x_0": [21, 48, 49, 54, 55], "2x_4": 52, "3": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 27, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 99, 100, 101, 102, 103], "30": [21, 37, 38, 40, 42, 45, 46, 47, 48, 49, 50, 51, 57, 58, 59, 60, 63, 66, 71, 72, 73, 74, 88, 101], "300": [38, 47, 50, 60, 63, 68, 102], "3000": 45, "30000000000000004": [50, 60, 63], "30031116e": 74, "30093956": 64, "301": 42, "3010661": 74, "301366": 88, "301371": 63, "3016": 59, "301737": 48, "30189": 60, "302357": 63, "302571": 71, "302648": 58, "303007": 48, "303324": 58, "303489": 63, "303613": 63, "30361321": 63, "30383": 60, "303835": 58, "303f00f0bd62": 42, "304130": 63, "304159": 63, "304201": 52, "304217": 48, "305133": 71, "305255": 49, "30527": 60, "305341": 63, "305612": 58, "305775": 63, "305b": 42, "30645": 60, "30672815": 40, "306915": 58, "306963": 63, "307176": 48, "307407": 63, "308": 60, "308568": 49, "308774": 48, "30917769": [54, 55], "3095204": 74, "309605": 48, "309772": 58, "309823e": 60, "30982972": 63, "309830": 63, "309962": 61, "31": [40, 41, 42, 45, 48, 49, 57, 58, 59, 60, 66, 71, 72, 73, 74, 88, 101, 104], "310000e": 60, "310761": 62, "311253": 60, "311712": 54, "3120": 60, "312008": 49, "312882": 49, "313056": 88, "313209": 50, "313324": 60, "31337878": 60, "313535": 63, "31378": 42, "314": 74, "314071e": 48, "3141": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 40, 42, 43, 58, 67, 69, 71, 72, 75, 88, 98, 101], "314247": 65, "314341": 48, "3146": 15, "314625": 49, "314651": 54, "31476": [59, 60], "315031": 65, "3151": 60, "315155": 49, "315223": 45, "315290": [54, 55], "315310": 48, "316": 42, "316193": 63, "31632": 60, "316407": 73, "316540": 58, "316717": [48, 49], "316863": 49, "317064": 48, "317394": 52, "317487": 63, "317607": 63, "318": 42, "318000e": 60, "318438": 60, "318552": 60, "318584": 88, "318753": [54, 55], "319": 42, "319100": [54, 55], "319759": 63, "319850": 63, "32": [40, 41, 42, 48, 49, 57, 58, 59, 60, 66, 71, 72, 73, 74, 75, 88, 101], "320": 60, "320314": 59, "320633": 50, "321520": 49, "321686": 88, "32236455588136": 51, "322404": 64, "3234": 60, "323622": 59, "323679": 58, "324": [41, 60], "324476": 45, "324518": 62, "32458367": 40, "3245837": 63, "325056": 63, "325090": 60, "3253641": 74, "326148": 49, "326740": 63, "326871": 65, "3268714482135234": 65, "327265": 49, "327803": 71, "3281196": 74, "329181": 49, "329339": 51, "32950022e": 74, "329679": 49, "33": [40, 41, 42, 48, 49, 54, 57, 58, 59, 60, 66, 71, 72, 73, 74, 88, 101, 102], "3300": [41, 59], "330143": 63, "33014346": 63, "330285": [48, 49], "3304269": 40, "330615": 63, "330731": [14, 71], "331365": 54, "331521": 63, "331602": 60, "331640": 49, "33175566": 63, "331756": 63, "332502": 49, "332782": [14, 71], "3329": 60, "332996": 58, "3333": [38, 40, 47, 71, 72, 73], "3333333": 42, "33335939e": 74, "3335": 60, "333575": 59, "333655": 48, "333704": 49, "334": 41, "334425": 48, "334649": 56, "334750": 50, "33500": 60, "335121": 49, "335176": 60, "335446": 45, "335609e": 63, "335846": 63, "335853": 60, "336": 61, "336153": 48, "336461": 60, "336510": 49, "336612": 52, "337380": 63, "3376": 39, "337619": 51, "338": 64, "33849": 60, "3386": 74, "338603": 48, "338775": 50, "338900": 49, "338908": 50, "339269": 64, "33928": 60, "339570": 63, "339875": [54, 55], "34": [38, 39, 40, 41, 42, 48, 49, 55, 57, 58, 59, 60, 64, 66, 71, 72, 73, 74, 88, 104], "340": [41, 60], "340274": 64, "340485e": 48, "341336": [10, 71], "3420": 60, "342362": 45, "342467": 71, "342675": 40, "34287815": 64, "342989": 60, "342992": 58, "343": 60, "344212": 104, "344305": 56, "344505": [59, 60], "344640": 63, "34475": 59, "344753": 45, "344787": [48, 49], "344834": 52, "345065e": 60, "345381": 50, "3453813031813522": 50, "3454": 60, "345852": 49, "345903": 63, "345989": 48, "346206": 63, "346238": 64, "346269": 49, "346678": 62, "34694538": 74, "347310": [14, 71], "347696": 50, "34769649731686": 50, "347929": 60, "34858240261807": 51, "348617": 63, "348700": 49, "3492131": 39, "349383": 58, "34943627": 57, "349638": 49, "34967621": 40, "3497411": 74, "349772": 55, "35": [41, 42, 48, 49, 50, 58, 59, 60, 61, 63, 71, 72, 73, 74, 88, 89, 94, 104], "3500000000000001": [50, 60, 63], "350165": 72, "350208": 48, "350518": 63, "350712": [54, 55], "35077502": [89, 94], "351629": 60, "351766": 62, "352": [41, 58], "352250e": 59, "352259e": 60, "3522697": 40, "352365": 48, "352813": [71, 72], "35292": 60, "352990": 60, "352998": 60, "353105": 15, "353412": 63, "35341202": 63, "35365143": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "353748e": 63, "3538": 39, "354": 60, "354188": 52, "354371": 63, "354688": 11, "355065": 45, "355209": 63, "355699e": 48, "356136e": 60, "356167": 55, "356183": 60, "35620768e": 74, "3564": 60, "3565": 60, "3568": 73, "356886e": 49, "357": 60, "357170": 48, "35731523": 73, "358158": [59, 104], "358289": 58, "358395": 64, "358653": 49, "358799": 88, "358977": 59, "359": 104, "359100": 60, "3593": 64, "359307": 49, "35th": 102, "36": [41, 42, 48, 49, 58, 59, 61, 71, 72, 73, 74, 88], "360004": 63, "360065": 88, "360122": 48, "360249": 56, "360475": [48, 49], "360655": 60, "360683": 50, "360801": 50, "361518": 50, "361518457569366": 50, "361521": 11, "3619201": 22, "362155e": 49, "36231307e": 74, "363276": 40, "3643": [88, 98], "364595": 40, "3647": 42, "364800": 63, "36501": 60, "36557195e": 74, "36566025e": 74, "365934": 61, "366": 60, "36616": 60, "366310": 73, "366529": 62, "366541e": 48, "366718627": 40, "366950": 48, "367056": 49, "367181": 48, "367323": 63, "367571": 50, "367625": 63, "368092": 49, "368152": 58, "3682": [41, 59, 60], "368324": 58, "368499": 50, "3684990272106954": 50, "369556": 50, "3696": 64, "369796": 63, "369869": 59, "369981": 58, "37": [41, 48, 49, 58, 59, 60, 71, 72, 73, 74, 88], "370186": 61, "3702770": 40, "370736": 58, "3707775": 40, "3710": 60, "371357": [59, 60], "371429": 50, "371535": 48, "372": 102, "37200": [59, 60], "372097": 50, "3722": 60, "37231324": 66, "3724": 60, "372427": 49, "372628": 48, "3727679": 40, "372989": 48, "373802": 49, "3738573": 40, "374364": 63, "37436439": 63, "3745": 60, "374821e": 60, "374862": 48, "375": 37, "375077e": 48, "375081": 60, "375465": 63, "376760": 49, "376780": 48, "376806": 49, "377060": 60, "377195": 45, "377311": 63, "377669": 49, "378351": 8, "378588": 48, "378596": 58, "378688": 63, "378828e": 48, "378834": 63, "3788859": 40, "379": 102, "379038": 63, "379117": 48, "37939": 60, "379614": 63, "379626": 48, "38": [42, 48, 49, 59, 71, 72, 73, 74, 88], "3800694": 40, "380170e": 48, "380432e": 49, "380837": [59, 60], "381072": 63, "381603": 48, "381623e": 55, "381685e": [59, 60], "381689": 63, "3817": 60, "381826": 12, "382188e": 49, "382286": 60, "382582e": 3, "382684": 71, "382872": 50, "383297": 63, "384": 60, "384223": 73, "384443": 49, "384677": 45, "384777": 60, "384928": 48, "385013": 45, "3851": 60, "385240": 88, "385615": 45, "385877e": 49, "385917": 58, "386": [42, 60], "386102": 50, "386502": 60, "386831": 45, "386834": 49, "386894": 49, "386988": 51, "387": 42, "3871": 39, "387426": 63, "3876543": 74, "387780": 63, "388071": 63, "388185": 45, "38818693": 74, "388216e": 72, "388298e": 48, "388593e": 49, "388668": 63, "38866808": 63, "388871": 60, "389": 42, "389126": 73, "38922": 73, "389566": 62, "38973512e": 74, "38990574": 74, "39": [37, 39, 40, 41, 42, 43, 45, 48, 49, 51, 55, 56, 57, 58, 59, 60, 64, 65, 66, 71, 72, 73, 74, 88], "39010121e": 74, "390379": 63, "390599": 49, "391377": 65, "392242": 56, "39236801": 57, "392400": 60, "392623": 49, "392752": 51, "392833": 64, "392864e": [59, 60], "393060": 71, "393604": 50, "393654": 45, "39425708": 40, "395076e": 60, "395136": 58, "395268": 71, "395603": 48, "3958": 73, "395889": 60, "39611477": 41, "396173": 54, "39621961e": 74, "396300": 54, "3964": 60, "396531": 60, "3969292": 74, "396985": 58, "396992": [48, 49], "397140": 50, "397155": 49, "397179": 45, "39727": 60, "397313": 39, "397578": 56, "397811": 64, "398": [69, 101], "3985": 60, "398770": 63, "398999": 71, "399": 41, "399056": 63, "399207": 49, "399223": 52, "399355": 52, "399692": 63, "399858": 65, "3cd0": 42, "3dx_1": [50, 63], "3e1c": 42, "3ec2": 42, "3f5d93": 61, "3x_": 63, "3x_4": [50, 63], "4": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 19, 20, 24, 29, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 101, 103], "40": [37, 40, 48, 49, 50, 51, 55, 59, 60, 63, 66, 69, 71, 72, 73, 74, 88, 89, 94], "400": [58, 104], "4000000000000001": 72, "40000000000000013": [50, 60, 63], "40029364": [89, 94], "400823": 63, "400855956463958": 50, "400856": 50, "400910": 48, "401": [16, 104], "401247": [75, 88], "40127723e": 74, "401861": 48, "401931": [54, 55], "402077": 60, "402113": 88, "402301e": 72, "402902": 60, "4033222": 74, "403425": 63, "403626490670169": 67, "4036264906701690": 67, "403626491": 67, "403715": 3, "403771948": 75, "4039": 39, "404300": 45, "404318": 39, "404411": 48, "40452": 60, "404550": 62, "405203": 52, "405374": 60, "405400e": 48, "40583": 39, "405890": [14, 71], "406": 59, "406285": 63, "406446": 50, "4065173": 74, "40676": 39, "407056": 61, "407558": 48, "40766772": 74, "4084408": 74, "408476": [89, 94], "40847623": [89, 94], "408479": 58, "408539": 63, "408565": 63, "409154": 39, "4093": 64, "409328": 60, "409395": 63, "409746": 50, "409848": [48, 49], "41": [45, 48, 49, 59, 60, 71, 72, 73, 74, 88, 98], "410124": 49, "410393": 50, "410667": 71, "410681": 52, "410693449": 74, "410795": 58, "41093655": 74, "411190": [48, 49], "411291": 62, "411295": 63, "411304": [48, 49], "411447": 60, "411582": 63, "4117871": 74, "411869": 49, "412004": 54, "412127": 63, "412304": 65, "412477": 52, "412653": 58, "412714": 50, "412726": 49, "412838": 49, "41336": 72, "41341040": 40, "413608": 63, "413933e": 49, "414073": 9, "414533": 49, "4149679": 74, "41525168e": 74, "415465": 49, "415545": 61, "41566": 73, "415812": 104, "41593014": 74, "415988": 60, "416": 37, "416052": 45, "416132": 49, "4166": 60, "4166667": 42, "416757": 63, "416899": 48, "417640": 48, "417767": [54, 55], "417822": 59, "417834": 45, "41798768e": 74, "418056": 63, "41805621": 63, "41836": 59, "418360": 59, "418741": 45, "418806e": 50, "41918406e": 74, "419371": 63, "419871": 45, "41989983e": 74, "4199952": 40, "41e5": 42, "42": [5, 6, 24, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 60, 62, 63, 64, 65, 66, 71, 72, 73, 74, 88, 98, 102], "4200": 60, "420316e": 60, "420608e": 64, "42073312": 40, "420967": 50, "421083": 39, "4211349413": 40, "421200": 65, "421234": 71, "421357": [54, 55], "421576e": 60, "421793": 64, "421919": 60, "422007": 64, "422266": 60, "422293e": 71, "422325": 50, "422561": 45, "42338": 60, "4235839": [54, 55], "423669e": 74, "42388745": 66, "423921e": 71, "423951": 39, "424108": 50, "424127": 74, "42412729": 40, "424292": 48, "424328": 63, "424651": 73, "424700": 49, "424717": 50, "424748": 65, "425": 58, "425072": 55, "425103": 39, "425208": 60, "425493": 39, "42550": 60, "426055": 39, "426283": 48, "426540": 58, "426540301": 40, "426736": 60, "427": 60, "427101": 48, "427486": [48, 49], "42755087": 64, "427551": 64, "427573": 58, "427725": 63, "428": [88, 98, 104], "428046": 62, "42811700": 104, "428255": 63, "428411": [59, 60], "428467": 63, "4284675": 63, "428588": 48, "428771": [14, 71], "4290": 39, "429057": 49, "429705": 48, "429986": 49, "42ba": 42, "43": [37, 41, 45, 48, 49, 71, 72, 73, 74, 88], "430298e": [59, 60], "430595": 49, "4311947070055128": 72, "43126727": 74, "431306": 63, "431701914": 99, "431848": 48, "431852": 49, "431998": 45, "432125e": 59, "432300e": 63, "43231359e": 74, "432484": 48, "43294": 42, "432f": 42, "433": 42, "433221": 50, "4336": 60, "43374433": 66, "433750": 48, "4339": 39, "434519": 71, "434535": 63, "43453524": 63, "434677": 49, "435": 42, "43503345": 73, "43511": 60, "435401": 58, "4357": 60, "435927": 60, "435967": 58, "43597565": 63, "435976": 63, "436": [42, 60], "436194": 48, "43627032": 51, "436327": 60, "436806": 60, "437594": 48, "437767": 59, "437924": 60, "438": 58, "438219": 63, "438289": 60, "438569": 60, "438578e": 60, "438709": 59, "43883": 55, "4389": 60, "438960": 58, "439541": [59, 60], "439699": 45, "43989": 71, "43f0": 42, "44": [45, 48, 49, 51, 71, 72, 73, 74, 88], "440320": 60, "440364": 71, "440605": 72, "440747": 48, "440a": 42, "441153": 63, "441209": 63, "441219": 54, "44124313": 73, "4416552": 40, "441676": 45, "441893": 48, "442202": 49, "442462": 49, "443016": 50, "443032": 59, "44312177": 41, "443686": 63, "4437": 60, "443701": 56, "444046": 60, "4444": [38, 40, 47, 73], "444500": [59, 60], "444850": 60, "4449272": 60, "445473": 48, "445476": 48, "44563945e": 74, "445642": 48, "4461928741399595": 50, "446193": 50, "4462": 42, "44647451": 64, "44713577e": 74, "447492": 60, "447624": [48, 49], "447706": 50, "447849": 51, "447999": 55, "448": 60, "44804392": 74, "448587": 50, "448745": 63, "448842": 49, "4489": 60, "44890536": 74, "448923": 56, "448973": 49, "449107": 6, "449150": [14, 71], "449406e": 48, "44950": 60, "44fa97767be8": 42, "45": [45, 48, 49, 50, 54, 56, 59, 60, 63, 71, 72, 73, 74, 88], "4500": 59, "45000000000000007": [50, 60, 63, 72], "450152": 58, "450870601": 40, "450926e": 48, "451918e": 74, "452": 42, "452091": 60, "452114": 71, "452484e": 49, "452488701": 40, "452489": 58, "453": 42, "453279": 48, "4535": 60, "4539": 42, "454081": 60, "454185": 49, "454397": 63, "454406": 45, "45467447": 74, "455": 42, "45500": 60, "455078": 50, "455091": 49, "455107": 50, "455120": 63, "4552": 42, "455293": 50, "4552b8af": 42, "455448": 64, "455672": 60, "455981": 89, "456370": [49, 58], "456432": 48, "456552": 71, "4566031": 88, "45660310": 88, "4567": 64, "456892": 50, "457": 37, "457088": 63, "457252": 49, "457667": 60, "458114": 60, "458307": 91, "458420": 60, "4584447": 40, "458784": 48, "458855": 41, "458976": 49, "4592": 40, "459200": 58, "459383": 50, "45957837": 74, "459584e": 49, "459760": 60, "459812": 50, "459913": 48, "46": [45, 48, 49, 56, 57, 71, 72, 73, 74, 88, 98], "460": 60, "4601": 60, "460207": [48, 49], "460218": 50, "460289": 63, "460535": 71, "4610": 104, "461458": 49, "461629": 65, "461646": 45, "462321": 12, "46232735394143444760616873848791929399": 74, "4623273539414344476061687384879192939951325282931323846495763646566798594979811141518202126303334404252566267718890961121617192224363748515558597476778295100": 74, "462451": 50, "462567": 49, "462979": 48, "463325": 63, "4634": 60, "463418": 65, "463668": 60, "463766": 55, "463857": 60, "463903": 49, "46391936": 74, "463b": 42, "464076": 50, "464284": 58, "46448227": 74, "464668": [10, 71], "465": 45, "46507214": 64, "465649": 65, "465730": 65, "465832": 49, "4658739": 74, "4659651": 67, "465965114589023": 67, "4659651145890230": 67, "466047": 63, "46618738": 74, "466440": 50, "466756": 63, "467": 60, "46709481": 74, "46722576e": 74, "467613": 58, "467613401": 40, "467681": [48, 49], "467770": 50, "468051e": 49, "468072": 49, "468075": 63, "46807543": 63, "46811985": 63, "468120": 63, "468406": 60, "468907": 45, "468919": 60, "468d": 42, "469": 42, "469474": 65, "469825": 50, "469895": 49, "47": [41, 45, 48, 49, 51, 59, 64, 71, 72, 73, 74, 88, 103], "470458": 48, "470904": 48, "471": 45, "472": 60, "47222159": 66, "472255": 60, "472657": 49, "472891": 63, "472e": 42, "473099": 50, "47319": 73, "47419634": 101, "474214": [54, 55], "474731": 71, "474846": 59, "475304": 60, "475569": 48, "476856": 50, "477130": [48, 49], "477150": 63, "477247": 49, "477443": 48, "477474": 58, "47759584": 74, "47761563": 51, "478032": 60, "4781": 60, "47857478": 74, "47966100e": 74, "479722": 49, "479860": 60, "479876": [54, 55], "479882": 49, "479928": 63, "47be": 42, "48": [42, 45, 48, 49, 59, 60, 71, 72, 73, 74, 88], "480": 45, "480133e": 63, "48029755": 64, "480579": 49, "48069071": [67, 75, 88], "480691": [75, 88], "480800e": 63, "481172": 63, "481218": 60, "481399": [59, 60], "481705": 73, "481761e": 60, "482": [42, 45], "482012": 54, "482038": 50, "48208358": 63, "482084": 63, "4822303": 74, "482461": [89, 94], "48246134": [89, 94], "482483": 63, "482790": 52, "48296": 64, "483": 73, "48315": 64, "483186": 52, "483192": [59, 60], "48331": 64, "4835": 60, "483694": 61, "483711": 63, "483717": 50, "48390784": 73, "483944": 48, "48404": 40, "4845": 60, "484640": 63, "4849": 42, "485": [42, 60], "485377": 48, "48550": 65, "485617": [59, 60], "485812e": 60, "48583": [59, 60], "485871": 55, "486": [25, 60], "486202": 50, "486532": 63, "48661": 60, "487": [45, 60], "487467": 60, "487641e": 63, "487872": 46, "488460": 60, "488485": 60, "48873663": 51, "488811": 63, "488909": [59, 60], "488982e": 50, "4895498": 63, "489550": 63, "489699": 50, "49": [42, 45, 48, 49, 71, 72, 73, 74, 88], "490000e": 60, "490070931": 40, "490488e": 59, "490504e": 60, "490700": 63, "490941": 60, "491034": 48, "491245": 58, "49135": 15, "4915707": 73, "492": 60, "4923156": 67, "49231564722955": 67, "492315647229550": 67, "492417e": 73, "492454": 49, "4926335": 74, "492656": 49, "49270769e": 74, "493": [73, 102], "493144": 65, "493219": 63, "493313": 60, "493325": 5, "494089": 49, "494129": 63, "494324": 58, "494324401": 40, "495": 62, "49530782": 40, "495657": 50, "495752": 63, "49596416e": 74, "496": 62, "4964126": 74, "49650883": 64, "496551": 63, "496714": 65, "496739": 61, "496777": 104, "49693": 72, "497": 62, "497298": 71, "497422": 49, "497655": 6, "497674": 51, "497964": 71, "498": 62, "498921": 63, "498979": 60, "498f": 42, "499": [37, 60, 62, 69, 101], "499000e": [59, 60], "499469": 61, "499776": 60, "49d4": 42, "4a53": 42, "4b8f": 42, "4dba": 42, "4dd2": 42, "4e": [40, 41], "4ecd": 42, "4fee": 42, "4x": 63, "4x_0": [21, 48, 49, 54, 55], "4x_1": [21, 48, 49], "5": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 100, 101, 103], "50": [14, 40, 42, 50, 52, 55, 57, 59, 60, 61, 63, 71, 72, 73, 74, 88], "500": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 22, 23, 27, 34, 38, 42, 43, 47, 48, 49, 54, 55, 57, 59, 62, 64, 68, 69, 71, 72, 73, 75, 88, 89, 94, 98, 101, 104], "5000": [48, 49, 50, 63], "50000": 58, "500000": [59, 60], "5000000000000001": [50, 60, 63], "500084": 63, "500267": 56, "5003517412": 40, "500517": 63, "500531": 61, "50093148e": 74, "501021": 60, "501954": 49, "501983": 63, "502054": 49, "502084": 73, "502494": 50, "5025850": 40, "502595": 49, "502612": 63, "502843e": 49, "502901": 49, "502995": 63, "503261": 61, "503504": 72, "503511": 60, "503700": 45, "50398782e": 74, "504286": 58, "5042861": 40, "504543e": 74, "504569": 48, "5050973": 40, "505913": 48, "506050": 48, "506159e": 48, "506644": 48, "506659": 60, "506687": 60, "50672034": 40, "506900e": 63, "506903": 50, "50768b": 61, "508": 104, "508153": 62, "508433": 48, "508459": 58, "5085": 60, "508630": 49, "508947": 73, "509059": 60, "509196": 63, "509461": 63, "50967": 65, "5097": 65, "509782": 49, "5098": [43, 69, 101], "509853": 63, "5099": [42, 43, 69, 101], "509951": 50, "509958": 58, "51": [39, 41, 42, 54, 71, 72, 73, 74, 88, 103], "510000e": [59, 60], "510385": 58, "510555": 45, "51079110": 40, "510982": 59, "511022": 71, "511293": 59, "511515": 60, "511540": 60, "5115547": 67, "5115547181877": 67, "51155471818770": 67, "511668": 65, "5116683753999614": 65, "511862": 63, "512": 58, "512081e": 48, "512108": 63, "512149": 63, "51214922": 63, "51243406e": 74, "512519": 58, "512572": 63, "512672": [73, 89, 94], "512832": 48, "513052": 48, "5131": 59, "513252829313238464957636465667985949798": 74, "513992": 63, "514": 42, "514160": 48, "514173": 49, "514545": 60, "515031": 48, "515358": 50, "5154": 60, "5154789948092002": 58, "5155": 42, "515950": 73, "516": 42, "516125": 50, "516222": 63, "516255": 63, "516256": 63, "516528": 63, "516888": 48, "516945": 45, "517": [42, 58], "517266": 49, "5175": 60, "517785": 48, "518175": 58, "518446": 60, "518478": 45, "518682": 49, "518767": 48, "518782": 60, "518846": 58, "519622": 48, "51966955": 40, "519710": 63, "519888e": 49, "52": [39, 42, 56, 71, 72, 73, 74, 88], "520": 60, "520641": 64, "520930": 50, "521002": 50, "521085": 71, "521233": 45, "521611": 49, "522753": 11, "522835": 52, "523030": 65, "523163": 50, "5232": 57, "52343523e": 74, "523794e": 63, "523807": 62, "523977545": 40, "524088": 48, "52424539": 40, "524657": 63, "524934": [48, 49], "5250": 60, "525064": 45, "52510803": 41, "525135": 49, "525138": 48, "5251546891842586": 65, "5255": 42, "52587000": 74, "52590": [41, 59], "526": 58, "526102": 73, "526532": 60, "526769": [48, 49], "52732": 72, "527452": 49, "527728": 49, "528381e": 66, "528580": 63, "528937": [54, 55], "528996901": 40, "528997": 58, "529": 58, "529405": 39, "529782": 39, "529969": 49, "53": [39, 42, 45, 59, 69, 71, 72, 73, 74, 88, 99, 102], "530940": 63, "53094017": 63, "531": 42, "531223": 50, "531594": 60, "53209683": 73, "532266": 50, "53257": 72, "532738": 63, "53273833": 63, "532751": 54, "5329": 60, "533489": 52, "533900": 63, "5346": 42, "535179": 63, "535318": 63, "535609": 60, "535718e": 60, "53606675": 63, "536067": 63, "536082": 45, "536143": 60, "536219": 45, "536746": 63, "536798e": [59, 60], "537240": 63, "53724023": 63, "53787697": 74, "53791422": 73, "538": 42, "538013": 60, "5382": 64, "5385456": 74, "538937": [59, 60], "539455": 63, "539475": 63, "53947541": 63, "539491": [54, 55], "539767": 50, "54": [39, 41, 42, 51, 59, 61, 68, 71, 72, 73, 74, 88, 103], "540240": 60, "540270": 49, "540542": 59, "540789": 48, "5408": 39, "541159": 63, "54163": 64, "5416844": 67, "541684435562712": 67, "541821": 60, "541990": 60, "542159": 49, "542333": 60, "542451": 63, "542560": 65, "542584": 50, "5425843074324594": 50, "542647": 63, "542671": 58, "542816": 12, "542883": [89, 94], "5428834": [89, 94], "542919": 71, "542989": 63, "543": [58, 60], "543075": 50, "543136": 50, "543358": 71, "543380": 58, "5434231": 67, "543423145188043": 67, "5436005": 40, "543691": 49, "543764": 55, "54378": 64, "543832": 63, "544097": 63, "544383": 65, "544555": 58, "544669": 54, "54483": [75, 88], "5448331": [75, 88], "54517706e": 74, "545492": 45, "545602": 49, "545605e": 63, "545919": 60, "546266": 45, "546294": 60, "5467606094959261": 50, "546761": 50, "547039": 48, "54716": 64, "547324": 49, "547431": 62, "5476": 60, "5479": 60, "547909": 60, "549109e": 60, "549645": 71, "55": [41, 42, 50, 55, 59, 60, 63, 71, 72, 73, 74, 88], "5500000000000002": [50, 60, 63], "551317": 49, "551355": 49, "551586928482123": 50, "551587": 50, "551686": 50, "55176": 72, "5517982": 74, "5518": 60, "552": 60, "552058": 64, "552508": 60, "552727": 58, "552776": 63, "553004": 45, "55307": 72, "553878": [13, 71], "553916": 60, "553965": 48, "554076": 50, "554203": 49, "554793e": 74, "555": 58, "555137": 49, "555150": 60, "555445": 62, "555498": 63, "5555": [38, 47], "555536": 48, "555949e": 60, "555954": 60, "556191": [48, 49], "556792": 63, "557267": 48, "5574dcd4": 42, "557595": 58, "557731": 62, "557999": 58, "558134": [48, 49], "5582204": 74, "5584": 58, "5585": 58, "55863386": 73, "558655": 50, "5589": 58, "559": 104, "5590": 58, "559144": 50, "559186": 50, "5592": 58, "559394": 63, "559522": 63, "559680": 60, "55dc37e31fb1": 42, "55e": 41, "56": [42, 59, 68, 71, 72, 73, 74, 88, 99, 102], "560135": [75, 88], "56018481": 63, "560185": 63, "5602727": 51, "560332": 61, "560545e": 48, "560689": 39, "560723": 56, "561183e": 49, "5616": 59, "561711": 60, "561785": 73, "561819": 48, "562001": 49, "562013": 63, "562153": 48, "56223": 64, "562288": 65, "562518": 60, "5625561": 39, "562557": 48, "562712": [48, 49], "563374e": 50, "563503": 63, "563528": 60, "563673": 60, "563851e": 48, "56387280e": 74, "56390147e": 74, "564045": 63, "564073": 60, "5641": 60, "564142": 50, "564232": [48, 49], "564451": 49, "564537": 49, "564577": 60, "565066": 50, "566": 65, "566024": 63, "566091": 60, "567004": 64, "567343": 60, "567364": 49, "567529": 63, "567531": 48, "567568": 48, "567695": 48, "567945": [54, 55], "568111": 71, "5690069": 74, "569135": 49, "569444": 45, "569540": 49, "56965663": 63, "569657": 63, "569684": 49, "569911": 40, "5699994715": 40, "57": [42, 71, 72, 73, 74, 88, 104], "570038": 50, "5700384030890744": 50, "570111": 62, "5702": 60, "570486": 39, "570562": 39, "570722": 101, "570936": 48, "571707": 71, "5717411": 74, "571778": 39, "5718": 60, "572153": 71, "5722": 59, "57245066": 63, "572451": 63, "572991": 49, "573700": 52, "574": 42, "5748": 72, "574904": 49, "57496671": 40, "575": 17, "57572422": 64, "575810": 48, "57585824": 64, "57592948e": 74, "57599221": 64, "576": 42, "5763996": 40, "57643609": 64, "577": [42, 61], "5770": 59, "57715074": 40, "5772": 74, "577271": 58, "577422": 48, "577647": 45, "5776971": 64, "57775704": 64, "577807": [48, 49], "577813": 48, "5780563": 74, "578081": 60, "578307": 63, "578523": 58, "578557": 49, "578846e": 50, "57914935": 41, "579213": 65, "579238": 50, "579322e": 59, "579605e": 49, "57e": 41, "58": [18, 41, 59, 65, 71, 72, 73, 74, 88, 103], "5800": 60, "58000": 59, "580231e": 49, "580368": 48, "5804": 42, "580414": 65, "580477e": 49, "580922": 54, "581655": 60, "581849": 49, "581868": 48, "581896": 45, "582146": 49, "58241568": 74, "582747": 49, "582761": 50, "583034": 54, "583195": [48, 49], "5833333": 42, "583404": 59, "583508": 48, "583534": 63, "584012": 60, "584742": 55, "584849": 50, "584877": 49, "584928": 48, "584942e": 58, "5852": 60, "585426": 74, "585793": 50, "586362": 63, "5864": 39, "5866": 60, "586719": 50, "586719493648897": 50, "5868472": 40, "587135": 49, "587292": 60, "588": 60, "588000": 71, "58812": 72, "588364": 71, "588992e": 49, "589248": 64, "589440": 50, "59": [71, 72, 73, 74, 88], "590320": 52, "5905": 59, "590736": 63, "590813": 63, "590911": 50, "590991": 50, "591080": 52, "591411": 54, "591441": 3, "591741": 59, "591782": 63, "591788": 59, "59199423e": 74, "592186": 49, "592681e": 50, "59307502e": 74, "593648": 72, "593754e": 55, "593981": 71, "594": 17, "594241": 71, "594316e": 63, "595": 37, "595353": 50, "596": 60, "596069e": 60, "5962": 59, "596270": [54, 55], "5964": 57, "596758": 48, "597": 41, "597098": 60, "5973549": 74, "597923": 60, "598080": 48, "598178": 60, "598539": 49, "59854797": 73, "5985730": 41, "59861": 60, "599208": 45, "599297": 73, "5cb31a99b9cc": 42, "5d": [50, 63], "5x_2": 52, "5x_3": 52, "5z_i": 63, "6": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 24, 25, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 99, 101, 102, 103], "60": [40, 50, 51, 60, 61, 63, 66, 71, 72, 73, 74, 88, 102], "600": 58, "6000": 60, "6000000000000002": [50, 60, 63], "600000e": 60, "600254": 62, "6003212": 74, "600484": 61, "600694": 73, "600776": 45, "600934": 71, "601": 41, "601061": 50, "601149": 48, "601314": 48, "601598": 58, "601645": 49, "602079": 55, "602168": 50, "602417": 61, "602587": 63, "602628": 50, "6029": 60, "603273": 48, "6032876": 74, "604016": 60, "604111": 60, "604227": 59, "604603": 6, "604825": 60, "604841": [59, 60], "605": 60, "605195": 55, "606034": 63, "606129": 63, "606342": 50, "6066547": 74, "606759": 60, "6068": 40, "606800": 58, "606954": 50, "607080": 49, "607264": 48, "6075": 104, "607600": 60, "608": 53, "608003e": 49, "608392": 63, "60857": 39, "608818": 64, "609205": 48, "609575": 73, "61": [71, 72, 73, 74, 88, 103], "610195e": 48, "610559": 49, "611": 104, "6110": 60, "611269": 58, "611859": 55, "612": 37, "612151": 49, "612792": 60, "6133": 41, "613314": 50, "613408": 63, "613498": 60, "613574": 56, "613622": 49, "613691": 73, "614185e": 49, "614188": 58, "614201": 45, "614678": 60, "615": 45, "615498": 3, "615573e": 49, "615574": 49, "615863": [54, 55], "61669761": [89, 94], "616698": [89, 94], "6167145": 74, "616797": 49, "616828": 60, "617": 58, "617283": 60, "6173": 42, "617800": 49, "617877": 63, "618069": 59, "61810738": 41, "618256": 49, "618776": 51, "618922e": 48, "619128": 49, "619177": 59, "619351": [48, 49], "619390": [48, 49], "619454": 52, "619613": 59, "61e": [41, 104], "62": [3, 56, 71, 72, 73, 74, 88], "620156": 63, "620407": 48, "620874e": 73, "620995": 66, "621094": 60, "621318": 63, "62131806": 63, "621490": 63, "6215": 59, "621902": 45, "622": 60, "622153": 60, "622272": 45, "622301": 48, "6224": 40, "622750": 45, "622949": 48, "623024": 50, "623147": 55, "623173": 48, "623197": 59, "624": 58, "6240": 64, "62403053": 51, "624224e": 48, "6243811": 40, "624482e": 48, "624535": 72, "624798": 59, "624919": 60, "624988": 60, "625": [40, 58], "625159": 56, "625183": 45, "625477": 63, "625766": 54, "625891": [54, 55], "626433": 63, "6266": 60, "626633": 49, "627505": [54, 55], "627560": 63, "627564": 50, "627588e": 60, "628": 37, "628069": 58, "629306": 49, "629346": 60, "629549": 49, "629595": 15, "629771": 49, "63": [40, 58, 71, 72, 73, 74, 88, 102, 103], "6300111": 74, "630150e": 63, "630914": 56, "631333": 63, "6318": [59, 104], "631821": 49, "632058": 58, "63245862e": 74, "632747e": 63, "632958": 62, "6330631": 88, "633350": 49, "633433": 58, "634055": 48, "63407762": 104, "634078": [59, 104], "634577": 88, "63499": 60, "635000e": [59, 60], "635199": [59, 60], "63593298": 73, "636048": 73, "636453": [10, 71], "6365569": 74, "636575": 50, "637326": 63, "6379": 59, "638264": 63, "638488": 56, "638742": 49, "639135": 58, "63916605": 41, "639345": 60, "639580": 49, "63983": 74, "64": [49, 59, 60, 71, 72, 73, 74, 88, 101], "640": 60, "640334": 45, "64062": 74, "640900": 60, "641528": 63, "641547": 63, "64154727": 63, "64197957": 63, "641980": 63, "6420": 60, "642016": 63, "642329": 45, "64269": 64, "642735": 59, "643133": 60, "64340": 64, "643512": 50, "643752": 63, "644": 37, "644113": 71, "644182": 71, "644665": 50, "64476745e": 74, "644799": 52, "644985": 48, "645": 60, "645583": 45, "64579": 39, "6458": 40, "645800": 58, "646937": 52, "646997": 48, "647002": 60, "647004": 73, "647010": 60, "647196": 52, "64723": 64, "647689": 65, "647873": 63, "64797": 64, "649": 102, "649158": 63, "649891": 49, "64e": 74, "65": [50, 56, 60, 63, 71, 72, 73, 74, 88], "650": 53, "6500000000000001": [50, 60, 63], "650000e": 60, "650234": 45, "650802": 49, "650810": 60, "650867": 50, "651127": 49, "65138830": 74, "652071": 60, "6522": 102, "652312": 54, "652349": 63, "652350": 58, "652450e": [59, 60], "6527": 53, "652778": 58, "6528": 60, "6530": 60, "653820": 71, "653846": 50, "653901": [48, 49], "653991": 71, "654070e": 73, "654755": 52, "655284": 63, "6553": 104, "6554": 102, "655422": 60, "655547": 48, "65557405e": 74, "6558095": 74, "6558826": 74, "656526": 49, "6567917": 74, "657": 42, "657024": 48, "657470": 49, "658": 58, "658267": 63, "6586": 39, "658702": 49, "659": 42, "659245": [48, 49], "659339": 49, "659361": 45, "6593871": 39, "659423": [48, 49], "659473": 65, "659605e": 48, "659636": 50, "6598": 57, "66": [45, 57, 61, 71, 72, 73, 74, 88, 101, 103], "660": 42, "660320": 55, "66035991": 74, "660479": 73, "660776": 63, "66133": 73, "661369": 62, "661388": 48, "6625": 60, "663081975281988": 50, "663082": 50, "663182": 50, "6634357241067617": 65, "663529": 63, "663533": 60, "664103e": 60, "664147": 60, "664276": [71, 72], "664824": 60, "664850": 58, "665264": 63, "665554": 48, "665585": 49, "66601815": 73, "666104": 63, "666259": 49, "666307": 52, "6666667": 42, "666865": 48, "666912": 49, "667": 58, "667492e": 60, "667536": 63, "667614": 50, "667614205604159": 50, "667985": 56, "668337": 60, "668452": 56, "668584": 52, "668981": 54, "669": 37, "66989604": 51, "67": [37, 42, 48, 59, 65, 71, 72, 73, 74, 88, 101], "670785": 45, "670867": [14, 71], "671271": [48, 49], "67136": 60, "6716717587835648": 50, "671672": 50, "671690": 48, "6722": 42, "672234": [48, 49], "672368": 50, "6723684718264447": 50, "672384": [48, 49], "67245350": 40, "673092": [48, 49], "673302": 58, "6733082": 74, "673586": 48, "67410934": 40, "6745349414": 40, "674552": 60, "67456": 65, "674609": 50, "674936": 49, "674949e": 64, "675293": 62, "675625": 71, "675733e": 49, "676405": 50, "6765": [41, 59], "676534": 88, "676756": 63, "676807": 59, "677614": 63, "677980": 50, "678117": 60, "678369": 49, "678826": 50, "67936506": 73, "6795": 59, "679539": 58, "67ad635a": 42, "68": [42, 45, 61, 64, 71, 72, 73, 74, 88], "680": 60, "680620": 49, "6810775": 64, "681176": 58, "681246": 49, "681448": 60, "681521": 48, "681562": 60, "681817dcfcda": 42, "682269": 60, "682353": 49, "682631": 49, "682875": 50, "683487": 49, "683581": 73, "683942": 63, "683984": 11, "684": 104, "68410364": 41, "68411700": [41, 104], "684142": 48, "684502": 63, "685104": 5, "685107": 63, "68554404e": 74, "68562150e": 74, "685807": 63, "686627": 48, "687": 61, "687345": 63, "687619": 49, "687647": 63, "687697": 45, "687854": 52, "687871": 58, "6878711": 40, "688": 102, "688747": 60, "688887": 73, "688918": 60, "689088": [48, 49], "689188": 52, "689392": 63, "69": [56, 71, 72, 73, 74, 88, 103], "690334": 50, "6903344145051182": 50, "690668": 49, "690796e": 49, "691136": 71, "691157": 51, "69140475e": 74, "691423": 48, "691511": 59, "691814": 48, "691911": 71, "692199": 49, "692297": 49, "692465": 49, "692725": 63, "692907": 60, "693316": 60, "693497e": 60, "693513": 49, "693632": 48, "693690": 60, "693796": 58, "694154": 50, "694839": 49, "694845e": 60, "694919": 58, "6950": 60, "695045": 48, "69508862": 73, "695581": 56, "69562150e": 74, "696011": [13, 71], "696289": [54, 55], "696770": 71, "69684828": 73, "697": 58, "697000": 50, "697089": 48, "697420": [54, 55], "697545": 63, "697616": 49, "698223": 52, "698244": 52, "69840389e": 74, "698509": 48, "698651": 45, "698694": 58, "699035": 63, "699082": 50, "69921": 42, "699259e": 63, "699333": 50, "699543": 45, "6_design_1a": 53, "6_r2d_0": 53, "6_r2y_0": 53, "6b": [88, 98], "6cea": 42, "7": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 19, 20, 24, 27, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 101, 102, 103], "70": [41, 50, 54, 59, 60, 61, 63, 71, 72, 73, 74, 88, 103], "700": [48, 49, 53, 58], "7000000000000002": [50, 60, 63], "700015": 63, "700102": 63, "701078": 63, "701088": 59, "701106": 56, "701265": 54, "701413": 60, "701672e": 50, "701866": 63, "7018663": 63, "701966": 60, "702489": 60, "703049": 48, "7033927": 74, "703772": 60, "703942": 71, "7040": 60, "704814": 48, "705090": 49, "705354": 48, "705456": 48, "705474": 55, "705581": 60, "7055958": 67, "705595810371231": 67, "7055958103712310": 67, "70583": 64, "706056": 60, "706231": 71, "706645": 50, "706657": 50, "706862": 6, "707125": 49, "707197": 71, "707738": 49, "707868": 63, "707963e": 59, "708190": 58, "708235": 48, "708459": 63, "708465": 49, "708821": 45, "708837": 45, "709026": 52, "709596": 48, "709606": [14, 71], "71": [71, 72, 73, 74, 88, 103], "710059": 45, "710202": 61, "710586e": 58, "711024": 60, "711328": 60, "711518": 60, "711638": 73, "711834": 49, "712082": 60, "712095": 45, "712157": 62, "712503": 64, "712592": 59, "712774": 54, "712960": 50, "713": [60, 74], "713407": 60, "713457": 48, "713959": 49, "713986": 60, "714240": 58, "714557": 49, "714651": 63, "71465114": 63, "715013": 60, "715075e": 48, "715180e": 60, "7154": 60, "715407": 50, "7155": 60, "715515": 49, "7158581": 40, "7161": 60, "716316": 48, "716387": 48, "716456": 63, "716595e": 60, "716762": 50, "716793": 50, "716799": 58, "7167991": 40, "717": 60, "717130": 60, "717185": 63, "7178": 74, "717860": 71, "718686": 65, "72": [71, 72, 73, 74, 88, 103], "720559": 48, "720571": 63, "720573": 48, "720664": 58, "721018": 48, "721071": 63, "721245": 49, "7215093d9089": 42, "72155839e": 74, "721609": 60, "722316": 63, "722634": 63, "722848": 50, "722881": 63, "7229": 60, "7229778": 74, "723": 42, "723314": 63, "723345e": 63, "723846": 45, "7239": 60, "7241399": 40, "724338": 63, "724603": 48, "724767": [54, 55], "724918": 65, "725": 42, "725080": 45, "725087": 60, "725166": 63, "725802": 6, "725820": 49, "726": 42, "7268131": 40, "727543": 52, "727693": 60, "727704": 60, "727976": 50, "7282094": 73, "728294": 62, "728710": 63, "728734": 45, "72875815e": 74, "728852": 60, "72945682": 74, "73": [41, 45, 71, 72, 73, 74, 88], "730023": 60, "7308": 39, "730884e": 49, "731317": 50, "732067": 48, "732405": 59, "732586": 59, "7326": 60, "732638": 63, "73285": [10, 71], "732918": 54, "733": 60, "733047": 49, "733644": 48, "734": 37, "734278": 45, "734635": 48, "734689": 48, "734770": 49, "734948": 63, "735048": 49, "735054": 49, "735369e": 71, "735656": 48, "7357": 60, "735848": 71, "735941": 9, "735964": 52, "736001": 48, "736082": [48, 49], "736084": 63, "73608412": 63, "736823": 49, "7369089": 74, "737052": 60, "7375615": 41, "73764317e": 74, "737694e": 48, "737951": [48, 49], "738065": 49, "738223": 60, "738315": 60, "738659e": 60, "738793": 71, "739": 60, "7395359436844482": 50, "739536": 50, "739720": 60, "739817": 56, "74": [18, 41, 59, 71, 72, 73, 74, 88, 103], "740": [58, 59], "740180e": 63, "740417": 59, "740505": 45, "740869": 50, "741104": 50, "741523": 45, "741702": 63, "7418": 39, "74189": 42, "742128": 63, "742375": 48, "742407": 62, "742758e": 49, "742907": 63, "7432": 39, "743247": 60, "743341": 49, "7437": 60, "744": 104, "74402577": 63, "744026": 63, "744228": 49, "744236": 64, "74461783e": 74, "745": 60, "745022": 45, "745207": 61, "745444": 48, "745714": 59, "745881": 48, "746361": 63, "746843": 55, "7470": 60, "747646": 60, "747945": 40, "747961": 60, "748377": 59, "748513": 60, "748880": 60, "749": 37, "74938952": 73, "749443": 60, "749540": 48, "749854893": 75, "75": [14, 18, 20, 42, 45, 48, 50, 52, 59, 60, 63, 71, 72, 73, 74, 88, 98, 103], "75000": 65, "7500000000000002": [50, 60, 63], "750000e": 60, "7500571": 74, "750571e": 49, "750597": 49, "750701": 45, "751013": 60, "751261": 60, "751482e": 55, "751633": 60, "75171": 59, "751710": [50, 59], "751712655588833": 67, "7517126555888330": 67, "751712656": 67, "752015": 8, "752283": 60, "752743204": 74, "7533": 59, "753393": 48, "753523": 63, "753866": 49, "754448": 48, "754710": 48, "7548": 65, "754870": 58, "755": 59, "755688": 48, "755717": 48, "755910": 60, "7559417564883749": 50, "755942": 50, "7560824": 40, "756200": 45, "756647": 48, "756805": 58, "756867e": 60, "756905": 6, "756969": 50, "757": 102, "757151": [48, 49], "757183": 50, "757411": 63, "757819": 58, "757917e": 63, "758391": 60, "75887": 42, "759006": 51, "759833": 49, "76": [71, 72, 73, 74, 88, 102, 103], "760104": 63, "7603": 39, "760386": 73, "760494e": 49, "760778": 58, "760915": 52, "761": [40, 58, 61], "761429": 49, "761714": 50, "762237": 48, "762284": 63, "76228406": 63, "762748": 60, "763219": 48, "763691": 60, "764093": [48, 49], "76419024e": 74, "764315": 63, "76444177e": 74, "764478": 62, "7646": 60, "764798": 63, "764953": 59, "765": [37, 59], "765202": 60, "765363": [48, 49], "765500e": [59, 60], "765710e": 66, "765792": 63, "765864": 64, "76591188": 40, "7660": 39, "7663": 60, "766499": 63, "766850e": 49, "766940": 45, "76702611e": 74, "767188": [54, 55], "767247": 71, "767349": 71, "767435": 65, "767616": 45, "768071": 63, "768273": [54, 55], "768331": 49, "768798": 45, "769290": 48, "769361": 63, "7694171": 74, "769805": 63, "77": [71, 72, 73, 74, 88], "770556": 60, "770751": 61, "770944": [54, 55], "7710": 64, "771157": 88, "771390e": 60, "7714": 61, "7716982": 41, "771741": 60, "771965": 60, "772253": 49, "77227783e": 74, "772291": 48, "772791": 60, "77289874e": 74, "773": 42, "773177": 50, "773488": 63, "77348822": 63, "77401500e": 74, "774253": 48, "774271e": 60, "775": [42, 60], "775191": [48, 49], "775252": 61, "775969": 64, "7763": 59, "776728e": 58, "776887": 59, "7776071": 40, "777728": 71, "7786": 39, "778852": 71, "779": 104, "779167": 3, "779185": 48, "779350": 48, "779517": [48, 49], "779682": 50, "7799": 57, "779912": 60, "77e": 74, "78": [49, 71, 72, 73, 74, 88, 103], "780": 42, "780120": 49, "780458": 63, "780857": 59, "780887e": 48, "781": [37, 60], "781233": 60, "781530": 63, "781681": 63, "782": 42, "782050": 63, "782117": 45, "782555": 60, "782646": 71, "783": 42, "7832060": 74, "783276": 73, "7833": 39, "7838": 39, "784": [88, 98], "784066": 49, "784238": 58, "784341": 48, "784405": 64, "784483": 58, "784624": 50, "785": 42, "785038": 49, "785815": 45, "785911": 63, "786": 42, "786744": 50, "78711285e": 74, "787396": 48, "787716": 48, "78777": 64, "788": 102, "78818": 42, "788400": 49, "789422e": 61, "789671": 50, "789671060840732": 50, "79": [45, 71, 72, 73, 74, 103], "790115": 60, "790261": 71, "790314": 48, "790723": [54, 55], "79122": 59, "791220": 59, "791241": 63, "791297": [14, 71], "791529": 48, "792939": 50, "793316": 71, "79338596e": 74, "793570": 63, "793735": 63, "793818": [48, 49], "794": 73, "794366": 60, "794526": 48, "79458848e": 74, "794805": 54, "795558": 49, "795647": 63, "7957": 60, "795932": 72, "796014": 49, "796203": 73, "796220": 49, "796294": 61, "796384": 49, "796444": 60, "797157": 45, "797280": 63, "797737": 88, "79792890e": 74, "797965": 88, "798071": 5, "798309": 59, "798697": 61, "798783": [54, 55], "799403": 63, "7999": 66, "7b428990": 42, "7x": 63, "8": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 35, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 101, 103, 104], "80": [50, 51, 60, 63, 66, 71, 72, 73, 74, 103], "800": [37, 58], "8000": [29, 66], "8000000000000002": [50, 60, 63], "800272": 71, "800351": 48, "800854": 48, "801": 104, "801623": 60, "802289": 60, "803300": 48, "803492e": 63, "803563": 60, "803902e": 60, "804": 60, "804081e": 49, "804219": 63, "804284": 64, "804316": 63, "804484": 63, "8048": 41, "804828": 63, "804889": 60, "805007": 58, "805153e": [59, 60], "8055563": 40, "805774": 48, "8059": 59, "805962": 48, "806218e": 60, "806531": 60, "806554": 48, "806964": 49, "80696592e": 74, "80714504e": 74, "807879": 63, "808": [41, 88, 98], "808246": 59, "808284": 60, "808640": 60, "8095": 61, "809913": [48, 49], "80a8": 42, "81": [40, 53, 56, 57, 71, 72, 73, 74, 103], "810044": 59, "810134": 63, "8102": [39, 59], "810306": 45, "810363": 60, "810382": [59, 60], "810707": 60, "811155": 56, "811398": 71, "8116912": [88, 98], "811696": 48, "811825": 58, "811901": 63, "81190107": 63, "812311": 48, "812484e": 48, "8132463": 40, "8132918": 74, "813293": 63, "813342": [88, 98], "813682": 60, "814136": 50, "814351": 50, "814410": 48, "814913": 58, "8152": 60, "815224": [88, 98], "815226": 73, "815574": 49, "81568484": 63, "815685": 63, "815993": 63, "816176": 65, "816318": 58, "816645": 45, "816752": 60, "817291": 60, "8173602": 57, "817628": 73, "81827267": 63, "818273": 63, "818289": 63, "81828926": 63, "818313": 45, "818380": [48, 49], "81856": 42, "818590": 48, "82": [65, 71, 72, 73, 74, 103], "8202": 41, "820366": 58, "8209": 41, "820963": 45, "8210": 41, "821021": 50, "821121": 61, "821457": 60, "821566": 63, "821855": 71, "821870": 49, "8221": 39, "822143": 61, "822289": [59, 104], "82228913": 104, "822482": 50, "8227": 60, "822822": 50, "823247": 63, "823273": [48, 49], "823769e": 48, "824350": [48, 49], "824701": 50, "824750": 50, "824889": 50, "824961e": 60, "8250": 39, "825140": 48, "825617": 58, "825801": 45, "825824": 49, "825862": 63, "825980": 50, "8259803249536914": 50, "8260": 59, "826065": [48, 49], "826215": 49, "826391": 49, "826426": 73, "826492": 63, "826519": [14, 71], "82666866e": 74, "826829": 48, "82684324": 64, "827192": 48, "827234": 48, "827375": 51, "827381": 63, "827438": 48, "827445": 45, "82761044": 74, "827735": 63, "827938162750831": [54, 55], "828058": 60, "828157": 45, "828915": [54, 55], "829162": 71, "829543": 50, "829619": 49, "82985": 56, "83": [71, 72, 73, 74, 103], "830301": 62, "830755e": 56, "831019": 50, "831741": 48, "832078": 45, "832086": 63, "8326928": 64, "832693": 64, "832844": 49, "832875": 63, "83287529": 63, "833024": 58, "833117": 48, "833227e": 72, "833464": 60, "833781": 48, "833907": 58, "8342644": 74, "8350": 60, "835125": 49, "835596": 60, "835822": 45, "836234": 73, "836515": 49, "837680": 48, "838006e": 49, "838114": 63, "838235": 61, "838457": 60, "83905": 5, "84": [42, 56, 71, 72, 73, 74, 103], "840041": 60, "840303": 63, "84030318": 63, "840630": 48, "840673": 48, "840718": 73, "840836": 63, "840995e": 59, "841": [40, 58], "841132": 59, "8415": 41, "841847": 60, "842132": 73, "842405": 50, "842444": 48, "842589": 45, "842625": 58, "842746": 63, "842770e": 49, "8428": 59, "842853": 63, "842859": 49, "842901": 49, "843730": 58, "843796": 48, "8440": 60, "844308": 63, "844549": [54, 55], "844667": 88, "844707": 63, "844889": 58, "845059": 49, "846388": 50, "847555": 48, "847595": [13, 71], "847948": 50, "847966": 60, "848757e": 59, "848868": 50, "849": 61, "849245": 45, "84930915e": 74, "849747": 64, "8497f641": 42, "8499": 60, "85": [23, 50, 56, 60, 63, 66, 71, 72, 73, 74], "8500000000000002": [50, 60, 63], "850038": 45, "850321": 58, "850439": 49, "850575": [48, 49], "850794": 63, "851198": 60, "8513": 42, "851366": 58, "852": 60, "85265193": 57, "85280376": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "85397773": 73, "855199e": 48, "855382e": 74, "855780": 63, "856117": 48, "856404": 55, "8571": 39, "857161": 63, "857294": 45, "857544": 58, "857765": 60, "858579": 49, "8587482": 74, "859": 60, "85911521e": 74, "85912862": 88, "859129": [75, 88], "85974356": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "85c5": 42, "85e": 41, "86": [71, 72, 73, 74, 103], "860261": 49, "860663": [88, 98], "860804": 63, "860992": 60, "862043": [54, 55], "862359": 50, "863687": 48, "863772": 59, "863982270": 75, "86415573": 41, "86424193e": 74, "8644": 42, "864741e": 60, "865074": 45, "865284": 48, "865313": 60, "865540": 49, "865562": [48, 49], "865854": 60, "865860": [59, 60], "866102": [48, 49], "866179899731091": 67, "866179900": 67, "866579": 60, "866798": 60, "867565": 63, "8679": 60, "868": 42, "8685788": 63, "868579": 63, "8688": 59, "869": [37, 42], "869020": 50, "869136": 49, "869425": 55, "869477": 48, "869586": 56, "869651": 49, "87": [41, 55, 56, 58, 71, 72, 73, 74, 103], "8700": 41, "870099": [54, 55], "870142": 73, "870185": 49, "870260": 63, "870332": 63, "870857": 63, "871": 42, "871887e": 49, "871923": 49, "872222": 60, "872768": 63, "872852": 63, "87290240e": 74, "872994": 60, "873048": 49, "873198": 60, "873677": [54, 55], "87384812361": 39, "87384812362": 39, "873972": 48, "87430335": [88, 98], "874303353": [88, 98], "874702": [54, 55], "8750": 60, "8759": 60, "876080": 48, "876083": 60, "87623301": 39, "876431e": 50, "876549": 60, "87674597e": 74, "8768": 39, "877": 61, "8771": 60, "877153": 60, "877455": 62, "877833": [48, 49], "878281": 63, "878289": 60, "878402": 48, "878746": 45, "878847e": 60, "879049": 60, "879103": 50, "87e": 41, "88": [41, 56, 71, 73, 74], "880106": 58, "880202e": 49, "880579": 63, "880591": 62, "880808e": 60, "880880e": 60, "880886": 59, "8810": 59, "881201": 60, "88125046e": 74, "881465": 52, "881581": 9, "88173062": 40, "881937": 45, "882475": 50, "883485": 49, "883622": 63, "883778": 49, "883914": 50, "884132": 63, "8843": 64, "8845": 39, "884996": 50, "8850": 41, "885065": 63, "885978": [54, 55], "886041": 49, "886086": [48, 49], "886266": 60, "88629": 39, "886577": 49, "88664": 42, "886771e": 48, "886777e": 49, "886989": 49, "887197": 45, "887345": 60, "887556": 50, "888146": 58, "8881461": 40, "888775": 55, "888804": 60, "888863e": 48, "889293": 63, "8893": 59, "889300": 59, "889326": 49, "889638": 45, "889733": 63, "88988263e": 74, "889913": [48, 49], "889963": 63, "88ad": 42, "89": [41, 49, 71, 73, 74, 102, 103], "890": [40, 58], "890229": 45, "89027368": [88, 98], "890273683": [88, 98], "89035917": 56, "890372": [43, 69, 101], "8903720000100010000010": [42, 69, 101], "8904": 37, "890454": 72, "8909": [40, 59, 104], "891697": 59, "892": 42, "892331": 49, "892648": 63, "892796": [48, 49], "893": 42, "8932105": 40, "893649": [48, 49], "893851": 63, "894": [42, 61], "894307e": 60, "89449": 59, "894490": 59, "894609e": 48, "895106": [48, 49], "895308": 60, "895333": 63, "895690": [48, 49], "895768e": 50, "896023": 63, "896681e": 49, "896758": 48, "897220": 63, "897240": 60, "8974": 59, "898": 37, "898722": 63, "899460": 63, "899716": 49, "8bdee1a1d83d": 42, "8da924c": 42, "8e3aa840": 42, "9": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 101, 103, 104], "90": [25, 41, 50, 51, 60, 63, 66, 71, 73, 74, 103], "9000000000000002": [50, 60, 63], "900000e": 60, "900021": 72, "901013": 49, "901148": 63, "90136": 59, "901360": 59, "901526": 56, "901683": 60, "902": [88, 98], "902573": 50, "903056e": 63, "903135": 71, "903339": 50, "903351e": 50, "903406": 73, "903418": 58, "903681": 63, "903767": [48, 49], "904156": 50, "9041560442482157": 50, "904315": 48, "905042": 49, "905494": 50, "905858": 65, "905951": 64, "905998": 55, "906073": 49, "9061": 60, "906716732639898": [54, 55], "906757": 46, "906864": 48, "907115": 63, "907130": 48, "907176": 63, "907198": 49, "9073": 60, "907491": 50, "907702": 48, "907801": 58, "90794478": [88, 98], "907944783": [88, 98], "907961": 60, "908024": 65, "908620": 48, "908788": 61, "909141": 49, "909304": [48, 49], "90963122e": 74, "909752": 49, "909942e": 71, "909975": 60, "909997": [59, 104], "91": [71, 73, 74, 103], "910000e": 60, "9102": 59, "910895": 49, "9109": 42, "910991": 48, "91102953": 63, "911030": 63, "911662": 54, "912230": [48, 49], "9126": [41, 104], "9127": [41, 104], "913": 42, "91315015": 40, "913280": 65, "913285": 48, "913485": 60, "913774": 50, "9142": 60, "91438767e": 74, "9145": 39, "915": [41, 42, 59, 60], "915000e": [59, 60], "915057e": 59, "915488": [54, 55], "916236": 39, "916528": 54, "9166667": 42, "916806": 49, "916914": 63, "917": 42, "917066": 60, "917248": 63, "91724807": 63, "917436": 63, "918104": 48, "918227": 50, "918747": 49, "919432": 63, "9194861": 74, "9197": 60, "919814": 48, "91e": 41, "92": [71, 72, 73, 74, 103], "920335": 60, "920337": 55, "920439": 48, "920645": 60, "9209": 39, "9210": 60, "921061": 65, "921372": 50, "921913": 58, "921956": [48, 49], "921e4f0d": 42, "922160": 60, "922201e": 48, "9223": 60, "9227618": 74, "922996": 58, "923": 61, "923074e": 50, "923517": 66, "923607": 63, "92369755": 40, "923804": 50, "923943": 104, "923977": 60, "924002": 63, "9243": 60, "924396": [54, 55], "92463": 59, "924630": 59, "924634": 52, "9248": 42, "924821": 50, "924843": 58, "924921": 71, "925": 51, "925248": [54, 55], "925660": 48, "925736": 50, "925957": 54, "926493": 59, "926621": 50, "927": 38, "927074": 63, "927232": 60, "9274": 60, "927950": 60, "92827999": 73, "92881435e": 74, "928947": 58, "92905": 40, "929363": 48, "929552": 48, "929598": 49, "92972925e": 88, "929729e": [75, 88], "93": [41, 71, 72, 73, 74, 103], "930": 37, "9304028": 40, "930417": 48, "931": 68, "931479": 63, "931507": 48, "931978": 101, "932027": 50, "932404e": 60, "9325": 39, "9327": 39, "932973": 63, "933259": 45, "933322": 49, "9334017": 74, "933996": 50, "934068": 45, "934433": [48, 49], "9345": 42, "934511": [88, 98], "934549": 60, "93458": 64, "934992": 50, "935": [57, 61], "935591": 63, "935730": 63, "935989": 58, "9359891": 40, "93648": 66, "936739": 63, "937116": 58, "937586": 60, "937857": 48, "938": [88, 98], "938975": [71, 72], "939068": [54, 55], "9392": 60, "939250": 48, "9395": 60, "93958082416": 104, "94": [51, 57, 71, 73, 74, 103, 104], "940354721701296": 50, "940355": 50, "940373": 60, "940450": 45, "941440": 48, "941724": 60, "941788": 54, "942139": 55, "942312": 63, "942460e": 63, "942489": 60, "9425": 39, "942550": 60, "942661": 58, "942823": 60, "943": 61, "94309994e": 74, "943200": 48, "943270": 48, "943465e": 48, "943938": 63, "943949e": 63, "944149": 71, "944253e": 63, "944266": [54, 55], "944280": 60, "94441007e": 74, "944839": 45, "945402e": 48, "945417": 48, "94563787": 74, "945881": 48, "94629": 66, "946297": 50, "946406": 55, "946433": 63, "946533": 48, "946658": 60, "946968": 50, "947440": 62, "947466": 72, "947613": 49, "9480": 60, "948154e": 54, "948344e": 49, "948868": 60, "94906344": 40, "949241": [88, 98], "949456": 63, "949866": 49, "95": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 39, 41, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 63, 64, 65, 66, 71, 73, 74, 88, 89, 94, 103, 104], "9500": 60, "950131e": 49, "950545": 46, "95062986e": 74, "951115": 49, "951415": 48, "951502": 63, "951532": 58, "951550": 49, "951920": 62, "952": [41, 104], "9523": 39, "952839": 63, "9534": 60, "953683": 58, "95372559e": 74, "954": [88, 98], "95401167e": 74, "954536": 71, "955005e": 60, "9551": 60, "9552": 39, "955541": [14, 71], "95559917": 72, "955701": 48, "955926": 49, "956047": 40, "9561": 39, "956110": 49, "956217": 48, "956574": 60, "956724": 50, "9567242535070148": 50, "9567876": 74, "956892": 60, "957": 37, "957375": 58, "957437": 48, "957745": 50, "9579": 41, "957996": 50, "958": [88, 98], "9580": 41, "958105": 71, "958541": 60, "959132": 49, "95e": 41, "96": [41, 48, 49, 61, 71, 73, 74, 103], "960074": 48, "9605": 60, "960808": 50, "960875e": 49, "9609": 39, "961360": 49, "961539": 60, "961962": 50, "962364": 45, "962523": 45, "963051": 49, "963055": 60, "963389": 48, "964025e": 63, "964261e": 58, "964318": 60, "9647": 39, "965341": 49, "965531": 73, "965696": 48, "965774": 60, "96582": 72, "966015": 63, "966097": 15, "966320": 45, "966659": 50, "9666592590622916": 50, "967467": 64, "968127": 45, "968134e": 63, "968577": 51, "968800": 48, "969141": 73, "9699": 59, "97": [3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 43, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 71, 72, 73, 74, 75, 88, 98, 101, 103, 104], "970065": 63, "971058": [54, 55], "971724": 48, "972088e": 48, "972509": 49, "972732": 49, "972748": 50, "97276281": 63, "972763": 63, "97314470": 40, "973156": 71, "973229": 49, "973241": 63, "973262": 48, "973331": 60, "973392e": 48, "973741": 49, "974202": 50, "974213": 49, "97441062": [54, 55], "974414": 50, "97470872": 64, "9748910611": 40, "975": [48, 49, 54, 55, 57, 61], "975232": 49, "975289": 45, "9753": 42, "975447": 51, "975450": 49, "975461": 58, "975592": 45, "975957e": 49, "976088": 63, "976562": 63, "977280": [48, 49], "977295": 60, "977507": 49, "978554": 48, "9787": 60, "978977": 63, "978997": 45, "979": 61, "979857": 48, "979896": 49, "98": [48, 49, 60, 71, 73, 74, 103], "980026": 60, "9802393": 40, "980256e": 48, "980643e": 50, "981104": 62, "981438": 48, "981672": 50, "982353e": 60, "982417": 50, "9825250": 74, "982720": 48, "982797": 62, "982986e": 48, "983": 61, "983192": 63, "983253": 48, "983759": 104, "983896": 48, "98393441": 64, "984024": 62, "984083": [54, 55], "984551": 8, "984562": 63, "984821": 48, "984866": [88, 98], "984872": [48, 49], "984937": 50, "985": 61, "98505871e": 74, "985207": [48, 49], "986383": 60, "986417": 48, "9870004": 42, "987220": 60, "987329": 49, "9875": 39, "9880384": 42, "988421": [48, 49], "988463": 63, "98861922": 74, "988690": 49, "988709": 60, "988780": 60, "988831": 61, "989291": 48, "99": [41, 45, 48, 49, 61, 71, 73, 74, 103], "990": 61, "990210": 60, "990377": 49, "990585": 61, "991": 42, "9914": [59, 60, 64], "991444e": 54, "9915": [41, 59, 60, 64], "991512": 41, "991539": 49, "991963": [48, 49], "991977": 60, "991988": 48, "99232145": 64, "992582": [48, 49], "993201": 49, "993575": 60, "994": 37, "994168239": 40, "994208": 45, "994214": 60, "994332": 46, "994377": 48, "9944": [57, 73], "994851": 60, "994937": 55, "995015": 60, "9951": 39, "995248": 63, "99549118e": 74, "99571372e": 74, "9961392": 40, "996454": 49, "996934": 58, "996946": 49, "997": 61, "9970": 60, "997034": 66, "997494": 66, "997571": 58, "997621": 50, "997934": [54, 55], "998063": 46, "99864670889": 104, "998766": 60, "9989": 59, "999": [51, 52, 56, 64, 104], "999207": 63, "9995": [48, 49, 52], "9996": [48, 49, 52], "9996553": 41, "9997": [48, 49, 52], "9998": [48, 49, 52], "9999": [48, 49, 52], "99c8": 42, "A": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 23, 24, 28, 32, 33, 34, 37, 38, 39, 41, 42, 46, 47, 53, 55, 61, 62, 64, 65, 68, 69, 71, 72, 73, 88, 89, 90, 91, 95, 96, 97, 98, 99, 101, 102, 104], "ATE": [9, 15, 18, 41, 43, 45, 59, 64, 65, 71, 73, 75, 81, 89, 95], "ATEs": [45, 61], "And": [61, 66, 89, 92], "As": [38, 39, 40, 41, 42, 45, 47, 48, 49, 50, 51, 53, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 72, 74, 75, 77, 88, 89, 91, 97, 98, 104], "At": [18, 19, 20, 40, 45, 51, 52, 56, 57, 58, 60, 63, 104], "Being": 104, "But": 57, "By": [39, 40, 58, 65, 72, 89, 94], "For": [1, 5, 6, 8, 9, 12, 20, 30, 31, 37, 39, 40, 42, 45, 46, 51, 56, 57, 58, 60, 62, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 95, 97, 98, 100, 101, 104], "ITE": [24, 45], "ITEs": 45, "If": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 32, 33, 34, 38, 40, 47, 48, 49, 51, 57, 58, 60, 68, 69, 71, 72, 73, 75, 76, 78, 79, 81, 88, 89, 91, 92, 93, 94, 96, 97, 99, 104], "In": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104], "It": [39, 40, 41, 48, 49, 53, 54, 55, 58, 59, 60, 65, 72, 74, 99, 103], "No": [22, 37, 39, 41, 42, 43, 45, 51, 56, 59, 60, 64, 66, 69, 72, 73, 75, 88, 101, 102], "Of": [57, 88, 104], "On": [38, 47, 61, 68, 102], "One": [41, 59, 60, 65, 71, 88], "Such": [65, 72], "That": 104, "The": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 37, 38, 39, 40, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 63, 64, 65, 66, 67, 70, 71, 72, 73, 74, 75, 76, 81, 84, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 102, 103, 104], "Then": [20, 50, 63, 88, 89, 97, 98, 99, 100], "There": [41, 59, 65, 100, 104], "These": [41, 42, 44, 59, 62, 64, 71, 104], "To": [31, 37, 38, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 68, 69, 71, 72, 74, 88, 89, 91, 94, 97, 98, 100, 101, 104], "With": [23, 48, 49, 72, 102], "_": [38, 40, 47, 48, 49, 50, 52, 53, 54, 55, 58, 59, 60, 62, 63, 67, 68, 71, 74, 75, 88, 89, 91, 94, 98], "_0": [38, 40, 47, 53, 58, 67, 68, 74, 75, 83, 84, 88, 89, 97], "_1": [18, 19, 20, 24, 61, 66, 75, 83, 84], "_2": [18, 19, 20, 24, 61], "_3": [18, 19, 20, 24], "_4": [18, 19, 20, 24], "_5": [18, 24], "__version__": 100, "_all_coef": 74, "_all_s": 74, "_compute_scor": 31, "_compute_score_deriv": 31, "_coordinate_desc": 58, "_est_causal_pars_and_s": 103, "_i": [38, 47, 63, 66, 68], "_id": 74, "_j": [18, 19, 20, 24, 26, 40, 58, 88, 98], "_l": 72, "_m": [72, 74], "_n": [75, 78, 79, 81, 88, 89, 94, 96, 98], "_n_folds_per_clust": 58, "_rmse": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "a09a": 42, "a09b": 42, "a3d9": 42, "a4a147": 61, "a5e6": 42, "a5e7": 42, "a6ba": 42, "a79359d2da46": 42, "a840": 42, "a_": 66, "a_0": 27, "a_1": 27, "a_j": 73, "ab": [39, 99], "ab71": 42, "abadi": [16, 51], "abb0fd28": 42, "abdt": [43, 69, 101], "abl": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 47, 57, 60, 61, 72, 89, 91, 97], "about": [41, 57, 59, 99, 101, 104], "abov": [38, 41, 45, 47, 48, 49, 54, 55, 57, 59, 61, 62, 63, 65, 68, 71, 72, 73, 100], "absolut": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 57, 72], "abstract": [31, 39, 40, 58, 75, 99, 103], "acc": [2, 39], "accept": [71, 72], "access": [32, 33, 39, 41, 54, 55, 56, 57, 64, 72, 89, 94, 104], "accord": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 41, 45, 47, 50, 51, 59, 63, 65, 66, 72, 88, 89, 90, 92, 93, 95, 98, 104], "accordingli": [51, 57, 59, 66], "account": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 41, 58, 59, 60, 64, 65, 89, 94, 97, 104], "accumul": [41, 59, 60, 64], "accuraci": 39, "acemoglu": 102, "achiev": [40, 58, 62, 65, 88, 98], "acic_2024_post": 61, "acknowledg": [41, 42, 59], "acm": 102, "acov": 102, "across": [41, 59, 61, 104], "action": 103, "activ": [4, 7, 100, 103], "actual": [56, 65], "acycl": [66, 104], "ad": [4, 7, 16, 17, 31, 56, 69, 72, 88, 89, 91, 103], "adapt": [8, 59, 103], "add": [39, 40, 43, 45, 51, 52, 54, 55, 56, 61, 63, 64, 65, 66, 72, 102, 103], "add_trac": 65, "addit": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 20, 24, 26, 27, 28, 53, 65, 72, 73, 75, 82, 89, 90, 95, 97, 102, 103], "addition": [18, 19, 45, 50, 60, 64, 72, 73, 74, 88, 89, 94, 101], "address": 65, "adel": 102, "adj": 65, "adj_coef_bench": 65, "adj_est": 65, "adj_vanderweelearah": 65, "adjust": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 35, 40, 52, 58, 60, 64, 65, 71, 88, 89, 94, 98, 104], "adopt": [51, 73], "advanc": [70, 74, 102], "advantag": [38, 39, 41, 45, 47, 59, 60, 68, 100], "advers": [89, 91], "adversari": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 64, 89, 94, 97], "ae": [38, 40, 41], "ae56": 42, "ae89": 42, "aesthet": 38, "aeturrel": 28, "afd9e4": 61, "affect": [45, 53, 73, 103, 104], "after": [39, 41, 42, 51, 53, 59, 60, 65, 66, 71, 72, 89, 92, 94, 100, 104], "after_stat": 38, "ag": [41, 59, 60, 62, 64, 104], "again": [38, 39, 40, 41, 45, 47, 51, 56, 58, 59, 64, 65, 66, 68, 89, 92], "against": [51, 56, 57, 62, 72], "agebra": 71, "agegt54": [42, 43, 69, 101], "agelt35": [42, 43, 69, 101], "agg": 39, "aggreg": [39, 67, 74, 103], "aggt": 39, "aipw": 61, "aipw_est_1": 61, "aipw_est_2": 61, "aipw_obj_1": 61, "aipw_obj_2": 61, "air": [40, 58], "al": [16, 17, 21, 23, 26, 27, 38, 40, 41, 42, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 60, 63, 64, 68, 73, 74, 75, 77, 82, 87, 88, 89, 91, 97, 98, 99, 101, 103], "alexandr": [53, 102], "algorithm": [37, 39, 40, 42, 45, 47, 50, 51, 57, 58, 60, 63, 64, 66, 70, 72, 73, 74, 75, 88, 103, 104], "align": [38, 40, 47, 50, 52, 57, 58, 59, 61, 62, 63, 66, 103], "all": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 36, 38, 39, 40, 41, 45, 47, 51, 56, 57, 58, 59, 60, 62, 65, 66, 68, 69, 71, 72, 73, 74, 88, 89, 97, 98, 99, 100, 103], "all_coef": 74, "all_dml1_coef": 67, "all_s": 74, "all_smpl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "all_smpls_clust": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "all_z_col": [40, 58], "allow": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 31, 41, 45, 59, 60, 71, 72, 73, 74, 75, 88, 98, 99, 103, 104], "almqvist": 102, "along": 72, "alpha": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 25, 27, 38, 40, 41, 43, 45, 47, 48, 49, 50, 53, 57, 58, 59, 60, 63, 67, 68, 71, 72, 73, 74, 75, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98], "alpha_": [26, 40, 58, 72], "alpha_0": [89, 97], "alpha_ml_l": 53, "alpha_ml_m": 53, "alpha_x": [8, 22, 73], "alreadi": [20, 51, 66, 72, 73], "also": [1, 5, 6, 8, 9, 12, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 51, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 68, 71, 72, 74, 75, 88, 89, 91, 100, 101, 103, 104], "alter": [40, 58], "altern": [39, 41, 42, 59, 62, 70, 72, 88, 98, 99, 100, 101], "although": 65, "alwai": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 39, 103], "always_tak": [8, 41, 59], "amamb": 58, "american": [25, 61], "amgrem": 58, "amhorn": 58, "amit": [65, 102], "amjavl": 58, "ammata": 58, "among": [41, 53, 59, 60, 64, 65], "amount": [41, 59, 60, 104], "amp": [37, 40, 42, 51, 58, 60, 64, 66], "an": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 24, 32, 33, 38, 39, 40, 41, 42, 45, 47, 48, 49, 53, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 88, 89, 91, 94, 98, 99, 100, 101, 102, 103, 104], "analog": [30, 31, 40, 58, 60, 64, 71, 73, 75, 78, 79, 88, 89, 94, 98], "analys": 104, "analysi": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 40, 41, 47, 58, 59, 60, 68, 70, 71, 91, 94, 97, 99, 103], "analyt": [61, 63], "analyz": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 41, 59, 60, 64, 104], "ancillari": 65, "andrea": 102, "angl": 41, "angrist": 61, "ani": [37, 38, 39, 42, 46, 47, 51, 65, 66, 68, 100, 104], "anna": [5, 6, 18, 19, 20, 24, 39, 51, 73, 102], "annal": [88, 98, 102], "anneal": 72, "annot": 38, "annual": 102, "anoth": [38, 39, 40, 41, 47, 57, 58, 68, 72, 73], "anticip": 39, "anymor": [40, 58], "aos1161": [88, 98], "aos1230": [88, 98], "aos1671": [88, 98], "ap": [41, 59], "ape_e401_uncond": 41, "ape_p401_uncond": 41, "api": [69, 99, 103], "apo": [1, 2, 76, 90], "apoorva": 103, "apoorva__l": 61, "apoorval": 61, "app": 103, "appeal": 65, "append": [47, 57, 68], "appendix": [23, 29, 64, 66, 89, 91], "appli": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 37, 38, 40, 41, 42, 47, 51, 52, 57, 58, 59, 60, 65, 66, 68, 73, 74, 75, 88, 98, 99, 101, 103, 104], "applic": [38, 47, 51, 61, 65, 68, 71, 74, 102, 104], "apply_along_axi": 62, "apply_cross_fit": [38, 74], "apply_crossfit": 103, "appreci": 99, "approach": [1, 3, 5, 6, 8, 9, 10, 13, 14, 15, 39, 40, 45, 58, 64, 65, 70, 72, 74, 88, 89, 91, 98, 100, 102, 104], "appropri": [41, 53, 59, 74, 104], "approx": 71, "approxim": [38, 47, 48, 49, 50, 57, 63, 65, 68, 71, 88, 98, 103, 104], "apt": 100, "ar": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 44, 45, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104], "arang": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 47, 50, 52, 60, 62, 63, 64, 65, 72], "architectur": [75, 102], "arellano": 102, "arg": 71, "argmin": 57, "argu": [38, 41, 47, 59, 60, 64, 68, 104], "argument": [20, 26, 27, 28, 41, 48, 49, 51, 56, 57, 59, 60, 67, 71, 72, 73, 104], "aris": [38, 39, 40, 47, 58, 65, 68, 104], "aronow": 61, "around": [39, 41, 59, 60, 75], "arr": 62, "arrai": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 22, 23, 25, 26, 27, 28, 29, 34, 35, 45, 47, 48, 49, 50, 51, 57, 58, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 74, 88, 89, 94, 98, 101, 103, 104], "arrang": 40, "array_lik": 14, "articl": [28, 99], "arxiv": [26, 39, 40, 58, 65, 99, 102, 103], "as_learn": [42, 72], "asarrai": [48, 49], "aspect": [41, 59, 60], "assert": 72, "assess": 39, "asset": [60, 64, 104], "assign": [4, 7, 41, 55, 59, 71, 72, 73, 104], "assmput": 73, "associ": [41, 53, 59, 73, 88, 98, 102], "assum": [37, 40, 46, 51, 58, 61, 62, 65, 73, 75, 78, 79, 88, 89, 97, 104], "assumpt": [39, 40, 41, 51, 52, 57, 58, 59, 61, 66, 73, 88, 104], "assur": 103, "astyp": [46, 59, 65], "asymptot": [30, 31, 38, 40, 47, 58, 68, 74, 88, 102], "ate": 45, "ate_estim": 66, "ates": 45, "athei": 102, "att": [9, 18, 39, 52, 56, 62, 65, 71, 73, 75, 81, 89, 95, 103], "att_gt": 39, "attach": 39, "atte_estim": 51, "attempt": [32, 33], "attenu": [41, 59], "attr": 41, "attribut": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 34, 35, 57, 67, 72, 74, 75, 88], "attributeerror": [32, 33], "attrict": 73, "attrit": [15, 66, 73], "au": [42, 72, 99, 101], "auc": 39, "author": [39, 65, 99], "automat": [38, 47, 56, 68, 71, 89, 94], "automobil": [40, 58], "autos": 53, "auxiliari": [38, 47, 68], "avail": [22, 39, 41, 42, 45, 51, 53, 57, 59, 60, 61, 62, 65, 68, 71, 72, 73, 89, 97, 99, 100, 103, 104], "avaiv": 35, "aver": 45, "averag": [1, 2, 8, 9, 12, 18, 19, 20, 37, 39, 42, 46, 51, 52, 56, 60, 61, 62, 64, 65, 66, 70, 76, 81, 88, 90, 95, 102, 103, 104], "average_it": 45, "avoid": [38, 39, 47, 74, 100, 103], "awai": 64, "ax": [45, 47, 48, 49, 50, 52, 54, 55, 57, 58, 59, 60, 61, 63], "ax1": [45, 50, 60, 63], "ax2": [45, 50, 60, 63], "axhlin": 52, "axi": [40, 41, 45, 53, 57, 58, 59, 61, 62], "axvlin": [45, 47], "b": [5, 6, 28, 38, 40, 42, 47, 48, 49, 58, 61, 63, 65, 68, 71, 72, 88, 89, 97, 98, 99, 101, 102], "b208": 42, "b371": 42, "b5d34a6f42b": 42, "b5d7": 42, "b_0": 27, "b_1": 27, "b_j": 28, "bach": [65, 99, 102, 103], "backbon": 57, "backend": [4, 7, 39, 60, 64, 65, 70, 103], "backward": 103, "bad": 61, "balanc": [41, 59, 60], "band": [39, 70, 104], "bandwidth": [10, 13, 14], "bar": [56, 59, 71, 75, 76, 81, 89, 90], "base": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 21, 24, 35, 38, 39, 40, 41, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 88, 89, 91, 94, 98, 99, 101, 102, 103, 104], "baselin": [24, 41, 59], "basi": [1, 9, 12, 34, 48, 49, 71], "basic": [39, 40, 41, 51, 58, 59, 60, 61, 64, 65, 70, 72], "batch": 42, "battocchi": 102, "bay": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 88, 98], "bb2913dc": 42, "bbotk": [42, 72, 103], "bbox_inch": 47, "bbox_to_anchor": 47, "bcallaway11": 39, "bd929a9e": 42, "bde4": 42, "becam": [41, 59, 60], "becaus": [37, 38, 39, 40, 46, 47, 55, 56, 58, 61, 65, 68, 104], "becker": [42, 72], "becom": [40, 55, 58, 71, 74], "bee": 52, "been": [40, 41, 58, 59, 60, 64, 65, 71, 72, 103], "befor": [39, 41, 45, 52, 56, 59, 63, 65, 73, 104], "begin": [22, 25, 26, 38, 40, 41, 42, 47, 50, 52, 57, 58, 59, 61, 62, 63, 66, 67, 69, 72, 74, 88, 98, 101, 104], "behav": 55, "behavior": [41, 61, 72], "behaviour": 55, "being": [24, 29, 30, 31, 40, 58, 65, 74, 75, 77, 88, 89, 94, 98, 99], "belloni": [23, 53, 88, 98, 102], "below": [37, 41, 46, 59, 61, 100, 101], "bench_x1": 65, "bench_x2": 65, "benchmark": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 36, 45, 56, 91, 103], "benchmark_dict": [36, 64], "benchmark_inc": 64, "benchmark_pira": 64, "benchmark_result": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "benchmark_twoearn": 64, "benchmarking_set": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 56, 64, 65, 89, 91], "benchmarking_vari": 56, "benefit": [38, 41, 47, 59, 68], "bernoulli": 22, "berri": [40, 58], "besid": 101, "best": [1, 9, 12, 34, 48, 49, 54, 55, 100], "beta": [15, 22, 23, 25, 29, 41, 59, 62, 66], "beta_": 66, "beta_0": [21, 62, 66, 71], "beta_a": [18, 19, 65], "beta_j": [22, 23, 25, 29], "better": [39, 45, 57, 65], "between": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 45, 46, 50, 52, 53, 61, 63, 64, 65, 66, 73, 75, 78, 79, 81, 85, 86, 88, 89, 97, 98, 101, 103], "betwen": [37, 46], "beyond": 102, "bia": [29, 37, 46, 53, 65, 66, 70, 73, 74, 75, 83, 84, 89, 97, 102, 103], "bias": [37, 41, 46, 59, 60, 64, 104], "bias_bench": 65, "bibtex": 99, "big": [53, 67, 74, 75, 79, 82, 88, 89, 92, 93, 95, 96, 97], "bigg": [40, 58, 75, 80, 81, 89, 95], "bilia": 17, "bin": [38, 45, 47, 100], "binari": [1, 3, 5, 6, 8, 9, 10, 12, 13, 15, 21, 37, 39, 41, 42, 46, 51, 56, 57, 59, 61, 62, 65, 71, 72, 89, 90, 95, 103, 104], "binary_treat": [21, 48, 54, 56], "bind": 103, "binder": [42, 72, 99, 101, 103], "binomi": [46, 61, 62, 63], "bischl": [42, 72, 99, 101], "black": [38, 42, 43, 69, 101], "blob": 39, "blog": 28, "blondel": [99, 101], "blp": [34, 40, 58], "blp_data": [40, 58], "blp_model": [54, 55], "blue": [38, 40, 58], "bodori": 102, "bond": [41, 59, 60], "bonferroni": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 88, 98], "bonu": [17, 42, 69, 101], "book": [42, 65, 72], "bool": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 21, 24, 32, 33, 34, 56], "boolean": [29, 54, 55, 69, 74], "boost": [37, 41, 46, 51, 57, 59], "boost_class": [41, 59], "boost_summari": 59, "boostrap": [50, 103], "bootstrap": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 45, 48, 49, 50, 54, 55, 60, 63, 70, 71, 74, 75, 99, 101, 103, 104], "both": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 19, 21, 39, 41, 42, 51, 52, 57, 59, 60, 62, 64, 65, 69, 72, 88, 89, 91, 94, 96, 97, 103, 104], "bottom": [40, 41, 57, 58, 59, 60], "bound": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 24, 41, 45, 56, 59, 64, 65, 89, 91, 94, 97, 104], "branch": 42, "brantli": 39, "break": [38, 103], "breviti": 104, "brew": 100, "brewer": 40, "bridg": 65, "brief": 68, "bring": [37, 46], "brucher": [99, 101], "bsd": 103, "budget": 72, "bug": [99, 103], "build": [40, 57, 58, 62], "build_design_matric": [48, 49], "build_sim_dataset": 39, "built": [35, 72, 99], "bureau": [65, 74, 102], "busi": [26, 29, 40, 58, 65, 102], "b\u00fchlmann": 102, "c": [16, 17, 19, 20, 23, 25, 27, 37, 38, 39, 40, 41, 42, 43, 46, 47, 52, 53, 54, 55, 58, 59, 61, 68, 69, 72, 99, 100, 101, 102, 104], "c1": [16, 17, 27, 40, 53, 58, 68, 99, 102], "c68": [16, 17, 27, 40, 53, 58, 68, 99, 102], "c895": 42, "c_": [88, 98], "c_d": [23, 89, 95, 96, 97], "c_y": [23, 89, 97], "ca1af7be64b2": 42, "caac5a95": 42, "calcualt": 62, "calcul": [1, 9, 12, 39, 41, 45, 48, 49, 50, 54, 55, 57, 59, 63, 64, 89, 94, 97], "calibr": [57, 65], "call": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 37, 39, 40, 41, 42, 46, 48, 49, 50, 51, 54, 55, 58, 59, 60, 62, 63, 64, 65, 66, 69, 72, 74, 75, 88, 89, 94, 97, 98, 100, 101, 103, 104], "callabl": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 47, 48, 49, 57, 70, 72, 99], "callawai": 39, "camera": 53, "cameron": [40, 58], "can": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 21, 35, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 78, 79, 81, 85, 86, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104], "candid": 65, "cannot": [57, 65, 104], "capabl": [4, 7, 37, 46], "capo": 1, "capsiz": [45, 61], "capthick": 45, "cardin": [40, 58], "care": 72, "carlo": [18, 19, 21, 24, 48, 49, 54, 55, 65, 102], "casalicchio": [42, 72, 99, 101], "case": [1, 4, 7, 8, 9, 17, 21, 37, 40, 41, 46, 48, 49, 50, 53, 55, 56, 58, 62, 63, 64, 65, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 101, 103, 104], "cat": [38, 103], "catboost": 57, "cate": [9, 12, 34, 70, 103], "cate_obj": 71, "caus": [38, 47, 68], "causal": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 22, 23, 25, 26, 27, 28, 29, 37, 38, 40, 41, 42, 46, 47, 58, 59, 61, 64, 66, 67, 68, 69, 70, 73, 74, 88, 89, 94, 98, 102], "causal_contrast": [2, 45, 73], "causal_contrast_model": [45, 73], "causaldml": 102, "causalweight": 102, "caution": 88, "caveat": [55, 65], "cbind": 40, "cc": 59, "ccp_alpha": [9, 35, 59], "cd": 100, "cd_fast": 58, "cda85647": 42, "cdf": 71, "cdid": [40, 58], "cdot": [18, 19, 20, 24, 40, 50, 52, 56, 58, 61, 63, 65, 71, 73, 75, 76, 81, 82, 83, 84, 88, 89, 90, 98], "cdot1": 56, "center": 53, "central": [74, 103], "certain": 55, "cexcol": 40, "cexrow": 40, "cf_d": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 36, 45, 56, 64, 65, 89, 90, 91, 94, 95, 96, 97, 104], "cf_y": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 36, 45, 56, 64, 65, 89, 90, 91, 94, 95, 96, 97, 104], "chad": 65, "chain": 55, "chainedassignmenterror": 55, "challeng": [40, 58, 89, 91], "chang": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 51, 55, 60, 64, 65, 66, 75, 81, 88, 89, 90, 91, 92, 93, 94, 95, 100, 102, 103], "channel": 104, "chapter": [30, 31, 42, 72, 89, 97], "charact": [41, 42, 72, 103], "characterist": [64, 104], "check": [32, 33, 38, 41, 47, 57, 59, 60, 67, 68, 99, 100, 103], "check_data": 103, "check_scor": 103, "checkmat": 103, "chernozhukov": [16, 17, 23, 25, 27, 38, 40, 41, 47, 53, 57, 58, 59, 60, 64, 68, 74, 88, 89, 91, 97, 98, 99, 102, 103], "chetverikov": [16, 17, 27, 40, 53, 58, 68, 88, 98, 99, 102], "chiang": [26, 40, 58, 102], "chieh": 102, "choic": [1, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 41, 53, 59, 62, 71, 72, 89, 91, 94, 97, 103], "choos": [37, 41, 46, 47, 53, 57, 59, 60, 67, 74, 75, 78, 79, 81, 85, 86, 88, 98, 101, 104], "chosen": [1, 19, 24, 57, 72], "chou": 61, "chr": 41, "christian": [53, 102], "chunk": 72, "ci": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 48, 49, 50, 51, 52, 54, 55, 56, 59, 60, 63, 64, 65, 71, 89, 94, 103, 104], "ci_at": 45, "ci_cvar": [50, 60], "ci_cvar_0": 50, "ci_cvar_1": 50, "ci_joint": 45, "ci_joint_cvar": 50, "ci_joint_lqt": 63, "ci_joint_qt": 63, "ci_length": 51, "ci_low": 45, "ci_lpq_0": 63, "ci_lpq_1": 63, "ci_lqt": [60, 63], "ci_pointwis": 45, "ci_pq_0": [60, 63], "ci_pq_1": [60, 63], "ci_qt": [60, 63], "ci_upp": 45, "cinelli": [65, 89, 91, 102], "circumv": 104, "citat": 103, "claim": 42, "clash": 39, "class": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 30, 31, 32, 33, 34, 35, 41, 42, 43, 45, 51, 56, 59, 60, 64, 66, 67, 69, 71, 72, 74, 75, 88, 99, 101, 103], "class_learn": 60, "class_learner_1": 57, "class_learner_2": 57, "classic": [39, 40, 58, 104], "classif": [9, 37, 39, 41, 42, 57, 62, 64, 71, 72, 73, 104], "classifavg": 42, "classifi": [1, 3, 5, 6, 8, 9, 10, 12, 13, 14, 15, 32, 42, 45, 72, 103], "classmethod": [4, 7], "claus": 103, "clean": 103, "cleaner": 57, "cleanup": 103, "clear": [40, 58], "clever": 57, "clone": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 38, 42, 47, 57, 58, 60, 67, 72, 73, 74, 75, 88, 89, 94, 98, 100, 101], "close": [39, 41, 59, 65, 89, 91], "cluster": [1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 26, 102, 103], "cluster_col": [4, 40, 58], "cluster_var": [4, 26], "cluster_var_i": [4, 40, 58], "cluster_var_j": [4, 40, 58], "cmap": 58, "cmd": 103, "co": [28, 52], "codaci": 103, "code": [1, 9, 12, 28, 37, 39, 40, 41, 42, 46, 53, 59, 68, 71, 72, 73, 74, 75, 88, 100, 101, 103, 104], "codecov": 103, "coef": [3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 88, 101, 104], "coef_": 65, "coef_df": 40, "coeffici": [18, 19, 21, 34, 41, 54, 55, 57, 59, 61, 62, 65, 66, 71, 88, 89, 94, 98, 104], "coefs_t": 62, "coefs_w": 62, "coffici": [89, 94], "cofid": 34, "coincid": [52, 60], "col": [38, 40, 55, 59], "collect": [42, 51, 58, 66], "colnam": [40, 57], "color": [41, 45, 47, 48, 49, 50, 52, 58, 59, 60, 61, 63, 65], "color_palett": [45, 47, 58, 59, 60], "colorbar": 58, "colorblind": 45, "colorramppalett": 40, "colorscal": [48, 49], "colour": [38, 40], "column": [4, 7, 43, 45, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 69, 71, 72, 74, 101, 103, 104], "column_stack": [45, 52, 54, 55, 64, 65], "colv": 40, "com": [28, 39, 41, 42, 53, 59, 61, 65, 72, 100], "comb": 53, "combin": [39, 40, 42, 45, 51, 57, 58, 65, 72, 74, 89, 94, 103], "combind": 60, "combined_loss": 53, "come": [67, 72, 75, 89, 91, 99, 104], "command": [100, 103], "comment": 69, "common": [57, 64, 65, 71, 73, 102], "companion": 102, "compar": [38, 40, 47, 48, 49, 50, 52, 54, 55, 58, 61, 63, 65, 68, 72, 89, 91], "comparevers": 41, "comparison": [45, 57, 61], "compat": [37, 39, 46, 103], "complement": 65, "complet": [68, 89, 94, 100], "complex": [9, 39], "complianc": [63, 75, 82], "complic": [42, 104], "complier": [41, 59, 60, 63, 71], "compon": [39, 41, 53, 57, 59, 62, 71, 72, 74, 75, 76, 78, 79, 80, 81, 82, 85, 86, 103], "compont": 39, "composit": 102, "compris": [88, 98], "comput": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 36, 38, 39, 41, 42, 47, 59, 60, 64, 65, 74, 75, 89, 90, 91, 92, 93, 94, 95, 99, 102, 103, 104], "computation": [89, 91], "concat": [58, 59, 62, 88], "concaten": [52, 59, 88], "concentr": 88, "concern": 65, "conclud": [65, 104], "cond": 73, "conda": [58, 102, 103], "condit": [1, 3, 9, 12, 18, 19, 21, 30, 31, 38, 40, 41, 45, 47, 51, 52, 56, 58, 59, 62, 65, 66, 68, 70, 73, 88, 89, 90, 95, 97, 98, 101, 102, 103, 104], "conduct": [71, 73, 104], "conf": [39, 63], "confer": 102, "confid": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 39, 40, 41, 45, 48, 49, 50, 51, 54, 55, 58, 60, 63, 64, 66, 70, 71, 74, 75, 89, 94, 101, 102, 104], "confidenceband": 50, "confidenti": 65, "config": 61, "configur": 42, "confint": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 41, 45, 48, 49, 50, 51, 52, 54, 55, 57, 60, 62, 63, 64, 66, 71, 74, 88, 98, 99, 101, 104], "conflict": 100, "confound": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 21, 36, 37, 41, 46, 56, 59, 63, 64, 65, 69, 73, 88, 89, 91, 94, 96, 97, 98, 101, 102, 103, 104], "congress": 102, "connect": [41, 59, 60], "consequ": [18, 19, 40, 56, 58, 64, 71, 73, 89, 90, 91, 95, 97], "conserv": [64, 65, 89, 97], "consid": [3, 8, 9, 10, 13, 38, 40, 41, 47, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 88, 89, 91, 98, 99, 104], "consider": 65, "consist": [11, 12, 41, 51, 59, 60, 61, 65, 68, 69, 73, 101, 103], "consol": [38, 103], "constant": [23, 53, 62, 71, 88, 98], "constrained_layout": 47, "construct": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 34, 42, 48, 49, 50, 52, 60, 64, 67, 71, 75, 77, 84, 88, 98, 103, 104], "construct_framework": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "construct_iv": 58, "constructiv": 40, "constructor": 42, "consum": [40, 58], "cont": 24, "cont_d": 45, "contain": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 24, 32, 33, 38, 40, 41, 45, 47, 48, 49, 54, 55, 57, 58, 59, 68, 71, 72, 88, 89, 91, 94, 103], "context": [65, 73, 104], "contin": 24, "continu": [24, 37, 42, 45, 46, 53, 61, 89, 97, 103, 104], "contour": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 53, 56, 64, 65, 89, 94], "contour_plot": 65, "contours_z": [48, 49], "contrast": [2, 50, 51, 73], "contribut": [100, 103], "contributor": 103, "control": [25, 39, 53, 60, 62, 65, 104], "convent": [41, 59, 60], "converg": [38, 47, 57, 58, 68], "convergencewarn": 58, "convers": 58, "convert": [50, 58, 63], "convex": 61, "coor": [42, 72, 99, 101], "coordin": 65, "copi": [55, 59, 62, 65], "cor": [89, 97], "core": [43, 45, 50, 51, 56, 58, 59, 60, 63, 64, 66, 69, 72, 101, 103], "cores_us": [50, 60, 63], "correct": [56, 65, 71, 88, 98, 103], "correctli": [51, 61, 64, 89, 97], "correl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 53, 58, 64, 66, 73, 89, 91, 97], "correpond": 73, "correspond": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 24, 30, 31, 38, 40, 41, 42, 45, 47, 48, 49, 51, 52, 53, 57, 58, 59, 60, 62, 63, 64, 65, 68, 71, 72, 73, 74, 88, 89, 91, 94, 95, 97, 98, 103, 104], "cosh": 28, "coul": 40, "could": [37, 42, 46, 48, 49, 65, 103, 104], "counfound": [18, 19, 63, 64, 71, 89, 97], "count": [45, 59, 60], "countour": [89, 94], "coupl": [41, 59, 60], "cournapeau": [99, 101], "cours": [41, 57, 59, 65, 88, 104], "cov": [15, 18], "covari": [4, 5, 6, 7, 9, 11, 12, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 35, 37, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 68, 69, 71, 72, 73, 75, 78, 79, 88, 89, 91, 101, 103], "cover": [39, 53, 64], "coverag": [57, 71, 103], "cp": [41, 42, 72], "cpu": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "cpu_count": [50, 60, 63], "cran": [42, 102, 103], "creat": [21, 37, 40, 42, 45, 46, 47, 48, 49, 50, 54, 55, 58, 60, 62, 63, 65, 72, 89, 91, 94, 97, 100], "create_synthetic_group_data": 62, "critic": [65, 104], "cross": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 20, 37, 38, 39, 41, 42, 47, 57, 59, 60, 65, 68, 70, 72, 78, 79, 84, 88, 92, 94, 103, 104], "cross_sectional_data": [6, 20, 51, 73], "crossfit": 57, "crosstab": 61, "crucial": [53, 104], "csail": [99, 101], "csv": 53, "cumul": 73, "current": [35, 39, 55, 75, 89, 97, 99, 104], "custom": [38, 39, 47, 65, 72], "custom_measur": 39, "cut": 62, "cv": [42, 59, 72, 74], "cv_glmnet": [40, 41, 42, 72, 88, 98, 101], "cvar": [3, 14, 70, 77, 103], "cvar_0": 50, "cvar_1": 50, "d": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 34, 35, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 104], "d0": [50, 63, 88], "d0_true": 63, "d0cdb0ea4795": 42, "d1": [50, 61, 63, 88, 98], "d10": [88, 98], "d1_true": 63, "d2": [61, 88, 98], "d21ee5775b5f": 42, "d3": [88, 98], "d4": [88, 98], "d5": [88, 98], "d5a0c70f1d98": 42, "d6": [88, 98], "d7": [88, 98], "d8": [88, 98], "d9": [88, 98], "d_": [24, 26, 40, 45, 52, 58, 73, 88, 98], "d_0": 73, "d_1": [61, 88, 98], "d_2": 61, "d_col": [4, 7, 37, 38, 40, 41, 42, 46, 48, 49, 54, 55, 58, 59, 60, 62, 64, 67, 68, 69, 72, 73, 74, 75, 101, 103, 104], "d_i": [21, 22, 23, 25, 27, 28, 29, 38, 45, 47, 50, 51, 61, 63, 66, 68, 73], "d_j": [45, 73, 88, 98], "d_k": [73, 88, 98], "d_l": 73, "d_w": 62, "da1440": 61, "dag": [65, 66, 104], "dark": [38, 47], "darkblu": 40, "darkr": 40, "dash": 45, "dat": 69, "data": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 34, 39, 52, 53, 57, 61, 67, 70, 71, 72, 74, 88, 93, 94, 98, 102, 103], "data_apo": 45, "data_cvar": 60, "data_dict": [48, 49, 54, 55, 56], "data_dml": 64, "data_dml_bas": [41, 48, 49, 54, 55, 59, 60, 62], "data_dml_base_iv": [41, 59, 60], "data_dml_flex": [41, 59], "data_dml_flex_iv": 41, "data_dml_iv_flex": 59, "data_dml_new": 62, "data_fram": 104, "data_lqt": 60, "data_pq": 60, "data_qt": 60, "data_transf": [40, 58, 59], "datafram": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 34, 35, 40, 43, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 73, 75, 88, 89, 91, 94, 101, 104], "dataset": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 38, 39, 45, 47, 48, 49, 51, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 88, 89, 94, 101, 104], "datatyp": 103, "db": [41, 59, 60, 64, 104], "dbl": [39, 40, 41, 42, 69, 88, 98, 101, 104], "dc13a11076b3": 42, "ddc9": 42, "de": [37, 46, 102], "deal": [37, 46], "debias": [16, 17, 26, 27, 40, 53, 58, 70, 72, 74, 99, 102, 103], "debt": [41, 59, 60], "decai": 66, "decid": [41, 59], "decis": [9, 37, 41, 46, 59, 60, 71, 102, 104], "decision_effect": 37, "decision_impact": [37, 46], "decisiontreeclassifi": [9, 35, 59], "decisiontreeregressor": 59, "declar": 104, "deep": [32, 33], "deeper": 9, "def": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 47, 50, 57, 58, 61, 62, 63, 65, 72, 75], "default": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 24, 26, 27, 28, 32, 33, 34, 35, 39, 40, 51, 54, 55, 57, 58, 62, 64, 65, 66, 67, 71, 72, 74, 88, 89, 90, 94, 98, 101, 104], "default_convert": 58, "defin": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 38, 41, 42, 45, 47, 48, 49, 50, 51, 53, 54, 55, 57, 59, 60, 62, 63, 64, 65, 71, 72, 73, 75, 78, 79, 89, 91, 94, 97], "definit": [28, 54, 55, 89, 90, 95], "defint": 89, "degre": [41, 48, 49, 58, 59, 71, 89, 91], "dekel": 102, "delete_origin": 42, "deliber": 61, "delta": [25, 39, 51, 65, 73], "delta_bench": 65, "delta_i": 39, "delta_j": 25, "delta_theta": [36, 45, 56, 64, 65, 89, 91], "delta_v": 65, "demand": [40, 58, 89, 91], "demir": [16, 17, 27, 40, 53, 58, 68, 74, 99, 102], "demo": 65, "demonstr": [38, 39, 40, 47, 58, 65, 69, 88, 98, 99, 101], "deni": 102, "denomin": [89, 90, 91, 95], "denot": [11, 40, 41, 51, 52, 58, 59, 65, 66, 71, 73, 75, 89, 91, 94, 95, 97], "dens_net_tfa": 41, "densiti": [10, 13, 14, 38, 45, 47], "dep": 43, "dep1": [42, 43, 69, 101], "dep2": [42, 43, 69, 101], "depend": [1, 3, 9, 10, 14, 21, 42, 48, 49, 51, 54, 55, 56, 57, 62, 67, 71, 72, 75, 82, 87, 89, 90, 91, 97, 101, 102], "deprec": [67, 74], "depreci": 103, "depth": [9, 35, 41, 42, 62, 67, 71, 72, 73, 74, 75, 88, 101, 104], "deriv": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 31, 88], "describ": [39, 40, 58, 59, 60, 65, 72, 74, 100, 103], "descript": [41, 43, 64, 72, 74, 89, 91], "design": [45, 102], "design_info": [48, 49], "design_matrix": [48, 49, 71], "desir": [19, 42, 62], "detail": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 30, 31, 38, 41, 42, 45, 47, 51, 52, 53, 60, 64, 65, 68, 69, 71, 72, 73, 75, 77, 81, 82, 83, 84, 87, 88, 89, 91, 97, 98, 99, 101, 103, 104], "determin": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 41, 50, 59, 60, 63, 64, 73, 88, 89, 97, 98], "determinist": [62, 71], "deutsch": 99, "dev": 103, "develop": [39, 40, 42, 58, 65, 73, 103], "deviat": [57, 89, 97], "dezeur": 102, "df": [4, 7, 37, 38, 40, 45, 46, 48, 49, 50, 52, 55, 58, 61, 63, 64, 65, 66, 68, 71, 73], "df_agg": 53, "df_apo": 45, "df_apo_ci": 45, "df_apos_ci": 45, "df_ate": 45, "df_bench": 65, "df_binari": 65, "df_bonu": [42, 69, 101], "df_cate": [48, 49], "df_ci": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34], "df_coef": 57, "df_cvar": 60, "df_lqte": 60, "df_ml_g0": 57, "df_ml_g1": 57, "df_ml_m": 57, "df_pa": [51, 66], "df_plot": 40, "df_pq": 60, "df_qte": 60, "df_result": 53, "df_sort": 45, "df_summari": 59, "df_wide": 58, "dfg": 99, "dgp": [20, 40, 50, 52, 53, 58, 61, 62, 63, 65, 66], "dgp1": 20, "dgp2": 20, "dgp3": 20, "dgp4": 20, "dgp5": 20, "dgp6": 20, "dgp_dict": 65, "dgp_tpye": 51, "dgp_type": [20, 51], "diagon": 65, "diagram": [37, 46, 73], "dichotom": [37, 46], "dict": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 32, 33, 35, 36, 48, 49, 53, 65, 72], "dict_kei": [89, 94], "dictionari": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 21, 24, 36, 48, 49, 54, 55, 64, 71, 72, 89, 94], "dictonari": [41, 59], "did": [4, 7, 38, 51, 52, 58, 70, 103, 104], "diff": 59, "differ": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 21, 37, 38, 40, 41, 42, 45, 46, 47, 50, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 70, 71, 72, 74, 78, 79, 100, 101, 102, 103, 104], "difficult": 65, "dillon": 102, "dim": 41, "dim_x": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 22, 23, 25, 26, 27, 28, 29, 38, 40, 42, 47, 57, 58, 68, 71, 72, 73, 89, 94], "dim_z": [11, 25, 73], "dimens": [21, 26, 40, 58, 62, 74], "dimension": [11, 12, 21, 23, 53, 71, 73, 74, 88, 89, 94, 98, 101, 102], "direct": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 47, 52, 66, 68, 104], "directli": [38, 39, 41, 45, 47, 57, 64, 68, 89, 94, 101, 104], "discret": [2, 24, 45, 58, 73, 103], "discretis": 60, "discuss": [22, 40, 41, 58, 59, 102, 103, 104], "disjoint": [40, 54, 55, 58], "displai": [40, 45, 58, 65, 71, 72, 89, 94], "displot": 59, "disproportion": [41, 59], "dist": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "distr": 72, "distribut": [38, 45, 47, 51, 57, 65, 68, 73, 89, 95, 100, 102, 103], "diverg": [38, 47, 68], "dmatrix": [48, 49, 71], "dml": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 30, 31, 37, 38, 42, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 88, 89, 94, 98, 100], "dml1": [70, 101, 103, 104], "dml2": [37, 40, 42, 43, 51, 58, 60, 70, 73, 75, 88, 101, 103, 104], "dml_apo_obj": 73, "dml_apos_obj": 73, "dml_base": 58, "dml_combin": 88, "dml_cv_predict": 103, "dml_cvar": [50, 60], "dml_cvar_0": 50, "dml_cvar_1": 50, "dml_cvar_obj": [3, 71], "dml_data": [39, 40, 43, 45, 51, 52, 56, 57, 58, 61, 64, 65, 66, 71, 72, 73, 88, 98, 104], "dml_data_bench": 65, "dml_data_bonu": [42, 101], "dml_data_df": 104, "dml_data_lasso": 43, "dml_data_sim": [42, 101], "dml_df": [40, 58], "dml_did": [51, 52], "dml_did_obj": [5, 6, 73], "dml_iivm_boost": [41, 59], "dml_iivm_forest": [41, 59], "dml_iivm_lasso": [41, 59], "dml_iivm_obj": [8, 46, 73], "dml_iivm_tre": [41, 59], "dml_irm": [48, 54, 57, 62], "dml_irm_at": 56, "dml_irm_boost": [41, 59], "dml_irm_forest": [41, 59], "dml_irm_gat": 56, "dml_irm_gatet": 56, "dml_irm_lasso": [41, 43, 59], "dml_irm_new": 62, "dml_irm_obj": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 64, 71, 72, 73], "dml_irm_obj_ext": 72, "dml_irm_rf": 43, "dml_irm_tre": [41, 59], "dml_long": 36, "dml_lpq_0": 63, "dml_lpq_1": 63, "dml_lpq_obj": [10, 71], "dml_lqte": [60, 63], "dml_obj": [39, 45, 64, 65], "dml_obj_bench": 65, "dml_pliv": [40, 58], "dml_pliv_obj": [11, 40, 58, 73], "dml_plr": [49, 55, 88, 98], "dml_plr_1": 88, "dml_plr_2": 88, "dml_plr_boost": [41, 59], "dml_plr_forest": [41, 59, 104], "dml_plr_lasso": [41, 43, 59], "dml_plr_no_split": 74, "dml_plr_obj": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 64, 67, 71, 72, 73, 74, 75, 88, 89, 91, 94], "dml_plr_obj_extern": 74, "dml_plr_obj_intern": 74, "dml_plr_rf": 43, "dml_plr_tree": [41, 59, 104], "dml_pq_0": [60, 63], "dml_pq_1": [60, 63], "dml_pq_obj": [13, 71], "dml_procedur": [43, 67, 101, 103, 104], "dml_qte": [60, 63], "dml_qte_obj": [14, 71], "dml_short": 36, "dml_ssm": [66, 73], "dml_tune": 103, "dmldummyclassifi": 72, "dmldummyregressor": 72, "dmlmt": 102, "dnorm": 38, "do": [39, 40, 41, 42, 57, 58, 59, 60, 61, 65, 71, 72, 89, 97, 101, 104], "doabl": 75, "doc": [37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 99, 103], "docu": 103, "document": [44, 48, 49, 52, 54, 55, 65, 99, 103], "doe": [2, 14, 39, 40, 41, 45, 58, 59, 61, 64, 65, 89, 97, 104], "doesn": [37, 46], "doi": [16, 17, 18, 19, 20, 22, 26, 27, 29, 39, 40, 42, 53, 58, 65, 68, 72, 74, 88, 98, 99, 101, 103], "domain": 62, "don": 39, "done": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 60, 72, 74, 89, 91], "dosag": 45, "dot": [15, 52, 62, 69, 71, 72, 73, 88, 98, 101], "doubl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 26, 27, 28, 29, 41, 53, 59, 61, 70, 72, 74, 75, 88, 89, 91, 98, 103], "double_ml_bonus_data": 43, "double_ml_data_from_data_fram": [38, 68, 69, 104], "double_ml_data_from_matrix": [39, 42, 69, 72, 88, 98, 101], "double_ml_irm": [43, 62], "doubleiivm": 99, "doubleml": [38, 40, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 89, 94, 98, 101, 102, 103], "doubleml2022python": 99, "doubleml2024r": 99, "doubleml_did_eval_linear": 39, "doubleml_did_eval_rf": 39, "doubleml_did_linear": 39, "doubleml_did_rf": 39, "doubleml_framework": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "doublemlapo": [45, 73, 75, 76, 103], "doublemlblp": [1, 9, 12, 48, 49, 71, 103], "doublemlclusterdata": 26, "doublemlcvar": [50, 71, 75, 77, 103], "doublemldata": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 25, 27, 28, 29, 37, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 88, 89, 94, 98, 103, 104], "doublemldid": [51, 52, 73, 75, 78, 103], "doublemldidc": [51, 73, 75, 79, 103], "doublemlframework": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 74, 88, 103], "doublemlframwork": 2, "doublemlidid": 73, "doublemlididc": 73, "doublemliivm": [37, 41, 46, 59, 72, 73, 74, 75, 80, 103], "doublemlirm": [1, 3, 5, 6, 8, 10, 11, 12, 13, 15, 39, 41, 43, 45, 48, 54, 56, 57, 59, 61, 62, 64, 65, 71, 72, 73, 74, 75, 81, 99, 103], "doublemllpq": [63, 71, 75, 82, 103], "doublemlpliv": [72, 73, 74, 75, 85, 99, 103], "doublemlplr": [1, 2, 3, 5, 6, 8, 9, 10, 11, 13, 14, 15, 38, 41, 42, 43, 47, 49, 55, 59, 61, 64, 67, 68, 71, 72, 73, 74, 75, 86, 88, 89, 94, 98, 99, 101, 103, 104], "doublemlpolicytre": [9, 71], "doublemlpq": [60, 63, 71, 75, 87, 103], "doublemlqt": [50, 60, 63, 71, 88, 103], "doublemlresampl": 57, "doublemlsmm": 103, "doublemlssm": [66, 73, 75, 83, 84], "doubli": [18, 19, 20, 39, 102], "down": 65, "download": [37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 100, 101], "downward": 65, "dpg_dict": 64, "dpi": [38, 47, 61], "dramat": 39, "draw": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 65, 74, 103], "draw_sample_split": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 57, 74], "drawn": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 21, 41, 59, 60, 62, 74], "drive": [38, 47, 68], "driven": [65, 104], "drop": [39, 58, 61, 69, 72, 75, 78, 79, 88, 98], "dt": [75, 79, 89, 92], "dt_bonu": 69, "dta": 39, "dtype": [43, 45, 51, 54, 55, 56, 57, 58, 59, 60, 64, 66, 69, 71, 101], "dualiti": 58, "dubourg": [99, 101], "duchesnai": [99, 101], "due": [38, 39, 47, 48, 49, 56, 64, 65, 68, 73, 89, 91, 103, 104], "duflo": [16, 17, 27, 40, 53, 58, 68, 74, 99, 102], "dummi": [1, 9, 12, 32, 33, 34, 65, 71, 72, 73, 103], "dummyclassifi": 32, "dummyregressor": 33, "duplic": 103, "durabl": [42, 43, 69, 101], "durat": 17, "dure": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 39, 40, 41, 42, 58, 59, 72, 74, 101, 103, 104], "dx": 22, "dynam": [39, 102], "e": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 24, 27, 29, 30, 31, 38, 39, 40, 41, 45, 47, 48, 49, 51, 53, 56, 57, 58, 59, 60, 61, 64, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104], "e20ea26": 42, "e401": [41, 59, 60, 64, 104], "e4016553": 104, "e45228": 61, "e57c": 42, "each": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 24, 40, 42, 45, 52, 54, 55, 57, 58, 60, 61, 62, 64, 65, 67, 69, 72, 74, 88, 89, 94, 98, 104], "earlier": 104, "earn": [41, 59, 60], "earner": [41, 59, 64], "easi": [42, 75], "easili": [42, 57, 60, 103], "ec973f": 61, "ecolor": [45, 52, 59, 61], "econ": 102, "econml": 102, "econom": [25, 26, 28, 29, 40, 53, 58, 61, 65, 74, 102], "econometr": [16, 17, 18, 19, 20, 27, 28, 39, 40, 53, 58, 68, 99, 102], "econometrica": [23, 40, 58, 61, 68, 102], "ecosystem": [99, 104], "ectj": [16, 17, 27, 40, 53, 58, 68, 99], "ed": 102, "edge_color": 47, "edgecolor": 47, "edit": [100, 102], "edu": [99, 101], "educ": [41, 59, 60, 64, 104], "ee97bda7": 42, "effect": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 24, 37, 38, 39, 40, 42, 45, 46, 47, 51, 52, 53, 56, 58, 62, 66, 68, 70, 72, 73, 74, 75, 81, 88, 89, 91, 101, 102, 103, 104], "effici": 102, "effort": 75, "eight": [40, 58], "either": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 21, 42, 52, 53, 62, 71, 72, 104], "eleanor": 102, "element": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 40, 48, 49, 50, 51, 57, 58, 60, 63, 64, 66, 75, 76, 78, 79, 89, 94, 96, 97, 103], "element_text": [40, 41], "elementari": 102, "elif": [54, 55, 62], "elig": [60, 64, 104], "eligibl": [41, 59, 64], "ell": [38, 40, 47, 53, 58, 68, 75, 85, 86, 101], "ell_0": [8, 11, 12, 38, 47, 53, 68, 73], "ell_2": 57, "els": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 34, 39, 40, 41, 52, 54, 55, 58, 62, 65], "em": 102, "emphas": [40, 58], "empir": [30, 31, 38, 40, 47, 58, 61, 65, 68, 74, 75, 88, 98], "emploi": [40, 53, 58, 65, 75, 80], "employ": [41, 59, 60], "employe": 104, "empti": 58, "emul": [89, 91], "enabl": [45, 62, 64, 71, 89, 91, 103], "encapsul": [32, 33], "encod": 61, "end": [22, 25, 26, 38, 39, 40, 41, 47, 50, 52, 53, 57, 58, 59, 61, 62, 63, 66, 67, 69, 72, 74, 88, 98, 101, 104], "endogen": [41, 59, 60, 104], "enet_coordinate_descent_gram": 58, "engin": [42, 102], "enrol": [41, 59, 60], "ensembl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 43, 45, 47, 48, 49, 54, 55, 56, 57, 59, 62, 64, 65, 67, 71, 72, 73, 74, 75, 88, 89, 94, 101, 104], "ensemble_learner_pipelin": 72, "ensemble_pipe_classif": 42, "ensemble_pipe_regr": 42, "ensur": [40, 55, 58, 62], "entir": [38, 41, 47, 59, 68, 89, 91], "entri": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 38, 40, 43, 45, 47, 51, 56, 58, 59, 60, 64, 66, 68, 69, 72, 99, 101, 103], "enumer": [45, 50, 52, 54, 55, 57, 58, 59, 60, 63, 67, 72, 74], "env": [58, 100], "environ": 100, "ep": 61, "epsilon": [41, 50, 51, 52, 59, 63, 71, 73], "epsilon_": [40, 52, 58], "epsilon_i": [21, 50, 61, 62, 63], "epsilon_sampl": 62, "epsilon_tru": [50, 63], "eqnarrai": 41, "equal": [1, 9, 40, 58, 61, 66, 71, 72, 89, 95], "equat": [40, 41, 58, 59, 65, 67, 88, 98, 104], "equilibrium": [40, 58], "equival": [53, 74], "err": [3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 43, 45, 46, 48, 49, 50, 51, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 71, 72, 73, 74, 75, 88, 101, 104], "error": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 37, 38, 39, 41, 42, 47, 52, 53, 54, 55, 57, 59, 65, 68, 72, 73, 74, 75, 88, 89, 94, 98, 101, 103, 104], "errorbar": [45, 52, 54, 55, 59, 61], "erstellt": [40, 41, 42], "especi": 57, "essenti": 65, "est_method": 39, "esther": [74, 102], "estim": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 30, 31, 32, 33, 34, 35, 38, 39, 40, 42, 45, 47, 48, 49, 50, 52, 54, 55, 57, 58, 62, 67, 68, 70, 71, 72, 73, 77, 78, 79, 82, 84, 87, 89, 91, 94, 98, 99, 102, 103], "estimatior": [4, 7], "et": [16, 17, 21, 23, 26, 27, 38, 40, 41, 42, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 60, 63, 64, 68, 73, 74, 75, 77, 82, 87, 88, 89, 91, 97, 98, 99, 101, 103], "eta": [30, 31, 38, 40, 41, 52, 58, 59, 63, 67, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 97, 98, 101, 104], "eta1": 61, "eta2": 61, "eta_": [88, 89, 97, 98], "eta_0": [67, 75, 88], "eta_i": [21, 52, 62, 63], "eta_sampl": 62, "eta_tru": 63, "etc": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 40, 57, 58, 103], "ev": [38, 47, 68], "eval": [42, 72], "eval_metr": [41, 59, 104], "eval_pr": 39, "eval_predict": 39, "evalu": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 42, 48, 49, 50, 52, 56, 60, 63, 64, 67, 102, 103], "evaluate_learn": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 57, 72, 103], "evalut": 72, "even": [41, 42, 59, 61, 72, 104], "eventu": [40, 58], "everi": [40, 58], "everyth": 99, "evid": 56, "exact": 65, "exactli": 65, "exampl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 21, 37, 38, 41, 42, 43, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 66, 67, 68, 71, 72, 73, 74, 75, 88, 89, 94, 98, 99, 101, 103, 104], "example_attgt": 39, "example_attgt_dml_eval_linear": 39, "example_attgt_dml_eval_rf": 39, "example_attgt_dml_linear": 39, "example_attgt_dml_rf": 39, "except": [53, 65, 103], "excess": 57, "exclud": 36, "exclus": [1, 9, 12, 54, 55, 71], "execut": [42, 104], "exemplarili": 101, "exemplatori": 62, "exhaust": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 72], "exhibit": [40, 58], "exist": [73, 89, 97], "exogen": [41, 59, 60, 104], "exp": [18, 19, 20, 21, 23, 24, 27, 38, 47, 48, 49, 52, 54, 55, 61, 62, 68], "expect": [18, 19, 39, 45, 51, 56, 57, 65, 66, 71, 74, 88, 89, 90, 101], "experi": [17, 22, 23, 38, 41, 47, 59, 65, 68, 69, 74, 101, 102], "experiment": [5, 6, 20, 75, 78, 79, 89, 92, 93], "expertis": 65, "explain": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 64, 89, 91, 96, 97], "explan": [40, 51, 58, 64, 89, 96, 99, 104], "explanatori": [65, 88, 98], "explicit": 65, "explicitli": [56, 104], "exploit": [38, 47, 68, 104], "exponenti": [88, 98], "export": 103, "exposur": 52, "express": [40, 53, 89, 97], "extend": [65, 72, 99, 103], "extendend": [89, 97], "extens": [72, 75, 99, 102, 103], "extent": 53, "extern": [38, 47, 70, 89, 91, 103], "external_predict": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 47, 72], "externalptr": 41, "extra": 42, "extract": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "extralearn": 42, "extrem": [41, 59], "ey": 53, "f": [41, 42, 45, 47, 50, 51, 52, 53, 57, 58, 59, 60, 62, 63, 64, 65, 66, 72, 89, 97, 99, 101], "f00584a57972": 42, "f1718fdeb9b0": 42, "f2e7": 42, "f3d24993": 42, "f6ebc": 61, "f_": [18, 20, 52, 71], "f_loc": [50, 63], "f_p": 52, "f_scale": [50, 63], "face_color": 47, "facet_wrap": 41, "fact": [41, 59, 60], "factor": [38, 39, 40, 41, 42, 47, 57, 68, 72, 104], "faculti": 102, "fail": 103, "fair": 57, "fake": [37, 46], "fals": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 24, 34, 38, 41, 42, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 65, 66, 69, 72, 73, 74, 75, 78, 79, 88, 89, 92, 93, 98, 104], "famili": [41, 59, 72], "fanci": 39, "far": [41, 59], "farbmach": 22, "fast": [57, 62, 72], "faster": 53, "fb5c25fa": 42, "fc9e": 42, "fd8a": 42, "featur": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 35, 39, 43, 56, 57, 59, 62, 71, 72], "featureless": [42, 72], "features_bas": [41, 59, 60, 64], "features_flex": 41, "featureunion": 42, "februari": 65, "femal": [42, 43, 69, 101], "fern\u00e1ndez": [23, 74, 102], "fetch": [41, 58, 59, 60, 69], "fetch_401k": [41, 59, 60, 64, 104], "fetch_bonu": [42, 43, 69, 101], "few": [41, 59, 60], "ff7f0e": 52, "field": [40, 58, 72, 104], "fifteenth": 102, "fifth": 40, "fig": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 48, 49, 50, 52, 53, 57, 60, 61, 63, 65], "fig_al": 47, "fig_dml": 47, "fig_non_orth": 47, "fig_orth_nosplit": 47, "fig_po_al": 47, "fig_po_dml": 47, "fig_po_nosplit": 47, "figsiz": [43, 45, 48, 49, 50, 52, 54, 55, 57, 58, 59, 60, 61, 63], "figur": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 27, 38, 40, 43, 45, 47, 48, 49, 50, 52, 53, 54, 55, 58, 59, 60, 63, 65, 68], "figure_format": 61, "file": [16, 17, 53, 61, 102, 103], "filenam": 38, "fill": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 40, 41, 51, 57, 59, 66], "fill_between": [48, 49, 50, 60, 63], "fill_valu": 57, "filter": 42, "filterwarn": 47, "final": [38, 42, 45, 47, 48, 49, 50, 52, 54, 55, 56, 60, 63, 66, 68, 73, 104], "financi": [16, 64, 104], "find": [41, 52, 59, 65, 71, 72, 104], "finish": 42, "finit": [38, 41], "firm": [40, 58, 64], "firmid": 58, "first": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 26, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 62, 63, 65, 66, 68, 71, 74, 88, 89, 94, 98, 100, 101, 103, 104], "fit": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 78, 79, 84, 88, 89, 91, 94, 98, 99, 103, 104], "fit_arg": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "fit_transform": [58, 59], "five": 58, "fix": [52, 57, 59, 103], "flag": [20, 74, 100], "flake8": 103, "flatten": 61, "flexibl": [37, 39, 41, 42, 46, 51, 59, 99, 104], "flexibli": [41, 59, 64], "float": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 34], "float32": [60, 64], "float64": [43, 45, 51, 55, 56, 58, 59, 64, 66, 69, 72, 101], "floor": 42, "floor_divid": 58, "flt": 42, "flush": 38, "fmt": [45, 52, 54, 55, 59, 61], "focu": [40, 41, 58, 59, 60, 65, 71, 73, 104], "focus": [60, 64, 65, 104], "fold": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 40, 41, 42, 51, 57, 58, 59, 60, 64, 66, 67, 70, 72, 73, 75, 78, 79, 88, 101, 104], "follow": [18, 19, 20, 21, 24, 38, 40, 41, 47, 48, 49, 50, 51, 52, 54, 55, 58, 59, 60, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 101, 104], "font_scal": [58, 59, 60], "fontsiz": [50, 60, 63], "force_all_x_finit": [4, 7], "forest": [22, 37, 38, 39, 41, 42, 46, 47, 51, 56, 57, 59, 64, 68, 72, 101, 104], "forest_summari": 59, "forg": [100, 102, 103], "form": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 21, 34, 41, 48, 49, 50, 51, 52, 54, 55, 56, 57, 59, 63, 64, 66, 71, 73, 75, 76, 81, 89, 90, 91, 94, 95, 96, 97, 100, 101], "format": [47, 56, 89, 94], "formula": [40, 41, 58, 59, 65, 103], "formula_flex": 41, "forschungsgemeinschaft": 99, "forthcom": [65, 102], "forum": 103, "forward": [9, 35], "found": [48, 49, 53, 54, 55, 68, 69, 72, 73, 101], "foundat": [99, 102], "four": [41, 57, 59, 103], "fourth": [40, 58], "frac": [8, 18, 19, 20, 22, 23, 25, 27, 28, 29, 31, 38, 40, 42, 47, 52, 53, 56, 58, 61, 67, 68, 71, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98], "fraction": 42, "frame": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 37, 38, 40, 41, 43, 45, 48, 49, 51, 54, 55, 56, 58, 59, 60, 61, 62, 64, 66, 68, 69, 101, 104], "framework": [31, 38, 40, 42, 47, 57, 58, 61, 65, 68, 72, 88, 98, 99, 101, 103, 104], "freez": 100, "fribourg": 102, "friendli": 45, "from": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 34, 37, 38, 40, 41, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 88, 89, 94, 98, 101, 103, 104], "from_arrai": [4, 7, 15, 47, 50, 51, 52, 63, 68, 69, 72, 88, 98, 101], "from_product": 58, "front": 45, "fr\u00e9chet": [89, 97], "fsize": [41, 59, 60, 64, 104], "full": [45, 47, 50, 51, 52, 54, 55, 57, 59, 60, 63, 66, 68], "fulli": [9, 41, 44, 59, 73], "fun": 38, "func": 39, "function": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 27, 28, 30, 31, 37, 38, 41, 42, 46, 47, 48, 49, 50, 51, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 93, 97, 98, 99, 102, 103, 104], "fund": [41, 59, 60, 99], "further": [18, 19, 20, 21, 24, 26, 40, 42, 45, 48, 49, 50, 51, 52, 56, 57, 58, 60, 62, 63, 64, 65, 66, 72, 73, 75, 77, 82, 83, 84, 87, 88, 89, 91, 94, 96, 97, 98, 99, 101, 103, 104], "furthermor": [47, 75, 76, 81], "futurewarn": 55, "g": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 38, 39, 42, 43, 47, 48, 49, 51, 52, 53, 56, 57, 60, 61, 62, 64, 66, 68, 71, 72, 73, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 104], "g_": [45, 75, 77, 78, 79, 82, 87, 88, 98], "g_0": [1, 5, 6, 8, 9, 11, 12, 13, 27, 28, 38, 40, 41, 47, 57, 58, 59, 68, 71, 72, 73, 75, 76, 83, 84, 89, 90, 95, 97, 101, 104], "g_1": 57, "g_all": [38, 41], "g_all_po": 38, "g_ci": 41, "g_d": [75, 77, 87], "g_dml": 38, "g_dml_po": 38, "g_hat": [11, 12, 38, 47, 75], "g_hat0": [8, 9], "g_hat1": [8, 9], "g_k": 71, "g_nonorth": 38, "g_nosplit": 38, "g_nosplit_po": 38, "g_x": 52, "gain": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 36, 57, 89, 91, 95, 103], "gain_statist": 103, "galleri": [68, 71, 72, 73, 99, 103], "gamma": [25, 28, 29, 40, 58, 61, 62, 65, 75, 77, 82], "gamma_0": [21, 62, 66, 75, 77, 82], "gamma_a": [18, 19, 65], "gamma_bench": 65, "gamma_v": 65, "gap": [58, 65], "gapo": 1, "gate": [1, 9, 12, 34, 61, 62, 70, 103], "gate_obj": 71, "gatet": 71, "gaussian": [10, 13, 14, 38, 47, 68, 71, 72, 88, 98, 102], "ge": [18, 20, 21, 56, 62, 71], "geer": 102, "gelbach": [40, 58], "gener": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 37, 39, 40, 41, 42, 43, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 81, 88, 90, 91, 92, 93, 95, 97, 98, 102, 103, 104], "generate_treat": 63, "geom_bar": 41, "geom_dens": 41, "geom_errorbar": 41, "geom_funct": 38, "geom_histogram": 38, "geom_hlin": 41, "geom_point": 41, "geom_til": 40, "geom_vlin": 38, "german": 99, "get": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 32, 33, 42, 45, 57, 61, 64, 65, 89, 91, 99, 100], "get_dummi": 61, "get_feature_names_out": [58, 59], "get_legend_handles_label": 45, "get_logg": [38, 39, 40, 41, 42, 67, 72, 73, 74, 75, 88, 98, 101], "get_metadata_rout": [32, 33], "get_param": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 32, 33, 72], "ggdid": 39, "ggplot": [38, 40, 41], "ggplot2": [38, 40, 41], "ggsave": 38, "ggtitl": 41, "gh": 103, "git": 100, "github": [39, 41, 53, 59, 61, 99, 102, 103], "githubusercont": 53, "give": [41, 59], "given": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 23, 27, 28, 31, 38, 40, 45, 47, 52, 54, 55, 58, 60, 61, 65, 66, 68, 71, 75, 76, 88, 89, 90, 94, 95, 96, 97, 98, 101, 103], "glmnet": [41, 42, 72, 103], "global": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 72], "glrn": 42, "glrn_lasso": 42, "gname": 39, "go": [48, 49, 53, 65], "goal": [45, 54, 55], "goldman": 102, "good": [53, 89, 91, 104], "gradient": [41, 59], "gradientboostingclassifi": 57, "gradientboostingregressor": 57, "gradual": 65, "gramfort": [99, 101], "graph": [42, 66, 104], "graph_ensemble_classif": 42, "graph_ensemble_regr": 42, "graph_object": [48, 49, 53, 65], "graphlearn": [42, 72], "grasp": [45, 89, 91], "great": [52, 104], "greater": 104, "green": [38, 48, 49, 50, 63], "greg": 102, "grei": [41, 45], "grenand": 102, "grey50": 40, "grid": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 42, 45, 48, 49, 50, 53, 60, 61, 63, 65, 72, 89, 94], "grid_arrai": [48, 49], "grid_bound": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 65], "grid_search": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 42, 72], "grid_siz": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 48, 49], "gridextra": 40, "gridsearchcv": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 72], "grisel": [99, 101], "grob": 40, "group": [1, 9, 12, 37, 39, 45, 46, 56, 60, 61, 62, 65, 70], "group_0": 71, "group_1": [54, 55, 71], "group_2": [54, 55, 71], "group_3": [54, 55], "group_effect": 62, "group_ind": 56, "group_treat": 56, "groupbi": [53, 59], "gruber": 22, "gt": [37, 39, 40, 41, 42, 43, 45, 46, 48, 49, 50, 51, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 101], "guarante": [40, 58], "guber": 22, "guess": [64, 89, 91], "guid": [30, 31, 32, 33, 38, 39, 40, 42, 45, 47, 52, 56, 58, 64, 72, 99, 101, 103], "guidelin": 103, "gunion": [42, 72], "gxidclusterperiodytreat": 39, "h": [18, 19, 20, 22, 26, 39, 40, 58, 102], "h_0": [45, 56, 64, 65, 89, 94, 104], "ha": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 20, 34, 35, 38, 39, 40, 41, 47, 53, 57, 58, 59, 60, 61, 64, 65, 71, 72, 73, 89, 90, 91, 94, 95, 96, 97, 104], "half": [38, 47, 61, 68, 74], "hand": [57, 61, 104], "handbook": 61, "handl": [39, 45, 57, 72, 103], "hansen": [16, 17, 23, 25, 27, 40, 53, 58, 68, 99, 102], "happend": 57, "hard": [64, 89, 91], "harold": 102, "hat": [38, 40, 47, 53, 56, 58, 61, 67, 68, 71, 74, 75, 88, 89, 91, 94, 96, 98], "have": [1, 2, 9, 12, 14, 21, 24, 34, 35, 37, 38, 39, 40, 41, 42, 45, 46, 48, 49, 51, 52, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 69, 71, 72, 88, 89, 90, 91, 97, 100, 101, 103, 104], "hazlett": [65, 89, 91], "hc": [39, 102], "hdm": [40, 58], "he": 66, "head": [39, 40, 42, 43, 48, 49, 54, 55, 58, 59, 61, 65, 69, 71, 101], "heat": [40, 58], "heatmap": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 58, 65], "heavili": 57, "hei": 102, "height": [38, 40, 53], "help": [39, 41, 50, 57, 60, 62, 65, 74, 104], "helper": 103, "henc": [39, 41, 42, 59, 65, 72, 75, 104], "here": [10, 13, 14, 39, 40, 41, 42, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 62, 63, 65, 66, 69, 72, 100], "heterogen": [9, 21, 41, 56, 59, 60, 62, 70, 73, 74, 102, 103, 104], "heteroskedast": [54, 55], "heurist": [38, 47, 68], "high": [11, 12, 23, 41, 52, 53, 59, 60, 67, 73, 88, 98, 99, 101, 102], "higher": [39, 41, 53, 59, 60, 61, 103, 104], "highli": [41, 59, 99], "highlight": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 51, 65, 103], "highlightcolor": [48, 49], "hispan": 43, "hist": 45, "hist_e401": 41, "hist_p401": 41, "histogram": 45, "histplot": 47, "hjust": 41, "hline": [69, 88, 98, 101, 104], "hold": [29, 40, 41, 58, 59, 66, 71, 72], "holdout": [72, 74], "holm": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "home": [41, 59], "homogen": 73, "hopefulli": 60, "horizont": [40, 52, 58], "hostedtoolcach": [59, 65], "hot": 61, "hotstart_backward": [42, 72], "hotstart_forward": [42, 72], "household": [41, 59, 60, 64], "how": [32, 33, 37, 39, 40, 41, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 68, 72, 99, 100], "howev": [38, 41, 47, 59, 65, 66, 68, 104], "hown": [41, 59, 60, 64, 104], "hpwt": [40, 58], "hpwt0": 40, "hpwtairmpdspac": 40, "href": 99, "hspace": 57, "hstack": [15, 52], "html": [42, 55, 99, 101, 103], "http": [22, 28, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 72, 99, 100, 101, 103], "huber": [29, 66, 73, 75, 83, 84, 102], "hue": 59, "huge": 57, "hugo": 102, "husd": [42, 43, 69, 101], "hyperparamet": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 42, 43, 53, 57, 59, 70, 101], "hypothes": [88, 98, 102], "hypothesi": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 59, 64, 89, 94, 102], "hypothet": 65, "i": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 84, 87, 88, 89, 90, 91, 94, 95, 97, 98, 99, 100, 101, 103, 104], "i0": [51, 52, 73], "i03": 99, "i1": [51, 73], "i_": [25, 58, 62], "i_1": [40, 58], "i_2": [40, 58], "i_3": [40, 58], "i_4": 52, "i_est": 47, "i_fold": 40, "i_k": [40, 58, 67, 74, 88, 98], "i_learn": 57, "i_level": 45, "i_rep": [38, 47, 51, 57, 66, 68], "i_split": 58, "i_train": 47, "icp": 102, "id": [39, 40, 42, 58], "id_var": 58, "idea": [41, 42, 59, 60, 65, 72, 89, 91, 104], "ident": [18, 19, 20, 21, 24, 25, 35, 42, 45, 72, 89, 94], "identfi": 65, "identif": [73, 104], "identifi": [40, 41, 51, 56, 58, 59, 60, 65, 71, 73, 89, 97, 103], "identifii": 71, "idnam": 39, "idx_tau": [50, 60, 63], "idx_treat": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 89, 94], "ieee": 102, "ifels": 39, "ignor": 47, "ii": [40, 58], "iid": 73, "iivm": [8, 22, 30, 31, 60, 67, 71, 80, 99, 103], "iivm_summari": 59, "iivmglmnet": 41, "iivmrang": 41, "iivmrpart": 41, "iivmxgboost11861": 41, "ij": [26, 40, 45, 58, 66], "ilia": 102, "illustr": [38, 40, 41, 42, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 62, 63, 64, 65, 66, 68, 72, 104], "iloc": [45, 51, 52, 57, 58, 61], "immedi": 100, "immun": [74, 102], "impact": [37, 46, 57, 61, 64], "implement": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 30, 31, 38, 39, 40, 41, 42, 47, 51, 53, 57, 58, 59, 61, 64, 65, 66, 68, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104], "impli": [18, 19, 40, 41, 58, 59, 60, 71, 89, 90, 92, 93, 95], "implment": 52, "import": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 100, 101, 103, 104], "importlib": 53, "impos": 65, "improv": [51, 57, 62, 103], "in_sample_norm": [5, 6, 51, 75, 78, 79, 89, 92, 93], "inbuild": 57, "inbuilt": 57, "inc": [41, 59, 60, 64, 104], "includ": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 36, 39, 41, 45, 52, 54, 55, 59, 64, 65, 71, 73, 88, 89, 90, 94, 95, 97, 98, 103, 104], "include_bia": [58, 59], "include_scenario": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 65], "incom": [41, 59, 60, 62, 64, 104], "incorpor": [42, 64, 89, 94], "increas": [56, 57, 58, 65, 104], "increment": 103, "ind": 59, "independ": [5, 6, 18, 19, 20, 21, 40, 42, 52, 56, 58, 62, 73, 75, 78, 79, 103], "index": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 40, 43, 47, 52, 53, 54, 55, 58, 59, 61, 62, 68, 69, 74, 75, 78, 79, 101], "index_col": 53, "india": [74, 102], "indic": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 24, 29, 34, 40, 41, 52, 56, 58, 59, 60, 65, 66, 67, 69, 71, 73, 74], "individu": [1, 9, 39, 41, 45, 52, 54, 55, 56, 59, 60, 64, 71, 104], "individual_df": 52, "induc": [70, 74], "industri": [40, 58], "inf": [4, 7, 39], "inf_model": 75, "infer": [23, 25, 37, 38, 40, 46, 47, 53, 58, 68, 70, 74, 99, 101, 102, 103], "inferenti": 104, "infinit": [4, 7, 103], "info": [37, 42, 43, 45, 51, 56, 58, 59, 60, 64, 66, 69, 101, 103, 104], "inform": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 33, 37, 42, 46, 48, 49, 57, 64, 65, 89, 91, 102], "infti": [38, 47, 68], "inher": 65, "inherit": [61, 103], "initi": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 41, 42, 50, 51, 59, 60, 63, 64, 65, 66, 69, 71, 72, 74, 101, 103, 104], "inlin": [43, 61], "inlinebackend": 61, "inner": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 72], "innermost": 72, "input": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 42, 64, 67, 88, 89, 91, 94, 98], "insight": [53, 65], "insignific": 64, "inspect": 101, "inspir": [18, 22, 23, 29, 65], "instal": [41, 103], "install_github": 100, "instanc": [41, 42, 59, 72], "instanti": [40, 41, 58, 59, 72, 74], "instead": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 37, 39, 41, 45, 46, 55, 56, 59, 60, 71, 72, 89, 92, 93, 95, 96, 103], "instruct": 103, "instrument": [4, 7, 8, 11, 16, 22, 25, 40, 41, 42, 43, 45, 51, 56, 58, 59, 60, 63, 64, 66, 69, 72, 73, 75, 82, 88, 101, 104], "instrument_effect": 37, "instrument_impact": 46, "int": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 21, 24, 34, 35, 39, 40, 41, 46, 50, 51, 62, 63, 65, 66], "int64": [43, 57, 58, 69, 101], "int8": [59, 60, 64], "integ": [20, 42, 72], "integr": [65, 89, 97, 103], "intend": [42, 65, 104], "intent": 104, "inter": 72, "interact": [1, 2, 8, 9, 18, 22, 23, 24, 45, 65, 70, 72, 90, 95, 99, 103, 104], "interchang": 88, "interest": [8, 9, 11, 12, 18, 19, 38, 41, 47, 51, 53, 59, 60, 66, 68, 71, 73, 75, 88, 98, 101, 104], "interfac": [39, 41, 42, 69, 72, 74, 101], "intermedi": [55, 65], "intern": [39, 41, 42, 45, 60, 72, 102], "internet": [41, 59, 60], "interpret": [54, 55, 65, 71, 89, 90, 91, 95, 96, 97, 100, 104], "intersect": [65, 89, 94, 103], "interv": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 39, 40, 41, 45, 48, 49, 50, 51, 54, 55, 58, 60, 63, 64, 66, 70, 71, 74, 75, 89, 94, 101, 102, 104], "introduc": [38, 47, 68, 69, 88, 98, 103, 104], "introduct": [38, 40, 42, 47, 58, 60, 64, 72, 73, 89, 91], "introductori": [39, 65], "intrument": 66, "intuit": 65, "inuidur1": [42, 43, 69, 101], "inuidur1femaleblackothracedep1dep2q2q3q4q5q6agelt35agegt54durablelusdhusdtg": [42, 69, 101], "inuidur2": [43, 69, 101], "inv_sigmoid": 61, "invalid": [38, 47, 68], "invari": 73, "invers": [1, 3, 8, 9, 10, 13, 14, 15, 66, 89, 90, 95], "invert_yaxi": 58, "investig": [53, 65], "involv": [71, 72, 75, 104], "io": [61, 103], "ipw_norm": 103, "ipykernel_42637": 55, "ipynb": [37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66], "ira": [41, 59, 60], "irm": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 23, 24, 30, 31, 34, 35, 57, 65, 67, 70, 72, 81, 90, 95, 99, 103, 104], "irm_summari": 59, "irmglmnet": 41, "irmrang": 41, "irmrpart": 41, "irmxgboost8047": 41, "irrespect": 65, "is_classifi": [1, 5, 6, 8, 9, 12], "is_gat": [1, 9, 12, 34], "isnan": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 57, 72], "isoton": 65, "isotonicregress": 65, "issn": 53, "issu": [59, 65, 99, 102, 103], "ite": [45, 54, 55, 56], "item": [8, 59, 67, 72, 74], "iter": [37, 51, 58, 66, 72, 88, 98, 104], "itertool": 53, "its": [32, 33, 65, 67, 71, 72, 73, 74, 75, 88], "iv": [8, 11, 12, 22, 25, 26, 38, 40, 47, 58, 68, 69, 85, 86, 89, 96, 99, 103, 104], "iv_2": 37, "iv_var": [40, 58], "iv\u00e1n": [74, 102], "j": [16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 38, 39, 40, 42, 45, 47, 53, 58, 61, 66, 68, 72, 73, 88, 98, 99, 101], "j_": [40, 58], "j_0": 88, "j_1": [40, 58], "j_2": [40, 58], "j_3": [40, 58], "j_k": [40, 58], "jame": 102, "janni": [41, 59], "javanmard": 102, "jbe": [40, 58], "jeconom": [18, 19, 20, 39], "jerzi": 102, "jia": 65, "jk": 73, "jmlr": [42, 99, 101, 103], "job": [41, 59, 60], "joint": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 45, 48, 49, 50, 54, 55, 60, 63, 73, 88, 103, 104], "jointli": [63, 71], "joss": [42, 72, 99, 101], "journal": [16, 17, 18, 19, 20, 26, 27, 29, 39, 40, 42, 53, 58, 61, 65, 68, 72, 99, 101, 102, 103], "jss": 99, "jump": 62, "jun": [39, 102], "jupyt": [37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66], "juraj": 102, "just": [39, 42, 45, 50, 51, 52, 54, 55, 56, 62, 63, 75, 78, 79, 89, 91], "justif": [74, 89, 91], "k": [16, 19, 20, 22, 23, 25, 26, 27, 29, 38, 40, 42, 47, 57, 58, 67, 68, 70, 71, 88, 98, 104], "kaggl": [41, 59], "kallu": [50, 60, 63, 64, 75, 77, 82, 87, 102], "kato": [26, 40, 58, 88, 98, 102], "kb": [45, 51, 56, 58, 59, 60, 64, 69, 101], "kde": [10, 13, 14, 59], "kdeplot": [51, 57, 66], "kdeunivari": [10, 13, 14], "kecsk\u00e9sov\u00e1": 103, "keep": [39, 55, 65, 104], "kei": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 35, 40, 41, 48, 49, 54, 55, 58, 59, 60, 65, 72, 75, 89, 94, 103], "keith": 102, "kengo": 102, "kernel": [10, 13, 14], "keyword": [20, 26, 27, 28], "kf": 74, "kfold": [58, 74], "kind": [37, 46, 59], "kj": [19, 20, 22, 23, 25, 26, 27, 29, 38, 40, 47, 58, 68], "klaassen": [22, 65, 99, 102], "klaa\u00dfen": 22, "knau": 102, "know": [51, 62], "knowledg": [37, 46, 57, 61, 62], "known": [56, 57, 65, 72], "kohei": 102, "kotthof": 42, "kotthoff": [42, 72, 99, 101], "krueger": 61, "kueck": [41, 59], "kurz": [99, 102, 103], "kwarg": [18, 19, 20, 24, 26, 27, 28, 32], "l": [40, 42, 43, 48, 49, 58, 65, 66, 72, 89, 96, 99, 101], "l1": [59, 66, 73], "l_hat": [11, 12, 38, 47, 75], "label": [45, 47, 48, 49, 50, 52, 54, 55, 60, 61, 63], "labor": 61, "laffer": 102, "laff\u00e9r": [29, 66, 73, 75, 83, 84], "lal": [61, 103], "lambda": [40, 41, 42, 59, 61, 62, 72, 75, 79, 88, 98, 101], "lambda_": 53, "lambda_0": [75, 79], "lambda_t": 20, "land": 62, "lang": [42, 72, 99, 101], "langl": [21, 62], "lappli": 74, "larg": [38, 47, 56, 57, 61, 65], "larger": [9, 39, 65, 89, 94], "largest": 57, "largli": 57, "lasso": [40, 41, 42, 59, 66, 72, 101, 102], "lasso_class": [41, 59], "lasso_pip": [42, 72], "lasso_summari": 59, "lassocv": [15, 53, 58, 59, 66, 72, 73, 88, 98, 101], "last": [20, 42, 100], "late": [8, 37, 41, 59, 73, 75, 80], "latent": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 64, 89, 96, 97], "later": [41, 42, 65, 72, 104], "layout": 53, "lbrace": [8, 9, 22, 23, 29, 40, 58, 67, 73, 74, 75, 76, 88, 89, 90, 98], "ldot": [11, 12, 40, 58, 66, 67, 73, 74, 88, 98, 101], "le": [20, 51, 62, 71, 73, 75, 82, 87], "lead": [39, 65], "leadsto": 88, "lear": [42, 72, 99, 101], "learn": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 26, 27, 28, 29, 37, 41, 42, 43, 45, 46, 50, 53, 57, 59, 60, 61, 63, 65, 69, 70, 72, 74, 75, 88, 89, 91, 98, 103, 104], "learner": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 38, 39, 40, 41, 47, 48, 49, 51, 53, 58, 59, 60, 64, 65, 66, 67, 68, 70, 73, 74, 75, 88, 89, 94, 98, 103, 104], "learner_class": [15, 103], "learner_cv": 42, "learner_forest_classif": 42, "learner_forest_regr": 42, "learner_l": 64, "learner_lasso": 42, "learner_list": 57, "learner_m": 64, "learner_nam": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 72], "learner_param_v": 42, "learner_rf": 88, "learnerclassif": 42, "learnerregr": 42, "learnerregrcvglmnet": 42, "learnerregrrang": [42, 72], "learning_r": [47, 50, 60, 63, 65, 68], "least": [37, 41, 46, 59, 60, 64, 74], "leav": [65, 66], "left": [22, 23, 25, 26, 29, 38, 40, 45, 47, 57, 58, 59, 60, 61, 63, 68, 75, 78, 79, 88, 89, 90, 92, 93, 95, 98], "legend": [41, 45, 47, 48, 49, 50, 52, 54, 55, 57, 60, 61, 63], "len": [45, 50, 57, 58, 60, 63], "length": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 42, 51, 72], "leq": [40, 58], "less": [39, 41, 59, 60, 65], "lester": 102, "let": [18, 19, 20, 24, 38, 39, 41, 42, 45, 47, 50, 51, 54, 55, 57, 59, 60, 63, 65, 66, 67, 68, 72, 73, 89, 91, 97, 104], "level": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 24, 34, 40, 41, 45, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 72, 75, 76, 89, 90, 94, 104], "level_0": [42, 58], "level_1": 58, "level_bound": 45, "levinsohn": [40, 58], "lewi": 102, "lgbmclassifi": [50, 51, 52, 57, 60, 63, 65], "lgbmregressor": [47, 50, 51, 52, 57, 60, 65, 68], "lgr": [38, 39, 40, 41, 42, 67, 72, 73, 74, 75, 88, 98, 101], "lib": [58, 59, 65], "liblinear": [59, 66, 73], "librari": [37, 38, 39, 40, 41, 42, 67, 68, 69, 72, 73, 74, 75, 88, 98, 100, 101, 104], "licens": 103, "lie": 102, "lightgbm": [47, 50, 51, 52, 57, 60, 63, 65], "like": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 39, 41, 42, 53, 55, 59, 60, 65, 72, 74, 101, 104], "lim": 61, "limegreen": [48, 49], "limit": [61, 102], "limits_": 71, "lin": 65, "line": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 52, 65], "linear": [1, 9, 11, 12, 18, 19, 24, 25, 26, 27, 28, 30, 31, 34, 37, 38, 39, 40, 42, 45, 46, 47, 48, 49, 51, 52, 53, 54, 57, 58, 64, 65, 67, 68, 70, 71, 72, 74, 76, 78, 79, 80, 81, 85, 86, 88, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104], "linear_model": [15, 43, 45, 46, 53, 57, 58, 59, 65, 66, 72, 73, 88, 98, 101], "linearregress": [37, 45, 46, 57, 65], "linearscoremixin": 75, "lineplot": 45, "linestyl": [45, 52], "linewidth": 52, "link": [65, 103], "linspac": [48, 49, 65], "lint": 103, "linux": 100, "list": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 38, 39, 40, 41, 42, 47, 48, 49, 58, 60, 62, 68, 72, 74, 75, 100, 103], "listedcolormap": 58, "literatur": [65, 73], "littl": 56, "ll": [42, 88, 98, 104], "lllllllllllllllll": [69, 101], "lm": [37, 39, 65], "ln_alpha_ml_l": 53, "ln_alpha_ml_m": 53, "load": [37, 39, 41, 42, 53, 59, 60, 69, 100, 101], "loc": [45, 47, 50, 52, 53, 55, 58, 61, 63, 64, 65], "local": [8, 10, 71, 73, 102, 103], "localconvert": 58, "locat": [50, 63], "log": [40, 53, 57, 58, 61, 64, 72, 73], "log_odd": 62, "log_p": [40, 58], "log_reg": [37, 39], "logarithm": 53, "logic": [8, 42, 72], "logical_not": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 57, 72], "logist": [18, 37, 39, 41, 45, 46, 59, 65, 66, 104], "logisticregress": [37, 43, 45, 46, 65], "logisticregressioncv": [15, 57, 59, 66, 73], "logit": [57, 61], "loglik": [42, 72], "logloss": [41, 59, 104], "logo": 103, "logspac": 59, "long": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 38, 47, 57, 64, 65, 89, 91, 97, 102], "look": [39, 41, 42, 50, 51, 52, 57, 59, 60, 63, 64], "loop": 45, "loss": [57, 64, 72, 73], "loss_ml_g0": 57, "loss_ml_g1": 57, "loss_ml_m": 57, "low": [52, 56, 71, 102], "lower": [41, 42, 45, 50, 52, 53, 56, 60, 61, 63, 64, 65, 72, 89, 94, 97, 104], "lower_bound": [48, 49], "lpq": [10, 14, 60, 71, 82, 103], "lpq_0": 63, "lpq_1": 63, "lqte": 71, "lrn": [37, 38, 39, 40, 41, 42, 67, 72, 73, 74, 75, 88, 98, 101, 104], "lrn_0": 42, "lt": [37, 39, 40, 41, 42, 43, 45, 51, 56, 58, 59, 60, 62, 64, 65, 66, 69, 101], "lucien": 103, "luka": 102, "luk\u00e1\u0161": 29, "lusd": [42, 43, 69, 101], "lvert": 53, "m": [15, 16, 17, 18, 25, 26, 27, 38, 40, 42, 43, 47, 53, 56, 58, 61, 68, 70, 71, 72, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 92, 93, 95, 96, 97, 99, 100, 101, 102, 103], "m_": [45, 73, 75, 76, 82, 88, 98], "m_0": [1, 3, 5, 6, 8, 9, 11, 12, 13, 27, 28, 38, 40, 41, 47, 53, 56, 58, 59, 68, 71, 72, 73, 75, 77, 78, 79, 82, 83, 84, 87, 101, 104], "m_hat": [8, 9, 11, 12, 38, 47, 75], "ma": [26, 40, 58, 102], "mac": 100, "machin": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 26, 27, 28, 29, 37, 41, 42, 43, 45, 46, 50, 51, 53, 59, 60, 61, 63, 64, 65, 66, 70, 72, 73, 74, 75, 88, 89, 91, 98, 103, 104], "machineri": [53, 102], "mackei": 102, "maco": 100, "made": [73, 104], "mae": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 57, 72], "maggi": 102, "magnitud": [89, 91], "mai": [51, 66], "main": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 53, 60, 65, 88, 89, 91, 98, 102, 104], "mainli": 65, "maintain": [39, 99, 103], "mainten": 103, "major": [42, 65, 103], "make": [37, 45, 46, 57, 65, 71, 72, 103, 104], "make_confounded_irm_data": [65, 103], "make_confounded_plr_data": 64, "make_did_sz2020": [5, 6, 51, 73], "make_heterogeneous_data": [48, 49, 54, 55, 56], "make_iivm_data": [8, 10, 71, 73], "make_irm_data": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 57, 71, 72, 73], "make_irm_data_discrete_treat": 45, "make_pipelin": 59, "make_pliv_chs2015": [11, 73], "make_pliv_multiway_cluster_ckms2021": [4, 40, 58], "make_plr_ccddhnr2018": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 38, 47, 67, 68, 71, 72, 73, 74, 75, 88, 89, 94], "make_spd_matrix": 28, "make_ssm_data": [66, 73], "malt": [99, 102], "maltekurz": 99, "man": [37, 46], "manag": [72, 100], "mani": [25, 30, 31, 38, 39, 40, 42, 47, 51, 58, 68, 75, 88, 98, 104], "manili": 34, "manipul": [41, 42], "manual": [41, 64, 104], "mao": 102, "map": [8, 32, 33, 39, 40, 58, 71, 73], "mapsto": [67, 71], "mar": [29, 73], "margin": [48, 49, 65], "marit": [41, 59], "marker": [45, 65], "markers": 61, "market": 61, "markettwo": 40, "markov": [28, 102], "marr": [41, 59, 60, 64, 104], "marshal": 72, "martin": [29, 65, 99, 102, 103], "masatoshi": 102, "master": 39, "mat": 40, "match": [72, 89, 96], "math": 15, "mathbb": [8, 9, 11, 12, 18, 19, 20, 24, 30, 31, 40, 45, 51, 52, 56, 57, 58, 61, 66, 71, 73, 75, 76, 77, 78, 79, 81, 82, 83, 84, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 101, 104], "mathcal": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 38, 40, 47, 50, 52, 58, 62, 63, 66, 68], "mathop": 71, "mathrm": [18, 19], "matplotlib": [43, 45, 47, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66], "matric": [62, 70, 103], "matrix": [18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 38, 40, 41, 42, 47, 58, 66, 68, 69, 72, 88, 98, 101, 103, 104], "matt": 102, "matter": [57, 61], "max": [41, 42, 59, 60, 67, 71, 72, 73, 74, 75, 77, 88, 101, 104], "max_depth": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 43, 59, 64, 67, 71, 72, 73, 74, 75, 88, 89, 94, 101, 104], "max_featur": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 43, 59, 64, 67, 71, 72, 73, 74, 75, 88, 89, 94, 101, 104], "max_it": [58, 59, 65], "maxim": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 62, 71], "maxima": [88, 98], "maximum": [71, 72], "mb": [43, 66, 69, 101], "mb706": 103, "mea": 22, "mean": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 38, 40, 41, 45, 46, 47, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 68, 72, 88, 104], "mean_absolute_error": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 57, 72], "meant": [71, 103], "measir": 64, "measur": [39, 42, 53, 64, 65, 72, 73, 89, 90, 91, 95, 96, 97], "measure_col": 53, "measure_func": 39, "measure_pr": 39, "measures_r": 39, "mechan": [32, 33, 65], "median": [65, 74], "melt": 40, "membership": 65, "memori": [43, 45, 51, 56, 58, 59, 60, 64, 66, 69, 101], "mention": [56, 71], "merg": [41, 59], "mert": [74, 102], "meshgrid": [48, 49, 65], "messag": [38, 39, 40, 41, 42, 101, 103], "meta": [72, 101], "metadata": [32, 33], "metadatarequest": [32, 33], "method": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 54, 55, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 88, 89, 91, 94, 98, 99, 101, 103], "methodolog": 102, "methodologi": 65, "metric": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 72], "michael": 102, "michaela": 103, "michel": [99, 101], "michela": [29, 102], "mid": [41, 59, 61], "mid_point": 45, "might": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 50, 57, 58, 62, 64, 65, 72], "mild": [38, 47, 68], "militari": 61, "miller": [40, 58], "mimic": 65, "min": [40, 41, 42, 50, 58, 59, 60, 63, 67, 72, 73, 74, 75, 88, 98, 101, 104], "min_": 71, "min_samples_leaf": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 35, 56, 59, 64, 67, 71, 72, 73, 74, 75, 88, 89, 94, 104], "min_samples_split": 59, "minim": [9, 35, 41, 57, 59], "minor": [38, 47, 68, 75, 103], "minsplit": 41, "miruna": 102, "mislead": 103, "miss": [4, 7, 15, 42, 72, 73, 75, 83, 103], "missing": [29, 66], "misspecif": 51, "misspecifi": 51, "mit": [99, 101], "mixin": [30, 31, 75], "ml": [28, 40, 41, 42, 53, 58, 59, 67, 70, 72, 74, 99, 102, 103], "ml_g": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 38, 39, 41, 43, 45, 46, 47, 48, 50, 51, 52, 54, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 68, 71, 72, 73, 103], "ml_g0": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 39, 41, 43, 51, 57, 59, 64, 72, 73], "ml_g1": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 39, 41, 43, 51, 57, 59, 64, 72, 73], "ml_g_d0": [66, 73], "ml_g_d0_t0": [51, 73], "ml_g_d0_t1": [51, 73], "ml_g_d1": [66, 73], "ml_g_d1_t0": [51, 73], "ml_g_d1_t1": [51, 73], "ml_g_sim": 15, "ml_l": [11, 12, 38, 40, 41, 42, 43, 47, 49, 55, 58, 59, 61, 64, 67, 68, 72, 73, 74, 75, 88, 89, 94, 98, 101, 103, 104], "ml_l_bonu": 101, "ml_l_forest": 42, "ml_l_forest_pip": 42, "ml_l_lasso": 42, "ml_l_lasso_pip": 42, "ml_l_rf": 104, "ml_l_sim": 101, "ml_l_tune": 72, "ml_l_xgb": 104, "ml_m": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 88, 89, 94, 98, 101, 103, 104], "ml_m_bench_control": 65, "ml_m_bench_treat": 65, "ml_m_bonu": 101, "ml_m_forest": 42, "ml_m_forest_pip": 42, "ml_m_lasso": 42, "ml_m_lasso_pip": 42, "ml_m_rf": 104, "ml_m_sim": [15, 101], "ml_m_tune": 72, "ml_m_xgb": 104, "ml_pi": [15, 66, 73], "ml_pi_sim": 15, "ml_r": [8, 11, 37, 40, 41, 46, 58, 59, 73, 103], "ml_r0": 73, "ml_r1": [41, 59, 73], "mlr": [42, 72], "mlr3": [37, 38, 39, 40, 41, 67, 72, 73, 74, 75, 88, 98, 99, 101, 103, 104], "mlr3book": [42, 72], "mlr3extralearn": [41, 72], "mlr3filter": 42, "mlr3learner": [37, 38, 39, 40, 41, 67, 72, 73, 74, 75, 88, 98, 101, 104], "mlr3measur": 39, "mlr3pipelin": [72, 103], "mlr3tune": [42, 72, 103], "mlr3vers": 41, "mlrmeasur": 39, "mode": [65, 100], "model": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 36, 37, 38, 39, 40, 42, 46, 47, 50, 51, 52, 53, 56, 57, 58, 60, 63, 64, 67, 68, 69, 70, 72, 76, 78, 79, 80, 81, 85, 86, 90, 91, 94, 95, 96, 97, 98, 99, 102, 103], "model_data": [41, 59], "model_select": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 47, 58, 72, 74], "modelmlestimatelowerupp": 41, "modern": [42, 72, 99, 101], "moment": [30, 31, 40, 58, 75, 88, 89, 91, 97, 98, 101], "monoton": 73, "mont": [18, 19, 21, 24, 48, 49, 54, 55], "montanari": 102, "more": [9, 37, 39, 41, 45, 46, 48, 49, 53, 57, 59, 60, 64, 65, 67, 71, 72, 73, 75, 81, 88, 89, 91, 94, 97, 101, 104], "moreov": [41, 42, 53, 72, 88, 98, 104], "mortgag": [41, 59, 60], "most": [41, 50, 57, 59, 60, 63, 65, 71, 72, 89, 94, 100], "motiv": [65, 68], "motivation_example_bch": 53, "mp": 39, "mpd": [40, 58], "mpg": 58, "mse": [42, 53, 72], "msr": [42, 72], "mtry": [41, 42, 67, 72, 73, 74, 75, 88, 104], "mu": 52, "mu_": 52, "mu_mean": 52, "much": [41, 42, 59, 65, 104], "muld": [43, 69, 101], "multi": [39, 40, 48, 49, 58], "multiclass": 42, "multiindex": 58, "multipl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 24, 39, 40, 41, 51, 58, 59, 64, 65, 66, 69, 72, 74, 88, 89, 91, 98, 103, 104], "multipletest": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "multipli": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 47, 70, 71, 75, 104], "multiprocess": [50, 60, 63], "multitest": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "multivariate_norm": 15, "multiwai": [26, 40, 58, 102], "music": 102, "must": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 72, 73], "mutat": 42, "mutual": [1, 9, 12, 41, 54, 55, 59, 60, 71], "my_sampl": 74, "my_task": 74, "n": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 37, 38, 40, 42, 45, 46, 47, 50, 52, 53, 56, 58, 61, 62, 63, 66, 67, 68, 71, 72, 74, 88, 98, 99, 100], "n_": [24, 52], "n_coef": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 89, 94], "n_complier": 63, "n_core": [50, 60, 63], "n_estim": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 43, 47, 48, 49, 50, 51, 52, 54, 55, 56, 59, 60, 62, 63, 64, 65, 67, 68, 71, 72, 73, 74, 75, 88, 89, 94, 101, 104], "n_eval": [42, 72], "n_fold": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 39, 40, 41, 43, 47, 48, 49, 50, 51, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 72, 74, 101, 104], "n_folds_per_clust": [40, 58], "n_folds_tun": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "n_iter_randomized_search": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 72], "n_job": 59, "n_jobs_cv": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 57], "n_jobs_model": [2, 14, 50, 60, 63], "n_level": [24, 45], "n_ob": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 34, 35, 38, 42, 45, 47, 48, 49, 51, 52, 54, 55, 56, 57, 64, 65, 66, 68, 69, 71, 72, 73, 74, 88, 89, 94, 98, 101], "n_rep": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 39, 40, 43, 45, 47, 51, 56, 57, 58, 64, 65, 66, 68, 72, 74, 89, 94, 101, 104], "n_rep_boot": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 45, 48, 49, 50, 54, 55, 60, 63, 88, 98], "n_sampl": 62, "n_split": 74, "n_t": 52, "n_time_period": 52, "n_true": [50, 63], "n_var": [38, 42, 47, 68, 69, 72, 88, 98, 101], "n_w": 62, "n_x": [21, 48, 49, 54, 55, 56], "na": [4, 7, 38, 40, 68, 103], "na_real_": [40, 103], "naiv": [38, 47, 68], "name": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 32, 33, 38, 39, 40, 54, 55, 56, 58, 64, 65, 72, 100, 103], "namespac": 39, "nan": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 45, 47, 50, 51, 52, 54, 55, 57, 59, 60, 63, 66, 68, 72], "nanmean": 47, "narita": 102, "nathan": 102, "nation": [65, 74, 102], "nativ": 39, "natt": 62, "natur": 65, "ncol": [40, 41, 42, 69, 72, 88, 98, 101], "ncoverag": 57, "ndarrai": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 20, 22, 23, 25, 26, 27, 28, 29, 69], "nearli": 57, "necess": [40, 58], "necessari": [39, 40, 58], "need": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 31, 37, 38, 39, 41, 46, 47, 60, 66, 72, 74, 89, 97, 103, 104], "neighborhood": 88, "neither": [4, 7, 40, 58, 69], "neng": 102, "neq": 73, "nest": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 72, 75, 84, 89, 94], "net": [60, 64, 104], "net_tfa": [41, 59, 60, 64, 104], "never": [8, 39, 40, 55, 58, 103], "never_tak": [8, 41, 59], "new": [37, 38, 39, 40, 41, 42, 48, 49, 59, 62, 67, 68, 69, 71, 72, 73, 74, 75, 88, 98, 99, 101, 102, 103, 104], "new_data": [48, 49, 62], "newei": [16, 17, 27, 40, 53, 58, 65, 68, 99, 102], "newest": 103, "next": [39, 41, 42, 48, 49, 50, 56, 57, 59, 60, 62, 63, 65, 103], "neyman": [40, 58, 67, 70, 89, 97, 99, 102], "nfold": [40, 41], "nice": 39, "nifa": [59, 60, 64], "nil": 65, "nine": [40, 58], "node": [41, 42, 67, 73, 74, 75, 88, 101, 104], "nois": [61, 62], "non": [20, 26, 27, 28, 37, 38, 41, 46, 47, 52, 59, 60, 62, 72, 74, 75, 88], "non_orth_scor": [38, 47, 75], "nondur": 43, "none": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 24, 34, 40, 41, 43, 45, 46, 51, 56, 59, 60, 64, 65, 66, 69, 72, 73, 75, 88, 100, 101], "nonignor": [15, 84], "nonlinear": [31, 41, 59, 75, 82, 87, 103], "nonlinearscoremixin": 75, "nonparametr": [10, 13, 14, 65, 89, 90, 91, 95, 96, 97, 102], "nop": 42, "nor": [4, 7, 40, 58, 69], "norm": 47, "normal": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 20, 38, 46, 47, 50, 51, 52, 56, 60, 61, 62, 63, 66, 68, 69, 72, 75, 78, 79, 88, 98, 101], "normalize_ipw": [1, 2, 3, 8, 9, 10, 13, 14, 15, 60, 66], "notat": [40, 51, 58, 66, 73], "note": [4, 7, 8, 9, 11, 12, 15, 30, 31, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 74, 75, 99, 101], "notebook": [37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 71, 72, 104], "notic": [37, 46], "now": [39, 40, 41, 48, 49, 57, 58, 59, 62, 65, 66, 101, 103], "np": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 22, 23, 25, 26, 27, 28, 29, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 101, 104], "nround": [38, 41, 104], "nrow": [39, 40, 42, 69, 72, 88, 98, 101], "nu": [8, 20, 28, 66, 73, 89, 91, 94, 96, 97], "nu2": [89, 94], "nu_0": [89, 97], "nu_i": 66, "nuis_g0": 37, "nuis_g1": 37, "nuis_l": 104, "nuis_m": [37, 104], "nuis_r0": 37, "nuis_r1": 37, "nuis_rmse_ml_l": 53, "nuis_rmse_ml_m": 53, "nuisanc": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 27, 28, 38, 39, 40, 41, 42, 47, 48, 49, 50, 51, 53, 56, 57, 58, 59, 60, 63, 64, 65, 66, 67, 68, 72, 74, 75, 76, 78, 79, 82, 88, 89, 97, 99, 103, 104], "nuisance_el": [89, 90, 92, 93, 95, 96], "nuisance_loss": [57, 72, 103], "nuisance_target": 57, "null": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 39, 64, 72, 89, 94, 103], "null_hypothesi": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 64, 89, 94], "num": [41, 42, 67, 72, 73, 74, 75, 88, 101], "num_leav": [50, 52, 60, 63], "number": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 34, 35, 38, 40, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 60, 62, 63, 65, 74, 88, 98, 99, 101, 104], "numer": [31, 37, 42, 61, 72, 75, 89, 90, 95, 103], "numeric_onli": 53, "numpi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 34, 35, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 101], "ny": 102, "o": [45, 52, 54, 55, 59, 61, 88, 99, 101], "ob": [39, 41, 52], "obei": 75, "obj_dml_data": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 38, 40, 46, 47, 50, 58, 63, 67, 68, 71, 72, 73, 74, 75, 88, 89, 94, 103], "obj_dml_data_bonu": 69, "obj_dml_data_bonus_df": 69, "obj_dml_data_from_arrai": [4, 7], "obj_dml_data_from_df": [4, 7], "obj_dml_data_sim": 69, "obj_dml_plr": [38, 47, 68], "obj_dml_plr_bonu": [42, 101], "obj_dml_plr_bonus_pip": 42, "obj_dml_plr_bonus_pipe2": 42, "obj_dml_plr_bonus_pipe3": 42, "obj_dml_plr_bonus_pipe_ensembl": 42, "obj_dml_plr_nonorth": [38, 47], "obj_dml_plr_orth_nosplit": [38, 47], "obj_dml_plr_sim": [42, 101], "obj_dml_plr_sim_pip": 42, "obj_dml_plr_sim_pipe_ensembl": 42, "obj_dml_plr_sim_pipe_tun": 42, "obj_dml_sim": 15, "object": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 32, 33, 34, 35, 37, 41, 42, 43, 45, 48, 49, 50, 51, 55, 56, 59, 60, 63, 66, 69, 71, 72, 73, 74, 75, 88, 99, 101, 102, 103, 104], "obs_confound": [37, 46], "observ": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 53, 56, 57, 58, 59, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 78, 79, 88, 89, 91, 92, 93, 101, 102, 104], "obtain": [19, 37, 38, 39, 40, 46, 47, 48, 49, 50, 51, 53, 57, 58, 63, 65, 66, 67, 68, 71, 72, 74, 75, 88, 89, 91, 94, 98, 100, 101], "occur": 103, "off": [62, 102], "offer": [39, 41, 59, 60, 65, 104], "offici": 100, "often": 63, "oka": 102, "omega": [56, 71, 75, 76, 81, 89, 90, 95], "omega_": [26, 40, 58], "omega_1": [26, 40, 58], "omega_2": [26, 40, 58], "omega_epsilon": [40, 58], "omega_v": [26, 40, 58], "omega_x": [26, 40, 58], "omit": [64, 65, 89, 91, 97, 102, 103, 104], "ommit": 65, "onc": [39, 65, 104], "one": [11, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 57, 58, 60, 61, 64, 65, 68, 71, 72, 73, 74, 75, 78, 79, 81, 85, 86, 88, 89, 90, 91, 94, 95, 96, 98, 101, 103], "ones": [42, 50, 52, 63, 64, 71], "ones_lik": [45, 63], "onli": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 34, 39, 40, 41, 48, 49, 54, 55, 56, 57, 58, 59, 60, 67, 71, 72, 73, 75, 77, 82, 87, 88, 89, 90, 91, 95, 97, 103], "onlin": 104, "onto": 57, "oob_error": [42, 72], "oop": 103, "opac": [48, 49], "open": [42, 72, 99, 101], "oper": 42, "opposit": 62, "oprescu": [21, 48, 49, 54, 55, 102], "opt": [59, 65], "optim": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 42, 48, 49, 62, 71, 72, 102], "option": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 38, 40, 41, 45, 48, 49, 54, 55, 56, 57, 58, 59, 60, 66, 72, 74, 75, 77, 82, 87, 88, 98, 103], "oracl": [24, 45], "oracle_valu": [18, 19, 24, 45], "orang": 38, "orcal": [18, 19], "order": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 39, 40, 41, 42, 58, 59, 72, 74, 75], "org": [22, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 72, 99, 100, 103], "orient": [42, 72, 75, 99, 101, 102, 103], "origin": [35, 39, 42, 55, 62, 64, 65, 71], "orign": [41, 59], "orth_sign": [34, 35], "orthogon": [34, 35, 40, 41, 58, 59, 67, 70, 88, 89, 97, 98, 99, 102], "orthongon": [89, 97], "osx": 100, "other": [4, 7, 11, 12, 38, 40, 41, 42, 45, 47, 51, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 81, 88, 89, 97, 99, 100, 101, 102, 103, 104], "other_ind": 58, "otherwis": [1, 5, 6, 8, 9, 12, 41, 59, 60, 62, 73], "othrac": [42, 43, 69, 101], "our": [38, 39, 41, 42, 47, 48, 49, 50, 51, 57, 59, 60, 63, 64, 65, 68, 99, 101, 103, 104], "ourselv": 57, "out": [11, 12, 40, 42, 43, 51, 53, 57, 58, 60, 64, 65, 66, 67, 69, 70, 71, 72, 73, 75, 85, 86, 88, 89, 91, 94, 96, 99, 101, 103, 104], "outcom": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 24, 37, 39, 40, 41, 42, 43, 46, 52, 53, 56, 58, 59, 60, 61, 62, 63, 64, 65, 69, 72, 76, 88, 90, 91, 94, 96, 97, 101, 103, 104], "outcome_0": 46, "outcome_1": 46, "outer": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 72], "output": [39, 57, 67, 88, 98, 104], "outshr": 58, "outsid": 38, "over": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 45, 47, 53, 57, 68, 70, 72, 89, 94, 98], "overal": [62, 65], "overcom": [70, 75], "overfit": [70, 74], "overlap": [51, 65, 73], "overrid": [72, 103], "overst": [41, 59, 60], "overview": [57, 88, 89, 94, 102], "overwrit": 103, "ownership": [41, 59], "p": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 38, 39, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 87, 88, 89, 90, 95, 98, 99, 100, 101, 103], "p401": [41, 59, 60], "p_0": [75, 78, 79], "p_1": [88, 98], "p_adjust": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 74, 88, 98, 99, 101], "p_dbl": [42, 72], "p_int": 72, "p_n": 25, "p_val": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "p_x": [26, 40, 58], "p_x0": 61, "p_x1": 61, "packag": [37, 38, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 60, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 88, 89, 91, 99, 101, 102, 103, 104], "packagedata": 58, "packagevers": 41, "page": [65, 99, 102], "pair": [37, 46], "pake": [40, 58], "paket": [40, 41, 42], "pal": 40, "palett": 45, "panda": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 34, 35, 43, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 71, 89, 91, 101], "pandas2ri": 58, "panel": [5, 20, 93, 102, 103], "paper": [22, 25, 42, 61, 64, 65, 89, 97, 99, 101, 102, 103], "par": 43, "par_grid": [42, 72], "paradox": [42, 72, 103], "parallel": [39, 45, 50, 51, 52, 57, 63, 73], "param": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 32, 33, 72], "param_grid": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 72], "param_nam": 39, "param_set": [42, 72], "param_v": 42, "paramet": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 45, 47, 48, 49, 50, 51, 53, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 82, 87, 88, 89, 91, 94, 95, 97, 98, 99, 101, 102, 103, 104], "parametr": [39, 65, 68, 72, 104], "params_exact": 72, "params_nam": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 39], "parenttoc": 99, "part": [28, 38, 40, 41, 42, 47, 57, 58, 59, 68, 72, 74, 89, 97, 103, 104], "parti": 28, "partial": [11, 12, 19, 25, 26, 27, 28, 31, 40, 42, 43, 53, 58, 64, 67, 70, 72, 74, 85, 86, 88, 90, 94, 95, 96, 97, 98, 99, 101, 103, 104], "partial_": [75, 88], "partiallli": 64, "particip": [16, 60, 64, 104], "particular": 99, "partion": [40, 58], "partit": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 40, 58, 67, 70], "partli": 104, "pass": [34, 39, 42, 72, 104], "passo": [99, 101], "past": 40, "paste0": 40, "pastel": 47, "path": [72, 73], "path_to_r": 53, "patsi": [48, 49, 71], "pattern": 65, "paul": 102, "pd": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 34, 45, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 71], "pdf": [47, 61], "pedregosa": [99, 101], "pedregosa11a": [99, 101], "pedro": [39, 102], "penal": 66, "penalti": [41, 42, 46, 59, 65, 66, 72, 73], "pennsylvania": [17, 69, 101], "pension": [41, 59, 60, 104], "peopl": [41, 59, 60], "pep8": 103, "per": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 40, 58], "percent": 72, "percentag": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19], "perf_count": 57, "perform": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 35, 38, 40, 42, 47, 51, 53, 55, 56, 57, 58, 60, 64, 65, 66, 68, 72, 73, 74, 75, 88, 98, 99, 101, 102, 104], "perfrom": 56, "perhap": 104, "period": [5, 39, 51, 52, 73], "perp": 73, "perrot": [99, 101], "person": 104, "pessimist": 65, "peter": 102, "pfister": [42, 72, 99, 101], "phi": [40, 58, 71, 88], "philipp": [65, 99, 102], "philippbach": [99, 103], "pi": [15, 23, 25, 28, 71, 73, 75, 83, 84], "pi_": [26, 40, 58], "pi_0": [75, 83, 84], "pi_i": [66, 73], "pick": 104, "pip3": 100, "pipe": 42, "pipe_forest_classif": 42, "pipe_forest_regr": 42, "pipe_lasso": 42, "pipelin": [42, 59, 103], "pipeop": 42, "pira": [41, 59, 60, 64, 104], "pivot": [53, 58, 102], "plai": 104, "plan": [16, 41, 59, 60, 104], "plausibl": 65, "pleas": [32, 33, 39, 45, 65, 74], "plim": 61, "pliv": [11, 30, 31, 40, 58, 67, 71, 85, 99, 103], "plm": [70, 72, 88, 89, 94, 104], "plot": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 35, 38, 39, 41, 42, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 59, 60, 61, 63, 64, 65, 66, 71, 89, 94], "plot_tre": [35, 62, 71], "plotli": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 48, 49, 53, 65], "plr": [12, 30, 31, 42, 61, 64, 67, 72, 74, 86, 88, 94, 95, 96, 97, 98, 99, 101, 103, 104], "plr_est": 61, "plr_est1": 61, "plr_est2": 61, "plr_obj": 61, "plr_obj_1": 61, "plr_obj_2": 61, "plr_summari": 59, "plrglmnet": 41, "plrranger": 41, "plrrpart": 41, "plrxgboost8700": 41, "plt": [43, 45, 47, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66], "plt_smpl": [40, 58], "plt_smpls_cluster": [40, 58], "plug": [56, 89, 90, 92, 93, 94, 95], "pm": [40, 58, 88, 89, 94, 97, 98], "pmatrix": 66, "po": [42, 72], "point": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 39, 40, 54, 55, 58, 65, 71, 104], "pointwis": [34, 50, 54, 55, 63], "poli": [41, 58, 59], "polici": [9, 11, 12, 35, 70, 73, 101, 102, 103], "policy_tre": [9, 62, 71], "policy_tree_2": 62, "policy_tree_obj": 71, "policytre": 62, "polit": 61, "poly_dict": 59, "polynomi": [16, 17, 41, 43, 59], "polynomial_featur": [16, 17, 41, 43], "polynomialfeatur": [58, 59], "popul": [65, 75], "popular": [57, 89, 91], "porport": 64, "posit": [28, 41, 61, 65, 104], "posixct": [42, 72], "possibl": [4, 7, 39, 42, 48, 49, 54, 55, 56, 57, 62, 64, 65, 72, 73, 88, 89, 91, 103, 104], "possibli": [89, 91], "post": [25, 28, 73, 88, 98, 102], "postdoubl": 102, "poster": 61, "potenti": [1, 2, 3, 10, 13, 15, 18, 24, 51, 61, 66, 76, 77, 88, 90, 100, 103, 104], "potential_level": 45, "power": [42, 65, 72, 102], "pp": 39, "pq": [10, 13, 14, 60, 87, 103], "pq_0": [60, 63], "pq_1": [60, 63], "pr": [15, 37, 40, 41, 42, 72, 73, 74, 75, 88, 101, 104], "practic": [57, 65, 102], "pre": [39, 51, 66, 72, 73], "precis": [39, 89, 95, 104], "pred": 39, "pred_df": 62, "pred_dict": 72, "pred_treat": 62, "predict": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 32, 33, 34, 35, 38, 40, 41, 42, 47, 50, 53, 57, 58, 59, 62, 65, 68, 71, 74, 89, 91, 94, 95, 103, 104], "predict_proba": [1, 3, 5, 6, 8, 9, 10, 12, 13, 14, 15, 32, 72], "predictor": [1, 9, 12, 34, 35, 48, 49, 54, 55, 65, 67], "prefer": [41, 59, 60, 104], "preliminari": [3, 38, 47, 75, 77, 82, 84, 87], "prepar": [39, 40, 58, 103], "preprint": 102, "preprocess": [41, 58, 59, 60, 72], "presenc": [41, 59, 60], "present": [39, 65, 72, 104], "prespecifi": 64, "pretest": 39, "pretreat": [5, 6, 39, 51], "prettenhof": [99, 101], "preval": 65, "prevent": [74, 103], "previou": [52, 56, 61, 100, 104], "previous": [72, 104], "price": [40, 58], "priliminari": [10, 14], "primari": 45, "principl": [89, 91], "print": [38, 39, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 100, 101, 103, 104], "print_detail": 39, "prior": [57, 73], "privat": 103, "prob": 42, "probabilit": 56, "probabl": [1, 3, 8, 9, 10, 13, 14, 15, 20, 24, 38, 39, 45, 47, 51, 56, 61, 63, 65, 66, 68, 73, 75, 78, 79, 82, 102], "problem": [41, 59, 60, 71, 72], "procedur": [38, 40, 41, 47, 57, 58, 59, 64, 65, 72, 88, 98, 103], "proceed": [25, 102], "process": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 39, 48, 49, 50, 51, 52, 53, 54, 55, 57, 62, 63, 65, 66, 70, 88, 89, 91, 98, 102, 103], "produc": 61, "product": [48, 49, 53, 57, 65, 89, 97], "producton": 40, "program": [23, 41, 59, 60, 102, 104], "progress": 44, "project": [42, 48, 49, 71, 99, 103], "project_z": [48, 49], "prone": 75, "propens": [10, 14, 18, 19, 41, 51, 56, 57, 59, 60, 65, 66, 71, 73, 89, 90], "properli": 104, "properti": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 42, 57, 59, 60, 61, 64, 72, 89, 94, 101, 103], "proport": [64, 89, 91, 96, 97], "propos": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 42, 58, 89, 91, 102, 103], "provid": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 39, 40, 41, 42, 48, 49, 54, 55, 58, 59, 65, 67, 68, 69, 70, 72, 88, 98, 99, 101, 103, 104], "prune": [9, 35], "ps911c": 58, "ps944": 58, "pscore1": 61, "pscore2": 61, "psi": [30, 31, 38, 39, 40, 58, 67, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 97, 101], "psi_": [88, 89, 94, 96, 97, 98], "psi_a": [8, 9, 11, 12, 30, 38, 40, 47, 58, 74, 75, 76, 78, 79, 80, 81, 85, 86, 88], "psi_b": [8, 9, 11, 12, 30, 38, 47, 71, 74, 75, 76, 78, 79, 80, 81, 85, 86], "psi_el": [74, 75], "psi_j": [88, 98], "psi_nu2": [89, 94], "psi_sigma2": [89, 94], "public": [37, 46, 103], "publish": [65, 103], "pull": [41, 103], "purchas": 65, "pure": 65, "purp": [48, 49], "purpos": [38, 47, 56, 64, 65, 89, 91, 101], "pval": [88, 98], "px": 53, "py": [55, 58, 59, 65, 99, 100, 103], "py3": 100, "py_al": 47, "py_dml": 47, "py_dml_nosplit": 47, "py_dml_po": 47, "py_dml_po_nosplit": 47, "py_double_ml_apo": 45, "py_double_ml_bas": 47, "py_double_ml_basic_iv": 46, "py_double_ml_c": 48, "py_double_ml_cate_plr": 49, "py_double_ml_cvar": 50, "py_double_ml_did": 51, "py_double_ml_did_pretest": 52, "py_double_ml_firststag": 53, "py_double_ml_g": 54, "py_double_ml_gate_plr": 55, "py_double_ml_gate_sensit": 56, "py_double_ml_learn": 57, "py_double_ml_multiway_clust": 58, "py_double_ml_pens": 59, "py_double_ml_pension_qt": 60, "py_double_ml_plm_irm_hetfx": 61, "py_double_ml_policy_tre": 62, "py_double_ml_pq": 63, "py_double_ml_sensit": 64, "py_double_ml_sensitivity_book": 65, "py_double_ml_ssm": 66, "py_non_orthogon": 47, "py_po_al": 47, "pydata": 55, "pypi": [102, 103], "pyplot": [43, 45, 47, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66], "python": [28, 39, 65, 67, 68, 69, 70, 71, 73, 74, 75, 88, 89, 91, 94, 98, 99, 101, 102, 103, 104], "python3": [59, 65, 100], "q": [42, 50, 63, 72, 99, 101], "q2": [42, 43, 69, 101], "q3": [42, 43, 69, 101], "q4": [42, 43, 69, 101], "q5": [42, 43, 69, 101], "q6": [42, 43, 69, 101], "qquad": 23, "qte": [50, 60, 103], "quad": [20, 41, 51, 59, 62, 66, 71, 73, 75, 82, 88, 89, 92, 98], "quadrat": 66, "qualiti": [64, 67, 103], "quanitl": 60, "quant": 50, "quantifi": 65, "quantil": [2, 3, 10, 13, 14, 24, 45, 50, 64, 70, 77, 82, 87, 102, 103], "quantiti": [37, 46, 65], "queri": 59, "question": [65, 104], "quick": 60, "quit": [57, 62, 64, 89, 91], "r": [8, 22, 47, 48, 49, 52, 53, 58, 61, 65, 67, 68, 69, 70, 73, 74, 75, 80, 85, 88, 89, 90, 91, 95, 96, 97, 98, 99, 101, 102, 103, 104], "r2_d": [23, 57], "r2_y": [23, 57], "r6": [42, 103], "r_0": [8, 11, 41, 59, 73], "r_all": 38, "r_d": 23, "r_df": 58, "r_dml": 38, "r_dml_nosplit": 38, "r_dml_po": 38, "r_dml_po_nosplit": 38, "r_double_ml_bas": 38, "r_double_ml_basic_iv": 37, "r_double_ml_did": 39, "r_double_ml_multiway_clust": 40, "r_double_ml_pens": 41, "r_double_ml_pipelin": 42, "r_hat": 11, "r_hat0": 8, "r_hat1": 8, "r_non_orthogon": 38, "r_po_al": 38, "r_y": 23, "rais": [4, 7, 32, 33, 72], "randint": 61, "randn": 15, "random": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 24, 28, 29, 37, 38, 39, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 74, 83, 88, 89, 94, 97, 98, 101, 102, 104], "random_search": 72, "random_st": [24, 47, 56, 62], "randomforest": [41, 57, 59], "randomforest_class": [41, 48, 59, 62], "randomforest_reg": [48, 62], "randomforestclassifi": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 43, 45, 48, 49, 54, 55, 56, 57, 59, 62, 64, 65, 71, 72, 73, 104], "randomforestregressor": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 43, 45, 47, 48, 49, 54, 55, 56, 57, 59, 62, 64, 65, 67, 71, 72, 73, 74, 75, 88, 89, 94, 101, 104], "randomized_search": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 72], "randomizedsearchcv": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 72], "randomli": [38, 40, 47, 58, 68, 74, 104], "rang": [38, 45, 47, 50, 51, 52, 54, 55, 57, 58, 60, 62, 63, 65, 66, 68, 72], "rangeindex": [43, 45, 51, 56, 58, 59, 60, 64, 66, 69, 101], "ranger": [39, 41, 42, 67, 72, 73, 74, 75, 88, 101, 104], "rangl": [21, 62], "rank": 103, "rate": [53, 57], "rather": 65, "ratio": [72, 74, 89, 91], "ravel": [48, 49], "raw": [41, 53, 59], "raw_res_manual_lasso_r_100_n_100_p_200_rho_0": 53, "rbind": 41, "rbindlist": 41, "rbinom": 37, "rbrace": [8, 9, 22, 23, 29, 40, 58, 67, 73, 74, 75, 76, 88, 89, 90, 98], "rcolorbrew": 40, "rcparam": [43, 48, 49, 50, 52, 54, 55, 58, 59, 60, 63], "rd": 103, "rdbu": 40, "rdbu_r": 58, "rdt044": 53, "re": [58, 65, 100], "read_csv": 53, "readabl": 103, "readili": 99, "real": [41, 59, 60, 64, 89, 91], "realat": 73, "realiz": 73, "reason": [4, 7, 37, 46, 64, 65, 89, 91, 104], "recal": [43, 89, 97], "receiv": [45, 73], "recent": 73, "recogn": [41, 59, 60], "recommend": [42, 57, 65, 67, 74, 100, 102, 103], "recov": [37, 39, 46, 61], "recsi": 102, "red": [40, 54, 55, 58], "reduc": [41, 56, 59, 64, 65, 103], "redund": 103, "reemploy": [17, 69, 101], "refactor": 103, "refer": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 41, 45, 52, 56, 59, 60, 64, 69, 70, 71, 73, 89, 91, 94, 102, 103], "reference_level": [2, 45, 73], "refin": 103, "refit": [89, 91], "reflect": [62, 65, 71], "reg": [20, 41, 59, 104], "reg_learn": 60, "reg_learner_1": 57, "reg_learner_2": 57, "regard": [65, 99], "regener": 103, "region": [40, 50, 58, 88, 98, 102], "regr": [37, 38, 39, 40, 41, 42, 67, 72, 73, 74, 75, 88, 98, 101, 104], "regravg": [42, 72], "regress": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 22, 23, 24, 25, 26, 27, 28, 37, 39, 40, 42, 45, 46, 53, 58, 61, 64, 65, 66, 67, 68, 70, 71, 72, 74, 88, 90, 91, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104], "regressor": [33, 38, 41, 45, 47, 50, 57, 59, 68], "regular": [25, 70, 72, 75, 88, 98, 102], "reich": [42, 72], "reinforc": 102, "reject": [41, 59], "rel": [41, 59, 89, 90, 91, 95], "relat": [65, 104], "relationship": [37, 46, 53, 65, 88, 98], "releas": 59, "relev": [4, 5, 6, 7, 21, 34, 50, 62, 63, 89, 104], "reli": [48, 49, 51, 52, 56, 71, 72, 73, 89, 91, 104], "reload": 41, "remain": [39, 88, 98, 104], "remark": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 45, 47, 48, 49, 50, 52, 54, 55, 56, 57, 60, 64, 71, 72, 73, 75, 78, 79, 82, 87, 88, 89, 95], "remot": 100, "remov": [41, 59, 65, 70, 74, 103], "renam": [59, 103], "render": [64, 65], "reorgan": 103, "rep": [38, 68, 72, 88, 98], "repeat": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 38, 40, 41, 42, 47, 56, 58, 59, 60, 61, 64, 66, 68, 70, 72, 88, 92, 101, 103, 104], "repeatedkfold": 58, "repet": 64, "repetit": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 48, 49, 53, 54, 55, 56, 57, 70, 72, 88, 101, 104], "repetiton": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "replac": [62, 65, 103], "replic": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 38, 41, 47, 53, 65], "repo": 103, "report": [41, 59, 99, 103], "repositori": [53, 103], "repr": [38, 40], "repres": [61, 65], "represent": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 64, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 101, 103], "reproduc": 24, "request": 103, "requir": [11, 12, 37, 41, 42, 45, 56, 59, 60, 64, 73, 88, 89, 91, 94, 98, 100, 103, 104], "requirenamespac": 39, "res_df": 58, "res_dict": [18, 19, 21, 24], "resampl": [37, 40, 42, 51, 58, 60, 64, 66, 72, 73, 74, 75, 88, 99, 101, 104], "research": [40, 42, 58, 61, 65, 74, 99, 101, 102, 104], "resembl": 66, "reset": 39, "reset_index": [53, 58, 59], "reshap": [47, 48, 49, 52], "reshape2": 40, "residu": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 64, 89, 91, 96, 97], "resolut": [42, 72], "resourc": 57, "resourcewis": 57, "respect": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 45, 59, 60, 71, 73, 74, 89, 97, 104], "respons": [16, 42, 72], "restart": 100, "restrict": 57, "restructur": 103, "restud": 53, "result": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 37, 38, 39, 42, 45, 47, 48, 49, 51, 52, 53, 56, 57, 62, 64, 65, 66, 68, 72, 74, 75, 78, 79, 89, 91, 94, 101, 103], "result_iivm": 41, "result_irm": 41, "result_plr": 41, "retina": 61, "retir": [41, 59, 60, 64], "return": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 38, 39, 40, 42, 47, 50, 55, 57, 58, 61, 62, 63, 64, 65, 66, 67, 72, 75, 89, 91, 103], "return_count": [45, 57], "return_tune_r": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "return_typ": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 38, 41, 42, 47, 51, 57, 59, 60, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 88, 89, 94, 101, 104], "rev": 40, "reveal": 56, "review": [25, 53, 102], "revist": [40, 58], "rho": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 36, 45, 56, 64, 65, 89, 91, 94, 97, 104], "rho_val": 65, "richter": [42, 72, 99, 101], "riesz": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 64, 89, 91, 92, 93, 94, 96, 97], "riesz_rep": [89, 94], "right": [22, 23, 25, 26, 29, 38, 40, 47, 57, 58, 59, 60, 61, 63, 65, 68, 75, 78, 79, 88, 89, 90, 92, 93, 95, 98], "rightarrow_": [38, 47, 68], "risk": [3, 70, 103], "ritov": 102, "rival": 58, "rival_ind": 58, "rmd": 39, "rmse": [39, 51, 57, 60, 64, 66, 72, 73, 75, 88, 101, 103], "rnorm": [37, 42, 69, 72, 88, 98, 101], "robin": [16, 17, 27, 40, 53, 58, 68, 99, 102], "robinson": [38, 47, 68], "robject": 58, "robu": [54, 55], "robust": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 26, 39, 45, 56, 64, 65, 89, 94, 102, 104], "role": [4, 7, 38, 47, 68, 104], "romano": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 88, 98], "root": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 31, 53, 68, 72, 75, 102], "roth": 73, "rough": [65, 104], "roughli": 65, "round": [41, 45, 57, 61, 65], "rout": [32, 33], "row": [38, 41, 43, 48, 49, 52, 58, 62, 69, 74, 101, 104], "row_index": 55, "rownam": 40, "rowv": 40, "roxygen2": 103, "royal": [65, 102], "rpart": [41, 42, 72], "rpart_cv": 42, "rprocess": 57, "rpy2": 58, "rpy2pi": 58, "rsmp": [42, 72, 74], "rsmp_tune": [42, 72], "rssb": 65, "rtype": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "ruben": 102, "ruiz": [37, 46], "rule": [39, 71], "run": [39, 100, 103], "runif": 37, "runtime_learn": 42, "rv": [45, 56, 64, 65, 89, 94, 104], "rva": [45, 56, 64, 65, 89, 94, 104], "rvert": 53, "rvert_": 53, "s_": [26, 40, 58, 73], "s_1": 27, "s_2": 27, "s_col": [4, 7, 66, 73], "s_i": [29, 66, 73], "s_x": [26, 40, 58], "safeguard": [51, 72], "sake": [41, 59, 65, 104], "same": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 24, 34, 38, 40, 47, 48, 49, 56, 57, 58, 60, 62, 64, 65, 66, 72, 75, 78, 79, 88, 89, 95, 103], "samii": 61, "sampl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 26, 29, 37, 39, 40, 42, 46, 51, 54, 55, 57, 58, 60, 62, 64, 70, 72, 88, 98, 101, 102, 103], "sant": [5, 6, 18, 19, 20, 24, 39, 51, 73, 102], "sara": 102, "sasaki": [26, 40, 58, 102], "satisfi": [66, 72, 75, 88], "save": [38, 41, 47, 54, 55, 57, 59, 60, 72, 89, 94, 104], "savefig": 47, "saveguard": 57, "saver": [41, 59, 60], "scalar": 73, "scale": [38, 40, 50, 52, 61, 63, 65, 88, 89, 97], "scale_color_manu": 38, "scale_fill_manu": [38, 40], "scatter": [45, 52, 54, 55, 61, 65], "scatterplot": 45, "scenario": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 56, 64, 65, 89, 94, 104], "scene": [48, 49, 53], "scene_camera": 53, "schaefer": 61, "schedul": 103, "scheme": [40, 58, 72, 74, 99], "schneider": 42, "schratz": [42, 72, 99, 101], "scienc": [28, 37, 46, 61, 102], "scikit": [57, 59, 72, 99, 101, 103, 104], "scipi": 47, "score": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 30, 31, 37, 39, 40, 41, 42, 43, 48, 49, 50, 51, 53, 56, 57, 58, 59, 60, 63, 64, 65, 66, 67, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 99, 103, 104], "scoring_method": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "script": 100, "sd": 37, "se": [38, 40, 47, 64, 68, 72, 74, 88, 89, 94, 102, 104], "se_df": 40, "se_dml": [38, 47, 68], "se_dml_po": [38, 47, 68], "se_nonorth": [38, 47], "se_orth_nosplit": [38, 47], "se_orth_po_nosplit": [38, 47], "seaborn": [43, 45, 47, 51, 57, 58, 59, 60, 65, 66], "search": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 31, 72, 75], "search_mod": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 72], "searchabl": 41, "second": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 26, 38, 40, 42, 47, 57, 58, 67, 68, 74, 88, 89, 91, 97, 98, 101], "secondari": 45, "section": [6, 20, 39, 40, 41, 42, 56, 58, 60, 65, 92, 103], "secur": 61, "see": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 23, 29, 30, 31, 37, 39, 40, 41, 42, 45, 46, 48, 49, 51, 55, 58, 60, 61, 62, 64, 65, 72, 73, 74, 75, 77, 81, 82, 83, 84, 87, 89, 91, 94, 97, 100, 101, 103], "seed": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 24, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 88, 89, 94, 98, 101, 104], "seek": 61, "seem": [39, 41, 56, 59, 60, 104], "seen": [54, 55], "sel_cols_chiang": 58, "select": [4, 7, 15, 24, 25, 29, 53, 57, 65, 67, 70, 72, 102, 103, 104], "selected_coef": 57, "selected_featur": [42, 72], "selected_learn": 57, "self": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 35, 57, 104], "selfref": 41, "semenova": [48, 49, 102], "semi": 68, "semiparametr": 16, "sens": [64, 65], "sensemakr": [89, 91], "sensit": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 36, 70, 71, 91, 94, 97, 103], "sensitivity_analysi": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 56, 64, 65, 89, 94, 104], "sensitivity_benchmark": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 56, 64, 65, 89, 91], "sensitivity_el": [89, 94], "sensitivity_param": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 64, 65, 89, 91, 94], "sensitivity_plot": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 56, 64, 65, 89, 94], "sensitivity_summari": [45, 56, 64, 65, 89, 94, 104], "sensitvity_benchmark": 45, "sensiv": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "senstiv": [89, 96], "sep": 38, "separ": [61, 64, 72, 103], "seper": [64, 74, 88, 89, 91], "seq_len": [38, 68], "sequenti": 17, "seri": [55, 65, 102], "serv": [69, 101, 103], "serverless": [102, 103], "servic": 61, "set": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 26, 27, 28, 35, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 51, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 71, 73, 74, 75, 76, 78, 79, 81, 88, 89, 90, 91, 95, 96, 98, 100, 101, 103, 104], "set_as_param": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "set_fold_specif": 72, "set_index": 59, "set_ml_nuisance_param": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 43, 59, 72, 103], "set_param": [32, 33, 72], "set_sample_split": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 57, 74, 103], "set_styl": [59, 60], "set_text": 57, "set_threshold": [38, 39, 40, 41, 42, 67, 72, 73, 74, 75, 88, 98, 101], "set_tick": 58, "set_ticklabel": 58, "set_titl": [45, 58], "set_x_d": [4, 7], "set_xlabel": [45, 47, 58], "set_xlim": 47, "set_xtick": 61, "set_xticklabel": 61, "set_ylabel": [45, 58, 61], "set_ylim": [50, 58, 63], "setdiff": 103, "setdiff1d": 58, "setminu": [40, 58, 88, 98], "setup": 100, "setuptool": 100, "seven": [40, 58], "sever": [36, 41, 42, 57, 59, 60, 64, 65, 68, 72, 104], "shape": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 34, 35, 45, 48, 49, 52, 54, 55, 57, 58, 59, 62, 64, 65, 72], "share": [40, 41, 58, 59], "sharma": [65, 102], "shock": [40, 58], "short": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 64, 65, 89, 91, 102, 103, 104], "shortcut": 41, "shortli": [40, 42, 58, 72], "shota": 102, "should": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 31, 41, 45, 54, 55, 57, 59, 64, 66, 69, 71, 72, 73, 88, 89, 91, 99], "show": [37, 38, 40, 43, 45, 46, 47, 48, 49, 51, 53, 56, 57, 58, 61, 65, 66, 68, 89, 96, 100], "showcas": 62, "showlabel": 65, "showlegend": 65, "shown": [37, 46, 61, 101], "showscal": [48, 49, 53], "shuffl": 74, "side": [89, 94], "sigma": [15, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 38, 40, 47, 58, 66, 68, 71, 74, 88, 89, 91, 94, 96, 97, 98], "sigma2": [89, 94], "sigma_": [19, 20, 22, 23, 25, 26, 27, 29, 38, 40, 47, 58, 68], "sigma_0": [89, 97], "sigma_j": [88, 98], "sigmoid": 61, "sign": 65, "signal": [34, 35], "signatur": [8, 9, 10, 11, 12, 13, 14, 75], "signif": [37, 39, 40, 41, 42, 72, 73, 74, 75, 88, 101, 104], "signific": [37, 40, 41, 42, 45, 56, 59, 62, 64, 65, 72, 73, 74, 75, 88, 89, 94, 101, 104], "silverman": [10, 13, 14], "sim": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 38, 39, 40, 47, 50, 52, 58, 62, 63, 66, 68], "similar": [19, 24, 39, 42, 48, 49, 56, 60, 64, 65], "simpl": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 21, 39, 42, 48, 49, 54, 55, 56, 62, 65, 70, 89, 91], "simplest": 71, "simpli": [42, 51, 104], "simplic": [41, 57, 59, 62, 65], "simplif": [89, 92], "simplifi": [61, 65, 71, 89, 96], "simul": [18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 38, 42, 47, 48, 49, 50, 53, 54, 55, 63, 65, 66, 68, 72, 88, 98, 101], "simul_data": 15, "simulaten": 73, "simulation_run": 53, "simult": 39, "simultan": [70, 104], "sin": [21, 24, 28, 48, 49, 52, 54, 55], "sinc": [18, 19, 41, 45, 51, 52, 54, 55, 56, 57, 59, 61, 66, 72, 73, 89, 94, 95, 103], "singl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 51, 54, 55, 60, 61, 72, 88, 98], "single_learner_pipelin": 72, "singleton": 74, "sinh": 28, "sipp": [41, 59, 60], "site": [58, 59, 65], "situat": [40, 58], "six": 40, "sixth": 58, "size": [15, 38, 40, 41, 42, 47, 50, 52, 53, 56, 57, 59, 61, 62, 63, 65, 67, 69, 72, 73, 74, 75, 88, 98, 101, 104], "sizeabl": 65, "skill": 102, "sklearn": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 28, 35, 43, 45, 46, 47, 48, 49, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 67, 71, 72, 73, 74, 75, 88, 89, 94, 98, 101, 104], "skotara": 65, "slide": 61, "slightli": [52, 54, 55, 56, 57, 71, 75, 78, 79, 89, 91], "sligthli": [5, 6], "slow": [38, 47, 68], "slower": [38, 47, 68], "small": [21, 51, 52, 62, 66, 89, 91, 95], "smaller": [41, 51, 54, 55, 56, 59, 65, 104], "smallest": 57, "smpl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 40, 47, 57, 58, 74, 75], "smpls_cluster": [40, 58], "smsg": 59, "sn": [43, 45, 47, 51, 57, 58, 59, 60, 65, 66], "so": [37, 41, 42, 46, 51, 59, 61, 65, 66, 72, 88, 104], "social": [61, 102], "societi": [40, 58, 65, 102], "softwar": [42, 72, 99, 101, 102, 103], "solari": 103, "sole": 65, "solut": [67, 71, 75], "solv": [30, 40, 58, 71, 72, 88, 98], "solver": [59, 66, 73], "some": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 42, 43, 51, 52, 57, 59, 60, 64, 66, 71, 72, 73, 103], "sometim": 57, "sonabend": [42, 72], "sophist": 72, "sort": [59, 73], "sort_valu": 45, "sourc": [42, 72, 101, 103], "sourcefileload": 53, "sp": 39, "space": [40, 58, 72], "spars": [53, 72, 88, 98, 101, 102], "sparsiti": 102, "spec": 102, "special": [40, 58], "specif": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 31, 40, 41, 45, 57, 58, 59, 65, 69, 70, 71, 72, 74, 75, 81, 88, 94, 97, 99, 101], "specifi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 37, 40, 41, 42, 45, 46, 48, 49, 50, 51, 54, 55, 58, 59, 60, 62, 63, 64, 65, 66, 67, 69, 70, 71, 76, 81, 101, 103, 104], "specifii": 60, "speed": [2, 14, 57], "speedup": 57, "spefici": 8, "spindler": [25, 65, 99, 102, 103], "spine": [59, 60], "spline": [48, 49, 71], "spline_basi": [48, 49, 71], "spline_grid": [48, 49], "split": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 40, 42, 51, 57, 58, 60, 62, 64, 66, 70, 71, 72, 73, 75, 88, 101, 103], "split_sampl": 57, "sponsor": [41, 59, 60], "sprintf": 38, "sq_error": 53, "sqrt": [18, 19, 20, 23, 24, 38, 40, 42, 43, 47, 50, 58, 63, 68, 74, 88, 89, 91, 98, 101], "squar": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 53, 59, 72, 89, 97, 102], "squarederror": [41, 59, 104], "squeez": [50, 51, 63, 66], "src": 59, "ssm": [4, 7, 29, 70], "ssrn": 22, "stabil": 56, "stabl": [37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 99], "stack": [42, 72], "stacklrn": 42, "stage": [48, 49, 54, 55, 62, 72, 103, 104], "standard": [20, 39, 42, 50, 54, 55, 74, 75, 88, 89, 94, 97, 98, 103, 104], "standard_norm": [69, 72, 88, 98, 101], "standardscal": 59, "start": [39, 41, 42, 48, 49, 53, 56, 57, 58, 59, 63, 65, 73, 99, 104], "stat": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 47, 69, 72, 88, 98, 99, 102], "stat_bin": 38, "stat_dens": 41, "state": 104, "stationar": 51, "stationari": 73, "statist": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 26, 29, 36, 40, 58, 64, 65, 88, 89, 94, 98, 99, 101, 102, 103, 104], "statsmodel": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "statu": [39, 41, 51, 59, 61, 66], "std": [3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 39, 40, 41, 42, 43, 45, 46, 48, 49, 50, 51, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 71, 72, 73, 74, 75, 88, 101, 104], "stefan": 102, "step": [38, 41, 42, 47, 54, 55, 56, 59, 62, 68, 72, 88, 98, 99, 104], "stepdown": [88, 98], "stick": [41, 59], "still": [48, 49, 51, 54, 55, 56, 60, 64, 66, 72], "stochast": [11, 12, 73, 101], "stock": [41, 59, 60], "store": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 67, 72, 74, 75, 88, 89, 94, 103], "store_model": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "store_predict": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 39, 59, 62], "stori": [65, 102], "str": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 41, 45, 54, 55, 63, 71, 103], "straightforward": [54, 55, 57, 71], "strategi": [61, 65, 104], "stratifi": 57, "stratum": 61, "strength": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 64, 65, 89, 91, 94, 96], "strictli": 73, "string": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 71, 88, 89, 94, 101, 103], "string_label": 61, "strong": [66, 89, 91], "stronger": [88, 104], "structur": [16, 17, 27, 40, 41, 53, 58, 59, 66, 68, 72, 99, 102, 104], "student": 102, "studi": [29, 40, 41, 53, 58, 59, 60, 64, 101, 104], "style": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 103], "styler": 103, "styliz": 65, "sub": [40, 58], "subclass": 103, "subfold": 72, "subgroup": [8, 41, 59, 103], "subject": [40, 58], "submiss": 103, "subobject": [32, 33], "subplot": [40, 45, 47, 48, 49, 50, 52, 54, 55, 57, 58, 59, 60, 61, 63], "subplots_adjust": 57, "subpopul": 73, "subsampl": [42, 57], "subscript": [89, 91], "subsequ": [40, 58], "subset": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 57, 58, 62, 67, 71, 72, 89, 91], "subseteq": 71, "substanti": [41, 59, 61], "substract": 88, "subtract": 88, "sudo": 100, "suffic": 65, "suffici": [57, 65], "suggest": [40, 41, 58, 59, 65, 103], "suitabl": [48, 49, 66], "sum": [40, 41, 58, 59, 60, 63, 71, 88, 98], "sum_": [38, 40, 47, 58, 67, 68, 71, 88, 98], "sum_i": 61, "sum_oth": 58, "sum_riv": 58, "summar": [39, 45, 61, 65, 67, 89, 94], "summari": [3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 39, 40, 42, 43, 45, 46, 48, 49, 50, 51, 54, 55, 56, 58, 60, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 88, 89, 101, 103, 104], "summary_result": 41, "suppli": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 48, 49, 54, 55, 56, 62, 71, 89, 90, 91, 94], "support": [8, 21, 39, 40, 57, 58, 62, 72, 73, 104], "support_s": [21, 48, 49, 54, 55, 62], "support_t": 62, "support_w": 62, "suppos": 65, "suppress": [39, 41, 42], "suppresswarn": 38, "suprema": [88, 98], "suptitl": [50, 57, 60, 63], "supxlabel": [50, 60, 63], "supylabel": [50, 60, 63], "sure": [45, 72, 103], "surfac": [48, 49, 53], "surpress": [40, 101], "survei": [41, 59, 60, 104], "susan": 102, "sven": [65, 99, 102], "svenk": 58, "svenklaassen": 99, "svg": [38, 47], "switch": [38, 47, 65, 68], "symbol": 65, "symmetr": 28, "synthet": [21, 37, 46, 48, 49, 50, 54, 55, 62, 63], "syrgkani": [65, 102], "system": 102, "szita": 102, "t": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 24, 37, 39, 40, 41, 42, 43, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 71, 72, 73, 74, 75, 79, 88, 89, 92, 98, 101, 104], "t_1_start": 57, "t_1_stop": 57, "t_2_start": 57, "t_2_stop": 57, "t_3_start": 57, "t_3_stop": 57, "t_col": [4, 6, 7, 73], "t_df": 62, "t_diff": 52, "t_dml": 38, "t_i": [51, 62, 73], "t_idx": 52, "t_nonorth": 38, "t_orth_nosplit": 38, "t_sigmoid": 62, "t_stat": 88, "tabl": [38, 40, 41, 42, 45, 67, 69, 72, 73, 74, 75, 88, 98, 101, 104], "tabular": [57, 69, 88, 98, 101, 104], "taddi": 102, "take": [8, 9, 11, 12, 18, 19, 21, 48, 49, 50, 51, 52, 53, 54, 55, 57, 60, 63, 64, 66, 67, 71, 72, 73, 75, 76, 81, 89, 90, 95, 96, 101], "taken": [41, 59, 60, 104], "taker": [8, 103], "talk": 104, "target": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 30, 31, 37, 40, 41, 42, 48, 49, 57, 58, 71, 72, 73, 74, 75, 82, 87, 88, 89, 95, 97, 98, 99, 101, 103, 104], "task": [37, 69, 74, 104], "task_typ": 103, "tau": [50, 52, 60, 61, 63, 71, 75, 77, 82, 87], "tau_": 61, "tau_1": 61, "tau_2": 61, "tau_vec": [50, 60, 63], "tax": [41, 59, 60], "te": [39, 48, 49, 62], "techniqu": [38, 47, 68, 74, 104], "templat": 103, "temporari": 59, "tend": [41, 59, 60], "tensor": [48, 49], "tenth": 102, "term": [38, 40, 41, 42, 47, 52, 53, 58, 59, 61, 65, 68, 99, 104], "termin": [42, 72], "terminatorev": 42, "test": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 22, 37, 38, 39, 40, 41, 42, 47, 56, 58, 65, 68, 72, 73, 74, 75, 88, 98, 101, 102, 103, 104], "test_id": [40, 74], "test_ind": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "test_set": 74, "test_siz": 47, "text": [18, 19, 20, 22, 24, 40, 41, 50, 53, 61, 62, 63, 65, 71, 74], "textbf": [67, 72, 104], "textposit": 65, "textrm": [89, 90, 91, 95, 96, 97], "tg": [42, 43, 69, 101], "th": [40, 58], "than": [9, 38, 39, 41, 47, 53, 57, 59, 60, 61, 64, 65, 68, 89, 94, 104], "thank": [39, 41, 42, 59, 103], "thatw": 52, "thei": [39, 41, 52, 54, 55, 59, 61, 89, 97], "them": [41, 42, 48, 49, 50, 56, 59, 63], "theme": [40, 41], "theme_minim": [38, 41], "theorem": [89, 97], "theoret": [57, 65, 74, 102], "theori": [71, 102], "therebi": [40, 42, 58, 104], "therefor": [45, 61, 64, 74, 75, 89, 96], "theta": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 22, 23, 24, 26, 28, 29, 30, 31, 38, 40, 42, 45, 47, 51, 52, 53, 56, 57, 58, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 94, 96, 97, 98, 101, 104], "theta_": [45, 65, 71, 73, 88, 89, 97, 98], "theta_0": [8, 9, 11, 12, 21, 38, 40, 41, 45, 47, 48, 49, 53, 54, 55, 58, 59, 65, 66, 68, 71, 73, 75, 82, 87, 88, 89, 90, 95, 97, 101], "theta_dml": [38, 47, 68], "theta_dml_po": [38, 47, 68], "theta_initi": 47, "theta_nonorth": [38, 47], "theta_orth_nosplit": [38, 47], "theta_orth_po_nosplit": [38, 47], "theta_resc": 38, "theta_t": 52, "thi": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 71, 72, 73, 74, 75, 77, 78, 79, 82, 87, 88, 89, 90, 91, 94, 95, 99, 100, 101, 102, 103, 104], "think": 42, "third": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 47, 58, 68, 74], "thirion": [99, 101], "this_df": [53, 59], "this_split_ind": 58, "those": [39, 41, 59, 60], "though": [37, 46, 61], "thread": [61, 72], "three": [40, 42, 54, 55, 100, 103], "threshold": [1, 3, 5, 6, 8, 9, 10, 13, 14, 15, 65, 73], "through": [39, 50, 54, 55, 63, 72], "throughout": 56, "thu": 71, "tibbl": 39, "tight": 47, "tight_layout": 58, "tild": [18, 19, 20, 24, 40, 58, 61, 67, 71, 74, 75, 82, 83, 84, 87, 88, 89, 96, 97, 98], "time": [4, 5, 7, 25, 26, 38, 39, 40, 41, 47, 51, 52, 53, 54, 55, 58, 59, 60, 64, 65, 66, 73, 103, 104], "time_df": 52, "time_period": 52, "titl": [40, 41, 45, 48, 49, 50, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 99], "tmp": 55, "tname": 39, "tnr": [42, 72], "to_fram": 62, "to_numpi": [50, 56, 60, 63], "todo": [40, 43], "toeplitz": 53, "togeth": [54, 55, 88], "toler": 58, "too": 57, "tool": [39, 42, 64, 104], "top": [40, 57, 58, 59, 60, 65, 99], "total": [41, 59], "tracker": 99, "tradit": [88, 98], "train": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 40, 42, 47, 48, 49, 50, 54, 55, 57, 58, 62, 63, 67, 68, 74], "train_id": [40, 74], "train_ind": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "train_set": 74, "train_test_split": 47, "transact": 102, "transform": [18, 19, 61, 65, 104], "translat": 53, "transpos": 52, "treament": 62, "treat": [9, 20, 39, 45, 51, 52, 56, 62, 65, 71, 73, 88, 104], "treat1_param": 61, "treat2_param": 61, "treat_var": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 72], "treatment": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 27, 37, 39, 40, 42, 43, 45, 46, 51, 52, 53, 56, 57, 58, 62, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 77, 78, 79, 81, 82, 87, 88, 89, 90, 94, 96, 98, 99, 101, 102, 103, 104], "treatment_df": 52, "treatment_effect": [21, 48, 49], "treatment_level": [1, 2, 45, 73], "treatment_var": [4, 7], "tree": [9, 35, 41, 42, 51, 52, 57, 59, 67, 70, 72, 73, 74, 75, 88, 101, 103], "tree_param": [9, 35], "tree_summari": 59, "trees_class": [41, 59], "trend": [39, 51, 52, 58, 73, 102], "tri": [53, 89, 91], "trim": [1, 3, 5, 6, 8, 9, 10, 13, 14, 15, 41, 59, 60, 65], "trimming_rul": [1, 2, 3, 5, 6, 8, 9, 10, 13, 14, 15, 60], "trimming_threshold": [1, 2, 3, 5, 6, 8, 9, 10, 13, 14, 15, 41, 48, 59, 60, 62, 63, 65], "trm": [42, 72], "true": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 24, 29, 32, 33, 37, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 72, 73, 74, 75, 76, 77, 82, 83, 84, 87, 88, 89, 92, 93, 97, 98, 101, 104], "true_effect": [48, 49, 52, 54, 55], "true_gatet_effect": 56, "true_group_effect": 56, "truncat": [1, 2, 3, 5, 6, 8, 9, 10, 13, 14, 15, 60], "try": [57, 64], "tune": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 53, 70, 99, 101, 103], "tune_on_fold": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 72], "tune_r": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "tune_set": [42, 72], "tuner": 72, "tunergridsearch": 42, "tupl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "turn": 65, "turrel": 28, "tutori": 41, "tw": [59, 60], "twinx": 45, "two": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 37, 38, 41, 42, 46, 47, 50, 51, 57, 59, 60, 61, 62, 63, 64, 65, 67, 68, 71, 72, 73, 74, 75, 82, 88, 98, 104], "twoclass": 42, "twoearn": [41, 59, 60, 64, 104], "type": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 21, 24, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 47, 57, 58, 65, 68, 72, 75, 85, 86, 88, 89, 96, 98, 103, 104], "typic": [55, 99], "u": [8, 9, 10, 13, 14, 18, 19, 20, 21, 23, 29, 38, 39, 40, 41, 45, 47, 50, 51, 52, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 68, 73, 89, 91, 100, 104], "u_hat": [38, 47, 75], "u_i": [22, 25, 28, 29], "u_t": 20, "uehara": 102, "uhash": 42, "ulf": 102, "unambigu": 65, "uncertainti": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 54, 55, 64, 89, 94, 104], "uncondit": [41, 59, 104], "unconfounded": [65, 102], "under": [15, 38, 41, 47, 51, 59, 62, 65, 68, 73, 88, 102], "underbrac": [38, 47, 52, 68, 71], "underli": [18, 24, 41, 42, 45, 54, 55, 61, 62, 89, 91, 104], "underlin": [40, 58], "understand": 65, "undesir": 72, "unevenli": 74, "uniform": [20, 46, 48, 49, 50, 52, 62, 63, 88], "uniformli": [50, 60, 88, 98], "uniqu": [37, 45, 46, 57, 75, 89, 97], "unit": [38, 39, 51, 52, 56, 66, 73, 75, 78, 79, 103], "univari": [21, 48, 49], "univers": 102, "unknown": 73, "unlik": [41, 59, 60, 65], "unobserv": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 37, 41, 46, 59, 60, 64, 65, 73, 89, 91, 97, 104], "unpen": 39, "unstabl": [89, 91], "unter": [40, 41, 42], "untest": 65, "until": [73, 103], "untreat": [65, 73], "up": [2, 14, 41, 53, 57, 59, 60, 64, 65, 72, 73, 74, 89, 91, 100, 103, 104], "upcom": 103, "updat": [40, 55, 58, 102, 103], "update_layout": [48, 49, 53, 65], "update_trac": [48, 49], "upload": 103, "upon": [75, 103], "upper": [41, 42, 45, 47, 50, 52, 56, 60, 63, 64, 65, 72, 89, 94, 97, 104], "upper_bound": [48, 49], "upsilon": 66, "upsilon_i": 66, "upward": [41, 59, 60, 65], "upweight": 61, "url": [53, 99, 102], "us": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 34, 38, 40, 41, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 74, 75, 78, 79, 88, 89, 91, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104], "usa": 102, "usabl": 57, "usag": [39, 43, 45, 51, 56, 58, 59, 60, 64, 66, 69, 101, 103], "use_label_encod": [59, 104], "use_other_treat_as_covari": [4, 7, 69], "usecolormap": [48, 49], "user": [30, 31, 32, 33, 38, 39, 40, 41, 42, 45, 47, 56, 57, 58, 59, 64, 71, 72, 75, 88, 98, 99, 100, 101, 103, 104], "user_guid": 55, "userwarn": [59, 65], "usual": [40, 48, 49, 51, 57, 58, 64, 65, 71, 72, 74, 89, 97], "util": [31, 57, 61, 72, 103], "v": [8, 9, 11, 12, 16, 17, 23, 25, 26, 27, 29, 38, 40, 41, 45, 47, 56, 58, 59, 61, 67, 68, 71, 73, 88, 98, 99, 101, 102, 103, 104], "v108": 99, "v12": [99, 101], "v22": 42, "v23": 99, "v_": [26, 40, 58], "v_i": [22, 23, 27, 28, 29, 38, 47, 68, 73], "v_j": [88, 98], "val": [23, 74, 102], "val_list": 53, "valid": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 22, 38, 39, 40, 41, 47, 50, 51, 57, 58, 59, 60, 63, 68, 70, 71, 72, 74, 75, 77, 82, 87, 89, 91, 102, 104], "valu": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 36, 37, 38, 39, 40, 41, 42, 45, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 64, 65, 67, 70, 72, 73, 74, 77, 82, 83, 84, 87, 88, 89, 91, 94, 97, 98, 101, 103, 104], "value_count": 59, "van": 102, "vanderpla": [99, 101], "vanish": [38, 47, 68], "var": [18, 19, 20, 24, 40, 58, 61, 89, 90, 91, 95, 96, 97], "var_ep": 65, "varepsilon": [8, 18, 19, 26, 40, 58, 66, 71, 73], "varepsilon_": [26, 40, 58], "varepsilon_0": 20, "varepsilon_1": 20, "varepsilon_d": [19, 24], "varepsilon_i": [24, 25, 50, 63, 66], "vari": [41, 52, 57, 59, 61, 65], "variabl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 40, 41, 42, 43, 45, 51, 53, 56, 58, 59, 60, 64, 65, 66, 69, 71, 72, 73, 74, 75, 88, 89, 91, 94, 97, 98, 101, 102, 103, 104], "varianc": [30, 31, 40, 42, 58, 64, 65, 70, 74, 89, 91, 94, 95, 96, 97, 101], "variant": 39, "variat": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 64, 89, 91, 97], "variou": [39, 65, 72, 104], "varoquaux": [99, 101], "vasili": [65, 102], "vector": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 21, 22, 23, 25, 26, 28, 29, 37, 40, 41, 46, 51, 54, 55, 56, 58, 59, 62, 66, 73, 88, 98, 101, 103], "venv": 100, "verbos": [41, 47, 52, 57, 65], "veri": [39, 40, 42, 56, 57, 58, 65, 75, 99], "verifi": 61, "versa": [57, 61, 89, 94], "version": [18, 40, 41, 42, 59, 65, 67, 71, 88, 89, 90, 92, 93, 95, 98, 103], "versoin": 65, "versu": 55, "vertic": [40, 45, 58], "via": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 31, 39, 50, 51, 52, 53, 54, 55, 56, 57, 64, 66, 67, 69, 70, 71, 72, 73, 74, 77, 84, 88, 89, 91, 94, 97, 98, 99, 100, 101, 102, 103, 104], "viabl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "vice": [57, 61, 89, 94], "victor": [53, 65, 74, 99, 102], "view": 55, "vignett": [39, 103], "villa": [37, 46], "violet": [50, 60, 63], "vira": 102, "virtual": 100, "virtualenv": 100, "visibl": [60, 65], "visit": [99, 104], "visual": [40, 56, 58], "vol": 39, "volum": [65, 99], "voluntari": 61, "vv740": 58, "vv760g": 58, "w": [16, 17, 18, 19, 20, 27, 30, 31, 40, 53, 58, 61, 62, 67, 68, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 101], "w24678": 74, "w30302": 102, "w_": [20, 40, 58, 62], "w_1": [20, 62], "w_2": [20, 62], "w_3": 20, "w_4": 20, "w_df": 62, "w_i": [29, 51, 62, 67, 71, 74, 75, 88, 98], "wa": [40, 52, 58, 65, 103], "wager": 102, "wai": [41, 57, 59, 65, 72, 75, 100], "wander": 28, "wang": 102, "want": [37, 40, 41, 42, 46, 50, 51, 57, 58, 63, 72, 99, 100, 102], "warn": [37, 38, 39, 40, 41, 42, 47, 59, 65, 67, 72, 73, 74, 75, 88, 98, 101, 103], "wayon": 40, "we": [9, 35, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 80, 88, 89, 91, 97, 98, 100, 101, 103, 104], "weak": [89, 91, 102], "wealth": [16, 64], "websit": [41, 42, 72, 99], "wedg": [40, 58], "week": 103, "wei": [88, 98], "weight": [1, 2, 3, 8, 9, 10, 13, 14, 15, 40, 41, 42, 45, 56, 58, 59, 66, 70, 72, 75, 76, 81, 88, 89, 90, 95, 98, 103], "weights_bar": [1, 9], "weiss": [99, 101], "well": [4, 7, 38, 40, 47, 53, 57, 58, 67, 68, 69, 74, 101], "were": [41, 59, 60, 66, 104], "what": [39, 53, 57], "when": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 32, 33, 41, 51, 55, 59, 61, 73, 75, 88, 98, 99, 100, 101, 103], "whenev": [41, 59], "whera": [89, 95], "where": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 34, 35, 37, 38, 40, 41, 45, 46, 47, 50, 51, 52, 56, 58, 59, 61, 62, 63, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 94, 95, 97, 100, 101, 103, 104], "wherea": [21, 45, 51, 65, 66, 75, 81, 89, 90, 104], "whether": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 24, 29, 34, 41, 52, 57, 59, 60, 65, 69, 72, 89, 91, 103], "which": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 21, 31, 37, 38, 39, 41, 42, 44, 45, 46, 47, 51, 53, 55, 56, 57, 59, 60, 62, 64, 65, 66, 68, 69, 71, 72, 73, 75, 88, 89, 90, 91, 94, 95, 97, 98, 100, 103, 104], "while": [37, 46], "white": [40, 54, 55, 58, 65], "whitegrid": [59, 60], "whitnei": [65, 102], "who": [39, 41, 59, 65], "whole": [38, 47, 51, 68, 72, 89, 91], "width": [38, 40, 48, 49, 53], "wiki": 103, "wiksel": 102, "wild": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 88, 98], "window": 100, "wise": [54, 55], "wish": 100, "within": [40, 54, 55, 58, 62], "without": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 24, 37, 38, 46, 47, 57, 65, 68, 70, 72, 89, 91, 100, 103], "wolf": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 88, 98], "won": 65, "word": 104, "work": [32, 33, 44, 45, 55, 56, 57, 61, 64, 72, 88, 100, 102], "workflow": [99, 103], "workspac": 59, "world": 102, "worri": 65, "would": [39, 41, 42, 48, 49, 53, 57, 59, 60, 64, 65, 71, 72, 89, 97, 104], "wrapper": [39, 72], "write": [38, 39, 47, 51, 55, 66, 68, 89, 97], "written": [75, 89, 90, 95], "wrong": [57, 61], "wspace": 57, "wurd": [40, 41, 42], "www": [99, 100], "x": [1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 38, 39, 40, 41, 42, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 95, 96, 97, 98, 101, 104], "x0": [45, 61], "x1": [40, 42, 45, 51, 58, 61, 64, 65, 66, 69, 71, 72, 73, 75, 88, 89, 91, 101], "x10": [40, 42, 58, 66, 69, 72, 73, 75, 88, 101], "x100": [40, 42, 58, 66, 69, 73, 101], "x11": [40, 42, 58, 66, 69, 72, 73, 75, 88, 101], "x12": [40, 42, 58, 66, 69, 72, 73, 75, 88, 101], "x13": [40, 42, 58, 66, 69, 72, 73, 75, 88, 101], "x14": [40, 42, 58, 66, 69, 72, 73, 75, 88, 101], "x15": [40, 42, 58, 66, 69, 72, 73, 75, 88, 101], "x16": [40, 42, 58, 66, 69, 72, 73, 75, 88, 101], "x17": [40, 42, 58, 66, 69, 72, 73, 75, 88, 101], "x18": [40, 42, 58, 66, 69, 72, 73, 75, 88, 101], "x19": [40, 42, 58, 66, 69, 72, 73, 75, 88, 101], "x1x2x3x4x5x6x7x8x9x10": 40, "x2": [40, 42, 45, 51, 58, 64, 65, 66, 69, 71, 72, 73, 75, 88, 101], "x20": [40, 42, 58, 66, 69, 72, 73, 75, 88, 101], "x21": [40, 42, 58, 66, 69, 73, 101], "x22": [40, 42, 58, 66, 69, 73, 101], "x23": [40, 42, 58, 66, 69, 73, 101], "x24": [40, 42, 58, 66, 69, 73, 101], "x25": [40, 42, 58, 66, 69, 73, 101], "x26": [40, 42, 58, 66, 69, 73, 101], "x27": [40, 42, 58, 66, 69, 73, 101], "x28": [40, 42, 58, 66, 69, 73, 101], "x29": [40, 42, 58, 66, 69, 73, 101], "x2_dummi": 65, "x2_preds_control": 65, "x2_preds_treat": 65, "x3": [40, 42, 45, 51, 58, 64, 65, 66, 69, 71, 72, 73, 75, 88, 101], "x30": [40, 42, 58, 66, 69, 73, 101], "x31": [40, 42, 58, 66, 69, 73, 101], "x32": [40, 42, 58, 66, 69, 73, 101], "x33": [40, 42, 58, 66, 69, 73, 101], "x34": [40, 42, 58, 66, 69, 73, 101], "x35": [40, 42, 58, 66, 69, 73, 101], "x36": [40, 42, 58, 66, 69, 73, 101], "x37": [40, 42, 58, 66, 69, 73, 101], "x38": [40, 42, 58, 66, 69, 73, 101], "x39": [40, 42, 58, 66, 69, 73, 101], "x4": [40, 42, 45, 51, 58, 64, 65, 66, 69, 72, 73, 75, 88, 101], "x40": [40, 42, 58, 66, 69, 73, 101], "x41": [40, 42, 58, 66, 69, 73, 101], "x42": [40, 42, 58, 66, 69, 73, 101], "x43": [40, 42, 58, 66, 69, 73, 101], "x44": [40, 42, 58, 66, 69, 73, 101], "x45": [40, 42, 58, 66, 69, 73, 101], "x46": [40, 42, 58, 66, 69, 73, 101], "x47": [40, 42, 58, 66, 69, 73, 101], "x48": [40, 42, 58, 66, 69, 73, 101], "x49": [40, 42, 58, 66, 69, 73, 101], "x5": [40, 42, 58, 65, 66, 69, 72, 73, 75, 88, 101], "x50": [40, 42, 58, 66, 69, 73, 101], "x51": [40, 42, 58, 66, 69, 73, 101], "x52": [40, 42, 58, 66, 69, 73, 101], "x53": [40, 42, 58, 66, 69, 73, 101], "x54": [40, 42, 58, 66, 69, 73, 101], "x55": [40, 42, 58, 66, 69, 73, 101], "x56": [40, 42, 58, 66, 69, 73, 101], "x57": [40, 42, 58, 66, 69, 73, 101], "x58": [40, 42, 58, 66, 69, 73, 101], "x59": [40, 42, 58, 66, 69, 73, 101], "x6": [40, 42, 58, 66, 69, 72, 73, 75, 88, 101], "x60": [40, 42, 58, 66, 69, 73, 101], "x61": [40, 42, 58, 66, 69, 73, 101], "x62": [40, 42, 58, 66, 69, 73, 101], "x63": [40, 42, 58, 66, 69, 73, 101], "x64": [40, 42, 58, 59, 65, 66, 69, 73, 101], "x65": [40, 42, 58, 66, 69, 73, 101], "x66": [40, 42, 58, 66, 69, 73, 101], "x67": [40, 42, 58, 66, 69, 73, 101], "x68": [40, 42, 58, 66, 69, 73, 101], "x69": [40, 42, 58, 66, 69, 73, 101], "x7": [40, 42, 58, 66, 69, 72, 73, 75, 88, 101], "x70": [40, 42, 58, 66, 69, 73, 101], "x71": [40, 42, 58, 66, 69, 73, 101], "x72": [40, 42, 58, 66, 69, 73, 101], "x73": [40, 42, 58, 66, 69, 73, 101], "x74": [40, 42, 58, 66, 69, 73, 101], "x75": [40, 42, 58, 66, 69, 73, 101], "x76": [40, 42, 58, 66, 69, 73, 101], "x77": [40, 42, 58, 66, 69, 73, 101], "x78": [40, 42, 58, 66, 69, 73, 101], "x79": [40, 42, 58, 66, 69, 73, 101], "x8": [40, 42, 58, 66, 69, 72, 73, 75, 88, 101], "x80": [40, 42, 58, 66, 69, 73, 101], "x81": [40, 42, 58, 66, 69, 73, 101], "x82": [40, 42, 58, 66, 69, 73, 101], "x83": [40, 42, 58, 66, 69, 73, 101], "x84": [40, 42, 58, 66, 69, 73, 101], "x85": [40, 42, 58, 66, 69, 73, 101], "x86": [40, 42, 58, 66, 69, 73, 101], "x87": [40, 42, 58, 66, 69, 73, 101], "x88": [40, 42, 58, 66, 69, 73, 101], "x89": [40, 42, 58, 66, 69, 73, 101], "x9": [40, 42, 58, 66, 69, 72, 73, 75, 88, 101], "x90": [40, 42, 58, 66, 69, 73, 101], "x91": [40, 42, 58, 66, 69, 73, 101], "x92": [40, 42, 58, 66, 69, 73, 101], "x93": [40, 42, 58, 66, 69, 73, 101], "x94": [40, 42, 58, 66, 69, 73, 101], "x95": [40, 42, 58, 66, 69, 73, 101], "x96": [40, 42, 58, 66, 69, 73, 101], "x96x97x98x99x100ydcluster_var_icluster_var_jz": 40, "x97": [40, 42, 58, 66, 69, 73, 101], "x98": [40, 42, 58, 66, 69, 73, 101], "x99": [40, 42, 58, 66, 69, 73, 101], "x_": [26, 27, 38, 40, 47, 52, 58, 65, 68], "x_0": [48, 49, 52, 54, 55, 56], "x_1": [11, 12, 18, 19, 20, 24, 48, 49, 50, 52, 54, 55, 56, 63, 65, 73, 89, 91, 101], "x_1x_3": [50, 63], "x_2": [18, 19, 20, 24, 48, 49, 50, 52, 54, 55, 56, 63, 65, 89, 91], "x_3": [18, 19, 20, 24, 48, 49, 52, 54, 55, 56, 89, 91], "x_4": [18, 19, 20, 24, 48, 49, 50, 54, 55, 56, 63], "x_5": [18, 19, 24, 48, 49, 54, 55], "x_6": [48, 49, 54, 55], "x_7": [48, 49, 54, 55], "x_8": [48, 49, 54, 55], "x_9": [48, 49, 54, 55], "x_binary_control": 65, "x_binary_tr": 65, "x_col": [4, 7, 37, 40, 41, 42, 46, 53, 58, 59, 60, 62, 64, 65, 69, 72, 101, 103, 104], "x_cols_bench": 65, "x_cols_binari": 65, "x_cols_poli": 58, "x_conf": 63, "x_conf_tru": 63, "x_df": 52, "x_domain": 42, "x_i": [21, 22, 23, 25, 27, 28, 29, 38, 47, 50, 51, 54, 55, 61, 63, 66, 68, 71, 73], "x_p": [11, 12, 73, 101], "x_true": [50, 63], "x_var": 42, "xaxis_titl": [48, 49, 53, 65], "xformla": 39, "xgbclassifi": [57, 59, 61, 104], "xgboost": [38, 41, 57, 59, 61, 104], "xgbregressor": [57, 59, 61, 104], "xi": [20, 24, 73], "xi_": [88, 98], "xi_0": [26, 40, 58], "xi_i": 66, "xiaoji": 102, "xintercept": 38, "xlab": [38, 40, 41], "xlabel": [45, 48, 49, 50, 52, 54, 55, 59, 60, 63], "xlim": [38, 41], "xtick": 45, "xval": [42, 72], "xx": 47, "y": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 101, 104], "y0": [39, 45, 50, 63], "y0_cvar": 50, "y0_quant": [50, 63], "y1": [39, 50, 63], "y1_cvar": 50, "y1_quant": [50, 63], "y_": [26, 40, 51, 52, 58, 66, 73], "y_0": [5, 20, 75, 78], "y_1": [5, 20, 75, 78], "y_col": [4, 7, 37, 38, 40, 41, 42, 46, 48, 49, 53, 54, 55, 58, 59, 60, 62, 64, 67, 68, 69, 72, 73, 74, 75, 101, 103, 104], "y_df": [52, 62], "y_diff": 52, "y_i": [21, 22, 23, 25, 27, 28, 29, 38, 47, 50, 51, 61, 62, 63, 66, 68, 73], "y_pred": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 57, 72], "y_true": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 57, 72], "ya": 102, "yasui": 102, "yata": 102, "yaxis_titl": [48, 49, 53, 65], "year": 99, "yerr": [45, 52, 54, 55, 59, 61], "yet": [40, 44], "yggvpl": 58, "yintercept": 41, "ylab": [38, 40, 41], "ylabel": [45, 48, 49, 50, 52, 54, 55, 59, 60, 63], "ylim": 59, "ymax": 41, "ymin": 41, "yname": 39, "york": 102, "you": [37, 38, 46, 52, 55, 58, 64, 99, 100, 104], "your": [57, 100], "ython": 99, "yukun": 102, "yusuk": 102, "yuya": 102, "yy": 47, "z": [4, 7, 8, 10, 11, 15, 18, 19, 20, 22, 24, 25, 26, 29, 37, 40, 41, 46, 48, 49, 53, 58, 59, 63, 65, 66, 71, 73, 75, 80, 82, 84, 85, 88, 98, 103], "z1": [11, 73], "z2": 73, "z3": 73, "z4": 73, "z_": [26, 40, 58], "z_1": [18, 19, 24], "z_2": [18, 19, 24], "z_3": [18, 19, 24], "z_4": [18, 19, 24], "z_5": 18, "z_col": [4, 7, 8, 10, 11, 37, 40, 41, 46, 58, 59, 60, 66, 69, 71, 73, 103], "z_i": [25, 29, 63, 66, 73], "z_j": [18, 19, 20, 24], "z_true": 63, "zadik": 102, "zaxis_titl": [48, 49, 53], "zero": [20, 50, 51, 52, 57, 62, 63, 64, 65, 88], "zeros_lik": 63, "zeta": [8, 11, 12, 41, 59, 71, 73, 101], "zeta_": [26, 40, 58], "zeta_0": [26, 40, 58], "zeta_i": [23, 25, 27, 38, 47, 68], "zeta_j": [88, 98], "zhang": 102, "zhao": [5, 6, 18, 19, 20, 24, 39, 51, 73, 102], "zimmert": [51, 102], "zip": [48, 49], "zorder": 45, "\u03c4_x0": 61, "\u03c4_x1": 61, "\u2139": 38}, "titles": ["API reference", "doubleml.DoubleMLAPO", "doubleml.DoubleMLAPOS", "doubleml.DoubleMLCVAR", "doubleml.DoubleMLClusterData", "doubleml.DoubleMLDID", "doubleml.DoubleMLDIDCS", "doubleml.DoubleMLData", "doubleml.DoubleMLIIVM", "doubleml.DoubleMLIRM", "doubleml.DoubleMLLPQ", "doubleml.DoubleMLPLIV", "doubleml.DoubleMLPLR", "doubleml.DoubleMLPQ", "doubleml.DoubleMLQTE", "doubleml.DoubleMLSSM", "doubleml.datasets.fetch_401K", "doubleml.datasets.fetch_bonus", "doubleml.datasets.make_confounded_irm_data", "doubleml.datasets.make_confounded_plr_data", "doubleml.datasets.make_did_SZ2020", "doubleml.datasets.make_heterogeneous_data", "doubleml.datasets.make_iivm_data", "doubleml.datasets.make_irm_data", "doubleml.datasets.make_irm_data_discrete_treatments", "doubleml.datasets.make_pliv_CHS2015", "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "doubleml.datasets.make_plr_CCDDHNR2018", "doubleml.datasets.make_plr_turrell2018", "doubleml.datasets.make_ssm_data", "doubleml.double_ml_score_mixins.LinearScoreMixin", "doubleml.double_ml_score_mixins.NonLinearScoreMixin", "doubleml.utils.DMLDummyClassifier", "doubleml.utils.DMLDummyRegressor", "doubleml.utils.DoubleMLBLP", "doubleml.utils.DoubleMLPolicyTree", "doubleml.utils.gain_statistics", "R: Basic Instrumental Variables Calculation", "R: Basics of Double Machine Learning", "R: DoubleML for Difference-in-Differences", "R: Cluster Robust Double Machine Learning", "R: Impact of 401(k) on Financial Wealth", "R: Ensemble Learners and More with <code class=\"docutils literal notranslate\"><span class=\"pre\">mlr3pipelines</span></code>", "DML: Bonus Data", "Examples", "Python: Average Potential Outcome (APO) Models", "Python: Basic Instrumental Variables calculation", "Python: Basics of Double Machine Learning", "Python: Conditional Average Treatment Effects (CATEs) for IRM models", "Python: Conditional Average Treatment Effects (CATEs) for PLR models", "Python: Conditional Value at Risk of potential outcomes", "Python: Difference-in-Differences", "Python: Difference-in-Differences Pre-Testing", "Python: First Stage and Causal Estimation", "Python: Group Average Treatment Effects (GATEs) for IRM models", "Python: Group Average Treatment Effects (GATEs) for PLR models", "Python: GATE Sensitivity Analysis", "Python: Choice of learners", "Python: Cluster Robust Double Machine Learning", "Python: Impact of 401(k) on Financial Wealth", "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)", "Python: PLM and IRM for Multiple Treatments", "Python: Policy Learning with Trees", "Python: Potential Quantiles and Quantile Treatment Effects", "Python: Sensitivity Analysis", "Example: Sensitivity Analysis for Causal ML", "Python: Sample Selection Models", "<span class=\"section-number\">6. </span>Double machine learning algorithms", "<span class=\"section-number\">1. </span>The basics of double/debiased machine learning", "<span class=\"section-number\">2. </span>The data-backend DoubleMLData", "User guide", "<span class=\"section-number\">4. </span>Heterogeneous treatment effects", "<span class=\"section-number\">7. </span>Learners, hyperparameters and hyperparameter tuning", "<span class=\"section-number\">3. </span>Models", "<span class=\"section-number\">9. </span>Sample-splitting, cross-fitting and repeated cross-fitting", "<span class=\"section-number\">5. </span>Score functions", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "<span class=\"section-number\">8. </span>Variance estimation and confidence intervals", "<span class=\"section-number\">10. </span>Sensitivity analysis", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "Confidence bands and multiplier bootstrap for valid simultaneous inference", "DoubleML", "Installing DoubleML", "Getting started", "Double machine learning literature", "Release notes", "DoubleML Workflow"], "titleterms": {"0": 104, "1": [65, 104], "2": [65, 104], "2011": 65, "2023": 65, "3": [65, 104], "4": [65, 104], "401": [41, 59, 60, 64], "5": [65, 104], "6": 104, "7": 104, "A": [40, 58], "ATE": [56, 61, 66], "No": [40, 58], "One": [40, 48, 49, 58], "The": [41, 59, 61, 68, 69, 101], "acknowledg": [39, 99], "acycl": [37, 46], "addit": 61, "advanc": [72, 88], "al": 65, "algorithm": [67, 89, 99, 101], "altern": 75, "analysi": [45, 56, 64, 65, 89, 104], "api": 0, "apo": [45, 73, 75, 89], "applic": [40, 58, 64], "approach": [38, 47, 57, 68], "arah": 65, "arbitrari": 61, "arrai": 69, "asset": [41, 59], "assumpt": 65, "att": 51, "augment": 61, "averag": [41, 45, 48, 49, 54, 55, 59, 71, 73, 75, 89], "backend": [40, 41, 58, 59, 69, 101, 104], "band": [88, 98], "base": 42, "basic": [37, 38, 46, 47, 68], "benchmark": [64, 65, 89], "bia": [38, 47, 68], "binari": [73, 75], "bonu": 43, "bootstrap": [88, 98], "build": 100, "calcul": [37, 46], "callabl": 75, "case": 44, "cate": [48, 49, 61, 71], "causal": [43, 45, 53, 65, 75, 101, 104], "chernozhukov": 65, "choic": 57, "citat": 99, "class": [0, 40, 58], "cluster": [40, 58], "code": 99, "combin": 53, "compar": 57, "comparison": 39, "comput": 57, "conclus": 65, "conda": 100, "condit": [48, 49, 50, 60, 71, 75], "confid": [88, 98], "construct": 72, "contrast": 45, "coverag": [51, 53], "cran": 100, "cross": [40, 51, 58, 73, 74, 75, 89, 101], "custom": 57, "cvar": [50, 60, 71, 75], "dag": [37, 46], "data": [0, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 58, 59, 60, 62, 63, 64, 65, 66, 68, 69, 73, 75, 89, 101, 104], "datafram": 69, "dataset": [0, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 43], "debias": [38, 47, 68, 101], "defin": [40, 58], "demo": 39, "detail": 39, "develop": 100, "dgp": [38, 45, 47], "did": [39, 73], "differ": [39, 51, 52, 57, 73, 75, 88, 89], "dimension": [48, 49], "direct": [37, 46], "disclaim": 65, "distribut": 66, "dml": [40, 43, 58, 74, 101, 104], "dml1": 67, "dml2": 67, "dmldummyclassifi": 32, "dmldummyregressor": 33, "doubl": [0, 38, 40, 47, 58, 67, 68, 99, 101, 102], "double_ml_score_mixin": [30, 31], "doubleml": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 46, 59, 64, 65, 88, 99, 100, 104], "doublemlapo": [1, 2], "doublemlblp": 34, "doublemlclusterdata": [4, 40, 58], "doublemlcvar": 3, "doublemldata": [7, 41, 59, 69, 101], "doublemldid": 5, "doublemldidc": 6, "doublemliivm": 8, "doublemlirm": 9, "doublemllpq": 10, "doublemlpliv": [11, 40, 58], "doublemlplr": 12, "doublemlpolicytre": 35, "doublemlpq": 13, "doublemlqt": 14, "doublemlssm": 15, "effect": [41, 44, 48, 49, 50, 54, 55, 59, 60, 61, 63, 64, 65, 71], "elig": [41, 59], "empir": 53, "ensembl": 42, "error": [40, 58], "estim": [37, 41, 43, 46, 51, 53, 56, 59, 60, 61, 63, 64, 65, 66, 74, 75, 88, 101, 104], "et": 65, "evalu": [57, 72], "exampl": [39, 40, 44, 48, 49, 58, 64, 65], "exploit": [39, 42], "extern": [72, 74], "featur": [42, 99], "fetch_401k": 16, "fetch_bonu": 17, "figur": 61, "file": 100, "final": 39, "financi": [41, 59, 60], "first": 53, "fit": [40, 58, 74, 101], "fold": 74, "forest": 43, "formul": [65, 104], "from": [39, 42, 69, 100], "function": [0, 39, 40, 58, 75, 101], "gain_statist": 36, "gate": [54, 55, 56, 71], "gatet": 56, "gener": [0, 38, 44, 45, 47, 68, 89], "get": 101, "github": 100, "graph": [37, 46], "group": [54, 55, 71], "guid": 70, "helper": [40, 58], "heterogen": [44, 61, 71], "how": 42, "hyperparamet": 72, "identif": 65, "iivm": [41, 59, 73, 75], "impact": [41, 59, 60], "implement": [67, 75, 89], "induc": [38, 47, 68], "infer": [88, 98, 104], "initi": [40, 58], "instal": 100, "instrument": [37, 46], "integr": 39, "interact": [41, 54, 59, 62, 73, 75, 89], "interv": [88, 98], "invers": 61, "irm": [41, 43, 48, 54, 59, 61, 62, 64, 71, 73, 75, 89], "iv": [37, 41, 46, 59, 73, 75], "joint": 98, "k": [41, 59, 60, 64, 74], "lambda": 53, "lasso": [43, 53], "latest": 100, "lear": [40, 58], "learn": [0, 38, 40, 47, 58, 62, 67, 68, 71, 99, 101, 102], "learner": [42, 43, 57, 72, 101], "level": 73, "linear": [41, 55, 59, 61, 73, 75, 89], "linearscoremixin": 30, "literatur": 102, "load": [40, 43, 58, 65], "loader": 0, "local": [41, 59, 60, 63, 75], "loss": 53, "lpq": [63, 75], "lqte": [60, 63], "m": 74, "machin": [0, 38, 40, 47, 58, 67, 68, 99, 101, 102], "main": 99, "mainten": 99, "make_confounded_irm_data": 18, "make_confounded_plr_data": 19, "make_did_sz2020": 20, "make_heterogeneous_data": 21, "make_iivm_data": 22, "make_irm_data": 23, "make_irm_data_discrete_treat": 24, "make_pliv_chs2015": 25, "make_pliv_multiway_cluster_ckms2021": 26, "make_plr_ccddhnr2018": 27, "make_plr_turrell2018": 28, "make_ssm_data": 29, "mar": 66, "market": [40, 58], "matric": 69, "method": 104, "metric": 57, "minimum": 72, "miss": 66, "missing": [73, 75], "mixin": 0, "ml": [38, 39, 47, 65, 68, 104], "mlr3": 42, "mlr3extralearn": 42, "mlr3learner": 42, "mlr3pipelin": 42, "model": [0, 41, 43, 45, 48, 49, 54, 55, 59, 61, 62, 65, 66, 71, 73, 74, 75, 88, 89, 101, 104], "modul": [0, 43], "more": 42, "motiv": [40, 58], "multipl": [45, 61, 73], "multipli": [88, 98], "naiv": [37, 46], "net": [41, 59], "neyman": [75, 101], "nonignor": [66, 73, 75], "nonlinearscoremixin": 31, "nonrespons": [66, 73, 75], "note": 103, "nuisanc": 101, "object": [40, 58, 64], "orthogon": [38, 47, 68, 75, 101], "out": [38, 47, 68], "outcom": [45, 50, 51, 66, 71, 73, 75, 89], "over": 88, "overcom": [38, 47, 68], "overfit": [38, 47, 68], "overlap": 61, "packag": [39, 41, 59, 100], "panel": [51, 73, 75, 89], "paramet": [42, 43, 75], "partial": [38, 41, 47, 55, 59, 61, 68, 73, 75, 89], "particip": [41, 59], "partit": 74, "penalti": 53, "perform": [39, 61], "pip": 100, "pipelin": 72, "pliv": [73, 75], "plm": [61, 73, 75], "plot": [40, 58], "plr": [41, 43, 49, 55, 59, 71, 73, 75, 89], "polici": [62, 71], "potenti": [45, 50, 60, 63, 71, 73, 75, 89], "pq": [63, 71, 75], "pre": 52, "predict": [39, 72], "preprocess": 42, "problem": 104, "process": [38, 40, 45, 47, 58, 68], "product": [40, 58], "propens": 61, "provid": 74, "python": [44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 72, 100], "qte": [63, 71], "qualiti": 53, "quantil": [60, 63, 71, 75], "r": [37, 38, 39, 40, 41, 42, 44, 72, 100], "random": [43, 66, 73, 75], "rank": 61, "real": [40, 58], "refer": [0, 37, 39, 40, 42, 46, 53, 58, 61, 65, 68, 72, 74, 88, 98, 99, 101], "regress": [41, 54, 55, 59, 62, 73, 75, 89], "regular": [38, 47, 68], "releas": [100, 103], "remark": 39, "remov": [38, 47, 68], "repeat": [51, 73, 74, 75, 89], "repetit": 74, "requir": 72, "respect": [40, 58], "result": [40, 41, 58, 59, 61], "risk": [50, 60, 71, 75], "robust": [40, 58], "sampl": [38, 47, 66, 68, 73, 74, 75], "sandbox": 44, "score": [0, 38, 47, 61, 68, 75, 101], "section": [51, 73, 75, 89], "select": [66, 73, 75], "sensit": [45, 56, 64, 65, 89, 104], "set": [42, 72], "simpl": [38, 47, 68], "simul": [37, 40, 46, 51, 58, 64], "simultan": [88, 98], "singl": 45, "sourc": [99, 100], "specif": [89, 104], "specifi": [43, 72, 75], "split": [38, 47, 68, 74], "ssm": 73, "stage": 53, "standard": [40, 57, 58], "start": 101, "studi": 44, "summari": [41, 59, 61], "test": 52, "theori": 89, "time": 57, "treatment": [41, 48, 49, 50, 54, 55, 59, 60, 61, 63, 71, 73], "tree": [62, 71], "tune": [42, 72], "two": [40, 48, 49, 58], "under": [61, 66], "up": 42, "us": [37, 39, 42, 43, 46, 72], "user": 70, "util": [0, 32, 33, 34, 35, 36], "v": 53, "valid": [88, 98], "valu": [50, 60, 71, 75], "vanderweel": 65, "variabl": [37, 46], "varianc": 88, "version": 100, "via": 75, "wai": [40, 58], "wealth": [41, 59, 60], "weight": [61, 71], "whl": 100, "without": 74, "workflow": 104, "zero": [40, 58]}})