Search.setIndex({"alltitles": {"(One-Way) Cluster Robust Double Machine Learing": [[34, "(One-Way)-Cluster-Robust-Double-Machine-Learing"], [51, "(One-Way)-Cluster-Robust-Double-Machine-Learing"]], "0. Problem Formulation": [[76, "problem-formulation"]], "1. Data-Backend": [[76, "data-backend"]], "2. Causal Model": [[76, "causal-model"]], "3. ML Methods": [[76, "ml-methods"]], "4. DML Specifications": [[76, "dml-specifications"]], "5. Estimation": [[76, "estimation"]], "6. Inference": [[76, "inference"]], "7. Sensitivity Analysis": [[76, "sensitivity-analysis"]], "A Motivating Example: Two-Way Cluster Robust DML": [[34, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"], [51, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"]], "API reference": [[0, "api-reference"]], "ATE Estimation and Sensitivity": [[49, "ATE-Estimation-and-Sensitivity"]], "ATE estimates distribution": [[58, "ATE-estimates-distribution"], [58, "id3"]], "ATTE Estimation": [[44, "ATTE-Estimation"], [44, "id2"]], "Acknowledgements": [[71, "acknowledgements"]], "Additional Results: CATE estimates": [[54, "Additional-Results:-CATE-estimates"]], "Advanced: External Predictions": [[64, "advanced-external-predictions"]], "Algorithm DML1": [[59, "algorithm-dml1"]], "Algorithm DML2": [[59, "algorithm-dml2"]], "Application Results": [[34, "Application-Results"], [51, "Application-Results"]], "Application: 401(k)": [[57, "Application:-401(k)"]], "Benchmarking": [[69, "benchmarking"]], "Benchmarking Analysis": [[57, "Benchmarking-Analysis"]], "CATEs for IRM models": [[63, "cates-for-irm-models"]], "CATEs for PLR models": [[63, "cates-for-plr-models"]], "CVaR Treatment Effects": [[43, "CVaR-Treatment-Effects"]], "CVaR of potential outcomes": [[63, "cvar-of-potential-outcomes"]], "CVaR treatment effects": [[63, "cvar-treatment-effects"]], "Causal estimation vs. lasso penalty \\lambda": [[46, "Causal-estimation-vs.-lasso-penalty-\\lambda"]], "Citation": [[71, "citation"]], "Cluster Robust Cross Fitting": [[34, "Cluster-Robust-Cross-Fitting"], [51, "Cluster-Robust-Cross-Fitting"]], "Cluster Robust Standard Errors": [[34, "Cluster-Robust-Standard-Errors"], [51, "Cluster-Robust-Standard-Errors"]], "Clustering and double machine learning": [[34, "Clustering-and-double-machine-learning"], [51, "Clustering-and-double-machine-learning"]], "Combined loss vs. lasso penalty \\lambda": [[46, "Combined-loss-vs.-lasso-penalty-\\lambda"]], "Comparing different learners": [[50, "Comparing-different-learners"]], "Computation time": [[50, "Computation-time"]], "Conditional Value at Risk (CVaR)": [[43, "Conditional-Value-at-Risk-(CVaR)"]], "Conditional average treatment effects (CATEs)": [[63, "conditional-average-treatment-effects-cates"]], "Conditional value at risk (CVaR)": [[63, "conditional-value-at-risk-cvar"], [67, "conditional-value-at-risk-cvar"]], "Confidence bands and multiplier bootstrap for valid simultaneous inference": [[68, "confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference"], [70, "confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference"]], "Coverage Simulation": [[44, "Coverage-Simulation"], [44, "id3"]], "Cross-fitting with K folds": [[66, "cross-fitting-with-k-folds"]], "Cross-fitting, DML algorithms and Neyman-orthogonal score functions": [[73, "cross-fitting-dml-algorithms-and-neyman-orthogonal-score-functions"]], "Custom evaluation metrics": [[50, "Custom-evaluation-metrics"]], "DML: Bonus Data": [[37, "DML:-Bonus-Data"]], "Data": [[35, "Data"], [41, "Data"], [42, "Data"], [43, "Data"], [44, "Data"], [44, "id1"], [47, "Data"], [48, "Data"], [49, "Data"], [52, "Data"], [53, "Data"], [55, "Data"], [56, "Data"], [56, "id1"], [57, "Data"], [58, "Data"], [58, "id1"], [73, "data"]], "Data Generating Process (DGP)": [[33, "Data-Generating-Process-(DGP)"], [40, "Data-Generating-Process-(DGP)"]], "Data Simulation": [[32, "Data-Simulation"], [39, "Data-Simulation"]], "Data and Effect Estimation": [[57, "Data-and-Effect-Estimation"]], "Data generating process": [[60, "data-generating-process"]], "Data preprocessing": [[36, "Data-preprocessing"]], "Data-Backend for Cluster Data": [[34, "Data-Backend-for-Cluster-Data"], [51, "Data-Backend-for-Cluster-Data"]], "Dataset generators": [[0, "dataset-generators"]], "Dataset loaders": [[0, "dataset-loaders"]], "Datasets module": [[0, "datasets-module"]], "Define Helper Functions for Plotting": [[34, "Define-Helper-Functions-for-Plotting"], [51, "Define-Helper-Functions-for-Plotting"]], "Difference-in-Differences Models (DID)": [[65, "difference-in-differences-models-did"]], "Difference-in-Differences for Panel Data": [[67, "difference-in-differences-for-panel-data"], [69, "difference-in-differences-for-panel-data"]], "Difference-in-Differences for repeated cross-sections": [[67, "difference-in-differences-for-repeated-cross-sections"], [69, "difference-in-differences-for-repeated-cross-sections"]], "Double Machine Learning Algorithm": [[71, "double-machine-learning-algorithm"]], "Double machine learning algorithms": [[59, "double-machine-learning-algorithms"]], "Double machine learning data class": [[0, "double-machine-learning-data-class"]], "Double machine learning literature": [[74, "double-machine-learning-literature"]], "Double machine learning models": [[0, "double-machine-learning-models"]], "Double/debiased machine learning": [[33, "Double/debiased-machine-learning"], [40, "Double/debiased-machine-learning"], [60, "double-debiased-machine-learning"]], "DoubleML": [[71, "doubleml"]], "DoubleML Object": [[57, "DoubleML-Object"]], "DoubleML Workflow": [[76, "doubleml-workflow"]], "DoubleMLData from arrays and matrices": [[61, "doublemldata-from-arrays-and-matrices"]], "DoubleMLData from dataframes": [[61, "doublemldata-from-dataframes"]], "Effect Heterogeneity": [[38, "effect-heterogeneity"]], "Empirical coverage vs. lasso penalty \\lambda": [[46, "Empirical-coverage-vs.-lasso-penalty-\\lambda"]], "Estimate DML models without sample-splitting": [[66, "estimate-dml-models-without-sample-splitting"]], "Estimate double/debiased machine learning models": [[73, "estimate-double-debiased-machine-learning-models"]], "Estimating Potential Quantiles and Quantile Treatment Effects": [[53, "Estimating-Potential-Quantiles-and-Quantile-Treatment-Effects"]], "Estimating local quantile treatment effects (LQTEs)": [[53, "Estimating-local-quantile-treatment-effects-(LQTEs)"]], "Estimating the Average Treatment Effect of 401(k) Eligibility on Net Financial Assets": [[35, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"], [52, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"]], "Estimating the treatment effect on the Conditional Value a Risk (CVaR)": [[53, "Estimating-the-treatment-effect-on-the-Conditional-Value-a-Risk-(CVaR)"]], "Estimation": [[58, "Estimation"], [58, "id2"]], "Estimation quality vs. \\lambda": [[46, "Estimation-quality-vs.-\\lambda"]], "Evaluate learners": [[64, "evaluate-learners"]], "Examples": [[38, "examples"]], "Externally provide a sample splitting / partition": [[66, "externally-provide-a-sample-splitting-partition"]], "GATE Estimation and Sensitivity": [[49, "GATE-Estimation-and-Sensitivity"]], "GATET Estimation and Sensitivity": [[49, "GATET-Estimation-and-Sensitivity"]], "GATEs for IRM models": [[63, "gates-for-irm-models"]], "GATEs for PLR models": [[63, "gates-for-plr-models"]], "General Examples": [[38, "general-examples"]], "General algorithm": [[69, "general-algorithm"]], "Getting started": [[73, "getting-started"]], "Group Average Treatment Effects (GATEs)": [[47, "Group-Average-Treatment-Effects-(GATEs)"], [48, "Group-Average-Treatment-Effects-(GATEs)"]], "Group average treatment effects (GATEs)": [[63, "group-average-treatment-effects-gates"]], "Heterogeneous treatment effects": [[63, "heterogeneous-treatment-effects"]], "How to exploit more features of mlr3pipelines in DoubleML": [[36, "How-to-exploit-more-features-of-mlr3pipelines-in-DoubleML"]], "Hyperparameter tuning": [[64, "hyperparameter-tuning"], [64, "id16"]], "Hyperparameter tuning with pipelines": [[64, "hyperparameter-tuning-with-pipelines"]], "Implementation": [[69, "implementation"]], "Implementation of the double machine learning algorithms": [[59, "implementation-of-the-double-machine-learning-algorithms"]], "Implementation of the score function and the estimate of the causal parameter": [[67, "implementation-of-the-score-function-and-the-estimate-of-the-causal-parameter"]], "Implemented Neyman orthogonal score functions": [[67, "implemented-neyman-orthogonal-score-functions"]], "Initialize DoubleMLClusterData object": [[34, "Initialize-DoubleMLClusterData-object"], [51, "Initialize-DoubleMLClusterData-object"]], "Initialize the objects of class DoubleMLPLIV": [[34, "Initialize-the-objects-of-class-DoubleMLPLIV"], [51, "Initialize-the-objects-of-class-DoubleMLPLIV"]], "Installing DoubleML": [[72, "installing-doubleml"]], "Instrumental Variables Directed Acyclic Graph (IV - DAG)": [[32, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"], [39, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"]], "Interactive IV Model (IIVM)": [[35, "Interactive-IV-Model-(IIVM)"], [52, "Interactive-IV-Model-(IIVM)"]], "Interactive IV model (IIVM)": [[65, "interactive-iv-model-iivm"], [67, "interactive-iv-model-iivm"]], "Interactive Regression Model (IRM)": [[35, "Interactive-Regression-Model-(IRM)"], [47, "Interactive-Regression-Model-(IRM)"], [52, "Interactive-Regression-Model-(IRM)"], [55, "Interactive-Regression-Model-(IRM)"]], "Interactive regression model (IRM)": [[65, "interactive-regression-model-irm"], [67, "interactive-regression-model-irm"], [69, "interactive-regression-model-irm"]], "Learners to estimate the nuisance models": [[73, "learners-to-estimate-the-nuisance-models"]], "Learners, hyperparameters and hyperparameter tuning": [[64, "learners-hyperparameters-and-hyperparameter-tuning"]], "Load and Process Data": [[34, "Load-and-Process-Data"], [51, "Load-and-Process-Data"]], "Load bonus data using the dml datasets module": [[37, "Load-bonus-data-using-the-dml-datasets-module"]], "Local Average Treatment Effects of 401(k) Participation on Net Financial Assets": [[35, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"], [52, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"]], "Local Potential Quantile Estimation": [[56, "Local-Potential-Quantile-Estimation"]], "Local Potential Quantiles (LPQs)": [[56, "Local-Potential-Quantiles-(LPQs)"]], "Local Quantile Treatment Effects (LQTEs)": [[56, "Local-Quantile-Treatment-Effects-(LQTEs)"]], "Local potential quantiles (LPQs)": [[67, "local-potential-quantiles-lpqs"]], "Main Features": [[71, "main-features"]], "Minimum requirements for learners": [[64, "minimum-requirements-for-learners"], [64, "id2"]], "Missingness at Random": [[65, "missingness-at-random"], [67, "missingness-at-random"]], "Model-specific implementations": [[69, "model-specific-implementations"]], "Models": [[65, "models"]], "Motivation": [[34, "Motivation"], [51, "Motivation"]], "Multiplier bootstrap and joint confidence intervals": [[70, "multiplier-bootstrap-and-joint-confidence-intervals"]], "Naive estimation": [[32, "Naive-estimation"], [39, "Naive-estimation"]], "No Clustering / Zero-Way Clustering": [[34, "No-Clustering-/-Zero-Way-Clustering"], [51, "No-Clustering-/-Zero-Way-Clustering"]], "Nonignorable Nonresponse": [[65, "nonignorable-nonresponse"], [67, "nonignorable-nonresponse"]], "One-Way Clustering with Respect to the Market": [[34, "One-Way-Clustering-with-Respect-to-the-Market"], [51, "One-Way-Clustering-with-Respect-to-the-Market"]], "One-Way Clustering with Respect to the Product": [[34, "One-Way-Clustering-with-Respect-to-the-Product"], [51, "One-Way-Clustering-with-Respect-to-the-Product"]], "One-dimensional Example": [[41, "One-dimensional-Example"], [42, "One-dimensional-Example"]], "Outcome missing at random (MAR)": [[58, "Outcome-missing-at-random-(MAR)"]], "Outcome missing under nonignorable nonresponse": [[58, "Outcome-missing-under-nonignorable-nonresponse"]], "Overcoming regularization bias by orthogonalization": [[33, "Overcoming-regularization-bias-by-orthogonalization"], [40, "Overcoming-regularization-bias-by-orthogonalization"], [60, "overcoming-regularization-bias-by-orthogonalization"]], "Panel Data (Repeated Outcomes)": [[44, "Panel-Data-(Repeated-Outcomes)"]], "Panel data": [[65, "panel-data"]], "Parameter tuning": [[36, "Parameter-tuning"]], "Partialling out score": [[33, "Partialling-out-score"], [40, "Partialling-out-score"], [60, "partialling-out-score"]], "Partially Linear Regression Model (PLR)": [[35, "Partially-Linear-Regression-Model-(PLR)"], [48, "Partially-Linear-Regression-Model-(PLR)"], [52, "Partially-Linear-Regression-Model-(PLR)"]], "Partially linear IV regression model (PLIV)": [[65, "partially-linear-iv-regression-model-pliv"], [67, "partially-linear-iv-regression-model-pliv"]], "Partially linear regression model (PLR)": [[65, "partially-linear-regression-model-plr"], [67, "partially-linear-regression-model-plr"], [69, "partially-linear-regression-model-plr"]], "Policy Learning with Trees": [[55, "Policy-Learning-with-Trees"], [63, "policy-learning-with-trees"]], "Potential Quantile Estimation": [[56, "Potential-Quantile-Estimation"]], "Potential Quantiles (PQs)": [[56, "Potential-Quantiles-(PQs)"]], "Potential quantiles (PQs)": [[63, "potential-quantiles-pqs"], [67, "potential-quantiles-pqs"]], "Python: Basic Instrumental Variables calculation": [[39, "Python:-Basic-Instrumental-Variables-calculation"]], "Python: Basics of Double Machine Learning": [[40, "Python:-Basics-of-Double-Machine-Learning"]], "Python: Building the package from source": [[72, "python-building-the-package-from-source"]], "Python: Case studies": [[38, "python-case-studies"]], "Python: Choice of learners": [[50, "Python:-Choice-of-learners"]], "Python: Cluster Robust Double Machine Learning": [[51, "Python:-Cluster-Robust-Double-Machine-Learning"]], "Python: Conditional Average Treatment Effects (CATEs) for IRM models": [[41, "Python:-Conditional-Average-Treatment-Effects-(CATEs)-for-IRM-models"]], "Python: Conditional Average Treatment Effects (CATEs) for PLR models": [[42, "Python:-Conditional-Average-Treatment-Effects-(CATEs)-for-PLR-models"]], "Python: Conditional Value at Risk of potential outcomes": [[43, "Python:-Conditional-Value-at-Risk-of-potential-outcomes"]], "Python: Difference-in-Differences": [[44, "Python:-Difference-in-Differences"]], "Python: Difference-in-Differences Pre-Testing": [[45, "Python:-Difference-in-Differences-Pre-Testing"]], "Python: First Stage and Causal Estimation": [[46, "Python:-First-Stage-and-Causal-Estimation"]], "Python: GATE Sensitivity Analysis": [[49, "Python:-GATE-Sensitivity-Analysis"]], "Python: Group Average Treatment Effects (GATEs) for IRM models": [[47, "Python:-Group-Average-Treatment-Effects-(GATEs)-for-IRM-models"]], "Python: Group Average Treatment Effects (GATEs) for PLR models": [[48, "Python:-Group-Average-Treatment-Effects-(GATEs)-for-PLR-models"]], "Python: Impact of 401(k) on Financial Wealth": [[52, "Python:-Impact-of-401(k)-on-Financial-Wealth"]], "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)": [[53, "Python:-Impact-of-401(k)-on-Financial-Wealth-(Quantile-Effects)"]], "Python: Installing DoubleML": [[72, "python-installing-doubleml"]], "Python: Installing a released version from a .whl file": [[72, "python-installing-a-released-version-from-a-whl-file"]], "Python: Installing the latest release from pip or conda": [[72, "python-installing-the-latest-release-from-pip-or-conda"]], "Python: Learners and hyperparameters": [[64, "python-learners-and-hyperparameters"]], "Python: PLM and IRM for Multiple Treatments": [[54, "Python:-PLM-and-IRM-for-Multiple-Treatments"]], "Python: Policy Learning with Trees": [[55, "Python:-Policy-Learning-with-Trees"]], "Python: Potential Quantiles and Quantile Treatment Effects": [[56, "Python:-Potential-Quantiles-and-Quantile-Treatment-Effects"]], "Python: Sample Selection Models": [[58, "Python:-Sample-Selection-Models"]], "Python: Sensitivity Analysis": [[57, "Python:-Sensitivity-Analysis"]], "Quantile Treatment Effects (QTEs)": [[56, "Quantile-Treatment-Effects-(QTEs)"]], "Quantile treatment effects (QTEs)": [[63, "quantile-treatment-effects-qtes"]], "Quantiles": [[63, "quantiles"]], "R: Basic Instrumental Variables Calculation": [[32, "R:-Basic-Instrumental-Variables-Calculation"]], "R: Basics of Double Machine Learning": [[33, "R:-Basics-of-Double-Machine-Learning"]], "R: Case studies": [[38, "r-case-studies"]], "R: Cluster Robust Double Machine Learning": [[34, "R:-Cluster-Robust-Double-Machine-Learning"]], "R: Ensemble Learners and More with mlr3pipelines": [[36, "R:-Ensemble-Learners-and-More-with-mlr3pipelines"]], "R: Impact of 401(k) on Financial Wealth": [[35, "R:-Impact-of-401(k)-on-Financial-Wealth"]], "R: Installing DoubleML": [[72, "r-installing-doubleml"]], "R: Installing the development version from GitHub": [[72, "r-installing-the-development-version-from-github"]], "R: Installing the latest release from CRAN": [[72, "r-installing-the-latest-release-from-cran"]], "R: Learners and hyperparameters": [[64, "r-learners-and-hyperparameters"]], "Ranking Treatment Effects under Treatment Propensity and Treatment Effect Heterogeneity": [[54, "Ranking-Treatment-Effects-under-Treatment-Propensity-and-Treatment-Effect-Heterogeneity"]], "Real-Data Application": [[34, "Real-Data-Application"], [51, "Real-Data-Application"]], "References": [[32, "References"], [34, "References"], [36, "References"], [39, "References"], [46, "References"], [51, "References"], [54, "References"], [60, "references"], [64, "references"], [66, "references"], [68, "references"], [70, "references"], [71, "references"], [73, "references"]], "Regularization Bias in Simple ML-Approaches": [[33, "Regularization-Bias-in-Simple-ML-Approaches"], [40, "Regularization-Bias-in-Simple-ML-Approaches"]], "Regularization bias in simple ML-approaches": [[60, "regularization-bias-in-simple-ml-approaches"]], "Release notes": [[75, "release-notes"]], "Repeated Cross-Sectional Data": [[44, "Repeated-Cross-Sectional-Data"]], "Repeated cross-fitting with K folds and M repetitions": [[66, "repeated-cross-fitting-with-k-folds-and-m-repetitions"]], "Repeated cross-sections": [[65, "repeated-cross-sections"]], "Sample Selection Models (SSM)": [[65, "sample-selection-models-ssm"]], "Sample splitting to remove bias induced by overfitting": [[33, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [40, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [60, "sample-splitting-to-remove-bias-induced-by-overfitting"]], "Sample-splitting without cross-fitting": [[66, "sample-splitting-without-cross-fitting"]], "Sample-splitting, cross-fitting and repeated cross-fitting": [[66, "sample-splitting-cross-fitting-and-repeated-cross-fitting"]], "Sandbox": [[38, "sandbox"]], "Score functions": [[67, "score-functions"]], "Score mixin classes for double machine learning models": [[0, "score-mixin-classes-for-double-machine-learning-models"]], "Sensitivity Analysis": [[57, "Sensitivity-Analysis"], [57, "id1"]], "Sensitivity Analysis with IRM": [[57, "Sensitivity-Analysis-with-IRM"]], "Sensitivity analysis": [[69, "sensitivity-analysis"]], "Set up learners based on mlr3pipelines": [[36, "Set-up-learners-based-on-mlr3pipelines"]], "Simulate two-way cluster data": [[34, "Simulate-two-way-cluster-data"], [51, "Simulate-two-way-cluster-data"]], "Simulation Example": [[57, "Simulation-Example"]], "Simultaneous inference over different DoubleML models (advanced)": [[68, "simultaneous-inference-over-different-doubleml-models-advanced"]], "Source code and maintenance": [[71, "source-code-and-maintenance"]], "Specify learner and estimate causal parameter: IRM model with Lasso as learner": [[37, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: IRM model with random forest as learner": [[37, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-random-forest-as-learner"]], "Specify learner and estimate causal parameter: PLR model with Lasso as learner": [[37, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: PLR model with random forest as learner": [[37, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-random-forest-as-learner"]], "Specifying alternative score functions via callables": [[67, "specifying-alternative-score-functions-via-callables"]], "Specifying learners and set hyperparameters": [[64, "specifying-learners-and-set-hyperparameters"], [64, "id9"]], "Standard approach": [[50, "Standard-approach"]], "Summary Figure": [[54, "Summary-Figure"]], "Summary of Results": [[35, "Summary-of-Results"], [52, "Summary-of-Results"]], "The Augmented Inverse Propensity Weighting Model estimates the ATE under arbitrary effect and propensity score heterogeneity": [[54, "The-Augmented-Inverse-Propensity-Weighting-Model-estimates-the-ATE-under-arbitrary-effect-and-propensity-score-heterogeneity"]], "The Data Backend: DoubleMLData": [[35, "The-Data-Backend:-DoubleMLData"], [52, "The-Data-Backend:-DoubleMLData"]], "The DoubleML package": [[35, "The-DoubleML-package"], [52, "The-DoubleML-package"]], "The Partially Linear Model performs overlap weighting": [[54, "The-Partially-Linear-Model-performs-overlap-weighting"]], "The basics of double/debiased machine learning": [[60, "the-basics-of-double-debiased-machine-learning"]], "The causal model": [[73, "the-causal-model"]], "The data-backend DoubleMLData": [[61, "the-data-backend-doublemldata"], [73, "the-data-backend-doublemldata"]], "Theory": [[69, "theory"]], "Two-Dimensional Example": [[41, "Two-Dimensional-Example"], [42, "Two-Dimensional-Example"]], "Two-Way Clustering with Respect to Product and Market": [[34, "Two-Way-Clustering-with-Respect-to-Product-and-Market"], [51, "Two-Way-Clustering-with-Respect-to-Product-and-Market"]], "Use ensemble learners based on mlr3pipelines": [[36, "Use-ensemble-learners-based-on-mlr3pipelines"]], "User guide": [[62, "user-guide"]], "Using DoubleML": [[32, "Using-DoubleML"], [39, "Using-DoubleML"]], "Using learners from mlr3, mlr3learners and mlr3extralearners": [[36, "Using-learners-from-mlr3,-mlr3learners-and-mlr3extralearners"]], "Using pipelines to construct learners": [[64, "using-pipelines-to-construct-learners"]], "Utility classes": [[0, "utility-classes"]], "Utility classes and functions": [[0, "utility-classes-and-functions"]], "Utility functions": [[0, "utility-functions"]], "Variance estimation": [[68, "variance-estimation"]], "Variance estimation and confidence intervals": [[68, "variance-estimation-and-confidence-intervals"]], "Weighted Average Treatment Effects": [[63, "weighted-average-treatment-effects"]], "doubleml.DoubleMLBLP": [[1, "doubleml-doublemlblp"]], "doubleml.DoubleMLCVAR": [[2, "doubleml-doublemlcvar"]], "doubleml.DoubleMLClusterData": [[3, "doubleml-doublemlclusterdata"]], "doubleml.DoubleMLDID": [[4, "doubleml-doublemldid"]], "doubleml.DoubleMLDIDCS": [[5, "doubleml-doublemldidcs"]], "doubleml.DoubleMLData": [[6, "doubleml-doublemldata"]], "doubleml.DoubleMLIIVM": [[7, "doubleml-doublemliivm"]], "doubleml.DoubleMLIRM": [[8, "doubleml-doublemlirm"]], "doubleml.DoubleMLLPQ": [[9, "doubleml-doublemllpq"]], "doubleml.DoubleMLPLIV": [[10, "doubleml-doublemlpliv"]], "doubleml.DoubleMLPLR": [[11, "doubleml-doublemlplr"]], "doubleml.DoubleMLPQ": [[12, "doubleml-doublemlpq"]], "doubleml.DoubleMLQTE": [[13, "doubleml-doublemlqte"]], "doubleml.datasets.fetch_401K": [[14, "doubleml-datasets-fetch-401k"]], "doubleml.datasets.fetch_bonus": [[15, "doubleml-datasets-fetch-bonus"]], "doubleml.datasets.make_confounded_irm_data": [[16, "doubleml-datasets-make-confounded-irm-data"]], "doubleml.datasets.make_confounded_plr_data": [[17, "doubleml-datasets-make-confounded-plr-data"]], "doubleml.datasets.make_did_SZ2020": [[18, "doubleml-datasets-make-did-sz2020"]], "doubleml.datasets.make_heterogeneous_data": [[19, "doubleml-datasets-make-heterogeneous-data"]], "doubleml.datasets.make_iivm_data": [[20, "doubleml-datasets-make-iivm-data"]], "doubleml.datasets.make_irm_data": [[21, "doubleml-datasets-make-irm-data"]], "doubleml.datasets.make_pliv_CHS2015": [[22, "doubleml-datasets-make-pliv-chs2015"]], "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021": [[23, "doubleml-datasets-make-pliv-multiway-cluster-ckms2021"]], "doubleml.datasets.make_plr_CCDDHNR2018": [[24, "doubleml-datasets-make-plr-ccddhnr2018"]], "doubleml.datasets.make_plr_turrell2018": [[25, "doubleml-datasets-make-plr-turrell2018"]], "doubleml.datasets.make_ssm_data": [[26, "doubleml-datasets-make-ssm-data"]], "doubleml.double_ml_score_mixins.LinearScoreMixin": [[27, "doubleml-double-ml-score-mixins-linearscoremixin"]], "doubleml.double_ml_score_mixins.NonLinearScoreMixin": [[28, "doubleml-double-ml-score-mixins-nonlinearscoremixin"]], "doubleml.utils.DMLDummyClassifier": [[29, "doubleml-utils-dmldummyclassifier"]], "doubleml.utils.DMLDummyRegressor": [[30, "doubleml-utils-dmldummyregressor"]], "doubleml.utils.gain_statistics": [[31, "doubleml-utils-gain-statistics"]]}, "docnames": ["api/api", "api/generated/doubleml.DoubleMLBLP", "api/generated/doubleml.DoubleMLCVAR", "api/generated/doubleml.DoubleMLClusterData", "api/generated/doubleml.DoubleMLDID", "api/generated/doubleml.DoubleMLDIDCS", "api/generated/doubleml.DoubleMLData", "api/generated/doubleml.DoubleMLIIVM", "api/generated/doubleml.DoubleMLIRM", "api/generated/doubleml.DoubleMLLPQ", "api/generated/doubleml.DoubleMLPLIV", "api/generated/doubleml.DoubleMLPLR", "api/generated/doubleml.DoubleMLPQ", "api/generated/doubleml.DoubleMLQTE", "api/generated/doubleml.datasets.fetch_401K", "api/generated/doubleml.datasets.fetch_bonus", "api/generated/doubleml.datasets.make_confounded_irm_data", "api/generated/doubleml.datasets.make_confounded_plr_data", "api/generated/doubleml.datasets.make_did_SZ2020", "api/generated/doubleml.datasets.make_heterogeneous_data", "api/generated/doubleml.datasets.make_iivm_data", "api/generated/doubleml.datasets.make_irm_data", "api/generated/doubleml.datasets.make_pliv_CHS2015", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018", "api/generated/doubleml.datasets.make_plr_turrell2018", "api/generated/doubleml.datasets.make_ssm_data", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin", "api/generated/doubleml.utils.DMLDummyClassifier", "api/generated/doubleml.utils.DMLDummyRegressor", "api/generated/doubleml.utils.gain_statistics", "examples/R_double_ml_basic_iv", "examples/R_double_ml_basics", "examples/R_double_ml_multiway_cluster", "examples/R_double_ml_pension", "examples/R_double_ml_pipeline", "examples/double_ml_bonus_data", "examples/index", "examples/py_double_ml_basic_iv", "examples/py_double_ml_basics", "examples/py_double_ml_cate", "examples/py_double_ml_cate_plr", "examples/py_double_ml_cvar", "examples/py_double_ml_did", "examples/py_double_ml_did_pretest", "examples/py_double_ml_firststage", "examples/py_double_ml_gate", "examples/py_double_ml_gate_plr", "examples/py_double_ml_gate_sensitivity", "examples/py_double_ml_learner", "examples/py_double_ml_multiway_cluster", "examples/py_double_ml_pension", "examples/py_double_ml_pension_qte", "examples/py_double_ml_plm_irm_hetfx", "examples/py_double_ml_policy_tree", "examples/py_double_ml_pq", "examples/py_double_ml_sensitivity", "examples/py_double_ml_ssm", "guide/algorithms", "guide/basics", "guide/data_backend", "guide/guide", "guide/heterogeneity", "guide/learners", "guide/models", "guide/resampling", "guide/scores", "guide/se_confint", "guide/sensitivity", "guide/sim_inf", "index", "intro/install", "intro/intro", "literature/literature", "release/release", "workflow/workflow"], "envversion": {"nbsphinx": 4, "sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["api/api.rst", "api/generated/doubleml.DoubleMLBLP.rst", "api/generated/doubleml.DoubleMLCVAR.rst", "api/generated/doubleml.DoubleMLClusterData.rst", "api/generated/doubleml.DoubleMLDID.rst", "api/generated/doubleml.DoubleMLDIDCS.rst", "api/generated/doubleml.DoubleMLData.rst", "api/generated/doubleml.DoubleMLIIVM.rst", "api/generated/doubleml.DoubleMLIRM.rst", "api/generated/doubleml.DoubleMLLPQ.rst", "api/generated/doubleml.DoubleMLPLIV.rst", "api/generated/doubleml.DoubleMLPLR.rst", "api/generated/doubleml.DoubleMLPQ.rst", "api/generated/doubleml.DoubleMLQTE.rst", "api/generated/doubleml.datasets.fetch_401K.rst", "api/generated/doubleml.datasets.fetch_bonus.rst", "api/generated/doubleml.datasets.make_confounded_irm_data.rst", "api/generated/doubleml.datasets.make_confounded_plr_data.rst", "api/generated/doubleml.datasets.make_did_SZ2020.rst", "api/generated/doubleml.datasets.make_heterogeneous_data.rst", "api/generated/doubleml.datasets.make_iivm_data.rst", "api/generated/doubleml.datasets.make_irm_data.rst", "api/generated/doubleml.datasets.make_pliv_CHS2015.rst", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021.rst", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018.rst", "api/generated/doubleml.datasets.make_plr_turrell2018.rst", "api/generated/doubleml.datasets.make_ssm_data.rst", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin.rst", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin.rst", "api/generated/doubleml.utils.DMLDummyClassifier.rst", "api/generated/doubleml.utils.DMLDummyRegressor.rst", "api/generated/doubleml.utils.gain_statistics.rst", "examples/R_double_ml_basic_iv.ipynb", "examples/R_double_ml_basics.ipynb", "examples/R_double_ml_multiway_cluster.ipynb", "examples/R_double_ml_pension.ipynb", "examples/R_double_ml_pipeline.ipynb", "examples/double_ml_bonus_data.ipynb", "examples/index.rst", "examples/py_double_ml_basic_iv.ipynb", "examples/py_double_ml_basics.ipynb", "examples/py_double_ml_cate.ipynb", "examples/py_double_ml_cate_plr.ipynb", "examples/py_double_ml_cvar.ipynb", "examples/py_double_ml_did.ipynb", "examples/py_double_ml_did_pretest.ipynb", "examples/py_double_ml_firststage.ipynb", "examples/py_double_ml_gate.ipynb", "examples/py_double_ml_gate_plr.ipynb", "examples/py_double_ml_gate_sensitivity.ipynb", "examples/py_double_ml_learner.ipynb", "examples/py_double_ml_multiway_cluster.ipynb", "examples/py_double_ml_pension.ipynb", "examples/py_double_ml_pension_qte.ipynb", "examples/py_double_ml_plm_irm_hetfx.ipynb", "examples/py_double_ml_policy_tree.ipynb", "examples/py_double_ml_pq.ipynb", "examples/py_double_ml_sensitivity.ipynb", "examples/py_double_ml_ssm.ipynb", "guide/algorithms.rst", "guide/basics.rst", "guide/data_backend.rst", "guide/guide.rst", "guide/heterogeneity.rst", "guide/learners.rst", "guide/models.rst", "guide/resampling.rst", "guide/scores.rst", "guide/se_confint.rst", "guide/sensitivity.rst", "guide/sim_inf.rst", "index.rst", "intro/install.rst", "intro/intro.rst", "literature/literature.rst", "release/release.rst", "workflow/workflow.rst"], "indexentries": {"bootstrap() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.bootstrap", false]], "bootstrap() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.bootstrap", false]], "bootstrap() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.bootstrap", false]], "bootstrap() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.bootstrap", false]], "bootstrap() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.bootstrap", false]], "bootstrap() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.bootstrap", false]], "bootstrap() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.bootstrap", false]], "bootstrap() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.bootstrap", false]], "bootstrap() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.bootstrap", false]], "bootstrap() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.bootstrap", false]], "cate() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.cate", false]], "cate() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.cate", false]], "confint() (doubleml.doublemlblp method)": [[1, "doubleml.DoubleMLBLP.confint", false]], "confint() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.confint", false]], "confint() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.confint", false]], "confint() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.confint", false]], "confint() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.confint", false]], "confint() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.confint", false]], "confint() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.confint", false]], "confint() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.confint", false]], "confint() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.confint", false]], "confint() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.confint", false]], "confint() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.confint", false]], "construct_framework() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.construct_framework", false]], "construct_framework() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.construct_framework", false]], "construct_framework() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.construct_framework", false]], "construct_framework() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.construct_framework", false]], "construct_framework() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.construct_framework", false]], "construct_framework() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.construct_framework", false]], "construct_framework() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.construct_framework", false]], "construct_framework() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.construct_framework", false]], "construct_framework() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.construct_framework", false]], "dmldummyclassifier (class in doubleml.utils)": [[29, "doubleml.utils.DMLDummyClassifier", false]], "dmldummyregressor (class in doubleml.utils)": [[30, "doubleml.utils.DMLDummyRegressor", false]], "doublemlblp (class in doubleml)": [[1, "doubleml.DoubleMLBLP", false]], "doublemlclusterdata (class in doubleml)": [[3, "doubleml.DoubleMLClusterData", false]], "doublemlcvar (class in doubleml)": [[2, "doubleml.DoubleMLCVAR", false]], "doublemldata (class in doubleml)": [[6, "doubleml.DoubleMLData", false]], "doublemldid (class in doubleml)": [[4, "doubleml.DoubleMLDID", false]], "doublemldidcs (class in doubleml)": [[5, "doubleml.DoubleMLDIDCS", false]], "doublemliivm (class in doubleml)": [[7, "doubleml.DoubleMLIIVM", false]], "doublemlirm (class in doubleml)": [[8, "doubleml.DoubleMLIRM", false]], "doublemllpq (class in doubleml)": [[9, "doubleml.DoubleMLLPQ", false]], "doublemlpliv (class in doubleml)": [[10, "doubleml.DoubleMLPLIV", false]], "doublemlplr (class in doubleml)": [[11, "doubleml.DoubleMLPLR", false]], "doublemlpq (class in doubleml)": [[12, "doubleml.DoubleMLPQ", false]], "doublemlqte (class in doubleml)": [[13, "doubleml.DoubleMLQTE", false]], "draw_sample_splitting() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.draw_sample_splitting", false]], "evaluate_learners() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.evaluate_learners", false]], "fetch_401k() (in module doubleml.datasets)": [[14, "doubleml.datasets.fetch_401K", false]], "fetch_bonus() (in module doubleml.datasets)": [[15, "doubleml.datasets.fetch_bonus", false]], "fit() (doubleml.doublemlblp method)": [[1, "doubleml.DoubleMLBLP.fit", false]], "fit() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.fit", false]], "fit() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.fit", false]], "fit() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.fit", false]], "fit() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.fit", false]], "fit() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.fit", false]], "fit() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.fit", false]], "fit() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.fit", false]], "fit() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.fit", false]], "fit() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.fit", false]], "fit() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.fit", false]], "fit() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.fit", false]], "fit() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.fit", false]], "from_arrays() (doubleml.doublemlclusterdata class method)": [[3, "doubleml.DoubleMLClusterData.from_arrays", false]], "from_arrays() (doubleml.doublemldata class method)": [[6, "doubleml.DoubleMLData.from_arrays", false]], "gain_statistics() (in module doubleml.utils)": [[31, "doubleml.utils.gain_statistics", false]], "gate() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.gate", false]], "gate() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.gate", false]], "get_metadata_routing() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.get_metadata_routing", false]], "get_metadata_routing() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.get_metadata_routing", false]], "get_params() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.get_params", false]], "get_params() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.get_params", false]], "get_params() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.get_params", false]], "get_params() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.get_params", false]], "get_params() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.get_params", false]], "get_params() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.get_params", false]], "get_params() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.get_params", false]], "get_params() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.get_params", false]], "get_params() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.get_params", false]], "get_params() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.get_params", false]], "get_params() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.get_params", false]], "linearscoremixin (class in doubleml.double_ml_score_mixins)": [[27, "doubleml.double_ml_score_mixins.LinearScoreMixin", false]], "make_confounded_irm_data() (in module doubleml.datasets)": [[16, "doubleml.datasets.make_confounded_irm_data", false]], "make_confounded_plr_data() (in module doubleml.datasets)": [[17, "doubleml.datasets.make_confounded_plr_data", false]], "make_did_sz2020() (in module doubleml.datasets)": [[18, "doubleml.datasets.make_did_SZ2020", false]], "make_heterogeneous_data() (in module doubleml.datasets)": [[19, "doubleml.datasets.make_heterogeneous_data", false]], "make_iivm_data() (in module doubleml.datasets)": [[20, "doubleml.datasets.make_iivm_data", false]], "make_irm_data() (in module doubleml.datasets)": [[21, "doubleml.datasets.make_irm_data", false]], "make_pliv_chs2015() (in module doubleml.datasets)": [[22, "doubleml.datasets.make_pliv_CHS2015", false]], "make_pliv_multiway_cluster_ckms2021() (in module doubleml.datasets)": [[23, "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", false]], "make_plr_ccddhnr2018() (in module doubleml.datasets)": [[24, "doubleml.datasets.make_plr_CCDDHNR2018", false]], "make_plr_turrell2018() (in module doubleml.datasets)": [[25, "doubleml.datasets.make_plr_turrell2018", false]], "make_ssm_data() (in module doubleml.datasets)": [[26, "doubleml.datasets.make_ssm_data", false]], "nonlinearscoremixin (class in doubleml.double_ml_score_mixins)": [[28, "doubleml.double_ml_score_mixins.NonLinearScoreMixin", false]], "p_adjust() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.p_adjust", false]], "p_adjust() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.p_adjust", false]], "p_adjust() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.p_adjust", false]], "p_adjust() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.p_adjust", false]], "p_adjust() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.p_adjust", false]], "p_adjust() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.p_adjust", false]], "p_adjust() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.p_adjust", false]], "p_adjust() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.p_adjust", false]], "p_adjust() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.p_adjust", false]], "p_adjust() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.p_adjust", false]], "policy_tree() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.policy_tree", false]], "predict() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.predict", false]], "predict() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.predict", false]], "predict_proba() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.predict_proba", false]], "sensitivity_analysis() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.sensitivity_analysis", false]], "sensitivity_benchmark() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.sensitivity_benchmark", false]], "sensitivity_plot() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.sensitivity_plot", false]], "set_ml_nuisance_params() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.set_ml_nuisance_params", false]], "set_params() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.set_params", false]], "set_params() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.set_params", false]], "set_sample_splitting() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.set_sample_splitting", false]], "set_x_d() (doubleml.doublemlclusterdata method)": [[3, "doubleml.DoubleMLClusterData.set_x_d", false]], "set_x_d() (doubleml.doublemldata method)": [[6, "doubleml.DoubleMLData.set_x_d", false]], "tune() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.tune", false]], "tune() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.tune", false]], "tune() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.tune", false]], "tune() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.tune", false]], "tune() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.tune", false]], "tune() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.tune", false]], "tune() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.tune", false]], "tune() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.tune", false]], "tune() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.tune", false]]}, "objects": {"doubleml": [[1, 0, 1, "", "DoubleMLBLP"], [2, 0, 1, "", "DoubleMLCVAR"], [3, 0, 1, "", "DoubleMLClusterData"], [4, 0, 1, "", "DoubleMLDID"], [5, 0, 1, "", "DoubleMLDIDCS"], [6, 0, 1, "", "DoubleMLData"], [7, 0, 1, "", "DoubleMLIIVM"], [8, 0, 1, "", "DoubleMLIRM"], [9, 0, 1, "", "DoubleMLLPQ"], [10, 0, 1, "", "DoubleMLPLIV"], [11, 0, 1, "", "DoubleMLPLR"], [12, 0, 1, "", "DoubleMLPQ"], [13, 0, 1, "", "DoubleMLQTE"]], "doubleml.DoubleMLBLP": [[1, 1, 1, "", "confint"], [1, 1, 1, "", "fit"]], "doubleml.DoubleMLCVAR": [[2, 1, 1, "", "bootstrap"], [2, 1, 1, "", "confint"], [2, 1, 1, "", "construct_framework"], [2, 1, 1, "", "draw_sample_splitting"], [2, 1, 1, "", "evaluate_learners"], [2, 1, 1, "", "fit"], [2, 1, 1, "", "get_params"], [2, 1, 1, "", "p_adjust"], [2, 1, 1, "", "sensitivity_analysis"], [2, 1, 1, "", "sensitivity_benchmark"], [2, 1, 1, "", "sensitivity_plot"], [2, 1, 1, "", "set_ml_nuisance_params"], [2, 1, 1, "", "set_sample_splitting"], [2, 1, 1, "", "tune"]], "doubleml.DoubleMLClusterData": [[3, 1, 1, "", "from_arrays"], [3, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLDID": [[4, 1, 1, "", "bootstrap"], [4, 1, 1, "", "confint"], [4, 1, 1, "", "construct_framework"], [4, 1, 1, "", "draw_sample_splitting"], [4, 1, 1, "", "evaluate_learners"], [4, 1, 1, "", "fit"], [4, 1, 1, "", "get_params"], [4, 1, 1, "", "p_adjust"], [4, 1, 1, "", "sensitivity_analysis"], [4, 1, 1, "", "sensitivity_benchmark"], [4, 1, 1, "", "sensitivity_plot"], [4, 1, 1, "", "set_ml_nuisance_params"], [4, 1, 1, "", "set_sample_splitting"], [4, 1, 1, "", "tune"]], "doubleml.DoubleMLDIDCS": [[5, 1, 1, "", "bootstrap"], [5, 1, 1, "", "confint"], [5, 1, 1, "", "construct_framework"], [5, 1, 1, "", "draw_sample_splitting"], [5, 1, 1, "", "evaluate_learners"], [5, 1, 1, "", "fit"], [5, 1, 1, "", "get_params"], [5, 1, 1, "", "p_adjust"], [5, 1, 1, "", "sensitivity_analysis"], [5, 1, 1, "", "sensitivity_benchmark"], [5, 1, 1, "", "sensitivity_plot"], [5, 1, 1, "", "set_ml_nuisance_params"], [5, 1, 1, "", "set_sample_splitting"], [5, 1, 1, "", "tune"]], "doubleml.DoubleMLData": [[6, 1, 1, "", "from_arrays"], [6, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLIIVM": [[7, 1, 1, "", "bootstrap"], [7, 1, 1, "", "confint"], [7, 1, 1, "", "construct_framework"], [7, 1, 1, "", "draw_sample_splitting"], [7, 1, 1, "", "evaluate_learners"], [7, 1, 1, "", "fit"], [7, 1, 1, "", "get_params"], [7, 1, 1, "", "p_adjust"], [7, 1, 1, "", "sensitivity_analysis"], [7, 1, 1, "", "sensitivity_benchmark"], [7, 1, 1, "", "sensitivity_plot"], [7, 1, 1, "", "set_ml_nuisance_params"], [7, 1, 1, "", "set_sample_splitting"], [7, 1, 1, "", "tune"]], "doubleml.DoubleMLIRM": [[8, 1, 1, "", "bootstrap"], [8, 1, 1, "", "cate"], [8, 1, 1, "", "confint"], [8, 1, 1, "", "construct_framework"], [8, 1, 1, "", "draw_sample_splitting"], [8, 1, 1, "", "evaluate_learners"], [8, 1, 1, "", "fit"], [8, 1, 1, "", "gate"], [8, 1, 1, "", "get_params"], [8, 1, 1, "", "p_adjust"], [8, 1, 1, "", "policy_tree"], [8, 1, 1, "", "sensitivity_analysis"], [8, 1, 1, "", "sensitivity_benchmark"], [8, 1, 1, "", "sensitivity_plot"], [8, 1, 1, "", "set_ml_nuisance_params"], [8, 1, 1, "", "set_sample_splitting"], [8, 1, 1, "", "tune"]], "doubleml.DoubleMLLPQ": [[9, 1, 1, "", "bootstrap"], [9, 1, 1, "", "confint"], [9, 1, 1, "", "construct_framework"], [9, 1, 1, "", "draw_sample_splitting"], [9, 1, 1, "", "evaluate_learners"], [9, 1, 1, "", "fit"], [9, 1, 1, "", "get_params"], [9, 1, 1, "", "p_adjust"], [9, 1, 1, "", "sensitivity_analysis"], [9, 1, 1, "", "sensitivity_benchmark"], [9, 1, 1, "", "sensitivity_plot"], [9, 1, 1, "", "set_ml_nuisance_params"], [9, 1, 1, "", "set_sample_splitting"], [9, 1, 1, "", "tune"]], "doubleml.DoubleMLPLIV": [[10, 1, 1, "", "bootstrap"], [10, 1, 1, "", "confint"], [10, 1, 1, "", "construct_framework"], [10, 1, 1, "", "draw_sample_splitting"], [10, 1, 1, "", "evaluate_learners"], [10, 1, 1, "", "fit"], [10, 1, 1, "", "get_params"], [10, 1, 1, "", "p_adjust"], [10, 1, 1, "", "sensitivity_analysis"], [10, 1, 1, "", "sensitivity_benchmark"], [10, 1, 1, "", "sensitivity_plot"], [10, 1, 1, "", "set_ml_nuisance_params"], [10, 1, 1, "", "set_sample_splitting"], [10, 1, 1, "", "tune"]], "doubleml.DoubleMLPLR": [[11, 1, 1, "", "bootstrap"], [11, 1, 1, "", "cate"], [11, 1, 1, "", "confint"], [11, 1, 1, "", "construct_framework"], [11, 1, 1, "", "draw_sample_splitting"], [11, 1, 1, "", "evaluate_learners"], [11, 1, 1, "", "fit"], [11, 1, 1, "", "gate"], [11, 1, 1, "", "get_params"], [11, 1, 1, "", "p_adjust"], [11, 1, 1, "", "sensitivity_analysis"], [11, 1, 1, "", "sensitivity_benchmark"], [11, 1, 1, "", "sensitivity_plot"], [11, 1, 1, "", "set_ml_nuisance_params"], [11, 1, 1, "", "set_sample_splitting"], [11, 1, 1, "", "tune"]], "doubleml.DoubleMLPQ": [[12, 1, 1, "", "bootstrap"], [12, 1, 1, "", "confint"], [12, 1, 1, "", "construct_framework"], [12, 1, 1, "", "draw_sample_splitting"], [12, 1, 1, "", "evaluate_learners"], [12, 1, 1, "", "fit"], [12, 1, 1, "", "get_params"], [12, 1, 1, "", "p_adjust"], [12, 1, 1, "", "sensitivity_analysis"], [12, 1, 1, "", "sensitivity_benchmark"], [12, 1, 1, "", "sensitivity_plot"], [12, 1, 1, "", "set_ml_nuisance_params"], [12, 1, 1, "", "set_sample_splitting"], [12, 1, 1, "", "tune"]], "doubleml.DoubleMLQTE": [[13, 1, 1, "", "bootstrap"], [13, 1, 1, "", "confint"], [13, 1, 1, "", "draw_sample_splitting"], [13, 1, 1, "", "fit"], [13, 1, 1, "", "p_adjust"]], "doubleml.datasets": [[14, 2, 1, "", "fetch_401K"], [15, 2, 1, "", "fetch_bonus"], [16, 2, 1, "", "make_confounded_irm_data"], [17, 2, 1, "", "make_confounded_plr_data"], [18, 2, 1, "", "make_did_SZ2020"], [19, 2, 1, "", "make_heterogeneous_data"], [20, 2, 1, "", "make_iivm_data"], [21, 2, 1, "", "make_irm_data"], [22, 2, 1, "", "make_pliv_CHS2015"], [23, 2, 1, "", "make_pliv_multiway_cluster_CKMS2021"], [24, 2, 1, "", "make_plr_CCDDHNR2018"], [25, 2, 1, "", "make_plr_turrell2018"], [26, 2, 1, "", "make_ssm_data"]], "doubleml.double_ml_score_mixins": [[27, 0, 1, "", "LinearScoreMixin"], [28, 0, 1, "", "NonLinearScoreMixin"]], "doubleml.utils": [[29, 0, 1, "", "DMLDummyClassifier"], [30, 0, 1, "", "DMLDummyRegressor"], [31, 2, 1, "", "gain_statistics"]], "doubleml.utils.DMLDummyClassifier": [[29, 1, 1, "", "fit"], [29, 1, 1, "", "get_metadata_routing"], [29, 1, 1, "", "get_params"], [29, 1, 1, "", "predict"], [29, 1, 1, "", "predict_proba"], [29, 1, 1, "", "set_params"]], "doubleml.utils.DMLDummyRegressor": [[30, 1, 1, "", "fit"], [30, 1, 1, "", "get_metadata_routing"], [30, 1, 1, "", "get_params"], [30, 1, 1, "", "predict"], [30, 1, 1, "", "set_params"]]}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function"}, "terms": {"": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 20, 21, 22, 23, 24, 25, 26, 32, 34, 35, 36, 37, 44, 47, 48, 49, 51, 52, 53, 57, 58, 59, 61, 64, 65, 67, 68, 69, 70, 71, 73, 74, 75, 76], "0": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75], "00": [52, 53, 66], "000": [68, 70, 76], "000000": [37, 52, 53, 61, 63, 73], "0000000": [68, 70], "0000000000000010000100": [36, 61, 73], "000000e": [52, 53], "00000591": 56, "000006": 56, "000017": 56, "000025": 51, "000034": 52, "000039": 51, "000064": 39, "000067": 51, "000091": [51, 63], "0001": [37, 52], "0001110464": 66, "000219": [12, 63], "000242": [13, 63], "000268": 66, "000341": 51, "000442": 51, "00047580260495": 32, "000488": 51, "000494": 49, "0005": 37, "000522": 51, "0005a80b528f": 36, "000670": 51, "000743": 57, "000784623154372457": 59, "0007846231543724570": 59, "0007846232": 59, "000915799": [68, 70], "0009157990": [68, 70], "000943": [41, 42], "0009695237": 67, "001": [32, 34, 35, 36, 40, 64, 65, 66, 67, 68, 73, 76], "001051": 51, "001234": 53, "00133": 36, "00138944": [59, 67], "00141": 65, "0016": [35, 52], "001714": 63, "0018": [35, 52], "0019": 37, "002110": 42, "002169338": [68, 70], "0021693380": [68, 70], "0021693381": [68, 70], "002290": 45, "002436": 49, "0026": 37, "002779": 57, "0028": [35, 52], "002983": 51, "003": [16, 17, 18], "00312": 66, "003134": 56, "003328": 56, "0034": 46, "003427": 51, "003779": 49, "003836": 56, "003965": 41, "00409412": [59, 67], "0042": [35, 52], "004392": 49, "004645": 42, "004688": 7, "0047": [35, 52], "00526": 66, "005339": [41, 42], "005571649": 66, "005857": 51, "006066": 41, "006425": 53, "00672053": 66, "006922": 37, "006958": [41, 42], "007017": 54, "007210e": 53, "00728": 73, "007284174": 66, "0073": 37, "007332": 43, "007332393760465": 43, "007659": 63, "00778625": 66, "007909": 41, "008": 54, "008023": 53, "008223": [41, 42], "008266e": 53, "008487": 37, "008642": 63, "008dbd": 54, "008e80": 54, "009": 54, "0090193584": 67, "00902031947837708": 59, "0090203195": 59, "009100952": 66, "009122": 56, "009428": 43, "009645422": 34, "009656": 56, "009719": 54, "00972": 37, "009790": 53, "009904": 63, "009986": 56, "01": [2, 4, 5, 7, 8, 9, 12, 13, 32, 34, 35, 36, 41, 42, 52, 53, 54, 55, 56, 64, 65, 66, 67, 68, 73, 76], "010": 54, "010213": 57, "010269": 51, "010360": 54, "010450": 34, "010582": 54, "010940": 51, "01098691": 66, "011131": 56, "01120478": 66, "01128": 37, "011511": 42, "011598": 56, "0118095": 34, "011823": 57, "011980": 54, "011988e": 56, "012": 54, "01219": 36, "01221971": 66, "01260674": 66, "012780": 53, "013067": 54, "013469": 41, "01351638": 34, "013593": 57, "013617": 53, "01398951": 34, "013990": [68, 70], "01403089": 34, "014080": [41, 42], "014432": 45, "014637": 51, "014681": 57, "015": 36, "015035": 41, "015038": 43, "01504119": 66, "015548": 42, "015565": 56, "015698": 56, "01574297": 56, "015743": 56, "015831": 41, "015895367": 66, "016011": 42, "016154": 51, "016200": [41, 42], "016315": 47, "016429": 63, "01643": 74, "017": 36, "017800092": [68, 70], "0178000920": [68, 70], "017805": 41, "018": 36, "018023": 55, "018099": 41, "018148": 56, "018508": 41, "019008": 42, "01903": [36, 64, 71, 73], "01916030e": 66, "01920056": 66, "01925597": 34, "019439633": [68, 70], "0194396330": [68, 70], "0194396331": [68, 70], "019596": 43, "019660": [13, 63], "01990373": 58, "019953": 41, "019974": 53, "02": [41, 42, 50, 52, 53, 56, 63, 66], "02016117": 73, "020166": 56, "020271": 51, "020360838": [68, 70], "0203608380": [68, 70], "0203608381": [68, 70], "020387": 42, "02052929": [59, 67], "02079162e": 66, "020819": 63, "02092": 73, "021013": 41, "021269": [47, 48], "02163217": 34, "021866": 55, "021926": 43, "02247976": 34, "022768": 37, "022783": 57, "022915": 51, "022954": 63, "022969": 53, "022991": 42, "023020e": [52, 53], "023160": 41, "023256": 56, "023505": 41, "023563": [68, 70], "023955": 53, "024355": 45, "024364": 69, "024401": [47, 48], "024604": 51, "024782": 56, "024926": 45, "025": [41, 42, 47, 48, 54], "025077": [68, 70], "0253": 36, "025443": 37, "025708e": 42, "025783e": 42, "025813114": [68, 70], "0258131140": [68, 70], "02584": 36, "025958": 63, "02649578": 50, "026518e": 41, "026669": 53, "026723": 43, "027329": 41, "02791": 37, "028001": 42, "0281": 36, "028520": [41, 42], "02897287": 44, "02900983": 56, "029010": 56, "029022": 42, "029209": 76, "029364": 69, "029831": 56, "029910e": [52, 53], "02e": 35, "03": [2, 4, 5, 7, 8, 9, 10, 11, 12, 41, 42, 43, 49, 52, 53, 56, 57, 66, 69, 76], "030087": 63, "0301": 36, "03018": [9, 63], "030346": 73, "0305736": 66, "0307": 36, "030934": 56, "030962": 56, "03113": 58, "031134": 64, "031156": 42, "03120321": 66, "031269": 37, "031639": 56, "031820": 42, "03191": 74, "032": 32, "03220": 75, "03244552": 64, "0325": 73, "032542": 54, "032953": 57, "033224": 41, "033737": 42, "033756": 43, "033946": [47, 48], "034097": 41, "03411": 73, "034226": 53, "034690": 43, "03476507": 66, "034812763": [68, 70], "0348127630": [68, 70], "0348127631": [68, 70], "034836": 52, "03489": [23, 34, 51], "035088": 42, "035119185": [68, 70], "0351191850": [68, 70], "0351191851": [68, 70], "035264": 42, "03536": 73, "03538": 36, "03539": 36, "035391": 37, "0354": 36, "035411": 73, "035441": 42, "03545": 36, "035545": 37, "035572": 37, "035730": 56, "03574": 37, "035762": 56, "0359": 36, "036129015": [68, 70], "0361290150": [68, 70], "0361290151": [68, 70], "036143": 56, "036147": 56, "036729": 51, "036874e": 42, "036945": 53, "03698487": 56, "036985": 56, "037008": [47, 48], "0374": 36, "037509": 58, "037747": [41, 42], "038845": 41, "039036": 41, "03917696": [67, 68], "03920960e": 66, "039310e": 43, "039660": 41, "039897": 42, "04": [16, 17, 35, 41, 42, 52, 53, 56, 57, 66, 76], "040112": [68, 70], "040139": [41, 42], "040141": 42, "040445": 41, "04052906": 66, "040533": [67, 68], "04053339": 68, "040688": 41, "0408": 41, "040902": 54, "040912": 42, "040919": 42, "04107": 11, "041112": 42, "041147": 43, "041284": 43, "041387": 43, "041459": 53, "04146556": 66, "041491e": 43, "04166": 65, "041831": 43, "041925": 41, "042249": 42, "042265": 43, "042266": 41, "0425": 64, "0428": 58, "042822e": 53, "042844e": 56, "043108": 53, "0434e374": 36, "043998": 42, "044": 54, "044062": 42, "044113": 43, "04415": [36, 64], "04424": 36, "044334": 41, "04444978": [68, 70], "044449780": [68, 70], "04458": 64, "04465": 34, "044704": 42, "04486": 73, "04487585": 69, "04491": 65, "04497975": 69, "045068548": 66, "04512": [67, 68], "04512331": 68, "045144": 51, "04532": 64, "045379": 73, "04552": 51, "045553": 43, "04559": 64, "045624": 45, "045754": 56, "0459": 64, "045932": 56, "045993": 64, "046": 54, "04631": 64, "046405": 63, "046527": 43, "04653976": 56, "046540": 56, "0466028": 34, "04661445": 66, "046728": 57, "046757": 42, "04682310e": 66, "046922": 64, "047": 54, "047156": 41, "047194": 7, "047215": 42, "047375e": 41, "04759138": 66, "04792887": 66, "047954": 51, "048308": 48, "048326": 42, "048699": 58, "048723": 64, "04874241": 66, "04886405": 66, "04973": 42, "049959": 41, "05": [32, 34, 35, 36, 41, 42, 43, 46, 51, 52, 53, 54, 56, 64, 65, 66, 67, 68, 73, 76], "05039": 57, "050399": 42, "050538": 42, "050843": 42, "050856": [63, 64, 65], "051": 36, "051578e": 42, "051867e": 43, "052000e": 53, "052298": 56, "052380": 41, "052488": 48, "052502": 56, "05255651": 66, "052745": 43, "053": 36, "053198": 54, "053331": 43, "053342": 53, "053389": [68, 70], "053436": 8, "053541": 56, "053558": 43, "054": 36, "054068": 51, "054162": 51, "054348": 68, "054370": 43, "054529": [68, 70], "054771e": 56, "055078": 41, "055165": 57, "055171": 42, "055338e": 52, "055439": 53, "055680": [68, 70], "056052": 41, "056389": 42, "056499": 48, "056745": 41, "056953": 41, "057": 54, "057095": 56, "0576": [35, 52], "057762": 56, "057962": 43, "058": 54, "058042": [68, 70], "058276": 53, "058463": 56, "058508": 58, "0590439788": 66, "059187": 42, "059384": 56, "059627": 53, "059630": 45, "059685": 56, "06": [16, 17, 18, 32, 41, 42, 43, 52, 53, 56, 63, 67, 68], "060": 32, "06008533": 65, "060201": 56, "060212": [52, 53], "060417": 41, "06046108": 50, "060845": [68, 70], "06111111": 36, "062414": 53, "062507": 56, "062964": [68, 70], "06332389": 66, "063618": 42, "063700": 41, "063881": 65, "064161": 53, "06428": 52, "064280": 52, "064400": 41, "0646222": 35, "06464": 68, "065128": 41, "065356": [47, 48], "065451": 53, "06548413": 66, "065725": 43, "065969": 65, "066464": 57, "066689e": 42, "066889": 56, "06692492": 66, "067240": 56, "06724028": 56, "067721": [68, 70], "068073": 42, "06827": 57, "06834315": 44, "068377": 53, "068514": 41, "06895837": 34, "0695854": 34, "069600": 53, "07": [32, 41, 42, 53, 56, 66, 76], "070020": 56, "070196": 43, "0701961897676835": 43, "0702127": 34, "070552": 41, "070574e": 53, "070751": 41, "070884": 56, "071285": 68, "07136": [34, 51], "071488e": 43, "07168291": 34, "071777": 64, "071782": [13, 63], "072": 54, "07202564": [47, 48], "072058": 41, "07222222": 36, "072293": 55, "07253912": 66, "07267712": 66, "072852": 41, "073": 65, "073013": 56, "073207": 51, "073352": 41, "07347676": 34, "07350015": [23, 26, 34, 51], "073520": 43, "07366": [36, 64], "073694": 42, "074": 54, "074304": 68, "074362": 54, "07436521": 66, "074426": 56, "07456127": 34, "074617": 42, "07479278": 57, "075261": 45, "075384": 56, "07538443": 56, "07544271e": 66, "07561": 73, "07564554e": 66, "075869": 64, "076019": 52, "076156": 68, "076179312": [68, 70], "0761793120": [68, 70], "076322": 56, "076347": 43, "0765": 36, "076559": [63, 64, 65], "076596": 41, "07663698": 66, "076684": 73, "07685043": 66, "07689": 36, "07691847": 66, "076953": [47, 48], "076971": 37, "077161": 53, "07727773e": 66, "077319": 56, "07742043": 66, "077502": 69, "0777777777777778": 64, "07777778": [36, 64], "077840": 53, "07786": 65, "077883": 56, "078096": 68, "078207": 37, "07828372": [68, 70], "078474": [68, 70], "078810": 56, "079085": 37, "07915": 36, "07919896": 66, "079458e": 52, "07961": 57, "07978296": 66, "08": [32, 41, 42, 43, 53, 56, 65], "08005229": 66, "08031571": 66, "080351": 42, "080854": 53, "080900": 41, "08091581": 66, "080947": 37, "081": 36, "081100": 56, "081230": [41, 42], "081488": 51, "08154161": 66, "08181827e": 66, "082": 54, "082263": 10, "082297": 66, "082574": 8, "082804": 45, "082858": 42, "082934": 53, "082973": 51, "083258": [68, 70], "083318": 68, "08333333": 36, "08333617": 66, "0835771416": 34, "083750": 53, "084": 34, "08410699": 66, "084156": 42, "084184": 43, "0841842065698133": 43, "084212": 49, "084269": 53, "084337": 65, "084633": 47, "084771": 41, "0853505": 34, "085395": 41, "085566": 43, "085671": 41, "085965": 53, "08602774e": 66, "086109": 42, "0862": 71, "086264": 43, "086464": 41, "08664208": 66, "086679": 64, "086889": 47, "087": 54, "087491e": 42, "087561": 41, "087634": 41, "087947": 56, "088048": 56, "088282": 48, "088357": 56, "08848": 64, "088482": [13, 63], "088504e": 10, "088696e": 42, "08888889": 36, "089064e": 41, "089661": 48, "08968939": 34, "089825": 42, "08e": 35, "09": [41, 43, 52, 53, 56, 63, 66], "09000000000000001": 64, "090025": 53, "090255": 56, "091046": 48, "091391": [68, 70], "091406": 69, "091535": 41, "091611": 42, "091992": 55, "092247": 56, "092263": 65, "092365": [68, 70], "093": 32, "093043": 56, "09310496": [68, 70], "093153": 56, "093474": 56, "09347419": 56, "093746": 68, "09392932": 65, "093950": 51, "094026": 51, "094118": 56, "094381": 51, "09444444": 36, "0945694": 66, "094829": 65, "094999": 56, "095475": 63, "095781": 2, "095835": 42, "09603": 71, "096245": 63, "096337": 51, "096550": 47, "096616": 63, "096741": 44, "096934": 42, "097468": 43, "09758533": 66, "09779675": [68, 70], "097796750": [68, 70], "09792": 66, "098": 35, "098256": 56, "09830758": 57, "098308": 57, "098317": 53, "098319": 56, "098712": 56, "09879814e": 66, "099": 54, "0992582": 66, "099647": 55, "099670": 53, "099731": [41, 42], "09980311": [68, 70], "09988": 74, "0_": 22, "0ff823b17d45": 36, "0x1747bdd4520": 37, "0x1747bdd6b90": 37, "0x2920d7b7150": 55, "0x7fe48d78e4f0": 76, "0x7fe48db78520": 64, "0x7fe48e5c58b0": 68, "0x7fe48f09bd00": 68, "0x7fe49a149fa0": 65, "0x7fe49a3108b0": 68, "0x7fe49a31f700": 69, "0x7fe49a48ea00": 65, "0x7fe49a48f430": 64, "0x7fe49abc3940": 68, "0x7fe4aab8a0a0": 64, "1": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "10": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 23, 24, 26, 32, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76], "100": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 23, 25, 26, 34, 36, 40, 41, 42, 44, 46, 49, 50, 51, 54, 58, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 75], "1000": [7, 9, 33, 39, 40, 44, 45, 47, 48, 49, 50, 52, 53, 57, 60, 63, 65], "10000": [32, 41, 42, 45, 52, 53, 56], "100000e": 53, "100356": 43, "10038": 57, "10039862": [58, 65], "100517": 68, "100614": 49, "10079785": 65, "100807": [41, 42], "100858": 57, "10089588": 56, "100896": 56, "10092": 53, "100923": 56, "100_000": 54, "101": [16, 17, 18, 63, 74, 75], "101076": 42, "10126": 53, "10127930": [68, 70], "101279300": [68, 70], "1015": [35, 52], "1016": [16, 17, 18], "1016010": 35, "1018": 53, "101875": 66, "102": [61, 63, 73, 75], "10235": 53, "102553e": 41, "10258": 53, "102616": 43, "102775": 43, "10299": 52, "103": [51, 58, 63, 75], "1031": 53, "103186": 42, "103189": 53, "10348": 52, "103497": 56, "1036504": 66, "1038": 53, "103806": 43, "103951906910721": 43, "103952": 43, "10396": 52, "104": [35, 52, 58, 63, 75], "10406": 53, "10414": 53, "1042349": 66, "1045303": 34, "104787": 51, "105": [22, 34, 41, 51, 63, 75], "105318": 56, "1054": 36, "105722": 42, "105751e": 41, "105942": 41, "106": [36, 63, 75], "10607": [37, 61, 73], "10618": 53, "10637173e": 66, "106391": 68, "106401e": 41, "106595": 65, "106691": 63, "106743": 42, "106746": 56, "107": [36, 63, 75], "107073": 43, "1072": 66, "107295": 68, "1073": 53, "10747": [37, 61, 73], "107872": 63, "1079462": 66, "10799": 53, "108": [63, 71, 74, 75], "1080": [23, 26, 34, 51], "10824": [37, 61, 73], "108257e": 53, "10831": [37, 61, 73], "1087617": 66, "10878571": 56, "108786": 56, "109": [41, 63], "109005": 56, "10903": 52, "109069": [68, 70], "109079e": 56, "1091551": 66, "109273": 51, "10928": 53, "1093": 46, "109454": 53, "10967": 52, "109861": 73, "1099472942084532": 39, "10e": [43, 56], "11": [11, 34, 35, 36, 37, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 76], "110": [63, 75], "1101": 53, "1102699": 66, "110359": 51, "1105579": 66, "110681": 57, "1107": 53, "11071087": [58, 65], "110717": [68, 70], "1109": 53, "110902": 43, "110902411746278": 43, "111": [63, 75], "1111": [14, 15, 24, 33, 34, 40, 46, 51, 60, 65, 69, 71], "111164": 55, "11120": 53, "1118": 35, "11199615e": 66, "112": [36, 63, 75], "1120": 52, "11208236": [59, 67], "1122": 53, "112216": 43, "1129": 53, "113": [14, 63, 75], "113207": 56, "113270": 43, "113415": 53, "11375": 53, "113780": 51, "114": [63, 75], "11409": 52, "11414": 52, "1144500": 34, "114467523": 66, "11447": 57, "114530": 47, "1145370": 34, "114570": 42, "11458": 53, "114591": 42, "114647": 43, "1148": 53, "114834": 53, "11488": 53, "1149293": 66, "11495": 53, "115": [63, 75], "11500": [52, 76], "115060e": 56, "115296e": 53, "115297e": 52, "1154153": 66, "11552911": 57, "11559": 53, "115636": 42, "11570": 52, "115792e": 53, "115972": 41, "116": [63, 75], "116027": 43, "1161246": 66, "11617": 53, "1161849": 66, "116274": 43, "116483": 42, "116569": 53, "1166": 74, "1167": 52, "11673": 53, "11675": 53, "117": [41, 63], "1170": 57, "11700": 76, "117072": 47, "117242": 56, "11724226": 56, "117366": 56, "11743": 76, "11750": 53, "1177": 52, "117710": 43, "11792": 35, "11796": 53, "118": 63, "11802": 53, "1182": 35, "118255": 56, "1183717": 66, "1186": 35, "118601": 51, "11861": 35, "118721": [42, 48], "1187339840850312": 51, "11879": 53, "118799": 53, "118938e": 65, "118952": 51, "119": [63, 75], "11932": 53, "119348e": 42, "11935": 57, "119766": 56, "1198": [34, 51], "12": [32, 33, 34, 35, 36, 37, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76], "120": [44, 58, 63, 75], "12002": 52, "1202": 74, "120456": 48, "120468": 56, "12046836": 56, "120567": [47, 48], "120636": 41, "120721": 51, "12097": [14, 15, 24, 34, 46, 51, 60, 71], "121": [32, 53, 63, 75], "1210": 53, "12101": 53, "12105472": [68, 70], "121054720": [68, 70], "1211": 53, "1213405": 34, "121399": 53, "1214": [68, 70], "121584e": 56, "121711": 53, "121774": 49, "12196389e": 66, "122": [16, 17, 18, 54, 61, 63, 74, 75], "12214": 35, "12223182e": 66, "122408": 43, "122777": 68, "123": [35, 36, 52, 63, 75, 76], "1230": 53, "12323": 53, "1234": [32, 33, 37, 39, 40, 60, 64, 66, 68, 70], "1238": 53, "123806e": 42, "123917": 53, "124": 63, "12410": 53, "12411908": 65, "124465": 41, "124805": 52, "125": [63, 75], "12500": 52, "125065": 68, "12539340": [68, 70], "1255": 53, "12579": 53, "1258": 34, "126": [63, 75], "12606": 53, "12612": 53, "126777": 68, "126802": 53, "126875": 41, "12689": 53, "127": [63, 75], "127006": 53, "12705095": [67, 68], "12707800": 34, "12721233": 66, "12752825": [68, 70], "127563": 57, "1277": 54, "127778": 53, "127831": 42, "128": [35, 63, 75], "12802": 35, "12814": 53, "128273e": 41, "128312": 56, "128408": 51, "12861": 53, "128651": 42, "129": [51, 63, 75], "129152": 41, "12945": 74, "1295": 53, "129514": 53, "12955": 52, "1298": 53, "12980769e": 66, "12983057": 65, "13": [16, 17, 18, 20, 33, 34, 35, 36, 37, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 56, 57, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 76], "130": [36, 47, 51, 63, 75], "130122": 57, "13034980e": 66, "130370": 43, "130526": 63, "1306": 57, "130829": 56, "13091": 53, "131": [63, 75], "13102231": 65, "13119": 57, "1312": 76, "131211": 53, "1313": [35, 76], "13137893e": 66, "131544": 41, "131771": 42, "132": [36, 51, 63, 75], "13208": 76, "1321": [52, 76], "1324": [35, 52], "132454": 45, "1325": 35, "1326343639475152606263687278798081879293": 66, "132634363947515260626368727879808187929313471719222833495657586164718489969959101823293537384143455359677375829194681215242730314042444654557074838590100": 66, "132634363947515260626368727879808187929321114162021253248506566697677868895979813471719222833495657586164718489969959101823293537384143455359677375829194": 66, "1326343639475152606263687278798081879293211141620212532485065666976778688959798134717192228334956575861647184899699681215242730314042444654557074838590100": 66, "132634363947515260626368727879808187929321114162021253248506566697677868895979859101823293537384143455359677375829194681215242730314042444654557074838590100": 66, "132671": 43, "13288": 52, "132903": 53, "133": [36, 61, 63, 74, 75], "13300": 53, "133202": 53, "133204": 41, "133343": 42, "133421": 53, "13356": 53, "133596": 56, "133f5a": 54, "134": [51, 58, 63, 75], "1341": 35, "134146": 53, "1342": 53, "134211": 56, "1343": 52, "134542": 41, "134567": 53, "1346035": 35, "134687": 53, "134717192228334956575861647184899699": 66, "13474": 53, "134765": 53, "1348": 52, "1349": 57, "13490": 53, "135": [36, 63, 75], "13505272": 34, "135329": 49, "135352": 4, "135379": 68, "135396": 41, "135707": 64, "135755": 63, "135856": 56, "13585644": 56, "135871": 51, "136": [37, 51, 63, 75], "1360": 35, "136089": 51, "1361": [53, 66], "13642": 53, "136442": 51, "1366": 54, "136836": 51, "137": [36, 37, 63, 75], "1371": 53, "137213": 42, "137396": 56, "1378": 53, "138": [63, 75], "1380": 52, "138068": 47, "13809": 53, "138378": 43, "13868238": [68, 70], "138682380": [68, 70], "138698": [68, 70], "138851": 47, "13893": 53, "139": [63, 73], "1390": 52, "139491": [68, 70], "13956": 57, "139582e": 11, "1398": 53, "139921": 63, "14": [33, 34, 35, 36, 37, 41, 42, 43, 44, 47, 48, 49, 51, 52, 53, 56, 57, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 76], "140": [44, 53, 58, 63, 75], "1400": 53, "14000073": 66, "140770": [41, 42], "140833": 43, "140861": 34, "140926": 56, "141": [53, 63, 75], "141098e": 53, "14114": 57, "141347": 41, "141384": 49, "14141": 53, "141546": [68, 70], "141729": 42, "141820": 43, "142": [63, 75], "14200098": [68, 70], "142270": 45, "1423550": 66, "142382": 41, "1424": 64, "142624": 42, "14268": 65, "14281403493938022": 64, "14289": 53, "143": [61, 63, 75], "143495": 63, "1435": 53, "14368145": [68, 70], "144": [41, 42, 63, 75], "14400": 52, "14405": 53, "14406": 53, "144084": 43, "144137": 44, "144241": 47, "1443": 53, "144500e": 53, "144669": 56, "1447": 53, "144800": 43, "144861": 52, "144908": 55, "145": [63, 75], "145245": 56, "14532650": [68, 70], "145513": 41, "145625": 56, "145748": 68, "14587": 53, "146": [63, 75], "146037": 56, "146046": 42, "146087": 73, "146142808990006": 43, "146143": 43, "14625": 53, "1465": 35, "146641": 68, "14667": 53, "1468115": 34, "146973": 43, "1469734445741286": 43, "147": [63, 75], "147015e": 53, "14702": 37, "147121": 56, "14744": 53, "14772": 53, "1479": 53, "14790924": [68, 70], "147909240": [68, 70], "147927": 37, "14798": 53, "148": [63, 75], "14803": 53, "148134": [41, 42], "148161": 56, "148443": 63, "14845": 37, "1485": 53, "148750e": [52, 53], "148790": 53, "148802": 53, "148950": 41, "149": [63, 75], "1492": [32, 50], "149285": 56, "149671e": 42, "149714": 51, "14984": 53, "149858": [12, 63], "149898": 56, "149973e": 42, "15": [2, 4, 5, 7, 8, 9, 10, 11, 12, 15, 33, 34, 35, 36, 41, 42, 43, 44, 47, 49, 50, 51, 52, 53, 56, 57, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 76], "150": [22, 36, 41, 42, 63, 75], "15000": [35, 52], "150000": 35, "15000000000000002": [43, 53, 56, 64], "150000e": 53, "150136": 42, "1502": 34, "150200": 51, "150334": 53, "150408": 34, "150614": 37, "150719e": 52, "151": [54, 63, 75], "151047e": 47, "151063": 41, "151087e": 41, "15113": 53, "151636": 43, "151819": 56, "15194": 52, "152": [63, 75], "152034": 53, "152148": [41, 42], "152772": 42, "15285": 53, "152926": 45, "153": [63, 75], "1530959776797396": 43, "153096": 43, "153119": 43, "15347": 53, "153587": 51, "153633": 37, "153639": 66, "15375": 57, "154": 63, "15430": 76, "154421": 68, "1545": 53, "154557": 56, "154758": 68, "154811": 42, "154828": 43, "155": [63, 75], "155000": 52, "155025": 56, "155120": 56, "15522412": 66, "155516": 55, "15556": 53, "155610": 41, "155676": 41, "1557093": 34, "156": [63, 75], "1560": 53, "156021": 56, "156202": [41, 42], "156317": [41, 42], "1564": [68, 70], "1564156": 66, "156473": 54, "156545": 68, "156567": 41, "1569": 53, "156969": 43, "157": [63, 75], "157054750": 66, "157091": 68, "1576": 53, "157613": 41, "1577657": 34, "158": [63, 75], "158007": 56, "158087": 41, "15815035": 35, "158178": 43, "1582": 53, "1586": 53, "158697": [68, 70], "1589": 53, "15891559": 56, "158916": 56, "159": 75, "159011": 41, "159202e": 42, "159386": 57, "1596": 36, "159959": 53, "15999624": 66, "16": [2, 32, 33, 34, 35, 36, 41, 42, 43, 49, 51, 52, 53, 56, 57, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 76], "160": [44, 58, 75], "1604": 35, "160438": 41, "160932": 43, "161": [36, 48, 74, 75], "161049": 42, "161088": 42, "161141": 51, "161198": 55, "161236": 56, "161243": 56, "161288": 42, "161543": 53, "1619": 35, "162": 75, "16201": 53, "16211": 52, "162153": 56, "1622": 53, "16241": 53, "162587": 57, "1626685": 34, "162710": 43, "1628": 52, "162930": 53, "163": [53, 75], "163194": 56, "163393e": 42, "163566": 53, "163895": 43, "164": [66, 75], "164034": 68, "164608": 56, "164617": 52, "164698": 49, "164801": 56, "164805": 43, "164864": 51, "165": 75, "16500": 52, "165178": 56, "16536299": [68, 70], "165362990": [68, 70], "16539906e": 66, "1654": 53, "165419": 56, "165549": 73, "165569": 41, "16587": 52, "16590": 53, "16597": 53, "166": 75, "166079": 41, "1661": 52, "166375": 63, "167": [35, 52, 75], "16725": 53, "167547": 56, "1676": 53, "167765": 53, "167993": 68, "168": 75, "16803512": [68, 70], "168092": 68, "168195": 57, "1683": 52, "168614": 56, "168931": 56, "169": [36, 75], "1691": 53, "16910": 53, "169196": 56, "169230e": 43, "16951": 53, "16984": 53, "17": [33, 34, 35, 36, 41, 42, 49, 51, 52, 53, 56, 57, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 76], "170": 75, "1704": 53, "170538822": 66, "17083": 53, "171": 75, "1712": 74, "1714": 35, "171575": 56, "171709": 41, "171815": 64, "171868e": 41, "171942": 53, "172": 75, "172022": [68, 70], "172083": 42, "172793": 56, "173": 75, "17372": 53, "1738": 53, "17385178": 64, "173969": 68, "174": 75, "174106": 57, "174185": 56, "174499": [68, 70], "174516e": 56, "17453": 53, "1746": 53, "174743": 63, "174884": 42, "174901": 42, "174940": 63, "17499": 53, "175": 75, "1751": 52, "175176": 56, "17522": 53, "175284": 43, "175342": 41, "175635027": 34, "17576": 53, "176495": 56, "17655394": 56, "176554": 56, "176929": [68, 70], "177": [74, 75], "177007": 56, "17700723": 56, "177043": [41, 42], "1773": 53, "177304": 42, "177463": 55, "177496": 56, "177611": 56, "177751": 56, "17778": 53, "17784378": 66, "177933e": 41, "17799": 53, "177995": 56, "178": [49, 75], "178169": 47, "178218": 42, "17823": 36, "178704": 68, "178763": 56, "178805": 48, "178934": 68, "178980": 42, "179": [47, 75], "1795850": 34, "179588e": 56, "1798913180930109556": 54, "18": [33, 34, 35, 36, 37, 41, 42, 49, 51, 52, 53, 56, 57, 61, 63, 64, 65, 66, 68, 69, 70, 73, 76], "180": [44, 58], "18015": 53, "180176e": 53, "18030": 53, "180348": 42, "180575": [47, 48], "1807": 53, "1809": 74, "180951": 56, "181": 75, "1812": 53, "18141": 53, "181446": 68, "182": 75, "182208e": 41, "182393": 41, "182633": 56, "182692": 42, "182849": 56, "183": [36, 75], "183373": 65, "183526": 43, "18356413": 65, "18368": 53, "183855": 64, "183888": 51, "184": [36, 74], "185": [35, 36], "18500": 53, "1855": 53, "185585": 63, "185984": 41, "186": [53, 75], "186027": 41, "18604": 53, "186237": 42, "18631": 53, "18637": 71, "18666": 53, "186735": 56, "18678094e": 66, "186795": 42, "186836": 56, "187153": 68, "187664": 41, "187690": 56, "18789": 53, "188": 75, "188175": 56, "1881752": 56, "188223": 56, "18888149e": 66, "188991": 68, "189": 36, "189195": 53, "189248": 41, "189293": 53, "189302": 41, "189493": 42, "1895815": [23, 34, 51], "189737": 56, "189927": 53, "189998": 56, "19": [33, 34, 35, 36, 41, 42, 50, 51, 52, 53, 56, 57, 63, 64, 65, 66, 68, 73, 76], "190": [36, 75], "19000": 53, "190096": 68, "190140": 41, "19031969": 56, "190320": 56, "19033538": 34, "190648": 7, "19073905e": 66, "190809": 56, "190869": 63, "1909": [23, 34, 51], "190915": 43, "190921": 48, "190982": 56, "191": [36, 50, 74, 75], "1912": 74, "1912705": 60, "191320e": 52, "191397": 63, "191606": 52, "191716": 53, "192": [65, 75], "1922": 53, "192240": 68, "192505": 55, "192526": 57, "19252647": 57, "192539": [13, 63], "192587": 56, "192739": 42, "193060": 56, "193069e": 41, "193300": 41, "193308": [13, 63], "19374710e": 66, "19382": 53, "19385": 53, "193f0d909729": 36, "194": [53, 75], "1940317": 66, "1941": 35, "19413": [52, 53], "194232": 42, "194601": 44, "195": 75, "19509680e": 66, "195377": 56, "195396": 56, "195547": 53, "195564": 51, "19559": [35, 52], "195761": 56, "1959": 74, "196": 75, "196189": 56, "1963211": 66, "196437": 53, "19680840": [68, 70], "1970": 53, "197000e": 53, "19705": 53, "197225": [37, 61, 73], "1972250000001000100001": [36, 61, 73], "1974": 53, "197424": 64, "197484": 68, "19756": 53, "19758": 53, "197600": 45, "197711": 53, "197920": 41, "19793": 53, "19794": 53, "198": 75, "198218": 51, "19824": 53, "198351": 56, "198549": 37, "198687": 35, "1988": [33, 40, 60], "198953": 63, "199": 75, "1990": [35, 52, 53, 65], "1991": [35, 52, 53, 76], "199206e": 41, "199281e": 56, "199282e": 53, "19928927": 66, "199412": 42, "199458": 68, "1995": [34, 51], "1998": 54, "19983954": 58, "199893": 47, "1999": [54, 58], "199959": 41, "1_": [43, 56], "1e": [2, 4, 5, 7, 8, 9, 12, 13, 53], "1f77b4": 45, "1x_4x_3": 45, "2": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 26, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75], "20": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, 21, 23, 24, 25, 33, 34, 35, 36, 41, 42, 43, 44, 47, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 63, 64, 65, 66, 67, 68, 69, 73, 76], "200": [19, 22, 40, 43, 44, 46, 50, 55, 56, 58, 60, 64, 75], "2000": [15, 35, 41, 42, 43, 52, 53, 56, 58, 65], "20000": [35, 52], "20000000000000004": [43, 53, 56], "200000e": 53, "20010": 53, "200110": 53, "2003": [14, 74], "200303": 73, "2005": 44, "20055": 53, "2006": 53, "20074": 53, "2007768": 66, "200863": 41, "201": [36, 53, 75], "2010": [34, 51], "2011": [34, 51, 71, 73], "2013": [46, 68, 70, 74], "2014": [68, 70, 74], "20148598": 50, "2015": [22, 74], "201528": [41, 42], "20158": 53, "2016": 54, "2017": [21, 74], "201768": 51, "201788e": 53, "201796": 49, "2018": [14, 15, 24, 25, 33, 34, 35, 40, 44, 46, 50, 51, 52, 53, 57, 60, 66, 68, 70, 71, 74, 75], "2019": [19, 36, 41, 42, 43, 47, 48, 53, 56, 57, 64, 67, 71, 73, 74], "20197670": 66, "202": 75, "2020": [4, 5, 16, 17, 18, 20, 36, 44, 64, 65, 69, 74], "2020435": 34, "2021": [23, 34, 36, 41, 42, 51, 74, 75], "20219609": 34, "2022": [57, 65, 69, 71, 74], "2023": [26, 58, 65, 67, 74], "2024": [32, 39, 54, 71, 74], "202650e": 43, "20269": 53, "20274": 53, "202846": 42, "203": [35, 52], "203284": 43, "20329": 53, "2036": 53, "203828": 53, "203893": 63, "204007": 56, "20400735": 56, "204482": 56, "204653": 63, "204794": 56, "205": 57, "205187": 43, "205656": 41, "205938": 51, "206": 75, "2061": 53, "206253": [52, 53], "2064": 53, "206614": 56, "206748": 42, "207222": 52, "20783816": 34, "207840": 48, "207912": 68, "208": 75, "208034e": 53, "2080787": 34, "20823898": 34, "2086": 53, "20869125": 66, "20885627": 66, "208922": 41, "209014": 56, "209219e": 57, "209257": 4, "209546e": 53, "2097": 65, "209894": 56, "21": [14, 15, 24, 33, 34, 35, 36, 41, 42, 46, 50, 51, 52, 53, 56, 57, 60, 63, 64, 65, 66, 68, 71, 73, 74, 76], "210": [16, 17, 18], "2103": [53, 71], "2103034": 34, "210319": [41, 42], "210323": 56, "2104": 75, "21078": 53, "211": 75, "21105": [36, 64, 71, 73], "211141620212532485065666976778688959798": 66, "21114162021253248506566697677868895979813471719222833495657586164718489969959101823293537384143455359677375829194681215242730314042444654557074838590100": 66, "21142": 53, "211534": 43, "21155656": 56, "211557": 56, "212": [54, 75], "2122": 53, "21254389": 66, "21257396e": 66, "212844": 51, "213": [74, 75], "213026": 53, "213070": 42, "213135": 42, "21361": 53, "213635": 41, "2139": 20, "214764": 57, "215": 48, "215069": 56, "215342": 56, "215389": 41, "2155": 53, "21550": 53, "21562": 53, "21573": 53, "215967": 68, "216": 76, "216130e": 41, "216207": 64, "21624417": 34, "2163": 53, "216344": 56, "21669513e": 66, "216761": 55, "217": 74, "21716": 53, "2171802": [34, 51], "217244": [9, 63], "21799899": 66, "21804": [35, 52], "218767": 53, "2189": 53, "218938": 53, "219": [16, 17, 18, 74], "2191274": 34, "219196e": 42, "21997": 52, "22": [33, 34, 35, 36, 41, 42, 51, 52, 56, 57, 63, 64, 65, 66, 68, 73, 76], "220": 75, "220088": 53, "220772": 56, "220773": 41, "221": 75, "221245": 42, "2213": 51, "2214": 51, "221419": 53, "2215": 51, "2216": 51, "2217": [34, 51], "222": [54, 75], "2222": [33, 34, 40, 65], "22222": 53, "22272803e": 66, "222843": 56, "223": [75, 76], "22336235": 34, "223485956098176": [47, 48], "22375856": 34, "22390": 52, "224": 75, "224539e": 41, "224546": 41, "224897": [41, 42], "225": [58, 75], "225034": 44, "22505965": 34, "22507006e": 66, "225175": 56, "225222": 56, "22522221": 56, "22528": 53, "225459760731946": 43, "225460": 43, "225574": 51, "2256": 53, "22562": 53, "2258": 57, "226": 75, "226524": 56, "226598": 51, "226776": 42, "226938": 48, "227": [53, 75], "2271071": 26, "227190": 48, "2279": 53, "227931e": 52, "228035": 53, "2281": 53, "228621": 41, "228630": 42, "228648": 35, "229": [35, 75], "22925": 53, "22937": 53, "229443": 56, "229472": 52, "2295": 53, "229759": 64, "229897": 41, "229961": [41, 42], "229994": [41, 42], "23": [5, 34, 35, 36, 41, 42, 44, 51, 52, 53, 56, 57, 61, 63, 64, 65, 66, 68, 71, 73, 74, 76], "230": 76, "230009": [47, 48], "2307": [34, 51, 60], "230956": 45, "231": [14, 75], "23113": 65, "231153": 42, "231310": 56, "231330e": 42, "231430": 68, "231467": 65, "231986": 56, "232134": [41, 42], "2328": 53, "232959": [47, 48], "233": 21, "233029": 41, "233154": 76, "234": 74, "234205": 53, "234534": 43, "234605": 37, "234798": 53, "234812e": 42, "234910": 51, "235": 75, "235501e": 41, "235873": 41, "2359": 76, "23590": 53, "236008": 43, "236309": 53, "23690345e": 66, "237": [32, 36], "237252": 53, "237292": 42, "237341": 41, "237430": 42, "237461": 57, "23748": 53, "23751359e": 66, "237896": 56, "23789633": 56, "238": [34, 51, 75], "238101": 56, "238225": 68, "238251": 43, "238529": 8, "23856": 53, "238794": 56, "239": 75, "239313": 42, "239317": 42, "23965": 53, "239799": 41, "23990390": 66, "23e": 35, "24": [34, 35, 36, 41, 42, 48, 51, 52, 53, 56, 57, 58, 63, 64, 65, 66, 68, 73, 74, 75, 76], "240127": [41, 42], "240295": 57, "240532": [41, 42], "2408": 66, "24080030a4d": 36, "240813": 49, "241049": 56, "241063": 41, "241064": 42, "241609": 53, "241678": 41, "24199": 53, "242": 74, "242000": 53, "242124": [52, 53], "242139": 68, "242158": [52, 53], "2422992546": 66, "2424596822": 48, "242815": 68, "242902": 56, "243246": 56, "2438": 53, "2439": 53, "244": 53, "244090": 53, "244455": 56, "244622": 68, "24469564": 73, "245": 74, "245062": 56, "24510393": 35, "245370": 51, "245416": 42, "245512": 56, "245720": 45, "246": 75, "24657516": 66, "246624": 63, "246731": 52, "2467506": 34, "246753": 56, "246879": 56, "247": 75, "247020": 43, "247057e": 56, "2471": 53, "2472": 53, "247207": 42, "247617": 63, "247717": 53, "24774": [52, 53], "247826": 51, "248171": 56, "248638": 43, "249": [34, 51, 54], "2491": 53, "249109e": 42, "24917": 53, "24942269": 66, "25": [13, 16, 17, 18, 22, 23, 24, 34, 35, 36, 41, 42, 43, 45, 46, 51, 52, 53, 56, 58, 63, 64, 65, 66, 68, 73, 76], "250": 54, "2500": 53, "25000000000000006": [43, 53, 56], "250073": 53, "2501763": 66, "250210": 43, "2503": 53, "250354": 56, "25037345": 66, "250425": 43, "251": [53, 57], "251101": [63, 64, 65], "251412": 42, "251480": 42, "251953": 53, "252133": 53, "252253": 57, "25240463": 65, "252524": 56, "252601": 68, "252644": 41, "253026": [41, 42], "2532": 53, "253437": 55, "253724": 56, "25374": 53, "254": 53, "25401679": 34, "254038": 48, "2543": 53, "254324": 43, "254400": 68, "254551": 42, "255": 53, "255598": 42, "256": [53, 64], "256416": 56, "256567": 51, "25672": 53, "256944": 56, "256983": 11, "256992": 53, "257207": 34, "257377": 45, "258158": [41, 42], "2583": 53, "258951": 56, "259118": 49, "2594": [35, 52], "259828": [41, 42], "25x_3": 45, "26": [34, 35, 36, 37, 41, 42, 44, 51, 52, 53, 58, 61, 63, 64, 65, 66, 68, 73], "26016": 53, "260161": [12, 63], "260211": [41, 42], "260356": 52, "260360": 56, "260687": 42, "2610": 53, "2613": 53, "261624": [52, 53], "261685": 53, "26175": 53, "261777": 53, "26184834": 66, "261903": 51, "2619317": 34, "262000e": 41, "262357": 42, "262423e": 53, "262621": 51, "262829": 66, "263": [14, 53], "2633": 53, "263672": 41, "263974e": 56, "264": 74, "264086": 45, "264274e": 53, "264884": 53, "265119": 55, "2652": [36, 52, 53], "265547": 53, "2658": 48, "266": 32, "266922": 68, "267": 54, "2670691": 34, "267099": 41, "26739906": 66, "267500": 51, "267581": 53, "267767": 42, "267950": 56, "268055": 53, "268942": 56, "268998": 35, "269043": 56, "2695553": 66, "269977": 53, "26bd56a6": 36, "26e": 35, "27": [16, 17, 18, 33, 34, 35, 36, 37, 41, 42, 44, 51, 52, 53, 58, 61, 63, 64, 65, 66, 68, 73, 74], "2700": 36, "270644": [41, 42], "270694e": 41, "271004": [52, 53], "271083": 53, "272296": 53, "272408": 42, "272662": 53, "273": 36, "273356": 43, "27371": [35, 52], "27372": [35, 52], "274": [36, 53], "274247e": 52, "274267": 51, "27429763": 65, "274430": 42, "274793": 56, "274825": [13, 63], "27487": 53, "275535": 41, "275596": 68, "276": 36, "276148": 56, "276189e": 51, "2764": 53, "2766091": 35, "27713": 53, "277299": 37, "27751": 53, "277561e": 51, "277968": 56, "278": 57, "2780": 34, "278000": 51, "278303e": 41, "278391": 53, "278434": 47, "2786": [68, 70], "278683": 41, "27951256e": 66, "27986": 53, "28": [34, 35, 36, 41, 42, 46, 49, 51, 52, 58, 63, 64, 65, 66, 68, 73, 75], "280": 32, "280196": 48, "280454dd": 36, "280514": 68, "280963": 55, "281": 54, "281024": 56, "28111364": 35, "2815": 53, "2819": [68, 70], "282": 74, "282200": 48, "2825": [71, 73], "28251": 53, "282870": 53, "2830": [71, 73], "28326": 53, "2836059": 34, "28382": 53, "283974": 56, "283994": 56, "28425026": 57, "284271": 49, "284397": 76, "28452": [35, 52], "2849": 53, "284949": 42, "284987": 53, "286027": 63, "286203": 41, "2865": 53, "286507": 43, "286563e": 53, "286593": 53, "287011": 42, "287041": 56, "287384": 57, "287815": 57, "287926": 56, "288": 54, "288006": 52, "288850e": 41, "288976": 53, "289": 74, "289357": 42, "289440": [41, 42], "289718": 41, "29": [11, 34, 35, 36, 41, 42, 51, 52, 57, 58, 63, 64, 65, 66, 68, 73], "290987": 52, "291": 53, "2910": 53, "291008": 41, "291011": 65, "291071": 56, "29107127": 56, "291405": 56, "291406": 56, "291434": 42, "291500e": [52, 53], "291517": [41, 42], "291963": 56, "292": 55, "292028": 43, "292047": 68, "292105": 56, "292178": 52, "292302995303554": 43, "292303": 43, "2925": 36, "2927": 53, "292997": 56, "29299726": 56, "293218": 56, "293617e": 53, "293960": 41, "294067": [41, 42], "295": 74, "295481": 56, "29548121": 56, "295642": 41, "295837": [37, 61, 73], "2958370000000100000100": [36, 61, 73], "2958370001000010011100": [36, 61, 73], "2958371000000010010100": [36, 61, 73], "296228": 53, "296585": 42, "296729": 51, "29678199": [59, 67], "296901": 41, "297136": 66, "297287": [41, 42], "2973": 53, "297349": [47, 48], "297682": 56, "297687": 53, "297749": 53, "297779e": 42, "29784405": 57, "298": [21, 36], "298076": 41, "298120": 43, "298228e": 53, "299": [32, 36], "2991": 66, "299537": 48, "299712": 47, "2_": [26, 58, 69], "2_x": [26, 58], "2d": 67, "2dx_5": [43, 56], "2e": [32, 34, 35, 36, 64, 65, 67, 68, 73], "2f": 49, "2m": 69, "2n_t": 45, "2x": 56, "2x_0": [19, 41, 42, 47, 48], "2x_4": 45, "3": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 24, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "30": [19, 32, 33, 34, 36, 39, 40, 41, 42, 43, 44, 51, 52, 53, 56, 58, 63, 64, 65, 66, 68, 73], "300": [33, 40, 43, 53, 56, 60, 74], "30000000000000004": [43, 53, 56], "30031116e": 66, "30093956": 57, "301": 36, "301366": 68, "301371": 56, "3016": 52, "301737": 41, "30189": 53, "302357": 56, "302571": 63, "302648": 51, "3028560": 66, "303007": 41, "303324": 51, "303489": 56, "303613": 56, "30361321": 56, "30383": 53, "303835": 51, "303f00f0bd62": 36, "304130": 56, "304159": 56, "304201": 45, "304217": 41, "305133": 63, "305255": 42, "30527": 53, "305341": 56, "305612": 51, "305775": 56, "305b": 36, "30645": 53, "30672815": 34, "306915": 51, "306963": 56, "307176": 41, "307407": 56, "308": 53, "3082218005": 66, "308568": 42, "308774": 41, "30917769": [47, 48], "309605": 41, "309772": 51, "309823e": 53, "30982972": 56, "309830": 56, "31": [34, 35, 36, 41, 42, 51, 52, 53, 58, 63, 64, 65, 66, 68, 73, 76], "310000e": 53, "310761": 55, "311253": 53, "311712": 47, "3120": 53, "312008": 42, "312882": 42, "313056": 68, "313209": 43, "313324": 53, "31337878": 53, "313535": 56, "31378": 36, "314": 66, "314071e": 41, "3141": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 36, 37, 51, 59, 61, 63, 64, 67, 68, 70, 73], "314341": 41, "314625": 42, "314651": 47, "31476": [52, 53], "3151": 53, "315155": 42, "315290": [47, 48], "315310": 41, "316": 36, "316193": 56, "31632": 53, "316407": 65, "316540": 51, "316541": 54, "316717": [41, 42], "316863": 42, "317064": 41, "317394": 45, "317487": 56, "317607": 56, "318": 36, "318000e": 53, "318438": 53, "318552": 53, "318584": 68, "318753": [47, 48], "319": 36, "319100": [47, 48], "319759": 56, "319850": 56, "32": [34, 35, 36, 41, 42, 51, 52, 53, 58, 63, 64, 65, 66, 67, 68, 73], "320": [53, 54], "320314": 52, "320633": 43, "321520": 42, "321686": 68, "32221349": 66, "32236455588136": 44, "322404": 57, "3234": 53, "323622": 52, "323679": 51, "324": [35, 53], "324518": 55, "32458367": 34, "3245837": 56, "325056": 56, "325090": 53, "325184": 54, "326148": 42, "326740": 56, "327": 32, "327265": 42, "327803": 63, "329181": 42, "329339": 44, "32950022e": 66, "329679": 42, "33": [34, 35, 36, 41, 42, 47, 51, 52, 53, 58, 63, 64, 65, 66, 68, 73, 74, 76], "3300": [35, 52], "330143": 56, "33014346": 56, "330285": [41, 42], "3304269": 34, "330615": 56, "330731": [13, 63], "331365": 47, "331521": 56, "331602": 53, "331640": 42, "33175566": 56, "331756": 56, "332502": 42, "332782": [13, 63], "3329": 53, "332996": 51, "3333": [33, 34, 40, 63, 64, 65], "3333333": 36, "33335939e": 66, "3335": 53, "333575": 52, "333655": 41, "333704": 42, "334": [35, 54], "334425": 41, "3347": 66, "334750": 43, "334785": 49, "33500": 53, "335121": 42, "335176": 53, "33527": 57, "3355408": 66, "335609e": 56, "335846": 56, "335853": 53, "336153": 41, "336461": 53, "336510": 42, "336612": 45, "337380": 56, "337619": 44, "338": 57, "33849": 53, "3386": 66, "338603": 41, "338775": 43, "338900": 42, "338908": 43, "339273": 57, "33928": 53, "339570": 56, "339875": [47, 48], "34": [33, 34, 35, 36, 41, 42, 48, 51, 52, 53, 57, 58, 63, 64, 65, 66, 68, 76], "340": [35, 53], "340485e": 41, "341336": [9, 63], "3420": 53, "342467": 63, "342675": 34, "34287815": 57, "342989": 53, "342992": 51, "343": 53, "344212": 76, "344305": 49, "344505": [52, 53], "344640": 56, "34475": 52, "344787": [41, 42], "344834": 45, "345065e": 53, "345381": 43, "3453813031813522": 43, "3454": 53, "345852": 42, "345903": 56, "345989": 41, "346206": 56, "346238": 57, "346269": 42, "346678": 55, "347310": [13, 63], "347696": 43, "34769649731686": 43, "347921": 54, "347929": 53, "34858240261807": 44, "348617": 56, "348700": 42, "349383": 51, "34943161": 50, "349638": 42, "34967621": 34, "349772": 48, "35": [35, 36, 41, 42, 43, 51, 52, 53, 54, 56, 63, 64, 65, 66, 68, 69, 76], "3500000000000001": [43, 53, 56], "350165": 64, "350208": 41, "350518": 56, "350712": [47, 48], "35077502": 69, "351629": 53, "351766": 55, "352": [35, 51], "352250e": 52, "352259e": 53, "3522697": 34, "352365": 41, "352813": [63, 64, 65], "35292": 53, "352990": 53, "352998": 53, "353412": 56, "35341202": 56, "35365143": [2, 4, 5, 7, 8, 9, 10, 11, 12], "353748e": 56, "354": 53, "354188": 45, "354371": 56, "354483": 54, "354688": 10, "3550164": 66, "355209": 56, "355699e": 41, "356136e": 53, "356167": 48, "356183": 53, "35620768e": 66, "3564": 53, "3565": 53, "3567657": 66, "35688": 66, "356886e": 42, "3569": 65, "357": 53, "357170": 41, "35731523": 65, "358158": [52, 76], "358289": 51, "358395": 57, "358653": 42, "358799": 68, "358977": 52, "359": [32, 76], "359100": 53, "3593": 57, "359307": 42, "35th": 74, "36": [35, 36, 41, 42, 51, 52, 63, 64, 65, 66, 68, 76], "360004": 56, "360065": 68, "360122": 41, "360475": [41, 42], "360655": 53, "360683": 43, "360801": 43, "361518": 43, "361518457569366": 43, "361521": 10, "3619201": 20, "362155e": 42, "3622318": 65, "36231307e": 66, "363276": 34, "3643": [68, 70], "364595": 34, "3647": 36, "364800": 56, "36501": 53, "36557195e": 66, "36566025e": 66, "366": 53, "3660403": 66, "36616": 53, "366529": 55, "366541e": 41, "366718627": 34, "366950": 41, "367056": 42, "367181": 41, "367323": 56, "367571": 43, "367625": 56, "368092": 42, "368152": 51, "3682": [35, 52, 53], "368324": 51, "368499": 43, "3684990272106954": 43, "369556": 43, "3696": 57, "369796": 56, "369869": 52, "369981": 51, "37": [35, 41, 42, 51, 52, 53, 63, 64, 65, 66, 68], "3702770": 34, "370736": 51, "3707775": 34, "3710": 53, "371357": [52, 53], "371429": 43, "371535": 41, "372": 74, "37200": [52, 53], "372097": 43, "3722": 53, "37231324": 58, "3724": 53, "372427": 42, "372628": 41, "3727679": 34, "372989": 41, "373802": 42, "3738573": 34, "374364": 56, "37436439": 56, "3745": 53, "374821e": 53, "374862": 41, "375077e": 41, "375081": 53, "375465": 56, "376": 32, "376760": 42, "376780": 41, "376806": 42, "377060": 53, "377311": 56, "37743524": 65, "377669": 42, "37782452": 66, "37790426": 66, "378351": 7, "378588": 41, "378596": 51, "378688": 56, "378828e": 41, "378834": 56, "3788859": 34, "379": 74, "379038": 56, "379117": 41, "37939": 53, "379614": 56, "379626": 41, "38": [36, 41, 42, 52, 63, 64, 65, 66, 68, 76], "3800694": 34, "380170e": 41, "380432e": 42, "380837": [52, 53], "381072": 56, "38118359": 66, "381603": 41, "381623e": 48, "381685e": [52, 53], "381689": 56, "3817": 53, "381826": 11, "382188e": 42, "382286": 53, "382582e": 2, "382684": 63, "382872": 43, "383297": 56, "384": 53, "384443": 42, "384777": 53, "384928": 41, "3851": 53, "385240": 68, "385877e": 42, "385917": 51, "386": [36, 53], "386102": 43, "386502": 53, "386834": 42, "386894": 42, "386988": 44, "387": 36, "38700566": 66, "387426": 56, "387780": 56, "388071": 56, "38818693": 66, "388216e": 64, "388298e": 41, "388593e": 42, "388668": 56, "38866808": 56, "388871": 53, "389": 36, "389126": 65, "3893058": 66, "389566": 55, "38973512e": 66, "38990574": 66, "39": [32, 34, 35, 36, 37, 41, 42, 44, 48, 49, 50, 51, 52, 53, 57, 58, 63, 64, 65, 66, 68, 76], "39010121e": 66, "390379": 56, "390599": 42, "392242": 49, "392400": 53, "392623": 42, "392752": 44, "392833": 57, "392864e": [52, 53], "39304610": 66, "393060": 63, "393604": 43, "393903": 54, "39425708": 34, "395076e": 53, "395136": 51, "395268": 63, "395603": 41, "395889": 53, "39611477": 35, "396173": 47, "39621961e": 66, "396300": 47, "3964": 53, "396531": 53, "396985": 51, "396992": [41, 42], "397140": 43, "397155": 42, "39727": 53, "397578": 49, "397811": 57, "398": [61, 73], "3985": 53, "398770": 56, "398835": 66, "398999": 63, "399": 35, "399056": 56, "399207": 42, "399223": 45, "399355": 45, "399692": 56, "3cd0": 36, "3dx_1": [43, 56], "3e1c": 36, "3ec2": 36, "3f5d93": 54, "3x_": 56, "3x_4": [43, 56], "4": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 26, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 75], "40": [34, 41, 42, 43, 44, 48, 52, 53, 56, 58, 61, 63, 64, 65, 66, 68, 69], "400": 51, "4000000000000001": 64, "40000000000000013": [43, 53, 56], "400164": 49, "40029364": 69, "400823": 56, "400855956463958": 43, "400856": 43, "400910": 41, "401": [14, 76], "401247": [67, 68], "40127723e": 66, "401861": 41, "401931": [47, 48], "402077": 53, "402113": 68, "4022": 66, "402301e": 64, "402902": 53, "403425": 56, "4035699755": 59, "403569975514042": 59, "4035699755140420": 59, "403715": 2, "4037269089": 67, "404411": 41, "40452": 53, "404550": 55, "405203": 45, "405374": 53, "405400e": 41, "405890": [13, 63], "406": 52, "406285": 56, "406446": 43, "4065173": 66, "407558": 41, "408014": 49, "4083642": 66, "408476": 69, "40847623": 69, "408479": 51, "408539": 56, "408565": 56, "4093": 57, "409328": 53, "409395": 56, "409746": 43, "409848": [41, 42], "40997195": 66, "41": [41, 42, 52, 53, 63, 64, 65, 66, 68, 70, 76], "410124": 42, "410393": 43, "4105307": 66, "410667": 63, "410681": 45, "410795": 51, "41093655": 66, "411190": [41, 42], "411291": 55, "411295": 56, "411304": [41, 42], "411447": 53, "411582": 56, "411869": 42, "412004": 47, "412127": 56, "412477": 45, "412653": 51, "412714": 43, "412726": 42, "412838": 42, "41336": 64, "41341040": 34, "413608": 56, "413933e": 42, "414": 32, "414073": 8, "414533": 42, "41525168e": 66, "415465": 42, "41566": 65, "415812": 76, "415988": 53, "416132": 42, "4166": 53, "4166667": 36, "416757": 56, "416899": 41, "41702876": 65, "417335e": 66, "417640": 41, "417767": [47, 48], "417822": 52, "41798768e": 66, "418056": 56, "41805621": 56, "41836": 52, "418360": 52, "418806e": 43, "41918406e": 66, "419371": 56, "4197205": 66, "41989983e": 66, "4199952": 34, "41e5": 36, "42": [4, 5, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 53, 55, 56, 57, 58, 63, 64, 65, 66, 68, 70, 74, 76], "4200": 53, "420316e": 53, "420608e": 57, "42073312": 34, "420967": 43, "4211349413": 34, "421234": 63, "421357": [47, 48], "421576e": 53, "421793": 57, "421919": 53, "422007": 57, "422266": 53, "422293e": 63, "422325": 43, "42338": 53, "4235839": [47, 48], "42388745": [58, 65], "423921e": 63, "424108": 43, "424127": 66, "42412729": 34, "424292": 41, "424328": 56, "424651": 65, "424700": 42, "424717": 43, "424889": 54, "425": 51, "425072": 48, "425208": 53, "4254397": 66, "42550": 53, "426283": 41, "426540": 51, "426540301": 34, "426736": 53, "427": 53, "427101": 41, "427486": [41, 42], "42755087": 57, "427551": 57, "427573": 51, "427725": 56, "428": [68, 70, 76], "428046": 55, "42811700": 76, "428255": 56, "428411": [52, 53], "428467": 56, "4284675": 56, "428588": 41, "428771": [13, 63], "429057": 42, "429705": 41, "429986": 42, "42ba": 36, "43": [35, 41, 42, 63, 64, 65, 66, 68, 76], "430298e": [52, 53], "430595": 42, "4311947070055128": 64, "431306": 56, "4313332": 66, "431701914": 71, "431848": 41, "431852": 42, "432125e": 52, "432300e": 56, "43231359e": 66, "432484": 41, "43294": 36, "432f": 36, "433": 36, "433221": 43, "4336": 53, "43374433": 58, "433750": 41, "434519": 63, "434535": 56, "43453524": 56, "434677": 42, "435": 36, "43511": 53, "435401": 51, "4357": 53, "435927": 53, "435967": 51, "43597565": 56, "435976": 56, "436": [36, 53], "436194": 41, "43627032": 44, "436327": 53, "436806": 53, "437594": 41, "437767": 52, "437924": 53, "438": 51, "438219": 56, "438289": 53, "438569": 53, "438578e": 53, "438709": 52, "43883": 48, "4389": 53, "438960": 51, "439541": [52, 53], "43989": 63, "43f0": 36, "44": [41, 42, 44, 63, 64, 65, 66, 68], "440320": 53, "440364": 63, "440605": 64, "440747": 41, "440a": 36, "441153": 56, "441209": 56, "441219": 47, "4416552": 34, "441893": 41, "442202": 42, "44239736": 66, "442462": 42, "443016": 43, "443032": 52, "44312177": 35, "443686": 56, "4437": 53, "443701": 49, "444046": 53, "44408333": 57, "44414044": 57, "44427868": 57, "44435333": 57, "4444": [33, 34, 40, 65], "444500": [52, 53], "4448089": 57, "44482929": 57, "444850": 53, "44488518": 66, "4449272": 53, "445473": 41, "445476": 41, "44563945e": 66, "445642": 41, "4461928741399595": 43, "446193": 43, "4462": 36, "44647451": 57, "44713577e": 66, "447492": 53, "447624": [41, 42], "447706": 43, "447849": 44, "447999": 48, "448": [32, 53], "4482213": 66, "448587": 43, "448745": 56, "448842": 42, "4489": 53, "44890536": 66, "448923": 49, "448973": 42, "449107": 5, "449150": [13, 63], "449406e": 41, "44950": 53, "44fa97767be8": 36, "45": [41, 42, 43, 47, 49, 52, 53, 56, 63, 64, 65, 66, 68], "4500": 52, "45000000000000007": [43, 53, 56, 64], "450152": 51, "450870601": 34, "450926e": 41, "45143571": 65, "452": 36, "452091": 53, "452114": 63, "452484e": 42, "452488701": 34, "452489": 51, "453": 36, "453279": 41, "4535": 53, "4539": 36, "454081": 53, "454185": 42, "454397": 56, "45467447": 66, "455": 36, "45500": 53, "455078": 43, "455091": 42, "455107": 43, "455120": 56, "4552": 36, "455293": 43, "4552b8af": 36, "455448": 57, "455672": 53, "4559565": 68, "45595650": 68, "455981": 69, "456370": [42, 51], "456432": 41, "456552": 63, "4567": 57, "456892": 43, "457088": 56, "457252": 42, "457667": 53, "458114": 53, "458420": 53, "4584447": 34, "458784": 41, "458855": 35, "458976": 42, "4592": 34, "459200": 51, "459383": 43, "45957837": 66, "459584e": 42, "459760": 53, "459812": 43, "459913": 41, "46": [41, 42, 49, 63, 64, 65, 66, 68, 70], "460": 53, "4601": 53, "460207": [41, 42], "460218": 43, "460289": 56, "460535": 63, "4610": 76, "461458": 42, "462321": 11, "46239231": 66, "462451": 43, "462567": 42, "462979": 41, "463325": 56, "4634": 53, "463668": 53, "463766": 48, "463857": 53, "463903": 42, "463b": 36, "464076": 43, "464284": 51, "46448227": 66, "464668": [9, 63], "46507214": 57, "465212699957609": 59, "4652126999576090": 59, "4652127": 59, "465832": 42, "466047": 56, "46618738": 66, "466440": 43, "466756": 56, "467": 53, "46709481": 66, "46722576e": 66, "467613": 51, "467613401": 34, "467681": [41, 42], "467770": 43, "468051e": 42, "468072": 42, "468075": 56, "46807543": 56, "46811985": 56, "468120": 56, "468406": 53, "468919": 53, "468d": 36, "469": 36, "469825": 43, "469895": 42, "47": [35, 41, 42, 44, 52, 57, 63, 64, 65, 66, 68, 75], "470458": 41, "470904": 41, "472": 53, "47222159": [58, 65], "472255": 53, "472657": 42, "472891": 56, "472e": 36, "473099": 43, "47419634": 73, "474214": [47, 48], "474731": 63, "474846": 52, "475304": 53, "475569": 41, "47659": 65, "476856": 43, "477130": [41, 42], "477150": 56, "477247": 42, "477443": 41, "477474": 51, "47759584": 66, "47761563": 44, "478032": 53, "4781": 53, "47857478": 66, "47966100e": 66, "479722": 42, "479860": 53, "479876": [47, 48], "479882": 42, "479928": 56, "47be": 36, "48": [36, 41, 42, 52, 53, 63, 64, 65, 66, 68], "480133e": 56, "48029755": 57, "480579": 42, "48069071": [59, 67, 68], "480691": [67, 68], "480800e": 56, "481172": 56, "481218": 53, "481399": [52, 53], "481705": 65, "481761e": 53, "482": 36, "482012": 47, "482038": 43, "48208358": 56, "482084": 56, "482461": 69, "48246134": 69, "482483": 56, "482790": 45, "48296": 57, "483": 32, "48315": 57, "483186": 45, "483192": [52, 53], "48331": 57, "4835": 53, "483711": 56, "483717": 43, "48390784": 65, "483944": 41, "48404": 34, "4845": 53, "484640": 56, "4849": 36, "485": [36, 53], "485377": 41, "485617": [52, 53], "485812e": 53, "48583": [52, 53], "48584006": 65, "485871": 48, "486": [22, 53], "486202": 43, "486532": 56, "48661": 53, "487": 53, "487467": 53, "487641e": 56, "487872": 39, "488460": 53, "488485": 53, "48873663": 44, "488811": 56, "488909": [52, 53], "488982e": 43, "4895498": 56, "489550": 56, "489699": 43, "49": [36, 41, 42, 63, 64, 65, 66, 68], "490000e": 53, "490070931": 34, "490488e": 52, "490504e": 53, "490700": 56, "490941": 53, "49098": 64, "491034": 41, "491245": 51, "4915707": 65, "492": 53, "49203859": 65, "492417e": 65, "492454": 42, "492656": 42, "49270769e": 66, "493": 74, "493219": 56, "493313": 53, "493325": 4, "494089": 42, "494129": 56, "494324": 51, "494324401": 34, "495": 55, "49530782": 34, "495657": 43, "495752": 56, "4958502": 59, "495850216426873": 59, "4958502164268730": 59, "49596416e": 66, "496": 55, "49650883": 57, "496551": 56, "496777": 76, "497": 55, "497298": 63, "497422": 42, "497655": 5, "497674": 44, "497904": 54, "497964": 63, "498": 55, "498921": 56, "498979": 53, "498f": 36, "499": [53, 55, 61, 73], "499000e": [52, 53], "499239": 54, "499776": 53, "49d4": 36, "4a53": 36, "4b8f": 36, "4dba": 36, "4dd2": 36, "4e": [34, 35], "4ecd": 36, "4fee": 36, "4x": 56, "4x_0": [19, 41, 42, 47, 48], "4x_1": [19, 41, 42], "5": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75], "50": [13, 34, 36, 43, 45, 48, 50, 52, 53, 54, 56, 63, 64, 65, 66, 68], "500": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, 21, 24, 33, 36, 37, 40, 41, 42, 47, 48, 50, 52, 55, 57, 60, 61, 63, 64, 65, 67, 68, 69, 70, 73, 76], "5000": [41, 42, 43, 56], "50000": 51, "500000": [52, 53], "5000000000000001": [43, 53, 56], "50003363": 65, "500084": 56, "500267": 49, "5003517412": 34, "500517": 56, "500761": 54, "50093148e": 66, "501021": 53, "50173922": 65, "501954": 42, "501983": 56, "502054": 42, "502084": 65, "502096": 54, "502494": 43, "5025850": 34, "502595": 42, "502612": 56, "502843e": 42, "502901": 42, "502995": 56, "503504": 64, "503511": 53, "50398782e": 66, "504286": 51, "5042861": 34, "50430434": 66, "504569": 41, "505056": 54, "5050973": 34, "505913": 41, "506050": 41, "506159e": 41, "506644": 41, "506659": 53, "506687": 53, "50672034": 34, "506900e": 56, "506903": 43, "50768b": 54, "508153": 55, "508433": 41, "508459": 51, "5085": 53, "508630": 42, "508947": 65, "509059": 53, "509196": 56, "509339693389362": 59, "5093396933893620": 59, "5093397": 59, "509461": 56, "509782": 42, "5098": [37, 61, 73], "509853": 56, "5099": [36, 37, 61, 73], "509951": 43, "509958": 51, "51": [35, 36, 47, 63, 64, 65, 66, 68, 75], "510000e": [52, 53], "510385": 51, "51079110": 34, "510982": 52, "511022": 63, "511293": 52, "511515": 53, "511540": 53, "511862": 56, "512": 51, "512081e": 41, "512108": 56, "512149": 56, "51214922": 56, "51243406e": 66, "512519": 51, "512572": 56, "512672": [65, 69], "512832": 41, "513052": 41, "5131": 52, "513992": 56, "514": 36, "514160": 41, "514173": 42, "514545": 53, "515031": 41, "515358": 43, "5154": 53, "5154789948092002": 51, "5155": 36, "516": 36, "516125": 43, "516222": 56, "516255": 56, "516256": 56, "516528": 56, "516888": 41, "517": [36, 51], "517266": 42, "5175": 53, "517785": 41, "518175": 51, "518446": 53, "518682": 42, "518767": 41, "518782": 53, "518846": 51, "519622": 41, "51966955": 34, "519710": 56, "519888e": 42, "52": [36, 49, 54, 63, 64, 65, 66, 68], "520": 53, "520641": 57, "520930": 43, "521002": 43, "521085": 63, "521611": 42, "52198357": 66, "522753": 10, "522835": 45, "523163": 43, "52343523e": 66, "523794e": 56, "523807": 55, "523977545": 34, "524088": 41, "52424539": 34, "524657": 56, "5249": 64, "524934": [41, 42], "5250": 53, "52510803": 35, "525135": 42, "525138": 41, "5255": 36, "52590": [35, 52], "526": 51, "526532": 53, "526769": [41, 42], "527452": 42, "527728": 42, "528381e": 58, "528580": 56, "528937": [47, 48], "528996901": 34, "528997": 51, "529": 51, "52984981": 66, "529969": 42, "53": [36, 61, 63, 64, 65, 66, 68, 71, 74], "530940": 56, "53094017": 56, "531": 36, "531223": 43, "531594": 53, "53209683": 65, "532266": 43, "53257": 64, "532738": 56, "53273833": 56, "532751": 47, "5329": 53, "533489": 45, "533900": 56, "5346": 36, "535179": 56, "535278991538703": 59, "535279": 59, "535318": 56, "535609": 53, "535718e": 53, "535726e": 66, "53606675": 56, "536067": 56, "536143": 53, "536746": 56, "536798e": [52, 53], "537240": 56, "53724023": 56, "538": 36, "538013": 53, "5382": 57, "538937": [52, 53], "539455": 56, "539475": 56, "53947541": 56, "539491": [47, 48], "539767": 43, "54": [35, 36, 44, 60, 63, 64, 65, 66, 68, 75], "540240": 53, "540270": 42, "540542": 52, "540789": 41, "541159": 56, "54163": 57, "541821": 53, "541990": 53, "542159": 42, "542333": 53, "542451": 56, "542584": 43, "5425843074324594": 43, "542647": 56, "542671": 51, "542816": 11, "5428753": 59, "54287532563466": 59, "542883": 69, "5428834": 69, "542919": 63, "542989": 56, "543": [51, 53], "543075": 43, "543136": 43, "543358": 63, "543380": 51, "5436005": 34, "543691": 42, "543764": 48, "54378": 57, "543832": 56, "544097": 56, "5443965": [67, 68], "54440": [67, 68], "544555": 51, "544669": 47, "54517706e": 66, "545602": 42, "545605e": 56, "545919": 53, "546294": 53, "5467606094959261": 43, "546761": 43, "547039": 41, "54716": 57, "547324": 42, "547431": 55, "5476": 53, "5479": 53, "547909": 53, "549109e": 53, "549645": 63, "55": [35, 36, 43, 48, 52, 53, 56, 63, 64, 65, 66, 68], "5500000000000002": [43, 53, 56], "551317": 42, "551355": 42, "551586928482123": 43, "551587": 43, "551686": 43, "55173": 64, "5518": 53, "552": 53, "552058": 57, "552508": 53, "552727": 51, "552776": 56, "55348": 64, "553878": [12, 63], "553916": 53, "553965": 41, "554076": 43, "554203": 42, "554793e": 66, "555": 51, "5550134": 66, "555137": 42, "555150": 53, "555445": 55, "555498": 56, "5555": [33, 40], "555536": 41, "555949e": 53, "555954": 53, "556191": [41, 42], "556792": 56, "557267": 41, "5574dcd4": 36, "557595": 51, "557731": 55, "557999": 51, "558134": [41, 42], "5584": 51, "5585": 51, "558655": 43, "5589": 51, "559": 76, "5590": 51, "559144": 43, "559186": 43, "5592": 51, "559394": 56, "559522": 56, "559680": 53, "55dc37e31fb1": 36, "55e": 35, "56": [36, 60, 63, 64, 65, 66, 68, 71, 74], "560135": [67, 68], "56018481": 56, "560185": 56, "5602727": 44, "560545e": 41, "561183e": 42, "5616": 52, "561711": 53, "561785": 65, "561819": 41, "562001": 42, "562013": 56, "562153": 41, "56223": 57, "562518": 53, "562557": 41, "562712": [41, 42], "563374e": 43, "563503": 56, "563528": 53, "563673": 53, "563851e": 41, "56387280e": 66, "56390147e": 66, "564045": 56, "564073": 53, "5641": 53, "564142": 43, "564232": [41, 42], "564451": 42, "564537": 42, "564577": 53, "565066": 43, "566024": 56, "566091": 53, "567004": 57, "567343": 53, "567364": 42, "567529": 56, "567531": 41, "567568": 41, "567695": 41, "567945": [47, 48], "568111": 63, "568916e": 66, "569135": 42, "569540": 42, "56965663": 56, "569657": 56, "569684": 42, "569911": 34, "5699994715": 34, "57": [36, 63, 64, 65, 66, 68, 76], "570038": 43, "5700384030890744": 43, "570111": 55, "5702": 53, "570722": 73, "570936": 41, "571707": 63, "5718": 53, "572153": 63, "5722": 52, "57245066": 56, "572451": 56, "572991": 42, "573700": 45, "574": 36, "574904": 42, "57496671": 34, "575": 15, "57505": 64, "575810": 41, "57592948e": 66, "576": 36, "5763996": 34, "577": 36, "5770": 52, "57715074": 34, "577271": 51, "577422": 41, "577807": [41, 42], "577813": 41, "578081": 53, "578307": 56, "578523": 51, "578557": 42, "578846e": 43, "57914935": 35, "579238": 43, "579322e": 52, "579605e": 42, "57e": 35, "58": [35, 52, 63, 64, 65, 66, 68, 75], "5800": 53, "58000": 52, "580231e": 42, "580368": 41, "5804": 36, "580477e": 42, "580922": 47, "581655": 53, "581849": 42, "581868": 41, "582146": 42, "58241568": 66, "582747": 42, "582761": 43, "583034": 47, "583195": [41, 42], "5833333": 36, "583404": 52, "583508": 41, "583534": 56, "584012": 53, "584742": 48, "584849": 43, "584877": 42, "584928": 41, "584942e": 51, "5852": 53, "585223": 54, "585426": 66, "585793": 43, "586362": 56, "5866": 53, "586719": 43, "586719493648897": 43, "5868472": 34, "587135": 42, "587292": 53, "58765": 64, "588": 53, "588000": 63, "588364": 63, "588992e": 42, "589248": 57, "589440": 43, "59": [32, 63, 64, 65, 66, 68], "590320": 45, "5905": 52, "590736": 56, "590813": 56, "590911": 43, "590991": 43, "59101823293537384143455359677375829194": 66, "591080": 45, "591411": 47, "591441": 2, "591741": 52, "591782": 56, "591788": 52, "59199423e": 66, "592186": 42, "592681e": 43, "59307502e": 66, "593648": 64, "593754e": 48, "593981": 63, "594": 15, "594241": 63, "594316e": 56, "595353": 43, "596": 53, "596069e": 53, "5962": 52, "596270": [47, 48], "596758": 41, "597": 35, "597098": 53, "597236182": 66, "597923": 53, "598080": 41, "598178": 53, "598539": 42, "5985730": 35, "59861": 53, "59867547": 66, "5987": 50, "5cb31a99b9cc": 36, "5d": [43, 56], "5x_2": 45, "5x_3": 45, "5z_i": 56, "6": [2, 4, 5, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 22, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75], "60": [34, 43, 44, 53, 54, 56, 58, 63, 64, 65, 66, 68, 74], "600": 51, "6000": 53, "6000000000000002": [43, 53, 56], "600000e": 53, "600254": 55, "600438": 49, "600694": 65, "600934": 63, "601": 35, "601061": 43, "601149": 41, "601314": 41, "601598": 51, "601645": 42, "602079": 48, "602168": 43, "602587": 56, "602628": 43, "6029": 53, "603273": 41, "604016": 53, "604111": 53, "604227": 52, "604603": 5, "604825": 53, "604841": [52, 53], "605": 53, "605195": 48, "606034": 56, "606129": 56, "606342": 43, "606759": 53, "6068": 34, "606800": 51, "606954": 43, "607080": 42, "607264": 41, "6075": 76, "607600": 53, "608": 46, "608003e": 42, "608392": 56, "608818": 57, "609205": 41, "609575": 65, "61": [63, 64, 65, 66, 68, 75], "610195e": 41, "610559": 42, "611": 76, "6110": 53, "611269": 51, "611859": 48, "612151": 42, "612792": 53, "6133": 35, "613314": 43, "613408": 56, "613498": 53, "613574": 49, "613622": 42, "613691": 65, "614185e": 42, "614188": 51, "614678": 53, "615498": 2, "615573e": 42, "615574": 42, "615863": [47, 48], "61669761": 69, "616698": 69, "616797": 42, "616828": 53, "617": 51, "617283": 53, "6173": 36, "617800": 42, "617877": 56, "618069": 52, "61810738": 35, "618256": 42, "618776": 44, "618922e": 41, "619128": 42, "619177": 52, "619351": [41, 42], "619390": [41, 42], "619454": 45, "619613": 52, "61e": [35, 76], "62": [2, 49, 63, 64, 65, 66, 68], "620": 32, "62014070": 66, "620156": 56, "620407": 41, "620874e": 65, "620995": 58, "621094": 53, "621318": 56, "62131806": 56, "621490": 56, "6215": 52, "622": 53, "622153": 53, "622301": 41, "6224": 34, "622949": 41, "623024": 43, "623147": 48, "623173": 41, "623197": 52, "623681e": 68, "624": 51, "6240": 57, "62403053": 44, "624224e": 41, "6243811": 34, "624482e": 41, "624535": 64, "624798": 52, "624919": 53, "624983e": 66, "624988": 53, "625": [34, 51], "625477": 56, "625766": 47, "625891": [47, 48], "626433": 56, "6266": 53, "626633": 42, "627505": [47, 48], "627560": 56, "627564": 43, "627588e": 53, "628069": 51, "629306": 42, "629346": 53, "629549": 42, "629771": 42, "629776408": 66, "63": [34, 51, 63, 64, 65, 66, 68, 74, 75], "63013496": 66, "630150e": 56, "630914": 49, "631333": 56, "6318": [52, 76], "631821": 42, "632058": 51, "63245862e": 66, "632747e": 56, "6328366": 68, "632958": 55, "633350": 42, "633433": 51, "634055": 41, "63407762": 76, "634078": [52, 76], "634577": 68, "63499": 53, "635000e": [52, 53], "635199": [52, 53], "635296": 49, "636048": 65, "636453": [9, 63], "636575": 43, "637326": 56, "637487172": 66, "6379": 52, "638264": 56, "638742": 42, "638888": 49, "639135": 51, "63916605": 35, "639345": 53, "639580": 42, "64": [42, 50, 52, 53, 54, 63, 64, 65, 66, 68, 73], "640": 53, "640900": 53, "641528": 56, "641547": 56, "64154727": 56, "64197957": 56, "641980": 56, "6420": 53, "642016": 56, "64269": 57, "642735": 52, "643133": 53, "64340": 57, "643512": 43, "643752": 56, "644": [32, 66], "644113": 63, "644182": 63, "644665": 43, "64476745e": 66, "644796183": 66, "644799": 45, "644985": 41, "645": 53, "6458": 34, "645800": 51, "646937": 45, "646997": 41, "647002": 53, "647004": 65, "647010": 53, "647196": 45, "64723": 57, "647873": 56, "64797": 57, "649": 74, "649158": 56, "649891": 42, "65": [43, 49, 50, 53, 56, 63, 64, 65, 66, 68], "650": 46, "6500000000000001": [43, 53, 56], "650000e": 53, "650802": 42, "650810": 53, "650867": 43, "651127": 42, "652071": 53, "6522": 74, "652312": 47, "652349": 56, "652350": 51, "652450e": [52, 53], "6527": 46, "652778": 51, "6528": 53, "6530": 53, "653820": 63, "653846": 43, "653901": [41, 42], "653991": 63, "654070e": 65, "654755": 45, "655284": 56, "6553": 76, "6554": 74, "655422": 53, "655547": 41, "65557405e": 66, "656526": 42, "657": 36, "657024": 41, "657470": 42, "658": 51, "658267": 56, "658702": 42, "659": 36, "659245": [41, 42], "659339": 42, "659423": [41, 42], "659605e": 41, "659636": 43, "66": [54, 63, 64, 65, 66, 68, 73, 75], "660": 36, "660320": 48, "660479": 65, "660776": 56, "661369": 55, "661388": 41, "661391": 49, "66184": 65, "662": 32, "6625": 53, "663081975281988": 43, "663082": 43, "663182": 43, "663529": 56, "663533": 53, "664103e": 53, "664147": 53, "664276": [63, 64, 65], "664824": 53, "664850": 51, "665264": 56, "665554": 41, "665585": 42, "666104": 56, "666259": 42, "666307": 45, "6666667": 36, "666865": 41, "666912": 42, "667": 51, "667492e": 53, "667536": 56, "667614": 43, "667614205604159": 43, "667841e": 66, "668337": 53, "668452": 49, "668584": 45, "668981": 47, "6695": 65, "66989604": 44, "67": [32, 36, 41, 52, 54, 63, 64, 65, 66, 68, 73], "670867": [13, 63], "671271": [41, 42], "67136": 53, "6716717587835648": 43, "671672": 43, "671690": 41, "6722": 36, "672234": [41, 42], "672368": 43, "6723684718264447": 43, "672384": [41, 42], "67245350": 34, "673092": [41, 42], "673302": 51, "673586": 41, "67410934": 34, "6745349414": 34, "674552": 53, "674609": 43, "674936": 42, "674949e": 57, "675293": 55, "675625": 63, "675733e": 42, "676405": 43, "6765": [35, 52], "676534": 68, "676756": 56, "676807": 52, "677614": 56, "677980": 43, "678117": 53, "678369": 42, "678826": 43, "6795": 52, "679539": 51, "67ad635a": 36, "68": [36, 57, 63, 64, 65, 66, 68], "680": [32, 53], "680620": 42, "6810775": 57, "681176": 51, "681215242730314042444654557074838590100": 66, "681246": 42, "681448": 53, "681521": 41, "681562": 53, "681817dcfcda": 36, "682269": 53, "682353": 42, "682631": 42, "682875": 43, "683487": 42, "683581": 65, "683942": 56, "683984": 10, "684": 76, "68410364": 35, "68411700": [35, 76], "684142": 41, "684502": 56, "685104": 4, "685107": 56, "68554404e": 66, "68562150e": 66, "685807": 56, "686627": 41, "687345": 56, "687619": 42, "687647": 56, "687854": 45, "687871": 51, "6878711": 34, "688": 74, "688747": 53, "688918": 53, "689088": [41, 42], "689188": 45, "689392": 56, "69": [49, 63, 64, 65, 66, 68, 75], "690334": 43, "6903344145051182": 43, "690668": 42, "690796e": 42, "691136": 63, "691157": 44, "69117507": 66, "69140475e": 66, "691423": 41, "691511": 52, "691814": 41, "691911": 63, "692199": 42, "692297": 42, "692465": 42, "692725": 56, "692907": 53, "693316": 53, "693497e": 53, "693513": 42, "693632": 41, "693690": 53, "693796": 51, "694154": 43, "694839": 42, "694845e": 53, "694919": 51, "6950": 53, "695045": 41, "695581": 49, "69562150e": 66, "696011": [12, 63], "696289": [47, 48], "696770": 63, "697": [32, 51], "697000": 43, "697089": 41, "697420": [47, 48], "697545": 56, "697616": 42, "698223": 45, "698244": 45, "69840389e": 66, "698509": 41, "698694": 51, "699035": 56, "699082": 43, "69921": 36, "699259e": 56, "699333": 43, "6_design_1a": 46, "6_r2d_0": 46, "6_r2y_0": 46, "6b": [68, 70], "6cea": 36, "7": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 24, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75], "70": [35, 43, 47, 52, 53, 56, 63, 64, 65, 66, 68, 75], "700": [41, 42, 46, 51], "7000000000000002": [43, 53, 56], "700015": 56, "700102": 56, "701078": 56, "701088": 52, "701265": 47, "701413": 53, "701672e": 43, "701866": 56, "7018663": 56, "701966": 53, "702489": 53, "703049": 41, "703772": 53, "703942": 63, "7040": 53, "704814": 41, "705090": 42, "705354": 41, "705456": 41, "705474": 48, "705581": 53, "70583": 57, "706056": 53, "706231": 63, "706645": 43, "706657": 43, "706862": 5, "7069966693": 66, "707125": 42, "707197": 63, "707738": 42, "707868": 56, "707963e": 52, "708190": 51, "708235": 41, "708459": 56, "708465": 42, "708695": 59, "708695026860755": 59, "7086950268607550": 59, "709026": 45, "709596": 41, "709606": [13, 63], "71": [63, 64, 65, 66, 68, 75], "710586e": 51, "711024": 53, "711328": 53, "711518": 53, "711638": 65, "711834": 42, "712082": 53, "712157": 55, "712503": 57, "712592": 52, "712774": 47, "712960": 43, "713": 53, "713407": 53, "713457": 41, "713959": 42, "713986": 53, "714240": 51, "714557": 42, "714651": 56, "71465114": 56, "715013": 53, "715075e": 41, "715180e": 53, "7154": 53, "715407": 43, "7155": 53, "715515": 42, "7158581": 34, "7161": 53, "716316": 41, "716387": 41, "716456": 56, "716595e": 53, "716762": 43, "716793": 43, "716799": 51, "7167991": 34, "717": 53, "717130": 53, "717185": 56, "717860": 63, "718": 54, "72": [63, 64, 65, 66, 68, 75], "720559": 41, "720571": 56, "720573": 41, "720664": 51, "721018": 41, "721071": 56, "721245": 42, "7215093d9089": 36, "72155839e": 66, "721609": 53, "722316": 56, "722634": 56, "722848": 43, "722881": 56, "7229": 53, "723": 36, "723314": 56, "723345e": 56, "7239": 53, "7241399": 34, "724338": 56, "724603": 41, "724767": [47, 48], "725": 36, "725087": 53, "725166": 56, "725802": 5, "725820": 42, "726": 36, "7268131": 34, "727543": 45, "727693": 53, "727704": 53, "727976": 43, "7282094": 65, "728294": 55, "728710": 56, "72875815e": 66, "728852": 53, "73": [35, 63, 64, 65, 66, 68], "730023": 53, "730884e": 42, "731317": 43, "732067": 41, "732405": 52, "732586": 52, "7326": 53, "732638": 56, "73285": [9, 63], "732918": 47, "733": 53, "733047": 42, "733644": 41, "734635": 41, "734689": 41, "734770": 42, "734948": 56, "735048": 42, "735054": 42, "735369e": 63, "735656": 41, "7357": 53, "735848": 63, "735941": 8, "735964": 45, "736001": 41, "736082": [41, 42], "736084": 56, "73608412": 56, "736823": 42, "737052": 53, "7375615": 35, "73764317e": 66, "737694e": 41, "737951": [41, 42], "738065": 42, "738223": 53, "738315": 53, "738659e": 53, "738793": 63, "739": 53, "7395359436844482": 43, "739536": 43, "739720": 53, "739817": 49, "74": [35, 52, 63, 64, 65, 66, 68, 75], "740": 51, "740180e": 56, "740417": 52, "740869": 43, "741104": 43, "741702": 56, "74189": 36, "742128": 56, "742375": 41, "742407": 55, "742758e": 42, "742907": 56, "743247": 53, "743341": 42, "7437": 53, "74402577": 56, "744026": 56, "744228": 42, "744236": 57, "74461783e": 66, "745": 53, "745042": 54, "745444": 41, "745714": 52, "745881": 41, "746361": 56, "746843": 48, "7470": 53, "747646": 53, "747945": 34, "747961": 53, "748377": 52, "748513": 53, "748880": 53, "749328": 54, "74938952": 65, "749443": 53, "749540": 41, "75": [13, 18, 36, 41, 43, 45, 52, 53, 56, 63, 64, 65, 66, 68, 70, 75], "7500000000000002": [43, 53, 56], "750000e": 53, "750571e": 42, "750597": 42, "751013": 53, "751261": 53, "751482e": 48, "751633": 53, "75171": 52, "751710": [43, 52], "752015": 7, "752283": 53, "75285767": 66, "7533": 52, "753393": 41, "753523": 56, "753866": 42, "754448": 41, "754710": 41, "754870": 51, "755": 52, "755688": 41, "755717": 41, "755910": 53, "7559417564883749": 43, "755942": 43, "7560824": 34, "756647": 41, "756805": 51, "756867e": 53, "756905": 5, "756969": 43, "757": 74, "757151": [41, 42], "757183": 43, "757411": 56, "7578": 50, "757819": 51, "757917e": 56, "758391": 53, "7584718": 66, "75887": 36, "759006": 44, "759833": 42, "75989902": 66, "76": [63, 64, 65, 66, 68, 74, 75], "760104": 56, "760386": 65, "760494e": 42, "760778": 51, "760915": 45, "761": [34, 51], "761429": 42, "761714": 43, "762237": 41, "762284": 56, "76228406": 56, "762748": 53, "763219": 41, "763691": 53, "764093": [41, 42], "76419024e": 66, "764315": 56, "76444177e": 66, "764478": 55, "7646": 53, "764798": 56, "764953": 52, "765": 52, "765202": 53, "765363": [41, 42], "765500e": [52, 53], "765710e": 58, "765792": 56, "765864": 57, "76591188": 34, "7663": 53, "766499": 56, "766850e": 42, "76702611e": 66, "767188": [47, 48], "767247": 63, "767349": 63, "768071": 56, "768273": [47, 48], "7683": 50, "768331": 42, "769290": 41, "769361": 56, "769805": 56, "77": [63, 64, 65, 66, 68], "770556": 53, "770944": [47, 48], "7710": 57, "771157": 68, "771390e": 53, "7714": 54, "7716982": 35, "771741": 53, "771965": 53, "772253": 42, "77227783e": 66, "772291": 41, "772791": 53, "77289874e": 66, "773": 36, "7731": 50, "773177": 43, "773488": 56, "77348822": 56, "77401500e": 66, "774253": 41, "774271e": 53, "774940": 54, "775": [36, 53], "775191": [41, 42], "775969": 57, "7763": 52, "776728e": 51, "776887": 52, "7776071": 34, "777728": 63, "778852": 63, "779167": 2, "779185": 41, "779350": 41, "779517": [41, 42], "779682": 43, "779912": 53, "78": [42, 63, 64, 65, 66, 68, 75], "780": 36, "780120": 42, "780458": 56, "780857": 52, "780887e": 41, "781": 53, "7811465543": 67, "781233": 53, "781530": 56, "781681": 56, "782": 36, "782050": 56, "782555": 53, "782646": 63, "783": 36, "7831243849": 59, "783124384910379": 59, "7831243849103790": 59, "783276": 65, "784": [68, 70], "784066": 42, "784238": 51, "784341": 41, "784405": 57, "784483": 51, "784624": 43, "785": 36, "785038": 42, "785911": 56, "786": 36, "786744": 43, "78711285e": 66, "787396": 41, "787716": 41, "78777": 57, "788": 74, "78818": 36, "788400": 42, "789357": 54, "789671": 43, "789671060840732": 43, "79": [63, 64, 65, 66, 75], "790115": 53, "790261": 63, "790314": 41, "790723": [47, 48], "791": 66, "79122": 52, "791220": 52, "791241": 56, "791297": [13, 63], "791529": 41, "792939": 43, "793": 65, "793316": 63, "79338596e": 66, "793570": 56, "793735": 56, "793818": [41, 42], "794366": 53, "794526": 41, "79458848e": 66, "794805": 47, "795558": 42, "795647": 56, "7957": 53, "795932": 64, "796014": 42, "796220": 42, "796384": 42, "796444": 53, "797280": 56, "797737": 68, "79792890e": 66, "797965": 68, "798071": 4, "798309": 52, "798783": [47, 48], "799403": 56, "7999": 58, "7b428990": 36, "7x": 56, "8": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 75, 76], "80": [43, 44, 53, 56, 58, 63, 64, 65, 66, 75], "800": 51, "8000": [26, 58], "8000000000000002": [43, 53, 56], "800272": 63, "800351": 41, "800552": 54, "800854": 41, "801623": 53, "802289": 53, "80285489": 66, "803300": 41, "803492e": 56, "803563": 53, "803902e": 53, "804": [32, 53], "804081e": 42, "804219": 56, "804284": 57, "804316": 56, "804484": 56, "8048": 35, "804828": 56, "804889": 53, "805007": 51, "805153e": [52, 53], "8055563": 34, "805774": 41, "8059": 52, "805962": 41, "806218e": 53, "806531": 53, "806554": 41, "806964": 42, "80696592e": 66, "80714504e": 66, "807879": 56, "808": [35, 68, 70], "808246": 52, "808284": 53, "808640": 53, "8095": 54, "809913": [41, 42], "80a8": 36, "81": [34, 46, 49, 63, 64, 65, 66, 75], "810044": 52, "810134": 56, "8102": 52, "810363": 53, "810382": [52, 53], "810707": 53, "811155": 49, "811398": 63, "8116912": [68, 70], "811696": 41, "811825": 51, "811901": 56, "81190107": 56, "812311": 41, "812484e": 41, "812838": 54, "8132463": 34, "813293": 56, "813342": [68, 70], "813682": 53, "814136": 43, "814351": 43, "814376920": 66, "814410": 41, "814913": 51, "8152": 53, "815224": [68, 70], "815226": 65, "815574": 42, "81568484": 56, "815685": 56, "815993": 56, "816318": 51, "816752": 53, "817": 76, "817291": 53, "81827267": 56, "818273": 56, "818289": 56, "81828926": 56, "818380": [41, 42], "81856": 36, "818590": 41, "82": [63, 64, 65, 66, 75], "8202": 35, "820366": 51, "8209": 35, "8210": 35, "821021": 43, "821457": 53, "821566": 56, "821855": 63, "821870": 42, "822289": [52, 76], "82228913": 76, "822482": 43, "82261299": 50, "8227": 53, "822822": 43, "823": 32, "823247": 56, "823273": [41, 42], "823769e": 41, "824350": [41, 42], "824701": 43, "824750": 43, "824889": 43, "824961e": 53, "825140": 41, "825617": 51, "825677479": 66, "825824": 42, "825862": 56, "825980": 43, "8259803249536914": 43, "8260": 52, "826065": [41, 42], "826215": 42, "826391": 42, "826426": 65, "826492": 56, "826519": [13, 63], "82666866e": 66, "826829": 41, "82684324": 57, "827192": 41, "827234": 41, "827375": 44, "827381": 56, "827438": 41, "827735": 56, "827938162750831": [47, 48], "828058": 53, "828915": [47, 48], "829162": 63, "829543": 43, "829619": 42, "82985": 49, "83": [63, 64, 65, 66, 75], "830301": 55, "830755e": 49, "831019": 43, "831741": 41, "832086": 56, "83237186": 66, "8326928": 57, "832693": 57, "832844": 42, "832875": 56, "83287529": 56, "833024": 51, "833117": 41, "833227e": 64, "833464": 53, "833781": 41, "833907": 51, "8350": 53, "835125": 42, "835596": 53, "835949099": 66, "836234": 65, "836319": 54, "836515": 42, "837680": 41, "838006e": 42, "838114": 56, "83812317": 66, "838235": 54, "838457": 53, "83905": 4, "84": [36, 63, 64, 65, 66, 75], "840": 32, "840041": 53, "840303": 56, "84030318": 56, "840630": 41, "840673": 41, "840718": 65, "840836": 56, "840995e": 52, "841": [34, 51], "841132": 52, "8415": 35, "841847": 53, "842132": 65, "842405": 43, "842444": 41, "842625": 51, "842746": 56, "842770e": 42, "8428": 52, "842853": 56, "842859": 42, "842901": 42, "843730": 51, "843796": 41, "8440": 53, "844308": 56, "844549": [47, 48], "844667": 68, "844707": 56, "844889": 51, "845059": 42, "845351": 54, "846388": 43, "847555": 41, "847595": [12, 63], "847948": 43, "847966": 53, "848757e": 52, "848868": 43, "84930915e": 66, "849747": 57, "8497f641": 36, "8499": 53, "85": [21, 43, 49, 53, 56, 58, 63, 64, 65, 66], "8500000000000002": [43, 53, 56], "850321": 51, "850439": 42, "850575": [41, 42], "850794": 56, "851198": 53, "8513": 36, "851366": 51, "852": 53, "85280376": [2, 4, 5, 7, 8, 9, 10, 11, 12], "853177": 50, "8534789": 66, "85397773": 65, "855199e": 41, "855780": 56, "856117": 41, "856404": 48, "857": 32, "857161": 56, "857544": 51, "857765": 53, "858579": 42, "859": 53, "85911521e": 66, "85912862": 68, "859129": [67, 68], "859379": 54, "85974356": [2, 4, 5, 7, 8, 9, 10, 11, 12], "85c5": 36, "85e": 35, "86": [63, 64, 65, 66, 75], "860261": 42, "860663": [68, 70], "860804": 56, "860992": 53, "861755": 49, "862043": [47, 48], "862359": 43, "863687": 41, "863772": 52, "86415573": 35, "86424193e": 66, "8644": 36, "8646627426": 67, "864741e": 53, "865284": 41, "865313": 53, "865540": 42, "865562": [41, 42], "865854": 53, "865860": [52, 53], "866102": [41, 42], "866579": 53, "866798": 53, "8670337521": 59, "867033752141195": 59, "867565": 56, "8679": 53, "868": 36, "8685788": 56, "868579": 56, "8688": 52, "869": 36, "869020": 43, "869136": 42, "869425": 48, "869477": 41, "869586": 49, "869651": 42, "87": [35, 48, 49, 51, 63, 64, 65, 66, 75], "8700": 35, "870099": [47, 48], "870185": 42, "870260": 56, "870332": 56, "870857": 56, "871": 36, "871887e": 42, "871923": 42, "872222": 53, "872768": 56, "872852": 56, "87290240e": 66, "872994": 53, "873048": 42, "873198": 53, "873677": [47, 48], "873972": 41, "874": 54, "87430335": [68, 70], "874303353": [68, 70], "874702": [47, 48], "8750": 53, "8759": 53, "876080": 41, "876083": 53, "876431e": 43, "876549": 53, "87674597e": 66, "877": 54, "8771": 53, "877153": 53, "877455": 55, "877833": [41, 42], "878281": 56, "878289": 53, "878402": 41, "878847e": 53, "879049": 53, "879103": 43, "87e": 35, "88": [35, 49, 63, 65, 66], "880106": 51, "880202e": 42, "880579": 56, "880591": 55, "880808e": 53, "880880e": 53, "880886": 52, "8810": 52, "881201": 53, "88125046e": 66, "881465": 45, "881581": 8, "88173062": 34, "882475": 43, "883485": 42, "883622": 56, "883778": 42, "883914": 43, "884132": 56, "8843": 57, "884996": 43, "885": 54, "8850": 35, "885065": 56, "885978": [47, 48], "886041": 42, "886086": [41, 42], "886266": 53, "886577": 42, "88664": 36, "886771e": 41, "886777e": 42, "886989": 42, "887345": 53, "887556": 43, "888146": 51, "8881461": 34, "888775": 48, "888804": 53, "888863e": 41, "889293": 56, "8893": 52, "889300": 52, "889326": 42, "889733": 56, "88988263e": 66, "889913": [41, 42], "889963": 56, "88ad": 36, "89": [35, 42, 63, 65, 66, 74, 75], "890": [34, 51], "89027368": [68, 70], "890273683": [68, 70], "89035917": 49, "890372": [37, 61, 73], "8903720000100010000010": [36, 61, 73], "8904": 32, "890454": 64, "8909": [34, 52, 76], "891697": 52, "892": [32, 36], "892331": 42, "892648": 56, "892796": [41, 42], "893": 36, "8932105": 34, "893649": [41, 42], "893851": 56, "894": 36, "894307e": 53, "89449": 52, "894490": 52, "894609e": 41, "895106": [41, 42], "895308": 53, "895333": 56, "895690": [41, 42], "895768e": 43, "896023": 56, "896681e": 42, "896758": 41, "897220": 56, "897240": 53, "8974": 52, "898722": 56, "899": 54, "899460": 56, "89966756": 66, "899716": 42, "8bdee1a1d83d": 36, "8da924c": 36, "8e3aa840": 36, "9": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 75, 76], "90": [22, 35, 43, 44, 53, 56, 58, 63, 65, 66, 75], "9000000000000002": [43, 53, 56], "900000e": 53, "900021": 64, "901013": 42, "901148": 56, "90136": 52, "901360": 52, "901683": 53, "902": [68, 70], "902573": 43, "903056e": 56, "903135": 63, "903339": 43, "903351e": 43, "903418": 51, "903681": 56, "903767": [41, 42], "904156": 43, "9041560442482157": 43, "904315": 41, "905042": 42, "905494": 43, "905951": 57, "905998": 48, "906": 54, "906073": 42, "9061": 53, "906716732639898": [47, 48], "906757": 39, "906864": 41, "907115": 56, "907130": 41, "907176": 56, "907198": 42, "9073": 53, "907491": 43, "907702": 41, "907801": 51, "90794478": [68, 70], "907944783": [68, 70], "907961": 53, "908620": 41, "909": 54, "909141": 42, "909304": [41, 42], "90963122e": 66, "909752": 42, "909942e": 63, "909975": 53, "909997": [52, 76], "91": [63, 64, 65, 66, 75], "910000e": 53, "9102": 52, "910895": 42, "9109": 36, "910991": 41, "91102953": 56, "911030": 56, "911662": 47, "912230": [41, 42], "9126": [35, 76], "9127": [35, 76], "913": 36, "91315015": 34, "913285": 41, "913485": 53, "913774": 43, "9142": 53, "91438767e": 66, "915": [35, 36, 52, 53], "915000e": [52, 53], "915057e": 52, "915488": [47, 48], "916528": 47, "9166667": 36, "916806": 42, "916914": 56, "917": 36, "917066": 53, "917248": 56, "91724807": 56, "917436": 56, "918104": 41, "918227": 43, "918747": 42, "919432": 56, "9197": 53, "919814": 41, "91e": 35, "92": [63, 65, 66, 75], "920335": 53, "920337": 48, "920439": 41, "920645": 53, "921": 54, "9210": 53, "92116343": 66, "921372": 43, "921913": 51, "921956": [41, 42], "921e4f0d": 36, "922160": 53, "922201e": 41, "9223": 53, "922996": 51, "923074e": 43, "923517": 58, "923607": 56, "92369755": 34, "923804": 43, "923943": 76, "923977": 53, "924002": 56, "9243": 53, "924396": [47, 48], "92463": 52, "924630": 52, "924634": 45, "9248": 36, "924821": 43, "924843": 51, "924921": 63, "925": 44, "925248": [47, 48], "925660": 41, "925736": 43, "925957": 47, "926493": 52, "926621": 43, "927": 33, "927074": 56, "927232": 53, "9274": 53, "927950": 53, "92827999": 65, "92881435e": 66, "928947": 51, "929": 54, "92905": 34, "929363": 41, "929552": 41, "929598": 42, "92972925e": 68, "929729e": [67, 68], "93": [35, 63, 64, 65, 66, 75], "9304028": 34, "930417": 41, "931": 60, "931479": 56, "931507": 41, "931978": 73, "932027": 43, "932404e": 53, "932973": 56, "933322": 42, "933996": 43, "934433": [41, 42], "9345": 36, "934511": [68, 70], "934549": 53, "934992": 43, "935": 50, "935591": 56, "935730": 56, "935989": 51, "9359891": 34, "93648": 58, "936739": 56, "937116": 51, "937586": 53, "937857": 41, "938": [68, 70, 76], "938975": [63, 64, 65], "939068": [47, 48], "9392": 53, "939250": 41, "9395": 53, "93958082416": 76, "94": [44, 50, 63, 65, 66, 75, 76], "940354721701296": 43, "940355": 43, "940373": 53, "941440": 41, "941724": 53, "941788": 47, "942139": 48, "942312": 56, "942460e": 56, "942489": 53, "942550": 53, "942661": 51, "942823": 53, "94309994e": 66, "943200": 41, "943270": 41, "943465e": 41, "943938": 56, "943949e": 56, "944149": 63, "944253e": 56, "944266": [47, 48], "944280": 53, "94441007e": 66, "945402e": 41, "945417": 41, "945881": 41, "94629": 58, "946297": 43, "946406": 48, "946433": 56, "946533": 41, "946658": 53, "946968": 43, "947440": 55, "947466": 64, "947613": 42, "9480": 53, "948154e": 47, "948344e": 42, "948868": 53, "94906344": 34, "949241": [68, 70], "949456": 56, "949866": 42, "95": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 56, 57, 58, 63, 65, 66, 68, 69, 75, 76], "9500": 53, "950131e": 42, "950545": 39, "95062986e": 66, "951115": 42, "951415": 41, "951502": 56, "951532": 51, "951550": 42, "951920": 55, "952": [35, 76], "952839": 56, "9534": 53, "953683": 51, "95372559e": 66, "954": [68, 70], "95401167e": 66, "954536": 63, "955005e": 53, "9551": 53, "955541": [13, 63], "95559917": 64, "955701": 41, "955926": 42, "956": 66, "956047": 34, "956110": 42, "956217": 41, "956574": 53, "956724": 43, "9567242535070148": 43, "956892": 53, "957375": 51, "957437": 41, "957745": 43, "9579": 35, "957996": 43, "958": [68, 70], "9580": 35, "958105": 63, "958541": 53, "959132": 42, "95e": 35, "96": [35, 41, 42, 49, 54, 63, 65, 66, 75], "960": 54, "960074": 41, "9605": 53, "960808": 43, "960875e": 42, "961360": 42, "961539": 53, "961962": 43, "963051": 42, "963055": 53, "963389": 41, "964025e": 56, "964261e": 51, "964318": 53, "965341": 42, "965531": 65, "965696": 41, "965774": 53, "96582": 64, "966015": 56, "966659": 43, "9666592590622916": 43, "967467": 57, "968": 76, "968134e": 56, "968577": 44, "968800": 41, "9699": 52, "97": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 37, 39, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 63, 64, 65, 66, 67, 68, 70, 73, 75, 76], "970065": 56, "971058": [47, 48], "971724": 41, "972": 54, "972088e": 41, "972509": 42, "972732": 42, "972748": 43, "97276281": 56, "972763": 56, "973": 54, "97314470": 34, "973156": 63, "973229": 42, "973241": 56, "973262": 41, "973331": 53, "973392e": 41, "973741": 42, "974202": 43, "974213": 42, "97441062": [47, 48], "974414": 43, "97470872": 57, "9748910611": 34, "975": [41, 42, 47, 48, 50, 54], "975232": 42, "9753": 36, "975447": 44, "975450": 42, "975461": 51, "975957e": 42, "976": 54, "976088": 56, "976562": 56, "977": 54, "977280": [41, 42], "977295": 53, "977507": 42, "978554": 41, "9787": 53, "978977": 56, "979857": 41, "979896": 42, "98": [41, 42, 53, 63, 65, 66, 75], "980026": 53, "9802393": 34, "980256e": 41, "980643e": 43, "981104": 55, "981438": 41, "981672": 43, "982353e": 53, "982417": 43, "982720": 41, "982797": 55, "982986e": 41, "983192": 56, "983253": 41, "983759": 76, "983896": 41, "98393441": 57, "984024": 55, "984083": [47, 48], "984551": 7, "984562": 56, "984821": 41, "984866": [68, 70], "984872": [41, 42], "984937": 43, "98505871e": 66, "985207": [41, 42], "986383": 53, "986417": 41, "9870004": 36, "987220": 53, "987329": 42, "988": 54, "9880384": 36, "988421": [41, 42], "988463": 56, "988690": 42, "988709": 53, "98872270": 66, "988780": 53, "989291": 41, "989372": 49, "989640": 54, "99": [35, 41, 42, 54, 63, 65, 66, 75], "990": 54, "990210": 53, "990281": 54, "990377": 42, "991": 36, "9914": [52, 53, 57], "991444e": 47, "9915": [35, 52, 53, 57], "991512": 35, "991539": 42, "991963": [41, 42], "991977": 53, "991988": 41, "99232145": 57, "992582": [41, 42], "993201": 42, "993575": 53, "994": 54, "994168239": 34, "994214": 53, "994332": 39, "994377": 41, "9944": 65, "994851": 53, "994937": 48, "995015": 53, "995248": 56, "99549118e": 66, "99571372e": 66, "9959607": 66, "996": 54, "9961392": 34, "996454": 42, "996934": 51, "996946": 42, "997": 54, "9970": 53, "997034": 58, "997494": 58, "997571": 51, "997621": 43, "997934": [47, 48], "998063": 39, "99864670889": 76, "998669e": 54, "998766": 53, "9989": 52, "999": [32, 44, 45, 49, 57, 76], "999207": 56, "9995": [41, 42, 45], "9996": [41, 42, 45], "9996553": 35, "9997": [41, 42, 45], "9998": [41, 42, 45], "9999": [41, 42, 45], "99c8": 36, "A": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 21, 25, 29, 30, 32, 33, 35, 36, 39, 40, 46, 48, 54, 55, 57, 60, 61, 63, 64, 65, 68, 69, 70, 71, 73, 74, 76], "ATE": [8, 35, 37, 52, 57, 63, 65, 67, 69], "ATEs": 54, "And": [54, 58, 69], "As": [33, 34, 35, 36, 40, 41, 42, 43, 44, 46, 49, 50, 51, 52, 53, 54, 56, 58, 59, 64, 66, 67, 68, 69, 70, 76], "At": [16, 17, 18, 34, 44, 45, 49, 50, 51, 53, 56, 76], "Being": 76, "But": 50, "By": [34, 51, 64, 69], "For": [4, 5, 7, 8, 11, 18, 27, 28, 32, 34, 36, 39, 44, 49, 50, 51, 53, 55, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 76], "If": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 33, 34, 40, 41, 42, 44, 50, 51, 53, 60, 61, 63, 64, 65, 67, 68, 69, 71, 76], "In": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76], "It": [34, 35, 41, 42, 46, 47, 48, 51, 52, 53, 64, 66, 71, 75], "No": [20, 32, 35, 36, 37, 44, 49, 52, 53, 57, 58, 61, 64, 65, 67, 68, 73, 74], "Of": [50, 68, 76], "On": [33, 40, 54, 60, 74], "One": [35, 52, 53, 63, 68], "Such": 64, "That": 76, "The": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 34, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76], "Then": [18, 43, 56, 68, 69, 70, 71, 72], "There": [35, 52, 72, 76], "These": [35, 36, 38, 52, 55, 57, 63, 76], "To": [28, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 47, 48, 50, 51, 52, 53, 55, 56, 57, 58, 60, 61, 63, 64, 66, 68, 69, 70, 72, 73, 76], "With": [21, 41, 42, 64, 74], "_": [33, 34, 40, 41, 42, 43, 45, 46, 47, 48, 51, 52, 53, 55, 56, 59, 60, 63, 66, 67, 68, 69, 70], "_0": [33, 34, 40, 46, 51, 59, 60, 66, 67, 68, 69], "_1": [16, 17, 18, 54, 58, 67], "_2": [16, 17, 18, 54], "_3": [16, 17, 18], "_4": [16, 17, 18], "_5": 16, "__version__": 72, "_all_coef": 66, "_all_s": 66, "_compute_scor": 28, "_compute_score_deriv": 28, "_coordinate_desc": 51, "_est_causal_pars_and_s": 75, "_i": [33, 40, 56, 58, 60], "_id": 66, "_j": [16, 17, 18, 23, 34, 51, 68, 70], "_l": 64, "_m": [64, 66], "_n": [67, 68, 69, 70], "_n_folds_per_clust": 51, "_rmse": [2, 4, 5, 7, 8, 9, 10, 11, 12], "_utils_resampl": 50, "a09a": 36, "a09b": 36, "a3d9": 36, "a4a147": 54, "a5e6": 36, "a5e7": 36, "a6ba": 36, "a79359d2da46": 36, "a840": 36, "a_": 58, "a_0": 24, "a_1": 24, "ab": 71, "ab71": 36, "abadi": [14, 44], "abb0fd28": 36, "abdt": [37, 61, 73], "abl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 40, 50, 53, 54, 64, 69], "about": [35, 50, 52, 71, 73, 76], "abov": [33, 35, 40, 41, 42, 47, 48, 50, 52, 54, 55, 56, 60, 63, 64, 65, 72], "absolut": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 64], "abstract": [28, 34, 51, 67, 71, 75], "accept": [63, 64], "access": [29, 30, 35, 47, 48, 49, 50, 57, 64, 69, 76], "accord": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 35, 40, 43, 44, 52, 56, 58, 64, 68, 69, 70, 76], "accordingli": [44, 50, 52, 58], "account": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 51, 52, 53, 57, 69, 76], "accumul": [35, 52, 53, 57], "acemoglu": 74, "achiev": [34, 51, 55, 68, 70], "acic_2024_post": 54, "acknowledg": [35, 36, 52], "acm": 74, "acov": 74, "across": [35, 52, 54, 76], "action": 75, "activ": [3, 6, 72, 75], "actual": 49, "acycl": [58, 76], "ad": [3, 6, 14, 15, 28, 49, 61, 64, 68, 69, 75], "adapt": [7, 52, 75], "add": [34, 37, 44, 45, 47, 48, 49, 54, 56, 57, 58, 64, 74, 75], "addit": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 23, 24, 25, 46, 64, 65, 67, 69, 74, 75], "addition": [16, 17, 43, 53, 57, 64, 65, 66, 68, 69, 73], "adel": 74, "adjust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 45, 51, 53, 57, 63, 68, 69, 70, 76], "adopt": [44, 65], "advanc": [62, 66, 74], "advantag": [33, 35, 40, 52, 53, 60, 72], "advers": 69, "adversari": [2, 4, 5, 7, 8, 9, 10, 11, 12, 57, 69], "ae": [33, 34, 35], "ae56": 36, "ae89": 36, "aesthet": 33, "aeturrel": 25, "afd9e4": 54, "affect": [46, 65, 75, 76], "after": [35, 36, 44, 46, 52, 53, 58, 63, 64, 69, 72, 76], "after_stat": 33, "ag": [35, 52, 53, 55, 57, 76], "again": [33, 34, 35, 40, 44, 49, 51, 52, 57, 58, 60, 69], "against": [44, 49, 50, 55, 64], "agebra": 63, "agegt54": [36, 37, 61, 73], "agelt35": [36, 37, 61, 73], "aggreg": [59, 66, 75], "aipw": 54, "aipw_est_1": 54, "aipw_est_2": 54, "aipw_obj_1": 54, "aipw_obj_2": 54, "air": [34, 51], "al": [14, 15, 19, 21, 23, 24, 33, 34, 35, 36, 40, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 56, 57, 60, 65, 66, 67, 68, 69, 70, 71, 73, 75], "alexandr": [46, 74], "algorithm": [32, 34, 36, 40, 43, 44, 50, 51, 53, 56, 57, 58, 62, 64, 65, 66, 67, 68, 75, 76], "align": [33, 34, 40, 43, 45, 50, 51, 52, 54, 55, 56, 58, 75], "all": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 31, 33, 34, 35, 40, 44, 49, 50, 51, 52, 53, 55, 58, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 75], "all_coef": 66, "all_dml1_coef": 59, "all_s": 66, "all_smpl": [2, 4, 5, 7, 8, 9, 10, 11, 12], "all_z_col": [34, 51], "allow": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 28, 35, 52, 53, 63, 64, 66, 67, 68, 70, 71, 75, 76], "almqvist": 74, "along": 64, "alpha": [2, 4, 5, 7, 8, 9, 10, 11, 12, 22, 24, 33, 34, 35, 37, 40, 41, 42, 43, 46, 50, 51, 52, 53, 56, 59, 60, 63, 64, 65, 66, 67, 68, 69, 70], "alpha_": [23, 34, 51, 64], "alpha_0": 69, "alpha_ml_l": 46, "alpha_ml_m": 46, "alpha_x": [7, 20, 65], "alreadi": [18, 44, 58, 64, 65], "also": [4, 5, 7, 8, 11, 32, 33, 34, 35, 36, 39, 40, 41, 42, 44, 47, 48, 49, 51, 52, 53, 55, 57, 60, 63, 64, 66, 67, 68, 69, 72, 73, 75, 76], "alter": [34, 51], "altern": [35, 36, 52, 55, 62, 64, 68, 70, 71, 72, 73], "alwai": [2, 4, 5, 7, 8, 9, 10, 11, 12, 75], "always_tak": [7, 35, 52], "amamb": 51, "american": [22, 54], "amgrem": 51, "amhorn": 51, "amit": 74, "amjavl": 51, "ammata": 51, "among": [35, 46, 52, 53, 57], "amount": [35, 52, 53, 76], "amp": [32, 34, 36, 44, 51, 53, 57, 58], "an": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 18, 29, 30, 33, 34, 35, 36, 40, 41, 42, 46, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "analog": [27, 28, 34, 51, 53, 57, 63, 65, 67, 68, 69, 70], "analys": 76, "analysi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 34, 35, 40, 51, 52, 53, 60, 62, 63, 71, 75], "analyt": [54, 56], "analyz": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 52, 53, 57, 76], "andrea": 74, "angl": 35, "angrist": 54, "ani": [32, 33, 36, 39, 40, 44, 58, 60, 72, 76], "anna": [4, 5, 16, 17, 18, 44, 65, 74], "annal": [68, 70, 74], "anneal": 64, "annot": 33, "annual": 74, "anoth": [33, 34, 35, 40, 50, 51, 60, 64], "anymor": [34, 51], "aos1161": [68, 70], "aos1230": [68, 70], "aos1671": [68, 70], "ap": [35, 52], "ape_e401_uncond": 35, "ape_p401_uncond": 35, "api": [61, 71, 75], "apoorva": 75, "apoorva__l": 54, "apoorval": 54, "app": 75, "append": [40, 50, 60], "appendix": [21, 26, 57, 58, 69], "appli": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 32, 33, 34, 35, 36, 40, 44, 45, 50, 51, 52, 53, 58, 60, 65, 66, 67, 68, 70, 71, 73, 75, 76], "applic": [33, 40, 44, 54, 60, 63, 66, 74, 76], "apply_along_axi": 55, "apply_cross_fit": [33, 50, 66], "apply_crossfit": 75, "appreci": 71, "approach": [2, 4, 5, 7, 8, 9, 12, 13, 34, 51, 57, 62, 64, 66, 68, 69, 70, 72, 74, 76], "appropri": [35, 46, 52, 66, 76], "approx": 63, "approxim": [33, 40, 41, 42, 43, 50, 56, 60, 63, 68, 70, 75, 76], "apt": 72, "ar": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 24, 25, 27, 28, 29, 30, 33, 34, 35, 36, 38, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76], "arang": [2, 4, 5, 7, 8, 9, 10, 11, 12, 40, 43, 45, 53, 55, 56, 57, 64], "architectur": [67, 74], "arellano": 74, "arg": 63, "argmin": 50, "argu": [33, 35, 40, 52, 53, 57, 60, 76], "argument": [18, 23, 24, 25, 35, 41, 42, 44, 49, 50, 52, 53, 59, 63, 64, 65, 76], "aris": [33, 34, 40, 51, 60, 76], "aronow": 54, "around": [35, 52, 53, 67], "arr": 55, "arrai": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 20, 21, 22, 23, 24, 25, 26, 40, 41, 42, 43, 44, 50, 51, 54, 55, 57, 58, 59, 60, 62, 63, 64, 66, 68, 69, 70, 73, 75, 76], "arrang": 34, "array_lik": 13, "articl": [25, 71], "arxiv": [23, 34, 51, 71, 74, 75], "as_learn": [36, 64], "asarrai": [41, 42], "aspect": [35, 52, 53], "assert": 64, "asset": [53, 57, 76], "assign": [3, 6, 35, 48, 52, 63, 64, 65, 76], "assmput": 65, "associ": [35, 46, 52, 65, 68, 70, 74], "assum": [32, 34, 39, 44, 51, 54, 55, 65, 67, 68, 69, 76], "assumpt": [34, 35, 44, 45, 50, 51, 52, 54, 58, 65, 68, 76], "assur": 75, "astyp": [39, 52], "asymptot": [27, 28, 33, 34, 40, 51, 60, 66, 68, 74], "ate_estim": 58, "athei": 74, "att": [8, 45, 49, 55, 63, 65, 67, 69, 75], "atte_estim": 44, "attempt": [29, 30], "attenu": [35, 52], "attr": 35, "attribut": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 50, 59, 64, 66, 67, 68], "attributeerror": [29, 30], "attrict": 65, "attrit": [58, 65], "au": [36, 64, 71, 73], "author": 71, "automat": [33, 40, 49, 60, 63, 69], "automobil": [34, 51], "autos": 46, "auxiliari": [33, 40, 60], "avail": [20, 35, 36, 44, 46, 50, 52, 53, 54, 55, 60, 63, 64, 65, 69, 71, 72, 75, 76], "averag": [7, 8, 11, 16, 17, 18, 32, 36, 39, 44, 45, 49, 53, 54, 55, 57, 58, 62, 65, 68, 69, 74, 76], "avoid": [33, 40, 66, 72, 75], "awai": 57, "ax": [40, 41, 42, 43, 45, 47, 48, 50, 51, 52, 53, 54, 56], "ax1": [43, 53, 56], "ax2": [43, 53, 56], "axhlin": 45, "axi": [34, 35, 46, 50, 51, 52, 54, 55], "axvlin": 40, "b": [4, 5, 25, 33, 34, 36, 40, 41, 42, 51, 54, 56, 60, 63, 64, 68, 69, 70, 71, 73, 74], "b208": 36, "b371": 36, "b5d34a6f42b": 36, "b5d7": 36, "b_0": 24, "b_1": 24, "b_j": 25, "bach": [71, 74, 75], "backbon": 50, "backend": [3, 6, 53, 57, 62, 75], "backward": 75, "bad": 54, "balanc": [35, 52, 53], "band": [62, 76], "bandwidth": [9, 12, 13], "bar": [49, 52, 63], "base": [2, 4, 5, 7, 8, 9, 10, 11, 12, 19, 33, 34, 35, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76], "baselin": [35, 52], "basi": [1, 8, 11, 41, 42, 63], "basic": [34, 35, 44, 51, 52, 53, 54, 57, 62, 64], "batch": 36, "battocchi": 74, "bay": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 68, 70], "bb2913dc": 36, "bbotk": [36, 64, 75], "bbox_inch": 40, "bbox_to_anchor": 40, "bd929a9e": 36, "bde4": 36, "becam": [35, 52, 53], "becaus": [32, 33, 34, 39, 40, 48, 49, 51, 54, 60, 76], "becker": [36, 64], "becom": [34, 48, 51, 63, 66], "bee": 45, "been": [34, 35, 51, 52, 53, 57, 63, 64, 75], "befor": [35, 45, 49, 52, 56, 65, 76], "begin": [20, 22, 23, 33, 34, 35, 36, 40, 43, 45, 50, 51, 52, 54, 55, 56, 58, 59, 61, 64, 66, 68, 70, 73, 76], "behav": 48, "behavior": [35, 54, 64], "behaviour": 48, "being": [26, 27, 28, 34, 51, 66, 67, 68, 69, 70, 71], "belloni": [21, 46, 68, 70, 74], "below": [32, 35, 39, 52, 54, 72, 73], "benchmark": [2, 4, 5, 7, 8, 9, 10, 11, 12, 31, 49, 75], "benchmark_dict": [31, 57], "benchmark_inc": 57, "benchmark_pira": 57, "benchmark_result": [2, 4, 5, 7, 8, 9, 10, 11, 12], "benchmark_twoearn": 57, "benchmarking_set": [2, 4, 5, 7, 8, 9, 10, 11, 12, 49, 57, 69], "benchmarking_vari": 49, "benefit": [33, 35, 40, 52, 60], "bernoulli": 20, "berri": [34, 51], "besid": 73, "best": [1, 8, 11, 41, 42, 47, 48, 72], "beta": [20, 21, 22, 26, 35, 52, 55, 58], "beta_": 58, "beta_0": [19, 55, 58, 63], "beta_a": [16, 17], "beta_j": [20, 21, 22, 26], "better": 50, "between": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 39, 43, 45, 46, 54, 56, 57, 58, 67, 68, 69, 70, 73, 75], "betwen": [32, 39], "beyond": 74, "bia": [26, 32, 39, 46, 58, 62, 65, 66, 67, 69, 74, 75], "bias": [32, 35, 39, 52, 53, 57, 76], "bibtex": 71, "big": [46, 59, 66, 67, 68, 69], "bigg": [34, 51, 67, 69], "bilia": 15, "bin": [33, 40, 72], "binari": [2, 4, 5, 7, 8, 9, 11, 12, 19, 32, 35, 36, 39, 44, 49, 52, 54, 55, 63, 64, 65, 75, 76], "binary_treat": [19, 41, 47, 49], "bind": 75, "binder": [36, 64, 71, 73, 75], "binomi": [39, 54, 55, 56], "bischl": [36, 64, 71, 73], "black": [33, 36, 37, 61, 73], "blog": 25, "blondel": [71, 73], "blp": [1, 34, 51], "blp_data": [34, 51], "blp_model": [47, 48], "blue": [33, 34, 51], "bodori": 74, "bond": [35, 52, 53], "bonferroni": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 68, 70], "bonu": [15, 36, 61, 73], "book": [36, 64], "bool": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 29, 30, 49], "boolean": [26, 47, 48, 61, 66], "boost": [32, 35, 39, 44, 50, 52], "boost_class": [35, 52], "boost_summari": 52, "boostrap": [43, 75], "bootstrap": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 41, 42, 43, 47, 48, 53, 56, 62, 63, 66, 67, 71, 73, 75, 76], "both": [16, 17, 19, 35, 36, 44, 45, 50, 52, 53, 55, 57, 61, 64, 68, 69, 75, 76], "bottom": [34, 35, 50, 51, 52, 53], "bound": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 49, 52, 57, 69, 76], "branch": 36, "break": [33, 75], "breviti": 76, "brew": 72, "brewer": 34, "brief": 60, "bring": [32, 39], "brucher": [71, 73], "bsd": 75, "budget": 64, "bug": [71, 75], "build": [34, 50, 51, 55], "build_design_matric": [41, 42], "built": [64, 71], "bureau": [66, 74], "busi": [23, 26, 34, 51, 74], "b\u00fchlmann": 74, "c": [14, 15, 17, 18, 21, 22, 24, 32, 33, 34, 35, 36, 37, 39, 40, 45, 46, 47, 48, 51, 52, 54, 60, 61, 64, 71, 72, 73, 74, 76], "c1": [14, 15, 24, 34, 46, 51, 60, 71, 74], "c68": [14, 15, 24, 34, 46, 51, 60, 71, 74], "c895": 36, "c_": [68, 70], "c_d": [21, 69], "c_y": [21, 69], "ca1af7be64b2": 36, "caac5a95": 36, "calcualt": 55, "calcul": [8, 11, 35, 41, 42, 43, 47, 48, 50, 52, 56, 57, 69], "call": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 34, 35, 36, 39, 41, 42, 43, 44, 47, 48, 51, 52, 53, 55, 56, 57, 58, 61, 64, 66, 67, 68, 69, 70, 72, 73, 75, 76], "callabl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 40, 41, 42, 50, 62, 64, 71], "camera": 46, "cameron": [34, 51], "can": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76], "cannot": [50, 76], "capabl": [3, 6, 32, 39], "capsiz": 54, "cardin": [34, 51], "care": 64, "carlo": [16, 17, 19, 41, 42, 47, 48, 74], "casalicchio": [36, 64, 71, 73], "case": [3, 6, 7, 8, 15, 19, 32, 34, 35, 39, 41, 42, 43, 46, 48, 49, 51, 55, 56, 57, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 75, 76], "cat": [33, 75], "catboost": 50, "cate": [1, 8, 11, 62, 75], "cate_obj": 63, "caus": [33, 40, 60], "causal": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 39, 40, 51, 52, 54, 57, 58, 59, 60, 61, 62, 65, 66, 68, 69, 70, 74], "causaldml": 74, "causalweight": 74, "caution": 68, "caveat": 48, "cbind": 34, "ccp_alpha": [8, 52], "cd": 72, "cd_fast": 51, "cda85647": 36, "cdf": 63, "cdid": [34, 51], "cdot": [16, 17, 18, 34, 43, 45, 49, 51, 54, 56, 63, 65, 67, 68, 70], "cdot1": 49, "center": 46, "central": [66, 75], "certain": 48, "cexcol": 34, "cexrow": 34, "cf_d": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 31, 49, 57, 69, 76], "cf_y": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 31, 49, 57, 69, 76], "chain": 48, "chainedassignmenterror": 48, "challeng": [34, 51, 69], "chang": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 44, 48, 53, 57, 58, 68, 69, 72, 74, 75], "channel": 76, "chapter": [27, 28, 36, 64, 69], "charact": [35, 36, 64, 75], "characterist": [57, 76], "check": [29, 30, 33, 35, 40, 50, 52, 53, 59, 60, 71, 72, 75], "check_data": 75, "check_scor": 75, "checkmat": 75, "chernozhukov": [14, 15, 21, 22, 24, 33, 34, 35, 40, 46, 50, 51, 52, 53, 57, 60, 66, 68, 69, 70, 71, 74, 75], "chetverikov": [14, 15, 24, 34, 46, 51, 60, 68, 70, 71, 74], "chiang": [23, 34, 51, 74], "chieh": 74, "choic": [2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 35, 46, 52, 55, 63, 64, 69, 75], "choos": [32, 35, 39, 40, 46, 50, 52, 53, 59, 66, 67, 68, 70, 73, 76], "chosen": [16, 17, 50, 64], "chou": 54, "chr": 35, "christian": [46, 74], "chunk": 64, "ci": [2, 4, 5, 7, 8, 9, 10, 11, 12, 41, 42, 43, 44, 45, 47, 48, 49, 52, 53, 56, 57, 63, 69, 75, 76], "ci_cvar": [43, 53], "ci_cvar_0": 43, "ci_cvar_1": 43, "ci_joint_cvar": 43, "ci_joint_lqt": 56, "ci_joint_qt": 56, "ci_length": 44, "ci_lpq_0": 56, "ci_lpq_1": 56, "ci_lqt": [53, 56], "ci_pq_0": [53, 56], "ci_pq_1": [53, 56], "ci_qt": [53, 56], "cinelli": [69, 74], "circumv": 76, "citat": 75, "claim": 36, "class": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 27, 28, 29, 30, 35, 36, 37, 44, 49, 52, 53, 57, 58, 59, 61, 63, 64, 66, 67, 68, 71, 73, 75], "class_learn": 53, "class_learner_1": 50, "class_learner_2": 50, "classic": [34, 51, 76], "classif": [8, 32, 35, 36, 50, 55, 63, 64, 65, 76], "classifavg": 36, "classifi": [2, 4, 5, 7, 8, 9, 11, 12, 13, 29, 36, 64, 75], "classmethod": [3, 6], "claus": 75, "clean": 75, "cleaner": 50, "cleanup": 75, "clear": [34, 51], "clever": 50, "clone": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 33, 36, 40, 50, 51, 53, 59, 64, 65, 66, 67, 68, 69, 70, 72, 73], "close": [35, 52, 69], "cluster": [3, 23, 74, 75], "cluster_col": [3, 34, 51], "cluster_var": [3, 23], "cluster_var_i": [3, 34, 51], "cluster_var_j": [3, 34, 51], "cmap": 51, "cmd": 75, "co": [25, 45], "codaci": 75, "code": [8, 11, 25, 32, 34, 35, 36, 39, 46, 52, 60, 63, 64, 65, 66, 67, 68, 72, 73, 75, 76], "codecov": 75, "coef": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 63, 64, 65, 66, 67, 68, 73, 76], "coef_df": 34, "coeffici": [1, 16, 17, 19, 35, 47, 48, 50, 52, 54, 55, 58, 63, 68, 69, 70, 76], "coefs_t": 55, "coefs_w": 55, "coffici": 69, "cofid": 1, "coincid": [45, 53], "col": [33, 34, 48, 52], "collect": [36, 44, 51, 58], "colnam": [34, 50], "color": [35, 40, 41, 42, 43, 45, 51, 52, 53, 54, 56], "color_palett": [40, 51, 52, 53], "colorbar": 51, "colorramppalett": 34, "colorscal": [41, 42], "colour": [33, 34], "column": [3, 6, 37, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 61, 63, 64, 66, 73, 75, 76], "column_stack": [45, 47, 48, 57], "colv": 34, "com": [25, 35, 36, 46, 52, 54, 64, 72], "comb": 46, "combin": [34, 36, 44, 50, 51, 64, 66, 69, 75], "combind": 53, "combined_loss": 46, "come": [59, 64, 67, 69, 71, 76], "command": [72, 75], "comment": 61, "common": [57, 63, 65, 74], "companion": 74, "compar": [33, 34, 40, 41, 42, 43, 45, 47, 48, 51, 54, 56, 60, 64, 69], "comparevers": 35, "comparison": [50, 54], "compat": [32, 39, 75], "complet": [60, 69, 72], "complex": 8, "complianc": [56, 67], "complic": [36, 76], "complier": [35, 52, 53, 56, 63], "compon": [35, 46, 50, 52, 55, 63, 64, 66, 67, 75], "composit": 74, "compris": [68, 70], "comput": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 31, 33, 35, 36, 40, 52, 53, 57, 66, 67, 69, 71, 74, 75, 76], "computation": 69, "concat": [51, 52, 55, 68], "concaten": [45, 52, 68], "concentr": 68, "conclud": 76, "cond": 65, "conda": [51, 74, 75], "condit": [2, 8, 11, 16, 17, 19, 27, 28, 33, 34, 35, 40, 44, 45, 49, 51, 52, 55, 58, 60, 62, 65, 68, 69, 70, 73, 74, 75, 76], "conduct": [63, 65, 76], "conf": 56, "confer": 74, "confid": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 41, 42, 43, 44, 47, 48, 51, 53, 56, 57, 58, 62, 63, 66, 67, 69, 73, 74, 76], "confidenceband": 43, "config": 54, "configur": 36, "confint": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 41, 42, 43, 44, 45, 47, 48, 50, 53, 55, 56, 57, 58, 63, 66, 68, 70, 71, 73, 76], "conflict": 72, "confound": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 19, 31, 32, 35, 39, 49, 52, 56, 57, 61, 65, 68, 69, 70, 73, 74, 75, 76], "congress": 74, "connect": [35, 52, 53], "consequ": [16, 17, 34, 49, 51, 57, 63, 65, 69], "conserv": [57, 69], "consid": [2, 7, 8, 9, 12, 33, 34, 35, 40, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 76], "consist": [10, 11, 35, 44, 52, 53, 54, 60, 61, 65, 73, 75], "consol": [33, 75], "constant": [21, 46, 55, 63, 68, 70], "constrained_layout": 40, "construct": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 41, 42, 43, 45, 53, 57, 59, 63, 67, 68, 70, 75, 76], "construct_framework": [2, 4, 5, 7, 8, 9, 10, 11, 12], "construct_iv": 51, "constructiv": 34, "constructor": 36, "consum": [34, 51], "contain": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 33, 34, 35, 40, 41, 42, 47, 48, 50, 51, 52, 60, 63, 64, 68, 69, 75], "context": [65, 76], "continu": [32, 36, 39, 46, 54, 69, 75, 76], "contour": [2, 4, 5, 7, 8, 9, 10, 11, 12, 46, 49, 57, 69], "contours_z": [41, 42], "contrast": [43, 44], "contribut": [72, 75], "contributor": 75, "control": [22, 46, 53, 55, 76], "convent": [35, 52, 53], "converg": [33, 40, 50, 51, 60], "convergencewarn": 51, "convers": 51, "convert": [43, 51, 56], "convex": 54, "coor": [36, 64, 71, 73], "copi": [48, 52, 55], "cor": 69, "core": [37, 43, 44, 49, 51, 52, 53, 56, 57, 58, 61, 64, 73, 75], "cores_us": [43, 53, 56], "correct": [49, 63, 68, 70, 75], "correctli": [44, 54, 57, 69], "correl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 46, 51, 57, 58, 65, 69], "correpond": 65, "correspond": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 27, 28, 33, 34, 35, 36, 40, 41, 42, 44, 45, 46, 50, 51, 52, 53, 55, 56, 57, 60, 63, 64, 65, 66, 68, 69, 70, 75, 76], "cosh": 25, "coul": 34, "could": [32, 36, 39, 41, 42, 75, 76], "counfound": [16, 17, 56, 57, 63, 69], "count": [52, 53], "countour": 69, "coupl": [35, 52, 53], "cournapeau": [71, 73], "cours": [35, 50, 52, 68, 76], "cov": 16, "covari": [3, 4, 5, 6, 8, 10, 11, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 60, 61, 63, 64, 65, 67, 68, 69, 73, 75], "cover": [46, 57], "coverag": [50, 63, 75], "cp": [35, 36, 64], "cpu": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "cpu_count": [43, 53, 56], "cran": [36, 74, 75], "creat": [19, 32, 34, 36, 39, 40, 41, 42, 43, 47, 48, 51, 53, 55, 56, 64, 69, 72], "create_synthetic_group_data": 55, "critic": 76, "cross": [2, 4, 5, 7, 8, 9, 10, 11, 12, 18, 32, 33, 35, 36, 40, 50, 52, 53, 60, 62, 64, 68, 75, 76], "cross_sectional_data": [5, 18, 44, 65], "crossfit": 50, "crosstab": 54, "crucial": [46, 76], "csail": [71, 73], "csv": 46, "cumul": 65, "current": [48, 67, 69, 71, 76], "custom": [33, 40, 64], "cut": 55, "cv": [36, 52, 64, 66], "cv_glmnet": [34, 35, 36, 64, 68, 70, 73], "cvar": [2, 13, 62, 75], "cvar_0": 43, "cvar_1": 43, "d": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76], "d0": [43, 56, 68], "d0_true": 56, "d0cdb0ea4795": 36, "d1": [43, 54, 56, 68, 70], "d10": [68, 70], "d1_true": 56, "d2": [54, 68, 70], "d21ee5775b5f": 36, "d3": [68, 70], "d4": [68, 70], "d5": [68, 70], "d5a0c70f1d98": 36, "d6": [68, 70], "d7": [68, 70], "d8": [68, 70], "d9": [68, 70], "d_": [23, 34, 45, 51, 65, 68, 70], "d_1": [54, 68, 70], "d_2": 54, "d_col": [3, 6, 32, 33, 34, 35, 36, 39, 41, 42, 47, 48, 51, 52, 53, 55, 57, 59, 60, 61, 64, 65, 66, 67, 73, 75, 76], "d_i": [19, 20, 21, 22, 24, 25, 26, 33, 40, 43, 44, 54, 56, 58, 60, 65], "d_j": [68, 70], "d_k": [68, 70], "d_w": 55, "da1440": 54, "dag": [58, 76], "dark": [33, 40], "darkblu": 34, "darkr": 34, "dat": 61, "data": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 45, 46, 50, 54, 59, 62, 63, 64, 66, 68, 70, 74, 75], "data_cvar": 53, "data_dict": [41, 42, 47, 48, 49], "data_dml": 57, "data_dml_bas": [35, 41, 42, 47, 48, 52, 53, 55], "data_dml_base_iv": [35, 52, 53], "data_dml_flex": [35, 52], "data_dml_flex_iv": 35, "data_dml_iv_flex": 52, "data_dml_new": 55, "data_fram": 76, "data_lqt": 53, "data_pq": 53, "data_qt": 53, "data_transf": [34, 51, 52], "datafram": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 34, 37, 39, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63, 64, 65, 67, 68, 69, 73, 76], "dataset": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 33, 40, 41, 42, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 73, 76], "datatyp": 75, "db": [35, 52, 53, 57, 76], "dbl": [34, 35, 36, 61, 68, 70, 73, 76], "dc13a11076b3": 36, "ddc9": 36, "de": [32, 39, 74], "deal": [32, 39], "debias": [14, 15, 23, 24, 34, 46, 51, 62, 64, 66, 71, 74, 75], "debt": [35, 52, 53], "decai": 58, "decid": [35, 52], "decis": [8, 32, 35, 39, 52, 53, 63, 74, 76], "decision_effect": 32, "decision_impact": [32, 39], "decisiontreeclassifi": [8, 52], "decisiontreeregressor": 52, "declar": 76, "deep": [29, 30], "deeper": 8, "def": [2, 4, 5, 7, 8, 9, 10, 11, 12, 40, 43, 50, 51, 54, 55, 56, 64, 67], "default": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 23, 24, 25, 29, 30, 34, 44, 47, 48, 50, 51, 55, 57, 58, 59, 63, 64, 66, 68, 69, 70, 73, 76], "default_convert": 51, "defin": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 35, 36, 40, 41, 42, 43, 44, 46, 47, 48, 50, 52, 53, 55, 56, 57, 63, 64, 65, 67, 69], "definit": [25, 47, 48, 69], "defint": 69, "degre": [35, 41, 42, 51, 52, 63, 69], "dekel": 74, "delete_origin": 36, "deliber": 54, "delta": [22, 44, 65], "delta_j": 22, "delta_theta": [31, 49, 57, 69], "demand": [34, 51, 69], "demir": [14, 15, 24, 34, 46, 51, 60, 66, 71, 74], "demonstr": [33, 34, 40, 51, 61, 68, 70, 71, 73], "deni": 74, "denomin": 69, "denot": [10, 34, 35, 44, 45, 51, 52, 58, 63, 65, 67, 69], "dens_net_tfa": 35, "densiti": [9, 12, 13, 33, 40], "dep": 37, "dep1": [36, 37, 61, 73], "dep2": [36, 37, 61, 73], "depend": [2, 8, 9, 13, 19, 36, 41, 42, 44, 47, 48, 49, 50, 55, 59, 63, 64, 67, 69, 73, 74], "deprec": [59, 66], "depreci": 75, "depth": [8, 35, 36, 55, 59, 63, 64, 65, 66, 67, 68, 73, 76], "deriv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 28, 68], "describ": [34, 51, 52, 53, 64, 66, 72, 75], "descript": [35, 37, 57, 64, 66, 69], "design": 74, "design_info": [41, 42], "design_matrix": [41, 42, 63], "desir": [16, 17, 36, 55], "detail": [2, 4, 5, 7, 8, 9, 10, 11, 12, 27, 28, 33, 35, 36, 40, 44, 45, 46, 53, 57, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 73, 75, 76], "determin": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 35, 43, 52, 53, 56, 57, 65, 68, 69, 70], "determinist": [55, 63], "deutsch": 71, "dev": 75, "develop": [34, 36, 51, 65, 75], "deviat": [50, 69], "dezeur": 74, "df": [3, 6, 32, 33, 34, 39, 41, 42, 43, 45, 48, 51, 54, 56, 57, 58, 60, 63, 65], "df_agg": 46, "df_bonu": [36, 61, 73], "df_cate": [41, 42], "df_ci": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "df_coef": 50, "df_cvar": 53, "df_lqte": 53, "df_ml_g0": 50, "df_ml_g1": 50, "df_ml_m": 50, "df_pa": [44, 58], "df_plot": 34, "df_pq": 53, "df_qte": 53, "df_result": 46, "df_summari": 52, "df_wide": 51, "dfg": 71, "dgp": [18, 34, 43, 45, 46, 51, 54, 55, 56, 58], "dgp1": 18, "dgp2": 18, "dgp3": 18, "dgp4": 18, "dgp5": 18, "dgp6": 18, "dgp_tpye": 44, "dgp_type": [18, 44], "diagram": [32, 39, 65], "dichotom": [32, 39], "dict": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 31, 41, 42, 46, 64], "dict_kei": 69, "dictionari": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 19, 31, 41, 42, 47, 48, 57, 63, 64, 69], "dictonari": [35, 52], "did": [3, 6, 33, 44, 45, 51, 62, 75, 76], "diff": 52, "differ": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 32, 33, 34, 35, 36, 39, 40, 43, 47, 48, 49, 51, 52, 53, 54, 56, 57, 58, 59, 62, 63, 64, 66, 72, 73, 74, 75, 76], "dillon": 74, "dim": 35, "dim_x": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 20, 21, 22, 23, 24, 25, 26, 33, 34, 36, 40, 50, 51, 60, 63, 64, 65, 69], "dim_z": [10, 22, 65], "dimens": [19, 23, 34, 51, 55, 66], "dimension": [10, 11, 19, 21, 46, 63, 65, 66, 68, 69, 70, 73, 74], "direct": [33, 40, 45, 58, 60, 76], "directli": [33, 35, 40, 50, 57, 60, 69, 73, 76], "discret": 51, "discretis": 53, "discuss": [20, 34, 35, 51, 52, 74, 75, 76], "disjoint": [34, 47, 48, 51], "displai": [34, 51, 63, 69], "displot": 52, "disproportion": [35, 52], "dist": [2, 4, 5, 7, 8, 9, 10, 11, 12], "distr": 64, "distribut": [33, 40, 44, 50, 60, 65, 69, 72, 74, 75], "diverg": [33, 40, 60], "dmatrix": [41, 42, 63], "dml": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 27, 28, 32, 33, 36, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 67, 68, 69, 70, 72], "dml1": [62, 73, 75, 76], "dml2": [32, 34, 36, 37, 44, 51, 53, 62, 65, 67, 68, 73, 75, 76], "dml_base": 51, "dml_combin": 68, "dml_cv_predict": 75, "dml_cvar": [43, 53], "dml_cvar_0": 43, "dml_cvar_1": 43, "dml_cvar_obj": [2, 63], "dml_data": [34, 37, 44, 45, 49, 50, 51, 54, 57, 58, 63, 64, 65, 68, 70, 76], "dml_data_bonu": [36, 73], "dml_data_df": 76, "dml_data_lasso": 37, "dml_data_sim": [36, 73], "dml_df": [34, 51], "dml_did": [44, 45], "dml_did_obj": [4, 5, 65], "dml_iivm_boost": [35, 52], "dml_iivm_forest": [35, 52], "dml_iivm_lasso": [35, 52], "dml_iivm_obj": [7, 39, 65], "dml_iivm_tre": [35, 52], "dml_irm": [41, 47, 50, 55], "dml_irm_at": 49, "dml_irm_boost": [35, 52], "dml_irm_forest": [35, 52], "dml_irm_gat": 49, "dml_irm_gatet": 49, "dml_irm_lasso": [35, 37, 52], "dml_irm_new": 55, "dml_irm_obj": [2, 4, 5, 7, 8, 9, 10, 11, 12, 57, 63, 64, 65], "dml_irm_obj_ext": 64, "dml_irm_rf": 37, "dml_irm_tre": [35, 52], "dml_long": 31, "dml_lpq_0": 56, "dml_lpq_1": 56, "dml_lpq_obj": [9, 63], "dml_lqte": [53, 56], "dml_obj": 57, "dml_pliv": [34, 51], "dml_pliv_obj": [10, 34, 51, 65], "dml_plr": [42, 48, 68, 70], "dml_plr_1": 68, "dml_plr_2": 68, "dml_plr_boost": [35, 52], "dml_plr_forest": [35, 52, 76], "dml_plr_lasso": [35, 37, 52], "dml_plr_no_split": 66, "dml_plr_obj": [2, 4, 5, 7, 8, 9, 10, 11, 12, 57, 59, 63, 64, 65, 66, 67, 68, 69], "dml_plr_obj_extern": 66, "dml_plr_obj_intern": 66, "dml_plr_rf": 37, "dml_plr_tree": [35, 52, 76], "dml_pq_0": [53, 56], "dml_pq_1": [53, 56], "dml_pq_obj": [12, 63], "dml_procedur": [37, 59, 73, 75, 76], "dml_qte": [53, 56], "dml_qte_obj": [13, 63], "dml_short": 31, "dml_ssm": [58, 65], "dml_tune": 75, "dmldummyclassifi": 64, "dmldummyregressor": 64, "dmlmt": 74, "dnorm": 33, "do": [34, 35, 36, 50, 51, 52, 53, 54, 63, 64, 69, 73, 76], "doabl": 67, "doc": [32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 71, 75], "docu": 75, "document": [38, 41, 42, 45, 47, 48, 71, 75], "doe": [13, 34, 35, 51, 52, 54, 57, 69, 76], "doesn": [32, 39], "doi": [14, 15, 16, 17, 18, 20, 23, 24, 26, 34, 36, 46, 51, 60, 64, 66, 68, 70, 71, 73, 75], "domain": 55, "done": [2, 4, 5, 7, 8, 9, 10, 11, 12, 53, 64, 66, 69], "dot": [45, 55, 61, 63, 64, 68, 70, 73], "doubl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 23, 24, 25, 26, 35, 46, 52, 54, 62, 64, 66, 67, 68, 69, 70, 75], "double_ml_bonus_data": 37, "double_ml_data_from_data_fram": [33, 60, 61, 76], "double_ml_data_from_matrix": [36, 61, 64, 68, 70, 73], "double_ml_irm": [37, 55], "doubleiivm": 71, "doubleml": [33, 34, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 73, 74, 75], "doubleml2022python": 71, "doubleml2024r": 71, "doubleml_framework": [2, 4, 5, 7, 8, 9, 10, 11, 12], "doublemlblp": [8, 11, 41, 42, 63, 75], "doublemlclusterdata": 23, "doublemlcvar": [43, 63, 67, 75], "doublemldata": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 24, 25, 26, 32, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 76], "doublemldid": [44, 45, 65, 67, 75], "doublemldidc": [44, 65, 67, 75], "doublemlframework": [2, 4, 5, 7, 8, 9, 10, 11, 12, 66, 68, 75], "doublemlidid": 65, "doublemlididc": 65, "doublemliivm": [32, 35, 39, 52, 64, 65, 66, 67, 75], "doublemlirm": [2, 4, 5, 7, 9, 10, 11, 12, 35, 37, 41, 47, 49, 50, 52, 54, 55, 57, 63, 64, 65, 66, 67, 71, 75], "doublemllpq": [56, 63, 67, 75], "doublemlpliv": [64, 65, 66, 67, 71, 75], "doublemlplr": [2, 4, 5, 7, 8, 9, 10, 12, 33, 35, 36, 37, 40, 42, 48, 52, 54, 57, 59, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76], "doublemlpolicytre": [8, 63], "doublemlpq": [53, 56, 63, 67, 75], "doublemlqt": [43, 53, 56, 63, 68, 75], "doublemlresampl": 50, "doublemlsmm": 75, "doublemlssm": [58, 65, 67], "doubli": [16, 17, 18, 74], "download": [32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 61, 72, 73], "dpg_dict": 57, "dpi": [33, 40, 54], "draw": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 66, 75], "draw_sample_split": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 50, 66], "drawn": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 19, 35, 52, 53, 55, 66], "drive": [33, 40, 60], "driven": 76, "drop": [51, 54, 61, 64, 67, 68, 70], "dt": [67, 69], "dt_bonu": 61, "dtype": [37, 44, 47, 48, 49, 50, 51, 52, 53, 57, 58, 61, 63, 73], "dualiti": 51, "dubourg": [71, 73], "duchesnai": [71, 73], "due": [33, 40, 41, 42, 49, 57, 60, 65, 69, 75, 76], "duflo": [14, 15, 24, 34, 46, 51, 60, 66, 71, 74], "dummi": [1, 8, 11, 29, 30, 63, 64, 65, 75], "dummyclassifi": 29, "dummyregressor": 30, "duplic": 75, "durabl": [36, 37, 61, 73], "durat": 15, "dure": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 51, 52, 64, 66, 73, 75, 76], "dx": 20, "dynam": 74, "e": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 24, 26, 27, 28, 33, 34, 35, 40, 41, 42, 44, 46, 49, 50, 51, 52, 53, 54, 57, 58, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76], "e20ea26": 36, "e401": [35, 52, 53, 57, 76], "e4016553": 76, "e45228": 54, "e57c": 36, "each": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 36, 45, 47, 48, 50, 51, 53, 54, 55, 57, 59, 61, 64, 66, 68, 69, 70, 76], "earlier": 76, "earn": [35, 52, 53], "earner": [35, 52, 57], "easi": [36, 67], "easili": [36, 50, 53, 75], "ec973f": 54, "ecolor": [45, 52, 54], "econ": 74, "econml": 74, "econom": [22, 23, 25, 26, 34, 46, 51, 54, 66, 74], "econometr": [14, 15, 16, 17, 18, 24, 25, 34, 46, 51, 60, 71, 74], "econometrica": [21, 34, 51, 54, 60, 74], "ecosystem": [71, 76], "ectj": [14, 15, 24, 34, 46, 51, 60, 71], "ed": 74, "edge_color": 40, "edgecolor": 40, "edit": [72, 74], "edu": [71, 73], "educ": [35, 52, 53, 57, 76], "ee97bda7": 36, "effect": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 32, 33, 34, 36, 39, 40, 44, 45, 46, 49, 51, 55, 58, 60, 62, 64, 65, 66, 67, 68, 69, 73, 74, 75, 76], "effici": 74, "effort": 67, "eight": [34, 51], "either": [2, 4, 5, 7, 8, 9, 10, 11, 12, 19, 36, 45, 46, 55, 63, 64, 76], "eleanor": 74, "element": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 41, 42, 43, 44, 50, 51, 53, 56, 57, 58, 67, 69, 75], "element_text": [34, 35], "elementari": 74, "elif": [47, 48, 55], "elig": [53, 57, 76], "eligibl": [35, 52, 57], "ell": [33, 34, 40, 46, 51, 60, 67, 73], "ell_0": [7, 10, 11, 33, 40, 46, 60, 65], "ell_2": 50, "els": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 45, 47, 48, 51, 55], "em": 74, "emphas": [34, 51], "empir": [27, 28, 33, 34, 40, 51, 54, 60, 66, 67, 68, 70], "emploi": [34, 46, 51, 67], "employ": [35, 52, 53], "employe": 76, "empti": 51, "emul": 69, "enabl": [55, 57, 63, 69, 75], "encapsul": [29, 30], "encod": 54, "end": [20, 22, 23, 33, 34, 35, 40, 43, 45, 46, 50, 51, 52, 54, 55, 56, 58, 59, 61, 64, 66, 68, 70, 73, 76], "endogen": [35, 52, 53, 76], "enet_coordinate_descent_gram": 51, "engin": [36, 74], "enrol": [35, 52, 53], "ensembl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 37, 40, 41, 42, 47, 48, 49, 50, 52, 55, 57, 59, 63, 64, 65, 66, 67, 68, 69, 73, 76], "ensemble_learner_pipelin": 64, "ensemble_pipe_classif": 36, "ensemble_pipe_regr": 36, "ensur": [34, 48, 51, 55], "entir": [33, 35, 40, 52, 60, 69], "entri": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 37, 40, 44, 49, 51, 52, 53, 57, 58, 60, 61, 64, 71, 73, 75], "enumer": [43, 45, 47, 48, 50, 51, 52, 53, 56, 59, 64, 66], "env": [51, 72], "environ": 72, "ep": 54, "epsilon": [35, 43, 44, 45, 52, 56, 63, 65], "epsilon_": [34, 45, 51], "epsilon_i": [19, 43, 54, 55, 56], "epsilon_sampl": 55, "epsilon_tru": [43, 56], "eqnarrai": 35, "equal": [8, 34, 51, 54, 58, 63, 64, 69], "equat": [34, 35, 51, 52, 59, 68, 70, 76], "equilibrium": [34, 51], "equival": [46, 66], "err": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 37, 39, 41, 42, 43, 44, 47, 48, 49, 51, 52, 53, 54, 56, 57, 58, 63, 64, 65, 66, 67, 68, 73, 76], "error": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 32, 33, 35, 36, 40, 45, 46, 47, 48, 50, 52, 60, 64, 65, 66, 67, 68, 69, 70, 73, 75, 76], "errorbar": [45, 47, 48, 52, 54], "erstellt": [34, 35, 36], "especi": 50, "esther": [66, 74], "estim": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 27, 28, 29, 30, 33, 34, 36, 40, 41, 42, 43, 45, 47, 48, 50, 51, 55, 59, 60, 62, 63, 64, 65, 69, 70, 71, 74, 75], "estimatior": [3, 6], "et": [14, 15, 19, 21, 23, 24, 33, 34, 35, 36, 40, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 56, 57, 60, 65, 66, 67, 68, 69, 70, 71, 73, 75], "eta": [27, 28, 33, 34, 35, 45, 51, 52, 56, 59, 63, 66, 67, 68, 69, 70, 73, 76], "eta1": 54, "eta2": 54, "eta_": [68, 69, 70], "eta_0": [59, 67, 68], "eta_i": [19, 45, 55, 56], "eta_sampl": 55, "eta_tru": 56, "etc": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 50, 51, 75], "ev": [33, 40, 60], "eval": [36, 64], "eval_metr": [35, 52, 76], "evalu": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 21, 28, 36, 41, 42, 43, 45, 49, 53, 56, 57, 59, 74, 75], "evaluate_learn": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 64, 75], "evalut": 64, "even": [35, 36, 52, 54, 64, 76], "eventu": [34, 51], "everi": [34, 51], "everyth": 71, "evid": 49, "exampl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 32, 33, 35, 36, 37, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76], "except": [46, 75], "excess": 50, "exclud": 31, "exclus": [8, 11, 47, 48, 63], "execut": [36, 76], "exemplarili": 73, "exemplatori": 55, "exhaust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 64], "exhibit": [34, 51], "exist": [65, 69], "exogen": [35, 52, 53, 76], "exp": [16, 17, 18, 19, 21, 24, 33, 40, 41, 42, 45, 47, 48, 54, 55, 60], "expect": [16, 17, 44, 49, 50, 58, 63, 66, 68, 73], "experi": [15, 20, 21, 33, 35, 40, 52, 60, 61, 66, 73, 74], "experiment": [4, 5, 18, 67, 69], "explain": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 57, 69], "explan": [34, 44, 51, 57, 69, 71, 76], "explanatori": [68, 70], "explicitli": [49, 76], "exploit": [33, 40, 60, 76], "exponenti": [68, 70], "export": 75, "exposur": 45, "express": [34, 46, 69], "extend": [64, 71, 75], "extendend": 69, "extens": [64, 67, 71, 74, 75], "extent": 46, "extern": [33, 40, 62, 69, 75], "external_predict": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 40, 64], "externalptr": 35, "extra": 36, "extract": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "extralearn": 36, "extrem": [35, 52], "ey": 46, "f": [35, 36, 40, 43, 44, 45, 46, 50, 51, 52, 53, 55, 56, 57, 58, 64, 69, 71, 73], "f00584a57972": 36, "f1718fdeb9b0": 36, "f2e7": 36, "f3d24993": 36, "f6ebc": 54, "f_": [18, 45, 63], "f_loc": [43, 56], "f_p": 45, "f_scale": [43, 56], "face_color": 40, "facet_wrap": 35, "fact": [35, 52, 53], "factor": [33, 34, 35, 36, 40, 50, 60, 64, 76], "faculti": 74, "fail": 75, "fair": 50, "fake": [32, 39], "fals": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 33, 35, 36, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 58, 61, 64, 65, 66, 67, 68, 69, 70, 76], "famili": [35, 52, 64], "far": [35, 52], "farbmach": 20, "fast": [50, 55, 64], "faster": 46, "fb5c25fa": 36, "fc9e": 36, "fd8a": 36, "featur": [2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 37, 49, 50, 52, 55, 63, 64], "featureless": [36, 64], "features_bas": [35, 52, 53, 57], "features_flex": 35, "featureunion": 36, "femal": [36, 37, 61, 73], "fern\u00e1ndez": [21, 66, 74], "fetch": [35, 51, 52, 53, 61], "fetch_401k": [35, 52, 53, 57, 76], "fetch_bonu": [36, 37, 61, 73], "few": [35, 52, 53], "ff7f0e": 45, "field": [34, 51, 64, 76], "fifteenth": 74, "fifth": 34, "fig": [2, 4, 5, 7, 8, 9, 10, 11, 12, 41, 42, 43, 45, 46, 50, 53, 54, 56], "fig_al": 40, "fig_dml": 40, "fig_non_orth": 40, "fig_orth_nosplit": 40, "fig_po_al": 40, "fig_po_dml": 40, "fig_po_nosplit": 40, "figsiz": [37, 41, 42, 43, 45, 47, 48, 50, 51, 52, 53, 54, 56], "figur": [2, 4, 5, 7, 8, 9, 10, 11, 12, 24, 33, 34, 37, 40, 41, 42, 43, 45, 46, 47, 48, 51, 52, 53, 56, 60], "figure_format": 54, "file": [14, 15, 46, 54, 74, 75], "filenam": 33, "fill": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 34, 35, 44, 50, 52, 58], "fill_between": [41, 42, 43, 53, 56], "fill_valu": 50, "filter": 36, "filterwarn": 40, "final": [33, 36, 40, 41, 42, 43, 45, 47, 48, 49, 53, 56, 58, 60, 65, 76], "financi": [14, 57, 76], "find": [35, 45, 52, 63, 64, 76], "finish": 36, "finit": [33, 35], "firm": [34, 51, 57], "firmid": 51, "first": [16, 17, 18, 23, 32, 33, 34, 35, 36, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 51, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 72, 73, 75, 76], "fit": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 29, 30, 32, 33, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 67, 68, 69, 70, 71, 75, 76], "fit_arg": [2, 4, 5, 7, 8, 9, 10, 11, 12], "fit_transform": [51, 52], "five": 51, "fix": [45, 50, 52, 75], "flag": [18, 66, 72], "flake8": 75, "flatten": 54, "flexibl": [32, 35, 36, 39, 44, 52, 71, 76], "flexibli": [35, 52, 57], "float": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17], "float32": [53, 57], "float64": [37, 44, 48, 49, 51, 52, 57, 58, 61, 64, 73], "floor": 36, "floor_divid": 51, "flt": 36, "flush": 33, "fmt": [45, 47, 48, 52, 54], "focu": [34, 35, 51, 52, 53, 63, 65, 76], "focus": [53, 57, 76], "fold": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 34, 35, 36, 44, 50, 51, 52, 53, 57, 58, 59, 62, 64, 65, 67, 68, 73, 76], "follow": [16, 17, 18, 19, 33, 34, 35, 40, 41, 42, 43, 44, 45, 47, 48, 51, 52, 53, 56, 57, 58, 60, 61, 63, 64, 65, 66, 69, 72, 73, 76], "font_scal": [51, 52, 53], "fontsiz": [43, 53, 56], "force_all_x_finit": [3, 6], "forest": [20, 32, 33, 35, 36, 39, 40, 44, 49, 50, 52, 57, 60, 64, 73, 76], "forest_summari": 52, "forg": [72, 74, 75], "form": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 19, 35, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 56, 57, 58, 63, 65, 69, 72, 73], "format": [40, 49, 69], "formula": [34, 35, 51, 52, 75], "formula_flex": 35, "forschungsgemeinschaft": 71, "forthcom": 74, "forum": 75, "forward": 8, "found": [41, 42, 46, 47, 48, 60, 61, 64, 65, 73], "foundat": [71, 74], "four": [35, 50, 52, 75], "fourth": [34, 51], "frac": [7, 16, 17, 18, 20, 21, 22, 24, 25, 26, 28, 33, 34, 36, 40, 45, 46, 49, 51, 54, 59, 60, 63, 65, 67, 68, 69, 70], "fraction": 36, "frame": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 37, 41, 42, 44, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 60, 61, 73, 76], "framework": [28, 33, 34, 36, 40, 50, 51, 54, 60, 64, 68, 70, 71, 73, 75, 76], "freez": 72, "fribourg": 74, "from": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 75, 76], "from_arrai": [3, 6, 40, 43, 44, 45, 56, 60, 61, 64, 68, 70, 73], "from_product": 51, "fr\u00e9chet": 69, "fsize": [35, 52, 53, 57, 76], "full": [40, 43, 44, 45, 47, 48, 50, 52, 53, 56, 58, 60], "fulli": [8, 35, 38, 52, 65], "fun": 33, "function": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 24, 25, 27, 28, 32, 33, 35, 36, 39, 40, 41, 42, 43, 44, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76], "fund": [35, 52, 53, 71], "further": [16, 17, 18, 19, 23, 34, 36, 41, 42, 43, 44, 45, 49, 50, 51, 53, 55, 56, 57, 58, 64, 65, 67, 68, 69, 70, 71, 73, 75, 76], "furthermor": 40, "futurewarn": 48, "g": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 33, 36, 37, 40, 41, 42, 44, 45, 46, 49, 50, 53, 54, 55, 57, 58, 60, 63, 64, 65, 67, 68, 69, 71, 72, 73, 76], "g_": [67, 68, 70], "g_0": [4, 5, 7, 8, 10, 11, 12, 24, 25, 33, 34, 35, 40, 50, 51, 52, 60, 63, 64, 65, 67, 69, 73, 76], "g_1": 50, "g_all": [33, 35], "g_all_po": 33, "g_ci": 35, "g_d": 67, "g_dml": 33, "g_dml_po": 33, "g_hat": [10, 11, 33, 40, 67], "g_hat0": [7, 8], "g_hat1": [7, 8], "g_k": 63, "g_nonorth": 33, "g_nosplit": 33, "g_nosplit_po": 33, "g_x": 45, "gain": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 31, 50, 69, 75], "gain_statist": 75, "galleri": [60, 63, 64, 65, 71, 75], "gamma": [22, 25, 26, 34, 51, 54, 55, 67], "gamma_0": [19, 55, 58, 67], "gamma_a": [16, 17], "gap": 51, "gate": [1, 8, 11, 54, 55, 62, 75], "gate_obj": 63, "gatet": 63, "gaussian": [9, 12, 13, 33, 40, 60, 63, 64, 68, 70, 74], "ge": [16, 18, 19, 49, 55, 63], "geer": 74, "gelbach": [34, 51], "gener": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 70, 74, 75, 76], "generate_treat": 56, "geom_bar": 35, "geom_dens": 35, "geom_errorbar": 35, "geom_funct": 33, "geom_histogram": 33, "geom_hlin": 35, "geom_point": 35, "geom_til": 34, "geom_vlin": 33, "german": 71, "get": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 36, 50, 54, 57, 69, 71, 72], "get_dummi": 54, "get_feature_names_out": [51, 52], "get_logg": [33, 34, 35, 36, 59, 64, 65, 66, 67, 68, 70, 73], "get_metadata_rout": [29, 30], "get_param": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 64], "ggplot": [33, 34, 35], "ggplot2": [33, 34, 35], "ggsave": 33, "ggtitl": 35, "gh": 75, "git": 72, "github": [35, 46, 52, 54, 71, 74, 75], "githubusercont": 46, "give": [35, 52], "given": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 21, 24, 25, 28, 33, 34, 40, 45, 47, 48, 51, 53, 54, 58, 60, 63, 68, 69, 70, 73, 75], "glmnet": [35, 36, 64, 75], "global": [2, 4, 5, 7, 8, 9, 10, 11, 12, 64], "glrn": 36, "glrn_lasso": 36, "go": [41, 42, 46], "goal": [47, 48], "goldman": 74, "good": [46, 69, 76], "gradient": [35, 52], "gradientboostingclassifi": 50, "gradientboostingregressor": 50, "gramfort": [71, 73], "graph": [36, 58, 76], "graph_ensemble_classif": 36, "graph_ensemble_regr": 36, "graph_object": [41, 42, 46], "graphlearn": [36, 64], "grasp": 69, "great": [45, 76], "greater": 76, "green": [33, 41, 42, 43, 56], "greg": 74, "grei": 35, "grenand": 74, "grey50": 34, "grid": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 36, 41, 42, 43, 46, 53, 54, 56, 64, 69], "grid_arrai": [41, 42], "grid_bound": [2, 4, 5, 7, 8, 9, 10, 11, 12], "grid_search": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 64], "grid_siz": [2, 4, 5, 7, 8, 9, 10, 11, 12, 41, 42], "gridextra": 34, "gridsearchcv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 64], "grisel": [71, 73], "grob": 34, "group": [8, 11, 32, 39, 49, 53, 54, 55, 62], "group_0": 63, "group_1": [47, 48, 63], "group_2": [47, 48, 63], "group_3": [47, 48], "group_effect": 55, "group_ind": 49, "group_treat": 49, "groupbi": [46, 52], "gruber": 20, "gt": [32, 34, 35, 36, 37, 39, 41, 42, 43, 44, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 61, 73], "guarante": [34, 51], "guber": 20, "guess": [57, 69], "guid": [27, 28, 29, 30, 33, 34, 36, 40, 45, 49, 51, 57, 64, 71, 73, 75], "guidelin": 75, "gunion": [36, 64], "h": [16, 17, 18, 20, 23, 34, 51, 74], "h_0": [49, 57, 69, 76], "ha": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 18, 33, 34, 35, 40, 46, 50, 51, 52, 53, 54, 57, 63, 64, 65, 69, 76], "half": [33, 40, 54, 60, 66], "hand": [50, 54, 76], "handbook": 54, "handl": [50, 64, 75], "hansen": [14, 15, 21, 22, 24, 34, 46, 51, 60, 71, 74], "happend": 50, "hard": [57, 69], "harold": 74, "hat": [33, 34, 40, 46, 49, 51, 54, 59, 60, 63, 66, 67, 68, 69, 70], "have": [1, 8, 11, 13, 19, 32, 33, 34, 35, 36, 39, 41, 42, 44, 45, 49, 50, 51, 52, 53, 54, 55, 57, 58, 61, 63, 64, 68, 69, 72, 73, 75, 76], "hazlett": 69, "hc": 74, "hdm": [34, 51], "he": 58, "head": [34, 36, 37, 41, 42, 47, 48, 51, 52, 54, 61, 63, 73], "heat": [34, 51], "heatmap": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 51], "heavili": 50, "hei": 74, "height": [33, 34, 46], "help": [35, 43, 50, 53, 55, 66, 76], "helper": 75, "henc": [35, 36, 52, 64, 67, 76], "here": [9, 12, 13, 34, 35, 36, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 55, 56, 58, 61, 64, 72], "heterogen": [8, 19, 35, 49, 52, 53, 55, 62, 65, 66, 74, 75, 76], "heteroskedast": [47, 48], "heurist": [33, 40, 60], "high": [10, 11, 21, 35, 45, 46, 52, 53, 59, 65, 68, 70, 71, 73, 74], "higher": [35, 46, 52, 53, 54, 75, 76], "highli": [35, 52, 71], "highlight": [2, 4, 5, 7, 8, 9, 10, 11, 12, 44, 75], "highlightcolor": [41, 42], "hispan": 37, "hist_e401": 35, "hist_p401": 35, "histplot": 40, "hjust": 35, "hline": [61, 68, 70, 73, 76], "hold": [26, 34, 35, 51, 52, 58, 63, 64], "holdout": [64, 66], "holm": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "home": [35, 52], "homogen": 65, "hopefulli": 53, "horizont": [34, 45, 51], "hot": 54, "hotstart_backward": [36, 64], "hotstart_forward": [36, 64], "household": [35, 52, 53, 57], "how": [29, 30, 32, 34, 35, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 60, 64, 71, 72], "howev": [33, 35, 40, 52, 58, 60, 76], "hown": [35, 52, 53, 57, 76], "hpwt": [34, 51], "hpwt0": 34, "hpwtairmpdspac": 34, "href": 71, "hspace": 50, "hstack": 45, "html": [36, 48, 71, 73, 75], "http": [20, 25, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 64, 71, 72, 73, 75], "huber": [26, 58, 65, 67, 74], "hue": 52, "huge": 50, "hugo": 74, "husd": [36, 37, 61, 73], "hyperparamet": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 36, 37, 46, 50, 52, 62, 73], "hypothes": [68, 70, 74], "hypothesi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 52, 57, 69, 74], "i": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76], "i0": [44, 45, 65], "i03": 71, "i1": [44, 65], "i_": [22, 51, 55], "i_1": [34, 51], "i_2": [34, 51], "i_3": [34, 51], "i_4": 45, "i_est": 40, "i_fold": 34, "i_k": [34, 51, 59, 66, 68, 70], "i_learn": 50, "i_rep": [33, 40, 44, 50, 58, 60], "i_split": 51, "i_train": 40, "icp": 74, "id": [34, 36, 51], "id_var": 51, "idea": [35, 36, 52, 53, 64, 69, 76], "ident": [16, 17, 18, 19, 22, 36, 64, 69], "identif": [65, 76], "identifi": [34, 35, 44, 49, 51, 52, 53, 63, 65, 69, 75], "identifii": 63, "idx_tau": [43, 53, 56], "idx_treat": [2, 4, 5, 7, 8, 9, 10, 11, 12, 69], "ieee": 74, "ignor": 40, "ii": [34, 51], "iid": 65, "iivm": [7, 20, 27, 28, 53, 59, 62, 63, 71, 75], "iivm_summari": 52, "iivmglmnet": 35, "iivmrang": 35, "iivmrpart": 35, "iivmxgboost11861": 35, "ij": [23, 34, 51, 58], "ilia": 74, "illustr": [33, 34, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 60, 64, 76], "iloc": [44, 45, 50, 51, 54], "immedi": 72, "immun": [66, 74], "impact": [32, 39, 50, 54, 57], "implement": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 27, 28, 33, 34, 35, 36, 40, 44, 46, 50, 51, 52, 54, 57, 58, 60, 62, 63, 64, 65, 66, 68, 70, 71, 73, 74, 75, 76], "impli": [16, 17, 34, 35, 51, 52, 53, 63, 69], "implment": 45, "import": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76], "importlib": 46, "improv": [44, 50, 55, 75], "in_sample_norm": [4, 5, 44, 67, 69], "inbuild": 50, "inbuilt": 50, "inc": [35, 52, 53, 57, 76], "includ": [2, 4, 5, 7, 8, 9, 10, 11, 12, 31, 35, 45, 47, 48, 52, 57, 63, 65, 68, 69, 70, 75, 76], "include_bia": [51, 52], "include_scenario": [2, 4, 5, 7, 8, 9, 10, 11, 12], "incom": [35, 52, 53, 55, 57, 76], "incorpor": [36, 57, 69], "increas": [49, 50, 51, 76], "increment": 75, "ind": 52, "independ": [4, 5, 16, 17, 18, 19, 34, 36, 45, 49, 51, 55, 65, 67, 75], "index": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 34, 37, 40, 45, 46, 47, 48, 51, 52, 54, 55, 60, 61, 66, 67, 73], "index_col": 46, "india": [66, 74], "indic": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 19, 26, 34, 35, 45, 49, 51, 52, 53, 58, 59, 61, 63, 65, 66], "individu": [8, 35, 45, 47, 48, 49, 52, 53, 57, 63, 76], "individual_df": 45, "induc": [62, 66], "industri": [34, 51], "inf": [3, 6], "inf_model": 67, "infer": [21, 22, 32, 33, 34, 39, 40, 46, 51, 60, 62, 66, 71, 73, 74, 75], "inferenti": 76, "infinit": [3, 6, 75], "info": [32, 36, 37, 44, 49, 51, 52, 53, 57, 58, 61, 73, 75, 76], "inform": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 29, 30, 32, 36, 39, 41, 42, 50, 57, 69, 74], "infti": [33, 40, 60], "inherit": [54, 75], "initi": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 35, 36, 43, 44, 52, 53, 56, 57, 58, 61, 63, 64, 66, 73, 75, 76], "inlin": [37, 54], "inlinebackend": 54, "inner": [2, 4, 5, 7, 8, 9, 10, 11, 12, 64], "innermost": 64, "input": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 57, 59, 68, 69, 70], "insight": 46, "insignific": 57, "inspect": 73, "inspir": [20, 21, 26], "instal": [35, 75], "install_github": 72, "instanc": [35, 36, 52, 64], "instanti": [34, 35, 51, 52, 64, 66], "instead": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 35, 39, 48, 49, 52, 53, 63, 64, 69, 75], "instruct": 75, "instrument": [3, 6, 7, 10, 14, 20, 22, 34, 35, 36, 37, 44, 49, 51, 52, 53, 56, 57, 58, 61, 64, 65, 67, 68, 73, 76], "instrument_effect": 32, "instrument_impact": 39, "int": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 34, 35, 39, 43, 44, 55, 56, 58], "int64": [37, 50, 51, 61, 73], "int8": [52, 53, 57], "integ": [18, 36, 64], "integr": [69, 75], "intend": [36, 76], "intent": 76, "inter": 64, "interact": [7, 8, 16, 20, 21, 62, 64, 71, 75, 76], "interchang": 68, "interest": [7, 8, 10, 11, 16, 17, 33, 35, 40, 44, 46, 52, 53, 58, 60, 63, 65, 67, 68, 70, 73, 76], "interfac": [35, 36, 61, 64, 66, 73], "intermedi": 48, "intern": [35, 36, 53, 64, 74], "internet": [35, 52, 53], "interpret": [47, 48, 63, 69, 72, 76], "intersect": [69, 75], "interv": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 41, 42, 43, 44, 47, 48, 51, 53, 56, 57, 58, 62, 63, 66, 67, 69, 73, 74, 76], "introduc": [33, 40, 60, 61, 68, 70, 75, 76], "introduct": [33, 34, 36, 40, 51, 53, 57, 64, 65, 69], "intrument": 58, "inuidur1": [36, 37, 61, 73], "inuidur1femaleblackothracedep1dep2q2q3q4q5q6agelt35agegt54durablelusdhusdtg": [36, 61, 73], "inuidur2": [37, 61, 73], "inv_sigmoid": 54, "invalid": [33, 40, 60], "invari": 65, "invers": [2, 7, 8, 9, 12, 13, 58, 69], "invert_yaxi": 51, "investig": 46, "involv": [63, 64, 67, 76], "io": [54, 75], "ipw_norm": 75, "ipykernel_12219": 48, "ipynb": [32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58], "ira": [35, 52, 53], "irm": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 21, 27, 28, 50, 59, 62, 64, 71, 75, 76], "irm_summari": 52, "irmglmnet": 35, "irmrang": 35, "irmrpart": 35, "irmxgboost8047": 35, "is_classifi": [4, 5, 7, 8, 11], "is_gat": [1, 8, 11], "isnan": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 64], "issn": 46, "issu": [52, 71, 74, 75], "ite": [47, 48, 49], "item": [7, 52, 59, 64, 66], "iter": [32, 44, 51, 58, 64, 68, 70, 76], "itertool": 46, "its": [29, 30, 59, 63, 64, 65, 66, 67, 68], "iv": [7, 10, 11, 20, 22, 23, 33, 34, 40, 51, 60, 61, 62, 69, 71, 75, 76], "iv_2": 32, "iv_var": [34, 51], "iv\u00e1n": [66, 74], "j": [14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 33, 34, 36, 40, 46, 51, 54, 58, 60, 64, 68, 70, 71, 73], "j_": [34, 51], "j_0": 68, "j_1": [34, 51], "j_2": [34, 51], "j_3": [34, 51], "j_k": [34, 51], "jame": 74, "janni": [35, 52], "javanmard": 74, "jbe": [34, 51], "jeconom": [16, 17, 18], "jerzi": 74, "jmlr": [36, 71, 73, 75], "job": [35, 52, 53], "joint": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 41, 42, 43, 47, 48, 53, 56, 65, 68, 75, 76], "jointli": [56, 63], "joss": [36, 64, 71, 73], "journal": [14, 15, 16, 17, 18, 23, 24, 26, 34, 36, 46, 51, 54, 60, 64, 71, 73, 74, 75], "jss": 71, "jump": 55, "jun": 74, "jupyt": [32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58], "juraj": 74, "just": [36, 43, 44, 45, 47, 48, 49, 55, 56, 67, 69], "justif": [66, 69], "k": [14, 17, 18, 20, 21, 22, 23, 24, 26, 33, 34, 36, 40, 50, 51, 59, 60, 62, 63, 68, 70, 76], "kaggl": [35, 52], "kallu": [43, 53, 56, 57, 67, 74], "kato": [23, 34, 51, 68, 70, 74], "kb": [44, 49, 51, 52, 53, 57, 61, 73], "kde": [9, 12, 13, 52], "kdeplot": [44, 50, 58], "kdeunivari": [9, 12, 13], "kecsk\u00e9sov\u00e1": 75, "keep": [48, 76], "kei": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 41, 42, 47, 48, 51, 52, 53, 64, 67, 69, 75], "keith": 74, "kengo": 74, "kernel": [9, 12, 13], "keyword": [18, 23, 24, 25], "kf": 66, "kfold": [51, 66], "kind": [32, 39, 52], "kj": [17, 18, 20, 21, 22, 23, 24, 26, 33, 34, 40, 51, 60], "klaassen": [20, 71, 74], "klaa\u00dfen": 20, "knau": 74, "know": [44, 55], "knowledg": [32, 39, 50, 54, 55], "known": [49, 50, 64], "kohei": 74, "kotthof": 36, "kotthoff": [36, 64, 71, 73], "krueger": 54, "kueck": [35, 52], "kurz": [71, 74, 75], "kwarg": [17, 18, 23, 24, 25, 29], "l": [34, 36, 37, 41, 42, 51, 58, 64, 69, 71, 73], "l1": [52, 58, 65], "l_hat": [10, 11, 33, 40, 67], "label": [40, 41, 42, 43, 45, 47, 48, 53, 54, 56], "labor": 54, "laffer": 74, "laff\u00e9r": [26, 58, 65, 67], "lal": [54, 75], "lambda": [34, 35, 36, 52, 54, 55, 64, 67, 68, 70, 73], "lambda_": 46, "lambda_0": 67, "lambda_t": 18, "land": 55, "lang": [36, 64, 71, 73], "langl": [19, 55], "lappli": 66, "larg": [33, 40, 49, 50, 54], "larger": [8, 69], "largest": 50, "largli": 50, "lasso": [34, 35, 36, 52, 58, 64, 73, 74], "lasso_class": [35, 52], "lasso_pip": [36, 64], "lasso_summari": 52, "lassocv": [46, 51, 52, 58, 64, 65, 68, 70, 73], "last": [18, 36, 72], "late": [7, 32, 35, 52, 65, 67], "latent": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 57, 69], "later": [35, 36, 64, 76], "layout": 46, "lbrace": [7, 8, 20, 21, 26, 34, 51, 59, 65, 66, 68, 70], "ldot": [10, 11, 34, 51, 58, 59, 65, 66, 68, 70, 73], "le": [18, 44, 55, 63, 65, 67], "leadsto": 68, "lear": [36, 64, 71, 73], "learn": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 23, 24, 25, 26, 32, 35, 36, 37, 39, 43, 46, 50, 52, 53, 54, 56, 61, 62, 64, 66, 67, 68, 69, 70, 75, 76], "learner": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 40, 41, 42, 44, 46, 51, 52, 53, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 70, 75, 76], "learner_class": 75, "learner_cv": 36, "learner_forest_classif": 36, "learner_forest_regr": 36, "learner_l": 57, "learner_lasso": 36, "learner_list": 50, "learner_m": 57, "learner_nam": [2, 4, 5, 7, 8, 9, 10, 11, 12, 64], "learner_param_v": 36, "learner_rf": 68, "learnerclassif": 36, "learnerregr": 36, "learnerregrcvglmnet": 36, "learnerregrrang": [36, 64], "learning_r": [40, 43, 53, 56, 60], "least": [32, 35, 39, 52, 53, 57, 66], "leav": 58, "left": [20, 21, 22, 23, 26, 33, 34, 40, 50, 51, 52, 53, 54, 56, 60, 67, 68, 69, 70], "legend": [35, 40, 41, 42, 43, 45, 47, 48, 50, 53, 54, 56], "len": [43, 50, 51, 53, 56], "length": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 36, 44, 64], "leq": [34, 51], "less": [35, 52, 53], "lester": 74, "let": [16, 17, 18, 33, 35, 36, 40, 43, 44, 47, 48, 50, 52, 53, 56, 58, 59, 60, 64, 65, 69, 76], "level": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 56, 57, 58, 64, 69, 76], "level_0": [36, 51], "level_1": 51, "levinsohn": [34, 51], "lewi": 74, "lgbmclassifi": [43, 44, 45, 50, 53, 56], "lgbmregressor": [40, 43, 44, 45, 50, 53, 60], "lgr": [33, 34, 35, 36, 59, 64, 65, 66, 67, 68, 70, 73], "lib": 51, "liblinear": [52, 58, 65], "librari": [32, 33, 34, 35, 36, 59, 60, 61, 64, 65, 66, 67, 68, 70, 72, 73, 76], "licens": 75, "lie": 74, "lightgbm": [40, 43, 44, 45, 50, 53, 56], "like": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 36, 46, 48, 52, 53, 64, 66, 73, 76], "lim": 54, "limegreen": [41, 42], "limit": [54, 74], "limits_": 63, "line": [2, 4, 5, 7, 8, 9, 10, 11, 12, 45], "linear": [1, 8, 10, 11, 17, 22, 23, 24, 25, 27, 28, 32, 33, 34, 36, 39, 40, 41, 42, 44, 45, 46, 47, 50, 51, 57, 59, 60, 62, 63, 64, 66, 68, 70, 71, 73, 74, 75, 76], "linear_model": [37, 39, 46, 50, 51, 52, 58, 64, 65, 68, 70, 73], "linearregress": [32, 39, 50], "linearscoremixin": 67, "linestyl": 45, "linewidth": 45, "link": 75, "linspac": [41, 42], "lint": 75, "linux": 72, "list": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 33, 34, 35, 36, 40, 41, 42, 51, 53, 55, 60, 64, 66, 67, 72, 75], "listedcolormap": 51, "literatur": 65, "littl": 49, "ll": [36, 68, 70, 76], "lllllllllllllllll": [61, 73], "lm": 32, "ln_alpha_ml_l": 46, "ln_alpha_ml_m": 46, "load": [32, 35, 36, 46, 52, 53, 61, 72, 73], "loc": [40, 43, 45, 46, 48, 51, 54, 56, 57], "local": [7, 9, 63, 65, 74, 75], "localconvert": 51, "locat": [43, 56], "log": [34, 46, 51, 54], "log_odd": 55, "log_p": [34, 51], "log_reg": 32, "logarithm": 46, "logic": [7, 36, 64], "logical_not": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 64], "logist": [32, 35, 39, 52, 58, 76], "logisticregress": [32, 37, 39], "logisticregressioncv": [50, 52, 58, 65], "logit": [50, 54], "loglik": [36, 64], "logloss": [35, 52, 76], "logo": 75, "logspac": 52, "long": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 33, 40, 50, 57, 69, 74], "look": [35, 36, 43, 44, 45, 50, 52, 53, 56, 57], "loss": 50, "low": [45, 49, 63, 74], "lower": [35, 36, 43, 45, 46, 49, 53, 54, 56, 57, 64, 69, 76], "lower_bound": [41, 42], "lpq": [9, 13, 53, 63, 75], "lpq_0": 56, "lpq_1": 56, "lqte": 63, "lrn": [32, 33, 34, 35, 36, 59, 64, 65, 66, 67, 68, 70, 73, 76], "lrn_0": 36, "lt": [32, 34, 35, 36, 37, 44, 49, 51, 52, 53, 55, 57, 58, 61, 73], "lucien": 75, "luka": 74, "luk\u00e1\u0161": 26, "lusd": [36, 37, 61, 73], "lvert": 46, "m": [14, 15, 16, 22, 23, 24, 33, 34, 36, 37, 40, 46, 49, 51, 54, 60, 62, 63, 64, 67, 69, 71, 72, 73, 74, 75], "m_": [67, 68, 70], "m_0": [2, 4, 5, 7, 8, 10, 11, 12, 24, 25, 33, 34, 35, 40, 46, 49, 51, 52, 60, 63, 64, 65, 67, 73, 76], "m_hat": [7, 8, 10, 11, 33, 40, 67], "ma": [23, 34, 51, 74], "mac": 72, "machin": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 23, 24, 25, 26, 32, 35, 36, 37, 39, 43, 44, 46, 52, 53, 54, 56, 57, 58, 62, 64, 65, 66, 67, 68, 69, 70, 75, 76], "machineri": [46, 74], "mackei": 74, "maco": 72, "made": [65, 76], "mae": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 64], "maggi": 74, "magnitud": 69, "mai": [44, 58], "main": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 46, 53, 68, 69, 70, 74, 76], "maintain": [71, 75], "mainten": 75, "major": [36, 75], "make": [32, 39, 50, 63, 64, 75, 76], "make_confounded_plr_data": 57, "make_did_sz2020": [4, 5, 44, 65], "make_heterogeneous_data": [41, 42, 47, 48, 49], "make_iivm_data": [7, 9, 63, 65], "make_irm_data": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 50, 63, 64, 65], "make_pipelin": 52, "make_pliv_chs2015": [10, 65], "make_pliv_multiway_cluster_ckms2021": [3, 34, 51], "make_plr_ccddhnr2018": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 33, 40, 59, 60, 63, 64, 65, 66, 67, 68, 69], "make_spd_matrix": 25, "make_ssm_data": [58, 65], "malt": [71, 74], "maltekurz": 71, "man": [32, 39], "manag": [64, 72], "mani": [22, 27, 28, 33, 34, 36, 40, 44, 51, 60, 67, 68, 70, 76], "manili": 1, "manipul": [35, 36], "manual": [35, 57, 76], "mao": 74, "map": [7, 29, 30, 34, 51, 63, 65], "mapsto": [59, 63], "mar": [26, 65], "margin": [41, 42], "marit": [35, 52], "markers": 54, "market": 54, "markettwo": 34, "markov": [25, 74], "marr": [35, 52, 53, 57, 76], "marshal": 64, "martin": [26, 71, 74, 75], "masatoshi": 74, "mat": 34, "match": [64, 69], "math": 49, "mathbb": [7, 8, 10, 11, 16, 17, 18, 27, 28, 34, 44, 45, 49, 50, 51, 54, 58, 63, 65, 67, 68, 69, 70, 73, 76], "mathcal": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 40, 43, 45, 51, 55, 56, 58, 60], "mathop": 63, "mathrm": [16, 17], "matplotlib": [37, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 56, 58], "matric": [55, 62, 75], "matrix": [16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 33, 34, 35, 36, 40, 51, 58, 60, 61, 64, 68, 70, 73, 75, 76], "matt": 74, "matter": [50, 54], "max": [35, 36, 52, 53, 59, 63, 64, 65, 66, 67, 68, 73, 76], "max_depth": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 37, 40, 52, 57, 59, 63, 64, 65, 66, 67, 68, 69, 73, 76], "max_featur": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 37, 40, 52, 57, 59, 63, 64, 65, 66, 67, 68, 69, 73, 76], "max_it": [51, 52], "maxim": [2, 4, 5, 7, 8, 9, 10, 11, 12, 55, 63], "maxima": [68, 70], "maximum": [63, 64], "mb": [37, 58, 61, 73], "mb706": 75, "mea": 20, "mean": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 39, 40, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 56, 57, 60, 64, 68, 76], "mean_absolute_error": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 64], "meant": [63, 75], "measir": 57, "measur": [36, 46, 57, 64, 65, 69], "measure_col": 46, "mechan": [29, 30], "median": 66, "melt": 34, "memori": [37, 44, 49, 51, 52, 53, 57, 58, 61, 73], "mention": [49, 63], "merg": [35, 52], "mert": [66, 74], "meshgrid": [41, 42], "messag": [33, 34, 35, 36, 73, 75], "meta": [64, 73], "metadata": [29, 30], "metadatarequest": [29, 30], "method": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 47, 48, 50, 51, 52, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75], "methodolog": 74, "metric": [2, 4, 5, 7, 8, 9, 10, 11, 12, 64], "michael": 74, "michaela": 75, "michel": [71, 73], "michela": [26, 74], "mid": [35, 52, 54], "might": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 43, 50, 51, 55, 57, 64], "mild": [33, 40, 60], "militari": 54, "miller": [34, 51], "min": [34, 35, 36, 43, 51, 52, 53, 56, 59, 64, 65, 66, 67, 68, 70, 73, 76], "min_": 63, "min_samples_leaf": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 40, 49, 52, 57, 59, 63, 64, 65, 66, 67, 68, 69, 76], "min_samples_split": 52, "minim": [8, 35, 50, 52], "minor": [33, 40, 60, 67, 75], "minsplit": 35, "miruna": 74, "mislead": 75, "miss": [3, 6, 36, 64, 65, 67, 75], "missing": [26, 58], "misspecif": 44, "misspecifi": 44, "mit": [71, 73], "mixin": [27, 28, 67], "ml": [25, 34, 35, 36, 46, 51, 52, 59, 62, 64, 66, 71, 74, 75], "ml_g": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 35, 37, 39, 40, 41, 43, 44, 45, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 60, 63, 64, 65, 75], "ml_g0": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 37, 44, 50, 52, 57, 64, 65], "ml_g1": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 37, 44, 50, 52, 57, 64, 65], "ml_g_d0": [58, 65], "ml_g_d0_t0": [44, 65], "ml_g_d0_t1": [44, 65], "ml_g_d1": [58, 65], "ml_g_d1_t0": [44, 65], "ml_g_d1_t1": [44, 65], "ml_l": [10, 11, 33, 34, 35, 36, 37, 40, 42, 48, 51, 52, 54, 57, 59, 60, 64, 65, 66, 67, 68, 69, 70, 73, 75, 76], "ml_l_bonu": 73, "ml_l_forest": 36, "ml_l_forest_pip": 36, "ml_l_lasso": 36, "ml_l_lasso_pip": 36, "ml_l_rf": 76, "ml_l_sim": 73, "ml_l_tune": 64, "ml_l_xgb": 76, "ml_m": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 67, 68, 69, 70, 73, 75, 76], "ml_m_bonu": 73, "ml_m_forest": 36, "ml_m_forest_pip": 36, "ml_m_lasso": 36, "ml_m_lasso_pip": 36, "ml_m_rf": 76, "ml_m_sim": 73, "ml_m_tune": 64, "ml_m_xgb": 76, "ml_pi": [58, 65], "ml_r": [7, 10, 32, 34, 35, 39, 51, 52, 65, 75], "ml_r0": 65, "ml_r1": [35, 52, 65], "mlr": [36, 64], "mlr3": [32, 33, 34, 35, 59, 64, 65, 66, 67, 68, 70, 71, 73, 75, 76], "mlr3book": [36, 64], "mlr3extralearn": [35, 64], "mlr3filter": 36, "mlr3learner": [32, 33, 34, 35, 59, 64, 65, 66, 67, 68, 70, 73, 76], "mlr3pipelin": [64, 75], "mlr3tune": [36, 64, 75], "mlr3vers": 35, "mode": 72, "model": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 36, 39, 40, 43, 44, 45, 46, 49, 50, 51, 53, 56, 57, 59, 60, 61, 62, 64, 70, 71, 74, 75], "model_data": [35, 52], "model_select": [2, 4, 5, 7, 8, 9, 10, 11, 12, 40, 51, 64, 66], "modelmlestimatelowerupp": 35, "modern": [36, 64, 71, 73], "moment": [27, 28, 34, 51, 67, 68, 69, 70, 73], "monoton": 65, "mont": [16, 17, 19, 41, 42, 47, 48], "montanari": 74, "more": [8, 32, 35, 39, 41, 42, 46, 50, 52, 53, 57, 59, 63, 64, 65, 67, 68, 69, 73, 76], "moreov": [35, 36, 46, 64, 68, 70, 76], "mortgag": [35, 52, 53], "most": [35, 43, 50, 52, 53, 56, 63, 64, 69, 72], "motiv": 60, "motivation_example_bch": 46, "mpd": [34, 51], "mpg": 51, "mse": [36, 46, 64], "msr": [36, 64], "mtry": [35, 36, 59, 64, 65, 66, 67, 68, 76], "mu": 45, "mu_": 45, "mu_mean": 45, "much": [35, 36, 52, 76], "muld": [37, 61, 73], "multi": [34, 41, 42, 51], "multiclass": 36, "multiindex": 51, "multipl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 34, 35, 44, 51, 52, 57, 58, 61, 64, 65, 66, 68, 69, 70, 75, 76], "multipletest": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "multipli": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 40, 62, 63, 67, 76], "multiprocess": [43, 53, 56], "multitest": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "multiwai": [23, 34, 51, 74], "music": 74, "must": [2, 4, 5, 7, 8, 9, 10, 11, 12, 64, 65], "mutat": 36, "mutual": [8, 11, 35, 47, 48, 52, 53, 63], "my_sampl": 66, "my_task": 66, "n": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 36, 39, 40, 43, 45, 46, 49, 51, 54, 55, 56, 58, 59, 60, 63, 64, 66, 68, 70, 71, 72], "n_": 45, "n_coef": [2, 4, 5, 7, 8, 9, 10, 11, 12, 69], "n_complier": 56, "n_core": [43, 53, 56], "n_estim": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 52, 53, 55, 56, 57, 59, 60, 63, 64, 65, 66, 67, 68, 69, 73, 76], "n_eval": [36, 64], "n_fold": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 34, 35, 37, 40, 41, 42, 43, 44, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 60, 64, 66, 73, 76], "n_folds_per_clust": [34, 51], "n_folds_tun": [2, 4, 5, 7, 8, 9, 10, 11, 12], "n_iter_randomized_search": [2, 4, 5, 7, 8, 9, 10, 11, 12, 64], "n_job": 52, "n_jobs_cv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 50], "n_jobs_model": [13, 43, 53, 56], "n_ob": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 33, 36, 40, 41, 42, 44, 45, 47, 48, 49, 50, 57, 58, 60, 61, 63, 64, 65, 66, 68, 69, 70, 73], "n_rep": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 34, 37, 40, 44, 49, 50, 51, 57, 58, 60, 64, 66, 69, 73, 76], "n_rep_boot": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 41, 42, 43, 47, 48, 53, 56, 68, 70], "n_sampl": 55, "n_split": 66, "n_t": 45, "n_time_period": 45, "n_true": [43, 56], "n_var": [33, 36, 40, 60, 61, 64, 68, 70, 73], "n_w": 55, "n_x": [19, 41, 42, 47, 48, 49], "na": [3, 6, 33, 34, 60, 75], "na_real_": [34, 75], "naiv": [33, 40, 60], "name": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 33, 34, 47, 48, 49, 51, 57, 64, 72, 75], "nan": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 40, 43, 44, 45, 47, 48, 50, 52, 53, 56, 58, 60, 64], "nanmean": 40, "narita": 74, "nathan": 74, "nation": [66, 74], "natt": 55, "nbsphinx": 49, "ncol": [34, 35, 36, 61, 64, 68, 70, 73], "ncoverag": 50, "ndarrai": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 20, 21, 22, 23, 24, 25, 26, 61], "nearli": 50, "necess": [34, 51], "necessari": [34, 51], "need": [2, 4, 5, 7, 8, 9, 10, 11, 12, 28, 32, 33, 35, 39, 40, 53, 58, 64, 66, 69, 75, 76], "neighborhood": 68, "neither": [3, 6, 34, 51, 61], "neng": 74, "neq": 65, "nest": [2, 4, 5, 7, 8, 9, 10, 11, 12, 64, 67, 69], "net": [53, 57, 76], "net_tfa": [35, 52, 53, 57, 76], "never": [7, 34, 48, 51, 75], "never_tak": [7, 35, 52], "new": [32, 33, 34, 35, 36, 41, 42, 52, 55, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 73, 74, 75, 76], "new_data": [41, 42, 55], "newei": [14, 15, 24, 34, 46, 51, 60, 71, 74], "newest": 75, "next": [35, 36, 41, 42, 43, 49, 50, 52, 53, 55, 56, 75], "neyman": [34, 51, 59, 62, 69, 71, 74], "nfold": [34, 35], "nifa": [52, 53, 57], "nine": [34, 51], "node": [35, 36, 59, 65, 66, 67, 68, 73, 76], "nois": [54, 55], "non": [18, 23, 24, 25, 32, 33, 35, 39, 40, 45, 52, 53, 55, 64, 66, 67, 68], "non_orth_scor": [33, 40, 67], "nondur": 37, "none": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 34, 35, 37, 39, 44, 49, 52, 53, 57, 58, 61, 64, 65, 67, 68, 72, 73], "nonlinear": [28, 35, 52, 67, 75], "nonlinearscoremixin": 67, "nonparametr": [9, 12, 13, 69, 74], "nop": 36, "nor": [3, 6, 34, 51, 61], "norm": 40, "normal": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 33, 39, 40, 43, 44, 45, 49, 53, 54, 55, 56, 58, 60, 61, 64, 67, 68, 70, 73], "normalize_ipw": [2, 7, 8, 9, 12, 13, 53, 58], "notat": [34, 44, 51, 58, 65], "note": [3, 6, 7, 8, 10, 11, 27, 28, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 66, 67, 71, 73], "notebook": [32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 63, 64, 76], "notic": [32, 39], "now": [34, 35, 41, 42, 50, 51, 52, 55, 58, 73, 75], "np": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 20, 21, 22, 23, 24, 25, 26, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 76], "nround": [33, 35, 76], "nrow": [34, 36, 61, 64, 68, 70, 73], "nu": [7, 18, 25, 58, 65, 69], "nu2": 69, "nu_0": 69, "nu_i": 58, "nuis_g0": 32, "nuis_g1": 32, "nuis_l": 76, "nuis_m": [32, 76], "nuis_r0": 32, "nuis_r1": 32, "nuis_rmse_ml_l": 46, "nuis_rmse_ml_m": 46, "nuisanc": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 24, 25, 33, 34, 35, 36, 40, 41, 42, 43, 44, 46, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 64, 66, 67, 68, 69, 71, 75, 76], "nuisance_el": 69, "nuisance_target": 50, "null": [2, 4, 5, 7, 8, 9, 10, 11, 12, 57, 69, 75], "null_hypothesi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 57, 69], "num": [35, 36, 59, 64, 65, 66, 67, 68, 73], "num_leav": [43, 45, 53, 56], "number": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 53, 55, 56, 66, 68, 70, 71, 73, 76], "numer": [28, 32, 36, 54, 64, 67, 69, 75], "numeric_onli": 46, "numpi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73], "ny": 74, "o": [45, 47, 48, 52, 54, 68, 71, 73], "ob": [35, 45], "obei": 67, "obj_dml_data": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 39, 40, 43, 51, 56, 59, 60, 63, 64, 65, 66, 67, 68, 69, 75], "obj_dml_data_bonu": 61, "obj_dml_data_bonus_df": 61, "obj_dml_data_from_arrai": [3, 6], "obj_dml_data_from_df": [3, 6], "obj_dml_data_sim": 61, "obj_dml_plr": [33, 40, 60], "obj_dml_plr_bonu": [36, 73], "obj_dml_plr_bonus_pip": 36, "obj_dml_plr_bonus_pipe2": 36, "obj_dml_plr_bonus_pipe3": 36, "obj_dml_plr_bonus_pipe_ensembl": 36, "obj_dml_plr_nonorth": [33, 40], "obj_dml_plr_orth_nosplit": [33, 40], "obj_dml_plr_sim": [36, 73], "obj_dml_plr_sim_pip": 36, "obj_dml_plr_sim_pipe_ensembl": 36, "obj_dml_plr_sim_pipe_tun": 36, "object": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30, 32, 35, 36, 37, 41, 42, 43, 44, 48, 49, 52, 53, 56, 58, 61, 63, 64, 65, 66, 67, 68, 71, 73, 74, 75, 76], "obs_confound": [32, 39], "observ": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 73, 74, 76], "obtain": [16, 17, 32, 33, 34, 39, 40, 41, 42, 43, 44, 46, 50, 51, 56, 58, 59, 60, 63, 64, 66, 67, 68, 69, 70, 72, 73], "occur": 75, "off": [55, 74], "offer": [35, 52, 53, 76], "offici": 72, "often": 56, "oka": 74, "omega": [49, 63, 69], "omega_": [23, 34, 51], "omega_1": [23, 34, 51], "omega_2": [23, 34, 51], "omega_epsilon": [34, 51], "omega_v": [23, 34, 51], "omega_x": [23, 34, 51], "omit": [57, 69, 74, 75, 76], "onc": 76, "one": [10, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 50, 51, 53, 54, 57, 60, 63, 64, 65, 66, 67, 68, 69, 70, 73, 75], "ones": [36, 43, 45, 56, 57, 63], "ones_lik": 56, "onli": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 34, 35, 41, 42, 47, 48, 49, 50, 51, 52, 53, 59, 63, 64, 65, 67, 68, 69, 75], "onlin": 76, "onto": 50, "oob_error": [36, 64], "oop": 75, "opac": [41, 42], "open": [36, 64, 71, 73], "oper": 36, "opposit": 55, "oprescu": [19, 41, 42, 47, 48, 74], "optim": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 41, 42, 55, 63, 64, 74], "option": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 33, 34, 35, 41, 42, 47, 48, 49, 50, 51, 52, 53, 58, 64, 66, 67, 68, 70, 75], "oracle_valu": [16, 17], "orang": 33, "orcal": [16, 17], "order": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 36, 51, 52, 64, 66, 67], "org": [20, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 64, 71, 72, 75], "orient": [36, 64, 67, 71, 73, 74, 75], "origin": [36, 48, 55, 57, 63], "orign": [35, 52], "orth_sign": 1, "orthogon": [1, 34, 35, 51, 52, 59, 62, 68, 69, 70, 71, 74], "orthongon": 69, "osx": 72, "other": [3, 6, 10, 11, 33, 34, 35, 36, 40, 44, 50, 51, 52, 53, 54, 56, 57, 58, 60, 61, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76], "other_ind": 51, "otherwis": [4, 5, 7, 8, 11, 35, 52, 53, 55, 65], "othrac": [36, 37, 61, 73], "our": [33, 35, 36, 40, 41, 42, 43, 44, 50, 52, 53, 56, 57, 60, 71, 73, 75, 76], "ourselv": 50, "out": [10, 11, 34, 36, 37, 44, 46, 50, 51, 53, 57, 58, 59, 61, 62, 63, 64, 65, 67, 68, 69, 71, 73, 75, 76], "outcom": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 18, 32, 34, 35, 36, 37, 39, 45, 46, 49, 51, 52, 53, 54, 55, 56, 57, 61, 64, 65, 67, 68, 69, 73, 75, 76], "outcome_0": 39, "outcome_1": 39, "outer": [2, 4, 5, 7, 8, 9, 10, 11, 12, 64], "output": [50, 59, 68, 70, 76], "outshr": 51, "outsid": 33, "over": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 40, 46, 50, 60, 62, 64, 69, 70], "overal": 55, "overcom": [62, 67], "overfit": [62, 66], "overlap": [44, 65], "overrid": [64, 75], "overst": [35, 52, 53], "overview": [50, 68, 69, 74], "overwrit": 75, "ownership": [35, 52], "p": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 21, 33, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75], "p401": [35, 52, 53], "p_0": 67, "p_1": [68, 70], "p_adjust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 66, 68, 70, 71, 73], "p_dbl": [36, 64], "p_int": 64, "p_n": 22, "p_val": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "p_x": [23, 34, 51], "p_x0": 54, "p_x1": 54, "packag": [32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 53, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 67, 68, 69, 71, 73, 74, 75, 76], "packagedata": 51, "packagevers": 35, "page": [71, 74], "pair": [32, 39], "pake": [34, 51], "paket": [34, 35, 36], "pal": 34, "panda": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 61, 63, 69, 73], "pandas2ri": 51, "panel": [4, 18, 74, 75], "paper": [20, 22, 36, 54, 57, 69, 71, 73, 74, 75], "par": 37, "par_grid": [36, 64], "paradox": [36, 64, 75], "parallel": [43, 44, 45, 50, 56, 65], "param": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 64], "param_grid": [2, 4, 5, 7, 8, 9, 10, 11, 12, 64], "param_set": [36, 64], "param_v": 36, "paramet": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 40, 41, 42, 43, 44, 46, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76], "parametr": [60, 64, 76], "params_exact": 64, "params_nam": [2, 4, 5, 7, 8, 9, 10, 11, 12], "parenttoc": 71, "part": [25, 33, 34, 35, 36, 40, 50, 51, 52, 60, 64, 66, 69, 75, 76], "parti": 25, "partial": [10, 11, 17, 22, 23, 24, 25, 28, 34, 36, 37, 46, 51, 57, 59, 62, 64, 66, 68, 70, 71, 73, 75, 76], "partial_": [67, 68], "partiallli": 57, "particip": [14, 53, 57, 76], "particular": 71, "partion": [34, 51], "partit": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 51, 59, 62], "partli": 76, "pass": [1, 36, 64, 76], "passo": [71, 73], "past": 34, "paste0": 34, "pastel": 40, "path": [64, 65], "path_to_r": 46, "patsi": [41, 42, 63], "paul": 74, "pd": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 63], "pdf": [40, 54], "pedregosa": [71, 73], "pedregosa11a": [71, 73], "pedro": 74, "penal": 58, "penalti": [35, 36, 39, 52, 58, 64, 65], "pennsylvania": [15, 61, 73], "pension": [35, 52, 53, 76], "peopl": [35, 52, 53], "pep8": 75, "per": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 51], "percent": 64, "percentag": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17], "perf_count": 50, "perform": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 34, 36, 40, 44, 46, 48, 49, 50, 51, 53, 57, 58, 60, 64, 65, 66, 67, 68, 70, 71, 73, 74, 76], "perfrom": 49, "perhap": 76, "period": [4, 44, 45, 65], "perp": 65, "perrot": [71, 73], "person": 76, "peter": 74, "pfister": [36, 64, 71, 73], "phi": [34, 51, 63, 68], "philipp": [71, 74], "philippbach": [71, 75], "pi": [21, 22, 25, 63, 65, 67], "pi_": [23, 34, 51], "pi_0": 67, "pi_i": [58, 65], "pick": 76, "pip3": 72, "pipe": 36, "pipe_forest_classif": 36, "pipe_forest_regr": 36, "pipe_lasso": 36, "pipelin": [36, 52, 75], "pipeop": 36, "pira": [35, 52, 53, 57, 76], "pivot": [46, 51, 74], "plai": 76, "plan": [14, 35, 52, 53, 76], "pleas": [29, 30, 66], "plim": 54, "pliv": [10, 27, 28, 34, 51, 59, 62, 63, 71, 75], "plm": [64, 68, 69, 76], "plot": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 35, 36, 40, 41, 42, 43, 45, 46, 47, 48, 49, 52, 53, 54, 56, 57, 58, 63, 69], "plot_tre": [55, 63], "plotli": [2, 4, 5, 7, 8, 9, 10, 11, 12, 41, 42, 46], "plr": [11, 27, 28, 36, 54, 57, 59, 62, 64, 66, 68, 70, 71, 73, 75, 76], "plr_est": 54, "plr_est1": 54, "plr_est2": 54, "plr_obj": 54, "plr_obj_1": 54, "plr_obj_2": 54, "plr_summari": 52, "plrglmnet": 35, "plrranger": 35, "plrrpart": 35, "plrxgboost8700": 35, "plt": [37, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 56, 58], "plt_smpl": [34, 51], "plt_smpls_cluster": [34, 51], "plug": [49, 69], "pm": [34, 51, 68, 69, 70], "pmatrix": 58, "po": [36, 64], "point": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 47, 48, 51, 63, 76], "pointwis": [1, 43, 47, 48, 56], "poli": [35, 51, 52], "polici": [8, 10, 11, 62, 65, 73, 74, 75], "policy_tre": [8, 55, 63], "policy_tree_2": 55, "policy_tree_obj": 63, "policytre": 55, "polit": 54, "poly_dict": 52, "polynomi": [14, 15, 35, 37, 52], "polynomial_featur": [14, 15, 35, 37], "polynomialfeatur": [51, 52], "popul": 67, "popular": [50, 69], "porport": 57, "posit": [25, 35, 54, 76], "posixct": [36, 64], "possibl": [3, 6, 36, 41, 42, 47, 48, 49, 50, 55, 57, 64, 68, 69, 75, 76], "possibli": 69, "post": [22, 25, 65, 68, 70, 74], "postdoubl": 74, "poster": 54, "potenti": [2, 9, 12, 16, 44, 54, 58, 65, 68, 72, 75, 76], "power": [36, 64, 74], "pq": [9, 12, 13, 53, 75], "pq_0": [53, 56], "pq_1": [53, 56], "pr": [32, 34, 35, 36, 64, 65, 66, 67, 68, 73, 76], "practic": [50, 74], "pre": [44, 58, 64, 65], "precis": [69, 76], "pred_df": 55, "pred_dict": 64, "pred_treat": 55, "predict": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 29, 30, 33, 34, 35, 36, 40, 43, 46, 50, 51, 52, 55, 60, 63, 66, 69, 75, 76], "predict_proba": [2, 4, 5, 7, 8, 9, 11, 12, 13, 29, 64], "predictor": [1, 8, 11, 41, 42, 47, 48, 59], "prefer": [35, 52, 53, 76], "preliminari": [2, 33, 40, 67], "prepar": [34, 51, 75], "preprint": 74, "preprocess": [35, 51, 52, 53, 64], "presenc": [35, 52, 53], "present": [64, 76], "prespecifi": 57, "pretreat": [4, 5, 44], "prettenhof": [71, 73], "prevent": [66, 75], "previou": [45, 49, 54, 72, 76], "previous": [64, 76], "price": [34, 51], "priliminari": [9, 13], "principl": 69, "print": [33, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76], "prior": [50, 65], "privat": 75, "prob": 36, "probabilit": 49, "probabl": [2, 7, 8, 9, 12, 13, 18, 33, 40, 44, 49, 54, 56, 58, 60, 65, 67, 74], "problem": [35, 52, 53, 63, 64], "procedur": [33, 34, 35, 40, 50, 51, 52, 57, 64, 68, 70, 75], "proceed": [22, 74], "process": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 41, 42, 43, 44, 45, 46, 47, 48, 50, 55, 56, 58, 62, 68, 69, 70, 74], "produc": 54, "product": [41, 42, 46, 50, 69], "producton": 34, "program": [21, 35, 52, 53, 74, 76], "progress": 38, "project": [36, 41, 42, 63, 71, 75], "project_z": [41, 42], "prone": 67, "propens": [9, 13, 16, 17, 35, 44, 49, 50, 52, 53, 58, 63], "properli": 76, "properti": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 36, 50, 52, 53, 54, 57, 64, 69, 73], "proport": [57, 69], "propos": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 36, 51, 69, 74], "provid": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 41, 42, 47, 48, 51, 52, 59, 60, 61, 62, 64, 68, 70, 71, 73, 75, 76], "prune": 8, "ps911c": 51, "ps944": 51, "pscore1": 54, "pscore2": 54, "psi": [27, 28, 33, 34, 51, 59, 67, 68, 69, 73], "psi_": [68, 69, 70], "psi_a": [7, 8, 10, 11, 27, 33, 34, 40, 51, 66, 67, 68], "psi_b": [7, 8, 10, 11, 27, 33, 40, 63, 66, 67], "psi_el": [66, 67], "psi_j": [68, 70], "psi_nu2": 69, "psi_sigma2": 69, "public": [32, 39, 75], "publish": 75, "pull": [35, 75], "purp": [41, 42], "purpos": [33, 40, 49, 57, 69, 73], "pval": [68, 70], "px": 46, "py": [48, 51, 71, 72, 75], "py3": 72, "py_al": 40, "py_dml": 40, "py_dml_nosplit": 40, "py_dml_po": 40, "py_dml_po_nosplit": 40, "py_double_ml_bas": 40, "py_double_ml_basic_iv": 39, "py_double_ml_c": 41, "py_double_ml_cate_plr": 42, "py_double_ml_cvar": 43, "py_double_ml_did": 44, "py_double_ml_did_pretest": 45, "py_double_ml_firststag": 46, "py_double_ml_g": 47, "py_double_ml_gate_plr": 48, "py_double_ml_gate_sensit": 49, "py_double_ml_learn": 50, "py_double_ml_multiway_clust": 51, "py_double_ml_pens": 52, "py_double_ml_pension_qt": 53, "py_double_ml_plm_irm_hetfx": 54, "py_double_ml_policy_tre": 55, "py_double_ml_pq": 56, "py_double_ml_sensit": 57, "py_double_ml_ssm": 58, "py_non_orthogon": 40, "py_po_al": 40, "pydata": 48, "pypi": [74, 75], "pyplot": [37, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 56, 58], "python": [25, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76], "python3": 72, "q": [36, 43, 56, 64, 71, 73], "q2": [36, 37, 61, 73], "q3": [36, 37, 61, 73], "q4": [36, 37, 61, 73], "q5": [36, 37, 61, 73], "q6": [36, 37, 61, 73], "qquad": 21, "qte": [43, 53, 75], "quad": [18, 35, 44, 52, 55, 58, 63, 65, 67, 68, 69, 70], "quadrat": 58, "qualiti": [57, 59, 75], "quanitl": 53, "quant": 43, "quantil": [2, 9, 12, 13, 43, 57, 62, 74, 75], "quantiti": [32, 39], "queri": 52, "question": 76, "quick": 53, "quit": [50, 55, 57, 69], "r": [7, 20, 40, 41, 42, 45, 46, 51, 54, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76], "r2_d": [21, 50], "r2_y": [21, 50], "r6": [36, 75], "r_0": [7, 10, 35, 52, 65], "r_all": 33, "r_d": 21, "r_df": 51, "r_dml": 33, "r_dml_nosplit": 33, "r_dml_po": 33, "r_dml_po_nosplit": 33, "r_double_ml_bas": 33, "r_double_ml_basic_iv": 32, "r_double_ml_multiway_clust": 34, "r_double_ml_pens": 35, "r_double_ml_pipelin": 36, "r_hat": 10, "r_hat0": 7, "r_hat1": 7, "r_non_orthogon": 33, "r_po_al": 33, "r_y": 21, "rais": [3, 6, 29, 30, 64], "randint": 54, "random": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 19, 25, 26, 32, 33, 35, 36, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 66, 68, 69, 70, 73, 74, 76], "random_search": 64, "random_st": [40, 49, 55], "randomforest": [35, 50, 52], "randomforest_class": [35, 41, 52, 55], "randomforest_reg": [41, 55], "randomforestclassifi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 37, 41, 42, 47, 48, 49, 50, 52, 55, 57, 63, 64, 65, 76], "randomforestregressor": [2, 4, 5, 7, 8, 9, 10, 11, 12, 37, 40, 41, 42, 47, 48, 49, 50, 52, 55, 57, 59, 63, 64, 65, 66, 67, 68, 69, 73, 76], "randomized_search": [2, 4, 5, 7, 8, 9, 10, 11, 12, 64], "randomizedsearchcv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 64], "randomli": [33, 34, 40, 51, 60, 66, 76], "rang": [33, 40, 43, 44, 45, 47, 48, 50, 51, 53, 55, 56, 58, 60, 64], "rangeindex": [37, 44, 49, 51, 52, 53, 57, 58, 61, 73], "ranger": [35, 36, 59, 64, 65, 66, 67, 68, 73, 76], "rangl": [19, 55], "rank": 75, "rate": [46, 50], "ratio": [64, 66, 69], "ravel": [41, 42], "raw": [35, 46, 52], "raw_res_manual_lasso_r_100_n_100_p_200_rho_0": 46, "rbind": 35, "rbindlist": 35, "rbinom": 32, "rbrace": [7, 8, 20, 21, 26, 34, 51, 59, 65, 66, 68, 70], "rcolorbrew": 34, "rcparam": [37, 41, 42, 43, 45, 47, 48, 51, 52, 53, 56], "rd": 75, "rdbu": 34, "rdbu_r": 51, "rdt044": 46, "re": [51, 72], "read_csv": 46, "readabl": 75, "readili": 71, "real": [35, 52, 53, 57, 69], "realat": 65, "realiz": 65, "reason": [3, 6, 32, 39, 57, 69, 76], "recal": [37, 69], "receiv": 65, "recent": 65, "recogn": [35, 52, 53], "recommend": [36, 50, 59, 66, 72, 74, 75], "recov": [32, 39, 54], "recsi": 74, "red": [34, 47, 48, 51], "reduc": [35, 49, 52, 57, 75], "redund": 75, "reemploy": [15, 61, 73], "refactor": 75, "refer": [2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 35, 45, 49, 52, 53, 57, 61, 62, 63, 65, 69, 74, 75], "refin": 75, "refit": 69, "reflect": [55, 63], "reg": [18, 35, 52, 76], "reg_learn": 53, "reg_learner_1": 50, "reg_learner_2": 50, "regard": 71, "regener": 75, "region": [34, 43, 51, 68, 70, 74], "regr": [32, 33, 34, 35, 36, 59, 64, 65, 66, 67, 68, 70, 73, 76], "regravg": [36, 64], "regress": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 20, 21, 22, 23, 24, 25, 32, 34, 36, 39, 46, 51, 54, 57, 58, 59, 60, 62, 63, 64, 66, 68, 70, 71, 73, 74, 75, 76], "regressor": [30, 33, 35, 40, 43, 52, 60], "regular": [22, 62, 64, 67, 68, 70, 74], "reich": [36, 64], "reinforc": 74, "reject": [35, 52], "rel": [35, 52, 69], "relat": 76, "relationship": [32, 39, 46, 68, 70], "releas": 52, "relev": [1, 3, 4, 5, 6, 19, 43, 55, 56, 69, 76], "reli": [41, 42, 44, 45, 49, 63, 64, 65, 69, 76], "reload": 35, "remain": [68, 70, 76], "remark": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 40, 41, 42, 43, 45, 47, 48, 49, 50, 53, 57, 63, 64, 65, 67, 68, 69], "remot": 72, "remov": [35, 52, 62, 66, 75], "renam": [52, 75], "render": 57, "reorgan": 75, "rep": [33, 60, 64, 68, 70], "repeat": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 33, 34, 35, 36, 40, 49, 51, 52, 53, 54, 57, 58, 60, 62, 64, 68, 73, 75, 76], "repeatedkfold": 51, "repet": 57, "repetit": [1, 41, 42, 46, 47, 48, 49, 50, 62, 64, 68, 73, 76], "repetiton": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "replac": [55, 75], "replic": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 33, 35, 40, 46], "repo": 75, "report": [35, 52, 71, 75], "repositori": [46, 75], "repr": [33, 34], "repres": 54, "represent": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 57, 68, 69, 73, 75], "request": 75, "requir": [10, 11, 32, 35, 36, 49, 52, 53, 57, 65, 68, 69, 70, 72, 75, 76], "res_df": 51, "res_dict": [16, 17, 19], "resampl": [32, 34, 36, 44, 51, 53, 57, 58, 64, 65, 66, 67, 68, 71, 73, 76], "research": [34, 36, 51, 54, 66, 71, 73, 74, 76], "resembl": 58, "reset_index": [46, 51, 52], "reshap": [40, 41, 42, 45], "reshape2": 34, "residu": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 57, 69], "resolut": [36, 64], "resourc": 50, "resourcewis": 50, "respect": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 52, 53, 63, 65, 66, 69, 76], "respons": [14, 36, 64], "restart": 72, "restrict": 50, "restructur": 75, "restud": 46, "result": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 33, 36, 40, 41, 42, 44, 45, 46, 49, 50, 55, 57, 58, 60, 64, 66, 67, 69, 73, 75], "result_iivm": 35, "result_irm": 35, "result_plr": 35, "retina": 54, "retir": [35, 52, 53, 57], "return": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 33, 34, 36, 40, 43, 48, 50, 51, 54, 55, 56, 57, 58, 59, 64, 67, 69, 75], "return_count": 50, "return_tune_r": [2, 4, 5, 7, 8, 9, 10, 11, 12], "return_typ": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 33, 35, 36, 40, 44, 50, 52, 53, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 73, 76], "rev": 34, "reveal": 49, "review": [22, 46, 74], "revist": [34, 51], "rho": [2, 4, 5, 7, 8, 9, 10, 11, 12, 31, 49, 57, 69, 76], "richter": [36, 64, 71, 73], "riesz": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 57, 69], "right": [20, 21, 22, 23, 26, 33, 34, 40, 50, 51, 52, 53, 54, 56, 60, 67, 68, 69, 70], "rightarrow_": [33, 40, 60], "risk": [2, 62, 75], "ritov": 74, "rival": 51, "rival_ind": 51, "rmse": [44, 50, 53, 57, 58, 64, 65, 67, 68, 73, 75], "rmses_ml_g0": 50, "rmses_ml_g1": 50, "rmses_ml_m": 50, "rnorm": [32, 36, 61, 64, 68, 70, 73], "robin": [14, 15, 24, 34, 46, 51, 60, 71, 74], "robinson": [33, 40, 60], "robject": 51, "robu": [47, 48], "robust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 23, 49, 57, 69, 74, 76], "role": [3, 6, 33, 40, 60, 76], "romano": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 68, 70], "root": [2, 4, 5, 7, 8, 9, 10, 11, 12, 28, 46, 60, 64, 67, 74], "roth": 65, "rough": 76, "round": [35, 50, 54], "rout": [29, 30], "row": [33, 35, 37, 41, 42, 45, 51, 55, 61, 66, 73, 76], "row_index": 48, "rownam": 34, "rowv": 34, "roxygen2": 75, "royal": 74, "rpart": [35, 36, 64], "rpart_cv": 36, "rprocess": 50, "rpy2": 51, "rpy2pi": 51, "rsmp": [36, 64, 66], "rsmp_tune": [36, 64], "rtype": [2, 4, 5, 7, 8, 9, 10, 11, 12], "ruben": 74, "ruiz": [32, 39], "rule": 63, "run": [72, 75], "runif": 32, "runtime_learn": 36, "rv": [49, 57, 69, 76], "rva": [49, 57, 69, 76], "rvert": 46, "rvert_": 46, "s_": [23, 34, 51, 65], "s_1": 24, "s_2": 24, "s_col": [3, 6, 58, 65], "s_i": [26, 58, 65], "s_x": [23, 34, 51], "safeguard": [44, 64], "sake": [35, 52, 76], "same": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 34, 40, 41, 42, 49, 50, 51, 53, 55, 57, 58, 64, 67, 68, 69, 75], "samii": 54, "sampl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 23, 26, 32, 34, 36, 39, 44, 47, 48, 50, 51, 53, 55, 57, 62, 64, 67, 68, 70, 73, 74, 75], "sant": [4, 5, 16, 17, 18, 44, 65, 74], "sara": 74, "sasaki": [23, 34, 51, 74], "satisfi": [58, 64, 67, 68], "save": [33, 35, 40, 47, 48, 50, 52, 53, 64, 69, 76], "savefig": 40, "saveguard": 50, "saver": [35, 52, 53], "scalar": 65, "scale": [33, 34, 43, 45, 54, 56, 68, 69], "scale_color_manu": 33, "scale_fill_manu": [33, 34], "scatter": [45, 47, 48, 54], "scenario": [2, 4, 5, 7, 8, 9, 10, 11, 12, 49, 57, 69, 76], "scene": [41, 42, 46], "scene_camera": 46, "schaefer": 54, "schedul": 75, "scheme": [34, 51, 64, 66, 71], "schneider": 36, "schratz": [36, 64, 71, 73], "scienc": [25, 32, 39, 54, 74], "scikit": [50, 52, 64, 71, 73, 75, 76], "scipi": 40, "score": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 27, 28, 32, 34, 35, 36, 37, 41, 42, 43, 44, 46, 49, 50, 51, 52, 53, 56, 57, 58, 59, 62, 63, 64, 65, 66, 68, 69, 71, 75, 76], "scoring_method": [2, 4, 5, 7, 8, 9, 10, 11, 12], "script": 72, "sd": 32, "se": [33, 34, 40, 57, 60, 64, 66, 68, 69, 74, 76], "se_df": 34, "se_dml": [33, 40, 60], "se_dml_po": [33, 40, 60], "se_nonorth": [33, 40], "se_orth_nosplit": [33, 40], "se_orth_po_nosplit": [33, 40], "seaborn": [37, 40, 44, 50, 51, 52, 53, 58], "search": [2, 4, 5, 7, 8, 9, 10, 11, 12, 28, 64, 67], "search_mod": [2, 4, 5, 7, 8, 9, 10, 11, 12, 64], "searchabl": 35, "second": [23, 33, 34, 36, 40, 50, 51, 59, 60, 66, 68, 69, 70, 73], "section": [5, 18, 34, 35, 36, 49, 51, 53, 75], "secur": 54, "see": [2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 21, 26, 27, 28, 32, 34, 35, 36, 39, 41, 42, 44, 48, 51, 53, 54, 55, 57, 64, 65, 66, 67, 69, 72, 73, 75], "seed": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 76], "seek": 54, "seem": [35, 49, 52, 53, 76], "seen": [47, 48], "sel_cols_chiang": 51, "select": [3, 6, 22, 26, 46, 50, 59, 62, 64, 74, 75, 76], "selected_coef": 50, "selected_featur": [36, 64], "selected_learn": 50, "self": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 50, 76], "selfref": 35, "semenova": [41, 42, 74], "semi": 60, "semiparametr": 14, "sens": 57, "sensemakr": 69, "sensit": [2, 4, 5, 7, 8, 9, 10, 11, 12, 31, 62, 63, 75], "sensitivity_analysi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 49, 57, 69, 76], "sensitivity_benchmark": [2, 4, 5, 7, 8, 9, 10, 11, 12, 49, 57, 69], "sensitivity_el": 69, "sensitivity_param": [2, 4, 5, 7, 8, 9, 10, 11, 12, 57, 69], "sensitivity_plot": [2, 4, 5, 7, 8, 9, 10, 11, 12, 49, 57, 69], "sensitivity_summari": [49, 57, 69, 76], "sensiv": [2, 4, 5, 7, 8, 9, 10, 11, 12], "senstiv": 69, "sep": 33, "separ": [54, 57, 64, 75], "seper": [57, 66, 68, 69], "seq_len": [33, 60], "sequenti": 15, "seri": [48, 74], "serv": [61, 73, 75], "serverless": [74, 75], "servic": 54, "set": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 18, 19, 23, 24, 25, 32, 33, 34, 35, 37, 39, 40, 41, 42, 44, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76], "set_as_param": [2, 4, 5, 7, 8, 9, 10, 11, 12], "set_fold_specif": 64, "set_index": 52, "set_ml_nuisance_param": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 37, 52, 64, 75], "set_param": [29, 30, 64], "set_sample_split": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 66], "set_styl": [52, 53], "set_text": 50, "set_threshold": [33, 34, 35, 36, 59, 64, 65, 66, 67, 68, 70, 73], "set_tick": 51, "set_ticklabel": 51, "set_titl": 51, "set_x_d": [3, 6], "set_xlabel": [40, 51], "set_xlim": 40, "set_xtick": 54, "set_xticklabel": 54, "set_ylabel": [51, 54], "set_ylim": [43, 51, 56], "setdiff": 75, "setdiff1d": 51, "setminu": [34, 51, 68, 70], "setup": 72, "setuptool": 72, "seven": [34, 51], "sever": [31, 35, 36, 50, 52, 53, 57, 60, 64, 76], "shape": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 41, 42, 45, 47, 48, 50, 51, 52, 55, 57, 64], "share": [34, 35, 51, 52], "sharma": 74, "shock": [34, 51], "short": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 57, 69, 74, 75, 76], "shortcut": 35, "shortli": [34, 36, 51, 64], "shota": 74, "should": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 28, 35, 47, 48, 50, 52, 57, 58, 61, 63, 64, 68, 69, 71], "show": [32, 33, 34, 37, 39, 40, 41, 42, 44, 46, 49, 50, 51, 54, 58, 60, 64, 69, 72], "showcas": 55, "shown": [32, 39, 54, 73], "showscal": [41, 42, 46], "shuffl": 66, "side": 69, "sigma": [16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 33, 34, 40, 51, 58, 60, 63, 66, 68, 69, 70], "sigma2": 69, "sigma_": [17, 18, 20, 21, 22, 23, 24, 26, 33, 34, 40, 51, 60], "sigma_0": 69, "sigma_j": [68, 70], "sigmoid": 54, "signal": 1, "signatur": [7, 8, 9, 10, 11, 12, 13, 67], "signif": [32, 34, 35, 36, 64, 65, 66, 67, 68, 73, 76], "signific": [32, 34, 35, 36, 49, 52, 55, 57, 64, 65, 66, 67, 68, 69, 73, 76], "silverman": [9, 12, 13], "sim": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 40, 43, 45, 51, 55, 56, 58, 60], "similar": [16, 17, 36, 41, 42, 49, 53, 57], "simpl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 19, 36, 41, 42, 47, 48, 49, 55, 62, 69], "simplest": 63, "simpli": [36, 44, 76], "simplic": [35, 50, 52, 55], "simplif": 69, "simplifi": [54, 63, 69], "simul": [16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 33, 36, 40, 41, 42, 43, 46, 47, 48, 56, 58, 60, 64, 68, 70, 73], "simulation_run": 46, "simultan": [62, 76], "sin": [19, 25, 41, 42, 45, 47, 48], "sinc": [16, 17, 35, 44, 45, 47, 48, 49, 50, 52, 54, 58, 64, 65, 69, 75], "singl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 44, 47, 48, 53, 54, 64, 68, 70], "single_learner_pipelin": 64, "singleton": 66, "sinh": 25, "sipp": [35, 52, 53], "site": 51, "situat": [34, 51], "six": 34, "sixth": 51, "size": [33, 34, 35, 36, 40, 43, 45, 46, 49, 50, 52, 54, 55, 56, 59, 61, 64, 65, 66, 67, 68, 70, 73, 76], "skill": 74, "sklearn": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 25, 37, 39, 40, 41, 42, 46, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 63, 64, 65, 66, 67, 68, 69, 70, 73, 76], "slide": 54, "slightli": [45, 47, 48, 49, 50, 63, 67, 69], "sligthli": [4, 5], "slow": [33, 40, 60], "slower": [33, 40, 60], "small": [19, 44, 45, 55, 58, 69], "smaller": [35, 44, 47, 48, 49, 52, 76], "smallest": 50, "smpl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 34, 40, 50, 51, 66, 67], "smpls_cluster": [34, 51], "sn": [37, 40, 44, 50, 51, 52, 53, 58], "so": [32, 35, 36, 39, 44, 52, 54, 58, 64, 68, 76], "social": [54, 74], "societi": [34, 51, 74], "softwar": [36, 64, 71, 73, 74, 75], "solari": 75, "solut": [59, 63, 67], "solv": [27, 34, 51, 63, 64, 68, 70], "solver": [52, 58, 65], "some": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 36, 37, 44, 45, 50, 52, 53, 57, 58, 63, 64, 65, 75], "sometim": 50, "sonabend": [36, 64], "sophist": 64, "sort": 52, "sourc": [36, 64, 73, 75], "sourcefileload": 46, "space": [34, 51, 64], "spars": [46, 64, 68, 70, 73, 74], "sparsiti": 74, "spec": 74, "special": [34, 51], "specif": [2, 4, 5, 7, 8, 9, 10, 11, 12, 28, 34, 35, 51, 52, 61, 62, 63, 64, 66, 67, 68, 71, 73], "specifi": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 32, 34, 35, 36, 39, 41, 42, 43, 44, 47, 48, 51, 52, 53, 55, 56, 57, 58, 59, 61, 62, 63, 73, 75, 76], "specifii": 53, "speed": [13, 50], "speedup": 50, "spefici": 7, "spindler": [22, 71, 74, 75], "spine": [52, 53], "spline": [41, 42, 63], "spline_basi": [41, 42, 63], "spline_grid": [41, 42], "split": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 34, 36, 44, 50, 51, 53, 55, 57, 58, 62, 63, 64, 65, 67, 68, 73, 75], "split_sampl": 50, "sponsor": [35, 52, 53], "sprintf": 33, "sq_error": 46, "sqrt": [16, 17, 18, 21, 33, 34, 36, 37, 40, 43, 51, 56, 60, 66, 68, 69, 70, 73], "squar": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 46, 52, 64, 69, 74], "squarederror": [35, 52, 76], "squeez": [43, 44, 56, 58], "ssm": [3, 6, 26, 62], "ssrn": 20, "stabil": 49, "stabl": [32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 71], "stack": [36, 64], "stacklrn": 36, "stage": [41, 42, 47, 48, 55, 64, 75, 76], "standard": [18, 36, 43, 47, 48, 66, 67, 68, 69, 70, 75, 76], "standard_norm": [61, 64, 68, 70, 73], "standardscal": 52, "start": [35, 36, 41, 42, 46, 49, 50, 51, 52, 56, 65, 71, 76], "stat": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 40, 61, 64, 68, 70, 71, 74], "stat_bin": 33, "stat_dens": 35, "state": 76, "stationar": 44, "stationari": 65, "statist": [2, 4, 5, 7, 8, 9, 10, 11, 12, 23, 26, 31, 34, 51, 57, 68, 69, 70, 71, 73, 74, 75, 76], "statsmodel": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "statu": [35, 44, 52, 54, 58], "std": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 34, 35, 36, 37, 39, 41, 42, 43, 44, 47, 48, 49, 51, 52, 53, 54, 56, 57, 58, 63, 64, 65, 66, 67, 68, 73, 76], "stefan": 74, "step": [33, 35, 36, 40, 47, 48, 49, 52, 55, 60, 64, 68, 70, 71, 76], "stepdown": [68, 70], "stick": [35, 52], "still": [41, 42, 44, 47, 48, 49, 53, 57, 58, 64], "stochast": [10, 11, 65, 73], "stock": [35, 52, 53], "store": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 59, 64, 66, 67, 68, 69, 75], "store_model": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "store_predict": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 52, 55], "stori": 74, "str": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 35, 47, 48, 56, 63, 75], "straightforward": [47, 48, 50, 63], "strategi": [54, 76], "stratifi": 50, "stratum": 54, "strength": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 57, 69], "strictli": 65, "string": [2, 4, 5, 7, 8, 9, 10, 11, 12, 63, 68, 69, 73, 75], "string_label": 54, "strong": [58, 69], "stronger": [68, 76], "structur": [14, 15, 24, 34, 35, 46, 51, 52, 58, 60, 64, 71, 74, 76], "student": 74, "studi": [26, 34, 35, 46, 51, 52, 53, 57, 73, 76], "style": [2, 4, 5, 7, 8, 9, 10, 11, 12, 75], "styler": 75, "sub": [34, 51], "subclass": 75, "subfold": 64, "subgroup": [7, 35, 52, 75], "subject": [34, 51], "submiss": 75, "subobject": [29, 30], "subplot": [34, 40, 41, 42, 43, 45, 47, 48, 50, 51, 52, 53, 54, 56], "subplots_adjust": 50, "subpopul": 65, "subsampl": [36, 50], "subscript": 69, "subsequ": [34, 51], "subset": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 50, 51, 55, 59, 63, 64, 69], "subseteq": 63, "substanti": [35, 52, 54], "substract": 68, "subtract": 68, "sudo": 72, "suffici": 50, "suggest": [34, 35, 51, 52, 75], "suitabl": [41, 42, 58], "sum": [34, 35, 51, 52, 53, 56, 63, 68, 70], "sum_": [33, 34, 40, 51, 59, 60, 63, 68, 70], "sum_i": 54, "sum_oth": 51, "sum_riv": 51, "summar": [54, 59, 69], "summari": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 34, 36, 37, 39, 41, 42, 43, 44, 47, 48, 49, 51, 53, 56, 57, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 73, 75, 76], "summary_result": 35, "suppli": [2, 4, 5, 7, 8, 9, 10, 11, 12, 41, 42, 47, 48, 49, 55, 63, 69], "support": [7, 19, 34, 50, 51, 55, 64, 65, 76], "support_s": [19, 41, 42, 47, 48, 55], "support_t": 55, "support_w": 55, "suppress": [35, 36], "suppresswarn": 33, "suprema": [68, 70], "suptitl": [43, 50, 53, 56], "supxlabel": [43, 53, 56], "supylabel": [43, 53, 56], "sure": [64, 75], "surfac": [41, 42, 46], "surpress": [34, 73], "survei": [35, 52, 53, 76], "susan": 74, "sven": [71, 74], "svenk": 51, "svenklaassen": 71, "svg": [33, 40], "switch": [33, 40, 60], "symmetr": 25, "synthet": [19, 32, 39, 41, 42, 43, 47, 48, 55, 56], "syrgkani": 74, "system": 74, "szita": 74, "t": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 32, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 63, 64, 65, 66, 67, 68, 69, 70, 73, 76], "t_1_start": 50, "t_1_stop": 50, "t_2_start": 50, "t_2_stop": 50, "t_3_start": 50, "t_3_stop": 50, "t_col": [3, 5, 6, 65], "t_df": 55, "t_diff": 45, "t_dml": 33, "t_i": [44, 55, 65], "t_idx": 45, "t_nonorth": 33, "t_orth_nosplit": 33, "t_sigmoid": 55, "t_stat": 68, "tabl": [33, 34, 35, 36, 59, 61, 64, 65, 66, 67, 68, 70, 73, 76], "tabular": [50, 61, 68, 70, 73, 76], "taddi": 74, "take": [7, 8, 10, 11, 16, 17, 19, 41, 42, 43, 44, 45, 46, 47, 48, 50, 53, 56, 57, 58, 59, 63, 64, 65, 69, 73], "taken": [35, 52, 53, 76], "taker": [7, 75], "talk": 76, "target": [2, 4, 5, 7, 8, 9, 10, 11, 12, 27, 28, 32, 34, 35, 36, 41, 42, 50, 51, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76], "task": [32, 61, 66, 76], "task_typ": 75, "tau": [43, 45, 53, 54, 56, 63, 67], "tau_": 54, "tau_1": 54, "tau_2": 54, "tau_vec": [43, 53, 56], "tax": [35, 52, 53], "te": [41, 42, 55], "techniqu": [33, 40, 60, 66, 76], "templat": 75, "temporari": 52, "tend": [35, 52, 53], "tensor": [41, 42], "tenth": 74, "term": [33, 34, 35, 36, 40, 45, 46, 51, 52, 54, 60, 71, 76], "termin": [36, 64], "terminatorev": 36, "test": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 20, 32, 33, 34, 35, 36, 40, 49, 51, 60, 64, 65, 66, 67, 68, 70, 73, 74, 75, 76], "test_id": [34, 66], "test_ind": [2, 4, 5, 7, 8, 9, 10, 11, 12], "test_set": 66, "test_siz": 40, "text": [16, 17, 18, 20, 34, 35, 43, 46, 54, 55, 56, 63, 66], "textbf": [59, 64, 76], "textrm": 69, "tg": [36, 37, 61, 73], "th": [34, 51], "than": [8, 33, 35, 40, 46, 50, 52, 53, 54, 57, 60, 69, 76], "thank": [35, 36, 52, 75], "thatw": 45, "thei": [35, 45, 47, 48, 52, 54, 69], "them": [35, 36, 41, 42, 43, 49, 52, 56], "theme": [34, 35], "theme_minim": [33, 35], "theorem": 69, "theoret": [50, 66, 74], "theori": [63, 74], "therebi": [34, 36, 51, 76], "therefor": [54, 57, 66, 67, 69], "theta": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 23, 25, 26, 27, 28, 33, 34, 36, 40, 44, 45, 46, 49, 50, 51, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 76], "theta_": [63, 68, 69, 70], "theta_0": [7, 8, 10, 11, 19, 33, 34, 35, 40, 41, 42, 46, 47, 48, 51, 52, 58, 60, 63, 65, 67, 68, 69, 73], "theta_dml": [33, 40, 60], "theta_dml_po": [33, 40, 60], "theta_initi": 40, "theta_nonorth": [33, 40], "theta_orth_nosplit": [33, 40], "theta_orth_po_nosplit": [33, 40], "theta_resc": 33, "theta_t": 45, "thi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76], "think": 36, "third": [33, 40, 51, 60, 66], "thirion": [71, 73], "this_df": [46, 52], "this_split_ind": 51, "those": [35, 52, 53], "though": [32, 39, 54], "thread": [54, 64], "three": [34, 36, 47, 48, 72, 75], "threshold": [2, 4, 5, 7, 8, 9, 12, 13, 65], "through": [43, 47, 48, 56, 64], "throughout": 49, "thu": 63, "tight": 40, "tight_layout": 51, "tild": [16, 17, 18, 34, 51, 54, 59, 63, 66, 67, 68, 69, 70], "time": [3, 4, 6, 22, 23, 33, 34, 35, 40, 44, 45, 46, 47, 48, 51, 52, 53, 57, 58, 65, 75, 76], "time_df": 45, "time_period": 45, "titl": [34, 35, 41, 42, 43, 46, 47, 48, 50, 51, 52, 53, 54, 56, 71], "tmp": 48, "tnr": [36, 64], "to_fram": 55, "to_numpi": [43, 49, 53, 56], "todo": [34, 37], "toeplitz": 46, "togeth": [47, 48, 68], "toler": 51, "too": 50, "tool": [36, 57, 76], "top": [34, 50, 51, 52, 53, 71], "total": [35, 52], "tracker": 71, "tradit": [68, 70], "train": [33, 34, 36, 40, 41, 42, 43, 47, 48, 50, 51, 55, 56, 59, 60, 66], "train_id": [34, 66], "train_ind": [2, 4, 5, 7, 8, 9, 10, 11, 12], "train_set": 66, "train_test_split": 40, "transact": 74, "transform": [16, 17, 54, 76], "translat": 46, "transpos": 45, "treament": 55, "treat": [8, 18, 44, 45, 49, 55, 63, 65, 68, 76], "treat1_param": 54, "treat2_param": 54, "treat_var": [2, 4, 5, 7, 8, 9, 10, 11, 12, 64], "treatment": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 32, 34, 36, 37, 39, 44, 45, 46, 49, 50, 51, 55, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76], "treatment_df": 45, "treatment_effect": [19, 41, 42], "treatment_var": [3, 6], "tree": [8, 35, 36, 44, 45, 50, 52, 59, 62, 64, 65, 66, 67, 68, 73, 75], "tree_param": 8, "tree_summari": 52, "trees_class": [35, 52], "trend": [44, 45, 51, 65, 74], "tri": [46, 69], "trim": [2, 4, 5, 7, 8, 9, 12, 13, 35, 52, 53], "trimming_rul": [2, 4, 5, 7, 8, 9, 12, 13, 53], "trimming_threshold": [2, 4, 5, 7, 8, 9, 12, 13, 35, 41, 52, 53, 55, 56], "trm": [36, 64], "true": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 26, 29, 30, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 64, 65, 66, 67, 68, 69, 70, 73, 76], "true_effect": [41, 42, 45, 47, 48], "true_gatet_effect": 49, "true_group_effect": 49, "truncat": [2, 4, 5, 7, 8, 9, 12, 13, 53], "try": [50, 57], "tune": [2, 4, 5, 7, 8, 9, 10, 11, 12, 46, 62, 71, 73, 75], "tune_on_fold": [2, 4, 5, 7, 8, 9, 10, 11, 12, 64], "tune_r": [2, 4, 5, 7, 8, 9, 10, 11, 12], "tune_set": [36, 64], "tuner": 64, "tunergridsearch": 36, "tupl": [2, 4, 5, 7, 8, 9, 10, 11, 12], "turrel": 25, "tutori": 35, "tw": [52, 53], "two": [2, 4, 5, 7, 8, 9, 10, 11, 12, 18, 19, 32, 33, 35, 36, 39, 40, 43, 44, 50, 52, 53, 54, 55, 56, 57, 59, 60, 63, 64, 65, 66, 67, 68, 70, 76], "twoclass": 36, "twoearn": [35, 52, 53, 57, 76], "type": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 29, 30, 31, 33, 34, 35, 36, 40, 50, 51, 60, 64, 67, 68, 69, 70, 75, 76], "typic": [48, 71], "u": [7, 8, 9, 12, 13, 16, 17, 18, 19, 21, 26, 33, 34, 35, 40, 43, 44, 45, 47, 48, 50, 51, 52, 53, 55, 56, 57, 60, 65, 69, 72, 76], "u_hat": [33, 40, 67], "u_i": [20, 22, 25, 26], "u_t": 18, "uehara": 74, "uhash": 36, "ulf": 74, "uncertainti": [2, 4, 5, 7, 8, 9, 10, 11, 12, 47, 48, 57, 69, 76], "uncondit": [35, 52, 76], "unconfounded": 74, "under": [33, 35, 40, 44, 52, 55, 60, 65, 68, 74], "underbrac": [33, 40, 45, 60, 63], "underli": [35, 36, 47, 48, 54, 55, 69, 76], "underlin": [34, 51], "undesir": 64, "unevenli": 66, "uniform": [18, 39, 41, 42, 43, 45, 55, 56, 68], "uniformli": [43, 53, 68, 70], "uniqu": [32, 39, 50, 67, 69], "unit": [33, 44, 45, 49, 58, 65, 67, 75], "univari": [19, 41, 42], "univers": 74, "unknown": 65, "unlik": [35, 52, 53], "unobserv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 35, 39, 52, 53, 57, 65, 69, 76], "unstabl": 69, "unter": [34, 35, 36], "until": [65, 75], "untreat": 65, "up": [13, 35, 46, 50, 52, 53, 57, 64, 65, 66, 69, 72, 75, 76], "upcom": 75, "updat": [34, 48, 51, 74, 75], "update_layout": [41, 42, 46], "update_trac": [41, 42], "upload": 75, "upon": [67, 75], "upper": [35, 36, 40, 43, 45, 49, 53, 56, 57, 64, 69, 76], "upper_bound": [41, 42], "upsilon": 58, "upsilon_i": 58, "upward": [35, 52, 53], "upweight": 54, "url": [46, 71, 74], "us": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 33, 34, 35, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76], "usa": 74, "usabl": 50, "usag": [37, 44, 49, 51, 52, 53, 57, 58, 61, 73, 75], "use_label_encod": [52, 76], "use_other_treat_as_covari": [3, 6, 61], "usecolormap": [41, 42], "user": [27, 28, 29, 30, 33, 34, 35, 36, 40, 49, 50, 51, 52, 57, 63, 64, 67, 68, 70, 71, 72, 73, 75, 76], "user_guid": 48, "usual": [34, 41, 42, 44, 50, 51, 57, 63, 64, 66, 69], "util": [28, 54, 64, 75], "v": [7, 8, 10, 11, 14, 15, 21, 22, 23, 24, 26, 33, 34, 35, 40, 49, 51, 52, 54, 59, 60, 63, 65, 68, 70, 71, 73, 74, 75, 76], "v108": 71, "v12": [71, 73], "v22": 36, "v23": 71, "v_": [23, 34, 51], "v_i": [20, 21, 24, 25, 26, 33, 40, 60, 65], "v_j": [68, 70], "val": [21, 66, 74], "val_list": 46, "valid": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 20, 33, 34, 35, 40, 43, 44, 50, 51, 52, 53, 56, 60, 62, 63, 64, 66, 67, 69, 74, 76], "valu": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 57, 59, 62, 64, 65, 66, 68, 69, 70, 73, 75, 76], "value_count": 52, "van": 74, "vanderpla": [71, 73], "vanish": [33, 40, 60], "var": [16, 17, 18, 34, 51, 54, 69], "varepsilon": [7, 16, 17, 23, 34, 51, 58, 63, 65], "varepsilon_": [23, 34, 51], "varepsilon_0": 18, "varepsilon_1": 18, "varepsilon_d": 17, "varepsilon_i": [22, 43, 56, 58], "vari": [35, 45, 50, 52, 54], "variabl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 34, 35, 36, 37, 44, 46, 49, 51, 52, 53, 57, 58, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75, 76], "varianc": [27, 28, 34, 36, 51, 57, 62, 66, 69, 73], "variat": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 57, 69], "variou": [64, 76], "varoquaux": [71, 73], "vasili": 74, "vector": [2, 4, 5, 7, 8, 9, 10, 11, 12, 19, 20, 21, 22, 23, 25, 26, 32, 34, 35, 39, 44, 47, 48, 49, 51, 52, 55, 58, 65, 68, 70, 73, 75], "venv": 72, "verbos": [35, 45], "veri": [34, 36, 49, 50, 51, 67, 71], "verifi": 54, "versa": [50, 54, 69], "version": [34, 35, 36, 52, 59, 63, 68, 69, 70, 75], "versu": 48, "vertic": [34, 51], "via": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 28, 43, 44, 45, 46, 47, 48, 49, 50, 57, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76], "viabl": [2, 4, 5, 7, 8, 9, 10, 11, 12], "vice": [50, 54, 69], "victor": [46, 66, 71, 74], "view": 48, "vignett": 75, "villa": [32, 39], "violet": [43, 53, 56], "vira": 74, "virtual": 72, "virtualenv": 72, "visibl": 53, "visit": [71, 76], "visual": [34, 49, 51], "volum": 71, "voluntari": 54, "vv740": 51, "vv760g": 51, "w": [14, 15, 16, 17, 18, 24, 27, 28, 34, 46, 51, 54, 55, 59, 60, 67, 68, 69, 70, 71, 73], "w24678": 66, "w30302": 74, "w_": [18, 34, 51, 55], "w_1": [18, 55], "w_2": [18, 55], "w_3": 18, "w_4": 18, "w_df": 55, "w_i": [26, 44, 55, 59, 63, 66, 67, 68, 70], "wa": [34, 45, 51, 75], "wager": 74, "wai": [35, 50, 52, 64, 67, 72], "wander": 25, "wang": 74, "want": [32, 34, 35, 36, 39, 43, 44, 50, 51, 56, 64, 71, 72, 74], "warn": [32, 33, 34, 35, 36, 40, 59, 64, 65, 66, 67, 68, 70, 73, 75], "wayon": 34, "we": [8, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76], "weak": [69, 74], "wealth": [14, 57], "websit": [35, 36, 64, 71], "wedg": [34, 51], "week": 75, "wei": [68, 70], "weight": [2, 7, 8, 9, 12, 13, 34, 35, 36, 49, 51, 52, 58, 62, 64, 68, 69, 70, 75], "weights_bar": 8, "weiss": [71, 73], "well": [3, 6, 33, 34, 40, 46, 50, 51, 59, 60, 61, 66, 73], "were": [35, 52, 53, 58, 76], "what": [46, 50], "when": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 35, 44, 48, 52, 54, 65, 67, 68, 70, 71, 72, 73, 75], "whenev": [35, 52], "whera": 69, "where": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 32, 33, 34, 35, 39, 40, 43, 44, 45, 49, 51, 52, 54, 55, 56, 58, 59, 60, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76], "wherea": [19, 44, 58, 69, 76], "whether": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 19, 26, 35, 45, 50, 52, 53, 61, 64, 69, 75], "which": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 28, 32, 33, 35, 36, 38, 39, 40, 44, 46, 48, 49, 50, 52, 53, 55, 57, 58, 60, 61, 63, 64, 65, 67, 68, 69, 70, 72, 75, 76], "while": [32, 39], "white": [34, 47, 48, 51], "whitegrid": [52, 53], "whitnei": 74, "who": [35, 52], "whole": [33, 40, 44, 60, 64, 69], "width": [33, 34, 41, 42, 46], "wiki": 75, "wiksel": 74, "wild": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 68, 70], "window": 72, "wise": [47, 48], "wish": 72, "within": [34, 47, 48, 51, 55], "without": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 33, 39, 40, 50, 60, 62, 64, 69, 72, 75], "wolf": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 68, 70], "word": 76, "work": [29, 30, 38, 48, 49, 50, 54, 57, 64, 68, 72, 74], "workflow": [71, 75], "world": 74, "would": [35, 36, 41, 42, 46, 50, 52, 53, 57, 63, 64, 69, 76], "wrapper": 64, "write": [33, 40, 44, 48, 58, 60, 69], "written": [67, 69], "wrong": [50, 54], "wspace": 50, "wurd": [34, 35, 36], "www": [71, 72], "x": [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 76], "x0": 54, "x1": [34, 36, 44, 51, 54, 57, 58, 61, 63, 64, 65, 67, 68, 69, 73], "x10": [34, 36, 51, 58, 61, 64, 65, 67, 68, 73], "x100": [34, 36, 51, 58, 61, 65, 73], "x11": [34, 36, 51, 58, 61, 64, 65, 67, 68, 73], "x12": [34, 36, 51, 58, 61, 64, 65, 67, 68, 73], "x13": [34, 36, 51, 58, 61, 64, 65, 67, 68, 73], "x14": [34, 36, 51, 58, 61, 64, 65, 67, 68, 73], "x15": [34, 36, 51, 58, 61, 64, 65, 67, 68, 73], "x16": [34, 36, 51, 58, 61, 64, 65, 67, 68, 73], "x17": [34, 36, 51, 58, 61, 64, 65, 67, 68, 73], "x18": [34, 36, 51, 58, 61, 64, 65, 67, 68, 73], "x19": [34, 36, 51, 58, 61, 64, 65, 67, 68, 73], "x1x2x3x4x5x6x7x8x9x10": 34, "x2": [34, 36, 44, 51, 57, 58, 61, 63, 64, 65, 67, 68, 73], "x20": [34, 36, 51, 58, 61, 64, 65, 67, 68, 73], "x21": [34, 36, 51, 58, 61, 65, 73], "x22": [34, 36, 51, 58, 61, 65, 73], "x23": [34, 36, 51, 58, 61, 65, 73], "x24": [34, 36, 51, 58, 61, 65, 73], "x25": [34, 36, 51, 58, 61, 65, 73], "x26": [34, 36, 51, 58, 61, 65, 73], "x27": [34, 36, 51, 58, 61, 65, 73], "x28": [34, 36, 51, 58, 61, 65, 73], "x29": [34, 36, 51, 58, 61, 65, 73], "x3": [34, 36, 44, 51, 57, 58, 61, 63, 64, 65, 67, 68, 73], "x30": [34, 36, 51, 58, 61, 65, 73], "x31": [34, 36, 51, 58, 61, 65, 73], "x32": [34, 36, 51, 58, 61, 65, 73], "x33": [34, 36, 51, 58, 61, 65, 73], "x34": [34, 36, 51, 58, 61, 65, 73], "x35": [34, 36, 51, 58, 61, 65, 73], "x36": [34, 36, 51, 58, 61, 65, 73], "x37": [34, 36, 51, 58, 61, 65, 73], "x38": [34, 36, 51, 58, 61, 65, 73], "x39": [34, 36, 51, 58, 61, 65, 73], "x4": [34, 36, 44, 51, 57, 58, 61, 64, 65, 67, 68, 73], "x40": [34, 36, 51, 58, 61, 65, 73], "x41": [34, 36, 51, 58, 61, 65, 73], "x42": [34, 36, 51, 58, 61, 65, 73], "x43": [34, 36, 51, 58, 61, 65, 73], "x44": [34, 36, 51, 58, 61, 65, 73], "x45": [34, 36, 51, 58, 61, 65, 73], "x46": [34, 36, 51, 58, 61, 65, 73], "x47": [34, 36, 51, 58, 61, 65, 73], "x48": [34, 36, 51, 58, 61, 65, 73], "x49": [34, 36, 51, 58, 61, 65, 73], "x5": [34, 36, 51, 58, 61, 64, 65, 67, 68, 73], "x50": [34, 36, 51, 58, 61, 65, 73], "x51": [34, 36, 51, 58, 61, 65, 73], "x52": [34, 36, 51, 58, 61, 65, 73], "x53": [34, 36, 51, 58, 61, 65, 73], "x54": [34, 36, 51, 58, 61, 65, 73], "x55": [34, 36, 51, 58, 61, 65, 73], "x56": [34, 36, 51, 58, 61, 65, 73], "x57": [34, 36, 51, 58, 61, 65, 73], "x58": [34, 36, 51, 58, 61, 65, 73], "x59": [34, 36, 51, 58, 61, 65, 73], "x6": [34, 36, 51, 58, 61, 64, 65, 67, 68, 73], "x60": [34, 36, 51, 58, 61, 65, 73], "x61": [34, 36, 51, 58, 61, 65, 73], "x62": [34, 36, 51, 58, 61, 65, 73], "x63": [34, 36, 51, 58, 61, 65, 73], "x64": [34, 36, 51, 58, 61, 65, 73], "x65": [34, 36, 51, 58, 61, 65, 73], "x66": [34, 36, 51, 58, 61, 65, 73], "x67": [34, 36, 51, 58, 61, 65, 73], "x68": [34, 36, 51, 58, 61, 65, 73], "x69": [34, 36, 51, 58, 61, 65, 73], "x7": [34, 36, 51, 58, 61, 64, 65, 67, 68, 73], "x70": [34, 36, 51, 58, 61, 65, 73], "x71": [34, 36, 51, 58, 61, 65, 73], "x72": [34, 36, 51, 58, 61, 65, 73], "x73": [34, 36, 51, 58, 61, 65, 73], "x74": [34, 36, 51, 58, 61, 65, 73], "x75": [34, 36, 51, 58, 61, 65, 73], "x76": [34, 36, 51, 58, 61, 65, 73], "x77": [34, 36, 51, 58, 61, 65, 73], "x78": [34, 36, 51, 58, 61, 65, 73], "x79": [34, 36, 51, 58, 61, 65, 73], "x8": [34, 36, 51, 58, 61, 64, 65, 67, 68, 73], "x80": [34, 36, 51, 58, 61, 65, 73], "x81": [34, 36, 51, 58, 61, 65, 73], "x82": [34, 36, 51, 58, 61, 65, 73], "x83": [34, 36, 51, 58, 61, 65, 73], "x84": [34, 36, 51, 58, 61, 65, 73], "x85": [34, 36, 51, 58, 61, 65, 73], "x86": [34, 36, 51, 58, 61, 65, 73], "x87": [34, 36, 51, 58, 61, 65, 73], "x88": [34, 36, 51, 58, 61, 65, 73], "x89": [34, 36, 51, 58, 61, 65, 73], "x9": [34, 36, 51, 58, 61, 64, 65, 67, 68, 73], "x90": [34, 36, 51, 58, 61, 65, 73], "x91": [34, 36, 51, 58, 61, 65, 73], "x92": [34, 36, 51, 58, 61, 65, 73], "x93": [34, 36, 51, 58, 61, 65, 73], "x94": [34, 36, 51, 58, 61, 65, 73], "x95": [34, 36, 51, 58, 61, 65, 73], "x96": [34, 36, 51, 58, 61, 65, 73], "x96x97x98x99x100ydcluster_var_icluster_var_jz": 34, "x97": [34, 36, 51, 58, 61, 65, 73], "x98": [34, 36, 51, 58, 61, 65, 73], "x99": [34, 36, 51, 58, 61, 65, 73], "x_": [23, 24, 33, 34, 40, 45, 51, 60], "x_0": [41, 42, 45, 47, 48, 49], "x_1": [10, 11, 16, 17, 18, 41, 42, 43, 45, 47, 48, 49, 56, 65, 69, 73], "x_1x_3": [43, 56], "x_2": [16, 17, 18, 41, 42, 43, 45, 47, 48, 49, 56, 69], "x_3": [16, 17, 18, 41, 42, 45, 47, 48, 49, 69], "x_4": [16, 17, 18, 41, 42, 43, 47, 48, 49, 56], "x_5": [16, 17, 41, 42, 47, 48], "x_6": [41, 42, 47, 48], "x_7": [41, 42, 47, 48], "x_8": [41, 42, 47, 48], "x_9": [41, 42, 47, 48], "x_col": [3, 6, 32, 34, 35, 36, 39, 46, 51, 52, 53, 55, 57, 61, 64, 73, 75, 76], "x_cols_poli": 51, "x_conf": 56, "x_conf_tru": 56, "x_df": 45, "x_domain": 36, "x_i": [19, 20, 21, 22, 24, 25, 26, 33, 40, 43, 44, 47, 48, 54, 56, 58, 60, 63, 65], "x_p": [10, 11, 65, 73], "x_true": [43, 56], "x_var": 36, "xaxis_titl": [41, 42, 46], "xgbclassifi": [50, 52, 54, 76], "xgboost": [33, 35, 50, 52, 54, 76], "xgbregressor": [50, 52, 54, 76], "xi": [18, 65], "xi_": [68, 70], "xi_0": [23, 34, 51], "xi_i": 58, "xiaoji": 74, "xintercept": 33, "xlab": [33, 34, 35], "xlabel": [41, 42, 43, 45, 47, 48, 52, 53, 56], "xlim": [33, 35], "xval": [36, 64], "xx": 40, "y": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 76], "y0": [43, 56], "y0_cvar": 43, "y0_quant": [43, 56], "y1": [43, 56], "y1_cvar": 43, "y1_quant": [43, 56], "y_": [23, 34, 44, 45, 51, 58, 65], "y_0": [4, 18, 67], "y_1": [4, 18, 67], "y_col": [3, 6, 32, 33, 34, 35, 36, 39, 41, 42, 46, 47, 48, 51, 52, 53, 55, 57, 59, 60, 61, 64, 65, 66, 67, 73, 75, 76], "y_df": [45, 55], "y_diff": 45, "y_i": [19, 20, 21, 22, 24, 25, 26, 33, 40, 43, 44, 54, 55, 56, 58, 60, 65], "y_pred": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 64], "y_true": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 64], "ya": 74, "yasui": 74, "yata": 74, "yaxis_titl": [41, 42, 46], "year": 71, "yerr": [45, 47, 48, 52, 54], "yet": [34, 38], "yggvpl": 51, "yintercept": 35, "ylab": [33, 34, 35], "ylabel": [41, 42, 43, 45, 47, 48, 52, 53, 56], "ylim": 52, "ymax": 35, "ymin": 35, "york": 74, "you": [32, 33, 39, 45, 48, 51, 57, 71, 72, 76], "your": [50, 72], "ython": 71, "yukun": 74, "yusuk": 74, "yuya": 74, "yy": 40, "z": [3, 6, 7, 9, 10, 16, 17, 18, 20, 22, 23, 26, 32, 34, 35, 39, 41, 42, 46, 51, 52, 56, 58, 63, 65, 67, 68, 70, 75], "z1": [10, 65], "z2": 65, "z3": 65, "z4": 65, "z_": [23, 34, 51], "z_1": [16, 17], "z_2": [16, 17], "z_3": [16, 17], "z_4": [16, 17], "z_5": 16, "z_col": [3, 6, 7, 9, 10, 32, 34, 35, 39, 51, 52, 53, 58, 61, 63, 65, 75], "z_i": [22, 26, 56, 58, 65], "z_j": [16, 17, 18], "z_true": 56, "zadik": 74, "zaxis_titl": [41, 42, 46], "zero": [18, 43, 44, 45, 50, 55, 56, 57, 68], "zeros_lik": 56, "zeta": [7, 10, 11, 35, 52, 63, 65, 73], "zeta_": [23, 34, 51], "zeta_0": [23, 34, 51], "zeta_i": [21, 22, 24, 33, 40, 60], "zeta_j": [68, 70], "zhang": 74, "zhao": [4, 5, 16, 17, 18, 44, 65, 74], "zimmert": [44, 74], "zip": [41, 42], "\u03c4_x0": 54, "\u03c4_x1": 54, "\u2139": 33}, "titles": ["API reference", "doubleml.DoubleMLBLP", "doubleml.DoubleMLCVAR", "doubleml.DoubleMLClusterData", "doubleml.DoubleMLDID", "doubleml.DoubleMLDIDCS", "doubleml.DoubleMLData", "doubleml.DoubleMLIIVM", "doubleml.DoubleMLIRM", "doubleml.DoubleMLLPQ", "doubleml.DoubleMLPLIV", "doubleml.DoubleMLPLR", "doubleml.DoubleMLPQ", "doubleml.DoubleMLQTE", "doubleml.datasets.fetch_401K", "doubleml.datasets.fetch_bonus", "doubleml.datasets.make_confounded_irm_data", "doubleml.datasets.make_confounded_plr_data", "doubleml.datasets.make_did_SZ2020", "doubleml.datasets.make_heterogeneous_data", "doubleml.datasets.make_iivm_data", "doubleml.datasets.make_irm_data", "doubleml.datasets.make_pliv_CHS2015", "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "doubleml.datasets.make_plr_CCDDHNR2018", "doubleml.datasets.make_plr_turrell2018", "doubleml.datasets.make_ssm_data", "doubleml.double_ml_score_mixins.LinearScoreMixin", "doubleml.double_ml_score_mixins.NonLinearScoreMixin", "doubleml.utils.DMLDummyClassifier", "doubleml.utils.DMLDummyRegressor", "doubleml.utils.gain_statistics", "R: Basic Instrumental Variables Calculation", "R: Basics of Double Machine Learning", "R: Cluster Robust Double Machine Learning", "R: Impact of 401(k) on Financial Wealth", "R: Ensemble Learners and More with <code class=\"docutils literal notranslate\"><span class=\"pre\">mlr3pipelines</span></code>", "DML: Bonus Data", "Examples", "Python: Basic Instrumental Variables calculation", "Python: Basics of Double Machine Learning", "Python: Conditional Average Treatment Effects (CATEs) for IRM models", "Python: Conditional Average Treatment Effects (CATEs) for PLR models", "Python: Conditional Value at Risk of potential outcomes", "Python: Difference-in-Differences", "Python: Difference-in-Differences Pre-Testing", "Python: First Stage and Causal Estimation", "Python: Group Average Treatment Effects (GATEs) for IRM models", "Python: Group Average Treatment Effects (GATEs) for PLR models", "Python: GATE Sensitivity Analysis", "Python: Choice of learners", "Python: Cluster Robust Double Machine Learning", "Python: Impact of 401(k) on Financial Wealth", "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)", "Python: PLM and IRM for Multiple Treatments", "Python: Policy Learning with Trees", "Python: Potential Quantiles and Quantile Treatment Effects", "Python: Sensitivity Analysis", "Python: Sample Selection Models", "<span class=\"section-number\">6. </span>Double machine learning algorithms", "<span class=\"section-number\">1. </span>The basics of double/debiased machine learning", "<span class=\"section-number\">2. </span>The data-backend DoubleMLData", "User guide", "<span class=\"section-number\">4. </span>Heterogeneous treatment effects", "<span class=\"section-number\">7. </span>Learners, hyperparameters and hyperparameter tuning", "<span class=\"section-number\">3. </span>Models", "<span class=\"section-number\">9. </span>Sample-splitting, cross-fitting and repeated cross-fitting", "<span class=\"section-number\">5. </span>Score functions", "<span class=\"section-number\">8. </span>Variance estimation and confidence intervals", "<span class=\"section-number\">10. </span>Sensitivity analysis", "Confidence bands and multiplier bootstrap for valid simultaneous inference", "DoubleML", "Installing DoubleML", "Getting started", "Double machine learning literature", "Release notes", "DoubleML Workflow"], "titleterms": {"0": 76, "1": 76, "2": 76, "3": 76, "4": 76, "401": [35, 52, 53, 57], "5": 76, "6": 76, "7": 76, "A": [34, 51], "ATE": [49, 54, 58], "No": [34, 51], "One": [34, 41, 42, 51], "The": [35, 52, 54, 60, 61, 73], "acknowledg": 71, "acycl": [32, 39], "addit": 54, "advanc": [64, 68], "algorithm": [59, 69, 71, 73], "altern": 67, "analysi": [49, 57, 69, 76], "api": 0, "applic": [34, 51, 57], "approach": [33, 40, 50, 60], "arbitrari": 54, "arrai": 61, "asset": [35, 52], "att": 44, "augment": 54, "averag": [35, 41, 42, 47, 48, 52, 63], "backend": [34, 35, 51, 52, 61, 73, 76], "band": [68, 70], "base": 36, "basic": [32, 33, 39, 40, 60], "benchmark": [57, 69], "bia": [33, 40, 60], "bonu": 37, "bootstrap": [68, 70], "build": 72, "calcul": [32, 39], "callabl": 67, "case": 38, "cate": [41, 42, 54, 63], "causal": [37, 46, 67, 73, 76], "choic": 50, "citat": 71, "class": [0, 34, 51], "cluster": [34, 51], "code": 71, "combin": 46, "compar": 50, "comput": 50, "conda": 72, "condit": [41, 42, 43, 53, 63, 67], "confid": [68, 70], "construct": 64, "coverag": [44, 46], "cran": 72, "cross": [34, 44, 51, 65, 66, 67, 69, 73], "custom": 50, "cvar": [43, 53, 63, 67], "dag": [32, 39], "data": [0, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 60, 61, 65, 67, 69, 73, 76], "datafram": 61, "dataset": [0, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 37], "debias": [33, 40, 60, 73], "defin": [34, 51], "develop": 72, "dgp": [33, 40], "did": 65, "differ": [44, 45, 50, 65, 67, 68, 69], "dimension": [41, 42], "direct": [32, 39], "distribut": 58, "dml": [34, 37, 51, 66, 73, 76], "dml1": 59, "dml2": 59, "dmldummyclassifi": 29, "dmldummyregressor": 30, "doubl": [0, 33, 34, 40, 51, 59, 60, 71, 73, 74], "double_ml_score_mixin": [27, 28], "doubleml": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 39, 52, 57, 68, 71, 72, 76], "doublemlblp": 1, "doublemlclusterdata": [3, 34, 51], "doublemlcvar": 2, "doublemldata": [6, 35, 52, 61, 73], "doublemldid": 4, "doublemldidc": 5, "doublemliivm": 7, "doublemlirm": 8, "doublemllpq": 9, "doublemlpliv": [10, 34, 51], "doublemlplr": 11, "doublemlpq": 12, "doublemlqt": 13, "effect": [35, 38, 41, 42, 43, 47, 48, 52, 53, 54, 56, 57, 63], "elig": [35, 52], "empir": 46, "ensembl": 36, "error": [34, 51], "estim": [32, 35, 37, 39, 44, 46, 49, 52, 53, 54, 56, 57, 58, 66, 67, 68, 73, 76], "evalu": [50, 64], "exampl": [34, 38, 41, 42, 51, 57], "exploit": 36, "extern": [64, 66], "featur": [36, 71], "fetch_401k": 14, "fetch_bonu": 15, "figur": 54, "file": 72, "financi": [35, 52, 53], "first": 46, "fit": [34, 51, 66, 73], "fold": 66, "forest": 37, "formul": 76, "from": [36, 61, 72], "function": [0, 34, 51, 67, 73], "gain_statist": 31, "gate": [47, 48, 49, 63], "gatet": 49, "gener": [0, 33, 38, 40, 60, 69], "get": 73, "github": 72, "graph": [32, 39], "group": [47, 48, 63], "guid": 62, "helper": [34, 51], "heterogen": [38, 54, 63], "how": 36, "hyperparamet": 64, "iivm": [35, 52, 65, 67], "impact": [35, 52, 53], "implement": [59, 67, 69], "induc": [33, 40, 60], "infer": [68, 70, 76], "initi": [34, 51], "instal": 72, "instrument": [32, 39], "interact": [35, 47, 52, 55, 65, 67, 69], "interv": [68, 70], "invers": 54, "irm": [35, 37, 41, 47, 52, 54, 55, 57, 63, 65, 67, 69], "iv": [32, 35, 39, 52, 65, 67], "joint": 70, "k": [35, 52, 53, 57, 66], "lambda": 46, "lasso": [37, 46], "latest": 72, "lear": [34, 51], "learn": [0, 33, 34, 40, 51, 55, 59, 60, 63, 71, 73, 74], "learner": [36, 37, 50, 64, 73], "linear": [35, 48, 52, 54, 65, 67, 69], "linearscoremixin": 27, "literatur": 74, "load": [34, 37, 51], "loader": 0, "local": [35, 52, 53, 56, 67], "loss": 46, "lpq": [56, 67], "lqte": [53, 56], "m": 66, "machin": [0, 33, 34, 40, 51, 59, 60, 71, 73, 74], "main": 71, "mainten": 71, "make_confounded_irm_data": 16, "make_confounded_plr_data": 17, "make_did_sz2020": 18, "make_heterogeneous_data": 19, "make_iivm_data": 20, "make_irm_data": 21, "make_pliv_chs2015": 22, "make_pliv_multiway_cluster_ckms2021": 23, "make_plr_ccddhnr2018": 24, "make_plr_turrell2018": 25, "make_ssm_data": 26, "mar": 58, "market": [34, 51], "matric": 61, "method": 76, "metric": 50, "minimum": 64, "miss": 58, "missing": [65, 67], "mixin": 0, "ml": [33, 40, 60, 76], "mlr3": 36, "mlr3extralearn": 36, "mlr3learner": 36, "mlr3pipelin": 36, "model": [0, 35, 37, 41, 42, 47, 48, 52, 54, 55, 58, 63, 65, 66, 67, 68, 69, 73, 76], "modul": [0, 37], "more": 36, "motiv": [34, 51], "multipl": 54, "multipli": [68, 70], "naiv": [32, 39], "net": [35, 52], "neyman": [67, 73], "nonignor": [58, 65, 67], "nonlinearscoremixin": 28, "nonrespons": [58, 65, 67], "note": 75, "nuisanc": 73, "object": [34, 51, 57], "orthogon": [33, 40, 60, 67, 73], "out": [33, 40, 60], "outcom": [43, 44, 58, 63], "over": 68, "overcom": [33, 40, 60], "overfit": [33, 40, 60], "overlap": 54, "packag": [35, 52, 72], "panel": [44, 65, 67, 69], "paramet": [36, 37, 67], "partial": [33, 35, 40, 48, 52, 54, 60, 65, 67, 69], "particip": [35, 52], "partit": 66, "penalti": 46, "perform": 54, "pip": 72, "pipelin": 64, "pliv": [65, 67], "plm": 54, "plot": [34, 51], "plr": [35, 37, 42, 48, 52, 63, 65, 67, 69], "polici": [55, 63], "potenti": [43, 53, 56, 63, 67], "pq": [56, 63, 67], "pre": 45, "predict": 64, "preprocess": 36, "problem": 76, "process": [33, 34, 40, 51, 60], "product": [34, 51], "propens": 54, "provid": 66, "python": [38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 64, 72], "qte": [56, 63], "qualiti": 46, "quantil": [53, 56, 63, 67], "r": [32, 33, 34, 35, 36, 38, 64, 72], "random": [37, 58, 65, 67], "rank": 54, "real": [34, 51], "refer": [0, 32, 34, 36, 39, 46, 51, 54, 60, 64, 66, 68, 70, 71, 73], "regress": [35, 47, 48, 52, 55, 65, 67, 69], "regular": [33, 40, 60], "releas": [72, 75], "remov": [33, 40, 60], "repeat": [44, 65, 66, 67, 69], "repetit": 66, "requir": 64, "respect": [34, 51], "result": [34, 35, 51, 52, 54], "risk": [43, 53, 63, 67], "robust": [34, 51], "sampl": [33, 40, 58, 60, 65, 66], "sandbox": 38, "score": [0, 33, 40, 54, 60, 67, 73], "section": [44, 65, 67, 69], "select": [58, 65], "sensit": [49, 57, 69, 76], "set": [36, 64], "simpl": [33, 40, 60], "simul": [32, 34, 39, 44, 51, 57], "simultan": [68, 70], "sourc": [71, 72], "specif": [69, 76], "specifi": [37, 64, 67], "split": [33, 40, 60, 66], "ssm": 65, "stage": 46, "standard": [34, 50, 51], "start": 73, "studi": 38, "summari": [35, 52, 54], "test": 45, "theori": 69, "time": 50, "treatment": [35, 41, 42, 43, 47, 48, 52, 53, 54, 56, 63], "tree": [55, 63], "tune": [36, 64], "two": [34, 41, 42, 51], "under": [54, 58], "up": 36, "us": [32, 36, 37, 39, 64], "user": 62, "util": [0, 29, 30, 31], "v": 46, "valid": [68, 70], "valu": [43, 53, 63, 67], "variabl": [32, 39], "varianc": 68, "version": 72, "via": 67, "wai": [34, 51], "wealth": [35, 52, 53], "weight": [54, 63], "whl": 72, "without": 66, "workflow": 76, "zero": [34, 51]}})