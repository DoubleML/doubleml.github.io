Search.setIndex({"alltitles": {"(One-Way) Cluster Robust Double Machine Learing": [[35, "(One-Way)-Cluster-Robust-Double-Machine-Learing"], [52, "(One-Way)-Cluster-Robust-Double-Machine-Learing"]], "0. Problem Formulation": [[78, "problem-formulation"]], "1. Data-Backend": [[78, "data-backend"]], "1. Formulation of Causal Model & Identification Assumptions": [[59, "1.-Formulation-of-Causal-Model-&-Identification-Assumptions"]], "2. Causal Model": [[78, "causal-model"]], "2. Estimation of Causal Effect": [[59, "2.-Estimation-of-Causal-Effect"]], "3. ML Methods": [[78, "ml-methods"]], "3. Sensitivity Analysis": [[59, "3.-Sensitivity-Analysis"]], "4. Benchmarking Analysis": [[59, "4.-Benchmarking-Analysis"]], "4. DML Specifications": [[78, "dml-specifications"]], "5. Conclusion": [[59, "5.-Conclusion"]], "5. Estimation": [[78, "estimation"]], "6. Inference": [[78, "inference"]], "7. Sensitivity Analysis": [[78, "sensitivity-analysis"]], "A Motivating Example: Two-Way Cluster Robust DML": [[35, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"], [52, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"]], "API reference": [[0, "api-reference"]], "ATE Estimation and Sensitivity": [[50, "ATE-Estimation-and-Sensitivity"]], "ATE estimates distribution": [[60, "ATE-estimates-distribution"], [60, "id3"]], "ATTE Estimation": [[45, "ATTE-Estimation"], [45, "id2"]], "Acknowledgements": [[73, "acknowledgements"]], "Acknowledgements and Final Remarks": [[34, "Acknowledgements-and-Final-Remarks"]], "Additional Results: CATE estimates": [[55, "Additional-Results:-CATE-estimates"]], "Advanced: External Predictions": [[66, "advanced-external-predictions"]], "Algorithm DML1": [[61, "algorithm-dml1"]], "Algorithm DML2": [[61, "algorithm-dml2"]], "Application Results": [[35, "Application-Results"], [52, "Application-Results"]], "Application: 401(k)": [[58, "Application:-401(k)"]], "Benchmarking": [[71, "benchmarking"]], "Benchmarking Analysis": [[58, "Benchmarking-Analysis"]], "CATEs for IRM models": [[65, "cates-for-irm-models"]], "CATEs for PLR models": [[65, "cates-for-plr-models"]], "CVaR Treatment Effects": [[44, "CVaR-Treatment-Effects"]], "CVaR of potential outcomes": [[65, "cvar-of-potential-outcomes"]], "CVaR treatment effects": [[65, "cvar-treatment-effects"]], "Causal Analysis with DoubleML": [[59, "Causal-Analysis-with-DoubleML"]], "Causal estimation vs. lasso penalty \\lambda": [[47, "Causal-estimation-vs.-lasso-penalty-\\lambda"]], "Chernozhukov et al. (2023): Benchmarking": [[59, "Chernozhukov-et-al.-(2023):-Benchmarking"]], "Citation": [[73, "citation"]], "Cluster Robust Cross Fitting": [[35, "Cluster-Robust-Cross-Fitting"], [52, "Cluster-Robust-Cross-Fitting"]], "Cluster Robust Standard Errors": [[35, "Cluster-Robust-Standard-Errors"], [52, "Cluster-Robust-Standard-Errors"]], "Clustering and double machine learning": [[35, "Clustering-and-double-machine-learning"], [52, "Clustering-and-double-machine-learning"]], "Combined loss vs. lasso penalty \\lambda": [[47, "Combined-loss-vs.-lasso-penalty-\\lambda"]], "Comparing different learners": [[51, "Comparing-different-learners"]], "Comparison to did package": [[34, "Comparison-to-did-package"]], "Computation time": [[51, "Computation-time"]], "Conditional Value at Risk (CVaR)": [[44, "Conditional-Value-at-Risk-(CVaR)"]], "Conditional average treatment effects (CATEs)": [[65, "conditional-average-treatment-effects-cates"]], "Conditional value at risk (CVaR)": [[65, "conditional-value-at-risk-cvar"], [69, "conditional-value-at-risk-cvar"]], "Confidence bands and multiplier bootstrap for valid simultaneous inference": [[70, "confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference"], [72, "confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference"]], "Coverage Simulation": [[45, "Coverage-Simulation"], [45, "id3"]], "Cross-fitting with K folds": [[68, "cross-fitting-with-k-folds"]], "Cross-fitting, DML algorithms and Neyman-orthogonal score functions": [[75, "cross-fitting-dml-algorithms-and-neyman-orthogonal-score-functions"]], "Custom evaluation metrics": [[51, "Custom-evaluation-metrics"]], "DML: Bonus Data": [[38, "DML:-Bonus-Data"]], "Data": [[36, "Data"], [42, "Data"], [43, "Data"], [44, "Data"], [45, "Data"], [45, "id1"], [48, "Data"], [49, "Data"], [50, "Data"], [53, "Data"], [54, "Data"], [56, "Data"], [57, "Data"], [57, "id1"], [58, "Data"], [60, "Data"], [60, "id1"], [75, "data"]], "Data Generating Process (DGP)": [[33, "Data-Generating-Process-(DGP)"], [41, "Data-Generating-Process-(DGP)"]], "Data Simulation": [[32, "Data-Simulation"], [40, "Data-Simulation"]], "Data and Effect Estimation": [[58, "Data-and-Effect-Estimation"]], "Data generating process": [[62, "data-generating-process"]], "Data preprocessing": [[37, "Data-preprocessing"]], "Data-Backend for Cluster Data": [[35, "Data-Backend-for-Cluster-Data"], [52, "Data-Backend-for-Cluster-Data"]], "Dataset generators": [[0, "dataset-generators"]], "Dataset loaders": [[0, "dataset-loaders"]], "Datasets module": [[0, "datasets-module"]], "Define Helper Functions for Plotting": [[35, "Define-Helper-Functions-for-Plotting"], [52, "Define-Helper-Functions-for-Plotting"]], "Demo Example from did": [[34, "Demo-Example-from-did"]], "Details on Predictive Performance": [[34, "Details-on-Predictive-Performance"]], "Difference-in-Differences Models (DID)": [[67, "difference-in-differences-models-did"]], "Difference-in-Differences for Panel Data": [[69, "difference-in-differences-for-panel-data"], [71, "difference-in-differences-for-panel-data"]], "Difference-in-Differences for repeated cross-sections": [[69, "difference-in-differences-for-repeated-cross-sections"], [71, "difference-in-differences-for-repeated-cross-sections"]], "Disclaimer": [[59, "Disclaimer"]], "Double Machine Learning Algorithm": [[73, "double-machine-learning-algorithm"]], "Double machine learning algorithms": [[61, "double-machine-learning-algorithms"]], "Double machine learning data class": [[0, "double-machine-learning-data-class"]], "Double machine learning literature": [[76, "double-machine-learning-literature"]], "Double machine learning models": [[0, "double-machine-learning-models"]], "Double/debiased machine learning": [[33, "Double/debiased-machine-learning"], [41, "Double/debiased-machine-learning"], [62, "double-debiased-machine-learning"]], "DoubleML": [[73, "doubleml"]], "DoubleML Object": [[58, "DoubleML-Object"]], "DoubleML Workflow": [[78, "doubleml-workflow"]], "DoubleMLData from arrays and matrices": [[63, "doublemldata-from-arrays-and-matrices"]], "DoubleMLData from dataframes": [[63, "doublemldata-from-dataframes"]], "Effect Heterogeneity": [[39, "effect-heterogeneity"]], "Empirical coverage vs. lasso penalty \\lambda": [[47, "Empirical-coverage-vs.-lasso-penalty-\\lambda"]], "Estimate DML models without sample-splitting": [[68, "estimate-dml-models-without-sample-splitting"]], "Estimate double/debiased machine learning models": [[75, "estimate-double-debiased-machine-learning-models"]], "Estimating Potential Quantiles and Quantile Treatment Effects": [[54, "Estimating-Potential-Quantiles-and-Quantile-Treatment-Effects"]], "Estimating local quantile treatment effects (LQTEs)": [[54, "Estimating-local-quantile-treatment-effects-(LQTEs)"]], "Estimating the Average Treatment Effect of 401(k) Eligibility on Net Financial Assets": [[36, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"], [53, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"]], "Estimating the treatment effect on the Conditional Value a Risk (CVaR)": [[54, "Estimating-the-treatment-effect-on-the-Conditional-Value-a-Risk-(CVaR)"]], "Estimation": [[60, "Estimation"], [60, "id2"]], "Estimation quality vs. \\lambda": [[47, "Estimation-quality-vs.-\\lambda"]], "Evaluate learners": [[66, "evaluate-learners"]], "Example: Sensitivity Analysis for Causal ML": [[59, "Example:-Sensitivity-Analysis-for-Causal-ML"]], "Examples": [[39, "examples"]], "Exploiting the Functionalities of did": [[34, "Exploiting-the-Functionalities-of-did"]], "Externally provide a sample splitting / partition": [[68, "externally-provide-a-sample-splitting-partition"]], "GATE Estimation and Sensitivity": [[50, "GATE-Estimation-and-Sensitivity"]], "GATET Estimation and Sensitivity": [[50, "GATET-Estimation-and-Sensitivity"]], "GATEs for IRM models": [[65, "gates-for-irm-models"]], "GATEs for PLR models": [[65, "gates-for-plr-models"]], "General Examples": [[39, "general-examples"]], "General algorithm": [[71, "general-algorithm"]], "Getting started": [[75, "getting-started"]], "Group Average Treatment Effects (GATEs)": [[48, "Group-Average-Treatment-Effects-(GATEs)"], [49, "Group-Average-Treatment-Effects-(GATEs)"]], "Group average treatment effects (GATEs)": [[65, "group-average-treatment-effects-gates"]], "Heterogeneous treatment effects": [[65, "heterogeneous-treatment-effects"]], "How to exploit more features of mlr3pipelines in DoubleML": [[37, "How-to-exploit-more-features-of-mlr3pipelines-in-DoubleML"]], "Hyperparameter tuning": [[66, "hyperparameter-tuning"], [66, "id16"]], "Hyperparameter tuning with pipelines": [[66, "hyperparameter-tuning-with-pipelines"]], "Implementation": [[71, "implementation"]], "Implementation of the double machine learning algorithms": [[61, "implementation-of-the-double-machine-learning-algorithms"]], "Implementation of the score function and the estimate of the causal parameter": [[69, "implementation-of-the-score-function-and-the-estimate-of-the-causal-parameter"]], "Implemented Neyman orthogonal score functions": [[69, "implemented-neyman-orthogonal-score-functions"]], "Initialize DoubleMLClusterData object": [[35, "Initialize-DoubleMLClusterData-object"], [52, "Initialize-DoubleMLClusterData-object"]], "Initialize the objects of class DoubleMLPLIV": [[35, "Initialize-the-objects-of-class-DoubleMLPLIV"], [52, "Initialize-the-objects-of-class-DoubleMLPLIV"]], "Installing DoubleML": [[74, "installing-doubleml"]], "Instrumental Variables Directed Acyclic Graph (IV - DAG)": [[32, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"], [40, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"]], "Interactive IV Model (IIVM)": [[36, "Interactive-IV-Model-(IIVM)"], [53, "Interactive-IV-Model-(IIVM)"]], "Interactive IV model (IIVM)": [[67, "interactive-iv-model-iivm"], [69, "interactive-iv-model-iivm"]], "Interactive Regression Model (IRM)": [[36, "Interactive-Regression-Model-(IRM)"], [48, "Interactive-Regression-Model-(IRM)"], [53, "Interactive-Regression-Model-(IRM)"], [56, "Interactive-Regression-Model-(IRM)"]], "Interactive regression model (IRM)": [[67, "interactive-regression-model-irm"], [69, "interactive-regression-model-irm"], [71, "interactive-regression-model-irm"]], "Learners to estimate the nuisance models": [[75, "learners-to-estimate-the-nuisance-models"]], "Learners, hyperparameters and hyperparameter tuning": [[66, "learners-hyperparameters-and-hyperparameter-tuning"]], "Load Data": [[59, "Load-Data"]], "Load and Process Data": [[35, "Load-and-Process-Data"], [52, "Load-and-Process-Data"]], "Load bonus data using the dml datasets module": [[38, "Load-bonus-data-using-the-dml-datasets-module"]], "Local Average Treatment Effects of 401(k) Participation on Net Financial Assets": [[36, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"], [53, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"]], "Local Potential Quantile Estimation": [[57, "Local-Potential-Quantile-Estimation"]], "Local Potential Quantiles (LPQs)": [[57, "Local-Potential-Quantiles-(LPQs)"]], "Local Quantile Treatment Effects (LQTEs)": [[57, "Local-Quantile-Treatment-Effects-(LQTEs)"]], "Local potential quantiles (LPQs)": [[69, "local-potential-quantiles-lpqs"]], "Main Features": [[73, "main-features"]], "Minimum requirements for learners": [[66, "minimum-requirements-for-learners"], [66, "id2"]], "Missingness at Random": [[67, "missingness-at-random"], [69, "missingness-at-random"]], "Model-specific implementations": [[71, "model-specific-implementations"]], "Models": [[67, "models"]], "Motivation": [[35, "Motivation"], [52, "Motivation"]], "Multiplier bootstrap and joint confidence intervals": [[72, "multiplier-bootstrap-and-joint-confidence-intervals"]], "Naive estimation": [[32, "Naive-estimation"], [40, "Naive-estimation"]], "No Clustering / Zero-Way Clustering": [[35, "No-Clustering-/-Zero-Way-Clustering"], [52, "No-Clustering-/-Zero-Way-Clustering"]], "Nonignorable Nonresponse": [[67, "nonignorable-nonresponse"], [69, "nonignorable-nonresponse"]], "One-Way Clustering with Respect to the Market": [[35, "One-Way-Clustering-with-Respect-to-the-Market"], [52, "One-Way-Clustering-with-Respect-to-the-Market"]], "One-Way Clustering with Respect to the Product": [[35, "One-Way-Clustering-with-Respect-to-the-Product"], [52, "One-Way-Clustering-with-Respect-to-the-Product"]], "One-dimensional Example": [[42, "One-dimensional-Example"], [43, "One-dimensional-Example"]], "Outcome missing at random (MAR)": [[60, "Outcome-missing-at-random-(MAR)"]], "Outcome missing under nonignorable nonresponse": [[60, "Outcome-missing-under-nonignorable-nonresponse"]], "Overcoming regularization bias by orthogonalization": [[33, "Overcoming-regularization-bias-by-orthogonalization"], [41, "Overcoming-regularization-bias-by-orthogonalization"], [62, "overcoming-regularization-bias-by-orthogonalization"]], "Panel Data (Repeated Outcomes)": [[45, "Panel-Data-(Repeated-Outcomes)"]], "Panel data": [[67, "panel-data"]], "Parameter tuning": [[37, "Parameter-tuning"]], "Partialling out score": [[33, "Partialling-out-score"], [41, "Partialling-out-score"], [62, "partialling-out-score"]], "Partially Linear Regression Model (PLR)": [[36, "Partially-Linear-Regression-Model-(PLR)"], [49, "Partially-Linear-Regression-Model-(PLR)"], [53, "Partially-Linear-Regression-Model-(PLR)"]], "Partially linear IV regression model (PLIV)": [[67, "partially-linear-iv-regression-model-pliv"], [69, "partially-linear-iv-regression-model-pliv"]], "Partially linear regression model (PLR)": [[67, "partially-linear-regression-model-plr"], [69, "partially-linear-regression-model-plr"], [71, "partially-linear-regression-model-plr"]], "Policy Learning with Trees": [[56, "Policy-Learning-with-Trees"], [65, "policy-learning-with-trees"]], "Potential Quantile Estimation": [[57, "Potential-Quantile-Estimation"]], "Potential Quantiles (PQs)": [[57, "Potential-Quantiles-(PQs)"]], "Potential quantiles (PQs)": [[65, "potential-quantiles-pqs"], [69, "potential-quantiles-pqs"]], "Python: Basic Instrumental Variables calculation": [[40, "Python:-Basic-Instrumental-Variables-calculation"]], "Python: Basics of Double Machine Learning": [[41, "Python:-Basics-of-Double-Machine-Learning"]], "Python: Building the package from source": [[74, "python-building-the-package-from-source"]], "Python: Case studies": [[39, "python-case-studies"]], "Python: Choice of learners": [[51, "Python:-Choice-of-learners"]], "Python: Cluster Robust Double Machine Learning": [[52, "Python:-Cluster-Robust-Double-Machine-Learning"]], "Python: Conditional Average Treatment Effects (CATEs) for IRM models": [[42, "Python:-Conditional-Average-Treatment-Effects-(CATEs)-for-IRM-models"]], "Python: Conditional Average Treatment Effects (CATEs) for PLR models": [[43, "Python:-Conditional-Average-Treatment-Effects-(CATEs)-for-PLR-models"]], "Python: Conditional Value at Risk of potential outcomes": [[44, "Python:-Conditional-Value-at-Risk-of-potential-outcomes"]], "Python: Difference-in-Differences": [[45, "Python:-Difference-in-Differences"]], "Python: Difference-in-Differences Pre-Testing": [[46, "Python:-Difference-in-Differences-Pre-Testing"]], "Python: First Stage and Causal Estimation": [[47, "Python:-First-Stage-and-Causal-Estimation"]], "Python: GATE Sensitivity Analysis": [[50, "Python:-GATE-Sensitivity-Analysis"]], "Python: Group Average Treatment Effects (GATEs) for IRM models": [[48, "Python:-Group-Average-Treatment-Effects-(GATEs)-for-IRM-models"]], "Python: Group Average Treatment Effects (GATEs) for PLR models": [[49, "Python:-Group-Average-Treatment-Effects-(GATEs)-for-PLR-models"]], "Python: Impact of 401(k) on Financial Wealth": [[53, "Python:-Impact-of-401(k)-on-Financial-Wealth"]], "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)": [[54, "Python:-Impact-of-401(k)-on-Financial-Wealth-(Quantile-Effects)"]], "Python: Installing DoubleML": [[74, "python-installing-doubleml"]], "Python: Installing a released version from a .whl file": [[74, "python-installing-a-released-version-from-a-whl-file"]], "Python: Installing the latest release from pip or conda": [[74, "python-installing-the-latest-release-from-pip-or-conda"]], "Python: Learners and hyperparameters": [[66, "python-learners-and-hyperparameters"]], "Python: PLM and IRM for Multiple Treatments": [[55, "Python:-PLM-and-IRM-for-Multiple-Treatments"]], "Python: Policy Learning with Trees": [[56, "Python:-Policy-Learning-with-Trees"]], "Python: Potential Quantiles and Quantile Treatment Effects": [[57, "Python:-Potential-Quantiles-and-Quantile-Treatment-Effects"]], "Python: Sample Selection Models": [[60, "Python:-Sample-Selection-Models"]], "Python: Sensitivity Analysis": [[58, "Python:-Sensitivity-Analysis"]], "Quantile Treatment Effects (QTEs)": [[57, "Quantile-Treatment-Effects-(QTEs)"]], "Quantile treatment effects (QTEs)": [[65, "quantile-treatment-effects-qtes"]], "Quantiles": [[65, "quantiles"]], "R: Basic Instrumental Variables Calculation": [[32, "R:-Basic-Instrumental-Variables-Calculation"]], "R: Basics of Double Machine Learning": [[33, "R:-Basics-of-Double-Machine-Learning"]], "R: Case studies": [[39, "r-case-studies"]], "R: Cluster Robust Double Machine Learning": [[35, "R:-Cluster-Robust-Double-Machine-Learning"]], "R: DoubleML for Difference-in-Differences": [[34, "R:-DoubleML-for-Difference-in-Differences"]], "R: Ensemble Learners and More with mlr3pipelines": [[37, "R:-Ensemble-Learners-and-More-with-mlr3pipelines"]], "R: Impact of 401(k) on Financial Wealth": [[36, "R:-Impact-of-401(k)-on-Financial-Wealth"]], "R: Installing DoubleML": [[74, "r-installing-doubleml"]], "R: Installing the development version from GitHub": [[74, "r-installing-the-development-version-from-github"]], "R: Installing the latest release from CRAN": [[74, "r-installing-the-latest-release-from-cran"]], "R: Learners and hyperparameters": [[66, "r-learners-and-hyperparameters"]], "Ranking Treatment Effects under Treatment Propensity and Treatment Effect Heterogeneity": [[55, "Ranking-Treatment-Effects-under-Treatment-Propensity-and-Treatment-Effect-Heterogeneity"]], "Real-Data Application": [[35, "Real-Data-Application"], [52, "Real-Data-Application"]], "References": [[32, "References"], [34, "References"], [35, "References"], [37, "References"], [40, "References"], [47, "References"], [52, "References"], [55, "References"], [59, "References"], [62, "references"], [66, "references"], [68, "references"], [70, "references"], [72, "references"], [73, "references"], [75, "references"]], "Regularization Bias in Simple ML-Approaches": [[33, "Regularization-Bias-in-Simple-ML-Approaches"], [41, "Regularization-Bias-in-Simple-ML-Approaches"]], "Regularization bias in simple ML-approaches": [[62, "regularization-bias-in-simple-ml-approaches"]], "Release notes": [[77, "release-notes"]], "Repeated Cross-Sectional Data": [[45, "Repeated-Cross-Sectional-Data"]], "Repeated cross-fitting with K folds and M repetitions": [[68, "repeated-cross-fitting-with-k-folds-and-m-repetitions"]], "Repeated cross-sections": [[67, "repeated-cross-sections"]], "Sample Selection Models (SSM)": [[67, "sample-selection-models-ssm"]], "Sample splitting to remove bias induced by overfitting": [[33, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [41, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [62, "sample-splitting-to-remove-bias-induced-by-overfitting"]], "Sample-splitting without cross-fitting": [[68, "sample-splitting-without-cross-fitting"]], "Sample-splitting, cross-fitting and repeated cross-fitting": [[68, "sample-splitting-cross-fitting-and-repeated-cross-fitting"]], "Sandbox": [[39, "sandbox"]], "Score functions": [[69, "score-functions"]], "Score mixin classes for double machine learning models": [[0, "score-mixin-classes-for-double-machine-learning-models"]], "Sensitivity Analysis": [[58, "Sensitivity-Analysis"], [58, "id1"]], "Sensitivity Analysis with IRM": [[58, "Sensitivity-Analysis-with-IRM"]], "Sensitivity analysis": [[71, "sensitivity-analysis"]], "Set up learners based on mlr3pipelines": [[37, "Set-up-learners-based-on-mlr3pipelines"]], "Simulate two-way cluster data": [[35, "Simulate-two-way-cluster-data"], [52, "Simulate-two-way-cluster-data"]], "Simulation Example": [[58, "Simulation-Example"]], "Simultaneous inference over different DoubleML models (advanced)": [[70, "simultaneous-inference-over-different-doubleml-models-advanced"]], "Source code and maintenance": [[73, "source-code-and-maintenance"]], "Specify learner and estimate causal parameter: IRM model with Lasso as learner": [[38, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: IRM model with random forest as learner": [[38, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-random-forest-as-learner"]], "Specify learner and estimate causal parameter: PLR model with Lasso as learner": [[38, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: PLR model with random forest as learner": [[38, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-random-forest-as-learner"]], "Specifying alternative score functions via callables": [[69, "specifying-alternative-score-functions-via-callables"]], "Specifying learners and set hyperparameters": [[66, "specifying-learners-and-set-hyperparameters"], [66, "id9"]], "Standard approach": [[51, "Standard-approach"]], "Summary Figure": [[55, "Summary-Figure"]], "Summary of Results": [[36, "Summary-of-Results"], [53, "Summary-of-Results"]], "The Augmented Inverse Propensity Weighting Model estimates the ATE under arbitrary effect and propensity score heterogeneity": [[55, "The-Augmented-Inverse-Propensity-Weighting-Model-estimates-the-ATE-under-arbitrary-effect-and-propensity-score-heterogeneity"]], "The Data Backend: DoubleMLData": [[36, "The-Data-Backend:-DoubleMLData"], [53, "The-Data-Backend:-DoubleMLData"]], "The DoubleML package": [[36, "The-DoubleML-package"], [53, "The-DoubleML-package"]], "The Partially Linear Model performs overlap weighting": [[55, "The-Partially-Linear-Model-performs-overlap-weighting"]], "The basics of double/debiased machine learning": [[62, "the-basics-of-double-debiased-machine-learning"]], "The causal model": [[75, "the-causal-model"]], "The data-backend DoubleMLData": [[63, "the-data-backend-doublemldata"], [75, "the-data-backend-doublemldata"]], "Theory": [[71, "theory"]], "Two-Dimensional Example": [[42, "Two-Dimensional-Example"], [43, "Two-Dimensional-Example"]], "Two-Way Clustering with Respect to Product and Market": [[35, "Two-Way-Clustering-with-Respect-to-Product-and-Market"], [52, "Two-Way-Clustering-with-Respect-to-Product-and-Market"]], "Use ensemble learners based on mlr3pipelines": [[37, "Use-ensemble-learners-based-on-mlr3pipelines"]], "User guide": [[64, "user-guide"]], "Using DoubleML": [[32, "Using-DoubleML"], [40, "Using-DoubleML"]], "Using ML for DiD: Integrating DoubleML in did": [[34, "Using-ML-for-DiD:-Integrating-DoubleML-in-did"]], "Using learners from mlr3, mlr3learners and mlr3extralearners": [[37, "Using-learners-from-mlr3,-mlr3learners-and-mlr3extralearners"]], "Using pipelines to construct learners": [[66, "using-pipelines-to-construct-learners"]], "Utility classes": [[0, "utility-classes"]], "Utility classes and functions": [[0, "utility-classes-and-functions"]], "Utility functions": [[0, "utility-functions"]], "VanderWeele and Arah (2011): Benchmarking": [[59, "VanderWeele-and-Arah-(2011):-Benchmarking"]], "Variance estimation": [[70, "variance-estimation"]], "Variance estimation and confidence intervals": [[70, "variance-estimation-and-confidence-intervals"]], "Weighted Average Treatment Effects": [[65, "weighted-average-treatment-effects"]], "doubleml.DoubleMLBLP": [[1, "doubleml-doublemlblp"]], "doubleml.DoubleMLCVAR": [[2, "doubleml-doublemlcvar"]], "doubleml.DoubleMLClusterData": [[3, "doubleml-doublemlclusterdata"]], "doubleml.DoubleMLDID": [[4, "doubleml-doublemldid"]], "doubleml.DoubleMLDIDCS": [[5, "doubleml-doublemldidcs"]], "doubleml.DoubleMLData": [[6, "doubleml-doublemldata"]], "doubleml.DoubleMLIIVM": [[7, "doubleml-doublemliivm"]], "doubleml.DoubleMLIRM": [[8, "doubleml-doublemlirm"]], "doubleml.DoubleMLLPQ": [[9, "doubleml-doublemllpq"]], "doubleml.DoubleMLPLIV": [[10, "doubleml-doublemlpliv"]], "doubleml.DoubleMLPLR": [[11, "doubleml-doublemlplr"]], "doubleml.DoubleMLPQ": [[12, "doubleml-doublemlpq"]], "doubleml.DoubleMLQTE": [[13, "doubleml-doublemlqte"]], "doubleml.datasets.fetch_401K": [[14, "doubleml-datasets-fetch-401k"]], "doubleml.datasets.fetch_bonus": [[15, "doubleml-datasets-fetch-bonus"]], "doubleml.datasets.make_confounded_irm_data": [[16, "doubleml-datasets-make-confounded-irm-data"]], "doubleml.datasets.make_confounded_plr_data": [[17, "doubleml-datasets-make-confounded-plr-data"]], "doubleml.datasets.make_did_SZ2020": [[18, "doubleml-datasets-make-did-sz2020"]], "doubleml.datasets.make_heterogeneous_data": [[19, "doubleml-datasets-make-heterogeneous-data"]], "doubleml.datasets.make_iivm_data": [[20, "doubleml-datasets-make-iivm-data"]], "doubleml.datasets.make_irm_data": [[21, "doubleml-datasets-make-irm-data"]], "doubleml.datasets.make_pliv_CHS2015": [[22, "doubleml-datasets-make-pliv-chs2015"]], "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021": [[23, "doubleml-datasets-make-pliv-multiway-cluster-ckms2021"]], "doubleml.datasets.make_plr_CCDDHNR2018": [[24, "doubleml-datasets-make-plr-ccddhnr2018"]], "doubleml.datasets.make_plr_turrell2018": [[25, "doubleml-datasets-make-plr-turrell2018"]], "doubleml.datasets.make_ssm_data": [[26, "doubleml-datasets-make-ssm-data"]], "doubleml.double_ml_score_mixins.LinearScoreMixin": [[27, "doubleml-double-ml-score-mixins-linearscoremixin"]], "doubleml.double_ml_score_mixins.NonLinearScoreMixin": [[28, "doubleml-double-ml-score-mixins-nonlinearscoremixin"]], "doubleml.utils.DMLDummyClassifier": [[29, "doubleml-utils-dmldummyclassifier"]], "doubleml.utils.DMLDummyRegressor": [[30, "doubleml-utils-dmldummyregressor"]], "doubleml.utils.gain_statistics": [[31, "doubleml-utils-gain-statistics"]]}, "docnames": ["api/api", "api/generated/doubleml.DoubleMLBLP", "api/generated/doubleml.DoubleMLCVAR", "api/generated/doubleml.DoubleMLClusterData", "api/generated/doubleml.DoubleMLDID", "api/generated/doubleml.DoubleMLDIDCS", "api/generated/doubleml.DoubleMLData", "api/generated/doubleml.DoubleMLIIVM", "api/generated/doubleml.DoubleMLIRM", "api/generated/doubleml.DoubleMLLPQ", "api/generated/doubleml.DoubleMLPLIV", "api/generated/doubleml.DoubleMLPLR", "api/generated/doubleml.DoubleMLPQ", "api/generated/doubleml.DoubleMLQTE", "api/generated/doubleml.datasets.fetch_401K", "api/generated/doubleml.datasets.fetch_bonus", "api/generated/doubleml.datasets.make_confounded_irm_data", "api/generated/doubleml.datasets.make_confounded_plr_data", "api/generated/doubleml.datasets.make_did_SZ2020", "api/generated/doubleml.datasets.make_heterogeneous_data", "api/generated/doubleml.datasets.make_iivm_data", "api/generated/doubleml.datasets.make_irm_data", "api/generated/doubleml.datasets.make_pliv_CHS2015", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018", "api/generated/doubleml.datasets.make_plr_turrell2018", "api/generated/doubleml.datasets.make_ssm_data", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin", "api/generated/doubleml.utils.DMLDummyClassifier", "api/generated/doubleml.utils.DMLDummyRegressor", "api/generated/doubleml.utils.gain_statistics", "examples/R_double_ml_basic_iv", "examples/R_double_ml_basics", "examples/R_double_ml_did", "examples/R_double_ml_multiway_cluster", "examples/R_double_ml_pension", "examples/R_double_ml_pipeline", "examples/double_ml_bonus_data", "examples/index", "examples/py_double_ml_basic_iv", "examples/py_double_ml_basics", "examples/py_double_ml_cate", "examples/py_double_ml_cate_plr", "examples/py_double_ml_cvar", "examples/py_double_ml_did", "examples/py_double_ml_did_pretest", "examples/py_double_ml_firststage", "examples/py_double_ml_gate", "examples/py_double_ml_gate_plr", "examples/py_double_ml_gate_sensitivity", "examples/py_double_ml_learner", "examples/py_double_ml_multiway_cluster", "examples/py_double_ml_pension", "examples/py_double_ml_pension_qte", "examples/py_double_ml_plm_irm_hetfx", "examples/py_double_ml_policy_tree", "examples/py_double_ml_pq", "examples/py_double_ml_sensitivity", "examples/py_double_ml_sensitivity_booking", "examples/py_double_ml_ssm", "guide/algorithms", "guide/basics", "guide/data_backend", "guide/guide", "guide/heterogeneity", "guide/learners", "guide/models", "guide/resampling", "guide/scores", "guide/se_confint", "guide/sensitivity", "guide/sim_inf", "index", "intro/install", "intro/intro", "literature/literature", "release/release", "workflow/workflow"], "envversion": {"nbsphinx": 4, "sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["api/api.rst", "api/generated/doubleml.DoubleMLBLP.rst", "api/generated/doubleml.DoubleMLCVAR.rst", "api/generated/doubleml.DoubleMLClusterData.rst", "api/generated/doubleml.DoubleMLDID.rst", "api/generated/doubleml.DoubleMLDIDCS.rst", "api/generated/doubleml.DoubleMLData.rst", "api/generated/doubleml.DoubleMLIIVM.rst", "api/generated/doubleml.DoubleMLIRM.rst", "api/generated/doubleml.DoubleMLLPQ.rst", "api/generated/doubleml.DoubleMLPLIV.rst", "api/generated/doubleml.DoubleMLPLR.rst", "api/generated/doubleml.DoubleMLPQ.rst", "api/generated/doubleml.DoubleMLQTE.rst", "api/generated/doubleml.datasets.fetch_401K.rst", "api/generated/doubleml.datasets.fetch_bonus.rst", "api/generated/doubleml.datasets.make_confounded_irm_data.rst", "api/generated/doubleml.datasets.make_confounded_plr_data.rst", "api/generated/doubleml.datasets.make_did_SZ2020.rst", "api/generated/doubleml.datasets.make_heterogeneous_data.rst", "api/generated/doubleml.datasets.make_iivm_data.rst", "api/generated/doubleml.datasets.make_irm_data.rst", "api/generated/doubleml.datasets.make_pliv_CHS2015.rst", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021.rst", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018.rst", "api/generated/doubleml.datasets.make_plr_turrell2018.rst", "api/generated/doubleml.datasets.make_ssm_data.rst", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin.rst", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin.rst", "api/generated/doubleml.utils.DMLDummyClassifier.rst", "api/generated/doubleml.utils.DMLDummyRegressor.rst", "api/generated/doubleml.utils.gain_statistics.rst", "examples/R_double_ml_basic_iv.ipynb", "examples/R_double_ml_basics.ipynb", "examples/R_double_ml_did.ipynb", "examples/R_double_ml_multiway_cluster.ipynb", "examples/R_double_ml_pension.ipynb", "examples/R_double_ml_pipeline.ipynb", "examples/double_ml_bonus_data.ipynb", "examples/index.rst", "examples/py_double_ml_basic_iv.ipynb", "examples/py_double_ml_basics.ipynb", "examples/py_double_ml_cate.ipynb", "examples/py_double_ml_cate_plr.ipynb", "examples/py_double_ml_cvar.ipynb", "examples/py_double_ml_did.ipynb", "examples/py_double_ml_did_pretest.ipynb", "examples/py_double_ml_firststage.ipynb", "examples/py_double_ml_gate.ipynb", "examples/py_double_ml_gate_plr.ipynb", "examples/py_double_ml_gate_sensitivity.ipynb", "examples/py_double_ml_learner.ipynb", "examples/py_double_ml_multiway_cluster.ipynb", "examples/py_double_ml_pension.ipynb", "examples/py_double_ml_pension_qte.ipynb", "examples/py_double_ml_plm_irm_hetfx.ipynb", "examples/py_double_ml_policy_tree.ipynb", "examples/py_double_ml_pq.ipynb", "examples/py_double_ml_sensitivity.ipynb", "examples/py_double_ml_sensitivity_booking.ipynb", "examples/py_double_ml_ssm.ipynb", "guide/algorithms.rst", "guide/basics.rst", "guide/data_backend.rst", "guide/guide.rst", "guide/heterogeneity.rst", "guide/learners.rst", "guide/models.rst", "guide/resampling.rst", "guide/scores.rst", "guide/se_confint.rst", "guide/sensitivity.rst", "guide/sim_inf.rst", "index.rst", "intro/install.rst", "intro/intro.rst", "literature/literature.rst", "release/release.rst", "workflow/workflow.rst"], "indexentries": {"bootstrap() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.bootstrap", false]], "bootstrap() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.bootstrap", false]], "bootstrap() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.bootstrap", false]], "bootstrap() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.bootstrap", false]], "bootstrap() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.bootstrap", false]], "bootstrap() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.bootstrap", false]], "bootstrap() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.bootstrap", false]], "bootstrap() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.bootstrap", false]], "bootstrap() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.bootstrap", false]], "bootstrap() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.bootstrap", false]], "cate() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.cate", false]], "cate() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.cate", false]], "confint() (doubleml.doublemlblp method)": [[1, "doubleml.DoubleMLBLP.confint", false]], "confint() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.confint", false]], "confint() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.confint", false]], "confint() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.confint", false]], "confint() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.confint", false]], "confint() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.confint", false]], "confint() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.confint", false]], "confint() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.confint", false]], "confint() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.confint", false]], "confint() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.confint", false]], "confint() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.confint", false]], "construct_framework() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.construct_framework", false]], "construct_framework() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.construct_framework", false]], "construct_framework() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.construct_framework", false]], "construct_framework() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.construct_framework", false]], "construct_framework() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.construct_framework", false]], "construct_framework() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.construct_framework", false]], "construct_framework() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.construct_framework", false]], "construct_framework() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.construct_framework", false]], "construct_framework() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.construct_framework", false]], "dmldummyclassifier (class in doubleml.utils)": [[29, "doubleml.utils.DMLDummyClassifier", false]], "dmldummyregressor (class in doubleml.utils)": [[30, "doubleml.utils.DMLDummyRegressor", false]], "doublemlblp (class in doubleml)": [[1, "doubleml.DoubleMLBLP", false]], "doublemlclusterdata (class in doubleml)": [[3, "doubleml.DoubleMLClusterData", false]], "doublemlcvar (class in doubleml)": [[2, "doubleml.DoubleMLCVAR", false]], "doublemldata (class in doubleml)": [[6, "doubleml.DoubleMLData", false]], "doublemldid (class in doubleml)": [[4, "doubleml.DoubleMLDID", false]], "doublemldidcs (class in doubleml)": [[5, "doubleml.DoubleMLDIDCS", false]], "doublemliivm (class in doubleml)": [[7, "doubleml.DoubleMLIIVM", false]], "doublemlirm (class in doubleml)": [[8, "doubleml.DoubleMLIRM", false]], "doublemllpq (class in doubleml)": [[9, "doubleml.DoubleMLLPQ", false]], "doublemlpliv (class in doubleml)": [[10, "doubleml.DoubleMLPLIV", false]], "doublemlplr (class in doubleml)": [[11, "doubleml.DoubleMLPLR", false]], "doublemlpq (class in doubleml)": [[12, "doubleml.DoubleMLPQ", false]], "doublemlqte (class in doubleml)": [[13, "doubleml.DoubleMLQTE", false]], "draw_sample_splitting() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.draw_sample_splitting", false]], "evaluate_learners() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.evaluate_learners", false]], "fetch_401k() (in module doubleml.datasets)": [[14, "doubleml.datasets.fetch_401K", false]], "fetch_bonus() (in module doubleml.datasets)": [[15, "doubleml.datasets.fetch_bonus", false]], "fit() (doubleml.doublemlblp method)": [[1, "doubleml.DoubleMLBLP.fit", false]], "fit() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.fit", false]], "fit() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.fit", false]], "fit() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.fit", false]], "fit() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.fit", false]], "fit() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.fit", false]], "fit() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.fit", false]], "fit() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.fit", false]], "fit() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.fit", false]], "fit() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.fit", false]], "fit() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.fit", false]], "fit() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.fit", false]], "fit() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.fit", false]], "from_arrays() (doubleml.doublemlclusterdata class method)": [[3, "doubleml.DoubleMLClusterData.from_arrays", false]], "from_arrays() (doubleml.doublemldata class method)": [[6, "doubleml.DoubleMLData.from_arrays", false]], "gain_statistics() (in module doubleml.utils)": [[31, "doubleml.utils.gain_statistics", false]], "gate() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.gate", false]], "gate() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.gate", false]], "get_metadata_routing() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.get_metadata_routing", false]], "get_metadata_routing() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.get_metadata_routing", false]], "get_params() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.get_params", false]], "get_params() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.get_params", false]], "get_params() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.get_params", false]], "get_params() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.get_params", false]], "get_params() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.get_params", false]], "get_params() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.get_params", false]], "get_params() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.get_params", false]], "get_params() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.get_params", false]], "get_params() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.get_params", false]], "get_params() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.get_params", false]], "get_params() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.get_params", false]], "linearscoremixin (class in doubleml.double_ml_score_mixins)": [[27, "doubleml.double_ml_score_mixins.LinearScoreMixin", false]], "make_confounded_irm_data() (in module doubleml.datasets)": [[16, "doubleml.datasets.make_confounded_irm_data", false]], "make_confounded_plr_data() (in module doubleml.datasets)": [[17, "doubleml.datasets.make_confounded_plr_data", false]], "make_did_sz2020() (in module doubleml.datasets)": [[18, "doubleml.datasets.make_did_SZ2020", false]], "make_heterogeneous_data() (in module doubleml.datasets)": [[19, "doubleml.datasets.make_heterogeneous_data", false]], "make_iivm_data() (in module doubleml.datasets)": [[20, "doubleml.datasets.make_iivm_data", false]], "make_irm_data() (in module doubleml.datasets)": [[21, "doubleml.datasets.make_irm_data", false]], "make_pliv_chs2015() (in module doubleml.datasets)": [[22, "doubleml.datasets.make_pliv_CHS2015", false]], "make_pliv_multiway_cluster_ckms2021() (in module doubleml.datasets)": [[23, "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", false]], "make_plr_ccddhnr2018() (in module doubleml.datasets)": [[24, "doubleml.datasets.make_plr_CCDDHNR2018", false]], "make_plr_turrell2018() (in module doubleml.datasets)": [[25, "doubleml.datasets.make_plr_turrell2018", false]], "make_ssm_data() (in module doubleml.datasets)": [[26, "doubleml.datasets.make_ssm_data", false]], "nonlinearscoremixin (class in doubleml.double_ml_score_mixins)": [[28, "doubleml.double_ml_score_mixins.NonLinearScoreMixin", false]], "p_adjust() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.p_adjust", false]], "p_adjust() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.p_adjust", false]], "p_adjust() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.p_adjust", false]], "p_adjust() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.p_adjust", false]], "p_adjust() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.p_adjust", false]], "p_adjust() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.p_adjust", false]], "p_adjust() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.p_adjust", false]], "p_adjust() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.p_adjust", false]], "p_adjust() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.p_adjust", false]], "p_adjust() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.p_adjust", false]], "policy_tree() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.policy_tree", false]], "predict() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.predict", false]], "predict() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.predict", false]], "predict_proba() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.predict_proba", false]], "sensitivity_analysis() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.sensitivity_analysis", false]], "sensitivity_benchmark() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.sensitivity_benchmark", false]], "sensitivity_plot() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.sensitivity_plot", false]], "set_ml_nuisance_params() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.set_ml_nuisance_params", false]], "set_params() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.set_params", false]], "set_params() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.set_params", false]], "set_sample_splitting() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.set_sample_splitting", false]], "set_x_d() (doubleml.doublemlclusterdata method)": [[3, "doubleml.DoubleMLClusterData.set_x_d", false]], "set_x_d() (doubleml.doublemldata method)": [[6, "doubleml.DoubleMLData.set_x_d", false]], "tune() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.tune", false]], "tune() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.tune", false]], "tune() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.tune", false]], "tune() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.tune", false]], "tune() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.tune", false]], "tune() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.tune", false]], "tune() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.tune", false]], "tune() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.tune", false]], "tune() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.tune", false]]}, "objects": {"doubleml": [[1, 0, 1, "", "DoubleMLBLP"], [2, 0, 1, "", "DoubleMLCVAR"], [3, 0, 1, "", "DoubleMLClusterData"], [4, 0, 1, "", "DoubleMLDID"], [5, 0, 1, "", "DoubleMLDIDCS"], [6, 0, 1, "", "DoubleMLData"], [7, 0, 1, "", "DoubleMLIIVM"], [8, 0, 1, "", "DoubleMLIRM"], [9, 0, 1, "", "DoubleMLLPQ"], [10, 0, 1, "", "DoubleMLPLIV"], [11, 0, 1, "", "DoubleMLPLR"], [12, 0, 1, "", "DoubleMLPQ"], [13, 0, 1, "", "DoubleMLQTE"]], "doubleml.DoubleMLBLP": [[1, 1, 1, "", "confint"], [1, 1, 1, "", "fit"]], "doubleml.DoubleMLCVAR": [[2, 1, 1, "", "bootstrap"], [2, 1, 1, "", "confint"], [2, 1, 1, "", "construct_framework"], [2, 1, 1, "", "draw_sample_splitting"], [2, 1, 1, "", "evaluate_learners"], [2, 1, 1, "", "fit"], [2, 1, 1, "", "get_params"], [2, 1, 1, "", "p_adjust"], [2, 1, 1, "", "sensitivity_analysis"], [2, 1, 1, "", "sensitivity_benchmark"], [2, 1, 1, "", "sensitivity_plot"], [2, 1, 1, "", "set_ml_nuisance_params"], [2, 1, 1, "", "set_sample_splitting"], [2, 1, 1, "", "tune"]], "doubleml.DoubleMLClusterData": [[3, 1, 1, "", "from_arrays"], [3, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLDID": [[4, 1, 1, "", "bootstrap"], [4, 1, 1, "", "confint"], [4, 1, 1, "", "construct_framework"], [4, 1, 1, "", "draw_sample_splitting"], [4, 1, 1, "", "evaluate_learners"], [4, 1, 1, "", "fit"], [4, 1, 1, "", "get_params"], [4, 1, 1, "", "p_adjust"], [4, 1, 1, "", "sensitivity_analysis"], [4, 1, 1, "", "sensitivity_benchmark"], [4, 1, 1, "", "sensitivity_plot"], [4, 1, 1, "", "set_ml_nuisance_params"], [4, 1, 1, "", "set_sample_splitting"], [4, 1, 1, "", "tune"]], "doubleml.DoubleMLDIDCS": [[5, 1, 1, "", "bootstrap"], [5, 1, 1, "", "confint"], [5, 1, 1, "", "construct_framework"], [5, 1, 1, "", "draw_sample_splitting"], [5, 1, 1, "", "evaluate_learners"], [5, 1, 1, "", "fit"], [5, 1, 1, "", "get_params"], [5, 1, 1, "", "p_adjust"], [5, 1, 1, "", "sensitivity_analysis"], [5, 1, 1, "", "sensitivity_benchmark"], [5, 1, 1, "", "sensitivity_plot"], [5, 1, 1, "", "set_ml_nuisance_params"], [5, 1, 1, "", "set_sample_splitting"], [5, 1, 1, "", "tune"]], "doubleml.DoubleMLData": [[6, 1, 1, "", "from_arrays"], [6, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLIIVM": [[7, 1, 1, "", "bootstrap"], [7, 1, 1, "", "confint"], [7, 1, 1, "", "construct_framework"], [7, 1, 1, "", "draw_sample_splitting"], [7, 1, 1, "", "evaluate_learners"], [7, 1, 1, "", "fit"], [7, 1, 1, "", "get_params"], [7, 1, 1, "", "p_adjust"], [7, 1, 1, "", "sensitivity_analysis"], [7, 1, 1, "", "sensitivity_benchmark"], [7, 1, 1, "", "sensitivity_plot"], [7, 1, 1, "", "set_ml_nuisance_params"], [7, 1, 1, "", "set_sample_splitting"], [7, 1, 1, "", "tune"]], "doubleml.DoubleMLIRM": [[8, 1, 1, "", "bootstrap"], [8, 1, 1, "", "cate"], [8, 1, 1, "", "confint"], [8, 1, 1, "", "construct_framework"], [8, 1, 1, "", "draw_sample_splitting"], [8, 1, 1, "", "evaluate_learners"], [8, 1, 1, "", "fit"], [8, 1, 1, "", "gate"], [8, 1, 1, "", "get_params"], [8, 1, 1, "", "p_adjust"], [8, 1, 1, "", "policy_tree"], [8, 1, 1, "", "sensitivity_analysis"], [8, 1, 1, "", "sensitivity_benchmark"], [8, 1, 1, "", "sensitivity_plot"], [8, 1, 1, "", "set_ml_nuisance_params"], [8, 1, 1, "", "set_sample_splitting"], [8, 1, 1, "", "tune"]], "doubleml.DoubleMLLPQ": [[9, 1, 1, "", "bootstrap"], [9, 1, 1, "", "confint"], [9, 1, 1, "", "construct_framework"], [9, 1, 1, "", "draw_sample_splitting"], [9, 1, 1, "", "evaluate_learners"], [9, 1, 1, "", "fit"], [9, 1, 1, "", "get_params"], [9, 1, 1, "", "p_adjust"], [9, 1, 1, "", "sensitivity_analysis"], [9, 1, 1, "", "sensitivity_benchmark"], [9, 1, 1, "", "sensitivity_plot"], [9, 1, 1, "", "set_ml_nuisance_params"], [9, 1, 1, "", "set_sample_splitting"], [9, 1, 1, "", "tune"]], "doubleml.DoubleMLPLIV": [[10, 1, 1, "", "bootstrap"], [10, 1, 1, "", "confint"], [10, 1, 1, "", "construct_framework"], [10, 1, 1, "", "draw_sample_splitting"], [10, 1, 1, "", "evaluate_learners"], [10, 1, 1, "", "fit"], [10, 1, 1, "", "get_params"], [10, 1, 1, "", "p_adjust"], [10, 1, 1, "", "sensitivity_analysis"], [10, 1, 1, "", "sensitivity_benchmark"], [10, 1, 1, "", "sensitivity_plot"], [10, 1, 1, "", "set_ml_nuisance_params"], [10, 1, 1, "", "set_sample_splitting"], [10, 1, 1, "", "tune"]], "doubleml.DoubleMLPLR": [[11, 1, 1, "", "bootstrap"], [11, 1, 1, "", "cate"], [11, 1, 1, "", "confint"], [11, 1, 1, "", "construct_framework"], [11, 1, 1, "", "draw_sample_splitting"], [11, 1, 1, "", "evaluate_learners"], [11, 1, 1, "", "fit"], [11, 1, 1, "", "gate"], [11, 1, 1, "", "get_params"], [11, 1, 1, "", "p_adjust"], [11, 1, 1, "", "sensitivity_analysis"], [11, 1, 1, "", "sensitivity_benchmark"], [11, 1, 1, "", "sensitivity_plot"], [11, 1, 1, "", "set_ml_nuisance_params"], [11, 1, 1, "", "set_sample_splitting"], [11, 1, 1, "", "tune"]], "doubleml.DoubleMLPQ": [[12, 1, 1, "", "bootstrap"], [12, 1, 1, "", "confint"], [12, 1, 1, "", "construct_framework"], [12, 1, 1, "", "draw_sample_splitting"], [12, 1, 1, "", "evaluate_learners"], [12, 1, 1, "", "fit"], [12, 1, 1, "", "get_params"], [12, 1, 1, "", "p_adjust"], [12, 1, 1, "", "sensitivity_analysis"], [12, 1, 1, "", "sensitivity_benchmark"], [12, 1, 1, "", "sensitivity_plot"], [12, 1, 1, "", "set_ml_nuisance_params"], [12, 1, 1, "", "set_sample_splitting"], [12, 1, 1, "", "tune"]], "doubleml.DoubleMLQTE": [[13, 1, 1, "", "bootstrap"], [13, 1, 1, "", "confint"], [13, 1, 1, "", "draw_sample_splitting"], [13, 1, 1, "", "fit"], [13, 1, 1, "", "p_adjust"], [13, 1, 1, "", "set_sample_splitting"]], "doubleml.datasets": [[14, 2, 1, "", "fetch_401K"], [15, 2, 1, "", "fetch_bonus"], [16, 2, 1, "", "make_confounded_irm_data"], [17, 2, 1, "", "make_confounded_plr_data"], [18, 2, 1, "", "make_did_SZ2020"], [19, 2, 1, "", "make_heterogeneous_data"], [20, 2, 1, "", "make_iivm_data"], [21, 2, 1, "", "make_irm_data"], [22, 2, 1, "", "make_pliv_CHS2015"], [23, 2, 1, "", "make_pliv_multiway_cluster_CKMS2021"], [24, 2, 1, "", "make_plr_CCDDHNR2018"], [25, 2, 1, "", "make_plr_turrell2018"], [26, 2, 1, "", "make_ssm_data"]], "doubleml.double_ml_score_mixins": [[27, 0, 1, "", "LinearScoreMixin"], [28, 0, 1, "", "NonLinearScoreMixin"]], "doubleml.utils": [[29, 0, 1, "", "DMLDummyClassifier"], [30, 0, 1, "", "DMLDummyRegressor"], [31, 2, 1, "", "gain_statistics"]], "doubleml.utils.DMLDummyClassifier": [[29, 1, 1, "", "fit"], [29, 1, 1, "", "get_metadata_routing"], [29, 1, 1, "", "get_params"], [29, 1, 1, "", "predict"], [29, 1, 1, "", "predict_proba"], [29, 1, 1, "", "set_params"]], "doubleml.utils.DMLDummyRegressor": [[30, 1, 1, "", "fit"], [30, 1, 1, "", "get_metadata_routing"], [30, 1, 1, "", "get_params"], [30, 1, 1, "", "predict"], [30, 1, 1, "", "set_params"]]}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function"}, "terms": {"": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 20, 21, 22, 23, 24, 25, 26, 32, 34, 35, 36, 37, 38, 45, 48, 49, 50, 52, 53, 54, 58, 59, 60, 61, 63, 66, 67, 69, 70, 71, 72, 73, 75, 76, 77, 78], "0": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77], "00": [53, 54, 68], "000": [70, 72, 78], "000000": [38, 53, 54, 63, 65, 75], "0000000": [70, 72], "0000000000000010000100": [37, 63, 75], "000000e": [53, 54], "00000591": 57, "000006": 57, "000017": 57, "000025": 52, "000034": 53, "000039": 52, "000064": 40, "000067": 52, "000091": [52, 65], "0001": [38, 53], "000219": [12, 65], "000242": [13, 65], "000341": 52, "000442": 52, "00047580260495": 32, "000488": 52, "000494": 50, "0005": 38, "000522": 52, "0005a80b528f": 37, "000670": 52, "0007213465": 68, "000743": 58, "000784623154372457": 61, "0007846231543724570": 61, "0007846232": 61, "000856924": 68, "000915799": [70, 72], "0009157990": [70, 72], "000943": [42, 43], "0009695237": 69, "001": [32, 34, 35, 36, 37, 41, 66, 67, 68, 69, 70, 75, 78], "001051": 52, "001234": 54, "00133": 37, "00138944": [61, 69], "00141": 67, "001505296": 68, "0016": [36, 53], "001714": 65, "0018": [36, 53], "0019": 38, "002110": 43, "002169338": [70, 72], "0021693380": [70, 72], "0021693381": [70, 72], "002290": 46, "0023": 34, "002436": 50, "0026": 38, "002779": 58, "0028": [34, 36, 53], "002821": 59, "0028213335041910427": 59, "002983": 52, "003": [16, 17, 18], "003134": 57, "003328": 57, "0034": 47, "00341": 68, "003427": 52, "003779": 50, "003836": 57, "003965": 42, "004": 55, "00409412": [61, 69], "0042": [36, 53], "004392": 50, "004645": 43, "004688": 7, "0047": [36, 53], "005": 32, "005339": [42, 43], "005857": 52, "006066": 42, "006425": 54, "006922": 38, "006958": [42, 43], "007": 55, "007210e": 54, "00728": 75, "0073": 38, "007332": 44, "007332393760465": 44, "007659": 65, "00778625": 68, "007909": 42, "008": 59, "008023": 54, "008048454": 68, "008223": [42, 43], "008266e": 54, "008487": 38, "008642": 65, "008dbd": 55, "008e80": 55, "009": [55, 59], "0090193584": 69, "00902031947837708": 61, "0090203195": 61, "009122": 57, "009428": 44, "00944171905420782": 59, "009645422": 35, "009656": 57, "00972": 38, "009740": 55, "009790": 54, "009904": 65, "009986": 57, "01": [2, 4, 5, 7, 8, 9, 12, 13, 32, 35, 36, 37, 42, 43, 53, 54, 55, 56, 57, 66, 67, 68, 69, 70, 75, 78], "010": 55, "01004050": 68, "010213": 58, "010269": 52, "010450": 35, "010896": 55, "010940": 52, "011131": 57, "0112": 34, "01128": 38, "011511": 43, "011598": 57, "0118095": 35, "011823": 58, "011852832": 68, "01195769": 68, "011988e": 57, "012129": 55, "01219": 37, "01274": 59, "012780": 54, "012831": 59, "013145": 55, "013469": 42, "01351638": 35, "013593": 58, "013617": 54, "01398951": 35, "013990": [70, 72], "01403089": 35, "014080": [42, 43], "0142625": 68, "014432": 46, "014637": 52, "014681": 58, "015": 37, "015035": 42, "015038": 44, "015548": 43, "015565": 57, "015698": 57, "01574297": 57, "015743": 57, "015831": 42, "01592805": 68, "016011": 43, "016154": 52, "016200": [42, 43], "016315": 48, "016429": 65, "01643": 76, "01671552": 68, "017": [37, 55], "017800092": [70, 72], "0178000920": [70, 72], "017805": 42, "018": 37, "018023": 56, "018099": 42, "018148": 57, "018508": 42, "018784": 55, "01887448": 68, "019008": 43, "01903": [37, 66, 73, 75], "01916030e": 68, "01925597": 35, "0193438": 68, "019439633": [70, 72], "0194396330": [70, 72], "0194396331": [70, 72], "019596": 44, "019660": [13, 65], "01990373": 60, "019953": 42, "019974": 54, "02": [42, 43, 53, 54, 57, 65, 68, 78], "02016117": 75, "020166": 57, "020271": 52, "020360838": [70, 72], "0203608380": [70, 72], "0203608381": [70, 72], "020387": 43, "02052929": [61, 69], "02055931": 68, "02079162e": 68, "020819": 65, "02092": 75, "021013": 42, "021269": [48, 49], "02163217": 35, "021866": 56, "021926": 44, "022": 55, "02247976": 35, "022768": 38, "022783": 58, "022915": 52, "022954": 65, "022969": 54, "022991": 43, "023020e": [53, 54], "023160": 42, "023256": 57, "023505": 42, "02352605": 68, "023563": [70, 72], "023955": 54, "024": 55, "024355": 46, "024364": 71, "024401": [48, 49], "024604": 52, "024782": 57, "02483551": 68, "024926": 46, "025": [42, 43, 48, 49, 55], "025077": [70, 72], "02528067": 51, "0253": 37, "025443": 38, "0257": 34, "025708e": 43, "025783e": 43, "025813114": [70, 72], "0258131140": [70, 72], "02584": 37, "025958": 65, "026518e": 42, "026669": 54, "026723": 44, "027329": 42, "02791": 38, "028001": 43, "0281": 37, "028520": [42, 43], "02897287": 45, "029": 78, "02900983": 57, "029010": 57, "029022": 43, "029209": 78, "029364": 71, "029831": 57, "029910e": [53, 54], "02e": [36, 68], "03": [2, 4, 5, 7, 8, 9, 10, 11, 12, 42, 43, 44, 50, 53, 54, 57, 58, 59, 68, 71, 78], "030087": 65, "0301": 37, "03018": [9, 65], "030346": 75, "0307": 37, "03077654": 68, "030934": 57, "030962": 57, "03113": 60, "031134": 66, "031156": 43, "031269": 38, "031639": 57, "031820": 43, "03191": 76, "032050732": 68, "03220": 77, "0323": 34, "03244552": 66, "0325": 75, "03282337": 68, "032953": 58, "033": 55, "033066": 55, "033224": 42, "033737": 43, "033756": 44, "033946": [48, 49], "034097": 42, "03411": 75, "034226": 54, "034690": 44, "034812763": [70, 72], "0348127630": [70, 72], "0348127631": [70, 72], "034836": 53, "03489": [23, 35, 52], "035": 32, "035088": 43, "035119185": [70, 72], "0351191850": [70, 72], "0351191851": [70, 72], "035264": 43, "03527933": 68, "03536": 75, "03538": 37, "03539": 37, "035391": 38, "0354": 37, "035411": 75, "035441": 43, "03545": 37, "035545": 38, "035572": 38, "035730": 57, "03574": 38, "035762": 57, "0359": 37, "036129015": [70, 72], "0361290150": [70, 72], "0361290151": [70, 72], "036143": 57, "036147": 57, "036729": 52, "0368": 34, "036874e": 43, "036945": 54, "03698487": 57, "036985": 57, "037008": [48, 49], "0374": 37, "037509": 60, "037747": [42, 43], "038845": 42, "039036": 42, "03917696": [69, 70], "03920960e": 68, "039310e": 44, "039542089": 68, "039660": 42, "03983094": 68, "039897": 43, "04": [17, 36, 42, 43, 53, 54, 57, 58, 68, 78], "040112": [70, 72], "040139": [42, 43], "040141": 43, "040445": 42, "040533": [69, 70], "04053339": 70, "040688": 42, "0408": 42, "040912": 43, "040919": 43, "04107": 11, "041112": 43, "041147": 44, "041284": 44, "041387": 44, "041459": 54, "041491e": 44, "041623": 55, "04166": 67, "0418": 34, "041831": 44, "041925": 42, "042249": 43, "042265": 44, "042266": 42, "0425": 66, "0428": 60, "042822e": 54, "042844e": 57, "043108": 54, "0433": 34, "0434e374": 37, "043998": 43, "044": 55, "044062": 43, "044113": 44, "04415": [37, 66], "04424": 37, "04425620": 68, "044334": 42, "04444978": [70, 72], "044449780": [70, 72], "04458": 66, "04458408": 68, "04465": 35, "044704": 43, "04486": 75, "04487585": 71, "04491": 67, "04497975": 71, "045": 55, "04512": [69, 70], "04512331": 70, "045144": 52, "04532": 66, "045379": 75, "04552": 52, "045553": 44, "04559": 66, "045624": 46, "045754": 57, "0459": 66, "045932": 57, "045993": 66, "046023": 55, "04631": 66, "046405": 65, "046527": 44, "04653976": 57, "046540": 57, "0466028": 35, "04671455": 68, "046728": 58, "046757": 43, "04682310e": 68, "046922": 66, "047156": 42, "047194": 7, "047215": 43, "047375e": 42, "047954": 52, "048": 78, "048308": 49, "048326": 43, "048699": 60, "048723": 66, "04973": 43, "049959": 42, "05": [32, 34, 35, 36, 37, 42, 43, 44, 47, 51, 52, 53, 54, 55, 57, 59, 66, 67, 68, 69, 70, 75, 78], "050": 55, "05039": 58, "050399": 43, "050538": 43, "050843": 43, "050856": [65, 66, 67], "051": 37, "051578e": 43, "051802927": 68, "051867e": 44, "052000e": 54, "052298": 57, "052380": 42, "052488": 49, "052502": 57, "052745": 44, "053": 37, "0533": 34, "053331": 44, "053342": 54, "053389": [70, 72], "053436": 8, "053541": 57, "053558": 44, "054": 37, "054068": 52, "054162": 52, "054348": 70, "054370": 44, "054529": [70, 72], "054771e": 57, "055078": 42, "055165": 58, "055171": 43, "055338e": 53, "055439": 54, "055680": [70, 72], "056052": 42, "056389": 43, "056499": 49, "056745": 42, "056953": 42, "057095": 57, "0576": [36, 53], "057762": 57, "057962": 44, "058": 55, "058042": [70, 72], "058276": 54, "058463": 57, "058508": 60, "0590": 34, "059187": 43, "059384": 57, "05941177": 68, "059627": 54, "059630": 46, "059685": 57, "06": [16, 17, 18, 42, 43, 44, 53, 54, 57, 65, 68, 69, 70], "06008533": 67, "060201": 57, "060212": [53, 54], "060417": 42, "060581": 51, "060845": [70, 72], "0611": 34, "06111111": 37, "0615": 34, "062142": 59, "062214693": 68, "062414": 54, "062507": 57, "0628": 34, "062964": [70, 72], "0632": 34, "0635": 34, "0636": 34, "063618": 43, "063700": 42, "0638": 34, "063881": 67, "0640": 34, "064161": 54, "06425829": 68, "06428": 53, "064280": 53, "064400": 42, "0645": 34, "0646222": 36, "06464": 70, "0647": 34, "0649": 34, "065": [59, 78], "065128": 42, "0653": 34, "065356": [48, 49], "0654": 34, "065451": 54, "0655": 34, "065725": 44, "0659": 34, "065969": 67, "066": 32, "0662": 34, "066464": 58, "066689e": 43, "066889": 57, "0669": 34, "06692492": 68, "0671": 34, "067240": 57, "06724028": 57, "0673": 34, "0675": 34, "067528": 59, "067721": [70, 72], "068073": 43, "06827": 58, "06834315": 45, "068377": 54, "068514": 42, "06895837": 35, "06907425": 68, "0695854": 35, "069600": 54, "07": [42, 43, 54, 57, 59, 68, 78], "070020": 57, "070196": 44, "0701961897676835": 44, "0702127": 35, "0704": 34, "070552": 42, "070574e": 54, "0707": 34, "070751": 42, "070884": 57, "0711": 34, "071285": 70, "07136": [35, 52], "071488e": 44, "0716": 34, "07168291": 35, "071777": 66, "071782": [13, 65], "0719": 34, "07202564": [48, 49], "072058": 42, "07222222": 37, "072293": 56, "072852": 42, "073": 67, "073013": 57, "073207": 52, "073352": 42, "07347676": 35, "07350015": [23, 26, 35, 52], "073520": 44, "0736": 34, "07366": [37, 66], "073694": 43, "07371799": 68, "0743": 34, "074304": 70, "07436521": 68, "074426": 57, "07449643": 68, "07456127": 35, "074617": 43, "07479278": 58, "075261": 46, "075384": 57, "07538443": 57, "07544271e": 68, "075595": 59, "07561": 75, "07564554e": 68, "0758": 59, "075869": 66, "076019": 53, "076156": 70, "076179312": [70, 72], "0761793120": [70, 72], "076322": 57, "076347": 44, "0765": 37, "076559": [65, 66, 67], "076596": 42, "076684": 75, "07685043": 68, "07689": 37, "07691847": 68, "076953": [48, 49], "076971": 38, "07701230": 68, "077161": 54, "07727773e": 68, "077319": 57, "077502": 71, "0777777777777778": 66, "07777778": [37, 66], "077840": 54, "07786": 67, "077883": 57, "078096": 70, "078207": 38, "078227938": 68, "07828372": [70, 72], "078474": [70, 72], "078810": 57, "079085": 38, "07915": 37, "07919896": 68, "079458e": 53, "07961": 58, "07978296": 68, "08": [42, 43, 44, 54, 57, 59, 67, 78], "08005229": 68, "08031571": 68, "080351": 43, "080854": 54, "080900": 42, "08091581": 68, "080947": 38, "081": 37, "081100": 57, "081230": [42, 43], "081488": 52, "08154161": 68, "081604673": 68, "08181827e": 68, "0820": 34, "082263": 10, "082297": 68, "082574": 8, "082804": 46, "082858": 43, "082934": 54, "082973": 52, "083258": [70, 72], "083318": 70, "08333333": 37, "08333617": 68, "0835771416": 35, "083591": 55, "083750": 54, "084": [35, 55], "084156": 43, "084184": 44, "0841842065698133": 44, "084212": 50, "084269": 54, "084337": 67, "084549": 59, "084633": 48, "084771": 42, "0853505": 35, "085395": 42, "085566": 44, "085671": 42, "085965": 54, "08602774e": 68, "086109": 43, "0862": 73, "086264": 44, "086464": 42, "08664208": 68, "086679": 66, "086889": 48, "0872": 34, "087491e": 43, "087561": 42, "087634": 42, "087947": 57, "088048": 57, "088282": 49, "088357": 57, "08848": 66, "088482": [13, 65], "088504e": 10, "088696e": 43, "08888889": 37, "089064e": 42, "0894": 34, "089661": 49, "08968939": 35, "089825": 43, "08e": 36, "09": [42, 44, 53, 54, 57, 65], "09000000000000001": 66, "090025": 54, "09015": 34, "090255": 57, "090726": 59, "091046": 49, "091391": [70, 72], "091406": 71, "091535": 42, "0916": 34, "091611": 43, "091871": 59, "09187106073162674": 59, "09191573": 68, "091992": 56, "092229": 59, "092247": 57, "092263": 67, "092365": [70, 72], "093043": 57, "09310496": [70, 72], "093153": 57, "093474": 57, "09347419": 57, "09353346": 68, "093746": 70, "09392932": 67, "093950": 52, "094": 32, "094026": 52, "094118": 57, "094381": 52, "09444444": 37, "09447757": 68, "09449": 68, "094829": 67, "094999": 57, "09526618": 68, "095475": 65, "095781": 2, "095835": 43, "09603": 73, "096245": 65, "096337": 52, "096550": 48, "096616": 65, "096741": 45, "096902": 59, "096934": 43, "0971814": 68, "097468": 44, "09779675": [70, 72], "097796750": [70, 72], "098": [36, 55, 59], "09814724": 68, "09816051": 68, "098256": 57, "09830758": 58, "098308": 58, "098317": 54, "098319": 57, "09851458": 68, "09859587": 68, "0986": 34, "098712": 57, "09879814e": 68, "099647": 56, "099670": 54, "099731": [42, 43], "09980311": [70, 72], "09988": 76, "0_": 22, "0ff823b17d45": 37, "0x1747bdd4520": 38, "0x1747bdd6b90": 38, "0x2920d7b7150": 56, "0x7f24da5c2340": 71, "0x7f24f27480d0": 70, "0x7f24f2748a30": 70, "0x7f24f27dd340": 70, "0x7f24f27dd7c0": 70, "0x7f24f2af3910": 66, "0x7f24f2cb68b0": 78, "0x7f24f30fe040": 67, "0x7f24f33b2340": 66, "0x7f24fafc5580": 66, "0x7f24fb78fa90": 67, "0x7f61da777e50": 59, "1": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "10": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 23, 24, 26, 32, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 78], "100": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 23, 25, 26, 35, 37, 41, 42, 43, 45, 47, 50, 51, 52, 55, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 77], "1000": [7, 9, 33, 40, 41, 45, 46, 48, 49, 50, 51, 53, 54, 58, 59, 62, 65, 67], "10000": [32, 42, 43, 46, 53, 54, 57], "100000e": 54, "100356": 44, "10038": 58, "10039862": [60, 67], "100517": 70, "100614": 50, "10079785": 67, "100807": [42, 43], "100858": 58, "10089588": 57, "100896": 57, "10092": 54, "100923": 57, "100_000": 55, "101": [16, 17, 18, 34, 65, 76, 77], "101076": 43, "10126": 54, "10127930": [70, 72], "101279300": [70, 72], "1015": [36, 53], "1016": [16, 17, 18, 34], "1016010": 36, "1017222327373942464953606163747783909197": 68, "1018": 54, "102": [63, 65, 75, 77], "10235": 54, "102553e": 42, "10258": 54, "102616": 44, "10276809": 68, "102775": 44, "10299": 53, "103": [52, 60, 65, 77], "1031": 54, "103186": 43, "103189": 54, "10348": 53, "103497": 57, "1038": 54, "103806": 44, "103951906910721": 44, "103952": 44, "10396": 53, "104": [36, 53, 60, 65, 77], "10406": 54, "1041": 34, "10414": 54, "1041497": 68, "1041612": 68, "104176": 59, "1045303": 35, "104787": 52, "105": [22, 35, 42, 52, 65, 77], "1050": 59, "105318": 57, "1054": 37, "1055": 34, "105722": 43, "105751e": 42, "105942": 42, "106": [37, 65, 77], "10607": [38, 63, 75], "10618": 54, "10637173e": 68, "106391": 70, "106401e": 42, "106595": 67, "106691": 65, "106743": 43, "106746": 57, "107": [37, 59, 65, 77], "107073": 44, "107295": 70, "1073": 54, "10747": [38, 63, 75], "1075827": 68, "1076": 68, "107872": 65, "10799": 54, "108": [65, 73, 76, 77], "1080": [23, 26, 34, 35, 52, 68], "10824": [38, 63, 75], "108257e": 54, "10831": [38, 63, 75], "1087654": 68, "10878571": 57, "108786": 57, "109": [42, 65], "109005": 57, "1090252": 68, "10903": 53, "109069": [70, 72], "109079e": 57, "109273": 52, "10928": 54, "1093": 47, "109454": 54, "1096": 34, "10967": 53, "109861": 75, "1099472942084532": 40, "10e": [44, 57], "11": [11, 35, 36, 37, 38, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 78], "110": [65, 77], "1101": 54, "110352": 59, "110359": 52, "110681": 58, "1107": 54, "11071087": [60, 67], "110717": [70, 72], "1109": 54, "110902": 44, "110902411746278": 44, "111": [65, 77], "1111": [14, 15, 24, 33, 35, 41, 47, 52, 59, 62, 67, 71, 73], "111164": 56, "11120": 54, "1118": 36, "11199615e": 68, "112": [37, 65, 77], "1120": 53, "11208236": [61, 69], "1122": 54, "112216": 44, "1125293031323547505562657278798182889499": 68, "1129": 54, "113": [14, 65, 77], "113207": 57, "113270": 44, "113415": 54, "11375": 54, "113780": 52, "114": [65, 77], "11409": 53, "11414": 53, "1144500": 35, "11447": 58, "114530": 48, "1145370": 35, "114570": 43, "11458": 54, "114591": 43, "114647": 44, "1147": 34, "1148": 54, "114834": 54, "11488": 54, "11495": 54, "115": [65, 77], "11500": [53, 78], "115060e": 57, "115296e": 54, "115297e": 53, "11552911": 58, "11559": 54, "115636": 43, "11570": 53, "115792e": 54, "115972": 42, "116": [65, 77], "116027": 44, "11617": 54, "116274": 44, "116483": 43, "116569": 54, "1166": 76, "1167": 53, "11673": 54, "11675": 54, "117": [42, 65], "1170": 58, "11700": 78, "117072": 48, "117242": 57, "11724226": 57, "117366": 57, "11743": 78, "11750": 54, "1176": 34, "1177": [34, 53], "117710": 44, "11792": 36, "11796": 54, "118": 65, "11802": 54, "1182": 36, "11823404": 59, "118255": 57, "1185844": 68, "1186": 36, "118601": 52, "11861": 36, "118721": [43, 49], "1187339840850312": 52, "11879": 54, "118799": 54, "118938e": 67, "118952": 52, "119": [59, 65, 77], "11932": 54, "119348e": 43, "11935": 58, "119766": 57, "1198": [35, 52], "12": [32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78], "120": [45, 60, 65, 77], "12002": 53, "1202": 76, "120456": 49, "120468": 57, "12046836": 57, "120567": [48, 49], "120636": 42, "120721": 52, "12097": [14, 15, 24, 35, 47, 52, 62, 73], "121": [54, 55, 65, 77], "1210": 54, "12101": 54, "12105472": [70, 72], "121054720": [70, 72], "1211": 54, "12116854": 68, "1213405": 35, "121399": 54, "1214": [70, 72], "121584e": 57, "121711": 54, "121774": 50, "12196389e": 68, "122": [16, 17, 18, 34, 63, 65, 76, 77], "12214": 36, "12223182e": 68, "122408": 44, "122777": 70, "123": [36, 37, 53, 55, 59, 65, 77, 78], "1230": 54, "123192": 59, "12323": 54, "1234": [32, 33, 34, 38, 40, 41, 62, 66, 68, 70, 72], "12348": 59, "1238": 54, "123806e": 43, "123917": 54, "124": 65, "12410": 54, "12411908": 67, "124465": 42, "124805": 53, "125": [65, 77], "12500": 53, "125065": 70, "12539340": [70, 72], "1255": 54, "12579": 54, "1258": 35, "126": [65, 77], "12606": 54, "12612": 54, "126777": 70, "126802": 54, "126875": 42, "12689": 54, "127": [16, 65, 77], "127006": 54, "12705095": [69, 70], "12707800": 35, "12752825": [70, 72], "127563": 58, "1277": 55, "127778": 54, "127831": 43, "128": [36, 65, 77], "12802": 36, "12814": 54, "128273e": 42, "128312": 57, "128408": 52, "1285": 34, "12861": 54, "128651": 43, "129": [52, 65, 77], "129152": 42, "12945": 76, "1294533": 68, "1295": [34, 54], "129514": 54, "12955": 53, "12959500": 68, "1298": 54, "12980769e": 68, "12983057": 67, "13": [17, 18, 20, 33, 35, 36, 37, 38, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 78], "130": [37, 48, 52, 65, 77], "130122": 58, "13034980e": 68, "130370": 44, "130526": 65, "1306": 58, "130829": 57, "13091": 54, "131": [65, 77], "13102231": 67, "13119": 58, "1312": 78, "131211": 54, "1313": [36, 78], "13137893e": 68, "131544": 42, "131771": 43, "1318": 34, "132": [37, 52, 65, 77], "13208": 78, "1321": [53, 78], "1324": [36, 53], "132454": 46, "1325": 36, "132671": 44, "13288": 53, "132903": 54, "133": [32, 37, 63, 65, 76, 77], "13300": 54, "133202": 54, "133204": 42, "133343": 43, "133421": 54, "13356": 54, "133596": 57, "13398": 59, "133f5a": 55, "134": [52, 60, 65, 77], "1340371": 34, "1341": 36, "134146": 54, "1342": 54, "134211": 57, "1343": 53, "134542": 42, "134567": 54, "13456816212644515658596466719398100": 68, "134568162126445156585964667193981001125293031323547505562657278798182889499271214151819202428364048526970738795961017222327373942464953606163747783909197": 68, "1346035": 36, "134687": 54, "13474": 54, "134765": 54, "1348": 53, "1349": 58, "13490": 54, "135": [37, 65, 77], "13505272": 35, "135329": 50, "135352": 4, "135379": 70, "135396": 42, "13567690": 68, "135707": 66, "135755": 65, "135856": 57, "13585644": 57, "135871": 52, "136": [38, 52, 59, 65, 77], "1360": 36, "136032": 59, "136089": 52, "1361": 54, "13631680": 68, "13642": 54, "136442": 52, "1366": 55, "136836": 52, "137": [16, 37, 38, 65, 77], "1371": 54, "137213": 43, "137396": 57, "1378": 54, "138": [65, 77], "1380": 53, "138068": 48, "13809": 54, "138264": 59, "138378": 44, "1386": 34, "13868238": [70, 72], "138682380": [70, 72], "138698": [70, 72], "1387": 34, "1388053": 68, "138851": 48, "13893": 54, "139": [55, 59, 65, 75], "1390": 53, "139491": [70, 72], "13956": 58, "139582e": 11, "1398": 54, "1399": 34, "139921": 65, "14": [33, 35, 36, 37, 38, 42, 43, 44, 45, 48, 49, 50, 52, 53, 54, 57, 58, 59, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 78], "140": [45, 54, 60, 65, 77], "1400": 54, "14000073": 68, "1401": 34, "140770": [42, 43], "140833": 44, "140861": 35, "140926": 57, "141": [54, 65, 77], "141098e": 54, "14114": 58, "141347": 42, "141384": 50, "14141": 54, "14147458": 68, "141546": [70, 72], "141729": 43, "141820": 44, "142": [65, 77], "14200098": [70, 72], "142209": 59, "142270": 46, "142382": 42, "1424": 66, "142624": 43, "14268": 67, "14281403493938022": 66, "14289": 54, "143": [63, 65, 77], "143495": 65, "1435": 54, "14368145": [70, 72], "144": [42, 43, 65, 77], "14400": 53, "1440433": 68, "14405": 54, "14406": 54, "144084": 44, "1441": 34, "144137": 45, "144241": 48, "1443": 54, "144500e": 54, "144669": 57, "1447": 54, "144800": 44, "144861": 53, "144908": 56, "145": [65, 77], "145245": 57, "14532650": [70, 72], "145513": 42, "145625": 57, "145748": 70, "14587": 54, "146": [65, 77], "146037": 57, "146046": 43, "146087": 75, "146142808990006": 44, "146143": 44, "14625": 54, "1465": 36, "146641": 70, "14667": 54, "1468115": 35, "146973": 44, "1469734445741286": 44, "147": [65, 77], "147015e": 54, "14702": 38, "147121": 57, "14744": 54, "14772": 54, "1479": 54, "14790924": [70, 72], "147909240": [70, 72], "147927": 38, "14798": 54, "148": [55, 65, 77], "14803": 54, "148134": [42, 43], "148161": 57, "148385": 59, "148443": 65, "14845": 38, "1485": 54, "148750e": [53, 54], "148790": 54, "148802": 54, "148950": 42, "149": [65, 77], "1492": 32, "1492228": 68, "149285": 57, "149484": 59, "149671e": 43, "149714": 52, "14984": 54, "149858": [12, 65], "149898": 57, "149973e": 43, "15": [2, 4, 5, 7, 8, 9, 10, 11, 12, 15, 33, 35, 36, 37, 42, 43, 44, 45, 48, 50, 51, 52, 53, 54, 57, 58, 59, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 78], "150": [22, 37, 42, 43, 59, 65, 77], "15000": [36, 53], "150000": 36, "15000000000000002": [44, 54, 57, 66], "150000e": 54, "150136": 43, "1502": 35, "150200": 52, "150334": 54, "150408": 35, "150614": 38, "150719e": 53, "151": [65, 77], "151047e": 48, "151063": 42, "151087e": 42, "15113": 54, "151636": 44, "151819": 57, "15194": 53, "152": [65, 77], "152034": 54, "152148": [42, 43], "152772": 43, "15285": 54, "15286168": 68, "152926": 46, "153": [55, 59, 65, 77], "1530959776797396": 44, "153096": 44, "153119": 44, "15347": 54, "153587": 52, "153633": 38, "153639": 68, "15375": 58, "154": 65, "15420173": 68, "15430": 78, "154421": 70, "1545": 54, "154557": 57, "154758": 70, "154811": 43, "154828": 44, "155": [65, 77], "155000": 53, "155025": 57, "155120": 57, "155516": 56, "15556": 54, "155610": 42, "155661": 59, "155676": 42, "1557093": 35, "156": [65, 77], "1560": 54, "156021": 57, "156202": [42, 43], "156317": [42, 43], "1564": [70, 72], "156545": 70, "156567": 42, "1569": 54, "156969": 44, "157": [55, 65, 77], "157091": 70, "1576": 54, "157613": 42, "1577657": 35, "158": [53, 65, 77], "158007": 57, "158087": 42, "15815035": 36, "158178": 44, "1582": 54, "1586": 54, "158697": [70, 72], "1589": 54, "15891559": 57, "158916": 57, "159": 77, "159011": 42, "15916": 34, "159202e": 43, "159386": 58, "1596": 37, "159959": 54, "16": [2, 32, 33, 35, 36, 37, 42, 43, 44, 50, 52, 53, 54, 57, 58, 59, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 78], "160": [45, 60, 77], "1604": 36, "160438": 42, "160932": 44, "161": [37, 49, 76, 77], "161049": 43, "161088": 43, "161141": 52, "161198": 56, "161236": 57, "161243": 57, "161288": 43, "161543": 54, "161839": 59, "1619": 36, "162": 77, "16201": 54, "16211": 53, "162153": 57, "1622": 54, "16241": 54, "162587": 58, "1626685": 35, "162710": 44, "1628": 53, "162930": 54, "163": [54, 77], "163194": 57, "163393e": 43, "163566": 54, "163895": 44, "164": 77, "164034": 70, "164608": 57, "164617": 53, "164698": 50, "1648": 34, "164801": 57, "164805": 44, "164864": 52, "165": 77, "16500": 53, "165178": 57, "16536299": [70, 72], "165362990": [70, 72], "16539906e": 68, "1654": 54, "165419": 57, "165549": 75, "165569": 42, "16587": 53, "16590": 54, "16597": 54, "166": 77, "166079": 42, "1661": 53, "166375": 65, "167": [36, 53, 77], "16725": 54, "167547": 57, "1676": 54, "167765": 54, "167993": 70, "168": 77, "16803512": [70, 72], "168092": 70, "1681": 34, "168195": 58, "1683": 53, "168614": 57, "168931": 57, "169": [37, 77], "1691": [34, 54], "16910": 54, "169196": 57, "169230e": 44, "16951": 54, "16984": 54, "17": [33, 35, 36, 37, 42, 43, 50, 52, 53, 54, 57, 58, 59, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 78], "170": 77, "1704": 54, "1707": 68, "170789": 59, "17083": 54, "171": 77, "1712": 76, "1714": 36, "171575": 57, "171709": 42, "171815": 66, "171868e": 42, "171942": 54, "172": 77, "172022": [70, 72], "172083": 43, "172793": 57, "173": 77, "17372": 54, "1738": 54, "17385178": 66, "173969": 70, "174": 77, "174106": 58, "174185": 57, "174499": [70, 72], "174516e": 57, "17453": 54, "1746": 54, "174743": 65, "174884": 43, "174901": 43, "174940": 65, "17499": 54, "175": 77, "1751": 53, "175176": 57, "17522": 54, "175284": 44, "175342": 42, "17551290": 68, "175635027": 35, "17576": 54, "1759735": 68, "176495": 57, "17655394": 57, "176554": 57, "176929": [70, 72], "177": [76, 77], "177007": 57, "17700723": 57, "177043": [42, 43], "1773": 54, "177304": 43, "1774": 34, "177463": 56, "177496": 57, "177611": 57, "177751": 57, "17778": 54, "1779196": 68, "177933e": 42, "17799": 54, "177995": 57, "178": [50, 77], "178169": 48, "178218": 43, "17823": 37, "178704": 70, "178763": 57, "178805": 49, "178934": 70, "178980": 43, "179": [48, 77], "1795850": 35, "179588e": 57, "1798913180930109556": 55, "18": [33, 35, 36, 37, 38, 42, 43, 50, 51, 52, 53, 54, 57, 58, 59, 63, 65, 66, 67, 68, 70, 71, 72, 75, 78], "180": [45, 60, 77], "18015": 54, "180176e": 54, "1803": 34, "18030": 54, "180348": 43, "180575": [48, 49], "1807": [34, 54], "1809": 76, "180951": 57, "181": 77, "1812": 54, "1814": 34, "18141": 54, "181446": 70, "182": 77, "1820": 34, "182208e": 42, "182393": 42, "182633": 57, "182692": 43, "182849": 57, "183": [37, 77], "183373": 67, "183526": 44, "18356413": 67, "18368": 54, "183855": 66, "183888": 52, "184": [37, 76, 77], "184249": 59, "185": [36, 37], "18500": 54, "1855": 54, "185585": 65, "185984": 42, "186": [54, 77], "186027": 42, "18603670": 68, "18604": 54, "1862": 34, "186237": 43, "18631": 54, "18637": 73, "18666": 54, "186735": 57, "18678094e": 68, "186795": 43, "186836": 57, "187": 77, "187153": 70, "187664": 42, "187690": 57, "18789": 54, "188": 77, "188175": 57, "1881752": 57, "188223": 57, "18888149e": 68, "1889065179": 68, "188991": 70, "189": [37, 77], "189195": 54, "189248": 42, "189293": 54, "189302": 42, "189493": 43, "1895815": [23, 35, 52], "189737": 57, "189927": 54, "189998": 57, "19": [32, 33, 35, 36, 37, 42, 43, 52, 53, 54, 57, 58, 59, 65, 66, 67, 68, 70, 75, 78], "190": [37, 77], "19000": 54, "190096": 70, "190140": 42, "19031969": 57, "190320": 57, "19033538": 35, "190648": 7, "19073905e": 68, "190809": 57, "190869": 65, "1909": [23, 35, 52], "190915": 44, "190921": 49, "190982": 57, "191": [37, 76, 77], "1912": 76, "1912705": 62, "191320e": 53, "191397": 65, "191606": 53, "191716": 54, "1918": 34, "192": [67, 77], "1922": 54, "192240": 70, "192505": 56, "192526": 58, "19252647": 58, "192539": [13, 65], "192587": 57, "192739": 43, "193060": 57, "193069e": 42, "193300": 42, "193308": [13, 65], "19374710e": 68, "19382": 54, "19385": 54, "193f0d909729": 37, "194": [51, 54, 77], "1941": 36, "19413": [53, 54], "194232": 43, "194601": 45, "195": 77, "19508": 59, "19508031003642462": 59, "19509680e": 68, "195377": 57, "195396": 57, "195547": 54, "195564": 52, "19559": [36, 53], "195761": 57, "1959": 76, "196": 77, "196189": 57, "196437": 54, "19680840": [70, 72], "1970": 54, "197000e": 54, "19705": 54, "197225": [38, 63, 75], "1972250000001000100001": [37, 63, 75], "1974": 54, "197424": 66, "197484": 70, "19756": 54, "19758": 54, "197600": 46, "197711": 54, "197920": 42, "19793": 54, "19794": 54, "198": [68, 77], "198218": 52, "19824": 54, "198351": 57, "198549": 38, "198687": 36, "1988": [33, 41, 62], "198953": 65, "199": 77, "1990": [36, 53, 54, 67], "1991": [36, 53, 54, 78], "199206e": 42, "199281e": 57, "199282e": 54, "199412": 43, "199458": 70, "1995": [35, 52], "1998": 55, "19983954": 60, "199893": 48, "1999": [55, 60], "199959": 42, "1_": [44, 57], "1e": [2, 4, 5, 7, 8, 9, 12, 13, 54], "1f77b4": 46, "1x_4x_3": 46, "2": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 26, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77], "20": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, 21, 23, 24, 25, 33, 35, 36, 37, 42, 43, 44, 45, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 75, 78], "200": [19, 22, 34, 41, 44, 45, 47, 51, 56, 57, 60, 62, 66, 77], "2000": [15, 36, 42, 43, 44, 53, 54, 57, 60, 67], "20000": [36, 53], "20000000000000004": [44, 54, 57], "200000e": 54, "20010": 54, "200110": 54, "2003": [14, 76], "200303": 75, "2005": 45, "20055": 54, "2006": 54, "20073763": 51, "20074": 54, "200863": 42, "201": [37, 54, 77], "2010": [35, 52], "2011": [35, 52, 73, 75], "2013": [47, 70, 72, 76], "2014": [70, 72, 76], "2015": [22, 76], "201528": [42, 43], "20158": 54, "2016": 55, "2017": [21, 76], "201768": 52, "201788e": 54, "201796": 50, "2018": [14, 15, 24, 25, 33, 35, 36, 41, 45, 47, 51, 52, 53, 54, 58, 62, 68, 70, 72, 73, 76, 77], "2019": [19, 37, 42, 43, 44, 48, 49, 54, 57, 58, 66, 69, 73, 75, 76], "202": 77, "2020": [4, 5, 16, 17, 18, 20, 34, 37, 45, 59, 66, 67, 71, 76], "2020435": 35, "2021": [23, 34, 35, 37, 42, 43, 52, 76, 77], "20219609": 35, "2022": [58, 59, 67, 71, 73, 76], "2023": [26, 60, 67, 69, 76], "2024": [32, 40, 55, 59, 73, 76], "202650e": 44, "20269": 54, "20274": 54, "202846": 43, "203": [36, 53], "203284": 44, "20329": 54, "2036": 54, "203828": 54, "203893": 65, "204007": 57, "20400735": 57, "204482": 57, "204653": 65, "204794": 57, "205": 58, "205187": 44, "205656": 42, "205938": 52, "206": 77, "2061": 54, "206253": [53, 54], "2064": 54, "206614": 57, "206748": 43, "207222": 53, "2075": 34, "20783816": 35, "207840": 49, "207912": 70, "208": 77, "208034e": 54, "2080787": 35, "20823898": 35, "2086": 54, "208922": 42, "209": 55, "209014": 57, "209219e": 58, "209257": 4, "209546e": 54, "2097": 67, "209894": 57, "21": [14, 15, 24, 33, 35, 36, 37, 42, 43, 47, 52, 53, 54, 57, 58, 59, 62, 65, 66, 67, 68, 70, 73, 75, 76, 78], "210": [17, 18], "2103": [54, 73], "2103034": 35, "210319": [42, 43], "210323": 57, "2104": 77, "21078": 54, "211": [32, 77], "21105": [37, 66, 73, 75], "2112": 59, "21142": 54, "211534": 44, "21155656": 57, "211557": 57, "212": 77, "2122": 54, "21257396e": 68, "212844": 52, "213": [76, 77], "213026": 54, "213070": 43, "21313146": 68, "213135": 43, "21361": 54, "213635": 42, "2139": 20, "21439780": 68, "214764": 58, "215": 49, "215069": 57, "215342": 57, "215389": 42, "2155": 54, "21550": 54, "21562": 54, "21573": 54, "215967": 70, "216130e": 42, "216207": 66, "21624417": 35, "2163": 54, "216344": 57, "21669513e": 68, "216761": 56, "217": 76, "21716": 54, "2171802": [35, 52], "217244": [9, 65], "21804": [36, 53], "218767": 54, "2189": 54, "218938": 54, "219": [16, 17, 18, 34, 76], "2191274": 35, "219196e": 43, "21997": 53, "22": [33, 35, 36, 37, 42, 43, 52, 53, 57, 58, 59, 65, 66, 67, 68, 70, 75, 78], "220": 77, "220088": 54, "220772": 57, "220773": 42, "221": 77, "221245": 43, "2213": 52, "2214": 52, "221419": 54, "2215": 52, "2216": 52, "2217": [35, 52], "222": 77, "2222": [33, 35, 41, 67], "22222": 54, "22272803e": 68, "222843": 57, "223": 77, "22336235": 35, "223485956098176": [48, 49], "22375856": 35, "22390": 53, "224": [55, 77], "224539e": 42, "224546": 42, "224897": [42, 43], "225": [34, 60, 77], "225034": 45, "22505965": 35, "22507006e": 68, "225175": 57, "225222": 57, "22522221": 57, "22528": 54, "225459760731946": 44, "225460": 44, "225574": 52, "2256": 54, "22562": 54, "225776": 59, "2258": 58, "226": 77, "2264": 34, "226524": 57, "226598": 52, "226776": 43, "226938": 49, "227": [54, 77], "2271071": 26, "227190": 49, "2276": 34, "2279": 54, "227931e": 53, "228035": 54, "2281": 54, "228621": 42, "228630": 43, "228648": 36, "229": [36, 77], "22925": 54, "22937": 54, "229443": 57, "229472": 53, "2295": 54, "229759": 66, "2298": 34, "229897": 42, "229961": [42, 43], "229994": [42, 43], "23": [5, 35, 36, 37, 42, 43, 45, 51, 52, 53, 54, 57, 58, 59, 63, 65, 66, 67, 68, 70, 73, 75, 76, 78], "230": 34, "230009": [48, 49], "2307": [35, 52, 62], "230956": 46, "231": [14, 77], "23113": 67, "231153": 43, "231310": 57, "231330e": 43, "231430": 70, "231467": 67, "231986": 57, "232134": [42, 43], "2328": 54, "232959": [48, 49], "233": 21, "233029": 42, "233154": 78, "2335": 34, "233538": 55, "234": 76, "234137": 59, "234153": 59, "234205": 54, "234534": 44, "234605": 38, "234798": 54, "234812e": 43, "234910": 52, "235": 77, "235501e": 42, "235873": 42, "2359": 78, "23590": 54, "236008": 44, "236309": 54, "23690345e": 68, "237": 37, "237252": 54, "237292": 43, "237341": 42, "237430": 43, "237461": 58, "23748": 54, "23751359e": 68, "237896": 57, "23789633": 57, "238": [35, 52, 77], "238101": 57, "238225": 70, "238251": 44, "238529": 8, "23856": 54, "238794": 57, "239": 77, "239313": 43, "239317": 43, "23965": 54, "239799": 42, "23e": 36, "24": [35, 36, 37, 42, 43, 49, 51, 52, 53, 54, 57, 58, 59, 60, 65, 66, 67, 68, 70, 75, 76, 77, 78], "240127": [42, 43], "240295": 58, "240532": [42, 43], "2407": 34, "24080030a4d": 37, "240813": 50, "241049": 57, "241063": 42, "241064": 43, "2416": 34, "241609": 54, "241678": 42, "241962": 59, "24199": 54, "242": 76, "242000": 54, "242124": [53, 54], "242139": 70, "242158": [53, 54], "2424596822": 49, "242815": 70, "242902": 57, "243": [32, 55], "2430561": 34, "243246": 57, "2438": 54, "2439": 54, "244": 54, "244090": 54, "244455": 57, "244622": 70, "24469564": 75, "245": 76, "245062": 57, "2451": 34, "24510393": 36, "245370": 52, "245416": 43, "245512": 57, "245720": 46, "246": 77, "246624": 65, "246731": 53, "2467506": 35, "246753": 57, "246879": 57, "247": 77, "247020": 44, "247057e": 57, "2471": 54, "2472": 54, "247207": 43, "247617": 65, "247717": 54, "24774": [53, 54], "247826": 52, "248171": 57, "248638": 44, "249": [35, 52, 55], "2491": 54, "249109e": 43, "24917": 54, "2499432": 68, "25": [13, 16, 17, 18, 22, 23, 24, 35, 36, 37, 42, 43, 44, 46, 47, 51, 52, 53, 54, 57, 59, 60, 65, 66, 67, 68, 70, 75, 78], "250": [32, 55], "2500": 54, "25000000000000006": [44, 54, 57], "250073": 54, "250210": 44, "2503": 54, "250354": 57, "250425": 44, "251": [54, 58], "251101": [65, 66, 67], "251412": 43, "251480": 43, "251953": 54, "252133": 54, "252253": 58, "25240463": 67, "252524": 57, "252601": 70, "2526366": 68, "252644": 42, "253026": [42, 43], "2532": 54, "253437": 56, "253724": 57, "25374": 54, "254": [54, 77], "25401679": 35, "254038": 49, "2543": 54, "254324": 44, "254400": 70, "254551": 43, "255": [54, 77], "255598": 43, "256": [54, 66], "256416": 57, "256567": 52, "25672": 54, "256944": 57, "256983": 11, "256992": 54, "257207": 35, "257377": 46, "258158": [42, 43], "2583": 54, "258951": 57, "259118": 50, "2594": [36, 53], "259828": [42, 43], "25x_3": 46, "26": [35, 36, 37, 38, 42, 43, 45, 51, 52, 53, 54, 60, 63, 65, 66, 67, 68, 70, 75], "26016": 54, "260161": [12, 65], "260211": [42, 43], "260356": 53, "260360": 57, "260687": 43, "2610": 54, "2613": 54, "261624": [53, 54], "261685": 54, "26175": 54, "261777": 54, "261903": 52, "2619317": 35, "262000e": 42, "262357": 43, "262423e": 54, "262621": 52, "26271285": 68, "262829": 68, "263": [14, 54, 77], "2633": 54, "263672": 42, "263974e": 57, "264": [76, 77], "264086": 46, "264274e": 54, "264884": 54, "265119": 56, "2652": [37, 53, 54], "265547": 54, "2658": 49, "26644688": 68, "266922": 70, "267": 55, "2670691": 35, "267099": 42, "267500": 52, "267581": 54, "267767": 43, "267950": 57, "268055": 54, "268942": 57, "268998": 36, "269043": 57, "269977": 54, "26bd56a6": 37, "26e": 36, "27": [17, 18, 33, 35, 36, 37, 38, 42, 43, 45, 51, 52, 53, 54, 60, 63, 65, 66, 67, 68, 70, 75, 76], "270": 32, "2700": 37, "270644": [42, 43], "270694e": 42, "271004": [53, 54], "271083": 54, "27121415181920242836404852697073879596": 68, "272296": 54, "272408": 43, "272662": 54, "273": 37, "273356": 44, "27371": [36, 53], "27372": [36, 53], "274": [37, 54], "2740991": 34, "274247e": 53, "2742583": 68, "274267": 52, "27429763": 67, "274430": 43, "274793": 57, "274825": [13, 65], "27487": 54, "2754": 34, "27540806": 68, "275535": 42, "275596": 70, "276": 37, "276148": 57, "276189e": 52, "2764": 54, "2766091": 36, "27713": 54, "277299": 38, "27751": 54, "277561e": 52, "277968": 57, "278": 58, "2780": 35, "278000": 52, "278303e": 42, "278391": 54, "278434": 48, "2786": [70, 72], "278683": 42, "27951256e": 68, "27986": 54, "28": [35, 36, 37, 42, 43, 47, 50, 51, 52, 53, 60, 65, 66, 67, 68, 70, 75, 77], "280196": 49, "280454dd": 37, "280514": 70, "280963": 56, "281024": 57, "28111364": 36, "2815": 54, "2818": 34, "2819": [70, 72], "282": 76, "282200": 49, "2825": [73, 75], "28251": 54, "282870": 54, "2830": [73, 75], "28326": 54, "2836": 34, "2836059": 35, "28382": 54, "283974": 57, "283994": 57, "28425026": 58, "284271": 50, "284397": 78, "28452": [36, 53], "2849": 54, "284949": 43, "284987": 54, "286027": 65, "286203": 42, "2865": [34, 54], "286507": 44, "286563e": 54, "286593": 54, "287011": 43, "287041": 57, "287384": 58, "287815": 58, "287926": 57, "288": 55, "288006": 53, "288048322": 68, "288850e": 42, "288976": 54, "289": 76, "289357": 43, "289440": [42, 43], "289718": 42, "29": [11, 32, 35, 36, 37, 42, 43, 51, 52, 53, 58, 60, 65, 66, 67, 68, 70, 75], "290987": 53, "291": 54, "2910": 54, "291008": 42, "291011": 67, "291071": 57, "29107127": 57, "291405": 57, "291406": 57, "291434": 43, "291500e": [53, 54], "291517": [42, 43], "291963": 57, "292": 56, "292028": 44, "292047": 70, "292105": 57, "292178": 53, "292302995303554": 44, "292303": 44, "29241328": 68, "2925": 37, "2927": 54, "292997": 57, "29299726": 57, "293218": 57, "293617e": 54, "293960": 42, "294067": [42, 43], "295": 76, "295481": 57, "29548121": 57, "295642": 42, "295837": [38, 63, 75], "2958370000000100000100": [37, 63, 75], "2958370001000010011100": [37, 63, 75], "2958371000000010010100": [37, 63, 75], "296228": 54, "296585": 43, "296729": 52, "29678199": [61, 69], "296901": 42, "297287": [42, 43], "2973": 54, "297349": [48, 49], "297682": 57, "297687": 54, "297749": 54, "297779e": 43, "29784405": 58, "298": [21, 37], "298076": 42, "298120": 44, "298228e": 54, "2984901840": 68, "299": 37, "299537": 49, "299712": 48, "2_": [26, 60, 71], "2_x": [26, 60], "2d": 69, "2dx_5": [44, 57], "2e": [32, 34, 35, 36, 37, 66, 67, 69, 70, 75], "2f": 50, "2m": 71, "2n_t": 46, "2x": 57, "2x_0": [19, 42, 43, 48, 49], "2x_4": 46, "3": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 24, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "30": [19, 32, 33, 35, 37, 40, 41, 42, 43, 44, 45, 51, 52, 53, 54, 57, 60, 65, 66, 67, 68, 70, 75], "300": [32, 33, 41, 44, 54, 57, 62, 76], "30000000000000004": [44, 54, 57], "30031116e": 68, "30093956": 58, "301": 37, "301366": 70, "301371": 57, "3016": 53, "301737": 42, "30189": 54, "302357": 57, "302571": 65, "302648": 52, "303007": 42, "303324": 52, "303489": 57, "303613": 57, "30361321": 57, "30383": 54, "303835": 52, "303f00f0bd62": 37, "304130": 57, "304159": 57, "304201": 46, "304217": 42, "305133": 65, "305255": 43, "30527": 54, "305341": 57, "305612": 52, "305642645": 68, "305775": 57, "305b": 37, "30645": 54, "30672815": 35, "306915": 52, "306963": 57, "307176": 42, "307407": 57, "308": 54, "308568": 43, "308774": 42, "30917769": [48, 49], "309605": 42, "309772": 52, "309823e": 54, "30982972": 57, "309830": 57, "31": [35, 36, 37, 42, 43, 51, 52, 53, 54, 60, 65, 66, 67, 68, 70, 75, 78], "310000e": 54, "310761": 56, "311253": 54, "311712": 48, "3120": 54, "312008": 43, "312882": 43, "313056": 70, "313209": 44, "313324": 54, "31334512": 68, "31337878": 54, "313535": 57, "31378": 37, "314": 68, "314071e": 42, "3141": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 37, 38, 52, 61, 63, 65, 66, 69, 70, 72, 75], "314247": 59, "314341": 42, "314625": 43, "314651": 48, "31476": [53, 54], "315031": 59, "3151": 54, "315155": 43, "315290": [48, 49], "315310": 42, "316": 37, "316193": 57, "31632": 54, "316407": 67, "316540": 52, "316717": [42, 43], "316863": 43, "317064": 42, "317394": 46, "317487": 57, "317607": 57, "318": 37, "318000e": 54, "318411": 59, "318438": 54, "318552": 54, "318584": 70, "318717": 55, "318753": [48, 49], "319": 37, "319100": [48, 49], "319759": 57, "319850": 57, "32": [35, 36, 37, 42, 43, 51, 52, 53, 54, 60, 65, 66, 67, 68, 69, 70, 75], "320": 54, "320314": 53, "320633": 44, "321520": 43, "321686": 70, "32236455588136": 45, "322404": 58, "3234": 54, "323622": 53, "323679": 52, "324": [36, 54], "324518": 56, "32458367": 35, "3245837": 57, "325056": 57, "325090": 54, "326148": 43, "326740": 57, "327": 32, "327265": 43, "327803": 65, "329181": 43, "329339": 45, "32950022e": 68, "329679": 43, "33": [35, 36, 37, 42, 43, 48, 51, 52, 53, 54, 60, 65, 66, 67, 68, 70, 75, 76], "3300": [36, 53], "330143": 57, "33014346": 57, "330285": [42, 43], "3304269": 35, "330615": 57, "330731": [13, 65], "331365": 48, "331521": 57, "331602": 54, "331640": 43, "33175566": 57, "331756": 57, "332502": 43, "332782": [13, 65], "3329": 54, "332996": 52, "3333": [33, 35, 41, 65, 66, 67], "3333333": 37, "33335939e": 68, "3335": 54, "333575": 53, "333655": 42, "333704": 43, "334": 36, "334425": 42, "334750": 44, "334785": 50, "335": 55, "33500": 54, "335121": 43, "335176": 54, "33527": 58, "335609e": 57, "335846": 57, "335853": 54, "336153": 42, "33634311": 68, "336461": 54, "336510": 43, "336612": 46, "337380": 57, "3376": 34, "337619": 45, "338": 58, "33849": 54, "3386": 68, "338603": 42, "338775": 44, "338900": 43, "338908": 44, "339273": 58, "33928": 54, "339570": 57, "339875": [48, 49], "34": [33, 34, 35, 36, 37, 42, 43, 49, 51, 52, 53, 54, 55, 58, 60, 65, 66, 67, 68, 70, 78], "340": [36, 54], "340485e": 42, "341336": [9, 65], "3420": 54, "34218744": 68, "342467": 65, "342675": 35, "34287815": 58, "342989": 54, "342992": 52, "343": 54, "344212": 78, "344305": 50, "344505": [53, 54], "344640": 57, "34475": 53, "344787": [42, 43], "344834": 46, "345065e": 54, "345381": 44, "3453813031813522": 44, "3454": 54, "345852": 43, "345903": 57, "345989": 42, "346206": 57, "346238": 58, "346269": 43, "346678": 56, "347310": [13, 65], "347696": 44, "34769649731686": 44, "347929": 54, "34855394": 68, "34858240261807": 45, "348617": 57, "348700": 43, "3492131": 34, "349383": 52, "34943627": 51, "349638": 43, "34967621": 35, "349772": 49, "35": [36, 37, 42, 43, 44, 52, 53, 54, 57, 65, 66, 67, 68, 70, 71, 78], "3500000000000001": [44, 54, 57], "350165": 66, "350208": 42, "350518": 57, "350712": [48, 49], "35077502": 71, "351629": 54, "351664": 55, "351766": 56, "352": [36, 52], "352250e": 53, "352259e": 54, "3522697": 35, "352365": 42, "352813": [65, 66, 67], "35292": 54, "352990": 54, "352998": 54, "353412": 57, "35341202": 57, "35365143": [2, 4, 5, 7, 8, 9, 10, 11, 12], "353748e": 57, "3538": 34, "354": 54, "354188": 46, "354371": 57, "354688": 10, "355209": 57, "355699e": 42, "356136e": 54, "356167": 49, "356183": 54, "35620768e": 68, "3564": 54, "3565": 54, "356886e": 43, "3569": 67, "357": 54, "357170": 42, "35731523": 67, "358158": [53, 78], "358289": 52, "358395": 58, "358653": 43, "358799": 70, "358977": 53, "359": 78, "359100": 54, "3593": 58, "359307": 43, "35th": 76, "36": [36, 37, 42, 43, 52, 53, 65, 66, 67, 68, 70], "360004": 57, "360065": 70, "360122": 42, "360475": [42, 43], "360655": 54, "360683": 44, "360801": 44, "361518": 44, "361518457569366": 44, "361521": 10, "3619201": 20, "362155e": 43, "36231307e": 68, "363276": 35, "3643": [70, 72], "364595": 35, "3647": 37, "364800": 57, "36501": 54, "36521263": 68, "36557195e": 68, "36566025e": 68, "366": 54, "36616": 54, "366529": 56, "366541e": 42, "366718627": 35, "366950": 42, "367056": 43, "367181": 42, "367323": 57, "367571": 44, "367625": 57, "368092": 43, "368152": 52, "3682": [36, 53, 54], "368324": 52, "368499": 44, "3684990272106954": 44, "369556": 44, "3696": 58, "369796": 57, "369869": 53, "369981": 52, "37": [36, 42, 43, 52, 53, 54, 65, 66, 67, 68, 70], "3702770": 35, "370736": 52, "3707775": 35, "3710": 54, "371357": [53, 54], "371429": 44, "371535": 42, "372": 76, "37200": [53, 54], "372097": 44, "3722": 54, "37231324": 60, "3724": 54, "372427": 43, "372628": 42, "3727679": 35, "372989": 42, "373802": 43, "3738573": 35, "374364": 57, "37436439": 57, "3745": 54, "374821e": 54, "374862": 42, "375077e": 42, "375081": 54, "375465": 57, "376": 68, "376760": 43, "376780": 42, "376806": 43, "377060": 54, "377311": 57, "377669": 43, "378351": 7, "378588": 42, "378596": 52, "378688": 57, "378828e": 42, "378834": 57, "3788859": 35, "379": 76, "379038": 57, "379117": 42, "37939": 54, "379614": 57, "379626": 42, "38": [37, 42, 43, 53, 65, 66, 67, 68, 70], "3800694": 35, "380170e": 42, "380432e": 43, "380837": [53, 54], "3808735489": 68, "381072": 57, "381603": 42, "381623e": 49, "381685e": [53, 54], "381689": 57, "3817": 54, "381826": 11, "382188e": 43, "382286": 54, "382582e": 2, "382684": 65, "382872": 44, "383297": 57, "384": 54, "384443": 43, "384777": 54, "384928": 42, "3851": 54, "385240": 70, "385877e": 43, "385917": 52, "386": [37, 54], "386102": 44, "386502": 54, "386834": 43, "386894": 43, "386988": 45, "387": 37, "3871": 34, "387426": 57, "387780": 57, "388071": 57, "38818693": 68, "388216e": 66, "388298e": 42, "388593e": 43, "388668": 57, "38866808": 57, "388871": 54, "389": 37, "389126": 67, "389566": 56, "38973512e": 68, "38990574": 68, "39": [32, 34, 35, 36, 37, 38, 42, 43, 45, 49, 50, 51, 52, 53, 54, 58, 59, 60, 65, 66, 67, 68, 70], "39010121e": 68, "390379": 57, "390599": 43, "3915005": 68, "392242": 50, "39236801": 51, "392400": 54, "392623": 43, "392752": 45, "392833": 58, "392864e": [53, 54], "393060": 65, "39309088": 68, "393604": 44, "39425708": 35, "395076e": 54, "395136": 52, "395268": 65, "395603": 42, "395889": 54, "39611477": 36, "396173": 48, "39621961e": 68, "396300": 48, "3964": 54, "396531": 54, "396985": 52, "396992": [42, 43], "397140": 44, "397155": 43, "39727": 54, "397313": 34, "397578": 50, "397811": 58, "398": [63, 75], "3985": 54, "398770": 57, "398999": 65, "399": 36, "399056": 57, "399207": 43, "399223": 46, "399355": 46, "399692": 57, "399858": 59, "3cd0": 37, "3dx_1": [44, 57], "3e1c": 37, "3ec2": 37, "3f5d93": 55, "3x_": 57, "3x_4": [44, 57], "4": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 17, 18, 26, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 77], "40": [35, 42, 43, 44, 45, 49, 53, 54, 55, 57, 60, 63, 65, 66, 67, 68, 70, 71], "400": 52, "4000000000000001": 66, "40000000000000013": [44, 54, 57], "400164": 50, "40029364": 71, "400823": 57, "400855956463958": 44, "400856": 44, "400910": 42, "401": [14, 78], "401247": [69, 70], "40127723e": 68, "401861": 42, "401931": [48, 49], "402077": 54, "402113": 70, "402301e": 66, "402902": 54, "403425": 57, "4035699755": 61, "403569975514042": 61, "4035699755140420": 61, "403715": 2, "4037269089": 69, "4039": 34, "404318": 34, "404411": 42, "40452": 54, "404550": 56, "405203": 46, "405374": 54, "405400e": 42, "40583": 34, "405890": [13, 65], "406": 53, "406285": 57, "406446": 44, "4065173": 68, "40676": 34, "407558": 42, "408014": 50, "408476": 71, "40847623": 71, "408479": 52, "408539": 57, "408565": 57, "409154": 34, "4093": 58, "409328": 54, "409395": 57, "409746": 44, "409848": [42, 43], "41": [32, 42, 43, 53, 54, 65, 66, 67, 68, 70, 72], "410124": 43, "410393": 44, "410667": 65, "410681": 46, "410795": 52, "41093655": 68, "411190": [42, 43], "411291": 56, "411295": 57, "411304": [42, 43], "411447": 54, "411582": 57, "411869": 43, "412004": 48, "412127": 57, "412304": 59, "412364386": 68, "412477": 46, "412653": 52, "412714": 44, "412726": 43, "412838": 43, "41336": 66, "41341040": 35, "413608": 57, "413933e": 43, "414073": 8, "414533": 43, "41500595": 68, "41525168e": 68, "415465": 43, "41566": 67, "415812": 78, "415988": 54, "416132": 43, "4166": 54, "4166667": 37, "416757": 57, "416899": 42, "417640": 42, "417767": [48, 49], "417822": 53, "41798768e": 68, "418056": 57, "41805621": 57, "41836": 53, "418360": 53, "418806e": 44, "41918406e": 68, "419371": 57, "41989983e": 68, "4199952": 35, "41e5": 37, "42": [4, 5, 32, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 54, 56, 57, 58, 59, 60, 65, 66, 67, 68, 70, 72, 76], "4200": 54, "420316e": 54, "420608e": 58, "42073312": 35, "420967": 44, "421083": 34, "4211349413": 35, "421200": 59, "421234": 65, "421357": [48, 49], "421576e": 54, "421793": 58, "421919": 54, "422007": 58, "422266": 54, "422293e": 65, "422325": 44, "423186": 68, "42338": 54, "4235839": [48, 49], "42388745": 60, "423921e": 65, "423951": 34, "424108": 44, "424127": 68, "42412729": 35, "424292": 42, "424328": 57, "424651": 67, "424700": 43, "424717": 44, "424748": 59, "425": 52, "425072": 49, "425103": 34, "425208": 54, "425445727": 68, "425493": 34, "42550": 54, "426055": 34, "426283": 42, "426540": 52, "426540301": 35, "426736": 54, "427": 54, "427101": 42, "427486": [42, 43], "42755087": 58, "427551": 58, "427573": 52, "427725": 57, "428": [70, 72, 78], "428046": 56, "42811700": 78, "428255": 57, "428411": [53, 54], "428467": 57, "4284675": 57, "428588": 42, "428771": [13, 65], "4290": 34, "429057": 43, "429705": 42, "429986": 43, "42ba": 37, "43": [36, 42, 43, 65, 66, 67, 68, 70], "430298e": [53, 54], "430595": 43, "4311947070055128": 66, "431306": 57, "431701914": 73, "431848": 42, "431852": 43, "432125e": 53, "432300e": 57, "43231359e": 68, "432484": 42, "43294": 37, "432f": 37, "433": 37, "433221": 44, "4336": 54, "43374433": 60, "433750": 42, "4339": 34, "434519": 65, "434535": 57, "43453524": 57, "434677": 43, "4347905": 68, "435": 37, "43503345": 67, "43511": 54, "435401": 52, "4357": 54, "435927": 54, "435967": 52, "43597565": 57, "435976": 57, "436": [37, 54], "436194": 42, "43627032": 45, "436327": 54, "436806": 54, "437594": 42, "437767": 53, "437924": 54, "438": 52, "438219": 57, "438289": 54, "438569": 54, "438578e": 54, "438709": 53, "43883": 49, "4389": 54, "438960": 52, "439541": [53, 54], "43989": 65, "43e": 68, "43f0": 37, "44": [42, 43, 45, 65, 66, 67, 68, 70], "440320": 54, "440364": 65, "440605": 66, "440747": 42, "440a": 37, "4410428": 68, "44114931": 68, "441153": 57, "441209": 57, "441219": 48, "44124313": 67, "4416552": 35, "441893": 42, "442202": 43, "442462": 43, "4426902": 68, "443016": 44, "443032": 53, "44312177": 36, "443686": 57, "4437": 54, "443701": 50, "444046": 54, "4444": [33, 35, 41, 67], "444500": [53, 54], "444850": 54, "4449272": 54, "445473": 42, "445476": 42, "44563945e": 68, "445642": 42, "4461928741399595": 44, "446193": 44, "4462": 37, "44647451": 58, "44713577e": 68, "447492": 54, "447624": [42, 43], "447706": 44, "447849": 45, "447999": 49, "448": 54, "448587": 44, "448745": 57, "448842": 43, "4489": 54, "44890536": 68, "448923": 50, "448973": 43, "449107": 5, "449150": [13, 65], "449406e": 42, "44950": 54, "44fa97767be8": 37, "45": [42, 43, 44, 48, 50, 53, 54, 57, 65, 66, 67, 68, 70], "4500": 53, "45000000000000007": [44, 54, 57, 66], "450152": 52, "450870601": 35, "450926e": 42, "452": 37, "452091": 54, "452114": 65, "452484e": 43, "452488701": 35, "452489": 52, "453": 37, "453279": 42, "4535": 54, "4539": 37, "454081": 54, "454185": 43, "454397": 57, "45467447": 68, "455": 37, "45500": 54, "455078": 44, "455091": 43, "455107": 44, "455120": 57, "4552": 37, "455293": 44, "4552b8af": 37, "4553632265": 68, "455448": 58, "455672": 54, "4559565": 70, "45595650": 70, "455981": 71, "456370": [43, 52], "456432": 42, "456552": 65, "4567": 58, "456892": 44, "457088": 57, "457252": 43, "457667": 54, "458114": 54, "458420": 54, "4584447": 35, "458784": 42, "458855": 36, "458976": 43, "4592": 35, "459200": 52, "459383": 44, "45957837": 68, "459584e": 43, "459760": 54, "459812": 44, "459913": 42, "46": [42, 43, 50, 51, 65, 66, 67, 68, 70, 72], "460": 54, "4601": 54, "460207": [42, 43], "460218": 44, "460289": 57, "460535": 65, "4610": 78, "461458": 43, "461629": 59, "462321": 11, "462451": 44, "462567": 43, "462979": 42, "463325": 57, "4634": 54, "463418": 59, "463668": 54, "463766": 49, "463857": 54, "463903": 43, "463b": 37, "464076": 44, "464284": 52, "46448227": 68, "464668": [9, 65], "4648876": 68, "46507214": 58, "465212699957609": 61, "4652126999576090": 61, "4652127": 61, "465649": 59, "465730": 59, "4658181": 68, "465832": 43, "466047": 57, "46618738": 68, "466440": 44, "466756": 57, "467": 54, "46709481": 68, "46722576e": 68, "467613": 52, "467613401": 35, "467681": [42, 43], "467770": 44, "468": 32, "468051e": 43, "468072": 43, "468075": 57, "46807543": 57, "46811985": 57, "468120": 57, "468406": 54, "468919": 54, "468d": 37, "469": 37, "469474": 59, "469825": 44, "469895": 43, "47": [36, 42, 43, 45, 53, 58, 65, 66, 67, 68, 70, 77], "470458": 42, "470904": 42, "472": 54, "47222159": 60, "472255": 54, "472657": 43, "472784": 55, "472891": 57, "472e": 37, "473099": 44, "47419634": 75, "474214": [48, 49], "4742479": 68, "474731": 65, "474846": 53, "475304": 54, "475569": 42, "47659": 67, "476856": 44, "477130": [42, 43], "477150": 57, "477247": 43, "477443": 42, "477474": 52, "47759584": 68, "47761563": 45, "478032": 54, "4781": 54, "47857478": 68, "47966100e": 68, "479722": 43, "479860": 54, "479876": [48, 49], "479882": 43, "479928": 57, "47be": 37, "48": [37, 42, 43, 53, 54, 65, 66, 67, 68, 70], "480133e": 57, "48029755": 58, "480579": 43, "48069071": [61, 69, 70], "480691": [69, 70], "480800e": 57, "481172": 57, "481218": 54, "481399": [53, 54], "481705": 67, "481761e": 54, "482": 37, "482012": 48, "482038": 44, "48208358": 57, "482084": 57, "482461": 71, "48246134": 71, "482483": 57, "482790": 46, "48296": 58, "48315": 58, "483186": 46, "483192": [53, 54], "48331": 58, "4834031": 68, "4835": 54, "483711": 57, "483717": 44, "48390784": 67, "483944": 42, "48404": 35, "4845": 54, "484640": 57, "4849": 37, "485": [37, 54], "48519611": 68, "485377": 42, "48550": 59, "485617": [53, 54], "485812e": 54, "48583": [53, 54], "485871": 49, "486": [22, 54, 55], "486202": 44, "486532": 57, "48661": 54, "487": 54, "487467": 54, "487641e": 57, "487872": 40, "488460": 54, "488485": 54, "48873663": 45, "488811": 57, "488909": [53, 54], "488982e": 44, "4895498": 57, "489550": 57, "489699": 44, "49": [37, 42, 43, 65, 66, 67, 68, 70], "490000e": 54, "490070931": 35, "4901455": 68, "490488e": 53, "490504e": 54, "490700": 57, "490941": 54, "49098": 66, "491034": 42, "49113": 68, "491245": 52, "4915707": 67, "492": 54, "492417e": 67, "492454": 43, "4925583": 68, "492656": 43, "49270769e": 68, "493": 76, "493144": 59, "493219": 57, "493313": 54, "493325": 4, "494089": 43, "494129": 57, "494324": 52, "494324401": 35, "495": 56, "49530782": 35, "495657": 44, "495752": 57, "4958502": 61, "495850216426873": 61, "4958502164268730": 61, "49596416e": 68, "496": 56, "49650883": 58, "496551": 57, "496674": 55, "496714": 59, "496777": 78, "497": 56, "497298": 65, "497422": 43, "497655": 5, "497674": 45, "497964": 65, "498": 56, "498921": 57, "498979": 54, "498f": 37, "499": [54, 56, 63, 75], "499000e": [53, 54], "499096": 55, "4997": 68, "499776": 54, "49d4": 37, "4a53": 37, "4b8f": 37, "4dba": 37, "4dd2": 37, "4e": [35, 36], "4ecd": 37, "4fee": 37, "4x": 57, "4x_0": [19, 42, 43, 48, 49], "4x_1": [19, 42, 43], "5": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77], "50": [13, 35, 37, 44, 46, 49, 51, 53, 54, 55, 57, 65, 66, 67, 68, 70], "500": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, 21, 24, 33, 37, 38, 41, 42, 43, 48, 49, 51, 53, 56, 58, 62, 63, 65, 66, 67, 69, 70, 71, 72, 75, 78], "5000": [42, 43, 44, 57], "50000": 52, "500000": [53, 54], "5000000000000001": [44, 54, 57], "500084": 57, "500267": 50, "5003517412": 35, "500517": 57, "500904": 55, "50093148e": 68, "501021": 54, "501954": 43, "501983": 57, "502054": 43, "502084": 67, "502494": 44, "5025850": 35, "502595": 43, "502612": 57, "50277392": 68, "502843e": 43, "502901": 43, "502995": 57, "503326": 55, "503504": 66, "503511": 54, "50398782e": 68, "504286": 52, "5042861": 35, "504569": 42, "50476159": 68, "5050973": 35, "505913": 42, "506050": 42, "506159e": 42, "506644": 42, "506659": 54, "506687": 54, "50672034": 35, "506900e": 57, "506903": 44, "5074": 68, "50768b": 55, "508": 32, "508153": 56, "508433": 42, "508459": 52, "5085": 54, "508630": 43, "508947": 67, "509059": 54, "509196": 57, "509339693389362": 61, "5093396933893620": 61, "5093397": 61, "509461": 57, "50967": 59, "5096700473980302": 59, "5097": 59, "509782": 43, "5098": [38, 63, 75], "509853": 57, "5099": [37, 38, 63, 75], "509951": 44, "509958": 52, "51": [34, 36, 37, 48, 65, 66, 67, 68, 70, 77], "510000e": [53, 54], "510385": 52, "51079110": 35, "510982": 53, "511022": 65, "511293": 53, "511515": 54, "511540": 54, "511862": 57, "512": 52, "5120025": 68, "512081e": 42, "512108": 57, "512149": 57, "51214922": 57, "51243406e": 68, "512519": 52, "512572": 57, "512672": [67, 71], "5127786": 68, "512832": 42, "513052": 42, "5131": 53, "513992": 57, "514": 37, "514160": 42, "514173": 43, "514545": 54, "515031": 42, "51504544": 67, "515358": 44, "5154": 54, "5154789948092002": 52, "5155": 37, "516": 37, "516125": 44, "516222": 57, "516255": 57, "516256": 57, "516528": 57, "516888": 42, "517": [37, 52], "517266": 43, "5175": 54, "517785": 42, "518175": 52, "518446": 54, "518682": 43, "518767": 42, "518782": 54, "518846": 52, "519622": 42, "51966955": 35, "519710": 57, "519888e": 43, "52": [34, 37, 50, 65, 66, 67, 68, 70], "520": 54, "520641": 58, "520930": 44, "521002": 44, "521085": 65, "5211179": 68, "521611": 43, "522753": 10, "522835": 46, "523030": 59, "523163": 44, "5232": 51, "52343523e": 68, "523794e": 57, "523807": 56, "523977545": 35, "524088": 42, "52424539": 35, "524657": 57, "5249": 66, "524934": [42, 43], "5250": 54, "52510803": 36, "525135": 43, "525138": 42, "5251546891842586": 59, "5255": 37, "52590": [36, 53], "526": 52, "526532": 54, "526769": [42, 43], "527452": 43, "527728": 43, "528381e": 60, "528580": 57, "528937": [48, 49], "528996901": 35, "528997": 52, "529": 52, "529405": 34, "529782": 34, "529969": 43, "53": [34, 37, 63, 65, 66, 67, 68, 70, 73, 76], "530132": 55, "530940": 57, "53094017": 57, "531": 37, "531223": 44, "531327": 59, "531594": 54, "53209683": 67, "532266": 44, "53257": 66, "532738": 57, "53273833": 57, "532751": 48, "5329": 54, "533489": 46, "5338047": 68, "533900": 57, "5346": 37, "535179": 57, "535278991538703": 61, "535279": 61, "535318": 57, "535609": 54, "535718e": 54, "53606675": 57, "536067": 57, "536143": 54, "536746": 57, "536798e": [53, 54], "537240": 57, "53724023": 57, "53791422": 67, "538": 37, "538013": 54, "5382": 58, "538937": [53, 54], "539455": 57, "539475": 57, "53947541": 57, "539491": [48, 49], "539767": 44, "54": [34, 36, 37, 45, 55, 62, 65, 66, 67, 68, 70, 77], "540240": 54, "540270": 43, "540542": 53, "540789": 42, "5408": 34, "541159": 57, "54163": 58, "541821": 54, "541990": 54, "542159": 43, "542333": 54, "542451": 57, "542560": 59, "542584": 44, "5425843074324594": 44, "542647": 57, "542671": 52, "542816": 11, "5428753": 61, "54287532563466": 61, "542883": 71, "5428834": 71, "542919": 65, "542989": 57, "543": [52, 54], "543075": 44, "543136": 44, "543358": 65, "543380": 52, "5436005": 35, "543691": 43, "543764": 49, "54378": 58, "543832": 57, "544097": 57, "54428539": 68, "544383": 59, "5443965": [69, 70], "54440": [69, 70], "544555": 52, "544669": 48, "54517706e": 68, "545602": 43, "545605e": 57, "545761": 59, "545919": 54, "546294": 54, "5467606094959261": 44, "546761": 44, "54687448": 68, "547039": 42, "54716": 58, "547324": 43, "547431": 56, "5476": 54, "5479": 54, "547909": 54, "548207": 68, "549": 32, "549109e": 54, "5493413": 68, "549645": 65, "55": [36, 37, 44, 49, 53, 54, 57, 65, 66, 67, 68, 70], "5500000000000002": [44, 54, 57], "551": 78, "551317": 43, "551355": 43, "551586928482123": 44, "551587": 44, "551686": 44, "55173": 66, "5518": 54, "552": 54, "552058": 58, "552508": 54, "552727": 52, "552776": 57, "55348": 66, "553878": [12, 65], "553916": 54, "553965": 42, "554076": 44, "554203": 43, "554364": 55, "554793e": 68, "555": 52, "555137": 43, "555150": 54, "555445": 56, "555498": 57, "5555": [33, 41], "555536": 42, "555949e": 54, "555954": 54, "556191": [42, 43], "556792": 57, "557267": 42, "5574dcd4": 37, "557595": 52, "557731": 56, "557999": 52, "558134": [42, 43], "5584": 52, "5585": 52, "558655": 44, "5589": 52, "559": 78, "5590": 52, "559144": 44, "559186": 44, "5592": 52, "559394": 57, "559522": 57, "559680": 54, "55dc37e31fb1": 37, "55e": 36, "56": [37, 62, 65, 66, 67, 68, 70, 73, 76, 78], "560135": [69, 70], "56018481": 57, "560185": 57, "5602727": 45, "560545e": 42, "560689": 34, "561183e": 43, "5616": 53, "561711": 54, "561785": 67, "561819": 42, "562001": 43, "562013": 57, "562153": 42, "56223": 58, "562288": 59, "562518": 54, "5625561": 34, "562557": 42, "562712": [42, 43], "56281409": 68, "563374e": 44, "563503": 57, "563528": 54, "563673": 54, "563851e": 42, "56387280e": 68, "56390147e": 68, "564045": 57, "564073": 54, "5641": 54, "564142": 44, "564232": [42, 43], "564451": 43, "564537": 43, "564577": 54, "565066": 44, "566": 59, "566024": 57, "566091": 54, "567004": 58, "567343": 54, "567364": 43, "567529": 57, "567531": 42, "567568": 42, "567695": 42, "567945": [48, 49], "568082": 55, "568111": 65, "569135": 43, "569540": 43, "56965663": 57, "569657": 57, "569684": 43, "569911": 35, "569979": 55, "5699994715": 35, "57": [37, 65, 66, 67, 68, 70, 78], "570038": 44, "5700384030890744": 44, "570111": 56, "5702": 54, "570486": 34, "570562": 34, "570722": 75, "570936": 42, "571707": 65, "571778": 34, "5718": 54, "572153": 65, "5722": 53, "57245066": 57, "572451": 57, "572991": 43, "573700": 46, "574": 37, "574904": 43, "57496671": 35, "575": 15, "57505": 66, "57572422": 58, "575810": 42, "57585824": 58, "57592948e": 68, "57599221": 58, "576": 37, "5763996": 35, "57643609": 58, "577": 37, "5770": 53, "57715074": 35, "577271": 52, "577422": 42, "5776971": 58, "57775704": 58, "577807": [42, 43], "577813": 42, "578081": 54, "578307": 57, "578523": 52, "578557": 43, "578846e": 44, "57914935": 36, "579213": 59, "579216": 59, "579238": 44, "579322e": 53, "579605e": 43, "57e": 36, "58": [16, 36, 53, 59, 65, 66, 67, 68, 70, 77, 78], "5800": 54, "58000": 53, "580231e": 43, "580368": 42, "5804": 37, "580477e": 43, "58067723": 68, "580922": 48, "581655": 54, "581849": 43, "581868": 42, "582146": 43, "58241568": 68, "582747": 43, "582761": 44, "583034": 48, "583195": [42, 43], "5833333": 37, "583404": 53, "583508": 42, "583534": 57, "584012": 54, "584742": 49, "584849": 44, "584877": 43, "584928": 42, "584942e": 52, "5852": 54, "585426": 68, "585793": 44, "586362": 57, "5864": 34, "5866": 54, "586719": 44, "586719493648897": 44, "5868472": 35, "587135": 43, "587292": 54, "58765": 66, "588": 54, "588000": 65, "588364": 65, "588992e": 43, "589": 32, "589248": 58, "589440": 44, "59": [65, 66, 67, 68, 70, 78], "590320": 46, "5905": 53, "590736": 57, "590813": 57, "590911": 44, "590991": 44, "591080": 46, "591411": 48, "591441": 2, "591741": 53, "591782": 57, "591788": 53, "59199423e": 68, "592186": 43, "592681e": 44, "59268336": 68, "59307502e": 68, "593648": 66, "593754e": 49, "593981": 65, "594": 15, "594241": 65, "594316e": 57, "595353": 44, "596": 54, "596069e": 54, "5962": 53, "596270": [48, 49], "5964": 51, "596758": 42, "597": 36, "597098": 54, "597923": 54, "598080": 42, "598178": 54, "598539": 43, "59854797": 67, "5985730": 36, "59861": 54, "5cb31a99b9cc": 37, "5d": [44, 57], "5x_2": 46, "5x_3": 46, "5z_i": 57, "6": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 22, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77], "60": [35, 44, 45, 54, 55, 57, 60, 65, 66, 67, 68, 70, 76], "600": 52, "6000": 54, "6000000000000002": [44, 54, 57], "600000e": 54, "600215": 55, "600254": 56, "600438": 50, "600694": 67, "600934": 65, "601": 36, "601061": 44, "601149": 42, "601314": 42, "601598": 52, "601645": 43, "602079": 49, "602168": 44, "602587": 57, "602628": 44, "6029": 54, "603273": 42, "604016": 54, "604111": 54, "604227": 53, "604603": 5, "604825": 54, "604841": [53, 54], "605": 54, "605195": 49, "606034": 57, "606129": 57, "606342": 44, "606759": 54, "6068": 35, "606800": 52, "606954": 44, "607080": 43, "607264": 42, "6075": 78, "607600": 54, "60771625": 68, "608": 47, "608003e": 43, "608392": 57, "60857": 34, "608818": 58, "609205": 42, "609575": 67, "61": [65, 66, 67, 68, 70, 77], "610195e": 42, "610559": 43, "611": 78, "6110": 54, "611269": 52, "611859": 49, "612151": 43, "612792": 54, "61283916": 68, "6133": 36, "613314": 44, "613408": 57, "613498": 54, "613574": 50, "613622": 43, "613691": 67, "614185e": 43, "614188": 52, "614678": 54, "615498": 2, "615573e": 43, "615574": 43, "615863": [48, 49], "61669761": 71, "616698": 71, "616797": 43, "616828": 54, "617": 52, "617283": 54, "6173": 37, "617800": 43, "617877": 57, "618069": 53, "61810738": 36, "618256": 43, "618776": 45, "618922e": 42, "619128": 43, "619177": 53, "619351": [42, 43], "619390": [42, 43], "619454": 46, "619613": 53, "61e": [36, 78], "62": [2, 50, 65, 66, 67, 68, 70], "620156": 57, "620407": 42, "620874e": 67, "6209816": 68, "620995": 60, "621094": 54, "621318": 57, "62131806": 57, "621490": 57, "6215": 53, "622": 54, "622153": 54, "622301": 42, "6224": 35, "622949": 42, "623024": 44, "623147": 49, "623173": 42, "623197": 53, "623681e": 70, "624": 52, "6240": 58, "62403053": 45, "624224e": 42, "6243811": 35, "624482e": 42, "624535": 66, "624798": 53, "624919": 54, "624988": 54, "625": [35, 52], "625477": 57, "625766": 48, "625891": [48, 49], "626433": 57, "6266": 54, "626633": 43, "627505": [48, 49], "627560": 57, "627564": 44, "627588e": 54, "628069": 52, "629306": 43, "629346": 54, "629549": 43, "629771": 43, "63": [35, 52, 65, 66, 67, 68, 70, 76, 77], "630150e": 57, "630914": 50, "631333": 57, "6318": [53, 78], "631821": 43, "632058": 52, "63245862e": 68, "632747e": 57, "6328366": 70, "632958": 56, "633350": 43, "633433": 52, "634055": 42, "63407762": 78, "634078": [53, 78], "634577": 70, "63499": 54, "635000e": [53, 54], "635199": [53, 54], "635296": 50, "63593298": 67, "635943": 55, "636048": 67, "636453": [9, 65], "636575": 44, "637326": 57, "6379": 53, "638264": 57, "638742": 43, "638888": 50, "639135": 52, "63916605": 36, "639345": 54, "639580": 43, "64": [43, 53, 54, 65, 66, 67, 68, 70, 75], "640": 54, "640900": 54, "6411571": 68, "641528": 57, "641547": 57, "64154727": 57, "64197957": 57, "641980": 57, "6420": 54, "642016": 57, "64269": 58, "642735": 53, "643133": 54, "64340": 58, "643512": 44, "643752": 57, "644": 78, "644113": 65, "644182": 65, "644665": 44, "64476745e": 68, "644799": 46, "644985": 42, "645": 54, "64579": 34, "6458": 35, "645800": 52, "646937": 46, "646997": 42, "647002": 54, "647004": 67, "647010": 54, "647196": 46, "64723": 58, "647689": 59, "647873": 57, "64797": 58, "649": 76, "649158": 57, "649891": 43, "65": [44, 50, 54, 57, 65, 66, 67, 68, 70], "650": 47, "6500000000000001": [44, 54, 57], "650000e": 54, "650802": 43, "650810": 54, "650867": 44, "651127": 43, "652071": 54, "6522": 76, "652312": 48, "652349": 57, "652350": 52, "652450e": [53, 54], "6527": 47, "652778": 52, "6528": 54, "6530": 54, "653820": 65, "653846": 44, "653901": [42, 43], "653991": 65, "654070e": 67, "654755": 46, "655284": 57, "6553": 78, "6554": 76, "655422": 54, "655547": 42, "65557405e": 68, "656526": 43, "657": 37, "657024": 42, "657470": 43, "658": 52, "658267": 57, "6586": 34, "658702": 43, "659": 37, "659245": [42, 43], "659339": 43, "6593871": 34, "659423": [42, 43], "6594250": 68, "659605e": 42, "659636": 44, "6598": 51, "66": [51, 55, 65, 66, 67, 68, 70, 75, 77], "660": 37, "660320": 49, "660479": 67, "660776": 57, "661369": 56, "661388": 42, "661391": 50, "66184": 67, "6625": 54, "663081975281988": 44, "663082": 44, "663182": 44, "663529": 57, "663533": 54, "664103e": 54, "664147": 54, "664276": [65, 66, 67], "664824": 54, "664850": 52, "665264": 57, "665554": 42, "665585": 43, "66601815": 67, "666104": 57, "666259": 43, "666307": 46, "6666667": 37, "666865": 42, "666912": 43, "667": 52, "667492e": 54, "667536": 57, "667614": 44, "667614205604159": 44, "668337": 54, "668452": 50, "668584": 46, "668981": 48, "6695": 67, "66989604": 45, "67": [32, 37, 42, 53, 55, 59, 65, 66, 67, 68, 70, 75], "670867": [13, 65], "671271": [42, 43], "67136": 54, "6716717587835648": 44, "671672": 44, "671690": 42, "6722": 37, "672234": [42, 43], "672368": 44, "6723684718264447": 44, "672384": [42, 43], "67245350": 35, "673092": [42, 43], "673302": 52, "673586": 42, "67410934": 35, "6745349414": 35, "674552": 54, "674609": 44, "674936": 43, "674949e": 58, "675293": 56, "675625": 65, "675733e": 43, "676405": 44, "6765": [36, 53], "676534": 70, "676756": 57, "676807": 53, "677614": 57, "677980": 44, "678117": 54, "678369": 43, "678826": 44, "67936506": 67, "6795": 53, "679539": 52, "67ad635a": 37, "68": [37, 58, 65, 66, 67, 68, 70], "680": 54, "680620": 43, "6810775": 58, "681176": 52, "681246": 43, "681448": 54, "681521": 42, "681562": 54, "681817dcfcda": 37, "682269": 54, "682353": 43, "682631": 43, "682875": 44, "683487": 43, "683581": 67, "683942": 57, "683984": 10, "684": 78, "68410364": 36, "68411700": [36, 78], "684142": 42, "684502": 57, "685104": 4, "685107": 57, "68554404e": 68, "68562150e": 68, "685807": 57, "686378447": 68, "686627": 42, "687345": 57, "687619": 43, "687647": 57, "687854": 46, "687871": 52, "6878711": 35, "688": 76, "6887": 68, "688747": 54, "688918": 54, "689088": [42, 43], "689188": 46, "689392": 57, "69": [50, 65, 66, 67, 68, 70, 77], "690334": 44, "6903344145051182": 44, "690668": 43, "690796e": 43, "691136": 65, "691157": 45, "69140475e": 68, "691423": 42, "691511": 53, "691814": 42, "691911": 65, "692199": 43, "692297": 43, "692465": 43, "692725": 57, "692907": 54, "693316": 54, "693497e": 54, "693513": 43, "693632": 42, "693690": 54, "693796": 52, "694154": 44, "694839": 43, "694845e": 54, "694919": 52, "6950": 54, "695045": 42, "69508862": 67, "695581": 50, "69562150e": 68, "696011": [12, 65], "696289": [48, 49], "696770": 65, "69684828": 67, "697": 52, "697000": 44, "697089": 42, "697420": [48, 49], "697545": 57, "697616": 43, "698223": 46, "698244": 46, "69840389e": 68, "698509": 42, "698694": 52, "699035": 57, "699082": 44, "69921": 37, "699259e": 57, "699333": 44, "6_design_1a": 47, "6_r2d_0": 47, "6_r2y_0": 47, "6b": [70, 72], "6cea": 37, "7": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 17, 18, 24, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77], "70": [36, 44, 48, 53, 54, 57, 65, 66, 67, 68, 70, 77], "700": [42, 43, 47, 52], "7000000000000002": [44, 54, 57], "700015": 57, "700102": 57, "701078": 57, "701088": 53, "701265": 48, "701413": 54, "701672e": 44, "701866": 57, "7018663": 57, "701966": 54, "702489": 54, "703049": 42, "703772": 54, "703942": 65, "7040": 54, "704814": 42, "705090": 43, "705354": 42, "705456": 42, "705474": 49, "705581": 54, "70583": 58, "706056": 54, "706231": 65, "706645": 44, "706657": 44, "706862": 5, "707125": 43, "707197": 65, "707738": 43, "707868": 57, "707963e": 53, "708190": 52, "708235": 42, "708459": 57, "708465": 43, "708695": 61, "708695026860755": 61, "7086950268607550": 61, "709026": 46, "709596": 42, "709606": [13, 65], "71": [65, 66, 67, 68, 70, 77], "710586e": 52, "711024": 54, "711328": 54, "711518": 54, "711638": 67, "711834": 43, "712082": 54, "712157": 56, "712503": 58, "712592": 53, "712774": 48, "712960": 44, "713": 54, "713407": 54, "713457": 42, "713959": 43, "713986": 54, "714": 68, "714240": 52, "714557": 43, "714651": 57, "71465114": 57, "715013": 54, "715075e": 42, "715180e": 54, "7154": 54, "715407": 44, "7155": 54, "715515": 43, "7158581": 35, "7161": 54, "716316": 42, "716387": 42, "716456": 57, "716595e": 54, "716762": 44, "716793": 44, "716799": 52, "7167991": 35, "717": 54, "717130": 54, "717185": 57, "717860": 65, "72": [65, 66, 67, 68, 70, 77], "720559": 42, "720571": 57, "720573": 42, "720664": 52, "721018": 42, "721071": 57, "721245": 43, "7215093d9089": 37, "72155839e": 68, "721609": 54, "722316": 57, "722634": 57, "722848": 44, "722881": 57, "7229": 54, "723": 37, "723314": 57, "723345e": 57, "7239": 54, "7239258076897552": 59, "723926": 59, "724": 32, "7241399": 35, "724338": 57, "724603": 42, "724767": [48, 49], "724918": 59, "725": 37, "725087": 54, "725166": 57, "725802": 5, "725820": 43, "726": 37, "7268131": 35, "727543": 46, "727693": 54, "727704": 54, "727976": 44, "7282094": 67, "728294": 56, "728710": 57, "72875815e": 68, "728852": 54, "73": [36, 65, 66, 67, 68, 70], "730023": 54, "7308": 34, "730884e": 43, "731317": 44, "731964": 55, "732067": 42, "732405": 53, "732586": 53, "7326": 54, "732638": 57, "73285": [9, 65], "732918": 48, "733": 54, "733047": 43, "733644": 42, "734635": 42, "734689": 42, "734770": 43, "734948": 57, "735048": 43, "735054": 43, "735369e": 65, "735656": 42, "7357": 54, "735848": 65, "735941": 8, "735964": 46, "736001": 42, "736082": [42, 43], "736084": 57, "73608412": 57, "736823": 43, "737052": 54, "7375615": 36, "73764317e": 68, "737694e": 42, "737951": [42, 43], "738065": 43, "738223": 54, "738315": 54, "738659e": 54, "738793": 65, "739": 54, "7395359436844482": 44, "739536": 44, "739720": 54, "739817": 50, "74": [16, 36, 53, 65, 66, 67, 68, 70, 77], "740": [52, 53], "740180e": 57, "740417": 53, "740869": 44, "741104": 44, "741702": 57, "7418": 34, "74189": 37, "742": 32, "742128": 57, "742375": 42, "742407": 56, "742758e": 43, "742907": 57, "7432": 34, "743247": 54, "743341": 43, "7437": 54, "74402577": 57, "744026": 57, "744228": 43, "744236": 58, "74461783e": 68, "745": 54, "745444": 42, "745714": 53, "745881": 42, "746361": 57, "746843": 49, "7470": 54, "747646": 54, "747945": 35, "747961": 54, "748377": 53, "748513": 54, "748880": 54, "74938952": 67, "749443": 54, "749540": 42, "75": [13, 16, 18, 37, 42, 44, 46, 53, 54, 57, 65, 66, 67, 68, 70, 72, 77], "75000": 59, "7500000000000002": [44, 54, 57], "750000e": 54, "750571e": 43, "750597": 43, "751013": 54, "751261": 54, "7513647": 68, "751482e": 49, "751633": 54, "75171": 53, "751710": [44, 53], "752015": 7, "752283": 54, "7533": 53, "753393": 42, "753523": 57, "753866": 43, "754448": 42, "754710": 42, "7548": 59, "7548350236990151": 59, "754870": 52, "755": 53, "755688": 42, "755717": 42, "755910": 54, "7559417564883749": 44, "755942": 44, "7560824": 35, "756647": 42, "756805": 52, "756867e": 54, "756905": 5, "756969": 44, "757": 76, "757151": [42, 43], "757183": 44, "757411": 57, "757727": 55, "757819": 52, "757917e": 57, "758391": 54, "75887": 37, "759006": 45, "759833": 43, "76": [65, 66, 67, 68, 70, 76, 77], "760104": 57, "7603": 34, "760386": 67, "760494e": 43, "760778": 52, "760915": 46, "761": [35, 52, 78], "761429": 43, "761714": 44, "762237": 42, "76223884": 68, "762284": 57, "76228406": 57, "762748": 54, "763219": 42, "763691": 54, "764093": [42, 43], "76419024e": 68, "764315": 57, "76444177e": 68, "764478": 56, "7646": 54, "764798": 57, "764953": 53, "765": 53, "765202": 54, "765363": [42, 43], "765500e": [53, 54], "765710e": 60, "765792": 57, "765864": 58, "76591188": 35, "7660": 34, "7663": 54, "766499": 57, "766850e": 43, "767": 32, "76702611e": 68, "767188": [48, 49], "767247": 65, "767349": 65, "767435": 59, "768071": 57, "768273": [48, 49], "768331": 43, "769290": 42, "769361": 57, "769805": 57, "77": [65, 66, 67, 68, 70], "770556": 54, "770944": [48, 49], "7710": 58, "771157": 70, "771390e": 54, "7714": 55, "7716982": 36, "771741": 54, "771965": 54, "772253": 43, "77227783e": 68, "772291": 42, "772791": 54, "77289874e": 68, "773": 37, "773177": 44, "773488": 57, "77348822": 57, "77401500e": 68, "774253": 42, "774271e": 54, "775": [37, 54], "775191": [42, 43], "775969": 58, "7763": 53, "776728e": 52, "776887": 53, "7776071": 35, "777712": 59, "777728": 65, "778592": 55, "7786": 34, "778852": 65, "779167": 2, "779185": 42, "779350": 42, "779464": 59, "779517": [42, 43], "779682": 44, "7799": 51, "779912": 54, "78": [43, 65, 66, 67, 68, 70, 77], "780": 37, "780120": 43, "780458": 57, "780857": 53, "780887e": 42, "781": 54, "7811465543": 69, "781233": 54, "781530": 57, "781681": 57, "782": 37, "782050": 57, "782555": 54, "782646": 65, "783": [32, 37], "7831243849": 61, "783124384910379": 61, "7831243849103790": 61, "783276": 67, "7833": 34, "783490": 55, "7838": 34, "784": [70, 72], "784066": 43, "784238": 52, "784341": 42, "784405": 58, "784483": 52, "784624": 44, "785": 37, "785038": 43, "785911": 57, "786": 37, "786744": 44, "78711285e": 68, "787396": 42, "787716": 42, "78777": 58, "788": 76, "78818": 37, "788400": 43, "789671": 44, "789671060840732": 44, "79": [65, 66, 67, 68, 77], "790115": 54, "790261": 65, "790314": 42, "790723": [48, 49], "79122": 53, "791220": 53, "791241": 57, "791297": [13, 65], "791529": 42, "792227": 59, "792939": 44, "793": 67, "793316": 65, "79338596e": 68, "793570": 57, "793735": 57, "793818": [42, 43], "794366": 54, "794526": 42, "79458848e": 68, "794805": 48, "795558": 43, "795647": 57, "7957": 54, "795932": 66, "796014": 43, "796220": 43, "796384": 43, "796444": 54, "797280": 57, "797737": 70, "79792890e": 68, "797965": 70, "79802103": 68, "798071": 4, "798309": 53, "798783": [48, 49], "799": 32, "799350": 55, "799403": 57, "7999": 60, "7b428990": 37, "7x": 57, "8": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 77, 78], "80": [44, 45, 54, 57, 60, 65, 66, 67, 68, 77], "800": 52, "8000": [26, 60], "8000000000000002": [44, 54, 57], "800272": 65, "800351": 42, "800748": 55, "800854": 42, "801623": 54, "801776e": 55, "802289": 54, "802364": 55, "803300": 42, "803492e": 57, "803563": 54, "803902e": 54, "804": 54, "804081e": 43, "804219": 57, "804284": 58, "804316": 57, "804484": 57, "8048": 36, "804828": 57, "804889": 54, "805007": 52, "805153e": [53, 54], "8055563": 35, "805774": 42, "8059": 53, "805962": 42, "806218e": 54, "806531": 54, "806554": 42, "806964": 43, "80696592e": 68, "80714504e": 68, "807879": 57, "808": [36, 70, 72], "808246": 53, "808284": 54, "808640": 54, "8095": 55, "809913": [42, 43], "80a8": 37, "81": [35, 47, 50, 51, 65, 66, 67, 68, 77], "810044": 53, "810134": 57, "8102": [34, 53], "810363": 54, "810382": [53, 54], "81040697": 68, "810707": 54, "811155": 50, "811398": 65, "8116912": [70, 72], "811696": 42, "811825": 52, "811901": 57, "81190107": 57, "812311": 42, "812484e": 42, "8132463": 35, "813293": 57, "813342": [70, 72], "813682": 54, "814136": 44, "814351": 44, "814410": 42, "814913": 52, "8152": 54, "815224": [70, 72], "815226": 67, "815574": 43, "81568484": 57, "815685": 57, "815993": 57, "816318": 52, "816752": 54, "817291": 54, "8173602": 51, "81827267": 57, "818273": 57, "818289": 57, "81828926": 57, "818380": [42, 43], "81856": 37, "818590": 42, "81e": 68, "82": [59, 65, 66, 67, 68, 77], "8202": 36, "820366": 52, "8209": 36, "8210": 36, "821021": 44, "821457": 54, "821566": 57, "821855": 65, "821870": 43, "8221": 34, "822289": [53, 78], "82228913": 78, "822482": 44, "8227": 54, "822822": 44, "823247": 57, "823273": [42, 43], "823769e": 42, "824350": [42, 43], "824701": 44, "824750": 44, "824889": 44, "824961e": 54, "8250": 34, "825140": 42, "825617": 52, "825824": 43, "825862": 57, "825980": 44, "8259803249536914": 44, "8260": 53, "826065": [42, 43], "826137": 55, "826215": 43, "826391": 43, "826426": 67, "826492": 57, "826519": [13, 65], "82666866e": 68, "826829": 42, "82684324": 58, "827192": 42, "827234": 42, "827375": 45, "827381": 57, "827438": 42, "827735": 57, "827938162750831": [48, 49], "828058": 54, "828915": [48, 49], "829162": 65, "829543": 44, "829619": 43, "82985": 50, "83": [65, 66, 67, 68, 77], "830301": 56, "830755e": 50, "831019": 44, "831741": 42, "832086": 57, "8326928": 58, "832693": 58, "832844": 43, "832875": 57, "83287529": 57, "833024": 52, "833117": 42, "833227e": 66, "833464": 54, "833781": 42, "833907": 52, "8350": 54, "835125": 43, "835596": 54, "836234": 67, "836515": 43, "837680": 42, "838006e": 43, "838114": 57, "838235": 55, "838457": 54, "83905": 4, "84": [37, 65, 66, 67, 68, 77], "840": 55, "840041": 54, "840303": 57, "84030318": 57, "840630": 42, "840673": 42, "840718": 67, "840836": 57, "840995e": 53, "841": [35, 52], "841132": 53, "8415": 36, "841847": 54, "842132": 67, "842405": 44, "842444": 42, "842625": 52, "842746": 57, "842770e": 43, "8428": 53, "842853": 57, "842859": 43, "842901": 43, "843730": 52, "843796": 42, "8440": 54, "844308": 57, "844549": [48, 49], "844667": 70, "844707": 57, "844889": 52, "845059": 43, "846388": 44, "8465903": 68, "847555": 42, "847595": [12, 65], "84788057": 68, "847948": 44, "847966": 54, "848757e": 53, "848868": 44, "849": 55, "84930915e": 68, "849747": 58, "8497f641": 37, "8499": 54, "85": [21, 44, 50, 54, 57, 60, 65, 66, 67, 68], "8500000000000002": [44, 54, 57], "850321": 52, "850439": 43, "850575": [42, 43], "850794": 57, "851198": 54, "8513": 37, "851366": 52, "852": 54, "85265193": 51, "85280376": [2, 4, 5, 7, 8, 9, 10, 11, 12], "85397773": 67, "855199e": 42, "855780": 57, "856117": 42, "85633094": 68, "856404": 49, "8571": 34, "857161": 57, "857544": 52, "85771457": 68, "857765": 54, "858579": 43, "859": 54, "85911521e": 68, "85912862": 70, "859129": [69, 70], "859395": 59, "85974356": [2, 4, 5, 7, 8, 9, 10, 11, 12], "85c5": 37, "85e": 36, "86": [65, 66, 67, 68, 77], "860261": 43, "860472": 59, "860663": [70, 72], "860804": 57, "860992": 54, "861": 55, "861755": 50, "862043": [48, 49], "862359": 44, "863687": 42, "863772": 53, "86415573": 36, "86424193e": 68, "8644": 37, "8646627426": 69, "864741e": 54, "865284": 42, "865313": 54, "865540": 43, "865562": [42, 43], "865854": 54, "865860": [53, 54], "866": 32, "866102": [42, 43], "866579": 54, "866798": 54, "8670337521": 61, "867033752141195": 61, "867565": 57, "8679": 54, "868": 37, "8685788": 57, "868579": 57, "8688": 53, "869": 37, "869020": 44, "869136": 43, "869425": 49, "869477": 42, "86953113": 68, "869586": 50, "869651": 43, "87": [36, 49, 50, 52, 65, 66, 67, 68, 77], "8700": 36, "870099": [48, 49], "870185": 43, "870260": 57, "870332": 57, "870857": 57, "871": 37, "871887e": 43, "871923": 43, "872222": 54, "872768": 57, "872852": 57, "87290240e": 68, "872994": 54, "873048": 43, "873198": 54, "873677": [48, 49], "87384812361": 34, "87384812362": 34, "873972": 42, "87430335": [70, 72], "874303353": [70, 72], "874702": [48, 49], "8750": 54, "8759": 54, "876080": 42, "876083": 54, "87623301": 34, "876431e": 44, "876549": 54, "87674597e": 68, "8768": 34, "8771": 54, "877153": 54, "877455": 56, "877833": [42, 43], "878281": 57, "878289": 54, "878402": 42, "878847e": 54, "879049": 54, "879103": 44, "879598": 59, "87e": 36, "88": [36, 50, 65, 67, 68], "880106": 52, "880202e": 43, "880579": 57, "880591": 56, "880808e": 54, "880880e": 54, "880886": 53, "8810": 53, "881201": 54, "88125046e": 68, "881465": 46, "881581": 8, "88173062": 35, "882": 32, "882475": 44, "883485": 43, "883622": 57, "883778": 43, "883914": 44, "884132": 57, "8843": 58, "8845": 34, "884996": 44, "8850": 36, "885065": 57, "885978": [48, 49], "886041": 43, "886086": [42, 43], "886266": 54, "88629": 34, "886577": 43, "88664": 37, "886771e": 42, "886777e": 43, "886989": 43, "887345": 54, "887556": 44, "88806102": 68, "888146": 52, "8881461": 35, "888775": 49, "888804": 54, "888863e": 42, "889293": 57, "8893": 53, "889300": 53, "889326": 43, "889733": 57, "88988263e": 68, "889913": [42, 43], "889963": 57, "88ad": 37, "89": [36, 43, 65, 67, 68, 76, 77], "890": [35, 52], "89027368": [70, 72], "890273683": [70, 72], "89035917": 50, "890372": [38, 63, 75], "8903720000100010000010": [37, 63, 75], "8904": 32, "890454": 66, "8909": [35, 53, 78], "891697": 53, "892": 37, "892331": 43, "892648": 57, "892796": [42, 43], "893": 37, "8932105": 35, "893649": [42, 43], "893851": 57, "894": 37, "894307e": 54, "89449": 53, "894490": 53, "894609e": 42, "895106": [42, 43], "895308": 54, "895333": 57, "895690": [42, 43], "895768e": 44, "896023": 57, "896681e": 43, "896758": 42, "897": 55, "897220": 57, "897240": 54, "8974": 53, "898722": 57, "899460": 57, "899716": 43, "8bdee1a1d83d": 37, "8da924c": 37, "8e3aa840": 37, "9": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 77, 78], "90": [22, 36, 44, 45, 54, 57, 60, 65, 67, 68, 77], "9000000000000002": [44, 54, 57], "900000e": 54, "900021": 66, "901013": 43, "901148": 57, "90136": 53, "901360": 53, "901683": 54, "902": [32, 70, 72], "902573": 44, "903056e": 57, "903135": 65, "903339": 44, "903351e": 44, "903418": 52, "903681": 57, "903767": [42, 43], "904156": 44, "9041560442482157": 44, "904315": 42, "905042": 43, "905494": 44, "905951": 58, "905998": 49, "906073": 43, "9061": 54, "906716732639898": [48, 49], "906757": 40, "906864": 42, "907115": 57, "907130": 42, "907176": 57, "907198": 43, "9073": 54, "907491": 44, "907702": 42, "907801": 52, "90794478": [70, 72], "907944783": [70, 72], "907961": 54, "908024": 59, "908620": 42, "909141": 43, "90919033": 68, "909304": [42, 43], "90963122e": 68, "909752": 43, "909942e": 65, "909975": 54, "909997": [53, 78], "91": [65, 66, 67, 68, 77], "910000e": 54, "9102": 53, "910895": 43, "9109": 37, "910991": 42, "91102953": 57, "911030": 57, "911662": 48, "912230": [42, 43], "9126": [36, 78], "9127": [36, 78], "913": 37, "913116": 59, "91315015": 35, "913280": 59, "913285": 42, "913333438414345545767687576808485868992": 68, "9133334384143455457676875768084858689921125293031323547505562657278798182889499271214151819202428364048526970738795961017222327373942464953606163747783909197": 68, "9133334384143455457676875768084858689921345681621264451565859646671939810011252930313235475055626572787981828894991017222327373942464953606163747783909197": 68, "91333343841434554576768757680848586899213456816212644515658596466719398100112529303132354750556265727879818288949927121415181920242836404852697073879596": 68, "91333343841434554576768757680848586899213456816212644515658596466719398100271214151819202428364048526970738795961017222327373942464953606163747783909197": 68, "913485": 54, "913774": 44, "9142": 54, "91438767e": 68, "9145": 34, "915": [36, 37, 53, 54], "915000e": [53, 54], "915057e": 53, "915488": [48, 49], "916236": 34, "916528": 48, "9166667": 37, "916806": 43, "916914": 57, "917": 37, "917066": 54, "917248": 57, "91724807": 57, "917436": 57, "918": 32, "918104": 42, "918227": 44, "918747": 43, "919432": 57, "9197": 54, "919814": 42, "91e": 36, "92": [65, 67, 68, 77], "920335": 54, "920337": 49, "920439": 42, "920645": 54, "9209": 34, "9210": 54, "921372": 44, "921913": 52, "921956": [42, 43], "921e4f0d": 37, "922": 55, "922160": 54, "922201e": 42, "9223": 54, "922996": 52, "923074e": 44, "923517": 60, "923607": 57, "92369755": 35, "923804": 44, "923943": 78, "923977": 54, "924002": 57, "9243": 54, "924396": [48, 49], "92463": 53, "924630": 53, "924634": 46, "9248": 37, "924821": 44, "924843": 52, "924921": 65, "925": 45, "925248": [48, 49], "925660": 42, "925736": 44, "925957": 48, "926493": 53, "926621": 44, "927": 33, "927074": 57, "927232": 54, "9274": 54, "927950": 54, "928": 68, "92827999": 67, "92881435e": 68, "928947": 52, "92905": 35, "929363": 42, "929552": 42, "929598": 43, "92972925e": 70, "929729e": [69, 70], "93": [36, 65, 66, 67, 68, 77], "9304028": 35, "930417": 42, "931": 62, "931479": 57, "931507": 42, "931978": 75, "932027": 44, "932404e": 54, "9325": 34, "9327": 34, "932973": 57, "933322": 43, "933996": 44, "934": 32, "934433": [42, 43], "9345": 37, "934511": [70, 72], "934549": 54, "934968": 55, "934992": 44, "935": 51, "935591": 57, "935730": 57, "935989": 52, "9359891": 35, "93648": 60, "936739": 57, "937116": 52, "937586": 54, "937857": 42, "938": [70, 72], "938975": [65, 66, 67], "939068": [48, 49], "9392": 54, "939250": 42, "9395": 54, "93958082416": 78, "94": [45, 51, 65, 67, 68, 77, 78], "940354721701296": 44, "940355": 44, "940373": 54, "941440": 42, "941724": 54, "941788": 48, "942139": 49, "942312": 57, "942460e": 57, "942489": 54, "9425": 34, "942550": 54, "942661": 52, "942823": 54, "94309994e": 68, "943200": 42, "943270": 42, "943465e": 42, "943938": 57, "943949e": 57, "944149": 65, "944253e": 57, "944266": [48, 49], "944280": 54, "94441007e": 68, "945402e": 42, "945417": 42, "945881": 42, "946": 55, "94629": 60, "946297": 44, "946406": 49, "946433": 57, "946533": 42, "946658": 54, "946968": 44, "947": 55, "947440": 56, "947466": 66, "947613": 43, "9480": 54, "948154e": 48, "948344e": 43, "948868": 54, "94906344": 35, "949241": [70, 72], "949456": 57, "949866": 43, "95": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 36, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 57, 58, 59, 60, 65, 67, 68, 70, 71, 77, 78], "9500": 54, "950131e": 43, "950545": 40, "95062986e": 68, "951115": 43, "951415": 42, "951502": 57, "951532": 52, "951550": 43, "951920": 56, "952": [36, 78], "9523": 34, "952839": 57, "9534": 54, "953683": 52, "95372559e": 68, "954": [70, 72], "95401167e": 68, "954536": 65, "955005e": 54, "9551": 54, "9552": 34, "955541": [13, 65], "95559917": 66, "955701": 42, "955926": 43, "956047": 35, "9561": 34, "956110": 43, "956217": 42, "956574": 54, "956724": 44, "9567242535070148": 44, "956892": 54, "957375": 52, "957437": 42, "957745": 44, "9579": 36, "957996": 44, "958": [70, 72], "9580": 36, "958105": 65, "958541": 54, "959132": 43, "95e": 36, "96": [36, 42, 43, 50, 55, 65, 67, 68, 77], "960074": 42, "9605": 54, "960808": 44, "960875e": 43, "9609": 34, "961": 55, "961360": 43, "961539": 54, "961962": 44, "963051": 43, "963055": 54, "963389": 42, "964025e": 57, "964261e": 52, "964318": 54, "9647": 34, "965341": 43, "965531": 67, "965696": 42, "965774": 54, "96582": 66, "966015": 57, "966659": 44, "9666592590622916": 44, "967": 55, "967467": 58, "968134e": 57, "968577": 45, "968800": 42, "9699": 53, "97": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 65, 66, 67, 68, 69, 70, 72, 75, 77, 78], "970065": 57, "971058": [48, 49], "971724": 42, "972088e": 42, "972509": 43, "972732": 43, "972748": 44, "97276281": 57, "972763": 57, "97314470": 35, "973156": 65, "973229": 43, "973241": 57, "973262": 42, "973331": 54, "973392e": 42, "973741": 43, "974202": 44, "974213": 43, "97441062": [48, 49], "974414": 44, "97470872": 58, "9748910611": 35, "975": [42, 43, 48, 49, 51, 55], "975232": 43, "9753": 37, "975447": 45, "975450": 43, "975461": 52, "975957e": 43, "976088": 57, "976562": 57, "977280": [42, 43], "977295": 54, "977507": 43, "978554": 42, "9787": 54, "978977": 57, "979857": 42, "979896": 43, "98": [42, 43, 54, 65, 67, 68, 77], "980026": 54, "9802393": 35, "980256e": 42, "980643e": 44, "981104": 56, "981438": 42, "981672": 44, "982353e": 54, "982417": 44, "982720": 42, "982797": 56, "982986e": 42, "983192": 57, "983253": 42, "983759": 78, "983896": 42, "98393441": 58, "984024": 56, "984083": [48, 49], "984551": 7, "984562": 57, "984821": 42, "984866": [70, 72], "984872": [42, 43], "984937": 44, "98505871e": 68, "985207": [42, 43], "986383": 54, "986417": 42, "987": 55, "9870004": 37, "987220": 54, "987329": 43, "9875": 34, "9880384": 37, "988421": [42, 43], "988463": 57, "988690": 43, "988709": 54, "988780": 54, "989": 55, "989104": 55, "989291": 42, "989372": 50, "99": [36, 42, 43, 55, 65, 67, 68, 77], "990210": 54, "990260": 55, "990377": 43, "991": 37, "9914": [53, 54, 58], "991444e": 48, "9915": [36, 53, 54, 58], "991512": 36, "991539": 43, "991963": [42, 43], "991977": 54, "991988": 42, "99232145": 58, "992582": [42, 43], "993201": 43, "993575": 54, "994168239": 35, "994214": 54, "994332": 40, "994377": 42, "9944": [51, 67], "994851": 54, "994937": 49, "995015": 54, "9951": 34, "995248": 57, "99549118e": 68, "99571372e": 68, "9961392": 35, "996454": 43, "996934": 52, "996946": 43, "9970": 54, "997034": 60, "997494": 60, "997571": 52, "997621": 44, "997934": [48, 49], "998063": 40, "99864670889": 78, "998766": 54, "9989": 53, "999": [45, 46, 50, 58, 78], "999207": 57, "9995": [42, 43, 46], "9996": [42, 43, 46], "9996553": 36, "9997": [42, 43, 46], "9998": [42, 43, 46], "9999": [42, 43, 46], "99c8": 37, "A": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 21, 25, 29, 30, 32, 33, 34, 36, 37, 40, 41, 47, 49, 55, 56, 58, 59, 62, 63, 65, 66, 67, 70, 71, 72, 73, 75, 76, 78], "ATE": [8, 16, 36, 38, 53, 58, 59, 65, 67, 69, 71], "ATEs": 55, "And": [55, 60, 71], "As": [33, 34, 35, 36, 37, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 66, 68, 69, 70, 71, 72, 78], "At": [16, 17, 18, 35, 45, 46, 50, 51, 52, 54, 57, 78], "Being": 78, "But": 51, "By": [34, 35, 52, 59, 66, 71], "For": [4, 5, 7, 8, 11, 18, 27, 28, 32, 34, 35, 37, 40, 45, 50, 51, 52, 54, 56, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 78], "If": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 33, 35, 41, 42, 43, 45, 51, 52, 54, 62, 63, 65, 66, 67, 69, 70, 71, 73, 78], "In": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78], "It": [34, 35, 36, 42, 43, 47, 48, 49, 52, 53, 54, 59, 66, 68, 73, 77], "No": [20, 32, 34, 36, 37, 38, 45, 50, 53, 54, 58, 60, 63, 66, 67, 69, 70, 75, 76], "Of": [51, 70, 78], "On": [33, 41, 55, 62, 76], "One": [36, 53, 54, 59, 65, 70], "Such": [59, 66], "That": 78, "The": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 34, 35, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78], "Then": [18, 44, 57, 70, 71, 72, 73, 74], "There": [36, 53, 59, 74, 78], "These": [36, 37, 39, 53, 56, 58, 65, 78], "To": [28, 32, 33, 35, 36, 37, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 63, 65, 66, 68, 70, 71, 72, 74, 75, 78], "With": [21, 42, 43, 66, 76], "_": [33, 35, 41, 42, 43, 44, 46, 47, 48, 49, 52, 53, 54, 56, 57, 61, 62, 65, 68, 69, 70, 71, 72], "_0": [33, 35, 41, 47, 52, 61, 62, 68, 69, 70, 71], "_1": [16, 17, 18, 55, 60, 69], "_2": [16, 17, 18, 55], "_3": [16, 17, 18], "_4": [16, 17, 18], "_5": 16, "__version__": 74, "_all_coef": 68, "_all_s": 68, "_compute_scor": 28, "_compute_score_deriv": 28, "_coordinate_desc": 52, "_est_causal_pars_and_s": 77, "_i": [33, 41, 57, 60, 62], "_id": 68, "_j": [16, 17, 18, 23, 35, 52, 70, 72], "_l": 66, "_m": [66, 68], "_n": [69, 70, 71, 72], "_n_folds_per_clust": 52, "_rmse": [2, 4, 5, 7, 8, 9, 10, 11, 12], "a09a": 37, "a09b": 37, "a3d9": 37, "a4a147": 55, "a5e6": 37, "a5e7": 37, "a6ba": 37, "a79359d2da46": 37, "a840": 37, "a_": 60, "a_0": 24, "a_1": 24, "ab": [34, 73], "ab71": 37, "abadi": [14, 45], "abb0fd28": 37, "abdt": [38, 63, 75], "abl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 41, 51, 54, 55, 66, 71], "about": [36, 51, 53, 73, 75, 78], "abov": [33, 36, 41, 42, 43, 48, 49, 51, 53, 55, 56, 57, 59, 62, 65, 66, 67, 74], "absolut": [2, 4, 5, 7, 8, 9, 10, 11, 12, 51, 66], "abstract": [28, 34, 35, 52, 69, 73, 77], "acc": 34, "accept": [65, 66], "access": [29, 30, 34, 36, 48, 49, 50, 51, 58, 66, 71, 78], "accord": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 36, 41, 44, 45, 53, 57, 59, 60, 66, 70, 71, 72, 78], "accordingli": [45, 51, 53, 60], "account": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 36, 52, 53, 54, 58, 59, 71, 78], "accumul": [36, 53, 54, 58], "accuraci": 34, "acemoglu": 76, "achiev": [35, 52, 56, 59, 70, 72], "acic_2024_post": 55, "acknowledg": [36, 37, 53], "acm": 76, "acov": 76, "across": [36, 53, 55, 78], "action": 77, "activ": [3, 6, 74, 77], "actual": [50, 59], "acycl": [60, 78], "ad": [3, 6, 14, 15, 28, 50, 63, 66, 70, 71, 77], "adapt": [7, 53, 77], "add": [34, 35, 38, 45, 46, 48, 49, 50, 55, 57, 58, 59, 60, 66, 76, 77], "add_trac": 59, "addit": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 23, 24, 25, 47, 59, 66, 67, 69, 71, 76, 77], "addition": [16, 17, 44, 54, 58, 66, 67, 68, 70, 71, 75], "address": 59, "adel": 76, "adj": 59, "adj_coef_bench": 59, "adj_est": 59, "adj_vanderweelearah": 59, "adjust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 46, 52, 54, 58, 59, 65, 70, 71, 72, 78], "adopt": [45, 67], "advanc": [64, 68, 76], "advantag": [33, 34, 36, 41, 53, 54, 62, 74], "advers": 71, "adversari": [2, 4, 5, 7, 8, 9, 10, 11, 12, 58, 71], "ae": [33, 35, 36], "ae56": 37, "ae89": 37, "aesthet": 33, "aeturrel": 25, "afd9e4": 55, "affect": [47, 67, 77, 78], "after": [34, 36, 37, 45, 47, 53, 54, 59, 60, 65, 66, 71, 74, 78], "after_stat": 33, "ag": [36, 53, 54, 56, 58, 78], "again": [33, 34, 35, 36, 41, 45, 50, 52, 53, 58, 59, 60, 62, 71], "against": [45, 50, 51, 56, 66], "agebra": 65, "agegt54": [37, 38, 63, 75], "agelt35": [37, 38, 63, 75], "agg": 34, "aggreg": [34, 61, 68, 77], "aggt": 34, "aipw": 55, "aipw_est_1": 55, "aipw_est_2": 55, "aipw_obj_1": 55, "aipw_obj_2": 55, "air": [35, 52], "al": [14, 15, 19, 21, 23, 24, 33, 35, 36, 37, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54, 57, 58, 62, 67, 68, 69, 70, 71, 72, 73, 75, 77], "alexandr": [47, 76], "algorithm": [32, 34, 35, 37, 41, 44, 45, 51, 52, 54, 57, 58, 60, 64, 66, 67, 68, 69, 70, 77, 78], "align": [33, 35, 41, 44, 46, 51, 52, 53, 55, 56, 57, 60, 77], "all": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 31, 33, 34, 35, 36, 41, 45, 50, 51, 52, 53, 54, 56, 59, 60, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 77], "all_coef": 68, "all_dml1_coef": 61, "all_s": 68, "all_smpl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "all_smpls_clust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "all_z_col": [35, 52], "allow": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 28, 36, 53, 54, 65, 66, 68, 69, 70, 72, 73, 77, 78], "almqvist": 76, "along": 66, "alpha": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 22, 24, 33, 35, 36, 38, 41, 42, 43, 44, 47, 51, 52, 53, 54, 57, 61, 62, 65, 66, 67, 68, 69, 70, 71, 72], "alpha_": [23, 35, 52, 66], "alpha_0": 71, "alpha_ml_l": 47, "alpha_ml_m": 47, "alpha_x": [7, 20, 67], "alreadi": [18, 45, 60, 66, 67], "also": [4, 5, 7, 8, 11, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 48, 49, 50, 51, 52, 53, 54, 56, 58, 59, 62, 65, 66, 68, 69, 70, 71, 74, 75, 77, 78], "alter": [35, 52], "altern": [34, 36, 37, 53, 56, 64, 66, 70, 72, 73, 74, 75], "although": 59, "alwai": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 77], "always_tak": [7, 36, 53], "amamb": 52, "american": [22, 55], "amgrem": 52, "amhorn": 52, "amit": [59, 76], "amjavl": 52, "ammata": 52, "among": [36, 47, 53, 54, 58, 59], "amount": [36, 53, 54, 78], "amp": [32, 35, 37, 45, 52, 54, 58, 60], "an": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 29, 30, 33, 34, 35, 36, 37, 41, 42, 43, 47, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78], "analog": [27, 28, 35, 52, 54, 58, 65, 67, 69, 70, 71, 72], "analys": 78, "analysi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 35, 36, 41, 52, 53, 54, 62, 64, 65, 73, 77], "analyt": [55, 57], "analyz": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 36, 53, 54, 58, 78], "ancillari": 59, "andrea": 76, "angl": 36, "angrist": 55, "ani": [32, 33, 34, 37, 40, 41, 45, 59, 60, 62, 74, 78], "anna": [4, 5, 16, 17, 18, 34, 45, 67, 76], "annal": [70, 72, 76], "anneal": 66, "annot": 33, "annual": 76, "anoth": [33, 34, 35, 36, 41, 51, 52, 62, 66], "anticip": 34, "anymor": [35, 52], "aos1161": [70, 72], "aos1230": [70, 72], "aos1671": [70, 72], "ap": [36, 53], "ape_e401_uncond": 36, "ape_p401_uncond": 36, "api": [63, 73, 77], "apoorva": 77, "apoorva__l": 55, "apoorval": 55, "app": 77, "appeal": 59, "append": [41, 51, 62], "appendix": [21, 26, 58, 60, 71], "appli": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 32, 33, 35, 36, 37, 41, 45, 46, 51, 52, 53, 54, 59, 60, 62, 67, 68, 69, 70, 72, 73, 75, 77, 78], "applic": [33, 41, 45, 55, 59, 62, 65, 68, 76, 78], "apply_along_axi": 56, "apply_cross_fit": [33, 68], "apply_crossfit": 77, "appreci": 73, "approach": [2, 4, 5, 7, 8, 9, 12, 13, 34, 35, 52, 58, 59, 64, 66, 68, 70, 71, 72, 74, 76, 78], "appropri": [36, 47, 53, 68, 78], "approx": 65, "approxim": [33, 41, 42, 43, 44, 51, 57, 59, 62, 65, 70, 72, 77, 78], "apt": 74, "ar": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 24, 25, 27, 28, 29, 30, 33, 34, 35, 36, 37, 39, 41, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78], "arang": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 41, 44, 46, 54, 56, 57, 58, 59, 66], "architectur": [69, 76], "arellano": 76, "arg": 65, "argmin": 51, "argu": [33, 36, 41, 53, 54, 58, 62, 78], "argument": [18, 23, 24, 25, 36, 42, 43, 45, 50, 51, 53, 54, 61, 65, 66, 67, 78], "aris": [33, 34, 35, 41, 52, 59, 62, 78], "aronow": 55, "around": [34, 36, 53, 54, 69], "arr": 56, "arrai": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 20, 21, 22, 23, 24, 25, 26, 41, 42, 43, 44, 45, 51, 52, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 68, 70, 71, 72, 75, 77, 78], "arrang": 35, "array_lik": 13, "articl": [25, 73], "arxiv": [23, 34, 35, 52, 59, 73, 76, 77], "as_learn": [37, 66], "asarrai": [42, 43], "aspect": [36, 53, 54], "assert": 66, "assess": 34, "asset": [54, 58, 78], "assign": [3, 6, 36, 49, 53, 65, 66, 67, 78], "assmput": 67, "associ": [36, 47, 53, 67, 70, 72, 76], "assum": [32, 35, 40, 45, 52, 55, 56, 59, 67, 69, 70, 71, 78], "assumpt": [34, 35, 36, 45, 46, 51, 52, 53, 55, 60, 67, 70, 78], "assur": 77, "astyp": [40, 53, 59], "asymptot": [27, 28, 33, 35, 41, 52, 62, 68, 70, 76], "ate_estim": 60, "athei": 76, "att": [8, 16, 34, 46, 50, 56, 59, 65, 67, 69, 71, 77], "att_gt": 34, "attach": 34, "atte_estim": 45, "attempt": [29, 30], "attenu": [36, 53], "attr": 36, "attribut": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 51, 61, 66, 68, 69, 70], "attributeerror": [29, 30], "attrict": 67, "attrit": [60, 67], "au": [37, 66, 73, 75], "auc": 34, "author": [34, 59, 73], "automat": [33, 41, 50, 62, 65, 71], "automobil": [35, 52], "autos": 47, "auxiliari": [33, 41, 62], "avail": [20, 34, 36, 37, 45, 47, 51, 53, 54, 55, 56, 59, 62, 65, 66, 67, 71, 73, 74, 77, 78], "averag": [7, 8, 11, 16, 17, 18, 32, 34, 37, 40, 45, 46, 50, 54, 55, 56, 58, 59, 60, 64, 67, 70, 71, 76, 78], "avoid": [33, 34, 41, 68, 74, 77], "awai": 58, "ax": [41, 42, 43, 44, 46, 48, 49, 51, 52, 53, 54, 55, 57], "ax1": [44, 54, 57], "ax2": [44, 54, 57], "axhlin": 46, "axi": [35, 36, 47, 51, 52, 53, 55, 56], "axvlin": 41, "b": [4, 5, 25, 33, 35, 37, 41, 42, 43, 52, 55, 57, 59, 62, 65, 66, 70, 71, 72, 73, 75, 76], "b208": 37, "b371": 37, "b5d34a6f42b": 37, "b5d7": 37, "b_0": 24, "b_1": 24, "b_j": 25, "bach": [59, 73, 76, 77], "backbon": 51, "backend": [3, 6, 34, 54, 58, 59, 64, 77], "backward": 77, "bad": 55, "balanc": [36, 53, 54], "band": [34, 64, 78], "bandwidth": [9, 12, 13], "bar": [50, 53, 65], "base": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 19, 33, 34, 35, 36, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78], "baselin": [36, 53], "basi": [1, 8, 11, 42, 43, 65], "basic": [34, 35, 36, 45, 52, 53, 54, 55, 58, 59, 64, 66], "batch": 37, "battocchi": 76, "bay": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 70, 72], "bb2913dc": 37, "bbotk": [37, 66, 77], "bbox_inch": 41, "bbox_to_anchor": 41, "bcallaway11": 34, "bd929a9e": 37, "bde4": 37, "becam": [36, 53, 54], "becaus": [32, 33, 34, 35, 40, 41, 49, 50, 52, 55, 59, 62, 78], "becker": [37, 66], "becom": [35, 49, 52, 65, 68], "bee": 46, "been": [35, 36, 52, 53, 54, 58, 59, 65, 66, 77], "befor": [34, 36, 46, 50, 53, 57, 59, 67, 78], "begin": [20, 22, 23, 33, 35, 36, 37, 41, 44, 46, 51, 52, 53, 55, 56, 57, 60, 61, 63, 66, 68, 70, 72, 75, 78], "behav": 49, "behavior": [36, 55, 66], "behaviour": 49, "being": [26, 27, 28, 35, 52, 59, 68, 69, 70, 71, 72, 73], "belloni": [21, 47, 70, 72, 76], "below": [32, 36, 40, 53, 55, 74, 75], "bench_x1": 59, "bench_x2": 59, "benchmark": [2, 4, 5, 7, 8, 9, 10, 11, 12, 31, 50, 77], "benchmark_dict": [31, 58], "benchmark_inc": 58, "benchmark_pira": 58, "benchmark_result": [2, 4, 5, 7, 8, 9, 10, 11, 12], "benchmark_twoearn": 58, "benchmarking_set": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 58, 59, 71], "benchmarking_vari": 50, "benefit": [33, 36, 41, 53, 62], "bernoulli": 20, "berri": [35, 52], "besid": 75, "best": [1, 8, 11, 42, 43, 48, 49, 74], "beta": [20, 21, 22, 26, 36, 53, 56, 60], "beta_": 60, "beta_0": [19, 56, 60, 65], "beta_a": [16, 17, 59], "beta_j": [20, 21, 22, 26], "better": [34, 51, 59], "between": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 40, 44, 46, 47, 55, 57, 58, 59, 60, 69, 70, 71, 72, 75, 77], "betwen": [32, 40], "beyond": 76, "bia": [26, 32, 40, 47, 59, 60, 64, 67, 68, 69, 71, 76, 77], "bias": [32, 36, 40, 53, 54, 58, 78], "bias_bench": 59, "bibtex": 73, "big": [47, 61, 68, 69, 70, 71], "bigg": [35, 52, 69, 71], "bilia": 15, "bin": [33, 41, 74], "binari": [2, 4, 5, 7, 8, 9, 11, 12, 19, 32, 34, 36, 37, 40, 45, 50, 51, 53, 55, 56, 59, 65, 66, 67, 77, 78], "binary_treat": [19, 42, 48, 50], "bind": 77, "binder": [37, 66, 73, 75, 77], "binomi": [40, 55, 56, 57], "bischl": [37, 66, 73, 75], "black": [33, 37, 38, 63, 75], "blob": 34, "blog": 25, "blondel": [73, 75], "blp": [1, 35, 52], "blp_data": [35, 52], "blp_model": [48, 49], "blue": [33, 35, 52], "bodori": 76, "bond": [36, 53, 54], "bonferroni": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 70, 72], "bonu": [15, 37, 63, 75], "book": [37, 59, 66], "bool": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 19, 29, 30, 50], "boolean": [26, 48, 49, 63, 68], "boost": [32, 36, 40, 45, 51, 53], "boost_class": [36, 53], "boost_summari": 53, "boostrap": [44, 77], "bootstrap": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 42, 43, 44, 48, 49, 54, 57, 64, 65, 68, 69, 73, 75, 77, 78], "both": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 17, 19, 34, 36, 37, 45, 46, 51, 53, 54, 56, 58, 59, 63, 66, 70, 71, 77, 78], "bottom": [35, 36, 51, 52, 53, 54], "bound": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 50, 53, 58, 59, 71, 78], "branch": 37, "brantli": 34, "break": [33, 77], "breviti": 78, "brew": 74, "brewer": 35, "bridg": 59, "brief": 62, "bring": [32, 40], "brucher": [73, 75], "bsd": 77, "budget": 66, "bug": [73, 77], "build": [35, 51, 52, 56], "build_design_matric": [42, 43], "build_sim_dataset": 34, "built": [66, 73], "bureau": [59, 68, 76], "busi": [23, 26, 35, 52, 59, 76], "b\u00fchlmann": 76, "c": [14, 15, 17, 18, 21, 22, 24, 32, 33, 34, 35, 36, 37, 38, 40, 41, 46, 47, 48, 49, 52, 53, 55, 62, 63, 66, 73, 74, 75, 76, 78], "c1": [14, 15, 24, 35, 47, 52, 62, 73, 76], "c68": [14, 15, 24, 35, 47, 52, 62, 73, 76], "c895": 37, "c_": [70, 72], "c_d": [21, 71], "c_y": [21, 71], "ca1af7be64b2": 37, "caac5a95": 37, "calcualt": 56, "calcul": [8, 11, 34, 36, 42, 43, 44, 48, 49, 51, 53, 57, 58, 71], "calibr": [51, 59], "call": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 34, 35, 36, 37, 40, 42, 43, 44, 45, 48, 49, 52, 53, 54, 56, 57, 58, 59, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 77, 78], "callabl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 41, 42, 43, 51, 64, 66, 73], "callawai": 34, "camera": 47, "cameron": [35, 52], "can": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 19, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78], "candid": 59, "cannot": [51, 59, 78], "capabl": [3, 6, 32, 40], "capsiz": 55, "cardin": [35, 52], "care": 66, "carlo": [16, 17, 19, 42, 43, 48, 49, 59, 76], "casalicchio": [37, 66, 73, 75], "case": [3, 6, 7, 8, 15, 19, 32, 35, 36, 40, 42, 43, 44, 47, 49, 50, 52, 56, 57, 58, 59, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 77, 78], "cat": [33, 77], "catboost": 51, "cate": [1, 8, 11, 64, 77], "cate_obj": 65, "caus": [33, 41, 62], "causal": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 20, 21, 22, 23, 24, 25, 26, 32, 33, 35, 36, 37, 40, 41, 52, 53, 55, 58, 60, 61, 62, 63, 64, 67, 68, 70, 71, 72, 76], "causaldml": 76, "causalweight": 76, "caution": 70, "caveat": [49, 59], "cbind": 35, "cc": 53, "ccp_alpha": [8, 53], "cd": 74, "cd_fast": 52, "cda85647": 37, "cdf": 65, "cdid": [35, 52], "cdot": [16, 17, 18, 35, 44, 46, 50, 52, 55, 57, 59, 65, 67, 69, 70, 72], "cdot1": 50, "center": 47, "central": [68, 77], "certain": 49, "cexcol": 35, "cexrow": 35, "cf_d": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 31, 50, 58, 59, 71, 78], "cf_y": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 31, 50, 58, 59, 71, 78], "chad": 59, "chain": 49, "chainedassignmenterror": 49, "challeng": [35, 52, 71], "chang": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 45, 49, 54, 58, 59, 60, 70, 71, 74, 76, 77], "channel": 78, "chapter": [27, 28, 37, 66, 71], "charact": [36, 37, 66, 77], "characterist": [58, 78], "check": [29, 30, 33, 36, 41, 51, 53, 54, 61, 62, 73, 74, 77], "check_data": 77, "check_scor": 77, "checkmat": 77, "chernozhukov": [14, 15, 21, 22, 24, 33, 35, 36, 41, 47, 51, 52, 53, 54, 58, 62, 68, 70, 71, 72, 73, 76, 77], "chetverikov": [14, 15, 24, 35, 47, 52, 62, 70, 72, 73, 76], "chiang": [23, 35, 52, 76], "chieh": 76, "choic": [2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 36, 47, 53, 56, 65, 66, 71, 77], "choos": [32, 36, 40, 41, 47, 51, 53, 54, 61, 68, 69, 70, 72, 75, 78], "chosen": [17, 51, 66], "chou": 55, "chr": 36, "christian": [47, 76], "chunk": 66, "ci": [2, 4, 5, 7, 8, 9, 10, 11, 12, 42, 43, 44, 45, 46, 48, 49, 50, 53, 54, 57, 58, 59, 65, 71, 77, 78], "ci_cvar": [44, 54], "ci_cvar_0": 44, "ci_cvar_1": 44, "ci_joint_cvar": 44, "ci_joint_lqt": 57, "ci_joint_qt": 57, "ci_length": 45, "ci_lpq_0": 57, "ci_lpq_1": 57, "ci_lqt": [54, 57], "ci_pq_0": [54, 57], "ci_pq_1": [54, 57], "ci_qt": [54, 57], "cinelli": [59, 71, 76], "circumv": 78, "citat": 77, "claim": 37, "clash": 34, "class": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 27, 28, 29, 30, 36, 37, 38, 45, 50, 53, 54, 58, 60, 61, 63, 65, 66, 68, 69, 70, 73, 75, 77], "class_learn": 54, "class_learner_1": 51, "class_learner_2": 51, "classic": [34, 35, 52, 78], "classif": [8, 32, 34, 36, 37, 51, 56, 58, 65, 66, 67, 78], "classifavg": 37, "classifi": [2, 4, 5, 7, 8, 9, 11, 12, 13, 29, 37, 66, 77], "classmethod": [3, 6], "claus": 77, "clean": 77, "cleaner": 51, "cleanup": 77, "clear": [35, 52], "clever": 51, "clone": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 37, 41, 51, 52, 54, 61, 66, 67, 68, 69, 70, 71, 72, 74, 75], "close": [34, 36, 53, 59, 71], "cluster": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 23, 76, 77], "cluster_col": [3, 35, 52], "cluster_var": [3, 23], "cluster_var_i": [3, 35, 52], "cluster_var_j": [3, 35, 52], "cmap": 52, "cmd": 77, "co": [25, 46], "codaci": 77, "code": [8, 11, 25, 32, 34, 35, 36, 37, 40, 47, 53, 62, 65, 66, 67, 68, 69, 70, 74, 75, 77, 78], "codecov": 77, "coef": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 75, 78], "coef_": 59, "coef_df": 35, "coeffici": [1, 16, 17, 19, 36, 48, 49, 51, 53, 55, 56, 59, 60, 65, 70, 71, 72, 78], "coefs_t": 56, "coefs_w": 56, "coffici": 71, "cofid": 1, "coincid": [46, 54], "col": [33, 35, 49, 53], "collect": [37, 45, 52, 60], "colnam": [35, 51], "color": [36, 41, 42, 43, 44, 46, 52, 53, 54, 55, 57, 59], "color_palett": [41, 52, 53, 54], "colorbar": 52, "colorramppalett": 35, "colorscal": [42, 43], "colour": [33, 35], "column": [3, 6, 38, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58, 59, 60, 63, 65, 66, 68, 75, 77, 78], "column_stack": [46, 48, 49, 58, 59], "colv": 35, "com": [25, 34, 36, 37, 47, 53, 55, 59, 66, 74], "comb": 47, "combin": [34, 35, 37, 45, 51, 52, 59, 66, 68, 71, 77], "combind": 54, "combined_loss": 47, "come": [61, 66, 69, 71, 73, 78], "command": [74, 77], "comment": 63, "common": [51, 58, 59, 65, 67, 76], "companion": 76, "compar": [33, 35, 41, 42, 43, 44, 46, 48, 49, 52, 55, 57, 59, 62, 66, 71], "comparevers": 36, "comparison": [51, 55], "compat": [32, 34, 40, 77], "complement": 59, "complet": [62, 71, 74], "complex": [8, 34], "complianc": [57, 69], "complic": [37, 78], "complier": [36, 53, 54, 57, 65], "compon": [34, 36, 47, 51, 53, 56, 65, 66, 68, 69, 77], "compont": 34, "composit": 76, "compris": [70, 72], "comput": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 31, 33, 34, 36, 37, 41, 53, 54, 58, 59, 68, 69, 71, 73, 76, 77, 78], "computation": 71, "concat": [52, 53, 56, 70], "concaten": [46, 53, 70], "concentr": 70, "concern": 59, "conclud": [59, 78], "cond": 67, "conda": [52, 76, 77], "condit": [2, 8, 11, 16, 17, 19, 27, 28, 33, 35, 36, 41, 45, 46, 50, 52, 53, 56, 59, 60, 62, 64, 67, 70, 71, 72, 75, 76, 77, 78], "conduct": [65, 67, 78], "conf": [34, 57], "confer": 76, "confid": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 42, 43, 44, 45, 48, 49, 52, 54, 57, 58, 60, 64, 65, 68, 69, 71, 75, 76, 78], "confidenceband": 44, "confidenti": 59, "config": 55, "configur": 37, "confint": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 36, 42, 43, 44, 45, 46, 48, 49, 51, 54, 56, 57, 58, 60, 65, 68, 70, 72, 73, 75, 78], "conflict": 74, "confound": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 19, 31, 32, 36, 40, 50, 53, 57, 58, 59, 63, 67, 70, 71, 72, 75, 76, 77, 78], "congress": 76, "connect": [36, 53, 54], "consequ": [16, 17, 35, 50, 52, 58, 65, 67, 71], "conserv": [58, 59, 71], "consid": [2, 7, 8, 9, 12, 33, 35, 36, 41, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 78], "consider": 59, "consist": [10, 11, 36, 45, 53, 54, 55, 59, 62, 63, 67, 75, 77], "consol": [33, 77], "constant": [21, 47, 56, 65, 70, 72], "constrained_layout": 41, "construct": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 37, 42, 43, 44, 46, 54, 58, 61, 65, 69, 70, 72, 77, 78], "construct_framework": [2, 4, 5, 7, 8, 9, 10, 11, 12], "construct_iv": 52, "constructiv": 35, "constructor": 37, "consum": [35, 52], "contain": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 29, 30, 33, 35, 36, 41, 42, 43, 48, 49, 51, 52, 53, 62, 65, 66, 70, 71, 77], "context": [59, 67, 78], "continu": [32, 37, 40, 47, 55, 71, 77, 78], "contour": [2, 4, 5, 7, 8, 9, 10, 11, 12, 47, 50, 58, 59, 71], "contour_plot": 59, "contours_z": [42, 43], "contrast": [44, 45], "contribut": [74, 77], "contributor": 77, "control": [22, 34, 47, 54, 56, 59, 78], "convent": [36, 53, 54], "converg": [33, 41, 51, 52, 62], "convergencewarn": 52, "convers": 52, "convert": [44, 52, 57], "convex": 55, "coor": [37, 66, 73, 75], "coordin": 59, "copi": [49, 53, 56, 59], "cor": 71, "core": [38, 44, 45, 50, 52, 53, 54, 57, 58, 60, 63, 66, 75, 77], "cores_us": [44, 54, 57], "correct": [50, 59, 65, 70, 72, 77], "correctli": [45, 55, 58, 71], "correl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 47, 52, 58, 60, 67, 71], "correpond": 67, "correspond": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 27, 28, 33, 35, 36, 37, 41, 42, 43, 45, 46, 47, 51, 52, 53, 54, 56, 57, 58, 59, 62, 65, 66, 67, 68, 70, 71, 72, 77, 78], "cosh": 25, "coul": 35, "could": [32, 37, 40, 42, 43, 59, 77, 78], "counfound": [16, 17, 57, 58, 65, 71], "count": [53, 54], "countour": 71, "coupl": [36, 53, 54], "cournapeau": [73, 75], "cours": [36, 51, 53, 59, 70, 78], "cov": 16, "covari": [3, 4, 5, 6, 8, 10, 11, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 62, 63, 65, 66, 67, 69, 70, 71, 75, 77], "cover": [34, 47, 58], "coverag": [51, 65, 77], "cp": [36, 37, 66], "cpu": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "cpu_count": [44, 54, 57], "cran": [37, 76, 77], "creat": [19, 32, 35, 37, 40, 41, 42, 43, 44, 48, 49, 52, 54, 56, 57, 59, 66, 71, 74], "create_synthetic_group_data": 56, "critic": [59, 78], "cross": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 32, 33, 34, 36, 37, 41, 51, 53, 54, 59, 62, 64, 66, 70, 77, 78], "cross_sectional_data": [5, 18, 45, 67], "crossfit": 51, "crosstab": 55, "crucial": [47, 78], "csail": [73, 75], "csv": 47, "cumul": 67, "current": [34, 49, 69, 71, 73, 78], "custom": [33, 34, 41, 59, 66], "custom_measur": 34, "cut": 56, "cv": [37, 53, 66, 68], "cv_glmnet": [35, 36, 37, 66, 70, 72, 75], "cvar": [2, 13, 64, 77], "cvar_0": 44, "cvar_1": 44, "d": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 78], "d0": [44, 57, 70], "d0_true": 57, "d0cdb0ea4795": 37, "d1": [44, 55, 57, 70, 72], "d10": [70, 72], "d1_true": 57, "d2": [55, 70, 72], "d21ee5775b5f": 37, "d3": [70, 72], "d4": [70, 72], "d5": [70, 72], "d5a0c70f1d98": 37, "d6": [70, 72], "d7": [70, 72], "d8": [70, 72], "d9": [70, 72], "d_": [23, 35, 46, 52, 67, 70, 72], "d_1": [55, 70, 72], "d_2": 55, "d_col": [3, 6, 32, 33, 35, 36, 37, 40, 42, 43, 48, 49, 52, 53, 54, 56, 58, 61, 62, 63, 66, 67, 68, 69, 75, 77, 78], "d_i": [19, 20, 21, 22, 24, 25, 26, 33, 41, 44, 45, 55, 57, 60, 62, 67], "d_j": [70, 72], "d_k": [70, 72], "d_w": 56, "da1440": 55, "dag": [59, 60, 78], "dark": [33, 41], "darkblu": 35, "darkr": 35, "dat": 63, "data": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 34, 46, 47, 51, 55, 61, 64, 65, 66, 68, 70, 72, 76, 77], "data_cvar": 54, "data_dict": [42, 43, 48, 49, 50], "data_dml": 58, "data_dml_bas": [36, 42, 43, 48, 49, 53, 54, 56], "data_dml_base_iv": [36, 53, 54], "data_dml_flex": [36, 53], "data_dml_flex_iv": 36, "data_dml_iv_flex": 53, "data_dml_new": 56, "data_fram": 78, "data_lqt": 54, "data_pq": 54, "data_qt": 54, "data_transf": [35, 52, 53], "datafram": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 35, 38, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 69, 70, 71, 75, 78], "dataset": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 33, 34, 41, 42, 43, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 75, 78], "datatyp": 77, "db": [36, 53, 54, 58, 78], "dbl": [34, 35, 36, 37, 63, 70, 72, 75, 78], "dc13a11076b3": 37, "ddc9": 37, "de": [32, 40, 76], "deal": [32, 40], "debias": [14, 15, 23, 24, 35, 47, 52, 64, 66, 68, 73, 76, 77], "debt": [36, 53, 54], "decai": 60, "decid": [36, 53], "decis": [8, 32, 36, 40, 53, 54, 65, 76, 78], "decision_effect": 32, "decision_impact": [32, 40], "decisiontreeclassifi": [8, 53], "decisiontreeregressor": 53, "declar": 78, "deep": [29, 30], "deeper": 8, "def": [2, 4, 5, 7, 8, 9, 10, 11, 12, 41, 44, 51, 52, 55, 56, 57, 59, 66, 69], "default": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 23, 24, 25, 29, 30, 34, 35, 45, 48, 49, 51, 52, 56, 58, 59, 60, 61, 65, 66, 68, 70, 71, 72, 75, 78], "default_convert": 52, "defin": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 36, 37, 41, 42, 43, 44, 45, 47, 48, 49, 51, 53, 54, 56, 57, 58, 59, 65, 66, 67, 69, 71], "definit": [25, 48, 49, 71], "defint": 71, "degre": [36, 42, 43, 52, 53, 65, 71], "dekel": 76, "delete_origin": 37, "deliber": 55, "delta": [22, 34, 45, 59, 67], "delta_bench": 59, "delta_i": 34, "delta_j": 22, "delta_theta": [31, 50, 58, 59, 71], "delta_v": 59, "demand": [35, 52, 71], "demir": [14, 15, 24, 35, 47, 52, 62, 68, 73, 76], "demo": 59, "demonstr": [33, 34, 35, 41, 52, 59, 63, 70, 72, 73, 75], "deni": 76, "denomin": 71, "denot": [10, 35, 36, 45, 46, 52, 53, 59, 60, 65, 67, 69, 71], "dens_net_tfa": 36, "densiti": [9, 12, 13, 33, 41], "dep": 38, "dep1": [37, 38, 63, 75], "dep2": [37, 38, 63, 75], "depend": [2, 8, 9, 13, 19, 37, 42, 43, 45, 48, 49, 50, 51, 56, 61, 65, 66, 69, 71, 75, 76], "deprec": [61, 68], "depreci": 77, "depth": [8, 36, 37, 56, 61, 65, 66, 67, 68, 69, 70, 75, 78], "deriv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 28, 70], "describ": [34, 35, 52, 53, 54, 59, 66, 68, 74, 77], "descript": [36, 38, 58, 66, 68, 71], "design": 76, "design_info": [42, 43], "design_matrix": [42, 43, 65], "desir": [17, 37, 56], "detail": [2, 4, 5, 7, 8, 9, 10, 11, 12, 27, 28, 33, 36, 37, 41, 45, 46, 47, 54, 58, 59, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 75, 77, 78], "determin": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 36, 44, 53, 54, 57, 58, 67, 70, 71, 72], "determinist": [56, 65], "deutsch": 73, "dev": 77, "develop": [34, 35, 37, 52, 59, 67, 77], "deviat": [51, 71], "dezeur": 76, "df": [3, 6, 32, 33, 35, 40, 42, 43, 44, 46, 49, 52, 55, 57, 58, 59, 60, 62, 65, 67], "df_agg": 47, "df_bench": 59, "df_binari": 59, "df_bonu": [37, 63, 75], "df_cate": [42, 43], "df_ci": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "df_coef": 51, "df_cvar": 54, "df_lqte": 54, "df_ml_g0": 51, "df_ml_g1": 51, "df_ml_m": 51, "df_pa": [45, 60], "df_plot": 35, "df_pq": 54, "df_qte": 54, "df_result": 47, "df_summari": 53, "df_wide": 52, "dfg": 73, "dgp": [18, 35, 44, 46, 47, 52, 55, 56, 57, 59, 60], "dgp1": 18, "dgp2": 18, "dgp3": 18, "dgp4": 18, "dgp5": 18, "dgp6": 18, "dgp_dict": 59, "dgp_tpye": 45, "dgp_type": [18, 45], "diagon": 59, "diagram": [32, 40, 67], "dichotom": [32, 40], "dict": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 31, 42, 43, 47, 59, 66], "dict_kei": 71, "dictionari": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 19, 31, 42, 43, 48, 49, 58, 65, 66, 71], "dictonari": [36, 53], "did": [3, 6, 33, 45, 46, 52, 64, 77, 78], "diff": 53, "differ": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 32, 33, 35, 36, 37, 40, 41, 44, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 64, 65, 66, 68, 74, 75, 76, 77, 78], "difficult": 59, "dillon": 76, "dim": 36, "dim_x": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 20, 21, 22, 23, 24, 25, 26, 33, 35, 37, 41, 51, 52, 62, 65, 66, 67, 71], "dim_z": [10, 22, 67], "dimens": [19, 23, 35, 52, 56, 68], "dimension": [10, 11, 19, 21, 47, 65, 67, 68, 70, 71, 72, 75, 76], "direct": [33, 41, 46, 60, 62, 78], "directli": [33, 34, 36, 41, 51, 58, 62, 71, 75, 78], "discret": 52, "discretis": 54, "discuss": [20, 35, 36, 52, 53, 76, 77, 78], "disjoint": [35, 48, 49, 52], "displai": [35, 52, 59, 65, 66, 71], "displot": 53, "disproportion": [36, 53], "dist": [2, 4, 5, 7, 8, 9, 10, 11, 12], "distr": 66, "distribut": [33, 41, 45, 51, 59, 62, 67, 71, 74, 76, 77], "diverg": [33, 41, 62], "dmatrix": [42, 43, 65], "dml": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 27, 28, 32, 33, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 53, 54, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 74], "dml1": [64, 75, 77, 78], "dml2": [32, 35, 37, 38, 45, 52, 54, 64, 67, 69, 70, 75, 77, 78], "dml_base": 52, "dml_combin": 70, "dml_cv_predict": 77, "dml_cvar": [44, 54], "dml_cvar_0": 44, "dml_cvar_1": 44, "dml_cvar_obj": [2, 65], "dml_data": [34, 35, 38, 45, 46, 50, 51, 52, 55, 58, 59, 60, 65, 66, 67, 70, 72, 78], "dml_data_bench": 59, "dml_data_bonu": [37, 75], "dml_data_df": 78, "dml_data_lasso": 38, "dml_data_sim": [37, 75], "dml_df": [35, 52], "dml_did": [45, 46], "dml_did_obj": [4, 5, 67], "dml_iivm_boost": [36, 53], "dml_iivm_forest": [36, 53], "dml_iivm_lasso": [36, 53], "dml_iivm_obj": [7, 40, 67], "dml_iivm_tre": [36, 53], "dml_irm": [42, 48, 51, 56], "dml_irm_at": 50, "dml_irm_boost": [36, 53], "dml_irm_forest": [36, 53], "dml_irm_gat": 50, "dml_irm_gatet": 50, "dml_irm_lasso": [36, 38, 53], "dml_irm_new": 56, "dml_irm_obj": [2, 4, 5, 7, 8, 9, 10, 11, 12, 58, 65, 66, 67], "dml_irm_obj_ext": 66, "dml_irm_rf": 38, "dml_irm_tre": [36, 53], "dml_long": 31, "dml_lpq_0": 57, "dml_lpq_1": 57, "dml_lpq_obj": [9, 65], "dml_lqte": [54, 57], "dml_obj": [34, 58, 59], "dml_obj_bench": 59, "dml_pliv": [35, 52], "dml_pliv_obj": [10, 35, 52, 67], "dml_plr": [43, 49, 70, 72], "dml_plr_1": 70, "dml_plr_2": 70, "dml_plr_boost": [36, 53], "dml_plr_forest": [36, 53, 78], "dml_plr_lasso": [36, 38, 53], "dml_plr_no_split": 68, "dml_plr_obj": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 58, 61, 65, 66, 67, 68, 69, 70, 71], "dml_plr_obj_extern": 68, "dml_plr_obj_intern": 68, "dml_plr_rf": 38, "dml_plr_tree": [36, 53, 78], "dml_pq_0": [54, 57], "dml_pq_1": [54, 57], "dml_pq_obj": [12, 65], "dml_procedur": [38, 61, 75, 77, 78], "dml_qte": [54, 57], "dml_qte_obj": [13, 65], "dml_short": 31, "dml_ssm": [60, 67], "dml_tune": 77, "dmldummyclassifi": 66, "dmldummyregressor": 66, "dmlmt": 76, "dnorm": 33, "do": [34, 35, 36, 37, 51, 52, 53, 54, 55, 59, 65, 66, 71, 75, 78], "doabl": 69, "doc": [32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 73, 77], "docu": 77, "document": [39, 42, 43, 46, 48, 49, 59, 73, 77], "doe": [13, 34, 35, 36, 52, 53, 55, 58, 59, 71, 78], "doesn": [32, 40], "doi": [14, 15, 16, 17, 18, 20, 23, 24, 26, 34, 35, 37, 47, 52, 59, 62, 66, 68, 70, 72, 73, 75, 77], "domain": 56, "don": 34, "done": [2, 4, 5, 7, 8, 9, 10, 11, 12, 54, 66, 68, 71], "dot": [46, 56, 63, 65, 66, 70, 72, 75], "doubl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 23, 24, 25, 26, 36, 47, 53, 55, 64, 66, 68, 69, 70, 71, 72, 77], "double_ml_bonus_data": 38, "double_ml_data_from_data_fram": [33, 62, 63, 78], "double_ml_data_from_matrix": [34, 37, 63, 66, 70, 72, 75], "double_ml_irm": [38, 56], "doubleiivm": 73, "doubleml": [33, 35, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 75, 76, 77], "doubleml2022python": 73, "doubleml2024r": 73, "doubleml_did_eval_linear": 34, "doubleml_did_eval_rf": 34, "doubleml_did_linear": 34, "doubleml_did_rf": 34, "doubleml_framework": [2, 4, 5, 7, 8, 9, 10, 11, 12], "doublemlblp": [8, 11, 42, 43, 65, 77], "doublemlclusterdata": 23, "doublemlcvar": [44, 65, 69, 77], "doublemldata": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 24, 25, 26, 32, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 77, 78], "doublemldid": [45, 46, 67, 69, 77], "doublemldidc": [45, 67, 69, 77], "doublemlframework": [2, 4, 5, 7, 8, 9, 10, 11, 12, 68, 70, 77], "doublemlidid": 67, "doublemlididc": 67, "doublemliivm": [32, 36, 40, 53, 66, 67, 68, 69, 77], "doublemlirm": [2, 4, 5, 7, 9, 10, 11, 12, 34, 36, 38, 42, 48, 50, 51, 53, 55, 56, 58, 59, 65, 66, 67, 68, 69, 73, 77], "doublemllpq": [57, 65, 69, 77], "doublemlpliv": [66, 67, 68, 69, 73, 77], "doublemlplr": [2, 4, 5, 7, 8, 9, 10, 12, 13, 33, 36, 37, 38, 41, 43, 49, 53, 55, 58, 61, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 77, 78], "doublemlpolicytre": [8, 65], "doublemlpq": [54, 57, 65, 69, 77], "doublemlqt": [44, 54, 57, 65, 70, 77], "doublemlresampl": 51, "doublemlsmm": 77, "doublemlssm": [60, 67, 69], "doubli": [16, 17, 18, 34, 76], "down": 59, "download": [32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 74, 75], "downward": 59, "dpg_dict": 58, "dpi": [33, 41, 55], "dramat": 34, "draw": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 59, 68, 77], "draw_sample_split": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 51, 68], "drawn": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 19, 36, 53, 54, 56, 68], "drive": [33, 41, 62], "driven": [59, 78], "drop": [34, 52, 55, 63, 66, 69, 70, 72], "dt": [69, 71], "dt_bonu": 63, "dta": 34, "dtype": [38, 45, 48, 49, 50, 51, 52, 53, 54, 58, 60, 63, 65, 75], "dualiti": 52, "dubourg": [73, 75], "duchesnai": [73, 75], "due": [33, 34, 41, 42, 43, 50, 58, 59, 62, 67, 71, 77, 78], "duflo": [14, 15, 24, 35, 47, 52, 62, 68, 73, 76], "dummi": [1, 8, 11, 29, 30, 59, 65, 66, 67, 77], "dummyclassifi": 29, "dummyregressor": 30, "duplic": 77, "durabl": [37, 38, 63, 75], "durat": 15, "dure": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 37, 52, 53, 66, 68, 75, 77, 78], "dx": 20, "dynam": [34, 76], "e": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 24, 26, 27, 28, 33, 34, 35, 36, 41, 42, 43, 45, 47, 50, 51, 52, 53, 54, 55, 58, 59, 60, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78], "e20ea26": 37, "e401": [36, 53, 54, 58, 78], "e4016553": 78, "e45228": 55, "e57c": 37, "each": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 37, 46, 48, 49, 51, 52, 54, 55, 56, 58, 59, 61, 63, 66, 68, 70, 71, 72, 78], "earlier": 78, "earn": [36, 53, 54], "earner": [36, 53, 58], "easi": [37, 69], "easili": [37, 51, 54, 77], "ec973f": 55, "ecolor": [46, 53, 55], "econ": 76, "econml": 76, "econom": [22, 23, 25, 26, 35, 47, 52, 55, 59, 68, 76], "econometr": [14, 15, 16, 17, 18, 24, 25, 34, 35, 47, 52, 62, 73, 76], "econometrica": [21, 35, 52, 55, 62, 76], "ecosystem": [73, 78], "ectj": [14, 15, 24, 35, 47, 52, 62, 73], "ed": 76, "edge_color": 41, "edgecolor": 41, "edit": [74, 76], "edu": [73, 75], "educ": [36, 53, 54, 58, 78], "ee97bda7": 37, "effect": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 32, 33, 34, 35, 37, 40, 41, 45, 46, 47, 50, 52, 56, 60, 62, 64, 66, 67, 68, 69, 70, 71, 75, 76, 77, 78], "effici": 76, "effort": 69, "eight": [35, 52], "either": [2, 4, 5, 7, 8, 9, 10, 11, 12, 19, 37, 46, 47, 56, 65, 66, 78], "eleanor": 76, "element": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 42, 43, 44, 45, 51, 52, 54, 57, 58, 60, 69, 71, 77], "element_text": [35, 36], "elementari": 76, "elif": [48, 49, 56], "elig": [54, 58, 78], "eligibl": [36, 53, 58], "ell": [33, 35, 41, 47, 52, 62, 69, 75], "ell_0": [7, 10, 11, 33, 41, 47, 62, 67], "ell_2": 51, "els": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 36, 46, 48, 49, 52, 56, 59], "em": 76, "emphas": [35, 52], "empir": [27, 28, 33, 35, 41, 52, 55, 59, 62, 68, 69, 70, 72], "emploi": [35, 47, 52, 59, 69], "employ": [36, 53, 54], "employe": 78, "empti": 52, "emul": 71, "enabl": [56, 58, 65, 71, 77], "encapsul": [29, 30], "encod": 55, "end": [20, 22, 23, 33, 34, 35, 36, 41, 44, 46, 47, 51, 52, 53, 55, 56, 57, 60, 61, 63, 66, 68, 70, 72, 75, 78], "endogen": [36, 53, 54, 78], "enet_coordinate_descent_gram": 52, "engin": [37, 76], "enrol": [36, 53, 54], "ensembl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 41, 42, 43, 48, 49, 50, 51, 53, 56, 58, 59, 61, 65, 66, 67, 68, 69, 70, 71, 75, 78], "ensemble_learner_pipelin": 66, "ensemble_pipe_classif": 37, "ensemble_pipe_regr": 37, "ensur": [35, 49, 52, 56], "entir": [33, 36, 41, 53, 62, 71], "entri": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 35, 38, 41, 45, 50, 52, 53, 54, 58, 60, 62, 63, 66, 73, 75, 77], "enumer": [44, 46, 48, 49, 51, 52, 53, 54, 57, 61, 66, 68], "env": [52, 74], "environ": 74, "ep": 55, "epsilon": [36, 44, 45, 46, 53, 57, 65, 67], "epsilon_": [35, 46, 52], "epsilon_i": [19, 44, 55, 56, 57], "epsilon_sampl": 56, "epsilon_tru": [44, 57], "eqnarrai": 36, "equal": [8, 35, 52, 55, 60, 65, 66, 71], "equat": [35, 36, 52, 53, 59, 61, 70, 72, 78], "equilibrium": [35, 52], "equival": [47, 68], "err": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 40, 42, 43, 44, 45, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 67, 68, 69, 70, 75, 78], "error": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 32, 33, 34, 36, 37, 41, 46, 47, 48, 49, 51, 53, 59, 62, 66, 67, 68, 69, 70, 71, 72, 75, 77, 78], "errorbar": [46, 48, 49, 53, 55], "erstellt": [35, 36, 37], "especi": 51, "essenti": 59, "est_method": 34, "esther": [68, 76], "estim": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 27, 28, 29, 30, 33, 34, 35, 37, 41, 42, 43, 44, 46, 48, 49, 51, 52, 56, 61, 62, 64, 65, 66, 67, 71, 72, 73, 76, 77], "estimatior": [3, 6], "et": [14, 15, 19, 21, 23, 24, 33, 35, 36, 37, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54, 57, 58, 62, 67, 68, 69, 70, 71, 72, 73, 75, 77], "eta": [27, 28, 33, 35, 36, 46, 52, 53, 57, 61, 65, 68, 69, 70, 71, 72, 75, 78], "eta1": 55, "eta2": 55, "eta_": [70, 71, 72], "eta_0": [61, 69, 70], "eta_i": [19, 46, 56, 57], "eta_sampl": 56, "eta_tru": 57, "etc": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 51, 52, 77], "ev": [33, 41, 62], "eval": [37, 66], "eval_metr": [36, 53, 78], "eval_pr": 34, "eval_predict": 34, "evalu": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 21, 28, 34, 37, 42, 43, 44, 46, 50, 54, 57, 58, 61, 76, 77], "evaluate_learn": [2, 4, 5, 7, 8, 9, 10, 11, 12, 51, 66, 77], "evalut": 66, "even": [36, 37, 53, 55, 66, 78], "eventu": [35, 52], "everi": [35, 52], "everyth": 73, "evid": 50, "exact": 59, "exactli": 59, "exampl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 32, 33, 36, 37, 38, 40, 41, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 77, 78], "example_attgt": 34, "example_attgt_dml_eval_linear": 34, "example_attgt_dml_eval_rf": 34, "example_attgt_dml_linear": 34, "example_attgt_dml_rf": 34, "except": [47, 59, 77], "excess": 51, "exclud": 31, "exclus": [8, 11, 48, 49, 65], "execut": [37, 78], "exemplarili": 75, "exemplatori": 56, "exhaust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 66], "exhibit": [35, 52], "exist": [67, 71], "exogen": [36, 53, 54, 78], "exp": [16, 17, 18, 19, 21, 24, 33, 41, 42, 43, 46, 48, 49, 55, 56, 62], "expect": [16, 17, 34, 45, 50, 51, 59, 60, 65, 68, 70, 75], "experi": [15, 20, 21, 33, 36, 41, 53, 59, 62, 63, 68, 75, 76], "experiment": [4, 5, 18, 69, 71], "expertis": 59, "explain": [2, 4, 5, 7, 8, 9, 10, 11, 12, 17, 58, 71], "explan": [35, 45, 52, 58, 71, 73, 78], "explanatori": [59, 70, 72], "explicit": 59, "explicitli": [50, 78], "exploit": [33, 41, 62, 78], "exponenti": [70, 72], "export": 77, "exposur": 46, "express": [35, 47, 71], "extend": [59, 66, 73, 77], "extendend": 71, "extens": [66, 69, 73, 76, 77], "extent": 47, "extern": [33, 41, 64, 71, 77], "external_predict": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 41, 66], "externalptr": 36, "extra": 37, "extract": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "extralearn": 37, "extrem": [36, 53], "ey": 47, "f": [36, 37, 41, 44, 45, 46, 47, 51, 52, 53, 54, 56, 57, 58, 59, 60, 66, 71, 73, 75], "f00584a57972": 37, "f1718fdeb9b0": 37, "f2e7": 37, "f3d24993": 37, "f6ebc": 55, "f_": [16, 18, 46, 65], "f_loc": [44, 57], "f_p": 46, "f_scale": [44, 57], "face_color": 41, "facet_wrap": 36, "fact": [36, 53, 54], "factor": [33, 34, 35, 36, 37, 41, 51, 62, 66, 78], "faculti": 76, "fail": 77, "fair": 51, "fake": [32, 40], "fals": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 33, 36, 37, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 59, 60, 63, 66, 67, 68, 69, 70, 71, 72, 78], "famili": [36, 53, 66], "fanci": 34, "far": [36, 53], "farbmach": 20, "fast": [51, 56, 66], "faster": 47, "fb5c25fa": 37, "fc9e": 37, "fd8a": 37, "featur": [2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 34, 38, 50, 51, 53, 56, 65, 66], "featureless": [37, 66], "features_bas": [36, 53, 54, 58], "features_flex": 36, "featureunion": 37, "februari": 59, "femal": [37, 38, 63, 75], "fern\u00e1ndez": [21, 68, 76], "fetch": [36, 52, 53, 54, 63], "fetch_401k": [36, 53, 54, 58, 78], "fetch_bonu": [37, 38, 63, 75], "few": [36, 53, 54], "ff7f0e": 46, "field": [35, 52, 66, 78], "fifteenth": 76, "fifth": 35, "fig": [2, 4, 5, 7, 8, 9, 10, 11, 12, 42, 43, 44, 46, 47, 51, 54, 55, 57, 59], "fig_al": 41, "fig_dml": 41, "fig_non_orth": 41, "fig_orth_nosplit": 41, "fig_po_al": 41, "fig_po_dml": 41, "fig_po_nosplit": 41, "figsiz": [38, 42, 43, 44, 46, 48, 49, 51, 52, 53, 54, 55, 57], "figur": [2, 4, 5, 7, 8, 9, 10, 11, 12, 24, 33, 35, 38, 41, 42, 43, 44, 46, 47, 48, 49, 52, 53, 54, 57, 59, 62], "figure_format": 55, "file": [14, 15, 47, 55, 76, 77], "filenam": 33, "fill": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 35, 36, 45, 51, 53, 60], "fill_between": [42, 43, 44, 54, 57], "fill_valu": 51, "filter": 37, "filterwarn": 41, "final": [33, 37, 41, 42, 43, 44, 46, 48, 49, 50, 54, 57, 60, 62, 67, 78], "financi": [14, 58, 78], "find": [36, 46, 53, 59, 65, 66, 78], "finish": 37, "finit": [33, 36], "firm": [35, 52, 58], "firmid": 52, "first": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 23, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 46, 48, 49, 50, 51, 52, 53, 54, 56, 57, 59, 60, 62, 65, 68, 70, 71, 72, 74, 75, 77, 78], "fit": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 29, 30, 32, 33, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 77, 78], "fit_arg": [2, 4, 5, 7, 8, 9, 10, 11, 12], "fit_transform": [52, 53], "five": 52, "fix": [46, 51, 53, 77], "flag": [18, 68, 74], "flake8": 77, "flatten": 55, "flexibl": [32, 34, 36, 37, 40, 45, 53, 73, 78], "flexibli": [36, 53, 58], "float": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17], "float32": [54, 58], "float64": [38, 45, 49, 50, 52, 53, 58, 60, 63, 66, 75], "floor": 37, "floor_divid": 52, "flt": 37, "flush": 33, "fmt": [46, 48, 49, 53, 55], "focu": [35, 36, 52, 53, 54, 59, 65, 67, 78], "focus": [54, 58, 59, 78], "fold": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 35, 36, 37, 45, 51, 52, 53, 54, 58, 60, 61, 64, 66, 67, 69, 70, 75, 78], "follow": [16, 17, 18, 19, 33, 35, 36, 41, 42, 43, 44, 45, 46, 48, 49, 52, 53, 54, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 71, 74, 75, 78], "font_scal": [52, 53, 54], "fontsiz": [44, 54, 57], "force_all_x_finit": [3, 6], "forest": [20, 32, 33, 34, 36, 37, 40, 41, 45, 50, 51, 53, 58, 62, 66, 75, 78], "forest_summari": 53, "forg": [74, 76, 77], "form": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 36, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 57, 58, 60, 65, 67, 71, 74, 75], "format": [41, 50, 71], "formula": [35, 36, 52, 53, 59, 77], "formula_flex": 36, "forschungsgemeinschaft": 73, "forthcom": [59, 76], "forum": 77, "forward": 8, "found": [42, 43, 47, 48, 49, 62, 63, 66, 67, 75], "foundat": [73, 76], "four": [36, 51, 53, 77], "fourth": [35, 52], "frac": [7, 16, 17, 18, 20, 21, 22, 24, 25, 26, 28, 33, 35, 37, 41, 46, 47, 50, 52, 55, 61, 62, 65, 67, 69, 70, 71, 72], "fraction": 37, "frame": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 35, 36, 38, 42, 43, 45, 48, 49, 50, 52, 53, 54, 55, 56, 58, 60, 62, 63, 75, 78], "framework": [28, 33, 35, 37, 41, 51, 52, 55, 59, 62, 66, 70, 72, 73, 75, 77, 78], "freez": 74, "fribourg": 76, "from": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 77, 78], "from_arrai": [3, 6, 41, 44, 45, 46, 57, 62, 63, 66, 70, 72, 75], "from_product": 52, "fr\u00e9chet": 71, "fsize": [36, 53, 54, 58, 78], "full": [41, 44, 45, 46, 48, 49, 51, 53, 54, 57, 60, 62], "fulli": [8, 36, 39, 53, 67], "fun": 33, "func": 34, "function": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 24, 25, 27, 28, 32, 33, 36, 37, 40, 41, 42, 43, 44, 45, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 68, 70, 71, 72, 73, 76, 77, 78], "fund": [36, 53, 54, 73], "further": [16, 17, 18, 19, 23, 35, 37, 42, 43, 44, 45, 46, 50, 51, 52, 54, 56, 57, 58, 59, 60, 66, 67, 69, 70, 71, 72, 73, 75, 77, 78], "furthermor": 41, "futurewarn": 49, "g": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 33, 34, 37, 38, 41, 42, 43, 45, 46, 47, 50, 51, 54, 55, 56, 58, 60, 62, 65, 66, 67, 69, 70, 71, 73, 74, 75, 78], "g_": [69, 70, 72], "g_0": [4, 5, 7, 8, 10, 11, 12, 24, 25, 33, 35, 36, 41, 51, 52, 53, 62, 65, 66, 67, 69, 71, 75, 78], "g_1": 51, "g_all": [33, 36], "g_all_po": 33, "g_ci": 36, "g_d": 69, "g_dml": 33, "g_dml_po": 33, "g_hat": [10, 11, 33, 41, 69], "g_hat0": [7, 8], "g_hat1": [7, 8], "g_k": 65, "g_nonorth": 33, "g_nosplit": 33, "g_nosplit_po": 33, "g_x": 46, "gain": [2, 4, 5, 7, 8, 9, 10, 11, 12, 17, 31, 51, 71, 77], "gain_statist": 77, "galleri": [62, 65, 66, 67, 73, 77], "gamma": [22, 25, 26, 35, 52, 55, 56, 59, 69], "gamma_0": [19, 56, 60, 69], "gamma_a": [16, 17, 59], "gamma_bench": 59, "gamma_v": 59, "gap": [52, 59], "gate": [1, 8, 11, 55, 56, 64, 77], "gate_obj": 65, "gatet": 65, "gaussian": [9, 12, 13, 33, 41, 62, 65, 66, 70, 72, 76], "ge": [16, 18, 19, 50, 56, 65], "geer": 76, "gelbach": [35, 52], "gener": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 76, 77, 78], "generate_treat": 57, "geom_bar": 36, "geom_dens": 36, "geom_errorbar": 36, "geom_funct": 33, "geom_histogram": 33, "geom_hlin": 36, "geom_point": 36, "geom_til": 35, "geom_vlin": 33, "german": 73, "get": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 37, 51, 55, 58, 59, 71, 73, 74], "get_dummi": 55, "get_feature_names_out": [52, 53], "get_logg": [33, 34, 35, 36, 37, 61, 66, 67, 68, 69, 70, 72, 75], "get_metadata_rout": [29, 30], "get_param": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 66], "ggdid": 34, "ggplot": [33, 35, 36], "ggplot2": [33, 35, 36], "ggsave": 33, "ggtitl": 36, "gh": 77, "git": 74, "github": [34, 36, 47, 53, 55, 73, 76, 77], "githubusercont": 47, "give": [36, 53], "given": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 21, 24, 25, 28, 33, 35, 41, 46, 48, 49, 52, 54, 55, 59, 60, 62, 65, 70, 71, 72, 75, 77], "glmnet": [36, 37, 66, 77], "global": [2, 4, 5, 7, 8, 9, 10, 11, 12, 66], "glrn": 37, "glrn_lasso": 37, "gname": 34, "go": [42, 43, 47, 59], "goal": [48, 49], "goldman": 76, "good": [47, 71, 78], "gradient": [36, 53], "gradientboostingclassifi": 51, "gradientboostingregressor": 51, "gradual": 59, "gramfort": [73, 75], "graph": [37, 60, 78], "graph_ensemble_classif": 37, "graph_ensemble_regr": 37, "graph_object": [42, 43, 47, 59], "graphlearn": [37, 66], "grasp": 71, "great": [46, 78], "greater": 78, "green": [33, 42, 43, 44, 57], "greg": 76, "grei": 36, "grenand": 76, "grey50": 35, "grid": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 37, 42, 43, 44, 47, 54, 55, 57, 59, 66, 71], "grid_arrai": [42, 43], "grid_bound": [2, 4, 5, 7, 8, 9, 10, 11, 12, 59], "grid_search": [2, 4, 5, 7, 8, 9, 10, 11, 12, 37, 66], "grid_siz": [2, 4, 5, 7, 8, 9, 10, 11, 12, 42, 43], "gridextra": 35, "gridsearchcv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 66], "grisel": [73, 75], "grob": 35, "group": [8, 11, 32, 34, 40, 50, 54, 55, 56, 59, 64], "group_0": 65, "group_1": [48, 49, 65], "group_2": [48, 49, 65], "group_3": [48, 49], "group_effect": 56, "group_ind": 50, "group_treat": 50, "groupbi": [47, 53], "gruber": 20, "gt": [32, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 75], "guarante": [35, 52], "guber": 20, "guess": [58, 71], "guid": [27, 28, 29, 30, 33, 34, 35, 37, 41, 46, 50, 52, 58, 66, 73, 75, 77], "guidelin": 77, "gunion": [37, 66], "gxidclusterperiodytreat": 34, "h": [16, 17, 18, 20, 23, 34, 35, 52, 76], "h_0": [50, 58, 59, 71, 78], "ha": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 18, 33, 34, 35, 36, 41, 47, 51, 52, 53, 54, 55, 58, 59, 65, 66, 67, 71, 78], "half": [33, 41, 55, 62, 68], "hand": [51, 55, 78], "handbook": 55, "handl": [34, 51, 66, 77], "hansen": [14, 15, 21, 22, 24, 35, 47, 52, 62, 73, 76], "happend": 51, "hard": [58, 71], "harold": 76, "hat": [33, 35, 41, 47, 50, 52, 55, 61, 62, 65, 68, 69, 70, 71, 72], "have": [1, 8, 11, 13, 19, 32, 33, 34, 35, 36, 37, 40, 42, 43, 45, 46, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 63, 65, 66, 70, 71, 74, 75, 77, 78], "hazlett": [59, 71], "hc": [34, 76], "hdm": [35, 52], "he": 60, "head": [34, 35, 37, 38, 42, 43, 48, 49, 52, 53, 55, 59, 63, 65, 75], "heat": [35, 52], "heatmap": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 52, 59], "heavili": 51, "hei": 76, "height": [33, 35, 47], "help": [34, 36, 44, 51, 54, 56, 59, 68, 78], "helper": 77, "henc": [34, 36, 37, 53, 59, 66, 69, 78], "here": [9, 12, 13, 34, 35, 36, 37, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 56, 57, 59, 60, 63, 66, 74], "heterogen": [8, 19, 36, 50, 53, 54, 56, 64, 67, 68, 76, 77, 78], "heteroskedast": [48, 49], "heurist": [33, 41, 62], "high": [10, 11, 21, 36, 46, 47, 53, 54, 61, 67, 70, 72, 73, 75, 76], "higher": [34, 36, 47, 53, 54, 55, 77, 78], "highli": [36, 53, 73], "highlight": [2, 4, 5, 7, 8, 9, 10, 11, 12, 45, 59, 77], "highlightcolor": [42, 43], "hispan": 38, "hist_e401": 36, "hist_p401": 36, "histplot": 41, "hjust": 36, "hline": [63, 70, 72, 75, 78], "hold": [26, 35, 36, 52, 53, 60, 65, 66], "holdout": [66, 68], "holm": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "home": [36, 53], "homogen": 67, "hopefulli": 54, "horizont": [35, 46, 52], "hostedtoolcach": [53, 59], "hot": 55, "hotstart_backward": [37, 66], "hotstart_forward": [37, 66], "household": [36, 53, 54, 58], "how": [29, 30, 32, 34, 35, 36, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 66, 73, 74], "howev": [33, 36, 41, 53, 59, 60, 62, 78], "hown": [36, 53, 54, 58, 78], "hpwt": [35, 52], "hpwt0": 35, "hpwtairmpdspac": 35, "href": 73, "hspace": 51, "hstack": 46, "html": [37, 49, 73, 75, 77], "http": [20, 25, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 66, 73, 74, 75, 77], "huber": [26, 60, 67, 69, 76], "hue": 53, "huge": 51, "hugo": 76, "husd": [37, 38, 63, 75], "hyperparamet": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 37, 38, 47, 51, 53, 64, 75], "hypothes": [70, 72, 76], "hypothesi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 53, 58, 71, 76], "hypothet": 59, "i": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78], "i0": [45, 46, 67], "i03": 73, "i1": [45, 67], "i_": [22, 52, 56], "i_1": [35, 52], "i_2": [35, 52], "i_3": [35, 52], "i_4": 46, "i_est": 41, "i_fold": 35, "i_k": [35, 52, 61, 68, 70, 72], "i_learn": 51, "i_rep": [33, 41, 45, 51, 60, 62], "i_split": 52, "i_train": 41, "icp": 76, "id": [34, 35, 37, 52], "id_var": 52, "idea": [36, 37, 53, 54, 59, 66, 71, 78], "ident": [16, 17, 18, 19, 22, 37, 66, 71], "identfi": 59, "identif": [67, 78], "identifi": [35, 36, 45, 50, 52, 53, 54, 59, 65, 67, 71, 77], "identifii": 65, "idnam": 34, "idx_tau": [44, 54, 57], "idx_treat": [2, 4, 5, 7, 8, 9, 10, 11, 12, 71], "ieee": 76, "ifels": 34, "ignor": 41, "ii": [35, 52], "iid": 67, "iivm": [7, 20, 27, 28, 54, 61, 64, 65, 73, 77], "iivm_summari": 53, "iivmglmnet": 36, "iivmrang": 36, "iivmrpart": 36, "iivmxgboost11861": 36, "ij": [23, 35, 52, 60], "ilia": 76, "illustr": [33, 35, 36, 37, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 57, 58, 59, 60, 62, 66, 78], "iloc": [45, 46, 51, 52, 55], "immedi": 74, "immun": [68, 76], "impact": [32, 40, 51, 55, 58], "implement": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 27, 28, 33, 34, 35, 36, 37, 41, 45, 47, 51, 52, 53, 55, 58, 59, 60, 62, 64, 65, 66, 67, 68, 70, 72, 73, 75, 76, 77, 78], "impli": [16, 17, 35, 36, 52, 53, 54, 65, 71], "implment": 46, "import": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 78], "importlib": 47, "impos": 59, "improv": [45, 51, 56, 77], "in_sample_norm": [4, 5, 45, 69, 71], "inbuild": 51, "inbuilt": 51, "inc": [36, 53, 54, 58, 78], "includ": [2, 4, 5, 7, 8, 9, 10, 11, 12, 31, 34, 36, 46, 48, 49, 53, 58, 59, 65, 67, 70, 71, 72, 77, 78], "include_bia": [52, 53], "include_scenario": [2, 4, 5, 7, 8, 9, 10, 11, 12, 59], "incom": [36, 53, 54, 56, 58, 78], "incorpor": [37, 58, 71], "increas": [50, 51, 52, 59, 78], "increment": 77, "ind": 53, "independ": [4, 5, 16, 17, 18, 19, 35, 37, 46, 50, 52, 56, 67, 69, 77], "index": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 35, 38, 41, 46, 47, 48, 49, 52, 53, 55, 56, 62, 63, 68, 69, 75], "index_col": 47, "india": [68, 76], "indic": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 19, 26, 35, 36, 46, 50, 52, 53, 54, 59, 60, 61, 63, 65, 67, 68], "individu": [8, 34, 36, 46, 48, 49, 50, 53, 54, 58, 65, 78], "individual_df": 46, "induc": [64, 68], "industri": [35, 52], "inf": [3, 6, 34], "inf_model": 69, "infer": [21, 22, 32, 33, 35, 40, 41, 47, 52, 62, 64, 68, 73, 75, 76, 77], "inferenti": 78, "infinit": [3, 6, 77], "info": [32, 37, 38, 45, 50, 52, 53, 54, 58, 60, 63, 75, 77, 78], "inform": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 29, 30, 32, 37, 40, 42, 43, 51, 58, 59, 71, 76], "infti": [33, 41, 62], "inher": 59, "inherit": [55, 77], "initi": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 36, 37, 44, 45, 53, 54, 57, 58, 59, 60, 63, 65, 66, 68, 75, 77, 78], "inlin": [38, 55], "inlinebackend": 55, "inner": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 66], "innermost": 66, "input": [2, 4, 5, 7, 8, 9, 10, 11, 12, 37, 58, 61, 70, 71, 72], "insight": [47, 59], "insignific": 58, "inspect": 75, "inspir": [16, 20, 21, 26, 59], "instal": [36, 77], "install_github": 74, "instanc": [36, 37, 53, 66], "instanti": [35, 36, 52, 53, 66, 68], "instead": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 34, 36, 40, 49, 50, 53, 54, 65, 66, 71, 77], "instruct": 77, "instrument": [3, 6, 7, 10, 14, 20, 22, 35, 36, 37, 38, 45, 50, 52, 53, 54, 57, 58, 60, 63, 66, 67, 69, 70, 75, 78], "instrument_effect": 32, "instrument_impact": 40, "int": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 34, 35, 36, 40, 44, 45, 56, 57, 59, 60], "int64": [38, 51, 52, 63, 75], "int8": [53, 54, 58], "integ": [18, 37, 66], "integr": [59, 71, 77], "intend": [37, 59, 78], "intent": 78, "inter": 66, "interact": [7, 8, 16, 20, 21, 59, 64, 66, 73, 77, 78], "interchang": 70, "interest": [7, 8, 10, 11, 16, 17, 33, 36, 41, 45, 47, 53, 54, 60, 62, 65, 67, 69, 70, 72, 75, 78], "interfac": [34, 36, 37, 63, 66, 68, 75], "intermedi": [49, 59], "intern": [34, 36, 37, 54, 66, 76], "internet": [36, 53, 54], "interpret": [48, 49, 59, 65, 71, 74, 78], "intersect": [59, 71, 77], "interv": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 42, 43, 44, 45, 48, 49, 52, 54, 57, 58, 60, 64, 65, 68, 69, 71, 75, 76, 78], "introduc": [33, 41, 62, 63, 70, 72, 77, 78], "introduct": [33, 35, 37, 41, 52, 54, 58, 66, 67, 71], "introductori": [34, 59], "intrument": 60, "intuit": 59, "inuidur1": [37, 38, 63, 75], "inuidur1femaleblackothracedep1dep2q2q3q4q5q6agelt35agegt54durablelusdhusdtg": [37, 63, 75], "inuidur2": [38, 63, 75], "inv_sigmoid": 55, "invalid": [33, 41, 62], "invari": 67, "invers": [2, 7, 8, 9, 12, 13, 60, 71], "invert_yaxi": 52, "investig": [47, 59], "involv": [65, 66, 69, 78], "io": [55, 77], "ipw_norm": 77, "ipykernel_42441": 49, "ipynb": [32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60], "ira": [36, 53, 54], "irm": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 21, 27, 28, 51, 59, 61, 64, 66, 73, 77, 78], "irm_summari": 53, "irmglmnet": 36, "irmrang": 36, "irmrpart": 36, "irmxgboost8047": 36, "irrespect": 59, "is_classifi": [4, 5, 7, 8, 11], "is_gat": [1, 8, 11], "isnan": [2, 4, 5, 7, 8, 9, 10, 11, 12, 51, 66], "isoton": 59, "isotonicregress": 59, "issn": 47, "issu": [53, 59, 73, 76, 77], "ite": [48, 49, 50], "item": [7, 53, 61, 66, 68], "iter": [32, 45, 52, 60, 66, 70, 72, 78], "itertool": 47, "its": [29, 30, 59, 61, 65, 66, 67, 68, 69, 70], "iv": [7, 10, 11, 20, 22, 23, 33, 35, 41, 52, 62, 63, 64, 71, 73, 77, 78], "iv_2": 32, "iv_var": [35, 52], "iv\u00e1n": [68, 76], "j": [14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 33, 34, 35, 37, 41, 47, 52, 55, 60, 62, 66, 70, 72, 73, 75], "j_": [35, 52], "j_0": 70, "j_1": [35, 52], "j_2": [35, 52], "j_3": [35, 52], "j_k": [35, 52], "jame": 76, "janni": [36, 53], "javanmard": 76, "jbe": [35, 52], "jeconom": [16, 17, 18, 34], "jerzi": 76, "jia": 59, "jmlr": [37, 73, 75, 77], "job": [36, 53, 54], "joint": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 42, 43, 44, 48, 49, 54, 57, 67, 70, 77, 78], "jointli": [57, 65], "joss": [37, 66, 73, 75], "journal": [14, 15, 16, 17, 18, 23, 24, 26, 34, 35, 37, 47, 52, 55, 59, 62, 66, 73, 75, 76, 77], "jss": 73, "jump": 56, "jun": [34, 76], "jupyt": [32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60], "juraj": 76, "just": [34, 37, 44, 45, 46, 48, 49, 50, 56, 57, 69, 71], "justif": [68, 71], "k": [14, 17, 18, 20, 21, 22, 23, 24, 26, 33, 35, 37, 41, 51, 52, 61, 62, 64, 65, 70, 72, 78], "kaggl": [36, 53], "kallu": [44, 54, 57, 58, 69, 76], "kato": [23, 35, 52, 70, 72, 76], "kb": [45, 50, 52, 53, 54, 58, 63, 75], "kde": [9, 12, 13, 53], "kdeplot": [45, 51, 60], "kdeunivari": [9, 12, 13], "kecsk\u00e9sov\u00e1": 77, "keep": [34, 49, 59, 78], "kei": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 36, 42, 43, 48, 49, 52, 53, 54, 59, 66, 69, 71, 77], "keith": 76, "kengo": 76, "kernel": [9, 12, 13], "keyword": [18, 23, 24, 25], "kf": 68, "kfold": [52, 68], "kind": [32, 40, 53], "kj": [17, 18, 20, 21, 22, 23, 24, 26, 33, 35, 41, 52, 62], "klaassen": [20, 59, 73, 76], "klaa\u00dfen": 20, "knau": 76, "know": [45, 56], "knowledg": [32, 40, 51, 55, 56], "known": [50, 51, 59, 66], "kohei": 76, "kotthof": 37, "kotthoff": [37, 66, 73, 75], "krueger": 55, "kueck": [36, 53], "kurz": [73, 76, 77], "kwarg": [16, 17, 18, 23, 24, 25, 29], "l": [35, 37, 38, 42, 43, 52, 59, 60, 66, 71, 73, 75], "l1": [53, 60, 67], "l_hat": [10, 11, 33, 41, 69], "label": [41, 42, 43, 44, 46, 48, 49, 54, 55, 57], "labor": 55, "laffer": 76, "laff\u00e9r": [26, 60, 67, 69], "lal": [55, 77], "lambda": [35, 36, 37, 53, 55, 56, 66, 69, 70, 72, 75], "lambda_": 47, "lambda_0": 69, "lambda_t": 18, "land": 56, "lang": [37, 66, 73, 75], "langl": [19, 56], "lappli": 68, "larg": [33, 41, 50, 51, 55, 59], "larger": [8, 34, 59, 71], "largest": 51, "largli": 51, "lasso": [35, 36, 37, 53, 60, 66, 75, 76], "lasso_class": [36, 53], "lasso_pip": [37, 66], "lasso_summari": 53, "lassocv": [47, 52, 53, 60, 66, 67, 70, 72, 75], "last": [18, 37, 74], "late": [7, 32, 36, 53, 67, 69], "latent": [2, 4, 5, 7, 8, 9, 10, 11, 12, 17, 58, 71], "later": [36, 37, 59, 66, 78], "layout": 47, "lbrace": [7, 8, 20, 21, 26, 35, 52, 61, 67, 68, 70, 72], "ldot": [10, 11, 35, 52, 60, 61, 67, 68, 70, 72, 75], "le": [18, 45, 56, 65, 67, 69], "lead": [34, 59], "leadsto": 70, "lear": [37, 66, 73, 75], "learn": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 23, 24, 25, 26, 32, 36, 37, 38, 40, 44, 47, 51, 53, 54, 55, 57, 59, 63, 64, 66, 68, 69, 70, 71, 72, 77, 78], "learner": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 36, 41, 42, 43, 45, 47, 52, 53, 54, 58, 59, 60, 61, 62, 64, 67, 68, 69, 70, 71, 72, 77, 78], "learner_class": 77, "learner_cv": 37, "learner_forest_classif": 37, "learner_forest_regr": 37, "learner_l": 58, "learner_lasso": 37, "learner_list": 51, "learner_m": 58, "learner_nam": [2, 4, 5, 7, 8, 9, 10, 11, 12, 66], "learner_param_v": 37, "learner_rf": 70, "learnerclassif": 37, "learnerregr": 37, "learnerregrcvglmnet": 37, "learnerregrrang": [37, 66], "learning_r": [41, 44, 54, 57, 59, 62], "least": [32, 36, 40, 53, 54, 58, 68], "leav": [59, 60], "left": [20, 21, 22, 23, 26, 33, 35, 41, 51, 52, 53, 54, 55, 57, 62, 69, 70, 71, 72], "legend": [36, 41, 42, 43, 44, 46, 48, 49, 51, 54, 55, 57], "len": [44, 51, 52, 54, 57], "length": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 37, 45, 66], "leq": [35, 52], "less": [34, 36, 53, 54, 59], "lester": 76, "let": [16, 17, 18, 33, 34, 36, 37, 41, 44, 45, 48, 49, 51, 53, 54, 57, 59, 60, 61, 62, 66, 67, 71, 78], "level": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 36, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 57, 58, 59, 60, 66, 71, 78], "level_0": [37, 52], "level_1": 52, "levinsohn": [35, 52], "lewi": 76, "lgbmclassifi": [44, 45, 46, 51, 54, 57, 59], "lgbmregressor": [41, 44, 45, 46, 51, 54, 59, 62], "lgr": [33, 34, 35, 36, 37, 61, 66, 67, 68, 69, 70, 72, 75], "lib": [52, 53, 59], "liblinear": [53, 60, 67], "librari": [32, 33, 34, 35, 36, 37, 61, 62, 63, 66, 67, 68, 69, 70, 72, 74, 75, 78], "licens": 77, "lie": 76, "lightgbm": [41, 44, 45, 46, 51, 54, 57, 59], "like": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 36, 37, 47, 49, 53, 54, 59, 66, 68, 75, 78], "lim": 55, "limegreen": [42, 43], "limit": [55, 76], "limits_": 65, "lin": 59, "line": [2, 4, 5, 7, 8, 9, 10, 11, 12, 46, 59], "linear": [1, 8, 10, 11, 16, 17, 22, 23, 24, 25, 27, 28, 32, 33, 34, 35, 37, 40, 41, 42, 43, 45, 46, 47, 48, 51, 52, 58, 59, 61, 62, 64, 65, 66, 68, 70, 72, 73, 75, 76, 77, 78], "linear_model": [38, 40, 47, 51, 52, 53, 59, 60, 66, 67, 70, 72, 75], "linearregress": [32, 40, 51, 59], "linearscoremixin": 69, "linestyl": 46, "linewidth": 46, "link": [59, 77], "linspac": [42, 43, 59], "lint": 77, "linux": 74, "list": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 33, 34, 35, 36, 37, 41, 42, 43, 52, 54, 56, 62, 66, 68, 69, 74, 77], "listedcolormap": 52, "literatur": [59, 67], "littl": 50, "ll": [37, 70, 72, 78], "lllllllllllllllll": [63, 75], "lm": [32, 34, 59], "ln_alpha_ml_l": 47, "ln_alpha_ml_m": 47, "load": [32, 34, 36, 37, 47, 53, 54, 63, 74, 75], "loc": [41, 44, 46, 47, 49, 52, 55, 57, 58, 59], "local": [7, 9, 65, 67, 76, 77], "localconvert": 52, "locat": [44, 57], "log": [35, 47, 51, 52, 55, 58, 66, 67], "log_odd": 56, "log_p": [35, 52], "log_reg": [32, 34], "logarithm": 47, "logic": [7, 37, 66], "logical_not": [2, 4, 5, 7, 8, 9, 10, 11, 12, 51, 66], "logist": [16, 32, 34, 36, 40, 53, 59, 60, 78], "logisticregress": [32, 38, 40, 59], "logisticregressioncv": [51, 53, 60, 67], "logit": [51, 55], "loglik": [37, 66], "logloss": [36, 53, 78], "logo": 77, "logspac": 53, "long": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 33, 41, 51, 58, 59, 71, 76], "look": [34, 36, 37, 44, 45, 46, 51, 53, 54, 57, 58], "loss": [51, 58, 66, 67], "loss_ml_g0": 51, "loss_ml_g1": 51, "loss_ml_m": 51, "low": [46, 50, 65, 76], "lower": [36, 37, 44, 46, 47, 50, 54, 55, 57, 58, 59, 66, 71, 78], "lower_bound": [42, 43], "lpq": [9, 13, 54, 65, 77], "lpq_0": 57, "lpq_1": 57, "lqte": 65, "lrn": [32, 33, 34, 35, 36, 37, 61, 66, 67, 68, 69, 70, 72, 75, 78], "lrn_0": 37, "lt": [32, 34, 35, 36, 37, 38, 45, 50, 52, 53, 54, 56, 58, 59, 60, 63, 75], "lucien": 77, "luka": 76, "luk\u00e1\u0161": 26, "lusd": [37, 38, 63, 75], "lvert": 47, "m": [14, 15, 16, 22, 23, 24, 33, 35, 37, 38, 41, 47, 50, 52, 55, 62, 64, 65, 66, 69, 71, 73, 74, 75, 76, 77], "m_": [69, 70, 72], "m_0": [2, 4, 5, 7, 8, 10, 11, 12, 24, 25, 33, 35, 36, 41, 47, 50, 52, 53, 62, 65, 66, 67, 69, 75, 78], "m_hat": [7, 8, 10, 11, 33, 41, 69], "ma": [23, 35, 52, 76], "mac": 74, "machin": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 23, 24, 25, 26, 32, 36, 37, 38, 40, 44, 45, 47, 53, 54, 55, 57, 58, 59, 60, 64, 66, 67, 68, 69, 70, 71, 72, 77, 78], "machineri": [47, 76], "mackei": 76, "maco": 74, "made": [67, 78], "mae": [2, 4, 5, 7, 8, 9, 10, 11, 12, 51, 66], "maggi": 76, "magnitud": 71, "mai": [45, 60], "main": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 47, 54, 59, 70, 71, 72, 76, 78], "mainli": 59, "maintain": [34, 73, 77], "mainten": 77, "major": [37, 59, 77], "make": [32, 40, 51, 59, 65, 66, 77, 78], "make_confounded_irm_data": [59, 77], "make_confounded_plr_data": 58, "make_did_sz2020": [4, 5, 45, 67], "make_heterogeneous_data": [42, 43, 48, 49, 50], "make_iivm_data": [7, 9, 65, 67], "make_irm_data": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 51, 65, 66, 67], "make_pipelin": 53, "make_pliv_chs2015": [10, 67], "make_pliv_multiway_cluster_ckms2021": [3, 35, 52], "make_plr_ccddhnr2018": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 33, 41, 61, 62, 65, 66, 67, 68, 69, 70, 71], "make_spd_matrix": 25, "make_ssm_data": [60, 67], "malt": [73, 76], "maltekurz": 73, "man": [32, 40], "manag": [66, 74], "mani": [22, 27, 28, 33, 34, 35, 37, 41, 45, 52, 62, 69, 70, 72, 78], "manili": 1, "manipul": [36, 37], "manual": [36, 58, 78], "mao": 76, "map": [7, 29, 30, 34, 35, 52, 65, 67], "mapsto": [61, 65], "mar": [26, 67], "margin": [42, 43, 59], "marit": [36, 53], "marker": 59, "markers": 55, "market": 55, "markettwo": 35, "markov": [25, 76], "marr": [36, 53, 54, 58, 78], "marshal": 66, "martin": [26, 59, 73, 76, 77], "masatoshi": 76, "master": 34, "mat": 35, "match": [66, 71], "mathbb": [7, 8, 10, 11, 16, 17, 18, 27, 28, 35, 45, 46, 50, 51, 52, 55, 60, 65, 67, 69, 70, 71, 72, 75, 78], "mathcal": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 35, 41, 44, 46, 52, 56, 57, 60, 62], "mathop": 65, "mathrm": [16, 17], "matplotlib": [38, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 57, 59, 60], "matric": [56, 64, 77], "matrix": [16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 33, 35, 36, 37, 41, 52, 60, 62, 63, 66, 70, 72, 75, 77, 78], "matt": 76, "matter": [51, 55], "max": [36, 37, 53, 54, 61, 65, 66, 67, 68, 69, 70, 75, 78], "max_depth": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 41, 53, 58, 61, 65, 66, 67, 68, 69, 70, 71, 75, 78], "max_featur": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 41, 53, 58, 61, 65, 66, 67, 68, 69, 70, 71, 75, 78], "max_it": [52, 53, 59], "maxim": [2, 4, 5, 7, 8, 9, 10, 11, 12, 56, 65], "maxima": [70, 72], "maximum": [65, 66], "mb": [38, 60, 63, 75], "mb706": 77, "mea": 20, "mean": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 35, 36, 40, 41, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 62, 66, 70, 78], "mean_absolute_error": [2, 4, 5, 7, 8, 9, 10, 11, 12, 51, 66], "meant": [65, 77], "measir": 58, "measur": [34, 37, 47, 58, 59, 66, 67, 71], "measure_col": 47, "measure_func": 34, "measure_pr": 34, "measures_r": 34, "mechan": [29, 30, 59], "median": [59, 68], "melt": 35, "membership": 59, "memori": [38, 45, 50, 52, 53, 54, 58, 60, 63, 75], "mention": [50, 65], "merg": [36, 53], "mert": [68, 76], "meshgrid": [42, 43, 59], "messag": [33, 34, 35, 36, 37, 75, 77], "meta": [66, 75], "metadata": [29, 30], "metadatarequest": [29, 30], "method": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 77], "methodolog": 76, "methodologi": 59, "metric": [2, 4, 5, 7, 8, 9, 10, 11, 12, 66], "michael": 76, "michaela": 77, "michel": [73, 75], "michela": [26, 76], "mid": [36, 53, 55], "might": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 44, 51, 52, 56, 58, 59, 66], "mild": [33, 41, 62], "militari": 55, "miller": [35, 52], "mimic": 59, "min": [35, 36, 37, 44, 52, 53, 54, 57, 61, 66, 67, 68, 69, 70, 72, 75, 78], "min_": 65, "min_samples_leaf": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 41, 50, 53, 58, 61, 65, 66, 67, 68, 69, 70, 71, 78], "min_samples_split": 53, "minim": [8, 36, 51, 53], "minor": [33, 41, 62, 69, 77], "minsplit": 36, "miruna": 76, "mislead": 77, "miss": [3, 6, 37, 66, 67, 69, 77], "missing": [26, 60], "misspecif": 45, "misspecifi": 45, "mit": [73, 75], "mixin": [27, 28, 69], "ml": [25, 35, 36, 37, 47, 52, 53, 61, 64, 66, 68, 73, 76, 77], "ml_g": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 36, 38, 40, 41, 42, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 62, 65, 66, 67, 77], "ml_g0": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 36, 38, 45, 51, 53, 58, 66, 67], "ml_g1": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 36, 38, 45, 51, 53, 58, 66, 67], "ml_g_d0": [60, 67], "ml_g_d0_t0": [45, 67], "ml_g_d0_t1": [45, 67], "ml_g_d1": [60, 67], "ml_g_d1_t0": [45, 67], "ml_g_d1_t1": [45, 67], "ml_l": [10, 11, 33, 35, 36, 37, 38, 41, 43, 49, 52, 53, 55, 58, 61, 62, 66, 67, 68, 69, 70, 71, 72, 75, 77, 78], "ml_l_bonu": 75, "ml_l_forest": 37, "ml_l_forest_pip": 37, "ml_l_lasso": 37, "ml_l_lasso_pip": 37, "ml_l_rf": 78, "ml_l_sim": 75, "ml_l_tune": 66, "ml_l_xgb": 78, "ml_m": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 72, 75, 77, 78], "ml_m_bench_control": 59, "ml_m_bench_treat": 59, "ml_m_bonu": 75, "ml_m_forest": 37, "ml_m_forest_pip": 37, "ml_m_lasso": 37, "ml_m_lasso_pip": 37, "ml_m_rf": 78, "ml_m_sim": 75, "ml_m_tune": 66, "ml_m_xgb": 78, "ml_pi": [60, 67], "ml_r": [7, 10, 32, 35, 36, 40, 52, 53, 67, 77], "ml_r0": 67, "ml_r1": [36, 53, 67], "mlr": [37, 66], "mlr3": [32, 33, 34, 35, 36, 61, 66, 67, 68, 69, 70, 72, 73, 75, 77, 78], "mlr3book": [37, 66], "mlr3extralearn": [36, 66], "mlr3filter": 37, "mlr3learner": [32, 33, 34, 35, 36, 61, 66, 67, 68, 69, 70, 72, 75, 78], "mlr3measur": 34, "mlr3pipelin": [66, 77], "mlr3tune": [37, 66, 77], "mlr3vers": 36, "mlrmeasur": 34, "mode": [59, 74], "model": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 37, 40, 41, 44, 45, 46, 47, 50, 51, 52, 54, 57, 58, 61, 62, 63, 64, 66, 72, 73, 76, 77], "model_data": [36, 53], "model_select": [2, 4, 5, 7, 8, 9, 10, 11, 12, 41, 52, 66, 68], "modelmlestimatelowerupp": 36, "modern": [37, 66, 73, 75], "moment": [27, 28, 35, 52, 69, 70, 71, 72, 75], "monoton": 67, "mont": [16, 17, 19, 42, 43, 48, 49], "montanari": 76, "more": [8, 32, 34, 36, 40, 42, 43, 47, 51, 53, 54, 58, 59, 61, 65, 66, 67, 69, 70, 71, 75, 78], "moreov": [36, 37, 47, 66, 70, 72, 78], "mortgag": [36, 53, 54], "most": [36, 44, 51, 53, 54, 57, 59, 65, 66, 71, 74], "motiv": [59, 62], "motivation_example_bch": 47, "mp": 34, "mpd": [35, 52], "mpg": 52, "mse": [37, 47, 66], "msr": [37, 66], "mtry": [36, 37, 61, 66, 67, 68, 69, 70, 78], "mu": 46, "mu_": 46, "mu_mean": 46, "much": [36, 37, 53, 59, 78], "muld": [38, 63, 75], "multi": [34, 35, 42, 43, 52], "multiclass": 37, "multiindex": 52, "multipl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 45, 52, 53, 58, 59, 60, 63, 66, 67, 68, 70, 71, 72, 77, 78], "multipletest": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "multipli": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 41, 64, 65, 69, 78], "multiprocess": [44, 54, 57], "multitest": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "multiwai": [23, 35, 52, 76], "music": 76, "must": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 66, 67], "mutat": 37, "mutual": [8, 11, 36, 48, 49, 53, 54, 65], "my_sampl": 68, "my_task": 68, "n": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 32, 33, 35, 37, 40, 41, 44, 46, 47, 50, 52, 55, 56, 57, 60, 61, 62, 65, 66, 68, 70, 72, 73, 74], "n_": 46, "n_coef": [2, 4, 5, 7, 8, 9, 10, 11, 12, 71], "n_complier": 57, "n_core": [44, 54, 57], "n_estim": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 41, 42, 43, 44, 45, 46, 48, 49, 50, 53, 54, 56, 57, 58, 59, 61, 62, 65, 66, 67, 68, 69, 70, 71, 75, 78], "n_eval": [37, 66], "n_fold": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 66, 68, 75, 78], "n_folds_per_clust": [35, 52], "n_folds_tun": [2, 4, 5, 7, 8, 9, 10, 11, 12], "n_iter_randomized_search": [2, 4, 5, 7, 8, 9, 10, 11, 12, 66], "n_job": 53, "n_jobs_cv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 51], "n_jobs_model": [13, 44, 54, 57], "n_ob": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 33, 37, 41, 42, 43, 45, 46, 48, 49, 50, 51, 58, 59, 60, 62, 63, 65, 66, 67, 68, 70, 71, 72, 75], "n_rep": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 34, 35, 38, 41, 45, 50, 51, 52, 58, 59, 60, 62, 66, 68, 71, 75, 78], "n_rep_boot": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 42, 43, 44, 48, 49, 54, 57, 70, 72], "n_sampl": 56, "n_split": 68, "n_t": 46, "n_time_period": 46, "n_true": [44, 57], "n_var": [33, 37, 41, 62, 63, 66, 70, 72, 75], "n_w": 56, "n_x": [19, 42, 43, 48, 49, 50], "na": [3, 6, 33, 35, 62, 77], "na_real_": [35, 77], "naiv": [33, 41, 62], "name": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 33, 34, 35, 48, 49, 50, 52, 58, 59, 66, 74, 77], "namespac": 34, "nan": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 41, 44, 45, 46, 48, 49, 51, 53, 54, 57, 60, 62, 66], "nanmean": 41, "narita": 76, "nathan": 76, "nation": [59, 68, 76], "nativ": 34, "natt": 56, "natur": 59, "ncol": [35, 36, 37, 63, 66, 70, 72, 75], "ncoverag": 51, "ndarrai": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 20, 21, 22, 23, 24, 25, 26, 63], "nearli": 51, "necess": [35, 52], "necessari": [34, 35, 52], "need": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 28, 32, 33, 34, 36, 40, 41, 54, 60, 66, 68, 71, 77, 78], "neighborhood": 70, "neither": [3, 6, 35, 52, 63], "neng": 76, "neq": 67, "nest": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 66, 69, 71], "net": [54, 58, 78], "net_tfa": [36, 53, 54, 58, 78], "never": [7, 34, 35, 49, 52, 77], "never_tak": [7, 36, 53], "new": [32, 33, 34, 35, 36, 37, 42, 43, 53, 56, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76, 77, 78], "new_data": [42, 43, 56], "newei": [14, 15, 24, 35, 47, 52, 59, 62, 73, 76], "newest": 77, "next": [34, 36, 37, 42, 43, 44, 50, 51, 53, 54, 56, 57, 59, 77], "neyman": [35, 52, 61, 64, 71, 73, 76], "nfold": [35, 36], "nice": 34, "nifa": [53, 54, 58], "nil": 59, "nine": [35, 52], "node": [36, 37, 61, 67, 68, 69, 70, 75, 78], "nois": [55, 56], "non": [18, 23, 24, 25, 32, 33, 36, 40, 41, 46, 53, 54, 56, 66, 68, 69, 70], "non_orth_scor": [33, 41, 69], "nondur": 38, "none": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 35, 36, 38, 40, 45, 50, 53, 54, 58, 59, 60, 63, 66, 67, 69, 70, 74, 75], "nonlinear": [28, 36, 53, 69, 77], "nonlinearscoremixin": 69, "nonparametr": [9, 12, 13, 59, 71, 76], "nop": 37, "nor": [3, 6, 35, 52, 63], "norm": 41, "normal": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 33, 40, 41, 44, 45, 46, 50, 54, 55, 56, 57, 60, 62, 63, 66, 69, 70, 72, 75], "normalize_ipw": [2, 7, 8, 9, 12, 13, 54, 60], "notat": [35, 45, 52, 60, 67], "note": [3, 6, 7, 8, 10, 11, 27, 28, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 68, 69, 73, 75], "notebook": [32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 65, 66, 78], "notic": [32, 40], "now": [34, 35, 36, 42, 43, 51, 52, 53, 56, 59, 60, 75, 77], "np": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 20, 21, 22, 23, 24, 25, 26, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 78], "nround": [33, 36, 78], "nrow": [34, 35, 37, 63, 66, 70, 72, 75], "nu": [7, 18, 25, 60, 67, 71], "nu2": 71, "nu_0": 71, "nu_i": 60, "nuis_g0": 32, "nuis_g1": 32, "nuis_l": 78, "nuis_m": [32, 78], "nuis_r0": 32, "nuis_r1": 32, "nuis_rmse_ml_l": 47, "nuis_rmse_ml_m": 47, "nuisanc": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 24, 25, 33, 34, 35, 36, 37, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 66, 68, 69, 70, 71, 73, 77, 78], "nuisance_el": 71, "nuisance_loss": [51, 66, 77], "nuisance_target": 51, "null": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 58, 66, 71, 77], "null_hypothesi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 58, 71], "num": [36, 37, 61, 66, 67, 68, 69, 70, 75], "num_leav": [44, 46, 54, 57], "number": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 35, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 54, 56, 57, 59, 68, 70, 72, 73, 75, 78], "numer": [28, 32, 37, 55, 66, 69, 71, 77], "numeric_onli": 47, "numpi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75], "ny": 76, "o": [46, 48, 49, 53, 55, 70, 73, 75], "ob": [34, 36, 46], "obei": 69, "obj_dml_data": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 35, 40, 41, 44, 52, 57, 61, 62, 65, 66, 67, 68, 69, 70, 71, 77], "obj_dml_data_bonu": 63, "obj_dml_data_bonus_df": 63, "obj_dml_data_from_arrai": [3, 6], "obj_dml_data_from_df": [3, 6], "obj_dml_data_sim": 63, "obj_dml_plr": [33, 41, 62], "obj_dml_plr_bonu": [37, 75], "obj_dml_plr_bonus_pip": 37, "obj_dml_plr_bonus_pipe2": 37, "obj_dml_plr_bonus_pipe3": 37, "obj_dml_plr_bonus_pipe_ensembl": 37, "obj_dml_plr_nonorth": [33, 41], "obj_dml_plr_orth_nosplit": [33, 41], "obj_dml_plr_sim": [37, 75], "obj_dml_plr_sim_pip": 37, "obj_dml_plr_sim_pipe_ensembl": 37, "obj_dml_plr_sim_pipe_tun": 37, "object": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30, 32, 36, 37, 38, 42, 43, 44, 45, 49, 50, 53, 54, 57, 60, 63, 65, 66, 67, 68, 69, 70, 73, 75, 76, 77, 78], "obs_confound": [32, 40], "observ": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 75, 76, 78], "obtain": [17, 32, 33, 34, 35, 40, 41, 42, 43, 44, 45, 47, 51, 52, 57, 59, 60, 61, 62, 65, 66, 68, 69, 70, 71, 72, 74, 75], "occur": 77, "off": [56, 76], "offer": [34, 36, 53, 54, 59, 78], "offici": 74, "often": 57, "oka": 76, "omega": [50, 65, 71], "omega_": [23, 35, 52], "omega_1": [23, 35, 52], "omega_2": [23, 35, 52], "omega_epsilon": [35, 52], "omega_v": [23, 35, 52], "omega_x": [23, 35, 52], "omit": [58, 59, 71, 76, 77, 78], "ommit": 59, "onc": [34, 59, 78], "one": [10, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 51, 52, 54, 55, 58, 59, 62, 65, 66, 67, 68, 69, 70, 71, 72, 75, 77], "ones": [37, 44, 46, 57, 58, 65], "ones_lik": 57, "onli": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 42, 43, 48, 49, 50, 51, 52, 53, 54, 61, 65, 66, 67, 69, 70, 71, 77], "onlin": 78, "onto": 51, "oob_error": [37, 66], "oop": 77, "opac": [42, 43], "open": [37, 66, 73, 75], "oper": 37, "opposit": 56, "oprescu": [19, 42, 43, 48, 49, 76], "opt": [53, 59], "optim": [2, 4, 5, 7, 8, 9, 10, 11, 12, 37, 42, 43, 56, 65, 66, 76], "option": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 35, 36, 42, 43, 48, 49, 50, 51, 52, 53, 54, 60, 66, 68, 69, 70, 72, 77], "oracle_valu": [16, 17], "orang": 33, "orcal": [16, 17], "order": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 36, 37, 52, 53, 66, 68, 69], "org": [20, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 66, 73, 74, 77], "orient": [37, 66, 69, 73, 75, 76, 77], "origin": [34, 37, 49, 56, 58, 59, 65], "orign": [36, 53], "orth_sign": 1, "orthogon": [1, 35, 36, 52, 53, 61, 64, 70, 71, 72, 73, 76], "orthongon": 71, "osx": 74, "other": [3, 6, 10, 11, 33, 35, 36, 37, 41, 45, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 70, 71, 73, 74, 75, 76, 77, 78], "other_ind": 52, "otherwis": [4, 5, 7, 8, 11, 36, 53, 54, 56, 67], "othrac": [37, 38, 63, 75], "our": [33, 34, 36, 37, 41, 42, 43, 44, 45, 51, 53, 54, 57, 58, 59, 62, 73, 75, 77, 78], "ourselv": 51, "out": [10, 11, 35, 37, 38, 45, 47, 51, 52, 54, 58, 59, 60, 61, 63, 64, 65, 66, 67, 69, 70, 71, 73, 75, 77, 78], "outcom": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 18, 32, 34, 35, 36, 37, 38, 40, 46, 47, 50, 52, 53, 54, 55, 56, 57, 58, 59, 63, 66, 67, 69, 70, 71, 75, 77, 78], "outcome_0": 40, "outcome_1": 40, "outer": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 66], "output": [34, 51, 61, 70, 72, 78], "outshr": 52, "outsid": 33, "over": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 41, 47, 51, 62, 64, 66, 71, 72], "overal": [56, 59], "overcom": [64, 69], "overfit": [64, 68], "overlap": [45, 59, 67], "overrid": [66, 77], "overst": [36, 53, 54], "overview": [51, 70, 71, 76], "overwrit": 77, "ownership": [36, 53], "p": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 21, 33, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77], "p401": [36, 53, 54], "p_0": 69, "p_1": [70, 72], "p_adjust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 68, 70, 72, 73, 75], "p_dbl": [37, 66], "p_int": 66, "p_n": 22, "p_val": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "p_x": [23, 35, 52], "p_x0": 55, "p_x1": 55, "packag": [32, 33, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 54, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 78], "packagedata": 52, "packagevers": 36, "page": [59, 73, 76], "pair": [32, 40], "pake": [35, 52], "paket": [35, 36, 37], "pal": 35, "panda": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 38, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 65, 71, 75], "pandas2ri": 52, "panel": [4, 18, 76, 77], "paper": [20, 22, 37, 55, 58, 59, 71, 73, 75, 76, 77], "par": 38, "par_grid": [37, 66], "paradox": [37, 66, 77], "parallel": [34, 44, 45, 46, 51, 57, 67], "param": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 66], "param_grid": [2, 4, 5, 7, 8, 9, 10, 11, 12, 66], "param_nam": 34, "param_set": [37, 66], "param_v": 37, "paramet": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78], "parametr": [34, 59, 62, 66, 78], "params_exact": 66, "params_nam": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34], "parenttoc": 73, "part": [25, 33, 35, 36, 37, 41, 51, 52, 53, 62, 66, 68, 71, 77, 78], "parti": 25, "partial": [10, 11, 17, 22, 23, 24, 25, 28, 35, 37, 38, 47, 52, 58, 61, 64, 66, 68, 70, 72, 73, 75, 77, 78], "partial_": [69, 70], "partiallli": 58, "particip": [14, 54, 58, 78], "particular": 73, "partion": [35, 52], "partit": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 52, 61, 64], "partli": 78, "pass": [1, 34, 37, 66, 78], "passo": [73, 75], "past": 35, "paste0": 35, "pastel": 41, "path": [66, 67], "path_to_r": 47, "patsi": [42, 43, 65], "pattern": 59, "paul": 76, "pd": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 65], "pdf": [41, 55], "pedregosa": [73, 75], "pedregosa11a": [73, 75], "pedro": [34, 76], "penal": 60, "penalti": [36, 37, 40, 53, 59, 60, 66, 67], "pennsylvania": [15, 63, 75], "pension": [36, 53, 54, 78], "peopl": [36, 53, 54], "pep8": 77, "per": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 52], "percent": 66, "percentag": [2, 4, 5, 7, 8, 9, 10, 11, 12, 17], "perf_count": 51, "perform": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 35, 37, 41, 45, 47, 49, 50, 51, 52, 54, 58, 59, 60, 62, 66, 67, 68, 69, 70, 72, 73, 75, 76, 78], "perfrom": 50, "perhap": 78, "period": [4, 34, 45, 46, 67], "perp": 67, "perrot": [73, 75], "person": 78, "pessimist": 59, "peter": 76, "pfister": [37, 66, 73, 75], "phi": [35, 52, 65, 70], "philipp": [59, 73, 76], "philippbach": [73, 77], "pi": [21, 22, 25, 65, 67, 69], "pi_": [23, 35, 52], "pi_0": 69, "pi_i": [60, 67], "pick": 78, "pip3": 74, "pipe": 37, "pipe_forest_classif": 37, "pipe_forest_regr": 37, "pipe_lasso": 37, "pipelin": [37, 53, 77], "pipeop": 37, "pira": [36, 53, 54, 58, 78], "pivot": [47, 52, 76], "plai": 78, "plan": [14, 36, 53, 54, 78], "plausibl": 59, "pleas": [29, 30, 34, 59, 68], "plim": 55, "pliv": [10, 27, 28, 35, 52, 61, 64, 65, 73, 77], "plm": [66, 70, 71, 78], "plot": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 34, 36, 37, 41, 42, 43, 44, 46, 47, 48, 49, 50, 53, 54, 55, 57, 58, 59, 60, 65, 71], "plot_tre": [56, 65], "plotli": [2, 4, 5, 7, 8, 9, 10, 11, 12, 42, 43, 47, 59], "plr": [11, 27, 28, 37, 55, 58, 61, 64, 66, 68, 70, 72, 73, 75, 77, 78], "plr_est": 55, "plr_est1": 55, "plr_est2": 55, "plr_obj": 55, "plr_obj_1": 55, "plr_obj_2": 55, "plr_summari": 53, "plrglmnet": 36, "plrranger": 36, "plrrpart": 36, "plrxgboost8700": 36, "plt": [38, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 57, 59, 60], "plt_smpl": [35, 52], "plt_smpls_cluster": [35, 52], "plug": [50, 71], "pm": [35, 52, 70, 71, 72], "pmatrix": 60, "po": [37, 66], "point": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 48, 49, 52, 59, 65, 78], "pointwis": [1, 44, 48, 49, 57], "poli": [36, 52, 53], "polici": [8, 10, 11, 64, 67, 75, 76, 77], "policy_tre": [8, 56, 65], "policy_tree_2": 56, "policy_tree_obj": 65, "policytre": 56, "polit": 55, "poly_dict": 53, "polynomi": [14, 15, 36, 38, 53], "polynomial_featur": [14, 15, 36, 38], "polynomialfeatur": [52, 53], "popul": [59, 69], "popular": [51, 71], "porport": 58, "posit": [25, 36, 55, 59, 78], "posixct": [37, 66], "possibl": [3, 6, 34, 37, 42, 43, 48, 49, 50, 51, 56, 58, 59, 66, 70, 71, 77, 78], "possibli": 71, "post": [22, 25, 67, 70, 72, 76], "postdoubl": 76, "poster": 55, "potenti": [2, 9, 12, 16, 45, 55, 60, 67, 70, 74, 77, 78], "power": [37, 59, 66, 76], "pp": 34, "pq": [9, 12, 13, 54, 77], "pq_0": [54, 57], "pq_1": [54, 57], "pr": [32, 35, 36, 37, 66, 67, 68, 69, 70, 75, 78], "practic": [51, 59, 76], "pre": [34, 45, 60, 66, 67], "precis": [34, 71, 78], "pred": 34, "pred_df": 56, "pred_dict": 66, "pred_treat": 56, "predict": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 29, 30, 33, 35, 36, 37, 41, 44, 47, 51, 52, 53, 56, 59, 62, 65, 68, 71, 77, 78], "predict_proba": [2, 4, 5, 7, 8, 9, 11, 12, 13, 29, 66], "predictor": [1, 8, 11, 42, 43, 48, 49, 59, 61], "prefer": [36, 53, 54, 78], "preliminari": [2, 33, 41, 69], "prepar": [34, 35, 52, 77], "preprint": 76, "preprocess": [36, 52, 53, 54, 66], "presenc": [36, 53, 54], "present": [34, 59, 66, 78], "prespecifi": 58, "pretest": 34, "pretreat": [4, 5, 34, 45], "prettenhof": [73, 75], "preval": 59, "prevent": [68, 77], "previou": [46, 50, 55, 74, 78], "previous": [66, 78], "price": [35, 52], "priliminari": [9, 13], "principl": 71, "print": [33, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 78], "print_detail": 34, "prior": [51, 67], "privat": 77, "prob": 37, "probabilit": 50, "probabl": [2, 7, 8, 9, 12, 13, 18, 33, 34, 41, 45, 50, 55, 57, 59, 60, 62, 67, 69, 76], "problem": [36, 53, 54, 65, 66], "procedur": [33, 35, 36, 41, 51, 52, 53, 58, 59, 66, 70, 72, 77], "proceed": [22, 76], "process": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 34, 42, 43, 44, 45, 46, 47, 48, 49, 51, 56, 57, 59, 60, 64, 70, 71, 72, 76, 77], "produc": 55, "product": [42, 43, 47, 51, 59, 71], "producton": 35, "program": [21, 36, 53, 54, 76, 78], "progress": 39, "project": [37, 42, 43, 65, 73, 77], "project_z": [42, 43], "prone": 69, "propens": [9, 13, 16, 17, 36, 45, 50, 51, 53, 54, 59, 60, 65], "properli": 78, "properti": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 37, 51, 53, 54, 55, 58, 66, 71, 75, 77], "proport": [58, 71], "propos": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 37, 52, 71, 76], "provid": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 37, 42, 43, 48, 49, 52, 53, 59, 61, 62, 63, 64, 66, 70, 72, 73, 75, 77, 78], "prune": 8, "ps911c": 52, "ps944": 52, "pscore1": 55, "pscore2": 55, "psi": [27, 28, 33, 34, 35, 52, 61, 69, 70, 71, 75], "psi_": [70, 71, 72], "psi_a": [7, 8, 10, 11, 27, 33, 35, 41, 52, 68, 69, 70], "psi_b": [7, 8, 10, 11, 27, 33, 41, 65, 68, 69], "psi_el": [68, 69], "psi_j": [70, 72], "psi_nu2": 71, "psi_sigma2": 71, "public": [32, 40, 77], "publish": [59, 77], "pull": [36, 77], "purchas": 59, "pure": 59, "purp": [42, 43], "purpos": [33, 41, 50, 58, 59, 71, 75], "pval": [70, 72], "px": 47, "py": [49, 52, 53, 59, 73, 74, 77], "py3": 74, "py_al": 41, "py_dml": 41, "py_dml_nosplit": 41, "py_dml_po": 41, "py_dml_po_nosplit": 41, "py_double_ml_bas": 41, "py_double_ml_basic_iv": 40, "py_double_ml_c": 42, "py_double_ml_cate_plr": 43, "py_double_ml_cvar": 44, "py_double_ml_did": 45, "py_double_ml_did_pretest": 46, "py_double_ml_firststag": 47, "py_double_ml_g": 48, "py_double_ml_gate_plr": 49, "py_double_ml_gate_sensit": 50, "py_double_ml_learn": 51, "py_double_ml_multiway_clust": 52, "py_double_ml_pens": 53, "py_double_ml_pension_qt": 54, "py_double_ml_plm_irm_hetfx": 55, "py_double_ml_policy_tre": 56, "py_double_ml_pq": 57, "py_double_ml_sensit": 58, "py_double_ml_sensitivity_book": 59, "py_double_ml_ssm": 60, "py_non_orthogon": 41, "py_po_al": 41, "pydata": 49, "pypi": [76, 77], "pyplot": [38, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 57, 59, 60], "python": [25, 34, 59, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78], "python3": [53, 59, 74], "q": [37, 44, 57, 66, 73, 75], "q2": [37, 38, 63, 75], "q3": [37, 38, 63, 75], "q4": [37, 38, 63, 75], "q5": [37, 38, 63, 75], "q6": [37, 38, 63, 75], "qquad": 21, "qte": [44, 54, 77], "quad": [18, 36, 45, 53, 56, 60, 65, 67, 69, 70, 71, 72], "quadrat": 60, "qualiti": [58, 61, 77], "quanitl": 54, "quant": 44, "quantifi": 59, "quantil": [2, 9, 12, 13, 44, 58, 64, 76, 77], "quantiti": [32, 40, 59], "queri": 53, "question": [59, 78], "quick": 54, "quit": [51, 56, 58, 71], "r": [7, 20, 41, 42, 43, 46, 47, 52, 55, 59, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78], "r2_d": [21, 51], "r2_y": [21, 51], "r6": [37, 77], "r_0": [7, 10, 36, 53, 67], "r_all": 33, "r_d": 21, "r_df": 52, "r_dml": 33, "r_dml_nosplit": 33, "r_dml_po": 33, "r_dml_po_nosplit": 33, "r_double_ml_bas": 33, "r_double_ml_basic_iv": 32, "r_double_ml_did": 34, "r_double_ml_multiway_clust": 35, "r_double_ml_pens": 36, "r_double_ml_pipelin": 37, "r_hat": 10, "r_hat0": 7, "r_hat1": 7, "r_non_orthogon": 33, "r_po_al": 33, "r_y": 21, "rais": [3, 6, 29, 30, 66], "randint": 55, "random": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 19, 25, 26, 32, 33, 34, 36, 37, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 65, 66, 68, 70, 71, 72, 75, 76, 78], "random_search": 66, "random_st": [41, 50, 56], "randomforest": [36, 51, 53], "randomforest_class": [36, 42, 53, 56], "randomforest_reg": [42, 56], "randomforestclassifi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 42, 43, 48, 49, 50, 51, 53, 56, 58, 59, 65, 66, 67, 78], "randomforestregressor": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 41, 42, 43, 48, 49, 50, 51, 53, 56, 58, 59, 61, 65, 66, 67, 68, 69, 70, 71, 75, 78], "randomized_search": [2, 4, 5, 7, 8, 9, 10, 11, 12, 66], "randomizedsearchcv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 66], "randomli": [33, 35, 41, 52, 62, 68, 78], "rang": [33, 41, 44, 45, 46, 48, 49, 51, 52, 54, 56, 57, 59, 60, 62, 66], "rangeindex": [38, 45, 50, 52, 53, 54, 58, 60, 63, 75], "ranger": [34, 36, 37, 61, 66, 67, 68, 69, 70, 75, 78], "rangl": [19, 56], "rank": 77, "rate": [47, 51], "rather": 59, "ratio": [66, 68, 71], "ravel": [42, 43], "raw": [36, 47, 53], "raw_res_manual_lasso_r_100_n_100_p_200_rho_0": 47, "rbind": 36, "rbindlist": 36, "rbinom": 32, "rbrace": [7, 8, 20, 21, 26, 35, 52, 61, 67, 68, 70, 72], "rcolorbrew": 35, "rcparam": [38, 42, 43, 44, 46, 48, 49, 52, 53, 54, 57], "rd": 77, "rdbu": 35, "rdbu_r": 52, "rdt044": 47, "re": [52, 59, 74], "read_csv": 47, "readabl": 77, "readili": 73, "real": [36, 53, 54, 58, 71], "realat": 67, "realiz": 67, "reason": [3, 6, 32, 40, 58, 59, 71, 78], "recal": [38, 71], "receiv": 67, "recent": 67, "recogn": [36, 53, 54], "recommend": [37, 51, 59, 61, 68, 74, 76, 77], "recov": [32, 34, 40, 55], "recsi": 76, "red": [35, 48, 49, 52], "reduc": [36, 50, 53, 58, 59, 77], "redund": 77, "reemploy": [15, 63, 75], "refactor": 77, "refer": [2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 36, 46, 50, 53, 54, 58, 63, 64, 65, 67, 71, 76, 77], "refin": 77, "refit": 71, "reflect": [56, 59, 65], "reg": [18, 36, 53, 78], "reg_learn": 54, "reg_learner_1": 51, "reg_learner_2": 51, "regard": [59, 73], "regener": 77, "region": [35, 44, 52, 70, 72, 76], "regr": [32, 33, 34, 35, 36, 37, 61, 66, 67, 68, 69, 70, 72, 75, 78], "regravg": [37, 66], "regress": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 20, 21, 22, 23, 24, 25, 32, 34, 35, 37, 40, 47, 52, 55, 58, 59, 60, 61, 62, 64, 65, 66, 68, 70, 72, 73, 75, 76, 77, 78], "regressor": [30, 33, 36, 41, 44, 51, 53, 62], "regular": [22, 64, 66, 69, 70, 72, 76], "reich": [37, 66], "reinforc": 76, "reject": [36, 53], "rel": [36, 53, 71], "relat": [59, 78], "relationship": [32, 40, 47, 59, 70, 72], "releas": 53, "relev": [1, 3, 4, 5, 6, 19, 44, 56, 57, 71, 78], "reli": [42, 43, 45, 46, 50, 65, 66, 67, 71, 78], "reload": 36, "remain": [34, 70, 72, 78], "remark": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 41, 42, 43, 44, 46, 48, 49, 50, 51, 54, 58, 65, 66, 67, 69, 70, 71], "remot": 74, "remov": [36, 53, 59, 64, 68, 77], "renam": [53, 77], "render": [58, 59], "reorgan": 77, "rep": [33, 62, 66, 70, 72], "repeat": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 35, 36, 37, 41, 50, 52, 53, 54, 55, 58, 60, 62, 64, 66, 70, 75, 77, 78], "repeatedkfold": 52, "repet": 58, "repetit": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 42, 43, 47, 48, 49, 50, 51, 64, 66, 70, 75, 78], "repetiton": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "replac": [56, 59, 77], "replic": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 33, 36, 41, 47, 59], "repo": 77, "report": [36, 53, 73, 77], "repositori": [47, 77], "repr": [33, 35], "repres": [55, 59], "represent": [2, 4, 5, 7, 8, 9, 10, 11, 12, 17, 58, 70, 71, 75, 77], "request": 77, "requir": [10, 11, 32, 36, 37, 50, 53, 54, 58, 67, 70, 71, 72, 74, 77, 78], "requirenamespac": 34, "res_df": 52, "res_dict": [16, 17, 19], "resampl": [32, 35, 37, 45, 52, 54, 58, 60, 66, 67, 68, 69, 70, 73, 75, 78], "research": [35, 37, 52, 55, 59, 68, 73, 75, 76, 78], "resembl": 60, "reset": 34, "reset_index": [47, 52, 53], "reshap": [41, 42, 43, 46], "reshape2": 35, "residu": [2, 4, 5, 7, 8, 9, 10, 11, 12, 17, 58, 71], "resolut": [37, 66], "resourc": 51, "resourcewis": 51, "respect": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 53, 54, 65, 67, 68, 71, 78], "respons": [14, 37, 66], "restart": 74, "restrict": 51, "restructur": 77, "restud": 47, "result": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 33, 34, 37, 41, 42, 43, 45, 46, 47, 50, 51, 56, 58, 59, 60, 62, 66, 68, 69, 71, 75, 77], "result_iivm": 36, "result_irm": 36, "result_plr": 36, "retina": 55, "retir": [36, 53, 54, 58], "return": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 33, 34, 35, 37, 41, 44, 49, 51, 52, 55, 56, 57, 58, 59, 60, 61, 66, 69, 71, 77], "return_count": 51, "return_tune_r": [2, 4, 5, 7, 8, 9, 10, 11, 12], "return_typ": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 33, 36, 37, 41, 45, 51, 53, 54, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 75, 78], "rev": 35, "reveal": 50, "review": [22, 47, 76], "revist": [35, 52], "rho": [2, 4, 5, 7, 8, 9, 10, 11, 12, 31, 50, 58, 59, 71, 78], "rho_val": 59, "richter": [37, 66, 73, 75], "riesz": [2, 4, 5, 7, 8, 9, 10, 11, 12, 17, 58, 71], "right": [20, 21, 22, 23, 26, 33, 35, 41, 51, 52, 53, 54, 55, 57, 59, 62, 69, 70, 71, 72], "rightarrow_": [33, 41, 62], "risk": [2, 64, 77], "ritov": 76, "rival": 52, "rival_ind": 52, "rmd": 34, "rmse": [34, 45, 51, 54, 58, 60, 66, 67, 69, 70, 75, 77], "rnorm": [32, 37, 63, 66, 70, 72, 75], "robin": [14, 15, 24, 35, 47, 52, 62, 73, 76], "robinson": [33, 41, 62], "robject": 52, "robu": [48, 49], "robust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 23, 34, 50, 58, 59, 71, 76, 78], "role": [3, 6, 33, 41, 62, 78], "romano": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 70, 72], "root": [2, 4, 5, 7, 8, 9, 10, 11, 12, 28, 47, 62, 66, 69, 76], "roth": 67, "rough": [59, 78], "roughli": 59, "round": [36, 51, 55, 59], "rout": [29, 30], "row": [33, 36, 38, 42, 43, 46, 52, 56, 63, 68, 75, 78], "row_index": 49, "rownam": 35, "rowv": 35, "roxygen2": 77, "royal": [59, 76], "rpart": [36, 37, 66], "rpart_cv": 37, "rprocess": 51, "rpy2": 52, "rpy2pi": 52, "rsmp": [37, 66, 68], "rsmp_tune": [37, 66], "rssb": 59, "rtype": [2, 4, 5, 7, 8, 9, 10, 11, 12], "ruben": 76, "ruiz": [32, 40], "rule": [34, 65], "run": [34, 74, 77], "runif": 32, "runtime_learn": 37, "rv": [50, 58, 59, 71, 78], "rva": [50, 58, 59, 71, 78], "rvert": 47, "rvert_": 47, "s_": [23, 35, 52, 67], "s_1": 24, "s_2": 24, "s_col": [3, 6, 60, 67], "s_i": [26, 60, 67], "s_x": [23, 35, 52], "safeguard": [45, 66], "sake": [36, 53, 59, 78], "same": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 35, 41, 42, 43, 50, 51, 52, 54, 56, 58, 59, 60, 66, 69, 70, 71, 77], "samii": 55, "sampl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 23, 26, 32, 34, 35, 37, 40, 45, 48, 49, 51, 52, 54, 56, 58, 64, 66, 69, 70, 72, 75, 76, 77], "sant": [4, 5, 16, 17, 18, 34, 45, 67, 76], "sara": 76, "sasaki": [23, 35, 52, 76], "satisfi": [60, 66, 69, 70], "save": [33, 36, 41, 48, 49, 51, 53, 54, 66, 71, 78], "savefig": 41, "saveguard": 51, "saver": [36, 53, 54], "scalar": 67, "scale": [33, 35, 44, 46, 55, 57, 59, 70, 71], "scale_color_manu": 33, "scale_fill_manu": [33, 35], "scatter": [46, 48, 49, 55, 59], "scenario": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 58, 59, 71, 78], "scene": [42, 43, 47], "scene_camera": 47, "schaefer": 55, "schedul": 77, "scheme": [35, 52, 66, 68, 73], "schneider": 37, "schratz": [37, 66, 73, 75], "scienc": [25, 32, 40, 55, 76], "scikit": [51, 53, 66, 73, 75, 77, 78], "scipi": 41, "score": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 27, 28, 32, 34, 35, 36, 37, 38, 42, 43, 44, 45, 47, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 70, 71, 73, 77, 78], "scoring_method": [2, 4, 5, 7, 8, 9, 10, 11, 12], "script": 74, "sd": 32, "se": [33, 35, 41, 58, 62, 66, 68, 70, 71, 76, 78], "se_df": 35, "se_dml": [33, 41, 62], "se_dml_po": [33, 41, 62], "se_nonorth": [33, 41], "se_orth_nosplit": [33, 41], "se_orth_po_nosplit": [33, 41], "seaborn": [38, 41, 45, 51, 52, 53, 54, 59, 60], "search": [2, 4, 5, 7, 8, 9, 10, 11, 12, 28, 66, 69], "search_mod": [2, 4, 5, 7, 8, 9, 10, 11, 12, 66], "searchabl": 36, "second": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 23, 33, 35, 37, 41, 51, 52, 61, 62, 68, 70, 71, 72, 75], "section": [5, 18, 34, 35, 36, 37, 50, 52, 54, 59, 77], "secur": 55, "see": [2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 21, 26, 27, 28, 32, 34, 35, 36, 37, 40, 42, 43, 45, 49, 52, 54, 55, 56, 58, 59, 66, 67, 68, 69, 71, 74, 75, 77], "seed": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 78], "seek": 55, "seem": [34, 36, 50, 53, 54, 78], "seen": [48, 49], "sel_cols_chiang": 52, "select": [3, 6, 22, 26, 47, 51, 59, 61, 64, 66, 76, 77, 78], "selected_coef": 51, "selected_featur": [37, 66], "selected_learn": 51, "self": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 51, 78], "selfref": 36, "semenova": [42, 43, 76], "semi": 62, "semiparametr": 14, "sens": [58, 59], "sensemakr": 71, "sensit": [2, 4, 5, 7, 8, 9, 10, 11, 12, 31, 64, 65, 77], "sensitivity_analysi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 58, 59, 71, 78], "sensitivity_benchmark": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 58, 59, 71], "sensitivity_el": 71, "sensitivity_param": [2, 4, 5, 7, 8, 9, 10, 11, 12, 58, 59, 71], "sensitivity_plot": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 58, 59, 71], "sensitivity_summari": [50, 58, 59, 71, 78], "sensiv": [2, 4, 5, 7, 8, 9, 10, 11, 12], "senstiv": 71, "sep": 33, "separ": [55, 58, 66, 77], "seper": [58, 68, 70, 71], "seq_len": [33, 62], "sequenti": 15, "seri": [49, 59, 76], "serv": [63, 75, 77], "serverless": [76, 77], "servic": 55, "set": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 23, 24, 25, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 45, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 65, 67, 68, 69, 70, 71, 72, 74, 75, 77, 78], "set_as_param": [2, 4, 5, 7, 8, 9, 10, 11, 12], "set_fold_specif": 66, "set_index": 53, "set_ml_nuisance_param": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 38, 53, 66, 77], "set_param": [29, 30, 66], "set_sample_split": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 51, 68, 77], "set_styl": [53, 54], "set_text": 51, "set_threshold": [33, 34, 35, 36, 37, 61, 66, 67, 68, 69, 70, 72, 75], "set_tick": 52, "set_ticklabel": 52, "set_titl": 52, "set_x_d": [3, 6], "set_xlabel": [41, 52], "set_xlim": 41, "set_xtick": 55, "set_xticklabel": 55, "set_ylabel": [52, 55], "set_ylim": [44, 52, 57], "setdiff": 77, "setdiff1d": 52, "setminu": [35, 52, 70, 72], "setup": 74, "setuptool": 74, "seven": [35, 52], "sever": [31, 36, 37, 51, 53, 54, 58, 59, 62, 66, 78], "shape": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 42, 43, 46, 48, 49, 51, 52, 53, 56, 58, 59, 66], "share": [35, 36, 52, 53], "sharma": [59, 76], "shock": [35, 52], "short": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 58, 59, 71, 76, 77, 78], "shortcut": 36, "shortli": [35, 37, 52, 66], "shota": 76, "should": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 28, 36, 48, 49, 51, 53, 58, 60, 63, 65, 66, 70, 71, 73], "show": [32, 33, 35, 38, 40, 41, 42, 43, 45, 47, 50, 51, 52, 55, 59, 60, 62, 71, 74], "showcas": 56, "showlabel": 59, "showlegend": 59, "shown": [32, 40, 55, 75], "showscal": [42, 43, 47], "shuffl": 68, "side": 71, "sigma": [16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 33, 35, 41, 52, 60, 62, 65, 68, 70, 71, 72], "sigma2": 71, "sigma_": [17, 18, 20, 21, 22, 23, 24, 26, 33, 35, 41, 52, 62], "sigma_0": 71, "sigma_j": [70, 72], "sigmoid": 55, "sign": 59, "signal": 1, "signatur": [7, 8, 9, 10, 11, 12, 13, 69], "signif": [32, 34, 35, 36, 37, 66, 67, 68, 69, 70, 75, 78], "signific": [32, 35, 36, 37, 50, 53, 56, 58, 59, 66, 67, 68, 69, 70, 71, 75, 78], "silverman": [9, 12, 13], "sim": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 35, 41, 44, 46, 52, 56, 57, 60, 62], "similar": [17, 34, 37, 42, 43, 50, 54, 58, 59], "simpl": [19, 34, 37, 42, 43, 48, 49, 50, 56, 59, 64, 71], "simplest": 65, "simpli": [37, 45, 78], "simplic": [36, 51, 53, 56, 59], "simplif": 71, "simplifi": [55, 59, 65, 71], "simul": [16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 33, 37, 41, 42, 43, 44, 47, 48, 49, 57, 59, 60, 62, 66, 70, 72, 75], "simulation_run": 47, "simult": 34, "simultan": [64, 78], "sin": [19, 25, 42, 43, 46, 48, 49], "sinc": [16, 17, 36, 45, 46, 48, 49, 50, 51, 53, 55, 60, 66, 67, 71, 77], "singl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 45, 48, 49, 54, 55, 66, 70, 72], "single_learner_pipelin": 66, "singleton": 68, "sinh": 25, "sipp": [36, 53, 54], "site": [52, 53, 59], "situat": [35, 52], "six": 35, "sixth": 52, "size": [33, 35, 36, 37, 41, 44, 46, 47, 50, 51, 53, 55, 56, 57, 59, 61, 63, 66, 67, 68, 69, 70, 72, 75, 78], "sizeabl": 59, "skill": 76, "sklearn": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 25, 38, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58, 59, 60, 61, 65, 66, 67, 68, 69, 70, 71, 72, 75, 78], "skotara": 59, "slide": 55, "slightli": [46, 48, 49, 50, 51, 65, 69, 71], "sligthli": [4, 5], "slow": [33, 41, 62], "slower": [33, 41, 62], "small": [19, 45, 46, 56, 60, 71], "smaller": [36, 45, 48, 49, 50, 53, 59, 78], "smallest": 51, "smpl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 35, 41, 51, 52, 68, 69], "smpls_cluster": [35, 52], "smsg": 53, "sn": [38, 41, 45, 51, 52, 53, 54, 59, 60], "so": [32, 36, 37, 40, 45, 53, 55, 59, 60, 66, 70, 78], "social": [55, 76], "societi": [35, 52, 59, 76], "softwar": [37, 66, 73, 75, 76, 77], "solari": 77, "sole": 59, "solut": [61, 65, 69], "solv": [27, 35, 52, 65, 66, 70, 72], "solver": [53, 60, 67], "some": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 37, 38, 45, 46, 51, 53, 54, 58, 60, 65, 66, 67, 77], "sometim": 51, "sonabend": [37, 66], "sophist": 66, "sort": 53, "sourc": [37, 66, 75, 77], "sourcefileload": 47, "sp": 34, "space": [35, 52, 66], "spars": [47, 66, 70, 72, 75, 76], "sparsiti": 76, "spec": 76, "special": [35, 52], "specif": [2, 4, 5, 7, 8, 9, 10, 11, 12, 28, 35, 36, 51, 52, 53, 59, 63, 64, 65, 66, 68, 69, 70, 73, 75], "specifi": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 32, 35, 36, 37, 40, 42, 43, 44, 45, 48, 49, 52, 53, 54, 56, 57, 58, 59, 60, 61, 63, 64, 65, 75, 77, 78], "specifii": 54, "speed": [13, 51], "speedup": 51, "spefici": 7, "spindler": [22, 59, 73, 76, 77], "spine": [53, 54], "spline": [42, 43, 65], "spline_basi": [42, 43, 65], "spline_grid": [42, 43], "split": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 35, 37, 45, 51, 52, 54, 56, 58, 60, 64, 65, 66, 67, 69, 70, 75, 77], "split_sampl": 51, "sponsor": [36, 53, 54], "sprintf": 33, "sq_error": 47, "sqrt": [16, 17, 18, 21, 33, 35, 37, 38, 41, 44, 52, 57, 62, 68, 70, 71, 72, 75], "squar": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 47, 53, 66, 71, 76], "squarederror": [36, 53, 78], "squeez": [44, 45, 57, 60], "src": 53, "ssm": [3, 6, 26, 64], "ssrn": 20, "stabil": 50, "stabl": [32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 73], "stack": [37, 66], "stacklrn": 37, "stage": [42, 43, 48, 49, 56, 66, 77, 78], "standard": [18, 34, 37, 44, 48, 49, 68, 69, 70, 71, 72, 77, 78], "standard_norm": [63, 66, 70, 72, 75], "standardscal": 53, "start": [34, 36, 37, 42, 43, 47, 50, 51, 52, 53, 57, 59, 67, 73, 78], "stat": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 41, 63, 66, 70, 72, 73, 76], "stat_bin": 33, "stat_dens": 36, "state": 78, "stationar": 45, "stationari": 67, "statist": [2, 4, 5, 7, 8, 9, 10, 11, 12, 23, 26, 31, 35, 52, 58, 59, 70, 71, 72, 73, 75, 76, 77, 78], "statsmodel": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "statu": [34, 36, 45, 53, 55, 60], "std": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 67, 68, 69, 70, 75, 78], "stefan": 76, "step": [33, 36, 37, 41, 48, 49, 50, 53, 56, 62, 66, 70, 72, 73, 78], "stepdown": [70, 72], "stick": [36, 53], "still": [42, 43, 45, 48, 49, 50, 54, 58, 60, 66], "stochast": [10, 11, 67, 75], "stock": [36, 53, 54], "store": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 61, 66, 68, 69, 70, 71, 77], "store_model": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "store_predict": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 53, 56], "stori": [59, 76], "str": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 36, 48, 49, 57, 65, 77], "straightforward": [48, 49, 51, 65], "strategi": [55, 59, 78], "stratifi": 51, "stratum": 55, "strength": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 58, 59, 71], "strictli": 67, "string": [2, 4, 5, 7, 8, 9, 10, 11, 12, 65, 70, 71, 75, 77], "string_label": 55, "strong": [60, 71], "stronger": [70, 78], "structur": [14, 15, 24, 35, 36, 47, 52, 53, 60, 62, 66, 73, 76, 78], "student": 76, "studi": [26, 35, 36, 47, 52, 53, 54, 58, 75, 78], "style": [2, 4, 5, 7, 8, 9, 10, 11, 12, 77], "styler": 77, "styliz": 59, "sub": [35, 52], "subclass": 77, "subfold": 66, "subgroup": [7, 36, 53, 77], "subject": [35, 52], "submiss": 77, "subobject": [29, 30], "subplot": [35, 41, 42, 43, 44, 46, 48, 49, 51, 52, 53, 54, 55, 57], "subplots_adjust": 51, "subpopul": 67, "subsampl": [37, 51], "subscript": 71, "subsequ": [35, 52], "subset": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 51, 52, 56, 61, 65, 66, 71], "subseteq": 65, "substanti": [36, 53, 55], "substract": 70, "subtract": 70, "sudo": 74, "suffic": 59, "suffici": [51, 59], "suggest": [35, 36, 52, 53, 59, 77], "suitabl": [42, 43, 60], "sum": [35, 36, 52, 53, 54, 57, 65, 70, 72], "sum_": [33, 35, 41, 52, 61, 62, 65, 70, 72], "sum_i": 55, "sum_oth": 52, "sum_riv": 52, "summar": [34, 55, 59, 61, 71], "summari": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 34, 35, 37, 38, 40, 42, 43, 44, 45, 48, 49, 50, 52, 54, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 70, 71, 75, 77, 78], "summary_result": 36, "suppli": [2, 4, 5, 7, 8, 9, 10, 11, 12, 42, 43, 48, 49, 50, 56, 65, 71], "support": [7, 19, 34, 35, 51, 52, 56, 66, 67, 78], "support_s": [19, 42, 43, 48, 49, 56], "support_t": 56, "support_w": 56, "suppos": 59, "suppress": [34, 36, 37], "suppresswarn": 33, "suprema": [70, 72], "suptitl": [44, 51, 54, 57], "supxlabel": [44, 54, 57], "supylabel": [44, 54, 57], "sure": [66, 77], "surfac": [42, 43, 47], "surpress": [35, 75], "survei": [36, 53, 54, 78], "susan": 76, "sven": [59, 73, 76], "svenk": 52, "svenklaassen": 73, "svg": [33, 41], "switch": [33, 41, 59, 62], "symbol": 59, "symmetr": 25, "synthet": [19, 32, 40, 42, 43, 44, 48, 49, 56, 57], "syrgkani": [59, 76], "system": 76, "szita": 76, "t": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 32, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 65, 66, 67, 68, 69, 70, 71, 72, 75, 78], "t_1_start": 51, "t_1_stop": 51, "t_2_start": 51, "t_2_stop": 51, "t_3_start": 51, "t_3_stop": 51, "t_col": [3, 5, 6, 67], "t_df": 56, "t_diff": 46, "t_dml": 33, "t_i": [45, 56, 67], "t_idx": 46, "t_nonorth": 33, "t_orth_nosplit": 33, "t_sigmoid": 56, "t_stat": 70, "tabl": [33, 35, 36, 37, 61, 63, 66, 67, 68, 69, 70, 72, 75, 78], "tabular": [51, 63, 70, 72, 75, 78], "taddi": 76, "take": [7, 8, 10, 11, 16, 17, 19, 42, 43, 44, 45, 46, 47, 48, 49, 51, 54, 57, 58, 60, 61, 65, 66, 67, 71, 75], "taken": [36, 53, 54, 78], "taker": [7, 77], "talk": 78, "target": [2, 4, 5, 7, 8, 9, 10, 11, 12, 27, 28, 32, 35, 36, 37, 42, 43, 51, 52, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 77, 78], "task": [32, 63, 68, 78], "task_typ": 77, "tau": [44, 46, 54, 55, 57, 65, 69], "tau_": 55, "tau_1": 55, "tau_2": 55, "tau_vec": [44, 54, 57], "tax": [36, 53, 54], "te": [34, 42, 43, 56], "techniqu": [33, 41, 62, 68, 78], "templat": 77, "temporari": 53, "tend": [36, 53, 54], "tensor": [42, 43], "tenth": 76, "term": [33, 35, 36, 37, 41, 46, 47, 52, 53, 55, 59, 62, 73, 78], "termin": [37, 66], "terminatorev": 37, "test": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 20, 32, 33, 34, 35, 36, 37, 41, 50, 52, 59, 62, 66, 67, 68, 69, 70, 72, 75, 76, 77, 78], "test_id": [35, 68], "test_ind": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "test_set": 68, "test_siz": 41, "text": [16, 17, 18, 20, 35, 36, 44, 47, 55, 56, 57, 59, 65, 68], "textbf": [61, 66, 78], "textposit": 59, "textrm": 71, "tg": [37, 38, 63, 75], "th": [35, 52], "than": [8, 33, 34, 36, 41, 47, 51, 53, 54, 55, 58, 59, 62, 71, 78], "thank": [34, 36, 37, 53, 77], "thatw": 46, "thei": [34, 36, 46, 48, 49, 53, 55, 71], "them": [36, 37, 42, 43, 44, 50, 53, 57], "theme": [35, 36], "theme_minim": [33, 36], "theorem": 71, "theoret": [51, 59, 68, 76], "theori": [65, 76], "therebi": [35, 37, 52, 78], "therefor": [55, 58, 68, 69, 71], "theta": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 23, 25, 26, 27, 28, 33, 35, 37, 41, 45, 46, 47, 50, 51, 52, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 78], "theta_": [59, 65, 70, 71, 72], "theta_0": [7, 8, 10, 11, 19, 33, 35, 36, 41, 42, 43, 47, 48, 49, 52, 53, 59, 60, 62, 65, 67, 69, 70, 71, 75], "theta_dml": [33, 41, 62], "theta_dml_po": [33, 41, 62], "theta_initi": 41, "theta_nonorth": [33, 41], "theta_orth_nosplit": [33, 41], "theta_orth_po_nosplit": [33, 41], "theta_resc": 33, "theta_t": 46, "thi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78], "think": 37, "third": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 41, 52, 62, 68], "thirion": [73, 75], "this_df": [47, 53], "this_split_ind": 52, "those": [34, 36, 53, 54], "though": [32, 40, 55], "thread": [55, 66], "three": [35, 37, 48, 49, 74, 77], "threshold": [2, 4, 5, 7, 8, 9, 12, 13, 59, 67], "through": [34, 44, 48, 49, 57, 66], "throughout": 50, "thu": 65, "tibbl": 34, "tight": 41, "tight_layout": 52, "tild": [16, 17, 18, 35, 52, 55, 61, 65, 68, 69, 70, 71, 72], "time": [3, 4, 6, 22, 23, 33, 34, 35, 36, 41, 45, 46, 47, 48, 49, 52, 53, 54, 58, 59, 60, 67, 77, 78], "time_df": 46, "time_period": 46, "titl": [35, 36, 42, 43, 44, 47, 48, 49, 51, 52, 53, 54, 55, 57, 59, 73], "tmp": 49, "tname": 34, "tnr": [37, 66], "to_fram": 56, "to_numpi": [44, 50, 54, 57], "todo": [35, 38], "toeplitz": 47, "togeth": [48, 49, 70], "toler": 52, "too": 51, "tool": [34, 37, 58, 78], "top": [35, 51, 52, 53, 54, 59, 73], "total": [36, 53], "tracker": 73, "tradit": [70, 72], "train": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 35, 37, 41, 42, 43, 44, 48, 49, 51, 52, 56, 57, 61, 62, 68], "train_id": [35, 68], "train_ind": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "train_set": 68, "train_test_split": 41, "transact": 76, "transform": [16, 17, 55, 59, 78], "translat": 47, "transpos": 46, "treament": 56, "treat": [8, 18, 34, 45, 46, 50, 56, 59, 65, 67, 70, 78], "treat1_param": 55, "treat2_param": 55, "treat_var": [2, 4, 5, 7, 8, 9, 10, 11, 12, 66], "treatment": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 32, 34, 35, 37, 38, 40, 45, 46, 47, 50, 51, 52, 56, 58, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78], "treatment_df": 46, "treatment_effect": [19, 42, 43], "treatment_var": [3, 6], "tree": [8, 36, 37, 45, 46, 51, 53, 61, 64, 66, 67, 68, 69, 70, 75, 77], "tree_param": 8, "tree_summari": 53, "trees_class": [36, 53], "trend": [34, 45, 46, 52, 67, 76], "tri": [47, 71], "trim": [2, 4, 5, 7, 8, 9, 12, 13, 36, 53, 54, 59], "trimming_rul": [2, 4, 5, 7, 8, 9, 12, 13, 54], "trimming_threshold": [2, 4, 5, 7, 8, 9, 12, 13, 36, 42, 53, 54, 56, 57, 59], "trm": [37, 66], "true": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 26, 29, 30, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 66, 67, 68, 69, 70, 71, 72, 75, 78], "true_effect": [42, 43, 46, 48, 49], "true_gatet_effect": 50, "true_group_effect": 50, "truncat": [2, 4, 5, 7, 8, 9, 12, 13, 54], "try": [51, 58], "tune": [2, 4, 5, 7, 8, 9, 10, 11, 12, 47, 64, 73, 75, 77], "tune_on_fold": [2, 4, 5, 7, 8, 9, 10, 11, 12, 66], "tune_r": [2, 4, 5, 7, 8, 9, 10, 11, 12], "tune_set": [37, 66], "tuner": 66, "tunergridsearch": 37, "tupl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "turn": 59, "turrel": 25, "tutori": 36, "tw": [53, 54], "two": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 19, 32, 33, 36, 37, 40, 41, 44, 45, 51, 53, 54, 55, 56, 57, 58, 59, 61, 62, 65, 66, 67, 68, 69, 70, 72, 78], "twoclass": 37, "twoearn": [36, 53, 54, 58, 78], "type": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 29, 30, 31, 33, 34, 35, 36, 37, 41, 51, 52, 59, 62, 66, 69, 70, 71, 72, 77, 78], "typic": [49, 73], "u": [7, 8, 9, 12, 13, 16, 17, 18, 19, 21, 26, 33, 34, 35, 36, 41, 44, 45, 46, 48, 49, 51, 52, 53, 54, 56, 57, 58, 59, 62, 67, 71, 74, 78], "u_hat": [33, 41, 69], "u_i": [20, 22, 25, 26], "u_t": 18, "uehara": 76, "uhash": 37, "ulf": 76, "unambigu": 59, "uncertainti": [2, 4, 5, 7, 8, 9, 10, 11, 12, 48, 49, 58, 71, 78], "uncondit": [36, 53, 78], "unconfounded": [59, 76], "under": [33, 36, 41, 45, 53, 56, 59, 62, 67, 70, 76], "underbrac": [33, 41, 46, 62, 65], "underli": [16, 36, 37, 48, 49, 55, 56, 71, 78], "underlin": [35, 52], "understand": 59, "undesir": 66, "unevenli": 68, "uniform": [18, 40, 42, 43, 44, 46, 56, 57, 70], "uniformli": [44, 54, 70, 72], "uniqu": [32, 40, 51, 69, 71], "unit": [33, 34, 45, 46, 50, 60, 67, 69, 77], "univari": [19, 42, 43], "univers": 76, "unknown": 67, "unlik": [36, 53, 54, 59], "unobserv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 32, 36, 40, 53, 54, 58, 59, 67, 71, 78], "unpen": 34, "unstabl": 71, "unter": [35, 36, 37], "untest": 59, "until": [67, 77], "untreat": [59, 67], "up": [13, 36, 47, 51, 53, 54, 58, 59, 66, 67, 68, 71, 74, 77, 78], "upcom": 77, "updat": [35, 49, 52, 76, 77], "update_layout": [42, 43, 47, 59], "update_trac": [42, 43], "upload": 77, "upon": [69, 77], "upper": [36, 37, 41, 44, 46, 50, 54, 57, 58, 59, 66, 71, 78], "upper_bound": [42, 43], "upsilon": 60, "upsilon_i": 60, "upward": [36, 53, 54, 59], "upweight": 55, "url": [47, 73, 76], "us": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 33, 35, 36, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 65, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78], "usa": 76, "usabl": 51, "usag": [34, 38, 45, 50, 52, 53, 54, 58, 60, 63, 75, 77], "use_label_encod": [53, 78], "use_other_treat_as_covari": [3, 6, 63], "usecolormap": [42, 43], "user": [27, 28, 29, 30, 33, 34, 35, 36, 37, 41, 50, 51, 52, 53, 58, 65, 66, 69, 70, 72, 73, 74, 75, 77, 78], "user_guid": 49, "userwarn": [53, 59], "usual": [35, 42, 43, 45, 51, 52, 58, 59, 65, 66, 68, 71], "util": [28, 51, 55, 66, 77], "v": [7, 8, 10, 11, 14, 15, 21, 22, 23, 24, 26, 33, 35, 36, 41, 50, 52, 53, 55, 61, 62, 65, 67, 70, 72, 73, 75, 76, 77, 78], "v108": 73, "v12": [73, 75], "v22": 37, "v23": 73, "v_": [23, 35, 52], "v_i": [20, 21, 24, 25, 26, 33, 41, 62, 67], "v_j": [70, 72], "val": [21, 68, 76], "val_list": 47, "valid": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 20, 33, 34, 35, 36, 41, 44, 45, 51, 52, 53, 54, 57, 62, 64, 65, 66, 68, 69, 71, 76, 78], "valu": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 58, 59, 61, 64, 66, 67, 68, 70, 71, 72, 75, 77, 78], "value_count": 53, "van": 76, "vanderpla": [73, 75], "vanish": [33, 41, 62], "var": [16, 17, 18, 35, 52, 55, 71], "var_ep": 59, "varepsilon": [7, 16, 17, 23, 35, 52, 60, 65, 67], "varepsilon_": [23, 35, 52], "varepsilon_0": 18, "varepsilon_1": 18, "varepsilon_d": 17, "varepsilon_i": [22, 44, 57, 60], "vari": [36, 46, 51, 53, 55, 59], "variabl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 35, 36, 37, 38, 45, 47, 50, 52, 53, 54, 58, 59, 60, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 78], "varianc": [27, 28, 35, 37, 52, 58, 59, 64, 68, 71, 75], "variant": 34, "variat": [2, 4, 5, 7, 8, 9, 10, 11, 12, 17, 58, 71], "variou": [34, 59, 66, 78], "varoquaux": [73, 75], "vasili": [59, 76], "vector": [2, 4, 5, 7, 8, 9, 10, 11, 12, 19, 20, 21, 22, 23, 25, 26, 32, 35, 36, 40, 45, 48, 49, 50, 52, 53, 56, 60, 67, 70, 72, 75, 77], "venv": 74, "verbos": [36, 46, 51, 59], "veri": [34, 35, 37, 50, 51, 52, 59, 69, 73], "verifi": 55, "versa": [51, 55, 71], "version": [16, 35, 36, 37, 53, 59, 61, 65, 70, 71, 72, 77], "versoin": 59, "versu": 49, "vertic": [35, 52], "via": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 28, 34, 44, 45, 46, 47, 48, 49, 50, 51, 58, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78], "viabl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "vice": [51, 55, 71], "victor": [47, 59, 68, 73, 76], "view": 49, "vignett": [34, 77], "villa": [32, 40], "violet": [44, 54, 57], "vira": 76, "virtual": 74, "virtualenv": 74, "visibl": [54, 59], "visit": [73, 78], "visual": [35, 50, 52], "vol": 34, "volum": [59, 73], "voluntari": 55, "vv740": 52, "vv760g": 52, "w": [14, 15, 16, 17, 18, 24, 27, 28, 35, 47, 52, 55, 56, 61, 62, 69, 70, 71, 72, 73, 75], "w24678": 68, "w30302": 76, "w_": [18, 35, 52, 56], "w_1": [18, 56], "w_2": [18, 56], "w_3": 18, "w_4": 18, "w_df": 56, "w_i": [26, 45, 56, 61, 65, 68, 69, 70, 72], "wa": [35, 46, 52, 59, 77], "wager": 76, "wai": [36, 51, 53, 59, 66, 69, 74], "wander": 25, "wang": 76, "want": [32, 35, 36, 37, 40, 44, 45, 51, 52, 57, 66, 73, 74, 76], "warn": [32, 33, 34, 35, 36, 37, 41, 53, 59, 61, 66, 67, 68, 69, 70, 72, 75, 77], "wayon": 35, "we": [8, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 78], "weak": [71, 76], "wealth": [14, 58], "websit": [36, 37, 66, 73], "wedg": [35, 52], "week": 77, "wei": [70, 72], "weight": [2, 7, 8, 9, 12, 13, 35, 36, 37, 50, 52, 53, 60, 64, 66, 70, 71, 72, 77], "weights_bar": 8, "weiss": [73, 75], "well": [3, 6, 33, 35, 41, 47, 51, 52, 61, 62, 63, 68, 75], "were": [36, 53, 54, 60, 78], "what": [34, 47, 51], "when": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 36, 45, 49, 53, 55, 67, 69, 70, 72, 73, 74, 75, 77], "whenev": [36, 53], "whera": 71, "where": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 32, 33, 35, 36, 40, 41, 44, 45, 46, 50, 52, 53, 55, 56, 57, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 74, 75, 77, 78], "wherea": [19, 45, 59, 60, 71, 78], "whether": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 19, 26, 36, 46, 51, 53, 54, 59, 63, 66, 71, 77], "which": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 19, 28, 32, 33, 34, 36, 37, 39, 40, 41, 45, 47, 49, 50, 51, 53, 54, 56, 58, 59, 60, 62, 63, 65, 66, 67, 69, 70, 71, 72, 74, 77, 78], "while": [32, 40], "white": [35, 48, 49, 52, 59], "whitegrid": [53, 54], "whitnei": [59, 76], "who": [34, 36, 53, 59], "whole": [33, 41, 45, 62, 66, 71], "width": [33, 35, 42, 43, 47], "wiki": 77, "wiksel": 76, "wild": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 70, 72], "window": 74, "wise": [48, 49], "wish": 74, "within": [35, 48, 49, 52, 56], "without": [7, 32, 33, 40, 41, 51, 59, 62, 64, 66, 71, 74, 77], "wolf": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 70, 72], "won": 59, "word": 78, "work": [29, 30, 39, 49, 50, 51, 55, 58, 66, 70, 74, 76], "workflow": [73, 77], "workspac": 53, "world": 76, "worri": 59, "would": [34, 36, 37, 42, 43, 47, 51, 53, 54, 58, 59, 65, 66, 71, 78], "wrapper": [34, 66], "write": [33, 34, 41, 45, 49, 60, 62, 71], "written": [69, 71], "wrong": [51, 55], "wspace": 51, "wurd": [35, 36, 37], "www": [73, 74], "x": [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 35, 36, 37, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 78], "x0": 55, "x1": [35, 37, 45, 52, 55, 58, 59, 60, 63, 65, 66, 67, 69, 70, 71, 75], "x10": [35, 37, 52, 60, 63, 66, 67, 69, 70, 75], "x100": [35, 37, 52, 60, 63, 67, 75], "x11": [35, 37, 52, 60, 63, 66, 67, 69, 70, 75], "x12": [35, 37, 52, 60, 63, 66, 67, 69, 70, 75], "x13": [35, 37, 52, 60, 63, 66, 67, 69, 70, 75], "x14": [35, 37, 52, 60, 63, 66, 67, 69, 70, 75], "x15": [35, 37, 52, 60, 63, 66, 67, 69, 70, 75], "x16": [35, 37, 52, 60, 63, 66, 67, 69, 70, 75], "x17": [35, 37, 52, 60, 63, 66, 67, 69, 70, 75], "x18": [35, 37, 52, 60, 63, 66, 67, 69, 70, 75], "x19": [35, 37, 52, 60, 63, 66, 67, 69, 70, 75], "x1x2x3x4x5x6x7x8x9x10": 35, "x2": [35, 37, 45, 52, 58, 59, 60, 63, 65, 66, 67, 69, 70, 75], "x20": [35, 37, 52, 60, 63, 66, 67, 69, 70, 75], "x21": [35, 37, 52, 60, 63, 67, 75], "x22": [35, 37, 52, 60, 63, 67, 75], "x23": [35, 37, 52, 60, 63, 67, 75], "x24": [35, 37, 52, 60, 63, 67, 75], "x25": [35, 37, 52, 60, 63, 67, 75], "x26": [35, 37, 52, 60, 63, 67, 75], "x27": [35, 37, 52, 60, 63, 67, 75], "x28": [35, 37, 52, 60, 63, 67, 75], "x29": [35, 37, 52, 60, 63, 67, 75], "x2_dummi": 59, "x2_preds_control": 59, "x2_preds_treat": 59, "x3": [35, 37, 45, 52, 58, 59, 60, 63, 65, 66, 67, 69, 70, 75], "x30": [35, 37, 52, 60, 63, 67, 75], "x31": [35, 37, 52, 60, 63, 67, 75], "x32": [35, 37, 52, 60, 63, 67, 75], "x33": [35, 37, 52, 60, 63, 67, 75], "x34": [35, 37, 52, 60, 63, 67, 75], "x35": [35, 37, 52, 60, 63, 67, 75], "x36": [35, 37, 52, 60, 63, 67, 75], "x37": [35, 37, 52, 60, 63, 67, 75], "x38": [35, 37, 52, 60, 63, 67, 75], "x39": [35, 37, 52, 60, 63, 67, 75], "x4": [35, 37, 45, 52, 58, 59, 60, 63, 66, 67, 69, 70, 75], "x40": [35, 37, 52, 60, 63, 67, 75], "x41": [35, 37, 52, 60, 63, 67, 75], "x42": [35, 37, 52, 60, 63, 67, 75], "x43": [35, 37, 52, 60, 63, 67, 75], "x44": [35, 37, 52, 60, 63, 67, 75], "x45": [35, 37, 52, 60, 63, 67, 75], "x46": [35, 37, 52, 60, 63, 67, 75], "x47": [35, 37, 52, 60, 63, 67, 75], "x48": [35, 37, 52, 60, 63, 67, 75], "x49": [35, 37, 52, 60, 63, 67, 75], "x5": [35, 37, 52, 59, 60, 63, 66, 67, 69, 70, 75], "x50": [35, 37, 52, 60, 63, 67, 75], "x51": [35, 37, 52, 60, 63, 67, 75], "x52": [35, 37, 52, 60, 63, 67, 75], "x53": [35, 37, 52, 60, 63, 67, 75], "x54": [35, 37, 52, 60, 63, 67, 75], "x55": [35, 37, 52, 60, 63, 67, 75], "x56": [35, 37, 52, 60, 63, 67, 75], "x57": [35, 37, 52, 60, 63, 67, 75], "x58": [35, 37, 52, 60, 63, 67, 75], "x59": [35, 37, 52, 60, 63, 67, 75], "x6": [35, 37, 52, 60, 63, 66, 67, 69, 70, 75], "x60": [35, 37, 52, 60, 63, 67, 75], "x61": [35, 37, 52, 60, 63, 67, 75], "x62": [35, 37, 52, 60, 63, 67, 75], "x63": [35, 37, 52, 60, 63, 67, 75], "x64": [35, 37, 52, 53, 59, 60, 63, 67, 75], "x65": [35, 37, 52, 60, 63, 67, 75], "x66": [35, 37, 52, 60, 63, 67, 75], "x67": [35, 37, 52, 60, 63, 67, 75], "x68": [35, 37, 52, 60, 63, 67, 75], "x69": [35, 37, 52, 60, 63, 67, 75], "x7": [35, 37, 52, 60, 63, 66, 67, 69, 70, 75], "x70": [35, 37, 52, 60, 63, 67, 75], "x71": [35, 37, 52, 60, 63, 67, 75], "x72": [35, 37, 52, 60, 63, 67, 75], "x73": [35, 37, 52, 60, 63, 67, 75], "x74": [35, 37, 52, 60, 63, 67, 75], "x75": [35, 37, 52, 60, 63, 67, 75], "x76": [35, 37, 52, 60, 63, 67, 75], "x77": [35, 37, 52, 60, 63, 67, 75], "x78": [35, 37, 52, 60, 63, 67, 75], "x79": [35, 37, 52, 60, 63, 67, 75], "x8": [35, 37, 52, 60, 63, 66, 67, 69, 70, 75], "x80": [35, 37, 52, 60, 63, 67, 75], "x81": [35, 37, 52, 60, 63, 67, 75], "x82": [35, 37, 52, 60, 63, 67, 75], "x83": [35, 37, 52, 60, 63, 67, 75], "x84": [35, 37, 52, 60, 63, 67, 75], "x85": [35, 37, 52, 60, 63, 67, 75], "x86": [35, 37, 52, 60, 63, 67, 75], "x87": [35, 37, 52, 60, 63, 67, 75], "x88": [35, 37, 52, 60, 63, 67, 75], "x89": [35, 37, 52, 60, 63, 67, 75], "x9": [35, 37, 52, 60, 63, 66, 67, 69, 70, 75], "x90": [35, 37, 52, 60, 63, 67, 75], "x91": [35, 37, 52, 60, 63, 67, 75], "x92": [35, 37, 52, 60, 63, 67, 75], "x93": [35, 37, 52, 60, 63, 67, 75], "x94": [35, 37, 52, 60, 63, 67, 75], "x95": [35, 37, 52, 60, 63, 67, 75], "x96": [35, 37, 52, 60, 63, 67, 75], "x96x97x98x99x100ydcluster_var_icluster_var_jz": 35, "x97": [35, 37, 52, 60, 63, 67, 75], "x98": [35, 37, 52, 60, 63, 67, 75], "x99": [35, 37, 52, 60, 63, 67, 75], "x_": [23, 24, 33, 35, 41, 46, 52, 59, 62], "x_0": [42, 43, 46, 48, 49, 50], "x_1": [10, 11, 16, 17, 18, 42, 43, 44, 46, 48, 49, 50, 57, 59, 67, 71, 75], "x_1x_3": [44, 57], "x_2": [16, 17, 18, 42, 43, 44, 46, 48, 49, 50, 57, 59, 71], "x_3": [16, 17, 18, 42, 43, 46, 48, 49, 50, 71], "x_4": [16, 17, 18, 42, 43, 44, 48, 49, 50, 57], "x_5": [16, 17, 42, 43, 48, 49], "x_6": [42, 43, 48, 49], "x_7": [42, 43, 48, 49], "x_8": [42, 43, 48, 49], "x_9": [42, 43, 48, 49], "x_binary_control": 59, "x_binary_tr": 59, "x_col": [3, 6, 32, 35, 36, 37, 40, 47, 52, 53, 54, 56, 58, 59, 63, 66, 75, 77, 78], "x_cols_bench": 59, "x_cols_binari": 59, "x_cols_poli": 52, "x_conf": 57, "x_conf_tru": 57, "x_df": 46, "x_domain": 37, "x_i": [19, 20, 21, 22, 24, 25, 26, 33, 41, 44, 45, 48, 49, 55, 57, 60, 62, 65, 67], "x_p": [10, 11, 67, 75], "x_true": [44, 57], "x_var": 37, "xaxis_titl": [42, 43, 47, 59], "xformla": 34, "xgbclassifi": [51, 53, 55, 78], "xgboost": [33, 36, 51, 53, 55, 78], "xgbregressor": [51, 53, 55, 78], "xi": [18, 67], "xi_": [70, 72], "xi_0": [23, 35, 52], "xi_i": 60, "xiaoji": 76, "xintercept": 33, "xlab": [33, 35, 36], "xlabel": [42, 43, 44, 46, 48, 49, 53, 54, 57], "xlim": [33, 36], "xval": [37, 66], "xx": 41, "y": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 78], "y0": [34, 44, 57], "y0_cvar": 44, "y0_quant": [44, 57], "y1": [34, 44, 57], "y1_cvar": 44, "y1_quant": [44, 57], "y_": [23, 35, 45, 46, 52, 60, 67], "y_0": [4, 18, 69], "y_1": [4, 18, 69], "y_col": [3, 6, 32, 33, 35, 36, 37, 40, 42, 43, 47, 48, 49, 52, 53, 54, 56, 58, 61, 62, 63, 66, 67, 68, 69, 75, 77, 78], "y_df": [46, 56], "y_diff": 46, "y_i": [19, 20, 21, 22, 24, 25, 26, 33, 41, 44, 45, 55, 56, 57, 60, 62, 67], "y_pred": [2, 4, 5, 7, 8, 9, 10, 11, 12, 51, 66], "y_true": [2, 4, 5, 7, 8, 9, 10, 11, 12, 51, 66], "ya": 76, "yasui": 76, "yata": 76, "yaxis_titl": [42, 43, 47, 59], "year": 73, "yerr": [46, 48, 49, 53, 55], "yet": [35, 39], "yggvpl": 52, "yintercept": 36, "ylab": [33, 35, 36], "ylabel": [42, 43, 44, 46, 48, 49, 53, 54, 57], "ylim": 53, "ymax": 36, "ymin": 36, "yname": 34, "york": 76, "you": [32, 33, 40, 46, 49, 52, 58, 73, 74, 78], "your": [51, 74], "ython": 73, "yukun": 76, "yusuk": 76, "yuya": 76, "yy": 41, "z": [3, 6, 7, 9, 10, 16, 17, 18, 20, 22, 23, 26, 32, 35, 36, 40, 42, 43, 47, 52, 53, 57, 59, 60, 65, 67, 69, 70, 72, 77], "z1": [10, 67], "z2": 67, "z3": 67, "z4": 67, "z_": [23, 35, 52], "z_1": [16, 17], "z_2": [16, 17], "z_3": [16, 17], "z_4": [16, 17], "z_5": 16, "z_col": [3, 6, 7, 9, 10, 32, 35, 36, 40, 52, 53, 54, 60, 63, 65, 67, 77], "z_i": [22, 26, 57, 60, 67], "z_j": [16, 17, 18], "z_true": 57, "zadik": 76, "zaxis_titl": [42, 43, 47], "zero": [18, 44, 45, 46, 51, 56, 57, 58, 59, 70], "zeros_lik": 57, "zeta": [7, 10, 11, 36, 53, 65, 67, 75], "zeta_": [23, 35, 52], "zeta_0": [23, 35, 52], "zeta_i": [21, 22, 24, 33, 41, 62], "zeta_j": [70, 72], "zhang": 76, "zhao": [4, 5, 16, 17, 18, 34, 45, 67, 76], "zimmert": [45, 76], "zip": [42, 43], "\u03c4_x0": 55, "\u03c4_x1": 55, "\u2139": 33}, "titles": ["API reference", "doubleml.DoubleMLBLP", "doubleml.DoubleMLCVAR", "doubleml.DoubleMLClusterData", "doubleml.DoubleMLDID", "doubleml.DoubleMLDIDCS", "doubleml.DoubleMLData", "doubleml.DoubleMLIIVM", "doubleml.DoubleMLIRM", "doubleml.DoubleMLLPQ", "doubleml.DoubleMLPLIV", "doubleml.DoubleMLPLR", "doubleml.DoubleMLPQ", "doubleml.DoubleMLQTE", "doubleml.datasets.fetch_401K", "doubleml.datasets.fetch_bonus", "doubleml.datasets.make_confounded_irm_data", "doubleml.datasets.make_confounded_plr_data", "doubleml.datasets.make_did_SZ2020", "doubleml.datasets.make_heterogeneous_data", "doubleml.datasets.make_iivm_data", "doubleml.datasets.make_irm_data", "doubleml.datasets.make_pliv_CHS2015", "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "doubleml.datasets.make_plr_CCDDHNR2018", "doubleml.datasets.make_plr_turrell2018", "doubleml.datasets.make_ssm_data", "doubleml.double_ml_score_mixins.LinearScoreMixin", "doubleml.double_ml_score_mixins.NonLinearScoreMixin", "doubleml.utils.DMLDummyClassifier", "doubleml.utils.DMLDummyRegressor", "doubleml.utils.gain_statistics", "R: Basic Instrumental Variables Calculation", "R: Basics of Double Machine Learning", "R: DoubleML for Difference-in-Differences", "R: Cluster Robust Double Machine Learning", "R: Impact of 401(k) on Financial Wealth", "R: Ensemble Learners and More with <code class=\"docutils literal notranslate\"><span class=\"pre\">mlr3pipelines</span></code>", "DML: Bonus Data", "Examples", "Python: Basic Instrumental Variables calculation", "Python: Basics of Double Machine Learning", "Python: Conditional Average Treatment Effects (CATEs) for IRM models", "Python: Conditional Average Treatment Effects (CATEs) for PLR models", "Python: Conditional Value at Risk of potential outcomes", "Python: Difference-in-Differences", "Python: Difference-in-Differences Pre-Testing", "Python: First Stage and Causal Estimation", "Python: Group Average Treatment Effects (GATEs) for IRM models", "Python: Group Average Treatment Effects (GATEs) for PLR models", "Python: GATE Sensitivity Analysis", "Python: Choice of learners", "Python: Cluster Robust Double Machine Learning", "Python: Impact of 401(k) on Financial Wealth", "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)", "Python: PLM and IRM for Multiple Treatments", "Python: Policy Learning with Trees", "Python: Potential Quantiles and Quantile Treatment Effects", "Python: Sensitivity Analysis", "Example: Sensitivity Analysis for Causal ML", "Python: Sample Selection Models", "<span class=\"section-number\">6. </span>Double machine learning algorithms", "<span class=\"section-number\">1. </span>The basics of double/debiased machine learning", "<span class=\"section-number\">2. </span>The data-backend DoubleMLData", "User guide", "<span class=\"section-number\">4. </span>Heterogeneous treatment effects", "<span class=\"section-number\">7. </span>Learners, hyperparameters and hyperparameter tuning", "<span class=\"section-number\">3. </span>Models", "<span class=\"section-number\">9. </span>Sample-splitting, cross-fitting and repeated cross-fitting", "<span class=\"section-number\">5. </span>Score functions", "<span class=\"section-number\">8. </span>Variance estimation and confidence intervals", "<span class=\"section-number\">10. </span>Sensitivity analysis", "Confidence bands and multiplier bootstrap for valid simultaneous inference", "DoubleML", "Installing DoubleML", "Getting started", "Double machine learning literature", "Release notes", "DoubleML Workflow"], "titleterms": {"0": 78, "1": [59, 78], "2": [59, 78], "2011": 59, "2023": 59, "3": [59, 78], "4": [59, 78], "401": [36, 53, 54, 58], "5": [59, 78], "6": 78, "7": 78, "A": [35, 52], "ATE": [50, 55, 60], "No": [35, 52], "One": [35, 42, 43, 52], "The": [36, 53, 55, 62, 63, 75], "acknowledg": [34, 73], "acycl": [32, 40], "addit": 55, "advanc": [66, 70], "al": 59, "algorithm": [61, 71, 73, 75], "altern": 69, "analysi": [50, 58, 59, 71, 78], "api": 0, "applic": [35, 52, 58], "approach": [33, 41, 51, 62], "arah": 59, "arbitrari": 55, "arrai": 63, "asset": [36, 53], "assumpt": 59, "att": 45, "augment": 55, "averag": [36, 42, 43, 48, 49, 53, 65], "backend": [35, 36, 52, 53, 63, 75, 78], "band": [70, 72], "base": 37, "basic": [32, 33, 40, 41, 62], "benchmark": [58, 59, 71], "bia": [33, 41, 62], "bonu": 38, "bootstrap": [70, 72], "build": 74, "calcul": [32, 40], "callabl": 69, "case": 39, "cate": [42, 43, 55, 65], "causal": [38, 47, 59, 69, 75, 78], "chernozhukov": 59, "choic": 51, "citat": 73, "class": [0, 35, 52], "cluster": [35, 52], "code": 73, "combin": 47, "compar": 51, "comparison": 34, "comput": 51, "conclus": 59, "conda": 74, "condit": [42, 43, 44, 54, 65, 69], "confid": [70, 72], "construct": 66, "coverag": [45, 47], "cran": 74, "cross": [35, 45, 52, 67, 68, 69, 71, 75], "custom": 51, "cvar": [44, 54, 65, 69], "dag": [32, 40], "data": [0, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 48, 49, 50, 52, 53, 54, 56, 57, 58, 59, 60, 62, 63, 67, 69, 71, 75, 78], "datafram": 63, "dataset": [0, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 38], "debias": [33, 41, 62, 75], "defin": [35, 52], "demo": 34, "detail": 34, "develop": 74, "dgp": [33, 41], "did": [34, 67], "differ": [34, 45, 46, 51, 67, 69, 70, 71], "dimension": [42, 43], "direct": [32, 40], "disclaim": 59, "distribut": 60, "dml": [35, 38, 52, 68, 75, 78], "dml1": 61, "dml2": 61, "dmldummyclassifi": 29, "dmldummyregressor": 30, "doubl": [0, 33, 35, 41, 52, 61, 62, 73, 75, 76], "double_ml_score_mixin": [27, 28], "doubleml": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 40, 53, 58, 59, 70, 73, 74, 78], "doublemlblp": 1, "doublemlclusterdata": [3, 35, 52], "doublemlcvar": 2, "doublemldata": [6, 36, 53, 63, 75], "doublemldid": 4, "doublemldidc": 5, "doublemliivm": 7, "doublemlirm": 8, "doublemllpq": 9, "doublemlpliv": [10, 35, 52], "doublemlplr": 11, "doublemlpq": 12, "doublemlqt": 13, "effect": [36, 39, 42, 43, 44, 48, 49, 53, 54, 55, 57, 58, 59, 65], "elig": [36, 53], "empir": 47, "ensembl": 37, "error": [35, 52], "estim": [32, 36, 38, 40, 45, 47, 50, 53, 54, 55, 57, 58, 59, 60, 68, 69, 70, 75, 78], "et": 59, "evalu": [51, 66], "exampl": [34, 35, 39, 42, 43, 52, 58, 59], "exploit": [34, 37], "extern": [66, 68], "featur": [37, 73], "fetch_401k": 14, "fetch_bonu": 15, "figur": 55, "file": 74, "final": 34, "financi": [36, 53, 54], "first": 47, "fit": [35, 52, 68, 75], "fold": 68, "forest": 38, "formul": [59, 78], "from": [34, 37, 63, 74], "function": [0, 34, 35, 52, 69, 75], "gain_statist": 31, "gate": [48, 49, 50, 65], "gatet": 50, "gener": [0, 33, 39, 41, 62, 71], "get": 75, "github": 74, "graph": [32, 40], "group": [48, 49, 65], "guid": 64, "helper": [35, 52], "heterogen": [39, 55, 65], "how": 37, "hyperparamet": 66, "identif": 59, "iivm": [36, 53, 67, 69], "impact": [36, 53, 54], "implement": [61, 69, 71], "induc": [33, 41, 62], "infer": [70, 72, 78], "initi": [35, 52], "instal": 74, "instrument": [32, 40], "integr": 34, "interact": [36, 48, 53, 56, 67, 69, 71], "interv": [70, 72], "invers": 55, "irm": [36, 38, 42, 48, 53, 55, 56, 58, 65, 67, 69, 71], "iv": [32, 36, 40, 53, 67, 69], "joint": 72, "k": [36, 53, 54, 58, 68], "lambda": 47, "lasso": [38, 47], "latest": 74, "lear": [35, 52], "learn": [0, 33, 35, 41, 52, 56, 61, 62, 65, 73, 75, 76], "learner": [37, 38, 51, 66, 75], "linear": [36, 49, 53, 55, 67, 69, 71], "linearscoremixin": 27, "literatur": 76, "load": [35, 38, 52, 59], "loader": 0, "local": [36, 53, 54, 57, 69], "loss": 47, "lpq": [57, 69], "lqte": [54, 57], "m": 68, "machin": [0, 33, 35, 41, 52, 61, 62, 73, 75, 76], "main": 73, "mainten": 73, "make_confounded_irm_data": 16, "make_confounded_plr_data": 17, "make_did_sz2020": 18, "make_heterogeneous_data": 19, "make_iivm_data": 20, "make_irm_data": 21, "make_pliv_chs2015": 22, "make_pliv_multiway_cluster_ckms2021": 23, "make_plr_ccddhnr2018": 24, "make_plr_turrell2018": 25, "make_ssm_data": 26, "mar": 60, "market": [35, 52], "matric": 63, "method": 78, "metric": 51, "minimum": 66, "miss": 60, "missing": [67, 69], "mixin": 0, "ml": [33, 34, 41, 59, 62, 78], "mlr3": 37, "mlr3extralearn": 37, "mlr3learner": 37, "mlr3pipelin": 37, "model": [0, 36, 38, 42, 43, 48, 49, 53, 55, 56, 59, 60, 65, 67, 68, 69, 70, 71, 75, 78], "modul": [0, 38], "more": 37, "motiv": [35, 52], "multipl": 55, "multipli": [70, 72], "naiv": [32, 40], "net": [36, 53], "neyman": [69, 75], "nonignor": [60, 67, 69], "nonlinearscoremixin": 28, "nonrespons": [60, 67, 69], "note": 77, "nuisanc": 75, "object": [35, 52, 58], "orthogon": [33, 41, 62, 69, 75], "out": [33, 41, 62], "outcom": [44, 45, 60, 65], "over": 70, "overcom": [33, 41, 62], "overfit": [33, 41, 62], "overlap": 55, "packag": [34, 36, 53, 74], "panel": [45, 67, 69, 71], "paramet": [37, 38, 69], "partial": [33, 36, 41, 49, 53, 55, 62, 67, 69, 71], "particip": [36, 53], "partit": 68, "penalti": 47, "perform": [34, 55], "pip": 74, "pipelin": 66, "pliv": [67, 69], "plm": 55, "plot": [35, 52], "plr": [36, 38, 43, 49, 53, 65, 67, 69, 71], "polici": [56, 65], "potenti": [44, 54, 57, 65, 69], "pq": [57, 65, 69], "pre": 46, "predict": [34, 66], "preprocess": 37, "problem": 78, "process": [33, 35, 41, 52, 62], "product": [35, 52], "propens": 55, "provid": 68, "python": [39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 66, 74], "qte": [57, 65], "qualiti": 47, "quantil": [54, 57, 65, 69], "r": [32, 33, 34, 35, 36, 37, 39, 66, 74], "random": [38, 60, 67, 69], "rank": 55, "real": [35, 52], "refer": [0, 32, 34, 35, 37, 40, 47, 52, 55, 59, 62, 66, 68, 70, 72, 73, 75], "regress": [36, 48, 49, 53, 56, 67, 69, 71], "regular": [33, 41, 62], "releas": [74, 77], "remark": 34, "remov": [33, 41, 62], "repeat": [45, 67, 68, 69, 71], "repetit": 68, "requir": 66, "respect": [35, 52], "result": [35, 36, 52, 53, 55], "risk": [44, 54, 65, 69], "robust": [35, 52], "sampl": [33, 41, 60, 62, 67, 68], "sandbox": 39, "score": [0, 33, 41, 55, 62, 69, 75], "section": [45, 67, 69, 71], "select": [60, 67], "sensit": [50, 58, 59, 71, 78], "set": [37, 66], "simpl": [33, 41, 62], "simul": [32, 35, 40, 45, 52, 58], "simultan": [70, 72], "sourc": [73, 74], "specif": [71, 78], "specifi": [38, 66, 69], "split": [33, 41, 62, 68], "ssm": 67, "stage": 47, "standard": [35, 51, 52], "start": 75, "studi": 39, "summari": [36, 53, 55], "test": 46, "theori": 71, "time": 51, "treatment": [36, 42, 43, 44, 48, 49, 53, 54, 55, 57, 65], "tree": [56, 65], "tune": [37, 66], "two": [35, 42, 43, 52], "under": [55, 60], "up": 37, "us": [32, 34, 37, 38, 40, 66], "user": 64, "util": [0, 29, 30, 31], "v": 47, "valid": [70, 72], "valu": [44, 54, 65, 69], "vanderweel": 59, "variabl": [32, 40], "varianc": 70, "version": 74, "via": 69, "wai": [35, 52], "wealth": [36, 53, 54], "weight": [55, 65], "whl": 74, "without": 68, "workflow": 78, "zero": [35, 52]}})