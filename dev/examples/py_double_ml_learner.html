
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Python: Choice of learners &#8212; DoubleML  documentation</title>
<script>
  document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
  document.documentElement.dataset.theme = localStorage.getItem("theme") || "light"
</script>

  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=92025949c220c2e29695" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=92025949c220c2e29695" rel="stylesheet">


  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css" />

  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="R: Ensemble Learners and More with mlr3pipelines" href="R_double_ml_pipeline.html" />
    <link rel="prev" title="Python: Coniditional Value at Risk of potential outcomes" href="py_double_ml_cvar.html" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="docsearch:language" content="None">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">
    <div class="bd-header-announcement container-fluid" id="banner">
      

    </div>

    
    <nav class="bd-header navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="bd-header__inner container-xl">

  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    <p class="title logo__title">DoubleML  documentation</p>
  
</a>
    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="fas fa-bars"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  DoubleML
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/install.html">
  Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/intro.html">
  Getting started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../guide/guide.html">
  User guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../workflow/workflow.html">
  Workflow
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api.html">
  Python API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference external nav-link" href="https://docs.doubleml.org/r/stable/">
  R API
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../literature/literature.html">
  Literature
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../release/release.html">
  Release notes
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <span id="theme-switch" class="btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" rel="noopener" target="_blank" title="GitHub"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="bd-container container-xl">
      <div class="bd-container__inner row">
          

<!-- Only show if we have sidebars configured, else just a small margin  -->
<div class="bd-sidebar-primary col-12 col-md-3 bd-sidebar">
  <div class="sidebar-start-items"><p class="logo" style="text-align:center;"><a href="../index.html">
    <img class="logo" src="../logo.png" alt="Logo" width="65%" height="65%">
</a></p><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="R_double_ml_pension.html">
   R: Impact of 401(k) on Financial Wealth
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="r_double_ml_multiway_cluster.html">
   R: Cluster Robust Double Machine Learning
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="py_double_ml_pension.html">
   Python: Impact of 401(k) on Financial Wealth
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="py_double_ml_multiway_cluster.html">
   Python: Cluster Robust Double Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="py_double_ml_gate.html">
   Python: Group Average Treatment Effects (GATEs)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="py_double_ml_cate.html">
   Python: Conditional Average Treatment Effects (CATEs)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="py_double_ml_pension_qte.html">
   Python: Impact of 401(k) on Financial Wealth (Quantile Effects)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="py_double_ml_pq.html">
   Python: Potential Quantiles and Quantile Treatment Effects
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="py_double_ml_cvar.html">
   Python: Coniditional Value at Risk of potential outcomes
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Python: Choice of learners
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="R_double_ml_pipeline.html">
   R: Ensemble Learners and More with
   <code class="docutils literal notranslate">
    <span class="pre">
     mlr3pipelines
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="double_ml_bonus_data.html">
   DML: Bonus Data
  </a>
 </li>
</ul>

  </div>
</nav>
  </div>
  <div class="sidebar-end-items">
  </div>
</div>


          


<div class="bd-sidebar-secondary d-none d-xl-block col-xl-2 bd-toc">
  
    
    <div class="toc-item">
      
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Comparing-different-learners">
   Comparing different learners
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Standard-approach">
     Standard approach
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Custom-evaluation-metrics">
     Custom evaluation metrics
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Computation-time">
   Computation time
  </a>
 </li>
</ul>

</nav>
    </div>
    
    <div class="toc-item">
      
    </div>
    
  
</div>


          
          
          <div class="bd-content col-12 col-md-9 col-xl-7">
              
              <article class="bd-article" role="main">
                
      <div class="admonition note">
    <p class="admonition-title">Note</p>
    <ul class="simple">

Download Jupyter notebook:
<a class="reference external" href="https://docs.doubleml.org/stable/examples/py_double_ml_learner.ipynb">https://docs.doubleml.org/stable/examples/py_double_ml_learner.ipynb</a>.

    </ul>
    </div><section id="Python:-Choice-of-learners">
<h1>Python: Choice of learners<a class="headerlink" href="#Python:-Choice-of-learners" title="Permalink to this headline">#</a></h1>
<p>This notebooks contains some practical recommendations to choose the right learner and evaluate different learners for the corresponding nuisance components.</p>
<p>For the example, we will work with a IRM, but all of the important components are directly usable for all other models too.</p>
<p>To be able to compare the properties of different learners, we will start by setting the true treatment parameter to zero, fix some other parameters of the data generating process and generate several datasets to obtain some information about the distribution of the estimators.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_irm_data</span>

<span class="n">theta</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">n_obs</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">dim_x</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">n_rep</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">datasets</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_rep</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">make_irm_data</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="n">theta</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="n">n_obs</span><span class="p">,</span> <span class="n">dim_x</span><span class="o">=</span><span class="n">dim_x</span><span class="p">,</span>
                         <span class="n">R2_d</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">R2_y</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;DataFrame&#39;</span><span class="p">)</span>
    <span class="n">datasets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<section id="Comparing-different-learners">
<h2>Comparing different learners<a class="headerlink" href="#Comparing-different-learners" title="Permalink to this headline">#</a></h2>
<p>For simplicity, we will restrict ourselves to the comparison of two different types and evaluate a learner of linear type and a tree based estimator for each nuisance component (with default hyperparameters).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">LogisticRegressionCV</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span><span class="p">,</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">clone</span>

<span class="n">reg_learner_1</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">reg_learner_2</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">()</span>
<span class="n">class_learner_1</span> <span class="o">=</span> <span class="n">LogisticRegressionCV</span><span class="p">()</span>
<span class="n">class_learner_2</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">()</span>

<span class="n">learner_list</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;ml_g&#39;</span><span class="p">:</span> <span class="n">reg_learner_1</span><span class="p">,</span> <span class="s1">&#39;ml_m&#39;</span><span class="p">:</span> <span class="n">class_learner_1</span><span class="p">},</span>
                <span class="p">{</span><span class="s1">&#39;ml_g&#39;</span><span class="p">:</span> <span class="n">reg_learner_2</span><span class="p">,</span> <span class="s1">&#39;ml_m&#39;</span><span class="p">:</span> <span class="n">class_learner_1</span><span class="p">},</span>
                <span class="p">{</span><span class="s1">&#39;ml_g&#39;</span><span class="p">:</span> <span class="n">reg_learner_1</span><span class="p">,</span> <span class="s1">&#39;ml_m&#39;</span><span class="p">:</span> <span class="n">class_learner_2</span><span class="p">},</span>
                <span class="p">{</span><span class="s1">&#39;ml_g&#39;</span><span class="p">:</span> <span class="n">reg_learner_2</span><span class="p">,</span> <span class="s1">&#39;ml_m&#39;</span><span class="p">:</span> <span class="n">class_learner_2</span><span class="p">}]</span>
</pre></div>
</div>
</div>
<p>In all combinations, we now can try to evaluate four different IRM models. To make the comparison fair, we will apply all different models to the same cross-fitting samples (usually this should not matter, we only consider this here to get slightly cleaner comparison).</p>
<section id="Standard-approach">
<h3>Standard approach<a class="headerlink" href="#Standard-approach" title="Permalink to this headline">#</a></h3>
<p>At first, we will look at the most straightforward approach using the inbuild RMSE. The <code class="docutils literal notranslate"><span class="pre">rmses</span></code> attribute contains the out-of-sample RMSE for the nuisance functions. We will save all RMSEs and the corresponding treatment estimates for all combinations of learners over all repetitions.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">doubleml._utils_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLResampling</span>

<span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_rep</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">learner_list</span><span class="p">)),</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
<span class="n">rmses_ml_m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_rep</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">learner_list</span><span class="p">)),</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
<span class="n">rmses_ml_g0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_rep</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">learner_list</span><span class="p">)),</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
<span class="n">rmses_ml_g1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_rep</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">learner_list</span><span class="p">)),</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

<span class="n">coverage</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_rep</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">learner_list</span><span class="p">)),</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i_rep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_rep</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">Processing: </span><span class="si">{</span><span class="nb">round</span><span class="p">((</span><span class="n">i_rep</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">n_rep</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2"> %&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="n">dml_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]</span>
    <span class="c1"># define the sample splitting</span>
    <span class="n">smpls</span> <span class="o">=</span> <span class="n">DoubleMLResampling</span><span class="p">(</span><span class="n">n_folds</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_rep</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="n">n_obs</span><span class="p">,</span>
                               <span class="n">apply_cross_fitting</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">dml_data</span><span class="o">.</span><span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">i_learners</span><span class="p">,</span> <span class="n">learners</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">learner_list</span><span class="p">):</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">dml_irm</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLIRM</span><span class="p">(</span><span class="n">dml_data</span><span class="p">,</span>
                                  <span class="n">ml_g</span><span class="o">=</span><span class="n">clone</span><span class="p">(</span><span class="n">learners</span><span class="p">[</span><span class="s1">&#39;ml_g&#39;</span><span class="p">]),</span>
                                  <span class="n">ml_m</span><span class="o">=</span><span class="n">clone</span><span class="p">(</span><span class="n">learners</span><span class="p">[</span><span class="s1">&#39;ml_m&#39;</span><span class="p">]),</span>
                                  <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">dml_irm</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">(</span><span class="n">smpls</span><span class="p">)</span>
        <span class="n">dml_irm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">n_jobs_cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

        <span class="n">coefs</span><span class="p">[</span><span class="n">i_rep</span><span class="p">,</span> <span class="n">i_learners</span><span class="p">]</span> <span class="o">=</span> <span class="n">dml_irm</span><span class="o">.</span><span class="n">coef</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">rmses_ml_m</span><span class="p">[</span><span class="n">i_rep</span><span class="p">,</span> <span class="n">i_learners</span><span class="p">]</span> <span class="o">=</span> <span class="n">dml_irm</span><span class="o">.</span><span class="n">rmses</span><span class="p">[</span><span class="s1">&#39;ml_m&#39;</span><span class="p">]</span>
        <span class="n">rmses_ml_g0</span><span class="p">[</span><span class="n">i_rep</span><span class="p">,</span> <span class="n">i_learners</span><span class="p">]</span> <span class="o">=</span> <span class="n">dml_irm</span><span class="o">.</span><span class="n">rmses</span><span class="p">[</span><span class="s1">&#39;ml_g0&#39;</span><span class="p">]</span>
        <span class="n">rmses_ml_g1</span><span class="p">[</span><span class="n">i_rep</span><span class="p">,</span> <span class="n">i_learners</span><span class="p">]</span> <span class="o">=</span> <span class="n">dml_irm</span><span class="o">.</span><span class="n">rmses</span><span class="p">[</span><span class="s1">&#39;ml_g1&#39;</span><span class="p">]</span>

        <span class="n">confint</span> <span class="o">=</span> <span class="n">dml_irm</span><span class="o">.</span><span class="n">confint</span><span class="p">()</span>
        <span class="n">coverage</span><span class="p">[</span><span class="n">i_rep</span><span class="p">,</span> <span class="n">i_learners</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">confint</span><span class="p">[</span><span class="s1">&#39;2.5 %&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">theta</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">confint</span><span class="p">[</span><span class="s1">&#39;97.5 %&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">theta</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Coverage: </span><span class="si">{</span><span class="n">coverage</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Processing: 83.0 %
</pre></div></div>
</div>
<p>Next, let us take a look at the corresponding results</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">colnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Linear + Logit&#39;</span><span class="p">,</span><span class="s1">&#39;Boost + Logit&#39;</span><span class="p">,</span> <span class="s1">&#39;Linear + Boost&#39;</span><span class="p">,</span> <span class="s1">&#39;Boost + Boost&#39;</span><span class="p">]</span>

<span class="n">df_coefs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">coefs</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">colnames</span><span class="p">)</span>
<span class="n">df_ml_m</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rmses_ml_m</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">colnames</span><span class="p">)</span>
<span class="n">df_ml_g0</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rmses_ml_g0</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">colnames</span><span class="p">)</span>
<span class="n">df_ml_g1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rmses_ml_g1</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">colnames</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Learner Comparison&#39;</span><span class="p">)</span>


<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_coefs</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_ml_m</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_ml_g0</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_ml_g1</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s1">&#39;Estimated Parameter&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s1">&#39;RMSE ml_m&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s1">&#39;RMSE ml_g0&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s1">&#39;RMSE ml_g1&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">bottom</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">right</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                    <span class="n">top</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                    <span class="n">wspace</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span>
                    <span class="n">hspace</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_py_double_ml_learner_9_0.png" src="../_images/examples_py_double_ml_learner_9_0.png" />
</div>
</div>
<p>We can now easily observe that in this setting, the linear learners are able to approximate the corresponding nuisance functions better than the boosting algorithm (as should be expected since the data is generated accordingly).</p>
<p>Let us take a look at what would have happend if a each repetition for each nuisance element, we would have selected the learner with smallest out-of-sample rmse (in our example this corresponds to minimizing the product of rmses). Remark that we cannot select different learners for <code class="docutils literal notranslate"><span class="pre">ml_g0</span></code> and <code class="docutils literal notranslate"><span class="pre">ml_g1</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">selected_learners</span> <span class="o">=</span> <span class="p">(</span><span class="n">rmses_ml_m</span> <span class="o">*</span> <span class="p">(</span><span class="n">rmses_ml_g0</span> <span class="o">+</span> <span class="n">rmses_ml_g1</span><span class="p">))</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">selected_learners</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(array([0, 2], dtype=int64), array([191,   9], dtype=int64))
</pre></div></div>
</div>
<p>Most of the time, we will use linear learners for both nuisance elements. Sometimes the tree-based estimator is chosen for the propensity score <code class="docutils literal notranslate"><span class="pre">ml_m</span></code>. Let us compare which learners, how the estimated coefficients would have performed with the selected learners.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Coverage of selected learners: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">coverage</span><span class="p">[</span><span class="n">i_rep</span><span class="p">,</span><span class="w"> </span><span class="n">selected_learners</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]]</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">i_rep</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nb">range</span><span class="p">(</span><span class="n">n_rep</span><span class="p">)]))</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">selected_coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">coefs</span><span class="p">[</span><span class="n">i_rep</span><span class="p">,</span> <span class="n">selected_learners</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]]</span> <span class="k">for</span> <span class="n">i_rep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_rep</span><span class="p">)])</span>
<span class="n">df_coefs</span><span class="p">[</span><span class="s1">&#39;Selected&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">selected_coefs</span>
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_coefs</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Coverage of selected learners: 0.94
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_py_double_ml_learner_13_1.png" src="../_images/examples_py_double_ml_learner_13_1.png" />
</div>
</div>
<p>This procedure will be generally valid as long as we do not compare a excessively large number of different learners.</p>
</section>
<section id="Custom-evaluation-metrics">
<h3>Custom evaluation metrics<a class="headerlink" href="#Custom-evaluation-metrics" title="Permalink to this headline">#</a></h3>
<p>If one wants to evaluate a learner based on some other metric/loss it is possible to use the inbuilt <code class="docutils literal notranslate"><span class="pre">evaluate_learners()</span></code> method. Without further arguments this will default to the RMSE for all nuisance components and result in the same output as the <code class="docutils literal notranslate"><span class="pre">rmses</span></code> attribute.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">dml_irm</span><span class="o">.</span><span class="n">evaluate_learners</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_irm</span><span class="o">.</span><span class="n">rmses</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;ml_g0&#39;: array([[1.02717222]]), &#39;ml_g1&#39;: array([[1.06176184]]), &#39;ml_m&#39;: array([[0.3498352]])}
{&#39;ml_g0&#39;: array([[1.02717222]]), &#39;ml_g1&#39;: array([[1.06176184]]), &#39;ml_m&#39;: array([[0.3498352]])}
</pre></div></div>
</div>
<p>To evaluate a self-defined metric, the user has to hand over a callable. In this example, we define the mean absolute deviation as an error metric.</p>
<p>Remark that the metric should be able to handle <code class="docutils literal notranslate"><span class="pre">nan</span></code> values, since e.g. in the IRM model the learner <code class="docutils literal notranslate"><span class="pre">ml_g</span></code> is used to onto two different subsamples. As a result, we have two different nuisance components for</p>
<p><span class="math">\begin{align*}
g_0(x) &= \mathbb{E}[Y|X=x, D=0] \\
g_1(x) &= \mathbb{E}[Y|X=x, D=1]
\end{align*}</span></p>
<p>which are both fitted with the learner <code class="docutils literal notranslate"><span class="pre">ml_g</span></code>. Of course, we can only observe the target value for <span class="math notranslate nohighlight">\(g_0(x)\)</span> if <span class="math notranslate nohighlight">\(D=0\)</span> and vice versa, resulting in <code class="docutils literal notranslate"><span class="pre">nan</span></code> values for all other observations.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>

<span class="k">def</span> <span class="nf">mae</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="n">subset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">y_true</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="n">subset</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">subset</span><span class="p">])</span>

<span class="n">dml_irm</span><span class="o">.</span><span class="n">evaluate_learners</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="n">mae</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;ml_g0&#39;: array([[0.82392532]]),
 &#39;ml_g1&#39;: array([[0.85653505]]),
 &#39;ml_m&#39;: array([[0.20092263]])}
</pre></div></div>
</div>
<p>Another option is to access the out-of-sample predictions and target values for the nuisance elements via the <code class="docutils literal notranslate"><span class="pre">nuisance_targets</span></code> and <code class="docutils literal notranslate"><span class="pre">predictions</span></code> attributes.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">dml_irm</span><span class="o">.</span><span class="n">nuisance_targets</span><span class="p">[</span><span class="s1">&#39;ml_g1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_irm</span><span class="o">.</span><span class="n">predictions</span><span class="p">[</span><span class="s1">&#39;ml_g1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(500, 1, 1)
(500, 1, 1)
</pre></div></div>
</div>
<p>For most models minimizing the RMSE for each learner should result in improved performance as the theoretical backbone of the DML Framework is build on <span class="math notranslate nohighlight">\(\ell_2\)</span>-convergence rates for the nuisance estimates (<a class="reference external" href="https://doi.org/10.1111/ectj.12097">Chernozhukov et al. (2018)</a>). But for some models (e.g. classification learners) it might be helpful to further check other error metrics (e.g. as in <a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html#">scikit-learn</a>) to gain a
overview whether the nuisance function can be approximated sufficiently well.</p>
<p>Of course, if one has some prior knowledge on functional form assumptions (e.g. linearity as in the IRM example above) using these learners will usually improve the performance of the estimator and might speed up computation time.</p>
</section>
</section>
<section id="Computation-time">
<h2>Computation time<a class="headerlink" href="#Computation-time" title="Permalink to this headline">#</a></h2>
<p>The choice of the learner has a huge impact on the computation time of the DoubleML models. As the largest part of the computation time is usually used to train the learners for the nuisance components, some clever choices of learners and hyperparameters can speed up the computation time.</p>
<p>Resourcewise, most implementations support the <code class="docutils literal notranslate"><span class="pre">n_jobs_cv</span></code> argument, which can parallelize the k-fold estimation and might speed up the calculation nearly up to <span class="math notranslate nohighlight">\(k\)</span>-times if the resources are available.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span><span class="p">,</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">perf_counter</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n_obs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="p">(</span><span class="n">make_irm_data</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="n">n_obs</span><span class="p">,</span> <span class="n">dim_x</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;DataFrame&#39;</span><span class="p">),</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

<span class="c1"># define the sample splitting</span>
<span class="n">smpls</span> <span class="o">=</span> <span class="n">DoubleMLResampling</span><span class="p">(</span><span class="n">n_folds</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_rep</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="n">n_obs</span><span class="p">,</span> <span class="n">apply_cross_fitting</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">dml_data</span><span class="o">.</span><span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_irm</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLIRM</span><span class="p">(</span><span class="n">dml_data</span><span class="p">,</span>
                          <span class="n">ml_g</span><span class="o">=</span><span class="n">RandomForestRegressor</span><span class="p">(),</span>
                          <span class="n">ml_m</span><span class="o">=</span><span class="n">RandomForestClassifier</span><span class="p">(),</span>
                          <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">dml_irm</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">(</span><span class="n">smpls</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">t_1_start</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">dml_irm</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">t_1_stop</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Time without parallelization of crossfitting: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">t_1_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_1_start</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s1"> seconds&#39;</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">t_2_start</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">dml_irm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">n_jobs_cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">t_2_stop</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Time with parallelization of crossfitting: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">t_2_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_2_start</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s1"> seconds&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Speedup of factor </span><span class="si">{</span><span class="nb">round</span><span class="p">((</span><span class="n">t_1_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_1_start</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">t_2_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_2_start</span><span class="p">),</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Time without parallelization of crossfitting: 5.9168 seconds
Time with parallelization of crossfitting: 1.2093 seconds
Speedup of factor 4.89
</pre></div></div>
</div>
<p>Other more helpful ways to improve computation time will largly depend on the implemented learner. Of course linear learners are quite fast, but if no functional form restrictions are known Boosting or Random Forest might be better default options to saveguard against wrong model assumptions. Especially Boosting performs very well as a default option for tabular data. As a general recommendation all popular Boosting frameworks (XGBoost, Lightgbm, Catboost, etc.) should improve computation time.
But this might vary heavily with the number of features in your dataset. Let us compare the computation time with Boosting and Random Forest (we increase the sample size and the number of features).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span><span class="p">,</span> <span class="n">XGBRegressor</span>
<span class="kn">from</span> <span class="nn">lightgbm</span> <span class="kn">import</span> <span class="n">LGBMClassifier</span><span class="p">,</span> <span class="n">LGBMRegressor</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n_obs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="p">(</span><span class="n">make_irm_data</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="n">n_obs</span><span class="p">,</span> <span class="n">dim_x</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;DataFrame&#39;</span><span class="p">),</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

<span class="c1"># define the sample splitting</span>
<span class="n">smpls</span> <span class="o">=</span> <span class="n">DoubleMLResampling</span><span class="p">(</span><span class="n">n_folds</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_rep</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="n">n_obs</span><span class="p">,</span> <span class="n">apply_cross_fitting</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">dml_data</span><span class="o">.</span><span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">t_1_start</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">dml_irm</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLIRM</span><span class="p">(</span><span class="n">dml_data</span><span class="p">,</span>
                          <span class="n">ml_g</span><span class="o">=</span><span class="n">RandomForestRegressor</span><span class="p">(),</span>
                          <span class="n">ml_m</span><span class="o">=</span><span class="n">RandomForestClassifier</span><span class="p">(),</span>
                          <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">dml_irm</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">(</span><span class="n">smpls</span><span class="p">)</span>
<span class="n">dml_irm</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">t_1_stop</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Time without RandomForest (Scikit-Learn): </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">t_1_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_1_start</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s1"> seconds&#39;</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">t_2_start</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">dml_irm</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLIRM</span><span class="p">(</span><span class="n">dml_data</span><span class="p">,</span>
                          <span class="n">ml_g</span><span class="o">=</span><span class="n">XGBRegressor</span><span class="p">(),</span>
                          <span class="n">ml_m</span><span class="o">=</span><span class="n">XGBClassifier</span><span class="p">(),</span>
                          <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">dml_irm</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">(</span><span class="n">smpls</span><span class="p">)</span>
<span class="n">dml_irm</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">t_2_stop</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Time with XGBoost: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">t_2_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_2_start</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s1"> seconds&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Speedup of factor </span><span class="si">{</span><span class="nb">round</span><span class="p">((</span><span class="n">t_1_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_1_start</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">t_2_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_2_start</span><span class="p">),</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">t_3_start</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">dml_irm</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLIRM</span><span class="p">(</span><span class="n">dml_data</span><span class="p">,</span>
                          <span class="n">ml_g</span><span class="o">=</span><span class="n">LGBMRegressor</span><span class="p">(),</span>
                          <span class="n">ml_m</span><span class="o">=</span><span class="n">LGBMClassifier</span><span class="p">(),</span>
                          <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">dml_irm</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">(</span><span class="n">smpls</span><span class="p">)</span>
<span class="n">dml_irm</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">t_3_stop</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Time with LightGBM: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">t_3_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_3_start</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s1"> seconds&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Speedup of factor </span><span class="si">{</span><span class="nb">round</span><span class="p">((</span><span class="n">t_1_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_1_start</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">t_3_stop</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_3_start</span><span class="p">),</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Time without RandomForest (Scikit-Learn): 12.0078 seconds
Time with XGBoost: 0.7409 seconds
Speedup of factor 16.21
Time with LightGBM: 0.5388 seconds
Speedup of factor 22.29
</pre></div></div>
</div>
</section>
</section>


              </article>
              

              
              <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="py_double_ml_cvar.html" title="previous page">
      <i class="fas fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">Python: Coniditional Value at Risk of potential outcomes</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="R_double_ml_pipeline.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">R: Ensemble Learners and More with <code class="docutils literal notranslate"><span class="pre">mlr3pipelines</span></code></p>
  </div>
  <i class="fas fa-angle-right"></i>
  </a>
</div>
              </footer>
              
          </div>
          
      </div>
    </div>

  
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695"></script>

<footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    <p class="copyright">
    &copy; Copyright 2023, Bach, P., Chernozhukov, V., Klaassen, S., Kurz, M. S., and Spindler, M..<br>
</p>
  </div>
  
  <div class="footer-item">
    <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
  </div>
  
</div>
</footer>
  </body>
</html>