
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.f6b7ca918bee2f46fd9abac01cfb07d5.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1e043a052b0af929e4d8.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">


    
    <a class="navbar-brand" href="../index.html">
      <p class="title">DoubleML</p>
    </a>
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  DoubleML
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/install.html">
  Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/intro.html">
  Getting started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../guide/guide.html">
  User guide
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api.html">
  Python API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference external nav-link" href="https://docs.doubleml.org/r/stable/">
  R API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../release/release.html">
  Release notes
 </a>
</li>

        
      </ul>

      <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><p class="logo" style="text-align:center;"><a href="../index.html">
    <img class="logo" src="../logo.png" alt="Logo" width="65%" height="65%">
</a></p><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l2 current active">
  <a class="current reference internal" href="#">
   Multiway Cluster Robust DML
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="double_ml_bonus_data.html">
   DML: Bonus Data
  </a>
 </li>
</ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulate-multiway-cluster-data">
   Simulate multiway cluster data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
   Initialize the objects of class DoubleMLData and DoubleMLPLIV
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#split-samples-and-transfer-the-sample-splitting-to-the-object">
   Split samples and transfer the sample splitting to the object
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fit-the-model-and-show-a-summary">
   Fit the model and show a summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing">
   Visualization of sample splitting with tuple and linear indexing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold">
     Visualize sample splitting with tuples (one plot per fold)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
     Visualize sample splitting with linear indexing (one column per fold)
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.701530</td>
      <td>0.553253</td>
      <td>0.743457</td>
      <td>0.084666</td>
      <td>0.018628</td>
      <td>0.924029</td>
      <td>1.740576</td>
      <td>-0.650760</td>
      <td>-0.442810</td>
      <td>-0.113766</td>
      <td>0.741291</td>
      <td>-0.727050</td>
      <td>0.024194</td>
      <td>-0.024096</td>
      <td>-0.077065</td>
      <td>-0.207844</td>
      <td>-0.674825</td>
      <td>-0.434945</td>
      <td>-0.104429</td>
      <td>0.199589</td>
      <td>0.267491</td>
      <td>-0.294259</td>
      <td>-0.367674</td>
      <td>0.782765</td>
      <td>-0.331286</td>
      <td>0.205035</td>
      <td>-0.328014</td>
      <td>0.122409</td>
      <td>-0.449846</td>
      <td>0.672952</td>
      <td>-0.113571</td>
      <td>0.214010</td>
      <td>-0.222848</td>
      <td>-0.724162</td>
      <td>0.222460</td>
      <td>0.701434</td>
      <td>0.924924</td>
      <td>0.572962</td>
      <td>-0.794052</td>
      <td>0.277214</td>
      <td>...</td>
      <td>0.292061</td>
      <td>0.208061</td>
      <td>-0.904061</td>
      <td>-0.278718</td>
      <td>-0.627471</td>
      <td>-0.248637</td>
      <td>-0.550490</td>
      <td>0.479583</td>
      <td>0.411766</td>
      <td>-0.124964</td>
      <td>-0.138620</td>
      <td>-0.563087</td>
      <td>0.013469</td>
      <td>0.367930</td>
      <td>0.724764</td>
      <td>-0.688507</td>
      <td>-0.733963</td>
      <td>-0.436897</td>
      <td>-1.393923</td>
      <td>0.223257</td>
      <td>0.044769</td>
      <td>0.023199</td>
      <td>-0.124313</td>
      <td>0.339199</td>
      <td>0.739326</td>
      <td>0.822266</td>
      <td>0.218386</td>
      <td>0.331593</td>
      <td>0.991048</td>
      <td>-0.347391</td>
      <td>0.466899</td>
      <td>0.737936</td>
      <td>0.192524</td>
      <td>-0.429727</td>
      <td>0.227602</td>
      <td>0.532856</td>
      <td>0.135647</td>
      <td>2.455813</td>
      <td>1.440874</td>
      <td>1.458321</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.614378</td>
      <td>0.213658</td>
      <td>1.154065</td>
      <td>-0.072562</td>
      <td>-0.546733</td>
      <td>0.108981</td>
      <td>0.332264</td>
      <td>0.193220</td>
      <td>1.342726</td>
      <td>0.050693</td>
      <td>-1.250103</td>
      <td>-0.410463</td>
      <td>0.299346</td>
      <td>1.196595</td>
      <td>0.693801</td>
      <td>-0.634428</td>
      <td>0.084659</td>
      <td>0.590777</td>
      <td>0.157110</td>
      <td>0.071629</td>
      <td>0.148642</td>
      <td>0.356305</td>
      <td>-0.116333</td>
      <td>-0.033399</td>
      <td>0.711072</td>
      <td>0.039929</td>
      <td>-1.579089</td>
      <td>-0.152619</td>
      <td>0.670596</td>
      <td>-0.436327</td>
      <td>0.761802</td>
      <td>0.256101</td>
      <td>-0.150375</td>
      <td>-0.185028</td>
      <td>0.246758</td>
      <td>0.494376</td>
      <td>-0.139291</td>
      <td>0.375193</td>
      <td>0.807544</td>
      <td>0.053169</td>
      <td>...</td>
      <td>0.390088</td>
      <td>0.595101</td>
      <td>-0.054064</td>
      <td>0.437526</td>
      <td>0.076355</td>
      <td>0.589142</td>
      <td>0.167097</td>
      <td>-0.192542</td>
      <td>-0.507647</td>
      <td>-0.387736</td>
      <td>-0.688495</td>
      <td>-0.101429</td>
      <td>0.710985</td>
      <td>0.422395</td>
      <td>0.795848</td>
      <td>0.917722</td>
      <td>-0.269028</td>
      <td>-0.016553</td>
      <td>0.417027</td>
      <td>0.727564</td>
      <td>-0.058726</td>
      <td>0.357873</td>
      <td>0.308646</td>
      <td>1.109421</td>
      <td>-0.013930</td>
      <td>0.642707</td>
      <td>0.685912</td>
      <td>1.126137</td>
      <td>1.610260</td>
      <td>0.459805</td>
      <td>-0.331813</td>
      <td>0.968748</td>
      <td>0.323482</td>
      <td>-0.681230</td>
      <td>-0.225226</td>
      <td>-1.019847</td>
      <td>-1.111169</td>
      <td>2.833859</td>
      <td>2.581902</td>
      <td>0.893881</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.546679</td>
      <td>1.099696</td>
      <td>0.142008</td>
      <td>-0.482484</td>
      <td>-1.372024</td>
      <td>-0.253090</td>
      <td>-0.163589</td>
      <td>0.033525</td>
      <td>0.463102</td>
      <td>-1.012039</td>
      <td>-0.943093</td>
      <td>-1.008327</td>
      <td>0.089314</td>
      <td>-0.520044</td>
      <td>0.923776</td>
      <td>0.774051</td>
      <td>0.015102</td>
      <td>-0.382556</td>
      <td>-0.707743</td>
      <td>0.642039</td>
      <td>-0.479563</td>
      <td>-0.618416</td>
      <td>-0.123331</td>
      <td>0.266305</td>
      <td>0.491865</td>
      <td>0.472518</td>
      <td>0.477079</td>
      <td>-0.081080</td>
      <td>-0.601387</td>
      <td>-0.095162</td>
      <td>-0.527795</td>
      <td>-0.626055</td>
      <td>0.141225</td>
      <td>-0.428282</td>
      <td>0.054435</td>
      <td>-0.752053</td>
      <td>0.505818</td>
      <td>0.099604</td>
      <td>0.016993</td>
      <td>-0.421638</td>
      <td>...</td>
      <td>0.234078</td>
      <td>0.049280</td>
      <td>0.205005</td>
      <td>0.401372</td>
      <td>-0.764664</td>
      <td>-0.057142</td>
      <td>0.511727</td>
      <td>-0.255363</td>
      <td>-0.581132</td>
      <td>-0.904612</td>
      <td>-0.886914</td>
      <td>0.408174</td>
      <td>0.147244</td>
      <td>-0.772669</td>
      <td>-0.680615</td>
      <td>0.230510</td>
      <td>-0.743162</td>
      <td>-0.472615</td>
      <td>-0.746415</td>
      <td>-1.018549</td>
      <td>0.054999</td>
      <td>-0.229457</td>
      <td>0.655837</td>
      <td>0.449127</td>
      <td>-0.042646</td>
      <td>-0.022332</td>
      <td>1.001724</td>
      <td>-0.094414</td>
      <td>0.147016</td>
      <td>-0.184829</td>
      <td>0.705600</td>
      <td>0.488764</td>
      <td>-0.436498</td>
      <td>-0.344760</td>
      <td>0.575458</td>
      <td>-1.426855</td>
      <td>-0.124519</td>
      <td>-3.066390</td>
      <td>-1.984193</td>
      <td>-1.307021</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.310245</td>
      <td>-0.308300</td>
      <td>0.554801</td>
      <td>0.203594</td>
      <td>0.022346</td>
      <td>-0.452276</td>
      <td>0.869477</td>
      <td>-0.377481</td>
      <td>0.420265</td>
      <td>-0.739775</td>
      <td>-0.810097</td>
      <td>0.568874</td>
      <td>0.810095</td>
      <td>1.124864</td>
      <td>-0.505321</td>
      <td>0.557315</td>
      <td>-0.019169</td>
      <td>-0.669212</td>
      <td>-1.107422</td>
      <td>0.822906</td>
      <td>-0.521996</td>
      <td>-0.251150</td>
      <td>-0.029057</td>
      <td>0.844486</td>
      <td>-0.862449</td>
      <td>-0.217047</td>
      <td>-1.283770</td>
      <td>-0.498328</td>
      <td>-0.150960</td>
      <td>-0.026111</td>
      <td>-0.130997</td>
      <td>0.228759</td>
      <td>0.004720</td>
      <td>-0.720429</td>
      <td>-0.817110</td>
      <td>0.290921</td>
      <td>0.220807</td>
      <td>-1.155571</td>
      <td>-0.472796</td>
      <td>-0.922575</td>
      <td>...</td>
      <td>0.540273</td>
      <td>0.060598</td>
      <td>-0.173841</td>
      <td>-0.004450</td>
      <td>-0.824739</td>
      <td>0.247499</td>
      <td>0.136211</td>
      <td>0.379547</td>
      <td>-0.655810</td>
      <td>0.307218</td>
      <td>0.348190</td>
      <td>-0.428052</td>
      <td>-0.127453</td>
      <td>0.090860</td>
      <td>0.334194</td>
      <td>0.296842</td>
      <td>-0.027806</td>
      <td>0.996728</td>
      <td>0.873732</td>
      <td>0.007869</td>
      <td>0.888591</td>
      <td>-0.062424</td>
      <td>0.700667</td>
      <td>0.865241</td>
      <td>-0.003129</td>
      <td>-0.465479</td>
      <td>-1.011224</td>
      <td>-0.512093</td>
      <td>0.011564</td>
      <td>0.313063</td>
      <td>0.495333</td>
      <td>0.579050</td>
      <td>-0.440667</td>
      <td>0.002584</td>
      <td>0.060095</td>
      <td>-1.509937</td>
      <td>-0.461908</td>
      <td>-2.692507</td>
      <td>-1.472870</td>
      <td>-1.432547</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.322359</td>
      <td>-1.065404</td>
      <td>-0.680277</td>
      <td>-0.178483</td>
      <td>-0.736313</td>
      <td>-0.723377</td>
      <td>0.150472</td>
      <td>-1.377388</td>
      <td>1.367905</td>
      <td>-0.647416</td>
      <td>-0.553526</td>
      <td>-0.745911</td>
      <td>0.073914</td>
      <td>-1.231026</td>
      <td>0.350695</td>
      <td>-1.354749</td>
      <td>-1.266142</td>
      <td>-0.644256</td>
      <td>0.732335</td>
      <td>0.731442</td>
      <td>1.028173</td>
      <td>-0.621285</td>
      <td>-0.079058</td>
      <td>-0.016831</td>
      <td>-0.648816</td>
      <td>-0.816150</td>
      <td>-0.980217</td>
      <td>0.250027</td>
      <td>0.410452</td>
      <td>0.043052</td>
      <td>-0.602984</td>
      <td>-0.659543</td>
      <td>0.552708</td>
      <td>0.393403</td>
      <td>0.661488</td>
      <td>-1.334753</td>
      <td>-0.909245</td>
      <td>0.203403</td>
      <td>-0.172961</td>
      <td>0.119512</td>
      <td>...</td>
      <td>-0.150564</td>
      <td>0.910251</td>
      <td>-0.035158</td>
      <td>0.036297</td>
      <td>-0.755317</td>
      <td>-1.225699</td>
      <td>0.357818</td>
      <td>-0.690562</td>
      <td>0.368989</td>
      <td>0.680693</td>
      <td>-0.496159</td>
      <td>-1.000079</td>
      <td>0.995972</td>
      <td>-0.148906</td>
      <td>0.379396</td>
      <td>-0.241344</td>
      <td>0.105023</td>
      <td>0.271400</td>
      <td>0.446995</td>
      <td>0.438243</td>
      <td>-0.439216</td>
      <td>-0.321214</td>
      <td>0.585753</td>
      <td>0.004727</td>
      <td>-0.189685</td>
      <td>0.138972</td>
      <td>1.096393</td>
      <td>-0.025635</td>
      <td>0.023278</td>
      <td>-0.097897</td>
      <td>0.684616</td>
      <td>-0.261427</td>
      <td>-0.787667</td>
      <td>-0.976469</td>
      <td>-0.023643</td>
      <td>-0.703681</td>
      <td>-0.052549</td>
      <td>-2.309632</td>
      <td>-1.343136</td>
      <td>-0.834450</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.697738</td>
      <td>-0.280805</td>
      <td>-0.100332</td>
      <td>1.105103</td>
      <td>-0.408402</td>
      <td>-0.087218</td>
      <td>-0.000359</td>
      <td>-1.696367</td>
      <td>0.354983</td>
      <td>-0.160666</td>
      <td>-0.338548</td>
      <td>0.427431</td>
      <td>0.638027</td>
      <td>1.086427</td>
      <td>0.378281</td>
      <td>0.124884</td>
      <td>1.214652</td>
      <td>0.978188</td>
      <td>0.222787</td>
      <td>0.553443</td>
      <td>0.178547</td>
      <td>-0.300907</td>
      <td>0.057711</td>
      <td>-0.092933</td>
      <td>-0.349141</td>
      <td>-0.023671</td>
      <td>0.281725</td>
      <td>0.367605</td>
      <td>-0.026019</td>
      <td>0.383883</td>
      <td>-0.212652</td>
      <td>0.048937</td>
      <td>0.355914</td>
      <td>-0.343436</td>
      <td>-0.459335</td>
      <td>-0.749852</td>
      <td>0.030170</td>
      <td>0.110812</td>
      <td>-1.157357</td>
      <td>-0.323143</td>
      <td>...</td>
      <td>0.650678</td>
      <td>1.291219</td>
      <td>0.794610</td>
      <td>0.812168</td>
      <td>-0.057131</td>
      <td>-0.465942</td>
      <td>-0.237444</td>
      <td>-0.406762</td>
      <td>0.320876</td>
      <td>0.285422</td>
      <td>0.555042</td>
      <td>-1.170029</td>
      <td>-0.135645</td>
      <td>-0.617005</td>
      <td>-0.066858</td>
      <td>-0.637427</td>
      <td>-0.249846</td>
      <td>0.857376</td>
      <td>-0.386708</td>
      <td>-0.209530</td>
      <td>0.263690</td>
      <td>0.084784</td>
      <td>0.073958</td>
      <td>0.387222</td>
      <td>0.289652</td>
      <td>0.435961</td>
      <td>0.459010</td>
      <td>0.301265</td>
      <td>0.176672</td>
      <td>0.218335</td>
      <td>0.995885</td>
      <td>0.084481</td>
      <td>-0.578672</td>
      <td>-0.033077</td>
      <td>0.463643</td>
      <td>-0.095384</td>
      <td>0.226554</td>
      <td>0.590533</td>
      <td>0.203464</td>
      <td>0.104345</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.505297</td>
      <td>0.133137</td>
      <td>-0.413707</td>
      <td>0.565562</td>
      <td>-0.136898</td>
      <td>-0.005190</td>
      <td>-0.119904</td>
      <td>-0.962012</td>
      <td>0.292968</td>
      <td>-0.421932</td>
      <td>0.073568</td>
      <td>-0.088654</td>
      <td>0.777300</td>
      <td>0.410492</td>
      <td>-0.711471</td>
      <td>-0.338859</td>
      <td>-0.406745</td>
      <td>-0.669579</td>
      <td>1.182609</td>
      <td>0.257828</td>
      <td>0.124488</td>
      <td>0.265075</td>
      <td>-0.275989</td>
      <td>-0.648111</td>
      <td>-0.416252</td>
      <td>0.144787</td>
      <td>-0.675571</td>
      <td>1.119620</td>
      <td>0.472379</td>
      <td>0.477702</td>
      <td>-1.090819</td>
      <td>0.034593</td>
      <td>1.341066</td>
      <td>-0.379114</td>
      <td>-0.705463</td>
      <td>-0.623584</td>
      <td>-0.639197</td>
      <td>-0.302610</td>
      <td>-0.136140</td>
      <td>-0.143118</td>
      <td>...</td>
      <td>-0.343621</td>
      <td>0.697570</td>
      <td>-0.746486</td>
      <td>0.153368</td>
      <td>1.482176</td>
      <td>-0.766043</td>
      <td>-0.018990</td>
      <td>0.919892</td>
      <td>-0.434663</td>
      <td>-0.427239</td>
      <td>-0.577219</td>
      <td>-1.375275</td>
      <td>0.412487</td>
      <td>-0.213556</td>
      <td>0.141130</td>
      <td>-0.329553</td>
      <td>0.415144</td>
      <td>0.183537</td>
      <td>0.676197</td>
      <td>-0.373672</td>
      <td>-0.007612</td>
      <td>1.292861</td>
      <td>1.134451</td>
      <td>0.668512</td>
      <td>0.364124</td>
      <td>-0.800237</td>
      <td>-0.332760</td>
      <td>0.634519</td>
      <td>0.783726</td>
      <td>0.433043</td>
      <td>0.050749</td>
      <td>1.769778</td>
      <td>0.356177</td>
      <td>0.152910</td>
      <td>0.065967</td>
      <td>-1.037113</td>
      <td>-1.088029</td>
      <td>-2.567027</td>
      <td>-1.879894</td>
      <td>-0.856937</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.143961</td>
      <td>-0.408985</td>
      <td>-0.025620</td>
      <td>-0.596339</td>
      <td>-0.583943</td>
      <td>-0.389785</td>
      <td>-0.003484</td>
      <td>0.611459</td>
      <td>0.767285</td>
      <td>0.168979</td>
      <td>-0.140537</td>
      <td>-0.319924</td>
      <td>0.601992</td>
      <td>-0.106859</td>
      <td>0.416512</td>
      <td>0.572173</td>
      <td>0.019844</td>
      <td>-0.096107</td>
      <td>0.726975</td>
      <td>0.015660</td>
      <td>-0.706344</td>
      <td>-0.338747</td>
      <td>-0.727933</td>
      <td>0.541172</td>
      <td>0.029450</td>
      <td>0.411742</td>
      <td>-0.485491</td>
      <td>0.937935</td>
      <td>-1.289262</td>
      <td>0.082743</td>
      <td>-0.797104</td>
      <td>-0.388850</td>
      <td>0.029856</td>
      <td>-0.024744</td>
      <td>-0.513238</td>
      <td>-0.474293</td>
      <td>-0.448684</td>
      <td>0.243225</td>
      <td>-0.356003</td>
      <td>-0.723238</td>
      <td>...</td>
      <td>-0.128290</td>
      <td>-0.842609</td>
      <td>0.185863</td>
      <td>0.621026</td>
      <td>-0.034335</td>
      <td>0.315223</td>
      <td>-0.630105</td>
      <td>0.693133</td>
      <td>0.105127</td>
      <td>0.326706</td>
      <td>0.236678</td>
      <td>0.103588</td>
      <td>0.208407</td>
      <td>0.013578</td>
      <td>0.481592</td>
      <td>0.223503</td>
      <td>-1.505307</td>
      <td>0.248411</td>
      <td>-0.507727</td>
      <td>-0.106537</td>
      <td>0.147602</td>
      <td>1.445730</td>
      <td>1.208219</td>
      <td>0.769648</td>
      <td>0.245217</td>
      <td>0.340459</td>
      <td>0.972717</td>
      <td>-0.265906</td>
      <td>0.558116</td>
      <td>0.362039</td>
      <td>0.090590</td>
      <td>0.299864</td>
      <td>-0.535348</td>
      <td>-0.387079</td>
      <td>0.753366</td>
      <td>-0.663957</td>
      <td>-0.022763</td>
      <td>-1.529102</td>
      <td>-1.056719</td>
      <td>-0.368064</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-1.597284</td>
      <td>-0.080151</td>
      <td>0.400994</td>
      <td>-0.249372</td>
      <td>-0.264624</td>
      <td>-0.080322</td>
      <td>-0.459573</td>
      <td>-0.163463</td>
      <td>0.405538</td>
      <td>-0.211982</td>
      <td>0.177077</td>
      <td>-0.537469</td>
      <td>-0.315057</td>
      <td>-0.267109</td>
      <td>0.141904</td>
      <td>0.041557</td>
      <td>-0.783819</td>
      <td>0.082087</td>
      <td>0.636099</td>
      <td>1.131788</td>
      <td>0.417614</td>
      <td>-0.012561</td>
      <td>0.741130</td>
      <td>0.156435</td>
      <td>-0.372254</td>
      <td>0.091933</td>
      <td>-0.947115</td>
      <td>0.400562</td>
      <td>0.611449</td>
      <td>1.324555</td>
      <td>-0.213484</td>
      <td>-0.919760</td>
      <td>0.157267</td>
      <td>-0.299754</td>
      <td>0.981648</td>
      <td>0.183245</td>
      <td>-0.716047</td>
      <td>-1.528477</td>
      <td>-0.726797</td>
      <td>0.095686</td>
      <td>...</td>
      <td>-0.386222</td>
      <td>0.442491</td>
      <td>-0.057921</td>
      <td>-0.392279</td>
      <td>0.442938</td>
      <td>-0.363905</td>
      <td>-0.545669</td>
      <td>-1.466380</td>
      <td>-0.343191</td>
      <td>0.391196</td>
      <td>0.161901</td>
      <td>-1.244615</td>
      <td>-0.395878</td>
      <td>-0.439104</td>
      <td>0.825689</td>
      <td>-0.684351</td>
      <td>-0.385230</td>
      <td>0.504197</td>
      <td>1.000419</td>
      <td>0.111056</td>
      <td>-0.051267</td>
      <td>0.028275</td>
      <td>0.034420</td>
      <td>0.427218</td>
      <td>0.821014</td>
      <td>0.578752</td>
      <td>0.889720</td>
      <td>0.650487</td>
      <td>0.353534</td>
      <td>-0.067383</td>
      <td>-0.361447</td>
      <td>-1.011968</td>
      <td>-1.152046</td>
      <td>0.537233</td>
      <td>0.498149</td>
      <td>-0.220329</td>
      <td>0.580408</td>
      <td>-1.953240</td>
      <td>-1.687309</td>
      <td>-1.490889</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-1.551358</td>
      <td>-0.082628</td>
      <td>0.231962</td>
      <td>0.743964</td>
      <td>0.509461</td>
      <td>-0.707262</td>
      <td>0.037494</td>
      <td>-0.094111</td>
      <td>0.148047</td>
      <td>0.446043</td>
      <td>-0.858487</td>
      <td>-1.287772</td>
      <td>-0.329979</td>
      <td>-0.117957</td>
      <td>-0.420531</td>
      <td>-0.740072</td>
      <td>0.264592</td>
      <td>0.399415</td>
      <td>0.010861</td>
      <td>1.552750</td>
      <td>-0.487871</td>
      <td>-1.264876</td>
      <td>-0.031992</td>
      <td>-0.038943</td>
      <td>0.943165</td>
      <td>0.419493</td>
      <td>-0.797119</td>
      <td>-0.174749</td>
      <td>-0.205979</td>
      <td>0.388121</td>
      <td>0.201345</td>
      <td>0.513655</td>
      <td>0.493517</td>
      <td>1.262499</td>
      <td>0.238110</td>
      <td>0.027101</td>
      <td>-0.580335</td>
      <td>-0.467108</td>
      <td>-0.712379</td>
      <td>-0.435229</td>
      <td>...</td>
      <td>0.630657</td>
      <td>-0.595620</td>
      <td>-0.710260</td>
      <td>0.682426</td>
      <td>-0.386247</td>
      <td>-0.313390</td>
      <td>-0.444265</td>
      <td>-0.279144</td>
      <td>0.425787</td>
      <td>-0.944941</td>
      <td>-0.923636</td>
      <td>-0.243747</td>
      <td>-0.461291</td>
      <td>-0.934590</td>
      <td>-0.277886</td>
      <td>-0.328492</td>
      <td>-0.460177</td>
      <td>1.024146</td>
      <td>0.258103</td>
      <td>-0.036317</td>
      <td>0.011919</td>
      <td>0.813946</td>
      <td>1.032141</td>
      <td>0.316980</td>
      <td>1.067505</td>
      <td>-0.269789</td>
      <td>0.423650</td>
      <td>-1.146070</td>
      <td>-0.867182</td>
      <td>-0.569320</td>
      <td>0.020930</td>
      <td>0.271938</td>
      <td>-0.278381</td>
      <td>-0.476333</td>
      <td>0.956170</td>
      <td>-0.893542</td>
      <td>-0.962774</td>
      <td>-2.729298</td>
      <td>-1.449262</td>
      <td>-0.620734</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-0.980729</td>
      <td>-2.030853</td>
      <td>-0.059350</td>
      <td>-0.531640</td>
      <td>-0.260410</td>
      <td>0.129873</td>
      <td>0.127909</td>
      <td>0.021297</td>
      <td>0.082925</td>
      <td>0.486164</td>
      <td>-0.098187</td>
      <td>-0.098420</td>
      <td>-0.062733</td>
      <td>0.745464</td>
      <td>0.369688</td>
      <td>0.366564</td>
      <td>0.683246</td>
      <td>0.978198</td>
      <td>0.340601</td>
      <td>1.449673</td>
      <td>0.776823</td>
      <td>-0.688621</td>
      <td>-0.700947</td>
      <td>-1.299526</td>
      <td>-0.967600</td>
      <td>-0.417998</td>
      <td>0.988336</td>
      <td>0.113916</td>
      <td>1.349317</td>
      <td>0.556686</td>
      <td>0.148828</td>
      <td>-0.868250</td>
      <td>-0.140624</td>
      <td>-1.169686</td>
      <td>-0.913797</td>
      <td>-1.532381</td>
      <td>-0.797825</td>
      <td>0.101077</td>
      <td>0.063257</td>
      <td>-0.062851</td>
      <td>...</td>
      <td>0.181500</td>
      <td>-0.215676</td>
      <td>-0.265155</td>
      <td>-0.094595</td>
      <td>0.366164</td>
      <td>0.653778</td>
      <td>0.304368</td>
      <td>-0.377556</td>
      <td>0.829777</td>
      <td>0.203717</td>
      <td>-0.304288</td>
      <td>-1.369933</td>
      <td>1.109188</td>
      <td>-0.918038</td>
      <td>-0.109984</td>
      <td>-0.315791</td>
      <td>0.476165</td>
      <td>-0.104152</td>
      <td>-0.122718</td>
      <td>-0.075515</td>
      <td>0.085891</td>
      <td>1.193620</td>
      <td>0.569342</td>
      <td>-0.347073</td>
      <td>0.404350</td>
      <td>-0.271117</td>
      <td>0.547546</td>
      <td>1.638569</td>
      <td>0.187494</td>
      <td>0.324441</td>
      <td>0.180643</td>
      <td>0.087733</td>
      <td>-0.745454</td>
      <td>-0.553720</td>
      <td>0.236536</td>
      <td>-1.080520</td>
      <td>-0.990675</td>
      <td>-3.195672</td>
      <td>-1.208461</td>
      <td>0.304870</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.521386</td>
      <td>-0.131662</td>
      <td>0.454476</td>
      <td>0.251941</td>
      <td>0.556572</td>
      <td>-0.133940</td>
      <td>-0.219749</td>
      <td>-0.225302</td>
      <td>0.304930</td>
      <td>-0.101001</td>
      <td>-0.688846</td>
      <td>0.766997</td>
      <td>0.090237</td>
      <td>-0.868269</td>
      <td>0.458017</td>
      <td>0.250702</td>
      <td>-0.868056</td>
      <td>-0.648393</td>
      <td>-0.441842</td>
      <td>0.569172</td>
      <td>-0.064906</td>
      <td>-1.065607</td>
      <td>-0.197578</td>
      <td>-0.706122</td>
      <td>0.036452</td>
      <td>-0.083905</td>
      <td>0.247297</td>
      <td>1.127930</td>
      <td>-0.220083</td>
      <td>0.233930</td>
      <td>-0.511435</td>
      <td>-0.114352</td>
      <td>-0.284521</td>
      <td>-1.326217</td>
      <td>-0.887680</td>
      <td>-0.076567</td>
      <td>-0.535500</td>
      <td>-0.628699</td>
      <td>-0.256759</td>
      <td>0.142186</td>
      <td>...</td>
      <td>0.784937</td>
      <td>-0.102754</td>
      <td>-0.368924</td>
      <td>-0.689652</td>
      <td>-0.067459</td>
      <td>-0.218493</td>
      <td>-1.095623</td>
      <td>-0.929135</td>
      <td>-0.352737</td>
      <td>-0.082103</td>
      <td>0.230105</td>
      <td>-0.035188</td>
      <td>0.980196</td>
      <td>0.047572</td>
      <td>0.677139</td>
      <td>0.205780</td>
      <td>-0.618089</td>
      <td>0.200683</td>
      <td>0.473444</td>
      <td>0.846740</td>
      <td>0.527189</td>
      <td>0.044693</td>
      <td>0.536973</td>
      <td>-0.342292</td>
      <td>0.188517</td>
      <td>0.939450</td>
      <td>1.096030</td>
      <td>0.488292</td>
      <td>1.321255</td>
      <td>0.104908</td>
      <td>0.125433</td>
      <td>-0.227139</td>
      <td>0.029770</td>
      <td>-1.219239</td>
      <td>0.295974</td>
      <td>-0.688040</td>
      <td>-0.934304</td>
      <td>-1.048587</td>
      <td>-0.444230</td>
      <td>-0.406674</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-0.272635</td>
      <td>-0.329441</td>
      <td>-0.174706</td>
      <td>-0.004977</td>
      <td>0.913583</td>
      <td>0.601928</td>
      <td>0.093106</td>
      <td>0.359573</td>
      <td>0.062026</td>
      <td>-1.498539</td>
      <td>-1.292996</td>
      <td>-0.899020</td>
      <td>1.040567</td>
      <td>0.102749</td>
      <td>0.519650</td>
      <td>0.589883</td>
      <td>-0.463371</td>
      <td>0.189611</td>
      <td>0.305753</td>
      <td>0.686094</td>
      <td>0.178660</td>
      <td>-0.413028</td>
      <td>-0.398854</td>
      <td>0.226650</td>
      <td>-1.839258</td>
      <td>-1.211009</td>
      <td>0.007423</td>
      <td>-0.108434</td>
      <td>0.278900</td>
      <td>0.213841</td>
      <td>-0.329691</td>
      <td>-0.070359</td>
      <td>0.426059</td>
      <td>-0.661827</td>
      <td>-0.154498</td>
      <td>0.184507</td>
      <td>-0.176894</td>
      <td>-0.190122</td>
      <td>0.176819</td>
      <td>-0.045384</td>
      <td>...</td>
      <td>0.319358</td>
      <td>0.215655</td>
      <td>-0.095634</td>
      <td>0.235092</td>
      <td>0.344228</td>
      <td>0.061876</td>
      <td>-0.400933</td>
      <td>0.248747</td>
      <td>-0.168939</td>
      <td>-0.874855</td>
      <td>-0.976825</td>
      <td>-0.843283</td>
      <td>-0.877927</td>
      <td>-0.540523</td>
      <td>0.474651</td>
      <td>0.879756</td>
      <td>0.344340</td>
      <td>-0.106905</td>
      <td>-0.135795</td>
      <td>0.115918</td>
      <td>-1.290790</td>
      <td>-0.183323</td>
      <td>0.790364</td>
      <td>-0.475430</td>
      <td>-0.026170</td>
      <td>0.617610</td>
      <td>0.674846</td>
      <td>-0.095284</td>
      <td>0.337298</td>
      <td>0.655457</td>
      <td>-0.286627</td>
      <td>0.248879</td>
      <td>-0.194792</td>
      <td>-1.403918</td>
      <td>-0.289633</td>
      <td>-1.184821</td>
      <td>-1.044989</td>
      <td>-0.712034</td>
      <td>-0.415840</td>
      <td>-0.316356</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-1.085563</td>
      <td>-0.120264</td>
      <td>-0.503545</td>
      <td>-0.475693</td>
      <td>-0.523027</td>
      <td>0.185646</td>
      <td>0.372280</td>
      <td>0.139927</td>
      <td>0.937710</td>
      <td>-0.175940</td>
      <td>-0.013034</td>
      <td>0.468785</td>
      <td>0.169531</td>
      <td>-0.512008</td>
      <td>0.212588</td>
      <td>0.269803</td>
      <td>-0.497291</td>
      <td>-1.174014</td>
      <td>-0.218672</td>
      <td>0.524870</td>
      <td>-0.821716</td>
      <td>-0.115873</td>
      <td>-0.256852</td>
      <td>1.079561</td>
      <td>-0.107321</td>
      <td>0.616856</td>
      <td>0.364040</td>
      <td>0.064163</td>
      <td>0.483417</td>
      <td>0.412603</td>
      <td>-0.140976</td>
      <td>0.189956</td>
      <td>0.064037</td>
      <td>-0.444018</td>
      <td>0.202905</td>
      <td>-0.115773</td>
      <td>0.218062</td>
      <td>-0.086731</td>
      <td>-0.511238</td>
      <td>0.045568</td>
      <td>...</td>
      <td>0.362549</td>
      <td>-0.039811</td>
      <td>-0.333780</td>
      <td>-0.676058</td>
      <td>-0.706085</td>
      <td>0.250795</td>
      <td>-0.317533</td>
      <td>0.222506</td>
      <td>-0.604550</td>
      <td>-0.549376</td>
      <td>-0.074832</td>
      <td>-0.839463</td>
      <td>0.182457</td>
      <td>-0.861052</td>
      <td>1.310083</td>
      <td>0.800486</td>
      <td>0.268630</td>
      <td>0.526042</td>
      <td>0.523609</td>
      <td>-0.947657</td>
      <td>-0.526075</td>
      <td>0.281909</td>
      <td>0.334175</td>
      <td>0.390282</td>
      <td>0.353878</td>
      <td>0.268494</td>
      <td>0.580677</td>
      <td>0.693399</td>
      <td>0.690485</td>
      <td>-0.154345</td>
      <td>0.252570</td>
      <td>0.370813</td>
      <td>-0.299376</td>
      <td>0.622826</td>
      <td>0.519462</td>
      <td>0.227076</td>
      <td>-0.618144</td>
      <td>-3.101760</td>
      <td>-1.938793</td>
      <td>-0.774600</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.861495</td>
      <td>-0.448546</td>
      <td>1.233049</td>
      <td>0.459397</td>
      <td>-0.312407</td>
      <td>0.067666</td>
      <td>0.429703</td>
      <td>-0.749746</td>
      <td>0.206783</td>
      <td>0.229532</td>
      <td>0.476252</td>
      <td>-0.547665</td>
      <td>0.184206</td>
      <td>0.084582</td>
      <td>0.140174</td>
      <td>0.207617</td>
      <td>-0.156397</td>
      <td>-0.409690</td>
      <td>-0.180593</td>
      <td>0.049670</td>
      <td>-0.687673</td>
      <td>0.449368</td>
      <td>-0.219257</td>
      <td>0.000367</td>
      <td>-0.567656</td>
      <td>-0.184707</td>
      <td>-0.496214</td>
      <td>-0.368541</td>
      <td>0.043005</td>
      <td>0.865798</td>
      <td>-0.197066</td>
      <td>-0.195231</td>
      <td>-0.264618</td>
      <td>-0.608785</td>
      <td>-0.276672</td>
      <td>-0.556052</td>
      <td>-0.780536</td>
      <td>-0.049863</td>
      <td>0.191442</td>
      <td>-0.734896</td>
      <td>...</td>
      <td>0.626921</td>
      <td>-0.121625</td>
      <td>-0.897981</td>
      <td>0.240471</td>
      <td>-0.722899</td>
      <td>-0.229798</td>
      <td>-0.151502</td>
      <td>0.010789</td>
      <td>-0.079464</td>
      <td>-0.916831</td>
      <td>-0.726069</td>
      <td>-0.519957</td>
      <td>0.137460</td>
      <td>0.605099</td>
      <td>-0.076646</td>
      <td>0.280905</td>
      <td>-0.143437</td>
      <td>0.412637</td>
      <td>0.320626</td>
      <td>-0.638565</td>
      <td>0.038535</td>
      <td>1.079773</td>
      <td>1.643186</td>
      <td>0.863399</td>
      <td>-0.047612</td>
      <td>0.427032</td>
      <td>0.224801</td>
      <td>0.801287</td>
      <td>0.821798</td>
      <td>0.338459</td>
      <td>0.300110</td>
      <td>-0.430737</td>
      <td>0.431490</td>
      <td>0.274476</td>
      <td>0.020839</td>
      <td>-0.093699</td>
      <td>-0.317644</td>
      <td>-0.488219</td>
      <td>-0.085907</td>
      <td>-0.630238</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-1.047541</td>
      <td>0.039904</td>
      <td>-0.006983</td>
      <td>0.251594</td>
      <td>-0.171631</td>
      <td>-0.172218</td>
      <td>0.223132</td>
      <td>-0.459450</td>
      <td>-0.350445</td>
      <td>-0.283051</td>
      <td>-0.558631</td>
      <td>-1.034937</td>
      <td>-0.322209</td>
      <td>-0.030267</td>
      <td>1.043900</td>
      <td>-0.004031</td>
      <td>-0.228003</td>
      <td>-0.456947</td>
      <td>-0.435189</td>
      <td>0.061663</td>
      <td>0.491146</td>
      <td>-1.395280</td>
      <td>-0.997621</td>
      <td>-0.007987</td>
      <td>-0.105369</td>
      <td>0.022672</td>
      <td>-0.311550</td>
      <td>0.684376</td>
      <td>0.629770</td>
      <td>0.031621</td>
      <td>0.395995</td>
      <td>-0.307122</td>
      <td>-0.955118</td>
      <td>-0.165212</td>
      <td>-0.259906</td>
      <td>-0.546716</td>
      <td>0.184886</td>
      <td>-0.070160</td>
      <td>-0.436069</td>
      <td>-0.520681</td>
      <td>...</td>
      <td>-0.227069</td>
      <td>0.540358</td>
      <td>-0.023066</td>
      <td>0.184267</td>
      <td>0.906039</td>
      <td>0.612267</td>
      <td>0.211921</td>
      <td>-0.194654</td>
      <td>0.045358</td>
      <td>-1.527496</td>
      <td>-0.120218</td>
      <td>-0.098749</td>
      <td>0.863860</td>
      <td>1.164888</td>
      <td>1.178240</td>
      <td>0.013708</td>
      <td>-0.569992</td>
      <td>0.388192</td>
      <td>0.213784</td>
      <td>0.203904</td>
      <td>-0.630007</td>
      <td>0.176629</td>
      <td>-1.014567</td>
      <td>0.209730</td>
      <td>0.529634</td>
      <td>-0.220987</td>
      <td>0.096422</td>
      <td>0.755055</td>
      <td>-0.096527</td>
      <td>-0.375701</td>
      <td>0.584317</td>
      <td>-0.312041</td>
      <td>0.717154</td>
      <td>0.411744</td>
      <td>0.598112</td>
      <td>-0.642175</td>
      <td>-1.304675</td>
      <td>-2.012236</td>
      <td>-1.210548</td>
      <td>-0.895155</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-0.449753</td>
      <td>-0.365485</td>
      <td>0.397412</td>
      <td>-0.088331</td>
      <td>0.168791</td>
      <td>0.545020</td>
      <td>0.033519</td>
      <td>-0.358736</td>
      <td>0.504343</td>
      <td>-1.357956</td>
      <td>-0.671032</td>
      <td>-0.524674</td>
      <td>0.206009</td>
      <td>-0.805078</td>
      <td>-0.340086</td>
      <td>-0.503038</td>
      <td>0.208074</td>
      <td>-0.567213</td>
      <td>-0.017253</td>
      <td>0.027603</td>
      <td>-0.134674</td>
      <td>-0.141773</td>
      <td>0.468586</td>
      <td>0.590242</td>
      <td>0.623023</td>
      <td>0.401646</td>
      <td>-0.039132</td>
      <td>1.465916</td>
      <td>0.220702</td>
      <td>0.568739</td>
      <td>-0.799828</td>
      <td>-0.789984</td>
      <td>0.050830</td>
      <td>-0.953892</td>
      <td>-0.669546</td>
      <td>-0.641555</td>
      <td>-0.758945</td>
      <td>-0.640878</td>
      <td>0.707989</td>
      <td>0.032172</td>
      <td>...</td>
      <td>0.018829</td>
      <td>1.295823</td>
      <td>-0.953244</td>
      <td>0.010552</td>
      <td>-0.062572</td>
      <td>0.358812</td>
      <td>0.507315</td>
      <td>0.066978</td>
      <td>0.001794</td>
      <td>0.241576</td>
      <td>-0.438836</td>
      <td>-1.217032</td>
      <td>-0.735522</td>
      <td>-0.477797</td>
      <td>-0.066474</td>
      <td>-0.256685</td>
      <td>0.469656</td>
      <td>0.758758</td>
      <td>1.058748</td>
      <td>0.314818</td>
      <td>-0.410370</td>
      <td>-0.142038</td>
      <td>-0.136015</td>
      <td>-0.612963</td>
      <td>0.001266</td>
      <td>-0.423642</td>
      <td>-0.351681</td>
      <td>0.539163</td>
      <td>-0.346987</td>
      <td>-0.329408</td>
      <td>0.197954</td>
      <td>0.337924</td>
      <td>-0.598651</td>
      <td>-0.423897</td>
      <td>-0.302377</td>
      <td>-2.067170</td>
      <td>-1.404220</td>
      <td>-1.392297</td>
      <td>-0.316227</td>
      <td>-0.229759</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-1.172939</td>
      <td>-0.149238</td>
      <td>0.071178</td>
      <td>-0.373844</td>
      <td>-0.322898</td>
      <td>-0.127024</td>
      <td>0.518153</td>
      <td>-1.499402</td>
      <td>-0.699625</td>
      <td>-1.025560</td>
      <td>-0.493314</td>
      <td>-0.732911</td>
      <td>1.108398</td>
      <td>0.750878</td>
      <td>1.064828</td>
      <td>1.233987</td>
      <td>0.396773</td>
      <td>-0.341684</td>
      <td>-0.552438</td>
      <td>-0.312386</td>
      <td>0.623091</td>
      <td>0.587694</td>
      <td>0.067967</td>
      <td>0.547732</td>
      <td>0.048296</td>
      <td>-0.615796</td>
      <td>-1.187525</td>
      <td>0.442110</td>
      <td>0.040997</td>
      <td>-0.196908</td>
      <td>-0.147059</td>
      <td>0.169937</td>
      <td>0.002407</td>
      <td>0.022382</td>
      <td>-1.295749</td>
      <td>-0.497675</td>
      <td>0.310430</td>
      <td>-0.696365</td>
      <td>-0.552234</td>
      <td>-0.038682</td>
      <td>...</td>
      <td>0.091993</td>
      <td>-0.678685</td>
      <td>-0.668783</td>
      <td>1.110718</td>
      <td>0.589510</td>
      <td>-0.437024</td>
      <td>-0.982085</td>
      <td>-0.572526</td>
      <td>-0.581416</td>
      <td>-0.877835</td>
      <td>-0.096248</td>
      <td>-0.446238</td>
      <td>0.506480</td>
      <td>0.234574</td>
      <td>0.850704</td>
      <td>0.799689</td>
      <td>-0.372574</td>
      <td>-0.859694</td>
      <td>-0.546011</td>
      <td>-0.274043</td>
      <td>0.299260</td>
      <td>0.564845</td>
      <td>-0.366105</td>
      <td>0.388265</td>
      <td>-0.232674</td>
      <td>-0.068227</td>
      <td>0.404402</td>
      <td>0.433513</td>
      <td>0.348825</td>
      <td>0.855996</td>
      <td>-0.256548</td>
      <td>-0.197974</td>
      <td>-0.435832</td>
      <td>0.074370</td>
      <td>-0.392729</td>
      <td>-0.764118</td>
      <td>0.359882</td>
      <td>-3.026174</td>
      <td>-1.721387</td>
      <td>-0.342341</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.489315</td>
      <td>-0.315800</td>
      <td>0.591131</td>
      <td>0.942964</td>
      <td>-0.629921</td>
      <td>0.182242</td>
      <td>0.075774</td>
      <td>-0.167172</td>
      <td>0.412696</td>
      <td>-0.053303</td>
      <td>1.554473</td>
      <td>0.380071</td>
      <td>-0.052409</td>
      <td>0.274696</td>
      <td>0.332426</td>
      <td>-0.964010</td>
      <td>-0.380662</td>
      <td>-0.408448</td>
      <td>-0.120322</td>
      <td>-0.407100</td>
      <td>0.329809</td>
      <td>0.290305</td>
      <td>-0.785420</td>
      <td>0.319379</td>
      <td>-0.166746</td>
      <td>0.039619</td>
      <td>-0.120245</td>
      <td>0.259078</td>
      <td>0.092048</td>
      <td>-0.230831</td>
      <td>-0.793121</td>
      <td>0.000945</td>
      <td>0.130550</td>
      <td>-1.233112</td>
      <td>1.097217</td>
      <td>-0.023359</td>
      <td>0.314266</td>
      <td>0.059769</td>
      <td>-1.092549</td>
      <td>-0.935832</td>
      <td>...</td>
      <td>0.416824</td>
      <td>-0.276761</td>
      <td>-0.665722</td>
      <td>0.066118</td>
      <td>-0.041672</td>
      <td>-0.067823</td>
      <td>-1.287338</td>
      <td>-0.407455</td>
      <td>-0.538914</td>
      <td>0.175188</td>
      <td>0.729740</td>
      <td>0.242993</td>
      <td>-0.045634</td>
      <td>-0.304940</td>
      <td>-0.224672</td>
      <td>0.130172</td>
      <td>1.190310</td>
      <td>1.262775</td>
      <td>0.660721</td>
      <td>-0.097500</td>
      <td>-0.697191</td>
      <td>0.654535</td>
      <td>0.568487</td>
      <td>0.477954</td>
      <td>-0.370824</td>
      <td>0.715521</td>
      <td>0.880478</td>
      <td>0.105630</td>
      <td>0.343374</td>
      <td>0.476715</td>
      <td>-0.566334</td>
      <td>-1.073624</td>
      <td>-0.920421</td>
      <td>-0.189615</td>
      <td>-0.067228</td>
      <td>-0.409536</td>
      <td>0.757687</td>
      <td>-1.966546</td>
      <td>-0.477917</td>
      <td>-0.386404</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.509000</td>
      <td>-0.136686</td>
      <td>0.000337</td>
      <td>0.143100</td>
      <td>-0.466836</td>
      <td>-0.106143</td>
      <td>0.392293</td>
      <td>-0.500597</td>
      <td>0.334351</td>
      <td>-1.002805</td>
      <td>0.246007</td>
      <td>-0.333722</td>
      <td>0.343689</td>
      <td>1.356862</td>
      <td>0.135028</td>
      <td>0.055074</td>
      <td>-1.328030</td>
      <td>-1.280621</td>
      <td>-0.067552</td>
      <td>1.060190</td>
      <td>0.145494</td>
      <td>0.350140</td>
      <td>0.274690</td>
      <td>-0.346054</td>
      <td>0.500822</td>
      <td>-0.033132</td>
      <td>-0.523187</td>
      <td>0.638010</td>
      <td>0.646637</td>
      <td>-1.085892</td>
      <td>-0.593907</td>
      <td>0.690258</td>
      <td>-0.192977</td>
      <td>0.119872</td>
      <td>0.175098</td>
      <td>-0.575266</td>
      <td>-0.374454</td>
      <td>-0.494460</td>
      <td>-0.035672</td>
      <td>-0.857953</td>
      <td>...</td>
      <td>0.770932</td>
      <td>-0.233375</td>
      <td>-0.239959</td>
      <td>1.025156</td>
      <td>0.404053</td>
      <td>0.814851</td>
      <td>-0.777176</td>
      <td>-1.384607</td>
      <td>-0.164602</td>
      <td>-0.702381</td>
      <td>-0.266720</td>
      <td>-0.207524</td>
      <td>0.848968</td>
      <td>0.175937</td>
      <td>-0.385136</td>
      <td>-0.254741</td>
      <td>-0.401824</td>
      <td>0.690949</td>
      <td>-0.555573</td>
      <td>-0.540554</td>
      <td>0.220360</td>
      <td>1.693035</td>
      <td>0.574368</td>
      <td>0.013645</td>
      <td>0.100030</td>
      <td>-0.942004</td>
      <td>-0.198062</td>
      <td>0.710387</td>
      <td>0.964849</td>
      <td>0.536251</td>
      <td>0.549809</td>
      <td>0.947389</td>
      <td>0.154313</td>
      <td>-0.321541</td>
      <td>-0.020952</td>
      <td>0.010410</td>
      <td>1.186072</td>
      <td>-0.520774</td>
      <td>-0.238516</td>
      <td>0.102234</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.823831</td>
      <td>-0.038422</td>
      <td>0.786408</td>
      <td>-0.200482</td>
      <td>-0.006522</td>
      <td>-0.675979</td>
      <td>0.537720</td>
      <td>0.171502</td>
      <td>0.771112</td>
      <td>0.018510</td>
      <td>0.521676</td>
      <td>-0.286017</td>
      <td>0.951732</td>
      <td>0.026266</td>
      <td>-0.220157</td>
      <td>0.033524</td>
      <td>-0.674325</td>
      <td>-2.040146</td>
      <td>-0.375001</td>
      <td>0.309767</td>
      <td>0.292533</td>
      <td>0.668173</td>
      <td>-0.341121</td>
      <td>1.202933</td>
      <td>-0.938581</td>
      <td>-0.732571</td>
      <td>-1.197075</td>
      <td>-0.014307</td>
      <td>-0.205929</td>
      <td>-0.092101</td>
      <td>0.976928</td>
      <td>0.262357</td>
      <td>-0.927364</td>
      <td>-0.342189</td>
      <td>0.155800</td>
      <td>-0.159963</td>
      <td>-0.673594</td>
      <td>-0.051668</td>
      <td>-0.025950</td>
      <td>-0.632621</td>
      <td>...</td>
      <td>-0.181047</td>
      <td>-0.828797</td>
      <td>0.587578</td>
      <td>0.566178</td>
      <td>-0.015992</td>
      <td>-0.684637</td>
      <td>-1.200623</td>
      <td>-0.079127</td>
      <td>0.389691</td>
      <td>0.555948</td>
      <td>-0.060718</td>
      <td>-0.862939</td>
      <td>-0.419440</td>
      <td>-0.598673</td>
      <td>0.527697</td>
      <td>1.126176</td>
      <td>-0.017651</td>
      <td>1.008172</td>
      <td>0.043114</td>
      <td>0.011370</td>
      <td>-0.092846</td>
      <td>0.123256</td>
      <td>0.264024</td>
      <td>-0.418937</td>
      <td>-0.607798</td>
      <td>0.305079</td>
      <td>0.396317</td>
      <td>0.080573</td>
      <td>-0.115492</td>
      <td>-0.230071</td>
      <td>-0.090689</td>
      <td>0.340402</td>
      <td>-0.322207</td>
      <td>-0.134109</td>
      <td>-0.816958</td>
      <td>-0.574755</td>
      <td>-0.332960</td>
      <td>-2.669233</td>
      <td>-1.693612</td>
      <td>-0.824519</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.335934</td>
      <td>0.203000</td>
      <td>0.084247</td>
      <td>1.004243</td>
      <td>0.181162</td>
      <td>-0.499591</td>
      <td>-0.283797</td>
      <td>-1.335429</td>
      <td>0.386194</td>
      <td>0.088967</td>
      <td>0.244360</td>
      <td>-0.202223</td>
      <td>-0.486091</td>
      <td>0.544568</td>
      <td>0.126825</td>
      <td>-0.428288</td>
      <td>-0.198711</td>
      <td>-0.406694</td>
      <td>-0.398003</td>
      <td>-0.092155</td>
      <td>-0.795651</td>
      <td>-0.755932</td>
      <td>0.016135</td>
      <td>0.161236</td>
      <td>0.051749</td>
      <td>-0.260526</td>
      <td>-0.504118</td>
      <td>0.161716</td>
      <td>-0.314618</td>
      <td>-0.360217</td>
      <td>-0.430062</td>
      <td>0.331623</td>
      <td>-0.533282</td>
      <td>-0.389504</td>
      <td>0.432638</td>
      <td>0.622604</td>
      <td>-0.849346</td>
      <td>-0.941112</td>
      <td>-0.208248</td>
      <td>-0.118145</td>
      <td>...</td>
      <td>0.002340</td>
      <td>-0.351663</td>
      <td>0.055273</td>
      <td>0.351134</td>
      <td>0.126295</td>
      <td>1.009878</td>
      <td>0.521994</td>
      <td>0.267317</td>
      <td>-0.684904</td>
      <td>-0.147315</td>
      <td>0.412578</td>
      <td>-0.266424</td>
      <td>-0.075858</td>
      <td>-0.251638</td>
      <td>0.017450</td>
      <td>-0.502523</td>
      <td>-0.068852</td>
      <td>1.230433</td>
      <td>0.141045</td>
      <td>0.460534</td>
      <td>-0.518468</td>
      <td>0.396991</td>
      <td>0.608889</td>
      <td>0.534900</td>
      <td>-0.066333</td>
      <td>-1.307802</td>
      <td>0.977085</td>
      <td>0.571131</td>
      <td>0.513333</td>
      <td>0.544422</td>
      <td>-0.150255</td>
      <td>-0.306693</td>
      <td>-0.561101</td>
      <td>0.369761</td>
      <td>0.466758</td>
      <td>-1.282114</td>
      <td>-0.220943</td>
      <td>0.346012</td>
      <td>0.602647</td>
      <td>0.194319</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.337951</td>
      <td>-0.132237</td>
      <td>0.840869</td>
      <td>-0.684393</td>
      <td>-1.176190</td>
      <td>-0.152289</td>
      <td>-0.012761</td>
      <td>-0.212882</td>
      <td>0.665555</td>
      <td>-0.607299</td>
      <td>0.018829</td>
      <td>-0.003913</td>
      <td>-0.369956</td>
      <td>-0.002859</td>
      <td>0.224473</td>
      <td>-1.162646</td>
      <td>-0.876677</td>
      <td>-0.485036</td>
      <td>-0.835655</td>
      <td>0.327647</td>
      <td>0.137500</td>
      <td>-0.261455</td>
      <td>-0.220648</td>
      <td>0.669472</td>
      <td>0.235696</td>
      <td>0.110414</td>
      <td>0.614109</td>
      <td>1.288704</td>
      <td>0.627579</td>
      <td>-0.198913</td>
      <td>-0.763853</td>
      <td>-1.186632</td>
      <td>-0.492047</td>
      <td>0.316499</td>
      <td>-0.810080</td>
      <td>-0.295047</td>
      <td>-0.941503</td>
      <td>-0.463614</td>
      <td>-0.244450</td>
      <td>-0.787691</td>
      <td>...</td>
      <td>0.162944</td>
      <td>0.355490</td>
      <td>-0.190891</td>
      <td>-0.785805</td>
      <td>-0.033177</td>
      <td>0.656340</td>
      <td>0.625249</td>
      <td>0.038475</td>
      <td>-0.018395</td>
      <td>-0.360705</td>
      <td>-0.396049</td>
      <td>-0.421255</td>
      <td>0.149470</td>
      <td>-0.925905</td>
      <td>-1.086667</td>
      <td>0.054352</td>
      <td>0.372440</td>
      <td>0.161544</td>
      <td>-0.002388</td>
      <td>-0.257026</td>
      <td>0.656955</td>
      <td>0.916561</td>
      <td>1.326401</td>
      <td>-0.066093</td>
      <td>0.906048</td>
      <td>-0.189310</td>
      <td>0.929171</td>
      <td>0.578607</td>
      <td>0.806551</td>
      <td>-0.157887</td>
      <td>0.341596</td>
      <td>0.075997</td>
      <td>0.037396</td>
      <td>0.085243</td>
      <td>-0.651201</td>
      <td>-0.494686</td>
      <td>-0.203552</td>
      <td>0.077159</td>
      <td>0.061721</td>
      <td>0.635522</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.757310</td>
      <td>-0.312502</td>
      <td>0.651486</td>
      <td>0.260125</td>
      <td>0.560097</td>
      <td>0.437921</td>
      <td>0.401471</td>
      <td>-0.135254</td>
      <td>-0.391774</td>
      <td>0.000343</td>
      <td>-0.093870</td>
      <td>0.124666</td>
      <td>1.077375</td>
      <td>-0.416416</td>
      <td>-0.364302</td>
      <td>-0.982180</td>
      <td>-0.929965</td>
      <td>-0.211363</td>
      <td>-0.417491</td>
      <td>0.963287</td>
      <td>0.720238</td>
      <td>0.035701</td>
      <td>-0.371538</td>
      <td>0.028979</td>
      <td>-0.300411</td>
      <td>0.380929</td>
      <td>-0.044891</td>
      <td>0.659148</td>
      <td>0.242516</td>
      <td>0.207988</td>
      <td>-0.448315</td>
      <td>-0.163921</td>
      <td>0.664312</td>
      <td>-0.108443</td>
      <td>-0.196717</td>
      <td>0.428686</td>
      <td>1.049016</td>
      <td>0.712276</td>
      <td>0.816261</td>
      <td>-0.240255</td>
      <td>...</td>
      <td>0.714651</td>
      <td>0.818987</td>
      <td>0.754309</td>
      <td>0.108807</td>
      <td>0.439977</td>
      <td>-0.139559</td>
      <td>-1.083274</td>
      <td>0.276506</td>
      <td>0.671555</td>
      <td>-0.338961</td>
      <td>-0.932020</td>
      <td>-0.115281</td>
      <td>0.586367</td>
      <td>0.106505</td>
      <td>0.997673</td>
      <td>0.012362</td>
      <td>-1.231933</td>
      <td>0.838901</td>
      <td>1.836652</td>
      <td>0.867437</td>
      <td>0.057003</td>
      <td>-0.317636</td>
      <td>-0.639238</td>
      <td>0.181620</td>
      <td>0.337745</td>
      <td>-0.354185</td>
      <td>-0.040137</td>
      <td>0.354269</td>
      <td>-0.387912</td>
      <td>-0.239777</td>
      <td>0.238951</td>
      <td>1.188440</td>
      <td>0.603038</td>
      <td>0.747204</td>
      <td>0.651941</td>
      <td>0.178308</td>
      <td>0.330515</td>
      <td>-0.137610</td>
      <td>-0.242963</td>
      <td>-0.598003</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.288826</td>
      <td>0.510853</td>
      <td>0.345257</td>
      <td>-0.381589</td>
      <td>-0.156211</td>
      <td>0.400544</td>
      <td>-0.193952</td>
      <td>-0.796199</td>
      <td>0.326251</td>
      <td>-0.051486</td>
      <td>0.279570</td>
      <td>0.771967</td>
      <td>1.189643</td>
      <td>0.250407</td>
      <td>0.927097</td>
      <td>-0.012763</td>
      <td>-0.638395</td>
      <td>-0.178408</td>
      <td>1.123124</td>
      <td>0.911858</td>
      <td>0.214263</td>
      <td>-0.657168</td>
      <td>-0.768828</td>
      <td>0.505081</td>
      <td>1.505050</td>
      <td>0.896303</td>
      <td>-0.498943</td>
      <td>0.143405</td>
      <td>-0.706173</td>
      <td>-1.007326</td>
      <td>-0.147095</td>
      <td>-0.803542</td>
      <td>0.007803</td>
      <td>-0.484906</td>
      <td>-1.089209</td>
      <td>0.018053</td>
      <td>-0.542854</td>
      <td>-0.137412</td>
      <td>-0.171330</td>
      <td>-0.145032</td>
      <td>...</td>
      <td>0.430503</td>
      <td>0.638323</td>
      <td>-0.254188</td>
      <td>-0.597721</td>
      <td>0.363537</td>
      <td>0.032650</td>
      <td>-0.364673</td>
      <td>-0.063350</td>
      <td>0.032480</td>
      <td>0.123123</td>
      <td>0.369256</td>
      <td>-0.363257</td>
      <td>-0.489937</td>
      <td>-0.433511</td>
      <td>0.898999</td>
      <td>0.208879</td>
      <td>0.542613</td>
      <td>1.058146</td>
      <td>0.541685</td>
      <td>0.084668</td>
      <td>-1.040872</td>
      <td>-0.202190</td>
      <td>-0.119753</td>
      <td>-1.038737</td>
      <td>-0.425561</td>
      <td>-0.761233</td>
      <td>-0.225366</td>
      <td>0.071761</td>
      <td>0.448276</td>
      <td>-0.877719</td>
      <td>0.038196</td>
      <td>-0.489397</td>
      <td>-0.393444</td>
      <td>0.361597</td>
      <td>-0.910375</td>
      <td>0.394614</td>
      <td>-0.211038</td>
      <td>0.519751</td>
      <td>-0.072734</td>
      <td>0.149588</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.044665</td>
      <td>-0.400397</td>
      <td>-0.423245</td>
      <td>-0.289707</td>
      <td>-1.571884</td>
      <td>0.070639</td>
      <td>0.547008</td>
      <td>-0.094847</td>
      <td>0.227918</td>
      <td>-0.728796</td>
      <td>-0.455548</td>
      <td>-0.510699</td>
      <td>1.451080</td>
      <td>0.517945</td>
      <td>-0.330563</td>
      <td>0.005481</td>
      <td>-0.111320</td>
      <td>0.242115</td>
      <td>-0.563580</td>
      <td>-0.444616</td>
      <td>-0.225859</td>
      <td>-0.600739</td>
      <td>0.743676</td>
      <td>0.386364</td>
      <td>-0.352202</td>
      <td>-0.342485</td>
      <td>0.195133</td>
      <td>0.118663</td>
      <td>-1.937228</td>
      <td>0.459381</td>
      <td>-0.255734</td>
      <td>-0.306338</td>
      <td>0.531588</td>
      <td>1.342962</td>
      <td>-0.586314</td>
      <td>0.267169</td>
      <td>-0.038614</td>
      <td>0.328216</td>
      <td>-0.028452</td>
      <td>0.748724</td>
      <td>...</td>
      <td>1.494523</td>
      <td>-0.259709</td>
      <td>0.347996</td>
      <td>0.292328</td>
      <td>0.464094</td>
      <td>-0.260912</td>
      <td>0.922391</td>
      <td>0.382786</td>
      <td>0.610103</td>
      <td>-0.465798</td>
      <td>-0.497953</td>
      <td>-0.725843</td>
      <td>1.367689</td>
      <td>-0.343592</td>
      <td>0.109343</td>
      <td>-0.025699</td>
      <td>-0.714346</td>
      <td>-0.336802</td>
      <td>-0.343079</td>
      <td>-0.127899</td>
      <td>-0.122964</td>
      <td>-0.456006</td>
      <td>0.048535</td>
      <td>0.080931</td>
      <td>-0.279296</td>
      <td>0.109493</td>
      <td>0.597124</td>
      <td>-0.202894</td>
      <td>-0.902326</td>
      <td>-0.411590</td>
      <td>0.019867</td>
      <td>0.090773</td>
      <td>1.117452</td>
      <td>0.347387</td>
      <td>0.087109</td>
      <td>1.038229</td>
      <td>-0.048969</td>
      <td>0.439728</td>
      <td>0.478780</td>
      <td>0.260364</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.017641</td>
      <td>-0.063065</td>
      <td>-0.316024</td>
      <td>0.208829</td>
      <td>0.414553</td>
      <td>0.297833</td>
      <td>0.185776</td>
      <td>0.343092</td>
      <td>0.076701</td>
      <td>-0.347892</td>
      <td>0.445384</td>
      <td>-0.360656</td>
      <td>0.158494</td>
      <td>0.220680</td>
      <td>0.227872</td>
      <td>1.073897</td>
      <td>0.926034</td>
      <td>0.710852</td>
      <td>0.583150</td>
      <td>-0.101812</td>
      <td>0.704694</td>
      <td>0.100146</td>
      <td>0.199465</td>
      <td>-0.055526</td>
      <td>0.129908</td>
      <td>-0.208855</td>
      <td>0.357928</td>
      <td>0.107421</td>
      <td>-1.503398</td>
      <td>0.185013</td>
      <td>-0.060668</td>
      <td>0.152272</td>
      <td>0.833800</td>
      <td>0.606508</td>
      <td>0.496229</td>
      <td>0.401504</td>
      <td>-0.506796</td>
      <td>-0.215844</td>
      <td>0.141621</td>
      <td>1.057348</td>
      <td>...</td>
      <td>-0.285261</td>
      <td>0.481415</td>
      <td>0.961587</td>
      <td>0.106586</td>
      <td>0.803978</td>
      <td>1.814080</td>
      <td>0.576531</td>
      <td>0.578965</td>
      <td>0.498316</td>
      <td>-0.230855</td>
      <td>0.303287</td>
      <td>-0.854883</td>
      <td>0.220065</td>
      <td>-0.497355</td>
      <td>-0.464424</td>
      <td>1.029641</td>
      <td>0.124951</td>
      <td>0.021815</td>
      <td>-0.223536</td>
      <td>-0.114062</td>
      <td>-0.540903</td>
      <td>-0.788337</td>
      <td>-0.574539</td>
      <td>0.466249</td>
      <td>-0.847467</td>
      <td>-0.259765</td>
      <td>0.757164</td>
      <td>-0.069086</td>
      <td>1.111016</td>
      <td>0.748611</td>
      <td>-1.034292</td>
      <td>-0.300870</td>
      <td>0.334327</td>
      <td>0.272203</td>
      <td>-0.050029</td>
      <td>-0.252357</td>
      <td>0.444403</td>
      <td>0.667715</td>
      <td>0.354759</td>
      <td>-0.281216</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.994602</td>
      <td>0.310643</td>
      <td>0.747444</td>
      <td>-0.199535</td>
      <td>0.094991</td>
      <td>0.557356</td>
      <td>0.696564</td>
      <td>0.752471</td>
      <td>1.037973</td>
      <td>-0.274108</td>
      <td>0.277120</td>
      <td>-0.459990</td>
      <td>-0.084288</td>
      <td>-0.012187</td>
      <td>0.040668</td>
      <td>0.111087</td>
      <td>0.502948</td>
      <td>-0.280735</td>
      <td>0.934493</td>
      <td>0.762994</td>
      <td>0.593748</td>
      <td>0.242041</td>
      <td>0.139479</td>
      <td>0.983222</td>
      <td>0.274272</td>
      <td>-0.230046</td>
      <td>-0.055769</td>
      <td>-0.564489</td>
      <td>-1.150013</td>
      <td>-0.660499</td>
      <td>-0.048912</td>
      <td>1.199036</td>
      <td>0.653244</td>
      <td>0.353476</td>
      <td>-0.767027</td>
      <td>0.367903</td>
      <td>-0.004784</td>
      <td>1.433142</td>
      <td>-0.534625</td>
      <td>1.306163</td>
      <td>...</td>
      <td>0.038018</td>
      <td>-1.006686</td>
      <td>0.104114</td>
      <td>-0.536415</td>
      <td>-0.751303</td>
      <td>-0.658702</td>
      <td>0.482000</td>
      <td>0.322843</td>
      <td>-0.409482</td>
      <td>-1.041604</td>
      <td>-0.466060</td>
      <td>0.410854</td>
      <td>1.159780</td>
      <td>-0.190605</td>
      <td>-0.908611</td>
      <td>1.128725</td>
      <td>-0.124162</td>
      <td>-0.234846</td>
      <td>-0.647831</td>
      <td>0.642546</td>
      <td>-0.343959</td>
      <td>1.267339</td>
      <td>0.105346</td>
      <td>0.945101</td>
      <td>0.457780</td>
      <td>0.277518</td>
      <td>0.518220</td>
      <td>-0.249030</td>
      <td>0.594271</td>
      <td>0.648992</td>
      <td>0.556694</td>
      <td>0.184668</td>
      <td>-0.353996</td>
      <td>1.079772</td>
      <td>-0.245570</td>
      <td>-0.225082</td>
      <td>-0.704657</td>
      <td>2.272960</td>
      <td>1.820227</td>
      <td>-0.352949</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.158478</td>
      <td>0.385015</td>
      <td>0.326306</td>
      <td>-0.660312</td>
      <td>-1.246900</td>
      <td>-0.232627</td>
      <td>-0.051185</td>
      <td>-0.769991</td>
      <td>-0.824991</td>
      <td>0.100164</td>
      <td>-0.504209</td>
      <td>0.083219</td>
      <td>0.684423</td>
      <td>0.106426</td>
      <td>0.232202</td>
      <td>0.656883</td>
      <td>1.286322</td>
      <td>0.619444</td>
      <td>0.209154</td>
      <td>0.329630</td>
      <td>0.190618</td>
      <td>0.184887</td>
      <td>1.051015</td>
      <td>0.162899</td>
      <td>-0.491526</td>
      <td>-0.376319</td>
      <td>-0.125437</td>
      <td>-0.699398</td>
      <td>-0.976635</td>
      <td>-0.940878</td>
      <td>-0.411214</td>
      <td>-0.311093</td>
      <td>0.833770</td>
      <td>0.736570</td>
      <td>0.584949</td>
      <td>-0.089663</td>
      <td>-0.845145</td>
      <td>-0.322074</td>
      <td>-0.040142</td>
      <td>0.756508</td>
      <td>...</td>
      <td>0.702633</td>
      <td>-0.219600</td>
      <td>1.175767</td>
      <td>0.641617</td>
      <td>0.848446</td>
      <td>1.172078</td>
      <td>0.906345</td>
      <td>0.013347</td>
      <td>-0.482762</td>
      <td>-0.564772</td>
      <td>0.623487</td>
      <td>-0.194244</td>
      <td>0.272107</td>
      <td>0.514796</td>
      <td>0.428691</td>
      <td>0.375182</td>
      <td>-0.594440</td>
      <td>-0.755584</td>
      <td>0.659138</td>
      <td>0.513073</td>
      <td>0.496118</td>
      <td>0.247117</td>
      <td>0.645758</td>
      <td>0.392495</td>
      <td>0.164191</td>
      <td>-0.599009</td>
      <td>0.635952</td>
      <td>-0.795507</td>
      <td>0.600639</td>
      <td>0.819302</td>
      <td>0.767062</td>
      <td>0.854695</td>
      <td>-0.131162</td>
      <td>1.209625</td>
      <td>-0.008489</td>
      <td>-0.470091</td>
      <td>0.369850</td>
      <td>0.355707</td>
      <td>-0.219735</td>
      <td>-0.990696</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.155845</td>
      <td>-1.084835</td>
      <td>0.158219</td>
      <td>1.328361</td>
      <td>-0.090450</td>
      <td>0.050346</td>
      <td>0.610739</td>
      <td>-0.260432</td>
      <td>-0.687587</td>
      <td>-0.578380</td>
      <td>0.448510</td>
      <td>-1.480340</td>
      <td>-0.098851</td>
      <td>-0.424541</td>
      <td>0.341087</td>
      <td>0.532599</td>
      <td>0.040001</td>
      <td>-0.311338</td>
      <td>-0.620417</td>
      <td>0.249340</td>
      <td>0.858828</td>
      <td>0.534632</td>
      <td>-0.038671</td>
      <td>0.303090</td>
      <td>-0.192894</td>
      <td>0.657622</td>
      <td>-0.177495</td>
      <td>-0.108117</td>
      <td>-1.670688</td>
      <td>0.226821</td>
      <td>-0.787026</td>
      <td>-0.326285</td>
      <td>-0.600298</td>
      <td>0.741084</td>
      <td>1.155127</td>
      <td>0.532890</td>
      <td>0.440432</td>
      <td>-0.045894</td>
      <td>-0.716934</td>
      <td>0.751892</td>
      <td>...</td>
      <td>0.000980</td>
      <td>-0.753104</td>
      <td>-0.438319</td>
      <td>-0.303110</td>
      <td>0.061473</td>
      <td>0.335118</td>
      <td>-0.127799</td>
      <td>-0.240745</td>
      <td>-0.740090</td>
      <td>0.720886</td>
      <td>-0.321028</td>
      <td>-0.740519</td>
      <td>0.464883</td>
      <td>0.555867</td>
      <td>-0.212624</td>
      <td>0.903664</td>
      <td>-0.439968</td>
      <td>-0.813173</td>
      <td>0.650095</td>
      <td>-0.647063</td>
      <td>0.422260</td>
      <td>0.243596</td>
      <td>0.681351</td>
      <td>-0.270946</td>
      <td>-0.878235</td>
      <td>-1.175037</td>
      <td>-0.027874</td>
      <td>-0.239927</td>
      <td>0.057095</td>
      <td>-0.561422</td>
      <td>0.585533</td>
      <td>0.448767</td>
      <td>0.465729</td>
      <td>-0.604861</td>
      <td>0.042639</td>
      <td>0.537112</td>
      <td>0.339019</td>
      <td>-0.042429</td>
      <td>-0.562616</td>
      <td>-0.481444</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7ff748095070&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.045853  0.035811  29.204971  1.676895e-187  0.975665  1.116041
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  5.301 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.1e043a052b0af929e4d8.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>