
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-0.068225</td>
      <td>-0.377751</td>
      <td>0.092508</td>
      <td>-0.246165</td>
      <td>0.152782</td>
      <td>-0.872869</td>
      <td>-0.265045</td>
      <td>-0.500345</td>
      <td>-0.056312</td>
      <td>0.160713</td>
      <td>0.250908</td>
      <td>-0.047778</td>
      <td>0.704370</td>
      <td>0.506336</td>
      <td>0.182730</td>
      <td>-0.217556</td>
      <td>0.516906</td>
      <td>0.427447</td>
      <td>-0.479217</td>
      <td>-0.137486</td>
      <td>-0.104049</td>
      <td>-0.496868</td>
      <td>0.261805</td>
      <td>0.165305</td>
      <td>0.278855</td>
      <td>-0.064715</td>
      <td>-0.393092</td>
      <td>-0.277155</td>
      <td>0.275329</td>
      <td>-0.568019</td>
      <td>-0.344826</td>
      <td>0.227483</td>
      <td>-0.388753</td>
      <td>0.188171</td>
      <td>-0.493405</td>
      <td>-0.098674</td>
      <td>0.371288</td>
      <td>1.026459</td>
      <td>0.892262</td>
      <td>-0.438810</td>
      <td>...</td>
      <td>0.425806</td>
      <td>0.556209</td>
      <td>0.847089</td>
      <td>0.649710</td>
      <td>-0.411299</td>
      <td>-0.023620</td>
      <td>-0.496620</td>
      <td>0.046149</td>
      <td>-0.097482</td>
      <td>-0.194610</td>
      <td>0.690001</td>
      <td>0.310840</td>
      <td>-0.740621</td>
      <td>-0.093515</td>
      <td>-0.656754</td>
      <td>-0.341871</td>
      <td>0.274101</td>
      <td>-0.245810</td>
      <td>-1.038212</td>
      <td>-0.406404</td>
      <td>0.191719</td>
      <td>0.171673</td>
      <td>0.009807</td>
      <td>0.144681</td>
      <td>-1.198720</td>
      <td>1.253586</td>
      <td>0.224690</td>
      <td>0.315588</td>
      <td>-0.256078</td>
      <td>0.236687</td>
      <td>-0.079297</td>
      <td>0.086772</td>
      <td>-0.602891</td>
      <td>-0.796840</td>
      <td>-0.952281</td>
      <td>-0.861873</td>
      <td>0.558965</td>
      <td>1.055015</td>
      <td>0.191827</td>
      <td>-0.476232</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.132870</td>
      <td>-1.474991</td>
      <td>-0.791076</td>
      <td>0.345073</td>
      <td>-0.708908</td>
      <td>1.125708</td>
      <td>1.044172</td>
      <td>-0.149887</td>
      <td>-0.275100</td>
      <td>-1.045407</td>
      <td>0.045064</td>
      <td>0.470172</td>
      <td>-0.147759</td>
      <td>-0.023901</td>
      <td>-0.267275</td>
      <td>-0.595598</td>
      <td>0.569026</td>
      <td>0.652279</td>
      <td>0.059656</td>
      <td>0.003929</td>
      <td>0.575778</td>
      <td>1.125333</td>
      <td>0.314865</td>
      <td>0.336829</td>
      <td>-0.269008</td>
      <td>-0.825165</td>
      <td>-0.712381</td>
      <td>0.182999</td>
      <td>0.552547</td>
      <td>-0.268127</td>
      <td>0.304270</td>
      <td>0.293912</td>
      <td>0.298577</td>
      <td>1.404807</td>
      <td>0.038644</td>
      <td>1.108693</td>
      <td>0.491236</td>
      <td>0.785040</td>
      <td>0.598335</td>
      <td>0.078598</td>
      <td>...</td>
      <td>1.705514</td>
      <td>-0.982390</td>
      <td>0.373407</td>
      <td>0.249742</td>
      <td>-0.318633</td>
      <td>-0.301288</td>
      <td>-0.841770</td>
      <td>-0.556970</td>
      <td>-0.318793</td>
      <td>-0.468801</td>
      <td>-0.176009</td>
      <td>0.435017</td>
      <td>0.109471</td>
      <td>0.101906</td>
      <td>0.181092</td>
      <td>-0.904151</td>
      <td>-0.089500</td>
      <td>0.459640</td>
      <td>-0.114619</td>
      <td>-0.004188</td>
      <td>-0.366100</td>
      <td>-0.227495</td>
      <td>-0.534306</td>
      <td>-0.219401</td>
      <td>-0.085155</td>
      <td>-0.409866</td>
      <td>0.687169</td>
      <td>-0.104915</td>
      <td>-0.069888</td>
      <td>-0.179792</td>
      <td>-0.082032</td>
      <td>-0.205632</td>
      <td>1.158268</td>
      <td>0.304130</td>
      <td>0.405632</td>
      <td>0.428633</td>
      <td>-0.813521</td>
      <td>-2.464201</td>
      <td>-1.434211</td>
      <td>-1.386368</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.786548</td>
      <td>-0.059002</td>
      <td>0.290959</td>
      <td>0.281248</td>
      <td>0.212514</td>
      <td>-0.113313</td>
      <td>-0.409035</td>
      <td>0.314420</td>
      <td>-1.207605</td>
      <td>0.019917</td>
      <td>0.415495</td>
      <td>-0.069176</td>
      <td>-1.284545</td>
      <td>-0.581425</td>
      <td>-0.287618</td>
      <td>-0.980299</td>
      <td>-0.605444</td>
      <td>0.666609</td>
      <td>-0.223823</td>
      <td>0.994983</td>
      <td>-1.281624</td>
      <td>0.178245</td>
      <td>-0.274623</td>
      <td>-0.646376</td>
      <td>-0.425492</td>
      <td>-0.182766</td>
      <td>0.814205</td>
      <td>0.038555</td>
      <td>-1.270508</td>
      <td>0.041345</td>
      <td>0.945350</td>
      <td>-0.909723</td>
      <td>-1.075165</td>
      <td>-0.130411</td>
      <td>-0.639210</td>
      <td>-0.008477</td>
      <td>-0.113090</td>
      <td>0.057139</td>
      <td>0.032756</td>
      <td>-0.144077</td>
      <td>...</td>
      <td>-1.114480</td>
      <td>-0.792584</td>
      <td>0.230415</td>
      <td>0.929752</td>
      <td>0.262726</td>
      <td>0.163550</td>
      <td>-0.133789</td>
      <td>-0.303081</td>
      <td>0.758651</td>
      <td>1.148616</td>
      <td>1.280239</td>
      <td>-0.138837</td>
      <td>-0.314530</td>
      <td>-0.575970</td>
      <td>1.030194</td>
      <td>0.112253</td>
      <td>0.197537</td>
      <td>0.251542</td>
      <td>-0.454211</td>
      <td>0.067655</td>
      <td>-0.753978</td>
      <td>-0.245401</td>
      <td>0.595238</td>
      <td>0.396793</td>
      <td>0.056062</td>
      <td>-0.281333</td>
      <td>-0.652009</td>
      <td>-1.126735</td>
      <td>0.045102</td>
      <td>-0.444958</td>
      <td>-0.844982</td>
      <td>-0.516987</td>
      <td>-0.355492</td>
      <td>-0.464278</td>
      <td>-0.528296</td>
      <td>0.841946</td>
      <td>0.042223</td>
      <td>0.260487</td>
      <td>0.202265</td>
      <td>-0.306095</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.866926</td>
      <td>-0.051046</td>
      <td>0.057623</td>
      <td>-0.080236</td>
      <td>0.292139</td>
      <td>0.001734</td>
      <td>0.686625</td>
      <td>0.438655</td>
      <td>0.535777</td>
      <td>-0.308410</td>
      <td>-0.742447</td>
      <td>0.675204</td>
      <td>0.420866</td>
      <td>0.207329</td>
      <td>-1.515695</td>
      <td>0.693306</td>
      <td>0.971937</td>
      <td>1.153859</td>
      <td>0.880707</td>
      <td>-0.459256</td>
      <td>-0.425467</td>
      <td>-0.860915</td>
      <td>0.613964</td>
      <td>0.203360</td>
      <td>-0.385829</td>
      <td>-1.010436</td>
      <td>0.329092</td>
      <td>-1.378100</td>
      <td>-0.285813</td>
      <td>1.086540</td>
      <td>0.422729</td>
      <td>0.398819</td>
      <td>-0.264852</td>
      <td>0.767576</td>
      <td>0.455995</td>
      <td>1.042097</td>
      <td>0.777944</td>
      <td>0.341860</td>
      <td>0.535040</td>
      <td>0.678824</td>
      <td>...</td>
      <td>-0.258984</td>
      <td>0.773487</td>
      <td>-0.006004</td>
      <td>0.659447</td>
      <td>0.858001</td>
      <td>0.523894</td>
      <td>-0.344348</td>
      <td>-0.676922</td>
      <td>0.608459</td>
      <td>-0.185400</td>
      <td>0.837725</td>
      <td>-0.213854</td>
      <td>-0.093496</td>
      <td>-0.303252</td>
      <td>0.249987</td>
      <td>-0.433480</td>
      <td>-1.245974</td>
      <td>-0.089135</td>
      <td>-0.252681</td>
      <td>-0.123477</td>
      <td>-1.220883</td>
      <td>-0.918961</td>
      <td>-0.753645</td>
      <td>-0.343774</td>
      <td>-0.306190</td>
      <td>-0.160450</td>
      <td>0.625748</td>
      <td>0.089970</td>
      <td>-0.261565</td>
      <td>0.515403</td>
      <td>0.015931</td>
      <td>0.130191</td>
      <td>0.720499</td>
      <td>-0.745198</td>
      <td>0.725708</td>
      <td>-0.405415</td>
      <td>-1.244304</td>
      <td>3.169199</td>
      <td>2.385774</td>
      <td>0.556948</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.087985</td>
      <td>-0.107880</td>
      <td>0.455080</td>
      <td>0.968103</td>
      <td>0.558745</td>
      <td>0.583281</td>
      <td>0.721392</td>
      <td>-0.732653</td>
      <td>-0.599154</td>
      <td>-0.011125</td>
      <td>-0.707053</td>
      <td>-1.041717</td>
      <td>0.251116</td>
      <td>0.560712</td>
      <td>0.507950</td>
      <td>0.056887</td>
      <td>0.043005</td>
      <td>0.045720</td>
      <td>0.266935</td>
      <td>-0.069577</td>
      <td>-1.044846</td>
      <td>-0.030205</td>
      <td>0.039336</td>
      <td>0.525498</td>
      <td>0.426737</td>
      <td>0.970297</td>
      <td>0.655676</td>
      <td>-0.933617</td>
      <td>-0.639236</td>
      <td>0.676330</td>
      <td>-0.308054</td>
      <td>-0.566163</td>
      <td>-0.295912</td>
      <td>-0.398344</td>
      <td>-1.257079</td>
      <td>0.069680</td>
      <td>-1.169828</td>
      <td>0.514720</td>
      <td>0.038145</td>
      <td>0.795456</td>
      <td>...</td>
      <td>0.673190</td>
      <td>-0.063019</td>
      <td>-0.888473</td>
      <td>-0.282620</td>
      <td>0.718369</td>
      <td>0.601687</td>
      <td>-0.154480</td>
      <td>0.938217</td>
      <td>0.027994</td>
      <td>0.429349</td>
      <td>-0.170909</td>
      <td>-0.437506</td>
      <td>-0.258043</td>
      <td>-0.389132</td>
      <td>0.656265</td>
      <td>0.041627</td>
      <td>0.832974</td>
      <td>1.383628</td>
      <td>0.953298</td>
      <td>-0.609901</td>
      <td>0.209287</td>
      <td>0.765059</td>
      <td>-0.366751</td>
      <td>0.503737</td>
      <td>0.786879</td>
      <td>-0.635757</td>
      <td>1.138682</td>
      <td>0.980576</td>
      <td>0.181464</td>
      <td>1.020832</td>
      <td>0.373773</td>
      <td>-0.317833</td>
      <td>-0.064516</td>
      <td>-0.848871</td>
      <td>0.119942</td>
      <td>-0.182235</td>
      <td>0.303138</td>
      <td>3.038551</td>
      <td>2.136577</td>
      <td>1.015714</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.455546</td>
      <td>-0.575988</td>
      <td>-0.521487</td>
      <td>-0.839730</td>
      <td>-1.626710</td>
      <td>-0.351068</td>
      <td>-0.379065</td>
      <td>-0.341165</td>
      <td>-0.057551</td>
      <td>-0.271352</td>
      <td>-0.860176</td>
      <td>-0.248263</td>
      <td>0.034796</td>
      <td>0.137876</td>
      <td>-0.448017</td>
      <td>-0.256139</td>
      <td>0.773726</td>
      <td>0.173036</td>
      <td>1.111843</td>
      <td>-0.350712</td>
      <td>-0.828496</td>
      <td>0.040432</td>
      <td>-0.039444</td>
      <td>-0.412692</td>
      <td>0.796388</td>
      <td>-0.338741</td>
      <td>-0.381749</td>
      <td>-0.050659</td>
      <td>-0.518530</td>
      <td>-0.103048</td>
      <td>0.058924</td>
      <td>0.091668</td>
      <td>-0.322869</td>
      <td>-1.153365</td>
      <td>-0.087984</td>
      <td>0.720175</td>
      <td>0.367310</td>
      <td>0.714768</td>
      <td>-0.177130</td>
      <td>0.354038</td>
      <td>...</td>
      <td>-0.463138</td>
      <td>-0.464857</td>
      <td>-0.217568</td>
      <td>-0.606991</td>
      <td>-0.027912</td>
      <td>-1.012467</td>
      <td>-1.050348</td>
      <td>-0.893090</td>
      <td>0.119029</td>
      <td>0.381153</td>
      <td>-0.357691</td>
      <td>0.012261</td>
      <td>-1.286082</td>
      <td>-0.379060</td>
      <td>-0.531610</td>
      <td>-0.015221</td>
      <td>-0.501906</td>
      <td>0.517663</td>
      <td>0.156445</td>
      <td>0.817946</td>
      <td>0.137420</td>
      <td>0.196493</td>
      <td>-0.560657</td>
      <td>-0.654152</td>
      <td>0.092103</td>
      <td>0.167001</td>
      <td>0.951793</td>
      <td>0.373301</td>
      <td>0.378056</td>
      <td>0.094455</td>
      <td>0.207491</td>
      <td>0.559380</td>
      <td>0.090521</td>
      <td>-0.124813</td>
      <td>-0.372255</td>
      <td>-0.525397</td>
      <td>-0.427344</td>
      <td>1.312115</td>
      <td>0.492701</td>
      <td>-0.525831</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.552597</td>
      <td>-0.807044</td>
      <td>-0.366561</td>
      <td>0.173685</td>
      <td>0.283607</td>
      <td>-0.787753</td>
      <td>-0.685123</td>
      <td>0.393789</td>
      <td>0.084396</td>
      <td>0.908356</td>
      <td>0.454350</td>
      <td>0.113850</td>
      <td>-0.436516</td>
      <td>-0.145827</td>
      <td>-0.817014</td>
      <td>-0.661129</td>
      <td>0.034336</td>
      <td>-0.386199</td>
      <td>-0.269080</td>
      <td>-0.147771</td>
      <td>-1.066020</td>
      <td>0.116878</td>
      <td>-0.126075</td>
      <td>-0.034538</td>
      <td>0.876066</td>
      <td>0.049746</td>
      <td>-0.680265</td>
      <td>-0.895087</td>
      <td>0.214733</td>
      <td>-0.274151</td>
      <td>-0.535287</td>
      <td>-0.893274</td>
      <td>-0.431766</td>
      <td>-0.042894</td>
      <td>-0.063347</td>
      <td>1.238830</td>
      <td>-0.416531</td>
      <td>0.299348</td>
      <td>0.714505</td>
      <td>0.484100</td>
      <td>...</td>
      <td>0.275928</td>
      <td>0.244243</td>
      <td>-0.135682</td>
      <td>-0.479906</td>
      <td>0.340421</td>
      <td>0.228151</td>
      <td>-0.652957</td>
      <td>-0.512162</td>
      <td>0.809598</td>
      <td>0.607843</td>
      <td>0.435365</td>
      <td>0.321028</td>
      <td>-0.174198</td>
      <td>-0.244166</td>
      <td>0.059776</td>
      <td>0.543776</td>
      <td>-0.462931</td>
      <td>0.983442</td>
      <td>0.199976</td>
      <td>0.521305</td>
      <td>-0.169007</td>
      <td>0.033097</td>
      <td>-0.755559</td>
      <td>-0.391096</td>
      <td>-0.092974</td>
      <td>0.310582</td>
      <td>0.354696</td>
      <td>-0.554781</td>
      <td>0.237568</td>
      <td>-0.606084</td>
      <td>0.153426</td>
      <td>-0.418707</td>
      <td>-0.243518</td>
      <td>-0.136554</td>
      <td>-0.570751</td>
      <td>-0.550664</td>
      <td>-1.161572</td>
      <td>1.661746</td>
      <td>1.007277</td>
      <td>-0.049650</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.143478</td>
      <td>-1.140443</td>
      <td>-0.371291</td>
      <td>-0.686607</td>
      <td>-0.161464</td>
      <td>0.009411</td>
      <td>0.223511</td>
      <td>-0.260940</td>
      <td>-1.239182</td>
      <td>-0.166946</td>
      <td>-0.132435</td>
      <td>-0.573664</td>
      <td>-0.176293</td>
      <td>0.273602</td>
      <td>-0.714754</td>
      <td>0.191854</td>
      <td>-0.130143</td>
      <td>-0.471128</td>
      <td>-0.321913</td>
      <td>0.426465</td>
      <td>-0.454704</td>
      <td>-0.279354</td>
      <td>-0.561139</td>
      <td>-0.072711</td>
      <td>0.560787</td>
      <td>-0.372352</td>
      <td>1.030572</td>
      <td>0.193024</td>
      <td>0.233213</td>
      <td>-0.297814</td>
      <td>1.075391</td>
      <td>0.212560</td>
      <td>0.361047</td>
      <td>0.661161</td>
      <td>0.364944</td>
      <td>1.260642</td>
      <td>-0.742892</td>
      <td>0.999152</td>
      <td>1.004240</td>
      <td>-0.075612</td>
      <td>...</td>
      <td>0.782165</td>
      <td>-0.471894</td>
      <td>0.013521</td>
      <td>-0.329838</td>
      <td>-0.492344</td>
      <td>0.290200</td>
      <td>-0.295303</td>
      <td>0.903077</td>
      <td>1.019848</td>
      <td>0.036838</td>
      <td>0.535353</td>
      <td>-0.184179</td>
      <td>-0.119990</td>
      <td>-1.148022</td>
      <td>-0.264670</td>
      <td>-0.564250</td>
      <td>-0.196607</td>
      <td>0.205334</td>
      <td>0.010327</td>
      <td>-0.598393</td>
      <td>-0.298130</td>
      <td>-0.152065</td>
      <td>0.133270</td>
      <td>0.444598</td>
      <td>-0.488592</td>
      <td>0.331108</td>
      <td>1.010219</td>
      <td>-0.407193</td>
      <td>0.694362</td>
      <td>-0.398856</td>
      <td>-0.345124</td>
      <td>-0.286156</td>
      <td>-0.954607</td>
      <td>-0.284473</td>
      <td>0.085729</td>
      <td>0.592816</td>
      <td>0.219142</td>
      <td>-0.154376</td>
      <td>-0.691121</td>
      <td>0.010065</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.028565</td>
      <td>0.053053</td>
      <td>-0.313721</td>
      <td>-0.227196</td>
      <td>0.206560</td>
      <td>-0.617157</td>
      <td>0.365086</td>
      <td>0.176841</td>
      <td>-1.095901</td>
      <td>-0.370322</td>
      <td>0.557574</td>
      <td>-0.099186</td>
      <td>0.402939</td>
      <td>0.466489</td>
      <td>-0.697079</td>
      <td>-0.636077</td>
      <td>0.530106</td>
      <td>-0.177924</td>
      <td>0.158731</td>
      <td>0.492476</td>
      <td>-0.014855</td>
      <td>-0.786853</td>
      <td>-0.333352</td>
      <td>-0.639853</td>
      <td>-1.622837</td>
      <td>-1.198974</td>
      <td>-0.553641</td>
      <td>-0.277725</td>
      <td>-0.419141</td>
      <td>-0.194489</td>
      <td>0.183871</td>
      <td>0.294471</td>
      <td>-0.436294</td>
      <td>0.407119</td>
      <td>0.650581</td>
      <td>0.781893</td>
      <td>0.071168</td>
      <td>0.747308</td>
      <td>0.145835</td>
      <td>0.826420</td>
      <td>...</td>
      <td>0.537345</td>
      <td>-0.180115</td>
      <td>-0.702032</td>
      <td>-0.918268</td>
      <td>-0.161676</td>
      <td>0.056510</td>
      <td>-0.271697</td>
      <td>-0.297154</td>
      <td>0.842508</td>
      <td>0.768212</td>
      <td>0.354502</td>
      <td>-0.797342</td>
      <td>-0.671880</td>
      <td>0.549855</td>
      <td>0.592679</td>
      <td>0.358997</td>
      <td>-0.218973</td>
      <td>0.971431</td>
      <td>0.113605</td>
      <td>0.273055</td>
      <td>0.321912</td>
      <td>0.100799</td>
      <td>-0.702374</td>
      <td>-0.065815</td>
      <td>-0.143617</td>
      <td>0.456176</td>
      <td>0.524500</td>
      <td>0.114722</td>
      <td>0.262509</td>
      <td>0.647603</td>
      <td>0.368797</td>
      <td>-0.036905</td>
      <td>0.380318</td>
      <td>0.346895</td>
      <td>1.112970</td>
      <td>0.618678</td>
      <td>0.048387</td>
      <td>1.849779</td>
      <td>0.768217</td>
      <td>-0.360380</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.118628</td>
      <td>-0.485451</td>
      <td>0.638712</td>
      <td>0.102778</td>
      <td>-0.072042</td>
      <td>0.047368</td>
      <td>-0.227191</td>
      <td>-0.031816</td>
      <td>0.405913</td>
      <td>-0.024444</td>
      <td>-0.869756</td>
      <td>-1.039178</td>
      <td>-0.559950</td>
      <td>1.340487</td>
      <td>-0.981616</td>
      <td>0.201059</td>
      <td>0.066066</td>
      <td>-0.269495</td>
      <td>-0.236013</td>
      <td>0.024530</td>
      <td>-0.663459</td>
      <td>-0.653267</td>
      <td>-0.186991</td>
      <td>0.336450</td>
      <td>-0.268299</td>
      <td>0.075875</td>
      <td>0.396458</td>
      <td>-0.041731</td>
      <td>-0.003519</td>
      <td>0.245729</td>
      <td>0.235442</td>
      <td>-1.047921</td>
      <td>-0.482738</td>
      <td>-0.580672</td>
      <td>0.339361</td>
      <td>1.057844</td>
      <td>-0.171140</td>
      <td>0.910030</td>
      <td>0.849801</td>
      <td>0.139185</td>
      <td>...</td>
      <td>1.079176</td>
      <td>0.283459</td>
      <td>-0.707663</td>
      <td>-0.331031</td>
      <td>-0.245748</td>
      <td>-0.318002</td>
      <td>-0.878003</td>
      <td>-0.332813</td>
      <td>1.334720</td>
      <td>0.022777</td>
      <td>-1.118479</td>
      <td>-0.487197</td>
      <td>0.197559</td>
      <td>-0.069239</td>
      <td>0.396188</td>
      <td>0.179675</td>
      <td>-0.563381</td>
      <td>-0.051306</td>
      <td>-0.703562</td>
      <td>0.582427</td>
      <td>0.987603</td>
      <td>-1.358130</td>
      <td>-0.045954</td>
      <td>-0.315875</td>
      <td>0.265531</td>
      <td>-0.499314</td>
      <td>0.514034</td>
      <td>-0.467780</td>
      <td>-0.743281</td>
      <td>-0.562461</td>
      <td>0.298417</td>
      <td>0.512684</td>
      <td>-0.410417</td>
      <td>0.364568</td>
      <td>-0.432221</td>
      <td>-0.885896</td>
      <td>-1.185710</td>
      <td>0.234177</td>
      <td>0.896709</td>
      <td>0.228996</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.185408</td>
      <td>0.446551</td>
      <td>0.396783</td>
      <td>-0.417682</td>
      <td>-0.405203</td>
      <td>-0.304507</td>
      <td>-0.443660</td>
      <td>0.160494</td>
      <td>-1.010859</td>
      <td>-0.412516</td>
      <td>-1.076891</td>
      <td>0.497860</td>
      <td>-0.051323</td>
      <td>1.047273</td>
      <td>0.206210</td>
      <td>-0.099275</td>
      <td>1.488801</td>
      <td>0.453795</td>
      <td>0.739634</td>
      <td>0.050108</td>
      <td>0.842962</td>
      <td>0.335799</td>
      <td>0.584768</td>
      <td>-0.814521</td>
      <td>-0.220263</td>
      <td>0.868875</td>
      <td>0.704513</td>
      <td>-0.241344</td>
      <td>-0.162556</td>
      <td>-0.129091</td>
      <td>-0.894081</td>
      <td>-0.208942</td>
      <td>-0.422311</td>
      <td>-0.286168</td>
      <td>-0.085968</td>
      <td>-0.083754</td>
      <td>-0.360516</td>
      <td>0.759785</td>
      <td>0.798033</td>
      <td>0.815387</td>
      <td>...</td>
      <td>0.018859</td>
      <td>-0.810323</td>
      <td>0.467468</td>
      <td>0.913720</td>
      <td>0.037914</td>
      <td>-0.477756</td>
      <td>-0.257483</td>
      <td>-1.131703</td>
      <td>0.463524</td>
      <td>-0.064399</td>
      <td>-0.839133</td>
      <td>-1.072104</td>
      <td>-0.967576</td>
      <td>-0.106148</td>
      <td>0.138086</td>
      <td>0.398272</td>
      <td>-0.103904</td>
      <td>1.232054</td>
      <td>-0.109276</td>
      <td>0.390408</td>
      <td>-0.686504</td>
      <td>-0.115813</td>
      <td>0.367422</td>
      <td>1.445298</td>
      <td>0.133011</td>
      <td>-0.109832</td>
      <td>-0.323801</td>
      <td>-0.278953</td>
      <td>-0.221827</td>
      <td>0.402332</td>
      <td>-0.670943</td>
      <td>-0.432419</td>
      <td>0.091156</td>
      <td>-0.719127</td>
      <td>0.559081</td>
      <td>-0.503274</td>
      <td>0.297491</td>
      <td>3.331309</td>
      <td>1.029871</td>
      <td>-0.277686</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.464884</td>
      <td>-0.568090</td>
      <td>0.289583</td>
      <td>-0.737142</td>
      <td>-0.174574</td>
      <td>-0.313305</td>
      <td>1.038803</td>
      <td>-0.186070</td>
      <td>-0.383872</td>
      <td>-0.122426</td>
      <td>-0.282133</td>
      <td>-0.178355</td>
      <td>0.308568</td>
      <td>-0.503762</td>
      <td>-1.091546</td>
      <td>0.831595</td>
      <td>0.167303</td>
      <td>-0.172529</td>
      <td>0.826484</td>
      <td>-0.213578</td>
      <td>-0.177219</td>
      <td>-0.545195</td>
      <td>-0.672971</td>
      <td>-0.950589</td>
      <td>0.114523</td>
      <td>-0.751030</td>
      <td>-0.013466</td>
      <td>0.336039</td>
      <td>-0.609684</td>
      <td>0.009015</td>
      <td>0.114121</td>
      <td>0.157327</td>
      <td>-0.345070</td>
      <td>0.138763</td>
      <td>0.180489</td>
      <td>0.023301</td>
      <td>-0.129332</td>
      <td>0.259111</td>
      <td>0.506694</td>
      <td>-0.811055</td>
      <td>...</td>
      <td>0.201920</td>
      <td>-0.278553</td>
      <td>0.395812</td>
      <td>-0.231864</td>
      <td>-1.092385</td>
      <td>-0.199655</td>
      <td>-0.492801</td>
      <td>0.003429</td>
      <td>-0.205157</td>
      <td>1.718436</td>
      <td>0.615875</td>
      <td>0.062766</td>
      <td>-0.482207</td>
      <td>-0.589115</td>
      <td>-0.545778</td>
      <td>0.288365</td>
      <td>0.265256</td>
      <td>0.833396</td>
      <td>-0.551257</td>
      <td>-0.256237</td>
      <td>-0.398200</td>
      <td>0.839354</td>
      <td>0.312389</td>
      <td>-0.396036</td>
      <td>0.448779</td>
      <td>-0.402593</td>
      <td>0.118696</td>
      <td>0.090658</td>
      <td>0.128213</td>
      <td>-0.291899</td>
      <td>-0.782265</td>
      <td>-0.731672</td>
      <td>-0.634854</td>
      <td>-0.250487</td>
      <td>0.055629</td>
      <td>0.277441</td>
      <td>-0.076016</td>
      <td>0.940477</td>
      <td>0.231387</td>
      <td>0.074118</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-0.153260</td>
      <td>0.268066</td>
      <td>0.105851</td>
      <td>-0.554320</td>
      <td>0.537803</td>
      <td>-0.879980</td>
      <td>0.055823</td>
      <td>-0.245279</td>
      <td>-0.449461</td>
      <td>-0.225058</td>
      <td>-0.806753</td>
      <td>-0.464292</td>
      <td>-0.670232</td>
      <td>0.281766</td>
      <td>0.168925</td>
      <td>-0.028201</td>
      <td>0.346336</td>
      <td>-0.838013</td>
      <td>-0.520687</td>
      <td>-1.139466</td>
      <td>0.244223</td>
      <td>0.286157</td>
      <td>-0.083848</td>
      <td>0.367593</td>
      <td>0.712064</td>
      <td>-1.122490</td>
      <td>-0.224193</td>
      <td>-0.287893</td>
      <td>-0.502653</td>
      <td>0.240584</td>
      <td>0.938054</td>
      <td>0.788916</td>
      <td>-0.770308</td>
      <td>-0.828718</td>
      <td>-1.080552</td>
      <td>0.331135</td>
      <td>-0.554631</td>
      <td>0.025906</td>
      <td>-0.023302</td>
      <td>0.899658</td>
      <td>...</td>
      <td>0.787067</td>
      <td>-0.174684</td>
      <td>0.482030</td>
      <td>0.034131</td>
      <td>-0.628693</td>
      <td>-1.152151</td>
      <td>-0.270447</td>
      <td>0.727324</td>
      <td>0.771145</td>
      <td>0.709010</td>
      <td>0.861477</td>
      <td>-0.767857</td>
      <td>-0.579960</td>
      <td>-0.309960</td>
      <td>0.009576</td>
      <td>0.888609</td>
      <td>0.384826</td>
      <td>0.193777</td>
      <td>-0.676152</td>
      <td>1.129249</td>
      <td>0.203859</td>
      <td>0.023547</td>
      <td>-0.679781</td>
      <td>-0.309192</td>
      <td>0.104255</td>
      <td>0.286315</td>
      <td>0.750555</td>
      <td>-0.108713</td>
      <td>1.049771</td>
      <td>0.586166</td>
      <td>-0.410526</td>
      <td>0.650180</td>
      <td>1.306226</td>
      <td>-0.177819</td>
      <td>-0.486933</td>
      <td>0.042857</td>
      <td>0.720067</td>
      <td>1.137866</td>
      <td>0.214995</td>
      <td>-0.644240</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.834312</td>
      <td>-0.294445</td>
      <td>-0.332992</td>
      <td>-0.043132</td>
      <td>0.418895</td>
      <td>0.204458</td>
      <td>0.372151</td>
      <td>-0.256124</td>
      <td>-0.789669</td>
      <td>-0.197312</td>
      <td>0.739111</td>
      <td>-0.741992</td>
      <td>-0.571485</td>
      <td>0.799785</td>
      <td>-0.539256</td>
      <td>-0.627998</td>
      <td>0.298748</td>
      <td>0.139691</td>
      <td>0.166048</td>
      <td>-0.747528</td>
      <td>-0.975386</td>
      <td>-0.292281</td>
      <td>0.280565</td>
      <td>-0.085375</td>
      <td>0.427000</td>
      <td>-0.586696</td>
      <td>-0.545460</td>
      <td>-0.276894</td>
      <td>0.110657</td>
      <td>0.599266</td>
      <td>0.207775</td>
      <td>-0.153829</td>
      <td>-0.262700</td>
      <td>0.318395</td>
      <td>0.272397</td>
      <td>0.177234</td>
      <td>0.482655</td>
      <td>0.577307</td>
      <td>0.466295</td>
      <td>0.505096</td>
      <td>...</td>
      <td>1.123098</td>
      <td>0.025058</td>
      <td>-0.473888</td>
      <td>-0.181910</td>
      <td>0.872322</td>
      <td>0.269935</td>
      <td>-0.036339</td>
      <td>-0.306753</td>
      <td>0.340253</td>
      <td>0.339247</td>
      <td>-0.548728</td>
      <td>-0.758520</td>
      <td>-0.037736</td>
      <td>-0.466455</td>
      <td>-0.070473</td>
      <td>0.451815</td>
      <td>0.189881</td>
      <td>1.135798</td>
      <td>0.157283</td>
      <td>-0.223315</td>
      <td>-1.112812</td>
      <td>1.403908</td>
      <td>-0.679826</td>
      <td>-0.214048</td>
      <td>-0.491369</td>
      <td>-0.477724</td>
      <td>-0.055372</td>
      <td>0.223373</td>
      <td>0.198590</td>
      <td>-1.188145</td>
      <td>-0.643207</td>
      <td>-1.169584</td>
      <td>-0.082298</td>
      <td>0.443018</td>
      <td>0.780879</td>
      <td>0.343946</td>
      <td>-0.341795</td>
      <td>2.867761</td>
      <td>2.309246</td>
      <td>0.817074</td>
    </tr>
    <tr>
      <th>14</th>
      <td>1.146970</td>
      <td>1.157617</td>
      <td>0.244012</td>
      <td>-0.059092</td>
      <td>0.541927</td>
      <td>-0.138172</td>
      <td>-0.262988</td>
      <td>-0.404227</td>
      <td>-0.429648</td>
      <td>0.193537</td>
      <td>0.885299</td>
      <td>0.485180</td>
      <td>-0.029993</td>
      <td>0.517816</td>
      <td>0.282856</td>
      <td>-0.662956</td>
      <td>1.160654</td>
      <td>-0.171038</td>
      <td>-0.184418</td>
      <td>-0.433188</td>
      <td>-0.544002</td>
      <td>0.433135</td>
      <td>-0.310818</td>
      <td>-1.126157</td>
      <td>0.547324</td>
      <td>-0.025288</td>
      <td>-0.078371</td>
      <td>-0.717638</td>
      <td>-0.213821</td>
      <td>0.901600</td>
      <td>1.082107</td>
      <td>1.435675</td>
      <td>0.685468</td>
      <td>0.284034</td>
      <td>0.920194</td>
      <td>1.885284</td>
      <td>-0.772528</td>
      <td>0.680647</td>
      <td>0.320171</td>
      <td>0.153380</td>
      <td>...</td>
      <td>1.181094</td>
      <td>0.242168</td>
      <td>-0.043779</td>
      <td>0.468812</td>
      <td>-0.509420</td>
      <td>-0.033678</td>
      <td>0.065405</td>
      <td>-0.262281</td>
      <td>0.808363</td>
      <td>0.528252</td>
      <td>0.136151</td>
      <td>0.117930</td>
      <td>-0.407212</td>
      <td>0.546720</td>
      <td>0.184430</td>
      <td>0.431480</td>
      <td>0.250620</td>
      <td>0.912953</td>
      <td>-0.245406</td>
      <td>0.599812</td>
      <td>-0.033363</td>
      <td>1.345562</td>
      <td>0.117461</td>
      <td>0.400611</td>
      <td>0.343662</td>
      <td>0.088667</td>
      <td>0.373102</td>
      <td>-0.234740</td>
      <td>0.007495</td>
      <td>0.208649</td>
      <td>-0.632930</td>
      <td>-0.491170</td>
      <td>-0.821162</td>
      <td>0.278262</td>
      <td>-0.454646</td>
      <td>-0.026718</td>
      <td>0.415436</td>
      <td>4.360021</td>
      <td>3.555821</td>
      <td>0.951268</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.527931</td>
      <td>-0.886925</td>
      <td>-0.643098</td>
      <td>-0.241495</td>
      <td>0.917303</td>
      <td>0.154538</td>
      <td>0.140789</td>
      <td>0.210015</td>
      <td>0.192323</td>
      <td>0.043571</td>
      <td>0.288575</td>
      <td>0.172938</td>
      <td>0.075242</td>
      <td>-0.065926</td>
      <td>-0.691167</td>
      <td>-1.256610</td>
      <td>-0.366819</td>
      <td>0.219419</td>
      <td>-0.230338</td>
      <td>-0.753838</td>
      <td>-0.336851</td>
      <td>-1.324724</td>
      <td>-0.401817</td>
      <td>-0.190752</td>
      <td>-0.144742</td>
      <td>0.202814</td>
      <td>0.393822</td>
      <td>0.155181</td>
      <td>-0.238796</td>
      <td>0.141810</td>
      <td>0.240642</td>
      <td>0.727678</td>
      <td>0.182540</td>
      <td>-1.050484</td>
      <td>-0.823406</td>
      <td>0.278728</td>
      <td>-1.051755</td>
      <td>1.189312</td>
      <td>1.135519</td>
      <td>0.016899</td>
      <td>...</td>
      <td>0.400904</td>
      <td>-0.288562</td>
      <td>0.628157</td>
      <td>-0.028280</td>
      <td>-0.787788</td>
      <td>-0.451004</td>
      <td>-0.863362</td>
      <td>-0.491617</td>
      <td>0.189411</td>
      <td>0.125559</td>
      <td>0.767287</td>
      <td>-0.268099</td>
      <td>-0.954657</td>
      <td>0.669772</td>
      <td>0.259532</td>
      <td>0.225463</td>
      <td>0.441924</td>
      <td>0.822486</td>
      <td>0.425297</td>
      <td>0.507624</td>
      <td>0.468135</td>
      <td>0.102842</td>
      <td>0.283776</td>
      <td>-0.010873</td>
      <td>-0.707427</td>
      <td>-0.645459</td>
      <td>0.668843</td>
      <td>-1.460199</td>
      <td>-1.883192</td>
      <td>0.269423</td>
      <td>0.540117</td>
      <td>0.771973</td>
      <td>0.460480</td>
      <td>0.410231</td>
      <td>0.288342</td>
      <td>0.551035</td>
      <td>-0.530971</td>
      <td>1.881616</td>
      <td>0.801648</td>
      <td>0.344996</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.232427</td>
      <td>-0.866882</td>
      <td>0.481326</td>
      <td>-0.080314</td>
      <td>0.194450</td>
      <td>0.353890</td>
      <td>0.352736</td>
      <td>0.440010</td>
      <td>0.660251</td>
      <td>0.298988</td>
      <td>-0.725783</td>
      <td>-0.427148</td>
      <td>-0.358671</td>
      <td>0.138979</td>
      <td>-0.481441</td>
      <td>-0.274131</td>
      <td>-0.059882</td>
      <td>-0.409987</td>
      <td>0.405137</td>
      <td>0.265862</td>
      <td>-0.068908</td>
      <td>-1.011296</td>
      <td>0.308331</td>
      <td>0.567494</td>
      <td>-0.067559</td>
      <td>0.334723</td>
      <td>0.462482</td>
      <td>0.133844</td>
      <td>-0.004979</td>
      <td>-0.493135</td>
      <td>0.391387</td>
      <td>-0.624066</td>
      <td>-0.560320</td>
      <td>-0.505723</td>
      <td>-0.303352</td>
      <td>0.846531</td>
      <td>0.555039</td>
      <td>1.102495</td>
      <td>0.416943</td>
      <td>-0.513493</td>
      <td>...</td>
      <td>1.513399</td>
      <td>0.467529</td>
      <td>-0.306567</td>
      <td>-0.838080</td>
      <td>-0.050431</td>
      <td>-0.710955</td>
      <td>0.122470</td>
      <td>-0.307064</td>
      <td>0.620078</td>
      <td>0.387924</td>
      <td>-0.184128</td>
      <td>-0.716472</td>
      <td>-0.774704</td>
      <td>0.428416</td>
      <td>-0.757240</td>
      <td>0.363901</td>
      <td>-0.602506</td>
      <td>0.650029</td>
      <td>-0.157204</td>
      <td>0.031905</td>
      <td>-0.547726</td>
      <td>0.174541</td>
      <td>-0.635347</td>
      <td>0.394289</td>
      <td>0.780732</td>
      <td>0.305255</td>
      <td>-0.054147</td>
      <td>0.022813</td>
      <td>0.751229</td>
      <td>-0.262876</td>
      <td>-0.111084</td>
      <td>-0.304807</td>
      <td>0.000876</td>
      <td>-0.185853</td>
      <td>0.558251</td>
      <td>-0.388110</td>
      <td>-1.261399</td>
      <td>-0.224768</td>
      <td>-0.821953</td>
      <td>-0.641839</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-1.182475</td>
      <td>-0.707511</td>
      <td>0.013028</td>
      <td>0.649712</td>
      <td>-0.071747</td>
      <td>0.396921</td>
      <td>0.349717</td>
      <td>0.284214</td>
      <td>-0.275858</td>
      <td>-0.293759</td>
      <td>0.900816</td>
      <td>-0.810482</td>
      <td>0.089699</td>
      <td>-0.739726</td>
      <td>-1.353457</td>
      <td>-0.379960</td>
      <td>-0.203696</td>
      <td>-0.013157</td>
      <td>-0.504583</td>
      <td>-0.748591</td>
      <td>-0.546474</td>
      <td>0.247925</td>
      <td>0.460581</td>
      <td>1.018408</td>
      <td>0.650951</td>
      <td>-0.576100</td>
      <td>1.054603</td>
      <td>0.089968</td>
      <td>1.023204</td>
      <td>0.151320</td>
      <td>-0.182926</td>
      <td>0.919897</td>
      <td>-1.114017</td>
      <td>0.339203</td>
      <td>0.113407</td>
      <td>0.385870</td>
      <td>0.090737</td>
      <td>1.067864</td>
      <td>-0.175574</td>
      <td>-0.427376</td>
      <td>...</td>
      <td>0.019927</td>
      <td>-0.065565</td>
      <td>0.207951</td>
      <td>-0.591664</td>
      <td>-0.281603</td>
      <td>0.553024</td>
      <td>-0.634924</td>
      <td>-0.582649</td>
      <td>0.109218</td>
      <td>1.017880</td>
      <td>0.061357</td>
      <td>-0.862251</td>
      <td>-1.023573</td>
      <td>0.438581</td>
      <td>-0.698016</td>
      <td>-1.200176</td>
      <td>-0.065247</td>
      <td>-0.608835</td>
      <td>0.349752</td>
      <td>-0.366107</td>
      <td>-0.362410</td>
      <td>-0.753178</td>
      <td>-1.131662</td>
      <td>-0.138405</td>
      <td>0.066409</td>
      <td>0.017059</td>
      <td>-0.168358</td>
      <td>-0.027338</td>
      <td>-0.019857</td>
      <td>-0.920045</td>
      <td>-0.979575</td>
      <td>0.372306</td>
      <td>0.178055</td>
      <td>-0.598158</td>
      <td>-0.289441</td>
      <td>-0.411064</td>
      <td>-0.654524</td>
      <td>-1.407955</td>
      <td>-1.484855</td>
      <td>-1.407479</td>
    </tr>
    <tr>
      <th>18</th>
      <td>1.041794</td>
      <td>0.517243</td>
      <td>0.968596</td>
      <td>0.293426</td>
      <td>0.763987</td>
      <td>0.394671</td>
      <td>0.184962</td>
      <td>0.091548</td>
      <td>0.113456</td>
      <td>0.018967</td>
      <td>0.831787</td>
      <td>-0.054100</td>
      <td>-0.262439</td>
      <td>-0.067232</td>
      <td>-1.515548</td>
      <td>0.005261</td>
      <td>0.208124</td>
      <td>0.630917</td>
      <td>-0.489963</td>
      <td>-0.347700</td>
      <td>-0.781879</td>
      <td>-0.218059</td>
      <td>0.190909</td>
      <td>-0.589371</td>
      <td>-0.890778</td>
      <td>-0.341215</td>
      <td>-0.258568</td>
      <td>-0.374029</td>
      <td>0.822231</td>
      <td>-0.445488</td>
      <td>0.293215</td>
      <td>0.479822</td>
      <td>1.094124</td>
      <td>0.565897</td>
      <td>1.708328</td>
      <td>-0.243591</td>
      <td>-0.751891</td>
      <td>0.672511</td>
      <td>0.209093</td>
      <td>-0.770085</td>
      <td>...</td>
      <td>0.229113</td>
      <td>0.133454</td>
      <td>-0.454168</td>
      <td>-0.513178</td>
      <td>0.500743</td>
      <td>0.150577</td>
      <td>0.678139</td>
      <td>-0.227221</td>
      <td>1.017446</td>
      <td>-0.317206</td>
      <td>-0.136413</td>
      <td>-0.613203</td>
      <td>-1.281430</td>
      <td>-0.988951</td>
      <td>0.513309</td>
      <td>-0.067730</td>
      <td>0.134591</td>
      <td>0.870560</td>
      <td>0.002739</td>
      <td>-0.079177</td>
      <td>-0.521433</td>
      <td>0.425422</td>
      <td>-0.827429</td>
      <td>-0.315410</td>
      <td>1.035110</td>
      <td>0.812149</td>
      <td>0.190696</td>
      <td>0.631199</td>
      <td>0.228395</td>
      <td>1.090144</td>
      <td>0.269314</td>
      <td>-0.632276</td>
      <td>-0.339333</td>
      <td>0.098382</td>
      <td>0.375066</td>
      <td>0.228503</td>
      <td>-1.196116</td>
      <td>2.848799</td>
      <td>2.134898</td>
      <td>1.201112</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.468201</td>
      <td>-0.021296</td>
      <td>0.122748</td>
      <td>0.336627</td>
      <td>0.293207</td>
      <td>0.252101</td>
      <td>0.761222</td>
      <td>0.923353</td>
      <td>-0.299700</td>
      <td>0.108240</td>
      <td>0.192456</td>
      <td>-0.235947</td>
      <td>-0.353496</td>
      <td>-0.167373</td>
      <td>0.087252</td>
      <td>0.140392</td>
      <td>0.986374</td>
      <td>-0.375686</td>
      <td>-0.204326</td>
      <td>-0.498252</td>
      <td>0.739099</td>
      <td>0.145623</td>
      <td>-0.598065</td>
      <td>0.035562</td>
      <td>-0.227761</td>
      <td>-0.713492</td>
      <td>1.397995</td>
      <td>0.923999</td>
      <td>0.112244</td>
      <td>-0.239174</td>
      <td>-0.201100</td>
      <td>-0.359519</td>
      <td>-0.453764</td>
      <td>-0.476904</td>
      <td>-0.649301</td>
      <td>0.228919</td>
      <td>0.589495</td>
      <td>1.602940</td>
      <td>1.215387</td>
      <td>-0.066993</td>
      <td>...</td>
      <td>0.437784</td>
      <td>-0.271415</td>
      <td>0.053833</td>
      <td>0.055409</td>
      <td>-0.611833</td>
      <td>0.325712</td>
      <td>-0.396605</td>
      <td>-0.761314</td>
      <td>-0.320808</td>
      <td>0.772354</td>
      <td>-0.736434</td>
      <td>-0.659958</td>
      <td>-0.846591</td>
      <td>0.228650</td>
      <td>-0.474897</td>
      <td>-0.138783</td>
      <td>0.537785</td>
      <td>-0.502998</td>
      <td>-1.280382</td>
      <td>-0.367419</td>
      <td>-0.719210</td>
      <td>-0.839206</td>
      <td>-0.521717</td>
      <td>0.269441</td>
      <td>0.534593</td>
      <td>0.849577</td>
      <td>0.456820</td>
      <td>0.995044</td>
      <td>-0.203680</td>
      <td>-0.690074</td>
      <td>-0.899664</td>
      <td>0.168467</td>
      <td>0.254607</td>
      <td>0.956083</td>
      <td>0.234224</td>
      <td>0.453958</td>
      <td>-0.168046</td>
      <td>1.909348</td>
      <td>1.085393</td>
      <td>-0.041193</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.209028</td>
      <td>-0.680470</td>
      <td>0.046280</td>
      <td>-0.695664</td>
      <td>0.477090</td>
      <td>-0.282905</td>
      <td>0.111111</td>
      <td>-0.121902</td>
      <td>-0.489601</td>
      <td>-0.064160</td>
      <td>0.373632</td>
      <td>0.245710</td>
      <td>-0.423722</td>
      <td>0.164571</td>
      <td>0.045596</td>
      <td>-0.036844</td>
      <td>0.563381</td>
      <td>-0.760190</td>
      <td>0.499318</td>
      <td>0.403847</td>
      <td>-0.762565</td>
      <td>-0.752364</td>
      <td>0.121493</td>
      <td>0.658779</td>
      <td>0.050355</td>
      <td>-0.373014</td>
      <td>0.285617</td>
      <td>-0.698828</td>
      <td>-0.513571</td>
      <td>0.170643</td>
      <td>0.128955</td>
      <td>-0.372989</td>
      <td>-0.534840</td>
      <td>-0.066711</td>
      <td>0.555984</td>
      <td>0.851086</td>
      <td>0.427441</td>
      <td>0.416385</td>
      <td>0.583147</td>
      <td>-0.516842</td>
      <td>...</td>
      <td>0.306527</td>
      <td>0.026732</td>
      <td>0.152717</td>
      <td>0.705456</td>
      <td>-0.468873</td>
      <td>-0.460512</td>
      <td>-0.406229</td>
      <td>-0.164044</td>
      <td>0.409886</td>
      <td>1.091633</td>
      <td>1.243628</td>
      <td>0.212485</td>
      <td>-0.875136</td>
      <td>0.064374</td>
      <td>-1.228150</td>
      <td>1.314866</td>
      <td>-0.057500</td>
      <td>0.502052</td>
      <td>0.070170</td>
      <td>0.074724</td>
      <td>0.944582</td>
      <td>0.258127</td>
      <td>-0.469738</td>
      <td>-0.809519</td>
      <td>0.988230</td>
      <td>-0.545902</td>
      <td>-0.219987</td>
      <td>0.294179</td>
      <td>0.330470</td>
      <td>-0.126446</td>
      <td>0.030928</td>
      <td>-0.278182</td>
      <td>-0.475147</td>
      <td>-0.700537</td>
      <td>-0.462116</td>
      <td>-0.251656</td>
      <td>0.167993</td>
      <td>2.689285</td>
      <td>1.867508</td>
      <td>0.732867</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.137684</td>
      <td>0.316219</td>
      <td>-0.885548</td>
      <td>-0.108189</td>
      <td>0.062124</td>
      <td>-1.602726</td>
      <td>-0.048049</td>
      <td>-0.134752</td>
      <td>-0.518670</td>
      <td>0.104615</td>
      <td>0.052688</td>
      <td>-0.149745</td>
      <td>-0.004071</td>
      <td>-0.722520</td>
      <td>-1.016829</td>
      <td>-0.693388</td>
      <td>0.305305</td>
      <td>-0.469840</td>
      <td>-0.435896</td>
      <td>-0.203612</td>
      <td>-0.305443</td>
      <td>0.398423</td>
      <td>0.139829</td>
      <td>-0.038464</td>
      <td>0.622201</td>
      <td>-0.369649</td>
      <td>-0.054072</td>
      <td>0.981791</td>
      <td>-0.068673</td>
      <td>0.035651</td>
      <td>-0.284903</td>
      <td>0.059746</td>
      <td>-0.879434</td>
      <td>-0.098243</td>
      <td>0.429253</td>
      <td>0.190131</td>
      <td>0.772664</td>
      <td>0.570114</td>
      <td>0.352376</td>
      <td>-0.364617</td>
      <td>...</td>
      <td>0.268520</td>
      <td>-0.531674</td>
      <td>1.152778</td>
      <td>0.559500</td>
      <td>-0.204809</td>
      <td>-0.338090</td>
      <td>-1.058744</td>
      <td>-0.452912</td>
      <td>0.222047</td>
      <td>-0.511512</td>
      <td>-0.229301</td>
      <td>-0.280705</td>
      <td>-0.038192</td>
      <td>0.188362</td>
      <td>-0.059577</td>
      <td>0.633873</td>
      <td>-0.054065</td>
      <td>0.795424</td>
      <td>0.243094</td>
      <td>0.373188</td>
      <td>1.022599</td>
      <td>0.806995</td>
      <td>0.675562</td>
      <td>-0.141506</td>
      <td>1.006298</td>
      <td>0.642323</td>
      <td>0.304721</td>
      <td>0.123907</td>
      <td>-0.544739</td>
      <td>-0.057708</td>
      <td>1.361171</td>
      <td>0.326991</td>
      <td>0.364710</td>
      <td>-0.555615</td>
      <td>-0.253063</td>
      <td>-0.576614</td>
      <td>0.039359</td>
      <td>1.878090</td>
      <td>1.721125</td>
      <td>-0.173941</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.267628</td>
      <td>0.331322</td>
      <td>0.207734</td>
      <td>0.284883</td>
      <td>0.766037</td>
      <td>-0.096114</td>
      <td>1.089512</td>
      <td>0.106191</td>
      <td>-0.595010</td>
      <td>-0.072801</td>
      <td>0.102471</td>
      <td>-0.501586</td>
      <td>0.095041</td>
      <td>-0.199788</td>
      <td>0.102792</td>
      <td>-0.407809</td>
      <td>0.035556</td>
      <td>-0.461328</td>
      <td>0.127323</td>
      <td>-0.060490</td>
      <td>-0.275478</td>
      <td>-0.141593</td>
      <td>-0.538116</td>
      <td>-0.150575</td>
      <td>-0.306617</td>
      <td>-0.664623</td>
      <td>-0.716796</td>
      <td>-0.663518</td>
      <td>-0.559352</td>
      <td>0.466332</td>
      <td>-0.243234</td>
      <td>0.124136</td>
      <td>-0.410497</td>
      <td>-1.277648</td>
      <td>-0.889402</td>
      <td>0.065241</td>
      <td>-0.621656</td>
      <td>0.606469</td>
      <td>0.423046</td>
      <td>0.296924</td>
      <td>...</td>
      <td>0.984552</td>
      <td>0.238719</td>
      <td>-0.870267</td>
      <td>-0.794705</td>
      <td>-0.987522</td>
      <td>-0.876116</td>
      <td>-1.395531</td>
      <td>-0.918412</td>
      <td>-0.789714</td>
      <td>0.920746</td>
      <td>-0.014043</td>
      <td>-0.478814</td>
      <td>0.088506</td>
      <td>-0.400010</td>
      <td>0.065793</td>
      <td>-0.342120</td>
      <td>0.647806</td>
      <td>0.571845</td>
      <td>0.528263</td>
      <td>-0.041611</td>
      <td>-0.882580</td>
      <td>-0.041873</td>
      <td>-1.100991</td>
      <td>-1.249800</td>
      <td>-0.475159</td>
      <td>0.025017</td>
      <td>0.557895</td>
      <td>0.017662</td>
      <td>0.013562</td>
      <td>-0.480541</td>
      <td>-0.064996</td>
      <td>0.329303</td>
      <td>1.428531</td>
      <td>-0.231232</td>
      <td>0.043740</td>
      <td>0.570065</td>
      <td>-0.070657</td>
      <td>-0.259400</td>
      <td>-0.304325</td>
      <td>-0.663638</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.316897</td>
      <td>-0.463050</td>
      <td>-0.402348</td>
      <td>0.637996</td>
      <td>0.710309</td>
      <td>0.271510</td>
      <td>0.080919</td>
      <td>-0.438009</td>
      <td>-0.766537</td>
      <td>-0.451849</td>
      <td>-0.493068</td>
      <td>-0.518390</td>
      <td>-1.474272</td>
      <td>-0.159477</td>
      <td>-0.161216</td>
      <td>0.104577</td>
      <td>0.886104</td>
      <td>-0.538908</td>
      <td>0.440632</td>
      <td>-0.237991</td>
      <td>-0.820140</td>
      <td>0.315903</td>
      <td>-0.373426</td>
      <td>0.176731</td>
      <td>0.214856</td>
      <td>0.227486</td>
      <td>-0.097883</td>
      <td>-0.203611</td>
      <td>-0.042375</td>
      <td>0.106959</td>
      <td>-0.191677</td>
      <td>-0.445714</td>
      <td>-0.212697</td>
      <td>1.127551</td>
      <td>1.190008</td>
      <td>0.596930</td>
      <td>1.316405</td>
      <td>0.840309</td>
      <td>0.840244</td>
      <td>0.218211</td>
      <td>...</td>
      <td>-0.211072</td>
      <td>-0.986233</td>
      <td>0.623331</td>
      <td>0.685771</td>
      <td>-1.353698</td>
      <td>-0.380993</td>
      <td>-0.816730</td>
      <td>-0.823680</td>
      <td>0.421144</td>
      <td>-0.253592</td>
      <td>-1.627915</td>
      <td>-1.372828</td>
      <td>0.256310</td>
      <td>-0.003630</td>
      <td>-0.095440</td>
      <td>-0.049785</td>
      <td>0.271679</td>
      <td>0.700358</td>
      <td>-0.761788</td>
      <td>0.074831</td>
      <td>0.114328</td>
      <td>0.441926</td>
      <td>-1.095543</td>
      <td>-0.271970</td>
      <td>0.009476</td>
      <td>0.431895</td>
      <td>1.169996</td>
      <td>0.256590</td>
      <td>0.857501</td>
      <td>-0.838995</td>
      <td>0.568844</td>
      <td>-0.426423</td>
      <td>0.492772</td>
      <td>0.825765</td>
      <td>-0.418003</td>
      <td>-0.221498</td>
      <td>0.155654</td>
      <td>0.681521</td>
      <td>0.480756</td>
      <td>-0.113259</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-0.647946</td>
      <td>-1.470670</td>
      <td>-0.226819</td>
      <td>0.110712</td>
      <td>0.305843</td>
      <td>0.210453</td>
      <td>0.573665</td>
      <td>0.967019</td>
      <td>0.238453</td>
      <td>-0.121116</td>
      <td>-0.073933</td>
      <td>-0.321106</td>
      <td>0.011234</td>
      <td>0.738305</td>
      <td>1.167721</td>
      <td>-0.192992</td>
      <td>1.197868</td>
      <td>0.803625</td>
      <td>0.211086</td>
      <td>-0.188018</td>
      <td>-0.184913</td>
      <td>0.984677</td>
      <td>-0.446690</td>
      <td>-0.455992</td>
      <td>-0.095269</td>
      <td>-0.955888</td>
      <td>-1.491437</td>
      <td>-0.217145</td>
      <td>-0.172879</td>
      <td>0.132451</td>
      <td>0.127301</td>
      <td>0.617448</td>
      <td>0.789955</td>
      <td>0.489324</td>
      <td>-1.047357</td>
      <td>0.463062</td>
      <td>-0.308012</td>
      <td>-0.662175</td>
      <td>-0.093842</td>
      <td>-1.066143</td>
      <td>...</td>
      <td>1.084815</td>
      <td>0.269086</td>
      <td>-0.315374</td>
      <td>0.545847</td>
      <td>1.301890</td>
      <td>-0.320555</td>
      <td>-0.343030</td>
      <td>-0.307941</td>
      <td>0.988678</td>
      <td>-0.611637</td>
      <td>0.092117</td>
      <td>-1.352742</td>
      <td>-0.113185</td>
      <td>0.088713</td>
      <td>0.386198</td>
      <td>-0.741160</td>
      <td>-0.636488</td>
      <td>0.158262</td>
      <td>0.369864</td>
      <td>0.111518</td>
      <td>-0.248150</td>
      <td>-0.885526</td>
      <td>-0.777294</td>
      <td>0.542109</td>
      <td>-0.064253</td>
      <td>-0.259807</td>
      <td>-0.378062</td>
      <td>0.071635</td>
      <td>0.162034</td>
      <td>-0.282194</td>
      <td>0.021482</td>
      <td>-0.098434</td>
      <td>0.502110</td>
      <td>-0.088708</td>
      <td>-0.824671</td>
      <td>0.223607</td>
      <td>-0.967063</td>
      <td>0.111988</td>
      <td>-1.036677</td>
      <td>-0.499276</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.103464</td>
      <td>0.492466</td>
      <td>-0.139977</td>
      <td>0.192605</td>
      <td>0.771549</td>
      <td>0.158877</td>
      <td>-1.189306</td>
      <td>-0.419659</td>
      <td>0.310204</td>
      <td>0.365170</td>
      <td>-0.468111</td>
      <td>0.664193</td>
      <td>-0.402140</td>
      <td>-0.317853</td>
      <td>-0.030138</td>
      <td>0.357866</td>
      <td>-0.353052</td>
      <td>0.243750</td>
      <td>-0.205574</td>
      <td>0.450141</td>
      <td>0.207344</td>
      <td>0.113015</td>
      <td>-1.540962</td>
      <td>-0.498611</td>
      <td>0.198024</td>
      <td>-0.172665</td>
      <td>0.230619</td>
      <td>0.596641</td>
      <td>0.255725</td>
      <td>0.153661</td>
      <td>1.135466</td>
      <td>-0.366487</td>
      <td>-0.333095</td>
      <td>0.171030</td>
      <td>0.848042</td>
      <td>-0.389961</td>
      <td>-0.019884</td>
      <td>0.125852</td>
      <td>-0.094158</td>
      <td>0.075469</td>
      <td>...</td>
      <td>-0.122982</td>
      <td>0.084247</td>
      <td>1.419686</td>
      <td>0.113454</td>
      <td>0.150154</td>
      <td>-0.332949</td>
      <td>-0.209458</td>
      <td>0.721569</td>
      <td>0.198070</td>
      <td>0.188465</td>
      <td>1.253018</td>
      <td>-0.019463</td>
      <td>0.302179</td>
      <td>-1.086085</td>
      <td>-1.428200</td>
      <td>0.289668</td>
      <td>-1.247588</td>
      <td>-1.207711</td>
      <td>-0.701949</td>
      <td>-0.041376</td>
      <td>0.679170</td>
      <td>-0.221175</td>
      <td>-0.210863</td>
      <td>0.037307</td>
      <td>0.181166</td>
      <td>-0.471146</td>
      <td>-0.338269</td>
      <td>0.250615</td>
      <td>-0.145139</td>
      <td>-0.102789</td>
      <td>0.392860</td>
      <td>-0.889040</td>
      <td>-0.564242</td>
      <td>-0.934343</td>
      <td>-0.817024</td>
      <td>-0.702942</td>
      <td>0.103748</td>
      <td>1.306567</td>
      <td>0.171852</td>
      <td>-0.108328</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.566006</td>
      <td>-0.512835</td>
      <td>-0.419426</td>
      <td>-0.130838</td>
      <td>-0.946382</td>
      <td>0.395592</td>
      <td>-0.169322</td>
      <td>0.180994</td>
      <td>1.138703</td>
      <td>-0.250370</td>
      <td>0.003874</td>
      <td>0.551228</td>
      <td>0.569967</td>
      <td>-0.753722</td>
      <td>0.221168</td>
      <td>-1.100316</td>
      <td>-0.127647</td>
      <td>-1.261234</td>
      <td>-0.380481</td>
      <td>0.211954</td>
      <td>0.717950</td>
      <td>0.824564</td>
      <td>-0.453073</td>
      <td>0.313536</td>
      <td>0.198009</td>
      <td>-1.307179</td>
      <td>-0.917185</td>
      <td>0.113932</td>
      <td>0.084492</td>
      <td>-0.836418</td>
      <td>-1.011731</td>
      <td>-0.772238</td>
      <td>1.056638</td>
      <td>1.120719</td>
      <td>0.638098</td>
      <td>0.952165</td>
      <td>0.423221</td>
      <td>0.542262</td>
      <td>-0.534092</td>
      <td>0.003257</td>
      <td>...</td>
      <td>0.281040</td>
      <td>-0.644062</td>
      <td>0.830450</td>
      <td>-0.475284</td>
      <td>0.207183</td>
      <td>0.304930</td>
      <td>1.270849</td>
      <td>0.677767</td>
      <td>-0.182437</td>
      <td>1.887901</td>
      <td>-0.155866</td>
      <td>0.452146</td>
      <td>0.334035</td>
      <td>-0.798790</td>
      <td>-0.785793</td>
      <td>0.000714</td>
      <td>0.863310</td>
      <td>1.068403</td>
      <td>1.022070</td>
      <td>0.531760</td>
      <td>0.417424</td>
      <td>0.091462</td>
      <td>-0.053812</td>
      <td>-0.057127</td>
      <td>-1.041302</td>
      <td>-0.165895</td>
      <td>0.494651</td>
      <td>-0.029556</td>
      <td>0.693176</td>
      <td>-0.069904</td>
      <td>0.327337</td>
      <td>-0.758402</td>
      <td>-0.808812</td>
      <td>0.084357</td>
      <td>-0.238359</td>
      <td>0.103033</td>
      <td>-0.197591</td>
      <td>0.173103</td>
      <td>0.313261</td>
      <td>0.434723</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.127016</td>
      <td>0.967394</td>
      <td>0.278310</td>
      <td>-0.835917</td>
      <td>-0.514421</td>
      <td>-0.606065</td>
      <td>-0.217497</td>
      <td>0.469816</td>
      <td>0.704718</td>
      <td>0.345164</td>
      <td>0.733242</td>
      <td>0.568828</td>
      <td>-0.550872</td>
      <td>-1.373806</td>
      <td>-0.756352</td>
      <td>-0.616637</td>
      <td>-0.288857</td>
      <td>-0.584847</td>
      <td>0.486183</td>
      <td>0.018107</td>
      <td>-0.846902</td>
      <td>0.619803</td>
      <td>-1.022839</td>
      <td>-0.052781</td>
      <td>0.193148</td>
      <td>0.300239</td>
      <td>-0.019654</td>
      <td>0.536422</td>
      <td>0.256442</td>
      <td>-0.131071</td>
      <td>0.616326</td>
      <td>-0.909585</td>
      <td>0.835416</td>
      <td>0.052001</td>
      <td>0.262014</td>
      <td>0.752689</td>
      <td>0.152525</td>
      <td>0.724932</td>
      <td>-0.200748</td>
      <td>-0.372948</td>
      <td>...</td>
      <td>0.100585</td>
      <td>0.148109</td>
      <td>0.532962</td>
      <td>-0.039491</td>
      <td>-1.266834</td>
      <td>-0.407922</td>
      <td>0.474803</td>
      <td>-0.013271</td>
      <td>0.662162</td>
      <td>1.766462</td>
      <td>1.097839</td>
      <td>0.393877</td>
      <td>1.200322</td>
      <td>0.818459</td>
      <td>-0.063767</td>
      <td>-0.368925</td>
      <td>-0.037296</td>
      <td>0.353171</td>
      <td>0.260925</td>
      <td>-0.276322</td>
      <td>-0.758410</td>
      <td>-0.083138</td>
      <td>0.369879</td>
      <td>0.530135</td>
      <td>-1.021961</td>
      <td>-0.586424</td>
      <td>-0.523390</td>
      <td>-0.566490</td>
      <td>-0.529860</td>
      <td>-0.654165</td>
      <td>-0.825411</td>
      <td>-0.177832</td>
      <td>-0.901223</td>
      <td>0.466418</td>
      <td>-0.403838</td>
      <td>0.043242</td>
      <td>-0.373316</td>
      <td>-1.457953</td>
      <td>-1.148148</td>
      <td>-0.843950</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.200810</td>
      <td>-1.238131</td>
      <td>-0.037504</td>
      <td>-0.049452</td>
      <td>-0.248906</td>
      <td>0.185415</td>
      <td>0.321580</td>
      <td>0.837876</td>
      <td>-0.111722</td>
      <td>0.687679</td>
      <td>0.106509</td>
      <td>1.923013</td>
      <td>-0.311581</td>
      <td>-0.695810</td>
      <td>-1.134434</td>
      <td>-0.574586</td>
      <td>0.944903</td>
      <td>0.789545</td>
      <td>0.509391</td>
      <td>-0.004258</td>
      <td>0.238659</td>
      <td>-0.122142</td>
      <td>-0.213626</td>
      <td>0.093261</td>
      <td>0.436074</td>
      <td>0.056685</td>
      <td>-0.159588</td>
      <td>-0.052660</td>
      <td>0.309802</td>
      <td>-0.906296</td>
      <td>-0.029851</td>
      <td>-1.557089</td>
      <td>-0.332490</td>
      <td>0.352244</td>
      <td>0.443504</td>
      <td>0.122168</td>
      <td>-0.099449</td>
      <td>0.025231</td>
      <td>-0.322971</td>
      <td>0.219074</td>
      <td>...</td>
      <td>0.375302</td>
      <td>0.593471</td>
      <td>-0.228116</td>
      <td>0.581563</td>
      <td>-1.075810</td>
      <td>-0.309690</td>
      <td>-0.293028</td>
      <td>-0.330217</td>
      <td>-0.017847</td>
      <td>0.440289</td>
      <td>0.362184</td>
      <td>-0.546644</td>
      <td>0.801097</td>
      <td>-0.253022</td>
      <td>-0.340662</td>
      <td>0.117537</td>
      <td>-0.135504</td>
      <td>-0.502183</td>
      <td>0.110311</td>
      <td>0.247721</td>
      <td>-0.574900</td>
      <td>-0.624912</td>
      <td>0.665346</td>
      <td>0.311566</td>
      <td>-0.236541</td>
      <td>0.548721</td>
      <td>0.667113</td>
      <td>0.823938</td>
      <td>-0.232218</td>
      <td>0.204301</td>
      <td>0.596836</td>
      <td>0.215338</td>
      <td>-0.348555</td>
      <td>-0.564325</td>
      <td>-0.285367</td>
      <td>-0.841272</td>
      <td>-0.272377</td>
      <td>-0.767541</td>
      <td>-0.342354</td>
      <td>-0.788302</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1.014050</td>
      <td>0.029409</td>
      <td>0.239057</td>
      <td>0.552864</td>
      <td>0.207958</td>
      <td>-0.172676</td>
      <td>0.005751</td>
      <td>-0.397717</td>
      <td>-0.002484</td>
      <td>0.265750</td>
      <td>-0.164896</td>
      <td>0.684813</td>
      <td>0.720603</td>
      <td>0.239373</td>
      <td>0.529077</td>
      <td>0.393817</td>
      <td>-0.365753</td>
      <td>-0.691567</td>
      <td>0.252807</td>
      <td>0.282615</td>
      <td>0.438197</td>
      <td>0.210996</td>
      <td>-0.906624</td>
      <td>0.116157</td>
      <td>-0.489869</td>
      <td>0.307795</td>
      <td>0.006688</td>
      <td>-0.181823</td>
      <td>1.117480</td>
      <td>0.106440</td>
      <td>0.380319</td>
      <td>-0.124628</td>
      <td>0.211621</td>
      <td>0.360943</td>
      <td>-0.108278</td>
      <td>-0.057064</td>
      <td>-0.770373</td>
      <td>-0.929158</td>
      <td>0.136276</td>
      <td>0.264857</td>
      <td>...</td>
      <td>0.091673</td>
      <td>-0.113021</td>
      <td>0.459316</td>
      <td>1.049128</td>
      <td>0.313986</td>
      <td>-0.050152</td>
      <td>-0.085219</td>
      <td>0.475101</td>
      <td>0.335986</td>
      <td>-0.706135</td>
      <td>0.177904</td>
      <td>-0.609055</td>
      <td>0.220511</td>
      <td>-0.668620</td>
      <td>-0.101947</td>
      <td>0.480543</td>
      <td>1.792740</td>
      <td>0.972237</td>
      <td>0.176332</td>
      <td>0.552055</td>
      <td>-0.645465</td>
      <td>-0.066171</td>
      <td>0.349116</td>
      <td>-0.254447</td>
      <td>0.446483</td>
      <td>-0.245761</td>
      <td>0.225500</td>
      <td>-1.221854</td>
      <td>-0.112913</td>
      <td>0.241875</td>
      <td>0.017051</td>
      <td>-0.136048</td>
      <td>-0.364208</td>
      <td>0.201648</td>
      <td>0.398745</td>
      <td>-0.337420</td>
      <td>-0.956218</td>
      <td>-1.558407</td>
      <td>-1.268320</td>
      <td>-1.588840</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7fb729294130&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef  std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.030618   0.0471  21.881611  3.888661e-106  0.938304  1.122932
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.356 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.4.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>