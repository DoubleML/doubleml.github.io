
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="http://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>     to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.336728</td>
      <td>-0.836856</td>
      <td>-1.208024</td>
      <td>0.706433</td>
      <td>0.233461</td>
      <td>0.007419</td>
      <td>-0.147548</td>
      <td>-0.387176</td>
      <td>0.199968</td>
      <td>-0.007481</td>
      <td>-0.184150</td>
      <td>0.122160</td>
      <td>0.551470</td>
      <td>-0.559797</td>
      <td>0.757434</td>
      <td>-0.185969</td>
      <td>0.371796</td>
      <td>-0.097331</td>
      <td>-0.057378</td>
      <td>-0.289247</td>
      <td>-1.388567</td>
      <td>-0.144532</td>
      <td>-1.016085</td>
      <td>0.350661</td>
      <td>-0.653013</td>
      <td>-1.014316</td>
      <td>-0.445997</td>
      <td>-0.173789</td>
      <td>-0.372492</td>
      <td>0.511861</td>
      <td>0.069312</td>
      <td>-0.044834</td>
      <td>0.935012</td>
      <td>0.058899</td>
      <td>-0.309957</td>
      <td>-0.078373</td>
      <td>0.498260</td>
      <td>-0.718366</td>
      <td>0.487797</td>
      <td>0.696868</td>
      <td>...</td>
      <td>0.462886</td>
      <td>0.478981</td>
      <td>-0.004037</td>
      <td>-0.233731</td>
      <td>-0.600142</td>
      <td>-0.942248</td>
      <td>-0.886415</td>
      <td>-0.313559</td>
      <td>0.430455</td>
      <td>0.587674</td>
      <td>0.066200</td>
      <td>0.079088</td>
      <td>0.620461</td>
      <td>-0.984886</td>
      <td>-1.182746</td>
      <td>-0.321023</td>
      <td>1.129956</td>
      <td>0.189543</td>
      <td>-0.419760</td>
      <td>0.319070</td>
      <td>-0.128350</td>
      <td>-0.126860</td>
      <td>0.163547</td>
      <td>0.590628</td>
      <td>0.243681</td>
      <td>-0.787071</td>
      <td>-0.177982</td>
      <td>-0.417172</td>
      <td>0.063214</td>
      <td>0.626132</td>
      <td>-0.553361</td>
      <td>0.719338</td>
      <td>0.319212</td>
      <td>0.462524</td>
      <td>0.807901</td>
      <td>0.257645</td>
      <td>1.271222</td>
      <td>-1.148304</td>
      <td>-0.950562</td>
      <td>-0.941051</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.078010</td>
      <td>0.238535</td>
      <td>0.212787</td>
      <td>0.696708</td>
      <td>-0.422703</td>
      <td>0.690111</td>
      <td>0.306711</td>
      <td>-1.117118</td>
      <td>-0.385719</td>
      <td>0.758831</td>
      <td>0.562150</td>
      <td>0.393123</td>
      <td>0.215571</td>
      <td>-0.851975</td>
      <td>0.087855</td>
      <td>0.481655</td>
      <td>0.253530</td>
      <td>0.642850</td>
      <td>0.297855</td>
      <td>0.026355</td>
      <td>0.471551</td>
      <td>0.179566</td>
      <td>0.382500</td>
      <td>0.814300</td>
      <td>-0.146986</td>
      <td>0.997663</td>
      <td>0.277301</td>
      <td>-0.159326</td>
      <td>0.899626</td>
      <td>-0.528371</td>
      <td>-0.328015</td>
      <td>0.006274</td>
      <td>-0.669214</td>
      <td>-0.179852</td>
      <td>-0.028876</td>
      <td>0.103518</td>
      <td>0.611431</td>
      <td>-0.757331</td>
      <td>-0.102063</td>
      <td>-0.215012</td>
      <td>...</td>
      <td>-0.818489</td>
      <td>-0.816320</td>
      <td>-1.041361</td>
      <td>-0.910158</td>
      <td>-0.001373</td>
      <td>-0.236804</td>
      <td>0.284698</td>
      <td>-0.406408</td>
      <td>0.350419</td>
      <td>-0.338406</td>
      <td>1.377842</td>
      <td>-0.566736</td>
      <td>-0.650676</td>
      <td>-1.179044</td>
      <td>-0.925718</td>
      <td>0.323199</td>
      <td>-0.908361</td>
      <td>-1.324547</td>
      <td>0.888344</td>
      <td>0.490820</td>
      <td>0.555591</td>
      <td>0.437330</td>
      <td>-1.058816</td>
      <td>0.931208</td>
      <td>0.510064</td>
      <td>-0.372433</td>
      <td>0.217903</td>
      <td>1.192790</td>
      <td>0.636295</td>
      <td>0.613123</td>
      <td>0.375270</td>
      <td>-0.097604</td>
      <td>-0.215216</td>
      <td>0.677080</td>
      <td>1.449750</td>
      <td>1.148063</td>
      <td>-1.031335</td>
      <td>2.045357</td>
      <td>0.639632</td>
      <td>-0.220269</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.135807</td>
      <td>-0.783401</td>
      <td>-0.268046</td>
      <td>1.054335</td>
      <td>-0.136590</td>
      <td>0.624717</td>
      <td>0.238502</td>
      <td>0.360121</td>
      <td>1.005599</td>
      <td>0.712014</td>
      <td>-0.143112</td>
      <td>0.514589</td>
      <td>0.355477</td>
      <td>0.270176</td>
      <td>0.749504</td>
      <td>1.113009</td>
      <td>0.118013</td>
      <td>-0.280814</td>
      <td>-0.247275</td>
      <td>-1.959237</td>
      <td>-1.076103</td>
      <td>-0.431412</td>
      <td>-0.751755</td>
      <td>0.930239</td>
      <td>-0.050303</td>
      <td>-0.228462</td>
      <td>-1.140068</td>
      <td>-0.845203</td>
      <td>0.783885</td>
      <td>1.320364</td>
      <td>-0.321511</td>
      <td>-0.299835</td>
      <td>0.896397</td>
      <td>-0.458204</td>
      <td>-0.143688</td>
      <td>0.440858</td>
      <td>-0.519401</td>
      <td>-0.687552</td>
      <td>0.041194</td>
      <td>0.570388</td>
      <td>...</td>
      <td>-0.314366</td>
      <td>-0.470517</td>
      <td>-0.292217</td>
      <td>-0.812508</td>
      <td>-0.816773</td>
      <td>0.641766</td>
      <td>0.008746</td>
      <td>-0.749257</td>
      <td>1.279661</td>
      <td>0.412005</td>
      <td>0.622083</td>
      <td>1.089105</td>
      <td>0.501243</td>
      <td>-0.345209</td>
      <td>0.120581</td>
      <td>-0.529680</td>
      <td>-0.904246</td>
      <td>-0.260190</td>
      <td>0.130104</td>
      <td>0.744355</td>
      <td>0.326429</td>
      <td>0.533283</td>
      <td>-0.156894</td>
      <td>0.060814</td>
      <td>-0.349880</td>
      <td>-0.490128</td>
      <td>-1.735049</td>
      <td>0.631947</td>
      <td>1.070489</td>
      <td>1.354302</td>
      <td>0.085364</td>
      <td>-0.361967</td>
      <td>-1.034104</td>
      <td>-0.237230</td>
      <td>0.619653</td>
      <td>0.373325</td>
      <td>0.025170</td>
      <td>-0.553529</td>
      <td>-0.436668</td>
      <td>-0.208282</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.244648</td>
      <td>-0.031973</td>
      <td>-0.161836</td>
      <td>0.132769</td>
      <td>-0.231855</td>
      <td>-0.712370</td>
      <td>0.388706</td>
      <td>-0.309224</td>
      <td>0.047318</td>
      <td>0.181675</td>
      <td>-0.473655</td>
      <td>0.964125</td>
      <td>0.008873</td>
      <td>0.087048</td>
      <td>0.427393</td>
      <td>-0.530756</td>
      <td>-0.395231</td>
      <td>-0.429453</td>
      <td>0.849682</td>
      <td>0.307464</td>
      <td>-0.255716</td>
      <td>-0.512563</td>
      <td>-0.357000</td>
      <td>0.557765</td>
      <td>-0.448093</td>
      <td>-0.418846</td>
      <td>0.398303</td>
      <td>-0.405133</td>
      <td>0.790330</td>
      <td>0.295810</td>
      <td>0.096493</td>
      <td>-0.718610</td>
      <td>-0.309961</td>
      <td>-0.159736</td>
      <td>-0.380112</td>
      <td>-1.477911</td>
      <td>-0.059730</td>
      <td>-0.729739</td>
      <td>-0.968889</td>
      <td>-0.018234</td>
      <td>...</td>
      <td>-0.140225</td>
      <td>0.944482</td>
      <td>0.449898</td>
      <td>0.313141</td>
      <td>-0.711192</td>
      <td>-0.363855</td>
      <td>0.195633</td>
      <td>1.087765</td>
      <td>-0.035326</td>
      <td>0.526847</td>
      <td>-0.019998</td>
      <td>0.448982</td>
      <td>0.191153</td>
      <td>-1.135829</td>
      <td>-0.743744</td>
      <td>-0.712859</td>
      <td>-0.664056</td>
      <td>-0.434911</td>
      <td>-0.350541</td>
      <td>0.272112</td>
      <td>-0.903941</td>
      <td>0.169449</td>
      <td>-0.571519</td>
      <td>-0.427122</td>
      <td>0.464308</td>
      <td>0.022676</td>
      <td>0.154874</td>
      <td>1.304533</td>
      <td>-0.023141</td>
      <td>-0.820710</td>
      <td>-0.189051</td>
      <td>-0.283456</td>
      <td>0.851001</td>
      <td>-0.786375</td>
      <td>0.997919</td>
      <td>-0.014824</td>
      <td>-0.274120</td>
      <td>-0.579867</td>
      <td>-0.095257</td>
      <td>-0.418299</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.692868</td>
      <td>-0.007432</td>
      <td>0.799565</td>
      <td>0.130819</td>
      <td>-0.485645</td>
      <td>-0.450707</td>
      <td>0.142662</td>
      <td>-0.115946</td>
      <td>-1.378256</td>
      <td>0.619167</td>
      <td>-0.454097</td>
      <td>0.111203</td>
      <td>0.147925</td>
      <td>-0.196947</td>
      <td>-0.059289</td>
      <td>-0.176924</td>
      <td>0.489138</td>
      <td>0.765348</td>
      <td>0.345081</td>
      <td>-0.071725</td>
      <td>0.284208</td>
      <td>-0.064925</td>
      <td>0.740415</td>
      <td>0.852721</td>
      <td>-0.814756</td>
      <td>0.040092</td>
      <td>-0.648065</td>
      <td>-0.677105</td>
      <td>0.308946</td>
      <td>-0.091146</td>
      <td>0.575710</td>
      <td>0.245623</td>
      <td>-0.272066</td>
      <td>-0.149628</td>
      <td>0.313400</td>
      <td>-1.680918</td>
      <td>0.491672</td>
      <td>-0.216619</td>
      <td>0.230226</td>
      <td>0.488761</td>
      <td>...</td>
      <td>-0.414495</td>
      <td>0.236327</td>
      <td>0.273217</td>
      <td>0.371588</td>
      <td>-0.346892</td>
      <td>-0.026903</td>
      <td>0.200160</td>
      <td>0.578592</td>
      <td>1.052047</td>
      <td>-0.384365</td>
      <td>0.094584</td>
      <td>-0.086295</td>
      <td>0.302582</td>
      <td>-0.618605</td>
      <td>-0.152976</td>
      <td>0.570542</td>
      <td>-0.840757</td>
      <td>-0.327461</td>
      <td>0.329859</td>
      <td>-0.131547</td>
      <td>-0.010745</td>
      <td>0.357476</td>
      <td>0.247591</td>
      <td>0.922016</td>
      <td>0.419615</td>
      <td>-0.333964</td>
      <td>0.267484</td>
      <td>0.232076</td>
      <td>0.333745</td>
      <td>0.189076</td>
      <td>-0.640542</td>
      <td>0.819264</td>
      <td>1.142706</td>
      <td>-1.371142</td>
      <td>-1.027145</td>
      <td>-1.437830</td>
      <td>0.000987</td>
      <td>1.423592</td>
      <td>0.659095</td>
      <td>0.263595</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.214489</td>
      <td>-0.057448</td>
      <td>-0.044286</td>
      <td>0.607253</td>
      <td>0.208941</td>
      <td>-0.199674</td>
      <td>0.530200</td>
      <td>-0.315902</td>
      <td>0.287887</td>
      <td>1.476221</td>
      <td>0.158728</td>
      <td>1.463915</td>
      <td>-0.061795</td>
      <td>-0.136313</td>
      <td>0.531901</td>
      <td>0.592036</td>
      <td>0.168537</td>
      <td>0.789579</td>
      <td>0.732211</td>
      <td>1.498262</td>
      <td>0.281947</td>
      <td>0.197748</td>
      <td>-0.949286</td>
      <td>0.058984</td>
      <td>-0.606168</td>
      <td>-0.164330</td>
      <td>-0.900460</td>
      <td>-0.419926</td>
      <td>0.425993</td>
      <td>-0.617353</td>
      <td>-0.007675</td>
      <td>-0.643882</td>
      <td>-1.022511</td>
      <td>-0.827779</td>
      <td>-0.028666</td>
      <td>0.076089</td>
      <td>0.560886</td>
      <td>-0.894099</td>
      <td>0.021336</td>
      <td>-0.817475</td>
      <td>...</td>
      <td>-0.590619</td>
      <td>0.266316</td>
      <td>-0.327906</td>
      <td>0.044006</td>
      <td>-0.869314</td>
      <td>-0.630793</td>
      <td>-1.242399</td>
      <td>0.131231</td>
      <td>0.185188</td>
      <td>0.665243</td>
      <td>0.417355</td>
      <td>0.439609</td>
      <td>0.325783</td>
      <td>0.004037</td>
      <td>0.085854</td>
      <td>-0.182134</td>
      <td>-0.739300</td>
      <td>-1.216449</td>
      <td>-0.061305</td>
      <td>1.275603</td>
      <td>0.813685</td>
      <td>0.329160</td>
      <td>0.315220</td>
      <td>0.917436</td>
      <td>-0.012482</td>
      <td>0.196447</td>
      <td>-0.370517</td>
      <td>0.397090</td>
      <td>-0.286451</td>
      <td>0.865101</td>
      <td>0.321734</td>
      <td>1.123413</td>
      <td>0.635259</td>
      <td>-0.197698</td>
      <td>0.104827</td>
      <td>-0.456901</td>
      <td>-0.943190</td>
      <td>-2.417839</td>
      <td>-1.212839</td>
      <td>-1.166477</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.376151</td>
      <td>0.513250</td>
      <td>0.227742</td>
      <td>1.100779</td>
      <td>-0.411168</td>
      <td>-0.401668</td>
      <td>0.985119</td>
      <td>-0.157471</td>
      <td>0.135728</td>
      <td>0.420145</td>
      <td>-0.501040</td>
      <td>0.107006</td>
      <td>-0.833097</td>
      <td>-0.257242</td>
      <td>0.428249</td>
      <td>-0.814549</td>
      <td>-0.421474</td>
      <td>0.548788</td>
      <td>0.970891</td>
      <td>0.796724</td>
      <td>0.270306</td>
      <td>-0.072723</td>
      <td>-0.569489</td>
      <td>0.804887</td>
      <td>0.133047</td>
      <td>0.138673</td>
      <td>-0.282915</td>
      <td>-1.061614</td>
      <td>0.920777</td>
      <td>-0.266780</td>
      <td>0.151465</td>
      <td>-0.581070</td>
      <td>-0.133645</td>
      <td>-0.358266</td>
      <td>0.220623</td>
      <td>-1.313565</td>
      <td>-0.274618</td>
      <td>0.111259</td>
      <td>0.563891</td>
      <td>-0.500497</td>
      <td>...</td>
      <td>-0.021251</td>
      <td>-0.559338</td>
      <td>0.157874</td>
      <td>-0.337271</td>
      <td>0.055424</td>
      <td>1.527241</td>
      <td>1.396532</td>
      <td>1.289924</td>
      <td>1.458982</td>
      <td>0.464645</td>
      <td>0.833833</td>
      <td>-0.111223</td>
      <td>-0.548515</td>
      <td>-0.052567</td>
      <td>-0.123483</td>
      <td>-0.792186</td>
      <td>-0.024337</td>
      <td>0.473897</td>
      <td>0.532045</td>
      <td>0.505547</td>
      <td>0.834547</td>
      <td>0.219145</td>
      <td>-0.750057</td>
      <td>0.116026</td>
      <td>1.113274</td>
      <td>-0.504916</td>
      <td>-0.420990</td>
      <td>0.716426</td>
      <td>-0.565070</td>
      <td>0.415989</td>
      <td>-0.191014</td>
      <td>0.466393</td>
      <td>0.401274</td>
      <td>0.767937</td>
      <td>-0.260772</td>
      <td>-0.142321</td>
      <td>0.790784</td>
      <td>2.166487</td>
      <td>1.434392</td>
      <td>0.854872</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.163451</td>
      <td>0.570439</td>
      <td>-0.045906</td>
      <td>1.582965</td>
      <td>-0.004794</td>
      <td>-0.151113</td>
      <td>1.124284</td>
      <td>0.186862</td>
      <td>-0.223300</td>
      <td>-0.186302</td>
      <td>0.265265</td>
      <td>0.170316</td>
      <td>1.468808</td>
      <td>-0.395317</td>
      <td>0.058410</td>
      <td>-0.115090</td>
      <td>-0.170859</td>
      <td>-0.412196</td>
      <td>-0.115110</td>
      <td>-0.496345</td>
      <td>0.233576</td>
      <td>0.829700</td>
      <td>-0.311496</td>
      <td>0.587402</td>
      <td>-0.645430</td>
      <td>-0.136841</td>
      <td>0.864653</td>
      <td>0.304210</td>
      <td>-0.258655</td>
      <td>0.028898</td>
      <td>-0.756994</td>
      <td>-0.775734</td>
      <td>0.652930</td>
      <td>-0.116311</td>
      <td>-0.625461</td>
      <td>0.085970</td>
      <td>0.267282</td>
      <td>1.056327</td>
      <td>0.322860</td>
      <td>0.798401</td>
      <td>...</td>
      <td>0.695474</td>
      <td>-0.110745</td>
      <td>-0.423216</td>
      <td>0.129299</td>
      <td>-1.447109</td>
      <td>0.591509</td>
      <td>-0.115342</td>
      <td>-1.151448</td>
      <td>-0.241193</td>
      <td>-0.480933</td>
      <td>-0.910564</td>
      <td>-0.222650</td>
      <td>0.076304</td>
      <td>1.068525</td>
      <td>0.169555</td>
      <td>1.046875</td>
      <td>0.352125</td>
      <td>0.216147</td>
      <td>0.722987</td>
      <td>-0.070428</td>
      <td>-0.638088</td>
      <td>0.798140</td>
      <td>-1.243405</td>
      <td>0.622390</td>
      <td>1.496768</td>
      <td>0.459855</td>
      <td>0.149710</td>
      <td>0.144283</td>
      <td>0.527301</td>
      <td>0.020139</td>
      <td>0.102362</td>
      <td>-1.261654</td>
      <td>-1.217870</td>
      <td>-0.549741</td>
      <td>-0.406216</td>
      <td>-0.408263</td>
      <td>-0.112277</td>
      <td>0.350856</td>
      <td>0.233173</td>
      <td>0.558918</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.611125</td>
      <td>-0.678989</td>
      <td>0.218318</td>
      <td>1.224965</td>
      <td>0.513252</td>
      <td>0.741116</td>
      <td>0.844073</td>
      <td>-0.345680</td>
      <td>0.213728</td>
      <td>0.538499</td>
      <td>-0.525803</td>
      <td>-0.505420</td>
      <td>-0.301028</td>
      <td>-0.161170</td>
      <td>0.038843</td>
      <td>-0.023256</td>
      <td>0.029839</td>
      <td>0.222630</td>
      <td>-0.097260</td>
      <td>-0.337506</td>
      <td>-0.145088</td>
      <td>-0.295058</td>
      <td>-0.751518</td>
      <td>0.020480</td>
      <td>-1.242671</td>
      <td>0.234475</td>
      <td>0.114757</td>
      <td>-0.307153</td>
      <td>1.043863</td>
      <td>0.313085</td>
      <td>0.736296</td>
      <td>-0.095450</td>
      <td>-0.141406</td>
      <td>-0.405145</td>
      <td>-0.558710</td>
      <td>-0.903016</td>
      <td>0.288044</td>
      <td>0.125487</td>
      <td>-0.236794</td>
      <td>0.026608</td>
      <td>...</td>
      <td>-0.451353</td>
      <td>1.238410</td>
      <td>0.499717</td>
      <td>-0.435380</td>
      <td>0.440136</td>
      <td>0.725840</td>
      <td>1.297224</td>
      <td>0.938009</td>
      <td>0.612176</td>
      <td>-0.230611</td>
      <td>-0.760599</td>
      <td>1.330427</td>
      <td>0.731991</td>
      <td>-0.185487</td>
      <td>-0.762582</td>
      <td>0.110699</td>
      <td>-0.436568</td>
      <td>0.280011</td>
      <td>0.198757</td>
      <td>0.172252</td>
      <td>0.340974</td>
      <td>0.048237</td>
      <td>-0.942454</td>
      <td>0.181627</td>
      <td>0.948452</td>
      <td>-0.271650</td>
      <td>-1.088404</td>
      <td>-0.528009</td>
      <td>0.165536</td>
      <td>1.342239</td>
      <td>0.834851</td>
      <td>0.619391</td>
      <td>-0.141902</td>
      <td>-0.382354</td>
      <td>0.359844</td>
      <td>0.821336</td>
      <td>-0.069763</td>
      <td>0.695171</td>
      <td>0.094847</td>
      <td>-0.791050</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-0.890190</td>
      <td>0.200257</td>
      <td>0.823618</td>
      <td>-0.125919</td>
      <td>0.333248</td>
      <td>-0.754732</td>
      <td>-0.888088</td>
      <td>-1.007065</td>
      <td>0.504970</td>
      <td>-0.117437</td>
      <td>0.318717</td>
      <td>0.494012</td>
      <td>0.106091</td>
      <td>-0.761694</td>
      <td>-0.358916</td>
      <td>-0.446516</td>
      <td>0.235034</td>
      <td>0.091671</td>
      <td>-1.112343</td>
      <td>0.272602</td>
      <td>-0.587845</td>
      <td>0.206214</td>
      <td>-0.977430</td>
      <td>0.788875</td>
      <td>0.642168</td>
      <td>0.978099</td>
      <td>0.149414</td>
      <td>-0.896817</td>
      <td>0.583071</td>
      <td>0.354353</td>
      <td>1.297264</td>
      <td>-0.237018</td>
      <td>0.433411</td>
      <td>0.129512</td>
      <td>0.028017</td>
      <td>-0.004604</td>
      <td>0.122331</td>
      <td>0.461509</td>
      <td>0.096885</td>
      <td>-0.001821</td>
      <td>...</td>
      <td>0.335804</td>
      <td>0.721779</td>
      <td>-0.462458</td>
      <td>0.320024</td>
      <td>0.062331</td>
      <td>0.848882</td>
      <td>0.623066</td>
      <td>1.171674</td>
      <td>1.121868</td>
      <td>-0.706108</td>
      <td>0.410649</td>
      <td>-0.008090</td>
      <td>0.282207</td>
      <td>-0.019227</td>
      <td>-0.365766</td>
      <td>-0.332502</td>
      <td>-0.004300</td>
      <td>-0.003086</td>
      <td>0.465222</td>
      <td>0.886402</td>
      <td>0.677865</td>
      <td>0.528864</td>
      <td>-0.080255</td>
      <td>-0.176919</td>
      <td>0.567159</td>
      <td>-0.594029</td>
      <td>-0.704843</td>
      <td>-0.768035</td>
      <td>-0.572646</td>
      <td>0.747803</td>
      <td>0.085783</td>
      <td>-1.219995</td>
      <td>0.493891</td>
      <td>-0.878225</td>
      <td>0.204893</td>
      <td>0.014126</td>
      <td>-0.209577</td>
      <td>-1.067803</td>
      <td>-0.366396</td>
      <td>0.325902</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-0.707553</td>
      <td>-0.633615</td>
      <td>0.471195</td>
      <td>0.853577</td>
      <td>0.604437</td>
      <td>-0.115652</td>
      <td>0.540298</td>
      <td>-0.122411</td>
      <td>-0.296258</td>
      <td>-0.204350</td>
      <td>-0.175920</td>
      <td>0.567947</td>
      <td>0.049114</td>
      <td>0.520232</td>
      <td>0.403692</td>
      <td>-0.876812</td>
      <td>-0.587171</td>
      <td>-0.183813</td>
      <td>0.817098</td>
      <td>0.754900</td>
      <td>-0.365227</td>
      <td>-0.603611</td>
      <td>-0.133022</td>
      <td>0.327419</td>
      <td>-0.777339</td>
      <td>-0.473161</td>
      <td>0.108522</td>
      <td>-0.357912</td>
      <td>0.586172</td>
      <td>-0.061779</td>
      <td>-0.200508</td>
      <td>-0.756924</td>
      <td>1.555397</td>
      <td>-0.020748</td>
      <td>0.712425</td>
      <td>-0.251271</td>
      <td>0.018788</td>
      <td>-1.086722</td>
      <td>-0.755584</td>
      <td>-0.293686</td>
      <td>...</td>
      <td>-0.564468</td>
      <td>-0.015212</td>
      <td>0.617909</td>
      <td>0.431654</td>
      <td>0.651787</td>
      <td>-0.290728</td>
      <td>-0.145168</td>
      <td>-0.200405</td>
      <td>0.216587</td>
      <td>0.378224</td>
      <td>-0.305909</td>
      <td>0.994711</td>
      <td>0.134536</td>
      <td>-0.643135</td>
      <td>0.654335</td>
      <td>-0.520536</td>
      <td>-0.816678</td>
      <td>-1.062591</td>
      <td>0.521025</td>
      <td>-0.076365</td>
      <td>0.075934</td>
      <td>0.884611</td>
      <td>-0.946948</td>
      <td>-0.122457</td>
      <td>-0.448144</td>
      <td>-0.096833</td>
      <td>-0.188190</td>
      <td>0.603878</td>
      <td>-0.946112</td>
      <td>-0.175357</td>
      <td>-0.375673</td>
      <td>-0.685986</td>
      <td>-0.808422</td>
      <td>-0.398949</td>
      <td>-0.392727</td>
      <td>-0.689487</td>
      <td>0.169449</td>
      <td>-0.482936</td>
      <td>-0.086343</td>
      <td>-0.247788</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.237048</td>
      <td>-1.028131</td>
      <td>-0.754612</td>
      <td>0.193273</td>
      <td>0.429472</td>
      <td>-0.173685</td>
      <td>-0.222827</td>
      <td>-0.883359</td>
      <td>-0.037899</td>
      <td>-0.084938</td>
      <td>-0.424351</td>
      <td>0.908056</td>
      <td>-0.035431</td>
      <td>1.085206</td>
      <td>0.087362</td>
      <td>0.405108</td>
      <td>0.083219</td>
      <td>-0.457537</td>
      <td>0.079201</td>
      <td>0.465406</td>
      <td>-0.974714</td>
      <td>0.156147</td>
      <td>-0.412240</td>
      <td>0.263672</td>
      <td>-0.783798</td>
      <td>-0.172473</td>
      <td>0.507688</td>
      <td>-0.269346</td>
      <td>0.393601</td>
      <td>0.799172</td>
      <td>0.489021</td>
      <td>-0.007396</td>
      <td>-0.500487</td>
      <td>-0.846396</td>
      <td>-0.965912</td>
      <td>-1.005140</td>
      <td>-0.253972</td>
      <td>-0.591125</td>
      <td>0.045361</td>
      <td>-0.093409</td>
      <td>...</td>
      <td>-0.632145</td>
      <td>0.340373</td>
      <td>0.295773</td>
      <td>-0.020574</td>
      <td>-0.401065</td>
      <td>0.391329</td>
      <td>0.261103</td>
      <td>0.083043</td>
      <td>-0.274595</td>
      <td>0.127748</td>
      <td>0.419304</td>
      <td>0.999622</td>
      <td>-0.354271</td>
      <td>-0.745359</td>
      <td>-0.271356</td>
      <td>0.057978</td>
      <td>0.453814</td>
      <td>0.624236</td>
      <td>0.470652</td>
      <td>0.685762</td>
      <td>-0.396734</td>
      <td>0.267986</td>
      <td>-0.761521</td>
      <td>0.536576</td>
      <td>1.230911</td>
      <td>0.121600</td>
      <td>0.336592</td>
      <td>-0.055625</td>
      <td>-0.000931</td>
      <td>0.799705</td>
      <td>-0.028815</td>
      <td>1.060161</td>
      <td>0.258749</td>
      <td>-0.618680</td>
      <td>0.142112</td>
      <td>-0.903474</td>
      <td>-1.007244</td>
      <td>-1.630355</td>
      <td>-1.647230</td>
      <td>-0.515892</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.131617</td>
      <td>0.154045</td>
      <td>-0.043927</td>
      <td>0.203927</td>
      <td>0.151075</td>
      <td>0.753507</td>
      <td>1.168244</td>
      <td>-1.133245</td>
      <td>0.111381</td>
      <td>-0.087992</td>
      <td>-0.523449</td>
      <td>0.274482</td>
      <td>0.456394</td>
      <td>-0.521870</td>
      <td>0.163734</td>
      <td>-0.388110</td>
      <td>-0.595105</td>
      <td>-0.174900</td>
      <td>-0.384475</td>
      <td>-0.704647</td>
      <td>0.760916</td>
      <td>0.662118</td>
      <td>-0.640558</td>
      <td>0.429500</td>
      <td>-0.375791</td>
      <td>0.199388</td>
      <td>0.600821</td>
      <td>0.381423</td>
      <td>0.046965</td>
      <td>-0.686027</td>
      <td>0.243455</td>
      <td>0.515739</td>
      <td>0.370857</td>
      <td>-0.453378</td>
      <td>-0.322296</td>
      <td>-1.561165</td>
      <td>0.216803</td>
      <td>-0.327052</td>
      <td>0.029064</td>
      <td>-0.594947</td>
      <td>...</td>
      <td>0.294899</td>
      <td>0.856606</td>
      <td>-0.723452</td>
      <td>1.088315</td>
      <td>-0.557184</td>
      <td>-0.439117</td>
      <td>0.182689</td>
      <td>1.485980</td>
      <td>0.518109</td>
      <td>-0.123084</td>
      <td>0.474211</td>
      <td>0.152482</td>
      <td>0.044060</td>
      <td>-0.264248</td>
      <td>0.360336</td>
      <td>-0.494664</td>
      <td>0.134624</td>
      <td>-0.106658</td>
      <td>-0.085861</td>
      <td>0.550631</td>
      <td>-0.829088</td>
      <td>0.600261</td>
      <td>0.075127</td>
      <td>0.482515</td>
      <td>1.078012</td>
      <td>-0.199956</td>
      <td>0.271574</td>
      <td>0.666854</td>
      <td>-0.319796</td>
      <td>0.484709</td>
      <td>0.057515</td>
      <td>-0.528040</td>
      <td>-0.241549</td>
      <td>-0.261025</td>
      <td>-0.294474</td>
      <td>-0.546547</td>
      <td>0.318443</td>
      <td>1.337511</td>
      <td>0.552646</td>
      <td>-0.135540</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.040855</td>
      <td>0.375337</td>
      <td>0.039491</td>
      <td>0.653952</td>
      <td>0.537103</td>
      <td>0.690138</td>
      <td>-0.102349</td>
      <td>-0.760841</td>
      <td>0.854391</td>
      <td>-0.403132</td>
      <td>-0.232353</td>
      <td>0.736666</td>
      <td>-0.248022</td>
      <td>-0.000966</td>
      <td>0.245811</td>
      <td>0.194662</td>
      <td>0.665980</td>
      <td>-0.150262</td>
      <td>0.297701</td>
      <td>0.818190</td>
      <td>0.676515</td>
      <td>-0.227410</td>
      <td>0.358131</td>
      <td>0.180198</td>
      <td>-0.667819</td>
      <td>1.279544</td>
      <td>0.138751</td>
      <td>-0.760248</td>
      <td>0.001313</td>
      <td>-0.197039</td>
      <td>-0.633630</td>
      <td>0.049899</td>
      <td>-0.744330</td>
      <td>-0.412798</td>
      <td>0.384420</td>
      <td>0.298594</td>
      <td>0.549186</td>
      <td>-0.259271</td>
      <td>-0.322099</td>
      <td>-0.459471</td>
      <td>...</td>
      <td>-0.190723</td>
      <td>0.188630</td>
      <td>-0.882279</td>
      <td>-0.371209</td>
      <td>0.847942</td>
      <td>-0.015044</td>
      <td>0.528341</td>
      <td>1.503638</td>
      <td>0.499844</td>
      <td>0.835495</td>
      <td>-0.102571</td>
      <td>0.570016</td>
      <td>0.257063</td>
      <td>-0.030637</td>
      <td>-0.644656</td>
      <td>0.078410</td>
      <td>0.121011</td>
      <td>-0.255089</td>
      <td>0.766218</td>
      <td>0.351827</td>
      <td>0.509389</td>
      <td>0.159224</td>
      <td>-0.326229</td>
      <td>-0.137993</td>
      <td>0.154889</td>
      <td>-1.245316</td>
      <td>0.125215</td>
      <td>-0.147001</td>
      <td>-0.427672</td>
      <td>0.653645</td>
      <td>-0.503185</td>
      <td>0.344923</td>
      <td>0.541565</td>
      <td>0.722639</td>
      <td>-0.193397</td>
      <td>-0.061338</td>
      <td>0.249653</td>
      <td>-0.969797</td>
      <td>-0.626941</td>
      <td>-0.264796</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.482066</td>
      <td>-1.219116</td>
      <td>0.082276</td>
      <td>0.306246</td>
      <td>0.115562</td>
      <td>-0.684623</td>
      <td>-0.092349</td>
      <td>-0.215049</td>
      <td>-0.075327</td>
      <td>1.342914</td>
      <td>0.124997</td>
      <td>0.985265</td>
      <td>-0.352859</td>
      <td>0.771309</td>
      <td>0.414740</td>
      <td>-0.142401</td>
      <td>-0.725904</td>
      <td>0.488731</td>
      <td>0.088945</td>
      <td>-0.648005</td>
      <td>-0.586666</td>
      <td>0.605456</td>
      <td>0.525601</td>
      <td>0.022391</td>
      <td>-0.920585</td>
      <td>0.567226</td>
      <td>0.234625</td>
      <td>-0.531770</td>
      <td>-0.252504</td>
      <td>0.572452</td>
      <td>-0.092578</td>
      <td>0.259115</td>
      <td>-0.673290</td>
      <td>-0.546388</td>
      <td>-0.385780</td>
      <td>-0.465752</td>
      <td>1.128618</td>
      <td>0.858865</td>
      <td>0.348824</td>
      <td>0.036614</td>
      <td>...</td>
      <td>-0.788189</td>
      <td>-0.631057</td>
      <td>-0.337772</td>
      <td>0.293980</td>
      <td>0.484031</td>
      <td>-0.419059</td>
      <td>0.337712</td>
      <td>0.078331</td>
      <td>-0.117706</td>
      <td>-0.427298</td>
      <td>-0.207136</td>
      <td>-0.422753</td>
      <td>-0.942523</td>
      <td>-0.655095</td>
      <td>-0.316206</td>
      <td>-0.110052</td>
      <td>-0.520952</td>
      <td>-0.237790</td>
      <td>-0.178565</td>
      <td>-1.594158</td>
      <td>0.067509</td>
      <td>0.630719</td>
      <td>-1.089785</td>
      <td>0.106004</td>
      <td>0.914205</td>
      <td>0.425448</td>
      <td>0.417852</td>
      <td>0.857779</td>
      <td>0.287011</td>
      <td>0.667819</td>
      <td>0.399587</td>
      <td>0.610650</td>
      <td>0.573147</td>
      <td>-0.294214</td>
      <td>0.563084</td>
      <td>0.287458</td>
      <td>0.221321</td>
      <td>-2.158665</td>
      <td>-1.358349</td>
      <td>-0.526176</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-0.905845</td>
      <td>-1.190331</td>
      <td>0.046915</td>
      <td>0.311488</td>
      <td>-0.051536</td>
      <td>-0.270490</td>
      <td>-0.230732</td>
      <td>0.516144</td>
      <td>0.052045</td>
      <td>0.284594</td>
      <td>0.167872</td>
      <td>0.837953</td>
      <td>0.787454</td>
      <td>0.144181</td>
      <td>-0.327931</td>
      <td>-0.389462</td>
      <td>-0.003274</td>
      <td>-0.295934</td>
      <td>-0.619960</td>
      <td>-0.196641</td>
      <td>-0.638460</td>
      <td>-0.045004</td>
      <td>0.443147</td>
      <td>0.486401</td>
      <td>-0.601808</td>
      <td>0.559233</td>
      <td>-0.562789</td>
      <td>-0.394536</td>
      <td>0.410300</td>
      <td>-0.428700</td>
      <td>0.276646</td>
      <td>0.092670</td>
      <td>-0.014308</td>
      <td>0.104639</td>
      <td>0.726567</td>
      <td>0.096838</td>
      <td>-0.597280</td>
      <td>-0.590154</td>
      <td>0.286619</td>
      <td>0.010519</td>
      <td>...</td>
      <td>-0.051426</td>
      <td>-0.164974</td>
      <td>0.721052</td>
      <td>0.194129</td>
      <td>-1.048835</td>
      <td>-0.911482</td>
      <td>0.297489</td>
      <td>0.388409</td>
      <td>0.808230</td>
      <td>0.160401</td>
      <td>0.270269</td>
      <td>-0.324071</td>
      <td>0.013093</td>
      <td>0.047507</td>
      <td>-0.176529</td>
      <td>-0.086862</td>
      <td>-1.475165</td>
      <td>-1.104656</td>
      <td>0.112082</td>
      <td>0.530023</td>
      <td>-0.090377</td>
      <td>-0.070608</td>
      <td>-0.488892</td>
      <td>-0.228478</td>
      <td>-0.058924</td>
      <td>-0.317790</td>
      <td>-0.789843</td>
      <td>-0.037731</td>
      <td>-0.054926</td>
      <td>0.089752</td>
      <td>-0.573570</td>
      <td>-0.674197</td>
      <td>0.281247</td>
      <td>0.033405</td>
      <td>-0.681725</td>
      <td>-0.532050</td>
      <td>-0.224715</td>
      <td>-1.773150</td>
      <td>-2.061066</td>
      <td>-2.171631</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-0.178483</td>
      <td>-1.188172</td>
      <td>-1.069843</td>
      <td>0.817343</td>
      <td>0.023581</td>
      <td>0.568675</td>
      <td>0.775729</td>
      <td>0.866593</td>
      <td>0.927743</td>
      <td>1.068832</td>
      <td>0.068897</td>
      <td>1.296959</td>
      <td>0.141773</td>
      <td>-0.608420</td>
      <td>-0.432089</td>
      <td>-0.192202</td>
      <td>0.539816</td>
      <td>0.237609</td>
      <td>-0.089671</td>
      <td>-0.606533</td>
      <td>0.401030</td>
      <td>0.244637</td>
      <td>-0.600577</td>
      <td>0.173683</td>
      <td>0.180008</td>
      <td>0.429406</td>
      <td>0.549148</td>
      <td>-0.335115</td>
      <td>0.955168</td>
      <td>0.108768</td>
      <td>-0.454641</td>
      <td>0.056680</td>
      <td>-0.111207</td>
      <td>-0.149232</td>
      <td>-0.489752</td>
      <td>-1.242217</td>
      <td>0.628375</td>
      <td>-1.073578</td>
      <td>-0.186156</td>
      <td>-0.158884</td>
      <td>...</td>
      <td>0.419070</td>
      <td>-0.022651</td>
      <td>-0.471939</td>
      <td>0.386741</td>
      <td>0.303877</td>
      <td>0.312501</td>
      <td>-0.445446</td>
      <td>0.352063</td>
      <td>0.074430</td>
      <td>0.528393</td>
      <td>0.038361</td>
      <td>-0.673985</td>
      <td>0.848459</td>
      <td>-1.105766</td>
      <td>-0.225040</td>
      <td>-0.861191</td>
      <td>-1.417384</td>
      <td>-0.185237</td>
      <td>-1.138424</td>
      <td>0.158096</td>
      <td>0.758245</td>
      <td>1.613608</td>
      <td>-0.089230</td>
      <td>0.720086</td>
      <td>0.374886</td>
      <td>0.922243</td>
      <td>-0.501955</td>
      <td>0.311847</td>
      <td>1.041553</td>
      <td>1.867613</td>
      <td>0.541478</td>
      <td>-0.360464</td>
      <td>-0.444792</td>
      <td>-0.359406</td>
      <td>0.756185</td>
      <td>0.096916</td>
      <td>-0.180167</td>
      <td>-3.628455</td>
      <td>-2.232244</td>
      <td>-1.690668</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.441775</td>
      <td>-0.982329</td>
      <td>0.185112</td>
      <td>-0.253465</td>
      <td>-0.342990</td>
      <td>-0.526085</td>
      <td>-0.164194</td>
      <td>-0.809435</td>
      <td>-0.849365</td>
      <td>0.401310</td>
      <td>-0.347951</td>
      <td>0.320353</td>
      <td>-0.622075</td>
      <td>0.143812</td>
      <td>0.502912</td>
      <td>0.182404</td>
      <td>0.034466</td>
      <td>0.336922</td>
      <td>0.002934</td>
      <td>0.719911</td>
      <td>-0.734938</td>
      <td>-1.157964</td>
      <td>-0.463880</td>
      <td>0.586112</td>
      <td>0.102836</td>
      <td>0.084220</td>
      <td>-0.112048</td>
      <td>-0.687359</td>
      <td>0.594371</td>
      <td>-0.252713</td>
      <td>0.693484</td>
      <td>-0.409057</td>
      <td>-1.135619</td>
      <td>-0.394210</td>
      <td>-0.436503</td>
      <td>0.294474</td>
      <td>0.661010</td>
      <td>-0.171934</td>
      <td>0.079975</td>
      <td>1.201882</td>
      <td>...</td>
      <td>0.113077</td>
      <td>0.854122</td>
      <td>0.514118</td>
      <td>-0.127749</td>
      <td>-0.553228</td>
      <td>-0.064811</td>
      <td>0.118713</td>
      <td>1.178070</td>
      <td>-0.071906</td>
      <td>-0.018580</td>
      <td>0.651231</td>
      <td>0.270022</td>
      <td>-0.306974</td>
      <td>-0.376519</td>
      <td>0.476211</td>
      <td>0.092643</td>
      <td>-0.760685</td>
      <td>-0.193266</td>
      <td>0.615292</td>
      <td>0.433707</td>
      <td>0.749038</td>
      <td>-0.042012</td>
      <td>-0.404952</td>
      <td>0.377307</td>
      <td>0.104359</td>
      <td>0.338536</td>
      <td>-0.766804</td>
      <td>0.096145</td>
      <td>-0.127059</td>
      <td>0.470219</td>
      <td>0.221896</td>
      <td>0.360309</td>
      <td>0.592312</td>
      <td>-0.600740</td>
      <td>0.771736</td>
      <td>0.326551</td>
      <td>-0.194525</td>
      <td>-1.698156</td>
      <td>-0.916533</td>
      <td>-0.957090</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.668029</td>
      <td>-1.163684</td>
      <td>0.289495</td>
      <td>-0.062163</td>
      <td>-0.718871</td>
      <td>0.450404</td>
      <td>-0.813121</td>
      <td>-0.069671</td>
      <td>-0.330658</td>
      <td>-0.478539</td>
      <td>0.686348</td>
      <td>1.056265</td>
      <td>0.195937</td>
      <td>0.703517</td>
      <td>0.230110</td>
      <td>-0.211778</td>
      <td>-0.260298</td>
      <td>-1.349593</td>
      <td>-0.036901</td>
      <td>-0.223323</td>
      <td>0.174727</td>
      <td>0.055082</td>
      <td>-0.340345</td>
      <td>0.812128</td>
      <td>-0.868096</td>
      <td>-0.167574</td>
      <td>0.214192</td>
      <td>-1.136440</td>
      <td>-0.002403</td>
      <td>-0.296362</td>
      <td>-0.419467</td>
      <td>-0.818728</td>
      <td>-0.069891</td>
      <td>0.725505</td>
      <td>-0.911169</td>
      <td>0.138422</td>
      <td>1.161335</td>
      <td>-0.003133</td>
      <td>0.343288</td>
      <td>0.768930</td>
      <td>...</td>
      <td>-0.544592</td>
      <td>-1.193432</td>
      <td>-0.760588</td>
      <td>0.645069</td>
      <td>0.257225</td>
      <td>-0.217220</td>
      <td>-0.263049</td>
      <td>1.195365</td>
      <td>1.384258</td>
      <td>-0.133445</td>
      <td>0.303683</td>
      <td>0.132408</td>
      <td>-0.411063</td>
      <td>-1.314466</td>
      <td>-1.080446</td>
      <td>-0.169996</td>
      <td>-0.589289</td>
      <td>0.360172</td>
      <td>0.620521</td>
      <td>0.648360</td>
      <td>0.743734</td>
      <td>0.969662</td>
      <td>0.843735</td>
      <td>0.298749</td>
      <td>1.016149</td>
      <td>0.782502</td>
      <td>0.810101</td>
      <td>0.127728</td>
      <td>0.178129</td>
      <td>0.405571</td>
      <td>0.123388</td>
      <td>-0.617561</td>
      <td>-0.290926</td>
      <td>-0.218517</td>
      <td>-0.720825</td>
      <td>-0.357457</td>
      <td>-1.033300</td>
      <td>-1.110169</td>
      <td>-0.500528</td>
      <td>0.133799</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.236667</td>
      <td>-1.327989</td>
      <td>0.217095</td>
      <td>0.715819</td>
      <td>-1.186929</td>
      <td>-1.055851</td>
      <td>0.570626</td>
      <td>0.096196</td>
      <td>-0.364444</td>
      <td>0.411683</td>
      <td>0.003767</td>
      <td>1.052582</td>
      <td>0.238109</td>
      <td>0.340261</td>
      <td>-0.189381</td>
      <td>-0.413782</td>
      <td>-0.888617</td>
      <td>-0.093349</td>
      <td>-0.377976</td>
      <td>0.031195</td>
      <td>-1.259563</td>
      <td>-1.453220</td>
      <td>0.202210</td>
      <td>0.260625</td>
      <td>-0.067817</td>
      <td>0.710376</td>
      <td>1.124159</td>
      <td>-0.351224</td>
      <td>0.817585</td>
      <td>0.029652</td>
      <td>-0.110910</td>
      <td>-0.011187</td>
      <td>0.410957</td>
      <td>0.017215</td>
      <td>-1.138102</td>
      <td>-1.232359</td>
      <td>0.447640</td>
      <td>-0.863902</td>
      <td>-0.085261</td>
      <td>0.194092</td>
      <td>...</td>
      <td>0.480799</td>
      <td>1.029331</td>
      <td>-0.260622</td>
      <td>-0.459341</td>
      <td>-0.938007</td>
      <td>0.039795</td>
      <td>0.473754</td>
      <td>1.003935</td>
      <td>0.270044</td>
      <td>0.082087</td>
      <td>0.542483</td>
      <td>-0.398154</td>
      <td>0.010095</td>
      <td>-0.482510</td>
      <td>0.737230</td>
      <td>1.400975</td>
      <td>-0.004458</td>
      <td>-0.629741</td>
      <td>0.558349</td>
      <td>0.468711</td>
      <td>0.395736</td>
      <td>1.989534</td>
      <td>1.247593</td>
      <td>0.402760</td>
      <td>0.666309</td>
      <td>0.463696</td>
      <td>0.270399</td>
      <td>-0.158322</td>
      <td>-0.846212</td>
      <td>1.264592</td>
      <td>0.136259</td>
      <td>-0.756971</td>
      <td>0.029758</td>
      <td>-0.275706</td>
      <td>-0.401377</td>
      <td>-0.527539</td>
      <td>0.563665</td>
      <td>1.118626</td>
      <td>0.609669</td>
      <td>-0.185734</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.684021</td>
      <td>0.088277</td>
      <td>-1.324701</td>
      <td>-0.345134</td>
      <td>0.035338</td>
      <td>-0.909063</td>
      <td>-0.315845</td>
      <td>-1.073737</td>
      <td>0.923530</td>
      <td>0.120299</td>
      <td>-0.583722</td>
      <td>0.440384</td>
      <td>-0.819359</td>
      <td>-0.388127</td>
      <td>0.691594</td>
      <td>0.654539</td>
      <td>-0.441667</td>
      <td>0.168473</td>
      <td>0.383829</td>
      <td>0.651291</td>
      <td>-0.087521</td>
      <td>0.583553</td>
      <td>-1.303954</td>
      <td>0.380099</td>
      <td>-1.269649</td>
      <td>-0.835920</td>
      <td>0.314564</td>
      <td>-0.657299</td>
      <td>-0.452390</td>
      <td>-0.372307</td>
      <td>0.382640</td>
      <td>-0.056910</td>
      <td>-0.376741</td>
      <td>0.024890</td>
      <td>-0.264676</td>
      <td>-0.014984</td>
      <td>0.139475</td>
      <td>-0.431043</td>
      <td>-0.519181</td>
      <td>0.629535</td>
      <td>...</td>
      <td>0.948498</td>
      <td>0.190736</td>
      <td>-0.389125</td>
      <td>-0.626464</td>
      <td>-0.087769</td>
      <td>0.336556</td>
      <td>0.057479</td>
      <td>0.640190</td>
      <td>0.265420</td>
      <td>0.277734</td>
      <td>0.844385</td>
      <td>0.502863</td>
      <td>0.021389</td>
      <td>-0.998018</td>
      <td>-1.620191</td>
      <td>-0.455073</td>
      <td>0.171278</td>
      <td>0.069758</td>
      <td>-0.643937</td>
      <td>-0.894290</td>
      <td>-0.111898</td>
      <td>0.342124</td>
      <td>-0.134691</td>
      <td>0.689785</td>
      <td>1.468770</td>
      <td>1.015911</td>
      <td>-0.256310</td>
      <td>0.060492</td>
      <td>0.267667</td>
      <td>0.422429</td>
      <td>0.471484</td>
      <td>0.877085</td>
      <td>0.697657</td>
      <td>0.522565</td>
      <td>0.376617</td>
      <td>1.133151</td>
      <td>-0.520754</td>
      <td>2.633622</td>
      <td>1.909574</td>
      <td>1.420085</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.783888</td>
      <td>-0.103942</td>
      <td>-0.979598</td>
      <td>0.341233</td>
      <td>-0.256355</td>
      <td>-0.045435</td>
      <td>0.981881</td>
      <td>0.328998</td>
      <td>0.234731</td>
      <td>0.378980</td>
      <td>-0.474356</td>
      <td>-0.456996</td>
      <td>0.361865</td>
      <td>0.687629</td>
      <td>1.123781</td>
      <td>-0.531640</td>
      <td>-0.351723</td>
      <td>-0.041198</td>
      <td>-0.026179</td>
      <td>0.468453</td>
      <td>0.656101</td>
      <td>0.129011</td>
      <td>-0.863192</td>
      <td>0.579564</td>
      <td>0.840359</td>
      <td>0.504118</td>
      <td>-0.007345</td>
      <td>-0.552245</td>
      <td>0.480135</td>
      <td>0.941348</td>
      <td>0.092972</td>
      <td>-0.281292</td>
      <td>0.552878</td>
      <td>0.182649</td>
      <td>-0.844393</td>
      <td>-0.064565</td>
      <td>1.240005</td>
      <td>0.189645</td>
      <td>0.231793</td>
      <td>-0.347614</td>
      <td>...</td>
      <td>0.796622</td>
      <td>-0.664381</td>
      <td>-0.033395</td>
      <td>0.144523</td>
      <td>0.322434</td>
      <td>-0.264135</td>
      <td>-0.741621</td>
      <td>1.098903</td>
      <td>1.606270</td>
      <td>0.379789</td>
      <td>-0.276782</td>
      <td>-0.694891</td>
      <td>0.070612</td>
      <td>-0.279320</td>
      <td>-0.002481</td>
      <td>0.042785</td>
      <td>-0.469282</td>
      <td>-0.584795</td>
      <td>-0.980006</td>
      <td>0.279103</td>
      <td>0.340792</td>
      <td>0.328746</td>
      <td>0.885130</td>
      <td>0.583109</td>
      <td>0.135453</td>
      <td>-0.958295</td>
      <td>-1.002658</td>
      <td>-0.495442</td>
      <td>0.534901</td>
      <td>-0.570860</td>
      <td>0.128263</td>
      <td>-0.161522</td>
      <td>-0.393883</td>
      <td>-0.162512</td>
      <td>0.554212</td>
      <td>-0.334699</td>
      <td>-0.384818</td>
      <td>-2.402776</td>
      <td>-1.433079</td>
      <td>-0.775637</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.402095</td>
      <td>-0.984907</td>
      <td>-0.062100</td>
      <td>0.629018</td>
      <td>-0.226058</td>
      <td>0.165007</td>
      <td>1.692577</td>
      <td>1.212008</td>
      <td>0.112683</td>
      <td>-0.624125</td>
      <td>-0.621656</td>
      <td>0.401922</td>
      <td>0.013208</td>
      <td>0.243804</td>
      <td>-0.088434</td>
      <td>-0.502272</td>
      <td>-0.439346</td>
      <td>-0.389677</td>
      <td>0.146530</td>
      <td>0.058267</td>
      <td>0.419607</td>
      <td>-0.066628</td>
      <td>0.969694</td>
      <td>0.259251</td>
      <td>-0.042996</td>
      <td>-0.321871</td>
      <td>0.420213</td>
      <td>0.409789</td>
      <td>0.161979</td>
      <td>0.593453</td>
      <td>-0.968836</td>
      <td>-1.197080</td>
      <td>0.034167</td>
      <td>0.006782</td>
      <td>0.182044</td>
      <td>0.734662</td>
      <td>0.198400</td>
      <td>-0.126665</td>
      <td>0.594553</td>
      <td>0.260712</td>
      <td>...</td>
      <td>0.514897</td>
      <td>0.410546</td>
      <td>-0.488523</td>
      <td>-0.142130</td>
      <td>-0.469054</td>
      <td>0.796992</td>
      <td>0.053903</td>
      <td>1.055764</td>
      <td>1.429711</td>
      <td>0.840945</td>
      <td>-1.073047</td>
      <td>-1.689912</td>
      <td>-1.197739</td>
      <td>-0.698771</td>
      <td>0.145122</td>
      <td>-0.265860</td>
      <td>-1.163827</td>
      <td>-0.333197</td>
      <td>-0.182877</td>
      <td>0.258520</td>
      <td>0.491157</td>
      <td>0.806296</td>
      <td>0.201293</td>
      <td>0.544959</td>
      <td>-0.059548</td>
      <td>0.280522</td>
      <td>0.027612</td>
      <td>0.075351</td>
      <td>1.070168</td>
      <td>0.994759</td>
      <td>-0.447531</td>
      <td>0.632356</td>
      <td>-0.463364</td>
      <td>0.471633</td>
      <td>-0.428424</td>
      <td>-0.038490</td>
      <td>-1.245094</td>
      <td>-0.978113</td>
      <td>-0.655835</td>
      <td>-0.071721</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.527209</td>
      <td>-0.498261</td>
      <td>0.457674</td>
      <td>1.594577</td>
      <td>0.009510</td>
      <td>-0.607194</td>
      <td>-0.450169</td>
      <td>-1.053800</td>
      <td>-0.725414</td>
      <td>0.131878</td>
      <td>-0.515569</td>
      <td>-0.062038</td>
      <td>-0.683990</td>
      <td>0.223658</td>
      <td>0.764723</td>
      <td>-0.848871</td>
      <td>0.042742</td>
      <td>0.986430</td>
      <td>-0.207331</td>
      <td>0.225238</td>
      <td>0.202176</td>
      <td>0.567645</td>
      <td>0.173035</td>
      <td>0.925938</td>
      <td>-0.311231</td>
      <td>-0.093843</td>
      <td>0.364556</td>
      <td>0.005185</td>
      <td>0.402678</td>
      <td>-0.273211</td>
      <td>-0.189929</td>
      <td>0.458234</td>
      <td>-0.558769</td>
      <td>0.042120</td>
      <td>0.113500</td>
      <td>0.018236</td>
      <td>0.206360</td>
      <td>-0.312899</td>
      <td>0.272595</td>
      <td>-0.347082</td>
      <td>...</td>
      <td>-0.043458</td>
      <td>0.593953</td>
      <td>0.387796</td>
      <td>-0.468893</td>
      <td>-0.708436</td>
      <td>0.659799</td>
      <td>-0.694352</td>
      <td>0.937361</td>
      <td>0.294394</td>
      <td>-0.660548</td>
      <td>0.411500</td>
      <td>0.760954</td>
      <td>-0.078435</td>
      <td>0.052060</td>
      <td>0.773689</td>
      <td>0.181754</td>
      <td>0.453856</td>
      <td>0.139509</td>
      <td>-0.402071</td>
      <td>-0.691181</td>
      <td>-0.477468</td>
      <td>-0.019075</td>
      <td>-0.859343</td>
      <td>0.608093</td>
      <td>1.077811</td>
      <td>0.164621</td>
      <td>1.551355</td>
      <td>1.321038</td>
      <td>0.313198</td>
      <td>-0.039369</td>
      <td>-0.450486</td>
      <td>0.129478</td>
      <td>1.129225</td>
      <td>0.743929</td>
      <td>0.249604</td>
      <td>0.434595</td>
      <td>0.270126</td>
      <td>-0.785067</td>
      <td>0.127028</td>
      <td>-0.710614</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-0.341530</td>
      <td>-1.539444</td>
      <td>-1.051077</td>
      <td>0.120110</td>
      <td>-0.497874</td>
      <td>-0.283143</td>
      <td>0.762927</td>
      <td>0.101509</td>
      <td>0.621549</td>
      <td>0.051179</td>
      <td>-0.836992</td>
      <td>-1.634061</td>
      <td>-0.235593</td>
      <td>0.158472</td>
      <td>-0.235916</td>
      <td>-0.409219</td>
      <td>-1.099953</td>
      <td>-0.221726</td>
      <td>-0.975302</td>
      <td>-0.314925</td>
      <td>-0.140859</td>
      <td>-0.709008</td>
      <td>-0.593375</td>
      <td>-0.593258</td>
      <td>-1.106390</td>
      <td>-0.820365</td>
      <td>0.311429</td>
      <td>-1.338745</td>
      <td>-0.497590</td>
      <td>0.250704</td>
      <td>0.948955</td>
      <td>-0.218731</td>
      <td>-0.106825</td>
      <td>-0.895205</td>
      <td>0.732430</td>
      <td>-0.320465</td>
      <td>-0.162384</td>
      <td>-0.313595</td>
      <td>0.054693</td>
      <td>-0.021009</td>
      <td>...</td>
      <td>-1.621863</td>
      <td>-0.182107</td>
      <td>-0.027406</td>
      <td>-0.611824</td>
      <td>-0.846045</td>
      <td>-0.148909</td>
      <td>0.054199</td>
      <td>0.007602</td>
      <td>-0.093348</td>
      <td>-0.400553</td>
      <td>0.467921</td>
      <td>1.088865</td>
      <td>0.277464</td>
      <td>-0.896476</td>
      <td>0.180838</td>
      <td>0.790470</td>
      <td>0.043401</td>
      <td>-0.424803</td>
      <td>0.019813</td>
      <td>0.645886</td>
      <td>0.274575</td>
      <td>1.819494</td>
      <td>-0.055200</td>
      <td>1.125287</td>
      <td>-0.041597</td>
      <td>-0.794649</td>
      <td>0.095435</td>
      <td>1.195358</td>
      <td>0.243301</td>
      <td>0.767320</td>
      <td>0.428166</td>
      <td>0.535007</td>
      <td>-0.002239</td>
      <td>0.325023</td>
      <td>0.298194</td>
      <td>-0.108084</td>
      <td>-0.760603</td>
      <td>-4.162357</td>
      <td>-3.257091</td>
      <td>-1.874785</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>0.233341</td>
      <td>0.335588</td>
      <td>-0.209108</td>
      <td>-0.716438</td>
      <td>-0.120305</td>
      <td>-0.988152</td>
      <td>-0.348608</td>
      <td>-0.131410</td>
      <td>-0.145352</td>
      <td>-0.207846</td>
      <td>0.703454</td>
      <td>0.483093</td>
      <td>0.936067</td>
      <td>-0.576972</td>
      <td>0.688451</td>
      <td>0.718481</td>
      <td>0.520106</td>
      <td>-0.516775</td>
      <td>-1.145741</td>
      <td>-0.261195</td>
      <td>-0.877157</td>
      <td>0.299766</td>
      <td>1.082212</td>
      <td>0.108292</td>
      <td>0.364296</td>
      <td>0.355986</td>
      <td>0.052470</td>
      <td>0.198493</td>
      <td>0.892928</td>
      <td>-0.396696</td>
      <td>-0.694208</td>
      <td>1.453537</td>
      <td>1.357895</td>
      <td>-0.194041</td>
      <td>-0.692442</td>
      <td>-0.288028</td>
      <td>0.503913</td>
      <td>0.767095</td>
      <td>-0.383822</td>
      <td>-1.019795</td>
      <td>...</td>
      <td>-0.117354</td>
      <td>0.695441</td>
      <td>-0.573987</td>
      <td>-0.396459</td>
      <td>0.462630</td>
      <td>-0.054784</td>
      <td>-0.597695</td>
      <td>-0.337923</td>
      <td>0.143001</td>
      <td>1.029439</td>
      <td>-0.610986</td>
      <td>0.308383</td>
      <td>0.999223</td>
      <td>0.935405</td>
      <td>0.760212</td>
      <td>0.285045</td>
      <td>-0.480094</td>
      <td>-0.720286</td>
      <td>-0.461347</td>
      <td>-0.409976</td>
      <td>-0.106785</td>
      <td>0.110008</td>
      <td>0.012952</td>
      <td>1.019207</td>
      <td>0.293922</td>
      <td>-0.016684</td>
      <td>-0.325985</td>
      <td>-0.360289</td>
      <td>0.853147</td>
      <td>0.031767</td>
      <td>-0.916901</td>
      <td>0.162621</td>
      <td>-0.710856</td>
      <td>-0.690188</td>
      <td>0.098578</td>
      <td>0.389056</td>
      <td>0.430381</td>
      <td>0.965463</td>
      <td>0.831500</td>
      <td>0.525294</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.376841</td>
      <td>-0.095849</td>
      <td>-0.188975</td>
      <td>0.275377</td>
      <td>0.172517</td>
      <td>0.172548</td>
      <td>-0.878812</td>
      <td>-0.289596</td>
      <td>0.085353</td>
      <td>1.079364</td>
      <td>0.523079</td>
      <td>0.152724</td>
      <td>0.926763</td>
      <td>0.031392</td>
      <td>-0.557202</td>
      <td>0.437722</td>
      <td>-0.774709</td>
      <td>0.025336</td>
      <td>-0.149585</td>
      <td>-0.452326</td>
      <td>-0.907712</td>
      <td>0.082991</td>
      <td>0.104159</td>
      <td>-0.221588</td>
      <td>-0.710359</td>
      <td>-0.257376</td>
      <td>0.432920</td>
      <td>0.731358</td>
      <td>-0.318689</td>
      <td>0.835528</td>
      <td>-0.402499</td>
      <td>0.308483</td>
      <td>-0.695468</td>
      <td>-0.687737</td>
      <td>0.087527</td>
      <td>0.881969</td>
      <td>0.239653</td>
      <td>-0.583522</td>
      <td>-0.051295</td>
      <td>-0.113921</td>
      <td>...</td>
      <td>0.648400</td>
      <td>1.375504</td>
      <td>0.714331</td>
      <td>-0.072906</td>
      <td>-0.708583</td>
      <td>-0.270348</td>
      <td>0.411831</td>
      <td>-0.862786</td>
      <td>0.551039</td>
      <td>0.642812</td>
      <td>-0.540710</td>
      <td>-0.189355</td>
      <td>0.312438</td>
      <td>0.716796</td>
      <td>0.585529</td>
      <td>1.430830</td>
      <td>-0.387813</td>
      <td>-1.767499</td>
      <td>-0.477239</td>
      <td>-0.212846</td>
      <td>0.016108</td>
      <td>0.664809</td>
      <td>-0.936037</td>
      <td>-0.228865</td>
      <td>0.727532</td>
      <td>0.137515</td>
      <td>-0.462126</td>
      <td>-0.434316</td>
      <td>0.212038</td>
      <td>-0.400969</td>
      <td>-0.124023</td>
      <td>-0.286102</td>
      <td>0.155968</td>
      <td>-0.142595</td>
      <td>1.154339</td>
      <td>1.368583</td>
      <td>0.459571</td>
      <td>-0.255829</td>
      <td>0.733240</td>
      <td>0.288082</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.079953</td>
      <td>0.059880</td>
      <td>-0.805182</td>
      <td>0.001924</td>
      <td>0.901173</td>
      <td>-0.044123</td>
      <td>-0.188791</td>
      <td>0.274258</td>
      <td>2.048567</td>
      <td>0.885778</td>
      <td>-0.355236</td>
      <td>-0.346643</td>
      <td>0.518661</td>
      <td>-1.166418</td>
      <td>-1.174999</td>
      <td>0.420871</td>
      <td>0.284035</td>
      <td>-0.273794</td>
      <td>0.304735</td>
      <td>-0.396741</td>
      <td>0.218700</td>
      <td>0.570054</td>
      <td>-0.363174</td>
      <td>0.163931</td>
      <td>-0.618156</td>
      <td>-0.401830</td>
      <td>-1.263316</td>
      <td>0.659896</td>
      <td>1.042501</td>
      <td>0.542232</td>
      <td>-0.294290</td>
      <td>-0.289713</td>
      <td>-0.739258</td>
      <td>0.168926</td>
      <td>-0.220459</td>
      <td>-0.130358</td>
      <td>-1.043951</td>
      <td>-0.799708</td>
      <td>-0.711279</td>
      <td>-0.100659</td>
      <td>...</td>
      <td>-0.016192</td>
      <td>0.508010</td>
      <td>-0.875443</td>
      <td>-0.874887</td>
      <td>0.184418</td>
      <td>0.073335</td>
      <td>-0.623440</td>
      <td>-1.079700</td>
      <td>0.367206</td>
      <td>0.980792</td>
      <td>-0.461250</td>
      <td>0.785373</td>
      <td>0.067986</td>
      <td>0.945128</td>
      <td>0.560854</td>
      <td>-0.508639</td>
      <td>-0.916912</td>
      <td>-0.855667</td>
      <td>-0.483910</td>
      <td>0.670171</td>
      <td>-0.154290</td>
      <td>0.912307</td>
      <td>-0.152004</td>
      <td>-0.007946</td>
      <td>-0.531173</td>
      <td>-0.791056</td>
      <td>0.125631</td>
      <td>0.550254</td>
      <td>0.070262</td>
      <td>0.020969</td>
      <td>-1.019418</td>
      <td>-1.507301</td>
      <td>-0.543635</td>
      <td>-0.055733</td>
      <td>0.285636</td>
      <td>0.537117</td>
      <td>0.465611</td>
      <td>0.363197</td>
      <td>0.437762</td>
      <td>-0.359277</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.027560</td>
      <td>0.169516</td>
      <td>0.279261</td>
      <td>0.100791</td>
      <td>1.965666</td>
      <td>1.064350</td>
      <td>-0.180189</td>
      <td>0.784121</td>
      <td>0.157542</td>
      <td>0.141007</td>
      <td>-0.266466</td>
      <td>-1.511281</td>
      <td>-0.569180</td>
      <td>0.179089</td>
      <td>-0.110211</td>
      <td>0.200847</td>
      <td>-0.691949</td>
      <td>0.185262</td>
      <td>-0.071232</td>
      <td>0.444723</td>
      <td>0.146246</td>
      <td>0.991175</td>
      <td>1.419886</td>
      <td>-0.682340</td>
      <td>-1.137522</td>
      <td>0.983251</td>
      <td>0.796373</td>
      <td>0.314746</td>
      <td>1.056158</td>
      <td>0.922500</td>
      <td>-1.173054</td>
      <td>0.159540</td>
      <td>-0.103244</td>
      <td>-0.495498</td>
      <td>-0.791088</td>
      <td>-0.399005</td>
      <td>-0.447095</td>
      <td>-0.037442</td>
      <td>-0.049765</td>
      <td>-1.600711</td>
      <td>...</td>
      <td>-0.845525</td>
      <td>-0.692075</td>
      <td>-1.119189</td>
      <td>-1.580882</td>
      <td>-1.457050</td>
      <td>-0.188243</td>
      <td>0.361488</td>
      <td>-0.237627</td>
      <td>-0.004720</td>
      <td>0.991611</td>
      <td>0.645411</td>
      <td>0.826766</td>
      <td>-0.130106</td>
      <td>-0.097211</td>
      <td>0.179786</td>
      <td>-0.384245</td>
      <td>0.269811</td>
      <td>1.115434</td>
      <td>-0.427280</td>
      <td>-0.099761</td>
      <td>-0.707890</td>
      <td>-1.212713</td>
      <td>-1.008038</td>
      <td>-0.001071</td>
      <td>-0.268145</td>
      <td>-0.704847</td>
      <td>-0.045651</td>
      <td>-0.102920</td>
      <td>0.251254</td>
      <td>-0.013878</td>
      <td>-0.555964</td>
      <td>0.311558</td>
      <td>0.282044</td>
      <td>0.423313</td>
      <td>1.531935</td>
      <td>0.371546</td>
      <td>-0.215195</td>
      <td>-0.810634</td>
      <td>-0.990196</td>
      <td>-1.057997</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1.022958</td>
      <td>0.041720</td>
      <td>0.237428</td>
      <td>0.116715</td>
      <td>0.665149</td>
      <td>0.172567</td>
      <td>-0.675229</td>
      <td>0.492174</td>
      <td>-1.241684</td>
      <td>0.429039</td>
      <td>0.936147</td>
      <td>0.141080</td>
      <td>-0.106751</td>
      <td>0.210820</td>
      <td>0.480910</td>
      <td>0.477337</td>
      <td>0.481411</td>
      <td>0.119916</td>
      <td>-0.917297</td>
      <td>0.207876</td>
      <td>-0.175654</td>
      <td>-1.728445</td>
      <td>-0.288297</td>
      <td>-0.260252</td>
      <td>-0.055975</td>
      <td>-0.206085</td>
      <td>0.095859</td>
      <td>0.920522</td>
      <td>1.679226</td>
      <td>0.688451</td>
      <td>-0.967952</td>
      <td>-0.527549</td>
      <td>-0.574613</td>
      <td>0.999261</td>
      <td>-0.027382</td>
      <td>0.028363</td>
      <td>0.169652</td>
      <td>0.350214</td>
      <td>-0.014276</td>
      <td>0.360052</td>
      <td>...</td>
      <td>-0.235200</td>
      <td>-0.869831</td>
      <td>-0.480383</td>
      <td>0.150591</td>
      <td>-0.773348</td>
      <td>-0.344635</td>
      <td>0.246971</td>
      <td>-0.511106</td>
      <td>0.843097</td>
      <td>0.325598</td>
      <td>-0.323114</td>
      <td>-0.007035</td>
      <td>1.631747</td>
      <td>0.106688</td>
      <td>-0.257062</td>
      <td>-0.367854</td>
      <td>0.369019</td>
      <td>0.384945</td>
      <td>-0.287566</td>
      <td>-1.132771</td>
      <td>-0.980329</td>
      <td>-0.134404</td>
      <td>-0.635212</td>
      <td>-0.133040</td>
      <td>-0.755769</td>
      <td>-0.580899</td>
      <td>0.192099</td>
      <td>0.534172</td>
      <td>1.082230</td>
      <td>-0.560009</td>
      <td>-0.248679</td>
      <td>-0.127342</td>
      <td>-0.527373</td>
      <td>-0.771067</td>
      <td>0.328421</td>
      <td>0.649008</td>
      <td>-0.740288</td>
      <td>-1.297549</td>
      <td>-0.529592</td>
      <td>-0.226332</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f7960041190&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.136351  0.038196  29.750342  1.716546e-194  1.061488  1.211214
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.582 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>