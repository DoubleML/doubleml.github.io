
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="http://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>     to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-0.908072</td>
      <td>0.080168</td>
      <td>0.316139</td>
      <td>0.049453</td>
      <td>0.244231</td>
      <td>0.950123</td>
      <td>0.158708</td>
      <td>-0.523656</td>
      <td>-0.844060</td>
      <td>-0.364001</td>
      <td>-0.715080</td>
      <td>0.174223</td>
      <td>-0.227430</td>
      <td>-0.555242</td>
      <td>-1.117200</td>
      <td>0.227919</td>
      <td>0.062657</td>
      <td>1.003293</td>
      <td>0.930464</td>
      <td>1.149179</td>
      <td>-0.438295</td>
      <td>-0.308252</td>
      <td>-0.303098</td>
      <td>-0.121163</td>
      <td>0.619122</td>
      <td>-0.422692</td>
      <td>0.773255</td>
      <td>-0.905063</td>
      <td>-0.184354</td>
      <td>0.333454</td>
      <td>-0.002991</td>
      <td>0.500975</td>
      <td>-0.408352</td>
      <td>-1.090330</td>
      <td>-0.102366</td>
      <td>1.043914</td>
      <td>0.201482</td>
      <td>-0.271182</td>
      <td>0.170721</td>
      <td>-0.220349</td>
      <td>...</td>
      <td>0.056365</td>
      <td>1.184264</td>
      <td>-0.001841</td>
      <td>0.609306</td>
      <td>0.196889</td>
      <td>0.567193</td>
      <td>0.480916</td>
      <td>0.601833</td>
      <td>-0.623473</td>
      <td>0.362603</td>
      <td>0.164314</td>
      <td>0.365434</td>
      <td>-1.441606</td>
      <td>-0.846589</td>
      <td>-0.758965</td>
      <td>0.099673</td>
      <td>-0.218082</td>
      <td>0.218376</td>
      <td>0.354423</td>
      <td>-0.823652</td>
      <td>-0.346123</td>
      <td>0.239484</td>
      <td>0.400524</td>
      <td>-0.266892</td>
      <td>-0.391454</td>
      <td>-0.478788</td>
      <td>0.053103</td>
      <td>0.019910</td>
      <td>0.217196</td>
      <td>0.835536</td>
      <td>-0.284395</td>
      <td>-0.744194</td>
      <td>0.034729</td>
      <td>-0.766527</td>
      <td>-0.131080</td>
      <td>-0.148483</td>
      <td>-0.478708</td>
      <td>-1.660569</td>
      <td>-0.408987</td>
      <td>-0.678042</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.185277</td>
      <td>-0.224065</td>
      <td>0.130186</td>
      <td>1.130602</td>
      <td>1.142590</td>
      <td>0.179212</td>
      <td>-0.850042</td>
      <td>-0.882134</td>
      <td>-0.283406</td>
      <td>-0.298749</td>
      <td>-0.114778</td>
      <td>0.087743</td>
      <td>-0.136864</td>
      <td>0.076462</td>
      <td>-0.112895</td>
      <td>0.869347</td>
      <td>-0.386736</td>
      <td>0.406640</td>
      <td>0.757834</td>
      <td>-0.665584</td>
      <td>-0.299902</td>
      <td>0.348659</td>
      <td>0.259931</td>
      <td>0.705563</td>
      <td>-0.443623</td>
      <td>-0.568534</td>
      <td>-0.661396</td>
      <td>-0.144549</td>
      <td>0.875649</td>
      <td>0.405780</td>
      <td>0.904899</td>
      <td>-0.497252</td>
      <td>-0.299203</td>
      <td>-0.576537</td>
      <td>0.681666</td>
      <td>-0.475157</td>
      <td>-0.362677</td>
      <td>-0.577055</td>
      <td>-0.905841</td>
      <td>-0.331379</td>
      <td>...</td>
      <td>0.030111</td>
      <td>0.482979</td>
      <td>-0.483635</td>
      <td>0.438836</td>
      <td>1.057317</td>
      <td>0.661739</td>
      <td>-0.427750</td>
      <td>-0.194178</td>
      <td>1.007328</td>
      <td>0.688963</td>
      <td>-0.070204</td>
      <td>0.749502</td>
      <td>0.341721</td>
      <td>-0.224586</td>
      <td>0.369194</td>
      <td>0.484226</td>
      <td>0.378888</td>
      <td>0.830303</td>
      <td>-0.273409</td>
      <td>-0.865269</td>
      <td>-0.070819</td>
      <td>-0.254218</td>
      <td>0.867147</td>
      <td>0.028627</td>
      <td>0.096499</td>
      <td>-1.001422</td>
      <td>0.257307</td>
      <td>-0.806446</td>
      <td>0.325645</td>
      <td>-0.549399</td>
      <td>-0.380435</td>
      <td>-0.127308</td>
      <td>0.307158</td>
      <td>0.001529</td>
      <td>-0.680763</td>
      <td>0.277765</td>
      <td>0.120209</td>
      <td>-2.067844</td>
      <td>-0.807799</td>
      <td>0.311301</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.218836</td>
      <td>-0.645641</td>
      <td>-0.067544</td>
      <td>-0.049657</td>
      <td>0.218409</td>
      <td>-0.390242</td>
      <td>0.235052</td>
      <td>-0.309711</td>
      <td>-0.244650</td>
      <td>-0.741687</td>
      <td>-0.329990</td>
      <td>0.130654</td>
      <td>-0.585371</td>
      <td>-0.546263</td>
      <td>-0.686455</td>
      <td>0.588771</td>
      <td>-0.580425</td>
      <td>1.296561</td>
      <td>1.974787</td>
      <td>1.130037</td>
      <td>-0.137033</td>
      <td>0.138809</td>
      <td>0.479741</td>
      <td>0.100141</td>
      <td>0.592225</td>
      <td>0.227821</td>
      <td>-0.176691</td>
      <td>-0.240737</td>
      <td>-1.086354</td>
      <td>0.442726</td>
      <td>0.394776</td>
      <td>0.668250</td>
      <td>0.466868</td>
      <td>0.722676</td>
      <td>0.751815</td>
      <td>-0.068986</td>
      <td>-0.574240</td>
      <td>-0.301174</td>
      <td>0.487605</td>
      <td>0.426345</td>
      <td>...</td>
      <td>-0.052749</td>
      <td>0.569186</td>
      <td>-0.212487</td>
      <td>-0.796523</td>
      <td>0.126324</td>
      <td>0.680473</td>
      <td>0.131741</td>
      <td>-0.604739</td>
      <td>-0.838773</td>
      <td>-0.283434</td>
      <td>-0.061933</td>
      <td>0.268285</td>
      <td>-0.249638</td>
      <td>0.068652</td>
      <td>-0.006097</td>
      <td>0.228922</td>
      <td>0.549980</td>
      <td>-0.169910</td>
      <td>0.363496</td>
      <td>-0.142118</td>
      <td>-1.114407</td>
      <td>-1.270870</td>
      <td>-0.298207</td>
      <td>0.214334</td>
      <td>-1.380567</td>
      <td>-1.772682</td>
      <td>-0.601320</td>
      <td>-0.607212</td>
      <td>-0.212138</td>
      <td>-0.672734</td>
      <td>0.136744</td>
      <td>-0.860696</td>
      <td>-0.063898</td>
      <td>0.096313</td>
      <td>-0.815213</td>
      <td>-0.816301</td>
      <td>-1.317040</td>
      <td>-2.036465</td>
      <td>-1.524705</td>
      <td>-0.267105</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.207675</td>
      <td>0.316274</td>
      <td>-0.323265</td>
      <td>-0.825598</td>
      <td>0.663756</td>
      <td>0.006112</td>
      <td>0.666659</td>
      <td>0.431242</td>
      <td>0.075627</td>
      <td>-1.146752</td>
      <td>-0.011680</td>
      <td>-0.416919</td>
      <td>-0.482376</td>
      <td>-0.588277</td>
      <td>-0.806229</td>
      <td>0.288432</td>
      <td>0.175462</td>
      <td>-1.480602</td>
      <td>0.650697</td>
      <td>0.280074</td>
      <td>-0.795698</td>
      <td>-0.567431</td>
      <td>-0.023117</td>
      <td>0.190782</td>
      <td>0.502152</td>
      <td>0.250650</td>
      <td>0.453955</td>
      <td>-0.364171</td>
      <td>0.784401</td>
      <td>-0.039959</td>
      <td>-1.146400</td>
      <td>0.234059</td>
      <td>0.889808</td>
      <td>-0.484381</td>
      <td>0.371643</td>
      <td>0.237974</td>
      <td>0.508087</td>
      <td>-0.456028</td>
      <td>0.365406</td>
      <td>0.452596</td>
      <td>...</td>
      <td>0.577593</td>
      <td>1.036662</td>
      <td>0.346345</td>
      <td>0.216012</td>
      <td>-0.198948</td>
      <td>-0.113459</td>
      <td>0.767402</td>
      <td>0.401915</td>
      <td>0.198348</td>
      <td>-0.214632</td>
      <td>-0.582734</td>
      <td>-1.032318</td>
      <td>-1.364430</td>
      <td>-0.728462</td>
      <td>0.490973</td>
      <td>-0.418339</td>
      <td>-0.069435</td>
      <td>0.527322</td>
      <td>0.186922</td>
      <td>-0.517070</td>
      <td>0.418645</td>
      <td>0.331693</td>
      <td>-0.716831</td>
      <td>-0.705145</td>
      <td>-0.972147</td>
      <td>-0.098080</td>
      <td>0.285044</td>
      <td>0.181928</td>
      <td>1.480122</td>
      <td>0.432045</td>
      <td>0.108834</td>
      <td>-0.490474</td>
      <td>-0.390429</td>
      <td>-0.208499</td>
      <td>0.363971</td>
      <td>-0.114919</td>
      <td>-0.840960</td>
      <td>1.405860</td>
      <td>1.763196</td>
      <td>0.274808</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.055840</td>
      <td>-0.062029</td>
      <td>-0.679350</td>
      <td>0.062012</td>
      <td>0.868920</td>
      <td>0.243291</td>
      <td>-0.045350</td>
      <td>0.564670</td>
      <td>-0.772301</td>
      <td>-0.379663</td>
      <td>0.409238</td>
      <td>-0.034646</td>
      <td>-0.067446</td>
      <td>-1.034229</td>
      <td>0.232488</td>
      <td>0.628253</td>
      <td>-1.096904</td>
      <td>-0.804638</td>
      <td>0.645818</td>
      <td>0.968689</td>
      <td>0.484745</td>
      <td>0.590998</td>
      <td>0.825421</td>
      <td>0.117616</td>
      <td>-0.292138</td>
      <td>-1.368981</td>
      <td>-0.064692</td>
      <td>0.300922</td>
      <td>-1.223210</td>
      <td>0.392705</td>
      <td>0.442517</td>
      <td>0.054116</td>
      <td>0.124599</td>
      <td>-0.596352</td>
      <td>-0.597610</td>
      <td>-0.110554</td>
      <td>-0.851628</td>
      <td>-0.746669</td>
      <td>-0.589947</td>
      <td>0.141660</td>
      <td>...</td>
      <td>-0.535132</td>
      <td>-0.357300</td>
      <td>-0.722360</td>
      <td>-0.523878</td>
      <td>-1.106935</td>
      <td>0.618904</td>
      <td>0.881278</td>
      <td>0.554494</td>
      <td>-1.041838</td>
      <td>0.129763</td>
      <td>-0.318414</td>
      <td>-0.015711</td>
      <td>0.227635</td>
      <td>-0.284992</td>
      <td>0.268370</td>
      <td>-0.039336</td>
      <td>0.666194</td>
      <td>0.958636</td>
      <td>0.874045</td>
      <td>0.434121</td>
      <td>1.252888</td>
      <td>-0.809871</td>
      <td>0.699677</td>
      <td>-0.057851</td>
      <td>0.263713</td>
      <td>-0.554069</td>
      <td>-1.757813</td>
      <td>-1.117751</td>
      <td>-0.175997</td>
      <td>-0.132500</td>
      <td>-0.222122</td>
      <td>-0.100606</td>
      <td>0.168391</td>
      <td>-0.456460</td>
      <td>-0.237240</td>
      <td>-0.123024</td>
      <td>0.607350</td>
      <td>1.176987</td>
      <td>-0.063241</td>
      <td>-0.880386</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.182880</td>
      <td>-0.075151</td>
      <td>0.705531</td>
      <td>0.200052</td>
      <td>0.436023</td>
      <td>0.282397</td>
      <td>0.712223</td>
      <td>0.105819</td>
      <td>0.202314</td>
      <td>0.600757</td>
      <td>0.031549</td>
      <td>0.686112</td>
      <td>0.891484</td>
      <td>-0.484779</td>
      <td>-0.222318</td>
      <td>0.269112</td>
      <td>-0.659258</td>
      <td>-0.333696</td>
      <td>-0.481329</td>
      <td>-0.291017</td>
      <td>-1.117052</td>
      <td>0.157841</td>
      <td>0.497879</td>
      <td>-0.078387</td>
      <td>-0.059921</td>
      <td>-0.927022</td>
      <td>-0.838862</td>
      <td>-1.131959</td>
      <td>-0.848235</td>
      <td>1.313643</td>
      <td>0.845035</td>
      <td>0.552158</td>
      <td>0.175999</td>
      <td>-0.193620</td>
      <td>-0.584575</td>
      <td>-0.021061</td>
      <td>0.114766</td>
      <td>-0.480795</td>
      <td>0.064066</td>
      <td>-0.155745</td>
      <td>...</td>
      <td>0.002010</td>
      <td>-0.236253</td>
      <td>0.274134</td>
      <td>-0.116426</td>
      <td>0.119259</td>
      <td>0.162337</td>
      <td>-0.830289</td>
      <td>-0.372127</td>
      <td>-0.352137</td>
      <td>0.960196</td>
      <td>0.103904</td>
      <td>-0.011059</td>
      <td>0.396759</td>
      <td>0.401257</td>
      <td>-0.706702</td>
      <td>-0.713760</td>
      <td>-0.408992</td>
      <td>0.795003</td>
      <td>0.543546</td>
      <td>-0.575323</td>
      <td>-0.470616</td>
      <td>-0.506266</td>
      <td>-0.558445</td>
      <td>-0.023661</td>
      <td>-0.408369</td>
      <td>-0.958974</td>
      <td>-0.488276</td>
      <td>-1.731384</td>
      <td>-1.610587</td>
      <td>-0.719065</td>
      <td>-0.025084</td>
      <td>-0.674789</td>
      <td>-0.727361</td>
      <td>-1.396459</td>
      <td>-0.418073</td>
      <td>-0.124494</td>
      <td>-0.826261</td>
      <td>-2.065527</td>
      <td>-0.546417</td>
      <td>-0.092516</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.535199</td>
      <td>-1.283331</td>
      <td>-0.186486</td>
      <td>-0.031288</td>
      <td>-0.056037</td>
      <td>-0.569629</td>
      <td>-0.252783</td>
      <td>0.221967</td>
      <td>0.082822</td>
      <td>-0.463890</td>
      <td>0.583982</td>
      <td>0.662541</td>
      <td>-0.811878</td>
      <td>-0.571084</td>
      <td>0.808252</td>
      <td>-0.170410</td>
      <td>-0.042681</td>
      <td>-0.113882</td>
      <td>0.953177</td>
      <td>-0.060632</td>
      <td>-0.516555</td>
      <td>-0.251978</td>
      <td>-0.464726</td>
      <td>-0.216917</td>
      <td>-0.378738</td>
      <td>-0.664768</td>
      <td>0.233014</td>
      <td>0.509042</td>
      <td>0.226035</td>
      <td>0.041744</td>
      <td>0.219981</td>
      <td>-0.168931</td>
      <td>-0.856474</td>
      <td>-0.619301</td>
      <td>-0.644573</td>
      <td>0.017127</td>
      <td>-0.719833</td>
      <td>-0.557580</td>
      <td>0.175252</td>
      <td>0.954540</td>
      <td>...</td>
      <td>-0.117743</td>
      <td>-0.218057</td>
      <td>-0.099116</td>
      <td>-0.091926</td>
      <td>0.121081</td>
      <td>0.724954</td>
      <td>0.172323</td>
      <td>0.323233</td>
      <td>0.532959</td>
      <td>1.350779</td>
      <td>0.821029</td>
      <td>0.215503</td>
      <td>-0.368900</td>
      <td>-0.224773</td>
      <td>-1.331967</td>
      <td>-0.636329</td>
      <td>-0.553701</td>
      <td>0.242882</td>
      <td>0.286305</td>
      <td>0.313627</td>
      <td>-0.486321</td>
      <td>0.147307</td>
      <td>-0.043856</td>
      <td>0.723394</td>
      <td>-0.017764</td>
      <td>-0.519062</td>
      <td>-0.431852</td>
      <td>-0.802826</td>
      <td>-0.728107</td>
      <td>-0.041209</td>
      <td>-0.348070</td>
      <td>0.165297</td>
      <td>-0.116870</td>
      <td>0.239641</td>
      <td>0.117441</td>
      <td>0.389689</td>
      <td>-0.047390</td>
      <td>-1.549343</td>
      <td>-1.480402</td>
      <td>-1.065326</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1.155419</td>
      <td>0.134010</td>
      <td>-0.553758</td>
      <td>0.879158</td>
      <td>0.353483</td>
      <td>0.417537</td>
      <td>-0.681525</td>
      <td>0.882934</td>
      <td>0.064172</td>
      <td>0.122234</td>
      <td>0.028876</td>
      <td>0.133787</td>
      <td>0.029033</td>
      <td>0.080930</td>
      <td>0.224341</td>
      <td>-0.023810</td>
      <td>-0.896356</td>
      <td>0.055761</td>
      <td>1.676808</td>
      <td>1.340412</td>
      <td>-0.675376</td>
      <td>1.570568</td>
      <td>-0.213371</td>
      <td>0.640279</td>
      <td>0.366525</td>
      <td>-0.027556</td>
      <td>-1.030092</td>
      <td>-1.110358</td>
      <td>-0.599315</td>
      <td>0.262378</td>
      <td>1.195556</td>
      <td>0.425149</td>
      <td>-0.716219</td>
      <td>-1.486063</td>
      <td>0.279135</td>
      <td>0.094551</td>
      <td>-0.570157</td>
      <td>-0.232247</td>
      <td>-1.039758</td>
      <td>0.863470</td>
      <td>...</td>
      <td>-0.187041</td>
      <td>0.916026</td>
      <td>-0.229891</td>
      <td>-0.077196</td>
      <td>0.596716</td>
      <td>-0.162672</td>
      <td>-0.190883</td>
      <td>-0.272388</td>
      <td>-0.144178</td>
      <td>-0.259187</td>
      <td>0.201847</td>
      <td>-0.067630</td>
      <td>0.306631</td>
      <td>-0.347605</td>
      <td>0.261767</td>
      <td>1.223209</td>
      <td>0.109193</td>
      <td>-0.085090</td>
      <td>-0.413558</td>
      <td>0.083795</td>
      <td>0.139349</td>
      <td>-0.529327</td>
      <td>-0.094540</td>
      <td>0.182075</td>
      <td>0.304881</td>
      <td>-0.865021</td>
      <td>0.396157</td>
      <td>-0.444805</td>
      <td>0.036058</td>
      <td>0.996564</td>
      <td>0.028633</td>
      <td>0.065035</td>
      <td>-0.034378</td>
      <td>-0.411372</td>
      <td>-0.128120</td>
      <td>0.471365</td>
      <td>-0.251690</td>
      <td>1.183196</td>
      <td>1.192961</td>
      <td>0.644186</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.269612</td>
      <td>-0.323607</td>
      <td>0.110339</td>
      <td>0.078676</td>
      <td>0.020821</td>
      <td>-0.147409</td>
      <td>-0.502093</td>
      <td>-0.187718</td>
      <td>-0.453911</td>
      <td>0.803684</td>
      <td>0.110664</td>
      <td>-0.913388</td>
      <td>-0.067598</td>
      <td>-0.526725</td>
      <td>-1.398364</td>
      <td>-0.725223</td>
      <td>-0.419981</td>
      <td>-0.209159</td>
      <td>0.408788</td>
      <td>-0.441535</td>
      <td>-0.247854</td>
      <td>0.656544</td>
      <td>0.742828</td>
      <td>0.593243</td>
      <td>-0.032161</td>
      <td>0.162105</td>
      <td>-0.070858</td>
      <td>0.096025</td>
      <td>0.019956</td>
      <td>0.192834</td>
      <td>-0.357710</td>
      <td>-0.047385</td>
      <td>-0.465843</td>
      <td>-0.499268</td>
      <td>-0.357279</td>
      <td>0.525418</td>
      <td>0.102910</td>
      <td>0.362861</td>
      <td>0.144797</td>
      <td>0.501558</td>
      <td>...</td>
      <td>-0.032407</td>
      <td>0.115329</td>
      <td>0.052769</td>
      <td>0.786783</td>
      <td>0.584163</td>
      <td>0.146149</td>
      <td>-0.017547</td>
      <td>0.242850</td>
      <td>-0.416854</td>
      <td>0.426442</td>
      <td>1.096814</td>
      <td>1.263606</td>
      <td>-0.329684</td>
      <td>-0.078301</td>
      <td>-0.807370</td>
      <td>-0.723488</td>
      <td>0.462578</td>
      <td>-0.755443</td>
      <td>0.119923</td>
      <td>-0.310196</td>
      <td>0.021217</td>
      <td>0.032467</td>
      <td>0.784516</td>
      <td>-0.007880</td>
      <td>-0.287148</td>
      <td>-0.852625</td>
      <td>0.345588</td>
      <td>-0.680272</td>
      <td>-0.302651</td>
      <td>0.186643</td>
      <td>-0.218453</td>
      <td>-0.508531</td>
      <td>0.837026</td>
      <td>0.825148</td>
      <td>0.095456</td>
      <td>-0.101111</td>
      <td>-0.134789</td>
      <td>-2.167805</td>
      <td>-1.734914</td>
      <td>-1.736276</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.248003</td>
      <td>1.047076</td>
      <td>0.308380</td>
      <td>0.010364</td>
      <td>0.230358</td>
      <td>-0.663235</td>
      <td>0.172443</td>
      <td>-0.845829</td>
      <td>0.176475</td>
      <td>0.956149</td>
      <td>0.177970</td>
      <td>0.434057</td>
      <td>0.396007</td>
      <td>0.189465</td>
      <td>-0.388532</td>
      <td>1.001368</td>
      <td>0.105696</td>
      <td>-0.109910</td>
      <td>1.764075</td>
      <td>0.309065</td>
      <td>-0.345618</td>
      <td>-0.336810</td>
      <td>0.246036</td>
      <td>1.216149</td>
      <td>-0.608537</td>
      <td>0.603956</td>
      <td>1.160113</td>
      <td>0.293464</td>
      <td>0.083673</td>
      <td>-0.127229</td>
      <td>-0.476140</td>
      <td>-0.670293</td>
      <td>1.376996</td>
      <td>1.392399</td>
      <td>0.359846</td>
      <td>0.215372</td>
      <td>0.596128</td>
      <td>1.358652</td>
      <td>0.206640</td>
      <td>0.448352</td>
      <td>...</td>
      <td>-0.103194</td>
      <td>0.883494</td>
      <td>0.078119</td>
      <td>-0.186035</td>
      <td>0.320639</td>
      <td>0.180033</td>
      <td>-0.115396</td>
      <td>-0.693534</td>
      <td>-0.808128</td>
      <td>-0.450989</td>
      <td>-0.443386</td>
      <td>-0.700093</td>
      <td>-0.820019</td>
      <td>-0.623231</td>
      <td>-0.131318</td>
      <td>-0.343460</td>
      <td>0.558049</td>
      <td>0.261686</td>
      <td>-0.658883</td>
      <td>0.019401</td>
      <td>-0.512477</td>
      <td>0.453303</td>
      <td>1.076938</td>
      <td>-0.056349</td>
      <td>0.717995</td>
      <td>-0.524971</td>
      <td>-0.248559</td>
      <td>-1.479975</td>
      <td>0.196504</td>
      <td>0.385950</td>
      <td>0.802114</td>
      <td>0.252211</td>
      <td>0.540579</td>
      <td>-0.392522</td>
      <td>-0.183117</td>
      <td>0.017198</td>
      <td>0.233984</td>
      <td>1.695796</td>
      <td>1.197531</td>
      <td>0.096395</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-0.281750</td>
      <td>-0.599761</td>
      <td>0.120646</td>
      <td>0.274892</td>
      <td>0.271931</td>
      <td>-1.092446</td>
      <td>0.533669</td>
      <td>-0.258656</td>
      <td>0.107997</td>
      <td>0.338667</td>
      <td>-0.832876</td>
      <td>-0.265795</td>
      <td>0.102950</td>
      <td>-0.903104</td>
      <td>-0.099936</td>
      <td>0.574126</td>
      <td>-1.126040</td>
      <td>-0.116336</td>
      <td>-0.557025</td>
      <td>0.147135</td>
      <td>-0.893628</td>
      <td>1.057186</td>
      <td>0.398023</td>
      <td>-1.280222</td>
      <td>0.107499</td>
      <td>-0.678976</td>
      <td>-1.190874</td>
      <td>-1.063658</td>
      <td>-0.085947</td>
      <td>0.110896</td>
      <td>0.329434</td>
      <td>-0.270759</td>
      <td>0.481526</td>
      <td>-0.213171</td>
      <td>-1.009925</td>
      <td>-0.603325</td>
      <td>-1.569171</td>
      <td>-0.566969</td>
      <td>-0.220160</td>
      <td>0.388017</td>
      <td>...</td>
      <td>-0.516510</td>
      <td>0.746234</td>
      <td>0.373323</td>
      <td>-0.332965</td>
      <td>-0.566613</td>
      <td>-0.321030</td>
      <td>0.270544</td>
      <td>-0.359680</td>
      <td>0.091108</td>
      <td>-1.196310</td>
      <td>-0.695917</td>
      <td>-1.299288</td>
      <td>0.084493</td>
      <td>0.388900</td>
      <td>0.292908</td>
      <td>0.124246</td>
      <td>0.197985</td>
      <td>0.628195</td>
      <td>-0.225288</td>
      <td>-0.794532</td>
      <td>-0.453540</td>
      <td>-0.212776</td>
      <td>-0.804841</td>
      <td>-0.201908</td>
      <td>0.640400</td>
      <td>-0.052548</td>
      <td>-0.094465</td>
      <td>-0.381432</td>
      <td>0.183921</td>
      <td>-0.433921</td>
      <td>0.266361</td>
      <td>-0.428923</td>
      <td>-0.340882</td>
      <td>-0.990360</td>
      <td>-0.924390</td>
      <td>-0.258694</td>
      <td>0.329058</td>
      <td>-1.628410</td>
      <td>-0.793848</td>
      <td>-0.099729</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.266623</td>
      <td>0.852259</td>
      <td>0.292126</td>
      <td>0.753997</td>
      <td>-0.364368</td>
      <td>0.851104</td>
      <td>-0.584043</td>
      <td>-0.490848</td>
      <td>0.214847</td>
      <td>0.268009</td>
      <td>-0.187678</td>
      <td>-0.979356</td>
      <td>0.452824</td>
      <td>-0.472668</td>
      <td>-0.664933</td>
      <td>0.610001</td>
      <td>-0.938524</td>
      <td>-0.011681</td>
      <td>-0.144101</td>
      <td>0.008980</td>
      <td>-0.226682</td>
      <td>1.130512</td>
      <td>1.145855</td>
      <td>0.624297</td>
      <td>0.509689</td>
      <td>0.657152</td>
      <td>1.072923</td>
      <td>0.755148</td>
      <td>0.031069</td>
      <td>0.428010</td>
      <td>1.106262</td>
      <td>0.472989</td>
      <td>-0.187710</td>
      <td>0.228705</td>
      <td>0.225305</td>
      <td>-0.325066</td>
      <td>-0.266526</td>
      <td>-0.488952</td>
      <td>0.204973</td>
      <td>0.167531</td>
      <td>...</td>
      <td>0.008560</td>
      <td>0.883567</td>
      <td>0.110731</td>
      <td>-0.453251</td>
      <td>-0.022674</td>
      <td>-0.461943</td>
      <td>0.018566</td>
      <td>-0.018326</td>
      <td>-1.237224</td>
      <td>0.414991</td>
      <td>-0.665230</td>
      <td>-0.366303</td>
      <td>-0.002356</td>
      <td>-0.329115</td>
      <td>0.229765</td>
      <td>0.250334</td>
      <td>1.012059</td>
      <td>0.010204</td>
      <td>0.409596</td>
      <td>0.639219</td>
      <td>0.321635</td>
      <td>-1.145402</td>
      <td>-0.448283</td>
      <td>-0.637329</td>
      <td>0.253415</td>
      <td>-1.152871</td>
      <td>0.164965</td>
      <td>-0.129677</td>
      <td>-0.572583</td>
      <td>-0.375889</td>
      <td>-0.023526</td>
      <td>-0.605604</td>
      <td>-1.002127</td>
      <td>-0.588660</td>
      <td>-0.679517</td>
      <td>0.388677</td>
      <td>1.077272</td>
      <td>1.476342</td>
      <td>1.706353</td>
      <td>1.427226</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-0.621136</td>
      <td>-0.014055</td>
      <td>0.402997</td>
      <td>-0.119926</td>
      <td>0.395800</td>
      <td>0.527244</td>
      <td>-0.017868</td>
      <td>0.931419</td>
      <td>0.239649</td>
      <td>0.651240</td>
      <td>-0.774948</td>
      <td>-0.503765</td>
      <td>-0.640357</td>
      <td>-1.337153</td>
      <td>-0.614305</td>
      <td>0.407103</td>
      <td>-0.879792</td>
      <td>-0.050173</td>
      <td>0.340487</td>
      <td>0.293081</td>
      <td>-0.442091</td>
      <td>0.316866</td>
      <td>-0.138092</td>
      <td>0.967680</td>
      <td>0.036271</td>
      <td>-0.372498</td>
      <td>-0.318385</td>
      <td>0.046093</td>
      <td>0.203930</td>
      <td>0.388646</td>
      <td>0.422553</td>
      <td>1.265470</td>
      <td>0.360590</td>
      <td>0.333555</td>
      <td>0.745795</td>
      <td>-0.466115</td>
      <td>-0.213042</td>
      <td>0.668688</td>
      <td>-1.083095</td>
      <td>0.001036</td>
      <td>...</td>
      <td>0.066578</td>
      <td>0.179008</td>
      <td>-0.304863</td>
      <td>-0.654767</td>
      <td>-0.252663</td>
      <td>0.307830</td>
      <td>0.455489</td>
      <td>1.801492</td>
      <td>-0.400440</td>
      <td>0.101521</td>
      <td>-0.092554</td>
      <td>-1.157690</td>
      <td>0.362323</td>
      <td>0.516555</td>
      <td>-0.117868</td>
      <td>0.005961</td>
      <td>-0.508201</td>
      <td>-0.118967</td>
      <td>0.129648</td>
      <td>-0.790618</td>
      <td>0.211443</td>
      <td>0.681686</td>
      <td>0.528242</td>
      <td>0.740158</td>
      <td>0.640500</td>
      <td>-0.079778</td>
      <td>0.113054</td>
      <td>-0.579615</td>
      <td>0.577946</td>
      <td>1.042512</td>
      <td>-0.493370</td>
      <td>-1.269225</td>
      <td>-0.146068</td>
      <td>-0.201421</td>
      <td>0.153206</td>
      <td>1.347575</td>
      <td>0.525619</td>
      <td>-0.208453</td>
      <td>0.341654</td>
      <td>-0.216446</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-1.354246</td>
      <td>-0.190603</td>
      <td>0.341607</td>
      <td>-0.176007</td>
      <td>-0.415182</td>
      <td>0.027018</td>
      <td>-0.001073</td>
      <td>-0.455143</td>
      <td>-0.403027</td>
      <td>-0.085427</td>
      <td>1.186286</td>
      <td>0.552300</td>
      <td>0.824599</td>
      <td>-0.411195</td>
      <td>-0.442846</td>
      <td>0.406747</td>
      <td>-0.864461</td>
      <td>1.148409</td>
      <td>-0.115518</td>
      <td>0.195186</td>
      <td>-0.407285</td>
      <td>1.385673</td>
      <td>1.736025</td>
      <td>0.173240</td>
      <td>-0.542723</td>
      <td>-0.898434</td>
      <td>0.509941</td>
      <td>0.924890</td>
      <td>0.690912</td>
      <td>-0.479859</td>
      <td>-0.852201</td>
      <td>-0.998077</td>
      <td>-0.150274</td>
      <td>-0.877033</td>
      <td>0.351341</td>
      <td>-0.637041</td>
      <td>0.321162</td>
      <td>-0.113413</td>
      <td>0.740618</td>
      <td>0.181147</td>
      <td>...</td>
      <td>-0.584312</td>
      <td>0.401894</td>
      <td>0.503315</td>
      <td>0.673080</td>
      <td>0.944068</td>
      <td>0.002583</td>
      <td>0.421383</td>
      <td>-0.119810</td>
      <td>-0.879579</td>
      <td>1.179512</td>
      <td>-0.288643</td>
      <td>-0.664497</td>
      <td>-1.073441</td>
      <td>0.017976</td>
      <td>-0.319418</td>
      <td>-0.540138</td>
      <td>-0.243723</td>
      <td>0.603351</td>
      <td>-0.230990</td>
      <td>-0.491585</td>
      <td>-1.557327</td>
      <td>-0.039164</td>
      <td>-0.234444</td>
      <td>0.235378</td>
      <td>0.425236</td>
      <td>-0.720318</td>
      <td>0.553671</td>
      <td>-0.229403</td>
      <td>0.149933</td>
      <td>1.223695</td>
      <td>-0.925849</td>
      <td>-0.645444</td>
      <td>-0.205551</td>
      <td>-1.133991</td>
      <td>-0.059093</td>
      <td>0.100666</td>
      <td>-0.013173</td>
      <td>-4.423376</td>
      <td>-2.483956</td>
      <td>-1.402879</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.367769</td>
      <td>0.487570</td>
      <td>0.615613</td>
      <td>-0.089241</td>
      <td>-0.295691</td>
      <td>-0.048048</td>
      <td>-0.313125</td>
      <td>-0.056337</td>
      <td>0.296930</td>
      <td>-0.510946</td>
      <td>0.017138</td>
      <td>-0.361003</td>
      <td>-0.209296</td>
      <td>-0.501258</td>
      <td>-0.308209</td>
      <td>-0.489484</td>
      <td>0.008821</td>
      <td>-0.068819</td>
      <td>-0.140135</td>
      <td>0.253468</td>
      <td>-1.034628</td>
      <td>0.549662</td>
      <td>-0.079509</td>
      <td>0.480039</td>
      <td>0.305951</td>
      <td>-1.225490</td>
      <td>-0.057279</td>
      <td>-0.388607</td>
      <td>-0.492330</td>
      <td>0.184112</td>
      <td>0.948113</td>
      <td>0.168602</td>
      <td>0.353640</td>
      <td>-1.011290</td>
      <td>-0.285866</td>
      <td>-0.128772</td>
      <td>0.835085</td>
      <td>1.254199</td>
      <td>0.109882</td>
      <td>0.803321</td>
      <td>...</td>
      <td>-0.238111</td>
      <td>0.280130</td>
      <td>-0.429569</td>
      <td>-1.053340</td>
      <td>-0.115740</td>
      <td>1.747630</td>
      <td>-0.151318</td>
      <td>-0.626501</td>
      <td>0.275121</td>
      <td>0.219634</td>
      <td>0.399793</td>
      <td>0.675281</td>
      <td>0.141267</td>
      <td>0.446019</td>
      <td>0.054329</td>
      <td>0.402208</td>
      <td>-0.373713</td>
      <td>-0.575982</td>
      <td>-0.100594</td>
      <td>-0.368537</td>
      <td>-0.083966</td>
      <td>0.329445</td>
      <td>-0.656627</td>
      <td>-0.243609</td>
      <td>0.036469</td>
      <td>-0.477377</td>
      <td>0.811618</td>
      <td>-1.317576</td>
      <td>-0.636423</td>
      <td>0.001842</td>
      <td>-1.175262</td>
      <td>-0.189124</td>
      <td>-0.071808</td>
      <td>-0.508246</td>
      <td>-0.792424</td>
      <td>-0.197097</td>
      <td>-0.856514</td>
      <td>1.214828</td>
      <td>0.908634</td>
      <td>0.307958</td>
    </tr>
    <tr>
      <th>15</th>
      <td>1.052505</td>
      <td>-0.364381</td>
      <td>1.325635</td>
      <td>0.670361</td>
      <td>0.680709</td>
      <td>-0.250046</td>
      <td>0.696872</td>
      <td>0.410711</td>
      <td>0.066063</td>
      <td>-0.757987</td>
      <td>0.423219</td>
      <td>0.240717</td>
      <td>-0.304545</td>
      <td>-0.832850</td>
      <td>-0.038771</td>
      <td>0.326251</td>
      <td>-0.601223</td>
      <td>-0.000674</td>
      <td>0.084388</td>
      <td>0.961440</td>
      <td>0.453076</td>
      <td>0.656486</td>
      <td>0.421435</td>
      <td>0.083630</td>
      <td>-0.065385</td>
      <td>0.002063</td>
      <td>-0.694023</td>
      <td>-0.542587</td>
      <td>-0.655157</td>
      <td>0.295183</td>
      <td>0.082385</td>
      <td>0.078832</td>
      <td>1.117271</td>
      <td>-0.365836</td>
      <td>-0.052942</td>
      <td>-0.470356</td>
      <td>0.677878</td>
      <td>0.339826</td>
      <td>-0.861253</td>
      <td>0.343271</td>
      <td>...</td>
      <td>-0.027610</td>
      <td>0.723106</td>
      <td>0.508982</td>
      <td>-0.142019</td>
      <td>1.061985</td>
      <td>0.511778</td>
      <td>-0.144447</td>
      <td>0.054967</td>
      <td>-0.564086</td>
      <td>-0.384451</td>
      <td>-0.359039</td>
      <td>-0.635718</td>
      <td>-0.234286</td>
      <td>-0.308508</td>
      <td>-0.138210</td>
      <td>0.687568</td>
      <td>-0.122553</td>
      <td>0.074950</td>
      <td>-0.452874</td>
      <td>-0.162166</td>
      <td>0.137442</td>
      <td>0.019132</td>
      <td>1.043701</td>
      <td>1.457414</td>
      <td>0.053144</td>
      <td>-1.043165</td>
      <td>-0.270255</td>
      <td>-0.627098</td>
      <td>-0.134725</td>
      <td>-0.172982</td>
      <td>-0.160216</td>
      <td>0.767009</td>
      <td>0.656133</td>
      <td>0.068528</td>
      <td>-0.953106</td>
      <td>-0.142013</td>
      <td>0.117069</td>
      <td>0.950974</td>
      <td>0.640380</td>
      <td>0.310089</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-0.913904</td>
      <td>-0.543778</td>
      <td>0.261290</td>
      <td>-0.270574</td>
      <td>0.218957</td>
      <td>-0.312203</td>
      <td>0.426617</td>
      <td>-0.684835</td>
      <td>-0.621694</td>
      <td>-0.118692</td>
      <td>0.057679</td>
      <td>-0.839244</td>
      <td>-0.674089</td>
      <td>-0.180972</td>
      <td>0.014368</td>
      <td>0.181786</td>
      <td>-0.751042</td>
      <td>0.363065</td>
      <td>0.576485</td>
      <td>0.347833</td>
      <td>0.307868</td>
      <td>0.837054</td>
      <td>0.678196</td>
      <td>1.662575</td>
      <td>-0.248575</td>
      <td>0.672887</td>
      <td>0.184666</td>
      <td>1.033964</td>
      <td>-0.114610</td>
      <td>0.015270</td>
      <td>-0.066608</td>
      <td>-0.040895</td>
      <td>-0.161574</td>
      <td>0.314654</td>
      <td>0.363716</td>
      <td>-0.025699</td>
      <td>-0.738587</td>
      <td>-0.648166</td>
      <td>-0.763286</td>
      <td>-0.061039</td>
      <td>...</td>
      <td>0.083685</td>
      <td>0.651547</td>
      <td>-0.194530</td>
      <td>-0.528791</td>
      <td>-0.374685</td>
      <td>0.417573</td>
      <td>-0.151743</td>
      <td>-1.181703</td>
      <td>-1.707528</td>
      <td>-0.231252</td>
      <td>0.184129</td>
      <td>-0.108899</td>
      <td>-0.617925</td>
      <td>0.075417</td>
      <td>1.313918</td>
      <td>0.370634</td>
      <td>1.118559</td>
      <td>-0.046094</td>
      <td>0.029462</td>
      <td>-1.343375</td>
      <td>-0.410706</td>
      <td>0.422842</td>
      <td>0.366821</td>
      <td>-0.535204</td>
      <td>-0.119072</td>
      <td>0.078718</td>
      <td>-0.256259</td>
      <td>1.001197</td>
      <td>-0.220907</td>
      <td>-0.365516</td>
      <td>-0.352801</td>
      <td>-0.450016</td>
      <td>0.260434</td>
      <td>-0.380734</td>
      <td>-0.582153</td>
      <td>-0.236857</td>
      <td>0.358501</td>
      <td>-0.449501</td>
      <td>-0.387680</td>
      <td>-0.126014</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.684623</td>
      <td>0.016859</td>
      <td>-0.438619</td>
      <td>0.807966</td>
      <td>-0.519931</td>
      <td>0.163257</td>
      <td>-0.219173</td>
      <td>-0.751498</td>
      <td>-0.706983</td>
      <td>-0.452991</td>
      <td>-1.075218</td>
      <td>-0.307141</td>
      <td>-0.455595</td>
      <td>-0.303434</td>
      <td>0.015991</td>
      <td>0.569057</td>
      <td>0.015920</td>
      <td>0.082925</td>
      <td>0.160466</td>
      <td>0.974792</td>
      <td>-0.599134</td>
      <td>-0.815295</td>
      <td>0.727940</td>
      <td>-0.419862</td>
      <td>-0.701337</td>
      <td>-0.509502</td>
      <td>-0.008852</td>
      <td>0.186444</td>
      <td>0.545823</td>
      <td>0.780406</td>
      <td>0.675190</td>
      <td>0.335458</td>
      <td>0.134154</td>
      <td>0.205353</td>
      <td>0.531477</td>
      <td>0.301955</td>
      <td>-0.103607</td>
      <td>-0.349274</td>
      <td>0.691111</td>
      <td>0.404731</td>
      <td>...</td>
      <td>-0.869940</td>
      <td>0.826825</td>
      <td>-0.969579</td>
      <td>-0.713111</td>
      <td>-0.047471</td>
      <td>-0.000077</td>
      <td>0.398614</td>
      <td>-0.362603</td>
      <td>-0.708835</td>
      <td>0.774045</td>
      <td>0.250326</td>
      <td>-0.086252</td>
      <td>0.114939</td>
      <td>0.248854</td>
      <td>-0.068105</td>
      <td>0.198420</td>
      <td>-0.017736</td>
      <td>0.514253</td>
      <td>0.399742</td>
      <td>0.186031</td>
      <td>-0.554525</td>
      <td>-0.097519</td>
      <td>0.720436</td>
      <td>0.396249</td>
      <td>0.324813</td>
      <td>-0.585750</td>
      <td>0.375294</td>
      <td>-0.762222</td>
      <td>0.176949</td>
      <td>-0.650214</td>
      <td>-1.401187</td>
      <td>-0.649127</td>
      <td>-0.469081</td>
      <td>0.249496</td>
      <td>-0.182660</td>
      <td>0.058803</td>
      <td>-1.659899</td>
      <td>-2.064249</td>
      <td>-1.203291</td>
      <td>-0.707776</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-1.008047</td>
      <td>0.282912</td>
      <td>0.952395</td>
      <td>-0.321418</td>
      <td>0.566242</td>
      <td>-0.213096</td>
      <td>0.698840</td>
      <td>0.655820</td>
      <td>-0.724448</td>
      <td>-0.107236</td>
      <td>-0.162407</td>
      <td>-0.233396</td>
      <td>0.297802</td>
      <td>0.040856</td>
      <td>0.045158</td>
      <td>0.326116</td>
      <td>-0.384809</td>
      <td>0.766296</td>
      <td>-0.095601</td>
      <td>0.144347</td>
      <td>0.803351</td>
      <td>1.025558</td>
      <td>0.505785</td>
      <td>-0.159601</td>
      <td>0.634223</td>
      <td>0.182875</td>
      <td>0.364347</td>
      <td>-0.136165</td>
      <td>0.416283</td>
      <td>-0.231452</td>
      <td>-0.094936</td>
      <td>-0.016446</td>
      <td>-0.070152</td>
      <td>-0.339859</td>
      <td>-0.079433</td>
      <td>0.059782</td>
      <td>-0.373120</td>
      <td>-0.705360</td>
      <td>-0.313084</td>
      <td>-0.493458</td>
      <td>...</td>
      <td>-1.066610</td>
      <td>0.329103</td>
      <td>0.071259</td>
      <td>-0.072756</td>
      <td>-0.552208</td>
      <td>-0.019811</td>
      <td>-0.956418</td>
      <td>-0.944551</td>
      <td>-0.190312</td>
      <td>0.008025</td>
      <td>0.371867</td>
      <td>0.700180</td>
      <td>0.201352</td>
      <td>-0.429967</td>
      <td>0.139363</td>
      <td>-0.182946</td>
      <td>0.221355</td>
      <td>0.805556</td>
      <td>-0.258971</td>
      <td>-0.367212</td>
      <td>-0.093183</td>
      <td>0.079153</td>
      <td>0.843131</td>
      <td>0.467895</td>
      <td>0.069154</td>
      <td>-0.422868</td>
      <td>-0.509184</td>
      <td>-0.895341</td>
      <td>-0.304313</td>
      <td>0.118424</td>
      <td>0.017058</td>
      <td>-0.370124</td>
      <td>-0.173771</td>
      <td>-0.278924</td>
      <td>-0.350502</td>
      <td>-0.170230</td>
      <td>0.287599</td>
      <td>0.783388</td>
      <td>-0.091099</td>
      <td>-0.090726</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.113042</td>
      <td>0.252127</td>
      <td>0.556823</td>
      <td>0.236178</td>
      <td>0.461929</td>
      <td>0.109516</td>
      <td>-0.256189</td>
      <td>0.335981</td>
      <td>0.332120</td>
      <td>0.461006</td>
      <td>-0.166679</td>
      <td>0.026923</td>
      <td>-0.553940</td>
      <td>-0.969853</td>
      <td>-0.203575</td>
      <td>-1.294999</td>
      <td>-0.193341</td>
      <td>0.618993</td>
      <td>0.618929</td>
      <td>-0.007556</td>
      <td>-0.391824</td>
      <td>0.665610</td>
      <td>0.921746</td>
      <td>1.204784</td>
      <td>0.282777</td>
      <td>-0.464458</td>
      <td>0.282212</td>
      <td>0.342454</td>
      <td>0.266359</td>
      <td>0.871893</td>
      <td>0.791612</td>
      <td>0.069533</td>
      <td>-0.761960</td>
      <td>-0.638245</td>
      <td>-0.154461</td>
      <td>-0.426538</td>
      <td>-0.384245</td>
      <td>0.358943</td>
      <td>-0.500870</td>
      <td>0.210694</td>
      <td>...</td>
      <td>-1.080134</td>
      <td>-0.632814</td>
      <td>-0.127371</td>
      <td>-0.049007</td>
      <td>1.160668</td>
      <td>1.222935</td>
      <td>0.050826</td>
      <td>-0.217220</td>
      <td>0.271949</td>
      <td>0.628289</td>
      <td>-0.572337</td>
      <td>-0.304627</td>
      <td>-1.139824</td>
      <td>-1.082395</td>
      <td>0.056750</td>
      <td>0.362108</td>
      <td>-1.087008</td>
      <td>0.048360</td>
      <td>-0.144506</td>
      <td>-1.232406</td>
      <td>-0.005981</td>
      <td>-0.378674</td>
      <td>0.550746</td>
      <td>-0.127532</td>
      <td>0.129568</td>
      <td>-0.595331</td>
      <td>-0.678623</td>
      <td>-0.490948</td>
      <td>-0.350926</td>
      <td>-0.528777</td>
      <td>0.236923</td>
      <td>-0.759372</td>
      <td>-0.076821</td>
      <td>0.248137</td>
      <td>0.331826</td>
      <td>-0.234093</td>
      <td>0.011228</td>
      <td>0.277803</td>
      <td>-0.061128</td>
      <td>-0.370866</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.960069</td>
      <td>-0.479094</td>
      <td>0.293820</td>
      <td>0.333277</td>
      <td>0.887919</td>
      <td>0.498938</td>
      <td>0.165288</td>
      <td>1.223181</td>
      <td>0.275608</td>
      <td>-0.150192</td>
      <td>0.691314</td>
      <td>0.926157</td>
      <td>0.564820</td>
      <td>-0.493091</td>
      <td>-0.221759</td>
      <td>0.328503</td>
      <td>-0.069705</td>
      <td>0.548438</td>
      <td>0.466407</td>
      <td>0.297103</td>
      <td>0.335786</td>
      <td>1.258184</td>
      <td>0.130087</td>
      <td>-0.603172</td>
      <td>0.816518</td>
      <td>-0.045295</td>
      <td>-0.120754</td>
      <td>-0.744950</td>
      <td>-0.975586</td>
      <td>0.131003</td>
      <td>0.503336</td>
      <td>0.491216</td>
      <td>0.582775</td>
      <td>0.088766</td>
      <td>1.505085</td>
      <td>-0.347454</td>
      <td>-0.238333</td>
      <td>0.257019</td>
      <td>-0.352593</td>
      <td>-0.197893</td>
      <td>...</td>
      <td>-0.258810</td>
      <td>-0.624045</td>
      <td>0.886321</td>
      <td>-0.741119</td>
      <td>0.418889</td>
      <td>0.867480</td>
      <td>0.635657</td>
      <td>0.815132</td>
      <td>0.078706</td>
      <td>-0.807768</td>
      <td>-1.152396</td>
      <td>-0.821685</td>
      <td>-0.380717</td>
      <td>-0.133972</td>
      <td>-0.822262</td>
      <td>0.311826</td>
      <td>-0.307346</td>
      <td>0.896153</td>
      <td>0.104238</td>
      <td>0.027912</td>
      <td>-0.185987</td>
      <td>-0.409337</td>
      <td>-0.600187</td>
      <td>0.621531</td>
      <td>0.211154</td>
      <td>-1.500141</td>
      <td>-0.473455</td>
      <td>-0.793182</td>
      <td>-0.978707</td>
      <td>-0.015264</td>
      <td>-0.299143</td>
      <td>-0.077558</td>
      <td>-0.010029</td>
      <td>-0.200119</td>
      <td>-0.045278</td>
      <td>-0.398679</td>
      <td>-0.161929</td>
      <td>-2.400331</td>
      <td>-1.104132</td>
      <td>-0.878248</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.666229</td>
      <td>-0.159948</td>
      <td>0.176914</td>
      <td>0.444622</td>
      <td>0.679863</td>
      <td>-1.147471</td>
      <td>-0.609970</td>
      <td>-1.037762</td>
      <td>-0.772785</td>
      <td>-0.430010</td>
      <td>-0.672257</td>
      <td>-0.602266</td>
      <td>-0.066513</td>
      <td>-0.177524</td>
      <td>1.094967</td>
      <td>0.452555</td>
      <td>0.555563</td>
      <td>0.221924</td>
      <td>0.751551</td>
      <td>0.196803</td>
      <td>-0.272483</td>
      <td>-0.093258</td>
      <td>-0.312228</td>
      <td>-0.114110</td>
      <td>0.375640</td>
      <td>-1.131550</td>
      <td>-0.134673</td>
      <td>0.151314</td>
      <td>0.241184</td>
      <td>0.480045</td>
      <td>0.050442</td>
      <td>-0.185365</td>
      <td>0.207492</td>
      <td>-0.577461</td>
      <td>1.101378</td>
      <td>0.768639</td>
      <td>-0.587903</td>
      <td>0.087374</td>
      <td>-1.135128</td>
      <td>0.139924</td>
      <td>...</td>
      <td>0.288271</td>
      <td>1.317985</td>
      <td>0.691474</td>
      <td>0.392076</td>
      <td>0.290015</td>
      <td>-0.635421</td>
      <td>-1.176775</td>
      <td>0.383619</td>
      <td>-0.441878</td>
      <td>-0.385930</td>
      <td>0.722767</td>
      <td>-0.520234</td>
      <td>-0.306220</td>
      <td>-0.580585</td>
      <td>-0.075322</td>
      <td>-1.077662</td>
      <td>0.552350</td>
      <td>-0.520473</td>
      <td>0.345821</td>
      <td>0.590566</td>
      <td>0.168390</td>
      <td>-0.062495</td>
      <td>-0.464841</td>
      <td>-0.067440</td>
      <td>0.366233</td>
      <td>-0.908203</td>
      <td>-0.366571</td>
      <td>-0.808349</td>
      <td>-1.088952</td>
      <td>0.697419</td>
      <td>0.043791</td>
      <td>-0.754574</td>
      <td>-0.176955</td>
      <td>-0.695034</td>
      <td>-0.770896</td>
      <td>0.486361</td>
      <td>-0.830217</td>
      <td>1.526610</td>
      <td>1.304980</td>
      <td>0.204694</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-1.386877</td>
      <td>0.106707</td>
      <td>0.623493</td>
      <td>0.818097</td>
      <td>0.121735</td>
      <td>-0.935514</td>
      <td>0.085024</td>
      <td>0.036911</td>
      <td>-0.376703</td>
      <td>0.701141</td>
      <td>0.243815</td>
      <td>0.217910</td>
      <td>-0.589630</td>
      <td>-1.093122</td>
      <td>-1.686697</td>
      <td>-0.173108</td>
      <td>-0.601209</td>
      <td>-0.033186</td>
      <td>0.351996</td>
      <td>0.519854</td>
      <td>-0.112078</td>
      <td>0.842841</td>
      <td>0.144190</td>
      <td>0.087494</td>
      <td>-0.272308</td>
      <td>0.662214</td>
      <td>0.231586</td>
      <td>0.934386</td>
      <td>0.156914</td>
      <td>0.377930</td>
      <td>0.497418</td>
      <td>-0.522836</td>
      <td>0.767713</td>
      <td>0.195362</td>
      <td>0.623237</td>
      <td>-0.305138</td>
      <td>-0.339626</td>
      <td>0.435522</td>
      <td>0.376119</td>
      <td>-0.058839</td>
      <td>...</td>
      <td>0.664562</td>
      <td>0.314814</td>
      <td>0.572531</td>
      <td>0.353844</td>
      <td>-0.034776</td>
      <td>0.421712</td>
      <td>0.536635</td>
      <td>-0.651226</td>
      <td>0.398269</td>
      <td>-0.358248</td>
      <td>-0.263804</td>
      <td>-0.073718</td>
      <td>-0.186586</td>
      <td>0.102169</td>
      <td>-0.109498</td>
      <td>-0.514000</td>
      <td>0.245065</td>
      <td>0.667107</td>
      <td>-0.704365</td>
      <td>-0.625864</td>
      <td>-0.096860</td>
      <td>-0.345622</td>
      <td>0.485084</td>
      <td>0.492212</td>
      <td>-0.450835</td>
      <td>-1.130210</td>
      <td>0.089171</td>
      <td>-0.804472</td>
      <td>-0.496327</td>
      <td>-0.749827</td>
      <td>-0.619129</td>
      <td>0.113723</td>
      <td>-0.321581</td>
      <td>-1.691362</td>
      <td>0.458147</td>
      <td>-0.164554</td>
      <td>-0.466345</td>
      <td>0.093101</td>
      <td>0.737712</td>
      <td>-0.245499</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.214375</td>
      <td>-0.378518</td>
      <td>0.116272</td>
      <td>0.620751</td>
      <td>0.385939</td>
      <td>0.187621</td>
      <td>0.793178</td>
      <td>0.855254</td>
      <td>-0.021201</td>
      <td>0.073099</td>
      <td>-0.725103</td>
      <td>-0.292107</td>
      <td>-0.812606</td>
      <td>-1.168928</td>
      <td>-1.198888</td>
      <td>-0.200004</td>
      <td>-1.043857</td>
      <td>-0.229150</td>
      <td>0.220603</td>
      <td>0.155718</td>
      <td>0.876347</td>
      <td>0.828675</td>
      <td>-0.252738</td>
      <td>-0.174010</td>
      <td>-0.658889</td>
      <td>-0.395374</td>
      <td>0.213483</td>
      <td>0.335868</td>
      <td>0.654608</td>
      <td>-0.510944</td>
      <td>-0.284472</td>
      <td>0.577457</td>
      <td>-0.404120</td>
      <td>-1.118769</td>
      <td>0.434341</td>
      <td>0.511735</td>
      <td>-0.225535</td>
      <td>0.406495</td>
      <td>-0.513720</td>
      <td>0.055383</td>
      <td>...</td>
      <td>-0.959769</td>
      <td>-0.189433</td>
      <td>-0.058297</td>
      <td>-0.925715</td>
      <td>-0.603114</td>
      <td>0.673650</td>
      <td>-0.442429</td>
      <td>-0.280723</td>
      <td>-0.678436</td>
      <td>-0.132684</td>
      <td>0.052456</td>
      <td>-0.533971</td>
      <td>-0.678374</td>
      <td>-0.801637</td>
      <td>-0.444334</td>
      <td>0.242051</td>
      <td>-0.395316</td>
      <td>0.896379</td>
      <td>0.238558</td>
      <td>-0.321681</td>
      <td>0.043185</td>
      <td>0.245240</td>
      <td>-0.787038</td>
      <td>-0.105048</td>
      <td>0.042976</td>
      <td>-0.897756</td>
      <td>-0.575544</td>
      <td>-0.459768</td>
      <td>0.252202</td>
      <td>0.417009</td>
      <td>-0.836758</td>
      <td>0.001616</td>
      <td>0.023769</td>
      <td>-1.256139</td>
      <td>-0.348972</td>
      <td>0.155907</td>
      <td>-0.229476</td>
      <td>1.638404</td>
      <td>0.760059</td>
      <td>-0.092380</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-0.590181</td>
      <td>-0.629554</td>
      <td>-0.538269</td>
      <td>0.252558</td>
      <td>-0.055429</td>
      <td>0.607754</td>
      <td>-0.210872</td>
      <td>0.430225</td>
      <td>-0.744929</td>
      <td>-0.031693</td>
      <td>0.181507</td>
      <td>-0.266398</td>
      <td>0.329658</td>
      <td>-0.202744</td>
      <td>-0.208716</td>
      <td>-0.127170</td>
      <td>-0.710212</td>
      <td>0.106736</td>
      <td>-0.212228</td>
      <td>0.508141</td>
      <td>0.104652</td>
      <td>1.212879</td>
      <td>0.568848</td>
      <td>0.266823</td>
      <td>0.325403</td>
      <td>-0.797551</td>
      <td>-0.373301</td>
      <td>0.230678</td>
      <td>0.141423</td>
      <td>0.062302</td>
      <td>0.748975</td>
      <td>0.533803</td>
      <td>-0.228819</td>
      <td>-0.043756</td>
      <td>0.038724</td>
      <td>-0.112051</td>
      <td>-0.439788</td>
      <td>-0.575553</td>
      <td>-0.084529</td>
      <td>-0.622559</td>
      <td>...</td>
      <td>-1.054347</td>
      <td>0.398639</td>
      <td>0.013134</td>
      <td>-0.538404</td>
      <td>0.413625</td>
      <td>-0.757014</td>
      <td>0.776450</td>
      <td>0.097695</td>
      <td>-0.931139</td>
      <td>-0.307801</td>
      <td>-1.806921</td>
      <td>-0.575387</td>
      <td>0.103268</td>
      <td>0.705756</td>
      <td>-0.688081</td>
      <td>-0.160798</td>
      <td>-0.230249</td>
      <td>0.353165</td>
      <td>0.427168</td>
      <td>0.609329</td>
      <td>-0.081158</td>
      <td>0.188530</td>
      <td>0.135689</td>
      <td>-0.197739</td>
      <td>-0.114975</td>
      <td>0.153250</td>
      <td>-0.574131</td>
      <td>-0.157076</td>
      <td>-0.173720</td>
      <td>-0.054994</td>
      <td>-1.017130</td>
      <td>-0.879374</td>
      <td>-0.644858</td>
      <td>-0.126591</td>
      <td>-0.058020</td>
      <td>0.040860</td>
      <td>-0.417145</td>
      <td>-2.506729</td>
      <td>-2.348617</td>
      <td>-1.406106</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>0.017098</td>
      <td>0.267186</td>
      <td>0.088520</td>
      <td>-0.178395</td>
      <td>-0.776886</td>
      <td>0.422369</td>
      <td>0.163601</td>
      <td>-0.717670</td>
      <td>-0.005680</td>
      <td>0.351680</td>
      <td>-0.172560</td>
      <td>0.497438</td>
      <td>0.578193</td>
      <td>0.441258</td>
      <td>-0.559357</td>
      <td>-0.467766</td>
      <td>0.903744</td>
      <td>1.270035</td>
      <td>1.399205</td>
      <td>0.463378</td>
      <td>-0.305885</td>
      <td>-0.146904</td>
      <td>-0.724557</td>
      <td>0.120419</td>
      <td>0.878799</td>
      <td>0.572696</td>
      <td>0.544579</td>
      <td>0.092652</td>
      <td>-0.251718</td>
      <td>0.106232</td>
      <td>-0.211683</td>
      <td>0.255830</td>
      <td>-0.399213</td>
      <td>-0.328174</td>
      <td>-0.620584</td>
      <td>0.595329</td>
      <td>0.525546</td>
      <td>0.606391</td>
      <td>0.909810</td>
      <td>-0.185314</td>
      <td>...</td>
      <td>-0.258469</td>
      <td>0.992901</td>
      <td>-0.050027</td>
      <td>0.437858</td>
      <td>0.172078</td>
      <td>-0.227941</td>
      <td>-0.367368</td>
      <td>-0.057602</td>
      <td>-0.232778</td>
      <td>-0.608812</td>
      <td>0.168808</td>
      <td>0.232890</td>
      <td>0.233305</td>
      <td>-0.496615</td>
      <td>-0.739940</td>
      <td>-1.275863</td>
      <td>0.352676</td>
      <td>0.428797</td>
      <td>0.212028</td>
      <td>-0.887713</td>
      <td>-0.226892</td>
      <td>-0.581275</td>
      <td>0.288341</td>
      <td>-0.029010</td>
      <td>0.531773</td>
      <td>0.745503</td>
      <td>0.382284</td>
      <td>0.094278</td>
      <td>-0.466497</td>
      <td>0.754407</td>
      <td>0.144084</td>
      <td>0.125390</td>
      <td>-0.068028</td>
      <td>-0.055750</td>
      <td>-0.079467</td>
      <td>-0.888316</td>
      <td>0.269971</td>
      <td>-0.867843</td>
      <td>0.916070</td>
      <td>0.062405</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.441017</td>
      <td>-0.605694</td>
      <td>0.002372</td>
      <td>0.475657</td>
      <td>-0.146263</td>
      <td>0.172154</td>
      <td>0.022077</td>
      <td>-1.152542</td>
      <td>-0.483395</td>
      <td>-0.240179</td>
      <td>-0.546547</td>
      <td>-0.005091</td>
      <td>0.209218</td>
      <td>0.746229</td>
      <td>-0.932148</td>
      <td>-0.801807</td>
      <td>0.518955</td>
      <td>-0.925664</td>
      <td>-0.040193</td>
      <td>-1.036498</td>
      <td>-0.615540</td>
      <td>-0.841094</td>
      <td>-0.585465</td>
      <td>0.100619</td>
      <td>0.642859</td>
      <td>0.019281</td>
      <td>-0.088856</td>
      <td>0.405271</td>
      <td>-0.282786</td>
      <td>0.328146</td>
      <td>0.543125</td>
      <td>-0.661765</td>
      <td>-0.167433</td>
      <td>0.032074</td>
      <td>-0.235129</td>
      <td>-0.660001</td>
      <td>0.346919</td>
      <td>0.306493</td>
      <td>-0.014230</td>
      <td>-0.169366</td>
      <td>...</td>
      <td>-0.938254</td>
      <td>-0.049142</td>
      <td>-0.073274</td>
      <td>0.109983</td>
      <td>0.032571</td>
      <td>0.181379</td>
      <td>0.831788</td>
      <td>0.518235</td>
      <td>-0.594873</td>
      <td>-0.441689</td>
      <td>-0.472592</td>
      <td>0.593899</td>
      <td>0.695855</td>
      <td>-0.074684</td>
      <td>-1.098682</td>
      <td>-0.412181</td>
      <td>0.034531</td>
      <td>0.108077</td>
      <td>0.976042</td>
      <td>-0.384156</td>
      <td>0.691357</td>
      <td>0.031262</td>
      <td>-0.289949</td>
      <td>-0.919679</td>
      <td>0.791878</td>
      <td>-0.157188</td>
      <td>-0.094722</td>
      <td>-0.415380</td>
      <td>0.855291</td>
      <td>1.896815</td>
      <td>0.491734</td>
      <td>0.429843</td>
      <td>0.335229</td>
      <td>0.591106</td>
      <td>-0.436741</td>
      <td>-0.502818</td>
      <td>0.618153</td>
      <td>2.470676</td>
      <td>1.845524</td>
      <td>1.114293</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.329836</td>
      <td>-0.820079</td>
      <td>-0.234946</td>
      <td>-0.145688</td>
      <td>0.158421</td>
      <td>0.158075</td>
      <td>-1.313252</td>
      <td>-0.272231</td>
      <td>-1.163030</td>
      <td>-1.162813</td>
      <td>-1.032481</td>
      <td>-0.344097</td>
      <td>-0.296973</td>
      <td>0.827295</td>
      <td>-0.209850</td>
      <td>-0.359517</td>
      <td>0.186242</td>
      <td>0.058397</td>
      <td>0.093001</td>
      <td>0.440998</td>
      <td>-0.574678</td>
      <td>0.167002</td>
      <td>0.537593</td>
      <td>-0.888216</td>
      <td>-0.460752</td>
      <td>0.028998</td>
      <td>-0.636931</td>
      <td>1.168850</td>
      <td>-1.309892</td>
      <td>-0.712721</td>
      <td>0.437526</td>
      <td>0.862942</td>
      <td>0.741947</td>
      <td>0.024669</td>
      <td>-1.285724</td>
      <td>0.504563</td>
      <td>-0.380416</td>
      <td>0.391161</td>
      <td>-0.839116</td>
      <td>-0.155491</td>
      <td>...</td>
      <td>-0.572442</td>
      <td>-0.922455</td>
      <td>-0.209906</td>
      <td>0.168689</td>
      <td>-0.299601</td>
      <td>-0.189152</td>
      <td>0.332048</td>
      <td>-0.331058</td>
      <td>0.117335</td>
      <td>-0.322300</td>
      <td>-0.788076</td>
      <td>-0.077334</td>
      <td>0.541227</td>
      <td>-0.346192</td>
      <td>-0.201191</td>
      <td>-0.546454</td>
      <td>0.535528</td>
      <td>-0.189991</td>
      <td>0.690864</td>
      <td>-0.860473</td>
      <td>0.136212</td>
      <td>0.213266</td>
      <td>-0.914178</td>
      <td>-0.504935</td>
      <td>0.108512</td>
      <td>-0.295004</td>
      <td>-0.223337</td>
      <td>-1.310913</td>
      <td>0.448564</td>
      <td>0.725740</td>
      <td>0.727660</td>
      <td>0.233469</td>
      <td>-0.180268</td>
      <td>-0.068739</td>
      <td>-0.370409</td>
      <td>-0.162922</td>
      <td>0.772824</td>
      <td>-2.888680</td>
      <td>-1.217744</td>
      <td>-0.097520</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.310710</td>
      <td>-0.428972</td>
      <td>-0.326547</td>
      <td>-0.375878</td>
      <td>0.452046</td>
      <td>0.286260</td>
      <td>-0.217140</td>
      <td>0.229631</td>
      <td>-0.093731</td>
      <td>-0.274744</td>
      <td>0.374899</td>
      <td>0.359233</td>
      <td>-0.503564</td>
      <td>0.311505</td>
      <td>0.237465</td>
      <td>-0.344550</td>
      <td>-0.043873</td>
      <td>-0.673161</td>
      <td>-0.732034</td>
      <td>0.596939</td>
      <td>0.124996</td>
      <td>-0.959964</td>
      <td>0.246009</td>
      <td>0.380023</td>
      <td>-0.987688</td>
      <td>0.304913</td>
      <td>0.873174</td>
      <td>-0.577766</td>
      <td>-0.649877</td>
      <td>0.396385</td>
      <td>0.655664</td>
      <td>0.261446</td>
      <td>0.225683</td>
      <td>-0.638073</td>
      <td>-0.227636</td>
      <td>-0.015485</td>
      <td>0.470349</td>
      <td>0.950231</td>
      <td>0.041015</td>
      <td>0.301321</td>
      <td>...</td>
      <td>0.758318</td>
      <td>-0.825535</td>
      <td>-0.493415</td>
      <td>-0.801475</td>
      <td>-1.073972</td>
      <td>-0.566942</td>
      <td>-0.499132</td>
      <td>-0.585976</td>
      <td>-0.517810</td>
      <td>-0.560550</td>
      <td>0.553706</td>
      <td>0.802145</td>
      <td>0.233297</td>
      <td>-0.052843</td>
      <td>0.071987</td>
      <td>-0.529677</td>
      <td>1.437259</td>
      <td>-0.677117</td>
      <td>-0.042733</td>
      <td>0.359461</td>
      <td>0.746864</td>
      <td>0.915043</td>
      <td>-0.316063</td>
      <td>-0.086477</td>
      <td>0.392258</td>
      <td>-0.100671</td>
      <td>-0.231832</td>
      <td>0.272995</td>
      <td>0.609334</td>
      <td>0.330426</td>
      <td>-0.412115</td>
      <td>0.122132</td>
      <td>0.118768</td>
      <td>-1.159163</td>
      <td>-1.886165</td>
      <td>-1.094166</td>
      <td>-0.587317</td>
      <td>-2.227831</td>
      <td>-1.531148</td>
      <td>-0.847976</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.202249</td>
      <td>0.580713</td>
      <td>0.231468</td>
      <td>0.092316</td>
      <td>0.632041</td>
      <td>1.139935</td>
      <td>-1.285709</td>
      <td>-1.670114</td>
      <td>-0.352672</td>
      <td>0.044407</td>
      <td>-0.339999</td>
      <td>-0.240440</td>
      <td>-0.631375</td>
      <td>0.187301</td>
      <td>0.210659</td>
      <td>0.791022</td>
      <td>-0.641941</td>
      <td>-0.014994</td>
      <td>-0.372888</td>
      <td>-0.061649</td>
      <td>0.048404</td>
      <td>0.167147</td>
      <td>1.047705</td>
      <td>0.287107</td>
      <td>-0.841209</td>
      <td>-0.673397</td>
      <td>-0.248357</td>
      <td>0.780571</td>
      <td>0.267822</td>
      <td>0.835443</td>
      <td>0.337815</td>
      <td>0.750170</td>
      <td>-0.020008</td>
      <td>-1.091016</td>
      <td>-1.319395</td>
      <td>-0.304591</td>
      <td>0.870230</td>
      <td>-0.485818</td>
      <td>-1.008656</td>
      <td>-0.079681</td>
      <td>...</td>
      <td>-0.202054</td>
      <td>-0.599956</td>
      <td>0.752696</td>
      <td>0.440157</td>
      <td>0.459946</td>
      <td>-0.267413</td>
      <td>-0.317453</td>
      <td>-0.838133</td>
      <td>-0.870192</td>
      <td>-0.100884</td>
      <td>-0.729364</td>
      <td>-0.149465</td>
      <td>0.127955</td>
      <td>0.748223</td>
      <td>-1.057642</td>
      <td>-0.608760</td>
      <td>1.535422</td>
      <td>-0.111828</td>
      <td>-0.963211</td>
      <td>-0.733995</td>
      <td>0.086917</td>
      <td>-0.778186</td>
      <td>-0.530472</td>
      <td>0.069408</td>
      <td>0.295887</td>
      <td>0.580663</td>
      <td>0.573335</td>
      <td>0.049865</td>
      <td>-0.051143</td>
      <td>-0.615874</td>
      <td>0.121371</td>
      <td>0.169756</td>
      <td>-0.059247</td>
      <td>0.442729</td>
      <td>-0.641465</td>
      <td>0.322035</td>
      <td>0.193930</td>
      <td>1.460391</td>
      <td>1.073400</td>
      <td>0.390500</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 103 columns</p>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f599c53e1f0&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err         t          P&gt;|t|     2.5 %    97.5 %
D  0.960701  0.037402  25.68598  1.676680e-145  0.887395  1.034007
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.531 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>