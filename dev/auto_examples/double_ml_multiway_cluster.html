
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-1.001064</td>
      <td>-0.275420</td>
      <td>-0.101846</td>
      <td>0.031839</td>
      <td>-0.184764</td>
      <td>-0.088079</td>
      <td>0.717628</td>
      <td>0.074325</td>
      <td>0.521402</td>
      <td>0.244876</td>
      <td>-0.322585</td>
      <td>-0.551647</td>
      <td>0.505372</td>
      <td>0.248063</td>
      <td>-0.190998</td>
      <td>-0.855244</td>
      <td>-0.409842</td>
      <td>-0.684266</td>
      <td>-0.318429</td>
      <td>-0.004278</td>
      <td>-0.854672</td>
      <td>-0.146626</td>
      <td>-0.055249</td>
      <td>0.022924</td>
      <td>0.330938</td>
      <td>0.688364</td>
      <td>0.707469</td>
      <td>-1.049808</td>
      <td>-0.221808</td>
      <td>0.385969</td>
      <td>0.420951</td>
      <td>0.498626</td>
      <td>-0.790582</td>
      <td>-0.367272</td>
      <td>0.258939</td>
      <td>-0.659981</td>
      <td>0.257049</td>
      <td>0.410720</td>
      <td>-1.357221</td>
      <td>-0.160280</td>
      <td>...</td>
      <td>0.882155</td>
      <td>1.357926</td>
      <td>0.402253</td>
      <td>0.884669</td>
      <td>0.768841</td>
      <td>0.830897</td>
      <td>-0.199491</td>
      <td>-0.547205</td>
      <td>0.124415</td>
      <td>-0.773209</td>
      <td>-0.604250</td>
      <td>0.592700</td>
      <td>-0.254364</td>
      <td>-0.065616</td>
      <td>-0.244315</td>
      <td>0.233367</td>
      <td>0.751974</td>
      <td>0.935123</td>
      <td>0.100584</td>
      <td>0.158165</td>
      <td>-0.858830</td>
      <td>-0.094617</td>
      <td>-0.079104</td>
      <td>0.498291</td>
      <td>0.576638</td>
      <td>0.170638</td>
      <td>0.584491</td>
      <td>0.075066</td>
      <td>0.135157</td>
      <td>-0.451855</td>
      <td>0.131958</td>
      <td>0.541359</td>
      <td>0.240429</td>
      <td>0.690176</td>
      <td>1.041130</td>
      <td>0.352207</td>
      <td>-0.143687</td>
      <td>-2.371310</td>
      <td>-1.248905</td>
      <td>-0.644768</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.442352</td>
      <td>1.289636</td>
      <td>0.360224</td>
      <td>-0.180218</td>
      <td>-0.262401</td>
      <td>0.213778</td>
      <td>-0.095583</td>
      <td>-0.206225</td>
      <td>0.325041</td>
      <td>0.858074</td>
      <td>-0.540619</td>
      <td>-0.340663</td>
      <td>-0.592893</td>
      <td>-0.504235</td>
      <td>-0.091012</td>
      <td>0.246842</td>
      <td>0.732809</td>
      <td>1.443457</td>
      <td>0.072535</td>
      <td>0.426115</td>
      <td>-0.358765</td>
      <td>0.899293</td>
      <td>0.089561</td>
      <td>0.313791</td>
      <td>0.633203</td>
      <td>0.180620</td>
      <td>-0.651537</td>
      <td>-0.618694</td>
      <td>0.305160</td>
      <td>0.404137</td>
      <td>-0.139395</td>
      <td>1.056998</td>
      <td>-0.145078</td>
      <td>0.233980</td>
      <td>-0.549826</td>
      <td>0.105461</td>
      <td>-0.486795</td>
      <td>0.683094</td>
      <td>-0.518623</td>
      <td>0.129816</td>
      <td>...</td>
      <td>0.231810</td>
      <td>0.081211</td>
      <td>-0.473459</td>
      <td>-0.271261</td>
      <td>-0.437796</td>
      <td>0.724935</td>
      <td>0.236166</td>
      <td>0.219284</td>
      <td>0.372262</td>
      <td>0.220801</td>
      <td>-0.258838</td>
      <td>1.009030</td>
      <td>0.737919</td>
      <td>1.219740</td>
      <td>0.200284</td>
      <td>0.504282</td>
      <td>-0.540600</td>
      <td>0.280100</td>
      <td>-0.645468</td>
      <td>-0.268527</td>
      <td>-0.597961</td>
      <td>-0.145576</td>
      <td>0.292665</td>
      <td>0.357991</td>
      <td>-0.549764</td>
      <td>-0.597178</td>
      <td>0.539827</td>
      <td>1.028073</td>
      <td>-0.113789</td>
      <td>-0.208188</td>
      <td>-0.188087</td>
      <td>0.239351</td>
      <td>0.419297</td>
      <td>-0.112046</td>
      <td>1.128310</td>
      <td>0.265682</td>
      <td>0.471235</td>
      <td>0.645799</td>
      <td>0.385019</td>
      <td>0.963957</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.128880</td>
      <td>0.663914</td>
      <td>0.472641</td>
      <td>0.417800</td>
      <td>-0.558782</td>
      <td>0.007746</td>
      <td>-0.334503</td>
      <td>0.040798</td>
      <td>0.235507</td>
      <td>0.380806</td>
      <td>0.367769</td>
      <td>0.548465</td>
      <td>0.496875</td>
      <td>0.126845</td>
      <td>-0.503438</td>
      <td>-1.190974</td>
      <td>0.562630</td>
      <td>0.430878</td>
      <td>0.584913</td>
      <td>0.539473</td>
      <td>0.120768</td>
      <td>0.132849</td>
      <td>0.338334</td>
      <td>0.942653</td>
      <td>0.851935</td>
      <td>0.106192</td>
      <td>0.755625</td>
      <td>-0.401311</td>
      <td>-0.396238</td>
      <td>0.425300</td>
      <td>0.140150</td>
      <td>-0.073847</td>
      <td>-0.346231</td>
      <td>-0.323783</td>
      <td>0.235267</td>
      <td>0.712674</td>
      <td>0.028727</td>
      <td>0.234618</td>
      <td>-0.199341</td>
      <td>0.648791</td>
      <td>...</td>
      <td>-0.337399</td>
      <td>0.208368</td>
      <td>-0.133886</td>
      <td>0.277884</td>
      <td>-0.262549</td>
      <td>-0.142453</td>
      <td>0.270876</td>
      <td>-0.442655</td>
      <td>-0.775412</td>
      <td>-0.767775</td>
      <td>-1.189472</td>
      <td>-0.574115</td>
      <td>0.304569</td>
      <td>0.335560</td>
      <td>-0.448152</td>
      <td>-1.369820</td>
      <td>-0.456391</td>
      <td>-0.502602</td>
      <td>0.008369</td>
      <td>0.698264</td>
      <td>-0.426800</td>
      <td>0.271823</td>
      <td>-0.492185</td>
      <td>-0.170106</td>
      <td>-0.084593</td>
      <td>0.400927</td>
      <td>0.587836</td>
      <td>-0.433811</td>
      <td>-0.521250</td>
      <td>-0.817102</td>
      <td>-0.455142</td>
      <td>-0.216521</td>
      <td>-0.479343</td>
      <td>0.620221</td>
      <td>0.691781</td>
      <td>-0.937583</td>
      <td>0.269640</td>
      <td>-0.657675</td>
      <td>-0.135844</td>
      <td>0.916409</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.601586</td>
      <td>0.078941</td>
      <td>-0.380338</td>
      <td>0.106241</td>
      <td>-0.728796</td>
      <td>-0.921855</td>
      <td>-1.019777</td>
      <td>-0.427052</td>
      <td>-0.051036</td>
      <td>0.144066</td>
      <td>-0.778788</td>
      <td>-0.851296</td>
      <td>-0.303823</td>
      <td>-0.004537</td>
      <td>0.022365</td>
      <td>0.443806</td>
      <td>1.258767</td>
      <td>-0.118923</td>
      <td>0.603111</td>
      <td>0.462815</td>
      <td>0.111131</td>
      <td>0.206686</td>
      <td>-0.071976</td>
      <td>-0.050043</td>
      <td>0.413554</td>
      <td>0.401560</td>
      <td>-0.088333</td>
      <td>0.808217</td>
      <td>0.332424</td>
      <td>0.519202</td>
      <td>-0.677710</td>
      <td>1.177453</td>
      <td>0.353194</td>
      <td>-0.432236</td>
      <td>0.131102</td>
      <td>0.260386</td>
      <td>-0.272352</td>
      <td>0.096893</td>
      <td>-0.802944</td>
      <td>0.235954</td>
      <td>...</td>
      <td>-1.202228</td>
      <td>0.875990</td>
      <td>0.549068</td>
      <td>0.023637</td>
      <td>-0.959533</td>
      <td>0.582067</td>
      <td>-0.149613</td>
      <td>-0.537615</td>
      <td>1.079660</td>
      <td>0.270472</td>
      <td>-0.521081</td>
      <td>0.990397</td>
      <td>0.021207</td>
      <td>0.099080</td>
      <td>-0.453348</td>
      <td>-0.719126</td>
      <td>-0.584544</td>
      <td>-0.515003</td>
      <td>-0.756413</td>
      <td>-0.451131</td>
      <td>-0.415861</td>
      <td>-0.053254</td>
      <td>0.059626</td>
      <td>1.022560</td>
      <td>0.336531</td>
      <td>0.024102</td>
      <td>0.119128</td>
      <td>-0.435878</td>
      <td>-0.221872</td>
      <td>0.010424</td>
      <td>0.764011</td>
      <td>-0.062645</td>
      <td>-0.646009</td>
      <td>0.509916</td>
      <td>-0.330862</td>
      <td>-0.413184</td>
      <td>0.424123</td>
      <td>0.139061</td>
      <td>0.395497</td>
      <td>0.560965</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.439412</td>
      <td>0.730459</td>
      <td>0.038992</td>
      <td>0.761253</td>
      <td>1.044092</td>
      <td>1.044952</td>
      <td>0.677312</td>
      <td>0.599533</td>
      <td>0.229468</td>
      <td>-0.965285</td>
      <td>-0.962446</td>
      <td>-1.424125</td>
      <td>-0.820560</td>
      <td>-0.233773</td>
      <td>0.108906</td>
      <td>-0.357250</td>
      <td>0.650688</td>
      <td>0.978771</td>
      <td>0.200731</td>
      <td>1.315494</td>
      <td>0.030085</td>
      <td>-0.722197</td>
      <td>0.017081</td>
      <td>0.376156</td>
      <td>0.477495</td>
      <td>-0.077246</td>
      <td>-0.076187</td>
      <td>-0.343600</td>
      <td>1.325167</td>
      <td>-0.234588</td>
      <td>-0.258680</td>
      <td>-1.180111</td>
      <td>-0.562549</td>
      <td>-0.600533</td>
      <td>-0.185134</td>
      <td>-0.830194</td>
      <td>0.278758</td>
      <td>-0.523564</td>
      <td>-0.528662</td>
      <td>0.322316</td>
      <td>...</td>
      <td>-0.609219</td>
      <td>0.474898</td>
      <td>0.649866</td>
      <td>0.582909</td>
      <td>1.094535</td>
      <td>-0.606177</td>
      <td>0.440582</td>
      <td>-1.339630</td>
      <td>-1.154903</td>
      <td>0.078467</td>
      <td>0.116169</td>
      <td>-0.085675</td>
      <td>0.510391</td>
      <td>-0.139987</td>
      <td>1.302442</td>
      <td>0.685985</td>
      <td>0.084092</td>
      <td>-0.112611</td>
      <td>-0.486917</td>
      <td>-0.512498</td>
      <td>-0.039973</td>
      <td>0.314042</td>
      <td>-1.430741</td>
      <td>0.195906</td>
      <td>1.026461</td>
      <td>0.338590</td>
      <td>-0.115828</td>
      <td>0.065541</td>
      <td>-0.200790</td>
      <td>0.398091</td>
      <td>0.345558</td>
      <td>0.122961</td>
      <td>-0.048826</td>
      <td>-0.026121</td>
      <td>0.013365</td>
      <td>-0.181719</td>
      <td>-0.408286</td>
      <td>2.019325</td>
      <td>2.079598</td>
      <td>1.669263</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.879444</td>
      <td>1.202612</td>
      <td>0.383802</td>
      <td>-0.250495</td>
      <td>-0.349755</td>
      <td>-0.256255</td>
      <td>0.349446</td>
      <td>-0.514648</td>
      <td>-0.491967</td>
      <td>-1.294588</td>
      <td>-0.800635</td>
      <td>-1.647811</td>
      <td>-0.223063</td>
      <td>-0.288576</td>
      <td>-0.377507</td>
      <td>-0.531550</td>
      <td>-0.392267</td>
      <td>-0.202855</td>
      <td>-0.781514</td>
      <td>0.224332</td>
      <td>-0.067397</td>
      <td>0.442472</td>
      <td>-0.890263</td>
      <td>-0.718178</td>
      <td>-1.099015</td>
      <td>-1.231247</td>
      <td>0.614460</td>
      <td>-0.806797</td>
      <td>-0.242297</td>
      <td>-0.402964</td>
      <td>-0.540222</td>
      <td>-0.318418</td>
      <td>-0.120091</td>
      <td>-0.506373</td>
      <td>1.129613</td>
      <td>0.342445</td>
      <td>0.389037</td>
      <td>0.565007</td>
      <td>-0.190180</td>
      <td>0.203331</td>
      <td>...</td>
      <td>-0.503800</td>
      <td>-0.410752</td>
      <td>0.450257</td>
      <td>0.930476</td>
      <td>-0.013957</td>
      <td>-0.447669</td>
      <td>-0.507160</td>
      <td>-1.486648</td>
      <td>-0.537683</td>
      <td>0.349400</td>
      <td>-0.200571</td>
      <td>0.338724</td>
      <td>0.473949</td>
      <td>0.217878</td>
      <td>-0.373787</td>
      <td>-0.093285</td>
      <td>-1.469359</td>
      <td>-0.087366</td>
      <td>-0.690462</td>
      <td>0.119743</td>
      <td>-0.244985</td>
      <td>-0.672645</td>
      <td>0.240031</td>
      <td>-0.110425</td>
      <td>0.167193</td>
      <td>-0.101293</td>
      <td>0.190058</td>
      <td>-0.357068</td>
      <td>-1.367807</td>
      <td>-0.060437</td>
      <td>0.158810</td>
      <td>0.885046</td>
      <td>-0.027471</td>
      <td>0.025479</td>
      <td>-0.185589</td>
      <td>-1.166391</td>
      <td>1.201401</td>
      <td>-2.033726</td>
      <td>-0.822954</td>
      <td>0.470649</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.341809</td>
      <td>1.196896</td>
      <td>0.237560</td>
      <td>0.344960</td>
      <td>-0.067711</td>
      <td>0.253995</td>
      <td>-0.024737</td>
      <td>-0.318478</td>
      <td>-0.801792</td>
      <td>0.167165</td>
      <td>-0.099821</td>
      <td>-0.245530</td>
      <td>-0.872686</td>
      <td>-0.493635</td>
      <td>-0.763401</td>
      <td>-0.169629</td>
      <td>0.281836</td>
      <td>-0.376407</td>
      <td>-0.020301</td>
      <td>0.843281</td>
      <td>-0.424745</td>
      <td>0.171614</td>
      <td>-0.908468</td>
      <td>0.305616</td>
      <td>-0.525994</td>
      <td>0.537939</td>
      <td>0.045799</td>
      <td>-0.020176</td>
      <td>-0.173006</td>
      <td>-0.021654</td>
      <td>-0.996625</td>
      <td>0.124205</td>
      <td>0.027883</td>
      <td>-0.448556</td>
      <td>-0.348523</td>
      <td>0.101070</td>
      <td>-0.701324</td>
      <td>0.244435</td>
      <td>-0.688717</td>
      <td>0.051765</td>
      <td>...</td>
      <td>-0.025133</td>
      <td>0.618416</td>
      <td>0.545412</td>
      <td>0.254785</td>
      <td>-0.257861</td>
      <td>0.427379</td>
      <td>0.445819</td>
      <td>-0.936862</td>
      <td>-1.022786</td>
      <td>-0.357154</td>
      <td>-1.354060</td>
      <td>0.873798</td>
      <td>-0.247590</td>
      <td>-0.062026</td>
      <td>-0.060091</td>
      <td>-0.328437</td>
      <td>-1.535298</td>
      <td>-1.102726</td>
      <td>-0.462627</td>
      <td>0.656854</td>
      <td>-0.215249</td>
      <td>-1.308029</td>
      <td>-0.658242</td>
      <td>-0.302821</td>
      <td>0.469144</td>
      <td>0.014146</td>
      <td>0.714459</td>
      <td>-0.283105</td>
      <td>-0.202768</td>
      <td>0.797291</td>
      <td>0.817774</td>
      <td>0.206203</td>
      <td>-0.440586</td>
      <td>0.007215</td>
      <td>0.631046</td>
      <td>-0.625578</td>
      <td>1.193788</td>
      <td>2.222870</td>
      <td>1.082178</td>
      <td>0.296715</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.544866</td>
      <td>-0.564781</td>
      <td>-0.226176</td>
      <td>-0.279955</td>
      <td>-0.970640</td>
      <td>-0.423784</td>
      <td>0.028416</td>
      <td>-0.504457</td>
      <td>0.897029</td>
      <td>0.019958</td>
      <td>0.720907</td>
      <td>0.067493</td>
      <td>-0.206101</td>
      <td>-0.597464</td>
      <td>0.005270</td>
      <td>0.389242</td>
      <td>-0.082481</td>
      <td>0.387774</td>
      <td>0.951734</td>
      <td>1.930646</td>
      <td>0.132042</td>
      <td>-0.377303</td>
      <td>0.219045</td>
      <td>-0.448917</td>
      <td>0.701072</td>
      <td>-0.137376</td>
      <td>1.057283</td>
      <td>-0.686127</td>
      <td>0.182010</td>
      <td>0.973169</td>
      <td>0.439051</td>
      <td>0.714983</td>
      <td>0.460157</td>
      <td>0.071258</td>
      <td>0.423896</td>
      <td>-0.424512</td>
      <td>0.143975</td>
      <td>-0.172767</td>
      <td>-1.261234</td>
      <td>0.341652</td>
      <td>...</td>
      <td>0.193004</td>
      <td>0.408847</td>
      <td>0.791894</td>
      <td>0.004969</td>
      <td>0.274757</td>
      <td>0.319875</td>
      <td>0.185776</td>
      <td>-0.990100</td>
      <td>-0.690161</td>
      <td>0.732796</td>
      <td>-0.724453</td>
      <td>-0.160216</td>
      <td>0.017203</td>
      <td>-0.121535</td>
      <td>-0.439643</td>
      <td>-0.111818</td>
      <td>-0.116733</td>
      <td>-0.688219</td>
      <td>-0.234229</td>
      <td>-0.078363</td>
      <td>0.422166</td>
      <td>1.113146</td>
      <td>-0.181940</td>
      <td>-0.235587</td>
      <td>-0.228045</td>
      <td>-0.792450</td>
      <td>0.490967</td>
      <td>0.390282</td>
      <td>-0.471109</td>
      <td>-1.100462</td>
      <td>-0.029675</td>
      <td>0.511013</td>
      <td>-0.842895</td>
      <td>-0.435885</td>
      <td>0.542075</td>
      <td>-0.485219</td>
      <td>0.820290</td>
      <td>1.602897</td>
      <td>0.895594</td>
      <td>-0.280116</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.176001</td>
      <td>-0.296322</td>
      <td>-0.433825</td>
      <td>0.201658</td>
      <td>-0.062313</td>
      <td>0.539296</td>
      <td>-0.511451</td>
      <td>-0.401264</td>
      <td>0.622379</td>
      <td>0.281033</td>
      <td>0.513920</td>
      <td>0.768149</td>
      <td>0.277121</td>
      <td>0.243430</td>
      <td>0.194567</td>
      <td>-1.226710</td>
      <td>-1.548538</td>
      <td>-0.002476</td>
      <td>-0.558068</td>
      <td>0.155759</td>
      <td>-0.591282</td>
      <td>0.413828</td>
      <td>-0.748201</td>
      <td>-0.157047</td>
      <td>0.481605</td>
      <td>-0.484643</td>
      <td>0.281298</td>
      <td>-0.721278</td>
      <td>0.179378</td>
      <td>0.358849</td>
      <td>-0.023406</td>
      <td>-0.281704</td>
      <td>-0.911116</td>
      <td>-0.625127</td>
      <td>-0.764070</td>
      <td>-0.474902</td>
      <td>-0.249466</td>
      <td>-0.578883</td>
      <td>-0.502880</td>
      <td>-0.121478</td>
      <td>...</td>
      <td>-0.157455</td>
      <td>1.158543</td>
      <td>0.210744</td>
      <td>1.042172</td>
      <td>-0.006350</td>
      <td>0.616970</td>
      <td>0.039730</td>
      <td>0.371497</td>
      <td>0.548661</td>
      <td>0.475306</td>
      <td>-0.934825</td>
      <td>0.246526</td>
      <td>0.031183</td>
      <td>-0.299176</td>
      <td>-0.344336</td>
      <td>-1.449815</td>
      <td>-1.026597</td>
      <td>0.019417</td>
      <td>-0.989473</td>
      <td>0.146668</td>
      <td>0.534836</td>
      <td>0.000988</td>
      <td>-0.272624</td>
      <td>-0.167951</td>
      <td>-0.863526</td>
      <td>-0.851433</td>
      <td>0.158473</td>
      <td>-0.283292</td>
      <td>0.355995</td>
      <td>0.118581</td>
      <td>0.581067</td>
      <td>0.807253</td>
      <td>0.218031</td>
      <td>0.216925</td>
      <td>-0.238539</td>
      <td>0.250144</td>
      <td>0.873454</td>
      <td>0.251130</td>
      <td>0.149431</td>
      <td>0.110208</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-0.671651</td>
      <td>-0.192903</td>
      <td>-0.317347</td>
      <td>0.587996</td>
      <td>1.070814</td>
      <td>0.248395</td>
      <td>0.711885</td>
      <td>0.283632</td>
      <td>1.059468</td>
      <td>0.844041</td>
      <td>-0.258153</td>
      <td>0.387014</td>
      <td>-0.132056</td>
      <td>-0.764759</td>
      <td>-1.414102</td>
      <td>0.293096</td>
      <td>0.078710</td>
      <td>1.438473</td>
      <td>0.001709</td>
      <td>-0.666885</td>
      <td>-0.160092</td>
      <td>0.814732</td>
      <td>-0.128135</td>
      <td>-0.219574</td>
      <td>1.443943</td>
      <td>0.924420</td>
      <td>-0.118139</td>
      <td>-0.426129</td>
      <td>-0.327603</td>
      <td>-0.844414</td>
      <td>-1.322526</td>
      <td>0.280717</td>
      <td>0.457687</td>
      <td>-0.162675</td>
      <td>0.396946</td>
      <td>-0.271076</td>
      <td>-0.823874</td>
      <td>-0.639378</td>
      <td>-0.578134</td>
      <td>-0.239526</td>
      <td>...</td>
      <td>0.282447</td>
      <td>-0.009526</td>
      <td>-1.052165</td>
      <td>-0.053538</td>
      <td>0.214276</td>
      <td>1.235782</td>
      <td>0.172115</td>
      <td>-1.148529</td>
      <td>-0.748520</td>
      <td>0.455793</td>
      <td>0.818980</td>
      <td>0.767180</td>
      <td>0.161073</td>
      <td>-0.154368</td>
      <td>-0.382659</td>
      <td>-0.574966</td>
      <td>-0.580782</td>
      <td>-0.441736</td>
      <td>-0.383700</td>
      <td>0.314589</td>
      <td>-0.309536</td>
      <td>-1.062062</td>
      <td>-0.115080</td>
      <td>-0.262771</td>
      <td>-0.527866</td>
      <td>0.167721</td>
      <td>0.582248</td>
      <td>-0.107474</td>
      <td>-1.093892</td>
      <td>-0.855593</td>
      <td>0.188431</td>
      <td>0.405035</td>
      <td>0.371375</td>
      <td>0.287181</td>
      <td>-1.188273</td>
      <td>0.156166</td>
      <td>-0.144241</td>
      <td>-0.314473</td>
      <td>-0.421606</td>
      <td>-0.571347</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.140156</td>
      <td>0.151124</td>
      <td>-0.562626</td>
      <td>0.604862</td>
      <td>0.607791</td>
      <td>-0.188320</td>
      <td>0.519753</td>
      <td>-0.635243</td>
      <td>-0.464655</td>
      <td>-1.082242</td>
      <td>-0.394999</td>
      <td>-0.342267</td>
      <td>-0.969150</td>
      <td>-1.147128</td>
      <td>-1.026161</td>
      <td>-0.698712</td>
      <td>-0.118449</td>
      <td>0.707722</td>
      <td>0.234478</td>
      <td>1.419109</td>
      <td>-0.713926</td>
      <td>-0.012084</td>
      <td>0.157659</td>
      <td>-0.374788</td>
      <td>0.808533</td>
      <td>0.089793</td>
      <td>-0.038487</td>
      <td>0.236200</td>
      <td>0.320189</td>
      <td>-0.171990</td>
      <td>-1.567538</td>
      <td>0.035030</td>
      <td>0.058095</td>
      <td>-0.088545</td>
      <td>-0.025806</td>
      <td>-0.398463</td>
      <td>0.573399</td>
      <td>0.701054</td>
      <td>-0.260932</td>
      <td>0.216809</td>
      <td>...</td>
      <td>0.323730</td>
      <td>0.086572</td>
      <td>-0.829172</td>
      <td>0.249080</td>
      <td>-0.557109</td>
      <td>0.356276</td>
      <td>0.189469</td>
      <td>0.364482</td>
      <td>0.199291</td>
      <td>0.436502</td>
      <td>-0.698567</td>
      <td>0.901597</td>
      <td>0.822193</td>
      <td>0.646646</td>
      <td>0.587344</td>
      <td>1.272101</td>
      <td>0.410863</td>
      <td>0.800024</td>
      <td>0.749269</td>
      <td>0.081917</td>
      <td>0.362767</td>
      <td>-0.568360</td>
      <td>-0.534431</td>
      <td>1.140045</td>
      <td>0.083750</td>
      <td>0.069691</td>
      <td>0.640239</td>
      <td>-0.435583</td>
      <td>-0.184336</td>
      <td>-0.210711</td>
      <td>-0.368183</td>
      <td>0.294284</td>
      <td>0.599967</td>
      <td>0.060250</td>
      <td>-0.220743</td>
      <td>-0.138018</td>
      <td>0.820319</td>
      <td>1.788843</td>
      <td>0.737013</td>
      <td>-0.598998</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.023877</td>
      <td>0.396882</td>
      <td>-0.305149</td>
      <td>-1.311673</td>
      <td>-0.408951</td>
      <td>-0.128238</td>
      <td>0.123361</td>
      <td>-0.082365</td>
      <td>-0.226187</td>
      <td>-0.895888</td>
      <td>-1.035427</td>
      <td>-1.209383</td>
      <td>-0.451462</td>
      <td>-0.354405</td>
      <td>0.267181</td>
      <td>0.182283</td>
      <td>0.218479</td>
      <td>0.105431</td>
      <td>0.137541</td>
      <td>1.266550</td>
      <td>-0.113847</td>
      <td>0.358072</td>
      <td>0.454640</td>
      <td>-0.315698</td>
      <td>0.722551</td>
      <td>0.617626</td>
      <td>0.051580</td>
      <td>0.666653</td>
      <td>0.312545</td>
      <td>-0.179150</td>
      <td>-0.731571</td>
      <td>-0.730514</td>
      <td>0.113654</td>
      <td>-0.769629</td>
      <td>0.341934</td>
      <td>-0.856516</td>
      <td>-0.313978</td>
      <td>0.008605</td>
      <td>-0.227956</td>
      <td>0.150210</td>
      <td>...</td>
      <td>-0.122601</td>
      <td>-0.013885</td>
      <td>-0.048028</td>
      <td>0.225403</td>
      <td>-0.557031</td>
      <td>-0.307973</td>
      <td>0.085441</td>
      <td>-1.394997</td>
      <td>0.381372</td>
      <td>-0.375951</td>
      <td>-1.361805</td>
      <td>0.457316</td>
      <td>0.500034</td>
      <td>-0.039240</td>
      <td>0.250341</td>
      <td>0.263297</td>
      <td>-0.797600</td>
      <td>-1.388179</td>
      <td>-0.477533</td>
      <td>-0.248242</td>
      <td>-0.842939</td>
      <td>-0.077542</td>
      <td>-0.529024</td>
      <td>-0.265379</td>
      <td>0.108008</td>
      <td>-0.573901</td>
      <td>-0.209046</td>
      <td>0.297234</td>
      <td>-1.638121</td>
      <td>-1.744708</td>
      <td>-0.282747</td>
      <td>0.083556</td>
      <td>0.630556</td>
      <td>0.369419</td>
      <td>0.595385</td>
      <td>0.115098</td>
      <td>0.625333</td>
      <td>-1.087572</td>
      <td>-0.497727</td>
      <td>-0.443490</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.167565</td>
      <td>0.150531</td>
      <td>0.324387</td>
      <td>-0.695558</td>
      <td>-0.258754</td>
      <td>0.904441</td>
      <td>-0.070394</td>
      <td>-0.424506</td>
      <td>-0.280226</td>
      <td>-0.864311</td>
      <td>0.437184</td>
      <td>0.411205</td>
      <td>-1.041261</td>
      <td>-0.145062</td>
      <td>-0.914518</td>
      <td>0.335987</td>
      <td>0.426713</td>
      <td>1.380083</td>
      <td>0.120202</td>
      <td>0.559900</td>
      <td>-0.035850</td>
      <td>1.123731</td>
      <td>0.086600</td>
      <td>0.046559</td>
      <td>0.991767</td>
      <td>0.786363</td>
      <td>1.000187</td>
      <td>0.248351</td>
      <td>0.693295</td>
      <td>-0.665618</td>
      <td>-0.420978</td>
      <td>-0.857209</td>
      <td>-0.746542</td>
      <td>0.565042</td>
      <td>0.848072</td>
      <td>-0.009978</td>
      <td>-0.230885</td>
      <td>0.412479</td>
      <td>-0.111728</td>
      <td>0.145310</td>
      <td>...</td>
      <td>0.598515</td>
      <td>1.107008</td>
      <td>1.720389</td>
      <td>-0.396664</td>
      <td>0.404992</td>
      <td>-0.122701</td>
      <td>-0.142703</td>
      <td>0.018867</td>
      <td>0.024365</td>
      <td>0.229569</td>
      <td>-1.004017</td>
      <td>-0.058322</td>
      <td>-0.194758</td>
      <td>0.523922</td>
      <td>0.504354</td>
      <td>0.375039</td>
      <td>-1.222941</td>
      <td>-0.093506</td>
      <td>0.240358</td>
      <td>0.756269</td>
      <td>0.430805</td>
      <td>0.790875</td>
      <td>-1.168527</td>
      <td>-0.435704</td>
      <td>0.205276</td>
      <td>-0.074444</td>
      <td>-0.216401</td>
      <td>0.538491</td>
      <td>-0.891122</td>
      <td>-0.953468</td>
      <td>-0.590228</td>
      <td>0.050174</td>
      <td>-0.705618</td>
      <td>-0.484015</td>
      <td>-0.092897</td>
      <td>-0.932715</td>
      <td>0.512080</td>
      <td>-0.375085</td>
      <td>-0.333407</td>
      <td>-0.292549</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.000547</td>
      <td>-0.131903</td>
      <td>-0.552266</td>
      <td>0.847427</td>
      <td>-0.060821</td>
      <td>-0.010378</td>
      <td>-0.659843</td>
      <td>-0.488401</td>
      <td>0.388798</td>
      <td>-0.647152</td>
      <td>-0.825925</td>
      <td>-0.682338</td>
      <td>0.003181</td>
      <td>0.402045</td>
      <td>0.842607</td>
      <td>-0.259252</td>
      <td>-0.124470</td>
      <td>0.023301</td>
      <td>0.093631</td>
      <td>-0.312380</td>
      <td>-0.619143</td>
      <td>-0.585706</td>
      <td>0.333994</td>
      <td>0.255228</td>
      <td>0.979351</td>
      <td>-1.002836</td>
      <td>0.148460</td>
      <td>-0.746865</td>
      <td>-0.036496</td>
      <td>0.041243</td>
      <td>0.042313</td>
      <td>-0.511716</td>
      <td>0.270621</td>
      <td>-0.481046</td>
      <td>0.281630</td>
      <td>-0.334339</td>
      <td>-0.508503</td>
      <td>-0.783604</td>
      <td>-0.153685</td>
      <td>0.036187</td>
      <td>...</td>
      <td>0.701469</td>
      <td>0.478862</td>
      <td>0.227356</td>
      <td>-0.113676</td>
      <td>0.309105</td>
      <td>0.748890</td>
      <td>0.065254</td>
      <td>-0.062810</td>
      <td>-0.655397</td>
      <td>0.950805</td>
      <td>-0.485273</td>
      <td>0.362400</td>
      <td>0.774999</td>
      <td>-0.960472</td>
      <td>-0.553880</td>
      <td>0.250915</td>
      <td>0.305521</td>
      <td>-0.192772</td>
      <td>-1.206629</td>
      <td>-0.960462</td>
      <td>-1.060058</td>
      <td>-0.185827</td>
      <td>-0.633635</td>
      <td>0.484927</td>
      <td>0.570067</td>
      <td>-0.328793</td>
      <td>-0.059643</td>
      <td>-0.097861</td>
      <td>-0.188395</td>
      <td>-0.279315</td>
      <td>-0.734191</td>
      <td>-0.936199</td>
      <td>0.388495</td>
      <td>0.162016</td>
      <td>-0.276362</td>
      <td>0.711471</td>
      <td>0.169578</td>
      <td>-0.051378</td>
      <td>-0.229020</td>
      <td>-0.965063</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.644003</td>
      <td>-0.762300</td>
      <td>-0.050528</td>
      <td>0.276148</td>
      <td>0.012764</td>
      <td>-0.175025</td>
      <td>-0.361112</td>
      <td>-0.472942</td>
      <td>0.140993</td>
      <td>0.064207</td>
      <td>-0.090489</td>
      <td>-0.719194</td>
      <td>-1.657936</td>
      <td>0.261274</td>
      <td>0.881111</td>
      <td>-1.471482</td>
      <td>0.157855</td>
      <td>0.200561</td>
      <td>-0.509313</td>
      <td>0.697549</td>
      <td>-0.230601</td>
      <td>-0.638620</td>
      <td>-0.487389</td>
      <td>0.547420</td>
      <td>-0.188374</td>
      <td>-0.713168</td>
      <td>-0.758867</td>
      <td>-0.164018</td>
      <td>-0.137400</td>
      <td>0.686147</td>
      <td>-0.122823</td>
      <td>-0.352537</td>
      <td>-0.199160</td>
      <td>0.580802</td>
      <td>0.095733</td>
      <td>-0.108642</td>
      <td>-0.657784</td>
      <td>-0.066456</td>
      <td>-0.227284</td>
      <td>1.237529</td>
      <td>...</td>
      <td>0.013640</td>
      <td>-0.495945</td>
      <td>-0.925825</td>
      <td>-0.463275</td>
      <td>-0.313726</td>
      <td>1.318453</td>
      <td>0.230212</td>
      <td>-0.439419</td>
      <td>-0.149523</td>
      <td>1.061872</td>
      <td>1.447366</td>
      <td>0.293460</td>
      <td>0.735575</td>
      <td>0.572564</td>
      <td>0.079357</td>
      <td>1.000159</td>
      <td>0.056064</td>
      <td>-0.035449</td>
      <td>-0.172821</td>
      <td>-1.025527</td>
      <td>-0.732921</td>
      <td>-0.004764</td>
      <td>-0.427222</td>
      <td>-0.147840</td>
      <td>0.346782</td>
      <td>-0.481268</td>
      <td>-0.698320</td>
      <td>-0.474278</td>
      <td>0.356736</td>
      <td>-0.922090</td>
      <td>0.280327</td>
      <td>0.568828</td>
      <td>-0.131569</td>
      <td>0.393315</td>
      <td>0.419970</td>
      <td>0.264400</td>
      <td>0.277079</td>
      <td>-0.282545</td>
      <td>-0.078855</td>
      <td>0.137049</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-0.818113</td>
      <td>0.052133</td>
      <td>-0.793297</td>
      <td>0.402334</td>
      <td>-0.193400</td>
      <td>-0.648659</td>
      <td>-0.374645</td>
      <td>-0.421207</td>
      <td>0.660699</td>
      <td>-0.358608</td>
      <td>-0.485299</td>
      <td>-1.143509</td>
      <td>-0.483576</td>
      <td>0.876350</td>
      <td>0.878025</td>
      <td>0.225812</td>
      <td>1.031219</td>
      <td>0.658269</td>
      <td>0.293977</td>
      <td>0.496400</td>
      <td>0.034502</td>
      <td>-0.433681</td>
      <td>0.020935</td>
      <td>-0.408991</td>
      <td>0.319207</td>
      <td>-1.487493</td>
      <td>-0.419701</td>
      <td>0.469172</td>
      <td>0.708856</td>
      <td>-0.182774</td>
      <td>-0.149815</td>
      <td>1.549361</td>
      <td>0.204870</td>
      <td>-0.727288</td>
      <td>-0.548973</td>
      <td>0.186106</td>
      <td>-0.621973</td>
      <td>-0.315051</td>
      <td>0.289789</td>
      <td>0.587860</td>
      <td>...</td>
      <td>-0.006915</td>
      <td>0.719676</td>
      <td>0.464948</td>
      <td>-0.682073</td>
      <td>-1.021917</td>
      <td>-0.113063</td>
      <td>0.646813</td>
      <td>-0.910731</td>
      <td>0.123181</td>
      <td>0.106440</td>
      <td>-0.482249</td>
      <td>-0.569025</td>
      <td>-0.119332</td>
      <td>0.328908</td>
      <td>-0.340064</td>
      <td>-0.296564</td>
      <td>-0.212181</td>
      <td>0.521362</td>
      <td>-1.179073</td>
      <td>-0.371258</td>
      <td>0.020785</td>
      <td>-0.051346</td>
      <td>-0.598968</td>
      <td>0.436508</td>
      <td>0.695954</td>
      <td>-0.121758</td>
      <td>0.271728</td>
      <td>-0.024821</td>
      <td>-1.741223</td>
      <td>-0.552456</td>
      <td>-1.699740</td>
      <td>0.854483</td>
      <td>-0.101924</td>
      <td>-0.255562</td>
      <td>-0.146022</td>
      <td>-0.059065</td>
      <td>0.421592</td>
      <td>-2.797041</td>
      <td>-1.530588</td>
      <td>-0.630719</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-0.891834</td>
      <td>-0.512417</td>
      <td>-1.248244</td>
      <td>-1.260151</td>
      <td>-0.231680</td>
      <td>-0.263830</td>
      <td>0.133886</td>
      <td>-0.218385</td>
      <td>-0.371983</td>
      <td>0.237552</td>
      <td>-1.145495</td>
      <td>0.245976</td>
      <td>-0.525134</td>
      <td>-0.763529</td>
      <td>-0.884811</td>
      <td>0.091712</td>
      <td>0.810031</td>
      <td>0.573293</td>
      <td>0.305708</td>
      <td>0.272541</td>
      <td>-0.093646</td>
      <td>0.329725</td>
      <td>0.129639</td>
      <td>-0.299897</td>
      <td>-0.006924</td>
      <td>-0.430551</td>
      <td>0.891363</td>
      <td>0.291134</td>
      <td>0.761879</td>
      <td>-0.685660</td>
      <td>-0.766239</td>
      <td>-0.075524</td>
      <td>-0.187160</td>
      <td>0.548569</td>
      <td>1.186102</td>
      <td>-0.073919</td>
      <td>-0.313697</td>
      <td>-0.161389</td>
      <td>-0.179542</td>
      <td>0.103070</td>
      <td>...</td>
      <td>-0.266390</td>
      <td>-0.230956</td>
      <td>0.280216</td>
      <td>0.117207</td>
      <td>-0.300456</td>
      <td>0.288771</td>
      <td>-0.062347</td>
      <td>0.377303</td>
      <td>-0.084719</td>
      <td>0.574551</td>
      <td>0.166244</td>
      <td>0.069074</td>
      <td>-0.382149</td>
      <td>-1.020654</td>
      <td>-0.683331</td>
      <td>-0.425868</td>
      <td>-0.783911</td>
      <td>0.254513</td>
      <td>0.707480</td>
      <td>0.323347</td>
      <td>-0.144465</td>
      <td>0.398341</td>
      <td>-0.010536</td>
      <td>-0.064741</td>
      <td>0.113902</td>
      <td>-0.519520</td>
      <td>0.209872</td>
      <td>-0.809332</td>
      <td>0.053456</td>
      <td>-0.301732</td>
      <td>-0.557558</td>
      <td>-0.159907</td>
      <td>-0.323602</td>
      <td>0.090757</td>
      <td>0.488964</td>
      <td>-0.377521</td>
      <td>0.000032</td>
      <td>-1.918489</td>
      <td>-0.946174</td>
      <td>-0.460671</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.245908</td>
      <td>-0.468915</td>
      <td>-0.860090</td>
      <td>-1.154992</td>
      <td>-0.221248</td>
      <td>-0.547488</td>
      <td>-0.355791</td>
      <td>-0.190858</td>
      <td>-0.221259</td>
      <td>-0.421064</td>
      <td>-0.394196</td>
      <td>0.124846</td>
      <td>-0.065742</td>
      <td>-0.118487</td>
      <td>-0.560059</td>
      <td>-1.018410</td>
      <td>0.009578</td>
      <td>0.385012</td>
      <td>-0.913773</td>
      <td>0.120530</td>
      <td>-0.827337</td>
      <td>-1.261819</td>
      <td>-0.225805</td>
      <td>-0.091079</td>
      <td>0.698284</td>
      <td>-0.553550</td>
      <td>0.619587</td>
      <td>-0.513305</td>
      <td>-0.017788</td>
      <td>0.529159</td>
      <td>0.231016</td>
      <td>0.924013</td>
      <td>0.032264</td>
      <td>-0.166482</td>
      <td>-0.496550</td>
      <td>-0.815574</td>
      <td>-0.296938</td>
      <td>-0.407332</td>
      <td>-0.573082</td>
      <td>0.013120</td>
      <td>...</td>
      <td>-0.104679</td>
      <td>0.230893</td>
      <td>-0.164084</td>
      <td>0.073853</td>
      <td>-0.545348</td>
      <td>0.722685</td>
      <td>-0.926121</td>
      <td>-0.839982</td>
      <td>-1.250913</td>
      <td>0.974866</td>
      <td>0.165160</td>
      <td>0.004027</td>
      <td>1.112351</td>
      <td>0.197943</td>
      <td>-1.114844</td>
      <td>-0.085541</td>
      <td>0.241902</td>
      <td>0.603521</td>
      <td>1.572529</td>
      <td>-0.266491</td>
      <td>-0.298135</td>
      <td>0.030209</td>
      <td>0.472686</td>
      <td>-0.571750</td>
      <td>0.836009</td>
      <td>0.207944</td>
      <td>0.608979</td>
      <td>-0.196005</td>
      <td>-0.147882</td>
      <td>-1.371267</td>
      <td>-0.565633</td>
      <td>-0.095867</td>
      <td>-0.030616</td>
      <td>-0.965871</td>
      <td>-0.036747</td>
      <td>-0.980523</td>
      <td>-0.495254</td>
      <td>-1.299203</td>
      <td>-0.158949</td>
      <td>-0.444183</td>
    </tr>
    <tr>
      <th>18</th>
      <td>1.817849</td>
      <td>0.212325</td>
      <td>-0.084340</td>
      <td>-0.912777</td>
      <td>-0.779499</td>
      <td>-0.368396</td>
      <td>-0.115228</td>
      <td>0.127059</td>
      <td>0.315244</td>
      <td>-0.278339</td>
      <td>0.071860</td>
      <td>-0.164008</td>
      <td>-1.237899</td>
      <td>-0.611161</td>
      <td>-0.427234</td>
      <td>0.235680</td>
      <td>-0.454381</td>
      <td>0.106703</td>
      <td>0.300004</td>
      <td>1.534978</td>
      <td>-0.136551</td>
      <td>0.878290</td>
      <td>0.782380</td>
      <td>-0.130154</td>
      <td>0.034219</td>
      <td>-0.223262</td>
      <td>-0.398378</td>
      <td>-0.016707</td>
      <td>0.653752</td>
      <td>0.876825</td>
      <td>0.472775</td>
      <td>-0.118681</td>
      <td>-0.571892</td>
      <td>-1.375658</td>
      <td>0.291215</td>
      <td>0.064886</td>
      <td>0.146362</td>
      <td>-0.841747</td>
      <td>-0.984328</td>
      <td>-0.256669</td>
      <td>...</td>
      <td>-1.426539</td>
      <td>0.487703</td>
      <td>0.940583</td>
      <td>-0.125427</td>
      <td>0.454073</td>
      <td>0.863369</td>
      <td>-0.124820</td>
      <td>-0.648120</td>
      <td>0.403431</td>
      <td>-0.013050</td>
      <td>0.379492</td>
      <td>0.469550</td>
      <td>0.049955</td>
      <td>-0.148359</td>
      <td>-0.123563</td>
      <td>-0.631454</td>
      <td>-1.126971</td>
      <td>-0.558420</td>
      <td>0.111914</td>
      <td>0.148297</td>
      <td>0.569954</td>
      <td>0.218473</td>
      <td>-0.288873</td>
      <td>-0.124954</td>
      <td>0.261888</td>
      <td>-0.085937</td>
      <td>1.103238</td>
      <td>-0.265701</td>
      <td>-0.625992</td>
      <td>-1.013331</td>
      <td>-0.495911</td>
      <td>-0.978834</td>
      <td>-0.783443</td>
      <td>0.374667</td>
      <td>-0.412968</td>
      <td>0.552082</td>
      <td>0.212644</td>
      <td>2.343285</td>
      <td>1.589470</td>
      <td>1.162858</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.118830</td>
      <td>0.302925</td>
      <td>-0.124363</td>
      <td>0.306588</td>
      <td>-1.060086</td>
      <td>0.932951</td>
      <td>0.429219</td>
      <td>-0.296173</td>
      <td>-0.954194</td>
      <td>-0.796202</td>
      <td>-0.135935</td>
      <td>0.479568</td>
      <td>-1.159042</td>
      <td>0.224596</td>
      <td>-0.988727</td>
      <td>-0.184904</td>
      <td>0.794073</td>
      <td>0.748981</td>
      <td>0.500190</td>
      <td>0.909350</td>
      <td>0.219091</td>
      <td>0.717062</td>
      <td>0.574254</td>
      <td>0.472383</td>
      <td>1.046667</td>
      <td>-0.927538</td>
      <td>-0.326154</td>
      <td>-0.350016</td>
      <td>-0.816997</td>
      <td>0.099372</td>
      <td>-0.065211</td>
      <td>-0.496303</td>
      <td>-0.469840</td>
      <td>0.001187</td>
      <td>-0.541444</td>
      <td>0.537973</td>
      <td>0.917729</td>
      <td>0.279224</td>
      <td>0.150307</td>
      <td>-0.279780</td>
      <td>...</td>
      <td>0.469548</td>
      <td>0.971845</td>
      <td>0.320079</td>
      <td>0.262925</td>
      <td>0.270552</td>
      <td>0.729869</td>
      <td>0.366651</td>
      <td>-0.060058</td>
      <td>-0.284997</td>
      <td>0.586740</td>
      <td>-0.592006</td>
      <td>0.031798</td>
      <td>-0.241086</td>
      <td>-0.600336</td>
      <td>-0.493937</td>
      <td>-0.293219</td>
      <td>-0.832274</td>
      <td>-0.863971</td>
      <td>-1.570670</td>
      <td>-0.615514</td>
      <td>-0.260544</td>
      <td>-0.584622</td>
      <td>-1.026253</td>
      <td>-0.196553</td>
      <td>-1.171829</td>
      <td>0.646842</td>
      <td>0.413620</td>
      <td>-0.297411</td>
      <td>-0.653471</td>
      <td>-0.867515</td>
      <td>-0.530007</td>
      <td>-0.585436</td>
      <td>-0.831834</td>
      <td>-0.061703</td>
      <td>0.496314</td>
      <td>0.148972</td>
      <td>0.247428</td>
      <td>-0.199043</td>
      <td>0.397468</td>
      <td>-0.052582</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-1.338593</td>
      <td>-0.568313</td>
      <td>-0.356553</td>
      <td>0.640839</td>
      <td>0.585086</td>
      <td>-0.611738</td>
      <td>1.008705</td>
      <td>0.193490</td>
      <td>0.143309</td>
      <td>-0.721777</td>
      <td>-0.459408</td>
      <td>-0.389323</td>
      <td>0.361923</td>
      <td>-0.115629</td>
      <td>-0.055657</td>
      <td>-0.929879</td>
      <td>0.132530</td>
      <td>0.218729</td>
      <td>-0.541810</td>
      <td>-0.666680</td>
      <td>-0.468973</td>
      <td>0.615897</td>
      <td>-0.119881</td>
      <td>-0.215890</td>
      <td>0.939208</td>
      <td>-0.846298</td>
      <td>1.109579</td>
      <td>-0.284265</td>
      <td>1.028904</td>
      <td>-0.827964</td>
      <td>-0.546779</td>
      <td>-0.400332</td>
      <td>-1.391484</td>
      <td>-0.464140</td>
      <td>0.298817</td>
      <td>0.036930</td>
      <td>-0.370818</td>
      <td>0.551724</td>
      <td>-0.151591</td>
      <td>-0.043233</td>
      <td>...</td>
      <td>0.270475</td>
      <td>0.293282</td>
      <td>-0.115294</td>
      <td>0.778060</td>
      <td>-0.535558</td>
      <td>0.775329</td>
      <td>-0.162664</td>
      <td>-1.337243</td>
      <td>-1.207092</td>
      <td>0.138201</td>
      <td>-0.284163</td>
      <td>-0.013656</td>
      <td>0.075000</td>
      <td>-0.591682</td>
      <td>-0.663782</td>
      <td>0.070824</td>
      <td>-0.426111</td>
      <td>-0.206552</td>
      <td>-0.277349</td>
      <td>-0.522539</td>
      <td>-0.038189</td>
      <td>0.161792</td>
      <td>-0.770737</td>
      <td>-0.285025</td>
      <td>-0.783501</td>
      <td>-0.544936</td>
      <td>-0.480276</td>
      <td>-1.056080</td>
      <td>0.705315</td>
      <td>-0.810601</td>
      <td>0.215910</td>
      <td>-0.397401</td>
      <td>0.340016</td>
      <td>0.490595</td>
      <td>-0.917283</td>
      <td>-0.955745</td>
      <td>0.281643</td>
      <td>-2.166511</td>
      <td>-1.223709</td>
      <td>-0.496530</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.058718</td>
      <td>-0.273222</td>
      <td>0.316781</td>
      <td>-0.116348</td>
      <td>-0.897386</td>
      <td>-0.030044</td>
      <td>-0.384627</td>
      <td>-0.915815</td>
      <td>-0.050633</td>
      <td>-0.015053</td>
      <td>-0.252383</td>
      <td>0.468008</td>
      <td>0.916561</td>
      <td>0.066447</td>
      <td>0.115715</td>
      <td>0.755502</td>
      <td>0.748720</td>
      <td>0.231128</td>
      <td>0.895263</td>
      <td>1.186102</td>
      <td>0.381511</td>
      <td>0.422259</td>
      <td>0.507647</td>
      <td>-0.675673</td>
      <td>-0.038704</td>
      <td>0.000505</td>
      <td>1.210312</td>
      <td>-0.346210</td>
      <td>-0.424201</td>
      <td>0.114700</td>
      <td>-0.521050</td>
      <td>0.294312</td>
      <td>0.016686</td>
      <td>0.093682</td>
      <td>-0.960590</td>
      <td>-0.954471</td>
      <td>-1.248285</td>
      <td>-0.373720</td>
      <td>-0.304096</td>
      <td>-0.535042</td>
      <td>...</td>
      <td>0.437738</td>
      <td>0.793241</td>
      <td>0.729633</td>
      <td>0.548160</td>
      <td>0.140260</td>
      <td>0.335018</td>
      <td>0.552705</td>
      <td>-0.053969</td>
      <td>-0.705120</td>
      <td>0.684554</td>
      <td>-0.477537</td>
      <td>-0.240989</td>
      <td>0.063139</td>
      <td>0.059957</td>
      <td>0.373251</td>
      <td>0.301049</td>
      <td>-1.385430</td>
      <td>-0.470243</td>
      <td>-0.307323</td>
      <td>-0.115269</td>
      <td>0.536754</td>
      <td>-0.211352</td>
      <td>-1.000990</td>
      <td>-0.097486</td>
      <td>-0.590107</td>
      <td>-0.510485</td>
      <td>0.996488</td>
      <td>-0.149378</td>
      <td>-0.593427</td>
      <td>-0.237934</td>
      <td>-0.616178</td>
      <td>-0.638908</td>
      <td>-0.158501</td>
      <td>-0.016459</td>
      <td>-0.132175</td>
      <td>0.000873</td>
      <td>0.000067</td>
      <td>-0.765505</td>
      <td>0.162334</td>
      <td>-0.124603</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.082396</td>
      <td>1.080604</td>
      <td>0.069130</td>
      <td>-0.544548</td>
      <td>-0.568685</td>
      <td>0.616251</td>
      <td>-0.531274</td>
      <td>-0.120106</td>
      <td>0.813801</td>
      <td>-0.217958</td>
      <td>-0.298139</td>
      <td>0.004895</td>
      <td>-0.870642</td>
      <td>-0.135465</td>
      <td>-0.479079</td>
      <td>-0.157069</td>
      <td>0.345752</td>
      <td>0.105801</td>
      <td>-0.416214</td>
      <td>0.971621</td>
      <td>0.117609</td>
      <td>0.489887</td>
      <td>-0.098024</td>
      <td>-0.041444</td>
      <td>0.840000</td>
      <td>-0.434382</td>
      <td>0.421794</td>
      <td>0.261189</td>
      <td>-0.179255</td>
      <td>-1.335781</td>
      <td>-1.132965</td>
      <td>-0.269994</td>
      <td>-0.699350</td>
      <td>-0.268551</td>
      <td>1.036391</td>
      <td>0.594447</td>
      <td>-0.493386</td>
      <td>-0.872132</td>
      <td>-0.641700</td>
      <td>0.028857</td>
      <td>...</td>
      <td>-1.264648</td>
      <td>0.029281</td>
      <td>0.687609</td>
      <td>-0.378459</td>
      <td>-1.247017</td>
      <td>-0.412750</td>
      <td>-0.301790</td>
      <td>-1.628135</td>
      <td>0.168110</td>
      <td>-0.024735</td>
      <td>-1.075865</td>
      <td>-0.204419</td>
      <td>-0.054860</td>
      <td>0.528996</td>
      <td>0.746227</td>
      <td>0.524756</td>
      <td>0.023052</td>
      <td>-0.094041</td>
      <td>0.310961</td>
      <td>-0.362394</td>
      <td>-0.052262</td>
      <td>0.133306</td>
      <td>-0.637709</td>
      <td>0.189957</td>
      <td>0.436393</td>
      <td>0.609966</td>
      <td>-0.167966</td>
      <td>-0.410018</td>
      <td>-0.235593</td>
      <td>-0.269326</td>
      <td>-0.310836</td>
      <td>0.003995</td>
      <td>-0.331373</td>
      <td>-0.086366</td>
      <td>-0.606847</td>
      <td>-0.959715</td>
      <td>-0.995407</td>
      <td>-0.334398</td>
      <td>0.612866</td>
      <td>0.728864</td>
    </tr>
    <tr>
      <th>23</th>
      <td>1.049865</td>
      <td>0.682938</td>
      <td>0.852841</td>
      <td>0.224061</td>
      <td>0.831932</td>
      <td>0.649897</td>
      <td>-0.290847</td>
      <td>-0.191324</td>
      <td>-0.165021</td>
      <td>-1.122876</td>
      <td>-0.456248</td>
      <td>-0.964642</td>
      <td>-0.292276</td>
      <td>-0.634629</td>
      <td>-0.925748</td>
      <td>-0.005907</td>
      <td>-0.104887</td>
      <td>0.942249</td>
      <td>-0.541713</td>
      <td>-0.406694</td>
      <td>-0.550824</td>
      <td>0.129684</td>
      <td>1.055616</td>
      <td>0.895833</td>
      <td>1.687575</td>
      <td>0.781180</td>
      <td>1.941796</td>
      <td>-0.459059</td>
      <td>0.580172</td>
      <td>-0.122154</td>
      <td>-0.160384</td>
      <td>-0.248994</td>
      <td>-0.275634</td>
      <td>-0.283498</td>
      <td>-0.344822</td>
      <td>0.127699</td>
      <td>-0.873140</td>
      <td>-0.773836</td>
      <td>-0.152498</td>
      <td>-0.205731</td>
      <td>...</td>
      <td>-0.079686</td>
      <td>0.128476</td>
      <td>0.670881</td>
      <td>-0.402879</td>
      <td>0.153995</td>
      <td>-0.057642</td>
      <td>-0.468097</td>
      <td>-0.206536</td>
      <td>0.649495</td>
      <td>-0.031179</td>
      <td>-0.709603</td>
      <td>0.147966</td>
      <td>0.794793</td>
      <td>0.595957</td>
      <td>0.480021</td>
      <td>0.445357</td>
      <td>0.016577</td>
      <td>0.248466</td>
      <td>-0.633771</td>
      <td>0.158045</td>
      <td>-0.923553</td>
      <td>0.329963</td>
      <td>0.875132</td>
      <td>0.425642</td>
      <td>-0.133260</td>
      <td>-0.474021</td>
      <td>-0.091749</td>
      <td>1.219412</td>
      <td>0.266965</td>
      <td>-0.422486</td>
      <td>0.424814</td>
      <td>0.056376</td>
      <td>-0.468609</td>
      <td>-0.943810</td>
      <td>0.394009</td>
      <td>0.247125</td>
      <td>0.335685</td>
      <td>2.381560</td>
      <td>1.092288</td>
      <td>0.914291</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-0.016759</td>
      <td>0.133994</td>
      <td>-0.174077</td>
      <td>-0.152707</td>
      <td>-0.719865</td>
      <td>-1.264526</td>
      <td>-0.560590</td>
      <td>-0.145447</td>
      <td>-0.448287</td>
      <td>-0.248540</td>
      <td>-0.261638</td>
      <td>0.160181</td>
      <td>0.524883</td>
      <td>0.446548</td>
      <td>0.282625</td>
      <td>0.036928</td>
      <td>-0.265012</td>
      <td>-0.037112</td>
      <td>-0.669244</td>
      <td>0.797594</td>
      <td>-0.411358</td>
      <td>-0.231214</td>
      <td>0.267668</td>
      <td>-1.087399</td>
      <td>0.493644</td>
      <td>-0.016383</td>
      <td>0.794756</td>
      <td>0.115965</td>
      <td>-0.081725</td>
      <td>-0.100589</td>
      <td>-0.387940</td>
      <td>0.233883</td>
      <td>0.241639</td>
      <td>-1.694781</td>
      <td>0.330670</td>
      <td>0.469641</td>
      <td>0.026771</td>
      <td>0.232757</td>
      <td>-0.433235</td>
      <td>-0.462465</td>
      <td>...</td>
      <td>-0.253809</td>
      <td>0.063633</td>
      <td>0.054353</td>
      <td>-0.002318</td>
      <td>-1.491796</td>
      <td>0.196691</td>
      <td>0.351974</td>
      <td>0.177979</td>
      <td>-0.414535</td>
      <td>1.142948</td>
      <td>0.306229</td>
      <td>-0.472036</td>
      <td>-0.158939</td>
      <td>0.751358</td>
      <td>0.178753</td>
      <td>1.062226</td>
      <td>-0.342428</td>
      <td>0.067558</td>
      <td>-0.864052</td>
      <td>-0.636479</td>
      <td>-1.315494</td>
      <td>-0.590629</td>
      <td>-0.235515</td>
      <td>-0.425053</td>
      <td>-0.225039</td>
      <td>-0.005914</td>
      <td>-0.010677</td>
      <td>-0.625112</td>
      <td>-0.376277</td>
      <td>-1.335532</td>
      <td>-0.503523</td>
      <td>0.004367</td>
      <td>0.139768</td>
      <td>-0.415828</td>
      <td>0.538506</td>
      <td>0.076081</td>
      <td>0.484376</td>
      <td>0.484043</td>
      <td>-0.223645</td>
      <td>-0.429511</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.960999</td>
      <td>1.354020</td>
      <td>0.388432</td>
      <td>0.073715</td>
      <td>0.055124</td>
      <td>0.329392</td>
      <td>0.825925</td>
      <td>0.526500</td>
      <td>-0.669112</td>
      <td>0.032066</td>
      <td>-0.232810</td>
      <td>0.463312</td>
      <td>0.130763</td>
      <td>0.359585</td>
      <td>0.343744</td>
      <td>0.078693</td>
      <td>0.221348</td>
      <td>-0.408565</td>
      <td>0.566514</td>
      <td>-0.349452</td>
      <td>0.193194</td>
      <td>-0.053259</td>
      <td>0.908925</td>
      <td>0.699879</td>
      <td>0.004354</td>
      <td>-1.698453</td>
      <td>-0.899636</td>
      <td>-0.719890</td>
      <td>-0.377429</td>
      <td>-0.113570</td>
      <td>-0.021393</td>
      <td>-0.312284</td>
      <td>-0.049141</td>
      <td>0.004972</td>
      <td>0.329945</td>
      <td>-0.319828</td>
      <td>0.098974</td>
      <td>-0.604958</td>
      <td>0.547704</td>
      <td>0.445932</td>
      <td>...</td>
      <td>0.444112</td>
      <td>1.144768</td>
      <td>0.582541</td>
      <td>-0.215693</td>
      <td>0.218497</td>
      <td>0.854937</td>
      <td>-0.428748</td>
      <td>-0.520637</td>
      <td>0.830409</td>
      <td>-0.462210</td>
      <td>-0.947920</td>
      <td>-1.117176</td>
      <td>-0.554879</td>
      <td>-0.691944</td>
      <td>0.588371</td>
      <td>-0.141200</td>
      <td>0.969599</td>
      <td>0.713203</td>
      <td>0.336563</td>
      <td>0.131475</td>
      <td>0.024302</td>
      <td>0.328319</td>
      <td>0.560237</td>
      <td>0.924780</td>
      <td>0.389073</td>
      <td>-0.157519</td>
      <td>-0.230661</td>
      <td>0.283537</td>
      <td>-0.200017</td>
      <td>0.402978</td>
      <td>0.898468</td>
      <td>0.457140</td>
      <td>0.006468</td>
      <td>-0.114421</td>
      <td>-0.483783</td>
      <td>0.620214</td>
      <td>-0.129731</td>
      <td>0.312024</td>
      <td>0.907623</td>
      <td>0.203906</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.546903</td>
      <td>-0.493339</td>
      <td>0.514999</td>
      <td>0.254725</td>
      <td>-0.046380</td>
      <td>0.284582</td>
      <td>1.755948</td>
      <td>1.066171</td>
      <td>-0.242756</td>
      <td>-0.253814</td>
      <td>-0.782487</td>
      <td>-0.902006</td>
      <td>0.302773</td>
      <td>0.543576</td>
      <td>-0.056067</td>
      <td>0.397349</td>
      <td>0.599208</td>
      <td>-0.270470</td>
      <td>-0.094942</td>
      <td>-0.733206</td>
      <td>-1.115202</td>
      <td>1.186050</td>
      <td>0.433055</td>
      <td>0.230958</td>
      <td>-0.898431</td>
      <td>-0.079818</td>
      <td>-0.260683</td>
      <td>-0.771387</td>
      <td>-1.075437</td>
      <td>-1.368148</td>
      <td>0.001498</td>
      <td>-0.830503</td>
      <td>0.374338</td>
      <td>-0.423645</td>
      <td>-0.869723</td>
      <td>-0.494681</td>
      <td>-0.231033</td>
      <td>-0.659017</td>
      <td>-0.358744</td>
      <td>-0.543606</td>
      <td>...</td>
      <td>0.812243</td>
      <td>-0.235025</td>
      <td>-0.252222</td>
      <td>0.605323</td>
      <td>0.679256</td>
      <td>0.366080</td>
      <td>-0.777460</td>
      <td>-0.460784</td>
      <td>0.403862</td>
      <td>-1.018178</td>
      <td>-0.080416</td>
      <td>-0.566459</td>
      <td>-0.067709</td>
      <td>0.169135</td>
      <td>0.664202</td>
      <td>-0.519261</td>
      <td>0.280266</td>
      <td>0.810943</td>
      <td>-0.053031</td>
      <td>-0.627014</td>
      <td>-0.353211</td>
      <td>0.254675</td>
      <td>-0.144529</td>
      <td>-0.771780</td>
      <td>-0.210721</td>
      <td>0.366816</td>
      <td>0.032209</td>
      <td>0.486348</td>
      <td>0.522647</td>
      <td>0.196498</td>
      <td>-0.567070</td>
      <td>-0.380929</td>
      <td>-1.688178</td>
      <td>-0.678987</td>
      <td>-0.250964</td>
      <td>-1.715084</td>
      <td>0.133040</td>
      <td>-2.657825</td>
      <td>-2.185873</td>
      <td>-0.748369</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.332688</td>
      <td>0.809422</td>
      <td>-0.008767</td>
      <td>0.451413</td>
      <td>-0.959915</td>
      <td>-0.323640</td>
      <td>1.030362</td>
      <td>0.654726</td>
      <td>0.913620</td>
      <td>0.364138</td>
      <td>0.548270</td>
      <td>0.184100</td>
      <td>-0.109912</td>
      <td>0.502883</td>
      <td>-0.889085</td>
      <td>-0.280576</td>
      <td>-0.395824</td>
      <td>-1.473049</td>
      <td>-0.130451</td>
      <td>0.437984</td>
      <td>-0.506335</td>
      <td>0.224071</td>
      <td>0.273209</td>
      <td>-0.314631</td>
      <td>-1.042764</td>
      <td>-0.239086</td>
      <td>0.747623</td>
      <td>0.641297</td>
      <td>0.617321</td>
      <td>-0.484184</td>
      <td>0.554354</td>
      <td>0.746124</td>
      <td>0.814216</td>
      <td>0.134767</td>
      <td>-0.347743</td>
      <td>-0.377218</td>
      <td>0.698702</td>
      <td>-0.529483</td>
      <td>-0.104427</td>
      <td>0.347403</td>
      <td>...</td>
      <td>0.009802</td>
      <td>0.146766</td>
      <td>-0.412867</td>
      <td>-0.658118</td>
      <td>0.849318</td>
      <td>0.305715</td>
      <td>0.308012</td>
      <td>0.533531</td>
      <td>2.036675</td>
      <td>-0.254100</td>
      <td>-0.245572</td>
      <td>-0.307157</td>
      <td>-0.830219</td>
      <td>0.360557</td>
      <td>-0.543455</td>
      <td>0.273039</td>
      <td>0.511755</td>
      <td>0.883924</td>
      <td>0.867780</td>
      <td>0.309462</td>
      <td>0.710743</td>
      <td>0.077581</td>
      <td>-0.358142</td>
      <td>-0.306429</td>
      <td>0.178602</td>
      <td>0.341492</td>
      <td>-0.177504</td>
      <td>-0.481969</td>
      <td>-0.803061</td>
      <td>0.357763</td>
      <td>1.013050</td>
      <td>-0.307222</td>
      <td>0.264045</td>
      <td>0.081234</td>
      <td>0.316921</td>
      <td>-1.143544</td>
      <td>-0.946532</td>
      <td>0.270585</td>
      <td>0.571538</td>
      <td>1.169665</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.340815</td>
      <td>-0.797420</td>
      <td>-0.834005</td>
      <td>0.263935</td>
      <td>-0.225235</td>
      <td>-0.607060</td>
      <td>0.508490</td>
      <td>0.248454</td>
      <td>0.606098</td>
      <td>0.180669</td>
      <td>0.395121</td>
      <td>-0.396237</td>
      <td>-0.322805</td>
      <td>-0.627914</td>
      <td>0.488546</td>
      <td>-0.159903</td>
      <td>0.040692</td>
      <td>-0.063551</td>
      <td>0.836739</td>
      <td>1.029436</td>
      <td>-0.522446</td>
      <td>0.801167</td>
      <td>-0.994259</td>
      <td>-0.089590</td>
      <td>0.162477</td>
      <td>-0.184438</td>
      <td>-0.400577</td>
      <td>0.896566</td>
      <td>-1.088480</td>
      <td>-0.366506</td>
      <td>-0.235562</td>
      <td>1.272838</td>
      <td>0.514824</td>
      <td>-0.761921</td>
      <td>0.768754</td>
      <td>0.789514</td>
      <td>-0.529514</td>
      <td>-0.333042</td>
      <td>0.798018</td>
      <td>0.859389</td>
      <td>...</td>
      <td>-1.291499</td>
      <td>0.340137</td>
      <td>0.791745</td>
      <td>-0.277696</td>
      <td>0.016944</td>
      <td>-0.199046</td>
      <td>-1.088955</td>
      <td>-0.309805</td>
      <td>0.509874</td>
      <td>-0.601270</td>
      <td>0.331656</td>
      <td>-0.419458</td>
      <td>-0.400471</td>
      <td>-0.375371</td>
      <td>0.567884</td>
      <td>-0.312065</td>
      <td>-1.006224</td>
      <td>0.152116</td>
      <td>-0.012281</td>
      <td>-0.305191</td>
      <td>-1.349122</td>
      <td>0.354035</td>
      <td>0.506623</td>
      <td>0.097347</td>
      <td>-0.112509</td>
      <td>-0.101495</td>
      <td>-0.177908</td>
      <td>-0.325369</td>
      <td>-1.324427</td>
      <td>0.918119</td>
      <td>0.307833</td>
      <td>-0.086223</td>
      <td>-0.268941</td>
      <td>0.516281</td>
      <td>-1.000787</td>
      <td>-0.817835</td>
      <td>-0.864742</td>
      <td>-2.455628</td>
      <td>-0.248193</td>
      <td>0.597375</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.571132</td>
      <td>0.036375</td>
      <td>0.219923</td>
      <td>0.370613</td>
      <td>-0.670055</td>
      <td>-0.437003</td>
      <td>0.301434</td>
      <td>-0.005233</td>
      <td>1.020861</td>
      <td>-1.100850</td>
      <td>-0.185043</td>
      <td>0.159005</td>
      <td>1.157316</td>
      <td>-0.063831</td>
      <td>-0.634784</td>
      <td>0.504650</td>
      <td>-0.440670</td>
      <td>-0.990800</td>
      <td>0.288978</td>
      <td>0.430288</td>
      <td>0.580943</td>
      <td>-0.028869</td>
      <td>-0.359194</td>
      <td>1.047033</td>
      <td>0.155700</td>
      <td>-0.408712</td>
      <td>0.191852</td>
      <td>-0.509992</td>
      <td>0.280049</td>
      <td>0.012287</td>
      <td>0.936206</td>
      <td>-0.387088</td>
      <td>1.242819</td>
      <td>-0.035687</td>
      <td>-0.538552</td>
      <td>-0.667625</td>
      <td>0.061103</td>
      <td>0.455486</td>
      <td>-0.165705</td>
      <td>0.309460</td>
      <td>...</td>
      <td>-0.008663</td>
      <td>0.672463</td>
      <td>0.211638</td>
      <td>0.690397</td>
      <td>0.610774</td>
      <td>0.271485</td>
      <td>-0.216676</td>
      <td>-0.589690</td>
      <td>-0.106329</td>
      <td>-0.567308</td>
      <td>-1.012792</td>
      <td>-0.333279</td>
      <td>-0.860592</td>
      <td>0.459934</td>
      <td>0.456315</td>
      <td>0.744207</td>
      <td>0.663486</td>
      <td>1.286647</td>
      <td>0.152017</td>
      <td>0.339846</td>
      <td>-1.357365</td>
      <td>-0.110189</td>
      <td>-0.926349</td>
      <td>-0.499769</td>
      <td>0.436667</td>
      <td>0.310653</td>
      <td>-0.372724</td>
      <td>-0.184717</td>
      <td>-0.496565</td>
      <td>-0.248683</td>
      <td>0.385124</td>
      <td>-0.399565</td>
      <td>0.338468</td>
      <td>-0.861367</td>
      <td>0.156005</td>
      <td>-0.427444</td>
      <td>-0.017405</td>
      <td>-0.400132</td>
      <td>0.119409</td>
      <td>0.758821</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f071825f670&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  0.994137  0.046304  21.469693  2.989884e-102  0.903383  1.084892
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.859 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.4.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>