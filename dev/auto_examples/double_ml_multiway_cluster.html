
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-1.066168</td>
      <td>0.348477</td>
      <td>-0.187081</td>
      <td>-0.282947</td>
      <td>1.071765</td>
      <td>0.058070</td>
      <td>0.121484</td>
      <td>0.432894</td>
      <td>-0.123573</td>
      <td>-0.732249</td>
      <td>0.440486</td>
      <td>1.542070</td>
      <td>1.626561</td>
      <td>0.136068</td>
      <td>-0.127699</td>
      <td>0.170566</td>
      <td>-0.337977</td>
      <td>-0.917603</td>
      <td>-0.330991</td>
      <td>-0.119266</td>
      <td>0.109725</td>
      <td>0.100711</td>
      <td>0.868050</td>
      <td>0.542856</td>
      <td>0.301082</td>
      <td>-0.158232</td>
      <td>-0.150285</td>
      <td>0.116207</td>
      <td>0.658077</td>
      <td>0.402823</td>
      <td>0.628364</td>
      <td>-0.009952</td>
      <td>-1.083413</td>
      <td>-0.337047</td>
      <td>-0.107390</td>
      <td>-0.856951</td>
      <td>-0.369439</td>
      <td>0.383113</td>
      <td>0.478525</td>
      <td>-0.782024</td>
      <td>...</td>
      <td>-0.755853</td>
      <td>-0.567246</td>
      <td>-0.113009</td>
      <td>-0.415363</td>
      <td>0.029435</td>
      <td>0.487780</td>
      <td>0.465291</td>
      <td>0.720421</td>
      <td>-0.991244</td>
      <td>-0.272025</td>
      <td>-0.791636</td>
      <td>-0.007180</td>
      <td>1.175037</td>
      <td>0.384470</td>
      <td>-0.323293</td>
      <td>0.391031</td>
      <td>-0.704361</td>
      <td>1.456630</td>
      <td>0.408400</td>
      <td>0.889605</td>
      <td>-0.467813</td>
      <td>0.330145</td>
      <td>0.359296</td>
      <td>0.138564</td>
      <td>-0.594516</td>
      <td>0.269989</td>
      <td>0.179551</td>
      <td>0.588196</td>
      <td>-0.100960</td>
      <td>0.784704</td>
      <td>-0.214482</td>
      <td>0.781506</td>
      <td>0.382189</td>
      <td>0.151909</td>
      <td>0.355946</td>
      <td>0.444456</td>
      <td>-0.116540</td>
      <td>-0.096161</td>
      <td>-0.075756</td>
      <td>0.787619</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.230569</td>
      <td>0.482791</td>
      <td>0.156746</td>
      <td>0.781014</td>
      <td>-0.308516</td>
      <td>0.248675</td>
      <td>0.240415</td>
      <td>0.932694</td>
      <td>-0.153655</td>
      <td>-0.559394</td>
      <td>-0.441823</td>
      <td>0.789521</td>
      <td>0.198152</td>
      <td>0.033307</td>
      <td>0.530880</td>
      <td>0.247243</td>
      <td>-0.464150</td>
      <td>-0.783237</td>
      <td>-1.005858</td>
      <td>0.262045</td>
      <td>-0.385132</td>
      <td>-0.346884</td>
      <td>-0.327892</td>
      <td>0.802244</td>
      <td>-0.009787</td>
      <td>-0.390711</td>
      <td>0.727493</td>
      <td>0.521273</td>
      <td>0.451841</td>
      <td>0.610907</td>
      <td>0.990276</td>
      <td>0.865577</td>
      <td>1.106847</td>
      <td>-0.510560</td>
      <td>-0.340096</td>
      <td>-1.004640</td>
      <td>-0.204498</td>
      <td>0.224144</td>
      <td>0.283375</td>
      <td>-0.381073</td>
      <td>...</td>
      <td>0.034060</td>
      <td>0.595908</td>
      <td>-0.171084</td>
      <td>0.111842</td>
      <td>0.190344</td>
      <td>0.709994</td>
      <td>0.017464</td>
      <td>0.096842</td>
      <td>-0.689461</td>
      <td>0.452738</td>
      <td>-0.859054</td>
      <td>-0.964862</td>
      <td>1.390600</td>
      <td>-0.357880</td>
      <td>0.176046</td>
      <td>-0.509518</td>
      <td>0.325779</td>
      <td>-0.431535</td>
      <td>-0.076547</td>
      <td>0.035454</td>
      <td>-0.030529</td>
      <td>-0.654259</td>
      <td>0.387104</td>
      <td>1.368891</td>
      <td>0.189798</td>
      <td>-0.458750</td>
      <td>0.338583</td>
      <td>0.249638</td>
      <td>0.129120</td>
      <td>-0.759690</td>
      <td>0.054110</td>
      <td>0.558368</td>
      <td>0.179425</td>
      <td>-0.684106</td>
      <td>0.533337</td>
      <td>-0.334657</td>
      <td>-0.867961</td>
      <td>0.773120</td>
      <td>1.031970</td>
      <td>0.550608</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.747334</td>
      <td>-0.519748</td>
      <td>-0.436601</td>
      <td>-0.040643</td>
      <td>0.574608</td>
      <td>0.721901</td>
      <td>0.145522</td>
      <td>0.002063</td>
      <td>-0.748565</td>
      <td>-0.209556</td>
      <td>-0.966655</td>
      <td>0.407586</td>
      <td>0.136933</td>
      <td>0.680421</td>
      <td>-0.560126</td>
      <td>-0.603100</td>
      <td>-0.066782</td>
      <td>-0.364512</td>
      <td>0.586441</td>
      <td>-0.183567</td>
      <td>-0.133200</td>
      <td>0.673974</td>
      <td>0.029615</td>
      <td>0.768287</td>
      <td>-0.033454</td>
      <td>-0.990437</td>
      <td>-0.400981</td>
      <td>0.181040</td>
      <td>0.258861</td>
      <td>-0.262035</td>
      <td>-0.022363</td>
      <td>-0.189899</td>
      <td>0.072767</td>
      <td>-0.949283</td>
      <td>-0.644577</td>
      <td>-0.592058</td>
      <td>0.278024</td>
      <td>0.704125</td>
      <td>0.221799</td>
      <td>0.686370</td>
      <td>...</td>
      <td>0.486397</td>
      <td>-0.286863</td>
      <td>0.062840</td>
      <td>0.616174</td>
      <td>0.600930</td>
      <td>-0.301017</td>
      <td>-0.456161</td>
      <td>0.168534</td>
      <td>-1.105114</td>
      <td>-0.303102</td>
      <td>-0.804946</td>
      <td>0.131650</td>
      <td>0.860222</td>
      <td>1.158754</td>
      <td>0.065826</td>
      <td>-0.225450</td>
      <td>0.252352</td>
      <td>0.228709</td>
      <td>-0.494419</td>
      <td>0.503954</td>
      <td>-0.715733</td>
      <td>-0.138322</td>
      <td>-1.089403</td>
      <td>-0.245367</td>
      <td>-0.553026</td>
      <td>-0.427346</td>
      <td>-1.172334</td>
      <td>0.090819</td>
      <td>-0.864908</td>
      <td>0.146512</td>
      <td>-0.998129</td>
      <td>-0.252045</td>
      <td>0.657438</td>
      <td>0.393330</td>
      <td>-0.080735</td>
      <td>0.015523</td>
      <td>0.347489</td>
      <td>2.248611</td>
      <td>1.424870</td>
      <td>0.233487</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.232915</td>
      <td>-0.825762</td>
      <td>0.166583</td>
      <td>-0.183197</td>
      <td>0.404362</td>
      <td>0.798539</td>
      <td>-0.231892</td>
      <td>0.280960</td>
      <td>-0.191503</td>
      <td>-0.385407</td>
      <td>0.354457</td>
      <td>0.403597</td>
      <td>1.365187</td>
      <td>-0.623559</td>
      <td>0.130586</td>
      <td>0.554898</td>
      <td>0.486388</td>
      <td>0.691916</td>
      <td>0.355103</td>
      <td>-0.078103</td>
      <td>-0.017715</td>
      <td>-0.813037</td>
      <td>0.208266</td>
      <td>-0.181491</td>
      <td>0.699799</td>
      <td>0.326875</td>
      <td>1.302007</td>
      <td>0.508353</td>
      <td>-0.323291</td>
      <td>-0.722548</td>
      <td>-0.112124</td>
      <td>-1.068950</td>
      <td>-0.275859</td>
      <td>-1.201153</td>
      <td>-0.290506</td>
      <td>-0.063878</td>
      <td>1.319573</td>
      <td>-0.496881</td>
      <td>-0.088643</td>
      <td>-0.283480</td>
      <td>...</td>
      <td>-0.205352</td>
      <td>0.005266</td>
      <td>-0.513148</td>
      <td>0.573638</td>
      <td>-0.478843</td>
      <td>0.554586</td>
      <td>-0.262120</td>
      <td>0.583345</td>
      <td>-0.534137</td>
      <td>0.214915</td>
      <td>-0.315699</td>
      <td>-0.881279</td>
      <td>0.416224</td>
      <td>0.514366</td>
      <td>0.237101</td>
      <td>-0.375170</td>
      <td>-0.599596</td>
      <td>-1.355397</td>
      <td>-0.563588</td>
      <td>0.482006</td>
      <td>-0.473790</td>
      <td>0.398724</td>
      <td>-0.922640</td>
      <td>0.010042</td>
      <td>-0.060629</td>
      <td>-0.190709</td>
      <td>0.212594</td>
      <td>0.691467</td>
      <td>-0.445393</td>
      <td>-1.390155</td>
      <td>-0.240945</td>
      <td>-0.484377</td>
      <td>0.607117</td>
      <td>-0.201975</td>
      <td>-0.525757</td>
      <td>-0.823571</td>
      <td>0.752494</td>
      <td>0.346931</td>
      <td>0.043466</td>
      <td>0.274309</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.525916</td>
      <td>-0.466265</td>
      <td>-0.355662</td>
      <td>-0.147465</td>
      <td>0.343201</td>
      <td>0.245479</td>
      <td>-0.063179</td>
      <td>0.269395</td>
      <td>-0.214958</td>
      <td>-0.572809</td>
      <td>0.178335</td>
      <td>0.508413</td>
      <td>0.182412</td>
      <td>-0.672915</td>
      <td>0.764523</td>
      <td>-0.533080</td>
      <td>-0.223746</td>
      <td>0.316468</td>
      <td>0.257724</td>
      <td>1.069228</td>
      <td>-0.654434</td>
      <td>-0.049639</td>
      <td>0.745089</td>
      <td>0.220036</td>
      <td>0.266127</td>
      <td>-0.242572</td>
      <td>-0.410101</td>
      <td>0.385027</td>
      <td>0.017587</td>
      <td>-0.328671</td>
      <td>0.917750</td>
      <td>0.633768</td>
      <td>-0.239595</td>
      <td>0.173571</td>
      <td>-0.747049</td>
      <td>-1.174828</td>
      <td>0.415774</td>
      <td>0.636750</td>
      <td>0.135136</td>
      <td>-0.221409</td>
      <td>...</td>
      <td>0.408151</td>
      <td>0.280141</td>
      <td>-0.838192</td>
      <td>-0.335342</td>
      <td>0.199431</td>
      <td>-0.029239</td>
      <td>-0.107871</td>
      <td>-0.286332</td>
      <td>-0.875294</td>
      <td>0.893032</td>
      <td>-0.200520</td>
      <td>0.824916</td>
      <td>1.188585</td>
      <td>-0.020885</td>
      <td>-0.221208</td>
      <td>-0.547711</td>
      <td>0.293495</td>
      <td>-0.144314</td>
      <td>0.739991</td>
      <td>0.323552</td>
      <td>-0.023644</td>
      <td>1.215677</td>
      <td>0.999001</td>
      <td>0.291460</td>
      <td>-0.045951</td>
      <td>-0.613165</td>
      <td>-1.163080</td>
      <td>-0.598643</td>
      <td>1.073791</td>
      <td>0.850109</td>
      <td>0.576068</td>
      <td>0.832968</td>
      <td>0.024828</td>
      <td>-0.695822</td>
      <td>-0.333587</td>
      <td>0.088406</td>
      <td>-0.144039</td>
      <td>0.631566</td>
      <td>-0.109758</td>
      <td>-0.234692</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.034646</td>
      <td>-0.501628</td>
      <td>-0.459327</td>
      <td>-0.701634</td>
      <td>0.135654</td>
      <td>1.067193</td>
      <td>0.216032</td>
      <td>-0.166529</td>
      <td>-0.978301</td>
      <td>-1.275651</td>
      <td>-0.852437</td>
      <td>-0.799134</td>
      <td>0.538692</td>
      <td>0.426793</td>
      <td>0.071572</td>
      <td>0.031642</td>
      <td>0.090319</td>
      <td>-0.217323</td>
      <td>0.908045</td>
      <td>-0.206227</td>
      <td>-0.337630</td>
      <td>-0.109326</td>
      <td>0.715600</td>
      <td>0.965360</td>
      <td>0.083983</td>
      <td>-0.988411</td>
      <td>0.961919</td>
      <td>0.184006</td>
      <td>-0.116155</td>
      <td>0.452013</td>
      <td>-0.119724</td>
      <td>-0.074646</td>
      <td>0.261479</td>
      <td>-1.052895</td>
      <td>-0.141301</td>
      <td>-0.465221</td>
      <td>0.299628</td>
      <td>0.731366</td>
      <td>0.466788</td>
      <td>-0.099533</td>
      <td>...</td>
      <td>-0.121895</td>
      <td>-0.566123</td>
      <td>-0.570456</td>
      <td>-1.272055</td>
      <td>0.195230</td>
      <td>-0.075844</td>
      <td>0.119758</td>
      <td>0.267919</td>
      <td>0.463663</td>
      <td>2.247668</td>
      <td>0.832837</td>
      <td>0.449811</td>
      <td>-0.779212</td>
      <td>0.871300</td>
      <td>0.131439</td>
      <td>0.171376</td>
      <td>0.417926</td>
      <td>-0.446209</td>
      <td>-0.188950</td>
      <td>0.418497</td>
      <td>-0.537751</td>
      <td>-1.690548</td>
      <td>-0.749913</td>
      <td>0.644954</td>
      <td>-0.525439</td>
      <td>-0.217033</td>
      <td>-0.388824</td>
      <td>1.437081</td>
      <td>0.774377</td>
      <td>0.405828</td>
      <td>-0.292725</td>
      <td>-0.011224</td>
      <td>0.025852</td>
      <td>-0.204063</td>
      <td>0.241886</td>
      <td>0.338586</td>
      <td>-0.125174</td>
      <td>-0.336714</td>
      <td>-0.545486</td>
      <td>-0.224301</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.589113</td>
      <td>0.006488</td>
      <td>-0.083080</td>
      <td>0.334086</td>
      <td>-0.462925</td>
      <td>1.108459</td>
      <td>0.732373</td>
      <td>1.386381</td>
      <td>0.072198</td>
      <td>-0.817451</td>
      <td>-0.815881</td>
      <td>-0.387875</td>
      <td>1.248065</td>
      <td>0.360965</td>
      <td>0.756180</td>
      <td>-0.210309</td>
      <td>0.781491</td>
      <td>0.026489</td>
      <td>-0.205218</td>
      <td>0.118789</td>
      <td>0.438776</td>
      <td>1.227722</td>
      <td>0.234132</td>
      <td>-0.433125</td>
      <td>-1.042911</td>
      <td>-0.152804</td>
      <td>-0.513790</td>
      <td>0.377082</td>
      <td>1.978091</td>
      <td>-0.399760</td>
      <td>0.716143</td>
      <td>-0.196811</td>
      <td>0.577965</td>
      <td>0.126326</td>
      <td>-0.016746</td>
      <td>-0.155607</td>
      <td>0.963734</td>
      <td>-0.597893</td>
      <td>-0.942278</td>
      <td>0.246625</td>
      <td>...</td>
      <td>0.878145</td>
      <td>-0.378734</td>
      <td>0.419403</td>
      <td>-0.203419</td>
      <td>-0.525400</td>
      <td>-0.943000</td>
      <td>-0.221886</td>
      <td>0.598164</td>
      <td>-0.117479</td>
      <td>0.213379</td>
      <td>0.235972</td>
      <td>1.082437</td>
      <td>0.982944</td>
      <td>-0.554936</td>
      <td>-0.261874</td>
      <td>-0.292486</td>
      <td>-0.280065</td>
      <td>-0.409172</td>
      <td>0.253400</td>
      <td>0.510113</td>
      <td>0.041606</td>
      <td>0.243779</td>
      <td>-0.533078</td>
      <td>0.745635</td>
      <td>-0.349986</td>
      <td>-0.585548</td>
      <td>-0.826750</td>
      <td>-0.275811</td>
      <td>-0.965269</td>
      <td>-0.083082</td>
      <td>-0.631689</td>
      <td>0.905145</td>
      <td>-0.006251</td>
      <td>-0.340385</td>
      <td>-0.244065</td>
      <td>-0.259337</td>
      <td>0.299716</td>
      <td>-0.574196</td>
      <td>-0.562104</td>
      <td>0.209523</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.474093</td>
      <td>-0.701794</td>
      <td>-0.742769</td>
      <td>0.513684</td>
      <td>-0.213346</td>
      <td>0.171446</td>
      <td>0.217828</td>
      <td>1.311650</td>
      <td>0.317965</td>
      <td>-0.091086</td>
      <td>0.318023</td>
      <td>0.007522</td>
      <td>1.170893</td>
      <td>0.108514</td>
      <td>0.178487</td>
      <td>0.540392</td>
      <td>0.762683</td>
      <td>-0.020639</td>
      <td>0.574572</td>
      <td>0.863475</td>
      <td>-0.099547</td>
      <td>-0.120503</td>
      <td>0.448875</td>
      <td>0.381145</td>
      <td>-0.158650</td>
      <td>1.209535</td>
      <td>0.345729</td>
      <td>0.243605</td>
      <td>0.763584</td>
      <td>-0.654831</td>
      <td>0.600677</td>
      <td>0.391245</td>
      <td>0.134521</td>
      <td>-0.397604</td>
      <td>0.376179</td>
      <td>-0.073961</td>
      <td>0.897191</td>
      <td>0.868001</td>
      <td>0.685457</td>
      <td>0.098911</td>
      <td>...</td>
      <td>0.553617</td>
      <td>-0.359761</td>
      <td>0.471584</td>
      <td>0.194254</td>
      <td>0.673826</td>
      <td>-0.782008</td>
      <td>0.085526</td>
      <td>0.104181</td>
      <td>-0.780999</td>
      <td>-0.647064</td>
      <td>-1.084142</td>
      <td>0.010960</td>
      <td>0.939172</td>
      <td>0.824649</td>
      <td>0.696944</td>
      <td>-0.139062</td>
      <td>0.912247</td>
      <td>-0.183186</td>
      <td>-0.547790</td>
      <td>-0.004674</td>
      <td>-0.526813</td>
      <td>-1.107249</td>
      <td>-1.356808</td>
      <td>0.372069</td>
      <td>-0.387801</td>
      <td>-0.982835</td>
      <td>0.098571</td>
      <td>-0.222648</td>
      <td>-0.536005</td>
      <td>0.036779</td>
      <td>-0.283235</td>
      <td>-0.297205</td>
      <td>-0.565863</td>
      <td>0.174072</td>
      <td>0.893154</td>
      <td>0.517558</td>
      <td>-0.710803</td>
      <td>-0.476832</td>
      <td>0.132738</td>
      <td>0.032359</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.022854</td>
      <td>-0.009394</td>
      <td>-0.258257</td>
      <td>0.475953</td>
      <td>0.185137</td>
      <td>0.329851</td>
      <td>0.139640</td>
      <td>1.339756</td>
      <td>0.364279</td>
      <td>1.042656</td>
      <td>-0.274671</td>
      <td>-0.303071</td>
      <td>1.933437</td>
      <td>-0.252034</td>
      <td>-0.482204</td>
      <td>0.372914</td>
      <td>0.357122</td>
      <td>-0.128284</td>
      <td>-0.055632</td>
      <td>0.337842</td>
      <td>-0.133232</td>
      <td>0.090332</td>
      <td>0.475702</td>
      <td>-0.275164</td>
      <td>0.959166</td>
      <td>0.409779</td>
      <td>0.733727</td>
      <td>-0.268835</td>
      <td>0.445912</td>
      <td>0.359899</td>
      <td>-0.462041</td>
      <td>-0.181014</td>
      <td>1.000399</td>
      <td>-0.235514</td>
      <td>0.214050</td>
      <td>-0.259246</td>
      <td>1.427528</td>
      <td>0.190242</td>
      <td>-0.156114</td>
      <td>0.205933</td>
      <td>...</td>
      <td>-1.026679</td>
      <td>-0.822407</td>
      <td>0.112841</td>
      <td>-0.013831</td>
      <td>-0.334297</td>
      <td>0.721980</td>
      <td>0.181482</td>
      <td>0.672503</td>
      <td>-0.613570</td>
      <td>0.327570</td>
      <td>0.657446</td>
      <td>-0.410539</td>
      <td>0.130072</td>
      <td>-0.235691</td>
      <td>0.090947</td>
      <td>0.404865</td>
      <td>0.565604</td>
      <td>-1.091156</td>
      <td>-0.367371</td>
      <td>0.715615</td>
      <td>-0.791528</td>
      <td>0.149268</td>
      <td>-1.036434</td>
      <td>-0.033310</td>
      <td>-1.260349</td>
      <td>-0.488902</td>
      <td>-0.850274</td>
      <td>0.082174</td>
      <td>-0.103095</td>
      <td>0.266064</td>
      <td>0.469654</td>
      <td>0.438699</td>
      <td>-0.092893</td>
      <td>1.001092</td>
      <td>0.240323</td>
      <td>-0.550520</td>
      <td>0.329826</td>
      <td>0.080773</td>
      <td>0.558649</td>
      <td>0.500862</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.924277</td>
      <td>-0.501633</td>
      <td>-0.819674</td>
      <td>0.771252</td>
      <td>0.603064</td>
      <td>1.129388</td>
      <td>-0.761443</td>
      <td>0.776339</td>
      <td>0.012952</td>
      <td>-0.479364</td>
      <td>-0.023133</td>
      <td>0.981558</td>
      <td>0.918945</td>
      <td>0.420055</td>
      <td>0.710477</td>
      <td>0.269412</td>
      <td>-0.033894</td>
      <td>0.642916</td>
      <td>0.247897</td>
      <td>0.828954</td>
      <td>0.199976</td>
      <td>-0.360974</td>
      <td>0.262118</td>
      <td>-0.045505</td>
      <td>0.538221</td>
      <td>0.549638</td>
      <td>-0.356645</td>
      <td>0.889139</td>
      <td>0.883551</td>
      <td>0.884362</td>
      <td>0.338069</td>
      <td>0.213513</td>
      <td>-1.157276</td>
      <td>-0.397315</td>
      <td>0.916965</td>
      <td>-0.631889</td>
      <td>-0.149476</td>
      <td>0.189096</td>
      <td>0.578402</td>
      <td>-0.999202</td>
      <td>...</td>
      <td>0.970167</td>
      <td>1.430724</td>
      <td>0.581201</td>
      <td>0.628301</td>
      <td>0.580225</td>
      <td>-0.104896</td>
      <td>-0.308009</td>
      <td>-0.006324</td>
      <td>-0.289603</td>
      <td>-0.338502</td>
      <td>-0.250776</td>
      <td>0.198055</td>
      <td>0.865969</td>
      <td>0.325536</td>
      <td>-0.112092</td>
      <td>-0.231469</td>
      <td>0.411425</td>
      <td>-0.647646</td>
      <td>0.278177</td>
      <td>0.137246</td>
      <td>-1.036612</td>
      <td>0.671601</td>
      <td>-0.248113</td>
      <td>-0.428520</td>
      <td>-0.750310</td>
      <td>-0.053274</td>
      <td>-0.334919</td>
      <td>-0.272775</td>
      <td>0.552234</td>
      <td>-0.414755</td>
      <td>-0.461098</td>
      <td>0.713077</td>
      <td>0.665865</td>
      <td>-0.308689</td>
      <td>0.311029</td>
      <td>0.673909</td>
      <td>1.543009</td>
      <td>0.350193</td>
      <td>0.794990</td>
      <td>0.392644</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-0.223512</td>
      <td>-0.303376</td>
      <td>-0.889585</td>
      <td>0.736903</td>
      <td>-0.243917</td>
      <td>0.674118</td>
      <td>-0.219968</td>
      <td>0.370222</td>
      <td>0.121857</td>
      <td>-0.997091</td>
      <td>0.243067</td>
      <td>-0.387447</td>
      <td>0.641610</td>
      <td>1.126246</td>
      <td>0.481012</td>
      <td>0.304494</td>
      <td>-0.453512</td>
      <td>0.407452</td>
      <td>1.073535</td>
      <td>0.542754</td>
      <td>-1.034381</td>
      <td>-0.351975</td>
      <td>-0.242580</td>
      <td>0.410091</td>
      <td>0.327899</td>
      <td>0.113508</td>
      <td>-0.201765</td>
      <td>-0.407206</td>
      <td>-0.181354</td>
      <td>-0.543292</td>
      <td>0.247988</td>
      <td>-0.093377</td>
      <td>-0.284386</td>
      <td>-0.516651</td>
      <td>-0.207296</td>
      <td>0.319501</td>
      <td>0.387490</td>
      <td>-0.485009</td>
      <td>1.087508</td>
      <td>0.177282</td>
      <td>...</td>
      <td>0.123282</td>
      <td>0.295356</td>
      <td>-0.669907</td>
      <td>1.030188</td>
      <td>0.762689</td>
      <td>0.778134</td>
      <td>0.037610</td>
      <td>0.166377</td>
      <td>-0.013655</td>
      <td>-0.023274</td>
      <td>-0.235707</td>
      <td>0.419584</td>
      <td>0.686011</td>
      <td>0.279442</td>
      <td>-0.059326</td>
      <td>0.886441</td>
      <td>-1.124857</td>
      <td>-1.889025</td>
      <td>-0.859610</td>
      <td>-0.507984</td>
      <td>-0.302387</td>
      <td>-0.816338</td>
      <td>-1.517829</td>
      <td>1.726388</td>
      <td>-0.305396</td>
      <td>-0.746810</td>
      <td>-0.429559</td>
      <td>-0.607113</td>
      <td>-0.317393</td>
      <td>0.281931</td>
      <td>0.145186</td>
      <td>0.155143</td>
      <td>0.480420</td>
      <td>0.464784</td>
      <td>0.617984</td>
      <td>-0.315709</td>
      <td>0.514229</td>
      <td>0.828218</td>
      <td>1.294240</td>
      <td>0.289012</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.585660</td>
      <td>0.139269</td>
      <td>0.486684</td>
      <td>0.086008</td>
      <td>0.372737</td>
      <td>0.152435</td>
      <td>-0.155616</td>
      <td>1.024869</td>
      <td>0.479883</td>
      <td>0.162039</td>
      <td>-0.160498</td>
      <td>-0.479598</td>
      <td>0.191169</td>
      <td>-0.930251</td>
      <td>0.025036</td>
      <td>-0.261778</td>
      <td>0.315750</td>
      <td>-0.079994</td>
      <td>0.228012</td>
      <td>0.011872</td>
      <td>0.352091</td>
      <td>0.906834</td>
      <td>0.681842</td>
      <td>-0.537675</td>
      <td>-0.639129</td>
      <td>-0.798686</td>
      <td>-0.346618</td>
      <td>0.596504</td>
      <td>1.235038</td>
      <td>-0.378401</td>
      <td>0.055703</td>
      <td>-0.195804</td>
      <td>-0.454328</td>
      <td>0.144483</td>
      <td>0.749825</td>
      <td>0.485516</td>
      <td>0.751761</td>
      <td>0.263136</td>
      <td>0.697241</td>
      <td>0.238636</td>
      <td>...</td>
      <td>0.229546</td>
      <td>1.578051</td>
      <td>-0.153674</td>
      <td>0.410166</td>
      <td>0.548968</td>
      <td>-1.317586</td>
      <td>-0.486633</td>
      <td>-0.260412</td>
      <td>-1.016538</td>
      <td>0.092998</td>
      <td>-0.194289</td>
      <td>0.405035</td>
      <td>1.637307</td>
      <td>-0.552492</td>
      <td>-1.450221</td>
      <td>-0.477313</td>
      <td>-0.336143</td>
      <td>0.166689</td>
      <td>0.107587</td>
      <td>0.431135</td>
      <td>-0.461477</td>
      <td>-0.555027</td>
      <td>0.150777</td>
      <td>0.690051</td>
      <td>-0.155962</td>
      <td>-0.230305</td>
      <td>0.405479</td>
      <td>0.650360</td>
      <td>-0.345712</td>
      <td>1.036385</td>
      <td>-0.047288</td>
      <td>-0.199265</td>
      <td>-0.076860</td>
      <td>0.326317</td>
      <td>0.542086</td>
      <td>-0.097826</td>
      <td>0.170806</td>
      <td>0.285076</td>
      <td>0.892718</td>
      <td>0.532026</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-0.461006</td>
      <td>-0.757396</td>
      <td>-0.193837</td>
      <td>-0.106924</td>
      <td>0.235149</td>
      <td>1.223334</td>
      <td>0.355721</td>
      <td>1.402514</td>
      <td>-0.637335</td>
      <td>-1.107774</td>
      <td>-0.843096</td>
      <td>0.012125</td>
      <td>0.973380</td>
      <td>0.416816</td>
      <td>-0.172423</td>
      <td>1.003534</td>
      <td>-0.017981</td>
      <td>-0.080127</td>
      <td>-0.109907</td>
      <td>-0.454970</td>
      <td>-1.449585</td>
      <td>0.474263</td>
      <td>-0.542697</td>
      <td>-0.178240</td>
      <td>0.013632</td>
      <td>-0.426173</td>
      <td>0.559387</td>
      <td>0.671311</td>
      <td>0.395753</td>
      <td>-0.000989</td>
      <td>0.254251</td>
      <td>0.572492</td>
      <td>0.416201</td>
      <td>-0.891345</td>
      <td>-1.718773</td>
      <td>-0.549046</td>
      <td>0.173544</td>
      <td>-0.247515</td>
      <td>-0.066180</td>
      <td>-0.728479</td>
      <td>...</td>
      <td>0.283968</td>
      <td>-0.400114</td>
      <td>-0.729230</td>
      <td>-0.839459</td>
      <td>0.725138</td>
      <td>-0.287514</td>
      <td>0.223539</td>
      <td>-0.086799</td>
      <td>-0.335730</td>
      <td>0.392316</td>
      <td>-0.810255</td>
      <td>0.002730</td>
      <td>1.115062</td>
      <td>0.298783</td>
      <td>0.202322</td>
      <td>0.433269</td>
      <td>-0.290078</td>
      <td>-0.261305</td>
      <td>0.600561</td>
      <td>0.596522</td>
      <td>0.000883</td>
      <td>-0.333947</td>
      <td>-0.691416</td>
      <td>-0.082752</td>
      <td>-0.097429</td>
      <td>-0.908867</td>
      <td>0.036402</td>
      <td>0.387457</td>
      <td>-0.427175</td>
      <td>-0.034654</td>
      <td>-0.452988</td>
      <td>-0.200124</td>
      <td>-0.637652</td>
      <td>-0.321445</td>
      <td>-0.164486</td>
      <td>-0.495722</td>
      <td>0.060604</td>
      <td>-1.179500</td>
      <td>-0.257108</td>
      <td>-0.304463</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.316319</td>
      <td>0.675748</td>
      <td>-0.070067</td>
      <td>-0.262961</td>
      <td>-0.255261</td>
      <td>0.751426</td>
      <td>0.054484</td>
      <td>0.808169</td>
      <td>-0.039981</td>
      <td>-0.387371</td>
      <td>-0.326428</td>
      <td>-0.556100</td>
      <td>-0.180817</td>
      <td>0.329214</td>
      <td>-0.712412</td>
      <td>0.120104</td>
      <td>0.261757</td>
      <td>-0.413888</td>
      <td>-0.103993</td>
      <td>-0.656633</td>
      <td>-0.059017</td>
      <td>-0.426293</td>
      <td>-0.518540</td>
      <td>0.094025</td>
      <td>-0.472068</td>
      <td>1.003872</td>
      <td>0.319924</td>
      <td>-0.036607</td>
      <td>-0.318143</td>
      <td>-0.132363</td>
      <td>-0.108379</td>
      <td>0.092726</td>
      <td>1.209084</td>
      <td>0.751478</td>
      <td>0.022016</td>
      <td>0.991187</td>
      <td>0.678638</td>
      <td>1.286388</td>
      <td>0.240964</td>
      <td>-0.237069</td>
      <td>...</td>
      <td>-0.133888</td>
      <td>-0.600993</td>
      <td>-0.429683</td>
      <td>-0.502472</td>
      <td>0.378440</td>
      <td>-0.320856</td>
      <td>0.573028</td>
      <td>0.072684</td>
      <td>-0.486388</td>
      <td>-0.192951</td>
      <td>-0.393335</td>
      <td>-0.576039</td>
      <td>0.024756</td>
      <td>-0.151012</td>
      <td>0.464659</td>
      <td>0.255133</td>
      <td>-0.525575</td>
      <td>0.992997</td>
      <td>-0.059007</td>
      <td>0.820898</td>
      <td>-0.979954</td>
      <td>-0.123896</td>
      <td>0.013704</td>
      <td>-0.066366</td>
      <td>-0.195707</td>
      <td>-0.190873</td>
      <td>0.477748</td>
      <td>0.511831</td>
      <td>0.811734</td>
      <td>1.296588</td>
      <td>0.957781</td>
      <td>1.149370</td>
      <td>0.833385</td>
      <td>-0.194125</td>
      <td>0.344247</td>
      <td>-0.609367</td>
      <td>-0.124380</td>
      <td>-0.598881</td>
      <td>-0.023264</td>
      <td>0.158947</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.653738</td>
      <td>0.204805</td>
      <td>-0.647276</td>
      <td>-0.391043</td>
      <td>-0.150172</td>
      <td>0.440544</td>
      <td>0.000038</td>
      <td>0.324511</td>
      <td>-1.622562</td>
      <td>0.186269</td>
      <td>-0.430159</td>
      <td>1.396597</td>
      <td>0.350091</td>
      <td>0.608740</td>
      <td>-0.118558</td>
      <td>-0.319029</td>
      <td>-0.410787</td>
      <td>-0.431434</td>
      <td>-0.205542</td>
      <td>-0.205901</td>
      <td>-0.533432</td>
      <td>0.337971</td>
      <td>0.290435</td>
      <td>-0.266189</td>
      <td>0.330257</td>
      <td>0.128156</td>
      <td>-0.325085</td>
      <td>-0.276966</td>
      <td>0.005341</td>
      <td>0.219960</td>
      <td>0.344176</td>
      <td>-0.769476</td>
      <td>-0.042012</td>
      <td>0.569769</td>
      <td>-0.384922</td>
      <td>1.216282</td>
      <td>1.330224</td>
      <td>0.898037</td>
      <td>0.256003</td>
      <td>0.016321</td>
      <td>...</td>
      <td>-0.689218</td>
      <td>0.207975</td>
      <td>1.325518</td>
      <td>-0.181609</td>
      <td>0.758514</td>
      <td>0.400251</td>
      <td>-0.885885</td>
      <td>-0.035455</td>
      <td>-0.525861</td>
      <td>0.245357</td>
      <td>0.206941</td>
      <td>0.184750</td>
      <td>1.147628</td>
      <td>0.052867</td>
      <td>0.342294</td>
      <td>0.084265</td>
      <td>0.450286</td>
      <td>0.064454</td>
      <td>-0.996417</td>
      <td>0.115791</td>
      <td>-0.396576</td>
      <td>0.436429</td>
      <td>-1.130846</td>
      <td>0.039669</td>
      <td>-0.026228</td>
      <td>0.217203</td>
      <td>0.189758</td>
      <td>0.231678</td>
      <td>-0.566822</td>
      <td>0.475784</td>
      <td>-0.277882</td>
      <td>-0.352420</td>
      <td>0.559784</td>
      <td>0.144240</td>
      <td>0.553790</td>
      <td>-0.556694</td>
      <td>-0.321123</td>
      <td>-2.027590</td>
      <td>-0.961530</td>
      <td>-0.215790</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-0.936131</td>
      <td>-0.323442</td>
      <td>-0.179553</td>
      <td>0.410963</td>
      <td>0.393663</td>
      <td>-0.315431</td>
      <td>0.142363</td>
      <td>0.279232</td>
      <td>-0.540288</td>
      <td>-1.156711</td>
      <td>-0.275197</td>
      <td>-1.669519</td>
      <td>0.134905</td>
      <td>0.317455</td>
      <td>0.177125</td>
      <td>-0.396830</td>
      <td>0.551588</td>
      <td>-0.010124</td>
      <td>-0.560121</td>
      <td>0.230738</td>
      <td>-0.536002</td>
      <td>-0.285881</td>
      <td>0.416382</td>
      <td>-0.831325</td>
      <td>0.451182</td>
      <td>-0.546806</td>
      <td>-1.162679</td>
      <td>-0.877730</td>
      <td>-0.256270</td>
      <td>0.397958</td>
      <td>-0.205481</td>
      <td>-0.387167</td>
      <td>-0.443357</td>
      <td>-0.794695</td>
      <td>-0.696440</td>
      <td>0.193859</td>
      <td>0.584801</td>
      <td>0.428954</td>
      <td>-0.290278</td>
      <td>-0.696319</td>
      <td>...</td>
      <td>0.847858</td>
      <td>0.097085</td>
      <td>-0.138790</td>
      <td>-0.361998</td>
      <td>0.274860</td>
      <td>-0.799166</td>
      <td>-0.660997</td>
      <td>0.226580</td>
      <td>0.201210</td>
      <td>0.475175</td>
      <td>0.469134</td>
      <td>0.085623</td>
      <td>0.705960</td>
      <td>-1.163241</td>
      <td>-0.092632</td>
      <td>-0.866821</td>
      <td>-0.901834</td>
      <td>-0.735227</td>
      <td>-0.433896</td>
      <td>0.910228</td>
      <td>0.174652</td>
      <td>0.429230</td>
      <td>-1.110460</td>
      <td>0.578006</td>
      <td>-1.054166</td>
      <td>-0.770509</td>
      <td>-0.676444</td>
      <td>0.520978</td>
      <td>1.506640</td>
      <td>1.132750</td>
      <td>-0.346183</td>
      <td>0.047245</td>
      <td>0.348179</td>
      <td>0.038011</td>
      <td>0.613465</td>
      <td>-1.393177</td>
      <td>-1.126834</td>
      <td>-1.631098</td>
      <td>-0.833218</td>
      <td>-0.465561</td>
    </tr>
    <tr>
      <th>16</th>
      <td>1.356979</td>
      <td>0.231527</td>
      <td>-0.460587</td>
      <td>-0.659950</td>
      <td>-0.048636</td>
      <td>-0.070644</td>
      <td>-0.038447</td>
      <td>0.602583</td>
      <td>-0.050366</td>
      <td>-0.421788</td>
      <td>-0.208038</td>
      <td>0.120694</td>
      <td>0.027849</td>
      <td>-0.546606</td>
      <td>-0.412548</td>
      <td>-0.711090</td>
      <td>0.216085</td>
      <td>-1.128907</td>
      <td>-0.820101</td>
      <td>-0.845384</td>
      <td>-0.456514</td>
      <td>-1.252532</td>
      <td>-0.612360</td>
      <td>-0.137260</td>
      <td>-0.227551</td>
      <td>-0.439290</td>
      <td>0.124961</td>
      <td>-0.058687</td>
      <td>0.457585</td>
      <td>-0.427506</td>
      <td>0.317050</td>
      <td>0.353493</td>
      <td>0.034857</td>
      <td>0.156027</td>
      <td>-1.926486</td>
      <td>-0.487464</td>
      <td>0.521605</td>
      <td>0.741317</td>
      <td>0.781059</td>
      <td>-0.636802</td>
      <td>...</td>
      <td>0.904156</td>
      <td>1.175962</td>
      <td>-0.322380</td>
      <td>-0.336148</td>
      <td>0.678469</td>
      <td>1.159645</td>
      <td>0.527558</td>
      <td>0.222289</td>
      <td>-0.449238</td>
      <td>0.605866</td>
      <td>0.636316</td>
      <td>-0.955735</td>
      <td>0.490063</td>
      <td>0.975037</td>
      <td>0.003409</td>
      <td>0.030656</td>
      <td>0.076864</td>
      <td>-0.484499</td>
      <td>0.355409</td>
      <td>-0.517519</td>
      <td>0.223786</td>
      <td>-0.128841</td>
      <td>-0.783942</td>
      <td>0.351212</td>
      <td>-0.572737</td>
      <td>-0.085753</td>
      <td>-0.294843</td>
      <td>-0.441020</td>
      <td>0.460425</td>
      <td>-0.675011</td>
      <td>-0.219508</td>
      <td>0.327541</td>
      <td>0.240740</td>
      <td>-0.704314</td>
      <td>-0.625719</td>
      <td>-0.784882</td>
      <td>-0.908886</td>
      <td>2.106574</td>
      <td>1.765371</td>
      <td>0.817767</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.723715</td>
      <td>-1.066672</td>
      <td>0.334654</td>
      <td>-0.230959</td>
      <td>0.616997</td>
      <td>0.976904</td>
      <td>0.732525</td>
      <td>0.022752</td>
      <td>0.051850</td>
      <td>0.140975</td>
      <td>-0.096250</td>
      <td>-0.058212</td>
      <td>1.136459</td>
      <td>1.413289</td>
      <td>0.323882</td>
      <td>-0.716699</td>
      <td>0.539414</td>
      <td>-0.061621</td>
      <td>-0.180434</td>
      <td>-0.116207</td>
      <td>-0.577739</td>
      <td>0.576390</td>
      <td>0.391150</td>
      <td>0.718878</td>
      <td>0.976967</td>
      <td>0.986837</td>
      <td>0.527697</td>
      <td>-0.279641</td>
      <td>0.117025</td>
      <td>0.407891</td>
      <td>0.835414</td>
      <td>0.220802</td>
      <td>-0.458020</td>
      <td>-0.606888</td>
      <td>-0.169919</td>
      <td>0.524903</td>
      <td>0.964479</td>
      <td>0.624246</td>
      <td>0.491868</td>
      <td>-0.286813</td>
      <td>...</td>
      <td>1.128240</td>
      <td>-0.633923</td>
      <td>-0.002003</td>
      <td>-0.469387</td>
      <td>0.150233</td>
      <td>0.934475</td>
      <td>-0.211268</td>
      <td>0.158887</td>
      <td>-1.187471</td>
      <td>-0.766815</td>
      <td>0.475686</td>
      <td>0.612327</td>
      <td>1.468685</td>
      <td>0.634547</td>
      <td>0.717933</td>
      <td>0.580353</td>
      <td>0.375868</td>
      <td>0.193133</td>
      <td>-0.540713</td>
      <td>0.334934</td>
      <td>-1.314436</td>
      <td>-0.013510</td>
      <td>0.396433</td>
      <td>0.396498</td>
      <td>-0.618550</td>
      <td>0.116568</td>
      <td>0.097783</td>
      <td>-0.959779</td>
      <td>-0.161921</td>
      <td>-0.596318</td>
      <td>1.034345</td>
      <td>0.548882</td>
      <td>-0.114868</td>
      <td>-0.410759</td>
      <td>-0.122510</td>
      <td>-0.629654</td>
      <td>-0.744635</td>
      <td>1.121940</td>
      <td>0.750215</td>
      <td>0.089452</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.433002</td>
      <td>-0.872205</td>
      <td>0.485953</td>
      <td>0.425875</td>
      <td>0.069023</td>
      <td>-0.091049</td>
      <td>-0.542057</td>
      <td>0.338084</td>
      <td>0.191905</td>
      <td>0.977842</td>
      <td>0.398268</td>
      <td>-0.607461</td>
      <td>0.461848</td>
      <td>-0.020771</td>
      <td>-0.002812</td>
      <td>0.024648</td>
      <td>0.299956</td>
      <td>0.582241</td>
      <td>0.346585</td>
      <td>0.398889</td>
      <td>-0.166061</td>
      <td>0.140142</td>
      <td>-0.289642</td>
      <td>-0.359931</td>
      <td>-0.330326</td>
      <td>-0.705770</td>
      <td>0.752667</td>
      <td>0.780513</td>
      <td>1.119796</td>
      <td>-0.008709</td>
      <td>0.367564</td>
      <td>-0.762787</td>
      <td>0.099920</td>
      <td>-0.370587</td>
      <td>-0.091802</td>
      <td>0.017403</td>
      <td>-0.323366</td>
      <td>-0.699992</td>
      <td>0.067956</td>
      <td>0.628360</td>
      <td>...</td>
      <td>0.749943</td>
      <td>0.173513</td>
      <td>0.435150</td>
      <td>0.364789</td>
      <td>0.943067</td>
      <td>0.750482</td>
      <td>-0.282173</td>
      <td>0.272231</td>
      <td>0.221742</td>
      <td>0.559727</td>
      <td>-0.115228</td>
      <td>-0.106525</td>
      <td>1.292931</td>
      <td>0.740921</td>
      <td>0.165024</td>
      <td>0.676590</td>
      <td>0.766348</td>
      <td>-0.559565</td>
      <td>-0.564660</td>
      <td>-0.377773</td>
      <td>-0.682867</td>
      <td>-0.365321</td>
      <td>0.309268</td>
      <td>0.541234</td>
      <td>-0.365642</td>
      <td>0.045793</td>
      <td>-0.296977</td>
      <td>0.460163</td>
      <td>-0.153944</td>
      <td>-0.517642</td>
      <td>-0.263255</td>
      <td>0.119840</td>
      <td>-0.432738</td>
      <td>-1.207753</td>
      <td>-0.388382</td>
      <td>-0.762187</td>
      <td>-0.577242</td>
      <td>1.310829</td>
      <td>1.298875</td>
      <td>1.170572</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.275702</td>
      <td>0.805501</td>
      <td>-0.144818</td>
      <td>0.231792</td>
      <td>0.494921</td>
      <td>0.055346</td>
      <td>1.037372</td>
      <td>0.937049</td>
      <td>0.486922</td>
      <td>0.711340</td>
      <td>0.704924</td>
      <td>0.532789</td>
      <td>-0.050976</td>
      <td>-0.259550</td>
      <td>-0.766442</td>
      <td>0.677495</td>
      <td>0.283455</td>
      <td>-0.706602</td>
      <td>-1.231441</td>
      <td>0.866962</td>
      <td>0.403368</td>
      <td>-0.276753</td>
      <td>1.192196</td>
      <td>0.013922</td>
      <td>0.066180</td>
      <td>-0.525620</td>
      <td>-0.453620</td>
      <td>-0.804332</td>
      <td>-0.007402</td>
      <td>-0.299571</td>
      <td>-0.030959</td>
      <td>-0.215807</td>
      <td>-0.349579</td>
      <td>-0.664393</td>
      <td>-0.655238</td>
      <td>0.424071</td>
      <td>1.173362</td>
      <td>0.765688</td>
      <td>0.166472</td>
      <td>0.054897</td>
      <td>...</td>
      <td>1.135367</td>
      <td>0.631820</td>
      <td>-0.302890</td>
      <td>0.772634</td>
      <td>-0.076702</td>
      <td>-0.375387</td>
      <td>-0.563978</td>
      <td>0.374480</td>
      <td>-1.017758</td>
      <td>-1.280108</td>
      <td>-1.449012</td>
      <td>-0.988440</td>
      <td>0.368055</td>
      <td>0.516354</td>
      <td>0.739908</td>
      <td>-0.361207</td>
      <td>-0.204838</td>
      <td>-0.375795</td>
      <td>-0.663094</td>
      <td>-0.096840</td>
      <td>0.306790</td>
      <td>-0.100149</td>
      <td>-0.202118</td>
      <td>0.276192</td>
      <td>-0.374288</td>
      <td>-0.874356</td>
      <td>-0.426426</td>
      <td>0.411376</td>
      <td>-0.445006</td>
      <td>-0.635761</td>
      <td>0.338678</td>
      <td>0.355112</td>
      <td>0.506475</td>
      <td>0.343588</td>
      <td>-0.060718</td>
      <td>0.407459</td>
      <td>0.595051</td>
      <td>2.121039</td>
      <td>1.029670</td>
      <td>0.822735</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.903744</td>
      <td>-0.558899</td>
      <td>-0.078645</td>
      <td>-0.355962</td>
      <td>0.444313</td>
      <td>0.454115</td>
      <td>0.570855</td>
      <td>-0.221341</td>
      <td>-0.066697</td>
      <td>-0.728040</td>
      <td>-0.308428</td>
      <td>-1.043623</td>
      <td>0.596908</td>
      <td>-0.335962</td>
      <td>-0.129269</td>
      <td>-0.261872</td>
      <td>0.154850</td>
      <td>-0.208888</td>
      <td>-0.043108</td>
      <td>0.782426</td>
      <td>-0.452185</td>
      <td>-0.265619</td>
      <td>-0.279538</td>
      <td>-0.013804</td>
      <td>0.037512</td>
      <td>-0.873063</td>
      <td>-0.005637</td>
      <td>0.701076</td>
      <td>-0.409465</td>
      <td>0.083589</td>
      <td>-0.289200</td>
      <td>-0.522516</td>
      <td>1.033432</td>
      <td>0.460647</td>
      <td>-0.043238</td>
      <td>-0.225038</td>
      <td>0.846277</td>
      <td>0.434282</td>
      <td>0.972009</td>
      <td>-0.524828</td>
      <td>...</td>
      <td>-0.102186</td>
      <td>0.003976</td>
      <td>0.357395</td>
      <td>0.111008</td>
      <td>0.420001</td>
      <td>-0.882001</td>
      <td>-1.428331</td>
      <td>-0.027944</td>
      <td>0.317563</td>
      <td>0.245970</td>
      <td>-0.695255</td>
      <td>-0.134220</td>
      <td>1.074160</td>
      <td>-0.122685</td>
      <td>0.447633</td>
      <td>-0.042568</td>
      <td>0.153867</td>
      <td>-0.014076</td>
      <td>0.368538</td>
      <td>-0.040159</td>
      <td>0.282004</td>
      <td>-0.511636</td>
      <td>-0.808359</td>
      <td>0.825795</td>
      <td>-0.575989</td>
      <td>0.155041</td>
      <td>-0.094502</td>
      <td>-0.529092</td>
      <td>-0.813944</td>
      <td>0.114505</td>
      <td>-0.508105</td>
      <td>-0.261387</td>
      <td>-1.092073</td>
      <td>-0.804841</td>
      <td>0.866204</td>
      <td>-0.851606</td>
      <td>-0.839543</td>
      <td>2.437550</td>
      <td>1.882747</td>
      <td>1.026092</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.760085</td>
      <td>0.636241</td>
      <td>0.135625</td>
      <td>0.552436</td>
      <td>0.229155</td>
      <td>1.001432</td>
      <td>0.262529</td>
      <td>1.150459</td>
      <td>-0.138543</td>
      <td>-0.716676</td>
      <td>-0.766134</td>
      <td>0.620780</td>
      <td>1.190517</td>
      <td>-0.066239</td>
      <td>0.023436</td>
      <td>0.341998</td>
      <td>0.621881</td>
      <td>-0.553412</td>
      <td>-2.101685</td>
      <td>0.099094</td>
      <td>0.277203</td>
      <td>-0.217194</td>
      <td>-0.729513</td>
      <td>-0.271103</td>
      <td>0.160936</td>
      <td>0.123809</td>
      <td>0.084476</td>
      <td>-0.605430</td>
      <td>1.020093</td>
      <td>-0.336024</td>
      <td>0.131689</td>
      <td>-0.451628</td>
      <td>0.350505</td>
      <td>-0.486881</td>
      <td>-0.227707</td>
      <td>-0.121082</td>
      <td>1.705811</td>
      <td>1.060847</td>
      <td>0.458992</td>
      <td>0.143461</td>
      <td>...</td>
      <td>0.003955</td>
      <td>0.420023</td>
      <td>-0.035983</td>
      <td>1.396490</td>
      <td>1.782679</td>
      <td>1.668361</td>
      <td>-1.026143</td>
      <td>-0.177461</td>
      <td>0.104206</td>
      <td>0.132770</td>
      <td>0.215714</td>
      <td>0.578773</td>
      <td>-0.014174</td>
      <td>-0.125958</td>
      <td>-0.889394</td>
      <td>0.247172</td>
      <td>0.444238</td>
      <td>-0.410670</td>
      <td>0.827142</td>
      <td>1.040502</td>
      <td>-0.963981</td>
      <td>0.256476</td>
      <td>-0.223562</td>
      <td>0.528263</td>
      <td>-0.268382</td>
      <td>-0.349332</td>
      <td>-0.077362</td>
      <td>0.305691</td>
      <td>-0.797341</td>
      <td>-1.283034</td>
      <td>-0.670645</td>
      <td>-0.374093</td>
      <td>-0.659871</td>
      <td>-1.069522</td>
      <td>-1.350384</td>
      <td>0.239379</td>
      <td>0.632055</td>
      <td>0.834600</td>
      <td>0.500842</td>
      <td>-0.092453</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.981200</td>
      <td>-0.063323</td>
      <td>-0.222825</td>
      <td>0.406386</td>
      <td>0.786779</td>
      <td>-0.117797</td>
      <td>-0.239378</td>
      <td>0.546062</td>
      <td>-0.127616</td>
      <td>-0.737920</td>
      <td>-1.145618</td>
      <td>-0.376278</td>
      <td>0.657909</td>
      <td>-0.113613</td>
      <td>0.024035</td>
      <td>0.909643</td>
      <td>1.097705</td>
      <td>-0.293585</td>
      <td>-0.083940</td>
      <td>0.214771</td>
      <td>-0.056175</td>
      <td>-0.172071</td>
      <td>0.224847</td>
      <td>-0.921674</td>
      <td>0.221576</td>
      <td>-0.771547</td>
      <td>-0.190280</td>
      <td>-0.024831</td>
      <td>0.257847</td>
      <td>-0.592589</td>
      <td>-0.344512</td>
      <td>0.328781</td>
      <td>0.180998</td>
      <td>0.583144</td>
      <td>0.753190</td>
      <td>0.306029</td>
      <td>0.506932</td>
      <td>-0.094920</td>
      <td>0.802155</td>
      <td>0.223398</td>
      <td>...</td>
      <td>1.660804</td>
      <td>-0.705186</td>
      <td>-0.068074</td>
      <td>0.905355</td>
      <td>1.013946</td>
      <td>1.198058</td>
      <td>0.237729</td>
      <td>-0.344724</td>
      <td>-0.956295</td>
      <td>-0.005394</td>
      <td>-0.144185</td>
      <td>0.419895</td>
      <td>0.168654</td>
      <td>-0.446433</td>
      <td>0.762949</td>
      <td>0.090065</td>
      <td>0.993327</td>
      <td>-0.751928</td>
      <td>-0.442861</td>
      <td>0.213789</td>
      <td>-0.411304</td>
      <td>0.373258</td>
      <td>-0.726076</td>
      <td>-0.099198</td>
      <td>-1.139919</td>
      <td>-0.839019</td>
      <td>-1.185149</td>
      <td>0.118885</td>
      <td>0.336337</td>
      <td>0.643862</td>
      <td>0.024943</td>
      <td>0.443356</td>
      <td>-0.497781</td>
      <td>-0.172593</td>
      <td>0.409965</td>
      <td>-0.155818</td>
      <td>-0.252639</td>
      <td>-0.645209</td>
      <td>0.211321</td>
      <td>0.422224</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.713018</td>
      <td>-0.473265</td>
      <td>-1.337906</td>
      <td>-0.578317</td>
      <td>-0.404659</td>
      <td>1.054977</td>
      <td>-0.132084</td>
      <td>0.853491</td>
      <td>0.305967</td>
      <td>-1.565161</td>
      <td>-0.069396</td>
      <td>-0.281887</td>
      <td>1.163712</td>
      <td>-0.582225</td>
      <td>-0.825042</td>
      <td>0.308425</td>
      <td>0.852313</td>
      <td>0.712223</td>
      <td>0.060674</td>
      <td>0.568881</td>
      <td>-1.058347</td>
      <td>-0.589589</td>
      <td>0.212597</td>
      <td>0.346559</td>
      <td>0.608594</td>
      <td>-0.585869</td>
      <td>-0.109669</td>
      <td>1.101495</td>
      <td>0.829344</td>
      <td>-0.017367</td>
      <td>0.466252</td>
      <td>-0.066774</td>
      <td>0.823117</td>
      <td>0.034515</td>
      <td>0.330948</td>
      <td>0.279561</td>
      <td>0.388098</td>
      <td>-0.673648</td>
      <td>-0.331901</td>
      <td>-0.212039</td>
      <td>...</td>
      <td>0.275633</td>
      <td>-0.440608</td>
      <td>-0.046306</td>
      <td>0.796112</td>
      <td>-0.022577</td>
      <td>0.407076</td>
      <td>0.615382</td>
      <td>0.285726</td>
      <td>-0.970732</td>
      <td>-0.051094</td>
      <td>-0.225198</td>
      <td>-0.397436</td>
      <td>1.722075</td>
      <td>0.094271</td>
      <td>-0.742779</td>
      <td>0.505828</td>
      <td>-0.464553</td>
      <td>-0.646340</td>
      <td>-0.605967</td>
      <td>0.696483</td>
      <td>-0.636105</td>
      <td>-0.333245</td>
      <td>-1.775141</td>
      <td>0.083655</td>
      <td>0.591826</td>
      <td>-1.294409</td>
      <td>-0.773533</td>
      <td>-0.933305</td>
      <td>0.172654</td>
      <td>0.210215</td>
      <td>-0.101682</td>
      <td>-0.252697</td>
      <td>0.273856</td>
      <td>-0.405343</td>
      <td>0.340337</td>
      <td>-0.727527</td>
      <td>-0.559013</td>
      <td>-2.191395</td>
      <td>-1.466242</td>
      <td>-0.689370</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-1.315980</td>
      <td>-0.345678</td>
      <td>-0.161222</td>
      <td>-0.046105</td>
      <td>-0.217844</td>
      <td>-0.053095</td>
      <td>-0.626694</td>
      <td>-0.788618</td>
      <td>0.014083</td>
      <td>-0.289910</td>
      <td>-0.914773</td>
      <td>0.250896</td>
      <td>0.550460</td>
      <td>0.350994</td>
      <td>0.050402</td>
      <td>0.556141</td>
      <td>0.626524</td>
      <td>-0.435476</td>
      <td>-0.713007</td>
      <td>-0.121102</td>
      <td>-1.439719</td>
      <td>-1.401871</td>
      <td>0.222420</td>
      <td>1.877527</td>
      <td>0.760412</td>
      <td>1.261493</td>
      <td>-1.011640</td>
      <td>0.967309</td>
      <td>0.141550</td>
      <td>-0.089448</td>
      <td>-0.248277</td>
      <td>0.867895</td>
      <td>0.927607</td>
      <td>0.522147</td>
      <td>-0.329604</td>
      <td>-1.243509</td>
      <td>0.086104</td>
      <td>0.296979</td>
      <td>-0.249636</td>
      <td>-0.692218</td>
      <td>...</td>
      <td>0.963826</td>
      <td>0.431962</td>
      <td>-1.064821</td>
      <td>0.109544</td>
      <td>0.254539</td>
      <td>-0.147556</td>
      <td>0.362153</td>
      <td>0.350392</td>
      <td>0.373189</td>
      <td>0.009125</td>
      <td>-0.069468</td>
      <td>0.720297</td>
      <td>1.192995</td>
      <td>-0.502147</td>
      <td>0.361192</td>
      <td>0.307976</td>
      <td>-0.440784</td>
      <td>0.273634</td>
      <td>-0.202630</td>
      <td>-0.021200</td>
      <td>-0.487914</td>
      <td>-0.027539</td>
      <td>-0.062362</td>
      <td>1.129743</td>
      <td>-0.099679</td>
      <td>-0.140673</td>
      <td>0.811761</td>
      <td>0.068791</td>
      <td>-1.621565</td>
      <td>-0.076079</td>
      <td>-0.457472</td>
      <td>-0.495979</td>
      <td>-0.688035</td>
      <td>-0.903960</td>
      <td>0.081705</td>
      <td>-0.394114</td>
      <td>-0.207935</td>
      <td>-1.467809</td>
      <td>-0.822480</td>
      <td>-0.165746</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.369101</td>
      <td>-0.424300</td>
      <td>0.194828</td>
      <td>1.192426</td>
      <td>0.229635</td>
      <td>-0.047601</td>
      <td>0.465640</td>
      <td>0.126224</td>
      <td>1.243267</td>
      <td>0.716991</td>
      <td>0.700006</td>
      <td>0.955751</td>
      <td>-0.394060</td>
      <td>0.115262</td>
      <td>-0.344761</td>
      <td>-0.208205</td>
      <td>-0.135626</td>
      <td>-0.077102</td>
      <td>0.097268</td>
      <td>0.394518</td>
      <td>-0.076508</td>
      <td>-0.120218</td>
      <td>0.563503</td>
      <td>0.456465</td>
      <td>-0.379227</td>
      <td>-0.791649</td>
      <td>-0.404188</td>
      <td>-0.324360</td>
      <td>0.287221</td>
      <td>-0.405323</td>
      <td>0.475074</td>
      <td>-0.075772</td>
      <td>0.180211</td>
      <td>0.076824</td>
      <td>-0.128383</td>
      <td>-1.175008</td>
      <td>-0.237277</td>
      <td>-1.082991</td>
      <td>0.444902</td>
      <td>-0.461067</td>
      <td>...</td>
      <td>-0.280304</td>
      <td>-0.683518</td>
      <td>-1.644369</td>
      <td>-1.352311</td>
      <td>-1.048006</td>
      <td>-0.422823</td>
      <td>0.486944</td>
      <td>0.191415</td>
      <td>0.968157</td>
      <td>0.043594</td>
      <td>-1.245857</td>
      <td>-0.667754</td>
      <td>0.020390</td>
      <td>-0.393615</td>
      <td>-0.200061</td>
      <td>-0.374263</td>
      <td>-0.959277</td>
      <td>-1.604502</td>
      <td>-1.417905</td>
      <td>0.020959</td>
      <td>-0.036000</td>
      <td>-0.221283</td>
      <td>-0.048645</td>
      <td>0.990412</td>
      <td>0.386355</td>
      <td>-0.008687</td>
      <td>0.203431</td>
      <td>0.374504</td>
      <td>-0.225983</td>
      <td>-1.537543</td>
      <td>-1.010641</td>
      <td>-0.624270</td>
      <td>-0.292379</td>
      <td>-0.462101</td>
      <td>0.372937</td>
      <td>-0.228770</td>
      <td>-0.237866</td>
      <td>-0.146705</td>
      <td>-0.516792</td>
      <td>-0.473540</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.986276</td>
      <td>-0.114089</td>
      <td>-0.212583</td>
      <td>0.876536</td>
      <td>-1.478793</td>
      <td>1.070006</td>
      <td>-0.623774</td>
      <td>0.465914</td>
      <td>-0.186316</td>
      <td>0.407156</td>
      <td>0.835369</td>
      <td>1.821928</td>
      <td>-0.551705</td>
      <td>0.307207</td>
      <td>0.197605</td>
      <td>-0.965610</td>
      <td>0.132978</td>
      <td>0.098937</td>
      <td>0.154898</td>
      <td>0.782590</td>
      <td>0.180752</td>
      <td>-0.414853</td>
      <td>0.258794</td>
      <td>0.271773</td>
      <td>-0.203947</td>
      <td>-1.005461</td>
      <td>-1.257051</td>
      <td>-0.643982</td>
      <td>-0.897968</td>
      <td>0.563118</td>
      <td>-0.196028</td>
      <td>0.006622</td>
      <td>0.519117</td>
      <td>-0.124919</td>
      <td>0.291665</td>
      <td>-0.443660</td>
      <td>-0.848384</td>
      <td>-1.583787</td>
      <td>0.562190</td>
      <td>0.032596</td>
      <td>...</td>
      <td>0.214807</td>
      <td>0.663827</td>
      <td>0.415710</td>
      <td>0.627852</td>
      <td>-0.777898</td>
      <td>0.297665</td>
      <td>1.497009</td>
      <td>0.088628</td>
      <td>0.026771</td>
      <td>-0.948763</td>
      <td>-1.080590</td>
      <td>0.525605</td>
      <td>0.174133</td>
      <td>0.908201</td>
      <td>0.025736</td>
      <td>0.210447</td>
      <td>-0.273254</td>
      <td>-1.137752</td>
      <td>-0.559698</td>
      <td>0.337050</td>
      <td>0.160570</td>
      <td>0.828317</td>
      <td>0.100510</td>
      <td>0.466087</td>
      <td>0.477697</td>
      <td>-0.867857</td>
      <td>-0.784209</td>
      <td>-0.888517</td>
      <td>-1.234272</td>
      <td>0.129810</td>
      <td>0.345104</td>
      <td>-0.545410</td>
      <td>-1.066676</td>
      <td>-0.988980</td>
      <td>-0.132849</td>
      <td>-0.074654</td>
      <td>1.050248</td>
      <td>0.617708</td>
      <td>0.822277</td>
      <td>-0.146462</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.801602</td>
      <td>0.634580</td>
      <td>0.670866</td>
      <td>0.183496</td>
      <td>-0.530004</td>
      <td>0.072750</td>
      <td>0.048899</td>
      <td>0.695852</td>
      <td>0.903441</td>
      <td>0.664997</td>
      <td>0.880457</td>
      <td>1.007531</td>
      <td>0.240457</td>
      <td>0.308737</td>
      <td>0.445907</td>
      <td>-0.556024</td>
      <td>-1.110209</td>
      <td>-0.274591</td>
      <td>0.273429</td>
      <td>0.427121</td>
      <td>-0.926516</td>
      <td>1.024219</td>
      <td>0.970544</td>
      <td>0.391516</td>
      <td>0.526425</td>
      <td>-1.024917</td>
      <td>-1.768736</td>
      <td>-0.982038</td>
      <td>0.192551</td>
      <td>-0.067728</td>
      <td>-0.310057</td>
      <td>0.748644</td>
      <td>-0.004702</td>
      <td>-0.338751</td>
      <td>-0.318340</td>
      <td>0.518049</td>
      <td>0.087653</td>
      <td>-0.494637</td>
      <td>1.340023</td>
      <td>1.969904</td>
      <td>...</td>
      <td>0.469023</td>
      <td>0.537097</td>
      <td>1.670450</td>
      <td>1.091567</td>
      <td>0.662727</td>
      <td>-0.302398</td>
      <td>1.221752</td>
      <td>0.895571</td>
      <td>0.056377</td>
      <td>-0.842025</td>
      <td>-0.212793</td>
      <td>-0.234290</td>
      <td>-0.518248</td>
      <td>-0.482527</td>
      <td>-1.426713</td>
      <td>-0.096977</td>
      <td>-1.052219</td>
      <td>0.184007</td>
      <td>-0.416039</td>
      <td>-0.198624</td>
      <td>-0.709451</td>
      <td>-0.619217</td>
      <td>-1.036073</td>
      <td>-0.554423</td>
      <td>0.263636</td>
      <td>1.206506</td>
      <td>-0.322948</td>
      <td>-0.387639</td>
      <td>-0.611441</td>
      <td>-0.912295</td>
      <td>-0.378304</td>
      <td>-0.435785</td>
      <td>-1.204204</td>
      <td>0.262788</td>
      <td>-0.003159</td>
      <td>-0.020848</td>
      <td>-0.168872</td>
      <td>2.001220</td>
      <td>2.030603</td>
      <td>0.642172</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.179780</td>
      <td>-0.713763</td>
      <td>0.116831</td>
      <td>0.668228</td>
      <td>-0.823015</td>
      <td>-0.453970</td>
      <td>0.890863</td>
      <td>0.646735</td>
      <td>0.354841</td>
      <td>-0.497958</td>
      <td>-0.141241</td>
      <td>0.288354</td>
      <td>-0.086672</td>
      <td>0.539805</td>
      <td>0.718598</td>
      <td>0.675666</td>
      <td>0.425747</td>
      <td>0.462864</td>
      <td>-0.502797</td>
      <td>0.244687</td>
      <td>0.592685</td>
      <td>0.445900</td>
      <td>0.219359</td>
      <td>0.002697</td>
      <td>-0.801595</td>
      <td>0.090413</td>
      <td>-0.114108</td>
      <td>-0.829270</td>
      <td>0.096408</td>
      <td>0.190532</td>
      <td>-0.114982</td>
      <td>-0.013760</td>
      <td>-0.274944</td>
      <td>-0.806626</td>
      <td>-0.659946</td>
      <td>0.725316</td>
      <td>0.739351</td>
      <td>-1.314262</td>
      <td>-0.085479</td>
      <td>-1.039687</td>
      <td>...</td>
      <td>-0.356539</td>
      <td>0.522159</td>
      <td>0.242168</td>
      <td>0.415178</td>
      <td>-0.554082</td>
      <td>-1.031998</td>
      <td>-0.506682</td>
      <td>-0.230973</td>
      <td>0.131189</td>
      <td>0.018451</td>
      <td>-0.145201</td>
      <td>-0.605816</td>
      <td>-0.884953</td>
      <td>0.395892</td>
      <td>-0.383475</td>
      <td>-0.403312</td>
      <td>-0.455842</td>
      <td>-0.505109</td>
      <td>0.514808</td>
      <td>-0.549427</td>
      <td>-0.626778</td>
      <td>-0.332398</td>
      <td>-0.615732</td>
      <td>0.268256</td>
      <td>-0.780064</td>
      <td>-0.862783</td>
      <td>-0.904368</td>
      <td>0.820353</td>
      <td>-0.180233</td>
      <td>-1.070460</td>
      <td>0.750480</td>
      <td>-0.077347</td>
      <td>-0.797717</td>
      <td>-0.436352</td>
      <td>-0.738675</td>
      <td>-0.635786</td>
      <td>-0.120115</td>
      <td>-1.020797</td>
      <td>-1.118483</td>
      <td>-0.589835</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.332724</td>
      <td>-0.438799</td>
      <td>0.269292</td>
      <td>1.067821</td>
      <td>0.104367</td>
      <td>-0.976488</td>
      <td>-0.084763</td>
      <td>0.734231</td>
      <td>0.645510</td>
      <td>0.226578</td>
      <td>1.107190</td>
      <td>1.274588</td>
      <td>-0.934259</td>
      <td>-0.077850</td>
      <td>0.397781</td>
      <td>0.137648</td>
      <td>-0.671810</td>
      <td>0.005379</td>
      <td>0.407121</td>
      <td>0.792875</td>
      <td>0.300434</td>
      <td>0.192110</td>
      <td>1.590130</td>
      <td>-0.043349</td>
      <td>-0.343619</td>
      <td>0.252365</td>
      <td>-1.404619</td>
      <td>-1.621149</td>
      <td>-0.760101</td>
      <td>-1.515619</td>
      <td>-0.633591</td>
      <td>-0.312732</td>
      <td>-0.555295</td>
      <td>0.169907</td>
      <td>0.038657</td>
      <td>-0.276065</td>
      <td>0.934982</td>
      <td>-1.205181</td>
      <td>0.932810</td>
      <td>-0.587961</td>
      <td>...</td>
      <td>0.520114</td>
      <td>0.416369</td>
      <td>-0.162218</td>
      <td>0.150334</td>
      <td>-0.207667</td>
      <td>-0.193645</td>
      <td>-0.152066</td>
      <td>-0.663863</td>
      <td>0.416713</td>
      <td>-0.810322</td>
      <td>-0.073429</td>
      <td>0.935750</td>
      <td>-0.205607</td>
      <td>-1.240119</td>
      <td>-0.637688</td>
      <td>-0.335322</td>
      <td>0.664441</td>
      <td>0.057740</td>
      <td>-0.749845</td>
      <td>-0.807645</td>
      <td>-0.858876</td>
      <td>-0.878599</td>
      <td>-0.245720</td>
      <td>0.271178</td>
      <td>-0.572394</td>
      <td>-0.573354</td>
      <td>-0.670157</td>
      <td>0.263182</td>
      <td>-0.248312</td>
      <td>-0.288527</td>
      <td>0.298518</td>
      <td>-0.196427</td>
      <td>-0.390364</td>
      <td>-1.993783</td>
      <td>-1.115865</td>
      <td>0.432501</td>
      <td>0.050994</td>
      <td>0.037099</td>
      <td>0.824654</td>
      <td>0.389592</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f8eec150a30&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.049051  0.040927  25.632459  6.633905e-145  0.968836  1.129266
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  5.348 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>