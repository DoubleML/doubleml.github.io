
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17: http://docutils.sourceforge.net/" />

    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.f6b7ca918bee2f46fd9abac01cfb07d5.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1e043a052b0af929e4d8.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">


    
    <a class="navbar-brand" href="../index.html">
      <p class="title">DoubleML</p>
    </a>
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  DoubleML
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/install.html">
  Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/intro.html">
  Getting started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../guide/guide.html">
  User guide
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api.html">
  Python API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference external nav-link" href="https://docs.doubleml.org/r/stable/">
  R API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../release/release.html">
  Release notes
 </a>
</li>

        
      </ul>

      <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><p class="logo" style="text-align:center;"><a href="../index.html">
    <img class="logo" src="../logo.png" alt="Logo" width="65%" height="65%">
</a></p><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l2 current active">
  <a class="current reference internal" href="#">
   Multiway Cluster Robust DML
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="double_ml_bonus_data.html">
   DML: Bonus Data
  </a>
 </li>
</ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulate-multiway-cluster-data">
   Simulate multiway cluster data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
   Initialize the objects of class DoubleMLData and DoubleMLPLIV
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#split-samples-and-transfer-the-sample-splitting-to-the-object">
   Split samples and transfer the sample splitting to the object
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fit-the-model-and-show-a-summary">
   Fit the model and show a summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing">
   Visualization of sample splitting with tuple and linear indexing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold">
     Visualize sample splitting with tuples (one plot per fold)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
     Visualize sample splitting with linear indexing (one column per fold)
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<section id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-0.347383</td>
      <td>0.399085</td>
      <td>0.619173</td>
      <td>1.065883</td>
      <td>0.075825</td>
      <td>-0.315708</td>
      <td>-0.473350</td>
      <td>0.780058</td>
      <td>0.489929</td>
      <td>0.155819</td>
      <td>-0.001845</td>
      <td>-0.649865</td>
      <td>-0.093462</td>
      <td>0.101486</td>
      <td>0.411852</td>
      <td>0.633175</td>
      <td>-0.526668</td>
      <td>-0.605880</td>
      <td>0.341477</td>
      <td>0.034656</td>
      <td>0.781355</td>
      <td>0.000519</td>
      <td>1.105115</td>
      <td>0.632984</td>
      <td>0.068370</td>
      <td>-0.340510</td>
      <td>0.653117</td>
      <td>0.140781</td>
      <td>0.071130</td>
      <td>-0.659340</td>
      <td>-1.186087</td>
      <td>-0.357757</td>
      <td>-0.839140</td>
      <td>-1.291923</td>
      <td>0.094444</td>
      <td>0.084427</td>
      <td>-0.191163</td>
      <td>-0.450314</td>
      <td>0.876530</td>
      <td>0.571141</td>
      <td>...</td>
      <td>0.143503</td>
      <td>0.483844</td>
      <td>-0.394477</td>
      <td>0.654803</td>
      <td>0.485918</td>
      <td>0.087372</td>
      <td>-0.122282</td>
      <td>0.847032</td>
      <td>-0.536987</td>
      <td>-0.097775</td>
      <td>-0.349829</td>
      <td>-0.948046</td>
      <td>-0.207073</td>
      <td>0.744032</td>
      <td>-0.379435</td>
      <td>0.654506</td>
      <td>0.470689</td>
      <td>0.486723</td>
      <td>0.554485</td>
      <td>-0.322533</td>
      <td>-0.143577</td>
      <td>-0.383932</td>
      <td>-0.078470</td>
      <td>0.054398</td>
      <td>0.333104</td>
      <td>0.351541</td>
      <td>-0.475869</td>
      <td>0.262769</td>
      <td>-0.189039</td>
      <td>0.579684</td>
      <td>-0.371326</td>
      <td>0.883908</td>
      <td>1.202546</td>
      <td>1.183689</td>
      <td>0.075347</td>
      <td>-0.179083</td>
      <td>1.030250</td>
      <td>1.748182</td>
      <td>1.167615</td>
      <td>0.886362</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.421623</td>
      <td>-0.924620</td>
      <td>-0.737795</td>
      <td>-0.732385</td>
      <td>-1.174914</td>
      <td>-1.871389</td>
      <td>-0.841716</td>
      <td>0.376551</td>
      <td>0.488507</td>
      <td>0.362344</td>
      <td>0.433351</td>
      <td>-1.012611</td>
      <td>0.496609</td>
      <td>0.675435</td>
      <td>0.826899</td>
      <td>-1.420858</td>
      <td>0.128491</td>
      <td>-0.935702</td>
      <td>-0.429076</td>
      <td>0.151656</td>
      <td>0.176602</td>
      <td>0.349964</td>
      <td>0.533448</td>
      <td>0.114277</td>
      <td>0.962663</td>
      <td>0.104209</td>
      <td>-0.663658</td>
      <td>0.902643</td>
      <td>0.138104</td>
      <td>0.737161</td>
      <td>0.186272</td>
      <td>0.477060</td>
      <td>0.136728</td>
      <td>-0.744997</td>
      <td>-1.122475</td>
      <td>0.644586</td>
      <td>-0.424290</td>
      <td>-1.529358</td>
      <td>0.221613</td>
      <td>0.576939</td>
      <td>...</td>
      <td>0.349925</td>
      <td>-0.420099</td>
      <td>-0.511362</td>
      <td>0.228719</td>
      <td>0.454907</td>
      <td>0.050098</td>
      <td>-0.276800</td>
      <td>-0.158643</td>
      <td>-1.033071</td>
      <td>-0.052507</td>
      <td>0.354738</td>
      <td>0.271363</td>
      <td>-0.551461</td>
      <td>-0.499653</td>
      <td>0.666679</td>
      <td>0.484451</td>
      <td>0.822158</td>
      <td>0.108166</td>
      <td>-0.542434</td>
      <td>0.006743</td>
      <td>0.626278</td>
      <td>0.117864</td>
      <td>0.239301</td>
      <td>0.213840</td>
      <td>0.611928</td>
      <td>-0.756456</td>
      <td>0.443649</td>
      <td>0.023078</td>
      <td>0.742143</td>
      <td>0.262537</td>
      <td>-0.980028</td>
      <td>-0.405413</td>
      <td>-0.826073</td>
      <td>-0.507704</td>
      <td>0.381357</td>
      <td>0.212499</td>
      <td>-0.039622</td>
      <td>-4.744816</td>
      <td>-2.946778</td>
      <td>-0.899447</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.286733</td>
      <td>0.070732</td>
      <td>0.652449</td>
      <td>0.513804</td>
      <td>0.548679</td>
      <td>-0.067627</td>
      <td>0.210866</td>
      <td>-0.551471</td>
      <td>-0.464526</td>
      <td>1.302956</td>
      <td>0.632896</td>
      <td>0.712793</td>
      <td>-0.550193</td>
      <td>0.606067</td>
      <td>-0.203558</td>
      <td>0.094659</td>
      <td>-0.386570</td>
      <td>-0.238925</td>
      <td>-0.147068</td>
      <td>-0.018469</td>
      <td>-1.004549</td>
      <td>-0.532694</td>
      <td>0.248362</td>
      <td>1.047281</td>
      <td>0.359046</td>
      <td>0.518417</td>
      <td>0.725629</td>
      <td>0.517143</td>
      <td>0.563787</td>
      <td>-0.232637</td>
      <td>0.652425</td>
      <td>0.739081</td>
      <td>0.083934</td>
      <td>-0.980316</td>
      <td>-1.262580</td>
      <td>-0.238612</td>
      <td>0.828289</td>
      <td>-0.294350</td>
      <td>0.041860</td>
      <td>0.749863</td>
      <td>...</td>
      <td>0.166463</td>
      <td>0.471564</td>
      <td>-0.063961</td>
      <td>0.692737</td>
      <td>1.317219</td>
      <td>0.534009</td>
      <td>0.272170</td>
      <td>-0.162382</td>
      <td>-0.339839</td>
      <td>-0.595467</td>
      <td>0.744523</td>
      <td>-0.230617</td>
      <td>0.453612</td>
      <td>0.108015</td>
      <td>-0.017344</td>
      <td>-0.467653</td>
      <td>-0.526531</td>
      <td>-0.220640</td>
      <td>-0.851730</td>
      <td>0.374258</td>
      <td>-0.596491</td>
      <td>0.047402</td>
      <td>0.902301</td>
      <td>0.048465</td>
      <td>-0.649908</td>
      <td>-1.351161</td>
      <td>-0.580985</td>
      <td>-1.703138</td>
      <td>-0.980866</td>
      <td>-0.772906</td>
      <td>-0.031864</td>
      <td>0.208324</td>
      <td>-0.095915</td>
      <td>1.486655</td>
      <td>0.150511</td>
      <td>0.742516</td>
      <td>0.897808</td>
      <td>0.384415</td>
      <td>-0.407275</td>
      <td>-1.157543</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.074759</td>
      <td>0.382294</td>
      <td>0.346409</td>
      <td>1.304387</td>
      <td>0.394734</td>
      <td>-0.040137</td>
      <td>-1.114190</td>
      <td>-0.293091</td>
      <td>-0.763814</td>
      <td>-0.383782</td>
      <td>0.720633</td>
      <td>-0.053307</td>
      <td>-0.641706</td>
      <td>0.449057</td>
      <td>-1.276548</td>
      <td>0.446621</td>
      <td>-0.050017</td>
      <td>0.148551</td>
      <td>0.853284</td>
      <td>0.238894</td>
      <td>0.113931</td>
      <td>-0.058635</td>
      <td>0.708909</td>
      <td>0.439069</td>
      <td>0.477987</td>
      <td>0.328020</td>
      <td>-0.115529</td>
      <td>-0.064891</td>
      <td>-0.733061</td>
      <td>-1.196796</td>
      <td>0.229396</td>
      <td>-0.036047</td>
      <td>0.052218</td>
      <td>0.184036</td>
      <td>0.208320</td>
      <td>0.106714</td>
      <td>-0.054553</td>
      <td>-0.510373</td>
      <td>0.124770</td>
      <td>-0.743845</td>
      <td>...</td>
      <td>-0.255121</td>
      <td>1.169441</td>
      <td>0.346717</td>
      <td>-0.192308</td>
      <td>-0.476787</td>
      <td>-0.761166</td>
      <td>0.401314</td>
      <td>-0.618991</td>
      <td>-0.287848</td>
      <td>0.433202</td>
      <td>0.179368</td>
      <td>1.119957</td>
      <td>0.892594</td>
      <td>0.889259</td>
      <td>0.002097</td>
      <td>0.611694</td>
      <td>1.116388</td>
      <td>0.432609</td>
      <td>1.202430</td>
      <td>-0.108544</td>
      <td>0.164224</td>
      <td>-0.425436</td>
      <td>0.246920</td>
      <td>-0.302295</td>
      <td>0.276574</td>
      <td>0.268598</td>
      <td>0.510028</td>
      <td>-0.041849</td>
      <td>0.034871</td>
      <td>0.066897</td>
      <td>-0.023865</td>
      <td>1.304214</td>
      <td>0.789366</td>
      <td>-0.349482</td>
      <td>-0.531882</td>
      <td>0.355905</td>
      <td>0.034701</td>
      <td>1.458662</td>
      <td>1.120940</td>
      <td>0.262896</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.354398</td>
      <td>-0.693702</td>
      <td>0.014073</td>
      <td>-0.511871</td>
      <td>-0.299664</td>
      <td>-0.297612</td>
      <td>-0.383404</td>
      <td>-0.592085</td>
      <td>0.282402</td>
      <td>1.535013</td>
      <td>0.367796</td>
      <td>0.066731</td>
      <td>-0.360655</td>
      <td>1.457798</td>
      <td>0.692457</td>
      <td>0.343593</td>
      <td>-0.985285</td>
      <td>-0.340652</td>
      <td>0.196295</td>
      <td>-0.032222</td>
      <td>0.381631</td>
      <td>1.252120</td>
      <td>0.548693</td>
      <td>-0.119163</td>
      <td>0.134523</td>
      <td>-0.081927</td>
      <td>0.908319</td>
      <td>0.807343</td>
      <td>0.373234</td>
      <td>-0.112024</td>
      <td>0.020172</td>
      <td>0.451374</td>
      <td>-0.452183</td>
      <td>-0.554754</td>
      <td>-0.790022</td>
      <td>0.474354</td>
      <td>0.876861</td>
      <td>-0.242102</td>
      <td>-0.367452</td>
      <td>0.241869</td>
      <td>...</td>
      <td>-0.518981</td>
      <td>0.215514</td>
      <td>-0.234449</td>
      <td>-0.178010</td>
      <td>-0.084294</td>
      <td>-1.122331</td>
      <td>0.537756</td>
      <td>-0.171673</td>
      <td>0.085993</td>
      <td>0.449643</td>
      <td>0.261656</td>
      <td>0.593395</td>
      <td>-0.586241</td>
      <td>0.839226</td>
      <td>0.537948</td>
      <td>-0.016603</td>
      <td>0.499330</td>
      <td>-0.561653</td>
      <td>0.264031</td>
      <td>-0.234203</td>
      <td>0.433422</td>
      <td>-0.742312</td>
      <td>0.164859</td>
      <td>0.529530</td>
      <td>0.208871</td>
      <td>-0.126368</td>
      <td>-0.653450</td>
      <td>-0.936295</td>
      <td>-1.070472</td>
      <td>-0.492587</td>
      <td>-0.668491</td>
      <td>0.013734</td>
      <td>0.716479</td>
      <td>1.297529</td>
      <td>-0.523301</td>
      <td>-0.339842</td>
      <td>-0.104215</td>
      <td>-1.418368</td>
      <td>-0.454509</td>
      <td>0.278972</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.604389</td>
      <td>-0.552941</td>
      <td>-0.527685</td>
      <td>-0.321727</td>
      <td>0.052544</td>
      <td>-0.735356</td>
      <td>0.218095</td>
      <td>0.828010</td>
      <td>1.240582</td>
      <td>0.865843</td>
      <td>0.576140</td>
      <td>-0.318240</td>
      <td>-0.830823</td>
      <td>1.008362</td>
      <td>0.036704</td>
      <td>-0.040651</td>
      <td>-1.011589</td>
      <td>-0.686731</td>
      <td>-0.446932</td>
      <td>0.392154</td>
      <td>0.485417</td>
      <td>0.132767</td>
      <td>0.927127</td>
      <td>0.388142</td>
      <td>-0.524824</td>
      <td>-0.443883</td>
      <td>0.282518</td>
      <td>-0.441208</td>
      <td>-0.398379</td>
      <td>0.006402</td>
      <td>-0.689681</td>
      <td>0.247816</td>
      <td>0.003282</td>
      <td>-0.400673</td>
      <td>0.346532</td>
      <td>0.360073</td>
      <td>0.780145</td>
      <td>0.060642</td>
      <td>0.046606</td>
      <td>-0.091911</td>
      <td>...</td>
      <td>-0.456969</td>
      <td>0.607791</td>
      <td>-0.320427</td>
      <td>0.358005</td>
      <td>0.737114</td>
      <td>-0.536484</td>
      <td>0.396391</td>
      <td>0.471380</td>
      <td>-0.160259</td>
      <td>-0.126271</td>
      <td>0.214816</td>
      <td>0.150570</td>
      <td>0.484835</td>
      <td>-0.855176</td>
      <td>0.597425</td>
      <td>0.082554</td>
      <td>0.102692</td>
      <td>-0.625405</td>
      <td>-0.174150</td>
      <td>-0.311395</td>
      <td>0.713487</td>
      <td>0.030484</td>
      <td>-0.544821</td>
      <td>0.433601</td>
      <td>0.278664</td>
      <td>0.058531</td>
      <td>-0.429519</td>
      <td>0.434553</td>
      <td>-0.089023</td>
      <td>0.849155</td>
      <td>1.136117</td>
      <td>-0.441676</td>
      <td>-0.915917</td>
      <td>0.355891</td>
      <td>-1.475634</td>
      <td>-1.512780</td>
      <td>1.291435</td>
      <td>-3.568345</td>
      <td>-2.410784</td>
      <td>-1.486015</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.629387</td>
      <td>0.647504</td>
      <td>1.210069</td>
      <td>0.616094</td>
      <td>0.646049</td>
      <td>-1.132022</td>
      <td>-0.410915</td>
      <td>1.137116</td>
      <td>0.512526</td>
      <td>0.747336</td>
      <td>0.014463</td>
      <td>-0.829581</td>
      <td>-0.366749</td>
      <td>0.928016</td>
      <td>0.521354</td>
      <td>-0.116563</td>
      <td>0.373708</td>
      <td>0.332877</td>
      <td>0.409362</td>
      <td>0.423578</td>
      <td>1.000426</td>
      <td>0.656099</td>
      <td>1.043505</td>
      <td>0.142478</td>
      <td>-0.385021</td>
      <td>-0.041257</td>
      <td>0.902759</td>
      <td>0.560289</td>
      <td>-0.095196</td>
      <td>-0.440995</td>
      <td>-0.091966</td>
      <td>1.672600</td>
      <td>0.386941</td>
      <td>-0.113582</td>
      <td>-1.404926</td>
      <td>0.567330</td>
      <td>-0.045691</td>
      <td>-0.576105</td>
      <td>1.078129</td>
      <td>0.032954</td>
      <td>...</td>
      <td>0.393353</td>
      <td>0.751338</td>
      <td>-1.091239</td>
      <td>-0.529653</td>
      <td>-0.065302</td>
      <td>0.341762</td>
      <td>-0.438756</td>
      <td>-0.382708</td>
      <td>-0.753410</td>
      <td>-1.221786</td>
      <td>-0.542814</td>
      <td>0.421869</td>
      <td>-0.090044</td>
      <td>-0.843667</td>
      <td>-0.753534</td>
      <td>-0.086633</td>
      <td>0.565957</td>
      <td>-1.247523</td>
      <td>-0.598769</td>
      <td>0.240274</td>
      <td>0.091425</td>
      <td>0.658255</td>
      <td>0.417617</td>
      <td>0.436433</td>
      <td>0.667781</td>
      <td>0.517115</td>
      <td>0.425624</td>
      <td>-0.148736</td>
      <td>0.268330</td>
      <td>0.561965</td>
      <td>-0.590874</td>
      <td>0.590068</td>
      <td>0.443239</td>
      <td>0.320136</td>
      <td>-0.536375</td>
      <td>0.125181</td>
      <td>1.143783</td>
      <td>1.607638</td>
      <td>1.733115</td>
      <td>0.902509</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.137602</td>
      <td>-0.334937</td>
      <td>-0.028886</td>
      <td>-0.432349</td>
      <td>0.333773</td>
      <td>0.616781</td>
      <td>-0.942114</td>
      <td>-1.467685</td>
      <td>-0.477850</td>
      <td>-0.815132</td>
      <td>0.054402</td>
      <td>-1.271300</td>
      <td>-0.209350</td>
      <td>-0.099744</td>
      <td>-0.734339</td>
      <td>-0.518416</td>
      <td>-0.072974</td>
      <td>-0.278586</td>
      <td>-0.004453</td>
      <td>0.281150</td>
      <td>-0.263960</td>
      <td>-0.306118</td>
      <td>0.061400</td>
      <td>0.240322</td>
      <td>0.621523</td>
      <td>-0.876556</td>
      <td>0.499143</td>
      <td>0.220784</td>
      <td>0.275482</td>
      <td>-0.120019</td>
      <td>0.948229</td>
      <td>-0.165621</td>
      <td>0.409253</td>
      <td>-0.080328</td>
      <td>-0.168639</td>
      <td>-0.352329</td>
      <td>-0.437782</td>
      <td>-0.705171</td>
      <td>-0.260694</td>
      <td>-0.062690</td>
      <td>...</td>
      <td>0.225429</td>
      <td>0.584037</td>
      <td>-0.169317</td>
      <td>-0.582399</td>
      <td>0.695742</td>
      <td>0.455344</td>
      <td>0.164794</td>
      <td>0.265746</td>
      <td>-0.662981</td>
      <td>-0.742897</td>
      <td>-0.380846</td>
      <td>0.077300</td>
      <td>0.509805</td>
      <td>-0.056189</td>
      <td>0.026340</td>
      <td>-0.269253</td>
      <td>-0.482456</td>
      <td>-0.425145</td>
      <td>-0.326447</td>
      <td>0.998191</td>
      <td>0.546948</td>
      <td>0.754985</td>
      <td>0.687272</td>
      <td>1.084885</td>
      <td>0.492437</td>
      <td>0.098858</td>
      <td>-0.694487</td>
      <td>0.886728</td>
      <td>1.742005</td>
      <td>0.813598</td>
      <td>0.906069</td>
      <td>0.771204</td>
      <td>0.158159</td>
      <td>0.745142</td>
      <td>0.028844</td>
      <td>-0.310196</td>
      <td>0.386469</td>
      <td>0.040691</td>
      <td>0.133540</td>
      <td>-0.021740</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-1.415828</td>
      <td>-0.225913</td>
      <td>0.730648</td>
      <td>0.791642</td>
      <td>-0.146660</td>
      <td>-0.210886</td>
      <td>0.559811</td>
      <td>-0.029189</td>
      <td>0.083364</td>
      <td>0.903261</td>
      <td>0.571283</td>
      <td>0.277719</td>
      <td>-0.290779</td>
      <td>-0.050021</td>
      <td>0.039578</td>
      <td>0.176769</td>
      <td>0.228282</td>
      <td>-0.836185</td>
      <td>0.123136</td>
      <td>0.388963</td>
      <td>-0.043485</td>
      <td>-0.889804</td>
      <td>1.019197</td>
      <td>0.240047</td>
      <td>1.113290</td>
      <td>-0.091869</td>
      <td>-0.088812</td>
      <td>0.133788</td>
      <td>-0.902755</td>
      <td>-1.590417</td>
      <td>-0.125077</td>
      <td>0.266754</td>
      <td>0.582530</td>
      <td>0.354129</td>
      <td>-0.779018</td>
      <td>-0.189673</td>
      <td>0.401273</td>
      <td>-0.975978</td>
      <td>0.180545</td>
      <td>-0.130551</td>
      <td>...</td>
      <td>-0.851740</td>
      <td>0.228602</td>
      <td>0.095163</td>
      <td>-0.024862</td>
      <td>0.535802</td>
      <td>-0.648045</td>
      <td>0.481271</td>
      <td>0.394974</td>
      <td>-0.788421</td>
      <td>0.453565</td>
      <td>0.290953</td>
      <td>0.907131</td>
      <td>-0.790213</td>
      <td>-0.709439</td>
      <td>-0.030030</td>
      <td>-0.208843</td>
      <td>0.710625</td>
      <td>-0.220221</td>
      <td>-0.057202</td>
      <td>-0.795958</td>
      <td>0.427025</td>
      <td>0.083836</td>
      <td>1.095136</td>
      <td>0.292672</td>
      <td>-0.252813</td>
      <td>-0.423779</td>
      <td>0.086237</td>
      <td>0.257659</td>
      <td>0.230528</td>
      <td>-0.740522</td>
      <td>-0.060332</td>
      <td>-0.075138</td>
      <td>-0.241969</td>
      <td>-0.004843</td>
      <td>0.819479</td>
      <td>1.364668</td>
      <td>0.576324</td>
      <td>-1.764091</td>
      <td>-1.481529</td>
      <td>-0.696177</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.140885</td>
      <td>-0.953562</td>
      <td>-0.117586</td>
      <td>0.622276</td>
      <td>0.786413</td>
      <td>0.212050</td>
      <td>-0.262425</td>
      <td>0.470296</td>
      <td>0.208684</td>
      <td>0.999911</td>
      <td>-0.593698</td>
      <td>-0.550331</td>
      <td>0.518605</td>
      <td>0.445324</td>
      <td>-1.580047</td>
      <td>-1.746789</td>
      <td>-0.537555</td>
      <td>-0.027039</td>
      <td>-0.167705</td>
      <td>-0.150386</td>
      <td>-0.217732</td>
      <td>0.717743</td>
      <td>0.056583</td>
      <td>0.033145</td>
      <td>0.375342</td>
      <td>-0.234292</td>
      <td>-0.065570</td>
      <td>0.894538</td>
      <td>-0.148744</td>
      <td>-0.172664</td>
      <td>-0.409540</td>
      <td>0.592444</td>
      <td>-0.465499</td>
      <td>-0.376789</td>
      <td>0.242072</td>
      <td>0.488270</td>
      <td>0.424907</td>
      <td>0.581265</td>
      <td>1.050147</td>
      <td>-0.162661</td>
      <td>...</td>
      <td>1.611378</td>
      <td>1.012465</td>
      <td>-0.329897</td>
      <td>1.011743</td>
      <td>0.212057</td>
      <td>0.432533</td>
      <td>0.534483</td>
      <td>-0.093232</td>
      <td>0.068927</td>
      <td>0.595124</td>
      <td>0.543728</td>
      <td>0.267810</td>
      <td>0.167559</td>
      <td>-0.280494</td>
      <td>0.587510</td>
      <td>-0.253052</td>
      <td>-0.469340</td>
      <td>-0.537510</td>
      <td>-0.867575</td>
      <td>-0.200446</td>
      <td>0.290835</td>
      <td>0.859878</td>
      <td>-0.138233</td>
      <td>-0.727759</td>
      <td>-0.825359</td>
      <td>-1.167516</td>
      <td>-1.217316</td>
      <td>0.181658</td>
      <td>0.014067</td>
      <td>-0.311856</td>
      <td>0.441999</td>
      <td>0.843647</td>
      <td>0.260853</td>
      <td>0.118531</td>
      <td>0.118229</td>
      <td>0.678999</td>
      <td>1.178455</td>
      <td>-1.476634</td>
      <td>-1.456960</td>
      <td>-0.332314</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.180795</td>
      <td>-0.809028</td>
      <td>0.068271</td>
      <td>1.050678</td>
      <td>1.085300</td>
      <td>0.035612</td>
      <td>-0.542556</td>
      <td>0.821454</td>
      <td>0.360187</td>
      <td>1.248885</td>
      <td>-0.204393</td>
      <td>-0.284516</td>
      <td>-0.169529</td>
      <td>0.291488</td>
      <td>0.186347</td>
      <td>0.483049</td>
      <td>0.236036</td>
      <td>-0.057611</td>
      <td>1.280611</td>
      <td>0.522099</td>
      <td>-0.112913</td>
      <td>0.169292</td>
      <td>0.228170</td>
      <td>-0.201806</td>
      <td>-0.851770</td>
      <td>0.207892</td>
      <td>-0.001398</td>
      <td>1.644420</td>
      <td>0.969665</td>
      <td>-0.092666</td>
      <td>-0.626045</td>
      <td>-0.334932</td>
      <td>-0.755485</td>
      <td>-0.897986</td>
      <td>-0.631953</td>
      <td>-0.190081</td>
      <td>1.174028</td>
      <td>0.099000</td>
      <td>-0.041060</td>
      <td>0.496629</td>
      <td>...</td>
      <td>0.213738</td>
      <td>1.005298</td>
      <td>-0.330902</td>
      <td>1.073371</td>
      <td>1.031750</td>
      <td>-0.298173</td>
      <td>1.069084</td>
      <td>1.115098</td>
      <td>-0.331108</td>
      <td>-0.070672</td>
      <td>0.749473</td>
      <td>0.893832</td>
      <td>-0.025621</td>
      <td>-0.050495</td>
      <td>-0.092859</td>
      <td>0.612473</td>
      <td>0.265632</td>
      <td>-0.646352</td>
      <td>0.470642</td>
      <td>-0.951534</td>
      <td>-0.548915</td>
      <td>0.479879</td>
      <td>0.635683</td>
      <td>0.552148</td>
      <td>1.040579</td>
      <td>-0.306350</td>
      <td>1.059320</td>
      <td>-0.502298</td>
      <td>-1.071474</td>
      <td>0.253354</td>
      <td>-0.014454</td>
      <td>0.545894</td>
      <td>0.513982</td>
      <td>0.096860</td>
      <td>-0.548173</td>
      <td>-0.169512</td>
      <td>0.868514</td>
      <td>-1.085631</td>
      <td>-0.675218</td>
      <td>-0.382713</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.570783</td>
      <td>0.007717</td>
      <td>0.288848</td>
      <td>0.663897</td>
      <td>0.127707</td>
      <td>0.311054</td>
      <td>-0.175167</td>
      <td>-0.062299</td>
      <td>1.640306</td>
      <td>1.364151</td>
      <td>0.702498</td>
      <td>-0.203633</td>
      <td>-0.521758</td>
      <td>0.661234</td>
      <td>0.551542</td>
      <td>0.117349</td>
      <td>-0.166452</td>
      <td>-0.734091</td>
      <td>-0.157453</td>
      <td>0.729388</td>
      <td>-0.439493</td>
      <td>-0.647127</td>
      <td>-0.776970</td>
      <td>-1.338105</td>
      <td>0.942128</td>
      <td>-0.017275</td>
      <td>0.595705</td>
      <td>1.171546</td>
      <td>-0.545737</td>
      <td>-0.993672</td>
      <td>-0.083026</td>
      <td>-0.006874</td>
      <td>-0.226363</td>
      <td>-0.593684</td>
      <td>-1.750614</td>
      <td>0.540991</td>
      <td>0.027376</td>
      <td>-0.571742</td>
      <td>-0.107768</td>
      <td>0.833162</td>
      <td>...</td>
      <td>-0.176540</td>
      <td>-0.028469</td>
      <td>-0.887072</td>
      <td>0.343697</td>
      <td>0.187885</td>
      <td>0.274762</td>
      <td>-0.469758</td>
      <td>1.204366</td>
      <td>-0.306543</td>
      <td>-0.781296</td>
      <td>0.408247</td>
      <td>-0.195945</td>
      <td>0.150999</td>
      <td>-0.992283</td>
      <td>-0.191842</td>
      <td>0.638357</td>
      <td>-0.819629</td>
      <td>-0.129706</td>
      <td>0.586196</td>
      <td>0.342579</td>
      <td>-0.260527</td>
      <td>-0.723749</td>
      <td>-0.172335</td>
      <td>-0.117029</td>
      <td>-0.035824</td>
      <td>-0.409908</td>
      <td>0.413870</td>
      <td>0.656707</td>
      <td>0.007286</td>
      <td>1.021721</td>
      <td>0.925678</td>
      <td>-0.675621</td>
      <td>0.280680</td>
      <td>0.909656</td>
      <td>-0.446934</td>
      <td>-0.441327</td>
      <td>1.074955</td>
      <td>-0.896962</td>
      <td>-0.707218</td>
      <td>-0.320338</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-0.504162</td>
      <td>0.420392</td>
      <td>0.409969</td>
      <td>-0.036526</td>
      <td>-0.017071</td>
      <td>-0.709217</td>
      <td>-0.644529</td>
      <td>0.661818</td>
      <td>-0.019942</td>
      <td>-0.645987</td>
      <td>0.087054</td>
      <td>0.173470</td>
      <td>-0.049423</td>
      <td>-0.102851</td>
      <td>0.103064</td>
      <td>0.228863</td>
      <td>0.917762</td>
      <td>0.283529</td>
      <td>-0.748322</td>
      <td>-0.352650</td>
      <td>-0.688620</td>
      <td>-0.456642</td>
      <td>0.222033</td>
      <td>0.990395</td>
      <td>0.878046</td>
      <td>0.441039</td>
      <td>0.884389</td>
      <td>-0.271820</td>
      <td>-0.021559</td>
      <td>0.356620</td>
      <td>-0.414048</td>
      <td>-0.141741</td>
      <td>0.889635</td>
      <td>-1.007078</td>
      <td>0.451037</td>
      <td>0.129647</td>
      <td>0.696898</td>
      <td>0.358119</td>
      <td>-0.001012</td>
      <td>0.609498</td>
      <td>...</td>
      <td>0.492647</td>
      <td>-0.040929</td>
      <td>-0.677920</td>
      <td>-0.463609</td>
      <td>-0.231779</td>
      <td>-0.018955</td>
      <td>0.176733</td>
      <td>0.579673</td>
      <td>0.023197</td>
      <td>-0.061493</td>
      <td>0.126364</td>
      <td>0.449447</td>
      <td>-0.132043</td>
      <td>0.067120</td>
      <td>-0.143594</td>
      <td>-0.641372</td>
      <td>0.507449</td>
      <td>0.370740</td>
      <td>0.076967</td>
      <td>1.047465</td>
      <td>0.426124</td>
      <td>0.233189</td>
      <td>0.018951</td>
      <td>-0.370167</td>
      <td>-0.802863</td>
      <td>-0.510956</td>
      <td>1.135758</td>
      <td>0.175760</td>
      <td>0.534940</td>
      <td>0.538788</td>
      <td>0.180674</td>
      <td>0.181098</td>
      <td>0.692860</td>
      <td>0.086809</td>
      <td>0.038168</td>
      <td>-0.757537</td>
      <td>0.688813</td>
      <td>-0.350342</td>
      <td>-0.857111</td>
      <td>-0.225628</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.055322</td>
      <td>0.071337</td>
      <td>-0.681882</td>
      <td>0.102057</td>
      <td>-0.054877</td>
      <td>0.272906</td>
      <td>0.464973</td>
      <td>0.289911</td>
      <td>1.067795</td>
      <td>-0.192355</td>
      <td>0.502570</td>
      <td>-0.594193</td>
      <td>-0.407956</td>
      <td>0.928680</td>
      <td>0.509681</td>
      <td>0.024969</td>
      <td>-0.626626</td>
      <td>0.013997</td>
      <td>-0.364840</td>
      <td>-0.323927</td>
      <td>-0.049821</td>
      <td>-0.921882</td>
      <td>0.877358</td>
      <td>1.225006</td>
      <td>1.323531</td>
      <td>0.683113</td>
      <td>-0.710139</td>
      <td>0.785627</td>
      <td>0.273670</td>
      <td>-0.193338</td>
      <td>0.323645</td>
      <td>0.270510</td>
      <td>-0.924893</td>
      <td>-0.112459</td>
      <td>-0.953519</td>
      <td>0.853841</td>
      <td>-0.386680</td>
      <td>-0.110718</td>
      <td>0.721013</td>
      <td>-0.109831</td>
      <td>...</td>
      <td>0.086220</td>
      <td>0.822121</td>
      <td>0.265918</td>
      <td>-0.503451</td>
      <td>0.916893</td>
      <td>0.746579</td>
      <td>-0.939363</td>
      <td>-0.087895</td>
      <td>0.001810</td>
      <td>-0.761541</td>
      <td>-0.137036</td>
      <td>-0.157693</td>
      <td>-0.867945</td>
      <td>-0.416937</td>
      <td>-0.207504</td>
      <td>-0.684228</td>
      <td>0.436750</td>
      <td>0.047716</td>
      <td>0.212124</td>
      <td>-0.791739</td>
      <td>0.004653</td>
      <td>0.887586</td>
      <td>-0.204921</td>
      <td>0.078629</td>
      <td>-0.676172</td>
      <td>-0.729502</td>
      <td>0.377990</td>
      <td>0.825314</td>
      <td>0.214596</td>
      <td>0.898774</td>
      <td>0.597468</td>
      <td>0.758360</td>
      <td>-0.065672</td>
      <td>0.990745</td>
      <td>-0.202161</td>
      <td>0.126054</td>
      <td>1.032540</td>
      <td>-0.964703</td>
      <td>-0.710145</td>
      <td>-0.727454</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.189066</td>
      <td>-0.428374</td>
      <td>-0.399145</td>
      <td>-1.017518</td>
      <td>0.254966</td>
      <td>-0.501888</td>
      <td>-0.326554</td>
      <td>0.014144</td>
      <td>-0.984840</td>
      <td>0.743699</td>
      <td>0.574956</td>
      <td>-0.691503</td>
      <td>-0.628223</td>
      <td>-0.360955</td>
      <td>-0.486778</td>
      <td>0.548230</td>
      <td>0.476385</td>
      <td>1.136939</td>
      <td>0.605530</td>
      <td>1.075939</td>
      <td>0.473627</td>
      <td>0.587841</td>
      <td>0.963618</td>
      <td>0.771497</td>
      <td>1.068993</td>
      <td>-0.077888</td>
      <td>0.217799</td>
      <td>-0.656672</td>
      <td>0.617498</td>
      <td>-0.452616</td>
      <td>0.414055</td>
      <td>0.853895</td>
      <td>0.507828</td>
      <td>-0.568844</td>
      <td>-0.149295</td>
      <td>-0.322194</td>
      <td>-0.153514</td>
      <td>-0.219508</td>
      <td>-0.452385</td>
      <td>-0.075698</td>
      <td>...</td>
      <td>-0.281237</td>
      <td>-0.071320</td>
      <td>-0.309183</td>
      <td>-0.193552</td>
      <td>0.252606</td>
      <td>0.072286</td>
      <td>0.267600</td>
      <td>0.603689</td>
      <td>0.842525</td>
      <td>0.324771</td>
      <td>-0.155376</td>
      <td>1.397875</td>
      <td>1.542228</td>
      <td>-0.410330</td>
      <td>-1.476370</td>
      <td>1.260341</td>
      <td>0.723215</td>
      <td>-0.902524</td>
      <td>0.036967</td>
      <td>0.878925</td>
      <td>-0.873050</td>
      <td>0.148091</td>
      <td>1.009817</td>
      <td>-0.044593</td>
      <td>-0.357701</td>
      <td>-0.551303</td>
      <td>1.342649</td>
      <td>-0.006829</td>
      <td>-0.622077</td>
      <td>0.215438</td>
      <td>0.737672</td>
      <td>0.491544</td>
      <td>-0.155500</td>
      <td>-0.245370</td>
      <td>-0.542698</td>
      <td>0.577060</td>
      <td>1.047933</td>
      <td>-1.179270</td>
      <td>-0.814961</td>
      <td>-0.177730</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-0.543648</td>
      <td>-0.029129</td>
      <td>-1.179477</td>
      <td>0.340196</td>
      <td>0.364259</td>
      <td>-0.369727</td>
      <td>-0.891751</td>
      <td>1.084417</td>
      <td>0.759659</td>
      <td>0.474098</td>
      <td>0.862240</td>
      <td>-0.690131</td>
      <td>-0.049408</td>
      <td>0.728900</td>
      <td>0.051144</td>
      <td>0.748855</td>
      <td>-0.013014</td>
      <td>0.009764</td>
      <td>-0.021383</td>
      <td>0.853645</td>
      <td>-0.240342</td>
      <td>0.579178</td>
      <td>1.069790</td>
      <td>0.608395</td>
      <td>0.168259</td>
      <td>0.368026</td>
      <td>0.912800</td>
      <td>0.490035</td>
      <td>-0.677442</td>
      <td>-0.675517</td>
      <td>-0.658155</td>
      <td>-0.203494</td>
      <td>0.216682</td>
      <td>0.132932</td>
      <td>-0.931632</td>
      <td>0.019868</td>
      <td>0.249648</td>
      <td>-0.547902</td>
      <td>-1.006525</td>
      <td>-1.624307</td>
      <td>...</td>
      <td>0.220994</td>
      <td>0.399497</td>
      <td>-0.390379</td>
      <td>1.336275</td>
      <td>0.583290</td>
      <td>0.236330</td>
      <td>-0.940847</td>
      <td>0.155551</td>
      <td>-0.923936</td>
      <td>-0.656852</td>
      <td>-0.307535</td>
      <td>-0.765742</td>
      <td>-0.508797</td>
      <td>-0.343870</td>
      <td>-0.405891</td>
      <td>-1.037207</td>
      <td>0.743758</td>
      <td>0.037062</td>
      <td>0.540770</td>
      <td>0.098548</td>
      <td>0.092604</td>
      <td>0.825427</td>
      <td>0.525879</td>
      <td>-0.389485</td>
      <td>-0.158821</td>
      <td>-0.201108</td>
      <td>0.172491</td>
      <td>0.076678</td>
      <td>0.799736</td>
      <td>-0.462659</td>
      <td>0.572020</td>
      <td>0.442714</td>
      <td>0.447119</td>
      <td>0.521845</td>
      <td>-0.372672</td>
      <td>-0.407528</td>
      <td>-0.208014</td>
      <td>0.049251</td>
      <td>-0.944691</td>
      <td>-0.598639</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-0.383960</td>
      <td>-0.261289</td>
      <td>1.050991</td>
      <td>0.106508</td>
      <td>0.084950</td>
      <td>-0.355004</td>
      <td>-0.391152</td>
      <td>0.943988</td>
      <td>0.509524</td>
      <td>0.555912</td>
      <td>0.164201</td>
      <td>-0.683454</td>
      <td>-0.284540</td>
      <td>0.812769</td>
      <td>0.269764</td>
      <td>-0.494944</td>
      <td>0.401281</td>
      <td>0.850635</td>
      <td>1.128491</td>
      <td>-0.074843</td>
      <td>-0.777300</td>
      <td>-0.005563</td>
      <td>-0.190166</td>
      <td>0.495736</td>
      <td>0.366387</td>
      <td>0.378394</td>
      <td>0.588479</td>
      <td>0.422678</td>
      <td>-0.309641</td>
      <td>-0.588815</td>
      <td>0.741626</td>
      <td>0.653058</td>
      <td>0.177381</td>
      <td>-0.538171</td>
      <td>-0.672076</td>
      <td>-1.128562</td>
      <td>-0.756601</td>
      <td>-0.725849</td>
      <td>0.036471</td>
      <td>-0.077819</td>
      <td>...</td>
      <td>0.818838</td>
      <td>-0.629116</td>
      <td>0.001937</td>
      <td>1.060700</td>
      <td>0.529385</td>
      <td>-0.149274</td>
      <td>-1.222549</td>
      <td>-0.049547</td>
      <td>-0.753854</td>
      <td>0.196210</td>
      <td>-0.436549</td>
      <td>0.121904</td>
      <td>-0.551686</td>
      <td>-0.028998</td>
      <td>0.581768</td>
      <td>0.195714</td>
      <td>-0.112656</td>
      <td>-0.672607</td>
      <td>0.464429</td>
      <td>-0.611349</td>
      <td>0.370642</td>
      <td>0.277985</td>
      <td>0.409950</td>
      <td>0.162159</td>
      <td>1.001314</td>
      <td>0.691723</td>
      <td>0.336249</td>
      <td>-0.173654</td>
      <td>1.298856</td>
      <td>0.417639</td>
      <td>-0.462238</td>
      <td>0.580736</td>
      <td>-0.225215</td>
      <td>-0.095535</td>
      <td>-1.769108</td>
      <td>-0.464589</td>
      <td>0.473533</td>
      <td>-0.019081</td>
      <td>-0.637596</td>
      <td>-0.253995</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.245090</td>
      <td>-1.198800</td>
      <td>-0.167524</td>
      <td>0.464972</td>
      <td>0.690472</td>
      <td>-0.599908</td>
      <td>-0.508754</td>
      <td>-0.259802</td>
      <td>-0.088637</td>
      <td>-0.477947</td>
      <td>-0.100189</td>
      <td>0.877829</td>
      <td>-0.543541</td>
      <td>-0.165986</td>
      <td>-1.072534</td>
      <td>-0.872576</td>
      <td>0.555190</td>
      <td>0.608049</td>
      <td>-0.470080</td>
      <td>0.187370</td>
      <td>0.875706</td>
      <td>0.083523</td>
      <td>0.188001</td>
      <td>0.094018</td>
      <td>0.404397</td>
      <td>-0.512130</td>
      <td>-0.474336</td>
      <td>-0.092256</td>
      <td>0.512003</td>
      <td>-1.169054</td>
      <td>0.203553</td>
      <td>0.050195</td>
      <td>-1.159847</td>
      <td>-0.841729</td>
      <td>-1.291877</td>
      <td>-0.404508</td>
      <td>-0.632075</td>
      <td>-0.000621</td>
      <td>0.595964</td>
      <td>0.167019</td>
      <td>...</td>
      <td>0.463113</td>
      <td>0.550447</td>
      <td>-0.334971</td>
      <td>-0.190519</td>
      <td>-0.192045</td>
      <td>0.048098</td>
      <td>0.022735</td>
      <td>-0.500401</td>
      <td>0.143892</td>
      <td>0.317063</td>
      <td>0.107681</td>
      <td>0.503221</td>
      <td>-0.135999</td>
      <td>0.208050</td>
      <td>-0.887198</td>
      <td>-0.374502</td>
      <td>0.133596</td>
      <td>-0.133160</td>
      <td>-0.997713</td>
      <td>-0.520756</td>
      <td>-0.661480</td>
      <td>0.613381</td>
      <td>0.486195</td>
      <td>0.900926</td>
      <td>-0.581202</td>
      <td>-0.484980</td>
      <td>-0.408934</td>
      <td>-1.505373</td>
      <td>-0.480379</td>
      <td>0.545186</td>
      <td>0.839434</td>
      <td>1.221728</td>
      <td>1.310406</td>
      <td>0.681301</td>
      <td>0.040724</td>
      <td>0.550766</td>
      <td>1.341607</td>
      <td>-2.905878</td>
      <td>-0.866893</td>
      <td>-0.317721</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.252768</td>
      <td>0.544524</td>
      <td>0.356304</td>
      <td>0.362041</td>
      <td>-1.117987</td>
      <td>-0.894044</td>
      <td>1.134879</td>
      <td>-0.033828</td>
      <td>0.356644</td>
      <td>0.341335</td>
      <td>-0.150623</td>
      <td>-1.280844</td>
      <td>-1.090516</td>
      <td>0.729499</td>
      <td>0.260772</td>
      <td>-0.281919</td>
      <td>-1.050721</td>
      <td>0.414058</td>
      <td>-0.420729</td>
      <td>-0.225719</td>
      <td>-0.427057</td>
      <td>0.455847</td>
      <td>0.245726</td>
      <td>0.420310</td>
      <td>0.902382</td>
      <td>-0.670199</td>
      <td>-0.467574</td>
      <td>0.818483</td>
      <td>-0.231304</td>
      <td>-1.156477</td>
      <td>-0.783004</td>
      <td>0.160499</td>
      <td>-0.401807</td>
      <td>1.063239</td>
      <td>0.631889</td>
      <td>0.422919</td>
      <td>0.833670</td>
      <td>-0.288717</td>
      <td>-0.636072</td>
      <td>-0.161978</td>
      <td>...</td>
      <td>1.279828</td>
      <td>0.347987</td>
      <td>-0.297847</td>
      <td>0.753900</td>
      <td>1.149078</td>
      <td>0.122124</td>
      <td>-1.157166</td>
      <td>-0.248396</td>
      <td>-0.290899</td>
      <td>-0.786659</td>
      <td>0.298071</td>
      <td>0.744688</td>
      <td>0.504332</td>
      <td>-0.829184</td>
      <td>-0.231056</td>
      <td>-0.190790</td>
      <td>0.622427</td>
      <td>0.605684</td>
      <td>0.029921</td>
      <td>0.152849</td>
      <td>0.280840</td>
      <td>0.761520</td>
      <td>0.503202</td>
      <td>-0.120848</td>
      <td>0.351310</td>
      <td>0.224476</td>
      <td>0.228470</td>
      <td>-0.231240</td>
      <td>-0.073884</td>
      <td>0.820209</td>
      <td>-0.211718</td>
      <td>1.168227</td>
      <td>0.457077</td>
      <td>1.101332</td>
      <td>0.013782</td>
      <td>-0.214581</td>
      <td>0.303581</td>
      <td>1.996646</td>
      <td>0.860123</td>
      <td>0.193729</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.979678</td>
      <td>1.110645</td>
      <td>0.106262</td>
      <td>0.199611</td>
      <td>-0.110649</td>
      <td>0.690374</td>
      <td>0.198886</td>
      <td>0.547882</td>
      <td>1.942514</td>
      <td>1.033112</td>
      <td>-0.404630</td>
      <td>-1.021213</td>
      <td>-0.451201</td>
      <td>0.693646</td>
      <td>-0.647671</td>
      <td>0.511050</td>
      <td>-0.102057</td>
      <td>0.263518</td>
      <td>-0.546440</td>
      <td>-0.215433</td>
      <td>0.873501</td>
      <td>-0.233164</td>
      <td>0.521183</td>
      <td>0.372287</td>
      <td>-0.544204</td>
      <td>-0.918885</td>
      <td>-0.153557</td>
      <td>-0.074520</td>
      <td>-0.038169</td>
      <td>-0.011998</td>
      <td>-1.037211</td>
      <td>0.253826</td>
      <td>1.012143</td>
      <td>-0.009737</td>
      <td>-0.194073</td>
      <td>0.209205</td>
      <td>-0.108661</td>
      <td>-0.221600</td>
      <td>-0.894943</td>
      <td>-0.255151</td>
      <td>...</td>
      <td>-0.217213</td>
      <td>0.706564</td>
      <td>-0.506830</td>
      <td>0.269172</td>
      <td>1.009492</td>
      <td>-0.659756</td>
      <td>-0.746270</td>
      <td>-0.531067</td>
      <td>-1.661024</td>
      <td>-0.829945</td>
      <td>0.272738</td>
      <td>-0.035157</td>
      <td>-0.736351</td>
      <td>0.247566</td>
      <td>0.012294</td>
      <td>-0.724821</td>
      <td>-0.026111</td>
      <td>0.264311</td>
      <td>-0.613165</td>
      <td>-0.741682</td>
      <td>0.331178</td>
      <td>-0.646141</td>
      <td>0.455916</td>
      <td>0.610482</td>
      <td>-0.138480</td>
      <td>-0.007179</td>
      <td>0.382464</td>
      <td>-0.224266</td>
      <td>-0.077901</td>
      <td>0.229808</td>
      <td>0.513010</td>
      <td>0.157077</td>
      <td>1.415550</td>
      <td>1.635609</td>
      <td>0.805400</td>
      <td>1.200147</td>
      <td>1.239894</td>
      <td>-2.568244</td>
      <td>-1.519798</td>
      <td>-0.757827</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.359547</td>
      <td>1.177740</td>
      <td>0.175811</td>
      <td>0.423957</td>
      <td>-1.268367</td>
      <td>-1.234802</td>
      <td>0.311581</td>
      <td>-0.145983</td>
      <td>0.866582</td>
      <td>0.912280</td>
      <td>0.471423</td>
      <td>-0.107135</td>
      <td>-0.097727</td>
      <td>0.597025</td>
      <td>-0.794723</td>
      <td>-0.492106</td>
      <td>-0.506225</td>
      <td>0.744713</td>
      <td>0.808055</td>
      <td>0.143099</td>
      <td>0.087405</td>
      <td>0.002002</td>
      <td>0.133613</td>
      <td>0.767124</td>
      <td>1.042247</td>
      <td>0.988528</td>
      <td>-0.071854</td>
      <td>0.869486</td>
      <td>0.413987</td>
      <td>-0.820651</td>
      <td>-1.212853</td>
      <td>0.904902</td>
      <td>0.753585</td>
      <td>-0.008181</td>
      <td>0.136296</td>
      <td>0.330669</td>
      <td>-0.301604</td>
      <td>-0.297835</td>
      <td>0.045707</td>
      <td>-0.005666</td>
      <td>...</td>
      <td>-0.009953</td>
      <td>0.209081</td>
      <td>-0.086010</td>
      <td>0.286157</td>
      <td>-0.123087</td>
      <td>-0.759085</td>
      <td>-0.481205</td>
      <td>0.063327</td>
      <td>-0.825814</td>
      <td>-0.486017</td>
      <td>0.623279</td>
      <td>0.704880</td>
      <td>0.739376</td>
      <td>1.271093</td>
      <td>-0.833799</td>
      <td>-0.510746</td>
      <td>-0.339868</td>
      <td>-0.554336</td>
      <td>0.593217</td>
      <td>-0.639835</td>
      <td>0.887435</td>
      <td>-0.008299</td>
      <td>-0.163009</td>
      <td>-1.714060</td>
      <td>-0.376772</td>
      <td>-0.805986</td>
      <td>-0.112740</td>
      <td>-0.679625</td>
      <td>0.155354</td>
      <td>0.751099</td>
      <td>0.306195</td>
      <td>0.202354</td>
      <td>0.174144</td>
      <td>0.552567</td>
      <td>-0.406987</td>
      <td>-1.040083</td>
      <td>-0.788461</td>
      <td>-0.389877</td>
      <td>-0.643054</td>
      <td>0.080892</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.558290</td>
      <td>0.310203</td>
      <td>1.513651</td>
      <td>0.674377</td>
      <td>-0.732340</td>
      <td>-1.219175</td>
      <td>-0.277014</td>
      <td>-0.128976</td>
      <td>0.266891</td>
      <td>0.549370</td>
      <td>-0.287899</td>
      <td>-1.190396</td>
      <td>-0.300813</td>
      <td>0.924723</td>
      <td>-0.299205</td>
      <td>-0.565633</td>
      <td>0.649251</td>
      <td>-0.710446</td>
      <td>0.121795</td>
      <td>0.838229</td>
      <td>-0.009345</td>
      <td>-0.939528</td>
      <td>-0.669787</td>
      <td>-0.466546</td>
      <td>0.993197</td>
      <td>-0.512032</td>
      <td>0.582427</td>
      <td>-0.323075</td>
      <td>-0.542860</td>
      <td>-0.004993</td>
      <td>0.898062</td>
      <td>1.126861</td>
      <td>0.714202</td>
      <td>0.380407</td>
      <td>-0.136491</td>
      <td>-0.537059</td>
      <td>-0.799156</td>
      <td>-1.003733</td>
      <td>0.018972</td>
      <td>-0.028438</td>
      <td>...</td>
      <td>-0.764043</td>
      <td>0.212304</td>
      <td>0.747395</td>
      <td>0.578169</td>
      <td>0.606220</td>
      <td>-0.267511</td>
      <td>-0.330406</td>
      <td>1.199636</td>
      <td>-0.550737</td>
      <td>-0.090245</td>
      <td>-0.606760</td>
      <td>-0.140452</td>
      <td>0.685188</td>
      <td>-0.954090</td>
      <td>0.090397</td>
      <td>0.415437</td>
      <td>0.625926</td>
      <td>-0.901052</td>
      <td>-0.831317</td>
      <td>-0.872672</td>
      <td>-0.167450</td>
      <td>0.309816</td>
      <td>0.861383</td>
      <td>0.345679</td>
      <td>-0.283629</td>
      <td>-0.869244</td>
      <td>0.545538</td>
      <td>-0.900779</td>
      <td>-0.190185</td>
      <td>1.317326</td>
      <td>1.235944</td>
      <td>0.008711</td>
      <td>-0.091014</td>
      <td>-0.035050</td>
      <td>-0.257166</td>
      <td>0.478476</td>
      <td>1.685199</td>
      <td>-0.789850</td>
      <td>-0.209110</td>
      <td>0.010337</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.537152</td>
      <td>0.016910</td>
      <td>0.603356</td>
      <td>-0.040197</td>
      <td>-0.926787</td>
      <td>-0.942000</td>
      <td>-0.267536</td>
      <td>0.093135</td>
      <td>0.211142</td>
      <td>0.565189</td>
      <td>0.132249</td>
      <td>0.095259</td>
      <td>0.145670</td>
      <td>0.550700</td>
      <td>-0.238471</td>
      <td>1.035610</td>
      <td>0.242791</td>
      <td>0.339878</td>
      <td>-0.224658</td>
      <td>0.012559</td>
      <td>0.229860</td>
      <td>0.946837</td>
      <td>0.867049</td>
      <td>0.100652</td>
      <td>-0.239665</td>
      <td>0.011125</td>
      <td>0.457593</td>
      <td>0.388956</td>
      <td>-0.039679</td>
      <td>-0.037824</td>
      <td>0.792303</td>
      <td>0.592928</td>
      <td>0.380021</td>
      <td>0.321190</td>
      <td>-0.811611</td>
      <td>-0.990343</td>
      <td>-0.290912</td>
      <td>-0.560080</td>
      <td>0.276612</td>
      <td>-0.203922</td>
      <td>...</td>
      <td>1.549374</td>
      <td>0.195712</td>
      <td>0.004990</td>
      <td>-0.792791</td>
      <td>0.616826</td>
      <td>0.533043</td>
      <td>0.177063</td>
      <td>-0.340935</td>
      <td>0.054899</td>
      <td>-1.494964</td>
      <td>0.107369</td>
      <td>0.223848</td>
      <td>0.079351</td>
      <td>0.301559</td>
      <td>0.426764</td>
      <td>0.519090</td>
      <td>0.751832</td>
      <td>1.109553</td>
      <td>0.687918</td>
      <td>0.244980</td>
      <td>0.294510</td>
      <td>0.327724</td>
      <td>0.185734</td>
      <td>-0.347980</td>
      <td>-0.591497</td>
      <td>-1.065356</td>
      <td>0.823568</td>
      <td>-0.498202</td>
      <td>-0.497781</td>
      <td>0.024507</td>
      <td>0.279106</td>
      <td>1.573331</td>
      <td>0.606679</td>
      <td>0.641044</td>
      <td>-0.300035</td>
      <td>-0.651494</td>
      <td>-0.129185</td>
      <td>1.706710</td>
      <td>0.906249</td>
      <td>0.560855</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.861985</td>
      <td>-0.464048</td>
      <td>0.395332</td>
      <td>0.119984</td>
      <td>0.770102</td>
      <td>-0.123082</td>
      <td>1.403805</td>
      <td>0.400131</td>
      <td>1.186875</td>
      <td>0.842793</td>
      <td>0.417158</td>
      <td>0.003000</td>
      <td>-0.129266</td>
      <td>-0.844446</td>
      <td>0.273365</td>
      <td>0.331035</td>
      <td>-0.003999</td>
      <td>0.356094</td>
      <td>0.576749</td>
      <td>-0.597137</td>
      <td>0.338864</td>
      <td>0.748836</td>
      <td>-0.390887</td>
      <td>-0.500934</td>
      <td>-0.548946</td>
      <td>0.368786</td>
      <td>0.012927</td>
      <td>-0.196223</td>
      <td>0.645664</td>
      <td>-0.289254</td>
      <td>0.640493</td>
      <td>-0.273840</td>
      <td>0.454607</td>
      <td>0.666044</td>
      <td>0.766399</td>
      <td>-0.334161</td>
      <td>-0.483508</td>
      <td>-1.113152</td>
      <td>-0.911108</td>
      <td>-1.147181</td>
      <td>...</td>
      <td>0.499517</td>
      <td>-0.234066</td>
      <td>0.234641</td>
      <td>0.933096</td>
      <td>0.305271</td>
      <td>0.143889</td>
      <td>0.250913</td>
      <td>0.393294</td>
      <td>-1.062634</td>
      <td>0.225518</td>
      <td>0.642449</td>
      <td>0.109617</td>
      <td>-0.243064</td>
      <td>-0.437701</td>
      <td>0.812387</td>
      <td>-0.469281</td>
      <td>0.827767</td>
      <td>0.322843</td>
      <td>-0.418658</td>
      <td>-1.042425</td>
      <td>1.027265</td>
      <td>0.565195</td>
      <td>1.211491</td>
      <td>0.478922</td>
      <td>-0.699772</td>
      <td>-0.752349</td>
      <td>-1.171510</td>
      <td>0.249694</td>
      <td>0.827902</td>
      <td>1.381513</td>
      <td>0.844848</td>
      <td>0.720548</td>
      <td>0.926301</td>
      <td>-0.079783</td>
      <td>0.256026</td>
      <td>-0.031753</td>
      <td>0.609917</td>
      <td>-1.993825</td>
      <td>-1.385189</td>
      <td>-0.976506</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.996098</td>
      <td>0.301863</td>
      <td>-0.788699</td>
      <td>0.110141</td>
      <td>0.389204</td>
      <td>-0.796612</td>
      <td>-0.277444</td>
      <td>0.534236</td>
      <td>0.267412</td>
      <td>0.569580</td>
      <td>-0.437121</td>
      <td>-1.490032</td>
      <td>-0.195318</td>
      <td>0.646858</td>
      <td>-0.081758</td>
      <td>0.277695</td>
      <td>0.282307</td>
      <td>-0.415048</td>
      <td>0.561091</td>
      <td>0.920322</td>
      <td>0.156772</td>
      <td>0.540281</td>
      <td>0.517651</td>
      <td>0.473375</td>
      <td>1.121567</td>
      <td>-0.070941</td>
      <td>0.611822</td>
      <td>-0.060862</td>
      <td>0.133114</td>
      <td>-0.396101</td>
      <td>-0.019180</td>
      <td>-0.065062</td>
      <td>-0.022866</td>
      <td>-0.832271</td>
      <td>-0.228658</td>
      <td>-0.394645</td>
      <td>0.242433</td>
      <td>0.900019</td>
      <td>-1.542406</td>
      <td>-0.958121</td>
      <td>...</td>
      <td>0.234640</td>
      <td>0.369989</td>
      <td>0.150026</td>
      <td>0.726096</td>
      <td>0.504371</td>
      <td>-0.892824</td>
      <td>0.042353</td>
      <td>0.033121</td>
      <td>-1.221272</td>
      <td>0.437389</td>
      <td>1.052090</td>
      <td>-0.131917</td>
      <td>-0.118136</td>
      <td>0.383770</td>
      <td>0.021144</td>
      <td>0.343423</td>
      <td>0.348602</td>
      <td>-0.100365</td>
      <td>-0.529147</td>
      <td>0.771803</td>
      <td>-0.211410</td>
      <td>-0.534743</td>
      <td>0.057935</td>
      <td>-0.301342</td>
      <td>-1.114829</td>
      <td>-1.252305</td>
      <td>-0.713340</td>
      <td>-0.675120</td>
      <td>-0.207143</td>
      <td>-0.145923</td>
      <td>0.668526</td>
      <td>0.230153</td>
      <td>0.107776</td>
      <td>-0.908271</td>
      <td>-0.420587</td>
      <td>0.585768</td>
      <td>0.815656</td>
      <td>0.998582</td>
      <td>0.493341</td>
      <td>-0.301398</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.161491</td>
      <td>0.769873</td>
      <td>-0.286527</td>
      <td>0.623804</td>
      <td>0.808732</td>
      <td>0.420763</td>
      <td>1.408304</td>
      <td>0.379724</td>
      <td>0.225349</td>
      <td>-0.996664</td>
      <td>-0.316621</td>
      <td>-0.941447</td>
      <td>-0.195449</td>
      <td>-0.187215</td>
      <td>-0.634952</td>
      <td>-0.607303</td>
      <td>-0.465450</td>
      <td>-0.224604</td>
      <td>-0.439034</td>
      <td>-1.176373</td>
      <td>0.576712</td>
      <td>0.696913</td>
      <td>0.573160</td>
      <td>0.199551</td>
      <td>-0.236168</td>
      <td>1.142571</td>
      <td>0.150108</td>
      <td>-0.326722</td>
      <td>-0.523859</td>
      <td>0.285514</td>
      <td>-1.296894</td>
      <td>-0.013946</td>
      <td>-0.216755</td>
      <td>-0.497046</td>
      <td>0.092793</td>
      <td>0.629410</td>
      <td>0.276716</td>
      <td>0.472742</td>
      <td>-1.024427</td>
      <td>-0.146733</td>
      <td>...</td>
      <td>0.350020</td>
      <td>-0.642797</td>
      <td>0.096035</td>
      <td>-0.588592</td>
      <td>-0.014609</td>
      <td>-0.034794</td>
      <td>-0.108934</td>
      <td>0.055356</td>
      <td>0.010593</td>
      <td>-0.456210</td>
      <td>0.094279</td>
      <td>0.204923</td>
      <td>-0.160558</td>
      <td>1.084860</td>
      <td>0.273291</td>
      <td>0.508421</td>
      <td>-0.334605</td>
      <td>0.506485</td>
      <td>0.274448</td>
      <td>-0.278388</td>
      <td>-0.481030</td>
      <td>-0.659463</td>
      <td>-0.796498</td>
      <td>0.194015</td>
      <td>0.182717</td>
      <td>0.173755</td>
      <td>-1.347421</td>
      <td>-0.831508</td>
      <td>-0.898465</td>
      <td>-1.033131</td>
      <td>-0.397126</td>
      <td>-0.399196</td>
      <td>0.093960</td>
      <td>1.156172</td>
      <td>1.299681</td>
      <td>-1.098005</td>
      <td>-0.131024</td>
      <td>0.940009</td>
      <td>0.467504</td>
      <td>-0.158586</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.261080</td>
      <td>-0.407925</td>
      <td>0.228405</td>
      <td>0.079352</td>
      <td>0.474241</td>
      <td>0.813416</td>
      <td>0.177506</td>
      <td>-0.140716</td>
      <td>-0.475060</td>
      <td>-1.016407</td>
      <td>-0.044260</td>
      <td>-0.738727</td>
      <td>-0.709887</td>
      <td>-0.515100</td>
      <td>-0.365554</td>
      <td>0.462756</td>
      <td>0.503823</td>
      <td>0.225303</td>
      <td>-0.416866</td>
      <td>-0.118601</td>
      <td>0.645205</td>
      <td>-0.740377</td>
      <td>-0.546440</td>
      <td>-0.039381</td>
      <td>0.617452</td>
      <td>-0.031837</td>
      <td>-0.106106</td>
      <td>0.394789</td>
      <td>-0.630260</td>
      <td>0.487267</td>
      <td>-1.319273</td>
      <td>-0.217474</td>
      <td>0.627845</td>
      <td>0.274974</td>
      <td>-0.807810</td>
      <td>0.159702</td>
      <td>-1.257060</td>
      <td>-0.512856</td>
      <td>-0.522364</td>
      <td>-0.242426</td>
      <td>...</td>
      <td>0.894068</td>
      <td>-0.343863</td>
      <td>0.313056</td>
      <td>-0.342961</td>
      <td>-0.185526</td>
      <td>-0.354038</td>
      <td>-0.150352</td>
      <td>-0.448460</td>
      <td>-0.429546</td>
      <td>0.681018</td>
      <td>-0.063740</td>
      <td>-0.076847</td>
      <td>-1.984392</td>
      <td>0.108784</td>
      <td>-0.057414</td>
      <td>0.037880</td>
      <td>0.510627</td>
      <td>-0.255068</td>
      <td>-0.027589</td>
      <td>-0.020890</td>
      <td>0.455338</td>
      <td>-1.113212</td>
      <td>0.044171</td>
      <td>0.397366</td>
      <td>0.619187</td>
      <td>-0.332447</td>
      <td>-0.209276</td>
      <td>0.126021</td>
      <td>0.889640</td>
      <td>0.120641</td>
      <td>0.548849</td>
      <td>0.064570</td>
      <td>-0.776178</td>
      <td>0.098492</td>
      <td>1.100076</td>
      <td>0.159496</td>
      <td>-0.135612</td>
      <td>-1.020680</td>
      <td>-1.497130</td>
      <td>-1.119159</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.863860</td>
      <td>-0.947581</td>
      <td>0.531513</td>
      <td>0.398182</td>
      <td>0.169507</td>
      <td>-0.574401</td>
      <td>0.679939</td>
      <td>0.477222</td>
      <td>0.315870</td>
      <td>0.031230</td>
      <td>0.055676</td>
      <td>0.207738</td>
      <td>-0.334483</td>
      <td>0.345889</td>
      <td>-0.314530</td>
      <td>0.006188</td>
      <td>0.815937</td>
      <td>-0.441044</td>
      <td>-0.243897</td>
      <td>-0.537462</td>
      <td>-0.048660</td>
      <td>0.657676</td>
      <td>-0.121467</td>
      <td>0.699270</td>
      <td>0.844667</td>
      <td>1.042802</td>
      <td>0.997392</td>
      <td>-0.498050</td>
      <td>-0.334784</td>
      <td>0.697235</td>
      <td>0.661462</td>
      <td>0.332928</td>
      <td>0.608864</td>
      <td>0.467459</td>
      <td>-0.038432</td>
      <td>0.019710</td>
      <td>0.368251</td>
      <td>0.074281</td>
      <td>0.340581</td>
      <td>0.092507</td>
      <td>...</td>
      <td>-0.817532</td>
      <td>0.992412</td>
      <td>0.087254</td>
      <td>-0.311102</td>
      <td>0.672719</td>
      <td>-0.241013</td>
      <td>-0.530264</td>
      <td>0.023163</td>
      <td>0.548766</td>
      <td>-0.475288</td>
      <td>0.429934</td>
      <td>-0.600212</td>
      <td>-0.750723</td>
      <td>-0.164218</td>
      <td>-0.591037</td>
      <td>0.325072</td>
      <td>-0.145292</td>
      <td>0.132932</td>
      <td>-0.509499</td>
      <td>-0.891856</td>
      <td>-0.250113</td>
      <td>-0.478371</td>
      <td>0.466575</td>
      <td>-0.263989</td>
      <td>-0.444016</td>
      <td>-0.328893</td>
      <td>-0.416199</td>
      <td>-0.548155</td>
      <td>0.379435</td>
      <td>0.446487</td>
      <td>0.743417</td>
      <td>0.958120</td>
      <td>0.072440</td>
      <td>0.835844</td>
      <td>1.282703</td>
      <td>0.262876</td>
      <td>0.261013</td>
      <td>0.254383</td>
      <td>0.543584</td>
      <td>-0.415291</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.689813</td>
      <td>-0.293969</td>
      <td>-1.165060</td>
      <td>0.492934</td>
      <td>0.158729</td>
      <td>0.765361</td>
      <td>1.069328</td>
      <td>-0.519082</td>
      <td>0.667176</td>
      <td>0.855619</td>
      <td>1.698924</td>
      <td>0.247992</td>
      <td>-0.870159</td>
      <td>-0.128382</td>
      <td>-0.511360</td>
      <td>0.661798</td>
      <td>-0.951209</td>
      <td>-0.849440</td>
      <td>-0.745559</td>
      <td>-0.529517</td>
      <td>0.889067</td>
      <td>-0.177309</td>
      <td>0.604840</td>
      <td>0.853521</td>
      <td>1.360015</td>
      <td>0.447945</td>
      <td>-0.324091</td>
      <td>-1.079465</td>
      <td>-1.060269</td>
      <td>-0.227501</td>
      <td>-0.054827</td>
      <td>-0.157901</td>
      <td>-0.792824</td>
      <td>0.472867</td>
      <td>-0.282985</td>
      <td>-0.248946</td>
      <td>-0.783917</td>
      <td>0.514361</td>
      <td>-0.688219</td>
      <td>0.434068</td>
      <td>...</td>
      <td>-0.522113</td>
      <td>-0.342330</td>
      <td>-0.146771</td>
      <td>0.960055</td>
      <td>0.044690</td>
      <td>-0.282446</td>
      <td>0.901185</td>
      <td>-0.031656</td>
      <td>-0.464797</td>
      <td>-0.991797</td>
      <td>-0.248901</td>
      <td>0.219501</td>
      <td>-0.622395</td>
      <td>-0.091417</td>
      <td>-0.691180</td>
      <td>0.369749</td>
      <td>0.628122</td>
      <td>0.703453</td>
      <td>0.505945</td>
      <td>-0.586178</td>
      <td>0.583133</td>
      <td>0.329674</td>
      <td>-0.005003</td>
      <td>-0.335716</td>
      <td>0.083984</td>
      <td>0.436833</td>
      <td>-0.002247</td>
      <td>-1.166280</td>
      <td>-1.361654</td>
      <td>-0.962619</td>
      <td>0.135512</td>
      <td>-0.058031</td>
      <td>0.575132</td>
      <td>0.152737</td>
      <td>0.327062</td>
      <td>-0.860296</td>
      <td>-0.453935</td>
      <td>-1.256773</td>
      <td>-1.251077</td>
      <td>-0.584609</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.413369</td>
      <td>0.419524</td>
      <td>-0.425227</td>
      <td>0.327634</td>
      <td>0.303412</td>
      <td>-0.301648</td>
      <td>0.793039</td>
      <td>0.175619</td>
      <td>-0.502963</td>
      <td>-0.494265</td>
      <td>-0.022329</td>
      <td>-0.404583</td>
      <td>-0.151879</td>
      <td>0.757560</td>
      <td>0.112200</td>
      <td>0.756401</td>
      <td>0.571464</td>
      <td>0.310164</td>
      <td>-0.024686</td>
      <td>-0.298676</td>
      <td>1.144756</td>
      <td>0.155111</td>
      <td>0.351905</td>
      <td>-0.061196</td>
      <td>0.124584</td>
      <td>-0.108354</td>
      <td>-0.470343</td>
      <td>-0.526227</td>
      <td>-0.672616</td>
      <td>0.990918</td>
      <td>0.712254</td>
      <td>1.043708</td>
      <td>-0.378692</td>
      <td>0.401522</td>
      <td>-0.666609</td>
      <td>0.119907</td>
      <td>0.691517</td>
      <td>1.267903</td>
      <td>-1.061711</td>
      <td>-0.155296</td>
      <td>...</td>
      <td>-0.263816</td>
      <td>-0.072991</td>
      <td>-0.000756</td>
      <td>-0.337973</td>
      <td>0.889812</td>
      <td>-0.266771</td>
      <td>0.013077</td>
      <td>0.403952</td>
      <td>0.760705</td>
      <td>-0.645873</td>
      <td>0.242827</td>
      <td>0.102788</td>
      <td>-1.402807</td>
      <td>0.229234</td>
      <td>0.321256</td>
      <td>-0.111213</td>
      <td>0.143126</td>
      <td>-0.067321</td>
      <td>0.638595</td>
      <td>0.143857</td>
      <td>0.840240</td>
      <td>0.068539</td>
      <td>0.047061</td>
      <td>0.388665</td>
      <td>-0.682492</td>
      <td>-0.180106</td>
      <td>-0.692993</td>
      <td>-0.292220</td>
      <td>0.087837</td>
      <td>-0.245703</td>
      <td>0.795985</td>
      <td>1.082566</td>
      <td>1.480588</td>
      <td>1.704362</td>
      <td>0.780738</td>
      <td>-0.570817</td>
      <td>-0.372632</td>
      <td>3.470059</td>
      <td>1.651531</td>
      <td>0.633140</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 103 columns</p>
</div>
</div>
<br />
<br /></section>
<section id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f0f50057df0&gt;
</pre></div>
</div>
</section>
<section id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.122446  0.042387  26.481126  1.599083e-154  1.039369  1.205522
</pre></div>
</div>
</section>
<section id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<section id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</section>
<section id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  5.049 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>
</section>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.1e043a052b0af929e4d8.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>