
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.680215</td>
      <td>0.884597</td>
      <td>1.062722</td>
      <td>0.117027</td>
      <td>0.574970</td>
      <td>-0.123037</td>
      <td>0.657265</td>
      <td>-0.655689</td>
      <td>-0.627960</td>
      <td>0.138206</td>
      <td>0.094756</td>
      <td>0.182250</td>
      <td>-0.410998</td>
      <td>0.335416</td>
      <td>-0.149932</td>
      <td>-0.810162</td>
      <td>0.094746</td>
      <td>-0.003679</td>
      <td>-0.382969</td>
      <td>-0.275963</td>
      <td>0.817167</td>
      <td>-0.566514</td>
      <td>0.574941</td>
      <td>-0.067416</td>
      <td>-0.143305</td>
      <td>0.497130</td>
      <td>-0.742453</td>
      <td>-0.466876</td>
      <td>-0.293755</td>
      <td>0.989133</td>
      <td>-0.510912</td>
      <td>0.296905</td>
      <td>0.514258</td>
      <td>-0.970724</td>
      <td>-0.746166</td>
      <td>-1.074895</td>
      <td>0.088473</td>
      <td>-1.125692</td>
      <td>-2.358888</td>
      <td>0.435968</td>
      <td>...</td>
      <td>0.536403</td>
      <td>-0.731160</td>
      <td>0.076519</td>
      <td>-0.451705</td>
      <td>-0.681260</td>
      <td>-0.057544</td>
      <td>0.614974</td>
      <td>-0.134406</td>
      <td>0.500019</td>
      <td>0.297732</td>
      <td>1.033526</td>
      <td>1.318757</td>
      <td>-0.918786</td>
      <td>0.776750</td>
      <td>1.100316</td>
      <td>0.772898</td>
      <td>0.512620</td>
      <td>1.167801</td>
      <td>0.749504</td>
      <td>0.396255</td>
      <td>1.004453</td>
      <td>0.589504</td>
      <td>1.065966</td>
      <td>0.836838</td>
      <td>-0.601548</td>
      <td>-0.000638</td>
      <td>0.985571</td>
      <td>-0.034776</td>
      <td>-0.743898</td>
      <td>-0.527872</td>
      <td>0.929363</td>
      <td>0.288900</td>
      <td>0.159415</td>
      <td>-0.148238</td>
      <td>0.086527</td>
      <td>0.193014</td>
      <td>0.534369</td>
      <td>2.262951</td>
      <td>1.141952</td>
      <td>0.953075</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.778536</td>
      <td>0.163332</td>
      <td>-0.041228</td>
      <td>-1.021020</td>
      <td>-1.346047</td>
      <td>0.260521</td>
      <td>0.272368</td>
      <td>0.649837</td>
      <td>-0.783149</td>
      <td>0.481731</td>
      <td>-0.151762</td>
      <td>0.714081</td>
      <td>0.045103</td>
      <td>0.621087</td>
      <td>0.319566</td>
      <td>-0.587281</td>
      <td>0.095064</td>
      <td>-0.244516</td>
      <td>1.241062</td>
      <td>0.959134</td>
      <td>0.767511</td>
      <td>-0.361142</td>
      <td>-0.448847</td>
      <td>-1.227064</td>
      <td>-0.889165</td>
      <td>-0.638789</td>
      <td>0.305918</td>
      <td>-0.266563</td>
      <td>-0.306786</td>
      <td>-1.128630</td>
      <td>-0.771399</td>
      <td>0.354946</td>
      <td>0.477668</td>
      <td>0.122763</td>
      <td>0.525292</td>
      <td>-0.995400</td>
      <td>1.034370</td>
      <td>-0.530152</td>
      <td>-1.010722</td>
      <td>-0.707852</td>
      <td>...</td>
      <td>0.323396</td>
      <td>0.681707</td>
      <td>-0.068055</td>
      <td>-0.427351</td>
      <td>0.060036</td>
      <td>0.674636</td>
      <td>1.121132</td>
      <td>-0.069586</td>
      <td>0.195607</td>
      <td>0.073065</td>
      <td>0.862989</td>
      <td>0.000057</td>
      <td>0.483436</td>
      <td>0.093533</td>
      <td>0.035084</td>
      <td>-0.645134</td>
      <td>-0.199428</td>
      <td>-0.787609</td>
      <td>-0.515857</td>
      <td>-0.823100</td>
      <td>-0.578228</td>
      <td>0.918915</td>
      <td>0.962609</td>
      <td>-0.629170</td>
      <td>-0.229302</td>
      <td>1.155061</td>
      <td>0.657496</td>
      <td>0.234236</td>
      <td>-0.382587</td>
      <td>-1.349083</td>
      <td>-0.028203</td>
      <td>-0.682412</td>
      <td>0.581017</td>
      <td>-0.312769</td>
      <td>-0.014381</td>
      <td>1.206128</td>
      <td>1.152631</td>
      <td>-0.857312</td>
      <td>-0.299878</td>
      <td>0.017752</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.350968</td>
      <td>-0.118637</td>
      <td>-1.299990</td>
      <td>-0.474625</td>
      <td>0.505749</td>
      <td>-0.245630</td>
      <td>0.451087</td>
      <td>0.250810</td>
      <td>0.526067</td>
      <td>0.129136</td>
      <td>0.257213</td>
      <td>0.980772</td>
      <td>-0.028929</td>
      <td>-0.613285</td>
      <td>-0.214280</td>
      <td>-0.904825</td>
      <td>-0.761880</td>
      <td>-0.442710</td>
      <td>0.628098</td>
      <td>-0.372801</td>
      <td>0.408103</td>
      <td>0.782581</td>
      <td>-0.932486</td>
      <td>-1.097743</td>
      <td>-0.517133</td>
      <td>0.546134</td>
      <td>-1.680561</td>
      <td>-0.572468</td>
      <td>0.103599</td>
      <td>0.577371</td>
      <td>0.128823</td>
      <td>0.394061</td>
      <td>1.784275</td>
      <td>1.244817</td>
      <td>0.242331</td>
      <td>-1.334164</td>
      <td>-1.507280</td>
      <td>-0.594205</td>
      <td>-0.481550</td>
      <td>0.468184</td>
      <td>...</td>
      <td>0.237387</td>
      <td>-0.000768</td>
      <td>0.061178</td>
      <td>-0.302193</td>
      <td>-0.845154</td>
      <td>0.734675</td>
      <td>-0.244484</td>
      <td>-0.264752</td>
      <td>-0.385949</td>
      <td>0.117856</td>
      <td>-0.252427</td>
      <td>0.466675</td>
      <td>-0.059817</td>
      <td>-0.449598</td>
      <td>-0.131902</td>
      <td>0.541603</td>
      <td>-0.061170</td>
      <td>-0.039001</td>
      <td>-0.338721</td>
      <td>0.088789</td>
      <td>-0.486410</td>
      <td>-0.105882</td>
      <td>1.131683</td>
      <td>0.645037</td>
      <td>0.742968</td>
      <td>1.758625</td>
      <td>0.000255</td>
      <td>-0.255639</td>
      <td>0.853915</td>
      <td>-0.703072</td>
      <td>0.351910</td>
      <td>-0.507804</td>
      <td>-0.370069</td>
      <td>0.405058</td>
      <td>0.997044</td>
      <td>1.442218</td>
      <td>1.656706</td>
      <td>-0.434724</td>
      <td>0.918849</td>
      <td>0.777903</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.310074</td>
      <td>0.477480</td>
      <td>-0.744734</td>
      <td>-0.585317</td>
      <td>0.100113</td>
      <td>-0.037541</td>
      <td>0.897019</td>
      <td>0.230944</td>
      <td>-0.349930</td>
      <td>-0.660962</td>
      <td>-0.140647</td>
      <td>1.534218</td>
      <td>-0.388370</td>
      <td>0.923614</td>
      <td>0.304746</td>
      <td>0.084453</td>
      <td>-0.302245</td>
      <td>0.607404</td>
      <td>-0.772088</td>
      <td>0.336712</td>
      <td>0.651079</td>
      <td>0.419261</td>
      <td>-0.156964</td>
      <td>0.540572</td>
      <td>-1.975933</td>
      <td>-1.118436</td>
      <td>0.005364</td>
      <td>-0.336333</td>
      <td>-0.034973</td>
      <td>0.462159</td>
      <td>-0.287327</td>
      <td>1.061031</td>
      <td>0.246166</td>
      <td>-0.223910</td>
      <td>0.071333</td>
      <td>-0.544388</td>
      <td>-0.541384</td>
      <td>-0.531677</td>
      <td>-1.083738</td>
      <td>-0.679379</td>
      <td>...</td>
      <td>0.429621</td>
      <td>-0.685439</td>
      <td>-0.235467</td>
      <td>-0.911938</td>
      <td>-0.423254</td>
      <td>0.684384</td>
      <td>0.355830</td>
      <td>-0.121210</td>
      <td>0.172844</td>
      <td>-0.996925</td>
      <td>-0.668980</td>
      <td>0.299616</td>
      <td>-0.005373</td>
      <td>-0.290085</td>
      <td>-1.183755</td>
      <td>0.258975</td>
      <td>-0.620797</td>
      <td>-0.047414</td>
      <td>0.570877</td>
      <td>0.600015</td>
      <td>-1.207508</td>
      <td>-0.185986</td>
      <td>0.420609</td>
      <td>0.450222</td>
      <td>-0.739909</td>
      <td>-0.682822</td>
      <td>-0.326517</td>
      <td>-0.919181</td>
      <td>-1.057131</td>
      <td>-0.291769</td>
      <td>0.851905</td>
      <td>1.645378</td>
      <td>0.516757</td>
      <td>-1.717818</td>
      <td>0.403902</td>
      <td>-0.094273</td>
      <td>1.067063</td>
      <td>-1.578208</td>
      <td>-0.954247</td>
      <td>-0.142013</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.173119</td>
      <td>0.641131</td>
      <td>-0.435033</td>
      <td>-0.601022</td>
      <td>-0.768920</td>
      <td>-0.663284</td>
      <td>-0.847378</td>
      <td>0.473910</td>
      <td>-0.362146</td>
      <td>-0.211604</td>
      <td>0.082011</td>
      <td>1.305179</td>
      <td>-0.281709</td>
      <td>-0.207822</td>
      <td>0.233359</td>
      <td>0.046263</td>
      <td>-0.515658</td>
      <td>-0.513668</td>
      <td>-0.127982</td>
      <td>0.987721</td>
      <td>1.270068</td>
      <td>0.850227</td>
      <td>1.179767</td>
      <td>0.178689</td>
      <td>-0.160708</td>
      <td>-0.675313</td>
      <td>-0.640381</td>
      <td>-0.052171</td>
      <td>0.357378</td>
      <td>0.673280</td>
      <td>0.836768</td>
      <td>0.467026</td>
      <td>0.607849</td>
      <td>0.434527</td>
      <td>-0.404172</td>
      <td>-2.102525</td>
      <td>0.588735</td>
      <td>-0.277592</td>
      <td>-0.445233</td>
      <td>0.070630</td>
      <td>...</td>
      <td>0.221427</td>
      <td>0.220394</td>
      <td>0.003233</td>
      <td>-0.951919</td>
      <td>-1.025801</td>
      <td>-0.143723</td>
      <td>-0.608964</td>
      <td>-1.243450</td>
      <td>0.264351</td>
      <td>0.246015</td>
      <td>0.565227</td>
      <td>-0.319868</td>
      <td>0.168123</td>
      <td>0.370470</td>
      <td>-0.407055</td>
      <td>-0.198946</td>
      <td>0.075641</td>
      <td>0.538635</td>
      <td>0.713807</td>
      <td>-0.443046</td>
      <td>-0.303135</td>
      <td>-0.429675</td>
      <td>0.167319</td>
      <td>-0.029445</td>
      <td>0.081364</td>
      <td>0.652871</td>
      <td>-0.094385</td>
      <td>-0.235677</td>
      <td>-1.180252</td>
      <td>-0.386556</td>
      <td>0.294450</td>
      <td>-0.130215</td>
      <td>-0.909319</td>
      <td>-0.913144</td>
      <td>1.282875</td>
      <td>1.199477</td>
      <td>1.580637</td>
      <td>0.162904</td>
      <td>-0.159025</td>
      <td>-0.044293</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.107552</td>
      <td>-0.357009</td>
      <td>-0.110706</td>
      <td>0.153523</td>
      <td>-0.503770</td>
      <td>-0.398228</td>
      <td>-0.640010</td>
      <td>0.216915</td>
      <td>0.414444</td>
      <td>1.091466</td>
      <td>-0.603661</td>
      <td>1.189270</td>
      <td>0.003951</td>
      <td>-0.688092</td>
      <td>-0.486667</td>
      <td>0.385798</td>
      <td>0.520287</td>
      <td>0.587187</td>
      <td>0.203807</td>
      <td>0.671647</td>
      <td>0.840037</td>
      <td>0.262245</td>
      <td>0.458641</td>
      <td>0.675515</td>
      <td>-0.548672</td>
      <td>-1.193223</td>
      <td>-0.575911</td>
      <td>0.269680</td>
      <td>0.552153</td>
      <td>0.033278</td>
      <td>1.276287</td>
      <td>1.051449</td>
      <td>1.056351</td>
      <td>0.015655</td>
      <td>-0.490793</td>
      <td>-0.279333</td>
      <td>1.193851</td>
      <td>0.308219</td>
      <td>-0.130044</td>
      <td>0.490574</td>
      <td>...</td>
      <td>0.237059</td>
      <td>0.097825</td>
      <td>0.242362</td>
      <td>0.295048</td>
      <td>0.039489</td>
      <td>0.838085</td>
      <td>-0.559475</td>
      <td>1.017514</td>
      <td>0.448586</td>
      <td>0.069060</td>
      <td>0.245304</td>
      <td>-0.622985</td>
      <td>-0.002214</td>
      <td>-0.283656</td>
      <td>-0.452575</td>
      <td>-0.762399</td>
      <td>0.079356</td>
      <td>-0.551544</td>
      <td>-0.753310</td>
      <td>-0.278609</td>
      <td>-0.602035</td>
      <td>-0.263358</td>
      <td>0.942111</td>
      <td>0.322531</td>
      <td>-0.140783</td>
      <td>0.942426</td>
      <td>-0.484137</td>
      <td>0.478716</td>
      <td>-0.121548</td>
      <td>0.771830</td>
      <td>1.614372</td>
      <td>0.625193</td>
      <td>0.620036</td>
      <td>-0.256905</td>
      <td>0.553509</td>
      <td>0.111592</td>
      <td>0.701269</td>
      <td>-0.818207</td>
      <td>-0.449753</td>
      <td>-0.303687</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.793025</td>
      <td>1.232659</td>
      <td>1.468269</td>
      <td>0.931828</td>
      <td>0.902686</td>
      <td>0.639223</td>
      <td>0.429848</td>
      <td>0.484763</td>
      <td>-0.079152</td>
      <td>0.395757</td>
      <td>-0.143994</td>
      <td>0.386616</td>
      <td>0.766813</td>
      <td>0.807965</td>
      <td>-0.807969</td>
      <td>-0.844822</td>
      <td>-0.231873</td>
      <td>-0.561358</td>
      <td>-0.083330</td>
      <td>0.183541</td>
      <td>-0.612126</td>
      <td>0.048571</td>
      <td>1.036591</td>
      <td>-0.268384</td>
      <td>-0.694332</td>
      <td>-0.842399</td>
      <td>-0.582022</td>
      <td>-0.433474</td>
      <td>-0.701926</td>
      <td>0.030545</td>
      <td>0.099406</td>
      <td>0.844553</td>
      <td>0.539514</td>
      <td>-0.205452</td>
      <td>-0.875342</td>
      <td>-0.522193</td>
      <td>-0.070564</td>
      <td>-0.726971</td>
      <td>-0.478461</td>
      <td>-0.272938</td>
      <td>...</td>
      <td>-0.418272</td>
      <td>0.427154</td>
      <td>-0.098206</td>
      <td>-0.881906</td>
      <td>1.122237</td>
      <td>1.016221</td>
      <td>0.486407</td>
      <td>0.349087</td>
      <td>-1.388568</td>
      <td>-0.113850</td>
      <td>-0.721309</td>
      <td>-0.324066</td>
      <td>-0.453424</td>
      <td>-0.652858</td>
      <td>-0.711821</td>
      <td>-0.592804</td>
      <td>-0.400725</td>
      <td>0.079011</td>
      <td>-0.871570</td>
      <td>-2.034730</td>
      <td>-0.692827</td>
      <td>0.334006</td>
      <td>0.496205</td>
      <td>-0.386193</td>
      <td>-0.657793</td>
      <td>0.829891</td>
      <td>-0.162469</td>
      <td>0.526183</td>
      <td>-0.060870</td>
      <td>0.202007</td>
      <td>0.792391</td>
      <td>0.204632</td>
      <td>-0.152619</td>
      <td>-0.104600</td>
      <td>-0.198537</td>
      <td>0.528237</td>
      <td>0.387358</td>
      <td>3.591650</td>
      <td>2.927865</td>
      <td>1.455145</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.777160</td>
      <td>1.407476</td>
      <td>-0.843549</td>
      <td>-0.524170</td>
      <td>0.260427</td>
      <td>0.244220</td>
      <td>0.177766</td>
      <td>-0.611446</td>
      <td>-0.030762</td>
      <td>0.424678</td>
      <td>-0.645366</td>
      <td>0.934002</td>
      <td>-0.558349</td>
      <td>-0.328644</td>
      <td>0.034029</td>
      <td>-1.444737</td>
      <td>-0.732524</td>
      <td>-0.635449</td>
      <td>-1.622745</td>
      <td>-0.228001</td>
      <td>0.544819</td>
      <td>-0.567963</td>
      <td>1.137873</td>
      <td>0.214793</td>
      <td>-0.513097</td>
      <td>-0.570025</td>
      <td>-0.430526</td>
      <td>-0.755481</td>
      <td>-0.580726</td>
      <td>-0.629015</td>
      <td>-0.667997</td>
      <td>0.850321</td>
      <td>-0.258571</td>
      <td>-0.467706</td>
      <td>-0.111979</td>
      <td>0.046679</td>
      <td>-0.074055</td>
      <td>-0.598809</td>
      <td>-0.412124</td>
      <td>-0.703155</td>
      <td>...</td>
      <td>0.057838</td>
      <td>0.305014</td>
      <td>0.455673</td>
      <td>-0.948952</td>
      <td>0.882916</td>
      <td>1.347335</td>
      <td>0.470391</td>
      <td>-0.899187</td>
      <td>0.115354</td>
      <td>-0.808041</td>
      <td>-0.545202</td>
      <td>-0.615539</td>
      <td>0.170152</td>
      <td>-0.341637</td>
      <td>-0.291345</td>
      <td>-0.143880</td>
      <td>0.722815</td>
      <td>0.202758</td>
      <td>-0.279078</td>
      <td>-0.523193</td>
      <td>-0.542879</td>
      <td>0.491937</td>
      <td>2.177590</td>
      <td>0.903631</td>
      <td>0.028070</td>
      <td>0.451532</td>
      <td>0.650299</td>
      <td>-1.011287</td>
      <td>0.304434</td>
      <td>-0.091630</td>
      <td>0.692095</td>
      <td>0.381575</td>
      <td>0.546423</td>
      <td>-0.189860</td>
      <td>-0.816784</td>
      <td>0.289178</td>
      <td>-0.178796</td>
      <td>-0.072618</td>
      <td>-0.167582</td>
      <td>0.878626</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.579757</td>
      <td>0.043492</td>
      <td>-1.178382</td>
      <td>-0.513673</td>
      <td>-0.286848</td>
      <td>0.753878</td>
      <td>1.123661</td>
      <td>-0.117179</td>
      <td>-0.407644</td>
      <td>1.018347</td>
      <td>0.239774</td>
      <td>0.180644</td>
      <td>0.244941</td>
      <td>0.565951</td>
      <td>0.836476</td>
      <td>0.092966</td>
      <td>-0.371115</td>
      <td>-0.929888</td>
      <td>0.019668</td>
      <td>-0.132776</td>
      <td>0.589540</td>
      <td>-0.543586</td>
      <td>0.815897</td>
      <td>0.785466</td>
      <td>0.074040</td>
      <td>0.304719</td>
      <td>-0.168486</td>
      <td>-0.557133</td>
      <td>-0.338470</td>
      <td>-0.221557</td>
      <td>0.010911</td>
      <td>-0.387121</td>
      <td>-0.287334</td>
      <td>-0.617281</td>
      <td>-0.368388</td>
      <td>-0.864885</td>
      <td>0.097702</td>
      <td>-0.294317</td>
      <td>-0.910643</td>
      <td>0.572189</td>
      <td>...</td>
      <td>-0.410421</td>
      <td>-0.113466</td>
      <td>-0.544192</td>
      <td>-0.501053</td>
      <td>-0.402624</td>
      <td>0.392769</td>
      <td>0.416607</td>
      <td>-0.445035</td>
      <td>-0.183681</td>
      <td>0.318767</td>
      <td>0.581490</td>
      <td>-0.328901</td>
      <td>0.318741</td>
      <td>1.263350</td>
      <td>0.933049</td>
      <td>0.795479</td>
      <td>-0.142328</td>
      <td>-0.222829</td>
      <td>-0.094837</td>
      <td>-0.223670</td>
      <td>0.460022</td>
      <td>0.924370</td>
      <td>1.403574</td>
      <td>-0.334464</td>
      <td>-1.229762</td>
      <td>0.229091</td>
      <td>-0.038931</td>
      <td>-0.413639</td>
      <td>0.147939</td>
      <td>0.110463</td>
      <td>0.338781</td>
      <td>0.350014</td>
      <td>1.070709</td>
      <td>-0.703151</td>
      <td>0.174499</td>
      <td>-0.284107</td>
      <td>0.814392</td>
      <td>1.140973</td>
      <td>1.188960</td>
      <td>0.430275</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.219541</td>
      <td>-0.050281</td>
      <td>-1.071000</td>
      <td>0.857608</td>
      <td>0.553619</td>
      <td>-0.043544</td>
      <td>-0.141311</td>
      <td>0.208833</td>
      <td>0.186330</td>
      <td>0.481510</td>
      <td>0.273591</td>
      <td>1.091111</td>
      <td>0.676812</td>
      <td>0.367236</td>
      <td>-0.255496</td>
      <td>-0.592733</td>
      <td>0.254258</td>
      <td>-0.414020</td>
      <td>-1.144914</td>
      <td>0.043098</td>
      <td>0.298694</td>
      <td>-0.091567</td>
      <td>-0.000242</td>
      <td>0.904653</td>
      <td>-0.181375</td>
      <td>-0.999511</td>
      <td>-0.299594</td>
      <td>-0.442810</td>
      <td>-0.212518</td>
      <td>-0.052234</td>
      <td>-0.875732</td>
      <td>0.249195</td>
      <td>0.291427</td>
      <td>-0.013170</td>
      <td>-0.402335</td>
      <td>0.001152</td>
      <td>-0.139270</td>
      <td>-0.221611</td>
      <td>-1.460063</td>
      <td>0.165387</td>
      <td>...</td>
      <td>0.490979</td>
      <td>0.046264</td>
      <td>-0.001029</td>
      <td>-0.820031</td>
      <td>-0.808985</td>
      <td>0.969416</td>
      <td>-0.434763</td>
      <td>0.495900</td>
      <td>-0.508342</td>
      <td>0.410860</td>
      <td>0.120809</td>
      <td>-0.718025</td>
      <td>-0.738042</td>
      <td>0.090858</td>
      <td>-0.313597</td>
      <td>-0.071053</td>
      <td>0.213637</td>
      <td>-1.025884</td>
      <td>-0.045042</td>
      <td>1.159909</td>
      <td>0.730096</td>
      <td>1.250168</td>
      <td>0.750359</td>
      <td>0.704104</td>
      <td>0.653635</td>
      <td>0.761152</td>
      <td>0.012159</td>
      <td>-0.591321</td>
      <td>0.815545</td>
      <td>-1.258843</td>
      <td>1.068462</td>
      <td>0.092317</td>
      <td>-0.050035</td>
      <td>-0.247220</td>
      <td>0.226462</td>
      <td>0.513590</td>
      <td>0.530108</td>
      <td>-0.339375</td>
      <td>0.014670</td>
      <td>-0.271405</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.772399</td>
      <td>0.974537</td>
      <td>-0.292843</td>
      <td>-0.354543</td>
      <td>-0.615007</td>
      <td>-0.232845</td>
      <td>0.648746</td>
      <td>-0.365058</td>
      <td>0.049011</td>
      <td>0.155576</td>
      <td>-0.648766</td>
      <td>-0.006399</td>
      <td>-0.085502</td>
      <td>0.330393</td>
      <td>0.081255</td>
      <td>-0.855838</td>
      <td>-0.448979</td>
      <td>-0.605426</td>
      <td>-0.514852</td>
      <td>0.707635</td>
      <td>0.722215</td>
      <td>0.601015</td>
      <td>-0.210822</td>
      <td>-0.005994</td>
      <td>-0.542355</td>
      <td>-0.717041</td>
      <td>-0.521479</td>
      <td>0.373289</td>
      <td>0.498913</td>
      <td>-0.365721</td>
      <td>-0.211498</td>
      <td>-0.307961</td>
      <td>0.056268</td>
      <td>-0.010905</td>
      <td>0.431128</td>
      <td>-0.500537</td>
      <td>1.355775</td>
      <td>0.391068</td>
      <td>-0.770900</td>
      <td>-0.361764</td>
      <td>...</td>
      <td>-0.885590</td>
      <td>0.434167</td>
      <td>-0.014673</td>
      <td>-1.313992</td>
      <td>-1.035095</td>
      <td>-0.183906</td>
      <td>0.071630</td>
      <td>-0.159307</td>
      <td>-0.355368</td>
      <td>0.137232</td>
      <td>-0.251738</td>
      <td>0.722591</td>
      <td>0.098048</td>
      <td>0.477890</td>
      <td>-0.000312</td>
      <td>0.461933</td>
      <td>-0.139356</td>
      <td>-0.404994</td>
      <td>0.151442</td>
      <td>0.549122</td>
      <td>0.080420</td>
      <td>0.833406</td>
      <td>-1.109316</td>
      <td>0.557482</td>
      <td>0.681443</td>
      <td>1.102798</td>
      <td>1.033222</td>
      <td>-0.907290</td>
      <td>0.606129</td>
      <td>-0.170385</td>
      <td>-0.842598</td>
      <td>-0.265050</td>
      <td>-0.035244</td>
      <td>0.982581</td>
      <td>0.711651</td>
      <td>0.328902</td>
      <td>1.261422</td>
      <td>1.718622</td>
      <td>1.268399</td>
      <td>1.370017</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.711254</td>
      <td>1.515300</td>
      <td>-0.392532</td>
      <td>0.355495</td>
      <td>-0.529989</td>
      <td>0.492235</td>
      <td>0.154838</td>
      <td>-0.572443</td>
      <td>0.467326</td>
      <td>-0.276467</td>
      <td>0.601708</td>
      <td>0.959675</td>
      <td>-0.158164</td>
      <td>-0.611381</td>
      <td>-0.420605</td>
      <td>-0.943716</td>
      <td>0.765023</td>
      <td>0.265728</td>
      <td>-0.771623</td>
      <td>-0.936165</td>
      <td>0.146777</td>
      <td>-0.697697</td>
      <td>0.311555</td>
      <td>0.634932</td>
      <td>-0.660614</td>
      <td>-0.464075</td>
      <td>-0.024752</td>
      <td>-0.032563</td>
      <td>0.158788</td>
      <td>0.822810</td>
      <td>0.085926</td>
      <td>-0.405443</td>
      <td>-0.325715</td>
      <td>0.050196</td>
      <td>-0.579515</td>
      <td>-1.146507</td>
      <td>-1.074120</td>
      <td>-0.524379</td>
      <td>-0.439637</td>
      <td>-0.694097</td>
      <td>...</td>
      <td>0.156696</td>
      <td>-0.081810</td>
      <td>0.132248</td>
      <td>-0.488489</td>
      <td>-0.720281</td>
      <td>-0.042212</td>
      <td>-0.530044</td>
      <td>0.927022</td>
      <td>0.544323</td>
      <td>-0.173526</td>
      <td>-1.166679</td>
      <td>0.351070</td>
      <td>0.110845</td>
      <td>0.378908</td>
      <td>-0.330727</td>
      <td>0.191511</td>
      <td>0.200214</td>
      <td>-0.208003</td>
      <td>0.113877</td>
      <td>-0.780350</td>
      <td>-0.405982</td>
      <td>-0.191722</td>
      <td>0.020295</td>
      <td>0.982233</td>
      <td>0.228872</td>
      <td>0.740985</td>
      <td>0.214303</td>
      <td>-0.417101</td>
      <td>0.633620</td>
      <td>-0.268056</td>
      <td>0.407655</td>
      <td>0.136989</td>
      <td>-0.164507</td>
      <td>-0.609690</td>
      <td>-0.204333</td>
      <td>0.405294</td>
      <td>-0.601187</td>
      <td>1.396822</td>
      <td>1.845568</td>
      <td>0.679419</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.278800</td>
      <td>1.039763</td>
      <td>-0.653120</td>
      <td>1.416348</td>
      <td>0.564145</td>
      <td>1.073953</td>
      <td>-0.116396</td>
      <td>0.570434</td>
      <td>-0.247254</td>
      <td>0.513855</td>
      <td>0.049403</td>
      <td>0.402769</td>
      <td>0.253749</td>
      <td>0.289070</td>
      <td>-0.692723</td>
      <td>-1.028153</td>
      <td>-0.180407</td>
      <td>0.116208</td>
      <td>0.085035</td>
      <td>-0.571481</td>
      <td>0.610532</td>
      <td>0.133845</td>
      <td>0.336678</td>
      <td>0.283865</td>
      <td>-0.394469</td>
      <td>0.175826</td>
      <td>-0.935287</td>
      <td>-0.649050</td>
      <td>-0.164457</td>
      <td>0.833883</td>
      <td>-0.248902</td>
      <td>0.171382</td>
      <td>-0.052329</td>
      <td>-0.473139</td>
      <td>-0.540696</td>
      <td>-0.537741</td>
      <td>0.078121</td>
      <td>-0.484554</td>
      <td>-0.697374</td>
      <td>-0.276075</td>
      <td>...</td>
      <td>0.636279</td>
      <td>-0.868109</td>
      <td>-0.264748</td>
      <td>-0.876893</td>
      <td>-0.840649</td>
      <td>-0.137706</td>
      <td>0.351922</td>
      <td>-0.434880</td>
      <td>-0.194750</td>
      <td>0.668692</td>
      <td>0.610138</td>
      <td>0.662340</td>
      <td>0.465795</td>
      <td>-0.068424</td>
      <td>-0.775550</td>
      <td>0.187644</td>
      <td>-0.695821</td>
      <td>-0.697218</td>
      <td>-0.369663</td>
      <td>0.841280</td>
      <td>0.554510</td>
      <td>-0.000652</td>
      <td>-0.101113</td>
      <td>0.688054</td>
      <td>0.599070</td>
      <td>-0.476832</td>
      <td>0.287570</td>
      <td>-0.076558</td>
      <td>0.088845</td>
      <td>0.512525</td>
      <td>0.364368</td>
      <td>0.591008</td>
      <td>0.465082</td>
      <td>0.293528</td>
      <td>0.497333</td>
      <td>1.898369</td>
      <td>1.866766</td>
      <td>0.153302</td>
      <td>-0.094887</td>
      <td>0.479270</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.240498</td>
      <td>1.017149</td>
      <td>0.186198</td>
      <td>0.369945</td>
      <td>0.869355</td>
      <td>0.334383</td>
      <td>0.683948</td>
      <td>0.427691</td>
      <td>0.276367</td>
      <td>0.690958</td>
      <td>0.660799</td>
      <td>0.910759</td>
      <td>-0.058253</td>
      <td>-0.068074</td>
      <td>0.237573</td>
      <td>-0.518202</td>
      <td>0.230219</td>
      <td>-0.183754</td>
      <td>-0.317759</td>
      <td>-0.596564</td>
      <td>-0.890367</td>
      <td>0.323562</td>
      <td>-0.077264</td>
      <td>0.549066</td>
      <td>-0.083001</td>
      <td>-0.189930</td>
      <td>-0.891498</td>
      <td>-0.474834</td>
      <td>-0.525212</td>
      <td>0.938648</td>
      <td>0.694722</td>
      <td>-0.261366</td>
      <td>0.583048</td>
      <td>0.443992</td>
      <td>0.156410</td>
      <td>-0.294550</td>
      <td>0.871324</td>
      <td>0.110907</td>
      <td>-0.506393</td>
      <td>0.162874</td>
      <td>...</td>
      <td>-0.051664</td>
      <td>-0.310987</td>
      <td>-0.323994</td>
      <td>-0.423501</td>
      <td>-1.618386</td>
      <td>-1.222487</td>
      <td>0.955419</td>
      <td>0.313484</td>
      <td>0.380877</td>
      <td>-0.310379</td>
      <td>0.617047</td>
      <td>0.485260</td>
      <td>0.511171</td>
      <td>1.006163</td>
      <td>0.039595</td>
      <td>0.566066</td>
      <td>0.007377</td>
      <td>-0.788422</td>
      <td>-1.071946</td>
      <td>-0.728069</td>
      <td>-1.073054</td>
      <td>1.172835</td>
      <td>0.843451</td>
      <td>0.818799</td>
      <td>-0.484454</td>
      <td>1.127086</td>
      <td>0.638163</td>
      <td>-0.230698</td>
      <td>-0.007847</td>
      <td>-1.030381</td>
      <td>0.254062</td>
      <td>0.573608</td>
      <td>1.110618</td>
      <td>0.430336</td>
      <td>0.420569</td>
      <td>0.011729</td>
      <td>0.246722</td>
      <td>-0.041783</td>
      <td>0.412213</td>
      <td>0.614617</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.694312</td>
      <td>0.451753</td>
      <td>0.347769</td>
      <td>0.570910</td>
      <td>-0.033729</td>
      <td>0.544682</td>
      <td>0.702384</td>
      <td>1.295162</td>
      <td>-0.928147</td>
      <td>0.302571</td>
      <td>0.092352</td>
      <td>0.819973</td>
      <td>-0.390775</td>
      <td>-1.233056</td>
      <td>-0.188347</td>
      <td>-0.467712</td>
      <td>-0.315807</td>
      <td>0.802285</td>
      <td>0.306917</td>
      <td>-0.458253</td>
      <td>0.813036</td>
      <td>-0.486866</td>
      <td>1.085776</td>
      <td>-0.012030</td>
      <td>0.322031</td>
      <td>-1.189026</td>
      <td>-0.834996</td>
      <td>-0.104568</td>
      <td>0.315096</td>
      <td>0.326734</td>
      <td>0.038763</td>
      <td>0.499864</td>
      <td>0.464247</td>
      <td>0.366684</td>
      <td>-0.009044</td>
      <td>-0.449933</td>
      <td>-0.110975</td>
      <td>-0.775869</td>
      <td>-1.372318</td>
      <td>0.737903</td>
      <td>...</td>
      <td>0.327529</td>
      <td>-0.585377</td>
      <td>-0.220858</td>
      <td>-0.433636</td>
      <td>-0.762415</td>
      <td>-0.159192</td>
      <td>-0.203339</td>
      <td>-0.650708</td>
      <td>-0.299672</td>
      <td>0.396726</td>
      <td>0.796601</td>
      <td>0.516594</td>
      <td>1.096619</td>
      <td>1.319415</td>
      <td>-0.146483</td>
      <td>0.041694</td>
      <td>-0.805340</td>
      <td>-0.663142</td>
      <td>-0.374521</td>
      <td>-0.074378</td>
      <td>1.080251</td>
      <td>0.406525</td>
      <td>0.069134</td>
      <td>-0.240433</td>
      <td>0.645342</td>
      <td>0.617335</td>
      <td>0.623672</td>
      <td>0.649227</td>
      <td>-0.448758</td>
      <td>0.320663</td>
      <td>1.903539</td>
      <td>0.645953</td>
      <td>0.222086</td>
      <td>-0.168971</td>
      <td>0.338000</td>
      <td>0.300728</td>
      <td>0.124931</td>
      <td>0.631199</td>
      <td>1.082095</td>
      <td>0.597851</td>
    </tr>
    <tr>
      <th>15</th>
      <td>1.177030</td>
      <td>-0.911635</td>
      <td>-0.821970</td>
      <td>-0.873834</td>
      <td>0.043097</td>
      <td>1.370489</td>
      <td>0.534640</td>
      <td>-0.258093</td>
      <td>0.065393</td>
      <td>-0.148083</td>
      <td>0.092258</td>
      <td>1.684246</td>
      <td>-0.056818</td>
      <td>0.219951</td>
      <td>-0.817789</td>
      <td>-0.240942</td>
      <td>-0.470232</td>
      <td>0.155382</td>
      <td>0.217832</td>
      <td>0.680274</td>
      <td>0.029261</td>
      <td>-0.511691</td>
      <td>0.006516</td>
      <td>-0.834313</td>
      <td>-0.311937</td>
      <td>-0.266134</td>
      <td>-0.681069</td>
      <td>-0.810923</td>
      <td>-0.015271</td>
      <td>0.642860</td>
      <td>0.034006</td>
      <td>-0.142306</td>
      <td>0.577866</td>
      <td>-0.342686</td>
      <td>-0.389043</td>
      <td>-1.210356</td>
      <td>1.093305</td>
      <td>0.329949</td>
      <td>-1.241222</td>
      <td>0.128361</td>
      <td>...</td>
      <td>-0.277540</td>
      <td>-1.023485</td>
      <td>-0.624727</td>
      <td>-0.998294</td>
      <td>-0.295006</td>
      <td>1.061874</td>
      <td>0.097752</td>
      <td>-0.073924</td>
      <td>1.006076</td>
      <td>0.280086</td>
      <td>0.159411</td>
      <td>0.385818</td>
      <td>-0.084845</td>
      <td>-0.189388</td>
      <td>-0.324636</td>
      <td>0.735374</td>
      <td>0.545308</td>
      <td>0.764979</td>
      <td>0.457102</td>
      <td>-0.427813</td>
      <td>0.186573</td>
      <td>0.573589</td>
      <td>0.405588</td>
      <td>0.714530</td>
      <td>-0.090086</td>
      <td>0.234985</td>
      <td>1.211890</td>
      <td>0.643296</td>
      <td>-0.024276</td>
      <td>0.772423</td>
      <td>1.419847</td>
      <td>1.478825</td>
      <td>-0.057641</td>
      <td>-0.508343</td>
      <td>0.317306</td>
      <td>1.504943</td>
      <td>1.469213</td>
      <td>-1.585662</td>
      <td>-0.368696</td>
      <td>0.071657</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.849567</td>
      <td>0.217477</td>
      <td>-0.229480</td>
      <td>-0.134399</td>
      <td>-0.981780</td>
      <td>0.348731</td>
      <td>1.331535</td>
      <td>0.960505</td>
      <td>0.629569</td>
      <td>0.261051</td>
      <td>-0.507234</td>
      <td>1.344576</td>
      <td>1.025882</td>
      <td>0.441423</td>
      <td>0.553781</td>
      <td>0.012130</td>
      <td>0.049875</td>
      <td>-1.227805</td>
      <td>-0.906287</td>
      <td>-0.051672</td>
      <td>-0.065207</td>
      <td>0.042356</td>
      <td>-0.998792</td>
      <td>0.633513</td>
      <td>-0.680570</td>
      <td>0.246158</td>
      <td>-0.870984</td>
      <td>-0.287139</td>
      <td>-0.770588</td>
      <td>-0.018620</td>
      <td>-0.435999</td>
      <td>0.134741</td>
      <td>-0.100224</td>
      <td>-0.923574</td>
      <td>0.164469</td>
      <td>0.206382</td>
      <td>-0.817116</td>
      <td>-1.079822</td>
      <td>-0.495454</td>
      <td>0.280612</td>
      <td>...</td>
      <td>0.339786</td>
      <td>0.269360</td>
      <td>-0.201231</td>
      <td>-0.880424</td>
      <td>-1.059386</td>
      <td>-0.147590</td>
      <td>-0.553787</td>
      <td>-0.170883</td>
      <td>0.614133</td>
      <td>-0.153010</td>
      <td>-0.390379</td>
      <td>0.959048</td>
      <td>0.333565</td>
      <td>0.085716</td>
      <td>0.382723</td>
      <td>0.455003</td>
      <td>0.156768</td>
      <td>0.270890</td>
      <td>0.675262</td>
      <td>-0.192418</td>
      <td>-0.014193</td>
      <td>-0.363824</td>
      <td>0.131251</td>
      <td>-0.272189</td>
      <td>-0.757619</td>
      <td>0.381854</td>
      <td>-0.012302</td>
      <td>-0.600968</td>
      <td>-0.259663</td>
      <td>-0.531230</td>
      <td>-0.136723</td>
      <td>0.192662</td>
      <td>-0.225592</td>
      <td>0.304032</td>
      <td>-0.081586</td>
      <td>0.335944</td>
      <td>0.614799</td>
      <td>1.879260</td>
      <td>1.385220</td>
      <td>0.298366</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.174260</td>
      <td>0.303508</td>
      <td>-0.115424</td>
      <td>0.452233</td>
      <td>-0.680907</td>
      <td>0.358001</td>
      <td>-0.165624</td>
      <td>-0.010331</td>
      <td>-0.396106</td>
      <td>-0.454006</td>
      <td>-0.640716</td>
      <td>0.183330</td>
      <td>-0.649015</td>
      <td>-0.053594</td>
      <td>0.947193</td>
      <td>-0.014463</td>
      <td>-0.188144</td>
      <td>-0.367627</td>
      <td>0.248009</td>
      <td>0.176864</td>
      <td>0.378459</td>
      <td>0.312240</td>
      <td>0.372339</td>
      <td>-0.791055</td>
      <td>-0.683753</td>
      <td>0.525913</td>
      <td>-0.171296</td>
      <td>0.492421</td>
      <td>0.179033</td>
      <td>0.271346</td>
      <td>0.340014</td>
      <td>0.230407</td>
      <td>-0.516682</td>
      <td>-0.566582</td>
      <td>-0.403254</td>
      <td>-0.425354</td>
      <td>0.657824</td>
      <td>-1.777000</td>
      <td>-1.642410</td>
      <td>0.162348</td>
      <td>...</td>
      <td>-0.262817</td>
      <td>-0.521967</td>
      <td>0.029418</td>
      <td>-0.721549</td>
      <td>-0.805002</td>
      <td>0.629944</td>
      <td>0.887399</td>
      <td>-0.235486</td>
      <td>-0.190698</td>
      <td>-0.236798</td>
      <td>-0.033531</td>
      <td>0.395473</td>
      <td>0.054505</td>
      <td>1.229670</td>
      <td>0.457604</td>
      <td>0.129465</td>
      <td>-1.307481</td>
      <td>-0.631900</td>
      <td>-0.225802</td>
      <td>0.427361</td>
      <td>-0.460647</td>
      <td>0.558510</td>
      <td>0.775193</td>
      <td>0.854294</td>
      <td>-0.263286</td>
      <td>0.498408</td>
      <td>-0.187114</td>
      <td>0.289806</td>
      <td>-0.768623</td>
      <td>-0.336214</td>
      <td>0.831360</td>
      <td>-0.122747</td>
      <td>0.692965</td>
      <td>-0.526513</td>
      <td>0.514417</td>
      <td>0.455600</td>
      <td>0.794486</td>
      <td>-1.170581</td>
      <td>-0.967482</td>
      <td>-0.392926</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.381264</td>
      <td>-0.763869</td>
      <td>-0.786038</td>
      <td>-0.858150</td>
      <td>-0.711428</td>
      <td>-0.482664</td>
      <td>-0.411242</td>
      <td>-0.155277</td>
      <td>0.541211</td>
      <td>0.347570</td>
      <td>-0.935075</td>
      <td>0.125230</td>
      <td>-0.301888</td>
      <td>0.255129</td>
      <td>-1.502596</td>
      <td>-0.595945</td>
      <td>0.998237</td>
      <td>-0.332670</td>
      <td>-0.046063</td>
      <td>0.825396</td>
      <td>1.300868</td>
      <td>0.316315</td>
      <td>0.650262</td>
      <td>0.622912</td>
      <td>-0.867475</td>
      <td>-0.582423</td>
      <td>-0.508611</td>
      <td>0.472076</td>
      <td>0.838018</td>
      <td>0.705570</td>
      <td>1.044933</td>
      <td>0.576486</td>
      <td>0.537964</td>
      <td>0.439496</td>
      <td>-0.282779</td>
      <td>-0.760686</td>
      <td>-0.528287</td>
      <td>-1.375210</td>
      <td>-0.117971</td>
      <td>0.505714</td>
      <td>...</td>
      <td>0.479318</td>
      <td>0.023520</td>
      <td>-0.240708</td>
      <td>-0.198524</td>
      <td>0.259281</td>
      <td>1.014287</td>
      <td>0.257379</td>
      <td>-1.081434</td>
      <td>-0.941930</td>
      <td>-1.300510</td>
      <td>-1.256337</td>
      <td>-0.861486</td>
      <td>-1.232988</td>
      <td>-0.856648</td>
      <td>-0.730719</td>
      <td>-0.394065</td>
      <td>-0.307352</td>
      <td>0.339588</td>
      <td>0.652923</td>
      <td>-0.096993</td>
      <td>0.360966</td>
      <td>0.764059</td>
      <td>0.670239</td>
      <td>0.339083</td>
      <td>-1.392763</td>
      <td>-0.819956</td>
      <td>0.077034</td>
      <td>0.198013</td>
      <td>-1.108716</td>
      <td>0.545784</td>
      <td>1.069239</td>
      <td>0.186555</td>
      <td>-0.268576</td>
      <td>-0.085389</td>
      <td>0.270412</td>
      <td>0.645483</td>
      <td>1.241000</td>
      <td>1.006501</td>
      <td>1.150232</td>
      <td>1.066968</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.331937</td>
      <td>-1.066755</td>
      <td>-1.412107</td>
      <td>0.323361</td>
      <td>0.199876</td>
      <td>0.820606</td>
      <td>0.646696</td>
      <td>0.311441</td>
      <td>-0.300376</td>
      <td>-0.535237</td>
      <td>-0.286272</td>
      <td>0.855598</td>
      <td>-0.117252</td>
      <td>-1.107836</td>
      <td>0.131013</td>
      <td>-0.063410</td>
      <td>0.633262</td>
      <td>0.410599</td>
      <td>0.194401</td>
      <td>0.717510</td>
      <td>0.225249</td>
      <td>0.830670</td>
      <td>0.056412</td>
      <td>-0.235069</td>
      <td>-1.583526</td>
      <td>-0.543690</td>
      <td>0.253945</td>
      <td>0.604347</td>
      <td>0.725802</td>
      <td>0.698017</td>
      <td>0.176143</td>
      <td>-0.291384</td>
      <td>0.245046</td>
      <td>-0.068884</td>
      <td>-0.470531</td>
      <td>0.451462</td>
      <td>0.932593</td>
      <td>0.000440</td>
      <td>-0.490144</td>
      <td>0.031706</td>
      <td>...</td>
      <td>-0.132804</td>
      <td>-0.253971</td>
      <td>-0.414401</td>
      <td>-0.224437</td>
      <td>-0.311643</td>
      <td>0.771325</td>
      <td>0.446385</td>
      <td>-0.235391</td>
      <td>0.199691</td>
      <td>0.666425</td>
      <td>0.127705</td>
      <td>-0.636927</td>
      <td>-0.098628</td>
      <td>0.315726</td>
      <td>-0.416620</td>
      <td>0.302116</td>
      <td>-0.657439</td>
      <td>-1.128567</td>
      <td>0.059470</td>
      <td>-0.667437</td>
      <td>-0.352596</td>
      <td>1.731935</td>
      <td>0.939283</td>
      <td>0.052031</td>
      <td>-0.709133</td>
      <td>0.614371</td>
      <td>-0.789489</td>
      <td>-0.845848</td>
      <td>-0.362094</td>
      <td>-0.394092</td>
      <td>0.343344</td>
      <td>-0.023107</td>
      <td>-0.565934</td>
      <td>-0.044544</td>
      <td>0.193437</td>
      <td>0.845416</td>
      <td>1.495293</td>
      <td>-1.845059</td>
      <td>-0.767947</td>
      <td>0.119010</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.020612</td>
      <td>0.401939</td>
      <td>-0.744252</td>
      <td>-0.276036</td>
      <td>0.059305</td>
      <td>0.190970</td>
      <td>-0.210459</td>
      <td>-0.256604</td>
      <td>0.981855</td>
      <td>0.310865</td>
      <td>-0.049439</td>
      <td>1.386027</td>
      <td>0.176334</td>
      <td>-0.762558</td>
      <td>0.740377</td>
      <td>0.470387</td>
      <td>0.285308</td>
      <td>0.055592</td>
      <td>0.716925</td>
      <td>0.227426</td>
      <td>0.044927</td>
      <td>-0.225628</td>
      <td>0.270221</td>
      <td>1.093996</td>
      <td>0.423159</td>
      <td>-0.180678</td>
      <td>-0.741415</td>
      <td>-0.057091</td>
      <td>0.501744</td>
      <td>1.087188</td>
      <td>-0.412042</td>
      <td>0.074692</td>
      <td>0.625175</td>
      <td>-0.402224</td>
      <td>-0.587968</td>
      <td>-0.092045</td>
      <td>-0.314133</td>
      <td>-0.934414</td>
      <td>-0.803441</td>
      <td>0.597319</td>
      <td>...</td>
      <td>-0.925004</td>
      <td>-0.583751</td>
      <td>-0.454440</td>
      <td>-0.260916</td>
      <td>0.094313</td>
      <td>0.225301</td>
      <td>-0.397940</td>
      <td>-0.724235</td>
      <td>-0.681051</td>
      <td>-0.522235</td>
      <td>0.422629</td>
      <td>0.771119</td>
      <td>-0.367037</td>
      <td>-0.295710</td>
      <td>-1.334889</td>
      <td>-0.095880</td>
      <td>-0.300555</td>
      <td>-0.164471</td>
      <td>0.199435</td>
      <td>-0.390225</td>
      <td>-0.097224</td>
      <td>-0.221118</td>
      <td>0.700347</td>
      <td>0.225156</td>
      <td>-1.587142</td>
      <td>0.324157</td>
      <td>-0.197334</td>
      <td>-0.915084</td>
      <td>-0.181735</td>
      <td>-0.648263</td>
      <td>0.838958</td>
      <td>-0.976270</td>
      <td>-0.196350</td>
      <td>0.141877</td>
      <td>0.538158</td>
      <td>0.052516</td>
      <td>0.950146</td>
      <td>1.278042</td>
      <td>0.736211</td>
      <td>-0.208156</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.246966</td>
      <td>1.026099</td>
      <td>-0.676781</td>
      <td>0.281302</td>
      <td>0.718550</td>
      <td>1.486739</td>
      <td>0.989709</td>
      <td>-0.527456</td>
      <td>0.416209</td>
      <td>1.013270</td>
      <td>-0.091078</td>
      <td>0.208866</td>
      <td>-0.236923</td>
      <td>-0.075259</td>
      <td>0.708560</td>
      <td>-1.313490</td>
      <td>-0.938724</td>
      <td>-0.438092</td>
      <td>0.017986</td>
      <td>-0.105742</td>
      <td>0.263000</td>
      <td>0.537345</td>
      <td>1.297884</td>
      <td>0.754763</td>
      <td>0.150593</td>
      <td>0.219275</td>
      <td>0.778688</td>
      <td>-0.712954</td>
      <td>-0.846755</td>
      <td>0.590343</td>
      <td>0.141267</td>
      <td>-0.263734</td>
      <td>-0.789964</td>
      <td>-0.752758</td>
      <td>-1.025360</td>
      <td>0.024775</td>
      <td>0.284033</td>
      <td>-0.140673</td>
      <td>-1.483608</td>
      <td>-0.203708</td>
      <td>...</td>
      <td>0.357257</td>
      <td>-1.098232</td>
      <td>0.053611</td>
      <td>0.438810</td>
      <td>-0.554458</td>
      <td>0.556669</td>
      <td>-0.316736</td>
      <td>0.697327</td>
      <td>0.096931</td>
      <td>-0.201820</td>
      <td>-0.298289</td>
      <td>0.711570</td>
      <td>0.386855</td>
      <td>0.177504</td>
      <td>-0.136686</td>
      <td>-0.185301</td>
      <td>0.027922</td>
      <td>0.351106</td>
      <td>0.439098</td>
      <td>-0.940581</td>
      <td>-1.319205</td>
      <td>-0.091871</td>
      <td>0.430895</td>
      <td>0.999253</td>
      <td>-0.434017</td>
      <td>-0.028270</td>
      <td>0.328950</td>
      <td>-0.252946</td>
      <td>-0.270435</td>
      <td>-0.661360</td>
      <td>0.641694</td>
      <td>0.212755</td>
      <td>-0.394619</td>
      <td>-0.529722</td>
      <td>-0.300101</td>
      <td>0.329061</td>
      <td>0.913163</td>
      <td>-0.051464</td>
      <td>0.534032</td>
      <td>0.038916</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.898385</td>
      <td>0.609629</td>
      <td>0.764025</td>
      <td>0.771464</td>
      <td>-0.033759</td>
      <td>0.366649</td>
      <td>0.982884</td>
      <td>0.780215</td>
      <td>0.449424</td>
      <td>1.264720</td>
      <td>-0.095756</td>
      <td>0.289389</td>
      <td>0.304445</td>
      <td>-0.650240</td>
      <td>-0.524140</td>
      <td>-0.587034</td>
      <td>-0.378714</td>
      <td>0.116054</td>
      <td>0.357554</td>
      <td>0.610737</td>
      <td>1.289996</td>
      <td>0.778354</td>
      <td>-0.002403</td>
      <td>0.147641</td>
      <td>-0.744313</td>
      <td>0.190467</td>
      <td>-1.336916</td>
      <td>-0.891719</td>
      <td>-0.114731</td>
      <td>-1.334263</td>
      <td>-0.687061</td>
      <td>-0.482581</td>
      <td>0.436010</td>
      <td>0.672762</td>
      <td>-0.411810</td>
      <td>-0.327622</td>
      <td>0.267001</td>
      <td>-0.393862</td>
      <td>-0.997398</td>
      <td>0.650331</td>
      <td>...</td>
      <td>0.159733</td>
      <td>0.373321</td>
      <td>0.209641</td>
      <td>-0.200612</td>
      <td>0.183658</td>
      <td>1.570569</td>
      <td>0.345100</td>
      <td>-0.014178</td>
      <td>0.816004</td>
      <td>-0.457656</td>
      <td>0.542073</td>
      <td>-0.045401</td>
      <td>0.539445</td>
      <td>0.303169</td>
      <td>0.046203</td>
      <td>0.406025</td>
      <td>0.751449</td>
      <td>-0.936622</td>
      <td>-0.353871</td>
      <td>-1.030633</td>
      <td>-0.090021</td>
      <td>0.213592</td>
      <td>-0.075576</td>
      <td>0.967554</td>
      <td>0.330588</td>
      <td>0.462412</td>
      <td>-0.564444</td>
      <td>-0.442817</td>
      <td>-0.570004</td>
      <td>-0.724455</td>
      <td>-0.118849</td>
      <td>0.118400</td>
      <td>-0.440342</td>
      <td>-0.514470</td>
      <td>0.263019</td>
      <td>0.874214</td>
      <td>0.038523</td>
      <td>2.149872</td>
      <td>0.841357</td>
      <td>0.576613</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.120909</td>
      <td>-0.549847</td>
      <td>-0.273001</td>
      <td>0.616756</td>
      <td>0.721311</td>
      <td>0.643588</td>
      <td>0.058192</td>
      <td>0.435079</td>
      <td>-0.579044</td>
      <td>-0.165771</td>
      <td>1.636334</td>
      <td>1.230952</td>
      <td>0.827742</td>
      <td>-1.018784</td>
      <td>-0.396368</td>
      <td>0.402099</td>
      <td>-0.022184</td>
      <td>-0.001710</td>
      <td>1.038200</td>
      <td>-0.659901</td>
      <td>-0.552860</td>
      <td>-0.212097</td>
      <td>0.747921</td>
      <td>0.286383</td>
      <td>0.242826</td>
      <td>0.046349</td>
      <td>-0.495523</td>
      <td>0.392797</td>
      <td>0.370146</td>
      <td>-0.025897</td>
      <td>-0.636711</td>
      <td>-0.432715</td>
      <td>1.071791</td>
      <td>-0.393285</td>
      <td>-0.389362</td>
      <td>-0.596160</td>
      <td>-0.791635</td>
      <td>0.498008</td>
      <td>-0.459581</td>
      <td>0.100292</td>
      <td>...</td>
      <td>-0.171564</td>
      <td>-1.522613</td>
      <td>0.369930</td>
      <td>-0.179094</td>
      <td>-0.324458</td>
      <td>-0.291949</td>
      <td>-0.477892</td>
      <td>-0.476349</td>
      <td>-0.245634</td>
      <td>-1.181492</td>
      <td>-0.800004</td>
      <td>-1.146942</td>
      <td>-1.096974</td>
      <td>-0.378018</td>
      <td>0.628367</td>
      <td>-0.260030</td>
      <td>-0.209640</td>
      <td>0.962127</td>
      <td>0.274868</td>
      <td>-0.313684</td>
      <td>-0.283743</td>
      <td>0.131893</td>
      <td>0.359420</td>
      <td>0.348825</td>
      <td>1.044349</td>
      <td>0.248528</td>
      <td>-0.134586</td>
      <td>0.390815</td>
      <td>-0.128767</td>
      <td>-0.349554</td>
      <td>1.287482</td>
      <td>-0.237463</td>
      <td>-0.228312</td>
      <td>-0.255543</td>
      <td>1.509667</td>
      <td>0.392598</td>
      <td>0.853230</td>
      <td>0.293808</td>
      <td>0.187706</td>
      <td>-0.569856</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-0.169200</td>
      <td>0.485635</td>
      <td>-1.125987</td>
      <td>0.800668</td>
      <td>0.712878</td>
      <td>0.516617</td>
      <td>0.048933</td>
      <td>0.350822</td>
      <td>0.546427</td>
      <td>-0.589655</td>
      <td>0.428502</td>
      <td>1.394073</td>
      <td>-0.472938</td>
      <td>-0.186907</td>
      <td>0.596543</td>
      <td>0.434237</td>
      <td>0.357703</td>
      <td>0.275663</td>
      <td>-0.113763</td>
      <td>0.489903</td>
      <td>-0.154517</td>
      <td>0.497844</td>
      <td>-0.941795</td>
      <td>0.697579</td>
      <td>0.432936</td>
      <td>-0.668679</td>
      <td>-0.290543</td>
      <td>0.010544</td>
      <td>0.344904</td>
      <td>-0.447213</td>
      <td>0.091877</td>
      <td>-0.139080</td>
      <td>1.079811</td>
      <td>-0.000150</td>
      <td>-0.752083</td>
      <td>-1.307267</td>
      <td>-0.028957</td>
      <td>-0.615715</td>
      <td>-0.220018</td>
      <td>0.621853</td>
      <td>...</td>
      <td>-0.207754</td>
      <td>0.132867</td>
      <td>-0.109469</td>
      <td>-1.390818</td>
      <td>-0.529171</td>
      <td>0.418649</td>
      <td>-0.028323</td>
      <td>0.826046</td>
      <td>0.206243</td>
      <td>-1.323314</td>
      <td>-0.920190</td>
      <td>0.053621</td>
      <td>-0.085187</td>
      <td>1.380735</td>
      <td>0.011806</td>
      <td>0.449195</td>
      <td>0.332887</td>
      <td>-0.421251</td>
      <td>0.682337</td>
      <td>-0.427992</td>
      <td>-0.301674</td>
      <td>0.141685</td>
      <td>0.812356</td>
      <td>0.595875</td>
      <td>0.119220</td>
      <td>0.788212</td>
      <td>0.422555</td>
      <td>0.310498</td>
      <td>-0.543085</td>
      <td>-0.900458</td>
      <td>0.638064</td>
      <td>0.273555</td>
      <td>-0.371619</td>
      <td>0.484697</td>
      <td>1.321415</td>
      <td>0.276684</td>
      <td>1.359789</td>
      <td>-0.442622</td>
      <td>-0.329029</td>
      <td>-0.036065</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>1.150623</td>
      <td>0.265141</td>
      <td>0.368574</td>
      <td>-0.751989</td>
      <td>0.552955</td>
      <td>-0.464376</td>
      <td>0.271320</td>
      <td>-0.532753</td>
      <td>-0.259924</td>
      <td>-0.545130</td>
      <td>-0.521984</td>
      <td>-1.511761</td>
      <td>-0.566664</td>
      <td>-0.636518</td>
      <td>0.066620</td>
      <td>-0.634106</td>
      <td>-0.912518</td>
      <td>-0.133080</td>
      <td>0.271393</td>
      <td>0.095096</td>
      <td>0.388223</td>
      <td>0.451101</td>
      <td>0.080050</td>
      <td>0.260493</td>
      <td>-0.301737</td>
      <td>0.476135</td>
      <td>0.185372</td>
      <td>-0.598940</td>
      <td>0.013574</td>
      <td>-0.275980</td>
      <td>-0.517416</td>
      <td>0.062877</td>
      <td>0.375091</td>
      <td>0.882335</td>
      <td>-1.391086</td>
      <td>-0.736520</td>
      <td>0.255842</td>
      <td>-0.605702</td>
      <td>0.169876</td>
      <td>1.179694</td>
      <td>...</td>
      <td>-1.357734</td>
      <td>0.208188</td>
      <td>0.512745</td>
      <td>0.592847</td>
      <td>0.528729</td>
      <td>-1.149970</td>
      <td>0.521814</td>
      <td>-0.545012</td>
      <td>-0.299507</td>
      <td>-0.548671</td>
      <td>0.159781</td>
      <td>0.583537</td>
      <td>1.012701</td>
      <td>0.446442</td>
      <td>0.577633</td>
      <td>-0.307806</td>
      <td>-0.367719</td>
      <td>0.450392</td>
      <td>0.533364</td>
      <td>1.248977</td>
      <td>0.255303</td>
      <td>0.896616</td>
      <td>1.020925</td>
      <td>-0.325252</td>
      <td>-0.947207</td>
      <td>-0.108842</td>
      <td>-0.085618</td>
      <td>0.050799</td>
      <td>0.241933</td>
      <td>0.666262</td>
      <td>0.512063</td>
      <td>0.314426</td>
      <td>-0.718581</td>
      <td>1.054025</td>
      <td>0.585579</td>
      <td>-0.181418</td>
      <td>-0.282672</td>
      <td>5.496492</td>
      <td>2.849615</td>
      <td>1.281476</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.143381</td>
      <td>-0.249284</td>
      <td>0.362209</td>
      <td>-0.637724</td>
      <td>-0.468777</td>
      <td>-0.965111</td>
      <td>-0.055146</td>
      <td>-0.722339</td>
      <td>-0.036029</td>
      <td>-0.665631</td>
      <td>2.214339</td>
      <td>0.299532</td>
      <td>0.384136</td>
      <td>-0.769355</td>
      <td>0.746593</td>
      <td>-0.065894</td>
      <td>0.129834</td>
      <td>-0.486835</td>
      <td>-0.121021</td>
      <td>0.404669</td>
      <td>-1.288111</td>
      <td>-0.467517</td>
      <td>-0.645793</td>
      <td>-0.406756</td>
      <td>0.256280</td>
      <td>0.430407</td>
      <td>1.409539</td>
      <td>-0.095191</td>
      <td>0.211662</td>
      <td>-0.781530</td>
      <td>-0.680650</td>
      <td>-1.052397</td>
      <td>-0.178842</td>
      <td>-0.535472</td>
      <td>-0.836995</td>
      <td>-0.057957</td>
      <td>0.836783</td>
      <td>-0.969737</td>
      <td>0.614159</td>
      <td>-0.996872</td>
      <td>...</td>
      <td>-0.203960</td>
      <td>0.662173</td>
      <td>-0.140409</td>
      <td>0.674150</td>
      <td>0.714233</td>
      <td>0.227796</td>
      <td>0.514188</td>
      <td>-0.036756</td>
      <td>-0.284091</td>
      <td>0.544824</td>
      <td>-0.479230</td>
      <td>-1.041928</td>
      <td>-0.888243</td>
      <td>0.201004</td>
      <td>0.330754</td>
      <td>-1.008032</td>
      <td>0.002968</td>
      <td>1.006874</td>
      <td>0.142714</td>
      <td>0.564976</td>
      <td>0.923440</td>
      <td>-0.078669</td>
      <td>-0.258395</td>
      <td>-0.523724</td>
      <td>0.316419</td>
      <td>-0.262984</td>
      <td>-0.035154</td>
      <td>-0.288784</td>
      <td>0.341760</td>
      <td>0.633937</td>
      <td>1.342082</td>
      <td>0.319254</td>
      <td>-0.412412</td>
      <td>-0.552287</td>
      <td>0.583363</td>
      <td>0.524992</td>
      <td>0.623937</td>
      <td>-0.147412</td>
      <td>0.026918</td>
      <td>0.044916</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.222955</td>
      <td>-0.810650</td>
      <td>0.310320</td>
      <td>-0.372042</td>
      <td>-0.077145</td>
      <td>0.106617</td>
      <td>-0.278452</td>
      <td>-0.130841</td>
      <td>0.503390</td>
      <td>0.230134</td>
      <td>0.216917</td>
      <td>-0.203526</td>
      <td>-0.541936</td>
      <td>0.158826</td>
      <td>0.230642</td>
      <td>-0.263653</td>
      <td>0.137514</td>
      <td>0.253385</td>
      <td>0.397955</td>
      <td>-0.463636</td>
      <td>0.916903</td>
      <td>1.331094</td>
      <td>0.865156</td>
      <td>-0.091769</td>
      <td>-0.740109</td>
      <td>0.182054</td>
      <td>-0.491079</td>
      <td>-1.175955</td>
      <td>-0.437079</td>
      <td>-0.744190</td>
      <td>-1.033845</td>
      <td>-0.887931</td>
      <td>-0.299258</td>
      <td>0.509110</td>
      <td>0.166074</td>
      <td>-0.652676</td>
      <td>0.138479</td>
      <td>-0.399113</td>
      <td>0.523087</td>
      <td>0.133816</td>
      <td>...</td>
      <td>0.033481</td>
      <td>-0.783175</td>
      <td>-0.063434</td>
      <td>0.971354</td>
      <td>1.868199</td>
      <td>1.017264</td>
      <td>0.230545</td>
      <td>-0.066068</td>
      <td>-0.750016</td>
      <td>0.063509</td>
      <td>-0.361657</td>
      <td>0.593969</td>
      <td>-0.092986</td>
      <td>0.025074</td>
      <td>-0.637114</td>
      <td>-0.097900</td>
      <td>0.431072</td>
      <td>0.043592</td>
      <td>-0.147890</td>
      <td>0.166537</td>
      <td>-0.230063</td>
      <td>0.556836</td>
      <td>0.192306</td>
      <td>1.004438</td>
      <td>0.324912</td>
      <td>0.055222</td>
      <td>-0.591741</td>
      <td>1.055207</td>
      <td>-0.053710</td>
      <td>1.205070</td>
      <td>0.586709</td>
      <td>-1.788576</td>
      <td>-0.146635</td>
      <td>0.464964</td>
      <td>0.417904</td>
      <td>0.527426</td>
      <td>0.150528</td>
      <td>0.526924</td>
      <td>0.675953</td>
      <td>-0.637316</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.063730</td>
      <td>-0.244657</td>
      <td>0.712292</td>
      <td>-0.468329</td>
      <td>0.168302</td>
      <td>-0.323307</td>
      <td>0.078338</td>
      <td>0.600302</td>
      <td>-0.694027</td>
      <td>0.070995</td>
      <td>0.191189</td>
      <td>0.522814</td>
      <td>1.124745</td>
      <td>0.609551</td>
      <td>0.272699</td>
      <td>-1.257075</td>
      <td>-1.094834</td>
      <td>-0.070422</td>
      <td>0.195541</td>
      <td>0.425721</td>
      <td>0.469462</td>
      <td>0.628445</td>
      <td>-0.514566</td>
      <td>-0.615594</td>
      <td>-1.192703</td>
      <td>-0.684516</td>
      <td>0.019000</td>
      <td>-0.397585</td>
      <td>0.722367</td>
      <td>0.092535</td>
      <td>-0.831095</td>
      <td>1.273660</td>
      <td>0.823217</td>
      <td>0.522887</td>
      <td>0.048646</td>
      <td>-0.005692</td>
      <td>0.787556</td>
      <td>-0.070975</td>
      <td>-0.069198</td>
      <td>0.038828</td>
      <td>...</td>
      <td>0.056561</td>
      <td>0.312817</td>
      <td>0.517409</td>
      <td>0.575902</td>
      <td>0.341856</td>
      <td>0.557815</td>
      <td>0.020426</td>
      <td>-0.474308</td>
      <td>-0.523214</td>
      <td>0.235756</td>
      <td>0.156680</td>
      <td>0.211330</td>
      <td>-0.164807</td>
      <td>-0.195334</td>
      <td>-0.184187</td>
      <td>-0.005044</td>
      <td>-0.084007</td>
      <td>0.104116</td>
      <td>-0.417226</td>
      <td>-0.036390</td>
      <td>0.592281</td>
      <td>-0.217438</td>
      <td>-0.219344</td>
      <td>0.305303</td>
      <td>0.638249</td>
      <td>-0.731813</td>
      <td>-0.183143</td>
      <td>0.142993</td>
      <td>0.456980</td>
      <td>0.626441</td>
      <td>-0.398943</td>
      <td>-0.497001</td>
      <td>-0.828651</td>
      <td>-0.866200</td>
      <td>0.720294</td>
      <td>-0.077799</td>
      <td>-0.114960</td>
      <td>0.541655</td>
      <td>0.655844</td>
      <td>0.608357</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.256686</td>
      <td>0.384282</td>
      <td>0.735970</td>
      <td>-0.572418</td>
      <td>-0.172717</td>
      <td>0.329317</td>
      <td>-0.294838</td>
      <td>-0.052612</td>
      <td>-0.309741</td>
      <td>-0.035554</td>
      <td>0.699652</td>
      <td>-1.010872</td>
      <td>-0.423232</td>
      <td>0.673578</td>
      <td>0.011624</td>
      <td>-0.257616</td>
      <td>-0.417357</td>
      <td>0.512730</td>
      <td>-1.222015</td>
      <td>0.267911</td>
      <td>-0.165626</td>
      <td>0.522125</td>
      <td>0.642050</td>
      <td>1.221828</td>
      <td>0.043614</td>
      <td>-0.733262</td>
      <td>-0.076707</td>
      <td>0.295725</td>
      <td>1.820236</td>
      <td>0.291106</td>
      <td>0.112528</td>
      <td>-0.128531</td>
      <td>0.691401</td>
      <td>-0.263818</td>
      <td>0.204619</td>
      <td>-0.156441</td>
      <td>0.599672</td>
      <td>-0.494690</td>
      <td>-0.138430</td>
      <td>0.130659</td>
      <td>...</td>
      <td>0.379762</td>
      <td>-0.247660</td>
      <td>0.355363</td>
      <td>0.293710</td>
      <td>-0.232557</td>
      <td>-0.166900</td>
      <td>-0.350281</td>
      <td>-0.462471</td>
      <td>-0.468117</td>
      <td>0.591251</td>
      <td>-0.285035</td>
      <td>0.187597</td>
      <td>0.771867</td>
      <td>-0.593539</td>
      <td>0.054796</td>
      <td>0.450818</td>
      <td>1.643378</td>
      <td>-0.399108</td>
      <td>-1.269907</td>
      <td>0.418388</td>
      <td>0.375696</td>
      <td>0.392521</td>
      <td>0.454088</td>
      <td>-0.180976</td>
      <td>0.545778</td>
      <td>0.440994</td>
      <td>0.830532</td>
      <td>0.515947</td>
      <td>0.244962</td>
      <td>0.178493</td>
      <td>1.482345</td>
      <td>-0.166418</td>
      <td>-0.210206</td>
      <td>-0.274121</td>
      <td>0.163594</td>
      <td>1.024949</td>
      <td>1.055502</td>
      <td>2.222189</td>
      <td>1.861504</td>
      <td>0.957668</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f4410d42100&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef  std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.038072  0.04743  21.886557  3.488934e-106  0.945111  1.131032
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.425 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.4.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>