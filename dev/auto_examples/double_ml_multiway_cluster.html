
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>     to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-1.179493</td>
      <td>-0.828665</td>
      <td>-0.979680</td>
      <td>-0.536832</td>
      <td>0.397196</td>
      <td>0.392570</td>
      <td>-0.625305</td>
      <td>-0.102823</td>
      <td>0.569325</td>
      <td>-1.507948</td>
      <td>0.048032</td>
      <td>1.242306</td>
      <td>-0.535097</td>
      <td>-0.518502</td>
      <td>-0.836210</td>
      <td>-0.619239</td>
      <td>-1.420159</td>
      <td>-0.775705</td>
      <td>-0.827492</td>
      <td>0.182839</td>
      <td>0.186858</td>
      <td>-0.249603</td>
      <td>0.347108</td>
      <td>0.456607</td>
      <td>0.309758</td>
      <td>-0.138738</td>
      <td>-0.364208</td>
      <td>0.094344</td>
      <td>0.133769</td>
      <td>0.169886</td>
      <td>0.567263</td>
      <td>-0.395687</td>
      <td>0.094156</td>
      <td>0.081322</td>
      <td>-0.355260</td>
      <td>0.095683</td>
      <td>0.038110</td>
      <td>0.295886</td>
      <td>-0.157528</td>
      <td>-0.178310</td>
      <td>...</td>
      <td>0.868094</td>
      <td>0.763756</td>
      <td>0.567546</td>
      <td>-0.312719</td>
      <td>1.525176</td>
      <td>-0.369270</td>
      <td>-0.247558</td>
      <td>0.442459</td>
      <td>-0.232396</td>
      <td>-1.174747</td>
      <td>-0.258527</td>
      <td>-0.159831</td>
      <td>-0.719185</td>
      <td>-0.529024</td>
      <td>-0.212925</td>
      <td>-0.519235</td>
      <td>-0.584070</td>
      <td>-0.537431</td>
      <td>0.733099</td>
      <td>0.961543</td>
      <td>0.623956</td>
      <td>-0.976268</td>
      <td>-0.077220</td>
      <td>-0.472104</td>
      <td>0.042453</td>
      <td>0.480423</td>
      <td>0.666107</td>
      <td>-0.736183</td>
      <td>-0.031728</td>
      <td>0.032256</td>
      <td>-0.184899</td>
      <td>-0.188144</td>
      <td>-0.854188</td>
      <td>-0.622887</td>
      <td>0.215722</td>
      <td>1.189950</td>
      <td>1.071426</td>
      <td>0.087930</td>
      <td>-0.195207</td>
      <td>-0.884991</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.168920</td>
      <td>0.022958</td>
      <td>-1.374142</td>
      <td>-0.628218</td>
      <td>0.348846</td>
      <td>0.238308</td>
      <td>0.666164</td>
      <td>-0.774320</td>
      <td>0.688834</td>
      <td>-0.111950</td>
      <td>-0.657378</td>
      <td>0.351178</td>
      <td>-0.200748</td>
      <td>0.196934</td>
      <td>-0.596690</td>
      <td>0.063807</td>
      <td>-0.624830</td>
      <td>0.222634</td>
      <td>0.132682</td>
      <td>1.037080</td>
      <td>0.305187</td>
      <td>-0.101603</td>
      <td>0.516790</td>
      <td>0.558053</td>
      <td>0.179058</td>
      <td>0.074505</td>
      <td>0.019353</td>
      <td>0.286466</td>
      <td>-1.118650</td>
      <td>0.066523</td>
      <td>1.248248</td>
      <td>-0.333004</td>
      <td>0.345883</td>
      <td>0.064898</td>
      <td>-0.160271</td>
      <td>-0.033267</td>
      <td>-0.539496</td>
      <td>-0.925961</td>
      <td>-0.452863</td>
      <td>-0.267063</td>
      <td>...</td>
      <td>0.510997</td>
      <td>-0.198086</td>
      <td>-0.980175</td>
      <td>0.872622</td>
      <td>0.670064</td>
      <td>-0.259513</td>
      <td>-0.581394</td>
      <td>-0.319631</td>
      <td>-0.701122</td>
      <td>-0.230399</td>
      <td>-0.073817</td>
      <td>-0.260714</td>
      <td>-1.274097</td>
      <td>-0.086247</td>
      <td>0.001643</td>
      <td>-0.260869</td>
      <td>0.393606</td>
      <td>-0.312680</td>
      <td>-1.324834</td>
      <td>-1.848987</td>
      <td>-0.801646</td>
      <td>0.541731</td>
      <td>0.323992</td>
      <td>-0.628065</td>
      <td>-0.476570</td>
      <td>-0.725619</td>
      <td>-0.772605</td>
      <td>-0.017455</td>
      <td>0.071134</td>
      <td>-0.686578</td>
      <td>0.242526</td>
      <td>0.546589</td>
      <td>0.049772</td>
      <td>-1.168126</td>
      <td>-0.106200</td>
      <td>0.007362</td>
      <td>0.103332</td>
      <td>1.898971</td>
      <td>1.418489</td>
      <td>-0.217227</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.103533</td>
      <td>-0.326322</td>
      <td>-0.776600</td>
      <td>-0.735991</td>
      <td>0.057514</td>
      <td>0.085267</td>
      <td>-0.534062</td>
      <td>0.514928</td>
      <td>0.045436</td>
      <td>-0.580845</td>
      <td>-0.115903</td>
      <td>0.171535</td>
      <td>-0.308389</td>
      <td>0.847099</td>
      <td>0.665719</td>
      <td>0.037973</td>
      <td>-0.438428</td>
      <td>0.516513</td>
      <td>-0.294106</td>
      <td>0.574120</td>
      <td>-0.465325</td>
      <td>1.111386</td>
      <td>0.043629</td>
      <td>1.027934</td>
      <td>0.854766</td>
      <td>-0.586850</td>
      <td>0.002234</td>
      <td>-0.074385</td>
      <td>-1.488192</td>
      <td>-0.036562</td>
      <td>0.210283</td>
      <td>-0.945466</td>
      <td>-0.950058</td>
      <td>0.175288</td>
      <td>0.209985</td>
      <td>0.802310</td>
      <td>0.653485</td>
      <td>-0.447277</td>
      <td>-0.171382</td>
      <td>-0.430063</td>
      <td>...</td>
      <td>0.157725</td>
      <td>-0.142782</td>
      <td>1.159152</td>
      <td>0.599236</td>
      <td>-0.879692</td>
      <td>-0.343573</td>
      <td>0.556538</td>
      <td>1.352798</td>
      <td>0.902597</td>
      <td>0.623134</td>
      <td>0.657601</td>
      <td>0.570776</td>
      <td>0.472266</td>
      <td>-0.768769</td>
      <td>-0.877580</td>
      <td>-0.336340</td>
      <td>-0.086423</td>
      <td>0.361244</td>
      <td>0.157865</td>
      <td>0.371637</td>
      <td>0.367003</td>
      <td>0.386521</td>
      <td>-1.500345</td>
      <td>-0.849613</td>
      <td>0.114534</td>
      <td>0.842860</td>
      <td>-0.215502</td>
      <td>0.461874</td>
      <td>0.092791</td>
      <td>-0.347135</td>
      <td>-0.708880</td>
      <td>-0.501716</td>
      <td>-0.496905</td>
      <td>-0.852627</td>
      <td>-0.514142</td>
      <td>0.497211</td>
      <td>-0.628085</td>
      <td>0.420823</td>
      <td>0.255714</td>
      <td>-0.078822</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.675027</td>
      <td>0.493277</td>
      <td>-0.633773</td>
      <td>0.478132</td>
      <td>0.249901</td>
      <td>-1.541326</td>
      <td>-0.754634</td>
      <td>-0.043749</td>
      <td>0.621055</td>
      <td>0.156563</td>
      <td>-1.267797</td>
      <td>-0.124371</td>
      <td>0.118598</td>
      <td>-0.124781</td>
      <td>-0.208545</td>
      <td>0.027105</td>
      <td>-0.021155</td>
      <td>-0.373060</td>
      <td>-0.424911</td>
      <td>0.626492</td>
      <td>-0.001039</td>
      <td>0.293971</td>
      <td>-0.174558</td>
      <td>-0.437457</td>
      <td>-0.078291</td>
      <td>-0.410502</td>
      <td>-0.404075</td>
      <td>0.513178</td>
      <td>0.196072</td>
      <td>0.142932</td>
      <td>-0.394586</td>
      <td>-0.242348</td>
      <td>0.282858</td>
      <td>0.555078</td>
      <td>0.839342</td>
      <td>0.137696</td>
      <td>-0.373649</td>
      <td>0.060685</td>
      <td>0.596652</td>
      <td>0.385520</td>
      <td>...</td>
      <td>0.152969</td>
      <td>-0.739938</td>
      <td>0.338233</td>
      <td>1.226761</td>
      <td>-0.577629</td>
      <td>0.045018</td>
      <td>0.644930</td>
      <td>0.774579</td>
      <td>0.129453</td>
      <td>0.286948</td>
      <td>-0.159028</td>
      <td>0.530826</td>
      <td>0.021216</td>
      <td>0.075816</td>
      <td>0.212275</td>
      <td>-0.286405</td>
      <td>-0.430262</td>
      <td>-0.098199</td>
      <td>0.076822</td>
      <td>-0.299898</td>
      <td>-0.379047</td>
      <td>0.286033</td>
      <td>-0.005597</td>
      <td>0.090554</td>
      <td>0.014584</td>
      <td>0.405353</td>
      <td>-0.354118</td>
      <td>0.350626</td>
      <td>0.784980</td>
      <td>-0.639285</td>
      <td>0.596824</td>
      <td>0.576454</td>
      <td>-0.069706</td>
      <td>-0.750163</td>
      <td>-0.116628</td>
      <td>0.501621</td>
      <td>0.418138</td>
      <td>2.835112</td>
      <td>2.133650</td>
      <td>0.823008</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.037390</td>
      <td>-0.192165</td>
      <td>-1.218735</td>
      <td>-0.113793</td>
      <td>0.642715</td>
      <td>0.064702</td>
      <td>-0.597121</td>
      <td>0.566898</td>
      <td>-0.048275</td>
      <td>-0.688039</td>
      <td>-0.816730</td>
      <td>-0.810155</td>
      <td>-0.061347</td>
      <td>0.367570</td>
      <td>0.733348</td>
      <td>-0.077751</td>
      <td>-0.022472</td>
      <td>-0.058919</td>
      <td>0.156827</td>
      <td>0.018557</td>
      <td>0.219237</td>
      <td>0.542537</td>
      <td>-1.178921</td>
      <td>-0.053277</td>
      <td>-0.039482</td>
      <td>-0.555849</td>
      <td>0.040987</td>
      <td>0.375022</td>
      <td>0.374883</td>
      <td>-0.175483</td>
      <td>0.494213</td>
      <td>-0.583165</td>
      <td>0.157579</td>
      <td>-0.811258</td>
      <td>-0.177057</td>
      <td>0.406485</td>
      <td>0.187920</td>
      <td>-0.099968</td>
      <td>-0.432892</td>
      <td>-0.427325</td>
      <td>...</td>
      <td>0.047586</td>
      <td>0.325761</td>
      <td>-0.321276</td>
      <td>0.346767</td>
      <td>-0.049739</td>
      <td>-1.106355</td>
      <td>-1.173505</td>
      <td>-1.143653</td>
      <td>0.091692</td>
      <td>0.485602</td>
      <td>-0.324570</td>
      <td>-0.004364</td>
      <td>0.511062</td>
      <td>0.568192</td>
      <td>-0.989522</td>
      <td>-1.245081</td>
      <td>-0.002562</td>
      <td>-0.695577</td>
      <td>-1.014881</td>
      <td>-0.525384</td>
      <td>-0.789909</td>
      <td>-0.242505</td>
      <td>-0.754383</td>
      <td>-0.327895</td>
      <td>-0.131062</td>
      <td>0.544925</td>
      <td>0.179219</td>
      <td>-0.309520</td>
      <td>-0.211662</td>
      <td>0.702978</td>
      <td>-0.652843</td>
      <td>-1.204575</td>
      <td>-1.030357</td>
      <td>-0.749489</td>
      <td>-0.546632</td>
      <td>0.615656</td>
      <td>0.635916</td>
      <td>-0.026336</td>
      <td>-0.177935</td>
      <td>-0.881444</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.074426</td>
      <td>0.720775</td>
      <td>-0.685841</td>
      <td>-0.153704</td>
      <td>1.021003</td>
      <td>-0.115789</td>
      <td>-1.058686</td>
      <td>0.523903</td>
      <td>1.394511</td>
      <td>0.495810</td>
      <td>-0.267342</td>
      <td>-0.298105</td>
      <td>0.387990</td>
      <td>-0.159169</td>
      <td>0.689113</td>
      <td>1.101755</td>
      <td>-0.321740</td>
      <td>-0.272433</td>
      <td>-0.268452</td>
      <td>-0.003788</td>
      <td>0.743473</td>
      <td>-0.006161</td>
      <td>0.669264</td>
      <td>1.589794</td>
      <td>-0.509588</td>
      <td>-1.202327</td>
      <td>0.824841</td>
      <td>0.030319</td>
      <td>0.582486</td>
      <td>0.938025</td>
      <td>0.965207</td>
      <td>0.040951</td>
      <td>0.593908</td>
      <td>0.052011</td>
      <td>0.869601</td>
      <td>0.107055</td>
      <td>1.073128</td>
      <td>0.076912</td>
      <td>-0.218470</td>
      <td>-1.261145</td>
      <td>...</td>
      <td>0.119298</td>
      <td>0.376831</td>
      <td>-0.274389</td>
      <td>0.995305</td>
      <td>-0.528427</td>
      <td>0.122707</td>
      <td>-0.702690</td>
      <td>0.426258</td>
      <td>-0.377547</td>
      <td>-1.184724</td>
      <td>-0.593341</td>
      <td>-0.360513</td>
      <td>-0.083086</td>
      <td>-1.278671</td>
      <td>-0.016768</td>
      <td>0.541301</td>
      <td>0.785868</td>
      <td>0.217365</td>
      <td>-0.024403</td>
      <td>0.051071</td>
      <td>-0.368943</td>
      <td>0.631306</td>
      <td>0.569650</td>
      <td>-0.949445</td>
      <td>0.516827</td>
      <td>0.355405</td>
      <td>0.787550</td>
      <td>0.599756</td>
      <td>-0.584416</td>
      <td>0.035664</td>
      <td>-0.096864</td>
      <td>-0.119334</td>
      <td>-0.433233</td>
      <td>-1.725516</td>
      <td>0.284359</td>
      <td>0.467757</td>
      <td>0.466862</td>
      <td>0.512540</td>
      <td>0.355189</td>
      <td>-0.744286</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.118010</td>
      <td>-0.110938</td>
      <td>-0.769889</td>
      <td>-0.727816</td>
      <td>0.179987</td>
      <td>0.314246</td>
      <td>-0.394673</td>
      <td>0.843350</td>
      <td>1.156334</td>
      <td>-1.041891</td>
      <td>-0.453525</td>
      <td>-0.380726</td>
      <td>-0.648767</td>
      <td>0.490228</td>
      <td>0.668568</td>
      <td>0.104278</td>
      <td>-0.199980</td>
      <td>0.049295</td>
      <td>-0.654260</td>
      <td>-0.451878</td>
      <td>-0.684894</td>
      <td>0.351878</td>
      <td>-0.185401</td>
      <td>0.182389</td>
      <td>-1.507170</td>
      <td>0.080727</td>
      <td>0.585718</td>
      <td>-0.059003</td>
      <td>-0.860860</td>
      <td>-0.067705</td>
      <td>0.224755</td>
      <td>-0.648707</td>
      <td>-0.173836</td>
      <td>0.827063</td>
      <td>0.022637</td>
      <td>-0.037152</td>
      <td>0.558563</td>
      <td>0.127048</td>
      <td>0.489948</td>
      <td>-0.801757</td>
      <td>...</td>
      <td>-0.395237</td>
      <td>-0.233787</td>
      <td>0.546032</td>
      <td>-0.052471</td>
      <td>-0.342751</td>
      <td>0.199035</td>
      <td>-0.284397</td>
      <td>0.288664</td>
      <td>-0.479685</td>
      <td>-0.788770</td>
      <td>-0.901236</td>
      <td>-0.035187</td>
      <td>-0.440319</td>
      <td>-0.389615</td>
      <td>0.345157</td>
      <td>-0.175774</td>
      <td>-0.463982</td>
      <td>-0.127680</td>
      <td>-1.417245</td>
      <td>0.202473</td>
      <td>0.240015</td>
      <td>0.393232</td>
      <td>-0.276140</td>
      <td>0.533907</td>
      <td>-0.248448</td>
      <td>-0.263374</td>
      <td>-0.490048</td>
      <td>-0.255219</td>
      <td>-0.102626</td>
      <td>-0.010867</td>
      <td>0.211549</td>
      <td>0.274460</td>
      <td>-1.100753</td>
      <td>-1.084001</td>
      <td>-0.065516</td>
      <td>0.119149</td>
      <td>0.048419</td>
      <td>2.146524</td>
      <td>1.283665</td>
      <td>-0.351967</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.547931</td>
      <td>-0.072221</td>
      <td>-0.601355</td>
      <td>0.458086</td>
      <td>0.658582</td>
      <td>0.382967</td>
      <td>-0.091238</td>
      <td>-0.300720</td>
      <td>-0.650548</td>
      <td>0.233992</td>
      <td>-0.089803</td>
      <td>0.503300</td>
      <td>0.336265</td>
      <td>0.060064</td>
      <td>0.209704</td>
      <td>-0.778701</td>
      <td>-0.965446</td>
      <td>0.404555</td>
      <td>-0.694055</td>
      <td>0.385031</td>
      <td>0.709694</td>
      <td>-0.285923</td>
      <td>-0.012381</td>
      <td>0.366072</td>
      <td>-0.919599</td>
      <td>-0.838409</td>
      <td>0.285756</td>
      <td>0.098058</td>
      <td>-0.425073</td>
      <td>0.240792</td>
      <td>0.990035</td>
      <td>0.100690</td>
      <td>0.936792</td>
      <td>0.244384</td>
      <td>-0.100973</td>
      <td>0.133257</td>
      <td>0.213522</td>
      <td>0.311993</td>
      <td>0.072865</td>
      <td>-0.656141</td>
      <td>...</td>
      <td>1.078583</td>
      <td>-0.801669</td>
      <td>0.653517</td>
      <td>0.617468</td>
      <td>0.577645</td>
      <td>0.877541</td>
      <td>-0.379115</td>
      <td>-0.635221</td>
      <td>-0.008311</td>
      <td>0.038965</td>
      <td>-0.651950</td>
      <td>-0.267040</td>
      <td>-0.148657</td>
      <td>-0.594555</td>
      <td>0.408654</td>
      <td>-0.269346</td>
      <td>-0.222597</td>
      <td>0.354472</td>
      <td>0.244913</td>
      <td>-0.451517</td>
      <td>0.854460</td>
      <td>-0.171323</td>
      <td>0.693818</td>
      <td>0.214809</td>
      <td>-0.332647</td>
      <td>0.107926</td>
      <td>-0.065774</td>
      <td>0.033186</td>
      <td>0.118186</td>
      <td>-0.028347</td>
      <td>0.652424</td>
      <td>-0.846945</td>
      <td>-0.213366</td>
      <td>0.353987</td>
      <td>0.343447</td>
      <td>-0.322653</td>
      <td>-0.622805</td>
      <td>2.999352</td>
      <td>3.002788</td>
      <td>1.107333</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.848486</td>
      <td>-0.539307</td>
      <td>0.553654</td>
      <td>0.718600</td>
      <td>0.895288</td>
      <td>0.067968</td>
      <td>0.344083</td>
      <td>0.368034</td>
      <td>0.193173</td>
      <td>-1.034410</td>
      <td>-1.163150</td>
      <td>0.023491</td>
      <td>0.380925</td>
      <td>0.025362</td>
      <td>0.146890</td>
      <td>0.538042</td>
      <td>-1.475189</td>
      <td>-0.442376</td>
      <td>-0.541119</td>
      <td>0.959742</td>
      <td>0.801951</td>
      <td>0.597590</td>
      <td>-0.853288</td>
      <td>0.963197</td>
      <td>-0.537331</td>
      <td>-0.337324</td>
      <td>-0.399897</td>
      <td>0.285555</td>
      <td>-0.602416</td>
      <td>-0.050425</td>
      <td>1.023366</td>
      <td>-0.889758</td>
      <td>-0.503110</td>
      <td>-1.064252</td>
      <td>-0.289279</td>
      <td>0.780180</td>
      <td>0.145973</td>
      <td>-0.376236</td>
      <td>-0.605605</td>
      <td>-0.251223</td>
      <td>...</td>
      <td>-0.742006</td>
      <td>-1.043261</td>
      <td>-0.220245</td>
      <td>-0.007036</td>
      <td>-0.769332</td>
      <td>0.143701</td>
      <td>-0.444287</td>
      <td>0.252559</td>
      <td>-0.786365</td>
      <td>-1.080261</td>
      <td>-0.375197</td>
      <td>-0.868754</td>
      <td>-0.071326</td>
      <td>0.067638</td>
      <td>-0.798402</td>
      <td>-0.300801</td>
      <td>-0.434576</td>
      <td>-1.020483</td>
      <td>-0.013687</td>
      <td>-1.073432</td>
      <td>0.021824</td>
      <td>0.705317</td>
      <td>-0.941083</td>
      <td>-0.234524</td>
      <td>-0.013258</td>
      <td>0.306726</td>
      <td>-1.367391</td>
      <td>-0.657647</td>
      <td>-0.056123</td>
      <td>-0.331849</td>
      <td>-0.426476</td>
      <td>-0.012853</td>
      <td>-0.125951</td>
      <td>-0.934068</td>
      <td>-0.186226</td>
      <td>0.388908</td>
      <td>0.941486</td>
      <td>-0.356446</td>
      <td>-0.906418</td>
      <td>-0.964000</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.772025</td>
      <td>0.334247</td>
      <td>-0.637601</td>
      <td>1.010241</td>
      <td>0.797267</td>
      <td>-0.452644</td>
      <td>-0.340663</td>
      <td>1.470171</td>
      <td>-0.149332</td>
      <td>0.032613</td>
      <td>-0.437933</td>
      <td>-0.162010</td>
      <td>-0.201446</td>
      <td>-0.847025</td>
      <td>-0.068727</td>
      <td>-0.839806</td>
      <td>0.218511</td>
      <td>-0.241697</td>
      <td>0.250515</td>
      <td>-0.652800</td>
      <td>0.315524</td>
      <td>0.460166</td>
      <td>-0.118864</td>
      <td>-0.009497</td>
      <td>0.316296</td>
      <td>-0.910924</td>
      <td>-0.612746</td>
      <td>-0.482854</td>
      <td>-1.006871</td>
      <td>-0.044628</td>
      <td>0.538422</td>
      <td>0.191289</td>
      <td>0.404523</td>
      <td>0.678384</td>
      <td>0.159976</td>
      <td>1.121503</td>
      <td>0.982691</td>
      <td>-0.062223</td>
      <td>0.624732</td>
      <td>0.857029</td>
      <td>...</td>
      <td>-0.318240</td>
      <td>0.041095</td>
      <td>-0.371247</td>
      <td>0.175909</td>
      <td>-0.534858</td>
      <td>-0.581079</td>
      <td>-1.281117</td>
      <td>-0.006773</td>
      <td>-0.076003</td>
      <td>-0.510893</td>
      <td>-1.013163</td>
      <td>-0.170928</td>
      <td>0.512178</td>
      <td>-0.208222</td>
      <td>-0.501973</td>
      <td>0.355617</td>
      <td>-0.130014</td>
      <td>-0.650470</td>
      <td>0.596900</td>
      <td>0.593078</td>
      <td>0.398483</td>
      <td>0.243673</td>
      <td>-0.267784</td>
      <td>-0.632820</td>
      <td>-1.369804</td>
      <td>0.613583</td>
      <td>0.021433</td>
      <td>-0.530162</td>
      <td>1.036578</td>
      <td>0.035830</td>
      <td>-0.033349</td>
      <td>0.232303</td>
      <td>-0.609797</td>
      <td>-0.338979</td>
      <td>0.099387</td>
      <td>-0.508644</td>
      <td>0.417189</td>
      <td>1.576318</td>
      <td>1.435147</td>
      <td>-0.113279</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-0.279804</td>
      <td>-0.003244</td>
      <td>-1.044915</td>
      <td>0.356384</td>
      <td>1.054924</td>
      <td>-0.708964</td>
      <td>-1.050909</td>
      <td>-0.264923</td>
      <td>0.461219</td>
      <td>-0.284769</td>
      <td>-0.294635</td>
      <td>0.296434</td>
      <td>1.083738</td>
      <td>1.099923</td>
      <td>-0.708802</td>
      <td>-1.203856</td>
      <td>-1.084269</td>
      <td>-0.123340</td>
      <td>-0.533660</td>
      <td>-0.647477</td>
      <td>-0.012007</td>
      <td>-0.051624</td>
      <td>0.243671</td>
      <td>0.894469</td>
      <td>0.867170</td>
      <td>0.494454</td>
      <td>-0.451869</td>
      <td>-1.506495</td>
      <td>-1.801524</td>
      <td>-0.605167</td>
      <td>-0.501438</td>
      <td>0.008486</td>
      <td>-0.642669</td>
      <td>-0.163429</td>
      <td>-0.603319</td>
      <td>0.364814</td>
      <td>0.238493</td>
      <td>-0.848730</td>
      <td>0.271065</td>
      <td>-0.205246</td>
      <td>...</td>
      <td>0.984372</td>
      <td>-0.251652</td>
      <td>-1.777849</td>
      <td>-0.090711</td>
      <td>0.420889</td>
      <td>-0.029203</td>
      <td>0.514491</td>
      <td>-0.186003</td>
      <td>-0.723518</td>
      <td>-0.240970</td>
      <td>-0.712608</td>
      <td>0.540397</td>
      <td>-0.096636</td>
      <td>-1.192677</td>
      <td>-0.782943</td>
      <td>-1.021553</td>
      <td>0.300012</td>
      <td>0.414967</td>
      <td>0.033889</td>
      <td>0.892121</td>
      <td>0.045180</td>
      <td>0.046039</td>
      <td>0.542257</td>
      <td>0.299045</td>
      <td>-0.636113</td>
      <td>-0.190370</td>
      <td>-0.165648</td>
      <td>0.069779</td>
      <td>0.552253</td>
      <td>0.325500</td>
      <td>-0.240443</td>
      <td>-0.212852</td>
      <td>-0.587332</td>
      <td>-0.162575</td>
      <td>0.119903</td>
      <td>0.132220</td>
      <td>0.444322</td>
      <td>-0.200671</td>
      <td>-0.353091</td>
      <td>-0.570220</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.240483</td>
      <td>0.614563</td>
      <td>-0.672505</td>
      <td>-1.227766</td>
      <td>0.729796</td>
      <td>-0.005470</td>
      <td>-0.829529</td>
      <td>-0.105979</td>
      <td>0.508948</td>
      <td>-0.469755</td>
      <td>-0.635454</td>
      <td>0.147393</td>
      <td>0.795876</td>
      <td>-0.110908</td>
      <td>0.284147</td>
      <td>0.952670</td>
      <td>-0.538050</td>
      <td>0.360640</td>
      <td>0.050109</td>
      <td>0.355728</td>
      <td>0.491471</td>
      <td>0.096392</td>
      <td>0.493343</td>
      <td>0.078136</td>
      <td>-0.536796</td>
      <td>-0.761916</td>
      <td>-0.325752</td>
      <td>-0.289044</td>
      <td>-0.062835</td>
      <td>-0.627814</td>
      <td>0.971293</td>
      <td>-0.645348</td>
      <td>0.252363</td>
      <td>0.517764</td>
      <td>-0.695069</td>
      <td>0.239130</td>
      <td>0.158201</td>
      <td>0.494502</td>
      <td>0.315596</td>
      <td>-0.127016</td>
      <td>...</td>
      <td>0.655523</td>
      <td>-0.893544</td>
      <td>0.192305</td>
      <td>0.581317</td>
      <td>-0.252849</td>
      <td>0.552035</td>
      <td>1.317420</td>
      <td>0.465554</td>
      <td>-0.562947</td>
      <td>0.364472</td>
      <td>-0.079435</td>
      <td>-0.386229</td>
      <td>-0.085736</td>
      <td>-0.311948</td>
      <td>0.061458</td>
      <td>0.556917</td>
      <td>-0.053368</td>
      <td>-0.723462</td>
      <td>-0.358490</td>
      <td>-0.502864</td>
      <td>-0.266424</td>
      <td>0.321865</td>
      <td>0.104279</td>
      <td>0.435664</td>
      <td>0.651276</td>
      <td>1.274781</td>
      <td>0.905569</td>
      <td>-0.398914</td>
      <td>0.329112</td>
      <td>-0.159909</td>
      <td>0.659135</td>
      <td>0.058828</td>
      <td>-0.223241</td>
      <td>-0.233657</td>
      <td>0.526939</td>
      <td>0.755009</td>
      <td>0.217973</td>
      <td>2.231990</td>
      <td>2.069460</td>
      <td>0.968073</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-0.073118</td>
      <td>-0.049798</td>
      <td>0.014247</td>
      <td>-0.168423</td>
      <td>0.571824</td>
      <td>-0.754766</td>
      <td>-0.488538</td>
      <td>1.187726</td>
      <td>-0.269059</td>
      <td>-0.491177</td>
      <td>-0.719620</td>
      <td>-0.176104</td>
      <td>0.307849</td>
      <td>0.937435</td>
      <td>-0.763040</td>
      <td>-0.937514</td>
      <td>-1.152833</td>
      <td>-0.094023</td>
      <td>-0.125148</td>
      <td>0.122391</td>
      <td>-0.056805</td>
      <td>0.469287</td>
      <td>0.216819</td>
      <td>0.511809</td>
      <td>0.580703</td>
      <td>-0.298425</td>
      <td>-0.177676</td>
      <td>-0.225735</td>
      <td>-1.202090</td>
      <td>-0.432869</td>
      <td>0.162033</td>
      <td>0.076684</td>
      <td>0.325288</td>
      <td>0.479120</td>
      <td>-0.125593</td>
      <td>-0.148949</td>
      <td>-0.963790</td>
      <td>0.319401</td>
      <td>-0.136226</td>
      <td>1.381005</td>
      <td>...</td>
      <td>0.306881</td>
      <td>-0.723059</td>
      <td>-0.109765</td>
      <td>0.533448</td>
      <td>-0.441458</td>
      <td>0.928407</td>
      <td>0.041063</td>
      <td>-0.171592</td>
      <td>-0.158791</td>
      <td>-0.154741</td>
      <td>-0.110160</td>
      <td>-0.341058</td>
      <td>0.043238</td>
      <td>1.067616</td>
      <td>-0.263962</td>
      <td>-0.065770</td>
      <td>-0.085362</td>
      <td>-0.977075</td>
      <td>-0.950943</td>
      <td>-1.101870</td>
      <td>-1.028061</td>
      <td>0.462672</td>
      <td>-0.840447</td>
      <td>-0.093938</td>
      <td>-0.153588</td>
      <td>0.622502</td>
      <td>0.462367</td>
      <td>-0.329228</td>
      <td>0.416565</td>
      <td>-0.236379</td>
      <td>-0.002541</td>
      <td>-0.911424</td>
      <td>-1.451273</td>
      <td>-0.200535</td>
      <td>0.537654</td>
      <td>-0.432411</td>
      <td>0.879435</td>
      <td>-1.051911</td>
      <td>0.009114</td>
      <td>-0.686137</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.528992</td>
      <td>0.730761</td>
      <td>0.531856</td>
      <td>0.146917</td>
      <td>-0.598744</td>
      <td>-0.570350</td>
      <td>-0.384097</td>
      <td>-0.917982</td>
      <td>0.466942</td>
      <td>0.784071</td>
      <td>-0.217720</td>
      <td>0.133885</td>
      <td>0.012912</td>
      <td>-0.153718</td>
      <td>-0.221880</td>
      <td>1.128202</td>
      <td>-0.014660</td>
      <td>-1.742461</td>
      <td>-1.203995</td>
      <td>-0.895732</td>
      <td>0.146479</td>
      <td>-0.318898</td>
      <td>-0.474915</td>
      <td>-0.172667</td>
      <td>-0.816553</td>
      <td>0.011483</td>
      <td>-0.120959</td>
      <td>0.833514</td>
      <td>-0.199376</td>
      <td>0.372531</td>
      <td>0.801751</td>
      <td>-0.290284</td>
      <td>-0.284768</td>
      <td>0.111160</td>
      <td>-0.441969</td>
      <td>0.515101</td>
      <td>1.397232</td>
      <td>-0.324818</td>
      <td>0.257625</td>
      <td>-0.475659</td>
      <td>...</td>
      <td>0.432248</td>
      <td>-0.458380</td>
      <td>0.575709</td>
      <td>0.050868</td>
      <td>-0.017707</td>
      <td>-0.400906</td>
      <td>-0.407213</td>
      <td>0.060465</td>
      <td>0.001809</td>
      <td>0.305832</td>
      <td>0.400228</td>
      <td>0.147949</td>
      <td>0.207415</td>
      <td>0.501415</td>
      <td>0.277030</td>
      <td>1.246042</td>
      <td>0.781403</td>
      <td>0.735288</td>
      <td>-0.475673</td>
      <td>-0.324680</td>
      <td>-0.111994</td>
      <td>1.130377</td>
      <td>1.224090</td>
      <td>-0.177489</td>
      <td>-1.313610</td>
      <td>0.897575</td>
      <td>-0.937388</td>
      <td>-0.375355</td>
      <td>-0.132184</td>
      <td>0.272013</td>
      <td>-0.567184</td>
      <td>-0.326178</td>
      <td>-0.627499</td>
      <td>-2.198927</td>
      <td>-0.806622</td>
      <td>-0.064325</td>
      <td>0.120701</td>
      <td>1.997119</td>
      <td>1.434084</td>
      <td>0.088234</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-1.027666</td>
      <td>-0.608241</td>
      <td>-0.298158</td>
      <td>0.706909</td>
      <td>0.534060</td>
      <td>0.273159</td>
      <td>0.106988</td>
      <td>-0.058276</td>
      <td>1.007045</td>
      <td>-0.892806</td>
      <td>-0.334782</td>
      <td>-0.107171</td>
      <td>-0.251299</td>
      <td>1.135008</td>
      <td>-0.380989</td>
      <td>-0.712565</td>
      <td>-1.304660</td>
      <td>-1.118470</td>
      <td>-0.924208</td>
      <td>-0.089418</td>
      <td>0.344384</td>
      <td>-0.982527</td>
      <td>-0.336086</td>
      <td>1.488450</td>
      <td>0.427561</td>
      <td>-0.174976</td>
      <td>-0.199580</td>
      <td>0.009633</td>
      <td>-0.227908</td>
      <td>-0.460047</td>
      <td>1.322282</td>
      <td>0.310658</td>
      <td>-0.288179</td>
      <td>-1.508903</td>
      <td>-0.564882</td>
      <td>0.217567</td>
      <td>1.465298</td>
      <td>0.191589</td>
      <td>0.766791</td>
      <td>0.417876</td>
      <td>...</td>
      <td>-0.385166</td>
      <td>-0.391073</td>
      <td>-0.215204</td>
      <td>0.712536</td>
      <td>0.234921</td>
      <td>-0.506074</td>
      <td>-0.351467</td>
      <td>0.341045</td>
      <td>-0.029506</td>
      <td>-0.159101</td>
      <td>-0.436131</td>
      <td>0.294602</td>
      <td>-0.315792</td>
      <td>-0.561920</td>
      <td>0.030403</td>
      <td>-0.176100</td>
      <td>1.485153</td>
      <td>1.037630</td>
      <td>0.537414</td>
      <td>0.554314</td>
      <td>-0.531910</td>
      <td>0.261997</td>
      <td>0.354120</td>
      <td>-0.304707</td>
      <td>-0.260691</td>
      <td>-0.405165</td>
      <td>-0.058434</td>
      <td>0.267566</td>
      <td>-0.674894</td>
      <td>0.359183</td>
      <td>-0.173574</td>
      <td>0.039859</td>
      <td>0.371735</td>
      <td>0.346442</td>
      <td>-0.239841</td>
      <td>0.274883</td>
      <td>0.018063</td>
      <td>-2.169202</td>
      <td>-0.423563</td>
      <td>-0.121000</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.359240</td>
      <td>0.074557</td>
      <td>0.348015</td>
      <td>0.267763</td>
      <td>1.316686</td>
      <td>-0.751541</td>
      <td>-0.277222</td>
      <td>-0.100118</td>
      <td>-0.262064</td>
      <td>-0.973941</td>
      <td>-0.820911</td>
      <td>-0.587136</td>
      <td>-0.669357</td>
      <td>-0.212188</td>
      <td>-0.706994</td>
      <td>0.211234</td>
      <td>-0.316920</td>
      <td>-1.629169</td>
      <td>-0.558741</td>
      <td>0.391174</td>
      <td>0.939177</td>
      <td>0.416875</td>
      <td>0.200996</td>
      <td>0.982334</td>
      <td>-0.119931</td>
      <td>-0.975350</td>
      <td>-0.629184</td>
      <td>-0.386135</td>
      <td>0.450545</td>
      <td>0.241665</td>
      <td>1.061880</td>
      <td>-1.363102</td>
      <td>-0.397799</td>
      <td>-0.449278</td>
      <td>-1.067580</td>
      <td>1.338859</td>
      <td>0.872039</td>
      <td>-0.544140</td>
      <td>0.122649</td>
      <td>-0.692222</td>
      <td>...</td>
      <td>0.390719</td>
      <td>0.716503</td>
      <td>0.086677</td>
      <td>0.474268</td>
      <td>0.333493</td>
      <td>0.798132</td>
      <td>-0.241057</td>
      <td>-0.533781</td>
      <td>0.239179</td>
      <td>0.345402</td>
      <td>-0.133861</td>
      <td>0.572197</td>
      <td>-0.408650</td>
      <td>-0.032990</td>
      <td>1.250861</td>
      <td>-0.230271</td>
      <td>0.100780</td>
      <td>-1.575120</td>
      <td>-0.620925</td>
      <td>0.175240</td>
      <td>-0.502891</td>
      <td>-0.568473</td>
      <td>-0.137043</td>
      <td>-0.591910</td>
      <td>-0.466151</td>
      <td>-0.194536</td>
      <td>0.036912</td>
      <td>-0.631711</td>
      <td>0.127840</td>
      <td>-0.093478</td>
      <td>0.059614</td>
      <td>-0.193003</td>
      <td>-0.716704</td>
      <td>-0.342583</td>
      <td>0.982895</td>
      <td>0.732283</td>
      <td>0.206895</td>
      <td>-0.384981</td>
      <td>-0.097659</td>
      <td>-0.030077</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.541212</td>
      <td>1.526317</td>
      <td>-0.333227</td>
      <td>1.022782</td>
      <td>1.041736</td>
      <td>-0.031749</td>
      <td>0.059623</td>
      <td>0.957308</td>
      <td>1.032497</td>
      <td>0.441373</td>
      <td>0.160029</td>
      <td>0.615302</td>
      <td>0.323289</td>
      <td>0.161266</td>
      <td>-0.042060</td>
      <td>-1.094146</td>
      <td>-0.757213</td>
      <td>-0.196822</td>
      <td>-0.910804</td>
      <td>0.137488</td>
      <td>-0.778102</td>
      <td>0.032152</td>
      <td>0.496343</td>
      <td>0.590704</td>
      <td>-0.194077</td>
      <td>-0.961902</td>
      <td>0.599629</td>
      <td>-0.369889</td>
      <td>-0.156781</td>
      <td>0.121568</td>
      <td>1.336367</td>
      <td>-0.115554</td>
      <td>0.657941</td>
      <td>1.129784</td>
      <td>0.121087</td>
      <td>1.496946</td>
      <td>1.568042</td>
      <td>0.181679</td>
      <td>0.906067</td>
      <td>0.591439</td>
      <td>...</td>
      <td>-0.154184</td>
      <td>-0.585250</td>
      <td>-0.361707</td>
      <td>0.103706</td>
      <td>-1.242583</td>
      <td>-0.566343</td>
      <td>0.430737</td>
      <td>0.043321</td>
      <td>0.867222</td>
      <td>0.248539</td>
      <td>-0.229670</td>
      <td>0.297325</td>
      <td>-0.022666</td>
      <td>-0.127439</td>
      <td>-0.284085</td>
      <td>-0.983302</td>
      <td>-1.227965</td>
      <td>-0.520095</td>
      <td>-0.966134</td>
      <td>0.027943</td>
      <td>-0.304300</td>
      <td>0.364183</td>
      <td>0.777371</td>
      <td>-0.390906</td>
      <td>0.568670</td>
      <td>0.158093</td>
      <td>0.231344</td>
      <td>0.030970</td>
      <td>0.228003</td>
      <td>-0.661844</td>
      <td>-0.593767</td>
      <td>-0.011129</td>
      <td>-1.585156</td>
      <td>-1.560191</td>
      <td>-0.339556</td>
      <td>0.299443</td>
      <td>0.490493</td>
      <td>1.944183</td>
      <td>1.705895</td>
      <td>-0.048389</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.148681</td>
      <td>0.191106</td>
      <td>-0.506730</td>
      <td>0.285953</td>
      <td>1.651688</td>
      <td>0.377486</td>
      <td>-0.730138</td>
      <td>0.250544</td>
      <td>0.689035</td>
      <td>0.103836</td>
      <td>0.037666</td>
      <td>-1.490770</td>
      <td>-1.178852</td>
      <td>-0.287536</td>
      <td>-0.886150</td>
      <td>-0.655092</td>
      <td>-0.868485</td>
      <td>-0.596369</td>
      <td>-0.542877</td>
      <td>-0.205739</td>
      <td>0.219585</td>
      <td>-0.454416</td>
      <td>0.068236</td>
      <td>-0.229560</td>
      <td>0.385405</td>
      <td>-0.370391</td>
      <td>-0.126222</td>
      <td>-0.402257</td>
      <td>0.183304</td>
      <td>0.345846</td>
      <td>1.303523</td>
      <td>-0.288950</td>
      <td>-0.132116</td>
      <td>0.367266</td>
      <td>-1.227789</td>
      <td>1.111583</td>
      <td>0.087663</td>
      <td>0.229663</td>
      <td>-0.616693</td>
      <td>-0.633199</td>
      <td>...</td>
      <td>0.490332</td>
      <td>0.359485</td>
      <td>0.658850</td>
      <td>0.813064</td>
      <td>-0.123507</td>
      <td>-0.330385</td>
      <td>0.285755</td>
      <td>1.049679</td>
      <td>-1.878496</td>
      <td>-0.113179</td>
      <td>-0.903377</td>
      <td>-0.252981</td>
      <td>0.232133</td>
      <td>-0.154369</td>
      <td>-0.081623</td>
      <td>-0.684814</td>
      <td>-0.823079</td>
      <td>-0.471017</td>
      <td>-0.554847</td>
      <td>-0.268331</td>
      <td>0.474082</td>
      <td>-0.765961</td>
      <td>-0.262043</td>
      <td>-0.449024</td>
      <td>0.138191</td>
      <td>-0.837062</td>
      <td>-0.757114</td>
      <td>-0.258748</td>
      <td>-0.379514</td>
      <td>1.142726</td>
      <td>-0.784629</td>
      <td>-1.022902</td>
      <td>-0.534313</td>
      <td>-0.431555</td>
      <td>0.212311</td>
      <td>0.702316</td>
      <td>-0.198445</td>
      <td>0.158262</td>
      <td>0.243352</td>
      <td>0.121307</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.650461</td>
      <td>0.451968</td>
      <td>0.010953</td>
      <td>-0.075409</td>
      <td>0.546696</td>
      <td>-0.342293</td>
      <td>-0.118448</td>
      <td>0.590285</td>
      <td>0.287110</td>
      <td>-0.109364</td>
      <td>-0.245498</td>
      <td>0.503449</td>
      <td>0.512517</td>
      <td>-0.268468</td>
      <td>-0.010761</td>
      <td>-0.581851</td>
      <td>-0.447083</td>
      <td>0.026868</td>
      <td>-0.580176</td>
      <td>-0.617941</td>
      <td>-0.405069</td>
      <td>0.165516</td>
      <td>0.007747</td>
      <td>1.052903</td>
      <td>0.107805</td>
      <td>0.487412</td>
      <td>-0.022632</td>
      <td>0.141504</td>
      <td>-0.296349</td>
      <td>0.555674</td>
      <td>-0.219200</td>
      <td>0.319793</td>
      <td>-0.048276</td>
      <td>0.164159</td>
      <td>-1.049605</td>
      <td>-0.091059</td>
      <td>0.174844</td>
      <td>-0.222993</td>
      <td>-0.553445</td>
      <td>-0.319299</td>
      <td>...</td>
      <td>-0.620346</td>
      <td>-1.097008</td>
      <td>0.223370</td>
      <td>-0.297375</td>
      <td>-0.775566</td>
      <td>-0.271508</td>
      <td>-1.156698</td>
      <td>-0.092295</td>
      <td>-0.607133</td>
      <td>-0.851664</td>
      <td>-0.947351</td>
      <td>-1.456786</td>
      <td>-0.792027</td>
      <td>-0.156639</td>
      <td>-0.557657</td>
      <td>-0.957450</td>
      <td>0.612592</td>
      <td>0.420888</td>
      <td>-0.897026</td>
      <td>0.200988</td>
      <td>-0.019399</td>
      <td>-0.348702</td>
      <td>-0.801365</td>
      <td>-0.398447</td>
      <td>0.008845</td>
      <td>-0.764076</td>
      <td>-0.215139</td>
      <td>-0.121225</td>
      <td>-0.717724</td>
      <td>0.492381</td>
      <td>-0.173277</td>
      <td>-1.103724</td>
      <td>-1.307167</td>
      <td>-0.689508</td>
      <td>-1.045589</td>
      <td>-1.198751</td>
      <td>0.009821</td>
      <td>0.797473</td>
      <td>0.742238</td>
      <td>-0.303093</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.338928</td>
      <td>0.836968</td>
      <td>-0.578144</td>
      <td>-0.064108</td>
      <td>-0.015480</td>
      <td>0.117462</td>
      <td>0.338515</td>
      <td>0.125412</td>
      <td>-0.170777</td>
      <td>0.128928</td>
      <td>-0.119906</td>
      <td>0.483988</td>
      <td>1.707504</td>
      <td>0.888708</td>
      <td>0.432639</td>
      <td>-0.031267</td>
      <td>-1.237827</td>
      <td>-0.217242</td>
      <td>-0.414414</td>
      <td>0.456136</td>
      <td>-0.260629</td>
      <td>-0.359073</td>
      <td>-0.166446</td>
      <td>0.596121</td>
      <td>0.509098</td>
      <td>0.773615</td>
      <td>0.112494</td>
      <td>-0.359293</td>
      <td>-1.164767</td>
      <td>0.128239</td>
      <td>0.026985</td>
      <td>0.086406</td>
      <td>-0.668404</td>
      <td>-0.570295</td>
      <td>-0.439706</td>
      <td>-0.309068</td>
      <td>-0.604542</td>
      <td>-0.656985</td>
      <td>-0.255583</td>
      <td>0.037246</td>
      <td>...</td>
      <td>0.684275</td>
      <td>0.599647</td>
      <td>0.854417</td>
      <td>1.580970</td>
      <td>-0.634281</td>
      <td>0.697159</td>
      <td>-0.036178</td>
      <td>0.497457</td>
      <td>-0.041330</td>
      <td>0.468551</td>
      <td>-0.233498</td>
      <td>-0.351634</td>
      <td>0.181694</td>
      <td>-0.818728</td>
      <td>0.394419</td>
      <td>-0.070440</td>
      <td>-0.424657</td>
      <td>-0.404381</td>
      <td>-0.522501</td>
      <td>0.285264</td>
      <td>0.824549</td>
      <td>0.120134</td>
      <td>0.237392</td>
      <td>0.095267</td>
      <td>0.087384</td>
      <td>0.142875</td>
      <td>-0.101366</td>
      <td>-0.077178</td>
      <td>0.616401</td>
      <td>0.090621</td>
      <td>-0.838468</td>
      <td>-0.139691</td>
      <td>-1.681144</td>
      <td>-0.300717</td>
      <td>-0.410427</td>
      <td>-0.372151</td>
      <td>0.304969</td>
      <td>2.266682</td>
      <td>1.776451</td>
      <td>0.354800</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.460372</td>
      <td>0.805867</td>
      <td>0.503792</td>
      <td>0.622404</td>
      <td>0.235476</td>
      <td>0.231860</td>
      <td>-0.638840</td>
      <td>0.536487</td>
      <td>0.253196</td>
      <td>1.085363</td>
      <td>-0.399832</td>
      <td>-0.222979</td>
      <td>0.440044</td>
      <td>-0.509716</td>
      <td>-0.898919</td>
      <td>-0.847777</td>
      <td>-0.231017</td>
      <td>-0.430071</td>
      <td>-1.083785</td>
      <td>-0.478296</td>
      <td>-0.376043</td>
      <td>0.277170</td>
      <td>0.498575</td>
      <td>1.329829</td>
      <td>1.240431</td>
      <td>-0.021748</td>
      <td>-0.275846</td>
      <td>1.126754</td>
      <td>-0.533597</td>
      <td>-0.881008</td>
      <td>1.163011</td>
      <td>-0.196725</td>
      <td>0.358802</td>
      <td>-0.871013</td>
      <td>-0.235994</td>
      <td>0.224509</td>
      <td>1.024500</td>
      <td>0.442733</td>
      <td>-0.381980</td>
      <td>-1.208911</td>
      <td>...</td>
      <td>0.060308</td>
      <td>0.030498</td>
      <td>-0.424673</td>
      <td>0.710345</td>
      <td>-0.655309</td>
      <td>-0.255005</td>
      <td>-0.169969</td>
      <td>0.296588</td>
      <td>0.521283</td>
      <td>0.803244</td>
      <td>-0.040642</td>
      <td>0.271605</td>
      <td>-0.341475</td>
      <td>-0.360272</td>
      <td>-0.129656</td>
      <td>-0.401910</td>
      <td>0.327208</td>
      <td>1.124824</td>
      <td>1.307825</td>
      <td>0.872030</td>
      <td>0.689793</td>
      <td>0.554222</td>
      <td>0.230112</td>
      <td>0.297401</td>
      <td>0.137768</td>
      <td>-0.041000</td>
      <td>-0.580782</td>
      <td>-0.196259</td>
      <td>-0.003407</td>
      <td>0.579620</td>
      <td>0.160338</td>
      <td>-0.240954</td>
      <td>-1.622707</td>
      <td>-0.114646</td>
      <td>-0.377166</td>
      <td>-0.087520</td>
      <td>-0.128169</td>
      <td>1.747731</td>
      <td>1.549107</td>
      <td>0.816211</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.476842</td>
      <td>0.418245</td>
      <td>-0.157524</td>
      <td>1.574360</td>
      <td>0.407777</td>
      <td>-0.044191</td>
      <td>-0.522590</td>
      <td>-0.608106</td>
      <td>0.853979</td>
      <td>-1.207878</td>
      <td>-1.584977</td>
      <td>0.099229</td>
      <td>0.008791</td>
      <td>-0.388940</td>
      <td>0.267429</td>
      <td>-0.016545</td>
      <td>-0.495620</td>
      <td>0.082812</td>
      <td>-1.389962</td>
      <td>-0.086319</td>
      <td>0.500156</td>
      <td>-0.505688</td>
      <td>-0.451045</td>
      <td>0.325071</td>
      <td>0.297908</td>
      <td>-0.039636</td>
      <td>-1.789119</td>
      <td>-0.932263</td>
      <td>-0.661905</td>
      <td>0.146277</td>
      <td>0.105362</td>
      <td>-0.451401</td>
      <td>0.675614</td>
      <td>0.228009</td>
      <td>-0.507056</td>
      <td>-0.993973</td>
      <td>0.110629</td>
      <td>-0.263758</td>
      <td>-0.589802</td>
      <td>-0.032209</td>
      <td>...</td>
      <td>0.752145</td>
      <td>-0.886418</td>
      <td>0.610291</td>
      <td>0.854900</td>
      <td>0.446579</td>
      <td>-0.014998</td>
      <td>-0.525565</td>
      <td>-0.334589</td>
      <td>0.438565</td>
      <td>0.545129</td>
      <td>-0.270300</td>
      <td>0.595028</td>
      <td>-0.171452</td>
      <td>-0.473369</td>
      <td>-0.030453</td>
      <td>-0.203752</td>
      <td>-0.207819</td>
      <td>-0.315259</td>
      <td>-0.666466</td>
      <td>-0.370279</td>
      <td>0.034190</td>
      <td>-0.627180</td>
      <td>-0.467688</td>
      <td>-0.258068</td>
      <td>0.036218</td>
      <td>-0.482603</td>
      <td>-0.072667</td>
      <td>0.472977</td>
      <td>-0.242148</td>
      <td>-0.161711</td>
      <td>-0.049007</td>
      <td>0.236102</td>
      <td>0.919532</td>
      <td>-0.156969</td>
      <td>0.239899</td>
      <td>-0.375818</td>
      <td>-0.586948</td>
      <td>1.256745</td>
      <td>1.217371</td>
      <td>0.598314</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.123461</td>
      <td>0.038252</td>
      <td>-0.728887</td>
      <td>-0.088239</td>
      <td>0.249207</td>
      <td>-0.703623</td>
      <td>-1.146711</td>
      <td>-0.198438</td>
      <td>0.922699</td>
      <td>-0.555495</td>
      <td>-0.616230</td>
      <td>-0.570245</td>
      <td>0.287215</td>
      <td>0.972492</td>
      <td>-0.028225</td>
      <td>0.063703</td>
      <td>0.549130</td>
      <td>0.050705</td>
      <td>-0.837391</td>
      <td>-0.455849</td>
      <td>0.595579</td>
      <td>0.059259</td>
      <td>0.344340</td>
      <td>0.127159</td>
      <td>0.313901</td>
      <td>-0.402550</td>
      <td>0.780172</td>
      <td>0.262497</td>
      <td>-0.213478</td>
      <td>-0.854794</td>
      <td>0.296551</td>
      <td>-1.112925</td>
      <td>-0.388979</td>
      <td>-0.265273</td>
      <td>0.172297</td>
      <td>-0.103854</td>
      <td>0.105282</td>
      <td>0.535003</td>
      <td>-0.330193</td>
      <td>-0.518377</td>
      <td>...</td>
      <td>0.290597</td>
      <td>-0.572508</td>
      <td>-0.266465</td>
      <td>1.310746</td>
      <td>0.005329</td>
      <td>0.093386</td>
      <td>0.326169</td>
      <td>0.873299</td>
      <td>-0.175375</td>
      <td>-1.392627</td>
      <td>0.171194</td>
      <td>-0.008313</td>
      <td>-0.307525</td>
      <td>-0.812774</td>
      <td>0.394024</td>
      <td>-0.561742</td>
      <td>0.356251</td>
      <td>0.065898</td>
      <td>0.642738</td>
      <td>-0.007374</td>
      <td>-0.032303</td>
      <td>0.917573</td>
      <td>-0.165821</td>
      <td>-0.798218</td>
      <td>0.706270</td>
      <td>0.380575</td>
      <td>-0.151237</td>
      <td>-0.049338</td>
      <td>-0.202200</td>
      <td>0.142887</td>
      <td>-0.777005</td>
      <td>-0.652540</td>
      <td>-1.206987</td>
      <td>-0.315656</td>
      <td>-0.680765</td>
      <td>0.120533</td>
      <td>0.047236</td>
      <td>0.909165</td>
      <td>1.402227</td>
      <td>0.242362</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.008239</td>
      <td>0.560905</td>
      <td>-1.262695</td>
      <td>0.451932</td>
      <td>0.414845</td>
      <td>0.157557</td>
      <td>-0.064160</td>
      <td>0.489840</td>
      <td>0.187570</td>
      <td>0.374389</td>
      <td>0.563126</td>
      <td>-0.620739</td>
      <td>0.293582</td>
      <td>0.010089</td>
      <td>0.398816</td>
      <td>0.351866</td>
      <td>-0.863064</td>
      <td>-0.038605</td>
      <td>0.908817</td>
      <td>-0.123068</td>
      <td>-0.404893</td>
      <td>-0.129693</td>
      <td>0.785257</td>
      <td>0.565124</td>
      <td>-0.201266</td>
      <td>-0.532422</td>
      <td>0.289372</td>
      <td>0.259547</td>
      <td>-0.959545</td>
      <td>0.389516</td>
      <td>1.086717</td>
      <td>0.056084</td>
      <td>0.416177</td>
      <td>-0.370895</td>
      <td>0.639767</td>
      <td>0.374473</td>
      <td>0.599675</td>
      <td>0.546646</td>
      <td>0.233214</td>
      <td>-0.089431</td>
      <td>...</td>
      <td>0.694083</td>
      <td>-0.496707</td>
      <td>-0.535436</td>
      <td>1.060950</td>
      <td>0.222639</td>
      <td>-0.319692</td>
      <td>-0.625545</td>
      <td>0.192370</td>
      <td>-0.435653</td>
      <td>-0.148724</td>
      <td>0.174898</td>
      <td>-0.288925</td>
      <td>-0.312400</td>
      <td>-0.937563</td>
      <td>-1.883544</td>
      <td>-0.825657</td>
      <td>-1.024163</td>
      <td>-0.778264</td>
      <td>-0.958166</td>
      <td>-0.333468</td>
      <td>0.315022</td>
      <td>1.313543</td>
      <td>0.284690</td>
      <td>0.495010</td>
      <td>0.666510</td>
      <td>1.325981</td>
      <td>0.564461</td>
      <td>1.669751</td>
      <td>-0.201856</td>
      <td>-0.107822</td>
      <td>-0.118184</td>
      <td>-0.119084</td>
      <td>-0.229160</td>
      <td>-0.190078</td>
      <td>-0.454532</td>
      <td>-0.499430</td>
      <td>-0.010657</td>
      <td>-0.580659</td>
      <td>0.539464</td>
      <td>0.084028</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-0.118203</td>
      <td>0.075481</td>
      <td>0.307946</td>
      <td>-0.082523</td>
      <td>0.779784</td>
      <td>-0.610929</td>
      <td>-0.829047</td>
      <td>-0.995660</td>
      <td>-1.118128</td>
      <td>-0.255156</td>
      <td>-0.917311</td>
      <td>0.469170</td>
      <td>0.157834</td>
      <td>0.091710</td>
      <td>-0.727672</td>
      <td>-0.968860</td>
      <td>-1.176233</td>
      <td>-0.176805</td>
      <td>-0.882035</td>
      <td>-0.219811</td>
      <td>-0.249268</td>
      <td>-0.561249</td>
      <td>-0.163823</td>
      <td>1.719467</td>
      <td>0.181043</td>
      <td>-0.670942</td>
      <td>-0.524512</td>
      <td>-0.466473</td>
      <td>-1.110156</td>
      <td>0.336758</td>
      <td>0.791308</td>
      <td>-0.125195</td>
      <td>0.720084</td>
      <td>-0.289901</td>
      <td>-0.390602</td>
      <td>0.060125</td>
      <td>0.164871</td>
      <td>0.243050</td>
      <td>0.765225</td>
      <td>0.324823</td>
      <td>...</td>
      <td>-0.162351</td>
      <td>-0.011072</td>
      <td>-0.591461</td>
      <td>0.960699</td>
      <td>0.299948</td>
      <td>0.593475</td>
      <td>0.068687</td>
      <td>1.160676</td>
      <td>-0.618414</td>
      <td>0.607845</td>
      <td>-0.843796</td>
      <td>-0.079021</td>
      <td>0.099592</td>
      <td>-0.384753</td>
      <td>0.193977</td>
      <td>0.136984</td>
      <td>0.917452</td>
      <td>-0.160387</td>
      <td>0.066480</td>
      <td>0.385444</td>
      <td>-0.178296</td>
      <td>0.480187</td>
      <td>1.081524</td>
      <td>-0.113540</td>
      <td>-0.168648</td>
      <td>1.067496</td>
      <td>0.734577</td>
      <td>0.106930</td>
      <td>0.107630</td>
      <td>0.447406</td>
      <td>0.325826</td>
      <td>-0.218313</td>
      <td>-0.996010</td>
      <td>-0.243595</td>
      <td>-0.011415</td>
      <td>0.964966</td>
      <td>0.014834</td>
      <td>0.345790</td>
      <td>0.520307</td>
      <td>-1.045717</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>0.085151</td>
      <td>-0.698104</td>
      <td>0.820061</td>
      <td>-0.377117</td>
      <td>0.355319</td>
      <td>-0.166887</td>
      <td>0.377675</td>
      <td>1.226292</td>
      <td>0.918907</td>
      <td>-0.858241</td>
      <td>0.983015</td>
      <td>0.050794</td>
      <td>0.273270</td>
      <td>1.455548</td>
      <td>0.542464</td>
      <td>-0.097210</td>
      <td>-0.273665</td>
      <td>-0.792809</td>
      <td>0.449473</td>
      <td>0.378640</td>
      <td>0.302957</td>
      <td>0.618678</td>
      <td>1.433711</td>
      <td>0.596563</td>
      <td>0.441285</td>
      <td>0.130626</td>
      <td>0.118956</td>
      <td>0.466797</td>
      <td>-0.612976</td>
      <td>-0.557951</td>
      <td>-0.098545</td>
      <td>0.189138</td>
      <td>-0.009422</td>
      <td>-0.848523</td>
      <td>0.471851</td>
      <td>0.144931</td>
      <td>-0.399580</td>
      <td>-0.866598</td>
      <td>-1.042191</td>
      <td>-1.131341</td>
      <td>...</td>
      <td>-0.531782</td>
      <td>-1.020026</td>
      <td>0.386270</td>
      <td>-0.646286</td>
      <td>0.047502</td>
      <td>0.545315</td>
      <td>0.472408</td>
      <td>0.063678</td>
      <td>0.790466</td>
      <td>-0.856716</td>
      <td>-0.433373</td>
      <td>0.590645</td>
      <td>0.561089</td>
      <td>-0.285485</td>
      <td>0.001241</td>
      <td>-0.158696</td>
      <td>0.621726</td>
      <td>0.102240</td>
      <td>0.469235</td>
      <td>-0.117796</td>
      <td>-0.111806</td>
      <td>0.282818</td>
      <td>-0.833524</td>
      <td>-1.137378</td>
      <td>-0.120962</td>
      <td>1.275857</td>
      <td>-0.345916</td>
      <td>0.241048</td>
      <td>0.267348</td>
      <td>-0.445372</td>
      <td>-0.720727</td>
      <td>0.676848</td>
      <td>1.083282</td>
      <td>-0.886872</td>
      <td>-0.201801</td>
      <td>-0.103777</td>
      <td>0.646284</td>
      <td>1.922848</td>
      <td>0.529117</td>
      <td>1.403495</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.091505</td>
      <td>0.143833</td>
      <td>0.501468</td>
      <td>0.625949</td>
      <td>0.911723</td>
      <td>-0.637693</td>
      <td>0.509664</td>
      <td>0.231217</td>
      <td>-0.137814</td>
      <td>0.431252</td>
      <td>0.063002</td>
      <td>0.143676</td>
      <td>-0.309555</td>
      <td>0.723282</td>
      <td>-0.074148</td>
      <td>0.182099</td>
      <td>-0.761628</td>
      <td>-0.656710</td>
      <td>0.548843</td>
      <td>1.131413</td>
      <td>-0.543462</td>
      <td>-0.253524</td>
      <td>0.734395</td>
      <td>0.088969</td>
      <td>-0.553033</td>
      <td>1.033471</td>
      <td>-0.978650</td>
      <td>-0.272332</td>
      <td>-0.387718</td>
      <td>0.068859</td>
      <td>0.446930</td>
      <td>0.512100</td>
      <td>-0.715044</td>
      <td>-0.705642</td>
      <td>-0.911971</td>
      <td>-0.988649</td>
      <td>-0.618902</td>
      <td>-1.106217</td>
      <td>-0.723297</td>
      <td>-0.770855</td>
      <td>...</td>
      <td>0.514090</td>
      <td>0.752399</td>
      <td>-0.007876</td>
      <td>0.181992</td>
      <td>0.721929</td>
      <td>-0.440320</td>
      <td>0.302311</td>
      <td>0.270232</td>
      <td>1.014530</td>
      <td>0.823209</td>
      <td>-0.893902</td>
      <td>-0.565647</td>
      <td>1.021960</td>
      <td>0.504524</td>
      <td>0.272189</td>
      <td>-0.147394</td>
      <td>-0.324055</td>
      <td>0.316631</td>
      <td>-0.193273</td>
      <td>-1.068090</td>
      <td>-0.948251</td>
      <td>0.107581</td>
      <td>0.991166</td>
      <td>-0.365536</td>
      <td>-0.071913</td>
      <td>-1.009796</td>
      <td>-1.228406</td>
      <td>0.175089</td>
      <td>0.521311</td>
      <td>-1.240794</td>
      <td>0.066794</td>
      <td>-0.406745</td>
      <td>0.848805</td>
      <td>0.125556</td>
      <td>1.029522</td>
      <td>-0.484142</td>
      <td>0.048035</td>
      <td>1.457525</td>
      <td>0.811969</td>
      <td>0.257865</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.575577</td>
      <td>0.533455</td>
      <td>0.471503</td>
      <td>0.751614</td>
      <td>0.858274</td>
      <td>-0.284054</td>
      <td>-0.150553</td>
      <td>-0.201216</td>
      <td>0.301715</td>
      <td>0.073250</td>
      <td>1.352574</td>
      <td>0.983313</td>
      <td>0.071993</td>
      <td>0.034805</td>
      <td>0.238119</td>
      <td>0.763887</td>
      <td>-0.374604</td>
      <td>-0.144592</td>
      <td>-0.184463</td>
      <td>0.714927</td>
      <td>0.426511</td>
      <td>0.931405</td>
      <td>1.230616</td>
      <td>0.684452</td>
      <td>0.483459</td>
      <td>-0.121665</td>
      <td>0.028292</td>
      <td>-0.102431</td>
      <td>-0.825231</td>
      <td>-0.294714</td>
      <td>-0.054633</td>
      <td>0.320756</td>
      <td>-0.713866</td>
      <td>-0.100020</td>
      <td>1.234715</td>
      <td>1.263071</td>
      <td>0.839510</td>
      <td>-0.587768</td>
      <td>-0.367083</td>
      <td>1.166998</td>
      <td>...</td>
      <td>0.061854</td>
      <td>0.065357</td>
      <td>-0.072395</td>
      <td>0.507883</td>
      <td>0.804717</td>
      <td>0.404252</td>
      <td>0.981762</td>
      <td>0.190509</td>
      <td>0.571122</td>
      <td>0.052275</td>
      <td>0.422829</td>
      <td>1.324273</td>
      <td>0.696013</td>
      <td>0.922179</td>
      <td>0.454226</td>
      <td>-0.738961</td>
      <td>0.662993</td>
      <td>1.024835</td>
      <td>0.187816</td>
      <td>0.284036</td>
      <td>0.056994</td>
      <td>0.762960</td>
      <td>-0.324749</td>
      <td>-0.240000</td>
      <td>0.375424</td>
      <td>0.770373</td>
      <td>0.176437</td>
      <td>0.252937</td>
      <td>0.695734</td>
      <td>-1.429293</td>
      <td>-0.586045</td>
      <td>-0.327633</td>
      <td>0.210468</td>
      <td>-0.036367</td>
      <td>-0.300063</td>
      <td>-0.763523</td>
      <td>-1.011000</td>
      <td>-1.841511</td>
      <td>-1.288874</td>
      <td>-0.427314</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.136127</td>
      <td>0.444948</td>
      <td>0.271151</td>
      <td>0.349715</td>
      <td>0.878075</td>
      <td>0.452547</td>
      <td>0.069635</td>
      <td>0.468627</td>
      <td>0.457861</td>
      <td>-0.070278</td>
      <td>0.613516</td>
      <td>1.073180</td>
      <td>0.256009</td>
      <td>-0.352323</td>
      <td>0.153556</td>
      <td>0.855345</td>
      <td>-0.964589</td>
      <td>-1.019033</td>
      <td>-0.103802</td>
      <td>0.467480</td>
      <td>-0.438759</td>
      <td>-0.061685</td>
      <td>0.518912</td>
      <td>0.587128</td>
      <td>0.448094</td>
      <td>-0.049382</td>
      <td>-0.684123</td>
      <td>0.731310</td>
      <td>-0.561634</td>
      <td>-0.050138</td>
      <td>-0.253767</td>
      <td>0.626408</td>
      <td>-0.179403</td>
      <td>0.104780</td>
      <td>0.897102</td>
      <td>0.566133</td>
      <td>-0.122801</td>
      <td>-0.762257</td>
      <td>-0.498284</td>
      <td>0.696921</td>
      <td>...</td>
      <td>0.095088</td>
      <td>-0.506968</td>
      <td>0.208429</td>
      <td>-0.395961</td>
      <td>-1.163307</td>
      <td>-0.817706</td>
      <td>0.977027</td>
      <td>0.639853</td>
      <td>-0.117775</td>
      <td>-0.304128</td>
      <td>-0.649288</td>
      <td>0.360529</td>
      <td>0.629450</td>
      <td>0.562752</td>
      <td>0.211002</td>
      <td>0.576320</td>
      <td>0.378636</td>
      <td>0.513182</td>
      <td>-0.004693</td>
      <td>-1.415783</td>
      <td>-0.307768</td>
      <td>0.813634</td>
      <td>-0.251397</td>
      <td>-0.144063</td>
      <td>-0.789854</td>
      <td>0.428372</td>
      <td>-1.106375</td>
      <td>-0.584496</td>
      <td>0.316496</td>
      <td>-0.714166</td>
      <td>-0.486736</td>
      <td>0.456508</td>
      <td>0.590176</td>
      <td>-0.287995</td>
      <td>0.273536</td>
      <td>-0.237490</td>
      <td>0.115561</td>
      <td>0.372460</td>
      <td>0.237633</td>
      <td>0.423218</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.345175</td>
      <td>0.356362</td>
      <td>-0.631806</td>
      <td>0.212098</td>
      <td>1.288190</td>
      <td>-0.405248</td>
      <td>0.171316</td>
      <td>0.629916</td>
      <td>0.695679</td>
      <td>1.104144</td>
      <td>0.751364</td>
      <td>-0.126284</td>
      <td>0.770983</td>
      <td>0.518042</td>
      <td>-0.178856</td>
      <td>0.016194</td>
      <td>-0.029889</td>
      <td>-0.794179</td>
      <td>0.000347</td>
      <td>0.089477</td>
      <td>0.290774</td>
      <td>0.330659</td>
      <td>0.277230</td>
      <td>0.872198</td>
      <td>-0.053863</td>
      <td>0.395389</td>
      <td>0.088485</td>
      <td>0.214128</td>
      <td>0.066940</td>
      <td>-0.358599</td>
      <td>0.175393</td>
      <td>0.465149</td>
      <td>0.737109</td>
      <td>0.093983</td>
      <td>0.817950</td>
      <td>0.142254</td>
      <td>0.089674</td>
      <td>0.055458</td>
      <td>0.140348</td>
      <td>-0.664947</td>
      <td>...</td>
      <td>0.228168</td>
      <td>-0.676055</td>
      <td>-0.240925</td>
      <td>0.264411</td>
      <td>-0.394274</td>
      <td>-0.297212</td>
      <td>0.739666</td>
      <td>0.499946</td>
      <td>0.820041</td>
      <td>1.203817</td>
      <td>-0.074082</td>
      <td>0.046424</td>
      <td>0.833941</td>
      <td>-0.292930</td>
      <td>-1.113638</td>
      <td>-0.008594</td>
      <td>-0.383209</td>
      <td>-0.324163</td>
      <td>-0.613798</td>
      <td>-1.196176</td>
      <td>-0.755014</td>
      <td>0.779527</td>
      <td>-0.417762</td>
      <td>-0.424733</td>
      <td>0.715199</td>
      <td>1.027728</td>
      <td>0.283387</td>
      <td>-0.453155</td>
      <td>0.543258</td>
      <td>-0.284095</td>
      <td>-0.074507</td>
      <td>-0.533954</td>
      <td>-0.316010</td>
      <td>-0.511954</td>
      <td>0.555520</td>
      <td>0.011651</td>
      <td>0.822027</td>
      <td>-0.833271</td>
      <td>-0.712096</td>
      <td>-0.095355</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f47c033b520&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.091799  0.039333  27.758173  1.388432e-169  1.014708  1.168889
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  5.191 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>