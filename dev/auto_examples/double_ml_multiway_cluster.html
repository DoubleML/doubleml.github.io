
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.051117</td>
      <td>0.312942</td>
      <td>0.680363</td>
      <td>-0.004425</td>
      <td>0.104772</td>
      <td>-0.806340</td>
      <td>-0.419401</td>
      <td>1.355377</td>
      <td>0.654541</td>
      <td>0.299422</td>
      <td>0.901068</td>
      <td>0.027022</td>
      <td>-0.141151</td>
      <td>-0.183941</td>
      <td>0.528232</td>
      <td>-0.763902</td>
      <td>0.548128</td>
      <td>0.086883</td>
      <td>-0.160257</td>
      <td>-0.381479</td>
      <td>0.150876</td>
      <td>-0.683584</td>
      <td>0.100842</td>
      <td>-0.996981</td>
      <td>-0.214862</td>
      <td>-0.707381</td>
      <td>-0.559429</td>
      <td>-0.336285</td>
      <td>0.420697</td>
      <td>-1.139580</td>
      <td>-0.005739</td>
      <td>-0.125149</td>
      <td>0.927448</td>
      <td>-0.567384</td>
      <td>-0.429483</td>
      <td>0.263444</td>
      <td>0.141168</td>
      <td>0.181251</td>
      <td>1.020931</td>
      <td>1.599437</td>
      <td>...</td>
      <td>0.215353</td>
      <td>0.189718</td>
      <td>-0.603988</td>
      <td>-0.281379</td>
      <td>0.016226</td>
      <td>1.080969</td>
      <td>0.166020</td>
      <td>0.319640</td>
      <td>-0.084786</td>
      <td>1.275717</td>
      <td>0.649401</td>
      <td>0.999681</td>
      <td>0.185025</td>
      <td>-0.121000</td>
      <td>0.634539</td>
      <td>0.493507</td>
      <td>-0.055393</td>
      <td>0.006595</td>
      <td>-0.132619</td>
      <td>0.100601</td>
      <td>-0.386960</td>
      <td>-1.084101</td>
      <td>-0.152900</td>
      <td>0.540731</td>
      <td>0.328172</td>
      <td>-0.400711</td>
      <td>-0.301386</td>
      <td>0.796470</td>
      <td>1.281657</td>
      <td>0.321151</td>
      <td>0.452400</td>
      <td>-0.210052</td>
      <td>0.187055</td>
      <td>0.743938</td>
      <td>0.453120</td>
      <td>-0.447244</td>
      <td>-0.835364</td>
      <td>-0.784641</td>
      <td>-0.297442</td>
      <td>0.106844</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.079267</td>
      <td>-0.182592</td>
      <td>-0.718543</td>
      <td>-0.414379</td>
      <td>-0.707205</td>
      <td>0.006171</td>
      <td>-0.670124</td>
      <td>0.642477</td>
      <td>0.761400</td>
      <td>1.006019</td>
      <td>0.618248</td>
      <td>0.615335</td>
      <td>0.199960</td>
      <td>-0.393441</td>
      <td>-0.660044</td>
      <td>-0.933239</td>
      <td>-0.035502</td>
      <td>-0.493723</td>
      <td>-0.011101</td>
      <td>-0.857104</td>
      <td>0.176866</td>
      <td>0.626030</td>
      <td>0.213553</td>
      <td>-0.240523</td>
      <td>0.013744</td>
      <td>0.433154</td>
      <td>0.112423</td>
      <td>0.049544</td>
      <td>0.468901</td>
      <td>-0.098833</td>
      <td>0.693310</td>
      <td>0.756265</td>
      <td>0.544384</td>
      <td>1.337123</td>
      <td>-0.023150</td>
      <td>0.153334</td>
      <td>-0.397946</td>
      <td>0.919589</td>
      <td>-0.129144</td>
      <td>-0.106817</td>
      <td>...</td>
      <td>-0.589006</td>
      <td>1.010196</td>
      <td>0.255234</td>
      <td>-1.020900</td>
      <td>-0.133358</td>
      <td>0.622717</td>
      <td>-1.126926</td>
      <td>0.105860</td>
      <td>0.481361</td>
      <td>1.317018</td>
      <td>0.852423</td>
      <td>-0.457812</td>
      <td>0.378165</td>
      <td>-0.445980</td>
      <td>0.239123</td>
      <td>-0.553864</td>
      <td>-0.419242</td>
      <td>-0.361013</td>
      <td>-0.699064</td>
      <td>0.121108</td>
      <td>-0.967213</td>
      <td>-0.448289</td>
      <td>-0.481149</td>
      <td>-0.483801</td>
      <td>-0.524566</td>
      <td>-0.246338</td>
      <td>-0.437321</td>
      <td>0.143359</td>
      <td>0.427647</td>
      <td>-0.982119</td>
      <td>-0.177073</td>
      <td>0.279706</td>
      <td>-0.967895</td>
      <td>-0.733509</td>
      <td>0.087689</td>
      <td>0.128124</td>
      <td>0.506677</td>
      <td>-1.784027</td>
      <td>-1.619037</td>
      <td>-1.158122</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.290512</td>
      <td>-0.528170</td>
      <td>-0.870793</td>
      <td>-1.061339</td>
      <td>-0.364650</td>
      <td>-0.481035</td>
      <td>0.721671</td>
      <td>0.255614</td>
      <td>-0.041525</td>
      <td>0.818773</td>
      <td>0.460432</td>
      <td>0.379876</td>
      <td>-0.558999</td>
      <td>-0.137130</td>
      <td>-0.968363</td>
      <td>-0.275107</td>
      <td>1.084754</td>
      <td>0.392862</td>
      <td>-1.216303</td>
      <td>0.017681</td>
      <td>0.049001</td>
      <td>-0.344417</td>
      <td>-0.050467</td>
      <td>0.871504</td>
      <td>0.714733</td>
      <td>-0.114725</td>
      <td>-0.535675</td>
      <td>0.034048</td>
      <td>0.597986</td>
      <td>-0.301092</td>
      <td>0.196880</td>
      <td>0.770555</td>
      <td>0.258108</td>
      <td>1.357305</td>
      <td>0.524790</td>
      <td>1.268352</td>
      <td>-0.007421</td>
      <td>1.167374</td>
      <td>0.051482</td>
      <td>-0.344052</td>
      <td>...</td>
      <td>-0.496157</td>
      <td>0.055839</td>
      <td>0.108299</td>
      <td>0.435312</td>
      <td>0.251979</td>
      <td>0.925123</td>
      <td>0.195634</td>
      <td>0.197212</td>
      <td>0.764924</td>
      <td>-0.115201</td>
      <td>0.786484</td>
      <td>1.330963</td>
      <td>0.936143</td>
      <td>-0.603358</td>
      <td>-0.643852</td>
      <td>0.572302</td>
      <td>0.298323</td>
      <td>0.462855</td>
      <td>1.384025</td>
      <td>-0.827850</td>
      <td>0.069013</td>
      <td>0.168867</td>
      <td>0.007316</td>
      <td>0.634771</td>
      <td>-0.080197</td>
      <td>0.351742</td>
      <td>-0.382699</td>
      <td>-0.954651</td>
      <td>0.216057</td>
      <td>0.423882</td>
      <td>0.476841</td>
      <td>-0.158676</td>
      <td>-0.119748</td>
      <td>-0.668110</td>
      <td>0.710238</td>
      <td>0.437080</td>
      <td>0.397302</td>
      <td>-1.395321</td>
      <td>-1.607679</td>
      <td>-1.164827</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.361263</td>
      <td>-1.354571</td>
      <td>-0.362546</td>
      <td>0.465519</td>
      <td>0.005327</td>
      <td>0.175281</td>
      <td>-0.132365</td>
      <td>0.700805</td>
      <td>-0.060002</td>
      <td>0.733501</td>
      <td>0.640269</td>
      <td>0.767982</td>
      <td>-0.454478</td>
      <td>-0.572311</td>
      <td>0.184190</td>
      <td>0.286315</td>
      <td>0.966926</td>
      <td>-0.346840</td>
      <td>-0.170053</td>
      <td>0.179663</td>
      <td>-0.499559</td>
      <td>-1.088776</td>
      <td>-0.360602</td>
      <td>-1.189950</td>
      <td>-0.144223</td>
      <td>-1.191694</td>
      <td>-0.401079</td>
      <td>0.542920</td>
      <td>-0.546518</td>
      <td>-0.691408</td>
      <td>0.532365</td>
      <td>0.430833</td>
      <td>-0.236937</td>
      <td>-0.395983</td>
      <td>-0.461691</td>
      <td>-0.207626</td>
      <td>-0.566285</td>
      <td>1.379470</td>
      <td>-0.379510</td>
      <td>0.929555</td>
      <td>...</td>
      <td>-0.025422</td>
      <td>0.333368</td>
      <td>0.296807</td>
      <td>1.041642</td>
      <td>2.532205</td>
      <td>1.688853</td>
      <td>0.249780</td>
      <td>-0.414560</td>
      <td>0.695472</td>
      <td>0.061675</td>
      <td>0.222991</td>
      <td>0.654508</td>
      <td>-0.406673</td>
      <td>-0.372646</td>
      <td>-0.188778</td>
      <td>-0.926186</td>
      <td>0.034501</td>
      <td>-0.294047</td>
      <td>-0.991741</td>
      <td>0.450227</td>
      <td>-0.353174</td>
      <td>-0.302987</td>
      <td>-0.260913</td>
      <td>1.038503</td>
      <td>0.618813</td>
      <td>0.771205</td>
      <td>0.411726</td>
      <td>-0.703276</td>
      <td>0.461247</td>
      <td>-0.165326</td>
      <td>-0.605160</td>
      <td>-0.143451</td>
      <td>-0.715504</td>
      <td>-0.835439</td>
      <td>-0.331622</td>
      <td>-0.573669</td>
      <td>-0.779369</td>
      <td>-1.561506</td>
      <td>-1.422783</td>
      <td>-0.928490</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.032327</td>
      <td>0.094257</td>
      <td>0.271055</td>
      <td>-0.327390</td>
      <td>0.350218</td>
      <td>0.039622</td>
      <td>0.108198</td>
      <td>1.114599</td>
      <td>-0.456077</td>
      <td>0.748819</td>
      <td>0.423560</td>
      <td>-0.534619</td>
      <td>0.471795</td>
      <td>0.720183</td>
      <td>-0.351323</td>
      <td>-0.054788</td>
      <td>0.284421</td>
      <td>1.145104</td>
      <td>-0.155537</td>
      <td>0.780132</td>
      <td>0.136163</td>
      <td>-0.157807</td>
      <td>-0.607971</td>
      <td>-0.927832</td>
      <td>-0.340772</td>
      <td>-0.224813</td>
      <td>-1.066743</td>
      <td>-0.714315</td>
      <td>0.341646</td>
      <td>-0.309762</td>
      <td>-0.501014</td>
      <td>0.312921</td>
      <td>0.062793</td>
      <td>0.322971</td>
      <td>0.265869</td>
      <td>0.405756</td>
      <td>0.177646</td>
      <td>1.697227</td>
      <td>0.822127</td>
      <td>0.066262</td>
      <td>...</td>
      <td>0.565197</td>
      <td>0.016753</td>
      <td>-0.203840</td>
      <td>-0.444622</td>
      <td>0.001893</td>
      <td>0.096003</td>
      <td>-0.700326</td>
      <td>-1.078302</td>
      <td>0.424329</td>
      <td>0.582389</td>
      <td>0.234943</td>
      <td>1.103293</td>
      <td>0.698694</td>
      <td>0.521245</td>
      <td>-0.175852</td>
      <td>-0.032775</td>
      <td>-0.228132</td>
      <td>-0.431134</td>
      <td>0.215975</td>
      <td>0.399519</td>
      <td>-0.786617</td>
      <td>0.202056</td>
      <td>-0.008884</td>
      <td>0.762154</td>
      <td>-0.338696</td>
      <td>-0.374212</td>
      <td>-0.382015</td>
      <td>-0.486435</td>
      <td>-0.709838</td>
      <td>-0.258923</td>
      <td>-0.006389</td>
      <td>0.503825</td>
      <td>-0.113874</td>
      <td>0.055136</td>
      <td>0.470396</td>
      <td>-0.359698</td>
      <td>-0.618120</td>
      <td>-1.314266</td>
      <td>-1.000815</td>
      <td>-1.018050</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.286559</td>
      <td>0.431791</td>
      <td>-1.117378</td>
      <td>0.368869</td>
      <td>0.369912</td>
      <td>-0.422002</td>
      <td>0.705525</td>
      <td>-0.135082</td>
      <td>0.157967</td>
      <td>0.469802</td>
      <td>0.526120</td>
      <td>0.050399</td>
      <td>-0.021338</td>
      <td>-1.169268</td>
      <td>-0.663764</td>
      <td>-1.118126</td>
      <td>-0.543549</td>
      <td>0.773216</td>
      <td>-0.600427</td>
      <td>0.275660</td>
      <td>0.338231</td>
      <td>1.062400</td>
      <td>0.658024</td>
      <td>-0.658560</td>
      <td>0.536185</td>
      <td>-0.371014</td>
      <td>-0.136135</td>
      <td>-0.325023</td>
      <td>-0.133559</td>
      <td>-0.886014</td>
      <td>-1.073699</td>
      <td>-0.585132</td>
      <td>0.793340</td>
      <td>0.743619</td>
      <td>-0.650403</td>
      <td>0.501676</td>
      <td>-0.396222</td>
      <td>0.227756</td>
      <td>0.698243</td>
      <td>-0.810844</td>
      <td>...</td>
      <td>-0.431476</td>
      <td>-0.743354</td>
      <td>-0.185023</td>
      <td>0.156660</td>
      <td>0.436233</td>
      <td>1.017115</td>
      <td>-0.156403</td>
      <td>-0.963909</td>
      <td>0.126409</td>
      <td>0.196840</td>
      <td>-0.617088</td>
      <td>-0.858821</td>
      <td>-0.483749</td>
      <td>-0.171459</td>
      <td>0.687127</td>
      <td>0.778184</td>
      <td>1.149627</td>
      <td>0.066794</td>
      <td>0.270746</td>
      <td>0.488843</td>
      <td>0.073799</td>
      <td>0.146491</td>
      <td>-0.938969</td>
      <td>-0.271094</td>
      <td>-0.791343</td>
      <td>0.813054</td>
      <td>0.500184</td>
      <td>-0.611367</td>
      <td>0.713631</td>
      <td>-0.245210</td>
      <td>0.501821</td>
      <td>-0.159023</td>
      <td>-0.272554</td>
      <td>0.048715</td>
      <td>-0.350779</td>
      <td>-0.793695</td>
      <td>-0.391778</td>
      <td>0.503764</td>
      <td>-0.054196</td>
      <td>0.821173</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.314878</td>
      <td>-0.219921</td>
      <td>0.945786</td>
      <td>0.666156</td>
      <td>0.276471</td>
      <td>-0.026382</td>
      <td>-0.226221</td>
      <td>0.179870</td>
      <td>0.826184</td>
      <td>0.449807</td>
      <td>0.883064</td>
      <td>-0.077589</td>
      <td>0.933260</td>
      <td>-0.133633</td>
      <td>-0.637756</td>
      <td>-0.194776</td>
      <td>1.085828</td>
      <td>0.045771</td>
      <td>-0.673925</td>
      <td>0.981233</td>
      <td>0.321135</td>
      <td>0.370085</td>
      <td>0.172236</td>
      <td>-0.609155</td>
      <td>1.451340</td>
      <td>-0.315362</td>
      <td>-0.537453</td>
      <td>0.343399</td>
      <td>-0.734290</td>
      <td>-0.729095</td>
      <td>-0.634537</td>
      <td>-0.494357</td>
      <td>0.101739</td>
      <td>0.778495</td>
      <td>-0.501474</td>
      <td>0.565674</td>
      <td>0.009332</td>
      <td>1.010060</td>
      <td>0.854930</td>
      <td>-1.389756</td>
      <td>...</td>
      <td>0.069226</td>
      <td>0.408480</td>
      <td>-0.553502</td>
      <td>-0.684936</td>
      <td>-0.394816</td>
      <td>0.269906</td>
      <td>-0.042163</td>
      <td>-0.402923</td>
      <td>-0.135724</td>
      <td>0.498573</td>
      <td>-0.502479</td>
      <td>-0.552364</td>
      <td>0.112250</td>
      <td>-0.580322</td>
      <td>0.504379</td>
      <td>-0.475306</td>
      <td>-0.992068</td>
      <td>0.352522</td>
      <td>-0.125071</td>
      <td>0.399236</td>
      <td>0.272725</td>
      <td>-0.350136</td>
      <td>-0.133967</td>
      <td>-0.366525</td>
      <td>-0.113278</td>
      <td>1.410196</td>
      <td>-0.090092</td>
      <td>-1.154086</td>
      <td>-1.226660</td>
      <td>-1.169215</td>
      <td>1.263614</td>
      <td>-0.248474</td>
      <td>-0.145171</td>
      <td>-0.204998</td>
      <td>0.923935</td>
      <td>-0.028313</td>
      <td>0.422223</td>
      <td>-0.337657</td>
      <td>-0.710599</td>
      <td>-0.471142</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.333986</td>
      <td>-0.273292</td>
      <td>-0.687470</td>
      <td>-0.891503</td>
      <td>-0.241011</td>
      <td>-1.028946</td>
      <td>0.144288</td>
      <td>-0.668215</td>
      <td>0.228073</td>
      <td>0.020748</td>
      <td>0.757716</td>
      <td>-0.085858</td>
      <td>0.019393</td>
      <td>-0.259330</td>
      <td>0.671587</td>
      <td>0.468367</td>
      <td>0.385140</td>
      <td>0.419910</td>
      <td>0.049142</td>
      <td>-0.033172</td>
      <td>0.479140</td>
      <td>-0.261044</td>
      <td>0.588215</td>
      <td>-1.006373</td>
      <td>-0.382976</td>
      <td>0.349664</td>
      <td>-0.516691</td>
      <td>0.198985</td>
      <td>0.362853</td>
      <td>-0.364716</td>
      <td>1.572647</td>
      <td>0.308970</td>
      <td>0.315235</td>
      <td>0.246529</td>
      <td>-0.471063</td>
      <td>-0.212945</td>
      <td>-0.466683</td>
      <td>0.484216</td>
      <td>0.437146</td>
      <td>0.125828</td>
      <td>...</td>
      <td>-0.625682</td>
      <td>-0.391085</td>
      <td>-0.360820</td>
      <td>-0.658495</td>
      <td>0.186057</td>
      <td>1.430208</td>
      <td>0.732360</td>
      <td>0.053392</td>
      <td>1.071910</td>
      <td>-0.164428</td>
      <td>-0.502238</td>
      <td>-0.025931</td>
      <td>-0.107604</td>
      <td>-0.097501</td>
      <td>-0.362254</td>
      <td>-0.478649</td>
      <td>0.982271</td>
      <td>1.153258</td>
      <td>0.393970</td>
      <td>0.743524</td>
      <td>0.228631</td>
      <td>0.051587</td>
      <td>0.515594</td>
      <td>-0.378021</td>
      <td>0.144450</td>
      <td>1.287753</td>
      <td>-0.140906</td>
      <td>-0.588097</td>
      <td>0.400635</td>
      <td>-0.445241</td>
      <td>0.691819</td>
      <td>0.200279</td>
      <td>-0.204488</td>
      <td>-0.537540</td>
      <td>-0.842797</td>
      <td>-0.450514</td>
      <td>-0.524245</td>
      <td>-2.397251</td>
      <td>-1.541084</td>
      <td>-0.713790</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.798174</td>
      <td>-0.133046</td>
      <td>-0.187441</td>
      <td>-0.010531</td>
      <td>0.898999</td>
      <td>0.242532</td>
      <td>-0.079402</td>
      <td>0.816806</td>
      <td>0.649220</td>
      <td>0.251693</td>
      <td>0.378365</td>
      <td>-0.596790</td>
      <td>0.868587</td>
      <td>-0.271868</td>
      <td>-0.746492</td>
      <td>0.252994</td>
      <td>1.050949</td>
      <td>0.758302</td>
      <td>0.389507</td>
      <td>0.472515</td>
      <td>0.032128</td>
      <td>0.889355</td>
      <td>0.669680</td>
      <td>-1.236281</td>
      <td>-0.748127</td>
      <td>-0.295858</td>
      <td>-0.269799</td>
      <td>0.001952</td>
      <td>-0.339467</td>
      <td>0.126411</td>
      <td>0.763124</td>
      <td>-0.012727</td>
      <td>-0.577962</td>
      <td>0.394219</td>
      <td>-0.105820</td>
      <td>0.142205</td>
      <td>-0.936133</td>
      <td>0.439818</td>
      <td>0.865886</td>
      <td>0.637279</td>
      <td>...</td>
      <td>-0.146256</td>
      <td>0.146971</td>
      <td>-0.584635</td>
      <td>-1.178171</td>
      <td>0.153504</td>
      <td>0.499203</td>
      <td>0.350806</td>
      <td>-0.225596</td>
      <td>0.104968</td>
      <td>0.826611</td>
      <td>-0.119392</td>
      <td>0.202157</td>
      <td>0.570832</td>
      <td>0.407716</td>
      <td>-0.519803</td>
      <td>-0.379419</td>
      <td>-0.556993</td>
      <td>0.159830</td>
      <td>-0.204522</td>
      <td>-0.509424</td>
      <td>0.399621</td>
      <td>-0.057156</td>
      <td>0.106833</td>
      <td>1.133375</td>
      <td>-0.157044</td>
      <td>-0.594500</td>
      <td>-0.852906</td>
      <td>-0.054555</td>
      <td>0.783618</td>
      <td>0.049023</td>
      <td>0.432245</td>
      <td>0.020347</td>
      <td>0.664535</td>
      <td>-0.076771</td>
      <td>-0.259345</td>
      <td>0.868911</td>
      <td>0.000494</td>
      <td>0.504433</td>
      <td>-0.204854</td>
      <td>-0.031212</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.058490</td>
      <td>0.418292</td>
      <td>-0.453450</td>
      <td>-0.491681</td>
      <td>-0.401231</td>
      <td>-0.258671</td>
      <td>0.048275</td>
      <td>0.810412</td>
      <td>0.233344</td>
      <td>-0.372671</td>
      <td>1.388279</td>
      <td>0.852673</td>
      <td>0.225374</td>
      <td>-0.169198</td>
      <td>-0.358027</td>
      <td>0.550020</td>
      <td>-0.381304</td>
      <td>-0.010559</td>
      <td>-0.074948</td>
      <td>-1.060699</td>
      <td>0.268239</td>
      <td>0.136203</td>
      <td>-0.157709</td>
      <td>-0.164112</td>
      <td>1.374101</td>
      <td>-0.704295</td>
      <td>0.394573</td>
      <td>0.048192</td>
      <td>-1.452836</td>
      <td>-0.050144</td>
      <td>-0.795179</td>
      <td>-0.408451</td>
      <td>0.686996</td>
      <td>0.657964</td>
      <td>-0.121808</td>
      <td>1.485399</td>
      <td>0.121520</td>
      <td>0.503083</td>
      <td>0.874935</td>
      <td>0.906161</td>
      <td>...</td>
      <td>0.054449</td>
      <td>-0.219287</td>
      <td>-0.181488</td>
      <td>0.383123</td>
      <td>1.176615</td>
      <td>0.954428</td>
      <td>0.039637</td>
      <td>0.278192</td>
      <td>0.345022</td>
      <td>0.276748</td>
      <td>-0.490350</td>
      <td>-0.003518</td>
      <td>-0.325975</td>
      <td>0.088196</td>
      <td>-0.797950</td>
      <td>0.014613</td>
      <td>-0.622157</td>
      <td>-0.768186</td>
      <td>-1.275132</td>
      <td>0.118751</td>
      <td>-0.326596</td>
      <td>-0.409352</td>
      <td>-0.281485</td>
      <td>1.694987</td>
      <td>0.651172</td>
      <td>-0.515388</td>
      <td>0.268424</td>
      <td>-1.206920</td>
      <td>0.080905</td>
      <td>-1.644529</td>
      <td>0.239319</td>
      <td>0.338629</td>
      <td>-0.036716</td>
      <td>0.340893</td>
      <td>-0.106227</td>
      <td>0.334898</td>
      <td>-1.213387</td>
      <td>-2.016920</td>
      <td>-0.966560</td>
      <td>-0.060995</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.402772</td>
      <td>-0.145436</td>
      <td>-0.743240</td>
      <td>-0.483522</td>
      <td>-1.056355</td>
      <td>-0.606738</td>
      <td>-0.235720</td>
      <td>-0.056667</td>
      <td>0.060725</td>
      <td>0.671172</td>
      <td>0.605850</td>
      <td>-0.331640</td>
      <td>-0.663016</td>
      <td>0.415796</td>
      <td>-0.011086</td>
      <td>-0.477954</td>
      <td>1.124247</td>
      <td>0.473102</td>
      <td>0.504714</td>
      <td>0.732283</td>
      <td>0.156490</td>
      <td>0.016064</td>
      <td>-0.586902</td>
      <td>-0.603261</td>
      <td>0.035613</td>
      <td>-0.188815</td>
      <td>0.313338</td>
      <td>-0.026216</td>
      <td>-1.225236</td>
      <td>-1.095547</td>
      <td>-0.164351</td>
      <td>-1.015533</td>
      <td>-0.677692</td>
      <td>-0.029010</td>
      <td>0.261142</td>
      <td>-0.602592</td>
      <td>-0.515549</td>
      <td>0.294915</td>
      <td>0.263892</td>
      <td>0.088019</td>
      <td>...</td>
      <td>0.145640</td>
      <td>0.544216</td>
      <td>-0.044378</td>
      <td>0.014620</td>
      <td>0.228166</td>
      <td>-0.233661</td>
      <td>-0.198169</td>
      <td>-0.542583</td>
      <td>1.054926</td>
      <td>0.505657</td>
      <td>-0.202386</td>
      <td>0.336506</td>
      <td>-1.075487</td>
      <td>-1.580710</td>
      <td>-1.343285</td>
      <td>1.051291</td>
      <td>0.318523</td>
      <td>-0.972791</td>
      <td>-0.376083</td>
      <td>-0.405503</td>
      <td>0.490557</td>
      <td>-0.579636</td>
      <td>-1.573163</td>
      <td>1.425876</td>
      <td>-0.305360</td>
      <td>0.799230</td>
      <td>0.260803</td>
      <td>-0.659489</td>
      <td>-1.078943</td>
      <td>-0.025997</td>
      <td>0.721194</td>
      <td>0.050461</td>
      <td>0.399784</td>
      <td>0.418360</td>
      <td>0.087827</td>
      <td>-0.127790</td>
      <td>-0.096724</td>
      <td>-1.049541</td>
      <td>-0.510163</td>
      <td>0.190479</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.001968</td>
      <td>-0.559135</td>
      <td>0.564650</td>
      <td>-0.094751</td>
      <td>0.279492</td>
      <td>-0.275149</td>
      <td>-0.835786</td>
      <td>-0.220563</td>
      <td>-0.288210</td>
      <td>-0.527624</td>
      <td>-0.501002</td>
      <td>0.302979</td>
      <td>-0.527661</td>
      <td>-1.360929</td>
      <td>-0.752941</td>
      <td>-0.284598</td>
      <td>0.725542</td>
      <td>0.480655</td>
      <td>0.200331</td>
      <td>0.395615</td>
      <td>-0.149186</td>
      <td>0.479219</td>
      <td>-0.098158</td>
      <td>0.032934</td>
      <td>0.591333</td>
      <td>0.081773</td>
      <td>0.042749</td>
      <td>0.614427</td>
      <td>-0.296587</td>
      <td>-0.392504</td>
      <td>1.089930</td>
      <td>0.144100</td>
      <td>0.160987</td>
      <td>0.450225</td>
      <td>-0.505266</td>
      <td>-0.100544</td>
      <td>-0.222060</td>
      <td>1.273436</td>
      <td>0.113118</td>
      <td>0.477055</td>
      <td>...</td>
      <td>0.959794</td>
      <td>1.322166</td>
      <td>0.107925</td>
      <td>0.111273</td>
      <td>-0.966287</td>
      <td>1.377915</td>
      <td>-0.636483</td>
      <td>-1.128410</td>
      <td>-0.443975</td>
      <td>0.370984</td>
      <td>0.285537</td>
      <td>-0.331271</td>
      <td>-0.291279</td>
      <td>-0.985038</td>
      <td>0.006913</td>
      <td>-0.459809</td>
      <td>-0.331691</td>
      <td>-0.126405</td>
      <td>-0.040217</td>
      <td>0.531639</td>
      <td>0.038244</td>
      <td>0.104874</td>
      <td>-0.694423</td>
      <td>0.217377</td>
      <td>-0.328965</td>
      <td>-0.092476</td>
      <td>-0.282768</td>
      <td>0.487723</td>
      <td>0.040025</td>
      <td>-0.239545</td>
      <td>-0.125078</td>
      <td>0.276372</td>
      <td>-0.166801</td>
      <td>-1.308604</td>
      <td>-0.381235</td>
      <td>-0.815155</td>
      <td>0.096981</td>
      <td>0.744265</td>
      <td>-0.043511</td>
      <td>0.175859</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.650915</td>
      <td>-0.095134</td>
      <td>-0.147079</td>
      <td>-0.817173</td>
      <td>-0.868820</td>
      <td>-0.257135</td>
      <td>0.299282</td>
      <td>1.532571</td>
      <td>1.098290</td>
      <td>0.021248</td>
      <td>0.160023</td>
      <td>-0.629064</td>
      <td>-0.177966</td>
      <td>-0.263026</td>
      <td>-1.306693</td>
      <td>-0.443066</td>
      <td>0.311812</td>
      <td>-0.058300</td>
      <td>-0.531663</td>
      <td>0.715405</td>
      <td>-0.195790</td>
      <td>0.183295</td>
      <td>0.538229</td>
      <td>-0.942522</td>
      <td>-0.150870</td>
      <td>-0.348469</td>
      <td>-0.337538</td>
      <td>0.581274</td>
      <td>0.308279</td>
      <td>-0.895957</td>
      <td>0.973020</td>
      <td>-1.065915</td>
      <td>0.349034</td>
      <td>0.876872</td>
      <td>0.792465</td>
      <td>1.546090</td>
      <td>0.190412</td>
      <td>0.548949</td>
      <td>0.883049</td>
      <td>0.467686</td>
      <td>...</td>
      <td>0.074272</td>
      <td>0.331185</td>
      <td>0.222656</td>
      <td>0.386532</td>
      <td>-0.451329</td>
      <td>-0.243792</td>
      <td>-0.417629</td>
      <td>-0.671115</td>
      <td>0.001658</td>
      <td>-0.151223</td>
      <td>-0.161336</td>
      <td>0.048464</td>
      <td>1.017061</td>
      <td>0.137685</td>
      <td>-0.301255</td>
      <td>0.274627</td>
      <td>-0.001895</td>
      <td>-0.037971</td>
      <td>-0.660240</td>
      <td>-0.961514</td>
      <td>-0.401748</td>
      <td>-0.616225</td>
      <td>-0.250015</td>
      <td>0.608544</td>
      <td>-0.556714</td>
      <td>0.004162</td>
      <td>0.405284</td>
      <td>-0.352935</td>
      <td>1.344476</td>
      <td>0.763604</td>
      <td>1.586539</td>
      <td>0.615582</td>
      <td>-0.475376</td>
      <td>-0.451616</td>
      <td>-0.499347</td>
      <td>-0.224086</td>
      <td>-1.246296</td>
      <td>-0.912569</td>
      <td>-1.052566</td>
      <td>-0.210750</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.318034</td>
      <td>-0.769272</td>
      <td>-0.295372</td>
      <td>0.490081</td>
      <td>-0.106260</td>
      <td>-1.024146</td>
      <td>-0.187329</td>
      <td>0.648061</td>
      <td>0.111124</td>
      <td>1.307532</td>
      <td>1.637765</td>
      <td>0.692732</td>
      <td>0.036188</td>
      <td>-0.229925</td>
      <td>-0.644928</td>
      <td>-0.777190</td>
      <td>0.459719</td>
      <td>0.741235</td>
      <td>0.350237</td>
      <td>0.613349</td>
      <td>0.183169</td>
      <td>-0.524306</td>
      <td>-0.743706</td>
      <td>-0.549642</td>
      <td>0.551033</td>
      <td>0.120345</td>
      <td>-0.924629</td>
      <td>-0.488406</td>
      <td>-1.689674</td>
      <td>0.247995</td>
      <td>-0.262781</td>
      <td>-0.043884</td>
      <td>0.060685</td>
      <td>0.077595</td>
      <td>-0.578996</td>
      <td>-0.114822</td>
      <td>-0.351849</td>
      <td>0.161842</td>
      <td>0.329335</td>
      <td>0.719618</td>
      <td>...</td>
      <td>-0.365855</td>
      <td>0.281973</td>
      <td>0.326025</td>
      <td>0.086843</td>
      <td>0.085155</td>
      <td>-0.184278</td>
      <td>-0.615926</td>
      <td>-0.618466</td>
      <td>0.703102</td>
      <td>-0.525893</td>
      <td>-0.076498</td>
      <td>0.767344</td>
      <td>0.026603</td>
      <td>0.588223</td>
      <td>-0.106976</td>
      <td>0.525678</td>
      <td>-0.106684</td>
      <td>0.058191</td>
      <td>-0.081136</td>
      <td>-0.348926</td>
      <td>0.439536</td>
      <td>0.177305</td>
      <td>0.088583</td>
      <td>0.814133</td>
      <td>0.495646</td>
      <td>0.042390</td>
      <td>-0.104594</td>
      <td>-0.457298</td>
      <td>0.651139</td>
      <td>1.287897</td>
      <td>0.701297</td>
      <td>0.663083</td>
      <td>-0.382661</td>
      <td>-0.267690</td>
      <td>0.217707</td>
      <td>0.069727</td>
      <td>0.718990</td>
      <td>-1.615238</td>
      <td>-0.906179</td>
      <td>-0.713059</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.293256</td>
      <td>0.065069</td>
      <td>-0.586452</td>
      <td>-0.418652</td>
      <td>0.303699</td>
      <td>-0.151973</td>
      <td>-0.075696</td>
      <td>0.522035</td>
      <td>0.385306</td>
      <td>0.210165</td>
      <td>0.367664</td>
      <td>-1.337106</td>
      <td>-0.145497</td>
      <td>-0.252828</td>
      <td>-0.552522</td>
      <td>0.075585</td>
      <td>0.236783</td>
      <td>0.843229</td>
      <td>-0.029668</td>
      <td>-0.450934</td>
      <td>-0.202114</td>
      <td>0.081464</td>
      <td>0.006124</td>
      <td>-0.181921</td>
      <td>0.143198</td>
      <td>-0.629982</td>
      <td>0.048136</td>
      <td>0.742784</td>
      <td>0.578377</td>
      <td>0.055135</td>
      <td>0.940863</td>
      <td>0.233081</td>
      <td>0.750583</td>
      <td>1.484373</td>
      <td>0.582267</td>
      <td>0.341811</td>
      <td>0.240449</td>
      <td>1.787528</td>
      <td>0.655459</td>
      <td>-0.030697</td>
      <td>...</td>
      <td>0.704257</td>
      <td>-0.002996</td>
      <td>-0.303063</td>
      <td>0.204029</td>
      <td>0.157438</td>
      <td>1.319848</td>
      <td>-0.963861</td>
      <td>-1.159318</td>
      <td>-1.100818</td>
      <td>-0.396136</td>
      <td>0.012695</td>
      <td>0.202624</td>
      <td>-0.632079</td>
      <td>-0.523759</td>
      <td>-1.196707</td>
      <td>-0.315367</td>
      <td>-0.945574</td>
      <td>0.479376</td>
      <td>0.708431</td>
      <td>-0.066051</td>
      <td>0.560543</td>
      <td>-0.000958</td>
      <td>-0.999549</td>
      <td>0.634100</td>
      <td>1.335989</td>
      <td>0.675012</td>
      <td>0.034284</td>
      <td>-0.502087</td>
      <td>0.243094</td>
      <td>-0.388572</td>
      <td>0.642464</td>
      <td>-0.254226</td>
      <td>-0.108566</td>
      <td>-1.009810</td>
      <td>-0.803345</td>
      <td>-0.684370</td>
      <td>-1.339948</td>
      <td>-0.516129</td>
      <td>-0.085813</td>
      <td>-0.212751</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-0.040438</td>
      <td>-0.422696</td>
      <td>0.947661</td>
      <td>-0.309676</td>
      <td>-0.885457</td>
      <td>0.206889</td>
      <td>0.327254</td>
      <td>0.984757</td>
      <td>0.926540</td>
      <td>0.945039</td>
      <td>-0.067594</td>
      <td>0.693244</td>
      <td>0.998949</td>
      <td>0.427385</td>
      <td>-0.169055</td>
      <td>-0.357478</td>
      <td>0.374829</td>
      <td>-0.176008</td>
      <td>-1.446230</td>
      <td>-0.008888</td>
      <td>-0.894377</td>
      <td>0.141299</td>
      <td>0.440060</td>
      <td>-1.025606</td>
      <td>-0.767519</td>
      <td>0.524895</td>
      <td>-0.070525</td>
      <td>0.477907</td>
      <td>0.225173</td>
      <td>0.322260</td>
      <td>0.971765</td>
      <td>-0.201247</td>
      <td>0.259679</td>
      <td>0.524485</td>
      <td>0.154158</td>
      <td>0.666230</td>
      <td>0.315586</td>
      <td>-0.192351</td>
      <td>-0.004114</td>
      <td>-1.261261</td>
      <td>...</td>
      <td>-1.424475</td>
      <td>0.301650</td>
      <td>0.293595</td>
      <td>-0.277984</td>
      <td>0.652897</td>
      <td>0.820652</td>
      <td>-2.041269</td>
      <td>-1.651838</td>
      <td>-0.474235</td>
      <td>-1.379600</td>
      <td>-0.384143</td>
      <td>-0.090383</td>
      <td>0.496839</td>
      <td>0.241531</td>
      <td>0.316304</td>
      <td>-0.516013</td>
      <td>0.305021</td>
      <td>0.461565</td>
      <td>-0.083165</td>
      <td>0.360351</td>
      <td>-0.028105</td>
      <td>-0.278780</td>
      <td>-0.965609</td>
      <td>-0.426255</td>
      <td>0.143148</td>
      <td>0.571130</td>
      <td>0.690988</td>
      <td>0.544064</td>
      <td>1.256710</td>
      <td>1.030981</td>
      <td>0.845117</td>
      <td>-0.239433</td>
      <td>-0.479348</td>
      <td>-0.431509</td>
      <td>0.241729</td>
      <td>0.380195</td>
      <td>-0.437422</td>
      <td>0.742054</td>
      <td>0.256552</td>
      <td>-0.306271</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-0.136048</td>
      <td>-0.256167</td>
      <td>0.591564</td>
      <td>0.014524</td>
      <td>-0.378204</td>
      <td>0.360619</td>
      <td>-0.855594</td>
      <td>-0.210411</td>
      <td>-0.106637</td>
      <td>-0.154680</td>
      <td>0.573983</td>
      <td>0.261170</td>
      <td>0.108572</td>
      <td>-1.000344</td>
      <td>-0.623872</td>
      <td>-0.376120</td>
      <td>0.366393</td>
      <td>-0.087083</td>
      <td>0.678485</td>
      <td>0.086908</td>
      <td>-1.145838</td>
      <td>-0.811774</td>
      <td>0.404844</td>
      <td>-0.753476</td>
      <td>-0.120752</td>
      <td>0.519665</td>
      <td>0.415576</td>
      <td>0.424101</td>
      <td>-0.242741</td>
      <td>0.587597</td>
      <td>0.602623</td>
      <td>-0.176168</td>
      <td>0.640158</td>
      <td>-0.152309</td>
      <td>0.073535</td>
      <td>-0.437690</td>
      <td>-0.553518</td>
      <td>0.141857</td>
      <td>0.365382</td>
      <td>-0.551420</td>
      <td>...</td>
      <td>0.908260</td>
      <td>1.384085</td>
      <td>-0.327875</td>
      <td>-0.535444</td>
      <td>0.279217</td>
      <td>0.088038</td>
      <td>0.286277</td>
      <td>-0.849350</td>
      <td>0.050102</td>
      <td>-0.227644</td>
      <td>-0.666415</td>
      <td>-0.357162</td>
      <td>-0.424499</td>
      <td>-0.513787</td>
      <td>0.445263</td>
      <td>0.982580</td>
      <td>0.235361</td>
      <td>0.002196</td>
      <td>0.673532</td>
      <td>0.326534</td>
      <td>-0.600675</td>
      <td>-0.577943</td>
      <td>-0.906641</td>
      <td>0.935222</td>
      <td>0.226212</td>
      <td>0.331168</td>
      <td>-1.372544</td>
      <td>0.576586</td>
      <td>0.141808</td>
      <td>-0.275909</td>
      <td>1.486067</td>
      <td>-0.233027</td>
      <td>-0.035328</td>
      <td>-0.374490</td>
      <td>-0.958683</td>
      <td>0.997397</td>
      <td>-1.123431</td>
      <td>-1.100781</td>
      <td>-1.251986</td>
      <td>-0.271808</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.522225</td>
      <td>-0.634507</td>
      <td>-0.543003</td>
      <td>-0.475970</td>
      <td>-0.607256</td>
      <td>-0.119481</td>
      <td>0.956531</td>
      <td>1.271340</td>
      <td>0.038160</td>
      <td>0.558436</td>
      <td>1.203042</td>
      <td>0.865285</td>
      <td>0.595477</td>
      <td>0.356918</td>
      <td>-0.694354</td>
      <td>0.657385</td>
      <td>1.821859</td>
      <td>0.626137</td>
      <td>-0.121310</td>
      <td>-0.507677</td>
      <td>-0.078456</td>
      <td>-0.173481</td>
      <td>0.340844</td>
      <td>-0.011917</td>
      <td>-0.542573</td>
      <td>-0.317244</td>
      <td>-0.495715</td>
      <td>0.607145</td>
      <td>0.711555</td>
      <td>-0.323222</td>
      <td>0.177678</td>
      <td>-0.175175</td>
      <td>1.104117</td>
      <td>0.356331</td>
      <td>0.471991</td>
      <td>0.975930</td>
      <td>-0.305792</td>
      <td>0.741983</td>
      <td>-0.375872</td>
      <td>0.507528</td>
      <td>...</td>
      <td>-0.426477</td>
      <td>-0.562111</td>
      <td>0.056971</td>
      <td>0.360993</td>
      <td>0.735784</td>
      <td>-0.350635</td>
      <td>0.026812</td>
      <td>-0.359798</td>
      <td>1.294787</td>
      <td>1.405801</td>
      <td>-0.406537</td>
      <td>-0.195250</td>
      <td>0.120636</td>
      <td>0.530838</td>
      <td>0.141956</td>
      <td>-0.283410</td>
      <td>0.345050</td>
      <td>0.169326</td>
      <td>0.266409</td>
      <td>0.033627</td>
      <td>-0.705939</td>
      <td>-0.421656</td>
      <td>0.405073</td>
      <td>1.142237</td>
      <td>0.417489</td>
      <td>0.803112</td>
      <td>-0.428195</td>
      <td>-0.396470</td>
      <td>1.187718</td>
      <td>0.740723</td>
      <td>0.733022</td>
      <td>0.119388</td>
      <td>-0.159497</td>
      <td>-0.532943</td>
      <td>0.156917</td>
      <td>0.051562</td>
      <td>0.302308</td>
      <td>-1.269233</td>
      <td>-1.175272</td>
      <td>-0.297670</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.389140</td>
      <td>-1.329078</td>
      <td>-0.158245</td>
      <td>0.140085</td>
      <td>0.094685</td>
      <td>-0.481609</td>
      <td>-1.128281</td>
      <td>0.226106</td>
      <td>-0.350375</td>
      <td>-0.593058</td>
      <td>0.099070</td>
      <td>-0.647587</td>
      <td>-0.744727</td>
      <td>0.482258</td>
      <td>0.136482</td>
      <td>0.603092</td>
      <td>1.137734</td>
      <td>1.840780</td>
      <td>0.897208</td>
      <td>0.817486</td>
      <td>-1.243309</td>
      <td>0.256439</td>
      <td>-0.760998</td>
      <td>-0.446363</td>
      <td>-0.859726</td>
      <td>-0.602077</td>
      <td>-0.851840</td>
      <td>0.027606</td>
      <td>0.857974</td>
      <td>-0.181921</td>
      <td>0.533032</td>
      <td>-0.598728</td>
      <td>-0.622574</td>
      <td>0.707895</td>
      <td>-0.694823</td>
      <td>0.390528</td>
      <td>-0.116703</td>
      <td>-0.542803</td>
      <td>0.236851</td>
      <td>-0.185824</td>
      <td>...</td>
      <td>-0.033119</td>
      <td>0.000049</td>
      <td>-0.115570</td>
      <td>-0.329489</td>
      <td>-0.810091</td>
      <td>0.048317</td>
      <td>-1.726929</td>
      <td>0.015821</td>
      <td>-0.111263</td>
      <td>0.098540</td>
      <td>-0.310833</td>
      <td>-0.433010</td>
      <td>-0.400153</td>
      <td>0.203489</td>
      <td>-0.627656</td>
      <td>0.687160</td>
      <td>-1.153497</td>
      <td>-0.448756</td>
      <td>0.656121</td>
      <td>-0.030867</td>
      <td>-0.435416</td>
      <td>-0.135281</td>
      <td>1.039798</td>
      <td>0.121242</td>
      <td>-0.243662</td>
      <td>0.031992</td>
      <td>-0.600846</td>
      <td>-0.775828</td>
      <td>-0.280690</td>
      <td>-0.102452</td>
      <td>-0.206292</td>
      <td>-0.228155</td>
      <td>-0.089037</td>
      <td>-0.308511</td>
      <td>0.689598</td>
      <td>-0.098315</td>
      <td>0.519565</td>
      <td>0.273081</td>
      <td>0.715921</td>
      <td>0.381049</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-1.113217</td>
      <td>-0.326666</td>
      <td>0.440649</td>
      <td>-1.152502</td>
      <td>-0.802904</td>
      <td>0.427110</td>
      <td>0.237250</td>
      <td>1.225584</td>
      <td>0.864094</td>
      <td>0.435039</td>
      <td>0.852606</td>
      <td>0.526125</td>
      <td>0.595784</td>
      <td>-0.426275</td>
      <td>-0.763578</td>
      <td>0.978456</td>
      <td>0.768276</td>
      <td>0.617458</td>
      <td>0.115587</td>
      <td>-0.028183</td>
      <td>0.299578</td>
      <td>-0.337822</td>
      <td>0.905249</td>
      <td>-1.079423</td>
      <td>-0.405404</td>
      <td>-0.449433</td>
      <td>0.192323</td>
      <td>0.297634</td>
      <td>0.710518</td>
      <td>-0.731181</td>
      <td>0.701376</td>
      <td>0.011420</td>
      <td>0.355370</td>
      <td>0.294744</td>
      <td>-0.271002</td>
      <td>-0.375110</td>
      <td>-1.040182</td>
      <td>1.052618</td>
      <td>-0.187201</td>
      <td>0.279823</td>
      <td>...</td>
      <td>0.102841</td>
      <td>0.496504</td>
      <td>0.199228</td>
      <td>0.126688</td>
      <td>-0.613192</td>
      <td>-0.370700</td>
      <td>-0.795409</td>
      <td>-0.847918</td>
      <td>-0.234928</td>
      <td>-0.281105</td>
      <td>0.134945</td>
      <td>0.538194</td>
      <td>0.427479</td>
      <td>-0.101658</td>
      <td>-0.651135</td>
      <td>-0.165170</td>
      <td>0.101061</td>
      <td>-0.436428</td>
      <td>-0.050763</td>
      <td>0.217405</td>
      <td>-0.036347</td>
      <td>-0.046092</td>
      <td>-0.529219</td>
      <td>-0.097388</td>
      <td>0.496594</td>
      <td>0.456234</td>
      <td>-0.660416</td>
      <td>0.589835</td>
      <td>1.353469</td>
      <td>0.361135</td>
      <td>0.173687</td>
      <td>-0.612757</td>
      <td>-0.857349</td>
      <td>-0.566125</td>
      <td>-0.260345</td>
      <td>0.102789</td>
      <td>-0.305775</td>
      <td>-3.986222</td>
      <td>-2.978898</td>
      <td>-2.177695</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.582488</td>
      <td>-0.066738</td>
      <td>-0.290011</td>
      <td>0.163402</td>
      <td>0.269180</td>
      <td>-0.012991</td>
      <td>0.690184</td>
      <td>1.181324</td>
      <td>1.271909</td>
      <td>1.012492</td>
      <td>0.365313</td>
      <td>0.409441</td>
      <td>0.866003</td>
      <td>-0.850953</td>
      <td>-1.180435</td>
      <td>0.605241</td>
      <td>1.593707</td>
      <td>0.175950</td>
      <td>0.122425</td>
      <td>0.814201</td>
      <td>-0.152706</td>
      <td>0.072696</td>
      <td>-0.425557</td>
      <td>0.466454</td>
      <td>0.161248</td>
      <td>0.268647</td>
      <td>-0.140050</td>
      <td>0.909534</td>
      <td>0.166103</td>
      <td>-0.107645</td>
      <td>0.663266</td>
      <td>0.618581</td>
      <td>0.621825</td>
      <td>-0.355878</td>
      <td>-0.254054</td>
      <td>0.274779</td>
      <td>-0.287685</td>
      <td>-1.051650</td>
      <td>-0.053286</td>
      <td>-0.309428</td>
      <td>...</td>
      <td>-0.413101</td>
      <td>-0.191269</td>
      <td>-0.000130</td>
      <td>-0.327593</td>
      <td>0.509435</td>
      <td>1.023183</td>
      <td>-0.231957</td>
      <td>-1.305490</td>
      <td>0.241141</td>
      <td>0.334446</td>
      <td>-0.721341</td>
      <td>0.192829</td>
      <td>-0.143107</td>
      <td>0.405884</td>
      <td>-0.785621</td>
      <td>0.844867</td>
      <td>1.320950</td>
      <td>0.737016</td>
      <td>-1.159334</td>
      <td>-0.000266</td>
      <td>-0.400344</td>
      <td>-0.488201</td>
      <td>0.109482</td>
      <td>0.848050</td>
      <td>0.654791</td>
      <td>-0.267166</td>
      <td>0.334172</td>
      <td>0.674118</td>
      <td>-0.602563</td>
      <td>-0.604356</td>
      <td>-0.703653</td>
      <td>-0.685523</td>
      <td>-0.883325</td>
      <td>-0.135674</td>
      <td>0.215332</td>
      <td>-0.180214</td>
      <td>-0.376837</td>
      <td>-1.015880</td>
      <td>-0.177876</td>
      <td>-0.158057</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.338303</td>
      <td>-0.042737</td>
      <td>0.486991</td>
      <td>0.075071</td>
      <td>0.283136</td>
      <td>0.019239</td>
      <td>-0.689261</td>
      <td>-0.810329</td>
      <td>-0.775411</td>
      <td>0.152020</td>
      <td>0.663754</td>
      <td>0.362310</td>
      <td>-0.311527</td>
      <td>-0.249083</td>
      <td>-1.120010</td>
      <td>-0.484805</td>
      <td>0.522218</td>
      <td>-0.682013</td>
      <td>0.210964</td>
      <td>0.252577</td>
      <td>0.293539</td>
      <td>0.359983</td>
      <td>0.411616</td>
      <td>-1.127328</td>
      <td>-0.262485</td>
      <td>-0.728754</td>
      <td>-0.603061</td>
      <td>0.763732</td>
      <td>-0.778983</td>
      <td>0.198753</td>
      <td>-0.039089</td>
      <td>-0.503014</td>
      <td>0.136765</td>
      <td>-0.901010</td>
      <td>-0.651712</td>
      <td>-0.488003</td>
      <td>-0.328516</td>
      <td>0.375814</td>
      <td>0.556906</td>
      <td>0.470246</td>
      <td>...</td>
      <td>0.404609</td>
      <td>-0.104837</td>
      <td>0.179295</td>
      <td>0.469642</td>
      <td>-0.172912</td>
      <td>1.291071</td>
      <td>0.182249</td>
      <td>-0.496780</td>
      <td>0.017939</td>
      <td>0.460455</td>
      <td>-0.590693</td>
      <td>-0.182184</td>
      <td>-0.385935</td>
      <td>-1.253937</td>
      <td>-0.252849</td>
      <td>0.380200</td>
      <td>0.232801</td>
      <td>0.333959</td>
      <td>0.177430</td>
      <td>0.251923</td>
      <td>-0.040548</td>
      <td>-0.077697</td>
      <td>-0.176755</td>
      <td>0.045321</td>
      <td>-0.305510</td>
      <td>1.008140</td>
      <td>-0.697989</td>
      <td>0.161036</td>
      <td>1.019781</td>
      <td>-0.848570</td>
      <td>0.784716</td>
      <td>-0.253820</td>
      <td>0.826167</td>
      <td>0.111992</td>
      <td>0.911012</td>
      <td>-0.113730</td>
      <td>-0.596901</td>
      <td>0.450267</td>
      <td>0.950755</td>
      <td>0.970533</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.338678</td>
      <td>-0.553571</td>
      <td>-0.410103</td>
      <td>-0.793935</td>
      <td>0.459206</td>
      <td>-0.509516</td>
      <td>0.176562</td>
      <td>0.232346</td>
      <td>-1.009967</td>
      <td>-0.758739</td>
      <td>0.732481</td>
      <td>0.038459</td>
      <td>0.646434</td>
      <td>-0.794591</td>
      <td>0.054433</td>
      <td>0.095336</td>
      <td>-0.343127</td>
      <td>-0.639631</td>
      <td>-0.616463</td>
      <td>1.006454</td>
      <td>-0.644835</td>
      <td>0.287157</td>
      <td>0.229784</td>
      <td>-0.504429</td>
      <td>0.198601</td>
      <td>-0.043392</td>
      <td>-0.418300</td>
      <td>0.052732</td>
      <td>0.266154</td>
      <td>-0.417178</td>
      <td>0.434244</td>
      <td>-1.060780</td>
      <td>0.327448</td>
      <td>-0.443106</td>
      <td>-0.763583</td>
      <td>0.321250</td>
      <td>0.535928</td>
      <td>0.929931</td>
      <td>0.400179</td>
      <td>0.473058</td>
      <td>...</td>
      <td>0.414842</td>
      <td>0.237102</td>
      <td>-0.795251</td>
      <td>0.548608</td>
      <td>0.287751</td>
      <td>0.860109</td>
      <td>0.092936</td>
      <td>-1.534605</td>
      <td>-0.174078</td>
      <td>0.035859</td>
      <td>-0.382440</td>
      <td>-1.090635</td>
      <td>0.294564</td>
      <td>0.521445</td>
      <td>0.200838</td>
      <td>1.104407</td>
      <td>0.531760</td>
      <td>-0.160569</td>
      <td>0.218133</td>
      <td>0.270602</td>
      <td>-0.886309</td>
      <td>-0.105748</td>
      <td>-0.783524</td>
      <td>-0.112283</td>
      <td>-0.549389</td>
      <td>-0.470921</td>
      <td>-0.767029</td>
      <td>-0.015368</td>
      <td>0.604185</td>
      <td>0.486874</td>
      <td>1.189708</td>
      <td>0.334159</td>
      <td>0.144609</td>
      <td>0.052292</td>
      <td>-0.841536</td>
      <td>-0.746116</td>
      <td>-0.628226</td>
      <td>1.448191</td>
      <td>1.118882</td>
      <td>0.249639</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.033871</td>
      <td>-0.269026</td>
      <td>-0.903427</td>
      <td>-0.301139</td>
      <td>0.172244</td>
      <td>-0.368380</td>
      <td>0.148994</td>
      <td>1.114641</td>
      <td>0.114295</td>
      <td>0.195135</td>
      <td>-0.246657</td>
      <td>-0.953028</td>
      <td>-0.096700</td>
      <td>-0.093080</td>
      <td>-0.496611</td>
      <td>0.292702</td>
      <td>1.468737</td>
      <td>0.179772</td>
      <td>-0.296634</td>
      <td>0.486335</td>
      <td>0.076835</td>
      <td>-0.139811</td>
      <td>-0.425619</td>
      <td>0.153778</td>
      <td>0.145584</td>
      <td>-0.165819</td>
      <td>-0.708127</td>
      <td>0.370567</td>
      <td>-0.381349</td>
      <td>0.191882</td>
      <td>0.121061</td>
      <td>0.015362</td>
      <td>0.240664</td>
      <td>-0.068270</td>
      <td>-0.077508</td>
      <td>0.555250</td>
      <td>-0.300553</td>
      <td>0.990815</td>
      <td>0.543437</td>
      <td>0.342525</td>
      <td>...</td>
      <td>-0.237866</td>
      <td>0.502144</td>
      <td>0.334864</td>
      <td>-0.672537</td>
      <td>0.367826</td>
      <td>0.445559</td>
      <td>-0.125178</td>
      <td>-0.535086</td>
      <td>0.048691</td>
      <td>0.125958</td>
      <td>-0.457036</td>
      <td>0.385066</td>
      <td>-0.418670</td>
      <td>-0.148283</td>
      <td>-0.822706</td>
      <td>0.094350</td>
      <td>-0.352160</td>
      <td>-0.044029</td>
      <td>-0.874347</td>
      <td>1.297139</td>
      <td>0.058622</td>
      <td>0.269085</td>
      <td>-0.247782</td>
      <td>0.347337</td>
      <td>0.573970</td>
      <td>-0.192057</td>
      <td>-1.390586</td>
      <td>-1.146670</td>
      <td>-0.232765</td>
      <td>0.369105</td>
      <td>0.036771</td>
      <td>-0.440578</td>
      <td>0.510843</td>
      <td>-0.749879</td>
      <td>0.665988</td>
      <td>-0.379481</td>
      <td>-1.458014</td>
      <td>-0.993512</td>
      <td>-1.088109</td>
      <td>-1.265219</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.608117</td>
      <td>-1.042872</td>
      <td>-0.109460</td>
      <td>-0.431425</td>
      <td>-0.433735</td>
      <td>-1.472073</td>
      <td>0.767878</td>
      <td>1.527060</td>
      <td>0.146664</td>
      <td>0.440205</td>
      <td>1.083736</td>
      <td>-0.055297</td>
      <td>0.195222</td>
      <td>-0.393005</td>
      <td>-1.835468</td>
      <td>1.113047</td>
      <td>1.618145</td>
      <td>1.491909</td>
      <td>0.236795</td>
      <td>0.150152</td>
      <td>-0.334464</td>
      <td>0.244446</td>
      <td>-0.156719</td>
      <td>0.168175</td>
      <td>0.015875</td>
      <td>0.384584</td>
      <td>-0.644853</td>
      <td>-0.091379</td>
      <td>-0.890567</td>
      <td>0.292538</td>
      <td>0.377780</td>
      <td>1.059979</td>
      <td>0.832449</td>
      <td>1.754467</td>
      <td>0.060811</td>
      <td>0.492155</td>
      <td>-1.217698</td>
      <td>1.590118</td>
      <td>0.270695</td>
      <td>1.335721</td>
      <td>...</td>
      <td>0.629679</td>
      <td>0.069802</td>
      <td>-0.440436</td>
      <td>1.677968</td>
      <td>0.957719</td>
      <td>0.783486</td>
      <td>0.207876</td>
      <td>-0.460377</td>
      <td>-0.272968</td>
      <td>0.400857</td>
      <td>-0.470566</td>
      <td>0.102258</td>
      <td>0.953799</td>
      <td>-0.966387</td>
      <td>-0.408465</td>
      <td>-0.921392</td>
      <td>-0.156851</td>
      <td>-0.349645</td>
      <td>0.878416</td>
      <td>0.493594</td>
      <td>-0.129606</td>
      <td>-0.010636</td>
      <td>-0.879858</td>
      <td>0.198302</td>
      <td>0.116054</td>
      <td>0.453197</td>
      <td>-0.365060</td>
      <td>-0.473471</td>
      <td>-0.054083</td>
      <td>-0.572888</td>
      <td>0.731158</td>
      <td>-0.497778</td>
      <td>0.178957</td>
      <td>0.036344</td>
      <td>-1.026337</td>
      <td>-0.181123</td>
      <td>0.040268</td>
      <td>-0.884994</td>
      <td>-0.744839</td>
      <td>-0.268886</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.165352</td>
      <td>0.179201</td>
      <td>0.113397</td>
      <td>-0.592307</td>
      <td>-1.085109</td>
      <td>-1.032339</td>
      <td>-0.340677</td>
      <td>1.128153</td>
      <td>0.862278</td>
      <td>0.262528</td>
      <td>-0.270099</td>
      <td>-0.074901</td>
      <td>0.732042</td>
      <td>0.815642</td>
      <td>0.374241</td>
      <td>-0.347910</td>
      <td>-0.477757</td>
      <td>0.027857</td>
      <td>0.819230</td>
      <td>-0.065461</td>
      <td>0.240305</td>
      <td>-0.543278</td>
      <td>0.555851</td>
      <td>-0.024432</td>
      <td>0.384775</td>
      <td>-0.292010</td>
      <td>0.311789</td>
      <td>-0.164504</td>
      <td>-0.534558</td>
      <td>0.484238</td>
      <td>-0.017971</td>
      <td>-0.612876</td>
      <td>0.113177</td>
      <td>-0.061341</td>
      <td>-0.259282</td>
      <td>-1.139951</td>
      <td>-1.374670</td>
      <td>0.181726</td>
      <td>0.579935</td>
      <td>1.342516</td>
      <td>...</td>
      <td>0.507656</td>
      <td>-0.061444</td>
      <td>0.624600</td>
      <td>0.566259</td>
      <td>0.090280</td>
      <td>0.395265</td>
      <td>1.577599</td>
      <td>0.721532</td>
      <td>0.462012</td>
      <td>0.093317</td>
      <td>-0.368803</td>
      <td>0.783846</td>
      <td>-0.760863</td>
      <td>-0.004107</td>
      <td>-0.529613</td>
      <td>0.264244</td>
      <td>0.145723</td>
      <td>-0.245257</td>
      <td>-0.131343</td>
      <td>-0.828972</td>
      <td>-0.649656</td>
      <td>-0.763767</td>
      <td>-1.242880</td>
      <td>0.101059</td>
      <td>0.934406</td>
      <td>-0.114749</td>
      <td>0.401636</td>
      <td>0.215637</td>
      <td>0.450743</td>
      <td>0.639399</td>
      <td>-1.160053</td>
      <td>-0.688035</td>
      <td>0.412291</td>
      <td>1.123403</td>
      <td>0.037402</td>
      <td>0.503260</td>
      <td>0.209483</td>
      <td>0.049572</td>
      <td>-0.090892</td>
      <td>-0.495323</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.317951</td>
      <td>-0.004468</td>
      <td>-0.492441</td>
      <td>0.378450</td>
      <td>0.008259</td>
      <td>0.245571</td>
      <td>0.651015</td>
      <td>-0.306047</td>
      <td>-0.895961</td>
      <td>0.118050</td>
      <td>-0.385789</td>
      <td>0.547626</td>
      <td>0.347405</td>
      <td>-0.279079</td>
      <td>0.803285</td>
      <td>0.872477</td>
      <td>-0.028891</td>
      <td>-0.718416</td>
      <td>0.517695</td>
      <td>-0.631393</td>
      <td>1.168979</td>
      <td>-0.335063</td>
      <td>-1.101793</td>
      <td>-0.582970</td>
      <td>0.318878</td>
      <td>0.756949</td>
      <td>-0.009360</td>
      <td>0.462359</td>
      <td>0.224183</td>
      <td>0.222383</td>
      <td>-0.210089</td>
      <td>-0.172794</td>
      <td>0.861250</td>
      <td>0.877099</td>
      <td>0.100603</td>
      <td>-0.448102</td>
      <td>-0.430597</td>
      <td>0.101369</td>
      <td>-0.405058</td>
      <td>0.273082</td>
      <td>...</td>
      <td>0.478454</td>
      <td>-0.039433</td>
      <td>-0.656921</td>
      <td>-0.077773</td>
      <td>0.542330</td>
      <td>0.242647</td>
      <td>-0.341571</td>
      <td>0.958761</td>
      <td>0.645185</td>
      <td>0.227846</td>
      <td>0.042610</td>
      <td>0.723057</td>
      <td>-0.339013</td>
      <td>-0.470852</td>
      <td>-0.728855</td>
      <td>-0.985666</td>
      <td>-0.319310</td>
      <td>0.606966</td>
      <td>0.099533</td>
      <td>0.387911</td>
      <td>-0.689706</td>
      <td>-0.590378</td>
      <td>0.293217</td>
      <td>0.122424</td>
      <td>0.507594</td>
      <td>-0.116087</td>
      <td>1.210591</td>
      <td>0.994923</td>
      <td>-0.835751</td>
      <td>-0.021335</td>
      <td>0.283580</td>
      <td>0.185894</td>
      <td>-0.223873</td>
      <td>0.338359</td>
      <td>-0.121656</td>
      <td>-0.471399</td>
      <td>-0.291699</td>
      <td>-1.628800</td>
      <td>-1.541584</td>
      <td>-0.475798</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.990301</td>
      <td>0.048325</td>
      <td>-1.008663</td>
      <td>-0.707273</td>
      <td>-0.742179</td>
      <td>0.045977</td>
      <td>-0.313992</td>
      <td>-0.349424</td>
      <td>-0.372270</td>
      <td>1.077161</td>
      <td>0.918139</td>
      <td>-0.409854</td>
      <td>-0.821757</td>
      <td>-0.208524</td>
      <td>-0.129003</td>
      <td>0.083567</td>
      <td>0.050743</td>
      <td>-0.213766</td>
      <td>-0.565749</td>
      <td>-0.955456</td>
      <td>0.104832</td>
      <td>0.240507</td>
      <td>-1.430948</td>
      <td>-0.358276</td>
      <td>-0.374877</td>
      <td>-0.605154</td>
      <td>0.399059</td>
      <td>-0.227799</td>
      <td>-0.070105</td>
      <td>0.569448</td>
      <td>-0.612338</td>
      <td>-0.739300</td>
      <td>0.223214</td>
      <td>1.448803</td>
      <td>1.078125</td>
      <td>0.656568</td>
      <td>0.344096</td>
      <td>-0.702617</td>
      <td>0.367093</td>
      <td>0.384542</td>
      <td>...</td>
      <td>-0.906446</td>
      <td>-0.724842</td>
      <td>0.856837</td>
      <td>-0.432954</td>
      <td>0.068848</td>
      <td>-0.019017</td>
      <td>0.523339</td>
      <td>0.110421</td>
      <td>-0.394201</td>
      <td>0.303548</td>
      <td>0.250564</td>
      <td>0.347584</td>
      <td>-0.287728</td>
      <td>-0.207569</td>
      <td>-0.373358</td>
      <td>0.636756</td>
      <td>-0.430194</td>
      <td>0.273624</td>
      <td>0.049200</td>
      <td>-0.445350</td>
      <td>0.532961</td>
      <td>0.974184</td>
      <td>-0.780912</td>
      <td>0.095640</td>
      <td>0.559220</td>
      <td>0.062376</td>
      <td>-1.231625</td>
      <td>-1.020650</td>
      <td>-1.119210</td>
      <td>-0.124138</td>
      <td>0.165688</td>
      <td>-0.469488</td>
      <td>0.904652</td>
      <td>0.706517</td>
      <td>-0.263684</td>
      <td>0.015565</td>
      <td>-0.276517</td>
      <td>-1.664325</td>
      <td>-1.031251</td>
      <td>-0.069536</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.450173</td>
      <td>0.157575</td>
      <td>-0.418621</td>
      <td>0.164841</td>
      <td>0.190129</td>
      <td>-0.100470</td>
      <td>1.052694</td>
      <td>1.047207</td>
      <td>0.526254</td>
      <td>0.918190</td>
      <td>0.353249</td>
      <td>-0.057531</td>
      <td>-1.278006</td>
      <td>-0.856728</td>
      <td>0.575627</td>
      <td>0.775823</td>
      <td>0.135881</td>
      <td>0.465220</td>
      <td>0.979650</td>
      <td>0.143109</td>
      <td>0.269768</td>
      <td>-0.633749</td>
      <td>0.056101</td>
      <td>-0.111979</td>
      <td>0.239872</td>
      <td>-0.677443</td>
      <td>0.581893</td>
      <td>-0.330178</td>
      <td>-1.558567</td>
      <td>-0.540073</td>
      <td>0.303777</td>
      <td>0.459171</td>
      <td>-0.482207</td>
      <td>0.291579</td>
      <td>0.174526</td>
      <td>0.789376</td>
      <td>-0.287511</td>
      <td>0.194110</td>
      <td>0.352842</td>
      <td>0.074451</td>
      <td>...</td>
      <td>-0.034112</td>
      <td>0.953097</td>
      <td>0.111510</td>
      <td>-0.155775</td>
      <td>-0.028995</td>
      <td>0.350386</td>
      <td>0.387551</td>
      <td>1.091166</td>
      <td>1.728613</td>
      <td>-0.252611</td>
      <td>-0.291639</td>
      <td>-0.035686</td>
      <td>-1.028204</td>
      <td>0.502893</td>
      <td>0.378082</td>
      <td>-0.063378</td>
      <td>-0.680606</td>
      <td>0.271984</td>
      <td>-0.549689</td>
      <td>-0.420682</td>
      <td>0.288988</td>
      <td>-0.560965</td>
      <td>-0.258039</td>
      <td>-0.078787</td>
      <td>-1.030978</td>
      <td>-0.091100</td>
      <td>0.139121</td>
      <td>1.259173</td>
      <td>-0.277983</td>
      <td>-0.375451</td>
      <td>0.871746</td>
      <td>0.023877</td>
      <td>1.121108</td>
      <td>-0.264572</td>
      <td>1.121837</td>
      <td>0.469590</td>
      <td>0.157459</td>
      <td>1.087459</td>
      <td>0.120710</td>
      <td>0.089101</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.374178</td>
      <td>1.038183</td>
      <td>-0.133466</td>
      <td>-0.196942</td>
      <td>0.376627</td>
      <td>0.456543</td>
      <td>0.506884</td>
      <td>0.884499</td>
      <td>0.164636</td>
      <td>0.289011</td>
      <td>1.206492</td>
      <td>-0.865952</td>
      <td>-1.273389</td>
      <td>0.527600</td>
      <td>-0.144370</td>
      <td>0.936589</td>
      <td>0.091861</td>
      <td>0.387423</td>
      <td>0.965054</td>
      <td>-0.647108</td>
      <td>-0.548625</td>
      <td>-1.561925</td>
      <td>-0.397002</td>
      <td>-0.781533</td>
      <td>-0.705625</td>
      <td>0.239858</td>
      <td>-0.242231</td>
      <td>-0.001690</td>
      <td>0.395917</td>
      <td>0.354442</td>
      <td>0.018942</td>
      <td>-0.628054</td>
      <td>-0.104252</td>
      <td>-0.488258</td>
      <td>0.739559</td>
      <td>-0.282002</td>
      <td>-0.202649</td>
      <td>1.141687</td>
      <td>-0.180956</td>
      <td>-0.896033</td>
      <td>...</td>
      <td>-0.823374</td>
      <td>-0.571055</td>
      <td>0.415332</td>
      <td>0.062821</td>
      <td>-0.206416</td>
      <td>-0.377848</td>
      <td>-0.627451</td>
      <td>-0.266291</td>
      <td>0.653232</td>
      <td>-0.016922</td>
      <td>-0.285527</td>
      <td>0.715068</td>
      <td>-0.345702</td>
      <td>-0.150420</td>
      <td>-0.411333</td>
      <td>-0.754912</td>
      <td>-1.492060</td>
      <td>-0.287503</td>
      <td>0.289521</td>
      <td>0.948388</td>
      <td>0.787672</td>
      <td>0.313974</td>
      <td>0.619439</td>
      <td>-0.376763</td>
      <td>0.238982</td>
      <td>0.896661</td>
      <td>0.077653</td>
      <td>-0.325920</td>
      <td>0.559009</td>
      <td>0.909270</td>
      <td>0.523376</td>
      <td>-0.385550</td>
      <td>-0.225109</td>
      <td>-0.149436</td>
      <td>-0.808733</td>
      <td>0.645198</td>
      <td>0.191285</td>
      <td>-1.704168</td>
      <td>-1.231655</td>
      <td>-0.045296</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f2cd43df5b0&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.099999  0.042889  25.647334  4.527736e-145  1.015937  1.184061
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  5.011 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>