
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.639763</td>
      <td>0.242708</td>
      <td>0.358978</td>
      <td>0.408469</td>
      <td>-0.084671</td>
      <td>0.312263</td>
      <td>-0.688309</td>
      <td>-0.365282</td>
      <td>-0.755487</td>
      <td>0.041786</td>
      <td>-0.159023</td>
      <td>-0.261463</td>
      <td>0.272585</td>
      <td>0.259400</td>
      <td>0.384641</td>
      <td>0.563572</td>
      <td>-0.292760</td>
      <td>-0.085350</td>
      <td>0.188653</td>
      <td>-0.411325</td>
      <td>-0.573063</td>
      <td>-0.528856</td>
      <td>0.156232</td>
      <td>-0.612357</td>
      <td>-0.589390</td>
      <td>0.157177</td>
      <td>-0.571232</td>
      <td>1.131667</td>
      <td>0.626811</td>
      <td>0.443866</td>
      <td>-0.919516</td>
      <td>0.370588</td>
      <td>0.523393</td>
      <td>-0.199017</td>
      <td>0.512927</td>
      <td>-0.553472</td>
      <td>-0.703466</td>
      <td>0.399004</td>
      <td>0.460245</td>
      <td>0.555781</td>
      <td>...</td>
      <td>0.291248</td>
      <td>0.285213</td>
      <td>-0.361932</td>
      <td>0.653138</td>
      <td>0.219447</td>
      <td>0.459607</td>
      <td>0.749276</td>
      <td>-0.202200</td>
      <td>-0.081548</td>
      <td>0.256672</td>
      <td>-0.058739</td>
      <td>-0.394254</td>
      <td>0.812713</td>
      <td>0.834301</td>
      <td>0.188388</td>
      <td>0.394477</td>
      <td>-0.686077</td>
      <td>-0.083253</td>
      <td>-0.374373</td>
      <td>0.638932</td>
      <td>1.225391</td>
      <td>0.612572</td>
      <td>0.847303</td>
      <td>0.376808</td>
      <td>1.137355</td>
      <td>-0.864343</td>
      <td>0.739668</td>
      <td>0.247560</td>
      <td>-0.266501</td>
      <td>0.032905</td>
      <td>0.002517</td>
      <td>0.697524</td>
      <td>-0.274910</td>
      <td>0.469861</td>
      <td>-0.417728</td>
      <td>-0.347257</td>
      <td>-1.350466</td>
      <td>0.147331</td>
      <td>-0.382069</td>
      <td>-0.665948</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.196256</td>
      <td>-0.199225</td>
      <td>0.190441</td>
      <td>-0.476421</td>
      <td>-0.218570</td>
      <td>-1.076089</td>
      <td>0.497638</td>
      <td>-0.158193</td>
      <td>-0.552380</td>
      <td>-0.199666</td>
      <td>0.152902</td>
      <td>0.812222</td>
      <td>-0.685135</td>
      <td>0.017120</td>
      <td>-0.073081</td>
      <td>1.394622</td>
      <td>-0.476877</td>
      <td>0.050707</td>
      <td>0.042744</td>
      <td>0.381040</td>
      <td>-0.256530</td>
      <td>0.666809</td>
      <td>0.944866</td>
      <td>-0.439106</td>
      <td>0.752143</td>
      <td>0.164903</td>
      <td>0.210596</td>
      <td>0.337705</td>
      <td>0.739261</td>
      <td>-0.207217</td>
      <td>0.070184</td>
      <td>-0.114318</td>
      <td>0.480334</td>
      <td>0.019235</td>
      <td>0.384717</td>
      <td>0.003473</td>
      <td>0.334260</td>
      <td>-0.903659</td>
      <td>-0.290948</td>
      <td>-0.112940</td>
      <td>...</td>
      <td>-0.128517</td>
      <td>-0.203379</td>
      <td>-0.036314</td>
      <td>1.361113</td>
      <td>0.441784</td>
      <td>0.728662</td>
      <td>-0.340832</td>
      <td>-0.941610</td>
      <td>-0.541121</td>
      <td>0.515394</td>
      <td>0.588794</td>
      <td>0.359909</td>
      <td>0.636180</td>
      <td>-0.724838</td>
      <td>0.003764</td>
      <td>1.013206</td>
      <td>-0.303361</td>
      <td>-0.577739</td>
      <td>-0.234696</td>
      <td>-0.322403</td>
      <td>-0.504440</td>
      <td>0.220005</td>
      <td>0.667313</td>
      <td>-0.205120</td>
      <td>-0.791211</td>
      <td>-0.583933</td>
      <td>-0.561653</td>
      <td>0.645489</td>
      <td>0.377620</td>
      <td>0.185269</td>
      <td>0.208725</td>
      <td>-0.481212</td>
      <td>-0.031265</td>
      <td>-0.257366</td>
      <td>-0.089976</td>
      <td>0.472204</td>
      <td>0.238139</td>
      <td>-1.122478</td>
      <td>-0.870442</td>
      <td>-0.946246</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.565279</td>
      <td>-1.186160</td>
      <td>-0.328278</td>
      <td>-0.978086</td>
      <td>-1.269197</td>
      <td>-0.184668</td>
      <td>0.676489</td>
      <td>0.012211</td>
      <td>0.322854</td>
      <td>0.092764</td>
      <td>-1.365772</td>
      <td>0.961708</td>
      <td>-0.442267</td>
      <td>0.274266</td>
      <td>0.587633</td>
      <td>0.539451</td>
      <td>-0.090530</td>
      <td>1.977053</td>
      <td>0.351690</td>
      <td>-0.092453</td>
      <td>0.123481</td>
      <td>0.102102</td>
      <td>-0.431362</td>
      <td>-0.400106</td>
      <td>-0.539151</td>
      <td>-0.330877</td>
      <td>0.567149</td>
      <td>-0.725686</td>
      <td>-1.143046</td>
      <td>-0.236786</td>
      <td>0.024106</td>
      <td>-0.575046</td>
      <td>1.294474</td>
      <td>0.760262</td>
      <td>1.220166</td>
      <td>0.854174</td>
      <td>-0.413552</td>
      <td>-1.112042</td>
      <td>-0.807913</td>
      <td>0.688951</td>
      <td>...</td>
      <td>-1.304792</td>
      <td>0.532323</td>
      <td>0.284662</td>
      <td>-0.559308</td>
      <td>-0.268543</td>
      <td>0.367737</td>
      <td>-0.749763</td>
      <td>-0.897997</td>
      <td>0.517005</td>
      <td>0.810171</td>
      <td>1.119501</td>
      <td>0.053694</td>
      <td>0.388002</td>
      <td>-0.523865</td>
      <td>0.956580</td>
      <td>-0.141017</td>
      <td>-0.747546</td>
      <td>0.239289</td>
      <td>-0.950784</td>
      <td>0.582591</td>
      <td>0.118648</td>
      <td>0.562950</td>
      <td>0.404674</td>
      <td>-0.562438</td>
      <td>-0.581069</td>
      <td>-0.284314</td>
      <td>-0.530743</td>
      <td>0.920737</td>
      <td>0.351033</td>
      <td>0.208223</td>
      <td>-0.667013</td>
      <td>-0.282356</td>
      <td>-0.714360</td>
      <td>-0.439514</td>
      <td>-0.677479</td>
      <td>-0.306808</td>
      <td>1.134817</td>
      <td>-1.255182</td>
      <td>-0.792310</td>
      <td>-0.184064</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.343978</td>
      <td>0.203321</td>
      <td>0.169258</td>
      <td>0.137853</td>
      <td>0.310498</td>
      <td>0.533613</td>
      <td>1.483293</td>
      <td>0.243887</td>
      <td>-0.468732</td>
      <td>0.888798</td>
      <td>0.177319</td>
      <td>0.509424</td>
      <td>0.122561</td>
      <td>0.261352</td>
      <td>1.206702</td>
      <td>0.071877</td>
      <td>-0.312187</td>
      <td>-0.494282</td>
      <td>-0.159508</td>
      <td>-0.584491</td>
      <td>-0.822549</td>
      <td>-0.177558</td>
      <td>-0.674906</td>
      <td>-0.484115</td>
      <td>0.696637</td>
      <td>0.697958</td>
      <td>0.018407</td>
      <td>-0.525084</td>
      <td>-0.260773</td>
      <td>-0.096239</td>
      <td>-0.262928</td>
      <td>-1.261636</td>
      <td>1.035712</td>
      <td>0.106135</td>
      <td>0.659922</td>
      <td>0.519190</td>
      <td>0.692215</td>
      <td>-0.972341</td>
      <td>-0.391487</td>
      <td>0.357854</td>
      <td>...</td>
      <td>-0.004063</td>
      <td>0.664025</td>
      <td>-1.264070</td>
      <td>-0.732888</td>
      <td>-0.382518</td>
      <td>-0.079711</td>
      <td>-0.201103</td>
      <td>-1.084724</td>
      <td>-0.381642</td>
      <td>0.763298</td>
      <td>0.835697</td>
      <td>0.136031</td>
      <td>-0.300586</td>
      <td>0.296078</td>
      <td>1.078809</td>
      <td>0.267258</td>
      <td>-0.183479</td>
      <td>-0.333733</td>
      <td>-0.309231</td>
      <td>-0.755044</td>
      <td>-1.435333</td>
      <td>-0.603795</td>
      <td>0.056871</td>
      <td>0.222281</td>
      <td>0.794259</td>
      <td>-0.221242</td>
      <td>-0.170098</td>
      <td>-0.606113</td>
      <td>-0.168008</td>
      <td>-0.164262</td>
      <td>-0.326628</td>
      <td>0.876332</td>
      <td>0.106116</td>
      <td>-0.586538</td>
      <td>-0.502660</td>
      <td>-1.004318</td>
      <td>0.008721</td>
      <td>2.162152</td>
      <td>0.920617</td>
      <td>0.086870</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.083098</td>
      <td>0.026365</td>
      <td>0.007727</td>
      <td>0.118861</td>
      <td>0.172217</td>
      <td>-1.008252</td>
      <td>-0.293825</td>
      <td>-0.487721</td>
      <td>-0.189915</td>
      <td>-0.840950</td>
      <td>-0.043855</td>
      <td>-0.265347</td>
      <td>-1.457915</td>
      <td>0.313531</td>
      <td>0.477928</td>
      <td>0.175462</td>
      <td>-0.024282</td>
      <td>0.069329</td>
      <td>0.537546</td>
      <td>0.361427</td>
      <td>0.182302</td>
      <td>0.396030</td>
      <td>-0.597175</td>
      <td>-0.489058</td>
      <td>-0.427827</td>
      <td>0.240113</td>
      <td>0.254242</td>
      <td>0.066347</td>
      <td>0.653373</td>
      <td>-0.267754</td>
      <td>0.489733</td>
      <td>0.237695</td>
      <td>0.277468</td>
      <td>0.230114</td>
      <td>0.657007</td>
      <td>0.561092</td>
      <td>0.635804</td>
      <td>1.213892</td>
      <td>-0.283494</td>
      <td>1.405441</td>
      <td>...</td>
      <td>0.547397</td>
      <td>1.024031</td>
      <td>0.380808</td>
      <td>0.133352</td>
      <td>-0.179909</td>
      <td>-0.404225</td>
      <td>-0.358766</td>
      <td>-1.091081</td>
      <td>-0.121869</td>
      <td>-0.402704</td>
      <td>-0.335309</td>
      <td>-0.469607</td>
      <td>-0.168222</td>
      <td>0.635438</td>
      <td>0.445338</td>
      <td>-0.918785</td>
      <td>0.324165</td>
      <td>-0.170113</td>
      <td>-0.084103</td>
      <td>-0.184357</td>
      <td>-0.191157</td>
      <td>1.286170</td>
      <td>0.394660</td>
      <td>-0.069577</td>
      <td>0.184188</td>
      <td>0.415763</td>
      <td>0.515892</td>
      <td>-0.999115</td>
      <td>-0.185229</td>
      <td>-0.443607</td>
      <td>0.072722</td>
      <td>0.167484</td>
      <td>0.390873</td>
      <td>0.159885</td>
      <td>0.388485</td>
      <td>0.027854</td>
      <td>-0.015740</td>
      <td>-0.889481</td>
      <td>-0.199257</td>
      <td>0.556060</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.261186</td>
      <td>1.204115</td>
      <td>-0.762798</td>
      <td>-0.543126</td>
      <td>-0.848311</td>
      <td>0.628813</td>
      <td>-0.127869</td>
      <td>1.119259</td>
      <td>0.518215</td>
      <td>0.155505</td>
      <td>-0.796473</td>
      <td>-1.369638</td>
      <td>-0.501128</td>
      <td>0.416369</td>
      <td>0.975564</td>
      <td>0.454955</td>
      <td>0.547937</td>
      <td>1.117731</td>
      <td>-0.625485</td>
      <td>0.685552</td>
      <td>0.157990</td>
      <td>0.528332</td>
      <td>-0.411355</td>
      <td>-0.448770</td>
      <td>-0.426153</td>
      <td>-0.071728</td>
      <td>0.447776</td>
      <td>0.544939</td>
      <td>-0.026829</td>
      <td>0.204693</td>
      <td>1.165950</td>
      <td>-1.418788</td>
      <td>-0.230279</td>
      <td>0.114637</td>
      <td>-0.005136</td>
      <td>-0.476041</td>
      <td>-0.387631</td>
      <td>-0.447244</td>
      <td>-0.350913</td>
      <td>-0.004169</td>
      <td>...</td>
      <td>0.036104</td>
      <td>0.895466</td>
      <td>0.549792</td>
      <td>-0.009934</td>
      <td>-0.441218</td>
      <td>-0.208966</td>
      <td>0.820938</td>
      <td>-0.369512</td>
      <td>-0.128385</td>
      <td>0.008556</td>
      <td>-0.423653</td>
      <td>-0.538331</td>
      <td>-0.309321</td>
      <td>-0.179140</td>
      <td>-0.053355</td>
      <td>-0.022150</td>
      <td>-0.395415</td>
      <td>-0.635697</td>
      <td>-1.691991</td>
      <td>-1.230698</td>
      <td>-0.000970</td>
      <td>-0.271066</td>
      <td>0.094588</td>
      <td>-0.095724</td>
      <td>0.045127</td>
      <td>0.136099</td>
      <td>0.084626</td>
      <td>-0.625577</td>
      <td>0.390323</td>
      <td>0.418333</td>
      <td>0.101920</td>
      <td>-0.060982</td>
      <td>0.111285</td>
      <td>-0.286502</td>
      <td>-0.478831</td>
      <td>-1.126871</td>
      <td>-0.224468</td>
      <td>0.556320</td>
      <td>0.726300</td>
      <td>0.164712</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.753610</td>
      <td>0.297562</td>
      <td>0.195699</td>
      <td>0.406945</td>
      <td>0.313986</td>
      <td>0.121515</td>
      <td>0.490665</td>
      <td>-1.360052</td>
      <td>-0.738774</td>
      <td>-0.252832</td>
      <td>-0.093362</td>
      <td>-0.414198</td>
      <td>-0.001937</td>
      <td>0.389204</td>
      <td>-0.172556</td>
      <td>0.308326</td>
      <td>-0.671161</td>
      <td>0.169313</td>
      <td>-0.137166</td>
      <td>-0.689815</td>
      <td>-0.392428</td>
      <td>-0.681219</td>
      <td>-0.308505</td>
      <td>0.381167</td>
      <td>0.179124</td>
      <td>0.808414</td>
      <td>1.009247</td>
      <td>0.770711</td>
      <td>0.471010</td>
      <td>0.880849</td>
      <td>-0.003560</td>
      <td>-0.927719</td>
      <td>-0.221784</td>
      <td>0.045723</td>
      <td>-0.528436</td>
      <td>-0.165300</td>
      <td>-0.003415</td>
      <td>-0.155862</td>
      <td>0.418379</td>
      <td>0.219217</td>
      <td>...</td>
      <td>0.143678</td>
      <td>-0.227279</td>
      <td>-0.079528</td>
      <td>0.800461</td>
      <td>-0.515542</td>
      <td>0.015098</td>
      <td>-0.973222</td>
      <td>-1.805008</td>
      <td>-0.169559</td>
      <td>0.507192</td>
      <td>0.083114</td>
      <td>-0.340778</td>
      <td>0.458346</td>
      <td>0.138142</td>
      <td>0.010194</td>
      <td>-0.029961</td>
      <td>0.017608</td>
      <td>0.940615</td>
      <td>-0.178591</td>
      <td>0.014087</td>
      <td>1.249316</td>
      <td>1.433803</td>
      <td>0.724731</td>
      <td>0.026575</td>
      <td>0.432434</td>
      <td>-0.325203</td>
      <td>-0.325403</td>
      <td>-0.450033</td>
      <td>-0.399669</td>
      <td>-0.357190</td>
      <td>-0.074964</td>
      <td>0.175752</td>
      <td>-0.388016</td>
      <td>0.229469</td>
      <td>0.040038</td>
      <td>0.448144</td>
      <td>0.983041</td>
      <td>0.840469</td>
      <td>0.550516</td>
      <td>0.567005</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.474571</td>
      <td>0.592292</td>
      <td>0.375942</td>
      <td>-0.214118</td>
      <td>-0.365008</td>
      <td>-0.048661</td>
      <td>0.670289</td>
      <td>-0.555012</td>
      <td>0.072554</td>
      <td>-0.325092</td>
      <td>-0.258660</td>
      <td>1.184601</td>
      <td>0.816816</td>
      <td>0.357434</td>
      <td>0.914984</td>
      <td>-0.082725</td>
      <td>-0.167803</td>
      <td>0.955046</td>
      <td>0.688830</td>
      <td>0.411356</td>
      <td>0.194196</td>
      <td>0.288862</td>
      <td>-0.427365</td>
      <td>-1.151808</td>
      <td>-0.477451</td>
      <td>0.193839</td>
      <td>-0.652786</td>
      <td>-0.826128</td>
      <td>0.445908</td>
      <td>-0.383450</td>
      <td>-0.161286</td>
      <td>0.513602</td>
      <td>-0.215310</td>
      <td>0.528924</td>
      <td>0.340277</td>
      <td>-0.065463</td>
      <td>-0.143307</td>
      <td>-0.219108</td>
      <td>-1.110516</td>
      <td>-0.556326</td>
      <td>...</td>
      <td>0.463738</td>
      <td>0.275749</td>
      <td>0.033402</td>
      <td>1.281699</td>
      <td>0.992400</td>
      <td>0.890365</td>
      <td>0.359710</td>
      <td>-0.795641</td>
      <td>-0.525219</td>
      <td>0.453267</td>
      <td>-1.054497</td>
      <td>-0.215139</td>
      <td>0.013883</td>
      <td>-0.091756</td>
      <td>0.187534</td>
      <td>-0.008322</td>
      <td>-1.249766</td>
      <td>-0.146453</td>
      <td>-0.150190</td>
      <td>0.554351</td>
      <td>0.142507</td>
      <td>0.471922</td>
      <td>1.239618</td>
      <td>0.118846</td>
      <td>-0.237795</td>
      <td>-0.222456</td>
      <td>-0.168603</td>
      <td>-0.364370</td>
      <td>0.411366</td>
      <td>-0.208042</td>
      <td>0.555974</td>
      <td>1.355429</td>
      <td>-0.863927</td>
      <td>-1.184737</td>
      <td>-0.975084</td>
      <td>-0.554134</td>
      <td>-0.340510</td>
      <td>2.476824</td>
      <td>1.647922</td>
      <td>0.448988</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.860927</td>
      <td>0.290327</td>
      <td>-0.383573</td>
      <td>0.483504</td>
      <td>-0.256708</td>
      <td>-0.323507</td>
      <td>0.027667</td>
      <td>-0.032493</td>
      <td>0.134281</td>
      <td>-1.262420</td>
      <td>-0.503399</td>
      <td>-0.357501</td>
      <td>-0.613801</td>
      <td>0.307069</td>
      <td>0.789263</td>
      <td>0.579106</td>
      <td>0.026694</td>
      <td>0.201250</td>
      <td>-1.358332</td>
      <td>-0.958300</td>
      <td>-0.348847</td>
      <td>0.288267</td>
      <td>-0.997615</td>
      <td>-0.313398</td>
      <td>0.155124</td>
      <td>0.554325</td>
      <td>-0.526188</td>
      <td>-0.761980</td>
      <td>0.464554</td>
      <td>0.952176</td>
      <td>-0.017351</td>
      <td>0.023491</td>
      <td>-0.129909</td>
      <td>0.088304</td>
      <td>-0.406951</td>
      <td>-1.012312</td>
      <td>0.232871</td>
      <td>0.105113</td>
      <td>-0.847125</td>
      <td>-0.298276</td>
      <td>...</td>
      <td>-0.394725</td>
      <td>-0.151649</td>
      <td>-0.289055</td>
      <td>0.121909</td>
      <td>-0.316272</td>
      <td>0.133698</td>
      <td>-0.059349</td>
      <td>-0.468936</td>
      <td>-0.718668</td>
      <td>0.044065</td>
      <td>-0.193793</td>
      <td>-0.236700</td>
      <td>-0.162566</td>
      <td>0.629750</td>
      <td>0.123576</td>
      <td>-0.427798</td>
      <td>-0.201766</td>
      <td>0.522291</td>
      <td>0.434936</td>
      <td>-1.349295</td>
      <td>-0.568787</td>
      <td>-0.090114</td>
      <td>-0.358730</td>
      <td>0.293744</td>
      <td>0.414744</td>
      <td>0.254468</td>
      <td>0.164073</td>
      <td>0.038103</td>
      <td>-0.155573</td>
      <td>-0.039723</td>
      <td>-0.768468</td>
      <td>-0.147566</td>
      <td>-0.691701</td>
      <td>0.068046</td>
      <td>-0.079401</td>
      <td>-0.415386</td>
      <td>0.310632</td>
      <td>0.246868</td>
      <td>1.559025</td>
      <td>1.094535</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-0.245845</td>
      <td>-0.079558</td>
      <td>-0.241173</td>
      <td>-0.551866</td>
      <td>-0.338490</td>
      <td>-1.220689</td>
      <td>0.606406</td>
      <td>0.692406</td>
      <td>-0.003691</td>
      <td>-0.994061</td>
      <td>-0.529193</td>
      <td>-0.194354</td>
      <td>-0.444713</td>
      <td>0.251476</td>
      <td>0.290152</td>
      <td>0.619142</td>
      <td>-0.211188</td>
      <td>-0.338694</td>
      <td>0.093672</td>
      <td>0.114055</td>
      <td>0.474368</td>
      <td>-0.114219</td>
      <td>-0.668032</td>
      <td>0.473033</td>
      <td>-1.055699</td>
      <td>0.199041</td>
      <td>0.374832</td>
      <td>-0.113956</td>
      <td>0.474427</td>
      <td>0.142259</td>
      <td>-0.709590</td>
      <td>-0.306135</td>
      <td>1.534824</td>
      <td>0.613013</td>
      <td>0.324092</td>
      <td>-0.759387</td>
      <td>-0.406170</td>
      <td>0.590260</td>
      <td>0.227423</td>
      <td>0.145340</td>
      <td>...</td>
      <td>-1.019699</td>
      <td>0.694216</td>
      <td>0.197752</td>
      <td>0.413998</td>
      <td>-0.503350</td>
      <td>0.165890</td>
      <td>0.227732</td>
      <td>-0.667070</td>
      <td>0.506350</td>
      <td>0.704864</td>
      <td>0.649653</td>
      <td>-0.738883</td>
      <td>-0.217000</td>
      <td>-0.308302</td>
      <td>0.043447</td>
      <td>-1.507650</td>
      <td>-0.136011</td>
      <td>0.509623</td>
      <td>-0.386921</td>
      <td>-0.062121</td>
      <td>-0.127789</td>
      <td>0.979542</td>
      <td>0.350877</td>
      <td>-1.054632</td>
      <td>-1.044566</td>
      <td>-1.047107</td>
      <td>-0.548442</td>
      <td>-0.193129</td>
      <td>0.494411</td>
      <td>0.258047</td>
      <td>0.065989</td>
      <td>-1.273318</td>
      <td>-1.229227</td>
      <td>-0.037065</td>
      <td>-0.616907</td>
      <td>-0.670771</td>
      <td>0.326239</td>
      <td>-0.747351</td>
      <td>-1.152973</td>
      <td>-0.616734</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.837423</td>
      <td>-0.110959</td>
      <td>0.123949</td>
      <td>-0.597610</td>
      <td>-0.043340</td>
      <td>-0.003629</td>
      <td>-1.033501</td>
      <td>1.105293</td>
      <td>0.477172</td>
      <td>0.705411</td>
      <td>0.161528</td>
      <td>-0.215064</td>
      <td>-0.500438</td>
      <td>-1.107086</td>
      <td>-0.024783</td>
      <td>-0.145531</td>
      <td>-0.017368</td>
      <td>0.520374</td>
      <td>0.251467</td>
      <td>0.069815</td>
      <td>-0.940987</td>
      <td>-0.882462</td>
      <td>-0.204834</td>
      <td>-0.578049</td>
      <td>0.510442</td>
      <td>-0.229693</td>
      <td>0.535602</td>
      <td>0.246651</td>
      <td>-0.143091</td>
      <td>0.908756</td>
      <td>0.266511</td>
      <td>-0.763286</td>
      <td>-0.510727</td>
      <td>0.463234</td>
      <td>0.128032</td>
      <td>-1.193253</td>
      <td>0.005708</td>
      <td>-0.326884</td>
      <td>-0.681631</td>
      <td>0.181704</td>
      <td>...</td>
      <td>-0.455744</td>
      <td>-0.323710</td>
      <td>-1.211337</td>
      <td>0.589761</td>
      <td>-0.174073</td>
      <td>-0.121265</td>
      <td>0.289254</td>
      <td>-1.212573</td>
      <td>-0.845409</td>
      <td>0.328066</td>
      <td>0.667677</td>
      <td>0.088955</td>
      <td>-0.538192</td>
      <td>-0.217386</td>
      <td>-0.057720</td>
      <td>-0.718149</td>
      <td>-0.733791</td>
      <td>0.117739</td>
      <td>-0.480809</td>
      <td>-1.393699</td>
      <td>-0.297827</td>
      <td>0.365657</td>
      <td>0.698667</td>
      <td>-1.180965</td>
      <td>-0.078009</td>
      <td>0.458380</td>
      <td>-0.023362</td>
      <td>-0.900085</td>
      <td>0.423521</td>
      <td>-0.264315</td>
      <td>0.368480</td>
      <td>0.217095</td>
      <td>0.173976</td>
      <td>-0.735068</td>
      <td>-1.099468</td>
      <td>0.083651</td>
      <td>0.038770</td>
      <td>0.807867</td>
      <td>0.302158</td>
      <td>-0.171586</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.421332</td>
      <td>0.472020</td>
      <td>0.167402</td>
      <td>0.639970</td>
      <td>0.368054</td>
      <td>-0.164929</td>
      <td>0.390671</td>
      <td>0.623069</td>
      <td>-0.200620</td>
      <td>0.198358</td>
      <td>-0.455360</td>
      <td>0.055832</td>
      <td>0.538169</td>
      <td>-0.645988</td>
      <td>0.167550</td>
      <td>0.644644</td>
      <td>-0.148636</td>
      <td>0.757637</td>
      <td>0.184051</td>
      <td>-0.354234</td>
      <td>-0.164378</td>
      <td>0.151884</td>
      <td>0.464226</td>
      <td>0.085195</td>
      <td>-0.247409</td>
      <td>-0.678726</td>
      <td>0.295382</td>
      <td>0.446688</td>
      <td>0.994123</td>
      <td>0.242138</td>
      <td>-0.860182</td>
      <td>-0.139421</td>
      <td>0.049969</td>
      <td>0.753144</td>
      <td>-0.878615</td>
      <td>-0.250621</td>
      <td>-0.743599</td>
      <td>-1.071901</td>
      <td>-0.965092</td>
      <td>0.259282</td>
      <td>...</td>
      <td>-0.023468</td>
      <td>-0.274936</td>
      <td>0.854322</td>
      <td>-0.405919</td>
      <td>0.826616</td>
      <td>0.775531</td>
      <td>0.304207</td>
      <td>-1.358649</td>
      <td>-0.897139</td>
      <td>1.031836</td>
      <td>-0.416137</td>
      <td>-1.159544</td>
      <td>-0.945426</td>
      <td>0.490971</td>
      <td>0.462618</td>
      <td>0.570204</td>
      <td>0.397151</td>
      <td>0.501464</td>
      <td>-0.584190</td>
      <td>-0.821920</td>
      <td>-0.254763</td>
      <td>0.124347</td>
      <td>-0.374938</td>
      <td>-0.932237</td>
      <td>-0.279017</td>
      <td>0.329556</td>
      <td>0.652407</td>
      <td>-0.472927</td>
      <td>0.165815</td>
      <td>-0.515517</td>
      <td>-0.127859</td>
      <td>0.313880</td>
      <td>0.699776</td>
      <td>-0.006102</td>
      <td>-0.419696</td>
      <td>0.206608</td>
      <td>0.906491</td>
      <td>2.698710</td>
      <td>1.730882</td>
      <td>0.695817</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.203317</td>
      <td>0.156410</td>
      <td>0.539791</td>
      <td>-0.022926</td>
      <td>1.207827</td>
      <td>0.460587</td>
      <td>0.072389</td>
      <td>0.128663</td>
      <td>0.490149</td>
      <td>-0.627121</td>
      <td>-0.442345</td>
      <td>-0.473780</td>
      <td>-0.023630</td>
      <td>0.326636</td>
      <td>0.903522</td>
      <td>0.842452</td>
      <td>1.475458</td>
      <td>0.175027</td>
      <td>0.371433</td>
      <td>-0.200406</td>
      <td>-0.621956</td>
      <td>0.075835</td>
      <td>-0.973826</td>
      <td>-0.033834</td>
      <td>0.461831</td>
      <td>0.776379</td>
      <td>0.394443</td>
      <td>0.626908</td>
      <td>0.225384</td>
      <td>-0.123266</td>
      <td>-1.261162</td>
      <td>-0.650639</td>
      <td>-0.194474</td>
      <td>-0.463295</td>
      <td>0.344623</td>
      <td>-0.157692</td>
      <td>-0.364819</td>
      <td>-0.298028</td>
      <td>-0.193851</td>
      <td>1.135889</td>
      <td>...</td>
      <td>-0.308435</td>
      <td>-1.199213</td>
      <td>0.610811</td>
      <td>0.456842</td>
      <td>0.315256</td>
      <td>0.029529</td>
      <td>-0.841507</td>
      <td>0.373652</td>
      <td>-0.016909</td>
      <td>0.445779</td>
      <td>-0.121464</td>
      <td>-0.384633</td>
      <td>-0.014474</td>
      <td>-0.078281</td>
      <td>-0.597051</td>
      <td>-0.472502</td>
      <td>-0.120798</td>
      <td>0.233958</td>
      <td>0.145255</td>
      <td>0.380234</td>
      <td>0.259884</td>
      <td>1.047584</td>
      <td>0.587374</td>
      <td>-0.321069</td>
      <td>0.227832</td>
      <td>0.542298</td>
      <td>0.443935</td>
      <td>-0.235200</td>
      <td>-1.192522</td>
      <td>-1.142711</td>
      <td>-0.104836</td>
      <td>0.181100</td>
      <td>-0.462526</td>
      <td>0.596740</td>
      <td>-0.171265</td>
      <td>-0.415002</td>
      <td>0.012087</td>
      <td>-0.280068</td>
      <td>-0.410990</td>
      <td>-0.282295</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.376745</td>
      <td>0.761436</td>
      <td>-0.241727</td>
      <td>-0.931821</td>
      <td>0.203979</td>
      <td>-0.486225</td>
      <td>0.623924</td>
      <td>0.837780</td>
      <td>-0.371091</td>
      <td>-0.204677</td>
      <td>-0.623988</td>
      <td>0.836971</td>
      <td>-0.251469</td>
      <td>0.272278</td>
      <td>0.659794</td>
      <td>0.432571</td>
      <td>-0.160277</td>
      <td>0.269328</td>
      <td>0.387543</td>
      <td>0.615392</td>
      <td>-0.482805</td>
      <td>-0.649151</td>
      <td>-1.480674</td>
      <td>-0.313525</td>
      <td>-0.285521</td>
      <td>1.006238</td>
      <td>0.148732</td>
      <td>-0.086991</td>
      <td>0.016939</td>
      <td>0.003183</td>
      <td>0.361205</td>
      <td>0.849659</td>
      <td>-0.151423</td>
      <td>-0.185914</td>
      <td>-0.658662</td>
      <td>-0.115056</td>
      <td>0.012064</td>
      <td>-0.501830</td>
      <td>-0.462636</td>
      <td>-0.340291</td>
      <td>...</td>
      <td>-0.452164</td>
      <td>-1.091078</td>
      <td>-0.507677</td>
      <td>0.691266</td>
      <td>-0.015394</td>
      <td>0.900601</td>
      <td>0.228216</td>
      <td>-0.580922</td>
      <td>0.027174</td>
      <td>-0.364468</td>
      <td>0.534688</td>
      <td>-1.091714</td>
      <td>-0.303971</td>
      <td>-0.517646</td>
      <td>0.673792</td>
      <td>-0.285785</td>
      <td>0.650029</td>
      <td>-0.912764</td>
      <td>-1.535337</td>
      <td>-0.617767</td>
      <td>0.584155</td>
      <td>0.030292</td>
      <td>-0.124062</td>
      <td>-0.285962</td>
      <td>-0.710177</td>
      <td>0.202663</td>
      <td>0.123565</td>
      <td>-0.866312</td>
      <td>0.145663</td>
      <td>0.036695</td>
      <td>0.521270</td>
      <td>0.204345</td>
      <td>-0.407775</td>
      <td>0.301639</td>
      <td>-0.585630</td>
      <td>0.307827</td>
      <td>0.329821</td>
      <td>0.994433</td>
      <td>0.455486</td>
      <td>0.641076</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.370641</td>
      <td>0.492093</td>
      <td>0.211898</td>
      <td>0.411949</td>
      <td>0.023534</td>
      <td>-0.306047</td>
      <td>0.526807</td>
      <td>0.089099</td>
      <td>0.589025</td>
      <td>0.306232</td>
      <td>0.287354</td>
      <td>-0.404661</td>
      <td>-0.004356</td>
      <td>-0.710001</td>
      <td>0.284656</td>
      <td>0.946197</td>
      <td>0.377438</td>
      <td>-0.076615</td>
      <td>0.294455</td>
      <td>-0.246653</td>
      <td>-0.551198</td>
      <td>-0.038267</td>
      <td>-0.609640</td>
      <td>0.063398</td>
      <td>-0.184635</td>
      <td>0.695928</td>
      <td>-0.870271</td>
      <td>-0.903662</td>
      <td>0.536145</td>
      <td>-0.450739</td>
      <td>-0.926912</td>
      <td>-0.707738</td>
      <td>0.659951</td>
      <td>-0.059461</td>
      <td>0.761712</td>
      <td>0.303675</td>
      <td>-0.167156</td>
      <td>-0.015887</td>
      <td>-1.408831</td>
      <td>0.193939</td>
      <td>...</td>
      <td>-0.623801</td>
      <td>-0.295500</td>
      <td>0.809322</td>
      <td>0.779497</td>
      <td>0.084783</td>
      <td>-0.973617</td>
      <td>-0.042433</td>
      <td>-0.347799</td>
      <td>0.400900</td>
      <td>-0.173200</td>
      <td>0.041646</td>
      <td>-0.381156</td>
      <td>-0.297519</td>
      <td>0.034792</td>
      <td>-0.546902</td>
      <td>-0.391461</td>
      <td>1.124428</td>
      <td>0.721682</td>
      <td>0.494432</td>
      <td>-0.567661</td>
      <td>-0.568074</td>
      <td>0.519886</td>
      <td>-0.061308</td>
      <td>-1.328770</td>
      <td>-0.167427</td>
      <td>1.092540</td>
      <td>-0.393916</td>
      <td>-0.439785</td>
      <td>-0.383408</td>
      <td>0.245394</td>
      <td>-0.621543</td>
      <td>-0.489810</td>
      <td>-0.211196</td>
      <td>-0.082370</td>
      <td>-0.179724</td>
      <td>-0.116794</td>
      <td>-0.097655</td>
      <td>1.281836</td>
      <td>0.388629</td>
      <td>-0.286430</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.740317</td>
      <td>0.627870</td>
      <td>0.288770</td>
      <td>0.179582</td>
      <td>1.275184</td>
      <td>-0.320793</td>
      <td>0.035467</td>
      <td>1.186943</td>
      <td>0.883554</td>
      <td>0.450339</td>
      <td>-0.423303</td>
      <td>0.427637</td>
      <td>-0.314549</td>
      <td>0.347373</td>
      <td>1.069606</td>
      <td>0.709347</td>
      <td>0.259124</td>
      <td>0.267092</td>
      <td>0.013916</td>
      <td>-0.234229</td>
      <td>0.775511</td>
      <td>-0.852945</td>
      <td>-1.138611</td>
      <td>0.316207</td>
      <td>1.010624</td>
      <td>0.460846</td>
      <td>-0.391709</td>
      <td>0.014088</td>
      <td>0.075066</td>
      <td>-0.130873</td>
      <td>-0.928660</td>
      <td>-0.524408</td>
      <td>0.471230</td>
      <td>0.131566</td>
      <td>-0.524615</td>
      <td>0.164825</td>
      <td>0.197593</td>
      <td>-0.023308</td>
      <td>-0.005695</td>
      <td>1.273970</td>
      <td>...</td>
      <td>-0.577148</td>
      <td>-0.659599</td>
      <td>-0.113831</td>
      <td>0.377951</td>
      <td>-0.199851</td>
      <td>-0.175251</td>
      <td>0.278852</td>
      <td>-1.218302</td>
      <td>0.450413</td>
      <td>0.188864</td>
      <td>1.062364</td>
      <td>-1.016694</td>
      <td>-0.415948</td>
      <td>0.136703</td>
      <td>-0.235616</td>
      <td>-0.079867</td>
      <td>-0.971200</td>
      <td>-0.184170</td>
      <td>0.002917</td>
      <td>-0.802234</td>
      <td>0.562616</td>
      <td>0.259884</td>
      <td>0.237676</td>
      <td>-0.240434</td>
      <td>-1.178679</td>
      <td>0.167475</td>
      <td>0.528022</td>
      <td>0.650564</td>
      <td>0.100788</td>
      <td>0.227724</td>
      <td>-0.150509</td>
      <td>0.566133</td>
      <td>-0.112751</td>
      <td>0.657465</td>
      <td>0.312026</td>
      <td>-1.042951</td>
      <td>-0.070923</td>
      <td>3.537007</td>
      <td>3.369421</td>
      <td>1.961059</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.685829</td>
      <td>0.883892</td>
      <td>1.019751</td>
      <td>1.224406</td>
      <td>-0.107807</td>
      <td>-0.591737</td>
      <td>0.122077</td>
      <td>0.322122</td>
      <td>-0.215067</td>
      <td>-0.366796</td>
      <td>0.481907</td>
      <td>-0.753717</td>
      <td>0.730257</td>
      <td>0.318805</td>
      <td>-0.615220</td>
      <td>-0.631007</td>
      <td>-0.094695</td>
      <td>0.036474</td>
      <td>-0.006936</td>
      <td>-0.485468</td>
      <td>-0.781721</td>
      <td>-1.078698</td>
      <td>-1.290069</td>
      <td>-0.708948</td>
      <td>-0.886215</td>
      <td>-0.925367</td>
      <td>-0.370858</td>
      <td>0.755408</td>
      <td>0.451850</td>
      <td>0.775264</td>
      <td>0.988511</td>
      <td>0.103330</td>
      <td>0.090785</td>
      <td>-0.416347</td>
      <td>-0.268949</td>
      <td>0.471061</td>
      <td>0.384742</td>
      <td>0.621696</td>
      <td>0.708396</td>
      <td>1.105644</td>
      <td>...</td>
      <td>-0.233413</td>
      <td>0.107898</td>
      <td>-0.049416</td>
      <td>0.756721</td>
      <td>-0.480595</td>
      <td>-0.009081</td>
      <td>0.048512</td>
      <td>-0.950875</td>
      <td>-0.976112</td>
      <td>0.059720</td>
      <td>0.250602</td>
      <td>-0.902125</td>
      <td>-0.588408</td>
      <td>0.134687</td>
      <td>0.694328</td>
      <td>1.026071</td>
      <td>0.512142</td>
      <td>-0.163622</td>
      <td>-0.781658</td>
      <td>-0.373458</td>
      <td>0.304216</td>
      <td>-0.001158</td>
      <td>1.341969</td>
      <td>-0.766893</td>
      <td>0.652116</td>
      <td>0.200417</td>
      <td>-0.913723</td>
      <td>-0.593771</td>
      <td>-0.311072</td>
      <td>-0.366268</td>
      <td>-0.879981</td>
      <td>-0.241668</td>
      <td>-0.562111</td>
      <td>-0.701123</td>
      <td>-0.294971</td>
      <td>0.652712</td>
      <td>-0.853729</td>
      <td>1.497357</td>
      <td>0.906401</td>
      <td>1.354304</td>
    </tr>
    <tr>
      <th>17</th>
      <td>1.101590</td>
      <td>0.972102</td>
      <td>0.838025</td>
      <td>-0.158400</td>
      <td>-0.575765</td>
      <td>-0.025731</td>
      <td>-0.323366</td>
      <td>-0.561810</td>
      <td>0.449519</td>
      <td>-0.205165</td>
      <td>0.491295</td>
      <td>0.068649</td>
      <td>-0.169602</td>
      <td>0.231589</td>
      <td>0.654272</td>
      <td>0.780442</td>
      <td>-0.830124</td>
      <td>0.209511</td>
      <td>0.596103</td>
      <td>0.498197</td>
      <td>-0.382851</td>
      <td>-0.444336</td>
      <td>-0.548168</td>
      <td>-0.671272</td>
      <td>-0.269972</td>
      <td>0.192408</td>
      <td>0.193989</td>
      <td>0.270113</td>
      <td>0.674519</td>
      <td>0.196577</td>
      <td>0.192339</td>
      <td>-0.169994</td>
      <td>0.410059</td>
      <td>-0.259320</td>
      <td>0.965596</td>
      <td>0.284413</td>
      <td>-0.093039</td>
      <td>0.405281</td>
      <td>-0.940572</td>
      <td>-0.320010</td>
      <td>...</td>
      <td>0.281691</td>
      <td>0.614116</td>
      <td>0.858610</td>
      <td>0.216767</td>
      <td>-0.981963</td>
      <td>-0.608300</td>
      <td>-0.244643</td>
      <td>-0.361212</td>
      <td>-0.219529</td>
      <td>1.246138</td>
      <td>-0.353928</td>
      <td>0.132066</td>
      <td>-0.129746</td>
      <td>0.428395</td>
      <td>0.621321</td>
      <td>-0.147654</td>
      <td>0.553835</td>
      <td>0.401280</td>
      <td>-0.530976</td>
      <td>-0.677453</td>
      <td>0.834657</td>
      <td>0.251208</td>
      <td>0.574526</td>
      <td>-1.077639</td>
      <td>-0.271696</td>
      <td>0.099927</td>
      <td>-0.873371</td>
      <td>-0.698192</td>
      <td>-0.694087</td>
      <td>-0.587615</td>
      <td>-0.200040</td>
      <td>0.172719</td>
      <td>0.004071</td>
      <td>0.535086</td>
      <td>-0.404501</td>
      <td>-0.403495</td>
      <td>0.938764</td>
      <td>2.099929</td>
      <td>0.736018</td>
      <td>0.061718</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.139316</td>
      <td>0.491471</td>
      <td>0.321661</td>
      <td>-1.261607</td>
      <td>-0.620142</td>
      <td>-1.238962</td>
      <td>0.041013</td>
      <td>0.686977</td>
      <td>0.493365</td>
      <td>0.346486</td>
      <td>0.579637</td>
      <td>1.031867</td>
      <td>1.769036</td>
      <td>0.714437</td>
      <td>0.061427</td>
      <td>-0.347982</td>
      <td>0.715726</td>
      <td>0.039046</td>
      <td>-0.645039</td>
      <td>-1.352784</td>
      <td>-1.515018</td>
      <td>-0.575414</td>
      <td>-1.509418</td>
      <td>-0.725318</td>
      <td>-0.051264</td>
      <td>-0.439033</td>
      <td>0.514671</td>
      <td>-0.853072</td>
      <td>-0.574578</td>
      <td>0.263867</td>
      <td>0.410875</td>
      <td>-0.678546</td>
      <td>0.290086</td>
      <td>0.614936</td>
      <td>0.512593</td>
      <td>0.363616</td>
      <td>0.813929</td>
      <td>-0.603094</td>
      <td>-0.917471</td>
      <td>0.338653</td>
      <td>...</td>
      <td>-0.126644</td>
      <td>0.408328</td>
      <td>0.343388</td>
      <td>0.824262</td>
      <td>0.633314</td>
      <td>0.594567</td>
      <td>-0.058101</td>
      <td>-0.730890</td>
      <td>-0.184846</td>
      <td>-0.545531</td>
      <td>-0.228822</td>
      <td>-0.137987</td>
      <td>-0.468117</td>
      <td>0.130331</td>
      <td>0.486890</td>
      <td>-0.595514</td>
      <td>-1.012498</td>
      <td>-1.375032</td>
      <td>-0.788629</td>
      <td>0.045419</td>
      <td>0.120369</td>
      <td>-0.398222</td>
      <td>-0.454350</td>
      <td>-1.103526</td>
      <td>-0.411765</td>
      <td>-0.676654</td>
      <td>-0.689211</td>
      <td>-0.935949</td>
      <td>0.283154</td>
      <td>-0.525755</td>
      <td>0.095907</td>
      <td>0.245113</td>
      <td>0.260197</td>
      <td>-0.490404</td>
      <td>0.219413</td>
      <td>-0.445855</td>
      <td>-0.340047</td>
      <td>0.651052</td>
      <td>0.546700</td>
      <td>-0.361976</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.164452</td>
      <td>-0.034469</td>
      <td>-0.463650</td>
      <td>0.240728</td>
      <td>-0.051610</td>
      <td>-0.846445</td>
      <td>0.579389</td>
      <td>-1.039036</td>
      <td>-0.042501</td>
      <td>-0.213520</td>
      <td>-0.164887</td>
      <td>0.826840</td>
      <td>0.961028</td>
      <td>1.112809</td>
      <td>0.780166</td>
      <td>0.591947</td>
      <td>-0.896029</td>
      <td>0.159743</td>
      <td>0.671331</td>
      <td>0.187077</td>
      <td>-0.840145</td>
      <td>-0.099498</td>
      <td>-1.284346</td>
      <td>0.049076</td>
      <td>-0.156423</td>
      <td>-0.549827</td>
      <td>-0.773285</td>
      <td>0.141785</td>
      <td>0.296705</td>
      <td>0.440346</td>
      <td>0.472189</td>
      <td>-0.522112</td>
      <td>0.102014</td>
      <td>0.100614</td>
      <td>0.170547</td>
      <td>-0.463279</td>
      <td>-0.158045</td>
      <td>-0.399402</td>
      <td>-0.461455</td>
      <td>0.421082</td>
      <td>...</td>
      <td>-0.201830</td>
      <td>-0.017092</td>
      <td>-1.067954</td>
      <td>0.677369</td>
      <td>-0.446144</td>
      <td>-0.293044</td>
      <td>-0.351852</td>
      <td>0.000057</td>
      <td>0.629013</td>
      <td>-0.514911</td>
      <td>0.282696</td>
      <td>-0.081607</td>
      <td>1.117775</td>
      <td>0.733352</td>
      <td>0.686128</td>
      <td>0.240128</td>
      <td>0.173782</td>
      <td>0.094241</td>
      <td>-0.386088</td>
      <td>-0.269888</td>
      <td>0.125267</td>
      <td>0.307154</td>
      <td>0.039017</td>
      <td>-0.894729</td>
      <td>0.620368</td>
      <td>0.315831</td>
      <td>0.279581</td>
      <td>-0.676708</td>
      <td>-1.092141</td>
      <td>-1.745956</td>
      <td>-0.771104</td>
      <td>-0.616571</td>
      <td>0.385686</td>
      <td>0.041377</td>
      <td>0.711207</td>
      <td>0.657695</td>
      <td>1.004324</td>
      <td>-0.720659</td>
      <td>-0.188455</td>
      <td>0.276226</td>
    </tr>
    <tr>
      <th>20</th>
      <td>2.078953</td>
      <td>0.274499</td>
      <td>-0.940686</td>
      <td>0.364842</td>
      <td>1.122947</td>
      <td>-0.032841</td>
      <td>0.355277</td>
      <td>-0.527040</td>
      <td>-0.466749</td>
      <td>-0.392761</td>
      <td>-0.568003</td>
      <td>0.287697</td>
      <td>1.276963</td>
      <td>1.256256</td>
      <td>1.048349</td>
      <td>-0.542782</td>
      <td>0.052703</td>
      <td>0.005094</td>
      <td>0.295528</td>
      <td>0.285505</td>
      <td>0.697752</td>
      <td>-0.310069</td>
      <td>0.005667</td>
      <td>0.062000</td>
      <td>0.447569</td>
      <td>0.924804</td>
      <td>0.493533</td>
      <td>0.581752</td>
      <td>0.679196</td>
      <td>0.616378</td>
      <td>0.414762</td>
      <td>-0.266101</td>
      <td>0.603411</td>
      <td>-0.775174</td>
      <td>0.242769</td>
      <td>0.323535</td>
      <td>0.499371</td>
      <td>-0.008194</td>
      <td>-1.113725</td>
      <td>-0.011274</td>
      <td>...</td>
      <td>1.166574</td>
      <td>0.632812</td>
      <td>0.042430</td>
      <td>0.393772</td>
      <td>0.035536</td>
      <td>-0.762962</td>
      <td>-0.804920</td>
      <td>-0.261505</td>
      <td>-0.026846</td>
      <td>-0.275839</td>
      <td>-0.583565</td>
      <td>-0.044420</td>
      <td>-0.095057</td>
      <td>-0.696245</td>
      <td>0.224212</td>
      <td>0.789387</td>
      <td>-0.214235</td>
      <td>1.131072</td>
      <td>0.004513</td>
      <td>-0.899373</td>
      <td>0.211795</td>
      <td>0.389585</td>
      <td>0.851870</td>
      <td>-0.033299</td>
      <td>0.533553</td>
      <td>0.799664</td>
      <td>0.802020</td>
      <td>0.326181</td>
      <td>-0.291230</td>
      <td>-0.540743</td>
      <td>0.039950</td>
      <td>-0.208084</td>
      <td>-0.964102</td>
      <td>-0.996173</td>
      <td>-0.185850</td>
      <td>-0.118632</td>
      <td>-0.154930</td>
      <td>2.489275</td>
      <td>1.523962</td>
      <td>0.611070</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.595242</td>
      <td>0.203218</td>
      <td>-0.265478</td>
      <td>-0.276756</td>
      <td>1.231170</td>
      <td>0.274341</td>
      <td>0.554411</td>
      <td>0.319630</td>
      <td>0.740808</td>
      <td>0.242367</td>
      <td>-0.761905</td>
      <td>-0.109128</td>
      <td>0.951116</td>
      <td>1.228189</td>
      <td>-0.329242</td>
      <td>0.358871</td>
      <td>-0.173462</td>
      <td>1.304218</td>
      <td>-0.663684</td>
      <td>-0.030033</td>
      <td>0.158332</td>
      <td>0.064636</td>
      <td>-0.335510</td>
      <td>-0.735949</td>
      <td>-0.011681</td>
      <td>0.486392</td>
      <td>0.482727</td>
      <td>-0.733623</td>
      <td>0.457650</td>
      <td>1.160979</td>
      <td>0.709299</td>
      <td>-0.362037</td>
      <td>0.083087</td>
      <td>-1.152987</td>
      <td>-0.767095</td>
      <td>-0.102631</td>
      <td>0.432407</td>
      <td>-0.425221</td>
      <td>-0.529654</td>
      <td>0.319684</td>
      <td>...</td>
      <td>-0.823064</td>
      <td>-0.459755</td>
      <td>-0.500439</td>
      <td>-0.123047</td>
      <td>0.185141</td>
      <td>0.147260</td>
      <td>-0.832206</td>
      <td>0.076120</td>
      <td>-0.950609</td>
      <td>-0.441489</td>
      <td>-0.471432</td>
      <td>-0.456225</td>
      <td>0.112048</td>
      <td>-0.554824</td>
      <td>0.042251</td>
      <td>-0.462740</td>
      <td>-0.639894</td>
      <td>0.206996</td>
      <td>-0.151791</td>
      <td>-0.697696</td>
      <td>0.056472</td>
      <td>0.975161</td>
      <td>-0.461658</td>
      <td>0.226145</td>
      <td>1.126465</td>
      <td>-1.280327</td>
      <td>0.181818</td>
      <td>-0.661098</td>
      <td>-0.767203</td>
      <td>0.207575</td>
      <td>0.478265</td>
      <td>1.562169</td>
      <td>0.762195</td>
      <td>-0.303789</td>
      <td>-0.537014</td>
      <td>-0.430275</td>
      <td>1.809421</td>
      <td>-0.218026</td>
      <td>0.023248</td>
      <td>0.072865</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.247020</td>
      <td>-0.141800</td>
      <td>0.114265</td>
      <td>-0.735760</td>
      <td>-0.227937</td>
      <td>-0.601322</td>
      <td>-0.165174</td>
      <td>-0.649143</td>
      <td>-0.505427</td>
      <td>0.201682</td>
      <td>-0.339625</td>
      <td>0.504381</td>
      <td>0.519988</td>
      <td>0.135223</td>
      <td>0.072282</td>
      <td>0.300894</td>
      <td>0.168908</td>
      <td>0.777706</td>
      <td>0.410394</td>
      <td>-0.155671</td>
      <td>-0.346204</td>
      <td>0.307665</td>
      <td>-1.114792</td>
      <td>-1.129351</td>
      <td>-0.396553</td>
      <td>0.766646</td>
      <td>1.048227</td>
      <td>0.078324</td>
      <td>0.162670</td>
      <td>-0.315030</td>
      <td>0.181897</td>
      <td>-0.552302</td>
      <td>-0.346699</td>
      <td>-0.392135</td>
      <td>-0.618183</td>
      <td>-0.689279</td>
      <td>-0.333844</td>
      <td>-0.109669</td>
      <td>-0.198482</td>
      <td>0.508061</td>
      <td>...</td>
      <td>-1.113121</td>
      <td>0.309734</td>
      <td>-0.206063</td>
      <td>0.912600</td>
      <td>0.135475</td>
      <td>-0.361071</td>
      <td>0.079993</td>
      <td>-0.042562</td>
      <td>-0.136652</td>
      <td>0.555933</td>
      <td>0.410614</td>
      <td>0.145387</td>
      <td>-0.016873</td>
      <td>-0.109181</td>
      <td>-0.077446</td>
      <td>-0.912938</td>
      <td>0.387714</td>
      <td>-0.327531</td>
      <td>-0.376143</td>
      <td>-0.059813</td>
      <td>0.465315</td>
      <td>-0.267769</td>
      <td>0.234097</td>
      <td>-0.720406</td>
      <td>0.367025</td>
      <td>0.954477</td>
      <td>1.026297</td>
      <td>-0.585328</td>
      <td>0.308498</td>
      <td>-0.479502</td>
      <td>-0.176793</td>
      <td>0.163606</td>
      <td>0.636749</td>
      <td>0.398999</td>
      <td>0.249900</td>
      <td>-0.005515</td>
      <td>0.995643</td>
      <td>0.842207</td>
      <td>0.312018</td>
      <td>0.410237</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.412230</td>
      <td>0.758020</td>
      <td>0.391937</td>
      <td>0.706024</td>
      <td>-0.340698</td>
      <td>-0.725743</td>
      <td>0.347377</td>
      <td>0.033313</td>
      <td>-0.168113</td>
      <td>0.242095</td>
      <td>-0.204867</td>
      <td>0.857109</td>
      <td>-0.340876</td>
      <td>0.191191</td>
      <td>0.543260</td>
      <td>1.082326</td>
      <td>0.016193</td>
      <td>1.049724</td>
      <td>-0.220399</td>
      <td>0.132166</td>
      <td>-0.369214</td>
      <td>0.225983</td>
      <td>0.371660</td>
      <td>0.399648</td>
      <td>-0.267046</td>
      <td>-0.243597</td>
      <td>0.289887</td>
      <td>1.455718</td>
      <td>1.233316</td>
      <td>0.621218</td>
      <td>-0.713117</td>
      <td>0.134757</td>
      <td>1.205869</td>
      <td>0.511381</td>
      <td>-0.237734</td>
      <td>-0.353790</td>
      <td>0.372765</td>
      <td>-0.316393</td>
      <td>-1.326561</td>
      <td>0.484882</td>
      <td>...</td>
      <td>-0.743300</td>
      <td>-0.364848</td>
      <td>0.845478</td>
      <td>1.004579</td>
      <td>-0.236813</td>
      <td>0.765803</td>
      <td>-1.038898</td>
      <td>-0.962703</td>
      <td>-0.509070</td>
      <td>0.132418</td>
      <td>-0.874078</td>
      <td>-0.922605</td>
      <td>0.250731</td>
      <td>0.525479</td>
      <td>0.598197</td>
      <td>0.172579</td>
      <td>0.598695</td>
      <td>-0.546337</td>
      <td>0.303311</td>
      <td>0.422401</td>
      <td>0.132676</td>
      <td>0.002090</td>
      <td>0.043684</td>
      <td>-1.153961</td>
      <td>0.153512</td>
      <td>0.545345</td>
      <td>0.746002</td>
      <td>0.483422</td>
      <td>-0.758096</td>
      <td>-0.869303</td>
      <td>-0.148822</td>
      <td>-0.860821</td>
      <td>-0.144556</td>
      <td>-0.769067</td>
      <td>0.647975</td>
      <td>0.797237</td>
      <td>-0.820943</td>
      <td>2.373640</td>
      <td>1.950311</td>
      <td>0.373523</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.220575</td>
      <td>-0.056596</td>
      <td>-0.379313</td>
      <td>0.174280</td>
      <td>-0.511527</td>
      <td>-1.193856</td>
      <td>0.290441</td>
      <td>0.282622</td>
      <td>-0.094596</td>
      <td>-0.103477</td>
      <td>-0.456052</td>
      <td>-0.424133</td>
      <td>0.495172</td>
      <td>1.638696</td>
      <td>0.768053</td>
      <td>0.420345</td>
      <td>-0.036783</td>
      <td>0.351473</td>
      <td>0.234936</td>
      <td>-0.308114</td>
      <td>-0.220376</td>
      <td>0.158590</td>
      <td>-1.523372</td>
      <td>0.090410</td>
      <td>-0.467848</td>
      <td>-0.369994</td>
      <td>0.206630</td>
      <td>0.856811</td>
      <td>0.810038</td>
      <td>0.374037</td>
      <td>-0.159120</td>
      <td>-0.245654</td>
      <td>0.056543</td>
      <td>-0.081342</td>
      <td>0.254787</td>
      <td>-0.267736</td>
      <td>-0.665519</td>
      <td>0.283895</td>
      <td>-0.861268</td>
      <td>1.110624</td>
      <td>...</td>
      <td>-0.848946</td>
      <td>0.500868</td>
      <td>-0.209128</td>
      <td>0.054185</td>
      <td>-1.073067</td>
      <td>-0.051529</td>
      <td>-0.538586</td>
      <td>-0.043281</td>
      <td>-0.560835</td>
      <td>0.720521</td>
      <td>-0.603786</td>
      <td>-0.141552</td>
      <td>-0.026340</td>
      <td>0.192811</td>
      <td>-0.484165</td>
      <td>-0.960224</td>
      <td>0.664370</td>
      <td>0.354107</td>
      <td>-1.007316</td>
      <td>-1.558164</td>
      <td>-0.131351</td>
      <td>0.043329</td>
      <td>-0.049510</td>
      <td>0.139868</td>
      <td>1.217234</td>
      <td>-0.175963</td>
      <td>-0.686808</td>
      <td>-0.138786</td>
      <td>-0.155322</td>
      <td>-0.546741</td>
      <td>-0.652061</td>
      <td>0.023911</td>
      <td>-0.173823</td>
      <td>-0.472354</td>
      <td>-0.340331</td>
      <td>-0.517003</td>
      <td>0.762995</td>
      <td>-1.436814</td>
      <td>-1.299588</td>
      <td>-1.591690</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>0.176079</td>
      <td>-0.301945</td>
      <td>-1.082691</td>
      <td>0.855098</td>
      <td>0.607570</td>
      <td>-0.482250</td>
      <td>-1.136077</td>
      <td>-1.036194</td>
      <td>-0.943562</td>
      <td>0.936789</td>
      <td>0.509962</td>
      <td>-0.581115</td>
      <td>-0.689328</td>
      <td>-0.585301</td>
      <td>-0.499105</td>
      <td>0.129473</td>
      <td>-0.198739</td>
      <td>0.129179</td>
      <td>-0.746042</td>
      <td>0.589711</td>
      <td>0.377087</td>
      <td>-0.461315</td>
      <td>0.471778</td>
      <td>1.430551</td>
      <td>0.218465</td>
      <td>0.961952</td>
      <td>0.574380</td>
      <td>0.986516</td>
      <td>0.800064</td>
      <td>0.638387</td>
      <td>0.090431</td>
      <td>0.479492</td>
      <td>0.650915</td>
      <td>-1.165410</td>
      <td>0.700364</td>
      <td>0.691440</td>
      <td>0.635801</td>
      <td>0.669553</td>
      <td>-0.287813</td>
      <td>0.071832</td>
      <td>...</td>
      <td>0.328843</td>
      <td>0.671463</td>
      <td>-0.685602</td>
      <td>0.360189</td>
      <td>0.661100</td>
      <td>-0.086741</td>
      <td>-0.469879</td>
      <td>-0.802346</td>
      <td>-0.865165</td>
      <td>0.698683</td>
      <td>0.718793</td>
      <td>-0.636576</td>
      <td>-0.306695</td>
      <td>-0.536658</td>
      <td>0.384215</td>
      <td>-0.115854</td>
      <td>-0.886226</td>
      <td>0.280923</td>
      <td>-0.424865</td>
      <td>-0.255835</td>
      <td>-0.193254</td>
      <td>-0.663108</td>
      <td>-0.014172</td>
      <td>0.284343</td>
      <td>-0.463384</td>
      <td>-0.507775</td>
      <td>0.414565</td>
      <td>0.676409</td>
      <td>0.134514</td>
      <td>-0.352952</td>
      <td>0.379504</td>
      <td>-0.149305</td>
      <td>0.771495</td>
      <td>0.966525</td>
      <td>-0.423840</td>
      <td>-0.768273</td>
      <td>-0.437296</td>
      <td>-1.223392</td>
      <td>-0.997666</td>
      <td>-0.374008</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.240738</td>
      <td>-0.477887</td>
      <td>-0.144847</td>
      <td>-1.323485</td>
      <td>-0.625450</td>
      <td>-0.872180</td>
      <td>-0.247932</td>
      <td>0.109463</td>
      <td>-0.382211</td>
      <td>0.301143</td>
      <td>0.139259</td>
      <td>-0.052368</td>
      <td>0.000170</td>
      <td>0.988449</td>
      <td>-0.709444</td>
      <td>-0.279827</td>
      <td>0.488444</td>
      <td>0.014786</td>
      <td>-0.086713</td>
      <td>-0.289298</td>
      <td>0.201581</td>
      <td>-0.153735</td>
      <td>0.408618</td>
      <td>-0.059753</td>
      <td>-0.422377</td>
      <td>-0.165644</td>
      <td>-0.194914</td>
      <td>1.075993</td>
      <td>-0.039850</td>
      <td>0.679632</td>
      <td>1.109406</td>
      <td>0.678672</td>
      <td>0.466547</td>
      <td>0.167150</td>
      <td>0.442880</td>
      <td>0.163625</td>
      <td>0.847556</td>
      <td>-0.352269</td>
      <td>-0.276333</td>
      <td>-0.538361</td>
      <td>...</td>
      <td>-0.276875</td>
      <td>-0.188005</td>
      <td>0.569767</td>
      <td>0.393664</td>
      <td>0.898666</td>
      <td>-0.430844</td>
      <td>-1.065401</td>
      <td>0.195531</td>
      <td>0.744640</td>
      <td>0.877844</td>
      <td>1.031499</td>
      <td>0.030129</td>
      <td>0.685626</td>
      <td>0.998537</td>
      <td>1.089308</td>
      <td>0.498117</td>
      <td>-0.511748</td>
      <td>0.119877</td>
      <td>-1.060957</td>
      <td>0.013983</td>
      <td>-0.927161</td>
      <td>0.304622</td>
      <td>0.633200</td>
      <td>0.924001</td>
      <td>-0.497176</td>
      <td>-0.949826</td>
      <td>0.106529</td>
      <td>2.141223</td>
      <td>-0.508550</td>
      <td>-0.871260</td>
      <td>-0.368777</td>
      <td>-0.558332</td>
      <td>0.140842</td>
      <td>-0.037426</td>
      <td>0.481865</td>
      <td>0.821648</td>
      <td>-0.280492</td>
      <td>-2.861113</td>
      <td>-1.945979</td>
      <td>-0.693115</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.538216</td>
      <td>0.052985</td>
      <td>0.488010</td>
      <td>-0.749933</td>
      <td>-0.788256</td>
      <td>-0.843621</td>
      <td>-0.050868</td>
      <td>0.241461</td>
      <td>-0.513256</td>
      <td>0.407947</td>
      <td>0.279561</td>
      <td>-0.060810</td>
      <td>1.433871</td>
      <td>0.780485</td>
      <td>-0.034209</td>
      <td>1.066802</td>
      <td>0.539061</td>
      <td>0.636446</td>
      <td>0.037522</td>
      <td>-0.576210</td>
      <td>0.201908</td>
      <td>0.299291</td>
      <td>0.606830</td>
      <td>0.617969</td>
      <td>-0.244372</td>
      <td>-0.478087</td>
      <td>0.405796</td>
      <td>0.030594</td>
      <td>0.976146</td>
      <td>-0.128445</td>
      <td>-0.478020</td>
      <td>0.022953</td>
      <td>-1.034888</td>
      <td>-1.211891</td>
      <td>0.168774</td>
      <td>0.799762</td>
      <td>-0.385259</td>
      <td>-0.570017</td>
      <td>-1.174498</td>
      <td>-0.019592</td>
      <td>...</td>
      <td>-1.008345</td>
      <td>0.428644</td>
      <td>0.085302</td>
      <td>-1.390799</td>
      <td>-0.851152</td>
      <td>-0.158589</td>
      <td>-0.742064</td>
      <td>-0.052121</td>
      <td>0.686808</td>
      <td>0.523403</td>
      <td>1.131120</td>
      <td>-0.356930</td>
      <td>-0.388253</td>
      <td>0.205379</td>
      <td>0.400409</td>
      <td>-0.323782</td>
      <td>0.592145</td>
      <td>-0.323064</td>
      <td>-0.705795</td>
      <td>-0.505256</td>
      <td>-0.913876</td>
      <td>-0.001713</td>
      <td>-0.548719</td>
      <td>0.426261</td>
      <td>0.518962</td>
      <td>-0.402078</td>
      <td>-0.313337</td>
      <td>0.759727</td>
      <td>0.089065</td>
      <td>-0.144051</td>
      <td>-0.783596</td>
      <td>0.110089</td>
      <td>0.032667</td>
      <td>1.339016</td>
      <td>0.098054</td>
      <td>-0.509040</td>
      <td>0.528923</td>
      <td>-0.553321</td>
      <td>-0.722403</td>
      <td>-0.461466</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.273352</td>
      <td>0.110609</td>
      <td>0.449332</td>
      <td>-0.717502</td>
      <td>-0.572220</td>
      <td>0.075575</td>
      <td>0.266467</td>
      <td>0.083965</td>
      <td>-0.248890</td>
      <td>0.111344</td>
      <td>-0.203025</td>
      <td>0.547502</td>
      <td>0.673887</td>
      <td>0.438979</td>
      <td>0.556078</td>
      <td>1.510018</td>
      <td>0.844836</td>
      <td>-0.212411</td>
      <td>0.373738</td>
      <td>-0.633452</td>
      <td>-0.797749</td>
      <td>-0.468364</td>
      <td>-0.132149</td>
      <td>-0.021198</td>
      <td>0.696041</td>
      <td>0.356043</td>
      <td>1.012070</td>
      <td>-0.115256</td>
      <td>0.631271</td>
      <td>-0.307355</td>
      <td>0.928540</td>
      <td>0.281298</td>
      <td>0.198645</td>
      <td>-1.228730</td>
      <td>0.048049</td>
      <td>0.247321</td>
      <td>0.355287</td>
      <td>0.394299</td>
      <td>-0.061105</td>
      <td>-1.064873</td>
      <td>...</td>
      <td>0.442029</td>
      <td>-0.516834</td>
      <td>-0.867879</td>
      <td>-0.984371</td>
      <td>0.686418</td>
      <td>-0.615517</td>
      <td>-0.428097</td>
      <td>-0.679480</td>
      <td>-0.186230</td>
      <td>-0.611575</td>
      <td>0.014589</td>
      <td>0.171698</td>
      <td>-0.763615</td>
      <td>0.047249</td>
      <td>0.860470</td>
      <td>0.042944</td>
      <td>-0.403573</td>
      <td>0.773910</td>
      <td>0.261128</td>
      <td>-0.166877</td>
      <td>-0.907730</td>
      <td>0.587333</td>
      <td>-0.719931</td>
      <td>-0.175278</td>
      <td>0.735891</td>
      <td>-0.793067</td>
      <td>0.650067</td>
      <td>0.777640</td>
      <td>0.359011</td>
      <td>-0.054388</td>
      <td>0.348439</td>
      <td>-0.253016</td>
      <td>0.024334</td>
      <td>0.236823</td>
      <td>-0.508959</td>
      <td>-0.605393</td>
      <td>0.356258</td>
      <td>0.483558</td>
      <td>0.321778</td>
      <td>0.388518</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.514170</td>
      <td>-0.296896</td>
      <td>-0.208132</td>
      <td>-1.009025</td>
      <td>0.091211</td>
      <td>0.004323</td>
      <td>0.800468</td>
      <td>0.458601</td>
      <td>0.320064</td>
      <td>-1.750817</td>
      <td>-1.130003</td>
      <td>-0.143706</td>
      <td>0.349648</td>
      <td>1.026927</td>
      <td>0.549743</td>
      <td>1.255290</td>
      <td>0.387492</td>
      <td>0.383818</td>
      <td>0.588590</td>
      <td>-0.479458</td>
      <td>0.298794</td>
      <td>0.219123</td>
      <td>0.140319</td>
      <td>0.950969</td>
      <td>0.228395</td>
      <td>-0.112333</td>
      <td>0.436979</td>
      <td>1.299349</td>
      <td>1.124616</td>
      <td>-0.401274</td>
      <td>0.123515</td>
      <td>0.768425</td>
      <td>0.567811</td>
      <td>-0.254917</td>
      <td>0.090189</td>
      <td>0.230041</td>
      <td>0.992888</td>
      <td>0.301013</td>
      <td>0.039296</td>
      <td>1.008777</td>
      <td>...</td>
      <td>0.504810</td>
      <td>1.452313</td>
      <td>0.432527</td>
      <td>-0.185669</td>
      <td>-1.033639</td>
      <td>1.040008</td>
      <td>0.614116</td>
      <td>-0.233239</td>
      <td>1.103453</td>
      <td>0.625947</td>
      <td>0.063914</td>
      <td>-0.469628</td>
      <td>-0.056520</td>
      <td>-0.472997</td>
      <td>0.556227</td>
      <td>-0.602328</td>
      <td>-1.068239</td>
      <td>0.010905</td>
      <td>-0.660903</td>
      <td>-0.138462</td>
      <td>-0.166316</td>
      <td>0.153427</td>
      <td>-1.231571</td>
      <td>-0.436565</td>
      <td>-0.683180</td>
      <td>-0.773965</td>
      <td>0.303515</td>
      <td>0.144060</td>
      <td>-0.093753</td>
      <td>0.948927</td>
      <td>0.638711</td>
      <td>0.400841</td>
      <td>0.649220</td>
      <td>1.689155</td>
      <td>0.889288</td>
      <td>0.282008</td>
      <td>0.178984</td>
      <td>0.559950</td>
      <td>1.127088</td>
      <td>1.305901</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f4c9d888040&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err         t          P&gt;|t|     2.5 %    97.5 %
D  0.966117  0.042033  22.98487  6.604966e-117  0.883734  1.048499
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  6.222 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>