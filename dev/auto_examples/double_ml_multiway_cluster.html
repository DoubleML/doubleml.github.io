
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.105056</td>
      <td>-0.445520</td>
      <td>0.538034</td>
      <td>0.090494</td>
      <td>0.608598</td>
      <td>0.078771</td>
      <td>-0.538229</td>
      <td>0.447597</td>
      <td>-0.770410</td>
      <td>0.386220</td>
      <td>0.401007</td>
      <td>0.669449</td>
      <td>0.276041</td>
      <td>-0.300525</td>
      <td>-0.261661</td>
      <td>-0.968980</td>
      <td>0.875911</td>
      <td>0.116388</td>
      <td>0.098723</td>
      <td>-0.827553</td>
      <td>0.578945</td>
      <td>-0.096093</td>
      <td>-0.218190</td>
      <td>-1.660352</td>
      <td>-0.155344</td>
      <td>-0.709161</td>
      <td>0.232620</td>
      <td>-0.318669</td>
      <td>-0.160119</td>
      <td>0.022523</td>
      <td>0.385608</td>
      <td>0.883455</td>
      <td>0.230665</td>
      <td>0.163110</td>
      <td>0.006865</td>
      <td>0.820673</td>
      <td>1.033082</td>
      <td>-0.938315</td>
      <td>-1.276625</td>
      <td>0.222164</td>
      <td>...</td>
      <td>-0.849906</td>
      <td>0.646495</td>
      <td>0.823423</td>
      <td>-0.799097</td>
      <td>0.492484</td>
      <td>0.166247</td>
      <td>0.782211</td>
      <td>-0.207707</td>
      <td>0.032029</td>
      <td>0.345976</td>
      <td>-0.929928</td>
      <td>-1.553404</td>
      <td>-0.766614</td>
      <td>-1.231477</td>
      <td>-0.168621</td>
      <td>-0.394410</td>
      <td>-0.290541</td>
      <td>0.375766</td>
      <td>0.842232</td>
      <td>-0.323280</td>
      <td>0.129892</td>
      <td>1.350441</td>
      <td>1.155340</td>
      <td>0.588131</td>
      <td>0.377836</td>
      <td>0.204619</td>
      <td>-0.381960</td>
      <td>-1.009811</td>
      <td>-1.009697</td>
      <td>-0.592836</td>
      <td>0.253947</td>
      <td>-0.201411</td>
      <td>0.290367</td>
      <td>-0.252814</td>
      <td>0.014693</td>
      <td>-0.140874</td>
      <td>0.165829</td>
      <td>-0.091872</td>
      <td>0.699891</td>
      <td>1.052164</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.124559</td>
      <td>1.059958</td>
      <td>0.631347</td>
      <td>-0.177466</td>
      <td>0.026607</td>
      <td>-0.078378</td>
      <td>-0.325612</td>
      <td>0.664176</td>
      <td>-0.462837</td>
      <td>0.812025</td>
      <td>0.769568</td>
      <td>0.789363</td>
      <td>-0.200441</td>
      <td>-1.094713</td>
      <td>0.017212</td>
      <td>-0.189486</td>
      <td>-0.018938</td>
      <td>0.397002</td>
      <td>-0.782536</td>
      <td>-0.618934</td>
      <td>-0.308827</td>
      <td>-0.296809</td>
      <td>0.303521</td>
      <td>0.135748</td>
      <td>-0.363540</td>
      <td>-0.372015</td>
      <td>-0.172570</td>
      <td>-0.244996</td>
      <td>0.494549</td>
      <td>-0.451986</td>
      <td>0.278664</td>
      <td>0.499125</td>
      <td>-0.032996</td>
      <td>0.460127</td>
      <td>0.022534</td>
      <td>0.320672</td>
      <td>0.803021</td>
      <td>0.473687</td>
      <td>0.517715</td>
      <td>0.895597</td>
      <td>...</td>
      <td>0.189988</td>
      <td>0.133197</td>
      <td>-0.908982</td>
      <td>-1.328930</td>
      <td>-0.074740</td>
      <td>0.305382</td>
      <td>1.148840</td>
      <td>-0.380940</td>
      <td>0.364426</td>
      <td>-0.091190</td>
      <td>-0.206949</td>
      <td>0.094787</td>
      <td>0.131606</td>
      <td>-0.588117</td>
      <td>0.086193</td>
      <td>-0.986040</td>
      <td>-0.797820</td>
      <td>0.533201</td>
      <td>1.094069</td>
      <td>0.579707</td>
      <td>0.357779</td>
      <td>0.336256</td>
      <td>0.334986</td>
      <td>-0.544347</td>
      <td>0.176301</td>
      <td>0.100105</td>
      <td>-0.806063</td>
      <td>0.436651</td>
      <td>0.011535</td>
      <td>-0.373099</td>
      <td>-0.123161</td>
      <td>-0.088742</td>
      <td>-0.265597</td>
      <td>0.612861</td>
      <td>0.205685</td>
      <td>0.438356</td>
      <td>-0.110734</td>
      <td>1.191652</td>
      <td>0.769865</td>
      <td>-0.106116</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.707452</td>
      <td>0.655203</td>
      <td>0.359380</td>
      <td>-0.488305</td>
      <td>0.122873</td>
      <td>-0.582137</td>
      <td>-1.674305</td>
      <td>-1.055678</td>
      <td>0.078845</td>
      <td>-0.726178</td>
      <td>0.449646</td>
      <td>-0.763085</td>
      <td>0.017995</td>
      <td>-0.413206</td>
      <td>-0.896468</td>
      <td>-0.460796</td>
      <td>0.147113</td>
      <td>0.188273</td>
      <td>1.565303</td>
      <td>0.288457</td>
      <td>0.880728</td>
      <td>1.124998</td>
      <td>-1.157937</td>
      <td>-0.979808</td>
      <td>-0.336529</td>
      <td>0.114260</td>
      <td>0.229759</td>
      <td>-0.326860</td>
      <td>-0.969989</td>
      <td>0.306982</td>
      <td>1.135442</td>
      <td>0.802779</td>
      <td>0.510550</td>
      <td>0.193170</td>
      <td>0.540470</td>
      <td>-0.478384</td>
      <td>-0.548646</td>
      <td>-0.449810</td>
      <td>-0.279290</td>
      <td>-0.317924</td>
      <td>...</td>
      <td>0.114287</td>
      <td>-0.255105</td>
      <td>-0.262029</td>
      <td>0.130158</td>
      <td>0.619359</td>
      <td>0.651898</td>
      <td>0.364001</td>
      <td>-0.866575</td>
      <td>-0.966011</td>
      <td>0.129300</td>
      <td>0.352906</td>
      <td>-0.050264</td>
      <td>-0.830272</td>
      <td>-0.546636</td>
      <td>0.055488</td>
      <td>0.248945</td>
      <td>0.056421</td>
      <td>-0.242331</td>
      <td>0.363910</td>
      <td>0.459571</td>
      <td>1.229096</td>
      <td>0.609558</td>
      <td>0.254065</td>
      <td>-0.164947</td>
      <td>-0.105458</td>
      <td>-0.212273</td>
      <td>-0.251880</td>
      <td>0.368168</td>
      <td>-0.592422</td>
      <td>-0.513408</td>
      <td>0.254702</td>
      <td>-0.278228</td>
      <td>-0.004858</td>
      <td>0.321154</td>
      <td>0.405145</td>
      <td>0.038809</td>
      <td>-0.192597</td>
      <td>-0.089425</td>
      <td>-0.221424</td>
      <td>-0.160954</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.260128</td>
      <td>0.840416</td>
      <td>0.589695</td>
      <td>0.424553</td>
      <td>0.332591</td>
      <td>-0.758219</td>
      <td>-1.438923</td>
      <td>0.242815</td>
      <td>0.640179</td>
      <td>0.417860</td>
      <td>-0.227822</td>
      <td>0.752589</td>
      <td>1.246744</td>
      <td>0.811710</td>
      <td>1.321901</td>
      <td>0.010354</td>
      <td>-0.402527</td>
      <td>-0.418738</td>
      <td>-0.711270</td>
      <td>0.233068</td>
      <td>0.126113</td>
      <td>-0.626382</td>
      <td>0.111741</td>
      <td>-0.376605</td>
      <td>-1.341004</td>
      <td>-0.861172</td>
      <td>-0.195086</td>
      <td>-0.322117</td>
      <td>-0.539819</td>
      <td>0.541224</td>
      <td>1.030996</td>
      <td>1.702600</td>
      <td>0.269974</td>
      <td>1.097804</td>
      <td>-0.119806</td>
      <td>0.176193</td>
      <td>0.543467</td>
      <td>-1.771030</td>
      <td>0.142099</td>
      <td>-0.338899</td>
      <td>...</td>
      <td>-0.510072</td>
      <td>-0.754738</td>
      <td>-0.673929</td>
      <td>0.778795</td>
      <td>1.128878</td>
      <td>0.192368</td>
      <td>0.662694</td>
      <td>-0.383415</td>
      <td>0.429886</td>
      <td>-0.507370</td>
      <td>-0.407620</td>
      <td>-0.211209</td>
      <td>0.027305</td>
      <td>-0.739280</td>
      <td>-0.323522</td>
      <td>-0.604822</td>
      <td>0.134663</td>
      <td>-0.624245</td>
      <td>0.411613</td>
      <td>0.936767</td>
      <td>0.450971</td>
      <td>0.032816</td>
      <td>0.136614</td>
      <td>0.982985</td>
      <td>-0.913493</td>
      <td>0.525870</td>
      <td>-0.019278</td>
      <td>-0.393593</td>
      <td>-0.672679</td>
      <td>0.485920</td>
      <td>0.104500</td>
      <td>-0.009567</td>
      <td>-0.801881</td>
      <td>-0.238803</td>
      <td>0.229303</td>
      <td>-0.082381</td>
      <td>-1.226553</td>
      <td>1.216369</td>
      <td>0.785900</td>
      <td>1.147586</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.636292</td>
      <td>1.059089</td>
      <td>0.254436</td>
      <td>-0.603378</td>
      <td>-0.318096</td>
      <td>0.596068</td>
      <td>0.143025</td>
      <td>0.635512</td>
      <td>-0.408396</td>
      <td>0.469225</td>
      <td>1.166912</td>
      <td>0.055033</td>
      <td>-0.971990</td>
      <td>0.142966</td>
      <td>-0.901842</td>
      <td>-1.467656</td>
      <td>-0.786144</td>
      <td>-0.391263</td>
      <td>-0.720416</td>
      <td>-0.867285</td>
      <td>-0.795049</td>
      <td>0.224946</td>
      <td>0.530485</td>
      <td>-1.387314</td>
      <td>-0.673892</td>
      <td>-0.084654</td>
      <td>0.964776</td>
      <td>-0.437511</td>
      <td>0.295522</td>
      <td>-0.629016</td>
      <td>0.747235</td>
      <td>0.049885</td>
      <td>0.161318</td>
      <td>-0.764345</td>
      <td>-1.318252</td>
      <td>0.047154</td>
      <td>-0.139465</td>
      <td>0.023433</td>
      <td>0.195613</td>
      <td>-0.004885</td>
      <td>...</td>
      <td>-0.177244</td>
      <td>-1.167354</td>
      <td>-0.582738</td>
      <td>0.214538</td>
      <td>0.142506</td>
      <td>-0.205541</td>
      <td>0.984651</td>
      <td>0.317222</td>
      <td>-0.006316</td>
      <td>0.791672</td>
      <td>0.437365</td>
      <td>-0.319733</td>
      <td>0.466168</td>
      <td>-0.803064</td>
      <td>0.529578</td>
      <td>-0.197550</td>
      <td>-0.436675</td>
      <td>-0.218182</td>
      <td>0.069770</td>
      <td>-0.276522</td>
      <td>0.453976</td>
      <td>-0.339227</td>
      <td>-0.298669</td>
      <td>0.229876</td>
      <td>0.125958</td>
      <td>-0.241939</td>
      <td>-0.217186</td>
      <td>-0.277989</td>
      <td>-0.237865</td>
      <td>0.057471</td>
      <td>0.219204</td>
      <td>-0.020198</td>
      <td>0.238098</td>
      <td>-0.371660</td>
      <td>-0.540149</td>
      <td>-0.434932</td>
      <td>0.725390</td>
      <td>3.317811</td>
      <td>2.446981</td>
      <td>0.958719</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.005798</td>
      <td>0.169317</td>
      <td>0.626746</td>
      <td>-0.754645</td>
      <td>0.436752</td>
      <td>0.150193</td>
      <td>-0.519690</td>
      <td>1.241258</td>
      <td>0.600764</td>
      <td>0.083215</td>
      <td>1.198886</td>
      <td>0.887874</td>
      <td>0.390044</td>
      <td>0.294154</td>
      <td>-0.290263</td>
      <td>0.093725</td>
      <td>-0.080397</td>
      <td>-0.438293</td>
      <td>0.461004</td>
      <td>-1.382867</td>
      <td>-0.380799</td>
      <td>0.274602</td>
      <td>0.968434</td>
      <td>-0.316627</td>
      <td>0.413071</td>
      <td>-0.951511</td>
      <td>-0.537860</td>
      <td>-0.541799</td>
      <td>-0.176226</td>
      <td>-0.673904</td>
      <td>0.238024</td>
      <td>0.204003</td>
      <td>0.079026</td>
      <td>-0.474623</td>
      <td>-0.209356</td>
      <td>0.858885</td>
      <td>-0.458362</td>
      <td>0.405206</td>
      <td>0.271088</td>
      <td>-0.455523</td>
      <td>...</td>
      <td>-0.184345</td>
      <td>-1.764685</td>
      <td>-0.307241</td>
      <td>0.752656</td>
      <td>0.451930</td>
      <td>0.691826</td>
      <td>0.391059</td>
      <td>-0.487564</td>
      <td>0.642552</td>
      <td>0.002497</td>
      <td>0.946613</td>
      <td>0.434685</td>
      <td>0.096696</td>
      <td>-0.935407</td>
      <td>0.015127</td>
      <td>-0.650961</td>
      <td>0.328246</td>
      <td>-0.420038</td>
      <td>0.321598</td>
      <td>0.291916</td>
      <td>-0.514386</td>
      <td>0.855192</td>
      <td>0.079544</td>
      <td>0.414548</td>
      <td>-0.640364</td>
      <td>-0.666393</td>
      <td>0.004464</td>
      <td>0.162570</td>
      <td>-0.165510</td>
      <td>-0.822410</td>
      <td>-0.476426</td>
      <td>-1.027188</td>
      <td>-0.723006</td>
      <td>-0.256210</td>
      <td>0.064259</td>
      <td>-0.127797</td>
      <td>0.522400</td>
      <td>0.852921</td>
      <td>0.959899</td>
      <td>0.452524</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.247760</td>
      <td>1.596672</td>
      <td>0.063248</td>
      <td>-0.108230</td>
      <td>-0.184625</td>
      <td>-0.853296</td>
      <td>-1.002964</td>
      <td>0.521937</td>
      <td>-0.182385</td>
      <td>0.600257</td>
      <td>0.837719</td>
      <td>-0.091425</td>
      <td>-0.095797</td>
      <td>0.117309</td>
      <td>0.595848</td>
      <td>-0.970279</td>
      <td>-0.245763</td>
      <td>1.000008</td>
      <td>-0.069553</td>
      <td>-1.359162</td>
      <td>0.969520</td>
      <td>-0.039662</td>
      <td>0.266002</td>
      <td>-0.973782</td>
      <td>-0.511684</td>
      <td>0.601096</td>
      <td>0.805290</td>
      <td>-0.081002</td>
      <td>-0.158300</td>
      <td>-0.746688</td>
      <td>0.497730</td>
      <td>-0.129584</td>
      <td>-0.309236</td>
      <td>-0.869770</td>
      <td>-0.321518</td>
      <td>0.054860</td>
      <td>-1.068784</td>
      <td>-0.996763</td>
      <td>0.457801</td>
      <td>0.488072</td>
      <td>...</td>
      <td>0.245623</td>
      <td>0.199471</td>
      <td>-0.268262</td>
      <td>-0.480106</td>
      <td>-0.114699</td>
      <td>-0.291991</td>
      <td>-0.595001</td>
      <td>-0.631089</td>
      <td>-0.720689</td>
      <td>-0.736820</td>
      <td>0.205274</td>
      <td>-0.284821</td>
      <td>-1.327640</td>
      <td>-2.064100</td>
      <td>-1.624431</td>
      <td>0.031760</td>
      <td>0.537826</td>
      <td>1.846673</td>
      <td>0.034403</td>
      <td>-0.507314</td>
      <td>-0.955790</td>
      <td>-0.329348</td>
      <td>0.306638</td>
      <td>0.234240</td>
      <td>-0.721801</td>
      <td>0.261587</td>
      <td>-0.716999</td>
      <td>-0.818863</td>
      <td>0.857578</td>
      <td>0.660357</td>
      <td>0.274809</td>
      <td>-0.124430</td>
      <td>-0.606711</td>
      <td>0.057493</td>
      <td>0.479922</td>
      <td>-0.736693</td>
      <td>0.022382</td>
      <td>0.110455</td>
      <td>0.995226</td>
      <td>0.751061</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.104008</td>
      <td>1.102678</td>
      <td>-0.117968</td>
      <td>-1.612256</td>
      <td>0.247072</td>
      <td>-0.105205</td>
      <td>-0.489030</td>
      <td>1.110301</td>
      <td>0.168601</td>
      <td>-0.283732</td>
      <td>0.117414</td>
      <td>-0.383866</td>
      <td>-0.296469</td>
      <td>-0.641705</td>
      <td>0.004889</td>
      <td>-0.890411</td>
      <td>-1.381681</td>
      <td>0.534696</td>
      <td>0.235827</td>
      <td>-1.002263</td>
      <td>0.003015</td>
      <td>-0.809215</td>
      <td>0.690781</td>
      <td>-0.056437</td>
      <td>0.198173</td>
      <td>-0.564772</td>
      <td>0.163387</td>
      <td>0.338508</td>
      <td>0.059784</td>
      <td>0.102245</td>
      <td>-0.731655</td>
      <td>-0.441496</td>
      <td>-0.389635</td>
      <td>0.428219</td>
      <td>0.216306</td>
      <td>0.816770</td>
      <td>-0.348964</td>
      <td>-0.929121</td>
      <td>0.694055</td>
      <td>1.354822</td>
      <td>...</td>
      <td>-0.629141</td>
      <td>-0.696378</td>
      <td>-0.113659</td>
      <td>-0.148673</td>
      <td>-0.300422</td>
      <td>0.253398</td>
      <td>-0.617306</td>
      <td>-0.741506</td>
      <td>-0.315348</td>
      <td>-1.035129</td>
      <td>-0.871354</td>
      <td>-0.287760</td>
      <td>-0.377801</td>
      <td>0.343067</td>
      <td>-0.484242</td>
      <td>0.049376</td>
      <td>0.270510</td>
      <td>-0.112885</td>
      <td>-0.124277</td>
      <td>0.795575</td>
      <td>1.820315</td>
      <td>0.574193</td>
      <td>0.348949</td>
      <td>-0.366401</td>
      <td>-0.643002</td>
      <td>0.363816</td>
      <td>-0.343290</td>
      <td>-0.075797</td>
      <td>-1.193537</td>
      <td>0.263108</td>
      <td>0.938058</td>
      <td>0.203188</td>
      <td>0.536473</td>
      <td>-0.482602</td>
      <td>-0.100451</td>
      <td>-0.649992</td>
      <td>-0.276504</td>
      <td>1.522339</td>
      <td>1.611574</td>
      <td>0.493304</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.304389</td>
      <td>-0.641726</td>
      <td>0.794927</td>
      <td>0.486181</td>
      <td>0.073248</td>
      <td>-0.142566</td>
      <td>-0.142397</td>
      <td>-0.600663</td>
      <td>0.921983</td>
      <td>0.666914</td>
      <td>0.580014</td>
      <td>0.071002</td>
      <td>0.802257</td>
      <td>0.194820</td>
      <td>-0.845184</td>
      <td>-1.375214</td>
      <td>-0.148021</td>
      <td>0.142138</td>
      <td>-0.090056</td>
      <td>-1.028914</td>
      <td>-0.008829</td>
      <td>0.579952</td>
      <td>0.400563</td>
      <td>-0.234847</td>
      <td>-0.225671</td>
      <td>-0.256471</td>
      <td>1.152191</td>
      <td>0.884097</td>
      <td>0.495662</td>
      <td>0.062646</td>
      <td>0.188836</td>
      <td>0.516199</td>
      <td>-0.372902</td>
      <td>-0.656396</td>
      <td>-0.360832</td>
      <td>0.391620</td>
      <td>0.705244</td>
      <td>0.683832</td>
      <td>0.511066</td>
      <td>-0.644826</td>
      <td>...</td>
      <td>-0.386753</td>
      <td>-0.124574</td>
      <td>-1.044114</td>
      <td>-0.572485</td>
      <td>1.425984</td>
      <td>0.446176</td>
      <td>1.012906</td>
      <td>-0.525739</td>
      <td>1.066596</td>
      <td>-0.662771</td>
      <td>-0.326803</td>
      <td>-0.549173</td>
      <td>0.466589</td>
      <td>0.636592</td>
      <td>0.534144</td>
      <td>0.399648</td>
      <td>-0.905951</td>
      <td>-0.016273</td>
      <td>1.093559</td>
      <td>0.443176</td>
      <td>-0.435903</td>
      <td>-0.198617</td>
      <td>0.175903</td>
      <td>-0.049606</td>
      <td>-0.186508</td>
      <td>0.661186</td>
      <td>-0.045467</td>
      <td>-0.253697</td>
      <td>0.080380</td>
      <td>0.349765</td>
      <td>0.401224</td>
      <td>0.372342</td>
      <td>0.262728</td>
      <td>0.430974</td>
      <td>0.208534</td>
      <td>-0.599606</td>
      <td>-0.452461</td>
      <td>0.035816</td>
      <td>0.636935</td>
      <td>0.040635</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.185201</td>
      <td>0.588769</td>
      <td>0.099861</td>
      <td>-0.880449</td>
      <td>-0.952640</td>
      <td>-0.122267</td>
      <td>-0.038029</td>
      <td>-0.867965</td>
      <td>-0.092098</td>
      <td>-0.107738</td>
      <td>0.178695</td>
      <td>0.415504</td>
      <td>-0.049157</td>
      <td>-0.489382</td>
      <td>0.161329</td>
      <td>-0.556969</td>
      <td>-0.549959</td>
      <td>-1.254453</td>
      <td>0.581789</td>
      <td>0.192845</td>
      <td>0.284715</td>
      <td>-0.253352</td>
      <td>0.466922</td>
      <td>0.678486</td>
      <td>0.305416</td>
      <td>-0.793111</td>
      <td>1.035609</td>
      <td>-0.434856</td>
      <td>1.078160</td>
      <td>-0.412066</td>
      <td>0.195205</td>
      <td>0.807679</td>
      <td>-0.277058</td>
      <td>-1.103080</td>
      <td>-0.845028</td>
      <td>-0.586348</td>
      <td>0.286703</td>
      <td>-0.134742</td>
      <td>0.583160</td>
      <td>0.885423</td>
      <td>...</td>
      <td>-0.279372</td>
      <td>-0.488079</td>
      <td>-0.987037</td>
      <td>-0.755999</td>
      <td>1.089110</td>
      <td>0.468947</td>
      <td>1.305004</td>
      <td>-0.172729</td>
      <td>-0.169018</td>
      <td>-0.396835</td>
      <td>-0.682246</td>
      <td>0.457914</td>
      <td>-0.150726</td>
      <td>-0.712138</td>
      <td>-1.060516</td>
      <td>-0.667296</td>
      <td>-0.057751</td>
      <td>-0.654357</td>
      <td>-0.236130</td>
      <td>0.505858</td>
      <td>0.537714</td>
      <td>-0.185202</td>
      <td>1.655510</td>
      <td>0.109502</td>
      <td>-0.083558</td>
      <td>-1.115323</td>
      <td>-0.275379</td>
      <td>-0.743817</td>
      <td>-0.054095</td>
      <td>-0.490407</td>
      <td>0.538288</td>
      <td>0.236519</td>
      <td>-0.848768</td>
      <td>-0.121858</td>
      <td>0.190481</td>
      <td>-0.137196</td>
      <td>-1.110009</td>
      <td>0.755953</td>
      <td>0.939953</td>
      <td>0.842704</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.054767</td>
      <td>0.846960</td>
      <td>0.292901</td>
      <td>-0.944136</td>
      <td>-0.252032</td>
      <td>-1.364545</td>
      <td>-0.567973</td>
      <td>-0.133305</td>
      <td>-0.397073</td>
      <td>0.137706</td>
      <td>0.694728</td>
      <td>0.096440</td>
      <td>0.406809</td>
      <td>0.031360</td>
      <td>0.289160</td>
      <td>-0.312988</td>
      <td>-0.207440</td>
      <td>-0.377651</td>
      <td>0.009793</td>
      <td>0.409373</td>
      <td>0.742160</td>
      <td>0.519861</td>
      <td>-0.178090</td>
      <td>-0.928088</td>
      <td>-0.550512</td>
      <td>0.219794</td>
      <td>0.618435</td>
      <td>-0.508307</td>
      <td>-0.069467</td>
      <td>-0.183650</td>
      <td>-0.164935</td>
      <td>-0.183265</td>
      <td>-0.146984</td>
      <td>-0.287712</td>
      <td>-0.524708</td>
      <td>-0.591905</td>
      <td>-0.253680</td>
      <td>-0.707210</td>
      <td>-0.402494</td>
      <td>0.320169</td>
      <td>...</td>
      <td>-0.041469</td>
      <td>0.058029</td>
      <td>0.259100</td>
      <td>-0.296713</td>
      <td>-0.175861</td>
      <td>-0.414594</td>
      <td>0.446499</td>
      <td>0.649374</td>
      <td>0.776173</td>
      <td>-0.101226</td>
      <td>-0.524526</td>
      <td>-0.732252</td>
      <td>0.262624</td>
      <td>-0.747798</td>
      <td>0.364583</td>
      <td>0.394134</td>
      <td>0.457934</td>
      <td>-0.149283</td>
      <td>0.501184</td>
      <td>0.184859</td>
      <td>0.207597</td>
      <td>-0.052583</td>
      <td>0.169477</td>
      <td>0.962202</td>
      <td>-0.191315</td>
      <td>-0.184110</td>
      <td>0.498412</td>
      <td>0.700471</td>
      <td>-0.721189</td>
      <td>-0.522191</td>
      <td>0.905511</td>
      <td>-0.267976</td>
      <td>-0.336542</td>
      <td>-0.954258</td>
      <td>-0.545236</td>
      <td>-0.683356</td>
      <td>0.446109</td>
      <td>0.019871</td>
      <td>-0.253503</td>
      <td>-0.340765</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.721720</td>
      <td>1.602748</td>
      <td>1.391895</td>
      <td>0.492464</td>
      <td>0.303628</td>
      <td>0.018437</td>
      <td>0.055366</td>
      <td>-0.629341</td>
      <td>-0.829966</td>
      <td>0.057300</td>
      <td>-0.040966</td>
      <td>-0.287949</td>
      <td>-0.016287</td>
      <td>1.060267</td>
      <td>0.486746</td>
      <td>-0.481474</td>
      <td>0.606134</td>
      <td>0.170202</td>
      <td>0.052165</td>
      <td>-1.287203</td>
      <td>0.021632</td>
      <td>-0.486860</td>
      <td>0.429195</td>
      <td>0.652287</td>
      <td>-0.865236</td>
      <td>-0.240673</td>
      <td>0.110014</td>
      <td>0.019052</td>
      <td>-0.406394</td>
      <td>-0.391617</td>
      <td>0.539865</td>
      <td>1.151762</td>
      <td>0.503857</td>
      <td>-0.360014</td>
      <td>-0.098865</td>
      <td>0.079098</td>
      <td>0.660843</td>
      <td>-0.310057</td>
      <td>0.298941</td>
      <td>0.035725</td>
      <td>...</td>
      <td>-0.936640</td>
      <td>-1.071712</td>
      <td>-0.237576</td>
      <td>-0.054897</td>
      <td>-0.214028</td>
      <td>0.912800</td>
      <td>0.924157</td>
      <td>1.013472</td>
      <td>1.615444</td>
      <td>1.144436</td>
      <td>0.802820</td>
      <td>0.070944</td>
      <td>0.030640</td>
      <td>-1.292676</td>
      <td>-1.130888</td>
      <td>-0.756636</td>
      <td>0.270125</td>
      <td>0.196132</td>
      <td>-0.605859</td>
      <td>0.225835</td>
      <td>-0.925363</td>
      <td>-0.781898</td>
      <td>0.079068</td>
      <td>0.534822</td>
      <td>0.658302</td>
      <td>0.142076</td>
      <td>-0.242739</td>
      <td>-0.385137</td>
      <td>-1.402460</td>
      <td>-0.322379</td>
      <td>0.184248</td>
      <td>0.193388</td>
      <td>0.735844</td>
      <td>-0.373675</td>
      <td>-0.592673</td>
      <td>-0.287009</td>
      <td>0.387681</td>
      <td>2.451274</td>
      <td>1.811818</td>
      <td>0.620974</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.601417</td>
      <td>0.411581</td>
      <td>0.557416</td>
      <td>0.208540</td>
      <td>-0.999881</td>
      <td>-0.405820</td>
      <td>-0.543195</td>
      <td>-0.759890</td>
      <td>-0.339738</td>
      <td>0.966674</td>
      <td>-0.589742</td>
      <td>0.127741</td>
      <td>0.264317</td>
      <td>0.496276</td>
      <td>0.562610</td>
      <td>0.249811</td>
      <td>1.150284</td>
      <td>0.151617</td>
      <td>0.194317</td>
      <td>-0.016939</td>
      <td>-0.174775</td>
      <td>0.690935</td>
      <td>-0.445581</td>
      <td>-0.209015</td>
      <td>-0.592721</td>
      <td>-0.032602</td>
      <td>-0.137792</td>
      <td>-0.046885</td>
      <td>-1.001252</td>
      <td>-0.781827</td>
      <td>-0.419586</td>
      <td>-0.669782</td>
      <td>0.644514</td>
      <td>1.158273</td>
      <td>1.000881</td>
      <td>0.420273</td>
      <td>-0.255281</td>
      <td>-0.802654</td>
      <td>0.692055</td>
      <td>0.185839</td>
      <td>...</td>
      <td>0.288409</td>
      <td>0.264490</td>
      <td>-0.202167</td>
      <td>-0.277578</td>
      <td>0.158917</td>
      <td>0.971048</td>
      <td>0.530054</td>
      <td>0.396707</td>
      <td>-0.676002</td>
      <td>0.555353</td>
      <td>-0.248237</td>
      <td>-0.436603</td>
      <td>1.337742</td>
      <td>-0.934249</td>
      <td>-0.380260</td>
      <td>-0.759307</td>
      <td>-0.626899</td>
      <td>-0.370447</td>
      <td>0.689430</td>
      <td>1.142798</td>
      <td>0.947045</td>
      <td>0.463072</td>
      <td>0.240667</td>
      <td>-0.490082</td>
      <td>-0.977807</td>
      <td>0.599445</td>
      <td>-0.577962</td>
      <td>-0.165145</td>
      <td>-0.098612</td>
      <td>0.617300</td>
      <td>-0.288546</td>
      <td>0.389568</td>
      <td>-0.009842</td>
      <td>-0.328037</td>
      <td>-0.588876</td>
      <td>-0.573111</td>
      <td>0.392194</td>
      <td>-0.093380</td>
      <td>0.056917</td>
      <td>-0.467531</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.448439</td>
      <td>0.282866</td>
      <td>0.619935</td>
      <td>-0.210143</td>
      <td>-0.689863</td>
      <td>-0.602614</td>
      <td>-0.672786</td>
      <td>-0.144397</td>
      <td>1.137468</td>
      <td>0.332682</td>
      <td>-0.170087</td>
      <td>-0.140792</td>
      <td>-0.847256</td>
      <td>-1.430059</td>
      <td>-0.186906</td>
      <td>0.117856</td>
      <td>0.251630</td>
      <td>-0.555152</td>
      <td>-0.844334</td>
      <td>-1.262294</td>
      <td>-0.005874</td>
      <td>0.264256</td>
      <td>0.004673</td>
      <td>-0.573529</td>
      <td>-0.460171</td>
      <td>-0.916634</td>
      <td>-0.013986</td>
      <td>0.537274</td>
      <td>-0.918314</td>
      <td>-0.686092</td>
      <td>-0.089377</td>
      <td>0.509713</td>
      <td>0.867552</td>
      <td>0.160334</td>
      <td>0.422978</td>
      <td>-0.262682</td>
      <td>0.127906</td>
      <td>0.232721</td>
      <td>0.578038</td>
      <td>-0.788838</td>
      <td>...</td>
      <td>-0.997586</td>
      <td>-2.024769</td>
      <td>-1.176179</td>
      <td>-0.060822</td>
      <td>-0.735676</td>
      <td>1.077761</td>
      <td>0.320663</td>
      <td>-0.538821</td>
      <td>0.085522</td>
      <td>-0.359081</td>
      <td>0.441058</td>
      <td>-0.539700</td>
      <td>0.028567</td>
      <td>-0.431320</td>
      <td>0.289026</td>
      <td>0.224523</td>
      <td>0.455748</td>
      <td>0.430452</td>
      <td>0.440248</td>
      <td>-0.273157</td>
      <td>0.886748</td>
      <td>-0.691118</td>
      <td>0.223432</td>
      <td>0.819175</td>
      <td>0.293665</td>
      <td>-0.003281</td>
      <td>-0.042670</td>
      <td>-1.102455</td>
      <td>-0.682863</td>
      <td>0.465878</td>
      <td>0.184019</td>
      <td>-0.417446</td>
      <td>-0.051577</td>
      <td>-0.080904</td>
      <td>-0.179452</td>
      <td>0.164446</td>
      <td>-0.265437</td>
      <td>-0.786391</td>
      <td>0.079868</td>
      <td>-0.191950</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.763801</td>
      <td>0.575575</td>
      <td>-0.019567</td>
      <td>0.086697</td>
      <td>0.247445</td>
      <td>-0.625864</td>
      <td>-0.650781</td>
      <td>-0.789269</td>
      <td>0.473517</td>
      <td>0.492646</td>
      <td>0.406843</td>
      <td>-0.076855</td>
      <td>-0.071949</td>
      <td>-0.075566</td>
      <td>-0.374643</td>
      <td>-1.206724</td>
      <td>-1.075629</td>
      <td>-1.114651</td>
      <td>0.263807</td>
      <td>-0.375703</td>
      <td>0.341471</td>
      <td>1.616535</td>
      <td>0.125269</td>
      <td>-0.656556</td>
      <td>-0.630543</td>
      <td>-0.296134</td>
      <td>0.638124</td>
      <td>-0.331684</td>
      <td>-0.572159</td>
      <td>-0.658931</td>
      <td>1.061658</td>
      <td>0.019050</td>
      <td>0.166446</td>
      <td>1.193841</td>
      <td>0.259000</td>
      <td>0.133885</td>
      <td>-0.505833</td>
      <td>-0.802502</td>
      <td>-0.259832</td>
      <td>-0.495198</td>
      <td>...</td>
      <td>-0.372630</td>
      <td>-0.583691</td>
      <td>-1.170872</td>
      <td>1.046898</td>
      <td>0.273171</td>
      <td>0.017250</td>
      <td>-0.055166</td>
      <td>0.379489</td>
      <td>-0.427918</td>
      <td>-0.220417</td>
      <td>0.561416</td>
      <td>-0.959081</td>
      <td>-0.011400</td>
      <td>-0.878181</td>
      <td>-0.499234</td>
      <td>-0.743334</td>
      <td>-0.259910</td>
      <td>-0.054616</td>
      <td>-0.057020</td>
      <td>-0.209669</td>
      <td>0.771244</td>
      <td>0.579255</td>
      <td>0.634104</td>
      <td>0.181061</td>
      <td>-0.639278</td>
      <td>0.834170</td>
      <td>0.529520</td>
      <td>0.049501</td>
      <td>-0.326521</td>
      <td>1.095227</td>
      <td>-0.324576</td>
      <td>-0.458111</td>
      <td>0.041815</td>
      <td>0.186699</td>
      <td>-0.416135</td>
      <td>-0.850828</td>
      <td>-0.306573</td>
      <td>2.467872</td>
      <td>1.706667</td>
      <td>0.934199</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-0.603069</td>
      <td>0.770889</td>
      <td>0.625577</td>
      <td>-0.222286</td>
      <td>-0.027338</td>
      <td>-0.021162</td>
      <td>-0.326618</td>
      <td>-0.370240</td>
      <td>-0.219696</td>
      <td>0.049966</td>
      <td>-0.338779</td>
      <td>-0.629677</td>
      <td>-0.491906</td>
      <td>-0.110626</td>
      <td>0.135183</td>
      <td>0.130875</td>
      <td>-0.079568</td>
      <td>-0.255183</td>
      <td>-0.187261</td>
      <td>-0.180147</td>
      <td>0.472002</td>
      <td>-0.127356</td>
      <td>0.597691</td>
      <td>0.480491</td>
      <td>0.199548</td>
      <td>0.055091</td>
      <td>-0.066161</td>
      <td>0.450625</td>
      <td>0.299066</td>
      <td>-0.313311</td>
      <td>0.207528</td>
      <td>0.042395</td>
      <td>-0.782864</td>
      <td>-0.965351</td>
      <td>0.193239</td>
      <td>0.845569</td>
      <td>1.420283</td>
      <td>-0.711024</td>
      <td>0.712292</td>
      <td>0.963312</td>
      <td>...</td>
      <td>0.168096</td>
      <td>-0.482523</td>
      <td>-1.126220</td>
      <td>0.630607</td>
      <td>-0.020765</td>
      <td>0.458864</td>
      <td>0.811057</td>
      <td>0.319605</td>
      <td>-0.513024</td>
      <td>-0.475492</td>
      <td>-1.166232</td>
      <td>-0.895887</td>
      <td>-0.103884</td>
      <td>-0.897244</td>
      <td>-0.602750</td>
      <td>-0.531305</td>
      <td>-0.160167</td>
      <td>0.031177</td>
      <td>0.115515</td>
      <td>0.563556</td>
      <td>0.299358</td>
      <td>0.180711</td>
      <td>0.634296</td>
      <td>0.081755</td>
      <td>-0.333333</td>
      <td>-0.453896</td>
      <td>-0.690025</td>
      <td>-1.277928</td>
      <td>-0.390155</td>
      <td>1.152714</td>
      <td>0.053454</td>
      <td>-0.091631</td>
      <td>-0.114984</td>
      <td>-0.516198</td>
      <td>-0.646824</td>
      <td>-0.279211</td>
      <td>0.136271</td>
      <td>2.503401</td>
      <td>1.106946</td>
      <td>0.731566</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.197621</td>
      <td>0.281497</td>
      <td>0.123891</td>
      <td>0.275752</td>
      <td>-0.248526</td>
      <td>-0.515095</td>
      <td>0.413843</td>
      <td>-0.022439</td>
      <td>0.100142</td>
      <td>-0.783832</td>
      <td>0.034431</td>
      <td>-0.287149</td>
      <td>0.149751</td>
      <td>0.150044</td>
      <td>0.608842</td>
      <td>-0.113923</td>
      <td>1.083654</td>
      <td>-0.705097</td>
      <td>-0.438437</td>
      <td>0.260350</td>
      <td>0.174090</td>
      <td>1.090259</td>
      <td>0.049173</td>
      <td>-1.128523</td>
      <td>-1.580856</td>
      <td>0.089165</td>
      <td>0.077877</td>
      <td>-0.153929</td>
      <td>0.480415</td>
      <td>0.459224</td>
      <td>0.477329</td>
      <td>0.100329</td>
      <td>0.105031</td>
      <td>0.076609</td>
      <td>-0.160050</td>
      <td>0.716133</td>
      <td>0.098565</td>
      <td>-0.601077</td>
      <td>0.035014</td>
      <td>-0.699259</td>
      <td>...</td>
      <td>0.118923</td>
      <td>0.106783</td>
      <td>-0.018546</td>
      <td>-0.197952</td>
      <td>0.793701</td>
      <td>0.250044</td>
      <td>0.708670</td>
      <td>-0.645065</td>
      <td>-0.991440</td>
      <td>-0.565289</td>
      <td>-1.135631</td>
      <td>0.315773</td>
      <td>0.140133</td>
      <td>0.338553</td>
      <td>-1.329361</td>
      <td>0.136892</td>
      <td>-0.310103</td>
      <td>-0.032097</td>
      <td>0.665237</td>
      <td>1.418736</td>
      <td>0.139774</td>
      <td>-0.485758</td>
      <td>0.423920</td>
      <td>0.596272</td>
      <td>-0.188879</td>
      <td>-0.593273</td>
      <td>0.025381</td>
      <td>0.492700</td>
      <td>0.256265</td>
      <td>-0.302809</td>
      <td>0.746611</td>
      <td>-0.201068</td>
      <td>-0.118747</td>
      <td>-0.135706</td>
      <td>-1.159987</td>
      <td>-0.338834</td>
      <td>-0.001343</td>
      <td>1.266811</td>
      <td>0.215688</td>
      <td>0.089626</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.478416</td>
      <td>0.580139</td>
      <td>0.030591</td>
      <td>-1.036502</td>
      <td>-0.292199</td>
      <td>-1.224920</td>
      <td>-0.111237</td>
      <td>-1.536023</td>
      <td>0.365896</td>
      <td>0.142433</td>
      <td>-0.128666</td>
      <td>-0.422229</td>
      <td>0.364944</td>
      <td>0.942454</td>
      <td>0.365873</td>
      <td>0.270077</td>
      <td>0.459687</td>
      <td>-0.416704</td>
      <td>0.565931</td>
      <td>-0.104309</td>
      <td>1.026929</td>
      <td>0.231805</td>
      <td>0.346783</td>
      <td>-0.477603</td>
      <td>0.205369</td>
      <td>-0.995337</td>
      <td>0.003211</td>
      <td>-0.514518</td>
      <td>0.561530</td>
      <td>-0.174429</td>
      <td>-0.251880</td>
      <td>-0.185346</td>
      <td>-0.250318</td>
      <td>-1.015123</td>
      <td>0.421587</td>
      <td>1.125362</td>
      <td>0.329781</td>
      <td>0.093539</td>
      <td>0.516660</td>
      <td>1.008863</td>
      <td>...</td>
      <td>-0.312616</td>
      <td>0.028438</td>
      <td>0.065054</td>
      <td>-1.380420</td>
      <td>0.331914</td>
      <td>0.028026</td>
      <td>-0.408285</td>
      <td>-0.073949</td>
      <td>1.182787</td>
      <td>-0.116113</td>
      <td>-0.249183</td>
      <td>0.181678</td>
      <td>0.704019</td>
      <td>-0.489202</td>
      <td>-0.440535</td>
      <td>0.101093</td>
      <td>0.182518</td>
      <td>-0.104405</td>
      <td>0.073083</td>
      <td>-0.170091</td>
      <td>0.896925</td>
      <td>-0.256469</td>
      <td>0.384092</td>
      <td>0.987416</td>
      <td>-0.534808</td>
      <td>-0.996500</td>
      <td>-0.080623</td>
      <td>0.023919</td>
      <td>0.339334</td>
      <td>-0.297913</td>
      <td>-0.281681</td>
      <td>0.072417</td>
      <td>-0.072450</td>
      <td>0.319690</td>
      <td>0.187856</td>
      <td>0.117259</td>
      <td>0.896354</td>
      <td>1.654175</td>
      <td>0.777552</td>
      <td>0.149148</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.241941</td>
      <td>0.388432</td>
      <td>0.896781</td>
      <td>-0.213414</td>
      <td>-0.194217</td>
      <td>-0.279914</td>
      <td>0.635504</td>
      <td>-0.095702</td>
      <td>0.437924</td>
      <td>-0.240655</td>
      <td>-0.010676</td>
      <td>0.575473</td>
      <td>0.970597</td>
      <td>-0.761402</td>
      <td>-0.288046</td>
      <td>-0.806951</td>
      <td>0.769212</td>
      <td>-1.390829</td>
      <td>-0.364513</td>
      <td>0.484306</td>
      <td>1.717664</td>
      <td>0.349527</td>
      <td>0.096329</td>
      <td>-0.075423</td>
      <td>-0.583955</td>
      <td>0.467965</td>
      <td>0.323678</td>
      <td>-1.010226</td>
      <td>0.299517</td>
      <td>0.206520</td>
      <td>0.664081</td>
      <td>0.589232</td>
      <td>0.670140</td>
      <td>1.559447</td>
      <td>-0.112048</td>
      <td>-0.172877</td>
      <td>-0.601049</td>
      <td>-1.399266</td>
      <td>0.427724</td>
      <td>-0.318698</td>
      <td>...</td>
      <td>0.196182</td>
      <td>-0.821257</td>
      <td>0.302200</td>
      <td>-0.401940</td>
      <td>0.784070</td>
      <td>1.209128</td>
      <td>-0.317859</td>
      <td>0.099141</td>
      <td>0.480646</td>
      <td>0.243289</td>
      <td>0.472602</td>
      <td>-0.513611</td>
      <td>0.529269</td>
      <td>0.108928</td>
      <td>0.242922</td>
      <td>0.171489</td>
      <td>-0.098656</td>
      <td>0.697172</td>
      <td>0.074858</td>
      <td>1.127568</td>
      <td>0.493377</td>
      <td>0.806473</td>
      <td>1.016054</td>
      <td>-0.296747</td>
      <td>0.127862</td>
      <td>0.560540</td>
      <td>0.144799</td>
      <td>-0.648461</td>
      <td>-0.470170</td>
      <td>-0.344139</td>
      <td>0.074720</td>
      <td>0.703626</td>
      <td>-0.985380</td>
      <td>0.908289</td>
      <td>0.453336</td>
      <td>-0.788042</td>
      <td>-0.384162</td>
      <td>0.858704</td>
      <td>1.242594</td>
      <td>0.345938</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.165513</td>
      <td>0.058193</td>
      <td>0.195439</td>
      <td>-0.636737</td>
      <td>-0.812415</td>
      <td>-0.964861</td>
      <td>-0.351664</td>
      <td>-0.120014</td>
      <td>0.696275</td>
      <td>0.836465</td>
      <td>0.626505</td>
      <td>0.361457</td>
      <td>0.893733</td>
      <td>1.484778</td>
      <td>0.334806</td>
      <td>0.066075</td>
      <td>-0.065767</td>
      <td>-0.309871</td>
      <td>0.083085</td>
      <td>-0.145804</td>
      <td>0.460247</td>
      <td>-0.685318</td>
      <td>-0.342210</td>
      <td>0.190537</td>
      <td>-0.286557</td>
      <td>-0.539708</td>
      <td>0.284041</td>
      <td>0.308691</td>
      <td>-0.588495</td>
      <td>-0.479845</td>
      <td>0.754360</td>
      <td>1.345867</td>
      <td>0.670817</td>
      <td>-0.537284</td>
      <td>0.062215</td>
      <td>-0.123705</td>
      <td>-0.198568</td>
      <td>-1.580112</td>
      <td>-0.009995</td>
      <td>0.456032</td>
      <td>...</td>
      <td>-0.312017</td>
      <td>-0.962058</td>
      <td>-0.780656</td>
      <td>0.114231</td>
      <td>0.122166</td>
      <td>0.297597</td>
      <td>-0.071584</td>
      <td>0.551523</td>
      <td>-0.142876</td>
      <td>0.419123</td>
      <td>0.042264</td>
      <td>0.268947</td>
      <td>1.346000</td>
      <td>-0.093727</td>
      <td>-0.258672</td>
      <td>0.654712</td>
      <td>0.363725</td>
      <td>-0.053322</td>
      <td>-0.614389</td>
      <td>0.037589</td>
      <td>-0.440940</td>
      <td>0.547808</td>
      <td>1.076341</td>
      <td>0.123812</td>
      <td>0.649974</td>
      <td>0.464630</td>
      <td>1.045609</td>
      <td>0.617214</td>
      <td>-0.379553</td>
      <td>-0.601986</td>
      <td>0.443105</td>
      <td>0.355625</td>
      <td>-0.500102</td>
      <td>-0.470510</td>
      <td>-0.041640</td>
      <td>-0.817393</td>
      <td>-0.007483</td>
      <td>0.504095</td>
      <td>0.115809</td>
      <td>0.106776</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.103684</td>
      <td>0.700786</td>
      <td>0.256423</td>
      <td>-0.912200</td>
      <td>-0.283757</td>
      <td>-0.897497</td>
      <td>-0.800822</td>
      <td>-0.336480</td>
      <td>0.270032</td>
      <td>-0.519515</td>
      <td>-0.484320</td>
      <td>0.223552</td>
      <td>0.187464</td>
      <td>0.290180</td>
      <td>0.667606</td>
      <td>-1.008038</td>
      <td>-0.177796</td>
      <td>-0.089600</td>
      <td>0.334279</td>
      <td>-0.671085</td>
      <td>0.190184</td>
      <td>0.402463</td>
      <td>0.091814</td>
      <td>-0.502936</td>
      <td>0.048623</td>
      <td>0.130291</td>
      <td>0.540792</td>
      <td>-0.335718</td>
      <td>-0.021589</td>
      <td>-0.196826</td>
      <td>-0.431898</td>
      <td>-0.628901</td>
      <td>0.718406</td>
      <td>1.410517</td>
      <td>-0.403302</td>
      <td>-0.584675</td>
      <td>-0.241956</td>
      <td>0.247053</td>
      <td>0.481173</td>
      <td>0.481048</td>
      <td>...</td>
      <td>0.366488</td>
      <td>0.383268</td>
      <td>-0.527416</td>
      <td>0.192908</td>
      <td>0.709848</td>
      <td>0.080345</td>
      <td>0.892095</td>
      <td>-0.251663</td>
      <td>-0.069878</td>
      <td>-0.351283</td>
      <td>-0.055812</td>
      <td>0.119824</td>
      <td>0.629247</td>
      <td>-1.685346</td>
      <td>-0.696537</td>
      <td>-0.119927</td>
      <td>-0.819052</td>
      <td>-0.022527</td>
      <td>-0.491283</td>
      <td>-0.344199</td>
      <td>0.757094</td>
      <td>0.720771</td>
      <td>0.127093</td>
      <td>1.328285</td>
      <td>-0.164166</td>
      <td>0.014866</td>
      <td>0.612273</td>
      <td>-0.690352</td>
      <td>0.630702</td>
      <td>0.575645</td>
      <td>0.844596</td>
      <td>0.696207</td>
      <td>-0.853109</td>
      <td>0.416844</td>
      <td>0.505073</td>
      <td>-0.275394</td>
      <td>-1.009805</td>
      <td>0.239453</td>
      <td>0.307474</td>
      <td>-0.045571</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.390639</td>
      <td>0.564156</td>
      <td>0.240376</td>
      <td>-1.068316</td>
      <td>0.213233</td>
      <td>-0.887502</td>
      <td>-0.015349</td>
      <td>-0.527735</td>
      <td>0.203354</td>
      <td>0.836046</td>
      <td>0.640865</td>
      <td>-0.501596</td>
      <td>0.016345</td>
      <td>0.868854</td>
      <td>0.083824</td>
      <td>-0.254687</td>
      <td>-0.297821</td>
      <td>-0.485112</td>
      <td>-0.344786</td>
      <td>-0.751849</td>
      <td>0.236501</td>
      <td>0.887980</td>
      <td>0.221661</td>
      <td>-1.563562</td>
      <td>-0.284328</td>
      <td>-0.324851</td>
      <td>0.808427</td>
      <td>-0.414943</td>
      <td>-1.600829</td>
      <td>-0.638091</td>
      <td>0.571057</td>
      <td>0.649726</td>
      <td>0.315947</td>
      <td>-0.450168</td>
      <td>0.410271</td>
      <td>0.266626</td>
      <td>0.460948</td>
      <td>-0.078190</td>
      <td>-0.077464</td>
      <td>0.651714</td>
      <td>...</td>
      <td>-0.015088</td>
      <td>-0.342792</td>
      <td>-0.641694</td>
      <td>-0.569124</td>
      <td>-0.504831</td>
      <td>0.181001</td>
      <td>-0.389613</td>
      <td>-0.965061</td>
      <td>1.109009</td>
      <td>0.320974</td>
      <td>0.395428</td>
      <td>0.398638</td>
      <td>0.749073</td>
      <td>-1.453024</td>
      <td>-0.852117</td>
      <td>-0.901340</td>
      <td>-0.711711</td>
      <td>-0.107701</td>
      <td>0.182546</td>
      <td>-0.235044</td>
      <td>-0.616281</td>
      <td>0.351993</td>
      <td>0.976910</td>
      <td>-0.449087</td>
      <td>-0.015016</td>
      <td>0.197108</td>
      <td>-0.137854</td>
      <td>0.122033</td>
      <td>-0.634487</td>
      <td>-0.804109</td>
      <td>-0.275025</td>
      <td>-0.591543</td>
      <td>-0.222370</td>
      <td>-0.127989</td>
      <td>0.146207</td>
      <td>-1.404057</td>
      <td>-0.161795</td>
      <td>-0.769069</td>
      <td>-0.240578</td>
      <td>0.118096</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.132951</td>
      <td>0.366356</td>
      <td>1.289033</td>
      <td>0.814870</td>
      <td>0.432005</td>
      <td>0.657560</td>
      <td>0.069977</td>
      <td>-0.443039</td>
      <td>0.276454</td>
      <td>0.394167</td>
      <td>0.008033</td>
      <td>0.198896</td>
      <td>0.247427</td>
      <td>0.211229</td>
      <td>0.301185</td>
      <td>0.571099</td>
      <td>1.154326</td>
      <td>1.046542</td>
      <td>1.108020</td>
      <td>-0.581714</td>
      <td>-0.235556</td>
      <td>0.282578</td>
      <td>0.878838</td>
      <td>-0.675835</td>
      <td>-0.044647</td>
      <td>0.507132</td>
      <td>-0.040330</td>
      <td>-1.309126</td>
      <td>-0.056784</td>
      <td>-0.995063</td>
      <td>0.333924</td>
      <td>-0.259767</td>
      <td>-0.510319</td>
      <td>0.516048</td>
      <td>0.966810</td>
      <td>-0.368123</td>
      <td>1.034665</td>
      <td>0.229065</td>
      <td>0.478862</td>
      <td>-0.249806</td>
      <td>...</td>
      <td>-0.485862</td>
      <td>-0.185651</td>
      <td>-0.857949</td>
      <td>0.332340</td>
      <td>0.680758</td>
      <td>2.035771</td>
      <td>1.169508</td>
      <td>0.767174</td>
      <td>-0.307028</td>
      <td>0.029473</td>
      <td>-0.249632</td>
      <td>-0.534096</td>
      <td>-0.317611</td>
      <td>-1.277949</td>
      <td>-0.832277</td>
      <td>0.313509</td>
      <td>0.427104</td>
      <td>0.531584</td>
      <td>1.576240</td>
      <td>0.010567</td>
      <td>0.516606</td>
      <td>-0.068428</td>
      <td>0.676709</td>
      <td>0.641632</td>
      <td>-0.227859</td>
      <td>-0.254171</td>
      <td>-0.333144</td>
      <td>-0.211251</td>
      <td>-0.428346</td>
      <td>0.199399</td>
      <td>-0.301257</td>
      <td>-0.761403</td>
      <td>-0.778285</td>
      <td>0.845729</td>
      <td>-0.081650</td>
      <td>-0.551181</td>
      <td>-0.545446</td>
      <td>0.536912</td>
      <td>0.517995</td>
      <td>0.565553</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.871815</td>
      <td>0.532290</td>
      <td>0.080918</td>
      <td>0.667994</td>
      <td>0.583610</td>
      <td>0.212916</td>
      <td>-1.082247</td>
      <td>0.175290</td>
      <td>-0.863969</td>
      <td>0.158849</td>
      <td>1.854437</td>
      <td>0.339256</td>
      <td>1.184614</td>
      <td>0.749979</td>
      <td>0.673094</td>
      <td>-0.913086</td>
      <td>0.196350</td>
      <td>0.579182</td>
      <td>-0.173470</td>
      <td>-1.079247</td>
      <td>-0.814833</td>
      <td>-0.025101</td>
      <td>-0.147899</td>
      <td>-0.788208</td>
      <td>0.255018</td>
      <td>0.629036</td>
      <td>0.484789</td>
      <td>0.312098</td>
      <td>0.491646</td>
      <td>-0.275413</td>
      <td>0.394337</td>
      <td>-0.043809</td>
      <td>0.309497</td>
      <td>0.627204</td>
      <td>-0.150993</td>
      <td>-0.633372</td>
      <td>-0.401165</td>
      <td>-0.327884</td>
      <td>0.230473</td>
      <td>0.696890</td>
      <td>...</td>
      <td>-0.642954</td>
      <td>-0.085110</td>
      <td>0.889485</td>
      <td>0.677437</td>
      <td>0.284789</td>
      <td>-0.549513</td>
      <td>0.374305</td>
      <td>-0.811992</td>
      <td>0.752889</td>
      <td>0.009151</td>
      <td>0.636943</td>
      <td>-0.113917</td>
      <td>0.494253</td>
      <td>-0.725271</td>
      <td>-0.051010</td>
      <td>-0.543180</td>
      <td>-0.570010</td>
      <td>0.418004</td>
      <td>-0.339499</td>
      <td>0.336128</td>
      <td>0.787898</td>
      <td>0.543225</td>
      <td>1.211554</td>
      <td>-0.165648</td>
      <td>0.321751</td>
      <td>0.241092</td>
      <td>-0.025343</td>
      <td>-2.056117</td>
      <td>-0.264539</td>
      <td>0.498357</td>
      <td>-0.668048</td>
      <td>0.317446</td>
      <td>-0.068144</td>
      <td>1.211890</td>
      <td>1.083873</td>
      <td>-0.398786</td>
      <td>-0.942759</td>
      <td>1.630795</td>
      <td>1.113036</td>
      <td>0.171301</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.016368</td>
      <td>0.062530</td>
      <td>-0.144755</td>
      <td>-0.311086</td>
      <td>0.164587</td>
      <td>-0.531340</td>
      <td>0.367106</td>
      <td>-0.075498</td>
      <td>-0.267071</td>
      <td>0.215361</td>
      <td>0.843185</td>
      <td>0.255251</td>
      <td>-0.002472</td>
      <td>0.069554</td>
      <td>-0.283567</td>
      <td>-1.230124</td>
      <td>-0.218544</td>
      <td>-0.824025</td>
      <td>-0.185840</td>
      <td>0.083970</td>
      <td>-0.408786</td>
      <td>0.115360</td>
      <td>-0.437717</td>
      <td>-0.035154</td>
      <td>-0.042570</td>
      <td>-1.186396</td>
      <td>-0.068140</td>
      <td>0.092365</td>
      <td>-0.113363</td>
      <td>-0.666921</td>
      <td>-1.073015</td>
      <td>0.706058</td>
      <td>0.428952</td>
      <td>-0.166835</td>
      <td>-0.251627</td>
      <td>-0.025213</td>
      <td>0.482655</td>
      <td>0.373194</td>
      <td>0.109483</td>
      <td>-0.171422</td>
      <td>...</td>
      <td>-0.220640</td>
      <td>-0.849228</td>
      <td>-0.440271</td>
      <td>-0.182658</td>
      <td>0.563148</td>
      <td>0.359777</td>
      <td>1.010062</td>
      <td>0.291440</td>
      <td>0.038504</td>
      <td>-0.085890</td>
      <td>0.728726</td>
      <td>0.806618</td>
      <td>0.803196</td>
      <td>-0.602124</td>
      <td>-1.263934</td>
      <td>-0.444843</td>
      <td>0.013470</td>
      <td>0.710711</td>
      <td>0.445900</td>
      <td>-0.071256</td>
      <td>-0.254607</td>
      <td>-0.195961</td>
      <td>-0.203004</td>
      <td>0.169674</td>
      <td>-1.416650</td>
      <td>0.518472</td>
      <td>0.820059</td>
      <td>-1.086719</td>
      <td>-0.125632</td>
      <td>-0.270067</td>
      <td>0.261384</td>
      <td>0.146168</td>
      <td>-0.139550</td>
      <td>-0.014226</td>
      <td>-0.374874</td>
      <td>-0.127431</td>
      <td>0.410044</td>
      <td>1.866321</td>
      <td>2.587475</td>
      <td>1.472834</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.165303</td>
      <td>-0.070076</td>
      <td>-0.008170</td>
      <td>0.340835</td>
      <td>0.837215</td>
      <td>-0.257746</td>
      <td>0.733792</td>
      <td>1.190532</td>
      <td>0.685451</td>
      <td>0.961376</td>
      <td>1.221932</td>
      <td>0.482922</td>
      <td>-0.253020</td>
      <td>-0.040306</td>
      <td>-0.680798</td>
      <td>0.100963</td>
      <td>1.008968</td>
      <td>0.486384</td>
      <td>0.201480</td>
      <td>-0.757602</td>
      <td>-0.256065</td>
      <td>0.913032</td>
      <td>-0.207697</td>
      <td>-0.129632</td>
      <td>-0.912741</td>
      <td>-0.570919</td>
      <td>0.252532</td>
      <td>-0.704843</td>
      <td>0.446030</td>
      <td>-0.190164</td>
      <td>0.203326</td>
      <td>-0.344241</td>
      <td>0.566006</td>
      <td>0.376736</td>
      <td>-0.119074</td>
      <td>1.077782</td>
      <td>0.665092</td>
      <td>0.265682</td>
      <td>0.767045</td>
      <td>0.334588</td>
      <td>...</td>
      <td>0.234761</td>
      <td>-0.672521</td>
      <td>0.746907</td>
      <td>-0.109908</td>
      <td>0.712542</td>
      <td>-0.774143</td>
      <td>-0.154034</td>
      <td>-0.148149</td>
      <td>0.780521</td>
      <td>0.295895</td>
      <td>-0.380393</td>
      <td>0.085029</td>
      <td>1.120590</td>
      <td>-0.175570</td>
      <td>0.088771</td>
      <td>-0.101508</td>
      <td>-0.027465</td>
      <td>0.594112</td>
      <td>0.285407</td>
      <td>-0.135063</td>
      <td>0.351723</td>
      <td>-0.414978</td>
      <td>0.140236</td>
      <td>1.308016</td>
      <td>-0.834162</td>
      <td>-0.662180</td>
      <td>-0.289236</td>
      <td>-0.436814</td>
      <td>-1.179515</td>
      <td>0.298232</td>
      <td>0.426056</td>
      <td>0.676914</td>
      <td>1.916787</td>
      <td>-0.613919</td>
      <td>-0.200707</td>
      <td>0.786155</td>
      <td>0.115458</td>
      <td>1.529334</td>
      <td>1.201888</td>
      <td>0.578762</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.359360</td>
      <td>-0.150528</td>
      <td>0.080200</td>
      <td>-0.534740</td>
      <td>0.997203</td>
      <td>0.326118</td>
      <td>-0.442087</td>
      <td>1.088703</td>
      <td>1.023841</td>
      <td>0.521954</td>
      <td>0.052990</td>
      <td>0.345056</td>
      <td>0.263432</td>
      <td>-0.462424</td>
      <td>-0.333692</td>
      <td>-0.276242</td>
      <td>0.696008</td>
      <td>-0.081388</td>
      <td>-0.307956</td>
      <td>-0.136365</td>
      <td>0.105547</td>
      <td>0.626577</td>
      <td>0.314236</td>
      <td>0.009645</td>
      <td>0.737307</td>
      <td>-0.484661</td>
      <td>0.488305</td>
      <td>0.237567</td>
      <td>1.480730</td>
      <td>1.534634</td>
      <td>0.769423</td>
      <td>-0.506596</td>
      <td>0.275277</td>
      <td>0.070857</td>
      <td>-0.939242</td>
      <td>-1.238801</td>
      <td>0.041115</td>
      <td>0.170106</td>
      <td>-0.222577</td>
      <td>-0.382889</td>
      <td>...</td>
      <td>0.916499</td>
      <td>0.856752</td>
      <td>-0.495747</td>
      <td>0.062504</td>
      <td>-0.309746</td>
      <td>1.007052</td>
      <td>0.920839</td>
      <td>0.056561</td>
      <td>0.444456</td>
      <td>-0.350796</td>
      <td>0.245856</td>
      <td>0.351714</td>
      <td>-0.890359</td>
      <td>-0.996723</td>
      <td>-0.914859</td>
      <td>0.042347</td>
      <td>-1.098511</td>
      <td>1.034800</td>
      <td>0.023026</td>
      <td>0.046698</td>
      <td>-0.365076</td>
      <td>-0.601575</td>
      <td>0.571033</td>
      <td>0.406240</td>
      <td>0.000172</td>
      <td>0.407953</td>
      <td>-1.005412</td>
      <td>-0.111101</td>
      <td>0.159228</td>
      <td>0.198590</td>
      <td>0.694128</td>
      <td>-0.846092</td>
      <td>1.616245</td>
      <td>0.366400</td>
      <td>0.354082</td>
      <td>0.709703</td>
      <td>-1.318269</td>
      <td>1.575030</td>
      <td>0.925524</td>
      <td>0.205535</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.299634</td>
      <td>0.568559</td>
      <td>1.138172</td>
      <td>0.808081</td>
      <td>1.574549</td>
      <td>1.297795</td>
      <td>1.214533</td>
      <td>0.114647</td>
      <td>0.220764</td>
      <td>0.650860</td>
      <td>0.554046</td>
      <td>0.807668</td>
      <td>0.209642</td>
      <td>-0.364032</td>
      <td>0.199148</td>
      <td>0.985047</td>
      <td>-0.411174</td>
      <td>0.154798</td>
      <td>-0.377719</td>
      <td>-0.729106</td>
      <td>-0.228934</td>
      <td>0.386216</td>
      <td>-1.154652</td>
      <td>-0.580299</td>
      <td>-0.099897</td>
      <td>-0.107496</td>
      <td>0.104457</td>
      <td>-0.778780</td>
      <td>0.035334</td>
      <td>-0.069679</td>
      <td>-0.338430</td>
      <td>-0.904745</td>
      <td>0.358611</td>
      <td>0.640021</td>
      <td>-0.144367</td>
      <td>-0.237043</td>
      <td>-0.158449</td>
      <td>-0.179000</td>
      <td>-0.033359</td>
      <td>-0.375393</td>
      <td>...</td>
      <td>-0.617472</td>
      <td>1.141844</td>
      <td>0.396364</td>
      <td>0.539468</td>
      <td>-0.219807</td>
      <td>-0.121849</td>
      <td>-0.105065</td>
      <td>0.533493</td>
      <td>-0.039285</td>
      <td>-0.367195</td>
      <td>-0.216967</td>
      <td>-1.170098</td>
      <td>0.105256</td>
      <td>-0.101761</td>
      <td>0.016141</td>
      <td>1.012453</td>
      <td>-0.158715</td>
      <td>0.665083</td>
      <td>-0.027494</td>
      <td>-0.328893</td>
      <td>-0.459326</td>
      <td>-0.410354</td>
      <td>-0.658403</td>
      <td>0.287911</td>
      <td>-0.267852</td>
      <td>-0.068256</td>
      <td>-0.802133</td>
      <td>-0.004161</td>
      <td>-0.968963</td>
      <td>-1.116220</td>
      <td>0.527251</td>
      <td>-0.568000</td>
      <td>0.306621</td>
      <td>0.206421</td>
      <td>0.460232</td>
      <td>1.055747</td>
      <td>0.233743</td>
      <td>2.134702</td>
      <td>2.159735</td>
      <td>1.872017</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.085443</td>
      <td>-0.263462</td>
      <td>-0.291596</td>
      <td>-0.184512</td>
      <td>-0.904042</td>
      <td>-0.009114</td>
      <td>0.700103</td>
      <td>0.146784</td>
      <td>0.415457</td>
      <td>0.135949</td>
      <td>0.092969</td>
      <td>0.950364</td>
      <td>-0.528209</td>
      <td>-0.895944</td>
      <td>-1.219155</td>
      <td>-0.107178</td>
      <td>-0.016328</td>
      <td>0.540246</td>
      <td>-0.354488</td>
      <td>0.071145</td>
      <td>-0.016324</td>
      <td>-0.306366</td>
      <td>0.182160</td>
      <td>-0.432760</td>
      <td>-1.898347</td>
      <td>-0.012530</td>
      <td>0.362810</td>
      <td>0.524251</td>
      <td>0.641688</td>
      <td>0.492232</td>
      <td>0.048333</td>
      <td>0.571911</td>
      <td>0.098110</td>
      <td>-0.127894</td>
      <td>-0.798404</td>
      <td>-1.206940</td>
      <td>0.475155</td>
      <td>-0.129719</td>
      <td>0.685764</td>
      <td>0.001677</td>
      <td>...</td>
      <td>-0.276753</td>
      <td>0.841500</td>
      <td>-0.258227</td>
      <td>0.238193</td>
      <td>0.350484</td>
      <td>0.780101</td>
      <td>0.752060</td>
      <td>0.606458</td>
      <td>-0.226292</td>
      <td>-0.756584</td>
      <td>-1.674228</td>
      <td>-0.577300</td>
      <td>-0.601985</td>
      <td>0.379038</td>
      <td>0.256639</td>
      <td>0.273658</td>
      <td>-0.427079</td>
      <td>-1.534414</td>
      <td>-0.484360</td>
      <td>0.747026</td>
      <td>0.615887</td>
      <td>0.208214</td>
      <td>0.213773</td>
      <td>0.209063</td>
      <td>-0.988079</td>
      <td>-0.387499</td>
      <td>-1.338184</td>
      <td>-0.354095</td>
      <td>0.351799</td>
      <td>0.420533</td>
      <td>0.534440</td>
      <td>-0.482878</td>
      <td>0.845285</td>
      <td>0.735828</td>
      <td>1.331627</td>
      <td>-0.700186</td>
      <td>-0.742557</td>
      <td>-0.198988</td>
      <td>-0.249368</td>
      <td>-0.002836</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.859403</td>
      <td>-0.456375</td>
      <td>0.306189</td>
      <td>0.527365</td>
      <td>0.116234</td>
      <td>0.921158</td>
      <td>0.742682</td>
      <td>-0.005344</td>
      <td>0.530160</td>
      <td>0.253676</td>
      <td>0.233882</td>
      <td>-0.349088</td>
      <td>-0.541479</td>
      <td>-0.617902</td>
      <td>-1.394719</td>
      <td>-1.305904</td>
      <td>-0.374755</td>
      <td>-0.189641</td>
      <td>-0.176807</td>
      <td>0.013190</td>
      <td>-0.256713</td>
      <td>0.331045</td>
      <td>-0.416518</td>
      <td>-0.587849</td>
      <td>0.197191</td>
      <td>-0.660397</td>
      <td>0.801404</td>
      <td>-0.166685</td>
      <td>0.492161</td>
      <td>0.804881</td>
      <td>-0.064677</td>
      <td>-0.243966</td>
      <td>0.042223</td>
      <td>0.085093</td>
      <td>0.077187</td>
      <td>-0.421440</td>
      <td>-0.771811</td>
      <td>-0.637850</td>
      <td>0.505686</td>
      <td>-0.529033</td>
      <td>...</td>
      <td>-0.039128</td>
      <td>-0.268665</td>
      <td>0.346606</td>
      <td>-0.345381</td>
      <td>2.041461</td>
      <td>1.156680</td>
      <td>-0.045515</td>
      <td>-0.309782</td>
      <td>0.068137</td>
      <td>0.344774</td>
      <td>-1.526600</td>
      <td>0.250035</td>
      <td>0.492906</td>
      <td>-0.611389</td>
      <td>-0.409057</td>
      <td>-1.102848</td>
      <td>-0.620950</td>
      <td>0.547318</td>
      <td>0.394261</td>
      <td>0.275137</td>
      <td>0.073411</td>
      <td>-0.156799</td>
      <td>-0.150959</td>
      <td>-0.152012</td>
      <td>-0.967716</td>
      <td>-0.535149</td>
      <td>-0.389196</td>
      <td>0.571888</td>
      <td>-0.170063</td>
      <td>-0.696451</td>
      <td>-0.802725</td>
      <td>-1.121573</td>
      <td>-0.547130</td>
      <td>0.050159</td>
      <td>0.693403</td>
      <td>0.234117</td>
      <td>0.091115</td>
      <td>2.095543</td>
      <td>2.165170</td>
      <td>1.062268</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7fbff702bcd0&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.104624  0.041258  26.773834  6.519133e-158  1.023761  1.185488
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.525 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.4.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>