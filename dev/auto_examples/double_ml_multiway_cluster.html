
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.f6b7ca918bee2f46fd9abac01cfb07d5.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1e043a052b0af929e4d8.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">


    
    <a class="navbar-brand" href="../index.html">
      <p class="title">DoubleML</p>
    </a>
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  DoubleML
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/install.html">
  Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/intro.html">
  Getting started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../guide/guide.html">
  User guide
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api.html">
  Python API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference external nav-link" href="https://docs.doubleml.org/r/stable/">
  R API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../release/release.html">
  Release notes
 </a>
</li>

        
      </ul>

      <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><p class="logo" style="text-align:center;"><a href="../index.html">
    <img class="logo" src="../logo.png" alt="Logo" width="65%" height="65%">
</a></p><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l2 current active">
  <a class="current reference internal" href="#">
   Multiway Cluster Robust DML
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="double_ml_bonus_data.html">
   DML: Bonus Data
  </a>
 </li>
</ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulate-multiway-cluster-data">
   Simulate multiway cluster data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
   Initialize the objects of class DoubleMLData and DoubleMLPLIV
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#split-samples-and-transfer-the-sample-splitting-to-the-object">
   Split samples and transfer the sample splitting to the object
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fit-the-model-and-show-a-summary">
   Fit the model and show a summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing">
   Visualization of sample splitting with tuple and linear indexing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold">
     Visualize sample splitting with tuples (one plot per fold)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
     Visualize sample splitting with linear indexing (one column per fold)
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-0.737370</td>
      <td>-0.408352</td>
      <td>-0.500008</td>
      <td>-0.107758</td>
      <td>0.133900</td>
      <td>-0.143025</td>
      <td>0.230933</td>
      <td>0.134102</td>
      <td>0.198179</td>
      <td>0.837409</td>
      <td>0.333476</td>
      <td>0.355466</td>
      <td>-0.029276</td>
      <td>0.252058</td>
      <td>-1.312216</td>
      <td>0.937491</td>
      <td>0.094190</td>
      <td>0.187542</td>
      <td>0.677796</td>
      <td>0.645977</td>
      <td>0.270437</td>
      <td>0.021172</td>
      <td>-0.066447</td>
      <td>0.665274</td>
      <td>-0.178829</td>
      <td>0.734107</td>
      <td>0.962353</td>
      <td>0.124546</td>
      <td>-0.004678</td>
      <td>1.005519</td>
      <td>1.182101</td>
      <td>0.101550</td>
      <td>0.735885</td>
      <td>0.869459</td>
      <td>0.065318</td>
      <td>0.147620</td>
      <td>-0.163963</td>
      <td>-0.845784</td>
      <td>-0.292697</td>
      <td>0.221326</td>
      <td>...</td>
      <td>1.146076</td>
      <td>0.031993</td>
      <td>0.125365</td>
      <td>-0.031737</td>
      <td>-0.575806</td>
      <td>-0.099145</td>
      <td>-0.172480</td>
      <td>0.236075</td>
      <td>0.095596</td>
      <td>-0.002487</td>
      <td>0.164399</td>
      <td>-1.234803</td>
      <td>-0.426291</td>
      <td>-0.188210</td>
      <td>-0.495967</td>
      <td>0.155840</td>
      <td>-0.489503</td>
      <td>-0.152060</td>
      <td>-0.078733</td>
      <td>-0.305644</td>
      <td>-0.056718</td>
      <td>-0.004301</td>
      <td>0.655173</td>
      <td>0.868336</td>
      <td>0.657079</td>
      <td>0.570629</td>
      <td>0.367907</td>
      <td>1.082998</td>
      <td>0.898496</td>
      <td>0.451387</td>
      <td>0.650193</td>
      <td>-0.411256</td>
      <td>-0.562323</td>
      <td>-0.115917</td>
      <td>-0.833129</td>
      <td>-0.367719</td>
      <td>-0.793903</td>
      <td>-1.586449</td>
      <td>-1.235884</td>
      <td>-1.410787</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.149794</td>
      <td>0.664369</td>
      <td>-0.067404</td>
      <td>-0.180199</td>
      <td>0.848729</td>
      <td>0.482222</td>
      <td>-0.413149</td>
      <td>-0.681011</td>
      <td>0.112716</td>
      <td>-0.031849</td>
      <td>-0.229478</td>
      <td>0.041284</td>
      <td>-0.011766</td>
      <td>0.331034</td>
      <td>0.201642</td>
      <td>1.190449</td>
      <td>-0.242823</td>
      <td>-0.626774</td>
      <td>-0.089768</td>
      <td>0.124224</td>
      <td>0.225393</td>
      <td>0.804829</td>
      <td>0.993678</td>
      <td>-0.064284</td>
      <td>-1.251847</td>
      <td>-1.167386</td>
      <td>-1.102092</td>
      <td>-1.043215</td>
      <td>-0.667939</td>
      <td>0.033729</td>
      <td>-0.122190</td>
      <td>-1.568081</td>
      <td>0.101030</td>
      <td>-0.900673</td>
      <td>-0.251075</td>
      <td>-0.479763</td>
      <td>-0.499314</td>
      <td>-0.234973</td>
      <td>0.137468</td>
      <td>0.257939</td>
      <td>...</td>
      <td>-0.576597</td>
      <td>-0.859452</td>
      <td>0.194836</td>
      <td>0.956686</td>
      <td>-0.112866</td>
      <td>0.146225</td>
      <td>-0.404485</td>
      <td>0.102479</td>
      <td>0.403629</td>
      <td>0.403264</td>
      <td>0.884434</td>
      <td>0.684595</td>
      <td>-0.420486</td>
      <td>-0.711688</td>
      <td>-0.108844</td>
      <td>-0.224099</td>
      <td>0.877678</td>
      <td>0.102137</td>
      <td>0.209934</td>
      <td>0.550779</td>
      <td>0.996806</td>
      <td>1.441720</td>
      <td>0.046941</td>
      <td>0.836511</td>
      <td>-0.469721</td>
      <td>0.045914</td>
      <td>-0.073190</td>
      <td>0.101875</td>
      <td>1.088902</td>
      <td>-0.461803</td>
      <td>-0.364716</td>
      <td>-0.481222</td>
      <td>-0.396199</td>
      <td>-0.315560</td>
      <td>0.573772</td>
      <td>-0.075753</td>
      <td>-0.453170</td>
      <td>0.076716</td>
      <td>-0.407459</td>
      <td>-0.194354</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.200674</td>
      <td>0.306486</td>
      <td>-0.179481</td>
      <td>0.494628</td>
      <td>0.619289</td>
      <td>-0.347777</td>
      <td>-0.854059</td>
      <td>-0.122169</td>
      <td>0.766481</td>
      <td>0.600907</td>
      <td>0.051196</td>
      <td>0.242965</td>
      <td>-0.189723</td>
      <td>0.732622</td>
      <td>-0.388710</td>
      <td>1.084853</td>
      <td>-0.494909</td>
      <td>0.472196</td>
      <td>1.099192</td>
      <td>0.774191</td>
      <td>1.627515</td>
      <td>1.275383</td>
      <td>0.996973</td>
      <td>-0.490864</td>
      <td>-1.024993</td>
      <td>-0.212805</td>
      <td>0.753748</td>
      <td>-0.111869</td>
      <td>-0.429268</td>
      <td>0.476112</td>
      <td>-0.317075</td>
      <td>-0.520942</td>
      <td>-0.164923</td>
      <td>0.731928</td>
      <td>-0.115776</td>
      <td>1.054957</td>
      <td>0.198131</td>
      <td>0.987028</td>
      <td>0.602014</td>
      <td>0.367598</td>
      <td>...</td>
      <td>0.588449</td>
      <td>-0.694655</td>
      <td>0.475695</td>
      <td>0.988251</td>
      <td>0.738989</td>
      <td>1.192371</td>
      <td>-0.160359</td>
      <td>-0.012794</td>
      <td>-0.192263</td>
      <td>-0.467010</td>
      <td>-1.111097</td>
      <td>0.576234</td>
      <td>-0.022085</td>
      <td>0.251757</td>
      <td>-0.197136</td>
      <td>0.340789</td>
      <td>0.680375</td>
      <td>-0.116849</td>
      <td>-0.107763</td>
      <td>-0.189668</td>
      <td>-0.038014</td>
      <td>0.765702</td>
      <td>-0.176459</td>
      <td>0.582054</td>
      <td>0.508287</td>
      <td>1.195199</td>
      <td>0.252119</td>
      <td>0.068783</td>
      <td>0.458172</td>
      <td>0.740310</td>
      <td>0.022187</td>
      <td>0.437413</td>
      <td>-1.119154</td>
      <td>-0.662159</td>
      <td>-0.199715</td>
      <td>0.003421</td>
      <td>-0.434337</td>
      <td>-0.697875</td>
      <td>-0.732612</td>
      <td>-1.593130</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.121454</td>
      <td>0.288428</td>
      <td>0.062410</td>
      <td>-0.309320</td>
      <td>0.522074</td>
      <td>-0.511208</td>
      <td>-0.164167</td>
      <td>-0.420339</td>
      <td>-0.775518</td>
      <td>-0.267916</td>
      <td>0.609363</td>
      <td>0.428163</td>
      <td>0.289063</td>
      <td>-0.752359</td>
      <td>-0.467898</td>
      <td>0.478782</td>
      <td>-0.135508</td>
      <td>0.145453</td>
      <td>-0.250518</td>
      <td>-0.488211</td>
      <td>0.140764</td>
      <td>1.484922</td>
      <td>0.074436</td>
      <td>-0.437554</td>
      <td>-0.063497</td>
      <td>-0.078214</td>
      <td>-0.160695</td>
      <td>0.128861</td>
      <td>-0.237698</td>
      <td>-0.095345</td>
      <td>-0.631572</td>
      <td>0.130106</td>
      <td>0.563562</td>
      <td>-0.472140</td>
      <td>0.615060</td>
      <td>-0.106685</td>
      <td>-1.507403</td>
      <td>0.568585</td>
      <td>-0.316948</td>
      <td>0.208126</td>
      <td>...</td>
      <td>0.758234</td>
      <td>-0.008199</td>
      <td>1.189930</td>
      <td>0.935538</td>
      <td>0.067942</td>
      <td>0.134507</td>
      <td>-1.206106</td>
      <td>-0.657386</td>
      <td>-0.305660</td>
      <td>0.396112</td>
      <td>-0.123721</td>
      <td>0.447183</td>
      <td>-0.857022</td>
      <td>-0.504323</td>
      <td>0.586374</td>
      <td>1.246847</td>
      <td>0.547571</td>
      <td>1.451230</td>
      <td>0.279702</td>
      <td>-0.423363</td>
      <td>-0.647367</td>
      <td>-0.549054</td>
      <td>0.134409</td>
      <td>0.415907</td>
      <td>0.012423</td>
      <td>1.011348</td>
      <td>1.021647</td>
      <td>-0.169576</td>
      <td>-1.070106</td>
      <td>-0.310933</td>
      <td>-0.387732</td>
      <td>-0.319836</td>
      <td>-0.375015</td>
      <td>-0.099273</td>
      <td>0.799359</td>
      <td>-0.628204</td>
      <td>-0.650457</td>
      <td>2.251526</td>
      <td>0.831007</td>
      <td>0.303110</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.678287</td>
      <td>0.795687</td>
      <td>0.615946</td>
      <td>-0.786117</td>
      <td>-0.235678</td>
      <td>0.349731</td>
      <td>0.413240</td>
      <td>-0.224688</td>
      <td>0.065964</td>
      <td>-0.138121</td>
      <td>0.079050</td>
      <td>0.890820</td>
      <td>-0.545632</td>
      <td>-0.160876</td>
      <td>-0.494437</td>
      <td>0.460856</td>
      <td>-0.677323</td>
      <td>0.676057</td>
      <td>0.579202</td>
      <td>0.581357</td>
      <td>1.105089</td>
      <td>-0.129277</td>
      <td>0.719124</td>
      <td>0.334593</td>
      <td>-0.296854</td>
      <td>0.287407</td>
      <td>0.315532</td>
      <td>-0.240501</td>
      <td>-1.141524</td>
      <td>0.404445</td>
      <td>0.496681</td>
      <td>0.478997</td>
      <td>0.495550</td>
      <td>-0.096297</td>
      <td>-1.038286</td>
      <td>-0.453984</td>
      <td>-0.845380</td>
      <td>-0.196337</td>
      <td>-0.683699</td>
      <td>0.933744</td>
      <td>...</td>
      <td>-0.029962</td>
      <td>-0.259559</td>
      <td>-0.706643</td>
      <td>0.117427</td>
      <td>0.176984</td>
      <td>0.556844</td>
      <td>-0.325293</td>
      <td>0.160325</td>
      <td>-0.659558</td>
      <td>0.164590</td>
      <td>-0.356277</td>
      <td>0.199378</td>
      <td>-0.986121</td>
      <td>-0.373756</td>
      <td>0.049586</td>
      <td>-1.139615</td>
      <td>-1.147760</td>
      <td>0.957625</td>
      <td>-0.562925</td>
      <td>-0.307293</td>
      <td>0.146025</td>
      <td>-0.161758</td>
      <td>0.431037</td>
      <td>0.448624</td>
      <td>0.371907</td>
      <td>-0.097305</td>
      <td>-0.306089</td>
      <td>0.100795</td>
      <td>-0.280589</td>
      <td>0.135245</td>
      <td>-0.362972</td>
      <td>0.412164</td>
      <td>-0.249003</td>
      <td>-0.110137</td>
      <td>-0.565270</td>
      <td>-0.001947</td>
      <td>-0.238598</td>
      <td>0.978847</td>
      <td>1.009853</td>
      <td>0.752575</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.641736</td>
      <td>-0.661618</td>
      <td>-0.968729</td>
      <td>-0.317004</td>
      <td>-0.496716</td>
      <td>-0.759604</td>
      <td>-0.025525</td>
      <td>-1.051080</td>
      <td>-0.258652</td>
      <td>-0.239348</td>
      <td>0.156321</td>
      <td>0.398114</td>
      <td>-0.591076</td>
      <td>-0.090169</td>
      <td>-0.483165</td>
      <td>-0.288154</td>
      <td>0.163747</td>
      <td>0.332984</td>
      <td>-0.210263</td>
      <td>0.069614</td>
      <td>0.470504</td>
      <td>-0.226127</td>
      <td>0.532363</td>
      <td>0.640273</td>
      <td>-0.448251</td>
      <td>-0.761993</td>
      <td>-0.699821</td>
      <td>0.008669</td>
      <td>-0.729384</td>
      <td>-1.219144</td>
      <td>-0.833267</td>
      <td>-1.207977</td>
      <td>0.588167</td>
      <td>-0.119774</td>
      <td>0.357426</td>
      <td>1.474956</td>
      <td>0.709713</td>
      <td>0.361034</td>
      <td>-0.363353</td>
      <td>-0.757738</td>
      <td>...</td>
      <td>1.940128</td>
      <td>0.527964</td>
      <td>0.039741</td>
      <td>0.312633</td>
      <td>0.814396</td>
      <td>0.983443</td>
      <td>0.088150</td>
      <td>0.018762</td>
      <td>0.048125</td>
      <td>-0.659225</td>
      <td>-0.191272</td>
      <td>-0.084187</td>
      <td>-0.197254</td>
      <td>0.198204</td>
      <td>-0.138385</td>
      <td>-0.588846</td>
      <td>-0.642207</td>
      <td>-0.083722</td>
      <td>-0.373638</td>
      <td>0.508374</td>
      <td>0.211363</td>
      <td>-0.528258</td>
      <td>0.401235</td>
      <td>0.754457</td>
      <td>-0.248499</td>
      <td>0.788855</td>
      <td>-0.177885</td>
      <td>0.382477</td>
      <td>0.611145</td>
      <td>0.475304</td>
      <td>-0.370087</td>
      <td>-0.548339</td>
      <td>-0.370217</td>
      <td>-0.114932</td>
      <td>-0.083228</td>
      <td>0.490612</td>
      <td>-0.106795</td>
      <td>-0.809257</td>
      <td>-0.880025</td>
      <td>-0.512918</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.696114</td>
      <td>-0.382777</td>
      <td>-1.262993</td>
      <td>-0.525482</td>
      <td>-0.388779</td>
      <td>-0.234891</td>
      <td>0.766628</td>
      <td>1.246239</td>
      <td>0.477574</td>
      <td>-0.673779</td>
      <td>0.188716</td>
      <td>-0.213399</td>
      <td>0.392918</td>
      <td>0.210035</td>
      <td>0.452773</td>
      <td>0.772988</td>
      <td>-0.042534</td>
      <td>-0.819560</td>
      <td>0.029063</td>
      <td>0.279864</td>
      <td>-0.193571</td>
      <td>0.087825</td>
      <td>0.274171</td>
      <td>0.053265</td>
      <td>-1.107359</td>
      <td>0.216010</td>
      <td>0.117853</td>
      <td>-0.181285</td>
      <td>0.635293</td>
      <td>0.294919</td>
      <td>0.094151</td>
      <td>0.102476</td>
      <td>-0.316441</td>
      <td>0.058170</td>
      <td>0.532240</td>
      <td>-0.090096</td>
      <td>-0.175739</td>
      <td>0.639057</td>
      <td>-0.261063</td>
      <td>-0.765278</td>
      <td>...</td>
      <td>-0.395518</td>
      <td>-0.775552</td>
      <td>-0.756246</td>
      <td>-0.715464</td>
      <td>0.113305</td>
      <td>0.528316</td>
      <td>-0.410141</td>
      <td>-0.783708</td>
      <td>-0.480916</td>
      <td>0.102000</td>
      <td>-0.522484</td>
      <td>0.265151</td>
      <td>-0.329998</td>
      <td>0.582169</td>
      <td>0.225776</td>
      <td>-0.282461</td>
      <td>0.777582</td>
      <td>-0.174200</td>
      <td>-1.047157</td>
      <td>-0.324106</td>
      <td>0.411335</td>
      <td>0.145147</td>
      <td>0.582242</td>
      <td>0.421108</td>
      <td>-0.138126</td>
      <td>-0.115792</td>
      <td>-0.110386</td>
      <td>0.312825</td>
      <td>0.467533</td>
      <td>0.681642</td>
      <td>0.747055</td>
      <td>-0.229328</td>
      <td>-0.150916</td>
      <td>0.115470</td>
      <td>0.419822</td>
      <td>0.762768</td>
      <td>-0.344650</td>
      <td>0.261929</td>
      <td>0.335948</td>
      <td>0.353933</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.190992</td>
      <td>0.275462</td>
      <td>0.614266</td>
      <td>-0.144798</td>
      <td>-0.137750</td>
      <td>-0.359724</td>
      <td>0.117829</td>
      <td>0.308869</td>
      <td>-0.143393</td>
      <td>-0.907250</td>
      <td>0.461142</td>
      <td>-0.528939</td>
      <td>0.186635</td>
      <td>0.707664</td>
      <td>0.367269</td>
      <td>0.662492</td>
      <td>-0.628102</td>
      <td>-1.244844</td>
      <td>-0.355027</td>
      <td>0.494177</td>
      <td>-0.656312</td>
      <td>0.079536</td>
      <td>0.640022</td>
      <td>0.052936</td>
      <td>0.383871</td>
      <td>1.003200</td>
      <td>0.936276</td>
      <td>0.045112</td>
      <td>0.695872</td>
      <td>1.000592</td>
      <td>0.581946</td>
      <td>-0.528029</td>
      <td>-0.218650</td>
      <td>0.076762</td>
      <td>-0.384313</td>
      <td>-0.316864</td>
      <td>-1.303804</td>
      <td>-0.034655</td>
      <td>0.407734</td>
      <td>-0.345353</td>
      <td>...</td>
      <td>0.372910</td>
      <td>-1.333515</td>
      <td>-0.492452</td>
      <td>0.148253</td>
      <td>-0.740246</td>
      <td>-0.571509</td>
      <td>-0.893399</td>
      <td>-0.248256</td>
      <td>-1.227006</td>
      <td>-0.329916</td>
      <td>0.626831</td>
      <td>0.534668</td>
      <td>-0.053533</td>
      <td>-0.241078</td>
      <td>0.803663</td>
      <td>0.049550</td>
      <td>1.104227</td>
      <td>0.827762</td>
      <td>-0.821981</td>
      <td>0.057464</td>
      <td>1.494686</td>
      <td>0.413300</td>
      <td>0.266768</td>
      <td>0.827296</td>
      <td>-0.655739</td>
      <td>-0.375197</td>
      <td>-0.405643</td>
      <td>0.130714</td>
      <td>0.371707</td>
      <td>0.423069</td>
      <td>-0.407607</td>
      <td>-0.031008</td>
      <td>0.995964</td>
      <td>-0.515623</td>
      <td>-0.095937</td>
      <td>0.426396</td>
      <td>0.224401</td>
      <td>0.911962</td>
      <td>0.837584</td>
      <td>-0.537448</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.307725</td>
      <td>-0.445787</td>
      <td>0.292357</td>
      <td>-0.057022</td>
      <td>-0.152874</td>
      <td>-0.512624</td>
      <td>0.996012</td>
      <td>0.686857</td>
      <td>-0.689438</td>
      <td>-0.588877</td>
      <td>-0.808545</td>
      <td>0.436158</td>
      <td>-0.414555</td>
      <td>-0.037511</td>
      <td>0.371439</td>
      <td>0.166823</td>
      <td>0.477854</td>
      <td>0.628989</td>
      <td>0.182729</td>
      <td>-1.155652</td>
      <td>0.649392</td>
      <td>-0.454919</td>
      <td>0.606365</td>
      <td>0.291823</td>
      <td>-0.395318</td>
      <td>-0.082009</td>
      <td>0.750971</td>
      <td>-0.758933</td>
      <td>-0.251161</td>
      <td>0.777115</td>
      <td>0.037445</td>
      <td>-0.851738</td>
      <td>-1.512850</td>
      <td>-0.118830</td>
      <td>-0.437220</td>
      <td>-0.365020</td>
      <td>-0.611566</td>
      <td>-0.950495</td>
      <td>0.097055</td>
      <td>-1.148214</td>
      <td>...</td>
      <td>0.808634</td>
      <td>-1.050696</td>
      <td>-0.035146</td>
      <td>-0.073470</td>
      <td>-0.477003</td>
      <td>-1.115155</td>
      <td>0.049209</td>
      <td>0.006751</td>
      <td>0.130157</td>
      <td>-0.226585</td>
      <td>-0.494560</td>
      <td>0.174538</td>
      <td>-0.679355</td>
      <td>0.908373</td>
      <td>0.633490</td>
      <td>-0.249957</td>
      <td>0.621134</td>
      <td>0.080718</td>
      <td>0.146644</td>
      <td>-0.847916</td>
      <td>0.519144</td>
      <td>1.054518</td>
      <td>0.938481</td>
      <td>0.669547</td>
      <td>0.720057</td>
      <td>1.104741</td>
      <td>0.349063</td>
      <td>0.114240</td>
      <td>-0.241807</td>
      <td>0.868139</td>
      <td>0.056019</td>
      <td>-0.565000</td>
      <td>0.206414</td>
      <td>-0.688863</td>
      <td>0.541035</td>
      <td>-0.169344</td>
      <td>-0.744810</td>
      <td>3.308075</td>
      <td>1.568643</td>
      <td>0.160791</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-0.818762</td>
      <td>-0.037004</td>
      <td>-0.934691</td>
      <td>-0.293992</td>
      <td>-0.597154</td>
      <td>-0.639273</td>
      <td>0.870593</td>
      <td>-0.010118</td>
      <td>0.455013</td>
      <td>0.064285</td>
      <td>0.917786</td>
      <td>-0.282153</td>
      <td>-1.329225</td>
      <td>0.089050</td>
      <td>-0.277976</td>
      <td>0.838476</td>
      <td>0.113181</td>
      <td>-0.803748</td>
      <td>0.500143</td>
      <td>0.827569</td>
      <td>0.489582</td>
      <td>0.028697</td>
      <td>0.584934</td>
      <td>0.047385</td>
      <td>-0.485361</td>
      <td>1.182801</td>
      <td>0.753237</td>
      <td>-0.076988</td>
      <td>-0.324503</td>
      <td>0.399951</td>
      <td>0.411601</td>
      <td>0.547218</td>
      <td>-0.751778</td>
      <td>0.681982</td>
      <td>0.129763</td>
      <td>-0.166025</td>
      <td>0.829090</td>
      <td>-0.321379</td>
      <td>0.124543</td>
      <td>0.427075</td>
      <td>...</td>
      <td>0.845679</td>
      <td>-0.316384</td>
      <td>-0.081648</td>
      <td>0.818308</td>
      <td>0.271989</td>
      <td>0.246233</td>
      <td>0.303463</td>
      <td>0.190126</td>
      <td>-0.035501</td>
      <td>0.587035</td>
      <td>0.465495</td>
      <td>0.615551</td>
      <td>-0.638734</td>
      <td>-0.011126</td>
      <td>0.014694</td>
      <td>0.088868</td>
      <td>0.485497</td>
      <td>-0.072819</td>
      <td>0.042290</td>
      <td>-0.515405</td>
      <td>-0.350143</td>
      <td>0.119138</td>
      <td>0.051839</td>
      <td>0.897667</td>
      <td>0.519990</td>
      <td>0.208969</td>
      <td>-0.454879</td>
      <td>0.909948</td>
      <td>1.051621</td>
      <td>0.354816</td>
      <td>-0.128628</td>
      <td>-0.337949</td>
      <td>0.148443</td>
      <td>0.430939</td>
      <td>0.150241</td>
      <td>0.481835</td>
      <td>0.268607</td>
      <td>-1.806231</td>
      <td>-1.767031</td>
      <td>-0.674978</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-0.550430</td>
      <td>-0.255342</td>
      <td>0.042654</td>
      <td>0.477057</td>
      <td>-0.553397</td>
      <td>-0.609866</td>
      <td>0.507014</td>
      <td>1.604594</td>
      <td>0.830906</td>
      <td>0.432927</td>
      <td>-1.237958</td>
      <td>-0.891754</td>
      <td>-1.290412</td>
      <td>0.288315</td>
      <td>-0.538816</td>
      <td>1.026501</td>
      <td>-0.736171</td>
      <td>-0.662827</td>
      <td>-0.618467</td>
      <td>0.924491</td>
      <td>1.303465</td>
      <td>0.870256</td>
      <td>0.568623</td>
      <td>0.105077</td>
      <td>-0.942200</td>
      <td>0.159274</td>
      <td>1.028394</td>
      <td>0.040824</td>
      <td>-1.341681</td>
      <td>-0.004083</td>
      <td>0.109845</td>
      <td>0.544488</td>
      <td>0.968179</td>
      <td>-0.012488</td>
      <td>-0.423733</td>
      <td>0.639338</td>
      <td>-1.134417</td>
      <td>-0.586008</td>
      <td>-0.735373</td>
      <td>-0.265442</td>
      <td>...</td>
      <td>0.395462</td>
      <td>-0.620006</td>
      <td>-1.068834</td>
      <td>-0.296390</td>
      <td>0.021718</td>
      <td>0.333131</td>
      <td>-0.310418</td>
      <td>0.561526</td>
      <td>-1.263737</td>
      <td>-0.112608</td>
      <td>0.843731</td>
      <td>0.404709</td>
      <td>-1.426637</td>
      <td>-0.074112</td>
      <td>0.134355</td>
      <td>0.083786</td>
      <td>0.515160</td>
      <td>-0.091970</td>
      <td>0.072986</td>
      <td>-0.091891</td>
      <td>-0.675763</td>
      <td>0.971372</td>
      <td>1.445397</td>
      <td>0.809176</td>
      <td>0.277684</td>
      <td>0.392751</td>
      <td>0.456055</td>
      <td>0.511499</td>
      <td>-0.188960</td>
      <td>-0.665588</td>
      <td>0.236789</td>
      <td>0.332467</td>
      <td>0.436042</td>
      <td>0.175936</td>
      <td>0.078390</td>
      <td>0.862346</td>
      <td>0.127159</td>
      <td>-0.970514</td>
      <td>-0.289756</td>
      <td>-0.385972</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.636271</td>
      <td>-0.266085</td>
      <td>0.633047</td>
      <td>0.447168</td>
      <td>-0.447804</td>
      <td>-0.493200</td>
      <td>0.671916</td>
      <td>0.343323</td>
      <td>0.447625</td>
      <td>-0.472972</td>
      <td>0.525255</td>
      <td>0.698318</td>
      <td>0.266613</td>
      <td>0.226028</td>
      <td>-1.316217</td>
      <td>0.890355</td>
      <td>0.575617</td>
      <td>0.848814</td>
      <td>1.444720</td>
      <td>0.417189</td>
      <td>0.641532</td>
      <td>0.056670</td>
      <td>0.108585</td>
      <td>0.326148</td>
      <td>-0.593750</td>
      <td>0.631357</td>
      <td>1.136499</td>
      <td>-0.041263</td>
      <td>-1.097582</td>
      <td>0.658865</td>
      <td>0.265049</td>
      <td>0.216418</td>
      <td>0.364263</td>
      <td>-0.194825</td>
      <td>-1.131015</td>
      <td>0.434987</td>
      <td>-0.941670</td>
      <td>1.513376</td>
      <td>0.731281</td>
      <td>-1.155727</td>
      <td>...</td>
      <td>-0.407254</td>
      <td>-0.249912</td>
      <td>-0.778883</td>
      <td>-0.963310</td>
      <td>-0.494912</td>
      <td>-0.341574</td>
      <td>-0.483800</td>
      <td>-0.685319</td>
      <td>-1.278148</td>
      <td>-0.075836</td>
      <td>-0.176044</td>
      <td>0.059898</td>
      <td>-0.367141</td>
      <td>0.106629</td>
      <td>-0.298559</td>
      <td>-0.006499</td>
      <td>0.278548</td>
      <td>0.687459</td>
      <td>0.346128</td>
      <td>-0.015541</td>
      <td>-0.858723</td>
      <td>0.322525</td>
      <td>0.719640</td>
      <td>-0.119279</td>
      <td>0.508472</td>
      <td>0.712038</td>
      <td>-0.284293</td>
      <td>0.602449</td>
      <td>0.860787</td>
      <td>-0.373733</td>
      <td>-0.533147</td>
      <td>-0.834868</td>
      <td>-1.264874</td>
      <td>0.063418</td>
      <td>0.208692</td>
      <td>-0.080386</td>
      <td>-0.120555</td>
      <td>-1.828927</td>
      <td>-1.711764</td>
      <td>-0.969292</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.133062</td>
      <td>-0.317685</td>
      <td>-0.169861</td>
      <td>-0.089479</td>
      <td>0.515326</td>
      <td>0.211527</td>
      <td>-0.070825</td>
      <td>0.315485</td>
      <td>1.173077</td>
      <td>0.919732</td>
      <td>0.132289</td>
      <td>-0.160864</td>
      <td>-0.440754</td>
      <td>0.449106</td>
      <td>-1.115160</td>
      <td>-0.177482</td>
      <td>-0.515960</td>
      <td>-0.676352</td>
      <td>-0.804913</td>
      <td>1.376564</td>
      <td>1.123713</td>
      <td>-0.397564</td>
      <td>-0.392606</td>
      <td>-0.203957</td>
      <td>-0.329838</td>
      <td>-0.883721</td>
      <td>0.202104</td>
      <td>-0.353156</td>
      <td>-0.153521</td>
      <td>0.291822</td>
      <td>0.337320</td>
      <td>0.293481</td>
      <td>0.326030</td>
      <td>-0.375126</td>
      <td>-0.666857</td>
      <td>-0.789505</td>
      <td>-0.522765</td>
      <td>0.760472</td>
      <td>0.430102</td>
      <td>-0.675392</td>
      <td>...</td>
      <td>0.015727</td>
      <td>-0.635894</td>
      <td>-0.572251</td>
      <td>0.684901</td>
      <td>0.085473</td>
      <td>0.000321</td>
      <td>0.073910</td>
      <td>0.500030</td>
      <td>-0.877561</td>
      <td>-0.453542</td>
      <td>0.019434</td>
      <td>0.691065</td>
      <td>-0.076445</td>
      <td>0.219232</td>
      <td>-0.157995</td>
      <td>0.991508</td>
      <td>0.769577</td>
      <td>1.536923</td>
      <td>-0.191536</td>
      <td>0.247986</td>
      <td>-0.199171</td>
      <td>-0.170967</td>
      <td>1.500743</td>
      <td>1.279723</td>
      <td>0.577225</td>
      <td>0.185685</td>
      <td>0.151447</td>
      <td>1.178529</td>
      <td>0.784003</td>
      <td>-0.364909</td>
      <td>0.346991</td>
      <td>-0.010870</td>
      <td>0.208014</td>
      <td>0.025423</td>
      <td>-0.085602</td>
      <td>-0.330538</td>
      <td>0.754385</td>
      <td>1.944838</td>
      <td>1.576579</td>
      <td>0.427557</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.575744</td>
      <td>0.547298</td>
      <td>0.287910</td>
      <td>-0.136290</td>
      <td>0.655371</td>
      <td>0.980285</td>
      <td>0.409424</td>
      <td>-0.715702</td>
      <td>-0.754738</td>
      <td>0.820134</td>
      <td>0.444342</td>
      <td>0.207263</td>
      <td>1.315335</td>
      <td>0.961907</td>
      <td>0.357291</td>
      <td>1.012097</td>
      <td>0.661166</td>
      <td>-0.270962</td>
      <td>-0.800317</td>
      <td>0.081205</td>
      <td>0.182360</td>
      <td>-0.892359</td>
      <td>-0.678826</td>
      <td>-1.113876</td>
      <td>-0.407806</td>
      <td>-0.978448</td>
      <td>0.101328</td>
      <td>-0.481748</td>
      <td>-0.567782</td>
      <td>-0.114871</td>
      <td>-0.491282</td>
      <td>0.405314</td>
      <td>-0.880903</td>
      <td>1.090961</td>
      <td>0.167036</td>
      <td>1.040987</td>
      <td>0.949866</td>
      <td>0.433116</td>
      <td>0.370425</td>
      <td>-0.966418</td>
      <td>...</td>
      <td>0.286362</td>
      <td>-0.857339</td>
      <td>-0.038098</td>
      <td>0.284108</td>
      <td>-0.155357</td>
      <td>-0.412024</td>
      <td>0.054965</td>
      <td>-0.377359</td>
      <td>0.351324</td>
      <td>-1.081325</td>
      <td>-0.065833</td>
      <td>0.653329</td>
      <td>0.161621</td>
      <td>0.556807</td>
      <td>-0.557864</td>
      <td>-1.151019</td>
      <td>-0.229729</td>
      <td>-0.073796</td>
      <td>-0.418220</td>
      <td>0.303353</td>
      <td>-0.485920</td>
      <td>-0.048002</td>
      <td>-0.128160</td>
      <td>-0.077625</td>
      <td>0.107403</td>
      <td>-0.991810</td>
      <td>-0.795206</td>
      <td>-0.066768</td>
      <td>0.452411</td>
      <td>0.563566</td>
      <td>-0.446569</td>
      <td>-0.802397</td>
      <td>-0.290999</td>
      <td>-0.202400</td>
      <td>-0.625797</td>
      <td>0.012835</td>
      <td>0.497011</td>
      <td>1.892162</td>
      <td>1.258778</td>
      <td>0.513510</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.744808</td>
      <td>0.085871</td>
      <td>-0.414665</td>
      <td>0.245194</td>
      <td>0.374663</td>
      <td>-0.202763</td>
      <td>0.020245</td>
      <td>0.095208</td>
      <td>0.846302</td>
      <td>0.962048</td>
      <td>0.820952</td>
      <td>-0.423233</td>
      <td>0.386017</td>
      <td>1.336785</td>
      <td>-0.284021</td>
      <td>0.069226</td>
      <td>-0.595890</td>
      <td>-0.146925</td>
      <td>-0.685100</td>
      <td>-0.477372</td>
      <td>1.130294</td>
      <td>0.077017</td>
      <td>1.758590</td>
      <td>0.200099</td>
      <td>0.528957</td>
      <td>1.401839</td>
      <td>0.947427</td>
      <td>-0.595481</td>
      <td>-0.229994</td>
      <td>0.809554</td>
      <td>-0.087658</td>
      <td>0.042816</td>
      <td>0.958286</td>
      <td>-0.108937</td>
      <td>0.239032</td>
      <td>1.446728</td>
      <td>0.111053</td>
      <td>0.240924</td>
      <td>0.168505</td>
      <td>-0.201614</td>
      <td>...</td>
      <td>-0.338365</td>
      <td>-1.020072</td>
      <td>0.059239</td>
      <td>0.422511</td>
      <td>-0.533704</td>
      <td>0.561725</td>
      <td>0.617019</td>
      <td>0.201207</td>
      <td>0.768488</td>
      <td>-0.201688</td>
      <td>-0.139910</td>
      <td>-1.013641</td>
      <td>-0.810204</td>
      <td>-0.572268</td>
      <td>0.061560</td>
      <td>0.030524</td>
      <td>-0.821370</td>
      <td>0.088784</td>
      <td>-1.355131</td>
      <td>0.811526</td>
      <td>-0.635762</td>
      <td>-0.291077</td>
      <td>0.404727</td>
      <td>0.302953</td>
      <td>-0.834401</td>
      <td>-0.662646</td>
      <td>0.732492</td>
      <td>0.823034</td>
      <td>0.579610</td>
      <td>-0.588644</td>
      <td>0.133084</td>
      <td>0.145492</td>
      <td>0.622259</td>
      <td>-0.351897</td>
      <td>-0.160530</td>
      <td>0.729855</td>
      <td>0.624792</td>
      <td>3.891179</td>
      <td>2.886189</td>
      <td>1.360812</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-0.174068</td>
      <td>-0.906097</td>
      <td>0.150626</td>
      <td>-0.429226</td>
      <td>-0.145781</td>
      <td>0.076209</td>
      <td>0.346343</td>
      <td>0.230266</td>
      <td>-0.007477</td>
      <td>-1.082142</td>
      <td>1.310032</td>
      <td>-0.022508</td>
      <td>0.491846</td>
      <td>-1.101350</td>
      <td>-0.663768</td>
      <td>-0.090665</td>
      <td>-0.284769</td>
      <td>0.763158</td>
      <td>-0.351343</td>
      <td>-0.019350</td>
      <td>-0.484792</td>
      <td>-0.410442</td>
      <td>-0.261537</td>
      <td>-0.285421</td>
      <td>-0.154930</td>
      <td>0.727003</td>
      <td>0.276518</td>
      <td>-0.295575</td>
      <td>0.310356</td>
      <td>1.682407</td>
      <td>-0.192939</td>
      <td>-0.838240</td>
      <td>-1.008130</td>
      <td>-0.226153</td>
      <td>0.257597</td>
      <td>0.548482</td>
      <td>-1.662907</td>
      <td>0.396962</td>
      <td>0.774178</td>
      <td>0.586490</td>
      <td>...</td>
      <td>0.835041</td>
      <td>-0.149399</td>
      <td>-0.737498</td>
      <td>1.089075</td>
      <td>-0.494877</td>
      <td>1.016125</td>
      <td>-0.161376</td>
      <td>0.609645</td>
      <td>0.677310</td>
      <td>-1.038989</td>
      <td>0.975711</td>
      <td>0.063775</td>
      <td>-0.843045</td>
      <td>-0.319085</td>
      <td>-0.845263</td>
      <td>-0.069846</td>
      <td>1.251674</td>
      <td>1.538075</td>
      <td>0.001931</td>
      <td>0.415570</td>
      <td>0.434701</td>
      <td>0.150070</td>
      <td>0.513263</td>
      <td>0.199047</td>
      <td>0.353796</td>
      <td>0.302190</td>
      <td>-0.735311</td>
      <td>-0.907390</td>
      <td>0.415168</td>
      <td>-0.357720</td>
      <td>-0.785136</td>
      <td>-1.088956</td>
      <td>-0.353970</td>
      <td>-1.262540</td>
      <td>-0.279898</td>
      <td>-1.239291</td>
      <td>0.328212</td>
      <td>-1.210177</td>
      <td>-1.478199</td>
      <td>-0.587876</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-0.083552</td>
      <td>-0.663060</td>
      <td>-2.083517</td>
      <td>-0.565708</td>
      <td>0.297853</td>
      <td>-0.483305</td>
      <td>0.157186</td>
      <td>0.744435</td>
      <td>0.283574</td>
      <td>-1.370862</td>
      <td>0.198155</td>
      <td>0.066850</td>
      <td>-0.210856</td>
      <td>-0.963307</td>
      <td>-0.857811</td>
      <td>0.335639</td>
      <td>-1.130965</td>
      <td>-0.011856</td>
      <td>-0.012464</td>
      <td>-0.245037</td>
      <td>0.724684</td>
      <td>0.100977</td>
      <td>-0.263600</td>
      <td>0.750106</td>
      <td>-0.020205</td>
      <td>-0.064090</td>
      <td>0.322331</td>
      <td>0.336993</td>
      <td>-0.768218</td>
      <td>-0.601097</td>
      <td>-1.126561</td>
      <td>-1.860684</td>
      <td>-0.729115</td>
      <td>-0.707748</td>
      <td>-1.152354</td>
      <td>0.361138</td>
      <td>0.544986</td>
      <td>0.712744</td>
      <td>0.690264</td>
      <td>0.057894</td>
      <td>...</td>
      <td>0.755674</td>
      <td>-1.826550</td>
      <td>-0.818238</td>
      <td>0.365669</td>
      <td>0.132848</td>
      <td>0.023885</td>
      <td>0.024528</td>
      <td>-0.242006</td>
      <td>0.602787</td>
      <td>0.861139</td>
      <td>0.451646</td>
      <td>0.416709</td>
      <td>0.171887</td>
      <td>-0.713077</td>
      <td>0.796390</td>
      <td>0.488294</td>
      <td>0.055602</td>
      <td>0.250347</td>
      <td>0.742031</td>
      <td>-0.164727</td>
      <td>-0.365085</td>
      <td>-0.329806</td>
      <td>-0.350679</td>
      <td>-0.382079</td>
      <td>-0.834344</td>
      <td>-0.775472</td>
      <td>-0.180248</td>
      <td>0.852921</td>
      <td>-0.355658</td>
      <td>-0.328920</td>
      <td>-0.051681</td>
      <td>-0.399722</td>
      <td>0.053876</td>
      <td>0.075906</td>
      <td>0.560376</td>
      <td>-0.034627</td>
      <td>-0.271348</td>
      <td>-3.131568</td>
      <td>-2.090035</td>
      <td>-1.767335</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.427203</td>
      <td>-0.952432</td>
      <td>-0.641626</td>
      <td>-0.421939</td>
      <td>-0.715378</td>
      <td>-0.770641</td>
      <td>0.478924</td>
      <td>1.050609</td>
      <td>1.178876</td>
      <td>-0.075762</td>
      <td>0.423360</td>
      <td>0.587841</td>
      <td>0.412660</td>
      <td>1.246472</td>
      <td>-0.090100</td>
      <td>-0.078039</td>
      <td>-0.563581</td>
      <td>-0.343820</td>
      <td>-0.343178</td>
      <td>0.417097</td>
      <td>1.208558</td>
      <td>-0.350116</td>
      <td>0.329966</td>
      <td>-0.134599</td>
      <td>-0.149010</td>
      <td>0.860184</td>
      <td>0.071119</td>
      <td>-0.627221</td>
      <td>-0.180035</td>
      <td>0.466575</td>
      <td>-0.182887</td>
      <td>-0.228619</td>
      <td>-0.596617</td>
      <td>-0.249746</td>
      <td>-0.359935</td>
      <td>0.247253</td>
      <td>-0.269900</td>
      <td>0.982669</td>
      <td>0.973299</td>
      <td>0.349390</td>
      <td>...</td>
      <td>-0.467452</td>
      <td>-0.375272</td>
      <td>-0.924524</td>
      <td>-0.994085</td>
      <td>-0.495807</td>
      <td>-0.091021</td>
      <td>0.036391</td>
      <td>0.590678</td>
      <td>-0.973657</td>
      <td>0.049465</td>
      <td>0.351310</td>
      <td>1.053403</td>
      <td>-0.710057</td>
      <td>0.661308</td>
      <td>1.318700</td>
      <td>-0.257903</td>
      <td>0.749708</td>
      <td>-0.386791</td>
      <td>-0.098481</td>
      <td>-0.701539</td>
      <td>-0.673358</td>
      <td>-1.754824</td>
      <td>-0.205539</td>
      <td>0.166408</td>
      <td>0.220102</td>
      <td>0.101908</td>
      <td>0.297227</td>
      <td>-0.378608</td>
      <td>0.072886</td>
      <td>0.020508</td>
      <td>0.373743</td>
      <td>0.287584</td>
      <td>0.669197</td>
      <td>0.542332</td>
      <td>0.269815</td>
      <td>0.007499</td>
      <td>-0.520071</td>
      <td>0.152265</td>
      <td>0.178867</td>
      <td>-0.373329</td>
    </tr>
    <tr>
      <th>18</th>
      <td>1.069679</td>
      <td>1.048855</td>
      <td>0.587528</td>
      <td>0.314581</td>
      <td>0.005280</td>
      <td>-0.008009</td>
      <td>0.036284</td>
      <td>0.128431</td>
      <td>0.165826</td>
      <td>0.379750</td>
      <td>-0.850338</td>
      <td>-0.770564</td>
      <td>0.681420</td>
      <td>-0.343419</td>
      <td>-0.161931</td>
      <td>-0.705960</td>
      <td>-0.917970</td>
      <td>0.349147</td>
      <td>-0.178802</td>
      <td>0.951936</td>
      <td>1.002303</td>
      <td>0.295336</td>
      <td>0.110053</td>
      <td>0.237468</td>
      <td>0.850854</td>
      <td>0.538923</td>
      <td>0.183142</td>
      <td>-0.021299</td>
      <td>-0.767929</td>
      <td>1.299937</td>
      <td>0.146522</td>
      <td>-0.268630</td>
      <td>0.273250</td>
      <td>-0.769648</td>
      <td>-0.882023</td>
      <td>-0.476467</td>
      <td>0.568964</td>
      <td>0.722011</td>
      <td>0.340466</td>
      <td>0.309235</td>
      <td>...</td>
      <td>0.613942</td>
      <td>0.542999</td>
      <td>-0.174213</td>
      <td>-0.308569</td>
      <td>-0.336152</td>
      <td>0.888982</td>
      <td>0.072496</td>
      <td>-0.311906</td>
      <td>-0.580332</td>
      <td>-0.930244</td>
      <td>0.461518</td>
      <td>-0.181762</td>
      <td>-0.001319</td>
      <td>0.413463</td>
      <td>0.710924</td>
      <td>-0.217584</td>
      <td>0.071691</td>
      <td>-0.388855</td>
      <td>0.165286</td>
      <td>-1.259839</td>
      <td>-0.021121</td>
      <td>0.352766</td>
      <td>0.493936</td>
      <td>0.437742</td>
      <td>0.198272</td>
      <td>0.058477</td>
      <td>0.180744</td>
      <td>-0.558686</td>
      <td>0.307796</td>
      <td>0.439993</td>
      <td>0.325275</td>
      <td>-1.052612</td>
      <td>0.126631</td>
      <td>0.042440</td>
      <td>0.644835</td>
      <td>-0.196139</td>
      <td>0.067378</td>
      <td>3.340776</td>
      <td>2.145245</td>
      <td>0.657018</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.043539</td>
      <td>0.021464</td>
      <td>0.236407</td>
      <td>1.153648</td>
      <td>0.857532</td>
      <td>0.645697</td>
      <td>0.647824</td>
      <td>1.222885</td>
      <td>1.004626</td>
      <td>-0.100441</td>
      <td>1.798263</td>
      <td>-0.352078</td>
      <td>-0.484123</td>
      <td>0.718164</td>
      <td>-0.269814</td>
      <td>-0.339926</td>
      <td>-1.526339</td>
      <td>-0.009046</td>
      <td>-0.821010</td>
      <td>0.366582</td>
      <td>0.640273</td>
      <td>-0.011223</td>
      <td>0.309378</td>
      <td>1.051752</td>
      <td>0.841231</td>
      <td>0.211438</td>
      <td>0.072277</td>
      <td>-0.510196</td>
      <td>-0.124654</td>
      <td>-0.073081</td>
      <td>-0.468927</td>
      <td>0.453174</td>
      <td>0.660458</td>
      <td>0.150466</td>
      <td>-0.904138</td>
      <td>-0.789745</td>
      <td>0.029024</td>
      <td>0.181526</td>
      <td>0.336174</td>
      <td>-0.244384</td>
      <td>...</td>
      <td>0.746873</td>
      <td>0.104989</td>
      <td>0.607114</td>
      <td>0.252931</td>
      <td>0.231703</td>
      <td>-0.787299</td>
      <td>-0.380202</td>
      <td>-0.548633</td>
      <td>0.006135</td>
      <td>0.406054</td>
      <td>-0.871181</td>
      <td>-0.529617</td>
      <td>-0.313248</td>
      <td>0.540433</td>
      <td>-0.689286</td>
      <td>0.299159</td>
      <td>1.270926</td>
      <td>0.809170</td>
      <td>0.394926</td>
      <td>0.047998</td>
      <td>-1.380870</td>
      <td>-0.744526</td>
      <td>0.055211</td>
      <td>0.517587</td>
      <td>-0.609465</td>
      <td>0.423838</td>
      <td>-0.631770</td>
      <td>0.653079</td>
      <td>0.501634</td>
      <td>-0.560279</td>
      <td>-0.100303</td>
      <td>0.070803</td>
      <td>0.045120</td>
      <td>0.098317</td>
      <td>-0.300042</td>
      <td>0.108983</td>
      <td>-0.512994</td>
      <td>0.778003</td>
      <td>1.072885</td>
      <td>0.076548</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.914305</td>
      <td>0.213769</td>
      <td>0.048595</td>
      <td>-0.345474</td>
      <td>-0.434531</td>
      <td>-0.596883</td>
      <td>0.788256</td>
      <td>0.245455</td>
      <td>-0.154415</td>
      <td>0.145559</td>
      <td>0.090744</td>
      <td>-0.249732</td>
      <td>-0.648792</td>
      <td>0.072112</td>
      <td>-0.057951</td>
      <td>1.489361</td>
      <td>0.277245</td>
      <td>0.153860</td>
      <td>-0.418727</td>
      <td>0.056081</td>
      <td>0.014132</td>
      <td>-0.021773</td>
      <td>-0.193333</td>
      <td>-0.130750</td>
      <td>-0.379815</td>
      <td>-0.101402</td>
      <td>1.206372</td>
      <td>0.152418</td>
      <td>-0.501213</td>
      <td>-0.521377</td>
      <td>0.101185</td>
      <td>-0.008503</td>
      <td>-0.118979</td>
      <td>0.467843</td>
      <td>0.645766</td>
      <td>0.284031</td>
      <td>0.164480</td>
      <td>0.207488</td>
      <td>-0.284636</td>
      <td>-0.617942</td>
      <td>...</td>
      <td>0.752179</td>
      <td>-0.856459</td>
      <td>0.125055</td>
      <td>0.611419</td>
      <td>-0.016822</td>
      <td>-0.433300</td>
      <td>-0.432102</td>
      <td>-0.089466</td>
      <td>-0.679172</td>
      <td>0.618911</td>
      <td>-0.297360</td>
      <td>0.086808</td>
      <td>-0.249677</td>
      <td>-0.336946</td>
      <td>-0.434647</td>
      <td>-0.847312</td>
      <td>-0.644097</td>
      <td>0.066121</td>
      <td>0.133699</td>
      <td>0.959246</td>
      <td>0.687949</td>
      <td>0.583007</td>
      <td>0.412807</td>
      <td>0.753048</td>
      <td>0.778071</td>
      <td>0.086999</td>
      <td>-0.236440</td>
      <td>0.423893</td>
      <td>1.199154</td>
      <td>0.611468</td>
      <td>0.528715</td>
      <td>0.164448</td>
      <td>0.276918</td>
      <td>-0.484344</td>
      <td>0.624736</td>
      <td>0.747937</td>
      <td>0.203620</td>
      <td>1.751889</td>
      <td>1.119051</td>
      <td>1.028434</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.318102</td>
      <td>-0.497109</td>
      <td>1.090494</td>
      <td>0.401714</td>
      <td>-1.096364</td>
      <td>-0.902621</td>
      <td>0.654020</td>
      <td>-0.636138</td>
      <td>0.012653</td>
      <td>-1.058258</td>
      <td>-0.270559</td>
      <td>-0.467355</td>
      <td>0.662182</td>
      <td>-0.220136</td>
      <td>0.761060</td>
      <td>-0.138734</td>
      <td>0.262829</td>
      <td>-0.566805</td>
      <td>0.732630</td>
      <td>0.225683</td>
      <td>0.828347</td>
      <td>-0.876203</td>
      <td>-0.365294</td>
      <td>0.648798</td>
      <td>-1.018707</td>
      <td>-1.637558</td>
      <td>0.279219</td>
      <td>-1.560943</td>
      <td>-0.942919</td>
      <td>0.012241</td>
      <td>-0.055830</td>
      <td>0.488177</td>
      <td>-0.506710</td>
      <td>0.435911</td>
      <td>-0.265880</td>
      <td>0.476697</td>
      <td>-0.420386</td>
      <td>0.604137</td>
      <td>0.626248</td>
      <td>-0.771727</td>
      <td>...</td>
      <td>0.942651</td>
      <td>-0.333306</td>
      <td>0.040716</td>
      <td>0.420686</td>
      <td>0.502204</td>
      <td>1.323135</td>
      <td>0.543493</td>
      <td>-0.526843</td>
      <td>-0.055927</td>
      <td>0.162308</td>
      <td>-0.350358</td>
      <td>-0.446171</td>
      <td>0.694125</td>
      <td>0.558429</td>
      <td>0.863964</td>
      <td>-0.841659</td>
      <td>0.749664</td>
      <td>0.694544</td>
      <td>-0.174588</td>
      <td>-0.113559</td>
      <td>-0.292972</td>
      <td>0.220774</td>
      <td>0.179258</td>
      <td>-0.176734</td>
      <td>-0.424547</td>
      <td>0.365639</td>
      <td>0.439739</td>
      <td>0.139901</td>
      <td>0.091740</td>
      <td>-1.038629</td>
      <td>-0.471719</td>
      <td>-1.160299</td>
      <td>0.523469</td>
      <td>-0.205231</td>
      <td>0.163845</td>
      <td>0.802600</td>
      <td>0.358893</td>
      <td>-0.043419</td>
      <td>-0.871377</td>
      <td>-0.604618</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.353105</td>
      <td>0.587540</td>
      <td>0.238299</td>
      <td>0.120634</td>
      <td>0.591031</td>
      <td>0.386341</td>
      <td>0.440322</td>
      <td>-0.764158</td>
      <td>0.069062</td>
      <td>-0.556537</td>
      <td>-0.637964</td>
      <td>-0.257873</td>
      <td>-0.427266</td>
      <td>0.450861</td>
      <td>-0.163308</td>
      <td>1.354169</td>
      <td>0.647589</td>
      <td>-0.055833</td>
      <td>-0.403232</td>
      <td>0.070768</td>
      <td>0.372891</td>
      <td>0.736591</td>
      <td>-1.174192</td>
      <td>-0.641910</td>
      <td>-0.374234</td>
      <td>-0.379022</td>
      <td>0.962998</td>
      <td>0.740540</td>
      <td>0.302249</td>
      <td>0.148380</td>
      <td>-0.268014</td>
      <td>0.225404</td>
      <td>-0.297677</td>
      <td>-0.024043</td>
      <td>-0.340859</td>
      <td>-0.152682</td>
      <td>-0.161197</td>
      <td>0.986692</td>
      <td>0.217419</td>
      <td>-0.637099</td>
      <td>...</td>
      <td>1.011599</td>
      <td>-0.738521</td>
      <td>0.172817</td>
      <td>0.156415</td>
      <td>-0.921294</td>
      <td>-1.147484</td>
      <td>-0.076201</td>
      <td>-0.441882</td>
      <td>-0.047722</td>
      <td>-0.418184</td>
      <td>0.591900</td>
      <td>-0.194223</td>
      <td>0.121441</td>
      <td>-0.273278</td>
      <td>0.367632</td>
      <td>0.411059</td>
      <td>0.958819</td>
      <td>0.240897</td>
      <td>0.541668</td>
      <td>-0.321082</td>
      <td>-0.517130</td>
      <td>-0.484463</td>
      <td>-0.856337</td>
      <td>0.016924</td>
      <td>-0.007467</td>
      <td>0.383032</td>
      <td>1.236931</td>
      <td>0.240439</td>
      <td>-0.760716</td>
      <td>-0.721121</td>
      <td>0.166542</td>
      <td>-0.559612</td>
      <td>-0.647334</td>
      <td>-0.190056</td>
      <td>-0.951073</td>
      <td>0.406457</td>
      <td>-0.521388</td>
      <td>1.843530</td>
      <td>0.924990</td>
      <td>0.589237</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.376276</td>
      <td>0.485909</td>
      <td>-0.064586</td>
      <td>-0.683373</td>
      <td>1.008628</td>
      <td>-0.414453</td>
      <td>-0.353234</td>
      <td>-0.071012</td>
      <td>0.207830</td>
      <td>-0.209321</td>
      <td>0.668977</td>
      <td>-0.211424</td>
      <td>-0.945175</td>
      <td>0.999238</td>
      <td>0.773088</td>
      <td>1.392099</td>
      <td>0.398530</td>
      <td>-0.150041</td>
      <td>-1.006872</td>
      <td>0.095112</td>
      <td>1.126936</td>
      <td>0.663540</td>
      <td>-0.335007</td>
      <td>0.003489</td>
      <td>0.946294</td>
      <td>0.850777</td>
      <td>1.134310</td>
      <td>-0.069586</td>
      <td>0.036939</td>
      <td>0.503439</td>
      <td>-0.146294</td>
      <td>-0.692331</td>
      <td>-0.336374</td>
      <td>0.606545</td>
      <td>-0.426096</td>
      <td>-0.155965</td>
      <td>-1.518017</td>
      <td>-1.674824</td>
      <td>-1.004562</td>
      <td>-0.007919</td>
      <td>...</td>
      <td>0.939266</td>
      <td>-1.092205</td>
      <td>-0.414128</td>
      <td>0.483581</td>
      <td>0.274588</td>
      <td>0.235261</td>
      <td>-0.235690</td>
      <td>-0.496765</td>
      <td>-1.039076</td>
      <td>0.270342</td>
      <td>0.103618</td>
      <td>0.979442</td>
      <td>-0.381950</td>
      <td>0.332790</td>
      <td>-0.760002</td>
      <td>-0.208164</td>
      <td>-0.021591</td>
      <td>0.206220</td>
      <td>0.770045</td>
      <td>0.658760</td>
      <td>0.485340</td>
      <td>0.578526</td>
      <td>-0.332666</td>
      <td>0.409060</td>
      <td>0.526004</td>
      <td>0.127179</td>
      <td>-0.683217</td>
      <td>-0.527778</td>
      <td>0.113904</td>
      <td>-0.450985</td>
      <td>-0.446802</td>
      <td>-0.236259</td>
      <td>0.041858</td>
      <td>-0.101109</td>
      <td>-0.361445</td>
      <td>0.503310</td>
      <td>0.467097</td>
      <td>0.541979</td>
      <td>0.393902</td>
      <td>-0.617550</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.326757</td>
      <td>-1.052477</td>
      <td>-0.379497</td>
      <td>-0.416224</td>
      <td>0.707080</td>
      <td>0.939654</td>
      <td>0.689526</td>
      <td>-0.177536</td>
      <td>1.154592</td>
      <td>0.377377</td>
      <td>-0.135218</td>
      <td>-0.250572</td>
      <td>-0.298052</td>
      <td>-0.079556</td>
      <td>-0.824781</td>
      <td>0.666180</td>
      <td>0.684434</td>
      <td>0.632518</td>
      <td>0.695288</td>
      <td>0.004573</td>
      <td>-0.315024</td>
      <td>0.084757</td>
      <td>-0.255321</td>
      <td>-0.136467</td>
      <td>0.042548</td>
      <td>0.799339</td>
      <td>1.261249</td>
      <td>0.459401</td>
      <td>0.457541</td>
      <td>0.085864</td>
      <td>0.258741</td>
      <td>0.564921</td>
      <td>-0.661426</td>
      <td>0.490956</td>
      <td>-0.249691</td>
      <td>0.059017</td>
      <td>-0.244854</td>
      <td>-0.508041</td>
      <td>-0.224795</td>
      <td>0.526108</td>
      <td>...</td>
      <td>0.478413</td>
      <td>0.114922</td>
      <td>-0.007972</td>
      <td>0.091575</td>
      <td>-0.660509</td>
      <td>0.851325</td>
      <td>0.696964</td>
      <td>-0.633885</td>
      <td>-0.168475</td>
      <td>0.811772</td>
      <td>0.388154</td>
      <td>-0.437052</td>
      <td>0.181501</td>
      <td>0.504089</td>
      <td>0.109312</td>
      <td>0.108942</td>
      <td>1.240145</td>
      <td>1.173167</td>
      <td>-0.514216</td>
      <td>-0.259191</td>
      <td>-0.398488</td>
      <td>-1.185103</td>
      <td>0.914643</td>
      <td>0.686994</td>
      <td>0.275765</td>
      <td>-0.048235</td>
      <td>1.669312</td>
      <td>1.219329</td>
      <td>0.939668</td>
      <td>-0.096481</td>
      <td>1.161823</td>
      <td>0.751195</td>
      <td>1.331908</td>
      <td>1.003954</td>
      <td>-0.044670</td>
      <td>0.076163</td>
      <td>0.258338</td>
      <td>0.562321</td>
      <td>0.693889</td>
      <td>0.475734</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.695242</td>
      <td>-0.078997</td>
      <td>0.820399</td>
      <td>0.632921</td>
      <td>0.961491</td>
      <td>0.066741</td>
      <td>-0.043982</td>
      <td>0.156285</td>
      <td>-0.332987</td>
      <td>0.104238</td>
      <td>-0.403716</td>
      <td>-0.642451</td>
      <td>1.182766</td>
      <td>0.861567</td>
      <td>-1.041792</td>
      <td>-0.557081</td>
      <td>0.087665</td>
      <td>-0.281012</td>
      <td>0.148506</td>
      <td>0.090949</td>
      <td>0.928173</td>
      <td>0.894666</td>
      <td>-0.303140</td>
      <td>0.670954</td>
      <td>-0.451395</td>
      <td>1.248967</td>
      <td>1.193480</td>
      <td>0.055853</td>
      <td>-0.113661</td>
      <td>-0.666118</td>
      <td>0.398573</td>
      <td>0.557208</td>
      <td>0.291749</td>
      <td>0.509001</td>
      <td>0.698743</td>
      <td>-0.416566</td>
      <td>-0.229294</td>
      <td>0.083686</td>
      <td>-0.183157</td>
      <td>-0.663525</td>
      <td>...</td>
      <td>0.128183</td>
      <td>0.472302</td>
      <td>-0.429553</td>
      <td>0.425183</td>
      <td>0.025012</td>
      <td>-1.150540</td>
      <td>-1.872891</td>
      <td>-0.260295</td>
      <td>0.315840</td>
      <td>1.407648</td>
      <td>-0.377618</td>
      <td>0.164765</td>
      <td>0.863026</td>
      <td>-0.228646</td>
      <td>-0.991382</td>
      <td>-0.363319</td>
      <td>0.607949</td>
      <td>1.046274</td>
      <td>0.138312</td>
      <td>-0.039131</td>
      <td>-0.888269</td>
      <td>-0.133705</td>
      <td>0.444042</td>
      <td>0.031998</td>
      <td>0.823356</td>
      <td>0.993222</td>
      <td>0.512820</td>
      <td>1.541316</td>
      <td>0.246627</td>
      <td>0.724815</td>
      <td>0.622587</td>
      <td>-0.512949</td>
      <td>-0.673926</td>
      <td>-0.902335</td>
      <td>-2.402671</td>
      <td>-0.774859</td>
      <td>0.200305</td>
      <td>0.465713</td>
      <td>-1.231221</td>
      <td>-1.408844</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.343317</td>
      <td>0.110424</td>
      <td>0.068902</td>
      <td>-0.873958</td>
      <td>0.404287</td>
      <td>0.663684</td>
      <td>0.130541</td>
      <td>-0.444297</td>
      <td>-0.261709</td>
      <td>-0.246077</td>
      <td>-0.239163</td>
      <td>0.912554</td>
      <td>-0.803286</td>
      <td>0.116384</td>
      <td>0.342743</td>
      <td>0.500803</td>
      <td>0.994944</td>
      <td>0.105795</td>
      <td>-0.328690</td>
      <td>0.188874</td>
      <td>-0.396234</td>
      <td>-0.089016</td>
      <td>0.051974</td>
      <td>0.371828</td>
      <td>-0.606944</td>
      <td>-0.342430</td>
      <td>-0.941618</td>
      <td>-0.112993</td>
      <td>0.276723</td>
      <td>0.064828</td>
      <td>0.637328</td>
      <td>-0.594428</td>
      <td>0.343439</td>
      <td>-0.394075</td>
      <td>-0.067740</td>
      <td>-0.902097</td>
      <td>0.231536</td>
      <td>-0.035799</td>
      <td>-0.704104</td>
      <td>-0.178207</td>
      <td>...</td>
      <td>0.850681</td>
      <td>-0.010767</td>
      <td>-0.158123</td>
      <td>-0.979667</td>
      <td>-0.655706</td>
      <td>0.247370</td>
      <td>-0.221946</td>
      <td>1.020727</td>
      <td>1.735817</td>
      <td>-0.013115</td>
      <td>-0.379557</td>
      <td>0.015886</td>
      <td>1.107611</td>
      <td>-0.128176</td>
      <td>0.222628</td>
      <td>0.366686</td>
      <td>0.883627</td>
      <td>0.415456</td>
      <td>0.441979</td>
      <td>0.713052</td>
      <td>0.563874</td>
      <td>0.823948</td>
      <td>1.038518</td>
      <td>-0.117418</td>
      <td>-1.446982</td>
      <td>0.024109</td>
      <td>0.475630</td>
      <td>-0.235201</td>
      <td>0.011499</td>
      <td>0.217848</td>
      <td>-0.667187</td>
      <td>-0.844692</td>
      <td>-0.076672</td>
      <td>0.038316</td>
      <td>-0.284831</td>
      <td>0.631184</td>
      <td>-0.111363</td>
      <td>-1.301622</td>
      <td>-1.593200</td>
      <td>-1.157593</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.146342</td>
      <td>0.081668</td>
      <td>-0.147543</td>
      <td>-0.869163</td>
      <td>0.415762</td>
      <td>-0.357089</td>
      <td>-0.280179</td>
      <td>0.218256</td>
      <td>0.245775</td>
      <td>-0.249795</td>
      <td>-0.198267</td>
      <td>-0.477908</td>
      <td>0.194276</td>
      <td>0.599667</td>
      <td>-0.067729</td>
      <td>-0.730046</td>
      <td>-0.575831</td>
      <td>-0.194171</td>
      <td>0.133480</td>
      <td>0.009814</td>
      <td>1.025138</td>
      <td>0.785103</td>
      <td>-0.032735</td>
      <td>0.768077</td>
      <td>-0.575312</td>
      <td>0.759152</td>
      <td>-0.559359</td>
      <td>-0.863292</td>
      <td>0.031820</td>
      <td>-0.394626</td>
      <td>-1.477295</td>
      <td>0.230245</td>
      <td>0.404142</td>
      <td>-0.260576</td>
      <td>-0.232684</td>
      <td>0.105157</td>
      <td>0.187686</td>
      <td>0.774695</td>
      <td>0.478282</td>
      <td>-0.330457</td>
      <td>...</td>
      <td>-0.967662</td>
      <td>-0.275027</td>
      <td>0.151550</td>
      <td>-0.181700</td>
      <td>0.177094</td>
      <td>0.058917</td>
      <td>-0.690547</td>
      <td>0.743429</td>
      <td>-0.167659</td>
      <td>0.146805</td>
      <td>-1.108367</td>
      <td>-0.588406</td>
      <td>0.021498</td>
      <td>-0.605853</td>
      <td>-0.792314</td>
      <td>-0.228217</td>
      <td>1.249189</td>
      <td>0.077454</td>
      <td>-0.180811</td>
      <td>0.300351</td>
      <td>-0.499362</td>
      <td>-0.466284</td>
      <td>-0.639673</td>
      <td>-1.010690</td>
      <td>-0.709012</td>
      <td>-0.646667</td>
      <td>-0.122113</td>
      <td>-0.641260</td>
      <td>0.322797</td>
      <td>0.256786</td>
      <td>0.198718</td>
      <td>0.075742</td>
      <td>-0.212485</td>
      <td>-0.602516</td>
      <td>-0.323651</td>
      <td>0.066557</td>
      <td>0.054451</td>
      <td>0.980215</td>
      <td>0.637392</td>
      <td>-0.033520</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.002809</td>
      <td>0.504145</td>
      <td>0.218140</td>
      <td>-0.418286</td>
      <td>-0.001918</td>
      <td>-0.170045</td>
      <td>-0.052732</td>
      <td>-0.883050</td>
      <td>-1.847924</td>
      <td>-0.188336</td>
      <td>-0.034648</td>
      <td>-0.466235</td>
      <td>-0.091539</td>
      <td>-0.153537</td>
      <td>-1.839684</td>
      <td>-0.048860</td>
      <td>-0.429426</td>
      <td>0.291135</td>
      <td>0.363259</td>
      <td>0.721325</td>
      <td>-0.757488</td>
      <td>-0.297970</td>
      <td>0.039302</td>
      <td>0.669209</td>
      <td>-0.785580</td>
      <td>0.110937</td>
      <td>-0.800395</td>
      <td>0.264643</td>
      <td>0.722647</td>
      <td>0.117900</td>
      <td>0.480801</td>
      <td>0.113764</td>
      <td>-0.061214</td>
      <td>-0.956677</td>
      <td>-0.750245</td>
      <td>-0.050999</td>
      <td>-1.763274</td>
      <td>-0.686121</td>
      <td>-0.431142</td>
      <td>-0.094537</td>
      <td>...</td>
      <td>0.049292</td>
      <td>0.805718</td>
      <td>0.559490</td>
      <td>0.223349</td>
      <td>1.280620</td>
      <td>-0.917189</td>
      <td>-0.769935</td>
      <td>-0.936576</td>
      <td>0.181104</td>
      <td>0.799307</td>
      <td>0.277771</td>
      <td>0.572195</td>
      <td>-0.487919</td>
      <td>-0.610960</td>
      <td>-0.599346</td>
      <td>0.807713</td>
      <td>-0.110220</td>
      <td>0.275398</td>
      <td>-0.302878</td>
      <td>-0.080495</td>
      <td>0.583055</td>
      <td>0.428218</td>
      <td>0.514624</td>
      <td>-0.005844</td>
      <td>-0.486550</td>
      <td>0.216438</td>
      <td>-0.128125</td>
      <td>-0.563666</td>
      <td>-0.239062</td>
      <td>-0.241748</td>
      <td>0.096198</td>
      <td>-0.218825</td>
      <td>1.040920</td>
      <td>-0.722087</td>
      <td>-1.343918</td>
      <td>-0.147904</td>
      <td>0.232908</td>
      <td>-1.530436</td>
      <td>-0.524368</td>
      <td>-0.079261</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.412632</td>
      <td>0.147064</td>
      <td>0.358744</td>
      <td>-0.019043</td>
      <td>0.466717</td>
      <td>0.210833</td>
      <td>0.401414</td>
      <td>-0.693943</td>
      <td>-0.172132</td>
      <td>-0.199920</td>
      <td>0.204605</td>
      <td>-0.528385</td>
      <td>-0.495985</td>
      <td>0.123726</td>
      <td>-0.120951</td>
      <td>0.053269</td>
      <td>-0.215469</td>
      <td>1.204715</td>
      <td>0.396207</td>
      <td>-0.933195</td>
      <td>0.511058</td>
      <td>0.063811</td>
      <td>0.188915</td>
      <td>0.336479</td>
      <td>-0.368847</td>
      <td>-0.475873</td>
      <td>0.006184</td>
      <td>1.049792</td>
      <td>0.378027</td>
      <td>-0.107870</td>
      <td>0.464799</td>
      <td>0.354952</td>
      <td>1.325737</td>
      <td>0.818106</td>
      <td>0.422151</td>
      <td>0.781558</td>
      <td>-0.028154</td>
      <td>1.300659</td>
      <td>0.130974</td>
      <td>0.117990</td>
      <td>...</td>
      <td>-0.328862</td>
      <td>-0.397345</td>
      <td>0.717939</td>
      <td>-0.069996</td>
      <td>0.024261</td>
      <td>-0.738204</td>
      <td>-1.616466</td>
      <td>-1.063685</td>
      <td>-1.215772</td>
      <td>-0.242691</td>
      <td>-1.384562</td>
      <td>-0.797896</td>
      <td>-0.264631</td>
      <td>-0.745753</td>
      <td>-0.935971</td>
      <td>-0.824080</td>
      <td>0.008354</td>
      <td>0.807319</td>
      <td>-0.577368</td>
      <td>0.695657</td>
      <td>0.060270</td>
      <td>0.348139</td>
      <td>0.430310</td>
      <td>-0.563907</td>
      <td>-0.474689</td>
      <td>-0.513657</td>
      <td>-0.345089</td>
      <td>-0.474429</td>
      <td>0.381434</td>
      <td>-0.115618</td>
      <td>-0.032988</td>
      <td>-0.899125</td>
      <td>0.744803</td>
      <td>0.817407</td>
      <td>0.466794</td>
      <td>0.581234</td>
      <td>0.117971</td>
      <td>-0.792709</td>
      <td>-0.015395</td>
      <td>0.645782</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f4c2808c7c0&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.018535  0.041366  24.622504  7.253243e-134  0.937459  1.099611
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.521 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.1e043a052b0af929e4d8.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>