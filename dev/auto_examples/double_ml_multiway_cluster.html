
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-0.048992</td>
      <td>-0.247165</td>
      <td>-0.535047</td>
      <td>-1.050604</td>
      <td>0.024844</td>
      <td>0.632332</td>
      <td>0.733287</td>
      <td>0.167555</td>
      <td>-0.425668</td>
      <td>0.780038</td>
      <td>0.420219</td>
      <td>0.322303</td>
      <td>0.904231</td>
      <td>1.039419</td>
      <td>-0.491157</td>
      <td>-0.792307</td>
      <td>-0.037980</td>
      <td>1.303573</td>
      <td>-0.335839</td>
      <td>-0.213013</td>
      <td>-0.282971</td>
      <td>0.495284</td>
      <td>0.702498</td>
      <td>0.274200</td>
      <td>0.264846</td>
      <td>0.310095</td>
      <td>1.268805</td>
      <td>0.557259</td>
      <td>1.760096</td>
      <td>-0.703657</td>
      <td>-0.356429</td>
      <td>0.025890</td>
      <td>0.644822</td>
      <td>-0.334252</td>
      <td>0.382956</td>
      <td>0.379126</td>
      <td>-0.077268</td>
      <td>-0.221238</td>
      <td>0.534341</td>
      <td>0.017407</td>
      <td>...</td>
      <td>0.183308</td>
      <td>0.103900</td>
      <td>1.593395</td>
      <td>0.803482</td>
      <td>-0.168075</td>
      <td>0.249305</td>
      <td>0.164604</td>
      <td>0.652596</td>
      <td>0.428957</td>
      <td>0.115811</td>
      <td>0.405536</td>
      <td>0.210682</td>
      <td>0.317995</td>
      <td>0.552404</td>
      <td>-0.303078</td>
      <td>0.515644</td>
      <td>0.222408</td>
      <td>-0.436421</td>
      <td>-0.391607</td>
      <td>-0.629455</td>
      <td>-0.230746</td>
      <td>-0.349128</td>
      <td>0.257894</td>
      <td>0.141659</td>
      <td>-0.308201</td>
      <td>0.565551</td>
      <td>0.446490</td>
      <td>0.144328</td>
      <td>0.524934</td>
      <td>-0.379077</td>
      <td>0.122701</td>
      <td>0.014661</td>
      <td>-0.144682</td>
      <td>0.282443</td>
      <td>-0.275025</td>
      <td>0.509475</td>
      <td>0.961363</td>
      <td>-1.379089</td>
      <td>-1.480511</td>
      <td>-0.567508</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.144270</td>
      <td>0.415440</td>
      <td>-0.483704</td>
      <td>-0.959504</td>
      <td>0.379465</td>
      <td>-0.021968</td>
      <td>0.529013</td>
      <td>-0.798303</td>
      <td>-0.393512</td>
      <td>-0.885043</td>
      <td>0.339867</td>
      <td>-0.777535</td>
      <td>-1.056368</td>
      <td>-0.120780</td>
      <td>0.090266</td>
      <td>-1.142525</td>
      <td>-0.620692</td>
      <td>0.611605</td>
      <td>-0.359409</td>
      <td>-0.709467</td>
      <td>-0.930204</td>
      <td>-0.624479</td>
      <td>0.833820</td>
      <td>1.827732</td>
      <td>-0.489822</td>
      <td>-1.311862</td>
      <td>-0.005587</td>
      <td>-0.496538</td>
      <td>-0.120321</td>
      <td>0.448109</td>
      <td>0.101021</td>
      <td>-0.206221</td>
      <td>0.488258</td>
      <td>-0.429060</td>
      <td>-0.087752</td>
      <td>0.255680</td>
      <td>-0.065309</td>
      <td>-0.370570</td>
      <td>-0.018508</td>
      <td>-0.082120</td>
      <td>...</td>
      <td>-0.243692</td>
      <td>-0.133971</td>
      <td>-0.043620</td>
      <td>0.430045</td>
      <td>-1.161261</td>
      <td>-0.498466</td>
      <td>-0.516491</td>
      <td>0.348435</td>
      <td>-1.190776</td>
      <td>-0.186079</td>
      <td>0.894627</td>
      <td>-0.531652</td>
      <td>-0.355303</td>
      <td>0.949739</td>
      <td>-0.518242</td>
      <td>-0.502196</td>
      <td>-1.176784</td>
      <td>-0.199335</td>
      <td>0.807908</td>
      <td>0.258084</td>
      <td>0.315990</td>
      <td>-0.009580</td>
      <td>-0.599370</td>
      <td>0.028715</td>
      <td>0.311865</td>
      <td>1.167704</td>
      <td>0.575219</td>
      <td>0.039144</td>
      <td>0.142905</td>
      <td>0.873075</td>
      <td>0.660251</td>
      <td>-0.345082</td>
      <td>-0.002333</td>
      <td>-0.281075</td>
      <td>-0.705208</td>
      <td>1.169720</td>
      <td>-0.414219</td>
      <td>-2.005257</td>
      <td>-1.217863</td>
      <td>-0.398663</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.280068</td>
      <td>0.538988</td>
      <td>0.162195</td>
      <td>-0.700518</td>
      <td>0.198825</td>
      <td>0.277685</td>
      <td>1.348267</td>
      <td>0.253043</td>
      <td>0.548770</td>
      <td>0.727259</td>
      <td>0.318118</td>
      <td>0.000490</td>
      <td>-0.118753</td>
      <td>0.384107</td>
      <td>-0.137838</td>
      <td>-0.032906</td>
      <td>-0.371516</td>
      <td>1.206439</td>
      <td>-0.106756</td>
      <td>0.075962</td>
      <td>-0.413162</td>
      <td>0.068048</td>
      <td>-0.400599</td>
      <td>0.112581</td>
      <td>0.454178</td>
      <td>-0.073554</td>
      <td>-0.431006</td>
      <td>0.588152</td>
      <td>0.643011</td>
      <td>0.239630</td>
      <td>0.004009</td>
      <td>0.508802</td>
      <td>-0.867819</td>
      <td>0.322792</td>
      <td>0.287540</td>
      <td>-1.370566</td>
      <td>-0.657814</td>
      <td>-0.213140</td>
      <td>1.179715</td>
      <td>0.922678</td>
      <td>...</td>
      <td>0.526170</td>
      <td>1.002947</td>
      <td>1.570588</td>
      <td>0.950203</td>
      <td>-0.008557</td>
      <td>-0.557735</td>
      <td>0.036929</td>
      <td>0.418327</td>
      <td>-1.085564</td>
      <td>-0.085505</td>
      <td>0.555549</td>
      <td>-0.685264</td>
      <td>0.045955</td>
      <td>0.975934</td>
      <td>1.047669</td>
      <td>-0.564441</td>
      <td>0.490510</td>
      <td>-0.288378</td>
      <td>-0.724519</td>
      <td>-0.575467</td>
      <td>-0.455932</td>
      <td>-0.781199</td>
      <td>-0.496875</td>
      <td>0.504200</td>
      <td>-0.403732</td>
      <td>1.010244</td>
      <td>-0.095730</td>
      <td>-0.078940</td>
      <td>0.994986</td>
      <td>0.100341</td>
      <td>-0.092012</td>
      <td>-0.594949</td>
      <td>-0.738565</td>
      <td>1.164657</td>
      <td>-0.690383</td>
      <td>-0.388264</td>
      <td>0.015804</td>
      <td>1.162555</td>
      <td>0.775339</td>
      <td>-0.143892</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.084331</td>
      <td>0.138735</td>
      <td>0.197750</td>
      <td>-1.172390</td>
      <td>0.091956</td>
      <td>0.308763</td>
      <td>0.274169</td>
      <td>0.760961</td>
      <td>0.754639</td>
      <td>0.331514</td>
      <td>1.169036</td>
      <td>0.545542</td>
      <td>1.808366</td>
      <td>1.243333</td>
      <td>-0.127707</td>
      <td>-0.139059</td>
      <td>0.605686</td>
      <td>0.261596</td>
      <td>-0.566179</td>
      <td>0.124319</td>
      <td>-0.553330</td>
      <td>-0.156967</td>
      <td>0.756305</td>
      <td>0.378912</td>
      <td>0.203021</td>
      <td>0.114235</td>
      <td>0.273873</td>
      <td>-0.669977</td>
      <td>-0.170544</td>
      <td>-0.641329</td>
      <td>-0.387600</td>
      <td>-0.832803</td>
      <td>-0.277172</td>
      <td>-0.260039</td>
      <td>0.001161</td>
      <td>0.074504</td>
      <td>0.508000</td>
      <td>0.095977</td>
      <td>-0.439891</td>
      <td>0.289600</td>
      <td>...</td>
      <td>-0.142546</td>
      <td>0.683847</td>
      <td>0.018821</td>
      <td>0.923398</td>
      <td>0.237646</td>
      <td>0.168766</td>
      <td>0.751452</td>
      <td>0.877303</td>
      <td>0.080553</td>
      <td>0.091995</td>
      <td>-0.225114</td>
      <td>-0.266187</td>
      <td>0.248298</td>
      <td>0.571903</td>
      <td>-0.425100</td>
      <td>0.519113</td>
      <td>-0.298071</td>
      <td>-0.944217</td>
      <td>-0.702980</td>
      <td>-0.136969</td>
      <td>-0.036430</td>
      <td>-1.485895</td>
      <td>-0.479744</td>
      <td>0.030516</td>
      <td>0.631605</td>
      <td>-0.042608</td>
      <td>-0.026802</td>
      <td>-1.138855</td>
      <td>-0.218090</td>
      <td>0.289092</td>
      <td>0.350662</td>
      <td>0.367054</td>
      <td>-0.015426</td>
      <td>0.945473</td>
      <td>-1.266912</td>
      <td>-0.144642</td>
      <td>-0.574903</td>
      <td>-1.630130</td>
      <td>-1.326470</td>
      <td>-0.131970</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.461462</td>
      <td>-0.813224</td>
      <td>0.096289</td>
      <td>0.075193</td>
      <td>0.558348</td>
      <td>1.747850</td>
      <td>0.744396</td>
      <td>0.113145</td>
      <td>0.079920</td>
      <td>0.029829</td>
      <td>-0.139613</td>
      <td>-0.167749</td>
      <td>0.036291</td>
      <td>-0.424177</td>
      <td>-0.469326</td>
      <td>0.663043</td>
      <td>-0.254030</td>
      <td>1.303618</td>
      <td>-0.018774</td>
      <td>-0.373054</td>
      <td>0.199566</td>
      <td>-0.777273</td>
      <td>-0.463349</td>
      <td>-0.281452</td>
      <td>-0.500360</td>
      <td>-0.372689</td>
      <td>-0.270037</td>
      <td>0.251697</td>
      <td>0.094328</td>
      <td>-1.395321</td>
      <td>0.124335</td>
      <td>-0.012531</td>
      <td>0.202663</td>
      <td>-0.096707</td>
      <td>0.023546</td>
      <td>-0.582961</td>
      <td>0.203043</td>
      <td>0.182356</td>
      <td>0.859556</td>
      <td>0.236732</td>
      <td>...</td>
      <td>-0.478485</td>
      <td>0.174880</td>
      <td>0.203220</td>
      <td>0.972296</td>
      <td>0.658136</td>
      <td>-0.535904</td>
      <td>0.501544</td>
      <td>0.318491</td>
      <td>-0.116031</td>
      <td>-1.107879</td>
      <td>-0.646368</td>
      <td>0.399688</td>
      <td>0.324998</td>
      <td>-0.134322</td>
      <td>-0.838723</td>
      <td>-0.295554</td>
      <td>-0.218666</td>
      <td>-0.605332</td>
      <td>-0.083887</td>
      <td>-0.750462</td>
      <td>-0.367376</td>
      <td>-0.179634</td>
      <td>0.234972</td>
      <td>-0.124320</td>
      <td>0.165567</td>
      <td>-0.425247</td>
      <td>0.194374</td>
      <td>-0.355433</td>
      <td>-0.356094</td>
      <td>-1.277291</td>
      <td>-0.297472</td>
      <td>-0.952087</td>
      <td>0.486655</td>
      <td>0.751931</td>
      <td>-0.333942</td>
      <td>0.244679</td>
      <td>-0.346252</td>
      <td>-3.127078</td>
      <td>-2.229933</td>
      <td>-1.917385</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.121955</td>
      <td>0.066038</td>
      <td>-0.883693</td>
      <td>-0.162123</td>
      <td>1.116170</td>
      <td>-0.104421</td>
      <td>-0.641212</td>
      <td>-0.523489</td>
      <td>-0.250413</td>
      <td>-0.340478</td>
      <td>0.158467</td>
      <td>-0.745740</td>
      <td>-0.152643</td>
      <td>-0.165371</td>
      <td>-0.819348</td>
      <td>-1.616006</td>
      <td>-0.399657</td>
      <td>0.542002</td>
      <td>0.125011</td>
      <td>0.178413</td>
      <td>0.721216</td>
      <td>-0.221614</td>
      <td>-0.464273</td>
      <td>-0.853213</td>
      <td>0.249842</td>
      <td>0.746961</td>
      <td>0.088975</td>
      <td>0.144374</td>
      <td>-0.615516</td>
      <td>-0.342696</td>
      <td>0.255254</td>
      <td>0.124827</td>
      <td>0.880835</td>
      <td>0.394946</td>
      <td>0.107705</td>
      <td>-0.370554</td>
      <td>0.198913</td>
      <td>0.182589</td>
      <td>1.934863</td>
      <td>0.178221</td>
      <td>...</td>
      <td>-0.134518</td>
      <td>0.130080</td>
      <td>0.154529</td>
      <td>1.009867</td>
      <td>-0.437915</td>
      <td>-0.934157</td>
      <td>-0.244103</td>
      <td>0.253028</td>
      <td>0.168998</td>
      <td>-0.096172</td>
      <td>-0.068327</td>
      <td>-0.725873</td>
      <td>-0.285608</td>
      <td>-0.312949</td>
      <td>-1.199837</td>
      <td>-0.951832</td>
      <td>0.941016</td>
      <td>-0.339239</td>
      <td>0.483454</td>
      <td>-0.478014</td>
      <td>-0.310132</td>
      <td>-1.737557</td>
      <td>-0.780459</td>
      <td>-1.447940</td>
      <td>-1.165772</td>
      <td>0.650770</td>
      <td>-0.150147</td>
      <td>0.741137</td>
      <td>0.786681</td>
      <td>0.427356</td>
      <td>0.121527</td>
      <td>0.504429</td>
      <td>0.023017</td>
      <td>0.653873</td>
      <td>-0.422288</td>
      <td>0.394332</td>
      <td>0.699604</td>
      <td>-0.757514</td>
      <td>0.249208</td>
      <td>0.509811</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.253793</td>
      <td>-0.396738</td>
      <td>0.858105</td>
      <td>-0.117336</td>
      <td>0.150935</td>
      <td>0.717611</td>
      <td>0.533785</td>
      <td>0.023213</td>
      <td>-0.189681</td>
      <td>0.307282</td>
      <td>-0.019318</td>
      <td>0.065864</td>
      <td>0.707273</td>
      <td>0.589924</td>
      <td>-0.730070</td>
      <td>-0.910917</td>
      <td>0.298875</td>
      <td>0.084141</td>
      <td>-0.680564</td>
      <td>-0.037952</td>
      <td>-0.124075</td>
      <td>-0.273217</td>
      <td>0.245182</td>
      <td>0.460056</td>
      <td>0.715982</td>
      <td>0.006726</td>
      <td>0.289638</td>
      <td>0.152818</td>
      <td>-0.128516</td>
      <td>-0.339815</td>
      <td>-0.918737</td>
      <td>-0.657021</td>
      <td>-0.412464</td>
      <td>-0.902275</td>
      <td>0.593191</td>
      <td>0.468903</td>
      <td>-0.617046</td>
      <td>0.449308</td>
      <td>0.945598</td>
      <td>0.134242</td>
      <td>...</td>
      <td>-1.276286</td>
      <td>0.266028</td>
      <td>1.046833</td>
      <td>-0.159842</td>
      <td>-0.889831</td>
      <td>-0.032414</td>
      <td>-0.176296</td>
      <td>0.325369</td>
      <td>-0.307411</td>
      <td>-0.117398</td>
      <td>-0.180248</td>
      <td>0.041621</td>
      <td>0.359600</td>
      <td>1.467573</td>
      <td>-0.182153</td>
      <td>-0.164334</td>
      <td>0.180025</td>
      <td>-0.914765</td>
      <td>-0.625832</td>
      <td>0.785011</td>
      <td>-0.345778</td>
      <td>-0.685387</td>
      <td>-0.412024</td>
      <td>0.291488</td>
      <td>0.356667</td>
      <td>-0.722352</td>
      <td>-1.007440</td>
      <td>0.196723</td>
      <td>0.110646</td>
      <td>-0.082622</td>
      <td>-0.445766</td>
      <td>-1.054799</td>
      <td>-0.059954</td>
      <td>-0.392745</td>
      <td>-1.284335</td>
      <td>0.025954</td>
      <td>0.873646</td>
      <td>-0.777552</td>
      <td>0.016352</td>
      <td>-0.110639</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.375852</td>
      <td>0.203305</td>
      <td>-0.385780</td>
      <td>-0.187893</td>
      <td>0.878049</td>
      <td>-0.418975</td>
      <td>-0.212228</td>
      <td>-0.556238</td>
      <td>-0.114978</td>
      <td>-0.485183</td>
      <td>-0.498131</td>
      <td>-0.641672</td>
      <td>0.434650</td>
      <td>-0.167426</td>
      <td>0.376206</td>
      <td>-0.138305</td>
      <td>-0.163270</td>
      <td>0.582853</td>
      <td>-0.432994</td>
      <td>-0.291994</td>
      <td>-0.368970</td>
      <td>-0.704863</td>
      <td>-0.859127</td>
      <td>0.937396</td>
      <td>-0.278564</td>
      <td>-0.353176</td>
      <td>-0.426247</td>
      <td>0.567715</td>
      <td>-0.612388</td>
      <td>-0.784552</td>
      <td>-0.274702</td>
      <td>0.002732</td>
      <td>-0.468180</td>
      <td>-0.455623</td>
      <td>0.720545</td>
      <td>0.773056</td>
      <td>0.629561</td>
      <td>0.951088</td>
      <td>0.394862</td>
      <td>1.830919</td>
      <td>...</td>
      <td>-0.220090</td>
      <td>-0.811925</td>
      <td>-0.162240</td>
      <td>-0.362455</td>
      <td>-0.743904</td>
      <td>-0.615964</td>
      <td>-0.575201</td>
      <td>0.230750</td>
      <td>-0.020047</td>
      <td>0.378650</td>
      <td>0.402767</td>
      <td>0.045931</td>
      <td>0.366042</td>
      <td>1.262131</td>
      <td>-1.232306</td>
      <td>0.364577</td>
      <td>-0.295782</td>
      <td>-0.190300</td>
      <td>-0.160287</td>
      <td>-0.564618</td>
      <td>0.330176</td>
      <td>-0.090798</td>
      <td>-0.430083</td>
      <td>-0.794629</td>
      <td>-0.209138</td>
      <td>-0.007020</td>
      <td>-0.293863</td>
      <td>-0.461539</td>
      <td>-0.464839</td>
      <td>-0.249305</td>
      <td>0.052107</td>
      <td>-0.288986</td>
      <td>-0.435165</td>
      <td>-0.356058</td>
      <td>-0.408818</td>
      <td>-0.418828</td>
      <td>0.250244</td>
      <td>-2.968607</td>
      <td>-1.578185</td>
      <td>0.122650</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-1.444369</td>
      <td>-0.472242</td>
      <td>-0.636362</td>
      <td>0.089670</td>
      <td>0.842498</td>
      <td>0.234908</td>
      <td>0.946696</td>
      <td>0.916455</td>
      <td>1.266806</td>
      <td>1.697731</td>
      <td>0.642034</td>
      <td>-0.117661</td>
      <td>0.658989</td>
      <td>0.279391</td>
      <td>-0.534053</td>
      <td>0.141292</td>
      <td>0.115501</td>
      <td>0.515363</td>
      <td>0.217612</td>
      <td>-0.584848</td>
      <td>-0.544768</td>
      <td>0.144830</td>
      <td>0.271452</td>
      <td>0.546794</td>
      <td>-0.075503</td>
      <td>-0.367239</td>
      <td>0.203426</td>
      <td>0.749570</td>
      <td>-0.631269</td>
      <td>-0.165190</td>
      <td>-0.550344</td>
      <td>-1.250695</td>
      <td>-0.279943</td>
      <td>-0.174710</td>
      <td>0.105486</td>
      <td>-0.073749</td>
      <td>0.165816</td>
      <td>0.492532</td>
      <td>1.244491</td>
      <td>0.896397</td>
      <td>...</td>
      <td>-0.940945</td>
      <td>0.471066</td>
      <td>0.049464</td>
      <td>1.034218</td>
      <td>-0.513212</td>
      <td>-0.792065</td>
      <td>-0.670180</td>
      <td>0.319382</td>
      <td>0.568770</td>
      <td>-0.355726</td>
      <td>0.136068</td>
      <td>0.773891</td>
      <td>0.209039</td>
      <td>0.545782</td>
      <td>-0.617880</td>
      <td>-0.721606</td>
      <td>-0.650431</td>
      <td>-0.002729</td>
      <td>-0.213846</td>
      <td>-0.043777</td>
      <td>0.830365</td>
      <td>0.172072</td>
      <td>-0.152738</td>
      <td>-0.592088</td>
      <td>0.773981</td>
      <td>0.588985</td>
      <td>0.614419</td>
      <td>-0.484279</td>
      <td>0.118870</td>
      <td>-0.743319</td>
      <td>-1.126887</td>
      <td>-0.011692</td>
      <td>0.029426</td>
      <td>-0.276297</td>
      <td>0.110922</td>
      <td>0.297240</td>
      <td>0.463551</td>
      <td>-2.466448</td>
      <td>-1.311759</td>
      <td>-0.095525</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-0.289714</td>
      <td>-0.404731</td>
      <td>-0.036067</td>
      <td>-0.564642</td>
      <td>0.419772</td>
      <td>-0.425762</td>
      <td>0.659444</td>
      <td>-0.235105</td>
      <td>-0.343687</td>
      <td>-0.583238</td>
      <td>-0.082640</td>
      <td>-0.292118</td>
      <td>0.428008</td>
      <td>-0.172049</td>
      <td>-1.546083</td>
      <td>-2.158640</td>
      <td>-0.735692</td>
      <td>0.521981</td>
      <td>-0.445103</td>
      <td>0.438869</td>
      <td>0.184157</td>
      <td>-0.531478</td>
      <td>0.003228</td>
      <td>0.081418</td>
      <td>-0.355307</td>
      <td>-0.154758</td>
      <td>-0.537684</td>
      <td>-0.825372</td>
      <td>-0.619393</td>
      <td>0.647454</td>
      <td>0.059089</td>
      <td>0.240210</td>
      <td>-0.630798</td>
      <td>-1.298141</td>
      <td>-0.243101</td>
      <td>-0.015002</td>
      <td>-0.170182</td>
      <td>-0.116332</td>
      <td>0.887975</td>
      <td>0.075503</td>
      <td>...</td>
      <td>-0.431893</td>
      <td>0.054050</td>
      <td>0.954363</td>
      <td>0.797199</td>
      <td>-0.139483</td>
      <td>-1.212659</td>
      <td>-0.164316</td>
      <td>0.114249</td>
      <td>-0.288878</td>
      <td>0.257828</td>
      <td>-0.287218</td>
      <td>-1.305689</td>
      <td>0.723146</td>
      <td>0.543888</td>
      <td>-0.181549</td>
      <td>-0.055167</td>
      <td>0.716288</td>
      <td>0.832655</td>
      <td>-0.646123</td>
      <td>-0.696063</td>
      <td>0.391713</td>
      <td>0.087752</td>
      <td>0.812455</td>
      <td>0.247583</td>
      <td>0.053005</td>
      <td>0.066365</td>
      <td>-0.020669</td>
      <td>-0.287646</td>
      <td>-0.131802</td>
      <td>-0.539744</td>
      <td>-0.720192</td>
      <td>0.157202</td>
      <td>0.137647</td>
      <td>1.380240</td>
      <td>-0.525905</td>
      <td>0.242413</td>
      <td>0.254399</td>
      <td>-1.803720</td>
      <td>-1.229405</td>
      <td>-0.491247</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-0.719145</td>
      <td>-1.079862</td>
      <td>0.032183</td>
      <td>0.075822</td>
      <td>0.838374</td>
      <td>-0.555125</td>
      <td>-0.640974</td>
      <td>-0.035270</td>
      <td>-0.212310</td>
      <td>-0.132481</td>
      <td>-0.241087</td>
      <td>-1.447328</td>
      <td>0.136110</td>
      <td>1.013596</td>
      <td>-0.728451</td>
      <td>-0.915980</td>
      <td>-0.265989</td>
      <td>0.569246</td>
      <td>0.432360</td>
      <td>0.813300</td>
      <td>0.410713</td>
      <td>-1.079883</td>
      <td>0.088727</td>
      <td>0.842184</td>
      <td>0.045672</td>
      <td>0.077208</td>
      <td>1.055266</td>
      <td>0.373139</td>
      <td>-0.643736</td>
      <td>-0.175137</td>
      <td>-1.196768</td>
      <td>0.604511</td>
      <td>-1.157180</td>
      <td>-0.028590</td>
      <td>0.887680</td>
      <td>-0.059670</td>
      <td>0.016444</td>
      <td>-0.168926</td>
      <td>-0.298274</td>
      <td>-0.351519</td>
      <td>...</td>
      <td>-0.429015</td>
      <td>1.264200</td>
      <td>0.137430</td>
      <td>0.135612</td>
      <td>-0.714839</td>
      <td>0.081245</td>
      <td>0.901354</td>
      <td>0.592396</td>
      <td>-0.523054</td>
      <td>-0.789724</td>
      <td>0.497277</td>
      <td>-0.580895</td>
      <td>0.182748</td>
      <td>-0.448185</td>
      <td>-0.750611</td>
      <td>-0.461255</td>
      <td>0.719196</td>
      <td>1.174422</td>
      <td>0.181148</td>
      <td>0.570598</td>
      <td>0.570022</td>
      <td>0.191524</td>
      <td>0.124191</td>
      <td>-0.001597</td>
      <td>-0.281424</td>
      <td>-0.582128</td>
      <td>-0.797500</td>
      <td>-0.281293</td>
      <td>0.427243</td>
      <td>-0.373052</td>
      <td>1.030156</td>
      <td>0.597887</td>
      <td>0.367717</td>
      <td>0.177231</td>
      <td>0.257124</td>
      <td>0.663839</td>
      <td>-0.470567</td>
      <td>-1.125609</td>
      <td>-0.810717</td>
      <td>-0.740418</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.408918</td>
      <td>0.485861</td>
      <td>-0.420131</td>
      <td>-0.824127</td>
      <td>0.413895</td>
      <td>0.643589</td>
      <td>0.435264</td>
      <td>0.447112</td>
      <td>0.056479</td>
      <td>0.383634</td>
      <td>0.006345</td>
      <td>0.022661</td>
      <td>1.631996</td>
      <td>0.597405</td>
      <td>0.362509</td>
      <td>-1.481197</td>
      <td>-0.769876</td>
      <td>0.887130</td>
      <td>-0.094535</td>
      <td>-0.436687</td>
      <td>-0.438144</td>
      <td>-0.090775</td>
      <td>0.064710</td>
      <td>-0.540415</td>
      <td>-0.148221</td>
      <td>-1.284013</td>
      <td>0.154092</td>
      <td>0.513663</td>
      <td>0.089781</td>
      <td>-0.974713</td>
      <td>0.023606</td>
      <td>-0.804001</td>
      <td>-0.243103</td>
      <td>0.154116</td>
      <td>0.258921</td>
      <td>-0.974590</td>
      <td>-0.510968</td>
      <td>-0.143288</td>
      <td>0.602810</td>
      <td>0.721276</td>
      <td>...</td>
      <td>0.069355</td>
      <td>0.579515</td>
      <td>0.829218</td>
      <td>0.528205</td>
      <td>-0.978880</td>
      <td>0.051432</td>
      <td>0.501509</td>
      <td>0.294835</td>
      <td>0.668019</td>
      <td>-0.812289</td>
      <td>1.624414</td>
      <td>-0.287900</td>
      <td>-0.556725</td>
      <td>-0.617255</td>
      <td>-0.403816</td>
      <td>0.226323</td>
      <td>0.335265</td>
      <td>0.609046</td>
      <td>0.011008</td>
      <td>0.701471</td>
      <td>-0.436723</td>
      <td>-0.672600</td>
      <td>0.373852</td>
      <td>0.153360</td>
      <td>-0.157111</td>
      <td>-0.583565</td>
      <td>0.434767</td>
      <td>-0.075936</td>
      <td>0.275680</td>
      <td>-0.503251</td>
      <td>-0.255987</td>
      <td>0.169438</td>
      <td>-0.660180</td>
      <td>0.255294</td>
      <td>-0.662142</td>
      <td>0.339294</td>
      <td>0.114147</td>
      <td>0.698345</td>
      <td>0.273169</td>
      <td>-0.163938</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.572268</td>
      <td>-0.129250</td>
      <td>-0.333832</td>
      <td>0.230121</td>
      <td>0.844130</td>
      <td>0.648849</td>
      <td>-0.153635</td>
      <td>0.184233</td>
      <td>0.197902</td>
      <td>0.577377</td>
      <td>1.160332</td>
      <td>0.302728</td>
      <td>0.783645</td>
      <td>0.988015</td>
      <td>-0.611327</td>
      <td>-0.770650</td>
      <td>-0.759097</td>
      <td>1.028531</td>
      <td>0.497022</td>
      <td>0.345557</td>
      <td>-0.281529</td>
      <td>0.387843</td>
      <td>0.457894</td>
      <td>0.431609</td>
      <td>-0.342835</td>
      <td>-0.309588</td>
      <td>0.555537</td>
      <td>1.059230</td>
      <td>0.434460</td>
      <td>0.108502</td>
      <td>-0.622210</td>
      <td>-0.428034</td>
      <td>0.520558</td>
      <td>0.120437</td>
      <td>-0.315858</td>
      <td>-0.429228</td>
      <td>0.640815</td>
      <td>0.724300</td>
      <td>-0.448330</td>
      <td>-0.295297</td>
      <td>...</td>
      <td>0.048163</td>
      <td>-0.259464</td>
      <td>0.814007</td>
      <td>0.883552</td>
      <td>-0.417412</td>
      <td>0.150368</td>
      <td>0.243564</td>
      <td>0.156023</td>
      <td>0.333412</td>
      <td>-0.822392</td>
      <td>-0.394259</td>
      <td>-0.443860</td>
      <td>0.194470</td>
      <td>0.373091</td>
      <td>-0.569778</td>
      <td>1.309141</td>
      <td>0.269894</td>
      <td>0.127236</td>
      <td>0.124265</td>
      <td>-0.128794</td>
      <td>-0.301871</td>
      <td>0.198179</td>
      <td>-0.087874</td>
      <td>0.667442</td>
      <td>0.851182</td>
      <td>1.260561</td>
      <td>0.190861</td>
      <td>-0.237679</td>
      <td>0.280549</td>
      <td>-0.637860</td>
      <td>0.578778</td>
      <td>-0.102144</td>
      <td>-0.529282</td>
      <td>-0.088746</td>
      <td>0.516550</td>
      <td>1.281195</td>
      <td>0.406139</td>
      <td>0.759610</td>
      <td>0.032415</td>
      <td>-0.286967</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.249471</td>
      <td>0.637006</td>
      <td>0.329180</td>
      <td>0.258233</td>
      <td>0.176433</td>
      <td>0.258823</td>
      <td>0.397171</td>
      <td>0.956283</td>
      <td>-0.669157</td>
      <td>-0.735115</td>
      <td>0.504476</td>
      <td>0.077571</td>
      <td>0.506867</td>
      <td>0.192774</td>
      <td>-0.015215</td>
      <td>0.182679</td>
      <td>1.342535</td>
      <td>0.872681</td>
      <td>-0.950083</td>
      <td>-1.101081</td>
      <td>-0.132479</td>
      <td>0.140503</td>
      <td>0.309894</td>
      <td>-0.078142</td>
      <td>-0.497313</td>
      <td>0.465803</td>
      <td>-0.229240</td>
      <td>-0.258678</td>
      <td>0.455689</td>
      <td>-0.570549</td>
      <td>-0.809685</td>
      <td>-0.764859</td>
      <td>-1.071312</td>
      <td>-0.196090</td>
      <td>0.578877</td>
      <td>0.125166</td>
      <td>-0.732404</td>
      <td>-1.628765</td>
      <td>-0.385168</td>
      <td>0.580898</td>
      <td>...</td>
      <td>-0.248371</td>
      <td>-0.624265</td>
      <td>-0.415441</td>
      <td>0.569595</td>
      <td>-0.295000</td>
      <td>0.080782</td>
      <td>0.768794</td>
      <td>0.846194</td>
      <td>0.321098</td>
      <td>-0.730315</td>
      <td>-0.339477</td>
      <td>0.202068</td>
      <td>0.685028</td>
      <td>0.004617</td>
      <td>0.270551</td>
      <td>-0.672985</td>
      <td>-0.351569</td>
      <td>-0.307070</td>
      <td>0.286924</td>
      <td>-0.696517</td>
      <td>-0.724189</td>
      <td>-0.150807</td>
      <td>0.248660</td>
      <td>-1.010304</td>
      <td>-1.023042</td>
      <td>1.270101</td>
      <td>1.131169</td>
      <td>-0.680698</td>
      <td>0.636881</td>
      <td>0.168187</td>
      <td>0.821262</td>
      <td>0.264601</td>
      <td>-0.404559</td>
      <td>-1.328553</td>
      <td>-0.650508</td>
      <td>-0.039104</td>
      <td>0.254856</td>
      <td>-0.724827</td>
      <td>-0.469126</td>
      <td>-0.947287</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.318477</td>
      <td>0.214325</td>
      <td>-0.231698</td>
      <td>0.703552</td>
      <td>0.617394</td>
      <td>0.135229</td>
      <td>0.117274</td>
      <td>-0.940272</td>
      <td>-0.375550</td>
      <td>0.118514</td>
      <td>-0.014817</td>
      <td>-1.144020</td>
      <td>0.065261</td>
      <td>0.379127</td>
      <td>-1.059906</td>
      <td>-0.868151</td>
      <td>0.187075</td>
      <td>0.850799</td>
      <td>-0.508743</td>
      <td>-0.860060</td>
      <td>-0.370363</td>
      <td>-0.235824</td>
      <td>-0.178009</td>
      <td>0.591149</td>
      <td>-0.372861</td>
      <td>0.083662</td>
      <td>0.230325</td>
      <td>0.237333</td>
      <td>-0.121344</td>
      <td>-0.865806</td>
      <td>-0.406019</td>
      <td>0.170591</td>
      <td>1.019196</td>
      <td>-0.496043</td>
      <td>-0.103919</td>
      <td>-0.410102</td>
      <td>-0.641403</td>
      <td>0.052761</td>
      <td>-0.466734</td>
      <td>0.545564</td>
      <td>...</td>
      <td>-0.318495</td>
      <td>0.003960</td>
      <td>0.339890</td>
      <td>0.852336</td>
      <td>0.355986</td>
      <td>0.428501</td>
      <td>0.324890</td>
      <td>0.311731</td>
      <td>0.292925</td>
      <td>-0.503715</td>
      <td>1.291269</td>
      <td>-0.044714</td>
      <td>-1.024456</td>
      <td>1.484181</td>
      <td>0.236353</td>
      <td>-0.582399</td>
      <td>-0.811501</td>
      <td>0.168247</td>
      <td>0.164042</td>
      <td>0.361480</td>
      <td>0.364609</td>
      <td>-0.414041</td>
      <td>0.142771</td>
      <td>-0.188930</td>
      <td>0.078060</td>
      <td>0.147377</td>
      <td>-0.129277</td>
      <td>-0.367694</td>
      <td>0.373365</td>
      <td>-0.623509</td>
      <td>0.186860</td>
      <td>0.791732</td>
      <td>-0.994692</td>
      <td>0.552811</td>
      <td>-0.299035</td>
      <td>-0.841286</td>
      <td>-0.257320</td>
      <td>-0.327056</td>
      <td>-0.827732</td>
      <td>0.169282</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.476626</td>
      <td>0.077418</td>
      <td>0.188223</td>
      <td>-0.248885</td>
      <td>-0.062435</td>
      <td>0.931793</td>
      <td>-0.087520</td>
      <td>0.191513</td>
      <td>-1.209103</td>
      <td>-0.801364</td>
      <td>-0.556572</td>
      <td>0.406860</td>
      <td>0.618981</td>
      <td>-0.854465</td>
      <td>-0.719256</td>
      <td>-0.940999</td>
      <td>-0.809836</td>
      <td>-0.016609</td>
      <td>0.162748</td>
      <td>-0.261247</td>
      <td>0.534701</td>
      <td>-0.986893</td>
      <td>-0.615381</td>
      <td>-0.558428</td>
      <td>-0.991218</td>
      <td>-0.202887</td>
      <td>0.960554</td>
      <td>0.867626</td>
      <td>-0.756253</td>
      <td>0.070542</td>
      <td>0.697241</td>
      <td>0.002552</td>
      <td>-0.269348</td>
      <td>-0.333114</td>
      <td>-0.296530</td>
      <td>-0.324092</td>
      <td>0.005172</td>
      <td>-0.288070</td>
      <td>0.050183</td>
      <td>0.075960</td>
      <td>...</td>
      <td>1.580814</td>
      <td>0.428119</td>
      <td>0.971867</td>
      <td>0.718149</td>
      <td>0.168129</td>
      <td>-1.601278</td>
      <td>-0.520659</td>
      <td>0.202941</td>
      <td>0.472826</td>
      <td>-0.817708</td>
      <td>0.407409</td>
      <td>-0.054403</td>
      <td>1.083970</td>
      <td>0.904980</td>
      <td>0.554861</td>
      <td>-0.505666</td>
      <td>0.304620</td>
      <td>0.361089</td>
      <td>1.011518</td>
      <td>0.462352</td>
      <td>-0.714302</td>
      <td>0.371950</td>
      <td>0.718137</td>
      <td>0.196896</td>
      <td>-0.110597</td>
      <td>-0.375271</td>
      <td>0.126965</td>
      <td>0.183433</td>
      <td>1.000726</td>
      <td>-0.668422</td>
      <td>-0.597391</td>
      <td>-0.186878</td>
      <td>-1.350341</td>
      <td>0.304332</td>
      <td>-0.314702</td>
      <td>-0.029217</td>
      <td>0.205091</td>
      <td>0.525155</td>
      <td>0.148988</td>
      <td>-0.018095</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-0.699913</td>
      <td>0.139653</td>
      <td>0.929641</td>
      <td>-0.861830</td>
      <td>-0.821577</td>
      <td>-0.511299</td>
      <td>0.282238</td>
      <td>0.886373</td>
      <td>0.082057</td>
      <td>-0.413585</td>
      <td>0.031988</td>
      <td>0.080174</td>
      <td>0.112352</td>
      <td>-0.232524</td>
      <td>-0.900730</td>
      <td>-1.450360</td>
      <td>0.082987</td>
      <td>0.741856</td>
      <td>0.132352</td>
      <td>0.462675</td>
      <td>-0.203072</td>
      <td>0.418326</td>
      <td>0.902426</td>
      <td>1.003652</td>
      <td>-0.691034</td>
      <td>0.015078</td>
      <td>1.036808</td>
      <td>-0.278002</td>
      <td>1.193713</td>
      <td>0.205357</td>
      <td>-0.422052</td>
      <td>-0.332746</td>
      <td>-0.441621</td>
      <td>-0.278618</td>
      <td>-0.198501</td>
      <td>-1.015750</td>
      <td>-0.181035</td>
      <td>-0.249623</td>
      <td>0.417875</td>
      <td>-0.008193</td>
      <td>...</td>
      <td>-0.664150</td>
      <td>0.372715</td>
      <td>-0.256694</td>
      <td>-0.458469</td>
      <td>-0.807357</td>
      <td>-0.849468</td>
      <td>-0.486121</td>
      <td>-0.005601</td>
      <td>0.133644</td>
      <td>-0.321749</td>
      <td>0.694378</td>
      <td>-0.653184</td>
      <td>-0.622011</td>
      <td>1.352158</td>
      <td>-0.825696</td>
      <td>0.273692</td>
      <td>0.254164</td>
      <td>-0.136020</td>
      <td>-0.726465</td>
      <td>0.067991</td>
      <td>0.338229</td>
      <td>0.787476</td>
      <td>-0.074091</td>
      <td>0.481165</td>
      <td>0.498805</td>
      <td>0.314208</td>
      <td>-0.601784</td>
      <td>-0.726307</td>
      <td>0.734128</td>
      <td>-0.443501</td>
      <td>-0.499470</td>
      <td>-0.588484</td>
      <td>-1.009283</td>
      <td>-0.688445</td>
      <td>0.636175</td>
      <td>0.373333</td>
      <td>0.441763</td>
      <td>-1.475345</td>
      <td>-0.907732</td>
      <td>-0.586087</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.672407</td>
      <td>0.952205</td>
      <td>0.709517</td>
      <td>0.267009</td>
      <td>-1.388344</td>
      <td>-0.463348</td>
      <td>-0.906605</td>
      <td>-1.048001</td>
      <td>0.007178</td>
      <td>-0.525365</td>
      <td>-0.354428</td>
      <td>-0.130515</td>
      <td>0.587777</td>
      <td>0.126074</td>
      <td>1.002365</td>
      <td>0.244704</td>
      <td>-0.213109</td>
      <td>0.208057</td>
      <td>-0.362083</td>
      <td>-0.152381</td>
      <td>0.176118</td>
      <td>-0.242888</td>
      <td>-0.162131</td>
      <td>-0.065513</td>
      <td>-1.188869</td>
      <td>-0.553337</td>
      <td>-0.743281</td>
      <td>-0.261555</td>
      <td>0.731723</td>
      <td>0.025330</td>
      <td>-0.349591</td>
      <td>0.014832</td>
      <td>0.887307</td>
      <td>0.609826</td>
      <td>0.251012</td>
      <td>-1.342625</td>
      <td>-0.483661</td>
      <td>-0.197459</td>
      <td>0.343918</td>
      <td>0.690247</td>
      <td>...</td>
      <td>-0.098649</td>
      <td>0.674940</td>
      <td>0.126655</td>
      <td>0.975087</td>
      <td>-0.498009</td>
      <td>-0.565403</td>
      <td>0.959195</td>
      <td>0.340496</td>
      <td>0.709971</td>
      <td>-0.408879</td>
      <td>-0.401947</td>
      <td>-0.292842</td>
      <td>0.879456</td>
      <td>0.334517</td>
      <td>0.623372</td>
      <td>1.120610</td>
      <td>-0.027454</td>
      <td>-0.775215</td>
      <td>-0.081390</td>
      <td>1.637924</td>
      <td>0.860235</td>
      <td>0.539339</td>
      <td>-0.122716</td>
      <td>0.551609</td>
      <td>0.972291</td>
      <td>0.992710</td>
      <td>0.255556</td>
      <td>-0.512729</td>
      <td>-0.969702</td>
      <td>-0.951861</td>
      <td>-0.720445</td>
      <td>0.144477</td>
      <td>0.520893</td>
      <td>0.457516</td>
      <td>0.208842</td>
      <td>0.587780</td>
      <td>0.516534</td>
      <td>1.949281</td>
      <td>1.447146</td>
      <td>1.081090</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.357172</td>
      <td>0.593300</td>
      <td>0.223267</td>
      <td>-0.829619</td>
      <td>0.315270</td>
      <td>1.057159</td>
      <td>0.199435</td>
      <td>0.578986</td>
      <td>0.897126</td>
      <td>0.414465</td>
      <td>0.016529</td>
      <td>-0.147698</td>
      <td>0.728637</td>
      <td>0.543296</td>
      <td>-0.843142</td>
      <td>-0.289779</td>
      <td>-0.194510</td>
      <td>0.176586</td>
      <td>-0.474214</td>
      <td>-0.926731</td>
      <td>-0.363247</td>
      <td>0.280390</td>
      <td>0.364010</td>
      <td>-0.454901</td>
      <td>-0.113495</td>
      <td>-0.009919</td>
      <td>-0.818093</td>
      <td>-0.786263</td>
      <td>0.640950</td>
      <td>-0.216296</td>
      <td>-1.146194</td>
      <td>-0.565503</td>
      <td>-1.032738</td>
      <td>-1.619208</td>
      <td>1.000053</td>
      <td>-0.239423</td>
      <td>0.011466</td>
      <td>0.044389</td>
      <td>0.740129</td>
      <td>1.055261</td>
      <td>...</td>
      <td>0.148251</td>
      <td>1.229684</td>
      <td>0.968781</td>
      <td>1.748174</td>
      <td>0.250375</td>
      <td>0.227883</td>
      <td>-0.279481</td>
      <td>0.980966</td>
      <td>0.394453</td>
      <td>-0.106956</td>
      <td>-0.217268</td>
      <td>-1.969188</td>
      <td>0.361639</td>
      <td>0.128588</td>
      <td>-0.100205</td>
      <td>-0.208876</td>
      <td>0.746194</td>
      <td>0.248356</td>
      <td>0.900583</td>
      <td>0.796537</td>
      <td>-0.449337</td>
      <td>-0.370367</td>
      <td>0.033177</td>
      <td>0.644887</td>
      <td>0.910088</td>
      <td>0.354319</td>
      <td>-0.208412</td>
      <td>-0.033956</td>
      <td>0.686307</td>
      <td>-0.796219</td>
      <td>-0.442499</td>
      <td>-0.160767</td>
      <td>-1.119778</td>
      <td>-0.246012</td>
      <td>-0.148857</td>
      <td>0.736086</td>
      <td>-0.030800</td>
      <td>-1.013410</td>
      <td>-0.575062</td>
      <td>0.094787</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.944952</td>
      <td>-0.407007</td>
      <td>0.107767</td>
      <td>0.639072</td>
      <td>-0.320666</td>
      <td>0.359890</td>
      <td>0.858073</td>
      <td>-0.345944</td>
      <td>1.412299</td>
      <td>0.013962</td>
      <td>0.190972</td>
      <td>-0.060249</td>
      <td>0.698852</td>
      <td>-0.213438</td>
      <td>-0.121265</td>
      <td>-0.302822</td>
      <td>0.630765</td>
      <td>0.595604</td>
      <td>-0.643902</td>
      <td>-0.533396</td>
      <td>0.672331</td>
      <td>-0.129760</td>
      <td>-0.189135</td>
      <td>0.148998</td>
      <td>0.400593</td>
      <td>0.161745</td>
      <td>0.715647</td>
      <td>1.704239</td>
      <td>0.607181</td>
      <td>0.758216</td>
      <td>0.186609</td>
      <td>0.227212</td>
      <td>-0.278890</td>
      <td>-0.303986</td>
      <td>-0.687726</td>
      <td>-0.375450</td>
      <td>-0.402042</td>
      <td>-0.871317</td>
      <td>0.355440</td>
      <td>-0.793708</td>
      <td>...</td>
      <td>0.297670</td>
      <td>0.072006</td>
      <td>-0.094669</td>
      <td>0.542605</td>
      <td>-0.672509</td>
      <td>-1.255771</td>
      <td>-1.584926</td>
      <td>-0.229287</td>
      <td>0.859134</td>
      <td>-0.680553</td>
      <td>-0.211054</td>
      <td>-1.043825</td>
      <td>0.671170</td>
      <td>-0.059779</td>
      <td>-1.106196</td>
      <td>-0.719889</td>
      <td>-0.673263</td>
      <td>-0.410117</td>
      <td>-0.298342</td>
      <td>-0.846200</td>
      <td>0.615161</td>
      <td>-0.589564</td>
      <td>-0.409902</td>
      <td>-0.065439</td>
      <td>0.315099</td>
      <td>0.751540</td>
      <td>0.672917</td>
      <td>-0.405178</td>
      <td>0.144187</td>
      <td>0.062243</td>
      <td>0.304998</td>
      <td>-0.034569</td>
      <td>-0.350933</td>
      <td>-0.496250</td>
      <td>0.176505</td>
      <td>-0.362411</td>
      <td>-0.951673</td>
      <td>-2.215378</td>
      <td>-1.047740</td>
      <td>-0.518872</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.469931</td>
      <td>0.237451</td>
      <td>-0.066353</td>
      <td>-0.226259</td>
      <td>0.565182</td>
      <td>-0.183846</td>
      <td>0.169062</td>
      <td>-0.639444</td>
      <td>-0.641793</td>
      <td>-0.320704</td>
      <td>-0.197231</td>
      <td>0.224836</td>
      <td>0.361237</td>
      <td>0.267065</td>
      <td>-0.421306</td>
      <td>0.193087</td>
      <td>-0.304498</td>
      <td>-0.724581</td>
      <td>-0.670857</td>
      <td>0.111787</td>
      <td>0.163908</td>
      <td>0.704773</td>
      <td>-0.401321</td>
      <td>0.852872</td>
      <td>-0.151160</td>
      <td>-0.205021</td>
      <td>-0.258609</td>
      <td>0.194151</td>
      <td>-0.444419</td>
      <td>-0.067794</td>
      <td>-0.018163</td>
      <td>0.135812</td>
      <td>-0.985811</td>
      <td>-0.683979</td>
      <td>-0.881234</td>
      <td>-0.554073</td>
      <td>-0.387612</td>
      <td>-0.245803</td>
      <td>0.563683</td>
      <td>-0.052867</td>
      <td>...</td>
      <td>-1.702369</td>
      <td>0.284283</td>
      <td>0.452808</td>
      <td>0.636388</td>
      <td>0.648865</td>
      <td>-0.526419</td>
      <td>0.471712</td>
      <td>0.054068</td>
      <td>0.709099</td>
      <td>-0.471019</td>
      <td>-0.513503</td>
      <td>-1.294713</td>
      <td>-0.005639</td>
      <td>0.726641</td>
      <td>0.070046</td>
      <td>0.254147</td>
      <td>-0.294250</td>
      <td>0.594361</td>
      <td>0.053567</td>
      <td>0.094482</td>
      <td>-0.428644</td>
      <td>0.054182</td>
      <td>-0.193110</td>
      <td>0.781435</td>
      <td>0.256793</td>
      <td>0.618104</td>
      <td>0.389914</td>
      <td>-0.313740</td>
      <td>0.356452</td>
      <td>-1.151711</td>
      <td>0.688105</td>
      <td>-0.163222</td>
      <td>-0.529900</td>
      <td>-0.044432</td>
      <td>-0.681172</td>
      <td>0.035051</td>
      <td>-0.344323</td>
      <td>0.502030</td>
      <td>0.465978</td>
      <td>0.176487</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.006950</td>
      <td>0.846758</td>
      <td>0.764945</td>
      <td>0.565248</td>
      <td>1.056352</td>
      <td>0.911092</td>
      <td>1.713120</td>
      <td>-0.352888</td>
      <td>-0.018394</td>
      <td>-0.830468</td>
      <td>-0.073678</td>
      <td>-0.852834</td>
      <td>0.650990</td>
      <td>-1.045777</td>
      <td>-0.460344</td>
      <td>-0.707618</td>
      <td>-0.126526</td>
      <td>0.382800</td>
      <td>-0.373834</td>
      <td>-0.585063</td>
      <td>-0.528367</td>
      <td>0.351074</td>
      <td>0.569952</td>
      <td>0.113688</td>
      <td>-0.409629</td>
      <td>-0.919849</td>
      <td>-0.528643</td>
      <td>-0.440009</td>
      <td>-0.779833</td>
      <td>-0.167433</td>
      <td>-0.210771</td>
      <td>-0.350512</td>
      <td>-0.962660</td>
      <td>-1.359123</td>
      <td>-0.084136</td>
      <td>-0.076466</td>
      <td>-0.139624</td>
      <td>0.403648</td>
      <td>-0.059625</td>
      <td>0.674641</td>
      <td>...</td>
      <td>-0.103446</td>
      <td>0.810935</td>
      <td>0.195566</td>
      <td>0.354135</td>
      <td>-1.620847</td>
      <td>0.113850</td>
      <td>0.745138</td>
      <td>1.211344</td>
      <td>0.824224</td>
      <td>-0.197713</td>
      <td>1.103005</td>
      <td>-0.465314</td>
      <td>-0.617223</td>
      <td>-0.193438</td>
      <td>-0.025244</td>
      <td>-0.028006</td>
      <td>-0.121334</td>
      <td>-0.681508</td>
      <td>-1.186248</td>
      <td>-0.796372</td>
      <td>0.420510</td>
      <td>-0.308458</td>
      <td>0.911989</td>
      <td>-0.386018</td>
      <td>-0.140467</td>
      <td>0.122142</td>
      <td>0.497843</td>
      <td>0.126234</td>
      <td>-0.000353</td>
      <td>0.192011</td>
      <td>-1.301727</td>
      <td>0.354945</td>
      <td>-1.099661</td>
      <td>0.360795</td>
      <td>-0.574758</td>
      <td>0.329130</td>
      <td>0.101404</td>
      <td>1.646240</td>
      <td>0.800153</td>
      <td>0.859373</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.296782</td>
      <td>1.160532</td>
      <td>0.166721</td>
      <td>-0.256818</td>
      <td>0.624648</td>
      <td>-0.259935</td>
      <td>0.566254</td>
      <td>-0.360533</td>
      <td>0.472135</td>
      <td>-0.862121</td>
      <td>0.455757</td>
      <td>-1.122278</td>
      <td>-0.048447</td>
      <td>-0.499051</td>
      <td>-1.184439</td>
      <td>-1.028375</td>
      <td>0.249714</td>
      <td>0.541549</td>
      <td>-0.073223</td>
      <td>1.347024</td>
      <td>0.331681</td>
      <td>0.118653</td>
      <td>-0.173511</td>
      <td>-0.259342</td>
      <td>-1.073230</td>
      <td>-0.048977</td>
      <td>0.463817</td>
      <td>0.310912</td>
      <td>0.534151</td>
      <td>-1.042947</td>
      <td>-0.059592</td>
      <td>0.468949</td>
      <td>-0.020222</td>
      <td>-0.834934</td>
      <td>0.476681</td>
      <td>1.199633</td>
      <td>-0.853842</td>
      <td>-0.776125</td>
      <td>0.134532</td>
      <td>0.083514</td>
      <td>...</td>
      <td>-0.610342</td>
      <td>-1.199190</td>
      <td>0.510126</td>
      <td>0.700067</td>
      <td>-0.869021</td>
      <td>-0.673886</td>
      <td>-0.375095</td>
      <td>1.070362</td>
      <td>0.483839</td>
      <td>-0.861496</td>
      <td>-0.275016</td>
      <td>-0.263592</td>
      <td>0.320546</td>
      <td>-0.354890</td>
      <td>-0.147337</td>
      <td>-0.337892</td>
      <td>0.461894</td>
      <td>0.130835</td>
      <td>-0.462720</td>
      <td>0.057263</td>
      <td>0.125284</td>
      <td>-0.358087</td>
      <td>0.490613</td>
      <td>-0.725922</td>
      <td>0.731560</td>
      <td>0.584100</td>
      <td>-0.783474</td>
      <td>-0.121794</td>
      <td>-0.282113</td>
      <td>0.187002</td>
      <td>-0.591829</td>
      <td>0.017711</td>
      <td>0.438936</td>
      <td>-0.146827</td>
      <td>0.552768</td>
      <td>-0.006442</td>
      <td>0.652018</td>
      <td>1.336224</td>
      <td>1.523541</td>
      <td>0.475603</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.430309</td>
      <td>-0.124762</td>
      <td>-0.168708</td>
      <td>-0.049586</td>
      <td>0.530616</td>
      <td>0.205161</td>
      <td>0.523787</td>
      <td>0.016217</td>
      <td>-0.182360</td>
      <td>0.275519</td>
      <td>0.079573</td>
      <td>-0.336723</td>
      <td>-0.334256</td>
      <td>-0.621340</td>
      <td>-1.131196</td>
      <td>-1.194860</td>
      <td>-0.235602</td>
      <td>1.078595</td>
      <td>0.015927</td>
      <td>-0.473061</td>
      <td>-0.737141</td>
      <td>-1.252234</td>
      <td>-0.196867</td>
      <td>0.550388</td>
      <td>-0.133387</td>
      <td>0.250685</td>
      <td>0.493851</td>
      <td>0.308240</td>
      <td>1.223927</td>
      <td>-0.505858</td>
      <td>0.372332</td>
      <td>0.744549</td>
      <td>0.084785</td>
      <td>0.961219</td>
      <td>1.052577</td>
      <td>-0.106071</td>
      <td>-0.331047</td>
      <td>0.261582</td>
      <td>0.531466</td>
      <td>0.434409</td>
      <td>...</td>
      <td>0.703600</td>
      <td>0.617017</td>
      <td>0.577329</td>
      <td>0.860862</td>
      <td>0.057195</td>
      <td>-0.671826</td>
      <td>-0.497900</td>
      <td>0.572486</td>
      <td>0.178192</td>
      <td>-1.184849</td>
      <td>0.021420</td>
      <td>-0.431379</td>
      <td>-0.178905</td>
      <td>-0.008344</td>
      <td>-0.476885</td>
      <td>0.116806</td>
      <td>1.691882</td>
      <td>-0.971180</td>
      <td>-0.398498</td>
      <td>0.981492</td>
      <td>0.255616</td>
      <td>-0.478849</td>
      <td>-1.075004</td>
      <td>-0.458067</td>
      <td>0.490489</td>
      <td>-0.552659</td>
      <td>-0.493013</td>
      <td>-0.170457</td>
      <td>0.776421</td>
      <td>-0.454685</td>
      <td>-0.699488</td>
      <td>-0.082939</td>
      <td>0.238813</td>
      <td>-0.413854</td>
      <td>-0.908726</td>
      <td>0.016666</td>
      <td>-0.193538</td>
      <td>-0.582733</td>
      <td>-0.999366</td>
      <td>-1.124612</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.581284</td>
      <td>-0.378962</td>
      <td>-0.256588</td>
      <td>-0.240862</td>
      <td>0.366177</td>
      <td>0.247617</td>
      <td>0.785169</td>
      <td>0.311228</td>
      <td>0.044228</td>
      <td>0.935957</td>
      <td>0.651968</td>
      <td>-0.419009</td>
      <td>0.338140</td>
      <td>-0.312807</td>
      <td>0.542174</td>
      <td>-0.075408</td>
      <td>0.645612</td>
      <td>-0.062614</td>
      <td>-0.279495</td>
      <td>-0.668231</td>
      <td>-1.042812</td>
      <td>0.355319</td>
      <td>0.426334</td>
      <td>0.306516</td>
      <td>-0.984489</td>
      <td>-0.153727</td>
      <td>0.390708</td>
      <td>-0.405402</td>
      <td>0.120100</td>
      <td>-0.128529</td>
      <td>-0.253222</td>
      <td>-0.105888</td>
      <td>0.333564</td>
      <td>-0.066969</td>
      <td>0.234990</td>
      <td>0.167639</td>
      <td>-0.076564</td>
      <td>-0.724083</td>
      <td>-0.581347</td>
      <td>-0.130863</td>
      <td>...</td>
      <td>-0.573951</td>
      <td>-0.159150</td>
      <td>-0.593616</td>
      <td>0.417595</td>
      <td>-0.392274</td>
      <td>-0.282237</td>
      <td>-0.411976</td>
      <td>0.508558</td>
      <td>-0.285962</td>
      <td>-1.196378</td>
      <td>0.501723</td>
      <td>-0.309344</td>
      <td>-0.274618</td>
      <td>-0.054761</td>
      <td>0.224497</td>
      <td>-0.243917</td>
      <td>0.330264</td>
      <td>-0.820614</td>
      <td>-0.178800</td>
      <td>-0.524566</td>
      <td>-0.453043</td>
      <td>-1.276315</td>
      <td>-0.251354</td>
      <td>0.389876</td>
      <td>0.873196</td>
      <td>0.281526</td>
      <td>0.313318</td>
      <td>0.346782</td>
      <td>0.833216</td>
      <td>0.258439</td>
      <td>-0.580957</td>
      <td>-0.613700</td>
      <td>-0.304791</td>
      <td>0.221215</td>
      <td>-0.703205</td>
      <td>-1.102491</td>
      <td>-0.647974</td>
      <td>-1.234992</td>
      <td>-1.249699</td>
      <td>-0.627882</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.063866</td>
      <td>-0.302876</td>
      <td>0.363307</td>
      <td>0.447656</td>
      <td>0.419185</td>
      <td>0.266603</td>
      <td>-0.228510</td>
      <td>0.305768</td>
      <td>0.298365</td>
      <td>-0.385153</td>
      <td>0.447235</td>
      <td>-0.285656</td>
      <td>0.196292</td>
      <td>0.948282</td>
      <td>0.134556</td>
      <td>-0.521656</td>
      <td>0.585631</td>
      <td>0.208435</td>
      <td>1.129653</td>
      <td>0.461843</td>
      <td>0.140844</td>
      <td>-0.098162</td>
      <td>0.298558</td>
      <td>0.362588</td>
      <td>-0.164187</td>
      <td>-0.152764</td>
      <td>-0.631488</td>
      <td>-0.453381</td>
      <td>0.841287</td>
      <td>0.527977</td>
      <td>0.809117</td>
      <td>0.105036</td>
      <td>0.332971</td>
      <td>-0.233513</td>
      <td>0.670245</td>
      <td>0.654795</td>
      <td>0.314376</td>
      <td>-0.484111</td>
      <td>0.157374</td>
      <td>-0.240928</td>
      <td>...</td>
      <td>0.609547</td>
      <td>-0.050807</td>
      <td>-0.358520</td>
      <td>0.007619</td>
      <td>0.095893</td>
      <td>0.139866</td>
      <td>-0.357958</td>
      <td>-0.132194</td>
      <td>0.108103</td>
      <td>0.533547</td>
      <td>0.184578</td>
      <td>1.221941</td>
      <td>0.248709</td>
      <td>0.764061</td>
      <td>0.238744</td>
      <td>-0.146290</td>
      <td>0.781898</td>
      <td>0.399413</td>
      <td>0.685375</td>
      <td>0.210844</td>
      <td>-0.039649</td>
      <td>0.073093</td>
      <td>0.754430</td>
      <td>-1.149095</td>
      <td>-0.332958</td>
      <td>0.807894</td>
      <td>0.123127</td>
      <td>-0.533025</td>
      <td>0.135056</td>
      <td>-0.761587</td>
      <td>-0.514864</td>
      <td>-0.113475</td>
      <td>0.367102</td>
      <td>0.318871</td>
      <td>1.000984</td>
      <td>-0.322166</td>
      <td>0.645765</td>
      <td>-0.311385</td>
      <td>0.190876</td>
      <td>-0.076661</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.006472</td>
      <td>-0.138200</td>
      <td>0.466418</td>
      <td>-0.449807</td>
      <td>0.431135</td>
      <td>0.688695</td>
      <td>-0.219907</td>
      <td>-1.312139</td>
      <td>-0.342582</td>
      <td>-0.959809</td>
      <td>-1.652990</td>
      <td>0.195393</td>
      <td>0.207240</td>
      <td>-0.158710</td>
      <td>1.356283</td>
      <td>0.374131</td>
      <td>0.433719</td>
      <td>0.380683</td>
      <td>0.503631</td>
      <td>-0.811851</td>
      <td>0.449467</td>
      <td>-0.958383</td>
      <td>0.467694</td>
      <td>1.063062</td>
      <td>-0.236981</td>
      <td>0.237868</td>
      <td>0.399120</td>
      <td>-0.651966</td>
      <td>0.014861</td>
      <td>0.387035</td>
      <td>-0.042264</td>
      <td>0.100157</td>
      <td>0.085534</td>
      <td>-0.616378</td>
      <td>-0.330783</td>
      <td>0.928625</td>
      <td>0.820370</td>
      <td>0.215375</td>
      <td>-0.380972</td>
      <td>0.448435</td>
      <td>...</td>
      <td>-0.022717</td>
      <td>0.703309</td>
      <td>0.317413</td>
      <td>-0.035865</td>
      <td>-0.384845</td>
      <td>0.231576</td>
      <td>0.682854</td>
      <td>0.032568</td>
      <td>-0.218840</td>
      <td>-0.848460</td>
      <td>-0.225581</td>
      <td>-0.314511</td>
      <td>-0.840510</td>
      <td>0.256946</td>
      <td>1.337600</td>
      <td>-0.463791</td>
      <td>0.275876</td>
      <td>0.101583</td>
      <td>0.265382</td>
      <td>0.520172</td>
      <td>0.286839</td>
      <td>-0.046771</td>
      <td>-0.141998</td>
      <td>-0.196719</td>
      <td>0.609429</td>
      <td>1.359995</td>
      <td>-0.443961</td>
      <td>-0.118385</td>
      <td>0.511550</td>
      <td>0.893834</td>
      <td>0.140471</td>
      <td>0.053400</td>
      <td>0.564842</td>
      <td>0.364722</td>
      <td>-0.139970</td>
      <td>1.014293</td>
      <td>1.179110</td>
      <td>-2.144794</td>
      <td>-1.045310</td>
      <td>-1.190442</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.724279</td>
      <td>-0.073510</td>
      <td>0.712096</td>
      <td>0.113409</td>
      <td>-0.704999</td>
      <td>0.574721</td>
      <td>0.309096</td>
      <td>0.075155</td>
      <td>-0.094951</td>
      <td>-1.376578</td>
      <td>-0.840602</td>
      <td>-0.712073</td>
      <td>-1.431700</td>
      <td>0.231272</td>
      <td>1.202960</td>
      <td>0.472758</td>
      <td>-1.198038</td>
      <td>0.041354</td>
      <td>-0.839701</td>
      <td>0.258968</td>
      <td>-0.436894</td>
      <td>-0.131854</td>
      <td>0.588039</td>
      <td>0.474290</td>
      <td>0.634711</td>
      <td>1.470497</td>
      <td>0.446854</td>
      <td>0.458535</td>
      <td>2.054990</td>
      <td>1.109946</td>
      <td>-0.020816</td>
      <td>0.300283</td>
      <td>-0.600881</td>
      <td>0.841757</td>
      <td>-0.127244</td>
      <td>0.235101</td>
      <td>0.459038</td>
      <td>0.172926</td>
      <td>0.050353</td>
      <td>-0.362680</td>
      <td>...</td>
      <td>0.409456</td>
      <td>0.824385</td>
      <td>0.178648</td>
      <td>1.915326</td>
      <td>0.808125</td>
      <td>0.293318</td>
      <td>0.016784</td>
      <td>-0.184315</td>
      <td>-0.319253</td>
      <td>0.181442</td>
      <td>1.391225</td>
      <td>0.914516</td>
      <td>0.117670</td>
      <td>1.015223</td>
      <td>0.312800</td>
      <td>-0.278868</td>
      <td>0.411468</td>
      <td>0.246970</td>
      <td>0.266464</td>
      <td>0.546159</td>
      <td>0.322583</td>
      <td>-1.163291</td>
      <td>-0.865371</td>
      <td>0.371831</td>
      <td>0.699836</td>
      <td>0.689090</td>
      <td>0.228458</td>
      <td>-0.401944</td>
      <td>-1.290389</td>
      <td>-0.106693</td>
      <td>-0.285406</td>
      <td>-1.020131</td>
      <td>-0.368875</td>
      <td>0.192957</td>
      <td>-0.084155</td>
      <td>-0.839335</td>
      <td>0.251757</td>
      <td>-0.247856</td>
      <td>-0.207683</td>
      <td>0.441967</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.049181</td>
      <td>0.366014</td>
      <td>-0.099563</td>
      <td>-0.753552</td>
      <td>-0.881491</td>
      <td>-0.141518</td>
      <td>-0.325178</td>
      <td>-1.094033</td>
      <td>0.058080</td>
      <td>0.601506</td>
      <td>0.656525</td>
      <td>0.946405</td>
      <td>1.483734</td>
      <td>-0.117030</td>
      <td>-0.159873</td>
      <td>0.451603</td>
      <td>0.163933</td>
      <td>-0.464928</td>
      <td>-0.317273</td>
      <td>0.441055</td>
      <td>0.004331</td>
      <td>0.037108</td>
      <td>-0.462271</td>
      <td>-0.284446</td>
      <td>-0.446608</td>
      <td>-1.323659</td>
      <td>0.041883</td>
      <td>-1.250205</td>
      <td>0.724910</td>
      <td>0.761434</td>
      <td>0.407200</td>
      <td>-0.273975</td>
      <td>-0.527509</td>
      <td>-0.277554</td>
      <td>0.646768</td>
      <td>0.031467</td>
      <td>0.539818</td>
      <td>0.017893</td>
      <td>-0.723198</td>
      <td>0.082932</td>
      <td>...</td>
      <td>0.403784</td>
      <td>0.880308</td>
      <td>-0.651993</td>
      <td>0.865299</td>
      <td>0.075799</td>
      <td>1.334470</td>
      <td>0.361255</td>
      <td>0.565873</td>
      <td>0.344903</td>
      <td>0.445266</td>
      <td>-0.282161</td>
      <td>0.715440</td>
      <td>0.358259</td>
      <td>0.315103</td>
      <td>-0.249089</td>
      <td>0.787231</td>
      <td>-0.768781</td>
      <td>0.983348</td>
      <td>0.876363</td>
      <td>1.289662</td>
      <td>0.887525</td>
      <td>0.784678</td>
      <td>-0.207587</td>
      <td>0.580917</td>
      <td>0.802298</td>
      <td>-0.282593</td>
      <td>-0.851757</td>
      <td>-0.852121</td>
      <td>0.178824</td>
      <td>0.332160</td>
      <td>-0.115686</td>
      <td>0.602048</td>
      <td>0.850947</td>
      <td>0.539927</td>
      <td>-0.411938</td>
      <td>-0.335042</td>
      <td>0.294932</td>
      <td>-2.104478</td>
      <td>-1.192249</td>
      <td>-0.769755</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.385702</td>
      <td>0.108454</td>
      <td>1.282936</td>
      <td>-0.269870</td>
      <td>0.089527</td>
      <td>0.267125</td>
      <td>0.491096</td>
      <td>0.066401</td>
      <td>-0.706782</td>
      <td>-1.372880</td>
      <td>-0.488664</td>
      <td>-0.154280</td>
      <td>-0.724820</td>
      <td>0.010292</td>
      <td>0.813152</td>
      <td>-0.831804</td>
      <td>-0.545759</td>
      <td>0.239092</td>
      <td>0.758477</td>
      <td>0.842976</td>
      <td>0.267276</td>
      <td>-0.205837</td>
      <td>-0.139815</td>
      <td>-0.490238</td>
      <td>-0.269294</td>
      <td>0.349357</td>
      <td>-0.400393</td>
      <td>0.076486</td>
      <td>0.247961</td>
      <td>-0.385522</td>
      <td>0.687161</td>
      <td>1.155165</td>
      <td>0.410807</td>
      <td>0.521932</td>
      <td>1.163077</td>
      <td>-0.174627</td>
      <td>0.370992</td>
      <td>0.037648</td>
      <td>-0.781791</td>
      <td>-1.793415</td>
      <td>...</td>
      <td>0.138344</td>
      <td>0.817678</td>
      <td>-0.506943</td>
      <td>0.748234</td>
      <td>1.025172</td>
      <td>-0.002868</td>
      <td>0.693764</td>
      <td>0.269171</td>
      <td>-0.117864</td>
      <td>-1.093793</td>
      <td>0.009883</td>
      <td>-0.102091</td>
      <td>-0.388235</td>
      <td>0.072237</td>
      <td>0.201684</td>
      <td>1.075657</td>
      <td>-0.514170</td>
      <td>-0.434135</td>
      <td>0.144728</td>
      <td>0.727487</td>
      <td>0.352759</td>
      <td>-0.485605</td>
      <td>-0.957925</td>
      <td>-0.278833</td>
      <td>-0.387349</td>
      <td>-0.692136</td>
      <td>-0.071486</td>
      <td>-0.382975</td>
      <td>-1.514153</td>
      <td>0.272134</td>
      <td>-1.062560</td>
      <td>-0.199587</td>
      <td>-0.248996</td>
      <td>0.719973</td>
      <td>-0.706507</td>
      <td>-1.042898</td>
      <td>0.777500</td>
      <td>0.616016</td>
      <td>0.666136</td>
      <td>0.916648</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f1c50151b50&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.140747  0.037876  30.117969  2.819010e-199  1.066511  1.214983
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  6.189 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>