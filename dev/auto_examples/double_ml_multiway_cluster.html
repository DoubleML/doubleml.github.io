
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.101715efdecc9b59cb6e1ddfa685c31f.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d8bbf5861d671d414e1a.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">


    
    <a class="navbar-brand" href="../index.html">
      <p class="title">DoubleML</p>
    </a>
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  DoubleML
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/install.html">
  Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/intro.html">
  Getting started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../guide/guide.html">
  User guide
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api.html">
  Python API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference external nav-link" href="https://docs.doubleml.org/r/stable/">
  R API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../release/release.html">
  Release notes
 </a>
</li>

        
      </ul>

      <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><p class="logo" style="text-align:center;"><a href="../index.html">
    <img class="logo" src="../logo.png" alt="Logo" width="65%" height="65%">
</a></p><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l2 current active">
  <a class="current reference internal" href="#">
   Multiway Cluster Robust DML
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="double_ml_bonus_data.html">
   DML: Bonus Data
  </a>
 </li>
</ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulate-multiway-cluster-data">
   Simulate multiway cluster data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
   Initialize the objects of class DoubleMLData and DoubleMLPLIV
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#split-samples-and-transfer-the-sample-splitting-to-the-object">
   Split samples and transfer the sample splitting to the object
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fit-the-model-and-show-a-summary">
   Fit the model and show a summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing">
   Visualization of sample splitting with tuple and linear indexing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold">
     Visualize sample splitting with tuples (one plot per fold)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
     Visualize sample splitting with linear indexing (one column per fold)
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.015927</td>
      <td>-0.053413</td>
      <td>-0.275129</td>
      <td>-0.435609</td>
      <td>0.550505</td>
      <td>-0.226743</td>
      <td>-0.619986</td>
      <td>0.518826</td>
      <td>-0.062400</td>
      <td>0.627035</td>
      <td>1.157321</td>
      <td>-0.318915</td>
      <td>-0.615691</td>
      <td>-0.138724</td>
      <td>0.097063</td>
      <td>0.058778</td>
      <td>0.553613</td>
      <td>-0.859910</td>
      <td>-0.573543</td>
      <td>-0.202899</td>
      <td>0.708357</td>
      <td>1.178221</td>
      <td>1.282013</td>
      <td>0.322629</td>
      <td>0.126559</td>
      <td>-0.249003</td>
      <td>0.510964</td>
      <td>0.190824</td>
      <td>0.043489</td>
      <td>-0.374563</td>
      <td>0.587695</td>
      <td>-0.124809</td>
      <td>-0.397126</td>
      <td>-0.082017</td>
      <td>1.047636</td>
      <td>0.502555</td>
      <td>0.557705</td>
      <td>0.212348</td>
      <td>0.862372</td>
      <td>0.504057</td>
      <td>...</td>
      <td>0.952212</td>
      <td>0.992712</td>
      <td>-0.485307</td>
      <td>-0.786844</td>
      <td>-0.220488</td>
      <td>-0.832066</td>
      <td>0.464014</td>
      <td>0.478512</td>
      <td>-0.776511</td>
      <td>0.176890</td>
      <td>0.430312</td>
      <td>0.345528</td>
      <td>-0.178159</td>
      <td>-0.493964</td>
      <td>-0.738140</td>
      <td>-0.009915</td>
      <td>0.106794</td>
      <td>-0.369218</td>
      <td>1.309025</td>
      <td>-0.035357</td>
      <td>-0.201403</td>
      <td>0.436288</td>
      <td>0.486094</td>
      <td>0.024215</td>
      <td>0.559012</td>
      <td>1.401712</td>
      <td>0.051688</td>
      <td>-0.202892</td>
      <td>0.720500</td>
      <td>0.226170</td>
      <td>0.420256</td>
      <td>0.483265</td>
      <td>0.036816</td>
      <td>-0.206271</td>
      <td>-0.671654</td>
      <td>-0.815376</td>
      <td>-0.494988</td>
      <td>0.601689</td>
      <td>0.457859</td>
      <td>-0.206606</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.883397</td>
      <td>-0.975812</td>
      <td>-0.208604</td>
      <td>-1.248655</td>
      <td>-0.474100</td>
      <td>-0.771750</td>
      <td>-1.336403</td>
      <td>-0.122133</td>
      <td>0.359352</td>
      <td>0.055886</td>
      <td>0.829860</td>
      <td>0.235146</td>
      <td>0.822163</td>
      <td>0.985955</td>
      <td>-0.963198</td>
      <td>0.524622</td>
      <td>0.215524</td>
      <td>-0.558002</td>
      <td>-0.062719</td>
      <td>-0.682429</td>
      <td>-0.111783</td>
      <td>-0.215013</td>
      <td>-0.921786</td>
      <td>0.135328</td>
      <td>0.967305</td>
      <td>0.096165</td>
      <td>-0.148783</td>
      <td>-0.727502</td>
      <td>-0.979134</td>
      <td>-0.087316</td>
      <td>0.066915</td>
      <td>-0.150741</td>
      <td>-0.555280</td>
      <td>-1.433834</td>
      <td>1.123850</td>
      <td>0.095060</td>
      <td>0.536807</td>
      <td>0.250372</td>
      <td>1.022352</td>
      <td>-0.444246</td>
      <td>...</td>
      <td>-0.910211</td>
      <td>-0.279985</td>
      <td>0.368220</td>
      <td>0.274961</td>
      <td>0.650271</td>
      <td>-0.244259</td>
      <td>-0.233051</td>
      <td>0.113048</td>
      <td>0.596396</td>
      <td>1.664225</td>
      <td>0.774958</td>
      <td>-0.030661</td>
      <td>0.201322</td>
      <td>-0.523267</td>
      <td>0.531225</td>
      <td>0.737504</td>
      <td>0.333659</td>
      <td>0.110755</td>
      <td>1.210671</td>
      <td>0.897282</td>
      <td>-0.093905</td>
      <td>0.122812</td>
      <td>1.137769</td>
      <td>0.422164</td>
      <td>0.051436</td>
      <td>0.168273</td>
      <td>-0.408536</td>
      <td>1.110479</td>
      <td>-0.028840</td>
      <td>-0.270576</td>
      <td>0.457366</td>
      <td>0.095698</td>
      <td>0.514659</td>
      <td>0.681674</td>
      <td>-1.104120</td>
      <td>-0.631010</td>
      <td>-0.306194</td>
      <td>-1.521027</td>
      <td>-1.552964</td>
      <td>-0.920984</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.084643</td>
      <td>0.046498</td>
      <td>-0.777528</td>
      <td>-0.420903</td>
      <td>0.311429</td>
      <td>-0.110018</td>
      <td>1.022309</td>
      <td>1.860774</td>
      <td>0.689077</td>
      <td>0.224136</td>
      <td>0.087286</td>
      <td>-0.176556</td>
      <td>-0.412960</td>
      <td>0.097598</td>
      <td>1.092567</td>
      <td>-0.048084</td>
      <td>-0.606851</td>
      <td>0.341836</td>
      <td>1.114013</td>
      <td>0.654483</td>
      <td>-1.023342</td>
      <td>-0.493885</td>
      <td>-0.127584</td>
      <td>0.605533</td>
      <td>0.825210</td>
      <td>0.007093</td>
      <td>0.429047</td>
      <td>0.564614</td>
      <td>1.506162</td>
      <td>-0.281386</td>
      <td>0.052774</td>
      <td>-0.189240</td>
      <td>-1.094337</td>
      <td>-0.728718</td>
      <td>0.723279</td>
      <td>0.042973</td>
      <td>-0.567317</td>
      <td>-0.274188</td>
      <td>0.024907</td>
      <td>-0.137459</td>
      <td>...</td>
      <td>-0.169797</td>
      <td>-0.043052</td>
      <td>0.051207</td>
      <td>0.375119</td>
      <td>0.072265</td>
      <td>0.362467</td>
      <td>0.524095</td>
      <td>-0.116052</td>
      <td>-0.212237</td>
      <td>-0.289885</td>
      <td>0.462690</td>
      <td>-0.558918</td>
      <td>-0.471416</td>
      <td>-0.219191</td>
      <td>-0.170008</td>
      <td>0.492044</td>
      <td>0.254170</td>
      <td>0.608368</td>
      <td>0.383069</td>
      <td>0.386024</td>
      <td>0.665452</td>
      <td>0.615391</td>
      <td>1.351070</td>
      <td>0.047717</td>
      <td>-0.546182</td>
      <td>0.239571</td>
      <td>-0.327869</td>
      <td>0.048017</td>
      <td>-0.887549</td>
      <td>-0.085047</td>
      <td>-0.553008</td>
      <td>0.492232</td>
      <td>0.418291</td>
      <td>0.823771</td>
      <td>-0.689673</td>
      <td>-0.333773</td>
      <td>0.199105</td>
      <td>-2.130341</td>
      <td>-2.168267</td>
      <td>-1.015416</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.111220</td>
      <td>-0.821039</td>
      <td>-1.035372</td>
      <td>-0.884933</td>
      <td>0.410784</td>
      <td>-0.048899</td>
      <td>-0.286331</td>
      <td>-0.034816</td>
      <td>0.264618</td>
      <td>0.422548</td>
      <td>0.173946</td>
      <td>-1.024874</td>
      <td>-0.077414</td>
      <td>0.153018</td>
      <td>0.690917</td>
      <td>-0.132326</td>
      <td>-0.734491</td>
      <td>0.025462</td>
      <td>0.035686</td>
      <td>0.665073</td>
      <td>0.674576</td>
      <td>0.096117</td>
      <td>-0.798230</td>
      <td>-0.884317</td>
      <td>-0.236251</td>
      <td>-0.102457</td>
      <td>0.652535</td>
      <td>-0.007465</td>
      <td>-0.303220</td>
      <td>0.483400</td>
      <td>-0.195852</td>
      <td>-0.617478</td>
      <td>-0.535050</td>
      <td>-0.265939</td>
      <td>1.198381</td>
      <td>0.797626</td>
      <td>-1.382033</td>
      <td>-0.330934</td>
      <td>0.366005</td>
      <td>0.794820</td>
      <td>...</td>
      <td>0.194696</td>
      <td>0.165885</td>
      <td>-0.022897</td>
      <td>0.303236</td>
      <td>1.135177</td>
      <td>0.136046</td>
      <td>1.307444</td>
      <td>0.251947</td>
      <td>0.113279</td>
      <td>0.889314</td>
      <td>-0.346254</td>
      <td>0.523509</td>
      <td>0.021251</td>
      <td>-0.203979</td>
      <td>0.391883</td>
      <td>-0.082133</td>
      <td>0.035591</td>
      <td>-0.660921</td>
      <td>-0.016383</td>
      <td>1.258887</td>
      <td>-0.155329</td>
      <td>-0.320938</td>
      <td>0.440910</td>
      <td>-0.713825</td>
      <td>-0.261714</td>
      <td>-0.593816</td>
      <td>0.800994</td>
      <td>0.826818</td>
      <td>0.231217</td>
      <td>-0.148443</td>
      <td>0.464348</td>
      <td>0.034755</td>
      <td>-0.448371</td>
      <td>-0.838853</td>
      <td>-1.398621</td>
      <td>-0.431325</td>
      <td>-0.327919</td>
      <td>1.526049</td>
      <td>0.652399</td>
      <td>0.667219</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.397854</td>
      <td>-0.245130</td>
      <td>-0.059379</td>
      <td>-0.888125</td>
      <td>-0.221287</td>
      <td>-0.273846</td>
      <td>-0.518692</td>
      <td>1.078847</td>
      <td>0.261003</td>
      <td>0.670096</td>
      <td>0.344074</td>
      <td>0.344623</td>
      <td>0.961286</td>
      <td>0.349518</td>
      <td>0.442372</td>
      <td>0.398875</td>
      <td>-0.397025</td>
      <td>-0.789536</td>
      <td>0.851492</td>
      <td>0.785835</td>
      <td>0.967438</td>
      <td>0.333432</td>
      <td>-0.401219</td>
      <td>1.173945</td>
      <td>-0.717235</td>
      <td>-0.949115</td>
      <td>-0.515704</td>
      <td>0.267193</td>
      <td>0.029594</td>
      <td>-0.009970</td>
      <td>0.420028</td>
      <td>-0.421048</td>
      <td>-0.461026</td>
      <td>-0.395819</td>
      <td>1.019676</td>
      <td>0.290281</td>
      <td>-0.297497</td>
      <td>0.431811</td>
      <td>0.421049</td>
      <td>0.261873</td>
      <td>...</td>
      <td>0.346217</td>
      <td>1.109540</td>
      <td>-0.483960</td>
      <td>-0.714383</td>
      <td>1.986282</td>
      <td>0.411669</td>
      <td>0.417573</td>
      <td>0.781092</td>
      <td>0.042137</td>
      <td>0.126449</td>
      <td>-0.057618</td>
      <td>0.204073</td>
      <td>0.542909</td>
      <td>-0.167077</td>
      <td>-0.027062</td>
      <td>0.075450</td>
      <td>-0.100092</td>
      <td>0.305856</td>
      <td>1.468019</td>
      <td>0.849795</td>
      <td>0.196106</td>
      <td>0.287915</td>
      <td>1.150711</td>
      <td>-1.009562</td>
      <td>-0.587397</td>
      <td>0.242317</td>
      <td>0.381121</td>
      <td>-0.204779</td>
      <td>-0.864511</td>
      <td>-0.547034</td>
      <td>0.661382</td>
      <td>-0.379665</td>
      <td>-0.897978</td>
      <td>0.318885</td>
      <td>-1.393737</td>
      <td>-1.340086</td>
      <td>-0.239684</td>
      <td>-2.310323</td>
      <td>-1.893524</td>
      <td>-0.392678</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.093099</td>
      <td>-0.782350</td>
      <td>-0.405705</td>
      <td>-0.147211</td>
      <td>0.117943</td>
      <td>-0.257987</td>
      <td>0.415208</td>
      <td>0.328428</td>
      <td>0.844630</td>
      <td>-0.236897</td>
      <td>0.026555</td>
      <td>-0.518477</td>
      <td>0.941218</td>
      <td>-0.426418</td>
      <td>-0.472650</td>
      <td>-0.311363</td>
      <td>-0.034682</td>
      <td>-0.371278</td>
      <td>0.330876</td>
      <td>-0.135675</td>
      <td>-0.488361</td>
      <td>-0.472919</td>
      <td>0.603692</td>
      <td>0.282625</td>
      <td>0.789372</td>
      <td>-0.366073</td>
      <td>0.030301</td>
      <td>-0.152686</td>
      <td>-1.026774</td>
      <td>0.751795</td>
      <td>-0.501805</td>
      <td>-0.354290</td>
      <td>-1.768125</td>
      <td>-1.080066</td>
      <td>1.004135</td>
      <td>-0.306320</td>
      <td>-0.810926</td>
      <td>0.433619</td>
      <td>0.996311</td>
      <td>1.356644</td>
      <td>...</td>
      <td>-1.311609</td>
      <td>-0.338444</td>
      <td>-0.049965</td>
      <td>-0.509718</td>
      <td>0.260444</td>
      <td>0.053115</td>
      <td>0.973665</td>
      <td>0.793662</td>
      <td>0.641207</td>
      <td>0.406509</td>
      <td>-0.323627</td>
      <td>-0.598848</td>
      <td>-0.718992</td>
      <td>0.026860</td>
      <td>-0.631080</td>
      <td>0.354139</td>
      <td>0.177258</td>
      <td>-1.010998</td>
      <td>0.732319</td>
      <td>-0.497909</td>
      <td>-0.654085</td>
      <td>0.891548</td>
      <td>-0.680667</td>
      <td>0.676629</td>
      <td>0.839179</td>
      <td>-0.557191</td>
      <td>-0.187062</td>
      <td>0.047546</td>
      <td>-0.370154</td>
      <td>0.340961</td>
      <td>0.255042</td>
      <td>0.906884</td>
      <td>0.512653</td>
      <td>1.579257</td>
      <td>-0.485027</td>
      <td>-1.425691</td>
      <td>0.077645</td>
      <td>-1.702517</td>
      <td>-1.337805</td>
      <td>-0.695534</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.832679</td>
      <td>0.114182</td>
      <td>-0.456205</td>
      <td>-0.891745</td>
      <td>0.197433</td>
      <td>-1.358634</td>
      <td>-0.364402</td>
      <td>0.793535</td>
      <td>0.414092</td>
      <td>0.309922</td>
      <td>-0.122977</td>
      <td>0.720752</td>
      <td>0.543282</td>
      <td>0.195726</td>
      <td>1.696274</td>
      <td>-0.513505</td>
      <td>-0.316122</td>
      <td>-0.190498</td>
      <td>-0.122507</td>
      <td>1.188507</td>
      <td>1.502996</td>
      <td>-0.152606</td>
      <td>0.249794</td>
      <td>0.140129</td>
      <td>-0.037749</td>
      <td>0.265638</td>
      <td>1.022455</td>
      <td>-0.066072</td>
      <td>0.308162</td>
      <td>-0.274741</td>
      <td>-0.430347</td>
      <td>0.963404</td>
      <td>-1.087466</td>
      <td>0.273848</td>
      <td>0.508151</td>
      <td>-0.493897</td>
      <td>-1.688334</td>
      <td>-0.574326</td>
      <td>0.446665</td>
      <td>0.269183</td>
      <td>...</td>
      <td>0.163752</td>
      <td>0.137612</td>
      <td>-1.357422</td>
      <td>-0.198514</td>
      <td>1.110010</td>
      <td>0.618540</td>
      <td>-0.589485</td>
      <td>-0.090491</td>
      <td>-0.469617</td>
      <td>0.218130</td>
      <td>0.000117</td>
      <td>-0.794478</td>
      <td>0.217353</td>
      <td>0.123390</td>
      <td>-0.349014</td>
      <td>0.452115</td>
      <td>0.609626</td>
      <td>0.237698</td>
      <td>0.511807</td>
      <td>1.170486</td>
      <td>-0.453357</td>
      <td>0.222812</td>
      <td>0.734412</td>
      <td>0.294857</td>
      <td>1.258041</td>
      <td>0.175028</td>
      <td>0.150734</td>
      <td>0.553609</td>
      <td>0.470646</td>
      <td>0.081452</td>
      <td>0.281637</td>
      <td>0.390086</td>
      <td>0.221993</td>
      <td>0.099920</td>
      <td>0.312846</td>
      <td>0.316192</td>
      <td>-0.411634</td>
      <td>-0.188395</td>
      <td>0.037983</td>
      <td>0.154303</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.677629</td>
      <td>-0.816743</td>
      <td>-0.600567</td>
      <td>-0.973036</td>
      <td>-1.220318</td>
      <td>-1.310139</td>
      <td>-0.371139</td>
      <td>0.542214</td>
      <td>0.501991</td>
      <td>0.461198</td>
      <td>0.405445</td>
      <td>-0.799833</td>
      <td>0.133297</td>
      <td>-0.089202</td>
      <td>0.565414</td>
      <td>1.324769</td>
      <td>0.256927</td>
      <td>-0.075134</td>
      <td>-0.157698</td>
      <td>1.061399</td>
      <td>0.595127</td>
      <td>0.460837</td>
      <td>0.263849</td>
      <td>0.431065</td>
      <td>-0.289458</td>
      <td>-0.105962</td>
      <td>0.396601</td>
      <td>-0.800488</td>
      <td>0.300529</td>
      <td>0.380863</td>
      <td>0.438249</td>
      <td>-0.673228</td>
      <td>-0.785127</td>
      <td>-0.600057</td>
      <td>1.335354</td>
      <td>0.147314</td>
      <td>0.116318</td>
      <td>0.183598</td>
      <td>0.325556</td>
      <td>-0.305976</td>
      <td>...</td>
      <td>0.387668</td>
      <td>0.714597</td>
      <td>0.552968</td>
      <td>-1.019463</td>
      <td>0.448108</td>
      <td>-0.664310</td>
      <td>0.433257</td>
      <td>0.125432</td>
      <td>0.571478</td>
      <td>-0.412451</td>
      <td>-0.240405</td>
      <td>0.560803</td>
      <td>0.126154</td>
      <td>0.430842</td>
      <td>-0.434287</td>
      <td>0.247646</td>
      <td>0.021973</td>
      <td>0.068544</td>
      <td>0.283924</td>
      <td>1.123718</td>
      <td>0.175159</td>
      <td>-0.009207</td>
      <td>1.063365</td>
      <td>-0.776718</td>
      <td>-0.177883</td>
      <td>1.229331</td>
      <td>0.685396</td>
      <td>0.510281</td>
      <td>0.230665</td>
      <td>0.068787</td>
      <td>0.838323</td>
      <td>0.440735</td>
      <td>0.676716</td>
      <td>0.040963</td>
      <td>-0.964981</td>
      <td>-0.849158</td>
      <td>-0.602066</td>
      <td>-2.074626</td>
      <td>-0.546757</td>
      <td>0.382452</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.457023</td>
      <td>-0.681549</td>
      <td>-0.074880</td>
      <td>-0.217004</td>
      <td>0.419338</td>
      <td>0.252997</td>
      <td>-0.901900</td>
      <td>0.408099</td>
      <td>0.650932</td>
      <td>0.495096</td>
      <td>0.549396</td>
      <td>-0.228765</td>
      <td>0.566454</td>
      <td>-0.409525</td>
      <td>0.534967</td>
      <td>-0.396503</td>
      <td>-0.492740</td>
      <td>-0.338850</td>
      <td>-0.674767</td>
      <td>-0.561853</td>
      <td>0.728799</td>
      <td>0.628446</td>
      <td>0.465464</td>
      <td>0.117283</td>
      <td>0.498788</td>
      <td>-0.710230</td>
      <td>-0.529190</td>
      <td>-1.158088</td>
      <td>0.244936</td>
      <td>-0.010398</td>
      <td>0.997316</td>
      <td>0.103117</td>
      <td>-0.746107</td>
      <td>-0.415285</td>
      <td>1.309653</td>
      <td>0.334796</td>
      <td>-0.181498</td>
      <td>0.542965</td>
      <td>0.257479</td>
      <td>-0.457731</td>
      <td>...</td>
      <td>0.034011</td>
      <td>0.722029</td>
      <td>0.004570</td>
      <td>-1.000478</td>
      <td>-0.457407</td>
      <td>-0.187290</td>
      <td>0.595653</td>
      <td>-0.131789</td>
      <td>0.071870</td>
      <td>0.103915</td>
      <td>-0.567056</td>
      <td>-0.383896</td>
      <td>0.022344</td>
      <td>0.050314</td>
      <td>-0.065955</td>
      <td>0.037806</td>
      <td>0.267477</td>
      <td>-0.072067</td>
      <td>-0.303741</td>
      <td>0.483307</td>
      <td>-0.714670</td>
      <td>0.280738</td>
      <td>0.649589</td>
      <td>0.399688</td>
      <td>0.498667</td>
      <td>0.078440</td>
      <td>0.064707</td>
      <td>0.400540</td>
      <td>-0.271575</td>
      <td>0.628133</td>
      <td>0.830438</td>
      <td>-0.088402</td>
      <td>-0.270694</td>
      <td>-0.113381</td>
      <td>-0.407857</td>
      <td>-0.155361</td>
      <td>0.111941</td>
      <td>0.068578</td>
      <td>0.029479</td>
      <td>0.107897</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.871962</td>
      <td>0.454822</td>
      <td>-1.039762</td>
      <td>-0.572433</td>
      <td>0.078561</td>
      <td>-0.437337</td>
      <td>-0.811373</td>
      <td>-0.355858</td>
      <td>0.300881</td>
      <td>0.178015</td>
      <td>-0.672322</td>
      <td>0.188963</td>
      <td>-0.089078</td>
      <td>-0.130406</td>
      <td>1.004279</td>
      <td>0.067859</td>
      <td>-0.425278</td>
      <td>-0.233438</td>
      <td>-0.054700</td>
      <td>0.260216</td>
      <td>0.627658</td>
      <td>-0.432163</td>
      <td>0.058930</td>
      <td>-0.380481</td>
      <td>-0.541831</td>
      <td>1.116897</td>
      <td>1.017415</td>
      <td>-0.329641</td>
      <td>-0.009814</td>
      <td>-0.933072</td>
      <td>0.704843</td>
      <td>0.311441</td>
      <td>-1.297273</td>
      <td>0.099620</td>
      <td>0.163944</td>
      <td>0.951373</td>
      <td>-0.024618</td>
      <td>-0.288379</td>
      <td>0.385627</td>
      <td>-0.005963</td>
      <td>...</td>
      <td>0.785240</td>
      <td>0.386567</td>
      <td>-0.582007</td>
      <td>-0.295916</td>
      <td>0.766816</td>
      <td>0.691793</td>
      <td>0.270324</td>
      <td>0.180937</td>
      <td>0.791372</td>
      <td>1.514861</td>
      <td>0.471519</td>
      <td>-0.683455</td>
      <td>0.052172</td>
      <td>-0.562682</td>
      <td>-0.760149</td>
      <td>-0.651623</td>
      <td>-0.144171</td>
      <td>-0.578544</td>
      <td>0.401822</td>
      <td>-0.249052</td>
      <td>-0.407996</td>
      <td>1.368094</td>
      <td>1.620248</td>
      <td>0.832392</td>
      <td>-0.673677</td>
      <td>-0.301947</td>
      <td>-0.335853</td>
      <td>0.257329</td>
      <td>0.664260</td>
      <td>0.992343</td>
      <td>-0.240325</td>
      <td>-0.806250</td>
      <td>-0.815071</td>
      <td>0.061234</td>
      <td>-0.394776</td>
      <td>-0.075891</td>
      <td>-0.850616</td>
      <td>1.766897</td>
      <td>0.806092</td>
      <td>0.466929</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-1.173610</td>
      <td>0.175410</td>
      <td>0.175542</td>
      <td>0.375142</td>
      <td>-0.184113</td>
      <td>-0.157782</td>
      <td>-2.088406</td>
      <td>0.472242</td>
      <td>0.408968</td>
      <td>-0.340553</td>
      <td>0.591235</td>
      <td>0.016883</td>
      <td>1.241571</td>
      <td>0.853108</td>
      <td>-0.727918</td>
      <td>0.846953</td>
      <td>-0.524778</td>
      <td>-0.396192</td>
      <td>0.965694</td>
      <td>0.381589</td>
      <td>0.656830</td>
      <td>0.008442</td>
      <td>-0.175618</td>
      <td>-0.618970</td>
      <td>-0.021483</td>
      <td>0.791564</td>
      <td>1.526010</td>
      <td>0.264968</td>
      <td>0.729558</td>
      <td>-0.035320</td>
      <td>1.061458</td>
      <td>0.113849</td>
      <td>-0.511464</td>
      <td>-0.555037</td>
      <td>0.509596</td>
      <td>0.073720</td>
      <td>-1.044674</td>
      <td>0.284937</td>
      <td>-0.141106</td>
      <td>1.614403</td>
      <td>...</td>
      <td>0.830547</td>
      <td>-0.054074</td>
      <td>-0.281707</td>
      <td>-0.262185</td>
      <td>0.567360</td>
      <td>0.626292</td>
      <td>0.554614</td>
      <td>0.499402</td>
      <td>-0.056929</td>
      <td>0.744917</td>
      <td>0.467014</td>
      <td>0.509700</td>
      <td>0.022448</td>
      <td>-0.654973</td>
      <td>-0.148941</td>
      <td>-0.433743</td>
      <td>0.005247</td>
      <td>0.344656</td>
      <td>-0.672451</td>
      <td>-0.017931</td>
      <td>-0.442354</td>
      <td>0.558581</td>
      <td>0.648298</td>
      <td>-1.243928</td>
      <td>0.073223</td>
      <td>0.140498</td>
      <td>0.461193</td>
      <td>0.857853</td>
      <td>0.713905</td>
      <td>0.016867</td>
      <td>0.175947</td>
      <td>0.358439</td>
      <td>-0.368709</td>
      <td>0.063801</td>
      <td>-0.040083</td>
      <td>-0.355008</td>
      <td>0.215983</td>
      <td>-2.467299</td>
      <td>-1.156081</td>
      <td>-0.665439</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.594842</td>
      <td>-1.059432</td>
      <td>-0.140527</td>
      <td>0.809105</td>
      <td>0.448755</td>
      <td>-0.021891</td>
      <td>0.536926</td>
      <td>0.714019</td>
      <td>1.699960</td>
      <td>1.514633</td>
      <td>0.077595</td>
      <td>0.366443</td>
      <td>-0.324541</td>
      <td>-0.082218</td>
      <td>-0.300329</td>
      <td>0.926045</td>
      <td>-0.053074</td>
      <td>-0.189631</td>
      <td>0.258130</td>
      <td>1.212926</td>
      <td>1.300270</td>
      <td>0.979554</td>
      <td>1.267824</td>
      <td>0.472643</td>
      <td>-0.419688</td>
      <td>0.935140</td>
      <td>0.926507</td>
      <td>-0.310452</td>
      <td>0.268638</td>
      <td>0.375758</td>
      <td>0.729148</td>
      <td>-0.842987</td>
      <td>-0.609446</td>
      <td>0.578376</td>
      <td>1.172011</td>
      <td>0.693879</td>
      <td>-0.997560</td>
      <td>1.085144</td>
      <td>-0.134062</td>
      <td>-0.216800</td>
      <td>...</td>
      <td>1.933795</td>
      <td>1.081089</td>
      <td>0.061900</td>
      <td>-0.412718</td>
      <td>1.168900</td>
      <td>-0.408115</td>
      <td>0.807158</td>
      <td>0.118452</td>
      <td>-0.407684</td>
      <td>0.153704</td>
      <td>0.369615</td>
      <td>-0.266808</td>
      <td>0.544129</td>
      <td>-0.497293</td>
      <td>-0.913063</td>
      <td>-0.773336</td>
      <td>-0.413190</td>
      <td>0.334239</td>
      <td>0.800486</td>
      <td>0.715895</td>
      <td>-0.349699</td>
      <td>0.050742</td>
      <td>0.916492</td>
      <td>0.651078</td>
      <td>0.787621</td>
      <td>-0.227038</td>
      <td>0.248410</td>
      <td>0.588527</td>
      <td>0.797857</td>
      <td>-0.046537</td>
      <td>0.591710</td>
      <td>0.309020</td>
      <td>-0.891787</td>
      <td>0.384550</td>
      <td>-0.013177</td>
      <td>-0.235594</td>
      <td>-0.868899</td>
      <td>1.198773</td>
      <td>1.319268</td>
      <td>0.369392</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-1.440393</td>
      <td>0.279591</td>
      <td>0.455580</td>
      <td>0.104404</td>
      <td>1.054448</td>
      <td>-0.401944</td>
      <td>0.665310</td>
      <td>0.125643</td>
      <td>0.322710</td>
      <td>0.632821</td>
      <td>-0.113294</td>
      <td>1.708998</td>
      <td>0.419484</td>
      <td>1.206730</td>
      <td>0.962468</td>
      <td>0.535249</td>
      <td>-0.276495</td>
      <td>-0.078665</td>
      <td>-0.002649</td>
      <td>1.397840</td>
      <td>1.053748</td>
      <td>0.052898</td>
      <td>0.072594</td>
      <td>-0.478798</td>
      <td>0.253803</td>
      <td>0.858065</td>
      <td>1.329991</td>
      <td>0.951222</td>
      <td>0.136451</td>
      <td>0.147557</td>
      <td>-0.146755</td>
      <td>-0.124361</td>
      <td>-0.685392</td>
      <td>0.139969</td>
      <td>2.362800</td>
      <td>0.912909</td>
      <td>-0.701488</td>
      <td>0.050226</td>
      <td>0.907128</td>
      <td>0.379934</td>
      <td>...</td>
      <td>-0.449297</td>
      <td>-0.168631</td>
      <td>-0.183872</td>
      <td>0.091603</td>
      <td>0.391138</td>
      <td>-0.728764</td>
      <td>0.744589</td>
      <td>0.151575</td>
      <td>-0.488336</td>
      <td>0.125538</td>
      <td>-0.357597</td>
      <td>-0.138937</td>
      <td>0.232392</td>
      <td>0.363265</td>
      <td>-0.750783</td>
      <td>-1.133857</td>
      <td>-0.335732</td>
      <td>-0.460761</td>
      <td>-0.598115</td>
      <td>0.220705</td>
      <td>-0.482554</td>
      <td>0.681893</td>
      <td>0.845715</td>
      <td>0.635778</td>
      <td>0.187435</td>
      <td>-0.784266</td>
      <td>-0.337726</td>
      <td>-0.167318</td>
      <td>-0.654495</td>
      <td>0.383656</td>
      <td>-0.017719</td>
      <td>0.050735</td>
      <td>0.762277</td>
      <td>-0.247857</td>
      <td>-1.091723</td>
      <td>-0.496860</td>
      <td>-0.521925</td>
      <td>-0.163848</td>
      <td>0.090434</td>
      <td>-0.148554</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.046526</td>
      <td>-0.552042</td>
      <td>-0.434476</td>
      <td>-0.072196</td>
      <td>0.565304</td>
      <td>-0.742321</td>
      <td>-0.613229</td>
      <td>0.877693</td>
      <td>1.127642</td>
      <td>-0.076442</td>
      <td>-0.982803</td>
      <td>-0.470477</td>
      <td>-0.670944</td>
      <td>-0.185455</td>
      <td>-0.013922</td>
      <td>-0.648224</td>
      <td>-0.022756</td>
      <td>-0.174672</td>
      <td>-0.319474</td>
      <td>-0.551882</td>
      <td>0.154112</td>
      <td>-0.501333</td>
      <td>-0.185832</td>
      <td>-0.379235</td>
      <td>-0.089698</td>
      <td>-0.271470</td>
      <td>0.138916</td>
      <td>-0.881333</td>
      <td>-0.246657</td>
      <td>0.017685</td>
      <td>0.598208</td>
      <td>0.523486</td>
      <td>-0.755791</td>
      <td>-0.521599</td>
      <td>1.653442</td>
      <td>1.160345</td>
      <td>-0.489076</td>
      <td>-1.111040</td>
      <td>0.073959</td>
      <td>-0.121704</td>
      <td>...</td>
      <td>-0.453170</td>
      <td>-0.124042</td>
      <td>-0.499627</td>
      <td>-0.336564</td>
      <td>0.469410</td>
      <td>-0.864216</td>
      <td>0.784769</td>
      <td>0.112411</td>
      <td>-0.429463</td>
      <td>-0.335743</td>
      <td>0.028050</td>
      <td>0.656603</td>
      <td>0.631872</td>
      <td>-0.080497</td>
      <td>-0.154089</td>
      <td>0.321872</td>
      <td>0.112033</td>
      <td>0.302983</td>
      <td>0.572109</td>
      <td>-0.175432</td>
      <td>-0.589098</td>
      <td>0.941225</td>
      <td>0.773969</td>
      <td>0.187099</td>
      <td>0.175806</td>
      <td>-0.332805</td>
      <td>-0.121665</td>
      <td>0.296412</td>
      <td>0.067646</td>
      <td>0.322869</td>
      <td>0.667119</td>
      <td>0.477132</td>
      <td>0.228544</td>
      <td>0.692497</td>
      <td>-0.449256</td>
      <td>-0.276797</td>
      <td>-0.615286</td>
      <td>0.992816</td>
      <td>0.207524</td>
      <td>0.141867</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.220862</td>
      <td>0.155613</td>
      <td>-0.205490</td>
      <td>-0.923317</td>
      <td>0.355643</td>
      <td>0.552011</td>
      <td>-1.015582</td>
      <td>0.379123</td>
      <td>0.929674</td>
      <td>0.578428</td>
      <td>0.518432</td>
      <td>0.029288</td>
      <td>-0.136140</td>
      <td>-0.217230</td>
      <td>-0.644416</td>
      <td>-0.169324</td>
      <td>-0.655442</td>
      <td>-0.590689</td>
      <td>0.009171</td>
      <td>0.233040</td>
      <td>0.565663</td>
      <td>-0.451730</td>
      <td>-0.420043</td>
      <td>0.465318</td>
      <td>-0.134122</td>
      <td>-0.647498</td>
      <td>-0.543673</td>
      <td>-0.497163</td>
      <td>0.137733</td>
      <td>0.154322</td>
      <td>-0.349898</td>
      <td>-0.789787</td>
      <td>-1.060608</td>
      <td>-0.407502</td>
      <td>1.605426</td>
      <td>0.080027</td>
      <td>-1.114336</td>
      <td>-0.471261</td>
      <td>0.319562</td>
      <td>-0.207905</td>
      <td>...</td>
      <td>-0.522068</td>
      <td>1.330508</td>
      <td>0.152283</td>
      <td>-0.887979</td>
      <td>-0.375738</td>
      <td>-0.151049</td>
      <td>0.730353</td>
      <td>0.165149</td>
      <td>-0.452422</td>
      <td>1.006658</td>
      <td>-0.855301</td>
      <td>0.327795</td>
      <td>-0.024059</td>
      <td>0.440904</td>
      <td>-0.859275</td>
      <td>0.073818</td>
      <td>-0.753873</td>
      <td>0.041129</td>
      <td>-0.476406</td>
      <td>0.316356</td>
      <td>0.106792</td>
      <td>0.833161</td>
      <td>1.589898</td>
      <td>-0.997314</td>
      <td>0.390226</td>
      <td>0.181778</td>
      <td>-0.258022</td>
      <td>0.777696</td>
      <td>0.354714</td>
      <td>0.126807</td>
      <td>-0.017140</td>
      <td>0.505600</td>
      <td>0.104718</td>
      <td>0.755347</td>
      <td>-0.646820</td>
      <td>-0.732458</td>
      <td>-0.104723</td>
      <td>0.381876</td>
      <td>-0.011188</td>
      <td>-0.247682</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.322853</td>
      <td>-0.651616</td>
      <td>-0.795644</td>
      <td>-0.513147</td>
      <td>0.388319</td>
      <td>-0.282461</td>
      <td>-0.353150</td>
      <td>0.189427</td>
      <td>2.052009</td>
      <td>0.773390</td>
      <td>-0.213164</td>
      <td>0.161632</td>
      <td>0.109293</td>
      <td>-0.540440</td>
      <td>0.003982</td>
      <td>1.280521</td>
      <td>-0.067907</td>
      <td>-0.382335</td>
      <td>-0.053245</td>
      <td>0.143657</td>
      <td>0.382154</td>
      <td>0.474152</td>
      <td>0.460433</td>
      <td>-0.305403</td>
      <td>0.360838</td>
      <td>0.462917</td>
      <td>0.746379</td>
      <td>-0.064936</td>
      <td>-0.121135</td>
      <td>0.162096</td>
      <td>1.063452</td>
      <td>0.437391</td>
      <td>0.080844</td>
      <td>-0.644021</td>
      <td>-0.708424</td>
      <td>0.534169</td>
      <td>-0.652237</td>
      <td>-0.599503</td>
      <td>0.804455</td>
      <td>0.372714</td>
      <td>...</td>
      <td>0.271762</td>
      <td>0.268940</td>
      <td>0.792813</td>
      <td>0.569107</td>
      <td>0.422942</td>
      <td>-0.418628</td>
      <td>0.201688</td>
      <td>-0.035018</td>
      <td>0.198918</td>
      <td>-0.017096</td>
      <td>0.862586</td>
      <td>-0.213853</td>
      <td>-1.065319</td>
      <td>-0.875046</td>
      <td>-0.584418</td>
      <td>-0.236455</td>
      <td>-0.609015</td>
      <td>-0.589508</td>
      <td>0.022662</td>
      <td>-0.075979</td>
      <td>-0.269174</td>
      <td>0.233629</td>
      <td>0.384293</td>
      <td>-0.355354</td>
      <td>1.063001</td>
      <td>0.692987</td>
      <td>0.379834</td>
      <td>0.613391</td>
      <td>-0.277820</td>
      <td>0.307544</td>
      <td>0.940848</td>
      <td>-0.243273</td>
      <td>-0.188263</td>
      <td>0.414596</td>
      <td>-0.179225</td>
      <td>0.053093</td>
      <td>0.650477</td>
      <td>-0.072416</td>
      <td>-0.676584</td>
      <td>-0.232571</td>
    </tr>
    <tr>
      <th>16</th>
      <td>1.117655</td>
      <td>0.337526</td>
      <td>-0.553716</td>
      <td>-0.771686</td>
      <td>0.864827</td>
      <td>0.402908</td>
      <td>0.284614</td>
      <td>0.752071</td>
      <td>0.005646</td>
      <td>0.551570</td>
      <td>-0.047303</td>
      <td>1.246756</td>
      <td>0.251136</td>
      <td>-0.390940</td>
      <td>0.278762</td>
      <td>0.149067</td>
      <td>0.111439</td>
      <td>-0.714703</td>
      <td>-1.086426</td>
      <td>-0.464805</td>
      <td>0.803344</td>
      <td>0.737566</td>
      <td>0.572543</td>
      <td>-0.066118</td>
      <td>-0.156546</td>
      <td>-0.677872</td>
      <td>0.080755</td>
      <td>-0.544645</td>
      <td>-0.551930</td>
      <td>-0.319719</td>
      <td>-0.157698</td>
      <td>1.046975</td>
      <td>-0.168214</td>
      <td>-0.509068</td>
      <td>1.753083</td>
      <td>0.367035</td>
      <td>-0.232905</td>
      <td>-0.990533</td>
      <td>0.622534</td>
      <td>0.432126</td>
      <td>...</td>
      <td>-0.105589</td>
      <td>1.061351</td>
      <td>0.620536</td>
      <td>-0.217866</td>
      <td>0.847254</td>
      <td>0.608747</td>
      <td>1.217050</td>
      <td>0.784343</td>
      <td>-0.825538</td>
      <td>-0.219450</td>
      <td>-0.383365</td>
      <td>0.365640</td>
      <td>-0.275550</td>
      <td>-0.511391</td>
      <td>-0.621452</td>
      <td>0.122882</td>
      <td>0.138431</td>
      <td>0.286250</td>
      <td>0.295375</td>
      <td>-0.037935</td>
      <td>-1.032526</td>
      <td>-1.018800</td>
      <td>-0.017385</td>
      <td>-0.086052</td>
      <td>0.119966</td>
      <td>0.179123</td>
      <td>-0.604845</td>
      <td>0.922096</td>
      <td>-0.441037</td>
      <td>0.001323</td>
      <td>0.185259</td>
      <td>0.697423</td>
      <td>0.263294</td>
      <td>-0.908983</td>
      <td>-1.411253</td>
      <td>-0.225261</td>
      <td>0.195995</td>
      <td>1.543771</td>
      <td>1.302820</td>
      <td>1.572043</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.259513</td>
      <td>0.392985</td>
      <td>-0.075240</td>
      <td>0.390299</td>
      <td>-0.561936</td>
      <td>-1.403918</td>
      <td>-0.041308</td>
      <td>-0.132168</td>
      <td>1.042125</td>
      <td>0.396819</td>
      <td>-0.270637</td>
      <td>-0.589608</td>
      <td>-0.226948</td>
      <td>-0.338849</td>
      <td>0.014490</td>
      <td>0.578370</td>
      <td>-0.512300</td>
      <td>-0.187006</td>
      <td>0.127944</td>
      <td>0.276274</td>
      <td>0.656725</td>
      <td>-0.607559</td>
      <td>-0.194728</td>
      <td>-0.489403</td>
      <td>-0.303364</td>
      <td>-0.905200</td>
      <td>1.080962</td>
      <td>-0.017431</td>
      <td>0.520178</td>
      <td>0.307308</td>
      <td>0.347480</td>
      <td>-0.531650</td>
      <td>-0.685414</td>
      <td>0.618338</td>
      <td>1.715321</td>
      <td>-0.255468</td>
      <td>0.136987</td>
      <td>0.342705</td>
      <td>0.119294</td>
      <td>0.351795</td>
      <td>...</td>
      <td>-0.953165</td>
      <td>0.686642</td>
      <td>-0.518913</td>
      <td>-0.371246</td>
      <td>-0.162925</td>
      <td>-0.416992</td>
      <td>0.195478</td>
      <td>0.432020</td>
      <td>0.081616</td>
      <td>-0.625331</td>
      <td>0.041753</td>
      <td>0.041870</td>
      <td>0.221214</td>
      <td>0.023860</td>
      <td>-0.180301</td>
      <td>-1.135363</td>
      <td>0.422937</td>
      <td>-0.180043</td>
      <td>0.592128</td>
      <td>0.795384</td>
      <td>-0.351834</td>
      <td>0.372429</td>
      <td>0.962965</td>
      <td>-0.736316</td>
      <td>-0.893249</td>
      <td>0.119264</td>
      <td>0.439324</td>
      <td>1.069756</td>
      <td>-0.056189</td>
      <td>0.201754</td>
      <td>1.226253</td>
      <td>0.812743</td>
      <td>-0.480196</td>
      <td>-0.118833</td>
      <td>-0.429981</td>
      <td>-0.560106</td>
      <td>-0.868798</td>
      <td>-1.169189</td>
      <td>-0.753854</td>
      <td>-0.427478</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.759624</td>
      <td>0.007443</td>
      <td>-1.118147</td>
      <td>-0.809690</td>
      <td>-0.621774</td>
      <td>1.237746</td>
      <td>-0.313886</td>
      <td>0.669484</td>
      <td>0.450809</td>
      <td>0.667052</td>
      <td>-0.943320</td>
      <td>-0.172792</td>
      <td>-0.535890</td>
      <td>-1.869658</td>
      <td>0.427180</td>
      <td>1.572624</td>
      <td>0.333802</td>
      <td>-0.417804</td>
      <td>-0.266087</td>
      <td>0.594514</td>
      <td>0.634297</td>
      <td>0.114324</td>
      <td>-0.497445</td>
      <td>0.041814</td>
      <td>0.448057</td>
      <td>1.005457</td>
      <td>0.613214</td>
      <td>-0.256478</td>
      <td>-0.073494</td>
      <td>-0.802790</td>
      <td>-0.225214</td>
      <td>-0.773412</td>
      <td>-0.582019</td>
      <td>0.074357</td>
      <td>0.397952</td>
      <td>-0.373872</td>
      <td>-0.165153</td>
      <td>0.270213</td>
      <td>0.618382</td>
      <td>0.548305</td>
      <td>...</td>
      <td>-0.704895</td>
      <td>-0.045054</td>
      <td>0.593311</td>
      <td>0.119564</td>
      <td>0.402499</td>
      <td>-0.122863</td>
      <td>0.566575</td>
      <td>0.716207</td>
      <td>-0.370219</td>
      <td>-0.516412</td>
      <td>-0.045088</td>
      <td>1.304339</td>
      <td>0.221551</td>
      <td>-0.251746</td>
      <td>-0.881171</td>
      <td>0.198847</td>
      <td>-0.908799</td>
      <td>-1.097461</td>
      <td>0.020806</td>
      <td>0.163152</td>
      <td>-0.057930</td>
      <td>-0.934308</td>
      <td>-0.329731</td>
      <td>-1.422948</td>
      <td>-1.229932</td>
      <td>-0.131510</td>
      <td>-0.334034</td>
      <td>1.372037</td>
      <td>-0.115729</td>
      <td>-0.130174</td>
      <td>0.911557</td>
      <td>0.564636</td>
      <td>-1.126921</td>
      <td>-0.313824</td>
      <td>-0.966139</td>
      <td>0.513362</td>
      <td>0.246243</td>
      <td>-0.564414</td>
      <td>-1.070040</td>
      <td>-0.563162</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.644852</td>
      <td>-0.389953</td>
      <td>0.519593</td>
      <td>0.085022</td>
      <td>0.326465</td>
      <td>-0.473424</td>
      <td>-0.367662</td>
      <td>0.000918</td>
      <td>0.917006</td>
      <td>0.981472</td>
      <td>0.942835</td>
      <td>-0.070420</td>
      <td>-0.240538</td>
      <td>0.741698</td>
      <td>0.253594</td>
      <td>0.201287</td>
      <td>-0.482094</td>
      <td>-0.741783</td>
      <td>-1.461268</td>
      <td>-0.235457</td>
      <td>-0.355623</td>
      <td>0.110499</td>
      <td>0.046405</td>
      <td>-0.894177</td>
      <td>-0.314273</td>
      <td>0.405788</td>
      <td>-0.180546</td>
      <td>-0.479207</td>
      <td>-0.068400</td>
      <td>0.484990</td>
      <td>0.321649</td>
      <td>-0.744324</td>
      <td>-0.557152</td>
      <td>-0.108734</td>
      <td>1.468437</td>
      <td>0.675540</td>
      <td>-0.310444</td>
      <td>-2.090799</td>
      <td>-0.154774</td>
      <td>0.077390</td>
      <td>...</td>
      <td>0.505532</td>
      <td>0.557985</td>
      <td>-0.289457</td>
      <td>-1.248139</td>
      <td>-0.025541</td>
      <td>-0.343742</td>
      <td>-0.410489</td>
      <td>-0.222950</td>
      <td>0.573491</td>
      <td>-0.637730</td>
      <td>0.468779</td>
      <td>-0.200256</td>
      <td>0.630316</td>
      <td>0.121650</td>
      <td>0.332511</td>
      <td>0.385442</td>
      <td>-0.531712</td>
      <td>0.156912</td>
      <td>-0.050005</td>
      <td>1.158336</td>
      <td>-0.677932</td>
      <td>0.635956</td>
      <td>0.551701</td>
      <td>-0.856399</td>
      <td>-0.157569</td>
      <td>-0.198761</td>
      <td>0.496480</td>
      <td>0.499289</td>
      <td>0.260164</td>
      <td>0.405556</td>
      <td>0.158088</td>
      <td>-0.930201</td>
      <td>0.180020</td>
      <td>0.046483</td>
      <td>0.108021</td>
      <td>-0.422360</td>
      <td>-0.732075</td>
      <td>0.569305</td>
      <td>0.104836</td>
      <td>0.764495</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.010410</td>
      <td>-0.246897</td>
      <td>-0.532979</td>
      <td>-0.189793</td>
      <td>0.150426</td>
      <td>0.901236</td>
      <td>-0.255583</td>
      <td>0.309878</td>
      <td>1.421333</td>
      <td>0.487027</td>
      <td>-0.282712</td>
      <td>-0.154446</td>
      <td>-0.427286</td>
      <td>-0.170880</td>
      <td>-0.833339</td>
      <td>-0.521627</td>
      <td>0.551506</td>
      <td>-0.471653</td>
      <td>-0.701988</td>
      <td>0.858213</td>
      <td>1.229938</td>
      <td>0.156177</td>
      <td>-0.239048</td>
      <td>0.118029</td>
      <td>-0.588299</td>
      <td>-1.210196</td>
      <td>0.287600</td>
      <td>-0.700425</td>
      <td>0.280494</td>
      <td>-0.156274</td>
      <td>-0.473228</td>
      <td>-0.060618</td>
      <td>-0.044646</td>
      <td>-0.247136</td>
      <td>1.303249</td>
      <td>0.412054</td>
      <td>-0.490695</td>
      <td>-0.325015</td>
      <td>-0.260034</td>
      <td>0.194896</td>
      <td>...</td>
      <td>-0.773306</td>
      <td>0.163983</td>
      <td>-0.241987</td>
      <td>-0.605235</td>
      <td>-0.227962</td>
      <td>-0.268874</td>
      <td>-1.478647</td>
      <td>-0.364349</td>
      <td>-0.184880</td>
      <td>0.970708</td>
      <td>0.095344</td>
      <td>-0.718074</td>
      <td>-0.245900</td>
      <td>-0.465676</td>
      <td>-0.775225</td>
      <td>-0.173252</td>
      <td>0.506529</td>
      <td>-1.087551</td>
      <td>0.051995</td>
      <td>0.224737</td>
      <td>-0.909732</td>
      <td>-0.151252</td>
      <td>0.415104</td>
      <td>0.323020</td>
      <td>0.935069</td>
      <td>0.651443</td>
      <td>0.494040</td>
      <td>-0.242921</td>
      <td>-0.311065</td>
      <td>0.175395</td>
      <td>-0.629296</td>
      <td>-0.318971</td>
      <td>-1.177666</td>
      <td>-0.519947</td>
      <td>-0.980070</td>
      <td>-1.602365</td>
      <td>-0.887664</td>
      <td>-1.066747</td>
      <td>-0.783002</td>
      <td>-0.349160</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.103295</td>
      <td>0.194847</td>
      <td>0.765366</td>
      <td>-0.309704</td>
      <td>-0.086332</td>
      <td>-0.632094</td>
      <td>-0.191787</td>
      <td>0.054085</td>
      <td>0.077330</td>
      <td>0.114547</td>
      <td>0.515261</td>
      <td>0.418488</td>
      <td>-0.181332</td>
      <td>-0.198379</td>
      <td>0.001695</td>
      <td>0.774982</td>
      <td>1.420384</td>
      <td>-0.293812</td>
      <td>-0.541532</td>
      <td>0.236339</td>
      <td>0.697245</td>
      <td>0.577392</td>
      <td>0.551497</td>
      <td>-0.326586</td>
      <td>-1.360640</td>
      <td>0.360446</td>
      <td>0.190563</td>
      <td>-0.908069</td>
      <td>-0.404808</td>
      <td>-0.624578</td>
      <td>0.300392</td>
      <td>-0.142914</td>
      <td>-1.481207</td>
      <td>-0.915151</td>
      <td>0.678942</td>
      <td>0.057496</td>
      <td>-0.161582</td>
      <td>-0.014940</td>
      <td>0.066372</td>
      <td>0.228825</td>
      <td>...</td>
      <td>0.268613</td>
      <td>0.839229</td>
      <td>0.050818</td>
      <td>-0.564736</td>
      <td>0.203211</td>
      <td>-0.482572</td>
      <td>0.321766</td>
      <td>-0.144752</td>
      <td>0.430398</td>
      <td>0.012822</td>
      <td>-0.030932</td>
      <td>-0.111553</td>
      <td>0.681030</td>
      <td>-0.252430</td>
      <td>0.273543</td>
      <td>0.810412</td>
      <td>-0.813710</td>
      <td>0.060833</td>
      <td>0.098059</td>
      <td>-0.069144</td>
      <td>-0.601231</td>
      <td>0.385265</td>
      <td>0.378075</td>
      <td>0.407138</td>
      <td>1.640948</td>
      <td>0.705207</td>
      <td>0.235656</td>
      <td>0.006532</td>
      <td>0.280739</td>
      <td>1.062417</td>
      <td>0.437457</td>
      <td>-0.101350</td>
      <td>0.612221</td>
      <td>0.487267</td>
      <td>1.083647</td>
      <td>0.414055</td>
      <td>0.499344</td>
      <td>0.605145</td>
      <td>0.456306</td>
      <td>0.314151</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.180817</td>
      <td>0.174185</td>
      <td>-0.225745</td>
      <td>-0.047300</td>
      <td>-0.545568</td>
      <td>-0.558887</td>
      <td>-0.680218</td>
      <td>0.312357</td>
      <td>0.773719</td>
      <td>1.052008</td>
      <td>-0.503191</td>
      <td>-0.307203</td>
      <td>0.752878</td>
      <td>-0.966842</td>
      <td>0.638417</td>
      <td>0.624445</td>
      <td>-0.154915</td>
      <td>-0.227556</td>
      <td>0.264973</td>
      <td>0.996843</td>
      <td>-0.115878</td>
      <td>-0.448362</td>
      <td>0.703795</td>
      <td>0.750510</td>
      <td>0.243921</td>
      <td>0.191473</td>
      <td>0.382923</td>
      <td>0.896761</td>
      <td>-0.473586</td>
      <td>0.013179</td>
      <td>0.274492</td>
      <td>0.514496</td>
      <td>0.114538</td>
      <td>0.838026</td>
      <td>0.900397</td>
      <td>-0.130850</td>
      <td>-0.969996</td>
      <td>0.207406</td>
      <td>0.183357</td>
      <td>0.027655</td>
      <td>...</td>
      <td>-0.868773</td>
      <td>-0.044646</td>
      <td>0.177575</td>
      <td>-0.851672</td>
      <td>-0.643750</td>
      <td>0.476046</td>
      <td>-0.358262</td>
      <td>-0.015221</td>
      <td>-0.450683</td>
      <td>0.683169</td>
      <td>0.772159</td>
      <td>1.026496</td>
      <td>0.140937</td>
      <td>-0.163741</td>
      <td>-0.392535</td>
      <td>-0.558100</td>
      <td>0.058063</td>
      <td>-0.085330</td>
      <td>-0.016785</td>
      <td>0.070954</td>
      <td>-1.478233</td>
      <td>-0.332912</td>
      <td>0.287541</td>
      <td>-0.005625</td>
      <td>0.298572</td>
      <td>-0.670599</td>
      <td>-0.660871</td>
      <td>-0.206898</td>
      <td>0.773394</td>
      <td>-0.282706</td>
      <td>-1.014575</td>
      <td>0.189962</td>
      <td>-0.484479</td>
      <td>-0.294547</td>
      <td>-0.709294</td>
      <td>-0.910268</td>
      <td>-0.647747</td>
      <td>-0.632382</td>
      <td>-0.409103</td>
      <td>0.192226</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.535631</td>
      <td>-0.735799</td>
      <td>0.168095</td>
      <td>-0.686050</td>
      <td>0.134296</td>
      <td>0.560818</td>
      <td>0.638580</td>
      <td>0.435187</td>
      <td>-0.182745</td>
      <td>-0.011650</td>
      <td>0.598655</td>
      <td>0.066598</td>
      <td>-0.403688</td>
      <td>0.197212</td>
      <td>0.657152</td>
      <td>0.068164</td>
      <td>0.155690</td>
      <td>0.188599</td>
      <td>1.147512</td>
      <td>0.611721</td>
      <td>1.469683</td>
      <td>0.400358</td>
      <td>0.244166</td>
      <td>0.562623</td>
      <td>-0.404464</td>
      <td>0.121179</td>
      <td>-0.391010</td>
      <td>0.420280</td>
      <td>0.169608</td>
      <td>0.111936</td>
      <td>0.067397</td>
      <td>-0.314761</td>
      <td>-0.219840</td>
      <td>-1.150762</td>
      <td>0.230494</td>
      <td>0.141139</td>
      <td>-0.542577</td>
      <td>-0.723923</td>
      <td>0.365682</td>
      <td>-0.952202</td>
      <td>...</td>
      <td>-1.171618</td>
      <td>-0.979304</td>
      <td>-0.933733</td>
      <td>-1.194545</td>
      <td>0.574156</td>
      <td>0.161590</td>
      <td>0.788719</td>
      <td>0.999085</td>
      <td>0.711052</td>
      <td>1.050149</td>
      <td>-0.528199</td>
      <td>-1.675819</td>
      <td>-0.301840</td>
      <td>0.330174</td>
      <td>-0.558091</td>
      <td>0.663426</td>
      <td>0.284658</td>
      <td>1.401847</td>
      <td>0.729693</td>
      <td>0.898638</td>
      <td>-0.082624</td>
      <td>0.462997</td>
      <td>1.652623</td>
      <td>0.474730</td>
      <td>-0.638270</td>
      <td>-0.136027</td>
      <td>-0.256582</td>
      <td>-0.101671</td>
      <td>-0.083128</td>
      <td>-0.272024</td>
      <td>-0.473747</td>
      <td>0.658364</td>
      <td>0.247844</td>
      <td>1.816014</td>
      <td>-0.918457</td>
      <td>-1.420547</td>
      <td>-0.496589</td>
      <td>1.491959</td>
      <td>1.325445</td>
      <td>0.605537</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.322599</td>
      <td>-0.977085</td>
      <td>-0.376375</td>
      <td>-0.963166</td>
      <td>0.943630</td>
      <td>0.225790</td>
      <td>-0.068723</td>
      <td>-0.674716</td>
      <td>0.236808</td>
      <td>-0.505719</td>
      <td>-0.089001</td>
      <td>-0.417538</td>
      <td>-0.829872</td>
      <td>-0.373423</td>
      <td>1.037788</td>
      <td>0.729926</td>
      <td>0.416768</td>
      <td>0.145566</td>
      <td>0.196482</td>
      <td>1.361573</td>
      <td>1.112967</td>
      <td>-0.255964</td>
      <td>-0.037144</td>
      <td>0.230323</td>
      <td>1.189288</td>
      <td>-0.020106</td>
      <td>0.593460</td>
      <td>-0.518159</td>
      <td>-1.043944</td>
      <td>-1.627342</td>
      <td>-0.638767</td>
      <td>-0.393611</td>
      <td>-1.225703</td>
      <td>-0.853081</td>
      <td>1.270919</td>
      <td>-0.202320</td>
      <td>-0.382057</td>
      <td>-0.054466</td>
      <td>0.394121</td>
      <td>0.863411</td>
      <td>...</td>
      <td>-0.283299</td>
      <td>-0.276557</td>
      <td>-0.297461</td>
      <td>-0.111338</td>
      <td>0.101650</td>
      <td>0.700224</td>
      <td>0.568189</td>
      <td>-0.287590</td>
      <td>0.166317</td>
      <td>0.234584</td>
      <td>-0.430895</td>
      <td>-0.575632</td>
      <td>-0.355680</td>
      <td>-0.487371</td>
      <td>-1.081700</td>
      <td>-0.103926</td>
      <td>-0.053425</td>
      <td>-0.210598</td>
      <td>0.567665</td>
      <td>0.646079</td>
      <td>-0.058058</td>
      <td>0.508848</td>
      <td>1.713013</td>
      <td>0.232235</td>
      <td>0.424946</td>
      <td>1.044525</td>
      <td>0.198200</td>
      <td>0.116102</td>
      <td>-0.541483</td>
      <td>-0.047198</td>
      <td>0.303450</td>
      <td>0.331360</td>
      <td>0.319681</td>
      <td>-0.356516</td>
      <td>-0.985401</td>
      <td>0.389090</td>
      <td>0.111266</td>
      <td>0.538344</td>
      <td>-0.552898</td>
      <td>-0.011390</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.340889</td>
      <td>-0.692293</td>
      <td>-0.101680</td>
      <td>0.121929</td>
      <td>0.660681</td>
      <td>0.780139</td>
      <td>-0.237821</td>
      <td>-1.384061</td>
      <td>-0.496254</td>
      <td>0.640847</td>
      <td>0.463397</td>
      <td>-0.788372</td>
      <td>-0.401736</td>
      <td>-0.612892</td>
      <td>-0.393994</td>
      <td>-0.917320</td>
      <td>-0.428737</td>
      <td>0.222051</td>
      <td>0.650341</td>
      <td>1.289450</td>
      <td>1.769031</td>
      <td>0.941958</td>
      <td>-1.084754</td>
      <td>-0.228092</td>
      <td>1.005846</td>
      <td>-0.433866</td>
      <td>-0.850971</td>
      <td>-0.503747</td>
      <td>-0.388648</td>
      <td>-0.310672</td>
      <td>0.363702</td>
      <td>0.281728</td>
      <td>0.667127</td>
      <td>0.823256</td>
      <td>0.630276</td>
      <td>-0.346239</td>
      <td>0.042842</td>
      <td>0.544455</td>
      <td>0.477631</td>
      <td>0.303885</td>
      <td>...</td>
      <td>0.562655</td>
      <td>0.512512</td>
      <td>0.453596</td>
      <td>0.217298</td>
      <td>-0.195342</td>
      <td>-1.144872</td>
      <td>0.042503</td>
      <td>0.867358</td>
      <td>-0.112144</td>
      <td>-0.039743</td>
      <td>-0.004713</td>
      <td>-0.447366</td>
      <td>0.770044</td>
      <td>-0.519561</td>
      <td>-0.312874</td>
      <td>-0.226328</td>
      <td>0.339274</td>
      <td>-0.110042</td>
      <td>0.345494</td>
      <td>-0.549925</td>
      <td>0.515190</td>
      <td>0.840652</td>
      <td>-0.183748</td>
      <td>0.054488</td>
      <td>-1.054920</td>
      <td>-1.373889</td>
      <td>-0.487286</td>
      <td>0.469827</td>
      <td>0.319685</td>
      <td>0.931723</td>
      <td>0.715189</td>
      <td>-0.617232</td>
      <td>0.445848</td>
      <td>-0.496956</td>
      <td>-0.662209</td>
      <td>-0.785085</td>
      <td>0.354121</td>
      <td>-0.367554</td>
      <td>-0.758776</td>
      <td>-1.196149</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.548054</td>
      <td>0.518588</td>
      <td>0.290710</td>
      <td>0.059988</td>
      <td>0.468109</td>
      <td>-0.474609</td>
      <td>-0.265146</td>
      <td>-0.328351</td>
      <td>-0.021261</td>
      <td>-0.191289</td>
      <td>0.122040</td>
      <td>-0.093355</td>
      <td>0.349283</td>
      <td>-0.161658</td>
      <td>-1.273357</td>
      <td>0.271880</td>
      <td>0.843311</td>
      <td>-0.364776</td>
      <td>-0.017262</td>
      <td>0.599465</td>
      <td>0.616026</td>
      <td>0.315150</td>
      <td>-0.919143</td>
      <td>-0.509432</td>
      <td>0.834459</td>
      <td>0.112885</td>
      <td>0.224460</td>
      <td>0.149568</td>
      <td>-0.614226</td>
      <td>-0.251589</td>
      <td>-0.678433</td>
      <td>0.559712</td>
      <td>0.264077</td>
      <td>0.063225</td>
      <td>0.603774</td>
      <td>0.614795</td>
      <td>0.588636</td>
      <td>-0.937042</td>
      <td>-0.128720</td>
      <td>-0.186026</td>
      <td>...</td>
      <td>-1.084402</td>
      <td>-0.671215</td>
      <td>0.777271</td>
      <td>-0.560017</td>
      <td>-1.314714</td>
      <td>-1.011718</td>
      <td>-0.597300</td>
      <td>-1.048915</td>
      <td>-1.235162</td>
      <td>1.431225</td>
      <td>1.063649</td>
      <td>-0.318733</td>
      <td>0.636446</td>
      <td>0.741150</td>
      <td>0.200475</td>
      <td>0.671155</td>
      <td>-0.141366</td>
      <td>0.129404</td>
      <td>-0.041560</td>
      <td>-0.073436</td>
      <td>-0.970187</td>
      <td>-0.400280</td>
      <td>0.292846</td>
      <td>0.152809</td>
      <td>-0.528334</td>
      <td>0.188371</td>
      <td>-0.262770</td>
      <td>0.160568</td>
      <td>-0.592047</td>
      <td>-0.335015</td>
      <td>0.527454</td>
      <td>-0.254810</td>
      <td>-0.598823</td>
      <td>-0.868928</td>
      <td>-1.149185</td>
      <td>0.081762</td>
      <td>0.180627</td>
      <td>-0.540478</td>
      <td>-1.245143</td>
      <td>-0.321529</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.115893</td>
      <td>-0.896519</td>
      <td>-0.242016</td>
      <td>-0.152096</td>
      <td>0.572580</td>
      <td>-0.487830</td>
      <td>0.156364</td>
      <td>-0.099651</td>
      <td>-0.160379</td>
      <td>0.376560</td>
      <td>-0.385988</td>
      <td>0.310489</td>
      <td>0.038225</td>
      <td>-0.631158</td>
      <td>0.162861</td>
      <td>0.665578</td>
      <td>-0.260656</td>
      <td>-0.145083</td>
      <td>0.706716</td>
      <td>0.328871</td>
      <td>0.223857</td>
      <td>0.763885</td>
      <td>-0.438104</td>
      <td>0.688711</td>
      <td>0.996699</td>
      <td>0.980669</td>
      <td>0.538922</td>
      <td>-1.419708</td>
      <td>-0.033370</td>
      <td>-1.007751</td>
      <td>-0.021261</td>
      <td>1.374626</td>
      <td>0.361395</td>
      <td>0.857212</td>
      <td>-0.373686</td>
      <td>-0.393757</td>
      <td>0.470146</td>
      <td>0.002252</td>
      <td>-0.397663</td>
      <td>0.651769</td>
      <td>...</td>
      <td>-0.589136</td>
      <td>1.206511</td>
      <td>2.222118</td>
      <td>1.282429</td>
      <td>0.124497</td>
      <td>-0.306968</td>
      <td>-0.160178</td>
      <td>0.112648</td>
      <td>0.730582</td>
      <td>-0.107420</td>
      <td>-0.228477</td>
      <td>-0.660990</td>
      <td>0.332516</td>
      <td>-0.304944</td>
      <td>0.561085</td>
      <td>-0.321712</td>
      <td>-0.348625</td>
      <td>-0.402289</td>
      <td>-0.173544</td>
      <td>-0.030049</td>
      <td>0.250501</td>
      <td>0.579427</td>
      <td>0.278946</td>
      <td>0.764602</td>
      <td>0.645543</td>
      <td>-0.173307</td>
      <td>0.325707</td>
      <td>-0.733477</td>
      <td>-1.021458</td>
      <td>-0.940379</td>
      <td>0.633091</td>
      <td>0.879835</td>
      <td>1.088875</td>
      <td>0.220607</td>
      <td>0.274559</td>
      <td>-0.000221</td>
      <td>-0.679160</td>
      <td>0.094915</td>
      <td>0.238047</td>
      <td>0.774585</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.051173</td>
      <td>-0.798251</td>
      <td>-0.828740</td>
      <td>-0.273027</td>
      <td>0.110989</td>
      <td>0.033034</td>
      <td>0.214381</td>
      <td>-0.234382</td>
      <td>-0.484320</td>
      <td>0.460991</td>
      <td>1.071572</td>
      <td>-0.024648</td>
      <td>-0.192763</td>
      <td>0.144665</td>
      <td>-0.529288</td>
      <td>-0.350707</td>
      <td>-0.837053</td>
      <td>-0.397364</td>
      <td>-0.734108</td>
      <td>-0.869550</td>
      <td>-0.041408</td>
      <td>0.155063</td>
      <td>-1.047648</td>
      <td>-1.392183</td>
      <td>0.775949</td>
      <td>-0.653662</td>
      <td>1.026303</td>
      <td>-0.934866</td>
      <td>-0.399299</td>
      <td>0.153408</td>
      <td>0.695399</td>
      <td>0.955121</td>
      <td>-0.106764</td>
      <td>0.310131</td>
      <td>-0.738276</td>
      <td>-0.633348</td>
      <td>-0.134466</td>
      <td>0.200890</td>
      <td>-0.225730</td>
      <td>0.568266</td>
      <td>...</td>
      <td>-0.132906</td>
      <td>0.425509</td>
      <td>-0.031657</td>
      <td>0.423025</td>
      <td>-0.138970</td>
      <td>-0.179841</td>
      <td>-0.449937</td>
      <td>-0.260332</td>
      <td>0.232676</td>
      <td>0.190716</td>
      <td>0.243616</td>
      <td>0.190337</td>
      <td>-0.081406</td>
      <td>0.287495</td>
      <td>0.506981</td>
      <td>-0.315748</td>
      <td>-1.116503</td>
      <td>-0.445581</td>
      <td>-0.884883</td>
      <td>-0.311945</td>
      <td>0.344353</td>
      <td>0.307758</td>
      <td>-0.059270</td>
      <td>0.261350</td>
      <td>-1.374247</td>
      <td>-1.206210</td>
      <td>0.186102</td>
      <td>0.780737</td>
      <td>-0.440292</td>
      <td>0.276104</td>
      <td>0.074462</td>
      <td>-0.824366</td>
      <td>-0.664202</td>
      <td>-0.529990</td>
      <td>-0.791091</td>
      <td>-0.687751</td>
      <td>-0.707081</td>
      <td>0.514913</td>
      <td>0.185856</td>
      <td>1.067031</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.846404</td>
      <td>0.564543</td>
      <td>1.119465</td>
      <td>-0.005617</td>
      <td>0.512006</td>
      <td>0.292476</td>
      <td>0.231257</td>
      <td>-0.348862</td>
      <td>0.143757</td>
      <td>0.661315</td>
      <td>-0.710666</td>
      <td>-0.612573</td>
      <td>-0.189410</td>
      <td>-0.753674</td>
      <td>-0.733868</td>
      <td>0.288729</td>
      <td>-0.318348</td>
      <td>1.181237</td>
      <td>-0.656323</td>
      <td>-1.133270</td>
      <td>0.327932</td>
      <td>0.519825</td>
      <td>-1.150796</td>
      <td>-0.954964</td>
      <td>-0.919805</td>
      <td>-1.054573</td>
      <td>-1.579557</td>
      <td>-0.764214</td>
      <td>0.073630</td>
      <td>-0.289724</td>
      <td>0.943519</td>
      <td>0.631761</td>
      <td>0.493406</td>
      <td>0.381188</td>
      <td>0.249499</td>
      <td>0.439467</td>
      <td>0.312408</td>
      <td>1.429904</td>
      <td>0.588839</td>
      <td>-0.096820</td>
      <td>...</td>
      <td>0.424046</td>
      <td>0.263115</td>
      <td>0.820148</td>
      <td>0.142521</td>
      <td>0.209054</td>
      <td>0.009568</td>
      <td>0.167512</td>
      <td>-0.107980</td>
      <td>0.515703</td>
      <td>0.278297</td>
      <td>0.111017</td>
      <td>0.497438</td>
      <td>-0.266017</td>
      <td>0.307386</td>
      <td>-0.355825</td>
      <td>-0.493600</td>
      <td>0.098116</td>
      <td>-0.486455</td>
      <td>0.478389</td>
      <td>0.478196</td>
      <td>0.395773</td>
      <td>-0.553077</td>
      <td>-0.667212</td>
      <td>-0.903333</td>
      <td>-1.585137</td>
      <td>0.291919</td>
      <td>-0.635644</td>
      <td>-1.881723</td>
      <td>-1.758601</td>
      <td>-0.755316</td>
      <td>0.936330</td>
      <td>0.339743</td>
      <td>0.357849</td>
      <td>0.047987</td>
      <td>-1.332827</td>
      <td>-0.555642</td>
      <td>0.029759</td>
      <td>0.336770</td>
      <td>-0.372241</td>
      <td>-0.444889</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f68400d3d00&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  0.937055  0.043047  21.768309  4.634178e-105  0.852685  1.021425
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.960 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d8bbf5861d671d414e1a.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>