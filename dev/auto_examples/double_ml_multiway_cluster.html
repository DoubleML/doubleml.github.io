
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.101715efdecc9b59cb6e1ddfa685c31f.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d8bbf5861d671d414e1a.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">


    
    <a class="navbar-brand" href="../index.html">
      <p class="title">DoubleML</p>
    </a>
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  DoubleML
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/install.html">
  Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/intro.html">
  Getting started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../guide/guide.html">
  User guide
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api.html">
  Python API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference external nav-link" href="https://docs.doubleml.org/r/stable/">
  R API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../release/release.html">
  Release notes
 </a>
</li>

        
      </ul>

      <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><p class="logo" style="text-align:center;"><a href="../index.html">
    <img class="logo" src="../logo.png" alt="Logo" width="65%" height="65%">
</a></p><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l2 current active">
  <a class="current reference internal" href="#">
   Multiway Cluster Robust DML
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="double_ml_bonus_data.html">
   DML: Bonus Data
  </a>
 </li>
</ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulate-multiway-cluster-data">
   Simulate multiway cluster data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
   Initialize the objects of class DoubleMLData and DoubleMLPLIV
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#split-samples-and-transfer-the-sample-splitting-to-the-object">
   Split samples and transfer the sample splitting to the object
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fit-the-model-and-show-a-summary">
   Fit the model and show a summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing">
   Visualization of sample splitting with tuple and linear indexing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold">
     Visualize sample splitting with tuples (one plot per fold)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
     Visualize sample splitting with linear indexing (one column per fold)
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-0.565323</td>
      <td>-1.279769</td>
      <td>-0.002347</td>
      <td>-0.515327</td>
      <td>-0.501701</td>
      <td>0.469554</td>
      <td>0.331729</td>
      <td>0.108562</td>
      <td>0.316633</td>
      <td>-0.228829</td>
      <td>-0.071283</td>
      <td>0.374927</td>
      <td>1.137415</td>
      <td>-0.639566</td>
      <td>-0.042388</td>
      <td>-0.075764</td>
      <td>-0.155233</td>
      <td>-0.413199</td>
      <td>0.810660</td>
      <td>-0.514418</td>
      <td>-0.509358</td>
      <td>0.202221</td>
      <td>-0.937230</td>
      <td>0.819718</td>
      <td>-0.122680</td>
      <td>-0.269330</td>
      <td>1.243752</td>
      <td>0.859791</td>
      <td>0.886948</td>
      <td>0.915531</td>
      <td>-0.539918</td>
      <td>0.484324</td>
      <td>-0.005009</td>
      <td>0.293524</td>
      <td>-0.165968</td>
      <td>-0.131074</td>
      <td>-0.361006</td>
      <td>-1.285498</td>
      <td>-0.400104</td>
      <td>-0.185140</td>
      <td>...</td>
      <td>0.251385</td>
      <td>0.321501</td>
      <td>0.786753</td>
      <td>0.567895</td>
      <td>1.341554</td>
      <td>0.772240</td>
      <td>0.559152</td>
      <td>-0.193112</td>
      <td>-0.472443</td>
      <td>-0.491725</td>
      <td>-0.600408</td>
      <td>-0.018060</td>
      <td>-0.791010</td>
      <td>-1.273632</td>
      <td>-1.098835</td>
      <td>-0.690205</td>
      <td>0.549187</td>
      <td>0.975564</td>
      <td>-0.214676</td>
      <td>-1.253929</td>
      <td>-0.157827</td>
      <td>0.190300</td>
      <td>-1.033076</td>
      <td>-0.798131</td>
      <td>-0.048588</td>
      <td>-0.024199</td>
      <td>-0.723789</td>
      <td>-0.192430</td>
      <td>0.689711</td>
      <td>-0.180537</td>
      <td>0.536109</td>
      <td>0.188526</td>
      <td>0.387262</td>
      <td>1.007845</td>
      <td>0.895179</td>
      <td>0.400841</td>
      <td>-0.661217</td>
      <td>-0.467841</td>
      <td>-0.062002</td>
      <td>-0.425481</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.660902</td>
      <td>-0.598458</td>
      <td>-0.185135</td>
      <td>-0.353357</td>
      <td>0.240683</td>
      <td>-0.155930</td>
      <td>-0.256074</td>
      <td>-0.539955</td>
      <td>0.510680</td>
      <td>0.149357</td>
      <td>-0.135199</td>
      <td>0.756080</td>
      <td>0.165591</td>
      <td>-0.589958</td>
      <td>-1.109761</td>
      <td>0.335822</td>
      <td>0.328837</td>
      <td>-0.814522</td>
      <td>-0.064323</td>
      <td>-0.012071</td>
      <td>-1.180538</td>
      <td>-0.306242</td>
      <td>-1.263920</td>
      <td>-0.681717</td>
      <td>0.318234</td>
      <td>0.777493</td>
      <td>0.209172</td>
      <td>-0.746937</td>
      <td>0.034102</td>
      <td>0.775261</td>
      <td>0.533747</td>
      <td>0.292137</td>
      <td>-0.711202</td>
      <td>0.696136</td>
      <td>1.538511</td>
      <td>-0.071214</td>
      <td>-0.162587</td>
      <td>0.998231</td>
      <td>0.270102</td>
      <td>0.204599</td>
      <td>...</td>
      <td>0.532870</td>
      <td>0.001175</td>
      <td>0.505812</td>
      <td>0.220151</td>
      <td>1.076002</td>
      <td>-0.849662</td>
      <td>0.210931</td>
      <td>0.056400</td>
      <td>0.290511</td>
      <td>-0.721994</td>
      <td>-0.029928</td>
      <td>1.229708</td>
      <td>1.146895</td>
      <td>-0.430274</td>
      <td>-0.651189</td>
      <td>-0.888851</td>
      <td>-0.766515</td>
      <td>-0.530709</td>
      <td>-0.518557</td>
      <td>0.173982</td>
      <td>-0.015087</td>
      <td>-0.815310</td>
      <td>-1.386347</td>
      <td>-0.850502</td>
      <td>0.238636</td>
      <td>0.412636</td>
      <td>-0.154926</td>
      <td>0.203127</td>
      <td>0.496873</td>
      <td>0.512158</td>
      <td>1.333953</td>
      <td>0.088083</td>
      <td>0.918145</td>
      <td>-0.595568</td>
      <td>0.201387</td>
      <td>0.421242</td>
      <td>-0.491443</td>
      <td>2.882182</td>
      <td>1.435964</td>
      <td>1.005583</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.842437</td>
      <td>-1.155739</td>
      <td>-0.349336</td>
      <td>-1.504286</td>
      <td>0.441301</td>
      <td>0.763604</td>
      <td>-0.017339</td>
      <td>-0.186575</td>
      <td>0.300401</td>
      <td>0.490622</td>
      <td>0.367941</td>
      <td>0.891871</td>
      <td>-0.444050</td>
      <td>-0.755395</td>
      <td>-0.443715</td>
      <td>0.001969</td>
      <td>0.811632</td>
      <td>0.238430</td>
      <td>0.532684</td>
      <td>0.376660</td>
      <td>-0.038216</td>
      <td>0.045455</td>
      <td>0.719667</td>
      <td>1.456947</td>
      <td>-0.125160</td>
      <td>-0.805262</td>
      <td>-0.217687</td>
      <td>-0.917475</td>
      <td>0.060011</td>
      <td>1.149915</td>
      <td>0.140366</td>
      <td>-0.394909</td>
      <td>0.726718</td>
      <td>-0.183115</td>
      <td>-1.040840</td>
      <td>0.463504</td>
      <td>0.024850</td>
      <td>1.220499</td>
      <td>0.648281</td>
      <td>-0.173524</td>
      <td>...</td>
      <td>0.537723</td>
      <td>0.201866</td>
      <td>-0.743576</td>
      <td>-0.376901</td>
      <td>0.629067</td>
      <td>0.451688</td>
      <td>0.045323</td>
      <td>-0.049503</td>
      <td>1.318221</td>
      <td>-0.738136</td>
      <td>-0.683118</td>
      <td>-0.627040</td>
      <td>0.426037</td>
      <td>-1.952145</td>
      <td>-0.754816</td>
      <td>0.175279</td>
      <td>-0.023260</td>
      <td>0.428857</td>
      <td>-0.035648</td>
      <td>1.238277</td>
      <td>-0.157981</td>
      <td>0.373553</td>
      <td>-0.355823</td>
      <td>-0.342467</td>
      <td>-0.893432</td>
      <td>-0.493911</td>
      <td>-0.091313</td>
      <td>0.462013</td>
      <td>-0.209657</td>
      <td>0.366536</td>
      <td>-0.024406</td>
      <td>-0.068162</td>
      <td>-0.050033</td>
      <td>0.412572</td>
      <td>0.181503</td>
      <td>-0.029891</td>
      <td>-0.786503</td>
      <td>-2.706813</td>
      <td>-2.539879</td>
      <td>-0.654518</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.398081</td>
      <td>-0.268046</td>
      <td>-0.280953</td>
      <td>0.409649</td>
      <td>0.380056</td>
      <td>1.847729</td>
      <td>1.143725</td>
      <td>0.196462</td>
      <td>-0.301435</td>
      <td>-1.910809</td>
      <td>0.470297</td>
      <td>0.726624</td>
      <td>0.025291</td>
      <td>-0.475897</td>
      <td>-0.716174</td>
      <td>0.164116</td>
      <td>1.688931</td>
      <td>0.317093</td>
      <td>-0.969300</td>
      <td>-1.347451</td>
      <td>-1.201262</td>
      <td>-0.683679</td>
      <td>-0.266558</td>
      <td>0.186087</td>
      <td>-0.009111</td>
      <td>0.920394</td>
      <td>0.754225</td>
      <td>0.073944</td>
      <td>-0.169186</td>
      <td>-0.064747</td>
      <td>-0.902308</td>
      <td>-0.149708</td>
      <td>0.263748</td>
      <td>0.094559</td>
      <td>-0.032296</td>
      <td>0.366726</td>
      <td>0.799192</td>
      <td>0.543675</td>
      <td>0.705502</td>
      <td>-0.015652</td>
      <td>...</td>
      <td>-0.637236</td>
      <td>-0.732346</td>
      <td>0.252966</td>
      <td>-0.352539</td>
      <td>0.369711</td>
      <td>0.611544</td>
      <td>0.159993</td>
      <td>0.460925</td>
      <td>1.064147</td>
      <td>-0.342899</td>
      <td>-0.051273</td>
      <td>0.477220</td>
      <td>0.123666</td>
      <td>-0.313052</td>
      <td>1.029594</td>
      <td>-0.711942</td>
      <td>0.136592</td>
      <td>0.618952</td>
      <td>0.728597</td>
      <td>0.461600</td>
      <td>-0.509169</td>
      <td>-0.535067</td>
      <td>0.851720</td>
      <td>-0.419145</td>
      <td>-0.258219</td>
      <td>-1.232830</td>
      <td>0.039541</td>
      <td>0.411539</td>
      <td>0.581294</td>
      <td>0.223224</td>
      <td>-0.136297</td>
      <td>1.079456</td>
      <td>0.573731</td>
      <td>0.323769</td>
      <td>0.296182</td>
      <td>0.446089</td>
      <td>-0.662571</td>
      <td>1.121115</td>
      <td>1.027432</td>
      <td>1.406115</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.219364</td>
      <td>-1.256054</td>
      <td>-0.089980</td>
      <td>0.217133</td>
      <td>0.487205</td>
      <td>1.076842</td>
      <td>-0.178193</td>
      <td>0.447694</td>
      <td>0.707020</td>
      <td>0.929195</td>
      <td>0.525448</td>
      <td>0.277429</td>
      <td>-0.159948</td>
      <td>-0.818244</td>
      <td>-0.060401</td>
      <td>-0.004853</td>
      <td>1.042102</td>
      <td>-0.265029</td>
      <td>1.057104</td>
      <td>0.702617</td>
      <td>-0.411568</td>
      <td>0.463640</td>
      <td>-0.959290</td>
      <td>-0.192864</td>
      <td>0.299549</td>
      <td>0.670561</td>
      <td>-0.093307</td>
      <td>-0.681697</td>
      <td>0.105699</td>
      <td>-0.209833</td>
      <td>0.221303</td>
      <td>-0.630615</td>
      <td>-0.704445</td>
      <td>0.728515</td>
      <td>-0.285514</td>
      <td>1.081256</td>
      <td>1.012415</td>
      <td>0.335923</td>
      <td>-0.098171</td>
      <td>-0.702798</td>
      <td>...</td>
      <td>-0.200376</td>
      <td>-1.293723</td>
      <td>-0.805356</td>
      <td>-0.751970</td>
      <td>1.499689</td>
      <td>1.360868</td>
      <td>-0.133310</td>
      <td>-0.070980</td>
      <td>0.500548</td>
      <td>-0.315206</td>
      <td>-0.184864</td>
      <td>0.058430</td>
      <td>0.529037</td>
      <td>-1.168871</td>
      <td>0.255847</td>
      <td>0.303268</td>
      <td>-0.742835</td>
      <td>-0.283182</td>
      <td>0.022869</td>
      <td>-0.916779</td>
      <td>0.366033</td>
      <td>0.154244</td>
      <td>-0.942109</td>
      <td>-0.427811</td>
      <td>-0.660562</td>
      <td>0.181241</td>
      <td>-0.003189</td>
      <td>-0.360953</td>
      <td>-0.145999</td>
      <td>-0.281012</td>
      <td>-0.878489</td>
      <td>1.373215</td>
      <td>0.629413</td>
      <td>0.632743</td>
      <td>-0.200035</td>
      <td>0.346130</td>
      <td>-1.093128</td>
      <td>1.383609</td>
      <td>0.452537</td>
      <td>0.591115</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.039749</td>
      <td>-0.239693</td>
      <td>-0.415932</td>
      <td>-0.272371</td>
      <td>-0.074597</td>
      <td>0.086191</td>
      <td>0.281817</td>
      <td>-0.141075</td>
      <td>0.336613</td>
      <td>1.306827</td>
      <td>-0.090842</td>
      <td>0.074918</td>
      <td>1.012818</td>
      <td>-0.071042</td>
      <td>-1.516996</td>
      <td>-0.190916</td>
      <td>-0.321124</td>
      <td>-0.500231</td>
      <td>0.614937</td>
      <td>-0.475990</td>
      <td>-0.690083</td>
      <td>0.289085</td>
      <td>-0.168542</td>
      <td>1.146975</td>
      <td>0.447874</td>
      <td>0.412050</td>
      <td>0.095052</td>
      <td>0.321552</td>
      <td>-0.105965</td>
      <td>-0.275118</td>
      <td>-0.380955</td>
      <td>0.651503</td>
      <td>-0.157073</td>
      <td>-0.348695</td>
      <td>0.703714</td>
      <td>0.519176</td>
      <td>-0.199611</td>
      <td>-0.130495</td>
      <td>-0.291245</td>
      <td>-0.673931</td>
      <td>...</td>
      <td>0.351597</td>
      <td>-0.115002</td>
      <td>0.691085</td>
      <td>0.588989</td>
      <td>1.027684</td>
      <td>-0.194158</td>
      <td>0.117228</td>
      <td>-0.795923</td>
      <td>0.105736</td>
      <td>-0.754364</td>
      <td>-0.400217</td>
      <td>0.402187</td>
      <td>0.479761</td>
      <td>-0.524058</td>
      <td>-0.547282</td>
      <td>0.076828</td>
      <td>0.143125</td>
      <td>-0.102149</td>
      <td>-0.059939</td>
      <td>-0.110141</td>
      <td>-0.157369</td>
      <td>0.283015</td>
      <td>0.480973</td>
      <td>0.327038</td>
      <td>1.500067</td>
      <td>1.298154</td>
      <td>0.394390</td>
      <td>-0.104509</td>
      <td>-0.665440</td>
      <td>-0.247310</td>
      <td>0.921311</td>
      <td>-0.189954</td>
      <td>-0.049180</td>
      <td>0.477128</td>
      <td>1.373808</td>
      <td>-0.764258</td>
      <td>-0.684864</td>
      <td>-0.759123</td>
      <td>-0.722208</td>
      <td>0.247380</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1.187760</td>
      <td>1.432768</td>
      <td>0.414163</td>
      <td>0.148179</td>
      <td>-0.626646</td>
      <td>-0.350538</td>
      <td>-0.384973</td>
      <td>-0.614460</td>
      <td>-0.070394</td>
      <td>-0.782240</td>
      <td>-0.693348</td>
      <td>0.209070</td>
      <td>0.189593</td>
      <td>0.123691</td>
      <td>-0.098816</td>
      <td>-0.887055</td>
      <td>0.318742</td>
      <td>-0.799252</td>
      <td>-0.985325</td>
      <td>-0.077313</td>
      <td>-0.918834</td>
      <td>-0.570174</td>
      <td>0.639035</td>
      <td>-0.186510</td>
      <td>-0.345950</td>
      <td>0.574114</td>
      <td>0.071530</td>
      <td>0.776597</td>
      <td>0.308718</td>
      <td>0.422530</td>
      <td>-0.521514</td>
      <td>0.159104</td>
      <td>0.444432</td>
      <td>0.656657</td>
      <td>0.030962</td>
      <td>0.719233</td>
      <td>0.476904</td>
      <td>0.599574</td>
      <td>0.864591</td>
      <td>-0.178891</td>
      <td>...</td>
      <td>-0.123596</td>
      <td>-0.205090</td>
      <td>-0.315484</td>
      <td>-1.509610</td>
      <td>0.845084</td>
      <td>1.585836</td>
      <td>0.874749</td>
      <td>0.078550</td>
      <td>1.069513</td>
      <td>-1.524484</td>
      <td>0.140875</td>
      <td>0.216456</td>
      <td>0.098310</td>
      <td>-0.166799</td>
      <td>-0.172510</td>
      <td>-0.457505</td>
      <td>-0.175904</td>
      <td>-0.418813</td>
      <td>-0.610598</td>
      <td>-0.316325</td>
      <td>-0.900270</td>
      <td>0.005654</td>
      <td>0.151471</td>
      <td>0.387036</td>
      <td>1.546733</td>
      <td>0.914055</td>
      <td>0.572767</td>
      <td>0.331032</td>
      <td>-0.630069</td>
      <td>-0.788487</td>
      <td>-0.370266</td>
      <td>-0.308012</td>
      <td>0.206386</td>
      <td>0.846612</td>
      <td>-0.407685</td>
      <td>-0.681574</td>
      <td>-0.040387</td>
      <td>1.718324</td>
      <td>1.470897</td>
      <td>0.722517</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.156995</td>
      <td>-1.820600</td>
      <td>-0.454882</td>
      <td>-0.005223</td>
      <td>0.302149</td>
      <td>0.229753</td>
      <td>0.229731</td>
      <td>0.190669</td>
      <td>0.730225</td>
      <td>1.093998</td>
      <td>-0.059936</td>
      <td>0.535949</td>
      <td>1.056021</td>
      <td>-0.503521</td>
      <td>-0.910583</td>
      <td>-0.488309</td>
      <td>0.029327</td>
      <td>-0.476514</td>
      <td>0.126140</td>
      <td>1.361949</td>
      <td>0.166214</td>
      <td>1.276163</td>
      <td>-0.191147</td>
      <td>-0.363221</td>
      <td>0.719732</td>
      <td>0.615192</td>
      <td>0.217258</td>
      <td>0.129370</td>
      <td>0.790778</td>
      <td>-0.983780</td>
      <td>-1.454312</td>
      <td>-1.078661</td>
      <td>0.060742</td>
      <td>-0.054849</td>
      <td>-0.014916</td>
      <td>0.733127</td>
      <td>-1.120684</td>
      <td>-1.035907</td>
      <td>-0.270993</td>
      <td>0.056879</td>
      <td>...</td>
      <td>0.352095</td>
      <td>-0.742489</td>
      <td>0.826819</td>
      <td>0.936309</td>
      <td>-0.000435</td>
      <td>0.648765</td>
      <td>0.489632</td>
      <td>-0.312994</td>
      <td>0.561900</td>
      <td>-0.174789</td>
      <td>0.574337</td>
      <td>0.946593</td>
      <td>0.514204</td>
      <td>-0.529113</td>
      <td>-0.395528</td>
      <td>-0.209558</td>
      <td>-0.067674</td>
      <td>0.037058</td>
      <td>-0.539831</td>
      <td>0.169318</td>
      <td>0.386891</td>
      <td>0.888459</td>
      <td>0.047816</td>
      <td>-0.915839</td>
      <td>0.219308</td>
      <td>0.849998</td>
      <td>0.195508</td>
      <td>-0.022324</td>
      <td>-0.639446</td>
      <td>-0.852445</td>
      <td>-0.090245</td>
      <td>0.449042</td>
      <td>0.685137</td>
      <td>0.625335</td>
      <td>0.503604</td>
      <td>-0.387680</td>
      <td>-1.647823</td>
      <td>-0.964744</td>
      <td>-0.619410</td>
      <td>-0.137756</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.355773</td>
      <td>0.217090</td>
      <td>0.454529</td>
      <td>-0.750254</td>
      <td>0.887436</td>
      <td>-0.297152</td>
      <td>-0.790643</td>
      <td>-1.323747</td>
      <td>-0.799528</td>
      <td>0.815826</td>
      <td>-0.169846</td>
      <td>-0.207793</td>
      <td>-0.319894</td>
      <td>-0.190742</td>
      <td>0.270731</td>
      <td>0.530806</td>
      <td>0.627629</td>
      <td>-0.152012</td>
      <td>-0.697482</td>
      <td>-0.118330</td>
      <td>-0.452363</td>
      <td>-0.548640</td>
      <td>0.326148</td>
      <td>1.603638</td>
      <td>0.638244</td>
      <td>0.198584</td>
      <td>1.129440</td>
      <td>0.780522</td>
      <td>-0.145338</td>
      <td>0.172208</td>
      <td>-0.249897</td>
      <td>-1.402504</td>
      <td>0.860331</td>
      <td>1.500234</td>
      <td>0.164135</td>
      <td>0.372178</td>
      <td>0.419769</td>
      <td>0.095938</td>
      <td>0.367910</td>
      <td>-0.180802</td>
      <td>...</td>
      <td>-0.495197</td>
      <td>-1.019942</td>
      <td>-0.294820</td>
      <td>1.029882</td>
      <td>0.973485</td>
      <td>0.030551</td>
      <td>0.292297</td>
      <td>0.215511</td>
      <td>0.284962</td>
      <td>-1.021407</td>
      <td>-0.314800</td>
      <td>-0.568898</td>
      <td>0.741377</td>
      <td>-0.652009</td>
      <td>-1.114400</td>
      <td>0.565986</td>
      <td>1.426695</td>
      <td>0.120510</td>
      <td>0.141777</td>
      <td>0.982307</td>
      <td>0.880533</td>
      <td>-0.239094</td>
      <td>-0.741735</td>
      <td>0.032071</td>
      <td>0.401776</td>
      <td>0.872997</td>
      <td>0.159022</td>
      <td>-0.624545</td>
      <td>0.451734</td>
      <td>0.073121</td>
      <td>1.103263</td>
      <td>1.080005</td>
      <td>0.532450</td>
      <td>-0.110555</td>
      <td>-0.319714</td>
      <td>0.212891</td>
      <td>0.211916</td>
      <td>0.325597</td>
      <td>0.808871</td>
      <td>0.855106</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-0.942529</td>
      <td>-1.727593</td>
      <td>-1.002971</td>
      <td>-0.549245</td>
      <td>-0.274428</td>
      <td>0.142430</td>
      <td>-0.194400</td>
      <td>0.599964</td>
      <td>0.682142</td>
      <td>0.211371</td>
      <td>-0.113572</td>
      <td>0.283133</td>
      <td>-0.968481</td>
      <td>-1.145387</td>
      <td>-0.088145</td>
      <td>-1.584720</td>
      <td>0.732583</td>
      <td>-0.722607</td>
      <td>0.942782</td>
      <td>-0.485903</td>
      <td>-0.412548</td>
      <td>-0.004426</td>
      <td>-2.212719</td>
      <td>-0.765387</td>
      <td>0.308498</td>
      <td>-0.920107</td>
      <td>0.441694</td>
      <td>0.119276</td>
      <td>0.031342</td>
      <td>0.103541</td>
      <td>0.924184</td>
      <td>0.021588</td>
      <td>-0.021736</td>
      <td>0.147992</td>
      <td>1.323583</td>
      <td>0.823587</td>
      <td>-0.147783</td>
      <td>-0.527092</td>
      <td>-0.121209</td>
      <td>-0.557949</td>
      <td>...</td>
      <td>0.290006</td>
      <td>0.008537</td>
      <td>0.231036</td>
      <td>-0.395608</td>
      <td>0.379326</td>
      <td>1.258577</td>
      <td>0.392507</td>
      <td>0.662520</td>
      <td>0.318888</td>
      <td>0.352729</td>
      <td>0.303745</td>
      <td>0.830629</td>
      <td>-0.682231</td>
      <td>-0.827191</td>
      <td>-0.733721</td>
      <td>-0.369759</td>
      <td>-0.169423</td>
      <td>0.080152</td>
      <td>0.434180</td>
      <td>-0.252174</td>
      <td>-0.290131</td>
      <td>0.074224</td>
      <td>-0.310695</td>
      <td>1.039558</td>
      <td>0.850317</td>
      <td>0.628566</td>
      <td>0.584859</td>
      <td>0.353698</td>
      <td>0.740132</td>
      <td>0.337616</td>
      <td>-0.591956</td>
      <td>1.214363</td>
      <td>-0.135536</td>
      <td>-0.072748</td>
      <td>1.068518</td>
      <td>-0.041129</td>
      <td>-0.548059</td>
      <td>-3.576492</td>
      <td>-2.247641</td>
      <td>-0.505674</td>
    </tr>
    <tr>
      <th>10</th>
      <td>1.113356</td>
      <td>0.244608</td>
      <td>1.287060</td>
      <td>0.184738</td>
      <td>-0.373895</td>
      <td>0.393743</td>
      <td>0.119345</td>
      <td>-0.779388</td>
      <td>1.040251</td>
      <td>0.240126</td>
      <td>0.134736</td>
      <td>0.655094</td>
      <td>0.673673</td>
      <td>-0.277222</td>
      <td>-0.291748</td>
      <td>0.419750</td>
      <td>0.201069</td>
      <td>-1.047306</td>
      <td>-1.407829</td>
      <td>-0.471779</td>
      <td>-0.550788</td>
      <td>-0.669515</td>
      <td>0.269919</td>
      <td>0.603283</td>
      <td>0.296205</td>
      <td>0.633075</td>
      <td>-0.390409</td>
      <td>-0.574336</td>
      <td>0.182857</td>
      <td>0.410645</td>
      <td>-0.303848</td>
      <td>0.280578</td>
      <td>0.419254</td>
      <td>1.046134</td>
      <td>-0.409637</td>
      <td>0.157877</td>
      <td>0.815349</td>
      <td>-0.768163</td>
      <td>-0.026537</td>
      <td>-0.709136</td>
      <td>...</td>
      <td>0.861320</td>
      <td>-0.360704</td>
      <td>-0.190165</td>
      <td>1.144953</td>
      <td>0.269132</td>
      <td>0.843685</td>
      <td>1.997390</td>
      <td>0.350475</td>
      <td>0.054563</td>
      <td>-0.506898</td>
      <td>0.358428</td>
      <td>-0.272451</td>
      <td>-0.567923</td>
      <td>0.583539</td>
      <td>1.342169</td>
      <td>1.008363</td>
      <td>0.192406</td>
      <td>-0.551617</td>
      <td>-0.040817</td>
      <td>-0.101021</td>
      <td>-0.925318</td>
      <td>-0.517385</td>
      <td>-1.230807</td>
      <td>0.294585</td>
      <td>-0.400525</td>
      <td>-0.565716</td>
      <td>-0.219998</td>
      <td>-0.361917</td>
      <td>0.523681</td>
      <td>0.773620</td>
      <td>0.124456</td>
      <td>0.317955</td>
      <td>-0.542378</td>
      <td>-0.250746</td>
      <td>-0.320270</td>
      <td>-0.134661</td>
      <td>-0.338121</td>
      <td>2.459769</td>
      <td>1.924087</td>
      <td>1.206240</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.734471</td>
      <td>0.070160</td>
      <td>0.122512</td>
      <td>0.561618</td>
      <td>0.174574</td>
      <td>0.159029</td>
      <td>-0.242259</td>
      <td>-0.527742</td>
      <td>-0.425975</td>
      <td>0.345290</td>
      <td>-0.257021</td>
      <td>0.250049</td>
      <td>0.523969</td>
      <td>-0.143832</td>
      <td>-0.180472</td>
      <td>0.701585</td>
      <td>1.003152</td>
      <td>-0.649001</td>
      <td>0.028336</td>
      <td>0.683280</td>
      <td>-0.004474</td>
      <td>-0.562543</td>
      <td>-0.593943</td>
      <td>-0.033974</td>
      <td>-0.391999</td>
      <td>0.299405</td>
      <td>-0.246269</td>
      <td>-0.101896</td>
      <td>0.526167</td>
      <td>0.627737</td>
      <td>-0.252962</td>
      <td>-0.258030</td>
      <td>-0.721391</td>
      <td>0.532636</td>
      <td>-0.384310</td>
      <td>-0.158866</td>
      <td>0.512861</td>
      <td>0.248279</td>
      <td>0.311084</td>
      <td>-0.682462</td>
      <td>...</td>
      <td>0.300106</td>
      <td>0.305556</td>
      <td>0.422407</td>
      <td>0.243169</td>
      <td>0.646612</td>
      <td>0.347125</td>
      <td>1.712775</td>
      <td>0.939627</td>
      <td>0.614841</td>
      <td>0.155654</td>
      <td>0.964060</td>
      <td>0.374922</td>
      <td>0.350490</td>
      <td>-1.573221</td>
      <td>-1.026083</td>
      <td>0.090182</td>
      <td>-1.096619</td>
      <td>-0.606861</td>
      <td>-0.084744</td>
      <td>0.625380</td>
      <td>-0.380213</td>
      <td>-0.867168</td>
      <td>-0.203978</td>
      <td>-0.483817</td>
      <td>1.389206</td>
      <td>0.314764</td>
      <td>0.251574</td>
      <td>-0.089513</td>
      <td>-0.932288</td>
      <td>-0.483946</td>
      <td>0.419755</td>
      <td>0.468086</td>
      <td>-0.043781</td>
      <td>0.046014</td>
      <td>0.567908</td>
      <td>0.632766</td>
      <td>-1.043075</td>
      <td>0.298029</td>
      <td>-0.361029</td>
      <td>-0.233741</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.744466</td>
      <td>-0.821220</td>
      <td>-0.090192</td>
      <td>0.782393</td>
      <td>-0.620368</td>
      <td>0.789169</td>
      <td>0.046227</td>
      <td>0.328170</td>
      <td>0.349774</td>
      <td>-0.207816</td>
      <td>-0.518379</td>
      <td>-0.372203</td>
      <td>-0.206983</td>
      <td>0.531289</td>
      <td>0.542884</td>
      <td>0.122126</td>
      <td>0.661428</td>
      <td>-0.064762</td>
      <td>0.389712</td>
      <td>0.193483</td>
      <td>-0.070757</td>
      <td>0.627437</td>
      <td>-0.113524</td>
      <td>0.225694</td>
      <td>0.045228</td>
      <td>-0.283179</td>
      <td>0.650056</td>
      <td>0.358059</td>
      <td>0.934916</td>
      <td>0.253507</td>
      <td>0.595188</td>
      <td>0.735489</td>
      <td>-0.217369</td>
      <td>0.098961</td>
      <td>0.249738</td>
      <td>-0.184512</td>
      <td>0.267172</td>
      <td>0.704632</td>
      <td>-0.114576</td>
      <td>-1.362737</td>
      <td>...</td>
      <td>0.296410</td>
      <td>0.073824</td>
      <td>0.008115</td>
      <td>-0.046673</td>
      <td>1.106654</td>
      <td>0.595463</td>
      <td>-0.205989</td>
      <td>-0.649555</td>
      <td>0.522864</td>
      <td>-0.197146</td>
      <td>-0.149197</td>
      <td>0.195440</td>
      <td>0.583812</td>
      <td>0.044644</td>
      <td>0.584455</td>
      <td>0.765829</td>
      <td>-0.474039</td>
      <td>-0.195974</td>
      <td>-0.083269</td>
      <td>-0.356141</td>
      <td>0.639614</td>
      <td>0.544679</td>
      <td>0.015332</td>
      <td>0.425780</td>
      <td>1.024436</td>
      <td>0.470219</td>
      <td>0.342408</td>
      <td>-0.535484</td>
      <td>-0.780086</td>
      <td>-0.273684</td>
      <td>0.523271</td>
      <td>0.931652</td>
      <td>-0.304994</td>
      <td>0.287958</td>
      <td>-0.123393</td>
      <td>-1.330084</td>
      <td>0.025768</td>
      <td>0.865288</td>
      <td>0.297066</td>
      <td>0.183183</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.087293</td>
      <td>-1.188635</td>
      <td>-0.028706</td>
      <td>-0.561967</td>
      <td>-0.580699</td>
      <td>-0.599414</td>
      <td>-0.475440</td>
      <td>0.356350</td>
      <td>0.496616</td>
      <td>-0.162152</td>
      <td>-0.464957</td>
      <td>-0.407390</td>
      <td>0.334852</td>
      <td>-1.381802</td>
      <td>-0.422746</td>
      <td>-1.025704</td>
      <td>-0.753992</td>
      <td>-1.328222</td>
      <td>-0.378002</td>
      <td>0.814495</td>
      <td>0.200181</td>
      <td>-0.005751</td>
      <td>-0.251960</td>
      <td>-0.075592</td>
      <td>-0.614706</td>
      <td>-0.180297</td>
      <td>-0.418657</td>
      <td>0.087546</td>
      <td>0.762625</td>
      <td>0.595667</td>
      <td>-0.578391</td>
      <td>-0.913520</td>
      <td>0.739663</td>
      <td>-0.431520</td>
      <td>0.160477</td>
      <td>0.327392</td>
      <td>-0.618814</td>
      <td>-0.741570</td>
      <td>0.094691</td>
      <td>-0.747340</td>
      <td>...</td>
      <td>0.766101</td>
      <td>0.241971</td>
      <td>-0.249148</td>
      <td>0.030521</td>
      <td>0.501636</td>
      <td>0.407915</td>
      <td>0.198457</td>
      <td>-0.156246</td>
      <td>0.789926</td>
      <td>-0.605116</td>
      <td>0.678009</td>
      <td>0.421642</td>
      <td>-0.213851</td>
      <td>-0.630384</td>
      <td>-0.509057</td>
      <td>-0.896950</td>
      <td>-0.849546</td>
      <td>0.685834</td>
      <td>0.074094</td>
      <td>-0.547669</td>
      <td>-0.026389</td>
      <td>-0.739531</td>
      <td>-0.727902</td>
      <td>-0.367958</td>
      <td>0.617635</td>
      <td>-0.199442</td>
      <td>-0.546512</td>
      <td>-0.340810</td>
      <td>0.319080</td>
      <td>0.980577</td>
      <td>-0.672208</td>
      <td>-0.359227</td>
      <td>0.591685</td>
      <td>-0.797093</td>
      <td>-0.359737</td>
      <td>-0.528352</td>
      <td>-0.078851</td>
      <td>-2.088039</td>
      <td>-1.970777</td>
      <td>-0.781163</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.273539</td>
      <td>-0.262757</td>
      <td>-0.217183</td>
      <td>-1.464284</td>
      <td>-0.140617</td>
      <td>-0.404062</td>
      <td>-0.269521</td>
      <td>-0.247322</td>
      <td>0.704457</td>
      <td>1.092849</td>
      <td>0.225553</td>
      <td>0.127975</td>
      <td>-0.641067</td>
      <td>-0.763281</td>
      <td>-0.283139</td>
      <td>1.372074</td>
      <td>0.409998</td>
      <td>0.020332</td>
      <td>-0.102460</td>
      <td>-0.257256</td>
      <td>-0.883402</td>
      <td>-0.317021</td>
      <td>0.157552</td>
      <td>0.974609</td>
      <td>0.433284</td>
      <td>0.562745</td>
      <td>0.184554</td>
      <td>-0.247277</td>
      <td>-0.440231</td>
      <td>-0.034189</td>
      <td>-0.135278</td>
      <td>-0.035252</td>
      <td>0.494563</td>
      <td>0.063144</td>
      <td>0.116355</td>
      <td>1.229087</td>
      <td>1.037146</td>
      <td>0.680194</td>
      <td>-0.482518</td>
      <td>-1.619256</td>
      <td>...</td>
      <td>-0.264480</td>
      <td>-0.500448</td>
      <td>-0.287371</td>
      <td>-0.306443</td>
      <td>-0.183812</td>
      <td>1.025860</td>
      <td>-0.209330</td>
      <td>-0.376538</td>
      <td>-0.813994</td>
      <td>-0.457627</td>
      <td>0.158142</td>
      <td>0.558954</td>
      <td>0.383347</td>
      <td>0.421646</td>
      <td>-0.259215</td>
      <td>0.056302</td>
      <td>0.345777</td>
      <td>0.485896</td>
      <td>0.930583</td>
      <td>0.970917</td>
      <td>-0.523379</td>
      <td>0.079423</td>
      <td>0.400942</td>
      <td>1.046670</td>
      <td>0.587609</td>
      <td>-0.021636</td>
      <td>-0.393004</td>
      <td>-0.015157</td>
      <td>-0.960346</td>
      <td>0.883889</td>
      <td>0.622845</td>
      <td>0.832194</td>
      <td>-0.431931</td>
      <td>-0.031880</td>
      <td>-0.058383</td>
      <td>-0.231443</td>
      <td>0.629724</td>
      <td>-1.274425</td>
      <td>-0.928486</td>
      <td>0.133623</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-0.306353</td>
      <td>-0.107438</td>
      <td>-0.713425</td>
      <td>-0.052542</td>
      <td>-0.497088</td>
      <td>0.411954</td>
      <td>0.106054</td>
      <td>0.142574</td>
      <td>0.297095</td>
      <td>0.686803</td>
      <td>0.267304</td>
      <td>0.314682</td>
      <td>-0.180022</td>
      <td>-0.623517</td>
      <td>-0.264016</td>
      <td>-0.533981</td>
      <td>-0.793589</td>
      <td>-1.141334</td>
      <td>-0.956735</td>
      <td>-0.043237</td>
      <td>-0.745886</td>
      <td>0.111662</td>
      <td>-0.164597</td>
      <td>0.460828</td>
      <td>0.125470</td>
      <td>0.412649</td>
      <td>-0.621602</td>
      <td>-0.184882</td>
      <td>-0.092315</td>
      <td>0.081962</td>
      <td>-0.224990</td>
      <td>0.444226</td>
      <td>0.466083</td>
      <td>0.337485</td>
      <td>0.220161</td>
      <td>-0.993155</td>
      <td>0.309829</td>
      <td>0.293581</td>
      <td>-0.426391</td>
      <td>-0.315262</td>
      <td>...</td>
      <td>0.069324</td>
      <td>0.516737</td>
      <td>-0.022023</td>
      <td>-0.563312</td>
      <td>-0.059461</td>
      <td>0.191665</td>
      <td>-0.986686</td>
      <td>-0.183123</td>
      <td>0.439467</td>
      <td>-0.729989</td>
      <td>1.007354</td>
      <td>0.560317</td>
      <td>-0.558137</td>
      <td>-0.639557</td>
      <td>0.529783</td>
      <td>0.090850</td>
      <td>0.855780</td>
      <td>-0.487352</td>
      <td>-0.164808</td>
      <td>-0.720340</td>
      <td>-0.546989</td>
      <td>0.891796</td>
      <td>0.702996</td>
      <td>-0.560771</td>
      <td>0.768593</td>
      <td>-0.295461</td>
      <td>-0.005767</td>
      <td>-0.393280</td>
      <td>-1.372525</td>
      <td>-0.421702</td>
      <td>0.088274</td>
      <td>0.509443</td>
      <td>0.195414</td>
      <td>-0.686694</td>
      <td>-0.152420</td>
      <td>-0.325649</td>
      <td>-0.693043</td>
      <td>-1.344016</td>
      <td>-1.095710</td>
      <td>-0.543837</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-0.560381</td>
      <td>-0.721305</td>
      <td>0.025654</td>
      <td>-0.550370</td>
      <td>0.178286</td>
      <td>-0.916999</td>
      <td>0.445205</td>
      <td>-0.470905</td>
      <td>0.178914</td>
      <td>0.331369</td>
      <td>-0.018147</td>
      <td>-0.583398</td>
      <td>0.002600</td>
      <td>-0.362139</td>
      <td>-0.815215</td>
      <td>0.140484</td>
      <td>0.503445</td>
      <td>0.073474</td>
      <td>-0.830405</td>
      <td>-1.270496</td>
      <td>-1.954304</td>
      <td>-0.288239</td>
      <td>0.237086</td>
      <td>0.614439</td>
      <td>1.313775</td>
      <td>0.032130</td>
      <td>-1.012104</td>
      <td>-0.774348</td>
      <td>0.050401</td>
      <td>-0.257420</td>
      <td>0.447376</td>
      <td>-0.096192</td>
      <td>-0.077828</td>
      <td>0.276631</td>
      <td>-0.187698</td>
      <td>0.525007</td>
      <td>-0.450159</td>
      <td>0.017300</td>
      <td>-0.334422</td>
      <td>-0.520821</td>
      <td>...</td>
      <td>0.221477</td>
      <td>0.260987</td>
      <td>0.300370</td>
      <td>0.533974</td>
      <td>0.515677</td>
      <td>-0.601522</td>
      <td>0.695464</td>
      <td>0.051253</td>
      <td>0.448651</td>
      <td>0.284662</td>
      <td>0.187251</td>
      <td>0.621632</td>
      <td>0.588451</td>
      <td>-0.803004</td>
      <td>-0.264221</td>
      <td>-0.042704</td>
      <td>-1.152109</td>
      <td>-0.930510</td>
      <td>-0.632633</td>
      <td>-0.218017</td>
      <td>-0.505321</td>
      <td>-0.463588</td>
      <td>-1.011993</td>
      <td>-0.807506</td>
      <td>0.392855</td>
      <td>-0.109630</td>
      <td>-0.434000</td>
      <td>-0.920420</td>
      <td>-0.426939</td>
      <td>-0.615240</td>
      <td>0.397296</td>
      <td>0.759165</td>
      <td>-0.088591</td>
      <td>0.183970</td>
      <td>0.728321</td>
      <td>-0.939494</td>
      <td>-0.251830</td>
      <td>-0.982926</td>
      <td>-0.307340</td>
      <td>0.172713</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.666413</td>
      <td>-1.896039</td>
      <td>0.373279</td>
      <td>1.221536</td>
      <td>0.871536</td>
      <td>-0.408875</td>
      <td>-0.528154</td>
      <td>-0.473336</td>
      <td>0.388280</td>
      <td>-0.317182</td>
      <td>-0.937619</td>
      <td>0.251458</td>
      <td>0.696130</td>
      <td>-1.067897</td>
      <td>-1.136774</td>
      <td>-0.049607</td>
      <td>-0.050459</td>
      <td>0.338212</td>
      <td>0.546789</td>
      <td>0.007375</td>
      <td>-0.865299</td>
      <td>-0.372808</td>
      <td>0.192353</td>
      <td>0.332849</td>
      <td>-0.325798</td>
      <td>-1.274040</td>
      <td>0.437124</td>
      <td>0.239072</td>
      <td>-0.311540</td>
      <td>0.624928</td>
      <td>-0.692923</td>
      <td>0.308649</td>
      <td>1.329031</td>
      <td>0.475643</td>
      <td>-0.074759</td>
      <td>1.111433</td>
      <td>-0.409413</td>
      <td>-0.660279</td>
      <td>0.479485</td>
      <td>0.306185</td>
      <td>...</td>
      <td>0.614509</td>
      <td>1.015257</td>
      <td>0.194752</td>
      <td>0.776767</td>
      <td>-0.569815</td>
      <td>0.300895</td>
      <td>0.272377</td>
      <td>-0.166799</td>
      <td>-0.529217</td>
      <td>-0.388423</td>
      <td>0.921943</td>
      <td>-0.955963</td>
      <td>0.176446</td>
      <td>-1.264463</td>
      <td>0.025384</td>
      <td>-0.273914</td>
      <td>-0.923180</td>
      <td>-0.451672</td>
      <td>-0.196048</td>
      <td>0.231006</td>
      <td>-0.170140</td>
      <td>-1.593866</td>
      <td>0.137524</td>
      <td>0.070732</td>
      <td>1.210074</td>
      <td>0.096274</td>
      <td>0.159939</td>
      <td>-0.534403</td>
      <td>-0.920726</td>
      <td>-0.210124</td>
      <td>0.228213</td>
      <td>-0.497408</td>
      <td>0.325343</td>
      <td>-0.148743</td>
      <td>0.536845</td>
      <td>0.085347</td>
      <td>0.826428</td>
      <td>-2.983125</td>
      <td>-2.252914</td>
      <td>-1.508469</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.107052</td>
      <td>0.450845</td>
      <td>0.226810</td>
      <td>-0.812987</td>
      <td>-0.878937</td>
      <td>0.554502</td>
      <td>0.393184</td>
      <td>0.175778</td>
      <td>1.392862</td>
      <td>0.449827</td>
      <td>0.251104</td>
      <td>0.157210</td>
      <td>0.749300</td>
      <td>0.232398</td>
      <td>-1.027261</td>
      <td>-0.138701</td>
      <td>0.673952</td>
      <td>0.153291</td>
      <td>-1.356094</td>
      <td>-0.698669</td>
      <td>-0.211440</td>
      <td>-0.771502</td>
      <td>-0.832568</td>
      <td>0.431223</td>
      <td>0.647663</td>
      <td>0.633180</td>
      <td>0.351535</td>
      <td>-0.079223</td>
      <td>-0.179485</td>
      <td>0.847167</td>
      <td>-0.783362</td>
      <td>-1.081266</td>
      <td>0.452836</td>
      <td>0.059027</td>
      <td>-0.009908</td>
      <td>0.602856</td>
      <td>-0.014950</td>
      <td>-0.137867</td>
      <td>0.633559</td>
      <td>0.233113</td>
      <td>...</td>
      <td>-0.415720</td>
      <td>-0.587639</td>
      <td>-0.889326</td>
      <td>0.453568</td>
      <td>1.736226</td>
      <td>-0.058757</td>
      <td>0.200260</td>
      <td>0.454248</td>
      <td>0.672831</td>
      <td>0.571584</td>
      <td>1.418282</td>
      <td>0.359158</td>
      <td>0.555506</td>
      <td>0.095503</td>
      <td>0.408347</td>
      <td>0.904894</td>
      <td>0.779211</td>
      <td>-0.868121</td>
      <td>-0.493514</td>
      <td>0.270084</td>
      <td>0.884974</td>
      <td>0.297774</td>
      <td>0.017096</td>
      <td>-0.733582</td>
      <td>-0.293203</td>
      <td>0.395943</td>
      <td>0.634992</td>
      <td>0.497644</td>
      <td>0.002149</td>
      <td>-0.117422</td>
      <td>0.522607</td>
      <td>0.346819</td>
      <td>0.249242</td>
      <td>-0.461166</td>
      <td>0.020306</td>
      <td>-0.044521</td>
      <td>-0.606764</td>
      <td>1.549066</td>
      <td>0.897830</td>
      <td>0.327338</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.409414</td>
      <td>0.091491</td>
      <td>1.364730</td>
      <td>0.509649</td>
      <td>-0.748632</td>
      <td>-0.492136</td>
      <td>-0.737297</td>
      <td>-0.155621</td>
      <td>0.397662</td>
      <td>-1.108261</td>
      <td>-0.125647</td>
      <td>0.821242</td>
      <td>-0.458407</td>
      <td>0.222978</td>
      <td>-1.045082</td>
      <td>-0.362347</td>
      <td>1.553017</td>
      <td>0.018473</td>
      <td>-0.073989</td>
      <td>1.233564</td>
      <td>0.385851</td>
      <td>1.432768</td>
      <td>-0.762056</td>
      <td>0.118768</td>
      <td>0.331456</td>
      <td>-0.145788</td>
      <td>-0.486492</td>
      <td>-0.027739</td>
      <td>-0.459572</td>
      <td>0.704284</td>
      <td>-0.579559</td>
      <td>1.081569</td>
      <td>0.152876</td>
      <td>0.066306</td>
      <td>-0.859399</td>
      <td>-0.053370</td>
      <td>0.539174</td>
      <td>0.021792</td>
      <td>-0.283389</td>
      <td>0.604395</td>
      <td>...</td>
      <td>1.059263</td>
      <td>-0.945611</td>
      <td>-0.204867</td>
      <td>0.246349</td>
      <td>0.271895</td>
      <td>-0.235831</td>
      <td>-0.039465</td>
      <td>-0.483880</td>
      <td>-0.409058</td>
      <td>-0.830967</td>
      <td>-0.010364</td>
      <td>0.494087</td>
      <td>1.564445</td>
      <td>0.053583</td>
      <td>-0.213583</td>
      <td>-0.373208</td>
      <td>-0.869100</td>
      <td>-0.410743</td>
      <td>-0.067690</td>
      <td>0.117641</td>
      <td>-1.289412</td>
      <td>-0.572737</td>
      <td>-1.064299</td>
      <td>-0.172123</td>
      <td>0.035982</td>
      <td>0.637945</td>
      <td>0.650019</td>
      <td>0.302037</td>
      <td>0.062192</td>
      <td>0.149333</td>
      <td>0.863849</td>
      <td>0.896175</td>
      <td>-0.290691</td>
      <td>0.110103</td>
      <td>0.346632</td>
      <td>0.164076</td>
      <td>-0.013064</td>
      <td>1.140160</td>
      <td>1.095826</td>
      <td>1.037830</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.273726</td>
      <td>-0.999570</td>
      <td>-1.156233</td>
      <td>0.098948</td>
      <td>0.231416</td>
      <td>0.733004</td>
      <td>-0.180275</td>
      <td>-0.183880</td>
      <td>0.404012</td>
      <td>-0.857768</td>
      <td>0.333721</td>
      <td>1.239526</td>
      <td>0.116244</td>
      <td>-0.151331</td>
      <td>-0.067206</td>
      <td>0.455397</td>
      <td>1.129435</td>
      <td>0.922760</td>
      <td>0.327478</td>
      <td>0.945440</td>
      <td>-0.036780</td>
      <td>-0.298816</td>
      <td>-0.236080</td>
      <td>0.096459</td>
      <td>-0.121434</td>
      <td>-0.951536</td>
      <td>0.384731</td>
      <td>0.211562</td>
      <td>0.869741</td>
      <td>0.047239</td>
      <td>-1.544641</td>
      <td>0.344962</td>
      <td>0.086315</td>
      <td>0.743853</td>
      <td>-0.138920</td>
      <td>1.045076</td>
      <td>0.724111</td>
      <td>0.797117</td>
      <td>1.349323</td>
      <td>-0.038312</td>
      <td>...</td>
      <td>0.361608</td>
      <td>0.182528</td>
      <td>-0.161166</td>
      <td>0.323307</td>
      <td>0.269073</td>
      <td>0.309514</td>
      <td>0.489376</td>
      <td>0.332725</td>
      <td>0.662076</td>
      <td>-0.830037</td>
      <td>-0.298004</td>
      <td>0.933546</td>
      <td>0.391271</td>
      <td>-0.653782</td>
      <td>0.094829</td>
      <td>0.378101</td>
      <td>0.974236</td>
      <td>-0.643098</td>
      <td>-0.916766</td>
      <td>-0.782415</td>
      <td>-1.028002</td>
      <td>-0.753627</td>
      <td>-1.615724</td>
      <td>-0.666677</td>
      <td>0.170794</td>
      <td>0.242432</td>
      <td>0.396646</td>
      <td>-0.274423</td>
      <td>0.049459</td>
      <td>0.590504</td>
      <td>0.893959</td>
      <td>1.774083</td>
      <td>0.225398</td>
      <td>0.251230</td>
      <td>1.020205</td>
      <td>0.001221</td>
      <td>-0.430573</td>
      <td>-1.596586</td>
      <td>-0.784449</td>
      <td>0.140722</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.552677</td>
      <td>-0.603879</td>
      <td>-0.141463</td>
      <td>0.038840</td>
      <td>0.191033</td>
      <td>-0.567334</td>
      <td>-0.135981</td>
      <td>-0.530704</td>
      <td>0.286777</td>
      <td>-0.136519</td>
      <td>0.065359</td>
      <td>0.062490</td>
      <td>0.270013</td>
      <td>-0.057341</td>
      <td>-0.313573</td>
      <td>-0.684556</td>
      <td>0.903866</td>
      <td>-0.466023</td>
      <td>-0.920523</td>
      <td>-0.162526</td>
      <td>-0.543111</td>
      <td>-0.523018</td>
      <td>-0.270786</td>
      <td>-0.318997</td>
      <td>0.011354</td>
      <td>0.601397</td>
      <td>0.360971</td>
      <td>-0.796474</td>
      <td>-1.059765</td>
      <td>-1.030543</td>
      <td>-0.891661</td>
      <td>0.229662</td>
      <td>0.232076</td>
      <td>1.275352</td>
      <td>1.337819</td>
      <td>0.746335</td>
      <td>0.366590</td>
      <td>0.722360</td>
      <td>0.562144</td>
      <td>-1.133062</td>
      <td>...</td>
      <td>0.842645</td>
      <td>-0.449376</td>
      <td>-0.111958</td>
      <td>-0.756971</td>
      <td>0.095241</td>
      <td>0.223349</td>
      <td>0.406488</td>
      <td>0.040797</td>
      <td>0.822881</td>
      <td>0.371357</td>
      <td>0.126713</td>
      <td>0.283491</td>
      <td>-0.048542</td>
      <td>-0.980773</td>
      <td>0.374830</td>
      <td>0.483918</td>
      <td>0.302268</td>
      <td>-0.058047</td>
      <td>-0.548825</td>
      <td>-0.268065</td>
      <td>-0.353047</td>
      <td>-0.397642</td>
      <td>-0.359183</td>
      <td>-0.601159</td>
      <td>0.852746</td>
      <td>1.272308</td>
      <td>1.025484</td>
      <td>1.155623</td>
      <td>-0.599836</td>
      <td>-0.325585</td>
      <td>-1.320026</td>
      <td>0.228235</td>
      <td>-1.256627</td>
      <td>-0.845197</td>
      <td>-0.719328</td>
      <td>-0.831301</td>
      <td>0.367622</td>
      <td>1.254484</td>
      <td>0.611136</td>
      <td>0.836770</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-1.121022</td>
      <td>-0.468740</td>
      <td>-0.779538</td>
      <td>-0.412814</td>
      <td>0.622410</td>
      <td>-0.203459</td>
      <td>0.380605</td>
      <td>-0.253370</td>
      <td>0.574553</td>
      <td>0.896112</td>
      <td>0.074477</td>
      <td>0.507943</td>
      <td>0.691606</td>
      <td>-0.487770</td>
      <td>-0.899492</td>
      <td>-0.547875</td>
      <td>-0.365749</td>
      <td>-0.796719</td>
      <td>-0.549387</td>
      <td>-0.123731</td>
      <td>-0.314048</td>
      <td>-0.287456</td>
      <td>-0.168997</td>
      <td>0.043143</td>
      <td>1.227331</td>
      <td>-0.438919</td>
      <td>-0.077428</td>
      <td>-1.528328</td>
      <td>0.816393</td>
      <td>0.232705</td>
      <td>-0.560402</td>
      <td>-0.069673</td>
      <td>0.745152</td>
      <td>1.892941</td>
      <td>1.095986</td>
      <td>0.643655</td>
      <td>0.079874</td>
      <td>-0.472215</td>
      <td>0.832585</td>
      <td>0.211711</td>
      <td>...</td>
      <td>0.880390</td>
      <td>-0.413672</td>
      <td>0.574488</td>
      <td>0.544054</td>
      <td>1.174430</td>
      <td>-0.400732</td>
      <td>-0.760112</td>
      <td>-0.050810</td>
      <td>-0.322415</td>
      <td>-0.958454</td>
      <td>1.103519</td>
      <td>0.938174</td>
      <td>1.002879</td>
      <td>-0.897375</td>
      <td>-0.932446</td>
      <td>-0.518501</td>
      <td>0.414330</td>
      <td>0.201260</td>
      <td>-0.183091</td>
      <td>0.131578</td>
      <td>0.055787</td>
      <td>0.110391</td>
      <td>0.084089</td>
      <td>0.137657</td>
      <td>1.886273</td>
      <td>-0.067605</td>
      <td>0.505727</td>
      <td>0.921404</td>
      <td>0.234470</td>
      <td>0.313874</td>
      <td>0.167997</td>
      <td>-0.334265</td>
      <td>-0.862210</td>
      <td>0.154783</td>
      <td>0.414526</td>
      <td>-0.458910</td>
      <td>-0.998378</td>
      <td>-1.458924</td>
      <td>-0.192675</td>
      <td>0.047941</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.010107</td>
      <td>-1.090844</td>
      <td>-1.183365</td>
      <td>-0.673579</td>
      <td>-1.086203</td>
      <td>0.328093</td>
      <td>-0.125946</td>
      <td>0.517822</td>
      <td>0.618024</td>
      <td>-0.135249</td>
      <td>-0.823328</td>
      <td>-0.426831</td>
      <td>-0.704167</td>
      <td>0.584978</td>
      <td>0.302689</td>
      <td>-0.000756</td>
      <td>-0.259011</td>
      <td>-0.482111</td>
      <td>0.367923</td>
      <td>0.317874</td>
      <td>-1.270687</td>
      <td>-0.586202</td>
      <td>0.056297</td>
      <td>0.488048</td>
      <td>0.639620</td>
      <td>0.193731</td>
      <td>0.176411</td>
      <td>-0.697129</td>
      <td>-1.040426</td>
      <td>-0.103729</td>
      <td>-0.643580</td>
      <td>-0.401111</td>
      <td>0.145768</td>
      <td>-0.345242</td>
      <td>0.095413</td>
      <td>1.386270</td>
      <td>0.413156</td>
      <td>0.223914</td>
      <td>0.002670</td>
      <td>-0.503386</td>
      <td>...</td>
      <td>-0.345351</td>
      <td>-0.326119</td>
      <td>0.555728</td>
      <td>-0.052713</td>
      <td>0.329410</td>
      <td>0.685173</td>
      <td>0.395121</td>
      <td>0.341841</td>
      <td>1.219103</td>
      <td>-0.301512</td>
      <td>0.572305</td>
      <td>0.441966</td>
      <td>0.232987</td>
      <td>-0.365685</td>
      <td>-0.769465</td>
      <td>0.205044</td>
      <td>-1.541777</td>
      <td>-0.592833</td>
      <td>1.446530</td>
      <td>-0.938825</td>
      <td>-0.413976</td>
      <td>-0.425106</td>
      <td>-1.262206</td>
      <td>-0.501917</td>
      <td>0.165407</td>
      <td>0.092362</td>
      <td>0.194193</td>
      <td>-0.383707</td>
      <td>-0.548519</td>
      <td>-0.069497</td>
      <td>0.209498</td>
      <td>0.012791</td>
      <td>-0.555361</td>
      <td>-0.178840</td>
      <td>0.079584</td>
      <td>-0.023944</td>
      <td>-1.672624</td>
      <td>0.374310</td>
      <td>-0.263070</td>
      <td>0.203381</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.335395</td>
      <td>-0.406920</td>
      <td>0.117249</td>
      <td>0.145684</td>
      <td>0.619678</td>
      <td>-0.386990</td>
      <td>-0.608005</td>
      <td>-0.234375</td>
      <td>-0.031305</td>
      <td>-0.207930</td>
      <td>-0.270281</td>
      <td>0.659300</td>
      <td>0.276472</td>
      <td>-0.157944</td>
      <td>-0.671885</td>
      <td>0.257514</td>
      <td>0.949138</td>
      <td>0.090480</td>
      <td>0.189887</td>
      <td>0.580908</td>
      <td>0.256559</td>
      <td>-0.226633</td>
      <td>0.325652</td>
      <td>0.522466</td>
      <td>0.623299</td>
      <td>-0.133367</td>
      <td>0.191342</td>
      <td>0.252525</td>
      <td>-0.616406</td>
      <td>-0.074117</td>
      <td>-0.132890</td>
      <td>-0.738558</td>
      <td>-0.179108</td>
      <td>-1.432465</td>
      <td>0.216006</td>
      <td>0.366462</td>
      <td>0.586426</td>
      <td>0.598978</td>
      <td>1.294592</td>
      <td>-0.558283</td>
      <td>...</td>
      <td>0.132600</td>
      <td>0.258342</td>
      <td>0.102321</td>
      <td>-0.763086</td>
      <td>-0.044993</td>
      <td>0.991730</td>
      <td>0.252018</td>
      <td>1.120212</td>
      <td>1.587481</td>
      <td>-0.264838</td>
      <td>0.036175</td>
      <td>0.453699</td>
      <td>-0.050525</td>
      <td>-0.784520</td>
      <td>-0.867020</td>
      <td>-0.187072</td>
      <td>0.088145</td>
      <td>-0.517634</td>
      <td>0.179160</td>
      <td>-0.102739</td>
      <td>0.318793</td>
      <td>0.355637</td>
      <td>-0.472079</td>
      <td>-0.871145</td>
      <td>0.136774</td>
      <td>0.815182</td>
      <td>0.668148</td>
      <td>1.145050</td>
      <td>-0.229610</td>
      <td>-0.345448</td>
      <td>-1.362388</td>
      <td>0.630680</td>
      <td>0.061927</td>
      <td>0.390032</td>
      <td>0.500177</td>
      <td>-0.058167</td>
      <td>-0.124169</td>
      <td>-1.647455</td>
      <td>-0.560713</td>
      <td>-0.335323</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.131535</td>
      <td>-0.926951</td>
      <td>-0.201128</td>
      <td>-0.761458</td>
      <td>0.351666</td>
      <td>0.763836</td>
      <td>-0.203541</td>
      <td>0.154414</td>
      <td>0.521885</td>
      <td>0.289092</td>
      <td>0.199965</td>
      <td>0.969929</td>
      <td>0.195830</td>
      <td>-0.696272</td>
      <td>-0.731834</td>
      <td>-0.142461</td>
      <td>-1.026127</td>
      <td>-0.234180</td>
      <td>-0.599215</td>
      <td>-0.108037</td>
      <td>0.283749</td>
      <td>0.129563</td>
      <td>-0.829130</td>
      <td>0.064318</td>
      <td>0.273687</td>
      <td>-0.442948</td>
      <td>0.213789</td>
      <td>0.931241</td>
      <td>0.733759</td>
      <td>0.582091</td>
      <td>-0.037030</td>
      <td>-0.047668</td>
      <td>0.893348</td>
      <td>0.007607</td>
      <td>0.415078</td>
      <td>-0.238302</td>
      <td>0.146472</td>
      <td>-0.147599</td>
      <td>0.822710</td>
      <td>-0.534601</td>
      <td>...</td>
      <td>0.278847</td>
      <td>0.581700</td>
      <td>0.459871</td>
      <td>-0.186569</td>
      <td>0.052474</td>
      <td>0.334297</td>
      <td>-0.328273</td>
      <td>-0.091317</td>
      <td>-0.669376</td>
      <td>-0.181429</td>
      <td>0.770207</td>
      <td>-0.593509</td>
      <td>-0.607307</td>
      <td>0.587798</td>
      <td>-0.754299</td>
      <td>-1.276784</td>
      <td>-0.134869</td>
      <td>0.584277</td>
      <td>-0.425603</td>
      <td>0.444188</td>
      <td>0.173523</td>
      <td>0.306869</td>
      <td>-0.077158</td>
      <td>0.427128</td>
      <td>0.270654</td>
      <td>-0.338077</td>
      <td>-0.390970</td>
      <td>0.192883</td>
      <td>-0.037554</td>
      <td>-0.186117</td>
      <td>-0.916104</td>
      <td>0.661483</td>
      <td>0.636119</td>
      <td>1.130606</td>
      <td>0.217485</td>
      <td>-0.451373</td>
      <td>-0.756151</td>
      <td>-2.233255</td>
      <td>-1.300823</td>
      <td>-1.224729</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.361264</td>
      <td>-0.269036</td>
      <td>-0.561687</td>
      <td>-0.075438</td>
      <td>0.176424</td>
      <td>-0.436271</td>
      <td>-1.315815</td>
      <td>0.938013</td>
      <td>0.171730</td>
      <td>-0.054142</td>
      <td>0.506747</td>
      <td>-0.726001</td>
      <td>-0.233706</td>
      <td>-1.365252</td>
      <td>-0.631397</td>
      <td>0.541917</td>
      <td>-1.312244</td>
      <td>-1.396439</td>
      <td>-1.241549</td>
      <td>0.883334</td>
      <td>-0.533964</td>
      <td>-0.385646</td>
      <td>0.422367</td>
      <td>0.547493</td>
      <td>-0.044391</td>
      <td>0.334655</td>
      <td>-0.148149</td>
      <td>0.406131</td>
      <td>0.230303</td>
      <td>0.308695</td>
      <td>0.995803</td>
      <td>0.415280</td>
      <td>0.576240</td>
      <td>0.380554</td>
      <td>-0.640088</td>
      <td>-1.213445</td>
      <td>-0.189108</td>
      <td>0.184667</td>
      <td>0.212323</td>
      <td>-0.348393</td>
      <td>...</td>
      <td>-0.541861</td>
      <td>-0.734131</td>
      <td>0.108288</td>
      <td>0.655809</td>
      <td>0.439075</td>
      <td>-0.769293</td>
      <td>-0.318312</td>
      <td>0.858814</td>
      <td>0.220581</td>
      <td>0.179895</td>
      <td>-0.152353</td>
      <td>-0.559790</td>
      <td>-0.453723</td>
      <td>-0.214258</td>
      <td>-0.576194</td>
      <td>-0.000648</td>
      <td>0.443844</td>
      <td>-0.160576</td>
      <td>-0.424859</td>
      <td>0.109027</td>
      <td>0.138084</td>
      <td>0.109157</td>
      <td>-0.362321</td>
      <td>-0.097448</td>
      <td>0.220003</td>
      <td>1.106353</td>
      <td>0.426963</td>
      <td>-0.759120</td>
      <td>-0.817696</td>
      <td>0.432630</td>
      <td>-0.053695</td>
      <td>0.989462</td>
      <td>-0.399313</td>
      <td>0.885721</td>
      <td>1.067722</td>
      <td>0.168889</td>
      <td>0.445710</td>
      <td>0.614857</td>
      <td>-0.610299</td>
      <td>-0.279770</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.368447</td>
      <td>-0.260183</td>
      <td>0.316340</td>
      <td>-0.221931</td>
      <td>0.750446</td>
      <td>-0.516207</td>
      <td>0.616872</td>
      <td>1.156089</td>
      <td>0.376020</td>
      <td>-0.417344</td>
      <td>0.428606</td>
      <td>0.189617</td>
      <td>1.388523</td>
      <td>-0.457454</td>
      <td>-0.387251</td>
      <td>0.600140</td>
      <td>1.503299</td>
      <td>-0.133936</td>
      <td>-0.200498</td>
      <td>0.175087</td>
      <td>1.145190</td>
      <td>-0.470419</td>
      <td>-0.982399</td>
      <td>0.208007</td>
      <td>-0.735657</td>
      <td>0.130019</td>
      <td>0.169241</td>
      <td>-0.129455</td>
      <td>-0.116339</td>
      <td>0.847461</td>
      <td>0.014077</td>
      <td>-0.377548</td>
      <td>0.755096</td>
      <td>0.325351</td>
      <td>-0.076772</td>
      <td>0.223491</td>
      <td>-1.041215</td>
      <td>-0.437999</td>
      <td>0.958613</td>
      <td>0.116206</td>
      <td>...</td>
      <td>0.725963</td>
      <td>1.193987</td>
      <td>0.142612</td>
      <td>1.044617</td>
      <td>0.505744</td>
      <td>-0.320865</td>
      <td>-0.774544</td>
      <td>0.975005</td>
      <td>-0.934932</td>
      <td>-0.770570</td>
      <td>-0.077489</td>
      <td>-0.530502</td>
      <td>-1.333365</td>
      <td>-0.179307</td>
      <td>-1.098522</td>
      <td>-1.105154</td>
      <td>-0.738422</td>
      <td>0.480291</td>
      <td>1.135331</td>
      <td>0.741130</td>
      <td>0.802331</td>
      <td>-0.319945</td>
      <td>-0.644854</td>
      <td>-0.587937</td>
      <td>-0.620477</td>
      <td>0.254553</td>
      <td>0.457122</td>
      <td>0.665769</td>
      <td>-0.164034</td>
      <td>-1.149891</td>
      <td>0.335242</td>
      <td>0.537598</td>
      <td>-0.168054</td>
      <td>-0.098501</td>
      <td>-0.518538</td>
      <td>0.636486</td>
      <td>0.132108</td>
      <td>0.636925</td>
      <td>-0.720664</td>
      <td>-0.725519</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.544319</td>
      <td>-0.357943</td>
      <td>-0.168659</td>
      <td>-0.139771</td>
      <td>1.293999</td>
      <td>1.211051</td>
      <td>-0.513683</td>
      <td>0.042469</td>
      <td>-1.021563</td>
      <td>-1.018980</td>
      <td>0.675157</td>
      <td>-0.679109</td>
      <td>-0.897291</td>
      <td>-0.146504</td>
      <td>-0.194909</td>
      <td>0.208680</td>
      <td>0.582236</td>
      <td>-0.721196</td>
      <td>-0.416031</td>
      <td>-0.353255</td>
      <td>-0.912714</td>
      <td>0.225470</td>
      <td>0.570248</td>
      <td>0.346034</td>
      <td>0.779387</td>
      <td>-0.549785</td>
      <td>0.112010</td>
      <td>0.594278</td>
      <td>0.629629</td>
      <td>0.204352</td>
      <td>0.099829</td>
      <td>-0.344521</td>
      <td>0.699493</td>
      <td>-1.002839</td>
      <td>0.053346</td>
      <td>0.127786</td>
      <td>0.586237</td>
      <td>-0.908748</td>
      <td>0.288710</td>
      <td>-0.642720</td>
      <td>...</td>
      <td>-0.353481</td>
      <td>0.244392</td>
      <td>1.071275</td>
      <td>0.918785</td>
      <td>0.313996</td>
      <td>-0.654367</td>
      <td>-1.011352</td>
      <td>1.388852</td>
      <td>0.800767</td>
      <td>0.181399</td>
      <td>0.129311</td>
      <td>0.402365</td>
      <td>0.020910</td>
      <td>0.577933</td>
      <td>0.667548</td>
      <td>0.212473</td>
      <td>0.836801</td>
      <td>0.816484</td>
      <td>0.584453</td>
      <td>0.674193</td>
      <td>-0.528452</td>
      <td>0.394451</td>
      <td>-0.241145</td>
      <td>-0.565743</td>
      <td>-0.390077</td>
      <td>-0.540760</td>
      <td>-0.549487</td>
      <td>0.877288</td>
      <td>-0.010302</td>
      <td>0.801505</td>
      <td>0.208468</td>
      <td>0.000249</td>
      <td>0.020137</td>
      <td>0.153876</td>
      <td>-0.121352</td>
      <td>0.375274</td>
      <td>-0.695164</td>
      <td>-0.022590</td>
      <td>0.413854</td>
      <td>0.505961</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1.321215</td>
      <td>-1.190625</td>
      <td>-0.517329</td>
      <td>0.063314</td>
      <td>0.026342</td>
      <td>0.515600</td>
      <td>-0.552630</td>
      <td>0.442853</td>
      <td>0.195616</td>
      <td>0.304623</td>
      <td>0.083471</td>
      <td>-0.623009</td>
      <td>-0.568826</td>
      <td>-0.830436</td>
      <td>-0.453687</td>
      <td>0.245931</td>
      <td>0.079744</td>
      <td>-0.830453</td>
      <td>-0.451870</td>
      <td>0.820122</td>
      <td>-1.008743</td>
      <td>-0.225378</td>
      <td>-0.625748</td>
      <td>-0.322383</td>
      <td>-0.443606</td>
      <td>-0.997200</td>
      <td>0.200854</td>
      <td>-0.645424</td>
      <td>-0.483535</td>
      <td>0.384288</td>
      <td>0.392631</td>
      <td>0.421533</td>
      <td>0.206442</td>
      <td>-0.406071</td>
      <td>-0.440872</td>
      <td>0.104499</td>
      <td>-0.178255</td>
      <td>-0.653911</td>
      <td>0.899545</td>
      <td>-1.235014</td>
      <td>...</td>
      <td>-0.471941</td>
      <td>-0.724933</td>
      <td>0.418800</td>
      <td>0.581834</td>
      <td>0.585614</td>
      <td>-0.550830</td>
      <td>-0.098389</td>
      <td>0.960015</td>
      <td>-0.684038</td>
      <td>-0.067018</td>
      <td>0.038483</td>
      <td>-0.683018</td>
      <td>-1.068649</td>
      <td>-1.020038</td>
      <td>0.211170</td>
      <td>-0.077868</td>
      <td>0.041119</td>
      <td>-0.606385</td>
      <td>0.039139</td>
      <td>-0.246051</td>
      <td>-0.156205</td>
      <td>0.364393</td>
      <td>0.182593</td>
      <td>-0.340129</td>
      <td>0.257034</td>
      <td>0.337592</td>
      <td>0.552878</td>
      <td>0.274620</td>
      <td>-0.951382</td>
      <td>0.009818</td>
      <td>0.326961</td>
      <td>0.703185</td>
      <td>0.748133</td>
      <td>1.441884</td>
      <td>0.120466</td>
      <td>-1.179526</td>
      <td>-0.165856</td>
      <td>-0.730030</td>
      <td>-0.342252</td>
      <td>-0.035000</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f1d3dd68100&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.137208  0.043802  25.962457  1.315335e-148  1.051358  1.223059
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  5.296 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d8bbf5861d671d414e1a.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>