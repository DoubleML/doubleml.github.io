
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.0.1 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="http://doubleml.org"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>     to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-0.091975</td>
      <td>-0.097119</td>
      <td>0.513072</td>
      <td>0.803880</td>
      <td>0.302744</td>
      <td>0.894287</td>
      <td>-0.455209</td>
      <td>-0.314350</td>
      <td>-0.369516</td>
      <td>-1.235353</td>
      <td>-1.123204</td>
      <td>-0.185326</td>
      <td>0.147467</td>
      <td>0.404238</td>
      <td>0.478676</td>
      <td>0.836445</td>
      <td>-0.328335</td>
      <td>0.635771</td>
      <td>1.291160</td>
      <td>0.616392</td>
      <td>-0.020567</td>
      <td>0.595236</td>
      <td>0.251585</td>
      <td>0.064052</td>
      <td>0.801872</td>
      <td>-0.226001</td>
      <td>-0.044582</td>
      <td>-1.716015</td>
      <td>0.099326</td>
      <td>0.470340</td>
      <td>0.063205</td>
      <td>-1.240606</td>
      <td>0.464355</td>
      <td>-0.208206</td>
      <td>0.858020</td>
      <td>0.606387</td>
      <td>0.676048</td>
      <td>-1.034037</td>
      <td>-1.111102</td>
      <td>-0.299474</td>
      <td>...</td>
      <td>0.711046</td>
      <td>0.143865</td>
      <td>-0.865027</td>
      <td>-0.069484</td>
      <td>0.450042</td>
      <td>0.318171</td>
      <td>0.131640</td>
      <td>-0.129464</td>
      <td>0.563617</td>
      <td>0.231688</td>
      <td>0.530468</td>
      <td>-0.574682</td>
      <td>0.595256</td>
      <td>0.226861</td>
      <td>-0.450466</td>
      <td>0.283563</td>
      <td>-0.236874</td>
      <td>-0.204872</td>
      <td>-0.340099</td>
      <td>-0.330006</td>
      <td>0.311797</td>
      <td>-0.109362</td>
      <td>-0.984264</td>
      <td>0.387375</td>
      <td>-0.545753</td>
      <td>0.613231</td>
      <td>-0.367096</td>
      <td>-0.043867</td>
      <td>0.910355</td>
      <td>0.054804</td>
      <td>0.891509</td>
      <td>0.742537</td>
      <td>-0.042342</td>
      <td>0.694048</td>
      <td>-0.224366</td>
      <td>-0.308386</td>
      <td>0.228426</td>
      <td>-0.234764</td>
      <td>0.239517</td>
      <td>0.799502</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.295949</td>
      <td>-1.039970</td>
      <td>-0.013498</td>
      <td>-0.265025</td>
      <td>-0.480189</td>
      <td>0.568841</td>
      <td>0.544725</td>
      <td>-0.166663</td>
      <td>-0.753217</td>
      <td>-1.113282</td>
      <td>-0.742875</td>
      <td>-0.743571</td>
      <td>-0.023405</td>
      <td>-0.427899</td>
      <td>-0.245437</td>
      <td>0.279261</td>
      <td>0.147597</td>
      <td>0.222647</td>
      <td>0.526545</td>
      <td>0.621074</td>
      <td>-0.652225</td>
      <td>0.287134</td>
      <td>0.169894</td>
      <td>0.012225</td>
      <td>0.526719</td>
      <td>0.286501</td>
      <td>0.167804</td>
      <td>-0.588301</td>
      <td>-0.153313</td>
      <td>0.597589</td>
      <td>0.219404</td>
      <td>0.369689</td>
      <td>0.133413</td>
      <td>0.443249</td>
      <td>-0.797049</td>
      <td>0.268975</td>
      <td>1.217459</td>
      <td>-1.020754</td>
      <td>-0.037594</td>
      <td>0.881430</td>
      <td>...</td>
      <td>0.687836</td>
      <td>0.255774</td>
      <td>-0.933782</td>
      <td>0.150801</td>
      <td>-0.323630</td>
      <td>-0.560843</td>
      <td>-0.234224</td>
      <td>0.580622</td>
      <td>0.317094</td>
      <td>0.639050</td>
      <td>0.460056</td>
      <td>0.513525</td>
      <td>-0.204526</td>
      <td>-1.115921</td>
      <td>-0.683411</td>
      <td>0.113296</td>
      <td>0.100951</td>
      <td>0.961022</td>
      <td>-0.310174</td>
      <td>-0.245194</td>
      <td>-0.076559</td>
      <td>0.645521</td>
      <td>-0.461619</td>
      <td>-0.521265</td>
      <td>0.300522</td>
      <td>0.171943</td>
      <td>-0.238514</td>
      <td>-0.308710</td>
      <td>-0.697647</td>
      <td>-0.487054</td>
      <td>-1.639730</td>
      <td>0.155326</td>
      <td>0.089877</td>
      <td>0.957190</td>
      <td>0.363935</td>
      <td>-0.638112</td>
      <td>-0.528658</td>
      <td>-0.872239</td>
      <td>0.157347</td>
      <td>0.572610</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.220280</td>
      <td>-0.960254</td>
      <td>-0.176707</td>
      <td>0.112723</td>
      <td>-0.052582</td>
      <td>-1.574654</td>
      <td>1.248015</td>
      <td>-0.329400</td>
      <td>-0.331366</td>
      <td>-0.705900</td>
      <td>-0.318657</td>
      <td>0.461222</td>
      <td>0.076936</td>
      <td>0.272404</td>
      <td>-0.264596</td>
      <td>0.023474</td>
      <td>0.420498</td>
      <td>0.695801</td>
      <td>-0.056729</td>
      <td>0.431334</td>
      <td>-0.849087</td>
      <td>0.008214</td>
      <td>0.788918</td>
      <td>0.201975</td>
      <td>-0.135742</td>
      <td>-0.397775</td>
      <td>-0.752128</td>
      <td>-1.062863</td>
      <td>-0.417955</td>
      <td>0.243891</td>
      <td>0.079310</td>
      <td>0.114168</td>
      <td>0.411653</td>
      <td>-0.392610</td>
      <td>-0.309006</td>
      <td>-1.263895</td>
      <td>-1.381443</td>
      <td>0.160720</td>
      <td>-0.264171</td>
      <td>0.108457</td>
      <td>...</td>
      <td>0.689971</td>
      <td>-0.498293</td>
      <td>-0.726158</td>
      <td>-0.303650</td>
      <td>-0.416966</td>
      <td>0.284485</td>
      <td>-0.148749</td>
      <td>-0.759286</td>
      <td>-0.046269</td>
      <td>0.107254</td>
      <td>0.329362</td>
      <td>0.015632</td>
      <td>-0.454136</td>
      <td>1.015859</td>
      <td>0.320117</td>
      <td>0.558447</td>
      <td>0.108718</td>
      <td>0.739376</td>
      <td>0.316849</td>
      <td>-0.251034</td>
      <td>0.239842</td>
      <td>0.804216</td>
      <td>-0.212093</td>
      <td>0.548338</td>
      <td>-1.103730</td>
      <td>-0.823930</td>
      <td>-0.412320</td>
      <td>0.444670</td>
      <td>-0.583121</td>
      <td>0.095144</td>
      <td>0.178282</td>
      <td>0.640270</td>
      <td>-0.381976</td>
      <td>-0.087181</td>
      <td>0.268573</td>
      <td>-0.305104</td>
      <td>0.394726</td>
      <td>-2.563506</td>
      <td>-2.269942</td>
      <td>-0.715902</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.522423</td>
      <td>-1.051599</td>
      <td>0.548334</td>
      <td>0.052553</td>
      <td>-0.246413</td>
      <td>0.200481</td>
      <td>0.320983</td>
      <td>-0.180368</td>
      <td>-1.940361</td>
      <td>-0.627481</td>
      <td>-0.283507</td>
      <td>-0.557604</td>
      <td>-0.678495</td>
      <td>0.083505</td>
      <td>-0.498282</td>
      <td>0.773548</td>
      <td>-0.951470</td>
      <td>-1.199230</td>
      <td>0.502743</td>
      <td>-0.092292</td>
      <td>-0.419000</td>
      <td>-0.726514</td>
      <td>0.007697</td>
      <td>-0.370605</td>
      <td>-0.518101</td>
      <td>0.627762</td>
      <td>1.143230</td>
      <td>-1.058627</td>
      <td>1.758546</td>
      <td>-0.470914</td>
      <td>-0.165226</td>
      <td>0.052635</td>
      <td>-0.122564</td>
      <td>0.294174</td>
      <td>0.221409</td>
      <td>0.313701</td>
      <td>-0.297016</td>
      <td>-0.614466</td>
      <td>-0.146601</td>
      <td>-0.955014</td>
      <td>...</td>
      <td>0.562542</td>
      <td>0.029377</td>
      <td>0.428999</td>
      <td>-0.340287</td>
      <td>-0.231376</td>
      <td>-0.166269</td>
      <td>-0.086399</td>
      <td>-0.420088</td>
      <td>0.493677</td>
      <td>0.491382</td>
      <td>1.592041</td>
      <td>-0.488059</td>
      <td>0.068451</td>
      <td>-0.133453</td>
      <td>-1.258383</td>
      <td>0.136852</td>
      <td>0.542010</td>
      <td>0.149807</td>
      <td>0.373818</td>
      <td>-0.197623</td>
      <td>-0.615574</td>
      <td>0.188056</td>
      <td>0.066416</td>
      <td>-0.100844</td>
      <td>0.319022</td>
      <td>-0.288754</td>
      <td>-0.522182</td>
      <td>-0.606452</td>
      <td>0.025987</td>
      <td>-0.563044</td>
      <td>0.552387</td>
      <td>0.087102</td>
      <td>0.707533</td>
      <td>1.095320</td>
      <td>0.246149</td>
      <td>-0.722994</td>
      <td>0.266677</td>
      <td>-1.674023</td>
      <td>-1.939538</td>
      <td>-1.313426</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.558788</td>
      <td>-0.225401</td>
      <td>0.855061</td>
      <td>0.214525</td>
      <td>-0.568802</td>
      <td>-1.223213</td>
      <td>-1.153267</td>
      <td>-0.237281</td>
      <td>-0.735361</td>
      <td>-1.070376</td>
      <td>-0.524183</td>
      <td>1.055962</td>
      <td>-0.081664</td>
      <td>-0.438322</td>
      <td>-0.591350</td>
      <td>-0.137662</td>
      <td>-0.493504</td>
      <td>-0.194254</td>
      <td>-0.027273</td>
      <td>-0.166193</td>
      <td>0.921870</td>
      <td>0.531493</td>
      <td>0.637683</td>
      <td>-1.497604</td>
      <td>0.232398</td>
      <td>-0.680822</td>
      <td>0.250163</td>
      <td>-0.893341</td>
      <td>0.113440</td>
      <td>0.365510</td>
      <td>-0.199984</td>
      <td>-0.374044</td>
      <td>-0.649644</td>
      <td>0.056805</td>
      <td>0.163765</td>
      <td>-0.640078</td>
      <td>1.025966</td>
      <td>-0.529709</td>
      <td>-0.948716</td>
      <td>0.051541</td>
      <td>...</td>
      <td>0.355983</td>
      <td>0.410231</td>
      <td>0.130116</td>
      <td>0.671200</td>
      <td>-0.586977</td>
      <td>-0.300632</td>
      <td>-0.933841</td>
      <td>0.353113</td>
      <td>-0.169500</td>
      <td>0.332807</td>
      <td>0.362938</td>
      <td>0.092933</td>
      <td>0.262453</td>
      <td>-0.350965</td>
      <td>-0.532653</td>
      <td>1.316631</td>
      <td>-0.287665</td>
      <td>0.337308</td>
      <td>0.304861</td>
      <td>0.614884</td>
      <td>0.279884</td>
      <td>0.532979</td>
      <td>0.767977</td>
      <td>-0.585629</td>
      <td>-1.052074</td>
      <td>0.279449</td>
      <td>-0.064756</td>
      <td>0.499311</td>
      <td>0.350566</td>
      <td>0.062471</td>
      <td>1.314616</td>
      <td>0.877998</td>
      <td>-0.449281</td>
      <td>0.471419</td>
      <td>1.435036</td>
      <td>0.389561</td>
      <td>0.311564</td>
      <td>0.263170</td>
      <td>0.797046</td>
      <td>0.784831</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.474329</td>
      <td>1.636221</td>
      <td>0.894672</td>
      <td>0.593405</td>
      <td>-0.394951</td>
      <td>-0.934932</td>
      <td>-1.636094</td>
      <td>-0.763849</td>
      <td>-0.620912</td>
      <td>-0.594078</td>
      <td>-0.513282</td>
      <td>0.784816</td>
      <td>0.411093</td>
      <td>-0.128096</td>
      <td>-0.626755</td>
      <td>0.292133</td>
      <td>0.368693</td>
      <td>0.605200</td>
      <td>0.190120</td>
      <td>0.272553</td>
      <td>0.002392</td>
      <td>1.024848</td>
      <td>1.233387</td>
      <td>-0.548934</td>
      <td>0.629145</td>
      <td>0.685390</td>
      <td>0.190814</td>
      <td>-0.591709</td>
      <td>0.379024</td>
      <td>1.317004</td>
      <td>0.517304</td>
      <td>-0.630107</td>
      <td>-0.857089</td>
      <td>0.372740</td>
      <td>0.095957</td>
      <td>0.217768</td>
      <td>-0.050795</td>
      <td>0.189455</td>
      <td>-0.090778</td>
      <td>-0.984034</td>
      <td>...</td>
      <td>0.465150</td>
      <td>0.388786</td>
      <td>0.422784</td>
      <td>0.485072</td>
      <td>-0.352014</td>
      <td>0.095475</td>
      <td>-0.292156</td>
      <td>0.937146</td>
      <td>0.054130</td>
      <td>1.109833</td>
      <td>0.516948</td>
      <td>0.328704</td>
      <td>0.545046</td>
      <td>0.727573</td>
      <td>-0.800873</td>
      <td>-0.061133</td>
      <td>0.134271</td>
      <td>0.839211</td>
      <td>-0.725828</td>
      <td>-0.136304</td>
      <td>-0.877851</td>
      <td>-0.388026</td>
      <td>0.930438</td>
      <td>0.290021</td>
      <td>0.736500</td>
      <td>0.886660</td>
      <td>1.023600</td>
      <td>1.111935</td>
      <td>0.445841</td>
      <td>0.789265</td>
      <td>1.293333</td>
      <td>1.601959</td>
      <td>0.607847</td>
      <td>0.781350</td>
      <td>0.497588</td>
      <td>-0.534906</td>
      <td>-0.495256</td>
      <td>4.232929</td>
      <td>2.293285</td>
      <td>1.009306</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.095926</td>
      <td>-0.836922</td>
      <td>-0.637446</td>
      <td>0.411392</td>
      <td>-0.149834</td>
      <td>-0.927298</td>
      <td>-0.355180</td>
      <td>-0.831352</td>
      <td>-0.207119</td>
      <td>-0.084717</td>
      <td>-0.963372</td>
      <td>-0.104398</td>
      <td>-0.688552</td>
      <td>-0.512638</td>
      <td>0.699482</td>
      <td>0.535382</td>
      <td>0.273587</td>
      <td>-0.175488</td>
      <td>-1.067484</td>
      <td>0.002778</td>
      <td>0.586833</td>
      <td>0.173888</td>
      <td>1.090102</td>
      <td>-0.251610</td>
      <td>0.518981</td>
      <td>0.155416</td>
      <td>-0.021782</td>
      <td>0.268581</td>
      <td>0.598762</td>
      <td>0.315384</td>
      <td>-0.837646</td>
      <td>-0.440977</td>
      <td>0.433269</td>
      <td>0.256809</td>
      <td>-0.437786</td>
      <td>-1.221623</td>
      <td>-0.770456</td>
      <td>-0.870803</td>
      <td>-0.147565</td>
      <td>-0.476835</td>
      <td>...</td>
      <td>1.511512</td>
      <td>1.232048</td>
      <td>-0.332882</td>
      <td>0.326274</td>
      <td>-0.194887</td>
      <td>-0.286753</td>
      <td>-0.376687</td>
      <td>-0.423750</td>
      <td>-0.341548</td>
      <td>-0.846768</td>
      <td>-0.660140</td>
      <td>0.619793</td>
      <td>0.248914</td>
      <td>0.361720</td>
      <td>-0.206667</td>
      <td>0.901985</td>
      <td>-0.647049</td>
      <td>-0.320904</td>
      <td>-0.822677</td>
      <td>-0.771471</td>
      <td>-0.608759</td>
      <td>-0.507914</td>
      <td>1.145370</td>
      <td>-0.076318</td>
      <td>0.734456</td>
      <td>0.342494</td>
      <td>0.394775</td>
      <td>-0.016010</td>
      <td>0.389593</td>
      <td>0.510939</td>
      <td>-0.309262</td>
      <td>0.144589</td>
      <td>-0.860306</td>
      <td>1.823111</td>
      <td>0.820896</td>
      <td>-0.569406</td>
      <td>-0.574679</td>
      <td>0.850173</td>
      <td>-0.348959</td>
      <td>-0.730155</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.584922</td>
      <td>-0.123228</td>
      <td>-0.156711</td>
      <td>1.094939</td>
      <td>0.355531</td>
      <td>-0.037409</td>
      <td>-0.872988</td>
      <td>-1.268249</td>
      <td>-1.344957</td>
      <td>-0.216732</td>
      <td>-0.759553</td>
      <td>-0.075106</td>
      <td>-1.115193</td>
      <td>-1.114377</td>
      <td>-0.126457</td>
      <td>1.001049</td>
      <td>-0.187480</td>
      <td>0.544231</td>
      <td>-0.416865</td>
      <td>-0.220436</td>
      <td>-0.753700</td>
      <td>-0.262852</td>
      <td>0.101268</td>
      <td>0.231132</td>
      <td>0.869947</td>
      <td>-0.430012</td>
      <td>0.293460</td>
      <td>-0.577724</td>
      <td>0.767904</td>
      <td>0.667001</td>
      <td>-0.073012</td>
      <td>-0.649233</td>
      <td>-0.689074</td>
      <td>-0.735709</td>
      <td>-0.574242</td>
      <td>0.132295</td>
      <td>0.934226</td>
      <td>0.184195</td>
      <td>0.847239</td>
      <td>0.840353</td>
      <td>...</td>
      <td>1.115827</td>
      <td>-0.256986</td>
      <td>0.084063</td>
      <td>0.443485</td>
      <td>-0.122471</td>
      <td>-0.547177</td>
      <td>-0.445957</td>
      <td>0.117324</td>
      <td>0.748311</td>
      <td>0.589471</td>
      <td>0.234055</td>
      <td>0.056696</td>
      <td>0.236352</td>
      <td>0.798188</td>
      <td>0.391088</td>
      <td>0.441639</td>
      <td>-0.060947</td>
      <td>0.349512</td>
      <td>-0.799368</td>
      <td>-0.383542</td>
      <td>-0.960763</td>
      <td>-0.336051</td>
      <td>0.151829</td>
      <td>-0.675677</td>
      <td>-0.171706</td>
      <td>-0.076000</td>
      <td>0.488690</td>
      <td>0.184908</td>
      <td>0.753843</td>
      <td>1.019087</td>
      <td>0.546177</td>
      <td>0.225381</td>
      <td>0.344342</td>
      <td>0.965116</td>
      <td>0.937883</td>
      <td>0.102587</td>
      <td>0.046439</td>
      <td>-1.005545</td>
      <td>-0.215698</td>
      <td>1.214106</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.229316</td>
      <td>1.021000</td>
      <td>0.647498</td>
      <td>0.279610</td>
      <td>1.250379</td>
      <td>-0.441477</td>
      <td>-0.937579</td>
      <td>-0.276817</td>
      <td>1.171891</td>
      <td>-0.244297</td>
      <td>-0.790455</td>
      <td>0.768152</td>
      <td>-0.464843</td>
      <td>-0.795523</td>
      <td>-0.087057</td>
      <td>0.505157</td>
      <td>-0.012765</td>
      <td>1.325115</td>
      <td>-0.010554</td>
      <td>0.264945</td>
      <td>1.350241</td>
      <td>0.482438</td>
      <td>-0.385766</td>
      <td>0.122666</td>
      <td>-0.812858</td>
      <td>-0.995725</td>
      <td>0.367546</td>
      <td>0.338571</td>
      <td>-0.113455</td>
      <td>0.581840</td>
      <td>1.527030</td>
      <td>1.337147</td>
      <td>0.421893</td>
      <td>0.306969</td>
      <td>-0.345991</td>
      <td>-0.119309</td>
      <td>0.737845</td>
      <td>-1.266212</td>
      <td>-0.589284</td>
      <td>0.050261</td>
      <td>...</td>
      <td>0.567712</td>
      <td>0.432643</td>
      <td>-0.355175</td>
      <td>-0.739064</td>
      <td>0.032604</td>
      <td>0.133073</td>
      <td>-0.107183</td>
      <td>0.315844</td>
      <td>-0.221108</td>
      <td>0.135027</td>
      <td>0.757118</td>
      <td>0.610553</td>
      <td>0.194657</td>
      <td>0.339041</td>
      <td>0.382379</td>
      <td>0.244862</td>
      <td>0.719428</td>
      <td>0.341914</td>
      <td>-0.677575</td>
      <td>-0.165634</td>
      <td>-0.141667</td>
      <td>-0.293827</td>
      <td>1.116898</td>
      <td>0.717646</td>
      <td>0.947006</td>
      <td>0.755320</td>
      <td>1.517184</td>
      <td>2.120273</td>
      <td>1.159353</td>
      <td>0.494413</td>
      <td>0.352811</td>
      <td>0.928371</td>
      <td>0.449423</td>
      <td>0.109244</td>
      <td>0.283770</td>
      <td>-0.500384</td>
      <td>0.065164</td>
      <td>1.404472</td>
      <td>0.501558</td>
      <td>0.691573</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.087404</td>
      <td>0.059382</td>
      <td>1.037537</td>
      <td>-0.189918</td>
      <td>-0.332582</td>
      <td>-0.781316</td>
      <td>-0.864872</td>
      <td>0.015703</td>
      <td>0.098723</td>
      <td>-1.068920</td>
      <td>-0.593992</td>
      <td>-0.236228</td>
      <td>-0.305711</td>
      <td>-0.640108</td>
      <td>0.087147</td>
      <td>-0.228375</td>
      <td>-0.887190</td>
      <td>0.014635</td>
      <td>-0.177530</td>
      <td>0.219154</td>
      <td>-0.414994</td>
      <td>0.473239</td>
      <td>0.377163</td>
      <td>-0.308015</td>
      <td>1.500850</td>
      <td>-0.414646</td>
      <td>-0.130914</td>
      <td>-1.507433</td>
      <td>-0.152446</td>
      <td>0.178964</td>
      <td>0.218176</td>
      <td>-0.158153</td>
      <td>0.228375</td>
      <td>0.955316</td>
      <td>0.549255</td>
      <td>-0.352785</td>
      <td>-0.201718</td>
      <td>-0.913482</td>
      <td>-1.280005</td>
      <td>-0.729033</td>
      <td>...</td>
      <td>0.251338</td>
      <td>0.624949</td>
      <td>-0.543229</td>
      <td>0.579322</td>
      <td>-0.084840</td>
      <td>0.094496</td>
      <td>0.020134</td>
      <td>0.166151</td>
      <td>0.139851</td>
      <td>0.574326</td>
      <td>-0.002755</td>
      <td>-0.769394</td>
      <td>-0.481501</td>
      <td>0.053815</td>
      <td>-0.238561</td>
      <td>0.312842</td>
      <td>0.420322</td>
      <td>-0.051940</td>
      <td>-0.250931</td>
      <td>1.232247</td>
      <td>0.738881</td>
      <td>0.604761</td>
      <td>0.344976</td>
      <td>-1.204832</td>
      <td>0.163965</td>
      <td>0.933252</td>
      <td>-0.716331</td>
      <td>0.778572</td>
      <td>1.213380</td>
      <td>0.271423</td>
      <td>0.021850</td>
      <td>1.293528</td>
      <td>0.309386</td>
      <td>0.916063</td>
      <td>1.048620</td>
      <td>-0.294269</td>
      <td>-0.645430</td>
      <td>1.633897</td>
      <td>0.992636</td>
      <td>0.330531</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-0.801090</td>
      <td>-0.516411</td>
      <td>0.870103</td>
      <td>0.605303</td>
      <td>0.773899</td>
      <td>-0.402819</td>
      <td>-0.013561</td>
      <td>-0.059784</td>
      <td>-0.211258</td>
      <td>-0.339469</td>
      <td>-0.892225</td>
      <td>-0.322262</td>
      <td>0.582883</td>
      <td>-1.182741</td>
      <td>0.142847</td>
      <td>-0.391302</td>
      <td>0.397189</td>
      <td>1.389247</td>
      <td>0.989535</td>
      <td>1.371080</td>
      <td>0.817591</td>
      <td>0.887047</td>
      <td>0.409868</td>
      <td>0.339641</td>
      <td>0.111352</td>
      <td>0.416401</td>
      <td>-0.311636</td>
      <td>-0.803583</td>
      <td>0.571168</td>
      <td>0.164956</td>
      <td>0.000362</td>
      <td>-1.133020</td>
      <td>0.010434</td>
      <td>0.518960</td>
      <td>-0.162071</td>
      <td>-0.441202</td>
      <td>0.655220</td>
      <td>-0.202872</td>
      <td>-1.483435</td>
      <td>-0.682274</td>
      <td>...</td>
      <td>-0.409409</td>
      <td>-0.296953</td>
      <td>0.667505</td>
      <td>0.231376</td>
      <td>-0.025791</td>
      <td>-0.017373</td>
      <td>-0.135360</td>
      <td>-0.009094</td>
      <td>-0.512257</td>
      <td>1.116904</td>
      <td>0.897568</td>
      <td>0.063826</td>
      <td>-0.049116</td>
      <td>-0.061600</td>
      <td>-0.708239</td>
      <td>-0.680157</td>
      <td>-0.075136</td>
      <td>-0.916231</td>
      <td>-0.051128</td>
      <td>-1.099762</td>
      <td>-0.207892</td>
      <td>-0.717383</td>
      <td>-0.742282</td>
      <td>-0.434320</td>
      <td>-0.828425</td>
      <td>0.116393</td>
      <td>-0.371937</td>
      <td>-0.175318</td>
      <td>-0.129408</td>
      <td>0.821910</td>
      <td>0.719953</td>
      <td>1.146301</td>
      <td>0.758778</td>
      <td>1.324023</td>
      <td>-0.098971</td>
      <td>-0.108455</td>
      <td>0.414650</td>
      <td>1.035042</td>
      <td>0.003033</td>
      <td>-0.360606</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.590788</td>
      <td>1.015303</td>
      <td>0.726596</td>
      <td>0.097886</td>
      <td>-0.993556</td>
      <td>-1.747888</td>
      <td>-0.893469</td>
      <td>-1.467198</td>
      <td>-0.713913</td>
      <td>0.243954</td>
      <td>0.656376</td>
      <td>0.682683</td>
      <td>0.150664</td>
      <td>-0.774073</td>
      <td>0.152582</td>
      <td>0.499054</td>
      <td>-0.319224</td>
      <td>0.612988</td>
      <td>-0.089145</td>
      <td>0.564370</td>
      <td>0.355128</td>
      <td>0.084176</td>
      <td>0.542632</td>
      <td>0.350967</td>
      <td>0.560039</td>
      <td>-0.321335</td>
      <td>0.382458</td>
      <td>-0.560224</td>
      <td>-0.166356</td>
      <td>-0.190136</td>
      <td>0.425030</td>
      <td>0.732281</td>
      <td>-0.021247</td>
      <td>0.422881</td>
      <td>0.341565</td>
      <td>0.497414</td>
      <td>1.041731</td>
      <td>-0.167833</td>
      <td>-0.154975</td>
      <td>-0.110100</td>
      <td>...</td>
      <td>0.402514</td>
      <td>-0.239644</td>
      <td>0.365310</td>
      <td>0.333331</td>
      <td>-0.421228</td>
      <td>-0.652461</td>
      <td>-0.079588</td>
      <td>-0.734525</td>
      <td>0.684898</td>
      <td>0.837682</td>
      <td>-0.075987</td>
      <td>0.428891</td>
      <td>0.119155</td>
      <td>0.283567</td>
      <td>-0.003411</td>
      <td>0.181799</td>
      <td>0.582229</td>
      <td>1.070662</td>
      <td>-0.196182</td>
      <td>0.151065</td>
      <td>-0.345417</td>
      <td>1.396664</td>
      <td>0.324977</td>
      <td>-0.561675</td>
      <td>0.119369</td>
      <td>-0.123264</td>
      <td>-0.076043</td>
      <td>0.428040</td>
      <td>0.231334</td>
      <td>0.775945</td>
      <td>0.597922</td>
      <td>1.051772</td>
      <td>0.502881</td>
      <td>0.362429</td>
      <td>-0.163936</td>
      <td>-0.238861</td>
      <td>-0.155800</td>
      <td>0.883570</td>
      <td>1.072833</td>
      <td>0.899167</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-0.062050</td>
      <td>0.830104</td>
      <td>-0.024300</td>
      <td>0.638783</td>
      <td>0.246399</td>
      <td>-0.806865</td>
      <td>-0.048066</td>
      <td>-0.570424</td>
      <td>-0.909070</td>
      <td>0.007863</td>
      <td>-0.461607</td>
      <td>0.586909</td>
      <td>-1.296583</td>
      <td>-0.237672</td>
      <td>0.913060</td>
      <td>0.501517</td>
      <td>0.327123</td>
      <td>1.248548</td>
      <td>0.534172</td>
      <td>0.376771</td>
      <td>0.148681</td>
      <td>0.867542</td>
      <td>0.718673</td>
      <td>-0.216686</td>
      <td>-0.440221</td>
      <td>-1.169615</td>
      <td>0.075710</td>
      <td>-0.650921</td>
      <td>-0.428246</td>
      <td>-0.549522</td>
      <td>0.262239</td>
      <td>0.538886</td>
      <td>1.078998</td>
      <td>0.925327</td>
      <td>0.105764</td>
      <td>0.852733</td>
      <td>1.130900</td>
      <td>-0.277738</td>
      <td>0.428178</td>
      <td>0.342686</td>
      <td>...</td>
      <td>1.185172</td>
      <td>0.585067</td>
      <td>-0.469515</td>
      <td>0.666569</td>
      <td>-0.823025</td>
      <td>-0.541721</td>
      <td>0.012875</td>
      <td>-0.131897</td>
      <td>-0.024663</td>
      <td>0.554158</td>
      <td>0.524128</td>
      <td>0.132477</td>
      <td>-0.706937</td>
      <td>-0.008899</td>
      <td>-0.424811</td>
      <td>0.135181</td>
      <td>-0.145298</td>
      <td>-0.006360</td>
      <td>-0.330006</td>
      <td>-0.028153</td>
      <td>-0.115006</td>
      <td>-0.140193</td>
      <td>0.076097</td>
      <td>0.754114</td>
      <td>-0.047483</td>
      <td>-0.213621</td>
      <td>-0.113919</td>
      <td>0.260722</td>
      <td>-0.033138</td>
      <td>1.280325</td>
      <td>-0.492939</td>
      <td>0.558440</td>
      <td>1.166578</td>
      <td>0.121757</td>
      <td>-1.050887</td>
      <td>-1.184350</td>
      <td>-0.363139</td>
      <td>1.398130</td>
      <td>0.673729</td>
      <td>-0.247221</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.546574</td>
      <td>0.034380</td>
      <td>1.014738</td>
      <td>1.271101</td>
      <td>0.368769</td>
      <td>-0.250681</td>
      <td>-0.177063</td>
      <td>-0.383217</td>
      <td>-1.678525</td>
      <td>-0.785015</td>
      <td>-0.171228</td>
      <td>0.171126</td>
      <td>0.047042</td>
      <td>-0.262435</td>
      <td>-0.248842</td>
      <td>-0.872722</td>
      <td>0.027366</td>
      <td>-0.108914</td>
      <td>0.491421</td>
      <td>0.691093</td>
      <td>0.041434</td>
      <td>-0.455862</td>
      <td>-0.281435</td>
      <td>-0.195765</td>
      <td>0.327521</td>
      <td>1.063232</td>
      <td>0.572138</td>
      <td>-0.005239</td>
      <td>0.566551</td>
      <td>-0.074336</td>
      <td>1.107257</td>
      <td>0.523263</td>
      <td>0.061163</td>
      <td>-0.829617</td>
      <td>0.198761</td>
      <td>0.322989</td>
      <td>0.011958</td>
      <td>-1.087075</td>
      <td>-0.343267</td>
      <td>0.104010</td>
      <td>...</td>
      <td>-0.421178</td>
      <td>0.643741</td>
      <td>0.102483</td>
      <td>-0.079604</td>
      <td>0.128749</td>
      <td>-0.189459</td>
      <td>-0.895966</td>
      <td>0.762935</td>
      <td>0.016121</td>
      <td>0.252494</td>
      <td>1.683255</td>
      <td>-0.232696</td>
      <td>1.240521</td>
      <td>1.091668</td>
      <td>-0.397503</td>
      <td>0.088942</td>
      <td>0.459319</td>
      <td>0.371739</td>
      <td>0.381372</td>
      <td>0.038873</td>
      <td>-0.121091</td>
      <td>0.002295</td>
      <td>1.085351</td>
      <td>0.297821</td>
      <td>0.296767</td>
      <td>-0.325631</td>
      <td>0.665090</td>
      <td>1.085619</td>
      <td>0.041604</td>
      <td>0.143709</td>
      <td>0.222455</td>
      <td>0.358909</td>
      <td>-0.535635</td>
      <td>0.270762</td>
      <td>-0.060626</td>
      <td>0.398714</td>
      <td>-0.223548</td>
      <td>1.080722</td>
      <td>0.099573</td>
      <td>0.052997</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.194342</td>
      <td>0.012214</td>
      <td>0.180681</td>
      <td>0.126011</td>
      <td>-0.019735</td>
      <td>0.187428</td>
      <td>0.000407</td>
      <td>0.587504</td>
      <td>-0.425644</td>
      <td>-1.076476</td>
      <td>0.288492</td>
      <td>1.366251</td>
      <td>0.253623</td>
      <td>-0.635879</td>
      <td>-0.829046</td>
      <td>-0.264416</td>
      <td>0.576027</td>
      <td>0.063358</td>
      <td>0.606623</td>
      <td>0.299086</td>
      <td>1.092628</td>
      <td>1.188311</td>
      <td>0.492480</td>
      <td>-0.662643</td>
      <td>-0.224204</td>
      <td>0.194717</td>
      <td>0.509495</td>
      <td>0.043307</td>
      <td>0.763857</td>
      <td>-0.979082</td>
      <td>-0.018283</td>
      <td>-0.335562</td>
      <td>0.452359</td>
      <td>0.125008</td>
      <td>-0.796668</td>
      <td>-0.168094</td>
      <td>0.251901</td>
      <td>-1.446264</td>
      <td>-0.452356</td>
      <td>-0.227158</td>
      <td>...</td>
      <td>0.618827</td>
      <td>0.540052</td>
      <td>0.244040</td>
      <td>-0.320810</td>
      <td>0.356540</td>
      <td>0.068902</td>
      <td>-1.324190</td>
      <td>-0.226299</td>
      <td>0.167317</td>
      <td>0.054454</td>
      <td>1.021122</td>
      <td>0.320828</td>
      <td>-0.362340</td>
      <td>0.564491</td>
      <td>0.667777</td>
      <td>-0.244123</td>
      <td>0.333048</td>
      <td>0.654584</td>
      <td>-0.583610</td>
      <td>-0.506389</td>
      <td>-1.201216</td>
      <td>-0.173507</td>
      <td>0.097283</td>
      <td>0.461870</td>
      <td>-0.395505</td>
      <td>-0.318024</td>
      <td>0.445961</td>
      <td>0.367990</td>
      <td>0.517443</td>
      <td>0.622505</td>
      <td>0.147232</td>
      <td>0.399988</td>
      <td>0.814551</td>
      <td>0.956721</td>
      <td>1.208087</td>
      <td>0.544011</td>
      <td>-0.529184</td>
      <td>0.642587</td>
      <td>-0.501430</td>
      <td>-0.519987</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-0.770093</td>
      <td>-0.413920</td>
      <td>0.371099</td>
      <td>-0.235110</td>
      <td>-0.240106</td>
      <td>0.267271</td>
      <td>-0.540611</td>
      <td>0.247106</td>
      <td>-1.126427</td>
      <td>-0.657732</td>
      <td>-0.603723</td>
      <td>-0.197649</td>
      <td>-0.032544</td>
      <td>-1.103311</td>
      <td>-0.536269</td>
      <td>0.851760</td>
      <td>-0.627090</td>
      <td>-0.241650</td>
      <td>0.326158</td>
      <td>0.947071</td>
      <td>-0.229419</td>
      <td>1.344200</td>
      <td>0.292547</td>
      <td>0.155574</td>
      <td>-0.059619</td>
      <td>-0.039007</td>
      <td>0.747777</td>
      <td>-0.474411</td>
      <td>0.524285</td>
      <td>-0.130358</td>
      <td>-0.299644</td>
      <td>-0.750423</td>
      <td>-0.960795</td>
      <td>-0.227421</td>
      <td>-0.843457</td>
      <td>-0.244555</td>
      <td>-0.535100</td>
      <td>-0.826766</td>
      <td>-1.289572</td>
      <td>-0.628464</td>
      <td>...</td>
      <td>0.238317</td>
      <td>-0.435400</td>
      <td>-1.011718</td>
      <td>-0.553180</td>
      <td>-0.292041</td>
      <td>-0.050627</td>
      <td>0.645959</td>
      <td>0.179861</td>
      <td>0.398990</td>
      <td>-0.092361</td>
      <td>-0.263550</td>
      <td>0.207407</td>
      <td>0.438470</td>
      <td>0.447671</td>
      <td>0.113906</td>
      <td>0.120809</td>
      <td>-0.204044</td>
      <td>-0.699381</td>
      <td>0.099346</td>
      <td>0.170666</td>
      <td>0.627763</td>
      <td>1.134189</td>
      <td>-0.141375</td>
      <td>-0.926416</td>
      <td>0.065201</td>
      <td>-0.098110</td>
      <td>-0.331362</td>
      <td>0.418343</td>
      <td>-0.386878</td>
      <td>0.498693</td>
      <td>-0.476814</td>
      <td>0.451121</td>
      <td>0.264707</td>
      <td>0.329682</td>
      <td>0.060525</td>
      <td>-1.360763</td>
      <td>0.572469</td>
      <td>-1.487638</td>
      <td>-1.642426</td>
      <td>-1.176625</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.334856</td>
      <td>0.167428</td>
      <td>-0.562002</td>
      <td>0.424351</td>
      <td>-0.272398</td>
      <td>-0.087641</td>
      <td>-0.629425</td>
      <td>0.737222</td>
      <td>0.414377</td>
      <td>-0.278732</td>
      <td>-1.870619</td>
      <td>-1.161348</td>
      <td>-1.001648</td>
      <td>-1.484142</td>
      <td>0.192768</td>
      <td>1.168832</td>
      <td>1.286810</td>
      <td>1.530153</td>
      <td>0.437525</td>
      <td>0.254252</td>
      <td>-0.049946</td>
      <td>0.430423</td>
      <td>-0.647450</td>
      <td>-0.266465</td>
      <td>0.969994</td>
      <td>0.010617</td>
      <td>0.026948</td>
      <td>-0.322056</td>
      <td>-0.085437</td>
      <td>-0.645219</td>
      <td>-0.406373</td>
      <td>-0.666669</td>
      <td>-0.929937</td>
      <td>0.089965</td>
      <td>0.316174</td>
      <td>-0.474494</td>
      <td>0.304055</td>
      <td>-0.041266</td>
      <td>-0.356765</td>
      <td>-0.349929</td>
      <td>...</td>
      <td>1.519817</td>
      <td>-0.245603</td>
      <td>-0.223691</td>
      <td>0.604270</td>
      <td>-0.067122</td>
      <td>-0.361209</td>
      <td>-0.622109</td>
      <td>0.068620</td>
      <td>-0.140355</td>
      <td>0.648608</td>
      <td>0.900080</td>
      <td>0.260553</td>
      <td>-0.447144</td>
      <td>0.030109</td>
      <td>-0.561262</td>
      <td>-0.184422</td>
      <td>0.362043</td>
      <td>-0.023381</td>
      <td>-0.105639</td>
      <td>-0.382024</td>
      <td>-0.735442</td>
      <td>0.217548</td>
      <td>-0.080211</td>
      <td>-0.519311</td>
      <td>-0.241509</td>
      <td>-0.049248</td>
      <td>-0.236398</td>
      <td>-0.492125</td>
      <td>1.316256</td>
      <td>0.759272</td>
      <td>0.816957</td>
      <td>0.746574</td>
      <td>0.003756</td>
      <td>0.498266</td>
      <td>0.349560</td>
      <td>-0.231311</td>
      <td>-0.896598</td>
      <td>0.548246</td>
      <td>-0.006357</td>
      <td>0.064123</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.592483</td>
      <td>-0.583022</td>
      <td>-0.909603</td>
      <td>-0.418528</td>
      <td>-0.351919</td>
      <td>-0.670982</td>
      <td>-0.470212</td>
      <td>-0.503498</td>
      <td>-0.731538</td>
      <td>-1.129172</td>
      <td>-0.537992</td>
      <td>1.037476</td>
      <td>0.034029</td>
      <td>-0.221562</td>
      <td>0.207203</td>
      <td>0.136464</td>
      <td>0.590319</td>
      <td>-0.131907</td>
      <td>0.546182</td>
      <td>0.658940</td>
      <td>0.731950</td>
      <td>-0.605905</td>
      <td>0.195413</td>
      <td>-1.663631</td>
      <td>-0.688073</td>
      <td>-1.513149</td>
      <td>0.092166</td>
      <td>0.138036</td>
      <td>1.637506</td>
      <td>-1.286256</td>
      <td>-0.677802</td>
      <td>-0.294018</td>
      <td>-0.366507</td>
      <td>-0.794761</td>
      <td>-0.535172</td>
      <td>-0.091676</td>
      <td>0.350015</td>
      <td>-0.612573</td>
      <td>-0.089037</td>
      <td>0.433846</td>
      <td>...</td>
      <td>0.561795</td>
      <td>-0.737751</td>
      <td>-0.025844</td>
      <td>0.223311</td>
      <td>-1.367218</td>
      <td>-0.989928</td>
      <td>-1.240434</td>
      <td>-0.887610</td>
      <td>-0.443293</td>
      <td>0.865808</td>
      <td>0.324997</td>
      <td>-0.077830</td>
      <td>-0.211090</td>
      <td>0.356682</td>
      <td>0.167576</td>
      <td>0.724320</td>
      <td>0.883245</td>
      <td>0.706524</td>
      <td>0.346959</td>
      <td>-0.016443</td>
      <td>-1.127274</td>
      <td>-0.215618</td>
      <td>-0.627618</td>
      <td>-0.365289</td>
      <td>-0.318650</td>
      <td>-0.017892</td>
      <td>-0.103727</td>
      <td>0.723727</td>
      <td>-0.077125</td>
      <td>0.518618</td>
      <td>-0.383158</td>
      <td>0.380392</td>
      <td>0.723971</td>
      <td>0.052464</td>
      <td>-0.090440</td>
      <td>0.576502</td>
      <td>0.542198</td>
      <td>-0.943413</td>
      <td>-1.111764</td>
      <td>-0.111037</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.406652</td>
      <td>0.410719</td>
      <td>0.533529</td>
      <td>0.556522</td>
      <td>-0.235132</td>
      <td>-0.360867</td>
      <td>-0.147182</td>
      <td>-0.292355</td>
      <td>-1.188705</td>
      <td>-1.234584</td>
      <td>-0.594497</td>
      <td>0.650678</td>
      <td>0.513527</td>
      <td>0.215255</td>
      <td>-0.464531</td>
      <td>0.735186</td>
      <td>0.470278</td>
      <td>-0.136962</td>
      <td>0.127578</td>
      <td>-0.173805</td>
      <td>-0.190124</td>
      <td>0.108161</td>
      <td>1.103901</td>
      <td>0.225268</td>
      <td>1.323110</td>
      <td>0.065164</td>
      <td>0.182364</td>
      <td>0.427713</td>
      <td>0.432180</td>
      <td>0.036864</td>
      <td>-0.199092</td>
      <td>0.091354</td>
      <td>0.402081</td>
      <td>0.153425</td>
      <td>0.044094</td>
      <td>-0.563179</td>
      <td>0.705033</td>
      <td>-0.786948</td>
      <td>-0.569565</td>
      <td>-1.654388</td>
      <td>...</td>
      <td>-0.251022</td>
      <td>0.267273</td>
      <td>0.074872</td>
      <td>0.238296</td>
      <td>0.087070</td>
      <td>0.016620</td>
      <td>-0.132887</td>
      <td>0.742759</td>
      <td>0.181125</td>
      <td>0.259396</td>
      <td>0.557272</td>
      <td>0.721335</td>
      <td>-0.873276</td>
      <td>0.372901</td>
      <td>0.682306</td>
      <td>-0.127175</td>
      <td>0.474060</td>
      <td>0.826838</td>
      <td>0.204698</td>
      <td>0.541755</td>
      <td>-0.384021</td>
      <td>0.584582</td>
      <td>-0.123797</td>
      <td>-0.281780</td>
      <td>0.025088</td>
      <td>-0.246389</td>
      <td>-0.095023</td>
      <td>1.076390</td>
      <td>-0.160888</td>
      <td>0.654858</td>
      <td>0.050981</td>
      <td>0.298019</td>
      <td>-0.697615</td>
      <td>0.744011</td>
      <td>-0.272147</td>
      <td>-0.192408</td>
      <td>-0.084544</td>
      <td>1.098826</td>
      <td>-0.074888</td>
      <td>-0.122695</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.377033</td>
      <td>-0.153485</td>
      <td>0.058708</td>
      <td>0.819406</td>
      <td>-0.211387</td>
      <td>-0.179455</td>
      <td>0.147302</td>
      <td>0.065544</td>
      <td>0.081637</td>
      <td>-0.501981</td>
      <td>-0.997222</td>
      <td>0.183743</td>
      <td>0.660609</td>
      <td>-0.697923</td>
      <td>-0.361012</td>
      <td>0.028862</td>
      <td>0.094133</td>
      <td>-0.153699</td>
      <td>-0.038927</td>
      <td>0.896425</td>
      <td>-0.050778</td>
      <td>-0.709475</td>
      <td>-0.446669</td>
      <td>-1.081116</td>
      <td>-1.115901</td>
      <td>0.163794</td>
      <td>0.492779</td>
      <td>-0.691324</td>
      <td>0.059680</td>
      <td>-0.583840</td>
      <td>-0.344594</td>
      <td>-0.829061</td>
      <td>-0.037709</td>
      <td>0.226822</td>
      <td>-0.042237</td>
      <td>0.324549</td>
      <td>-0.089868</td>
      <td>-0.907968</td>
      <td>-0.814996</td>
      <td>-1.783909</td>
      <td>...</td>
      <td>0.474472</td>
      <td>0.423271</td>
      <td>0.301117</td>
      <td>0.418460</td>
      <td>-0.450179</td>
      <td>0.292727</td>
      <td>0.092563</td>
      <td>-0.519833</td>
      <td>-0.167906</td>
      <td>-0.575903</td>
      <td>-0.430552</td>
      <td>-0.348432</td>
      <td>-0.078314</td>
      <td>0.020698</td>
      <td>0.550961</td>
      <td>0.125040</td>
      <td>0.397494</td>
      <td>0.864224</td>
      <td>-0.022612</td>
      <td>-0.474513</td>
      <td>0.188704</td>
      <td>0.183902</td>
      <td>-0.122917</td>
      <td>0.040138</td>
      <td>-1.091067</td>
      <td>1.303132</td>
      <td>0.099453</td>
      <td>0.794211</td>
      <td>-0.160781</td>
      <td>0.451540</td>
      <td>-0.115459</td>
      <td>0.789103</td>
      <td>0.604659</td>
      <td>0.644139</td>
      <td>0.951930</td>
      <td>-0.046748</td>
      <td>-0.358980</td>
      <td>1.614291</td>
      <td>0.426706</td>
      <td>0.581752</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-1.628432</td>
      <td>-1.123498</td>
      <td>1.353849</td>
      <td>0.472135</td>
      <td>0.565812</td>
      <td>0.485251</td>
      <td>0.297881</td>
      <td>1.051606</td>
      <td>0.060501</td>
      <td>-1.080967</td>
      <td>-1.609073</td>
      <td>-0.569682</td>
      <td>0.166801</td>
      <td>-0.878295</td>
      <td>0.014674</td>
      <td>-0.896922</td>
      <td>-0.309994</td>
      <td>1.201785</td>
      <td>-0.375123</td>
      <td>-0.403125</td>
      <td>0.377784</td>
      <td>-0.809598</td>
      <td>0.065334</td>
      <td>-1.161265</td>
      <td>-0.122048</td>
      <td>-0.281596</td>
      <td>0.590798</td>
      <td>-0.742382</td>
      <td>0.688342</td>
      <td>-0.429991</td>
      <td>-0.730453</td>
      <td>-0.643026</td>
      <td>0.673517</td>
      <td>0.290482</td>
      <td>0.122147</td>
      <td>-0.223736</td>
      <td>-0.030506</td>
      <td>-0.979754</td>
      <td>-0.606731</td>
      <td>-0.617498</td>
      <td>...</td>
      <td>-0.285752</td>
      <td>-0.691056</td>
      <td>-0.845564</td>
      <td>-0.204401</td>
      <td>-0.555085</td>
      <td>-0.073280</td>
      <td>-0.446484</td>
      <td>-0.336196</td>
      <td>-0.014407</td>
      <td>0.688631</td>
      <td>0.408098</td>
      <td>0.231956</td>
      <td>-0.173369</td>
      <td>-0.040412</td>
      <td>-0.288717</td>
      <td>-0.014772</td>
      <td>-0.341537</td>
      <td>-0.253034</td>
      <td>0.398308</td>
      <td>-0.932612</td>
      <td>0.174602</td>
      <td>-0.825383</td>
      <td>0.577101</td>
      <td>0.246784</td>
      <td>-0.866169</td>
      <td>-0.961285</td>
      <td>0.360717</td>
      <td>0.220429</td>
      <td>0.866590</td>
      <td>0.943024</td>
      <td>-0.521790</td>
      <td>0.616920</td>
      <td>-0.025645</td>
      <td>-0.937501</td>
      <td>0.318801</td>
      <td>-0.860270</td>
      <td>-0.329961</td>
      <td>-2.767652</td>
      <td>-1.947628</td>
      <td>-0.490508</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.574308</td>
      <td>-0.228451</td>
      <td>0.872786</td>
      <td>0.271454</td>
      <td>-0.347482</td>
      <td>-0.595228</td>
      <td>-1.166104</td>
      <td>-0.836066</td>
      <td>-0.440290</td>
      <td>-0.793836</td>
      <td>-0.717286</td>
      <td>0.025019</td>
      <td>0.599611</td>
      <td>0.892652</td>
      <td>0.756196</td>
      <td>-0.139323</td>
      <td>-0.239775</td>
      <td>1.066305</td>
      <td>0.022004</td>
      <td>0.114131</td>
      <td>0.197674</td>
      <td>-0.250375</td>
      <td>-0.144490</td>
      <td>-1.158494</td>
      <td>-0.704880</td>
      <td>0.144824</td>
      <td>0.860355</td>
      <td>-0.946608</td>
      <td>-0.167131</td>
      <td>1.011114</td>
      <td>-0.088284</td>
      <td>-1.267528</td>
      <td>-0.711177</td>
      <td>0.273099</td>
      <td>1.352260</td>
      <td>-0.136452</td>
      <td>0.990579</td>
      <td>0.012535</td>
      <td>-2.129801</td>
      <td>-0.866870</td>
      <td>...</td>
      <td>-0.619086</td>
      <td>-1.034809</td>
      <td>-0.616955</td>
      <td>-0.196738</td>
      <td>-0.635802</td>
      <td>-0.733570</td>
      <td>-1.013278</td>
      <td>0.218605</td>
      <td>-1.207638</td>
      <td>-0.293933</td>
      <td>0.732115</td>
      <td>0.334644</td>
      <td>0.188604</td>
      <td>0.285917</td>
      <td>-1.066527</td>
      <td>0.250467</td>
      <td>0.626352</td>
      <td>0.384047</td>
      <td>-0.483530</td>
      <td>-0.456098</td>
      <td>0.211290</td>
      <td>0.241510</td>
      <td>0.231109</td>
      <td>0.375390</td>
      <td>0.190397</td>
      <td>-0.010106</td>
      <td>0.818777</td>
      <td>0.881469</td>
      <td>0.209294</td>
      <td>-0.435697</td>
      <td>-0.139584</td>
      <td>-0.288094</td>
      <td>0.283439</td>
      <td>0.151549</td>
      <td>0.642293</td>
      <td>0.911590</td>
      <td>0.528701</td>
      <td>-0.009053</td>
      <td>-0.242745</td>
      <td>-0.975640</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-1.685905</td>
      <td>-0.494062</td>
      <td>0.021071</td>
      <td>0.808156</td>
      <td>0.277658</td>
      <td>-0.282906</td>
      <td>-0.054817</td>
      <td>0.060121</td>
      <td>-1.430419</td>
      <td>-1.341050</td>
      <td>-0.615944</td>
      <td>0.455584</td>
      <td>0.003746</td>
      <td>0.812275</td>
      <td>0.785196</td>
      <td>-0.629400</td>
      <td>-0.638704</td>
      <td>1.096864</td>
      <td>0.566328</td>
      <td>0.652358</td>
      <td>-0.033730</td>
      <td>0.071658</td>
      <td>0.052869</td>
      <td>-0.389332</td>
      <td>-0.207543</td>
      <td>-1.368889</td>
      <td>0.231497</td>
      <td>-1.864147</td>
      <td>-0.526179</td>
      <td>0.647674</td>
      <td>-0.585628</td>
      <td>-0.007506</td>
      <td>-0.275349</td>
      <td>-0.248788</td>
      <td>0.064587</td>
      <td>-0.292756</td>
      <td>0.477030</td>
      <td>-0.199982</td>
      <td>-0.305341</td>
      <td>0.243909</td>
      <td>...</td>
      <td>1.449235</td>
      <td>0.545526</td>
      <td>0.468232</td>
      <td>0.030303</td>
      <td>0.104610</td>
      <td>0.506159</td>
      <td>-0.941511</td>
      <td>-0.926800</td>
      <td>0.359680</td>
      <td>0.423510</td>
      <td>0.238772</td>
      <td>-0.085367</td>
      <td>-0.184210</td>
      <td>0.418389</td>
      <td>0.780976</td>
      <td>-0.223612</td>
      <td>0.919420</td>
      <td>1.054320</td>
      <td>-0.071844</td>
      <td>-1.215865</td>
      <td>-0.275735</td>
      <td>0.279819</td>
      <td>1.629060</td>
      <td>0.467402</td>
      <td>-0.098727</td>
      <td>0.679383</td>
      <td>1.668553</td>
      <td>0.013452</td>
      <td>-0.081212</td>
      <td>0.790151</td>
      <td>0.431868</td>
      <td>0.416387</td>
      <td>-0.155149</td>
      <td>0.213505</td>
      <td>0.515178</td>
      <td>0.301351</td>
      <td>0.211490</td>
      <td>-1.140085</td>
      <td>-1.600615</td>
      <td>-0.629105</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.339397</td>
      <td>-0.114034</td>
      <td>0.998004</td>
      <td>0.666476</td>
      <td>0.145994</td>
      <td>0.740679</td>
      <td>-0.366916</td>
      <td>0.107804</td>
      <td>-0.739306</td>
      <td>-0.129263</td>
      <td>0.189235</td>
      <td>-0.230893</td>
      <td>-0.272009</td>
      <td>-0.281790</td>
      <td>0.102649</td>
      <td>0.030848</td>
      <td>-0.595167</td>
      <td>-0.116501</td>
      <td>-0.601622</td>
      <td>0.707103</td>
      <td>-0.317114</td>
      <td>-0.488246</td>
      <td>0.450569</td>
      <td>-0.828286</td>
      <td>-0.766149</td>
      <td>-0.488076</td>
      <td>0.218809</td>
      <td>-1.668646</td>
      <td>-0.046710</td>
      <td>-0.522671</td>
      <td>0.788406</td>
      <td>0.362533</td>
      <td>-0.176749</td>
      <td>0.246814</td>
      <td>-0.094889</td>
      <td>-0.185578</td>
      <td>-0.138335</td>
      <td>0.204106</td>
      <td>-0.748664</td>
      <td>-0.556569</td>
      <td>...</td>
      <td>-0.712361</td>
      <td>0.128828</td>
      <td>-0.506175</td>
      <td>-1.365415</td>
      <td>-0.838628</td>
      <td>0.170395</td>
      <td>-0.053415</td>
      <td>0.183044</td>
      <td>0.147970</td>
      <td>-0.153072</td>
      <td>0.299435</td>
      <td>0.313475</td>
      <td>0.957387</td>
      <td>1.001549</td>
      <td>-0.138119</td>
      <td>-0.667266</td>
      <td>0.352215</td>
      <td>0.131944</td>
      <td>-1.189819</td>
      <td>-1.029839</td>
      <td>-0.846114</td>
      <td>-0.032186</td>
      <td>-0.239519</td>
      <td>-0.298066</td>
      <td>0.130154</td>
      <td>0.446735</td>
      <td>-0.288378</td>
      <td>0.444842</td>
      <td>-1.286083</td>
      <td>0.524148</td>
      <td>0.147564</td>
      <td>1.008493</td>
      <td>0.619286</td>
      <td>0.383030</td>
      <td>-1.193689</td>
      <td>-0.180425</td>
      <td>0.286029</td>
      <td>-0.758473</td>
      <td>-1.369017</td>
      <td>-1.166293</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-0.918474</td>
      <td>-0.021170</td>
      <td>1.440980</td>
      <td>0.336059</td>
      <td>-0.420498</td>
      <td>-0.525899</td>
      <td>0.210878</td>
      <td>-1.725404</td>
      <td>-0.824024</td>
      <td>-0.402450</td>
      <td>-1.301916</td>
      <td>0.016069</td>
      <td>-0.038159</td>
      <td>-1.243493</td>
      <td>-0.272642</td>
      <td>0.681018</td>
      <td>-0.202706</td>
      <td>-0.084605</td>
      <td>-0.089365</td>
      <td>1.262593</td>
      <td>0.602201</td>
      <td>1.626924</td>
      <td>1.087364</td>
      <td>-0.585538</td>
      <td>0.661609</td>
      <td>-0.103998</td>
      <td>1.132561</td>
      <td>-1.045609</td>
      <td>1.051332</td>
      <td>0.626921</td>
      <td>-0.231167</td>
      <td>0.440762</td>
      <td>0.683548</td>
      <td>-1.064797</td>
      <td>-0.135275</td>
      <td>0.076262</td>
      <td>1.120933</td>
      <td>-1.011694</td>
      <td>-0.472565</td>
      <td>0.472602</td>
      <td>...</td>
      <td>0.400556</td>
      <td>0.758717</td>
      <td>0.291668</td>
      <td>0.232778</td>
      <td>0.327300</td>
      <td>-0.228781</td>
      <td>0.132122</td>
      <td>-0.274888</td>
      <td>-0.922597</td>
      <td>0.356864</td>
      <td>0.085805</td>
      <td>-0.003081</td>
      <td>0.704087</td>
      <td>0.561917</td>
      <td>-0.637935</td>
      <td>-0.374393</td>
      <td>-0.008869</td>
      <td>0.455360</td>
      <td>-0.171054</td>
      <td>-0.362365</td>
      <td>-1.403180</td>
      <td>-1.339242</td>
      <td>0.373530</td>
      <td>-0.011100</td>
      <td>0.013666</td>
      <td>-0.560669</td>
      <td>0.396415</td>
      <td>0.847764</td>
      <td>0.196703</td>
      <td>0.509131</td>
      <td>-0.143983</td>
      <td>0.376684</td>
      <td>0.135892</td>
      <td>-0.408755</td>
      <td>0.224224</td>
      <td>-0.917628</td>
      <td>-0.123121</td>
      <td>-1.064157</td>
      <td>-0.329860</td>
      <td>0.339363</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>0.932563</td>
      <td>-0.001782</td>
      <td>-1.000385</td>
      <td>-0.553437</td>
      <td>0.006268</td>
      <td>1.255058</td>
      <td>0.306478</td>
      <td>1.215610</td>
      <td>0.233596</td>
      <td>-0.490629</td>
      <td>-0.935315</td>
      <td>-1.027737</td>
      <td>0.903218</td>
      <td>-0.228197</td>
      <td>1.415144</td>
      <td>0.320876</td>
      <td>0.049401</td>
      <td>-0.445459</td>
      <td>-0.269526</td>
      <td>-0.415578</td>
      <td>-0.249110</td>
      <td>0.646573</td>
      <td>0.183821</td>
      <td>0.538311</td>
      <td>0.260675</td>
      <td>0.515076</td>
      <td>-0.021757</td>
      <td>0.210109</td>
      <td>0.006871</td>
      <td>-0.403881</td>
      <td>0.220105</td>
      <td>-0.420111</td>
      <td>-0.018905</td>
      <td>1.047502</td>
      <td>0.327882</td>
      <td>0.062514</td>
      <td>0.469798</td>
      <td>-0.363669</td>
      <td>0.080499</td>
      <td>-0.127874</td>
      <td>...</td>
      <td>-0.293841</td>
      <td>-0.207507</td>
      <td>0.074507</td>
      <td>0.059793</td>
      <td>1.080424</td>
      <td>0.763742</td>
      <td>0.282804</td>
      <td>-0.410278</td>
      <td>-0.143319</td>
      <td>0.245023</td>
      <td>-0.368440</td>
      <td>-1.047766</td>
      <td>-0.360205</td>
      <td>0.282608</td>
      <td>-0.133152</td>
      <td>0.805378</td>
      <td>-1.076323</td>
      <td>0.101438</td>
      <td>0.558928</td>
      <td>-0.833263</td>
      <td>-0.029120</td>
      <td>-0.578016</td>
      <td>0.416055</td>
      <td>0.107739</td>
      <td>0.170988</td>
      <td>-0.891448</td>
      <td>0.194827</td>
      <td>-0.341706</td>
      <td>0.089919</td>
      <td>-1.062970</td>
      <td>-0.838876</td>
      <td>-0.079519</td>
      <td>-0.133501</td>
      <td>0.210598</td>
      <td>0.283481</td>
      <td>-0.164593</td>
      <td>-0.135521</td>
      <td>2.516580</td>
      <td>1.443000</td>
      <td>0.985221</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.451829</td>
      <td>-0.389719</td>
      <td>-0.946619</td>
      <td>-0.196827</td>
      <td>-0.956228</td>
      <td>-0.349814</td>
      <td>1.196708</td>
      <td>0.362147</td>
      <td>-0.691956</td>
      <td>-0.477753</td>
      <td>-1.191175</td>
      <td>-0.314530</td>
      <td>0.968808</td>
      <td>0.653714</td>
      <td>-0.122190</td>
      <td>0.413395</td>
      <td>-0.526229</td>
      <td>-0.932460</td>
      <td>-0.609587</td>
      <td>-0.323027</td>
      <td>-0.530794</td>
      <td>-0.500080</td>
      <td>-0.574391</td>
      <td>-1.276464</td>
      <td>-0.164579</td>
      <td>0.759029</td>
      <td>0.068286</td>
      <td>0.693846</td>
      <td>0.622395</td>
      <td>0.531992</td>
      <td>-0.384475</td>
      <td>-0.712071</td>
      <td>0.216231</td>
      <td>0.861693</td>
      <td>0.420589</td>
      <td>0.396201</td>
      <td>0.296351</td>
      <td>-1.712100</td>
      <td>-0.173605</td>
      <td>-0.590129</td>
      <td>...</td>
      <td>-0.615885</td>
      <td>0.521721</td>
      <td>0.044422</td>
      <td>0.785089</td>
      <td>0.114197</td>
      <td>0.355602</td>
      <td>0.172244</td>
      <td>-0.313803</td>
      <td>-0.145816</td>
      <td>0.504450</td>
      <td>-0.770356</td>
      <td>0.504433</td>
      <td>-0.313615</td>
      <td>-0.092377</td>
      <td>-0.114072</td>
      <td>-0.227331</td>
      <td>-0.631157</td>
      <td>-0.473847</td>
      <td>0.498524</td>
      <td>-0.630667</td>
      <td>0.131481</td>
      <td>-0.570044</td>
      <td>1.189542</td>
      <td>-0.081409</td>
      <td>0.494959</td>
      <td>-0.469555</td>
      <td>0.510226</td>
      <td>-1.265139</td>
      <td>-0.873304</td>
      <td>-0.497409</td>
      <td>-1.146190</td>
      <td>-0.551240</td>
      <td>0.886433</td>
      <td>0.008501</td>
      <td>-0.757643</td>
      <td>-0.394382</td>
      <td>-0.389289</td>
      <td>0.065646</td>
      <td>0.439688</td>
      <td>-0.293950</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.229704</td>
      <td>0.344840</td>
      <td>0.106009</td>
      <td>-0.931097</td>
      <td>0.111072</td>
      <td>0.136806</td>
      <td>0.826820</td>
      <td>1.057393</td>
      <td>1.067454</td>
      <td>1.119239</td>
      <td>-0.163817</td>
      <td>-0.489897</td>
      <td>0.404058</td>
      <td>-0.016478</td>
      <td>0.719322</td>
      <td>-0.649561</td>
      <td>0.393453</td>
      <td>-0.087850</td>
      <td>0.261797</td>
      <td>0.229788</td>
      <td>-1.094517</td>
      <td>0.349342</td>
      <td>1.094324</td>
      <td>0.083513</td>
      <td>1.053406</td>
      <td>-0.123855</td>
      <td>-1.083341</td>
      <td>0.303453</td>
      <td>-0.153488</td>
      <td>-0.770738</td>
      <td>-0.742380</td>
      <td>0.384772</td>
      <td>0.343917</td>
      <td>-0.420129</td>
      <td>-0.164027</td>
      <td>-0.959676</td>
      <td>-0.055227</td>
      <td>-0.698047</td>
      <td>-0.495690</td>
      <td>-0.138553</td>
      <td>...</td>
      <td>1.480642</td>
      <td>0.401549</td>
      <td>-0.147733</td>
      <td>1.383698</td>
      <td>0.215583</td>
      <td>0.494934</td>
      <td>-0.742699</td>
      <td>-1.543844</td>
      <td>-0.950990</td>
      <td>-1.426122</td>
      <td>-1.093075</td>
      <td>-1.269797</td>
      <td>-0.049821</td>
      <td>0.988306</td>
      <td>0.522857</td>
      <td>-0.183933</td>
      <td>-1.114583</td>
      <td>0.166123</td>
      <td>0.200395</td>
      <td>0.100951</td>
      <td>1.412473</td>
      <td>0.089095</td>
      <td>0.633865</td>
      <td>1.029855</td>
      <td>1.357741</td>
      <td>-1.405179</td>
      <td>-1.188775</td>
      <td>-0.480670</td>
      <td>-1.277158</td>
      <td>-1.528499</td>
      <td>0.053875</td>
      <td>0.332179</td>
      <td>-0.547271</td>
      <td>0.139803</td>
      <td>-0.271556</td>
      <td>-0.374925</td>
      <td>-0.443546</td>
      <td>-1.393908</td>
      <td>-0.533161</td>
      <td>0.216481</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.108123</td>
      <td>0.021603</td>
      <td>-0.055921</td>
      <td>-0.045455</td>
      <td>0.136975</td>
      <td>1.243685</td>
      <td>0.937291</td>
      <td>-0.087078</td>
      <td>-0.737267</td>
      <td>-0.548640</td>
      <td>-0.792125</td>
      <td>-0.360550</td>
      <td>0.328480</td>
      <td>-0.525562</td>
      <td>0.009868</td>
      <td>0.050863</td>
      <td>0.173788</td>
      <td>-0.439633</td>
      <td>0.399353</td>
      <td>-0.349670</td>
      <td>-0.581357</td>
      <td>-1.030933</td>
      <td>-0.101731</td>
      <td>-0.427177</td>
      <td>-0.482740</td>
      <td>-0.981579</td>
      <td>-0.829846</td>
      <td>0.425795</td>
      <td>-0.387717</td>
      <td>-0.469283</td>
      <td>-0.104432</td>
      <td>0.378436</td>
      <td>-0.296802</td>
      <td>-0.105765</td>
      <td>-0.346504</td>
      <td>-0.427905</td>
      <td>-0.069741</td>
      <td>-0.130631</td>
      <td>0.234756</td>
      <td>-0.105737</td>
      <td>...</td>
      <td>0.284877</td>
      <td>0.217067</td>
      <td>-0.970580</td>
      <td>-0.553844</td>
      <td>-0.446845</td>
      <td>1.399910</td>
      <td>-0.147837</td>
      <td>-0.024005</td>
      <td>1.004538</td>
      <td>-0.008975</td>
      <td>0.010458</td>
      <td>-0.044092</td>
      <td>-0.352449</td>
      <td>0.092595</td>
      <td>-0.486392</td>
      <td>0.026710</td>
      <td>-0.308073</td>
      <td>-0.723354</td>
      <td>-0.404853</td>
      <td>-0.105427</td>
      <td>-0.683979</td>
      <td>-0.987203</td>
      <td>-0.084761</td>
      <td>0.686489</td>
      <td>1.311974</td>
      <td>-0.071751</td>
      <td>-0.850818</td>
      <td>-0.843657</td>
      <td>0.089504</td>
      <td>-1.396891</td>
      <td>-0.283664</td>
      <td>0.469063</td>
      <td>-0.012052</td>
      <td>-0.243891</td>
      <td>-0.973668</td>
      <td>-0.140117</td>
      <td>0.482312</td>
      <td>0.579370</td>
      <td>0.401063</td>
      <td>0.344915</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.305490</td>
      <td>0.381902</td>
      <td>-0.071285</td>
      <td>0.615016</td>
      <td>0.099351</td>
      <td>0.414375</td>
      <td>0.836696</td>
      <td>1.004604</td>
      <td>0.847558</td>
      <td>-0.360471</td>
      <td>0.127940</td>
      <td>0.740931</td>
      <td>0.777873</td>
      <td>-0.180429</td>
      <td>-0.391645</td>
      <td>1.334668</td>
      <td>0.104379</td>
      <td>-0.060418</td>
      <td>-0.761539</td>
      <td>-0.996753</td>
      <td>-0.967425</td>
      <td>-0.709091</td>
      <td>-0.140903</td>
      <td>-1.338355</td>
      <td>0.252068</td>
      <td>0.107493</td>
      <td>-0.103941</td>
      <td>0.450435</td>
      <td>-0.599673</td>
      <td>0.103242</td>
      <td>0.258764</td>
      <td>0.828133</td>
      <td>0.439819</td>
      <td>0.718108</td>
      <td>0.566786</td>
      <td>-0.530133</td>
      <td>0.811410</td>
      <td>0.302320</td>
      <td>-0.359011</td>
      <td>-0.255604</td>
      <td>...</td>
      <td>-0.333899</td>
      <td>0.333538</td>
      <td>1.084838</td>
      <td>0.565221</td>
      <td>0.219093</td>
      <td>0.757072</td>
      <td>-1.350131</td>
      <td>-0.296459</td>
      <td>0.264642</td>
      <td>-0.261035</td>
      <td>-0.001028</td>
      <td>-1.222769</td>
      <td>-0.129684</td>
      <td>0.122992</td>
      <td>-1.544732</td>
      <td>-0.290195</td>
      <td>-0.185724</td>
      <td>-0.986177</td>
      <td>0.387536</td>
      <td>0.128301</td>
      <td>-0.074926</td>
      <td>-0.571611</td>
      <td>0.166542</td>
      <td>-0.701860</td>
      <td>1.008546</td>
      <td>0.001943</td>
      <td>-0.123970</td>
      <td>-1.295118</td>
      <td>-1.201726</td>
      <td>-1.479918</td>
      <td>-0.103092</td>
      <td>-0.231738</td>
      <td>0.329027</td>
      <td>-0.011805</td>
      <td>0.073078</td>
      <td>0.379940</td>
      <td>0.036285</td>
      <td>1.215049</td>
      <td>1.400687</td>
      <td>0.832494</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f01d6460d30&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef  std err          t          P&gt;|t|     2.5 %    97.5 %
D  0.971397   0.0421  23.073467  8.552744e-118  0.888883  1.053912
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  5.265 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>