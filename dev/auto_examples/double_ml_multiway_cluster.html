
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.f6b7ca918bee2f46fd9abac01cfb07d5.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1e043a052b0af929e4d8.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">


    
    <a class="navbar-brand" href="../index.html">
      <p class="title">DoubleML</p>
    </a>
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  DoubleML
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/install.html">
  Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/intro.html">
  Getting started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../guide/guide.html">
  User guide
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api.html">
  Python API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference external nav-link" href="https://docs.doubleml.org/r/stable/">
  R API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../release/release.html">
  Release notes
 </a>
</li>

        
      </ul>

      <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><p class="logo" style="text-align:center;"><a href="../index.html">
    <img class="logo" src="../logo.png" alt="Logo" width="65%" height="65%">
</a></p><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l2 current active">
  <a class="current reference internal" href="#">
   Multiway Cluster Robust DML
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="double_ml_bonus_data.html">
   DML: Bonus Data
  </a>
 </li>
</ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulate-multiway-cluster-data">
   Simulate multiway cluster data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
   Initialize the objects of class DoubleMLData and DoubleMLPLIV
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#split-samples-and-transfer-the-sample-splitting-to-the-object">
   Split samples and transfer the sample splitting to the object
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fit-the-model-and-show-a-summary">
   Fit the model and show a summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing">
   Visualization of sample splitting with tuple and linear indexing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold">
     Visualize sample splitting with tuples (one plot per fold)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
     Visualize sample splitting with linear indexing (one column per fold)
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.150366</td>
      <td>1.896030e-01</td>
      <td>0.413643</td>
      <td>0.817215</td>
      <td>1.269013</td>
      <td>0.108340</td>
      <td>0.093687</td>
      <td>-0.211790</td>
      <td>-0.794345</td>
      <td>-0.164117</td>
      <td>1.304648</td>
      <td>0.453777</td>
      <td>0.473064</td>
      <td>0.846459</td>
      <td>0.005493</td>
      <td>-0.607782</td>
      <td>0.288050</td>
      <td>-0.641856</td>
      <td>-0.804275</td>
      <td>-0.125582</td>
      <td>-0.013667</td>
      <td>-0.339868</td>
      <td>0.878832</td>
      <td>0.427374</td>
      <td>-0.122080</td>
      <td>0.383696</td>
      <td>-0.077908</td>
      <td>1.032313</td>
      <td>0.597232</td>
      <td>1.037335</td>
      <td>0.334226</td>
      <td>-0.008715</td>
      <td>0.314230</td>
      <td>-0.188833</td>
      <td>-0.557080</td>
      <td>-0.295413</td>
      <td>-0.457279</td>
      <td>-0.449129</td>
      <td>-0.390803</td>
      <td>-0.602444</td>
      <td>...</td>
      <td>-0.446025</td>
      <td>-0.075189</td>
      <td>0.428638</td>
      <td>-0.254644</td>
      <td>-0.151208</td>
      <td>-0.553160</td>
      <td>-0.845326</td>
      <td>-0.775378</td>
      <td>-0.267142</td>
      <td>-0.545361</td>
      <td>0.272615</td>
      <td>0.150836</td>
      <td>0.058490</td>
      <td>-0.465357</td>
      <td>-0.671889</td>
      <td>-0.722600</td>
      <td>0.691295</td>
      <td>-0.125830</td>
      <td>0.241294</td>
      <td>-0.105755</td>
      <td>-0.438185</td>
      <td>-0.222281</td>
      <td>-0.214977</td>
      <td>0.397092</td>
      <td>0.861671</td>
      <td>0.244869</td>
      <td>-0.016631</td>
      <td>-0.454099</td>
      <td>-0.387654</td>
      <td>-0.630562</td>
      <td>-0.972539</td>
      <td>-1.151462</td>
      <td>0.008401</td>
      <td>-0.462450</td>
      <td>0.064416</td>
      <td>0.076104</td>
      <td>-0.625526</td>
      <td>0.775207</td>
      <td>0.078569</td>
      <td>-0.401110</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.080970</td>
      <td>1.647245e-02</td>
      <td>0.756445</td>
      <td>-0.465006</td>
      <td>-0.195049</td>
      <td>-0.148047</td>
      <td>-0.092869</td>
      <td>0.358840</td>
      <td>-0.421656</td>
      <td>0.655292</td>
      <td>0.365340</td>
      <td>0.022739</td>
      <td>-0.386449</td>
      <td>-0.656074</td>
      <td>-0.065433</td>
      <td>0.422311</td>
      <td>0.314477</td>
      <td>0.326642</td>
      <td>-0.313604</td>
      <td>0.213673</td>
      <td>-0.200856</td>
      <td>0.339046</td>
      <td>0.989800</td>
      <td>0.542925</td>
      <td>-0.668473</td>
      <td>-0.963920</td>
      <td>-0.299171</td>
      <td>-0.172650</td>
      <td>0.367901</td>
      <td>0.568586</td>
      <td>0.358217</td>
      <td>0.278108</td>
      <td>-0.514575</td>
      <td>-0.814861</td>
      <td>-0.384062</td>
      <td>-0.639247</td>
      <td>-0.232217</td>
      <td>0.901107</td>
      <td>1.609000</td>
      <td>-1.246502</td>
      <td>...</td>
      <td>0.069360</td>
      <td>-0.513491</td>
      <td>0.483758</td>
      <td>0.445099</td>
      <td>-0.254976</td>
      <td>0.249049</td>
      <td>-0.356438</td>
      <td>-0.339726</td>
      <td>0.473958</td>
      <td>0.171190</td>
      <td>1.244059</td>
      <td>0.712281</td>
      <td>-0.019272</td>
      <td>-0.046139</td>
      <td>-0.193419</td>
      <td>0.544660</td>
      <td>-0.753993</td>
      <td>-0.129957</td>
      <td>0.390864</td>
      <td>0.943429</td>
      <td>0.120566</td>
      <td>-0.963240</td>
      <td>-0.438364</td>
      <td>-0.772210</td>
      <td>0.390618</td>
      <td>0.708580</td>
      <td>-0.928909</td>
      <td>-0.146438</td>
      <td>-0.530961</td>
      <td>-1.302094</td>
      <td>0.053657</td>
      <td>0.730664</td>
      <td>-0.206947</td>
      <td>0.262743</td>
      <td>0.346336</td>
      <td>-0.135735</td>
      <td>-0.602549</td>
      <td>1.406839</td>
      <td>0.683351</td>
      <td>0.336658</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.461371</td>
      <td>-2.695543e-01</td>
      <td>0.056398</td>
      <td>0.530502</td>
      <td>0.472409</td>
      <td>-0.212890</td>
      <td>-0.484529</td>
      <td>-0.180473</td>
      <td>0.038518</td>
      <td>0.866599</td>
      <td>-0.220472</td>
      <td>0.111726</td>
      <td>-0.160025</td>
      <td>0.682600</td>
      <td>-0.399026</td>
      <td>-0.069504</td>
      <td>0.776177</td>
      <td>-0.365740</td>
      <td>0.585886</td>
      <td>-0.098118</td>
      <td>-0.162254</td>
      <td>-0.223864</td>
      <td>-0.065489</td>
      <td>0.768418</td>
      <td>-0.366264</td>
      <td>-0.653939</td>
      <td>0.011913</td>
      <td>-0.170065</td>
      <td>0.636379</td>
      <td>-0.162792</td>
      <td>-0.517276</td>
      <td>-0.062684</td>
      <td>-0.617140</td>
      <td>0.105892</td>
      <td>-0.305426</td>
      <td>-0.450369</td>
      <td>0.302983</td>
      <td>0.019872</td>
      <td>0.546865</td>
      <td>-0.713898</td>
      <td>...</td>
      <td>-0.683447</td>
      <td>0.480795</td>
      <td>0.171108</td>
      <td>0.137010</td>
      <td>-0.962540</td>
      <td>-0.285876</td>
      <td>0.384906</td>
      <td>-0.215131</td>
      <td>1.676961</td>
      <td>0.930418</td>
      <td>-0.502250</td>
      <td>-0.593651</td>
      <td>0.584410</td>
      <td>1.261712</td>
      <td>0.490678</td>
      <td>-0.523434</td>
      <td>-0.407499</td>
      <td>-0.784019</td>
      <td>0.475079</td>
      <td>-0.078243</td>
      <td>-0.184427</td>
      <td>-0.254024</td>
      <td>0.502460</td>
      <td>0.878193</td>
      <td>0.607407</td>
      <td>-0.110298</td>
      <td>0.044166</td>
      <td>-0.936372</td>
      <td>-0.326182</td>
      <td>-1.063885</td>
      <td>-1.002316</td>
      <td>-0.316398</td>
      <td>-0.407570</td>
      <td>-0.333415</td>
      <td>-0.239484</td>
      <td>0.183891</td>
      <td>0.952428</td>
      <td>-0.355420</td>
      <td>0.319852</td>
      <td>0.083281</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.201800</td>
      <td>3.716282e-01</td>
      <td>-0.371343</td>
      <td>0.069288</td>
      <td>0.726860</td>
      <td>-0.274115</td>
      <td>-1.062886</td>
      <td>-0.424986</td>
      <td>-0.045449</td>
      <td>-0.187885</td>
      <td>0.317008</td>
      <td>-0.973134</td>
      <td>0.511385</td>
      <td>0.460257</td>
      <td>-0.192464</td>
      <td>0.218082</td>
      <td>0.000546</td>
      <td>0.087984</td>
      <td>-0.701429</td>
      <td>-0.140538</td>
      <td>-0.030770</td>
      <td>-0.361613</td>
      <td>1.039471</td>
      <td>0.893335</td>
      <td>-0.046166</td>
      <td>1.153107</td>
      <td>-0.260522</td>
      <td>-0.016400</td>
      <td>0.784835</td>
      <td>0.501566</td>
      <td>-0.993833</td>
      <td>-0.428544</td>
      <td>1.015811</td>
      <td>1.059609</td>
      <td>-0.581037</td>
      <td>-0.632490</td>
      <td>0.061608</td>
      <td>-0.307894</td>
      <td>-0.504748</td>
      <td>-0.098547</td>
      <td>...</td>
      <td>-0.673865</td>
      <td>0.287774</td>
      <td>-0.206523</td>
      <td>0.847377</td>
      <td>0.289588</td>
      <td>0.324472</td>
      <td>-1.065614</td>
      <td>0.835276</td>
      <td>0.178577</td>
      <td>-0.738950</td>
      <td>0.906247</td>
      <td>0.186264</td>
      <td>0.513963</td>
      <td>0.166734</td>
      <td>0.076001</td>
      <td>0.332974</td>
      <td>-0.793972</td>
      <td>-0.875377</td>
      <td>0.401267</td>
      <td>-0.057081</td>
      <td>-0.326399</td>
      <td>-0.426403</td>
      <td>-0.377414</td>
      <td>-1.121865</td>
      <td>-0.110176</td>
      <td>0.097536</td>
      <td>0.386767</td>
      <td>-0.958792</td>
      <td>0.468749</td>
      <td>0.284726</td>
      <td>-0.652358</td>
      <td>-0.458029</td>
      <td>-0.604034</td>
      <td>0.493071</td>
      <td>0.781449</td>
      <td>1.012634</td>
      <td>-0.258576</td>
      <td>-1.378048</td>
      <td>-0.882434</td>
      <td>-0.534730</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.132346</td>
      <td>1.270291e-01</td>
      <td>-0.594259</td>
      <td>0.397381</td>
      <td>0.710992</td>
      <td>-0.508053</td>
      <td>-0.980534</td>
      <td>-0.445494</td>
      <td>-0.145928</td>
      <td>-0.490374</td>
      <td>-0.864847</td>
      <td>-0.601571</td>
      <td>-0.701198</td>
      <td>-0.819972</td>
      <td>0.209261</td>
      <td>0.451446</td>
      <td>1.467578</td>
      <td>1.050550</td>
      <td>0.612349</td>
      <td>0.072069</td>
      <td>-0.499489</td>
      <td>-0.127678</td>
      <td>-0.034264</td>
      <td>0.586783</td>
      <td>-0.000200</td>
      <td>0.125182</td>
      <td>0.182991</td>
      <td>0.070594</td>
      <td>-0.179963</td>
      <td>0.363123</td>
      <td>-0.024449</td>
      <td>-0.606017</td>
      <td>0.257457</td>
      <td>-0.449152</td>
      <td>0.210100</td>
      <td>-0.664020</td>
      <td>-1.179745</td>
      <td>0.113926</td>
      <td>0.220044</td>
      <td>0.364024</td>
      <td>...</td>
      <td>0.802157</td>
      <td>1.201905</td>
      <td>0.231024</td>
      <td>0.345536</td>
      <td>-0.440463</td>
      <td>-0.405486</td>
      <td>0.078599</td>
      <td>-0.215330</td>
      <td>0.902368</td>
      <td>-0.558286</td>
      <td>-0.389798</td>
      <td>-0.342010</td>
      <td>-0.049790</td>
      <td>0.232913</td>
      <td>0.284175</td>
      <td>-0.027893</td>
      <td>0.476731</td>
      <td>-0.600025</td>
      <td>-0.660304</td>
      <td>-0.137834</td>
      <td>-0.551120</td>
      <td>-0.107104</td>
      <td>0.768740</td>
      <td>0.321975</td>
      <td>0.164663</td>
      <td>-0.325112</td>
      <td>-0.350222</td>
      <td>-0.037901</td>
      <td>0.925578</td>
      <td>-1.086802</td>
      <td>-1.342185</td>
      <td>-0.635624</td>
      <td>-0.459948</td>
      <td>-0.059147</td>
      <td>-0.126591</td>
      <td>-1.356013</td>
      <td>-1.672023</td>
      <td>0.732605</td>
      <td>-0.178337</td>
      <td>-0.539120</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.725305</td>
      <td>4.558693e-01</td>
      <td>-0.148453</td>
      <td>-1.044337</td>
      <td>-0.459250</td>
      <td>-0.332093</td>
      <td>0.095864</td>
      <td>0.630756</td>
      <td>0.043196</td>
      <td>0.754991</td>
      <td>0.300343</td>
      <td>-0.095677</td>
      <td>0.123634</td>
      <td>0.975899</td>
      <td>0.644676</td>
      <td>0.231953</td>
      <td>-0.600767</td>
      <td>0.579488</td>
      <td>-0.543951</td>
      <td>-0.287925</td>
      <td>0.341875</td>
      <td>0.702624</td>
      <td>0.501644</td>
      <td>1.012983</td>
      <td>0.583397</td>
      <td>-0.029106</td>
      <td>-0.507468</td>
      <td>-0.274421</td>
      <td>-0.670540</td>
      <td>0.187510</td>
      <td>0.050920</td>
      <td>-0.555762</td>
      <td>-0.114750</td>
      <td>0.480608</td>
      <td>-0.406130</td>
      <td>-0.625076</td>
      <td>-0.275853</td>
      <td>0.744459</td>
      <td>-0.374381</td>
      <td>-0.019158</td>
      <td>...</td>
      <td>0.461302</td>
      <td>0.893731</td>
      <td>0.795257</td>
      <td>0.416009</td>
      <td>-0.702366</td>
      <td>-0.566990</td>
      <td>-0.018057</td>
      <td>0.336988</td>
      <td>1.828428</td>
      <td>0.133283</td>
      <td>0.845208</td>
      <td>-0.129385</td>
      <td>-0.885845</td>
      <td>0.681367</td>
      <td>-0.464413</td>
      <td>0.458708</td>
      <td>0.620524</td>
      <td>-0.901605</td>
      <td>-0.348624</td>
      <td>0.731910</td>
      <td>-0.602841</td>
      <td>-0.311057</td>
      <td>-0.413679</td>
      <td>0.264844</td>
      <td>0.341417</td>
      <td>0.404736</td>
      <td>-0.801841</td>
      <td>-0.932924</td>
      <td>0.243723</td>
      <td>-0.273990</td>
      <td>-0.138457</td>
      <td>-1.137421</td>
      <td>-1.243203</td>
      <td>-0.756017</td>
      <td>-0.121144</td>
      <td>0.984784</td>
      <td>0.003068</td>
      <td>-0.380628</td>
      <td>-1.096195</td>
      <td>-0.951146</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.930236</td>
      <td>5.011402e-01</td>
      <td>0.177396</td>
      <td>-0.220933</td>
      <td>-0.585691</td>
      <td>-0.725964</td>
      <td>-0.938710</td>
      <td>1.076915</td>
      <td>0.800561</td>
      <td>0.108081</td>
      <td>-0.152982</td>
      <td>-0.688146</td>
      <td>0.034004</td>
      <td>0.909256</td>
      <td>0.073292</td>
      <td>0.304882</td>
      <td>-0.213108</td>
      <td>-0.293623</td>
      <td>0.138074</td>
      <td>1.304814</td>
      <td>0.231916</td>
      <td>0.196415</td>
      <td>0.627498</td>
      <td>0.204107</td>
      <td>-0.251454</td>
      <td>0.328947</td>
      <td>-0.044206</td>
      <td>0.713410</td>
      <td>0.490115</td>
      <td>0.573575</td>
      <td>-0.106815</td>
      <td>-0.703517</td>
      <td>-1.723710</td>
      <td>-0.392443</td>
      <td>0.017891</td>
      <td>-0.554473</td>
      <td>-0.146497</td>
      <td>0.364483</td>
      <td>-0.663983</td>
      <td>-0.025581</td>
      <td>...</td>
      <td>0.414077</td>
      <td>-0.635072</td>
      <td>-0.267131</td>
      <td>-0.077152</td>
      <td>0.499453</td>
      <td>-0.141017</td>
      <td>0.791458</td>
      <td>0.497418</td>
      <td>1.240554</td>
      <td>-0.080443</td>
      <td>0.747030</td>
      <td>1.245025</td>
      <td>0.404881</td>
      <td>-0.041134</td>
      <td>-0.328889</td>
      <td>-0.762574</td>
      <td>0.090540</td>
      <td>0.167027</td>
      <td>0.066219</td>
      <td>-0.451309</td>
      <td>-0.767627</td>
      <td>-0.130127</td>
      <td>-0.556291</td>
      <td>-0.247172</td>
      <td>0.490559</td>
      <td>0.668007</td>
      <td>0.244772</td>
      <td>-0.089692</td>
      <td>-0.330263</td>
      <td>-0.203868</td>
      <td>-0.734996</td>
      <td>0.927913</td>
      <td>0.828652</td>
      <td>0.084865</td>
      <td>0.552033</td>
      <td>0.505096</td>
      <td>-0.098740</td>
      <td>2.109459</td>
      <td>1.747776</td>
      <td>0.801311</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.162193</td>
      <td>3.485240e-01</td>
      <td>0.462076</td>
      <td>-0.330233</td>
      <td>0.553963</td>
      <td>0.477888</td>
      <td>-0.798248</td>
      <td>0.113233</td>
      <td>0.871229</td>
      <td>1.045107</td>
      <td>0.710853</td>
      <td>-0.373519</td>
      <td>0.708608</td>
      <td>0.535832</td>
      <td>0.085590</td>
      <td>1.425209</td>
      <td>0.291264</td>
      <td>-0.551577</td>
      <td>-0.211628</td>
      <td>0.991719</td>
      <td>-0.185262</td>
      <td>0.208549</td>
      <td>-0.364158</td>
      <td>0.440051</td>
      <td>-0.266241</td>
      <td>0.179915</td>
      <td>0.905643</td>
      <td>1.192584</td>
      <td>-0.261728</td>
      <td>0.278251</td>
      <td>0.515343</td>
      <td>-0.058152</td>
      <td>-0.525275</td>
      <td>0.056237</td>
      <td>0.012165</td>
      <td>-0.896509</td>
      <td>0.147955</td>
      <td>0.428936</td>
      <td>1.741068</td>
      <td>-0.525268</td>
      <td>...</td>
      <td>0.513009</td>
      <td>0.563761</td>
      <td>-0.620792</td>
      <td>0.173535</td>
      <td>0.733944</td>
      <td>-0.419798</td>
      <td>-0.082125</td>
      <td>-1.279426</td>
      <td>0.060830</td>
      <td>0.258236</td>
      <td>0.823644</td>
      <td>0.411226</td>
      <td>-0.708409</td>
      <td>0.304469</td>
      <td>-0.561538</td>
      <td>0.452214</td>
      <td>-0.365430</td>
      <td>-1.518545</td>
      <td>0.136851</td>
      <td>0.124602</td>
      <td>0.249866</td>
      <td>0.252341</td>
      <td>1.012064</td>
      <td>0.172912</td>
      <td>0.571509</td>
      <td>-0.552706</td>
      <td>0.094484</td>
      <td>-0.621039</td>
      <td>0.119359</td>
      <td>-0.486050</td>
      <td>-0.761457</td>
      <td>-1.217055</td>
      <td>-0.831547</td>
      <td>0.688741</td>
      <td>0.758273</td>
      <td>0.409503</td>
      <td>-0.476819</td>
      <td>1.950864</td>
      <td>1.868111</td>
      <td>0.602144</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.231383</td>
      <td>2.080652e-03</td>
      <td>0.721636</td>
      <td>0.458100</td>
      <td>0.121279</td>
      <td>0.514481</td>
      <td>-1.140887</td>
      <td>0.069757</td>
      <td>-0.183954</td>
      <td>-0.278995</td>
      <td>0.475569</td>
      <td>-1.613065</td>
      <td>-0.886533</td>
      <td>-0.043425</td>
      <td>0.437705</td>
      <td>-0.267574</td>
      <td>-0.373405</td>
      <td>0.872445</td>
      <td>0.183278</td>
      <td>-0.146567</td>
      <td>-0.074033</td>
      <td>0.494004</td>
      <td>0.283397</td>
      <td>1.184527</td>
      <td>-0.441623</td>
      <td>0.519867</td>
      <td>0.681054</td>
      <td>-0.228952</td>
      <td>0.312615</td>
      <td>0.242983</td>
      <td>0.054452</td>
      <td>-0.553277</td>
      <td>-0.534323</td>
      <td>-0.035503</td>
      <td>-0.586654</td>
      <td>-0.485805</td>
      <td>0.449750</td>
      <td>0.658085</td>
      <td>0.355404</td>
      <td>-0.611123</td>
      <td>...</td>
      <td>0.827006</td>
      <td>1.375073</td>
      <td>-0.184329</td>
      <td>-0.794779</td>
      <td>0.346169</td>
      <td>0.423731</td>
      <td>-1.115491</td>
      <td>0.076485</td>
      <td>0.572236</td>
      <td>0.941454</td>
      <td>0.774558</td>
      <td>-0.348326</td>
      <td>-0.358783</td>
      <td>-0.130363</td>
      <td>-0.865086</td>
      <td>0.271106</td>
      <td>-0.826104</td>
      <td>-0.086704</td>
      <td>-0.439226</td>
      <td>-0.052741</td>
      <td>0.183050</td>
      <td>-0.584305</td>
      <td>0.493819</td>
      <td>-0.240153</td>
      <td>0.073730</td>
      <td>0.006174</td>
      <td>-0.732945</td>
      <td>0.082274</td>
      <td>0.741145</td>
      <td>-0.258029</td>
      <td>-0.036259</td>
      <td>-0.270529</td>
      <td>-0.039245</td>
      <td>0.374688</td>
      <td>0.520607</td>
      <td>0.262910</td>
      <td>-0.525961</td>
      <td>1.790873</td>
      <td>1.820594</td>
      <td>1.250331</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-0.877703</td>
      <td>-2.227303e-01</td>
      <td>0.630065</td>
      <td>-0.661614</td>
      <td>-0.393437</td>
      <td>-0.037737</td>
      <td>-1.100480</td>
      <td>0.206366</td>
      <td>-1.617531</td>
      <td>-0.636904</td>
      <td>0.196419</td>
      <td>0.349154</td>
      <td>0.398425</td>
      <td>-0.213159</td>
      <td>0.887681</td>
      <td>0.500595</td>
      <td>-0.263011</td>
      <td>-0.186397</td>
      <td>-0.666976</td>
      <td>-0.380867</td>
      <td>0.610674</td>
      <td>-0.352262</td>
      <td>0.146278</td>
      <td>0.398754</td>
      <td>0.010278</td>
      <td>-0.247869</td>
      <td>-0.106211</td>
      <td>-0.557823</td>
      <td>-0.865809</td>
      <td>-0.468142</td>
      <td>0.082879</td>
      <td>0.103950</td>
      <td>-0.531098</td>
      <td>-1.117855</td>
      <td>-0.325826</td>
      <td>-0.458458</td>
      <td>0.786891</td>
      <td>0.551995</td>
      <td>-0.176478</td>
      <td>0.625891</td>
      <td>...</td>
      <td>0.399503</td>
      <td>-0.751097</td>
      <td>0.259990</td>
      <td>-0.508078</td>
      <td>-0.922173</td>
      <td>-0.815648</td>
      <td>-0.419241</td>
      <td>-0.656751</td>
      <td>0.203524</td>
      <td>0.674110</td>
      <td>1.273993</td>
      <td>0.195975</td>
      <td>-0.258764</td>
      <td>0.428631</td>
      <td>-0.761589</td>
      <td>-0.119270</td>
      <td>-0.255870</td>
      <td>-0.431776</td>
      <td>-0.210812</td>
      <td>0.079109</td>
      <td>-0.674111</td>
      <td>-0.524543</td>
      <td>1.325695</td>
      <td>-0.090114</td>
      <td>-0.203698</td>
      <td>0.084381</td>
      <td>0.315055</td>
      <td>-0.218405</td>
      <td>-0.129972</td>
      <td>0.113021</td>
      <td>-0.883575</td>
      <td>-0.909704</td>
      <td>-0.394421</td>
      <td>0.678861</td>
      <td>0.027669</td>
      <td>0.768186</td>
      <td>-0.004351</td>
      <td>-0.069736</td>
      <td>0.480358</td>
      <td>0.371123</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.130929</td>
      <td>1.303189e+00</td>
      <td>0.277850</td>
      <td>-1.004633</td>
      <td>-0.226102</td>
      <td>0.084255</td>
      <td>-0.613532</td>
      <td>0.084504</td>
      <td>-0.315437</td>
      <td>0.393699</td>
      <td>-0.526112</td>
      <td>-0.782545</td>
      <td>-0.778139</td>
      <td>1.126801</td>
      <td>0.423420</td>
      <td>0.440742</td>
      <td>0.139405</td>
      <td>0.140983</td>
      <td>-0.577458</td>
      <td>-0.539126</td>
      <td>0.142296</td>
      <td>-0.343939</td>
      <td>-0.557491</td>
      <td>-0.320912</td>
      <td>-0.546556</td>
      <td>-1.232290</td>
      <td>-0.259476</td>
      <td>0.842907</td>
      <td>0.114215</td>
      <td>0.924872</td>
      <td>0.426691</td>
      <td>0.299716</td>
      <td>-0.359581</td>
      <td>0.355178</td>
      <td>0.780718</td>
      <td>-0.166872</td>
      <td>-0.712420</td>
      <td>-0.272164</td>
      <td>0.914511</td>
      <td>1.036121</td>
      <td>...</td>
      <td>0.447254</td>
      <td>0.358417</td>
      <td>0.148233</td>
      <td>-0.070231</td>
      <td>-0.415521</td>
      <td>-0.147253</td>
      <td>-0.007501</td>
      <td>0.155491</td>
      <td>0.242480</td>
      <td>0.529821</td>
      <td>1.362196</td>
      <td>-0.500290</td>
      <td>-0.382585</td>
      <td>-0.794769</td>
      <td>-1.291018</td>
      <td>-0.327647</td>
      <td>0.598673</td>
      <td>1.091617</td>
      <td>1.053713</td>
      <td>-0.406894</td>
      <td>-0.188788</td>
      <td>0.183112</td>
      <td>1.602021</td>
      <td>-0.022381</td>
      <td>0.577526</td>
      <td>1.054962</td>
      <td>0.140419</td>
      <td>0.072385</td>
      <td>-0.543856</td>
      <td>-0.475235</td>
      <td>-2.028435</td>
      <td>-1.583281</td>
      <td>-1.121875</td>
      <td>0.253563</td>
      <td>1.006771</td>
      <td>1.526142</td>
      <td>0.121830</td>
      <td>1.368492</td>
      <td>0.719515</td>
      <td>-0.012145</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.493535</td>
      <td>1.405013e+00</td>
      <td>0.125055</td>
      <td>-1.102008</td>
      <td>-0.272960</td>
      <td>0.517769</td>
      <td>-0.220877</td>
      <td>0.207347</td>
      <td>-0.187378</td>
      <td>0.065689</td>
      <td>0.320312</td>
      <td>0.204740</td>
      <td>0.801580</td>
      <td>0.602326</td>
      <td>-0.088055</td>
      <td>0.358712</td>
      <td>0.378331</td>
      <td>0.110535</td>
      <td>-1.968525</td>
      <td>-0.315816</td>
      <td>-0.142987</td>
      <td>-0.231888</td>
      <td>0.931981</td>
      <td>1.255315</td>
      <td>0.245921</td>
      <td>-1.068962</td>
      <td>-0.117567</td>
      <td>0.067820</td>
      <td>0.209973</td>
      <td>0.845574</td>
      <td>0.051863</td>
      <td>0.247496</td>
      <td>-0.186922</td>
      <td>0.175552</td>
      <td>0.114665</td>
      <td>-0.658513</td>
      <td>-0.379203</td>
      <td>-0.248812</td>
      <td>-0.174257</td>
      <td>-0.360409</td>
      <td>...</td>
      <td>-0.801876</td>
      <td>-0.265104</td>
      <td>-0.074422</td>
      <td>-0.973049</td>
      <td>-0.842620</td>
      <td>-1.140207</td>
      <td>-0.471441</td>
      <td>-0.322254</td>
      <td>0.795127</td>
      <td>0.617139</td>
      <td>1.761319</td>
      <td>0.184850</td>
      <td>0.181633</td>
      <td>-0.509427</td>
      <td>0.654802</td>
      <td>1.331468</td>
      <td>0.250400</td>
      <td>-1.105925</td>
      <td>1.161094</td>
      <td>0.916190</td>
      <td>-0.124116</td>
      <td>-1.199735</td>
      <td>-0.789528</td>
      <td>-0.500120</td>
      <td>0.874742</td>
      <td>0.633272</td>
      <td>-0.120955</td>
      <td>-0.329952</td>
      <td>0.953776</td>
      <td>-0.264766</td>
      <td>-1.094270</td>
      <td>-0.384467</td>
      <td>0.053888</td>
      <td>0.595023</td>
      <td>-0.195368</td>
      <td>-0.645817</td>
      <td>-0.187721</td>
      <td>1.693062</td>
      <td>0.942833</td>
      <td>0.691262</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-0.855262</td>
      <td>2.901029e-01</td>
      <td>0.091454</td>
      <td>0.185175</td>
      <td>-0.608449</td>
      <td>-1.113595</td>
      <td>0.274153</td>
      <td>-0.743378</td>
      <td>-0.419365</td>
      <td>-0.446036</td>
      <td>0.383942</td>
      <td>0.074501</td>
      <td>-0.218058</td>
      <td>0.463215</td>
      <td>-0.686473</td>
      <td>0.484495</td>
      <td>0.440941</td>
      <td>-0.026885</td>
      <td>0.391982</td>
      <td>0.626660</td>
      <td>0.418894</td>
      <td>1.030433</td>
      <td>-0.438886</td>
      <td>1.247159</td>
      <td>1.029867</td>
      <td>0.402651</td>
      <td>1.030201</td>
      <td>0.138070</td>
      <td>-0.523889</td>
      <td>1.202458</td>
      <td>-0.628964</td>
      <td>0.060188</td>
      <td>-0.249338</td>
      <td>1.129875</td>
      <td>-0.256663</td>
      <td>-0.147462</td>
      <td>-0.033211</td>
      <td>0.285077</td>
      <td>-0.123724</td>
      <td>0.028885</td>
      <td>...</td>
      <td>-0.495515</td>
      <td>-0.067273</td>
      <td>0.360482</td>
      <td>0.011793</td>
      <td>-0.479806</td>
      <td>-0.602232</td>
      <td>-1.922757</td>
      <td>0.372890</td>
      <td>0.837185</td>
      <td>0.678178</td>
      <td>0.478498</td>
      <td>0.084924</td>
      <td>-0.170068</td>
      <td>-1.204635</td>
      <td>-0.541636</td>
      <td>-0.386302</td>
      <td>-0.650653</td>
      <td>-0.827195</td>
      <td>0.097543</td>
      <td>-0.022366</td>
      <td>-0.244295</td>
      <td>-0.763773</td>
      <td>-0.327663</td>
      <td>-0.685176</td>
      <td>-0.668612</td>
      <td>-0.151186</td>
      <td>-0.490141</td>
      <td>-1.858801</td>
      <td>-0.230525</td>
      <td>-1.057800</td>
      <td>-0.065634</td>
      <td>-0.531213</td>
      <td>-0.686226</td>
      <td>0.483607</td>
      <td>0.058255</td>
      <td>-0.643041</td>
      <td>-0.980451</td>
      <td>-1.730890</td>
      <td>-1.096037</td>
      <td>-0.031354</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.421974</td>
      <td>4.881592e-01</td>
      <td>0.690362</td>
      <td>0.956661</td>
      <td>0.132612</td>
      <td>-0.438041</td>
      <td>-0.976992</td>
      <td>-0.019335</td>
      <td>-0.436750</td>
      <td>0.232711</td>
      <td>0.940495</td>
      <td>0.148882</td>
      <td>-0.549643</td>
      <td>0.981891</td>
      <td>0.958127</td>
      <td>0.764201</td>
      <td>0.061752</td>
      <td>0.392328</td>
      <td>0.470353</td>
      <td>0.869936</td>
      <td>0.184079</td>
      <td>0.288976</td>
      <td>-0.245626</td>
      <td>-0.562615</td>
      <td>-0.301798</td>
      <td>0.249802</td>
      <td>-0.082560</td>
      <td>-0.174691</td>
      <td>0.228391</td>
      <td>0.123109</td>
      <td>-0.368918</td>
      <td>0.215222</td>
      <td>0.559608</td>
      <td>0.261423</td>
      <td>-0.184346</td>
      <td>0.368411</td>
      <td>0.651183</td>
      <td>0.753882</td>
      <td>-0.779799</td>
      <td>-1.058333</td>
      <td>...</td>
      <td>-0.732952</td>
      <td>-0.138275</td>
      <td>0.542365</td>
      <td>0.269530</td>
      <td>-0.226811</td>
      <td>-0.441327</td>
      <td>-0.848630</td>
      <td>-0.545888</td>
      <td>-0.097977</td>
      <td>0.662795</td>
      <td>0.623431</td>
      <td>-0.733732</td>
      <td>0.229795</td>
      <td>-0.677594</td>
      <td>-0.803339</td>
      <td>0.205167</td>
      <td>0.177688</td>
      <td>-0.283791</td>
      <td>1.026137</td>
      <td>0.037356</td>
      <td>0.313333</td>
      <td>0.182664</td>
      <td>-0.435370</td>
      <td>0.144132</td>
      <td>-0.633426</td>
      <td>0.576361</td>
      <td>0.163702</td>
      <td>0.159668</td>
      <td>0.199048</td>
      <td>-0.886921</td>
      <td>-0.975530</td>
      <td>-0.375917</td>
      <td>0.179169</td>
      <td>0.219682</td>
      <td>0.260704</td>
      <td>0.725896</td>
      <td>-0.019489</td>
      <td>-0.566987</td>
      <td>-0.480881</td>
      <td>0.228490</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.956998</td>
      <td>4.310191e-01</td>
      <td>0.307898</td>
      <td>0.020073</td>
      <td>-0.019271</td>
      <td>-0.303155</td>
      <td>-1.330781</td>
      <td>-0.833022</td>
      <td>-0.817073</td>
      <td>-0.585651</td>
      <td>0.026319</td>
      <td>0.315210</td>
      <td>-0.562245</td>
      <td>0.116251</td>
      <td>0.764660</td>
      <td>-0.046045</td>
      <td>0.153292</td>
      <td>-0.358267</td>
      <td>-1.202835</td>
      <td>0.575506</td>
      <td>0.197452</td>
      <td>-0.180742</td>
      <td>0.273071</td>
      <td>0.226717</td>
      <td>1.152477</td>
      <td>0.985435</td>
      <td>-0.213488</td>
      <td>-0.623954</td>
      <td>0.549015</td>
      <td>1.023480</td>
      <td>-0.436756</td>
      <td>0.048804</td>
      <td>-0.708134</td>
      <td>-0.530411</td>
      <td>-0.008918</td>
      <td>-0.967100</td>
      <td>0.283569</td>
      <td>1.262591</td>
      <td>0.925755</td>
      <td>0.017265</td>
      <td>...</td>
      <td>-0.076029</td>
      <td>-0.806909</td>
      <td>0.123806</td>
      <td>0.957416</td>
      <td>0.327133</td>
      <td>0.338310</td>
      <td>-0.451438</td>
      <td>-0.827975</td>
      <td>0.783159</td>
      <td>0.756933</td>
      <td>0.804566</td>
      <td>-0.815463</td>
      <td>0.758727</td>
      <td>1.251375</td>
      <td>-0.023967</td>
      <td>0.782127</td>
      <td>0.398173</td>
      <td>-0.663826</td>
      <td>0.545156</td>
      <td>0.977031</td>
      <td>0.720394</td>
      <td>1.004611</td>
      <td>1.179437</td>
      <td>-0.966017</td>
      <td>-0.544511</td>
      <td>0.595380</td>
      <td>-0.209955</td>
      <td>0.008305</td>
      <td>0.164695</td>
      <td>-0.893531</td>
      <td>-0.852417</td>
      <td>-1.077619</td>
      <td>-0.458414</td>
      <td>0.365476</td>
      <td>0.033535</td>
      <td>-0.294969</td>
      <td>-0.189537</td>
      <td>0.225705</td>
      <td>-0.511893</td>
      <td>-0.664412</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.880400</td>
      <td>1.384340e-01</td>
      <td>-0.397817</td>
      <td>0.886868</td>
      <td>-0.428021</td>
      <td>0.141474</td>
      <td>-0.749384</td>
      <td>-0.919525</td>
      <td>-1.342298</td>
      <td>-0.319884</td>
      <td>0.127727</td>
      <td>-0.831323</td>
      <td>-1.206265</td>
      <td>0.144417</td>
      <td>0.721574</td>
      <td>0.398451</td>
      <td>0.331228</td>
      <td>0.238329</td>
      <td>0.402138</td>
      <td>-0.014169</td>
      <td>-0.114168</td>
      <td>0.890984</td>
      <td>0.975842</td>
      <td>0.248480</td>
      <td>-0.622546</td>
      <td>-0.140306</td>
      <td>-0.911845</td>
      <td>-0.209674</td>
      <td>0.067347</td>
      <td>-0.250637</td>
      <td>-0.446478</td>
      <td>-0.086068</td>
      <td>-1.019101</td>
      <td>-0.474089</td>
      <td>-0.029701</td>
      <td>-0.030325</td>
      <td>0.388575</td>
      <td>-0.755112</td>
      <td>0.086097</td>
      <td>0.104943</td>
      <td>...</td>
      <td>-0.265889</td>
      <td>0.363941</td>
      <td>1.216277</td>
      <td>0.035672</td>
      <td>0.057777</td>
      <td>0.478750</td>
      <td>-0.117012</td>
      <td>-0.420864</td>
      <td>0.883225</td>
      <td>-0.177233</td>
      <td>0.589044</td>
      <td>-0.657002</td>
      <td>-0.507144</td>
      <td>-0.076138</td>
      <td>-0.680230</td>
      <td>0.027284</td>
      <td>0.562682</td>
      <td>-0.472472</td>
      <td>0.236516</td>
      <td>0.323216</td>
      <td>0.163799</td>
      <td>-0.391137</td>
      <td>-0.038203</td>
      <td>0.399776</td>
      <td>0.068960</td>
      <td>0.250530</td>
      <td>-0.580940</td>
      <td>-0.008864</td>
      <td>0.494584</td>
      <td>-0.283911</td>
      <td>-0.799500</td>
      <td>-0.343749</td>
      <td>-0.361687</td>
      <td>1.194991</td>
      <td>0.475434</td>
      <td>0.607623</td>
      <td>-0.350675</td>
      <td>1.895203</td>
      <td>1.096230</td>
      <td>1.608426</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.706375</td>
      <td>-1.203167e-01</td>
      <td>-0.046791</td>
      <td>-0.547796</td>
      <td>1.022326</td>
      <td>-0.629853</td>
      <td>-0.260094</td>
      <td>0.351903</td>
      <td>-0.556620</td>
      <td>0.139743</td>
      <td>0.241113</td>
      <td>0.036429</td>
      <td>-0.394481</td>
      <td>-0.150995</td>
      <td>1.195169</td>
      <td>0.744018</td>
      <td>0.709486</td>
      <td>0.579571</td>
      <td>-0.367222</td>
      <td>-0.075265</td>
      <td>0.417885</td>
      <td>0.480469</td>
      <td>0.270636</td>
      <td>-0.509894</td>
      <td>0.315863</td>
      <td>-0.515752</td>
      <td>0.047431</td>
      <td>-0.576030</td>
      <td>1.046516</td>
      <td>0.772170</td>
      <td>-0.647471</td>
      <td>-0.672073</td>
      <td>-0.509251</td>
      <td>0.142426</td>
      <td>-0.426431</td>
      <td>-0.595629</td>
      <td>-0.551554</td>
      <td>-1.182980</td>
      <td>0.953562</td>
      <td>-0.233274</td>
      <td>...</td>
      <td>-1.490990</td>
      <td>-0.472090</td>
      <td>0.040872</td>
      <td>-0.153059</td>
      <td>-0.795086</td>
      <td>-0.300893</td>
      <td>0.585593</td>
      <td>-0.702716</td>
      <td>-0.311633</td>
      <td>-0.186251</td>
      <td>-0.096502</td>
      <td>-0.246343</td>
      <td>-0.919019</td>
      <td>0.454378</td>
      <td>0.229332</td>
      <td>0.126741</td>
      <td>-0.092841</td>
      <td>-0.043167</td>
      <td>0.196928</td>
      <td>0.174661</td>
      <td>0.110633</td>
      <td>-0.380861</td>
      <td>0.181689</td>
      <td>-0.102106</td>
      <td>1.091232</td>
      <td>0.236222</td>
      <td>-1.249078</td>
      <td>0.332389</td>
      <td>0.256372</td>
      <td>-0.176327</td>
      <td>-0.750505</td>
      <td>-0.834091</td>
      <td>-1.043971</td>
      <td>-0.601029</td>
      <td>-0.266125</td>
      <td>-0.291772</td>
      <td>-0.417009</td>
      <td>2.456438</td>
      <td>2.097791</td>
      <td>1.114666</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.621363</td>
      <td>-3.362344e-02</td>
      <td>-0.486267</td>
      <td>-0.060226</td>
      <td>0.550301</td>
      <td>1.123463</td>
      <td>-0.516438</td>
      <td>0.032444</td>
      <td>-0.691579</td>
      <td>-0.103699</td>
      <td>-0.107595</td>
      <td>-0.459134</td>
      <td>-1.550270</td>
      <td>-0.781274</td>
      <td>-0.239609</td>
      <td>-0.440017</td>
      <td>-0.418274</td>
      <td>0.427023</td>
      <td>0.493432</td>
      <td>0.785451</td>
      <td>-0.476325</td>
      <td>-0.181099</td>
      <td>-0.525579</td>
      <td>0.703955</td>
      <td>0.895686</td>
      <td>-0.847493</td>
      <td>-0.876755</td>
      <td>1.278859</td>
      <td>0.128625</td>
      <td>-0.311305</td>
      <td>0.148192</td>
      <td>0.503132</td>
      <td>-0.216809</td>
      <td>0.515840</td>
      <td>-0.725384</td>
      <td>-2.457794</td>
      <td>0.160536</td>
      <td>-0.061317</td>
      <td>0.664371</td>
      <td>-0.660675</td>
      <td>...</td>
      <td>-0.672719</td>
      <td>0.056678</td>
      <td>0.282764</td>
      <td>-0.336545</td>
      <td>0.671326</td>
      <td>0.348017</td>
      <td>-0.659604</td>
      <td>-0.464645</td>
      <td>1.528464</td>
      <td>0.810704</td>
      <td>1.802951</td>
      <td>0.911264</td>
      <td>-0.079522</td>
      <td>-0.026483</td>
      <td>-0.368491</td>
      <td>0.014271</td>
      <td>-0.387768</td>
      <td>-0.852872</td>
      <td>-0.013199</td>
      <td>-0.285863</td>
      <td>-0.215603</td>
      <td>-0.656899</td>
      <td>-0.471664</td>
      <td>-0.500652</td>
      <td>-0.275458</td>
      <td>0.212174</td>
      <td>-1.001034</td>
      <td>0.471045</td>
      <td>0.925646</td>
      <td>0.366983</td>
      <td>0.308138</td>
      <td>0.182711</td>
      <td>-0.088520</td>
      <td>0.911952</td>
      <td>0.767901</td>
      <td>0.772706</td>
      <td>-0.649064</td>
      <td>2.697722</td>
      <td>1.990399</td>
      <td>1.214369</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.172269</td>
      <td>-4.018255e-01</td>
      <td>-0.325088</td>
      <td>-0.060240</td>
      <td>0.249431</td>
      <td>0.482980</td>
      <td>-0.729826</td>
      <td>0.020801</td>
      <td>-0.491222</td>
      <td>0.415285</td>
      <td>0.532257</td>
      <td>-0.515915</td>
      <td>-0.357003</td>
      <td>0.140726</td>
      <td>1.169989</td>
      <td>1.078298</td>
      <td>0.130230</td>
      <td>0.829477</td>
      <td>0.143929</td>
      <td>-0.451943</td>
      <td>-0.119985</td>
      <td>0.256268</td>
      <td>-0.526213</td>
      <td>0.780707</td>
      <td>0.330324</td>
      <td>0.064602</td>
      <td>0.555091</td>
      <td>-0.026344</td>
      <td>-0.023050</td>
      <td>-0.084941</td>
      <td>-0.686658</td>
      <td>0.020105</td>
      <td>0.441523</td>
      <td>0.011581</td>
      <td>-0.002386</td>
      <td>-0.249563</td>
      <td>-0.261940</td>
      <td>0.023048</td>
      <td>0.586348</td>
      <td>-0.233123</td>
      <td>...</td>
      <td>0.484430</td>
      <td>0.224478</td>
      <td>0.857242</td>
      <td>0.500741</td>
      <td>-0.186205</td>
      <td>0.452403</td>
      <td>-0.282275</td>
      <td>-0.622952</td>
      <td>0.740352</td>
      <td>1.045213</td>
      <td>0.991553</td>
      <td>-1.060938</td>
      <td>-0.350219</td>
      <td>-0.290243</td>
      <td>-0.391453</td>
      <td>0.653251</td>
      <td>1.270041</td>
      <td>-0.559526</td>
      <td>0.565027</td>
      <td>0.919130</td>
      <td>0.424337</td>
      <td>-0.194875</td>
      <td>-0.478009</td>
      <td>0.108366</td>
      <td>0.734800</td>
      <td>-0.254094</td>
      <td>-0.105612</td>
      <td>-1.016935</td>
      <td>-0.529860</td>
      <td>0.581200</td>
      <td>-0.620301</td>
      <td>-0.698218</td>
      <td>0.105351</td>
      <td>-0.108163</td>
      <td>0.251848</td>
      <td>-0.261256</td>
      <td>-1.001412</td>
      <td>-0.693958</td>
      <td>-0.894508</td>
      <td>-0.887034</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.263990</td>
      <td>6.246431e-01</td>
      <td>0.001837</td>
      <td>0.583435</td>
      <td>0.525777</td>
      <td>-0.628463</td>
      <td>-0.100345</td>
      <td>0.057023</td>
      <td>-0.244648</td>
      <td>-0.215873</td>
      <td>-0.000357</td>
      <td>0.528129</td>
      <td>0.649150</td>
      <td>-0.014034</td>
      <td>0.794604</td>
      <td>0.198621</td>
      <td>-0.635161</td>
      <td>-0.372407</td>
      <td>-0.119728</td>
      <td>0.741423</td>
      <td>-0.111727</td>
      <td>-0.048531</td>
      <td>0.571996</td>
      <td>-0.560005</td>
      <td>-0.947203</td>
      <td>-0.499851</td>
      <td>-0.166622</td>
      <td>-0.317065</td>
      <td>0.297525</td>
      <td>0.982434</td>
      <td>0.859226</td>
      <td>0.075893</td>
      <td>-0.497673</td>
      <td>-0.999214</td>
      <td>-0.037275</td>
      <td>0.180251</td>
      <td>0.829826</td>
      <td>0.005014</td>
      <td>0.655309</td>
      <td>0.033448</td>
      <td>...</td>
      <td>1.077469</td>
      <td>0.547136</td>
      <td>1.792041</td>
      <td>-0.233395</td>
      <td>-0.413559</td>
      <td>0.265287</td>
      <td>0.420184</td>
      <td>0.361383</td>
      <td>-0.034993</td>
      <td>0.245612</td>
      <td>0.337990</td>
      <td>-0.579940</td>
      <td>-0.160641</td>
      <td>-0.174855</td>
      <td>0.363740</td>
      <td>0.448976</td>
      <td>0.906205</td>
      <td>-0.163707</td>
      <td>-0.078079</td>
      <td>-0.210470</td>
      <td>-0.845149</td>
      <td>-0.394220</td>
      <td>-0.379107</td>
      <td>0.373640</td>
      <td>0.173710</td>
      <td>-0.030049</td>
      <td>-0.219790</td>
      <td>-0.391573</td>
      <td>0.276755</td>
      <td>-1.018447</td>
      <td>-0.820042</td>
      <td>0.237584</td>
      <td>-0.221782</td>
      <td>0.500438</td>
      <td>-1.137542</td>
      <td>-0.357847</td>
      <td>0.026825</td>
      <td>0.567710</td>
      <td>0.939237</td>
      <td>0.433925</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.778778</td>
      <td>-8.257716e-02</td>
      <td>0.587985</td>
      <td>-0.244783</td>
      <td>0.889411</td>
      <td>0.635342</td>
      <td>-0.203866</td>
      <td>-0.487411</td>
      <td>-0.503619</td>
      <td>-0.350058</td>
      <td>0.718019</td>
      <td>-0.202815</td>
      <td>-0.961464</td>
      <td>0.003870</td>
      <td>0.709082</td>
      <td>0.188057</td>
      <td>0.104797</td>
      <td>0.840154</td>
      <td>-0.232074</td>
      <td>-0.491531</td>
      <td>-0.576727</td>
      <td>-0.676054</td>
      <td>-0.117039</td>
      <td>0.752325</td>
      <td>0.444082</td>
      <td>-0.696132</td>
      <td>-1.460264</td>
      <td>0.028167</td>
      <td>-0.177138</td>
      <td>0.109598</td>
      <td>0.539772</td>
      <td>0.072568</td>
      <td>-0.074768</td>
      <td>-0.488303</td>
      <td>-0.450162</td>
      <td>-0.197749</td>
      <td>-0.490326</td>
      <td>0.429769</td>
      <td>1.241526</td>
      <td>0.865848</td>
      <td>...</td>
      <td>0.803386</td>
      <td>1.276715</td>
      <td>0.623003</td>
      <td>0.045061</td>
      <td>-0.462711</td>
      <td>-0.994313</td>
      <td>0.182925</td>
      <td>-1.204940</td>
      <td>-0.155070</td>
      <td>-0.328063</td>
      <td>1.361604</td>
      <td>0.935855</td>
      <td>0.497471</td>
      <td>-0.125058</td>
      <td>-0.779978</td>
      <td>0.649454</td>
      <td>0.411436</td>
      <td>-0.793827</td>
      <td>0.747983</td>
      <td>-0.061754</td>
      <td>0.420654</td>
      <td>-0.860441</td>
      <td>0.398956</td>
      <td>-0.780201</td>
      <td>1.001372</td>
      <td>0.595843</td>
      <td>-0.129734</td>
      <td>-0.520576</td>
      <td>-0.203221</td>
      <td>-0.866076</td>
      <td>-0.135875</td>
      <td>-0.533811</td>
      <td>-0.009252</td>
      <td>-0.370825</td>
      <td>0.538233</td>
      <td>1.560763</td>
      <td>-0.762063</td>
      <td>-0.279949</td>
      <td>-0.469230</td>
      <td>-0.216363</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.653461</td>
      <td>6.740092e-01</td>
      <td>0.159841</td>
      <td>0.220431</td>
      <td>-0.507505</td>
      <td>-0.321222</td>
      <td>-1.011285</td>
      <td>0.504044</td>
      <td>-0.159983</td>
      <td>-0.165173</td>
      <td>0.338141</td>
      <td>-0.605843</td>
      <td>-1.057074</td>
      <td>-0.526710</td>
      <td>0.444945</td>
      <td>0.584119</td>
      <td>-1.191232</td>
      <td>-0.550126</td>
      <td>0.610922</td>
      <td>-0.683155</td>
      <td>-0.222325</td>
      <td>-0.269308</td>
      <td>0.907818</td>
      <td>0.898100</td>
      <td>-0.160837</td>
      <td>-0.764566</td>
      <td>0.450108</td>
      <td>0.907099</td>
      <td>-0.009664</td>
      <td>0.213888</td>
      <td>-0.165373</td>
      <td>-1.187022</td>
      <td>-0.345091</td>
      <td>-0.495995</td>
      <td>0.868272</td>
      <td>-0.169787</td>
      <td>0.733583</td>
      <td>-0.147405</td>
      <td>0.308888</td>
      <td>-0.284935</td>
      <td>...</td>
      <td>0.008652</td>
      <td>0.278505</td>
      <td>-0.008498</td>
      <td>0.097378</td>
      <td>-0.559643</td>
      <td>-0.434979</td>
      <td>0.174646</td>
      <td>-0.092242</td>
      <td>0.516599</td>
      <td>-0.112144</td>
      <td>0.181513</td>
      <td>0.603012</td>
      <td>-0.086850</td>
      <td>-0.420861</td>
      <td>-0.326731</td>
      <td>0.551023</td>
      <td>0.196684</td>
      <td>0.457076</td>
      <td>-0.106373</td>
      <td>-0.658857</td>
      <td>0.277225</td>
      <td>-0.360759</td>
      <td>-0.157812</td>
      <td>0.469644</td>
      <td>-0.035548</td>
      <td>-0.327896</td>
      <td>0.375811</td>
      <td>-0.459901</td>
      <td>-0.135350</td>
      <td>-1.003309</td>
      <td>-0.493070</td>
      <td>-0.246468</td>
      <td>-0.591402</td>
      <td>0.180190</td>
      <td>0.068812</td>
      <td>-0.249114</td>
      <td>-0.823055</td>
      <td>1.156074</td>
      <td>0.944252</td>
      <td>0.427001</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.119169</td>
      <td>-9.013711e-08</td>
      <td>-0.100443</td>
      <td>-0.301714</td>
      <td>0.501509</td>
      <td>0.313629</td>
      <td>0.333481</td>
      <td>0.250884</td>
      <td>-0.866104</td>
      <td>0.069663</td>
      <td>0.761192</td>
      <td>0.114797</td>
      <td>0.414951</td>
      <td>1.108886</td>
      <td>1.237968</td>
      <td>0.258684</td>
      <td>-0.141057</td>
      <td>0.807183</td>
      <td>0.499724</td>
      <td>0.276107</td>
      <td>-0.352498</td>
      <td>-0.208215</td>
      <td>0.268901</td>
      <td>0.528325</td>
      <td>0.189517</td>
      <td>-0.449987</td>
      <td>0.418801</td>
      <td>0.526053</td>
      <td>0.558729</td>
      <td>0.344868</td>
      <td>0.789767</td>
      <td>-0.735559</td>
      <td>0.247640</td>
      <td>-0.142945</td>
      <td>0.456830</td>
      <td>-0.147554</td>
      <td>-0.619191</td>
      <td>-0.104207</td>
      <td>-0.179832</td>
      <td>0.123499</td>
      <td>...</td>
      <td>-0.018584</td>
      <td>-0.490195</td>
      <td>0.279801</td>
      <td>0.260450</td>
      <td>0.301675</td>
      <td>0.348227</td>
      <td>0.499217</td>
      <td>0.879721</td>
      <td>1.233411</td>
      <td>1.105293</td>
      <td>1.748132</td>
      <td>1.258143</td>
      <td>0.538316</td>
      <td>0.634802</td>
      <td>-0.259244</td>
      <td>0.311840</td>
      <td>0.034683</td>
      <td>-0.040873</td>
      <td>-0.211497</td>
      <td>-0.053543</td>
      <td>-0.725949</td>
      <td>-1.031712</td>
      <td>-0.519837</td>
      <td>-0.870793</td>
      <td>-0.238530</td>
      <td>0.023091</td>
      <td>-1.017160</td>
      <td>-0.634623</td>
      <td>-1.054132</td>
      <td>-0.865241</td>
      <td>-0.854798</td>
      <td>-0.577307</td>
      <td>-1.098267</td>
      <td>-0.410792</td>
      <td>-0.461620</td>
      <td>0.141588</td>
      <td>0.662722</td>
      <td>-0.487534</td>
      <td>0.024238</td>
      <td>-0.685813</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.317108</td>
      <td>-4.896280e-01</td>
      <td>0.082721</td>
      <td>0.199798</td>
      <td>0.819033</td>
      <td>0.026637</td>
      <td>0.418439</td>
      <td>0.193057</td>
      <td>-0.393548</td>
      <td>0.048958</td>
      <td>0.499278</td>
      <td>-1.207311</td>
      <td>-0.893101</td>
      <td>0.327737</td>
      <td>0.168720</td>
      <td>-0.848947</td>
      <td>0.145747</td>
      <td>-0.633210</td>
      <td>-0.195984</td>
      <td>0.734722</td>
      <td>-0.149790</td>
      <td>0.894980</td>
      <td>-0.075437</td>
      <td>0.542787</td>
      <td>-0.816626</td>
      <td>-1.286737</td>
      <td>-1.117987</td>
      <td>-0.303954</td>
      <td>-0.071502</td>
      <td>-0.001060</td>
      <td>1.619333</td>
      <td>-0.450445</td>
      <td>-0.441953</td>
      <td>-0.209443</td>
      <td>0.570423</td>
      <td>-0.367066</td>
      <td>0.392358</td>
      <td>-0.297335</td>
      <td>-0.263543</td>
      <td>-0.747815</td>
      <td>...</td>
      <td>0.915359</td>
      <td>0.535250</td>
      <td>0.135882</td>
      <td>-0.016829</td>
      <td>-0.717866</td>
      <td>0.125333</td>
      <td>1.126657</td>
      <td>0.975899</td>
      <td>1.093510</td>
      <td>0.069845</td>
      <td>1.094461</td>
      <td>0.053211</td>
      <td>-0.508254</td>
      <td>-0.478601</td>
      <td>-0.153886</td>
      <td>0.180879</td>
      <td>0.086396</td>
      <td>0.035870</td>
      <td>0.421495</td>
      <td>0.207194</td>
      <td>0.454070</td>
      <td>0.467528</td>
      <td>0.468141</td>
      <td>-0.013579</td>
      <td>0.242031</td>
      <td>-0.154675</td>
      <td>-0.436039</td>
      <td>0.347734</td>
      <td>0.136015</td>
      <td>-1.123448</td>
      <td>-0.730960</td>
      <td>-0.609150</td>
      <td>-0.694324</td>
      <td>-0.239495</td>
      <td>-0.317638</td>
      <td>0.443098</td>
      <td>-0.950574</td>
      <td>1.067339</td>
      <td>1.148732</td>
      <td>0.217716</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-1.449969</td>
      <td>-1.196739e+00</td>
      <td>0.405239</td>
      <td>-0.175564</td>
      <td>0.197669</td>
      <td>-0.328857</td>
      <td>-0.416052</td>
      <td>0.296415</td>
      <td>-0.228710</td>
      <td>0.571831</td>
      <td>0.422149</td>
      <td>-0.729316</td>
      <td>-1.336301</td>
      <td>-0.043544</td>
      <td>0.183402</td>
      <td>0.631531</td>
      <td>0.480860</td>
      <td>0.446960</td>
      <td>-0.090872</td>
      <td>0.321077</td>
      <td>0.447674</td>
      <td>0.195559</td>
      <td>0.321481</td>
      <td>0.029731</td>
      <td>0.209131</td>
      <td>0.695840</td>
      <td>0.203171</td>
      <td>0.946422</td>
      <td>0.355468</td>
      <td>0.437892</td>
      <td>0.453447</td>
      <td>0.144796</td>
      <td>0.071487</td>
      <td>-0.408928</td>
      <td>-0.331862</td>
      <td>-1.540422</td>
      <td>-0.495793</td>
      <td>-1.047884</td>
      <td>0.067335</td>
      <td>-1.085539</td>
      <td>...</td>
      <td>-0.060754</td>
      <td>0.704501</td>
      <td>-0.053353</td>
      <td>0.102645</td>
      <td>-0.518951</td>
      <td>-0.372623</td>
      <td>0.228315</td>
      <td>-0.433253</td>
      <td>0.173524</td>
      <td>0.012690</td>
      <td>-0.427798</td>
      <td>-0.302388</td>
      <td>0.234869</td>
      <td>-0.212104</td>
      <td>-0.401164</td>
      <td>1.201778</td>
      <td>-0.172386</td>
      <td>0.077249</td>
      <td>1.882993</td>
      <td>1.054540</td>
      <td>0.496748</td>
      <td>0.232467</td>
      <td>0.858337</td>
      <td>0.176037</td>
      <td>0.152217</td>
      <td>0.378679</td>
      <td>0.140383</td>
      <td>-0.382463</td>
      <td>-0.465986</td>
      <td>-1.196676</td>
      <td>-0.891126</td>
      <td>-0.369332</td>
      <td>0.663997</td>
      <td>0.804724</td>
      <td>0.843838</td>
      <td>-0.961186</td>
      <td>-0.728917</td>
      <td>-1.237683</td>
      <td>-1.220707</td>
      <td>-0.213960</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.111300</td>
      <td>-4.814922e-01</td>
      <td>-0.450692</td>
      <td>0.724726</td>
      <td>0.760890</td>
      <td>-0.807459</td>
      <td>-1.028756</td>
      <td>-1.597526</td>
      <td>-0.612134</td>
      <td>-0.949934</td>
      <td>-0.730025</td>
      <td>-0.924303</td>
      <td>0.203552</td>
      <td>0.501399</td>
      <td>-0.706703</td>
      <td>-1.431277</td>
      <td>-0.425808</td>
      <td>0.636347</td>
      <td>0.344336</td>
      <td>-0.110208</td>
      <td>0.107290</td>
      <td>-0.215934</td>
      <td>-0.206345</td>
      <td>-0.047311</td>
      <td>-1.429339</td>
      <td>0.194312</td>
      <td>0.588376</td>
      <td>-0.071233</td>
      <td>0.209723</td>
      <td>-0.271224</td>
      <td>-1.615610</td>
      <td>-0.235270</td>
      <td>0.314525</td>
      <td>0.301195</td>
      <td>-0.306550</td>
      <td>0.251246</td>
      <td>-0.726430</td>
      <td>0.307580</td>
      <td>-0.688666</td>
      <td>-0.769506</td>
      <td>...</td>
      <td>-0.062691</td>
      <td>0.406977</td>
      <td>-0.607080</td>
      <td>-0.127351</td>
      <td>-0.739401</td>
      <td>-0.083513</td>
      <td>-0.890958</td>
      <td>-0.227124</td>
      <td>-0.911422</td>
      <td>-0.468871</td>
      <td>-0.507300</td>
      <td>0.011733</td>
      <td>-1.163921</td>
      <td>0.089887</td>
      <td>0.390248</td>
      <td>-0.046140</td>
      <td>-0.375647</td>
      <td>-0.209164</td>
      <td>-0.418120</td>
      <td>0.408115</td>
      <td>1.268383</td>
      <td>0.709123</td>
      <td>0.243711</td>
      <td>-0.069425</td>
      <td>-0.302936</td>
      <td>-0.444086</td>
      <td>0.123808</td>
      <td>0.444041</td>
      <td>0.439573</td>
      <td>0.711769</td>
      <td>-1.137318</td>
      <td>-0.828078</td>
      <td>-1.281777</td>
      <td>-0.375728</td>
      <td>-0.223165</td>
      <td>-0.204060</td>
      <td>1.895429</td>
      <td>-0.717511</td>
      <td>0.142851</td>
      <td>0.999952</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.224596</td>
      <td>-1.519165e+00</td>
      <td>0.917993</td>
      <td>0.750155</td>
      <td>0.460403</td>
      <td>0.842810</td>
      <td>0.380388</td>
      <td>-0.161072</td>
      <td>-0.551466</td>
      <td>-0.704974</td>
      <td>1.542068</td>
      <td>-0.734437</td>
      <td>0.146722</td>
      <td>0.593013</td>
      <td>-0.152762</td>
      <td>0.138783</td>
      <td>0.409895</td>
      <td>-0.161918</td>
      <td>-0.054180</td>
      <td>-1.375684</td>
      <td>-0.598598</td>
      <td>0.097269</td>
      <td>0.843934</td>
      <td>1.172967</td>
      <td>-1.201215</td>
      <td>0.254168</td>
      <td>-0.255233</td>
      <td>-0.372389</td>
      <td>0.081302</td>
      <td>-0.362374</td>
      <td>-0.519010</td>
      <td>-0.853657</td>
      <td>-0.223632</td>
      <td>1.249240</td>
      <td>1.162101</td>
      <td>-0.262661</td>
      <td>0.583606</td>
      <td>0.669270</td>
      <td>0.029491</td>
      <td>-0.636200</td>
      <td>...</td>
      <td>0.574450</td>
      <td>0.837750</td>
      <td>0.389681</td>
      <td>0.067407</td>
      <td>-0.388172</td>
      <td>0.687398</td>
      <td>-1.233956</td>
      <td>-0.041229</td>
      <td>-0.422116</td>
      <td>-0.299391</td>
      <td>0.318631</td>
      <td>-0.708505</td>
      <td>0.671730</td>
      <td>0.087768</td>
      <td>-0.010035</td>
      <td>0.445787</td>
      <td>-0.786107</td>
      <td>-0.853936</td>
      <td>-0.522758</td>
      <td>-0.211139</td>
      <td>0.124439</td>
      <td>0.260236</td>
      <td>0.295926</td>
      <td>0.268434</td>
      <td>-0.154759</td>
      <td>-1.649274</td>
      <td>-0.676344</td>
      <td>0.951231</td>
      <td>0.723222</td>
      <td>0.051455</td>
      <td>0.585874</td>
      <td>0.460095</td>
      <td>-0.287074</td>
      <td>0.694520</td>
      <td>-0.404586</td>
      <td>-0.298923</td>
      <td>0.387750</td>
      <td>0.481069</td>
      <td>0.643083</td>
      <td>0.918343</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.142337</td>
      <td>-1.340411e+00</td>
      <td>0.620696</td>
      <td>0.987874</td>
      <td>0.952254</td>
      <td>-0.569502</td>
      <td>-0.172878</td>
      <td>-0.485203</td>
      <td>-0.397475</td>
      <td>0.102538</td>
      <td>0.039139</td>
      <td>-0.097613</td>
      <td>-0.057763</td>
      <td>-0.216160</td>
      <td>0.119469</td>
      <td>-0.063924</td>
      <td>-0.588414</td>
      <td>-0.911964</td>
      <td>0.930289</td>
      <td>0.037160</td>
      <td>-1.082246</td>
      <td>0.499505</td>
      <td>0.018118</td>
      <td>0.351958</td>
      <td>-0.330112</td>
      <td>-0.115259</td>
      <td>-1.116871</td>
      <td>-0.625265</td>
      <td>-0.705615</td>
      <td>0.523841</td>
      <td>-0.944337</td>
      <td>-0.034722</td>
      <td>0.112541</td>
      <td>0.441199</td>
      <td>-0.379000</td>
      <td>-0.065431</td>
      <td>-0.734310</td>
      <td>1.097822</td>
      <td>-0.232230</td>
      <td>-0.742007</td>
      <td>...</td>
      <td>0.118653</td>
      <td>0.558904</td>
      <td>1.016131</td>
      <td>-0.027937</td>
      <td>-0.613262</td>
      <td>-0.365036</td>
      <td>0.363781</td>
      <td>-0.929939</td>
      <td>-0.917715</td>
      <td>-0.730901</td>
      <td>-0.417545</td>
      <td>-1.079047</td>
      <td>-0.235145</td>
      <td>-0.898813</td>
      <td>0.456305</td>
      <td>0.606710</td>
      <td>1.208665</td>
      <td>0.167181</td>
      <td>-0.498708</td>
      <td>0.530293</td>
      <td>0.828266</td>
      <td>1.025203</td>
      <td>0.382450</td>
      <td>0.275224</td>
      <td>0.482423</td>
      <td>0.095624</td>
      <td>1.089607</td>
      <td>0.403865</td>
      <td>-0.484666</td>
      <td>-0.691010</td>
      <td>-0.154215</td>
      <td>-0.953677</td>
      <td>-0.697491</td>
      <td>-0.476377</td>
      <td>0.485881</td>
      <td>-0.803119</td>
      <td>-0.232070</td>
      <td>-1.002768</td>
      <td>0.008586</td>
      <td>0.588701</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.240600</td>
      <td>9.393589e-01</td>
      <td>0.572305</td>
      <td>0.729313</td>
      <td>0.747029</td>
      <td>-0.486952</td>
      <td>-0.333666</td>
      <td>0.865163</td>
      <td>-0.587753</td>
      <td>-0.655153</td>
      <td>-0.088749</td>
      <td>-0.150866</td>
      <td>-0.069533</td>
      <td>0.427818</td>
      <td>-1.074090</td>
      <td>-0.396831</td>
      <td>0.376690</td>
      <td>0.267790</td>
      <td>0.702801</td>
      <td>0.402073</td>
      <td>-0.298629</td>
      <td>-0.926430</td>
      <td>-0.230691</td>
      <td>0.084970</td>
      <td>-0.556677</td>
      <td>0.771281</td>
      <td>-0.229199</td>
      <td>1.222492</td>
      <td>0.308606</td>
      <td>1.434027</td>
      <td>-0.131071</td>
      <td>0.628686</td>
      <td>0.538143</td>
      <td>0.320041</td>
      <td>-0.076699</td>
      <td>0.941358</td>
      <td>-0.136960</td>
      <td>0.629081</td>
      <td>-0.564536</td>
      <td>0.251811</td>
      <td>...</td>
      <td>0.885479</td>
      <td>-0.360933</td>
      <td>0.322619</td>
      <td>-0.712975</td>
      <td>-0.060290</td>
      <td>0.178393</td>
      <td>0.184788</td>
      <td>0.896781</td>
      <td>-0.342756</td>
      <td>-0.287865</td>
      <td>0.515871</td>
      <td>0.222530</td>
      <td>0.599339</td>
      <td>0.298621</td>
      <td>0.170084</td>
      <td>-0.166397</td>
      <td>-0.687110</td>
      <td>-0.644776</td>
      <td>0.256010</td>
      <td>0.351301</td>
      <td>-0.270981</td>
      <td>1.516167</td>
      <td>0.288069</td>
      <td>-0.541683</td>
      <td>0.579492</td>
      <td>-0.503982</td>
      <td>2.183290</td>
      <td>1.021483</td>
      <td>0.154211</td>
      <td>0.226112</td>
      <td>-0.166567</td>
      <td>-0.167693</td>
      <td>-0.499599</td>
      <td>-0.157010</td>
      <td>0.434913</td>
      <td>0.459258</td>
      <td>0.671080</td>
      <td>-0.037007</td>
      <td>-0.474338</td>
      <td>0.216430</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.248428</td>
      <td>8.157785e-02</td>
      <td>-0.387259</td>
      <td>-0.011370</td>
      <td>-0.243577</td>
      <td>-0.186812</td>
      <td>-0.019175</td>
      <td>-1.070255</td>
      <td>-1.358136</td>
      <td>-0.758685</td>
      <td>-1.124847</td>
      <td>-1.069071</td>
      <td>-0.073441</td>
      <td>0.759063</td>
      <td>-0.567336</td>
      <td>0.431861</td>
      <td>0.857963</td>
      <td>-0.383371</td>
      <td>0.644814</td>
      <td>-0.762685</td>
      <td>-1.246538</td>
      <td>-0.694096</td>
      <td>-0.298835</td>
      <td>-1.356696</td>
      <td>-0.828081</td>
      <td>-0.098588</td>
      <td>0.557699</td>
      <td>0.151838</td>
      <td>0.548567</td>
      <td>0.733144</td>
      <td>-0.442571</td>
      <td>-0.665114</td>
      <td>-1.226571</td>
      <td>0.637517</td>
      <td>0.779009</td>
      <td>-0.166918</td>
      <td>-1.614192</td>
      <td>-0.533814</td>
      <td>-1.242772</td>
      <td>-0.806170</td>
      <td>...</td>
      <td>0.631273</td>
      <td>0.010073</td>
      <td>-0.379192</td>
      <td>-0.792260</td>
      <td>-0.740269</td>
      <td>0.268635</td>
      <td>-1.353581</td>
      <td>-1.586939</td>
      <td>-1.759185</td>
      <td>-0.568251</td>
      <td>-0.049016</td>
      <td>-1.056590</td>
      <td>-1.207012</td>
      <td>-0.297934</td>
      <td>-0.284664</td>
      <td>0.440000</td>
      <td>-0.051094</td>
      <td>-0.100192</td>
      <td>-0.669335</td>
      <td>-0.122600</td>
      <td>-0.570408</td>
      <td>-0.446994</td>
      <td>0.562878</td>
      <td>0.119565</td>
      <td>-0.134446</td>
      <td>-0.626367</td>
      <td>0.753022</td>
      <td>1.074754</td>
      <td>0.622239</td>
      <td>0.021975</td>
      <td>0.344253</td>
      <td>-0.175927</td>
      <td>0.279336</td>
      <td>0.371622</td>
      <td>0.572716</td>
      <td>-0.570763</td>
      <td>-0.728941</td>
      <td>2.033879</td>
      <td>0.607538</td>
      <td>-0.066621</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7fb8d8929670&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.089987  0.038412  28.375991  4.001005e-177  1.014701  1.165274
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  3.846 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.1e043a052b0af929e4d8.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>