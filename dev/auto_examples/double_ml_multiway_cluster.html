
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17: http://docutils.sourceforge.net/" />

    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.f6b7ca918bee2f46fd9abac01cfb07d5.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1e043a052b0af929e4d8.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">


    
    <a class="navbar-brand" href="../index.html">
      <p class="title">DoubleML</p>
    </a>
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  DoubleML
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/install.html">
  Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/intro.html">
  Getting started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../guide/guide.html">
  User guide
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api.html">
  Python API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference external nav-link" href="https://docs.doubleml.org/r/stable/">
  R API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../release/release.html">
  Release notes
 </a>
</li>

        
      </ul>

      <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><p class="logo" style="text-align:center;"><a href="../index.html">
    <img class="logo" src="../logo.png" alt="Logo" width="65%" height="65%">
</a></p><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l2 current active">
  <a class="current reference internal" href="#">
   Multiway Cluster Robust DML
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="double_ml_bonus_data.html">
   DML: Bonus Data
  </a>
 </li>
</ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulate-multiway-cluster-data">
   Simulate multiway cluster data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
   Initialize the objects of class DoubleMLData and DoubleMLPLIV
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#split-samples-and-transfer-the-sample-splitting-to-the-object">
   Split samples and transfer the sample splitting to the object
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fit-the-model-and-show-a-summary">
   Fit the model and show a summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing">
   Visualization of sample splitting with tuple and linear indexing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold">
     Visualize sample splitting with tuples (one plot per fold)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
     Visualize sample splitting with linear indexing (one column per fold)
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<section id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-0.124420</td>
      <td>-0.491731</td>
      <td>-0.578641</td>
      <td>-0.162597</td>
      <td>0.060931</td>
      <td>-0.125910</td>
      <td>-0.320340</td>
      <td>-0.533591</td>
      <td>-0.719047</td>
      <td>0.329078</td>
      <td>-0.262371</td>
      <td>-0.605729</td>
      <td>0.119855</td>
      <td>0.664016</td>
      <td>-0.259857</td>
      <td>-0.013550</td>
      <td>1.410320</td>
      <td>0.021584</td>
      <td>0.507102</td>
      <td>0.564959</td>
      <td>0.415304</td>
      <td>0.032311</td>
      <td>0.541404</td>
      <td>-0.482598</td>
      <td>-0.249041</td>
      <td>-0.624382</td>
      <td>-0.755461</td>
      <td>0.161588</td>
      <td>0.640982</td>
      <td>0.651234</td>
      <td>0.311677</td>
      <td>-1.096722</td>
      <td>0.791463</td>
      <td>0.420732</td>
      <td>0.580128</td>
      <td>0.384296</td>
      <td>-0.744743</td>
      <td>-0.622135</td>
      <td>0.095135</td>
      <td>0.946507</td>
      <td>...</td>
      <td>-0.487609</td>
      <td>0.094580</td>
      <td>0.516684</td>
      <td>0.100621</td>
      <td>-0.348218</td>
      <td>-0.033379</td>
      <td>-0.084277</td>
      <td>-0.227354</td>
      <td>0.301522</td>
      <td>0.340511</td>
      <td>-0.046294</td>
      <td>-0.054129</td>
      <td>0.021032</td>
      <td>-0.177459</td>
      <td>-0.056210</td>
      <td>0.596696</td>
      <td>0.151381</td>
      <td>-0.187371</td>
      <td>-0.467277</td>
      <td>0.092091</td>
      <td>0.323541</td>
      <td>-0.579626</td>
      <td>-0.229735</td>
      <td>0.868848</td>
      <td>0.652083</td>
      <td>1.466273</td>
      <td>-0.255239</td>
      <td>0.156121</td>
      <td>1.285609</td>
      <td>0.542414</td>
      <td>0.036895</td>
      <td>0.312190</td>
      <td>-0.057429</td>
      <td>0.085514</td>
      <td>-0.180965</td>
      <td>-0.141990</td>
      <td>-0.640681</td>
      <td>-1.662550</td>
      <td>-0.633964</td>
      <td>-0.361703</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.895525</td>
      <td>1.402676</td>
      <td>-0.117232</td>
      <td>-0.410805</td>
      <td>-0.441876</td>
      <td>-0.585187</td>
      <td>-0.999747</td>
      <td>-0.586372</td>
      <td>-0.365587</td>
      <td>0.163704</td>
      <td>0.803181</td>
      <td>0.535099</td>
      <td>-0.136365</td>
      <td>0.215086</td>
      <td>0.427058</td>
      <td>0.065239</td>
      <td>0.450046</td>
      <td>-0.392162</td>
      <td>-0.322431</td>
      <td>-0.167476</td>
      <td>1.045813</td>
      <td>0.170623</td>
      <td>0.445056</td>
      <td>0.578980</td>
      <td>-0.606124</td>
      <td>-0.318548</td>
      <td>-0.139225</td>
      <td>1.312583</td>
      <td>0.135562</td>
      <td>0.724121</td>
      <td>-0.014105</td>
      <td>-0.967231</td>
      <td>0.431522</td>
      <td>0.048290</td>
      <td>0.568453</td>
      <td>1.012273</td>
      <td>-0.756843</td>
      <td>-0.732661</td>
      <td>-0.397869</td>
      <td>0.868943</td>
      <td>...</td>
      <td>0.437739</td>
      <td>-0.386137</td>
      <td>-0.392989</td>
      <td>0.034114</td>
      <td>-0.017950</td>
      <td>0.624514</td>
      <td>0.178544</td>
      <td>0.855912</td>
      <td>0.270152</td>
      <td>0.228971</td>
      <td>0.305770</td>
      <td>-0.077588</td>
      <td>0.385462</td>
      <td>0.042293</td>
      <td>-0.362314</td>
      <td>0.180582</td>
      <td>-0.363735</td>
      <td>1.347812</td>
      <td>0.407213</td>
      <td>1.228595</td>
      <td>0.218583</td>
      <td>0.770199</td>
      <td>0.365486</td>
      <td>0.438507</td>
      <td>0.172116</td>
      <td>-0.323126</td>
      <td>-0.368717</td>
      <td>0.259048</td>
      <td>0.329675</td>
      <td>-0.677867</td>
      <td>0.508968</td>
      <td>0.571107</td>
      <td>0.222902</td>
      <td>0.646850</td>
      <td>-0.743265</td>
      <td>-0.635782</td>
      <td>0.061123</td>
      <td>2.773862</td>
      <td>2.273351</td>
      <td>1.438117</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.638345</td>
      <td>0.463044</td>
      <td>-0.882633</td>
      <td>0.069953</td>
      <td>0.243145</td>
      <td>0.395920</td>
      <td>-0.068664</td>
      <td>-0.153942</td>
      <td>-0.078503</td>
      <td>0.187667</td>
      <td>-0.435084</td>
      <td>0.364891</td>
      <td>0.072708</td>
      <td>0.861572</td>
      <td>-0.241984</td>
      <td>0.232326</td>
      <td>0.380571</td>
      <td>-0.116030</td>
      <td>-1.362785</td>
      <td>0.751097</td>
      <td>0.659604</td>
      <td>-1.458606</td>
      <td>-0.273905</td>
      <td>0.047263</td>
      <td>-0.208437</td>
      <td>0.750234</td>
      <td>1.124954</td>
      <td>0.511576</td>
      <td>-0.537510</td>
      <td>0.101899</td>
      <td>0.311769</td>
      <td>0.344003</td>
      <td>0.794172</td>
      <td>1.463976</td>
      <td>0.297420</td>
      <td>0.733071</td>
      <td>0.618424</td>
      <td>1.185567</td>
      <td>-0.096683</td>
      <td>-0.692258</td>
      <td>...</td>
      <td>0.234470</td>
      <td>-1.431391</td>
      <td>0.359389</td>
      <td>0.632851</td>
      <td>-0.275087</td>
      <td>0.657301</td>
      <td>-0.033789</td>
      <td>-0.201858</td>
      <td>1.074420</td>
      <td>1.042252</td>
      <td>0.396346</td>
      <td>0.530585</td>
      <td>0.231404</td>
      <td>-0.461469</td>
      <td>0.509825</td>
      <td>0.124124</td>
      <td>-0.963398</td>
      <td>0.518234</td>
      <td>-1.402590</td>
      <td>-0.983224</td>
      <td>0.372909</td>
      <td>-0.349030</td>
      <td>0.021185</td>
      <td>-0.198021</td>
      <td>1.323208</td>
      <td>1.099464</td>
      <td>0.211358</td>
      <td>-0.761111</td>
      <td>-0.682257</td>
      <td>0.632642</td>
      <td>0.639538</td>
      <td>0.546549</td>
      <td>-0.226214</td>
      <td>1.087337</td>
      <td>0.081110</td>
      <td>-0.887106</td>
      <td>-0.297865</td>
      <td>2.868273</td>
      <td>1.624189</td>
      <td>0.453136</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.309803</td>
      <td>0.108993</td>
      <td>-0.590898</td>
      <td>-0.663951</td>
      <td>0.056451</td>
      <td>-0.861084</td>
      <td>-0.262189</td>
      <td>-0.065818</td>
      <td>0.728544</td>
      <td>0.478947</td>
      <td>1.457765</td>
      <td>0.657522</td>
      <td>-0.373824</td>
      <td>-1.059610</td>
      <td>0.472530</td>
      <td>1.273423</td>
      <td>0.203734</td>
      <td>-0.269726</td>
      <td>-0.402125</td>
      <td>-0.029655</td>
      <td>0.865532</td>
      <td>0.626363</td>
      <td>0.137429</td>
      <td>-0.023123</td>
      <td>-0.819550</td>
      <td>0.510947</td>
      <td>-0.677095</td>
      <td>-0.377947</td>
      <td>-0.257612</td>
      <td>0.665010</td>
      <td>-0.327760</td>
      <td>0.740487</td>
      <td>0.411633</td>
      <td>-0.374389</td>
      <td>-0.656329</td>
      <td>0.613886</td>
      <td>-0.399201</td>
      <td>-0.504925</td>
      <td>-0.474865</td>
      <td>-0.253746</td>
      <td>...</td>
      <td>0.123390</td>
      <td>-0.593760</td>
      <td>0.536137</td>
      <td>0.858265</td>
      <td>-0.124892</td>
      <td>0.534277</td>
      <td>0.257494</td>
      <td>-0.767101</td>
      <td>-0.683361</td>
      <td>1.363893</td>
      <td>-0.021562</td>
      <td>-0.409693</td>
      <td>-0.467633</td>
      <td>0.349991</td>
      <td>1.183817</td>
      <td>0.836228</td>
      <td>-0.564990</td>
      <td>-0.651001</td>
      <td>-0.696361</td>
      <td>-0.377162</td>
      <td>-0.644003</td>
      <td>-0.329457</td>
      <td>0.233544</td>
      <td>-0.902655</td>
      <td>0.572794</td>
      <td>0.444131</td>
      <td>0.977318</td>
      <td>0.277090</td>
      <td>-0.405647</td>
      <td>0.384330</td>
      <td>-0.216328</td>
      <td>-0.610790</td>
      <td>-0.230264</td>
      <td>-0.063624</td>
      <td>0.223470</td>
      <td>0.624393</td>
      <td>-0.562716</td>
      <td>0.619413</td>
      <td>0.580361</td>
      <td>-0.702359</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.323363</td>
      <td>-0.170523</td>
      <td>-1.238354</td>
      <td>-0.439339</td>
      <td>-0.651898</td>
      <td>-1.055328</td>
      <td>-0.567609</td>
      <td>0.148217</td>
      <td>-0.662647</td>
      <td>-0.182241</td>
      <td>0.361343</td>
      <td>1.296960</td>
      <td>-0.075662</td>
      <td>0.163961</td>
      <td>0.350932</td>
      <td>0.876272</td>
      <td>0.276751</td>
      <td>-0.016224</td>
      <td>0.408144</td>
      <td>-0.930218</td>
      <td>0.733587</td>
      <td>0.861409</td>
      <td>1.284617</td>
      <td>-0.408017</td>
      <td>-0.064027</td>
      <td>-0.809003</td>
      <td>0.377677</td>
      <td>-0.115505</td>
      <td>0.106781</td>
      <td>0.467324</td>
      <td>-0.490077</td>
      <td>0.050687</td>
      <td>0.074772</td>
      <td>-0.649713</td>
      <td>-0.072129</td>
      <td>0.009084</td>
      <td>0.407153</td>
      <td>-0.564726</td>
      <td>-0.839081</td>
      <td>0.685859</td>
      <td>...</td>
      <td>0.857166</td>
      <td>0.138077</td>
      <td>0.746008</td>
      <td>-0.119649</td>
      <td>-0.286090</td>
      <td>0.957596</td>
      <td>0.736265</td>
      <td>-0.071190</td>
      <td>0.098655</td>
      <td>0.546774</td>
      <td>0.497549</td>
      <td>0.475121</td>
      <td>0.230695</td>
      <td>-0.250449</td>
      <td>0.365460</td>
      <td>-0.947110</td>
      <td>-0.779169</td>
      <td>-0.044353</td>
      <td>0.642710</td>
      <td>-0.238438</td>
      <td>0.842191</td>
      <td>0.811884</td>
      <td>0.184966</td>
      <td>0.356919</td>
      <td>0.096044</td>
      <td>-0.541853</td>
      <td>0.762932</td>
      <td>-0.182753</td>
      <td>0.565264</td>
      <td>0.079076</td>
      <td>0.526502</td>
      <td>0.972527</td>
      <td>0.231929</td>
      <td>-0.069853</td>
      <td>0.094220</td>
      <td>-0.569354</td>
      <td>0.378727</td>
      <td>2.681559</td>
      <td>1.483371</td>
      <td>0.512527</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.395896</td>
      <td>-0.337911</td>
      <td>-0.201389</td>
      <td>-0.835800</td>
      <td>-0.815592</td>
      <td>-1.125264</td>
      <td>-1.109357</td>
      <td>-0.115833</td>
      <td>0.350318</td>
      <td>-0.025303</td>
      <td>0.319437</td>
      <td>-1.095782</td>
      <td>-0.163182</td>
      <td>0.498905</td>
      <td>0.619572</td>
      <td>0.119283</td>
      <td>0.937244</td>
      <td>-0.413877</td>
      <td>0.951753</td>
      <td>0.519660</td>
      <td>0.325742</td>
      <td>0.373826</td>
      <td>-1.072764</td>
      <td>-1.017428</td>
      <td>-0.701104</td>
      <td>-0.595086</td>
      <td>-0.607680</td>
      <td>-1.135429</td>
      <td>-1.217841</td>
      <td>-1.511937</td>
      <td>-0.720990</td>
      <td>0.445929</td>
      <td>-0.120356</td>
      <td>-0.649087</td>
      <td>0.055217</td>
      <td>1.038931</td>
      <td>0.630771</td>
      <td>0.178533</td>
      <td>-0.209715</td>
      <td>-0.072775</td>
      <td>...</td>
      <td>0.322176</td>
      <td>-0.586704</td>
      <td>0.467494</td>
      <td>0.384312</td>
      <td>0.529238</td>
      <td>0.297636</td>
      <td>-0.209069</td>
      <td>0.117888</td>
      <td>0.607365</td>
      <td>0.854613</td>
      <td>0.054350</td>
      <td>0.259206</td>
      <td>0.074096</td>
      <td>-0.854342</td>
      <td>-0.564445</td>
      <td>0.087088</td>
      <td>-0.093163</td>
      <td>0.441918</td>
      <td>0.697620</td>
      <td>0.255234</td>
      <td>0.008989</td>
      <td>0.144025</td>
      <td>0.168509</td>
      <td>-0.583719</td>
      <td>0.494542</td>
      <td>1.246331</td>
      <td>0.151123</td>
      <td>0.801218</td>
      <td>0.086999</td>
      <td>-0.814635</td>
      <td>0.642614</td>
      <td>0.671430</td>
      <td>-0.171022</td>
      <td>-0.615557</td>
      <td>-0.181236</td>
      <td>-0.519857</td>
      <td>0.108195</td>
      <td>-0.402267</td>
      <td>-0.707405</td>
      <td>-0.962361</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.191584</td>
      <td>0.977816</td>
      <td>-0.303177</td>
      <td>0.235252</td>
      <td>0.719466</td>
      <td>-0.225458</td>
      <td>-1.652680</td>
      <td>-0.071698</td>
      <td>-0.768935</td>
      <td>-0.507088</td>
      <td>0.733075</td>
      <td>1.217700</td>
      <td>0.660529</td>
      <td>-0.142558</td>
      <td>0.540138</td>
      <td>0.089169</td>
      <td>0.157300</td>
      <td>-0.402359</td>
      <td>0.300809</td>
      <td>0.287087</td>
      <td>0.977553</td>
      <td>-0.093334</td>
      <td>1.010556</td>
      <td>-1.075880</td>
      <td>-0.499625</td>
      <td>0.311219</td>
      <td>1.144625</td>
      <td>-0.313465</td>
      <td>0.439312</td>
      <td>1.430984</td>
      <td>-0.133838</td>
      <td>0.344286</td>
      <td>0.396061</td>
      <td>0.051065</td>
      <td>0.757786</td>
      <td>0.413811</td>
      <td>0.371727</td>
      <td>1.316360</td>
      <td>0.859850</td>
      <td>1.199894</td>
      <td>...</td>
      <td>-0.152165</td>
      <td>-0.815822</td>
      <td>0.298420</td>
      <td>0.427152</td>
      <td>0.617678</td>
      <td>1.655728</td>
      <td>-0.389324</td>
      <td>1.175409</td>
      <td>0.497811</td>
      <td>0.540844</td>
      <td>-0.886745</td>
      <td>0.544078</td>
      <td>0.662847</td>
      <td>-0.223330</td>
      <td>0.378473</td>
      <td>-0.421304</td>
      <td>0.012937</td>
      <td>-1.129670</td>
      <td>-0.175852</td>
      <td>-0.077815</td>
      <td>0.678333</td>
      <td>-0.101246</td>
      <td>0.596977</td>
      <td>-0.588013</td>
      <td>0.488332</td>
      <td>0.519409</td>
      <td>0.170187</td>
      <td>-1.005326</td>
      <td>-0.411773</td>
      <td>-0.202000</td>
      <td>0.375532</td>
      <td>-0.380426</td>
      <td>0.937087</td>
      <td>1.123894</td>
      <td>-0.404330</td>
      <td>-0.335347</td>
      <td>1.044839</td>
      <td>3.280717</td>
      <td>2.245856</td>
      <td>0.985313</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.200963</td>
      <td>-0.971457</td>
      <td>0.166200</td>
      <td>-0.062699</td>
      <td>-0.969816</td>
      <td>-0.823198</td>
      <td>-0.430003</td>
      <td>-0.484811</td>
      <td>0.984535</td>
      <td>0.951047</td>
      <td>0.005019</td>
      <td>0.411650</td>
      <td>0.767159</td>
      <td>-0.046159</td>
      <td>0.134848</td>
      <td>-0.494382</td>
      <td>0.337429</td>
      <td>0.286884</td>
      <td>0.139777</td>
      <td>0.246994</td>
      <td>1.034614</td>
      <td>0.286341</td>
      <td>0.404114</td>
      <td>0.136772</td>
      <td>0.983658</td>
      <td>0.198022</td>
      <td>-0.165818</td>
      <td>-0.192952</td>
      <td>0.294469</td>
      <td>1.314833</td>
      <td>-0.411662</td>
      <td>-1.108581</td>
      <td>-0.902793</td>
      <td>-0.633454</td>
      <td>-0.245943</td>
      <td>0.405409</td>
      <td>0.431608</td>
      <td>0.176440</td>
      <td>-0.229764</td>
      <td>0.439822</td>
      <td>...</td>
      <td>0.658040</td>
      <td>-0.583245</td>
      <td>-0.189189</td>
      <td>-0.102686</td>
      <td>-0.221855</td>
      <td>1.090853</td>
      <td>1.133876</td>
      <td>-0.229296</td>
      <td>0.659586</td>
      <td>-0.302315</td>
      <td>-0.960917</td>
      <td>0.141850</td>
      <td>-1.106561</td>
      <td>0.851842</td>
      <td>0.784646</td>
      <td>-0.157183</td>
      <td>0.133921</td>
      <td>0.765751</td>
      <td>0.623765</td>
      <td>0.159244</td>
      <td>0.532705</td>
      <td>-0.205181</td>
      <td>0.022278</td>
      <td>-0.858070</td>
      <td>0.193210</td>
      <td>-0.261526</td>
      <td>0.258271</td>
      <td>-0.229945</td>
      <td>0.263719</td>
      <td>0.647873</td>
      <td>-0.308103</td>
      <td>0.357055</td>
      <td>0.561654</td>
      <td>-0.666471</td>
      <td>-1.477771</td>
      <td>-0.951668</td>
      <td>0.267187</td>
      <td>-0.684928</td>
      <td>-0.442081</td>
      <td>-0.741477</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.965802</td>
      <td>0.264336</td>
      <td>0.189376</td>
      <td>0.171995</td>
      <td>0.017821</td>
      <td>-0.965601</td>
      <td>0.011728</td>
      <td>-0.661119</td>
      <td>-0.000814</td>
      <td>-0.201037</td>
      <td>-0.875682</td>
      <td>0.433328</td>
      <td>-0.265248</td>
      <td>0.611275</td>
      <td>0.264252</td>
      <td>0.562098</td>
      <td>0.732150</td>
      <td>-1.124815</td>
      <td>-0.140522</td>
      <td>1.134206</td>
      <td>1.214132</td>
      <td>0.573207</td>
      <td>0.850092</td>
      <td>0.338279</td>
      <td>0.423719</td>
      <td>0.456752</td>
      <td>-0.181794</td>
      <td>0.878327</td>
      <td>-0.314610</td>
      <td>-0.156846</td>
      <td>-0.203613</td>
      <td>0.244999</td>
      <td>0.220084</td>
      <td>0.380121</td>
      <td>-0.028695</td>
      <td>-0.606527</td>
      <td>-0.685301</td>
      <td>0.331725</td>
      <td>-0.113439</td>
      <td>1.593711</td>
      <td>...</td>
      <td>0.893825</td>
      <td>0.190061</td>
      <td>0.308758</td>
      <td>-0.518433</td>
      <td>-0.761312</td>
      <td>0.430874</td>
      <td>0.225471</td>
      <td>0.350158</td>
      <td>0.953863</td>
      <td>0.432850</td>
      <td>0.006868</td>
      <td>0.547407</td>
      <td>0.559572</td>
      <td>-0.040030</td>
      <td>0.921106</td>
      <td>0.216457</td>
      <td>0.201555</td>
      <td>-0.012710</td>
      <td>-0.868394</td>
      <td>0.237841</td>
      <td>1.294451</td>
      <td>0.965232</td>
      <td>0.439344</td>
      <td>0.035776</td>
      <td>0.302441</td>
      <td>-0.149733</td>
      <td>-1.242782</td>
      <td>0.015357</td>
      <td>-0.433698</td>
      <td>-0.190166</td>
      <td>1.662528</td>
      <td>0.926311</td>
      <td>-0.396872</td>
      <td>-0.593508</td>
      <td>-1.029563</td>
      <td>-0.961374</td>
      <td>-0.724357</td>
      <td>2.051861</td>
      <td>0.979291</td>
      <td>0.467963</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.093459</td>
      <td>0.497593</td>
      <td>-0.154249</td>
      <td>0.283834</td>
      <td>0.327385</td>
      <td>0.243700</td>
      <td>0.409209</td>
      <td>0.555063</td>
      <td>0.877499</td>
      <td>0.167945</td>
      <td>-0.093819</td>
      <td>1.061161</td>
      <td>0.592978</td>
      <td>0.459608</td>
      <td>0.053469</td>
      <td>-0.121100</td>
      <td>-0.095599</td>
      <td>-0.026775</td>
      <td>-0.661925</td>
      <td>0.259927</td>
      <td>0.680303</td>
      <td>0.188023</td>
      <td>0.929005</td>
      <td>-0.730978</td>
      <td>-0.074005</td>
      <td>0.314550</td>
      <td>0.333336</td>
      <td>0.085954</td>
      <td>0.170123</td>
      <td>1.072551</td>
      <td>-0.489016</td>
      <td>-0.162173</td>
      <td>0.174964</td>
      <td>0.188618</td>
      <td>-0.109916</td>
      <td>0.342367</td>
      <td>-0.763735</td>
      <td>-0.047640</td>
      <td>0.049191</td>
      <td>0.286600</td>
      <td>...</td>
      <td>0.385942</td>
      <td>0.333355</td>
      <td>0.503468</td>
      <td>0.455540</td>
      <td>0.205588</td>
      <td>0.509143</td>
      <td>-0.635893</td>
      <td>0.166094</td>
      <td>-0.087674</td>
      <td>-0.422761</td>
      <td>0.309051</td>
      <td>1.002730</td>
      <td>0.099504</td>
      <td>-0.672741</td>
      <td>0.067832</td>
      <td>-0.453376</td>
      <td>-0.244349</td>
      <td>-0.500150</td>
      <td>-0.500309</td>
      <td>-0.542197</td>
      <td>0.782056</td>
      <td>0.273126</td>
      <td>0.082659</td>
      <td>-0.642610</td>
      <td>-1.189036</td>
      <td>-0.549562</td>
      <td>-0.689822</td>
      <td>0.178504</td>
      <td>0.634892</td>
      <td>0.831229</td>
      <td>0.487747</td>
      <td>-0.651092</td>
      <td>-0.109476</td>
      <td>0.233323</td>
      <td>-0.434646</td>
      <td>-0.215259</td>
      <td>0.293108</td>
      <td>0.296698</td>
      <td>0.303396</td>
      <td>0.076812</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.259205</td>
      <td>0.051115</td>
      <td>-0.303022</td>
      <td>-0.826697</td>
      <td>-0.356983</td>
      <td>-1.029514</td>
      <td>-0.572891</td>
      <td>0.198373</td>
      <td>0.204814</td>
      <td>-0.592329</td>
      <td>-0.291199</td>
      <td>0.522935</td>
      <td>0.323505</td>
      <td>-0.509394</td>
      <td>-0.541527</td>
      <td>0.104384</td>
      <td>-0.340664</td>
      <td>0.637291</td>
      <td>0.632777</td>
      <td>0.031629</td>
      <td>0.385322</td>
      <td>-0.281251</td>
      <td>0.405477</td>
      <td>-0.297653</td>
      <td>-0.849831</td>
      <td>-1.245313</td>
      <td>-0.069407</td>
      <td>0.793294</td>
      <td>0.173710</td>
      <td>0.222336</td>
      <td>-0.098966</td>
      <td>-0.341838</td>
      <td>0.093763</td>
      <td>0.680368</td>
      <td>0.300270</td>
      <td>0.470320</td>
      <td>0.961275</td>
      <td>-0.246187</td>
      <td>0.543688</td>
      <td>1.470661</td>
      <td>...</td>
      <td>-0.372582</td>
      <td>0.111014</td>
      <td>0.597893</td>
      <td>-0.294158</td>
      <td>-0.982720</td>
      <td>-0.232254</td>
      <td>0.240062</td>
      <td>0.534207</td>
      <td>0.630375</td>
      <td>0.875220</td>
      <td>0.409892</td>
      <td>-0.203914</td>
      <td>0.296863</td>
      <td>0.932970</td>
      <td>0.395128</td>
      <td>0.634086</td>
      <td>-0.357595</td>
      <td>0.457147</td>
      <td>-1.217129</td>
      <td>-0.367811</td>
      <td>0.079958</td>
      <td>-0.327769</td>
      <td>1.531239</td>
      <td>-0.554265</td>
      <td>-0.131321</td>
      <td>-0.286380</td>
      <td>-0.491469</td>
      <td>-0.600800</td>
      <td>-0.346161</td>
      <td>0.942422</td>
      <td>1.367352</td>
      <td>0.762966</td>
      <td>0.200146</td>
      <td>0.474327</td>
      <td>0.000206</td>
      <td>-0.219821</td>
      <td>-0.996331</td>
      <td>-1.197387</td>
      <td>-0.440634</td>
      <td>-0.259393</td>
    </tr>
    <tr>
      <th>11</th>
      <td>1.136008</td>
      <td>1.122315</td>
      <td>0.104314</td>
      <td>0.075226</td>
      <td>-1.222741</td>
      <td>-0.041569</td>
      <td>1.143464</td>
      <td>0.111693</td>
      <td>-0.321313</td>
      <td>-1.248807</td>
      <td>0.143892</td>
      <td>0.311237</td>
      <td>0.212103</td>
      <td>-0.821193</td>
      <td>-0.181191</td>
      <td>0.367141</td>
      <td>0.696323</td>
      <td>-1.057355</td>
      <td>0.450567</td>
      <td>0.540661</td>
      <td>1.419953</td>
      <td>0.415953</td>
      <td>0.160346</td>
      <td>0.199166</td>
      <td>0.380099</td>
      <td>0.569235</td>
      <td>-0.349885</td>
      <td>0.276003</td>
      <td>-0.449714</td>
      <td>0.617775</td>
      <td>-1.713389</td>
      <td>-0.531973</td>
      <td>0.836330</td>
      <td>0.190419</td>
      <td>0.510785</td>
      <td>1.483628</td>
      <td>0.030691</td>
      <td>1.101784</td>
      <td>0.874400</td>
      <td>0.906849</td>
      <td>...</td>
      <td>0.062655</td>
      <td>-0.584029</td>
      <td>0.023010</td>
      <td>0.394286</td>
      <td>0.263693</td>
      <td>2.273224</td>
      <td>-0.723538</td>
      <td>-0.341130</td>
      <td>1.283596</td>
      <td>2.238454</td>
      <td>-0.120679</td>
      <td>0.490301</td>
      <td>0.963095</td>
      <td>0.721235</td>
      <td>0.176051</td>
      <td>-0.108411</td>
      <td>0.032997</td>
      <td>0.695627</td>
      <td>-0.466478</td>
      <td>-0.425303</td>
      <td>-0.010208</td>
      <td>-0.437376</td>
      <td>0.406766</td>
      <td>-0.419126</td>
      <td>-0.189460</td>
      <td>0.644292</td>
      <td>0.234382</td>
      <td>-0.368747</td>
      <td>0.266035</td>
      <td>0.229990</td>
      <td>0.524624</td>
      <td>1.636836</td>
      <td>0.176328</td>
      <td>0.743437</td>
      <td>0.182999</td>
      <td>-1.016158</td>
      <td>0.247766</td>
      <td>2.063147</td>
      <td>1.440166</td>
      <td>0.216313</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.011577</td>
      <td>0.041885</td>
      <td>-1.925892</td>
      <td>0.165815</td>
      <td>-0.353547</td>
      <td>0.247614</td>
      <td>-0.273185</td>
      <td>-0.358339</td>
      <td>-0.059011</td>
      <td>0.781558</td>
      <td>0.220275</td>
      <td>-0.414007</td>
      <td>0.638819</td>
      <td>0.181821</td>
      <td>-0.194327</td>
      <td>0.816443</td>
      <td>1.053980</td>
      <td>-0.092672</td>
      <td>0.407195</td>
      <td>1.037672</td>
      <td>0.830923</td>
      <td>-0.218128</td>
      <td>-0.095461</td>
      <td>-2.425675</td>
      <td>-0.897756</td>
      <td>-0.991400</td>
      <td>-0.549278</td>
      <td>0.251583</td>
      <td>0.157833</td>
      <td>-0.332728</td>
      <td>-0.115992</td>
      <td>0.771547</td>
      <td>0.586488</td>
      <td>0.491089</td>
      <td>0.374811</td>
      <td>0.369730</td>
      <td>-0.146757</td>
      <td>-0.026268</td>
      <td>-1.088706</td>
      <td>0.989406</td>
      <td>...</td>
      <td>-0.108351</td>
      <td>-0.309766</td>
      <td>0.064592</td>
      <td>0.698363</td>
      <td>-0.436871</td>
      <td>-0.056218</td>
      <td>0.508339</td>
      <td>-0.423492</td>
      <td>-0.149330</td>
      <td>0.535582</td>
      <td>0.827819</td>
      <td>0.337560</td>
      <td>0.395566</td>
      <td>-0.532608</td>
      <td>0.396133</td>
      <td>0.429808</td>
      <td>0.344867</td>
      <td>0.546243</td>
      <td>-0.361333</td>
      <td>-0.191966</td>
      <td>-0.839267</td>
      <td>-0.191511</td>
      <td>-0.797543</td>
      <td>-0.556516</td>
      <td>0.147002</td>
      <td>0.293992</td>
      <td>0.158567</td>
      <td>0.148171</td>
      <td>-0.679001</td>
      <td>-0.426227</td>
      <td>-0.158616</td>
      <td>-0.476685</td>
      <td>1.579980</td>
      <td>0.105638</td>
      <td>-1.028886</td>
      <td>-0.577049</td>
      <td>-1.052018</td>
      <td>-0.142825</td>
      <td>0.237949</td>
      <td>0.367942</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-1.069134</td>
      <td>0.682002</td>
      <td>-0.910281</td>
      <td>-0.124770</td>
      <td>0.800620</td>
      <td>-1.060113</td>
      <td>-0.493733</td>
      <td>0.123343</td>
      <td>0.707643</td>
      <td>-0.670070</td>
      <td>0.555159</td>
      <td>-0.044809</td>
      <td>0.339666</td>
      <td>0.637778</td>
      <td>0.091719</td>
      <td>0.354771</td>
      <td>1.624348</td>
      <td>-0.104945</td>
      <td>-0.382390</td>
      <td>0.428269</td>
      <td>1.127161</td>
      <td>0.915210</td>
      <td>0.551668</td>
      <td>-0.169955</td>
      <td>0.273546</td>
      <td>0.457416</td>
      <td>-0.094245</td>
      <td>0.846795</td>
      <td>-0.122073</td>
      <td>0.606124</td>
      <td>0.512149</td>
      <td>0.164742</td>
      <td>0.492377</td>
      <td>0.585171</td>
      <td>-0.527376</td>
      <td>0.807230</td>
      <td>0.615390</td>
      <td>-0.600636</td>
      <td>0.064664</td>
      <td>0.481370</td>
      <td>...</td>
      <td>-0.775312</td>
      <td>0.096587</td>
      <td>1.267061</td>
      <td>-0.101933</td>
      <td>-0.050361</td>
      <td>0.392350</td>
      <td>-0.312306</td>
      <td>-0.828805</td>
      <td>0.363757</td>
      <td>0.001867</td>
      <td>-0.374909</td>
      <td>-0.418363</td>
      <td>-0.932465</td>
      <td>-0.537881</td>
      <td>-0.063410</td>
      <td>0.255909</td>
      <td>0.276251</td>
      <td>-0.781984</td>
      <td>-0.858588</td>
      <td>-1.528208</td>
      <td>-1.013265</td>
      <td>0.218984</td>
      <td>0.721987</td>
      <td>1.012307</td>
      <td>-0.317081</td>
      <td>0.548509</td>
      <td>0.483198</td>
      <td>0.321645</td>
      <td>-0.134713</td>
      <td>-0.557976</td>
      <td>0.030443</td>
      <td>-0.675151</td>
      <td>-0.045822</td>
      <td>-0.476987</td>
      <td>-0.093349</td>
      <td>-1.259643</td>
      <td>0.194338</td>
      <td>0.862593</td>
      <td>0.370695</td>
      <td>-0.544055</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.586759</td>
      <td>0.721173</td>
      <td>-0.650732</td>
      <td>-1.058338</td>
      <td>-1.334318</td>
      <td>-0.318357</td>
      <td>-0.490314</td>
      <td>-0.046407</td>
      <td>-0.537816</td>
      <td>-0.668872</td>
      <td>0.274666</td>
      <td>0.056425</td>
      <td>0.166528</td>
      <td>-0.028344</td>
      <td>0.279518</td>
      <td>-0.114641</td>
      <td>-0.026261</td>
      <td>-0.487675</td>
      <td>0.356626</td>
      <td>0.591654</td>
      <td>0.117995</td>
      <td>-0.718943</td>
      <td>-0.094618</td>
      <td>-0.747659</td>
      <td>-0.421092</td>
      <td>0.472330</td>
      <td>1.206174</td>
      <td>0.308317</td>
      <td>0.220532</td>
      <td>0.265530</td>
      <td>-0.341777</td>
      <td>-1.006348</td>
      <td>-0.874332</td>
      <td>0.174442</td>
      <td>-0.798610</td>
      <td>0.308920</td>
      <td>0.601955</td>
      <td>-0.052347</td>
      <td>-1.106999</td>
      <td>0.294543</td>
      <td>...</td>
      <td>0.970656</td>
      <td>-0.613758</td>
      <td>-0.220269</td>
      <td>-0.294955</td>
      <td>0.276830</td>
      <td>-0.061659</td>
      <td>-0.857300</td>
      <td>0.649944</td>
      <td>-0.542157</td>
      <td>0.450213</td>
      <td>0.461465</td>
      <td>0.175771</td>
      <td>-0.506869</td>
      <td>-0.408796</td>
      <td>0.860317</td>
      <td>1.595591</td>
      <td>0.315027</td>
      <td>0.207737</td>
      <td>-0.488651</td>
      <td>-0.011838</td>
      <td>0.845601</td>
      <td>0.229952</td>
      <td>0.532967</td>
      <td>0.651442</td>
      <td>1.023509</td>
      <td>-0.228022</td>
      <td>-0.921801</td>
      <td>-1.180587</td>
      <td>-0.473132</td>
      <td>0.536607</td>
      <td>0.689642</td>
      <td>-0.015031</td>
      <td>-0.588308</td>
      <td>0.058867</td>
      <td>-0.184733</td>
      <td>0.209151</td>
      <td>-0.524397</td>
      <td>2.843831</td>
      <td>2.274731</td>
      <td>0.653501</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.236694</td>
      <td>0.088997</td>
      <td>-0.481475</td>
      <td>-1.143826</td>
      <td>-0.582359</td>
      <td>0.461847</td>
      <td>0.446209</td>
      <td>-0.273291</td>
      <td>-0.011899</td>
      <td>-0.159741</td>
      <td>0.850893</td>
      <td>0.534050</td>
      <td>0.036721</td>
      <td>-1.139974</td>
      <td>0.231006</td>
      <td>-0.207330</td>
      <td>0.504348</td>
      <td>-0.158411</td>
      <td>0.253115</td>
      <td>0.553539</td>
      <td>2.085240</td>
      <td>0.742244</td>
      <td>0.534187</td>
      <td>-0.839985</td>
      <td>-0.104300</td>
      <td>-0.223047</td>
      <td>0.655406</td>
      <td>0.154969</td>
      <td>0.265154</td>
      <td>0.421057</td>
      <td>0.245772</td>
      <td>-0.059446</td>
      <td>-0.445280</td>
      <td>-0.695858</td>
      <td>-0.299327</td>
      <td>0.921019</td>
      <td>1.040008</td>
      <td>0.547324</td>
      <td>-0.166531</td>
      <td>0.257306</td>
      <td>...</td>
      <td>-0.154306</td>
      <td>-0.903559</td>
      <td>-0.251198</td>
      <td>-0.628939</td>
      <td>-0.121590</td>
      <td>0.422028</td>
      <td>0.190926</td>
      <td>-0.074728</td>
      <td>0.827831</td>
      <td>1.006890</td>
      <td>0.273287</td>
      <td>-0.568614</td>
      <td>0.305097</td>
      <td>-0.901035</td>
      <td>0.406998</td>
      <td>0.083394</td>
      <td>-0.269401</td>
      <td>0.497271</td>
      <td>-0.069807</td>
      <td>-0.037800</td>
      <td>0.102688</td>
      <td>-0.132110</td>
      <td>0.506610</td>
      <td>-0.372638</td>
      <td>-0.107611</td>
      <td>0.587421</td>
      <td>-0.186410</td>
      <td>-0.458523</td>
      <td>-0.575619</td>
      <td>0.126637</td>
      <td>0.361149</td>
      <td>0.852615</td>
      <td>-0.632607</td>
      <td>0.159630</td>
      <td>-0.871972</td>
      <td>-0.489802</td>
      <td>0.460131</td>
      <td>1.495464</td>
      <td>1.606082</td>
      <td>0.674490</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.903874</td>
      <td>-0.227745</td>
      <td>-0.176699</td>
      <td>-0.023308</td>
      <td>-0.319153</td>
      <td>-0.351760</td>
      <td>0.178631</td>
      <td>0.292818</td>
      <td>0.549468</td>
      <td>-0.339028</td>
      <td>-0.070788</td>
      <td>0.343476</td>
      <td>0.607486</td>
      <td>0.442296</td>
      <td>1.126696</td>
      <td>0.943993</td>
      <td>0.625733</td>
      <td>0.275443</td>
      <td>0.083877</td>
      <td>0.741938</td>
      <td>0.157503</td>
      <td>1.191243</td>
      <td>1.493329</td>
      <td>0.073808</td>
      <td>-0.151887</td>
      <td>0.137615</td>
      <td>0.830005</td>
      <td>-0.161253</td>
      <td>0.188368</td>
      <td>1.034295</td>
      <td>-0.038656</td>
      <td>-0.624668</td>
      <td>0.393708</td>
      <td>1.056198</td>
      <td>0.960417</td>
      <td>0.953881</td>
      <td>0.902335</td>
      <td>0.642694</td>
      <td>0.488549</td>
      <td>0.317260</td>
      <td>...</td>
      <td>0.333404</td>
      <td>0.694167</td>
      <td>-0.401805</td>
      <td>0.153853</td>
      <td>0.562748</td>
      <td>0.374629</td>
      <td>0.206930</td>
      <td>1.070855</td>
      <td>0.673495</td>
      <td>1.282827</td>
      <td>0.768720</td>
      <td>0.065020</td>
      <td>0.801403</td>
      <td>-0.044420</td>
      <td>0.261273</td>
      <td>0.233377</td>
      <td>0.284616</td>
      <td>0.320771</td>
      <td>-0.500422</td>
      <td>0.081212</td>
      <td>1.223537</td>
      <td>0.320989</td>
      <td>0.050179</td>
      <td>0.357640</td>
      <td>-0.108949</td>
      <td>0.031089</td>
      <td>-0.461931</td>
      <td>-0.802339</td>
      <td>0.200867</td>
      <td>0.121216</td>
      <td>0.641069</td>
      <td>0.846043</td>
      <td>0.056829</td>
      <td>-0.207057</td>
      <td>0.353384</td>
      <td>-0.095612</td>
      <td>-0.588973</td>
      <td>0.821186</td>
      <td>0.834213</td>
      <td>0.564029</td>
    </tr>
    <tr>
      <th>17</th>
      <td>1.530739</td>
      <td>0.346077</td>
      <td>-0.069820</td>
      <td>-0.276787</td>
      <td>0.558165</td>
      <td>-0.835904</td>
      <td>0.029882</td>
      <td>0.226046</td>
      <td>0.155108</td>
      <td>0.532379</td>
      <td>1.024124</td>
      <td>0.743683</td>
      <td>0.203078</td>
      <td>-0.145001</td>
      <td>0.398462</td>
      <td>0.408460</td>
      <td>0.361822</td>
      <td>-0.517845</td>
      <td>0.642413</td>
      <td>0.747114</td>
      <td>0.131823</td>
      <td>0.227532</td>
      <td>1.081933</td>
      <td>-0.617497</td>
      <td>-0.520569</td>
      <td>-0.875215</td>
      <td>-0.843983</td>
      <td>-0.707860</td>
      <td>-1.105397</td>
      <td>-0.129542</td>
      <td>-0.544749</td>
      <td>0.162075</td>
      <td>-0.065354</td>
      <td>-0.094483</td>
      <td>0.473641</td>
      <td>1.569405</td>
      <td>0.821527</td>
      <td>0.966274</td>
      <td>0.594991</td>
      <td>1.452095</td>
      <td>...</td>
      <td>-1.430934</td>
      <td>-0.982115</td>
      <td>0.757720</td>
      <td>0.147850</td>
      <td>-0.945598</td>
      <td>-0.250519</td>
      <td>-0.163293</td>
      <td>0.509030</td>
      <td>1.612328</td>
      <td>0.616351</td>
      <td>0.378071</td>
      <td>0.139694</td>
      <td>-0.253245</td>
      <td>-0.246098</td>
      <td>0.677759</td>
      <td>0.654131</td>
      <td>-0.821792</td>
      <td>-0.005705</td>
      <td>0.559705</td>
      <td>0.362563</td>
      <td>0.356544</td>
      <td>0.196731</td>
      <td>0.710879</td>
      <td>-1.038033</td>
      <td>-0.661251</td>
      <td>0.102957</td>
      <td>-0.745516</td>
      <td>0.020428</td>
      <td>-0.399362</td>
      <td>0.878046</td>
      <td>-0.171660</td>
      <td>0.865018</td>
      <td>-0.822506</td>
      <td>0.211666</td>
      <td>-0.402342</td>
      <td>-0.729300</td>
      <td>-0.411664</td>
      <td>1.410314</td>
      <td>1.013473</td>
      <td>0.294254</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.711772</td>
      <td>0.786669</td>
      <td>0.731947</td>
      <td>0.891675</td>
      <td>-0.657351</td>
      <td>-0.364960</td>
      <td>0.079720</td>
      <td>-0.293775</td>
      <td>0.000770</td>
      <td>-0.443241</td>
      <td>-0.853544</td>
      <td>-0.483014</td>
      <td>0.206944</td>
      <td>-1.175866</td>
      <td>-0.072110</td>
      <td>-0.121142</td>
      <td>0.236673</td>
      <td>0.201659</td>
      <td>0.416376</td>
      <td>0.612110</td>
      <td>1.024845</td>
      <td>1.043975</td>
      <td>0.456302</td>
      <td>-0.485311</td>
      <td>0.105601</td>
      <td>-0.265672</td>
      <td>-0.268077</td>
      <td>-0.036233</td>
      <td>0.447234</td>
      <td>0.177144</td>
      <td>-1.267204</td>
      <td>-1.009678</td>
      <td>0.318411</td>
      <td>0.448194</td>
      <td>0.365740</td>
      <td>2.361061</td>
      <td>0.989657</td>
      <td>0.158761</td>
      <td>-0.120944</td>
      <td>1.283026</td>
      <td>...</td>
      <td>0.093548</td>
      <td>0.562874</td>
      <td>-0.361614</td>
      <td>0.034651</td>
      <td>-0.261419</td>
      <td>-0.050520</td>
      <td>-0.243295</td>
      <td>0.215654</td>
      <td>0.276302</td>
      <td>-0.027025</td>
      <td>-1.003167</td>
      <td>-0.608908</td>
      <td>0.566834</td>
      <td>-0.351356</td>
      <td>1.368254</td>
      <td>0.008188</td>
      <td>-0.364954</td>
      <td>0.069308</td>
      <td>-1.145450</td>
      <td>-0.258722</td>
      <td>0.139135</td>
      <td>0.631977</td>
      <td>0.784661</td>
      <td>-0.175834</td>
      <td>0.509903</td>
      <td>1.121349</td>
      <td>0.184364</td>
      <td>-1.087258</td>
      <td>0.353977</td>
      <td>0.233497</td>
      <td>0.410281</td>
      <td>0.175918</td>
      <td>0.301963</td>
      <td>-0.267695</td>
      <td>0.029764</td>
      <td>0.285304</td>
      <td>0.296308</td>
      <td>2.178107</td>
      <td>0.859043</td>
      <td>1.088323</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.667770</td>
      <td>1.313161</td>
      <td>-0.467182</td>
      <td>0.183760</td>
      <td>-0.459452</td>
      <td>-0.321275</td>
      <td>0.686689</td>
      <td>0.491530</td>
      <td>0.441779</td>
      <td>0.493301</td>
      <td>0.203232</td>
      <td>0.472130</td>
      <td>-0.011176</td>
      <td>-0.948269</td>
      <td>0.029321</td>
      <td>-0.387821</td>
      <td>0.058684</td>
      <td>-0.548126</td>
      <td>0.781107</td>
      <td>0.579334</td>
      <td>0.503695</td>
      <td>0.555693</td>
      <td>0.528311</td>
      <td>-0.621869</td>
      <td>0.286350</td>
      <td>0.897039</td>
      <td>0.747125</td>
      <td>-0.080267</td>
      <td>-0.496576</td>
      <td>-1.143003</td>
      <td>-0.159851</td>
      <td>-0.484812</td>
      <td>0.206829</td>
      <td>-0.927141</td>
      <td>-0.361881</td>
      <td>0.818126</td>
      <td>0.459419</td>
      <td>1.072348</td>
      <td>-0.136525</td>
      <td>0.938854</td>
      <td>...</td>
      <td>0.347285</td>
      <td>-0.066836</td>
      <td>0.610840</td>
      <td>0.730593</td>
      <td>0.708648</td>
      <td>1.447380</td>
      <td>-0.418945</td>
      <td>0.639492</td>
      <td>0.792248</td>
      <td>0.645185</td>
      <td>-0.619399</td>
      <td>-0.141801</td>
      <td>-0.299624</td>
      <td>0.118430</td>
      <td>0.977605</td>
      <td>0.168139</td>
      <td>-0.761897</td>
      <td>-0.325054</td>
      <td>-0.217223</td>
      <td>0.085702</td>
      <td>0.037235</td>
      <td>0.539687</td>
      <td>0.620049</td>
      <td>-0.079324</td>
      <td>0.185941</td>
      <td>0.164342</td>
      <td>0.663377</td>
      <td>-0.242414</td>
      <td>-0.030833</td>
      <td>0.318858</td>
      <td>-0.013571</td>
      <td>0.819241</td>
      <td>-0.116556</td>
      <td>-0.239312</td>
      <td>-0.331069</td>
      <td>-1.485765</td>
      <td>-1.215156</td>
      <td>0.706397</td>
      <td>0.261838</td>
      <td>-0.501992</td>
    </tr>
    <tr>
      <th>20</th>
      <td>1.031758</td>
      <td>0.959228</td>
      <td>-1.472212</td>
      <td>0.106213</td>
      <td>-0.706913</td>
      <td>0.006935</td>
      <td>-0.551212</td>
      <td>0.078275</td>
      <td>-0.643357</td>
      <td>-0.910858</td>
      <td>0.122599</td>
      <td>-0.123679</td>
      <td>0.278346</td>
      <td>-0.267332</td>
      <td>1.228405</td>
      <td>-0.319216</td>
      <td>0.428643</td>
      <td>0.058019</td>
      <td>-0.374593</td>
      <td>0.571248</td>
      <td>0.565872</td>
      <td>0.447797</td>
      <td>0.394218</td>
      <td>-0.352158</td>
      <td>-0.693290</td>
      <td>-0.703963</td>
      <td>0.747487</td>
      <td>0.153698</td>
      <td>0.244439</td>
      <td>-0.649685</td>
      <td>-0.653533</td>
      <td>0.185610</td>
      <td>0.170319</td>
      <td>1.177717</td>
      <td>0.693884</td>
      <td>0.503180</td>
      <td>-0.651832</td>
      <td>-0.128029</td>
      <td>0.583170</td>
      <td>1.110759</td>
      <td>...</td>
      <td>-0.956337</td>
      <td>-0.671227</td>
      <td>0.206144</td>
      <td>0.331840</td>
      <td>0.887210</td>
      <td>0.117596</td>
      <td>-0.857282</td>
      <td>-0.662932</td>
      <td>0.504109</td>
      <td>0.839508</td>
      <td>0.553543</td>
      <td>-0.228391</td>
      <td>0.492217</td>
      <td>-0.650337</td>
      <td>0.729907</td>
      <td>1.166030</td>
      <td>-0.093809</td>
      <td>-0.397411</td>
      <td>0.097393</td>
      <td>-0.188867</td>
      <td>0.052485</td>
      <td>0.659096</td>
      <td>0.533205</td>
      <td>1.300431</td>
      <td>0.535968</td>
      <td>0.457456</td>
      <td>-0.306138</td>
      <td>-0.537831</td>
      <td>-0.940963</td>
      <td>-0.293902</td>
      <td>0.439993</td>
      <td>1.866523</td>
      <td>-0.061607</td>
      <td>-0.084945</td>
      <td>0.830532</td>
      <td>0.537578</td>
      <td>-0.356979</td>
      <td>2.160371</td>
      <td>2.384713</td>
      <td>0.961326</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.551369</td>
      <td>0.433271</td>
      <td>-0.365031</td>
      <td>-0.362344</td>
      <td>-0.486727</td>
      <td>-0.556250</td>
      <td>-0.227110</td>
      <td>-0.310916</td>
      <td>-0.604001</td>
      <td>-0.066517</td>
      <td>-0.002117</td>
      <td>0.079315</td>
      <td>0.656858</td>
      <td>-0.719178</td>
      <td>-0.203668</td>
      <td>0.425723</td>
      <td>1.587523</td>
      <td>0.260791</td>
      <td>0.465567</td>
      <td>-0.541930</td>
      <td>0.968122</td>
      <td>1.235082</td>
      <td>0.787614</td>
      <td>-0.178864</td>
      <td>0.431084</td>
      <td>0.209847</td>
      <td>0.338053</td>
      <td>0.880083</td>
      <td>0.693857</td>
      <td>-0.075752</td>
      <td>-0.505180</td>
      <td>0.879459</td>
      <td>0.868576</td>
      <td>0.010608</td>
      <td>0.248864</td>
      <td>1.222178</td>
      <td>0.190376</td>
      <td>0.233064</td>
      <td>0.009236</td>
      <td>0.671585</td>
      <td>...</td>
      <td>0.947430</td>
      <td>-0.156887</td>
      <td>0.556690</td>
      <td>-0.029723</td>
      <td>-1.599221</td>
      <td>-0.064816</td>
      <td>-1.112267</td>
      <td>-0.129538</td>
      <td>-0.147674</td>
      <td>0.516824</td>
      <td>-0.117916</td>
      <td>0.593046</td>
      <td>-0.501022</td>
      <td>-0.304710</td>
      <td>1.314589</td>
      <td>0.225496</td>
      <td>-0.876737</td>
      <td>-0.719070</td>
      <td>-1.336912</td>
      <td>-0.270670</td>
      <td>0.302353</td>
      <td>0.054823</td>
      <td>-0.052925</td>
      <td>-0.160121</td>
      <td>-1.271901</td>
      <td>0.283178</td>
      <td>0.266415</td>
      <td>-0.568899</td>
      <td>0.280269</td>
      <td>0.476095</td>
      <td>0.321132</td>
      <td>-0.583667</td>
      <td>0.296587</td>
      <td>-0.100748</td>
      <td>-0.369501</td>
      <td>-0.275974</td>
      <td>0.498674</td>
      <td>-0.425478</td>
      <td>0.200641</td>
      <td>0.116587</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.763498</td>
      <td>0.345771</td>
      <td>-0.860491</td>
      <td>-0.693248</td>
      <td>-0.608640</td>
      <td>-0.734432</td>
      <td>-0.821227</td>
      <td>-0.888857</td>
      <td>0.270298</td>
      <td>-0.726997</td>
      <td>-0.249201</td>
      <td>-0.198049</td>
      <td>-0.195877</td>
      <td>-0.025020</td>
      <td>-0.536674</td>
      <td>-0.290007</td>
      <td>0.889280</td>
      <td>-1.027911</td>
      <td>0.270473</td>
      <td>1.356502</td>
      <td>-0.192890</td>
      <td>0.450760</td>
      <td>0.537318</td>
      <td>0.841692</td>
      <td>0.358399</td>
      <td>-0.373334</td>
      <td>-0.439468</td>
      <td>1.004004</td>
      <td>0.047018</td>
      <td>0.630879</td>
      <td>-0.281619</td>
      <td>-0.043522</td>
      <td>0.958141</td>
      <td>0.003733</td>
      <td>0.772696</td>
      <td>0.103393</td>
      <td>-0.055973</td>
      <td>-0.872281</td>
      <td>-0.259444</td>
      <td>-0.086443</td>
      <td>...</td>
      <td>0.312354</td>
      <td>0.077038</td>
      <td>-0.180758</td>
      <td>0.155387</td>
      <td>-0.051890</td>
      <td>0.652059</td>
      <td>-0.015280</td>
      <td>0.417808</td>
      <td>0.714457</td>
      <td>1.402917</td>
      <td>0.432966</td>
      <td>-0.156192</td>
      <td>-0.248094</td>
      <td>-0.321843</td>
      <td>1.527957</td>
      <td>-0.015287</td>
      <td>-0.028127</td>
      <td>-1.139917</td>
      <td>-0.078129</td>
      <td>-0.093816</td>
      <td>0.834355</td>
      <td>0.055035</td>
      <td>0.787506</td>
      <td>-0.029904</td>
      <td>-0.106199</td>
      <td>-0.224423</td>
      <td>0.158446</td>
      <td>0.706533</td>
      <td>-0.764880</td>
      <td>0.377179</td>
      <td>0.008049</td>
      <td>1.330175</td>
      <td>-0.186274</td>
      <td>-0.559676</td>
      <td>-0.734196</td>
      <td>0.250353</td>
      <td>-0.013182</td>
      <td>2.539326</td>
      <td>1.760473</td>
      <td>0.377691</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.231893</td>
      <td>1.569426</td>
      <td>0.421412</td>
      <td>0.635138</td>
      <td>0.525903</td>
      <td>0.795214</td>
      <td>-0.554866</td>
      <td>0.934179</td>
      <td>0.034150</td>
      <td>-0.569026</td>
      <td>-0.806030</td>
      <td>-0.460440</td>
      <td>-0.339275</td>
      <td>0.361421</td>
      <td>-0.157140</td>
      <td>0.318407</td>
      <td>1.659380</td>
      <td>-0.329685</td>
      <td>0.184471</td>
      <td>0.012195</td>
      <td>0.502119</td>
      <td>0.138661</td>
      <td>0.044245</td>
      <td>0.063104</td>
      <td>-0.195340</td>
      <td>-0.474350</td>
      <td>-0.162404</td>
      <td>0.119440</td>
      <td>0.164162</td>
      <td>-0.169259</td>
      <td>0.334147</td>
      <td>0.586660</td>
      <td>0.898325</td>
      <td>-0.187509</td>
      <td>-0.082690</td>
      <td>0.849491</td>
      <td>0.274229</td>
      <td>0.149170</td>
      <td>-0.787058</td>
      <td>1.325644</td>
      <td>...</td>
      <td>0.863910</td>
      <td>0.399073</td>
      <td>-0.174067</td>
      <td>-0.134107</td>
      <td>0.145342</td>
      <td>1.299801</td>
      <td>0.529581</td>
      <td>-0.314710</td>
      <td>0.440496</td>
      <td>0.823815</td>
      <td>0.579796</td>
      <td>0.555513</td>
      <td>0.128767</td>
      <td>-0.103521</td>
      <td>0.188928</td>
      <td>0.098001</td>
      <td>-0.249422</td>
      <td>0.198686</td>
      <td>-1.316653</td>
      <td>0.234414</td>
      <td>0.190973</td>
      <td>0.890335</td>
      <td>1.060120</td>
      <td>0.347880</td>
      <td>0.232843</td>
      <td>0.243429</td>
      <td>-0.132954</td>
      <td>0.085654</td>
      <td>0.149645</td>
      <td>0.610647</td>
      <td>0.343420</td>
      <td>-0.184829</td>
      <td>-0.614896</td>
      <td>-0.144351</td>
      <td>0.072124</td>
      <td>0.085875</td>
      <td>-0.494066</td>
      <td>2.113104</td>
      <td>1.264998</td>
      <td>1.200887</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.254591</td>
      <td>-0.299099</td>
      <td>-0.376073</td>
      <td>0.882525</td>
      <td>0.015220</td>
      <td>-0.106966</td>
      <td>0.007906</td>
      <td>0.081673</td>
      <td>0.491889</td>
      <td>0.847339</td>
      <td>0.333411</td>
      <td>0.516724</td>
      <td>0.930079</td>
      <td>0.800232</td>
      <td>0.976925</td>
      <td>0.912158</td>
      <td>1.601700</td>
      <td>-0.606812</td>
      <td>0.021025</td>
      <td>1.431403</td>
      <td>0.671105</td>
      <td>-0.235743</td>
      <td>0.096737</td>
      <td>-0.620466</td>
      <td>0.303261</td>
      <td>-0.273354</td>
      <td>-0.009688</td>
      <td>-0.776243</td>
      <td>-0.421975</td>
      <td>0.247470</td>
      <td>-0.185210</td>
      <td>-0.307564</td>
      <td>0.096128</td>
      <td>-0.231347</td>
      <td>-0.515927</td>
      <td>-0.195565</td>
      <td>-0.269120</td>
      <td>0.204310</td>
      <td>0.140589</td>
      <td>0.694788</td>
      <td>...</td>
      <td>0.907438</td>
      <td>-0.059883</td>
      <td>-0.297531</td>
      <td>-0.039853</td>
      <td>-0.020554</td>
      <td>1.504724</td>
      <td>0.559849</td>
      <td>-0.170790</td>
      <td>0.304018</td>
      <td>0.406310</td>
      <td>0.977639</td>
      <td>-0.082403</td>
      <td>0.029457</td>
      <td>-0.008914</td>
      <td>0.622345</td>
      <td>0.465494</td>
      <td>-0.279183</td>
      <td>0.283451</td>
      <td>-0.868548</td>
      <td>0.021778</td>
      <td>0.400501</td>
      <td>0.786730</td>
      <td>0.448690</td>
      <td>-0.135153</td>
      <td>0.276882</td>
      <td>-0.202480</td>
      <td>0.426170</td>
      <td>-0.756763</td>
      <td>-0.961049</td>
      <td>0.338108</td>
      <td>0.995048</td>
      <td>0.573569</td>
      <td>-0.275183</td>
      <td>-0.335567</td>
      <td>-0.521284</td>
      <td>-0.052555</td>
      <td>-0.851083</td>
      <td>0.812565</td>
      <td>0.127268</td>
      <td>-0.495815</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>0.061368</td>
      <td>0.222762</td>
      <td>-0.370035</td>
      <td>0.670530</td>
      <td>0.412034</td>
      <td>0.732888</td>
      <td>-0.436721</td>
      <td>-0.574178</td>
      <td>0.028854</td>
      <td>0.382202</td>
      <td>0.154263</td>
      <td>-0.772280</td>
      <td>-1.033209</td>
      <td>-0.126237</td>
      <td>-0.764319</td>
      <td>-1.324157</td>
      <td>0.648685</td>
      <td>0.143599</td>
      <td>0.688899</td>
      <td>-0.085633</td>
      <td>0.494427</td>
      <td>0.438508</td>
      <td>0.607806</td>
      <td>0.952177</td>
      <td>0.171737</td>
      <td>-0.096062</td>
      <td>-0.311128</td>
      <td>-0.193705</td>
      <td>0.118818</td>
      <td>-0.071008</td>
      <td>0.687131</td>
      <td>-0.415355</td>
      <td>0.968236</td>
      <td>-0.065392</td>
      <td>0.804034</td>
      <td>-0.016139</td>
      <td>0.244255</td>
      <td>-0.023502</td>
      <td>-0.103789</td>
      <td>-0.704805</td>
      <td>...</td>
      <td>-0.556649</td>
      <td>0.146212</td>
      <td>-0.149778</td>
      <td>0.057003</td>
      <td>-0.569996</td>
      <td>-0.303408</td>
      <td>-0.307288</td>
      <td>0.185539</td>
      <td>-0.341608</td>
      <td>0.201790</td>
      <td>0.737256</td>
      <td>-0.512025</td>
      <td>-0.525378</td>
      <td>0.063973</td>
      <td>0.545319</td>
      <td>-0.055967</td>
      <td>-0.187862</td>
      <td>-0.738131</td>
      <td>-0.358130</td>
      <td>-0.524174</td>
      <td>-0.232602</td>
      <td>-1.178172</td>
      <td>-0.308028</td>
      <td>-0.308154</td>
      <td>-0.186006</td>
      <td>0.100769</td>
      <td>-0.404044</td>
      <td>0.811426</td>
      <td>0.504156</td>
      <td>0.417171</td>
      <td>0.530581</td>
      <td>0.031260</td>
      <td>-0.417498</td>
      <td>1.225917</td>
      <td>-0.111195</td>
      <td>0.381173</td>
      <td>-0.559982</td>
      <td>-1.413673</td>
      <td>-0.368490</td>
      <td>0.195922</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.401325</td>
      <td>0.091847</td>
      <td>-0.341281</td>
      <td>0.078053</td>
      <td>0.281713</td>
      <td>-0.460658</td>
      <td>-0.462919</td>
      <td>-0.496853</td>
      <td>-0.240948</td>
      <td>0.633045</td>
      <td>-0.106626</td>
      <td>-0.040706</td>
      <td>0.016496</td>
      <td>-0.136494</td>
      <td>0.657261</td>
      <td>1.163136</td>
      <td>-0.124880</td>
      <td>-0.203339</td>
      <td>-0.643203</td>
      <td>0.188985</td>
      <td>0.345661</td>
      <td>0.043820</td>
      <td>-1.139147</td>
      <td>0.380719</td>
      <td>0.666650</td>
      <td>0.707633</td>
      <td>0.020081</td>
      <td>0.505057</td>
      <td>-0.123936</td>
      <td>-0.192349</td>
      <td>-1.046677</td>
      <td>-0.738821</td>
      <td>-0.341729</td>
      <td>0.112683</td>
      <td>0.809897</td>
      <td>1.022080</td>
      <td>0.541241</td>
      <td>0.113174</td>
      <td>0.446499</td>
      <td>0.388260</td>
      <td>...</td>
      <td>0.852535</td>
      <td>0.182968</td>
      <td>-0.372800</td>
      <td>-0.115222</td>
      <td>-0.139384</td>
      <td>-0.665315</td>
      <td>0.157236</td>
      <td>0.679020</td>
      <td>0.197937</td>
      <td>0.572413</td>
      <td>0.559700</td>
      <td>0.419155</td>
      <td>0.882636</td>
      <td>-0.644613</td>
      <td>-1.244210</td>
      <td>1.118012</td>
      <td>-0.677870</td>
      <td>0.178364</td>
      <td>0.017302</td>
      <td>-0.487482</td>
      <td>-0.549673</td>
      <td>0.007504</td>
      <td>0.367955</td>
      <td>0.485958</td>
      <td>-0.110879</td>
      <td>0.455956</td>
      <td>-0.096052</td>
      <td>0.963965</td>
      <td>0.982478</td>
      <td>-0.512248</td>
      <td>0.411581</td>
      <td>-0.198220</td>
      <td>-0.349873</td>
      <td>0.701185</td>
      <td>-0.209833</td>
      <td>0.384246</td>
      <td>0.721040</td>
      <td>-0.679804</td>
      <td>-0.293154</td>
      <td>0.499991</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.644911</td>
      <td>0.066241</td>
      <td>-0.376540</td>
      <td>-0.665603</td>
      <td>-0.279245</td>
      <td>0.292405</td>
      <td>0.165944</td>
      <td>0.198571</td>
      <td>-0.186703</td>
      <td>-0.268347</td>
      <td>-0.620181</td>
      <td>-0.470457</td>
      <td>0.892713</td>
      <td>0.855275</td>
      <td>-0.726589</td>
      <td>-0.265921</td>
      <td>-0.710976</td>
      <td>-0.087407</td>
      <td>0.608498</td>
      <td>0.730496</td>
      <td>0.240917</td>
      <td>-1.070078</td>
      <td>-1.187065</td>
      <td>-0.470866</td>
      <td>0.342170</td>
      <td>1.617377</td>
      <td>-0.290942</td>
      <td>1.055607</td>
      <td>0.466523</td>
      <td>0.477210</td>
      <td>1.075473</td>
      <td>0.163191</td>
      <td>-0.203058</td>
      <td>0.392229</td>
      <td>0.188640</td>
      <td>0.267687</td>
      <td>-0.865236</td>
      <td>0.442029</td>
      <td>0.344403</td>
      <td>-0.348778</td>
      <td>...</td>
      <td>1.216869</td>
      <td>0.346584</td>
      <td>-0.668059</td>
      <td>-0.066349</td>
      <td>-0.409844</td>
      <td>-0.676411</td>
      <td>-0.419873</td>
      <td>0.030294</td>
      <td>-0.292914</td>
      <td>1.034785</td>
      <td>-0.145135</td>
      <td>0.023069</td>
      <td>-0.099387</td>
      <td>0.071216</td>
      <td>-0.218919</td>
      <td>-0.228993</td>
      <td>0.530458</td>
      <td>0.099277</td>
      <td>0.231326</td>
      <td>0.132199</td>
      <td>0.435223</td>
      <td>-0.900403</td>
      <td>-1.220544</td>
      <td>-0.561332</td>
      <td>-0.055075</td>
      <td>-0.441526</td>
      <td>0.577038</td>
      <td>0.526264</td>
      <td>0.066541</td>
      <td>0.074583</td>
      <td>-0.167388</td>
      <td>-0.666472</td>
      <td>0.349851</td>
      <td>1.714920</td>
      <td>0.157859</td>
      <td>-0.713572</td>
      <td>0.069026</td>
      <td>1.028351</td>
      <td>-0.027047</td>
      <td>-0.290782</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.821134</td>
      <td>-0.157668</td>
      <td>0.565343</td>
      <td>0.665545</td>
      <td>0.902954</td>
      <td>-0.327019</td>
      <td>-0.362945</td>
      <td>0.396872</td>
      <td>0.299973</td>
      <td>-0.343749</td>
      <td>0.886541</td>
      <td>-0.453912</td>
      <td>-0.738944</td>
      <td>-0.301597</td>
      <td>0.345769</td>
      <td>0.651651</td>
      <td>-0.404643</td>
      <td>-0.705617</td>
      <td>0.107005</td>
      <td>0.354818</td>
      <td>0.552548</td>
      <td>-0.369830</td>
      <td>-1.073168</td>
      <td>0.548443</td>
      <td>-0.956554</td>
      <td>-0.097495</td>
      <td>0.136131</td>
      <td>0.312489</td>
      <td>0.410596</td>
      <td>-0.846946</td>
      <td>-0.288212</td>
      <td>-0.526770</td>
      <td>-1.132151</td>
      <td>0.011074</td>
      <td>0.169151</td>
      <td>0.244574</td>
      <td>-0.362518</td>
      <td>0.183175</td>
      <td>0.968341</td>
      <td>-0.435129</td>
      <td>...</td>
      <td>1.039387</td>
      <td>0.889156</td>
      <td>0.241846</td>
      <td>0.033109</td>
      <td>0.170405</td>
      <td>-0.876675</td>
      <td>-0.259135</td>
      <td>-0.013618</td>
      <td>-0.107739</td>
      <td>-0.037418</td>
      <td>-0.771063</td>
      <td>-0.218054</td>
      <td>0.376642</td>
      <td>-0.295388</td>
      <td>-0.597499</td>
      <td>0.371018</td>
      <td>-0.967185</td>
      <td>0.958831</td>
      <td>0.449471</td>
      <td>-0.062477</td>
      <td>-0.472326</td>
      <td>0.528339</td>
      <td>-0.874021</td>
      <td>-0.745432</td>
      <td>0.102112</td>
      <td>1.187817</td>
      <td>0.497044</td>
      <td>-0.256412</td>
      <td>0.330742</td>
      <td>0.590803</td>
      <td>0.168724</td>
      <td>0.677019</td>
      <td>0.779818</td>
      <td>-0.072527</td>
      <td>0.721489</td>
      <td>0.697458</td>
      <td>-0.551766</td>
      <td>-1.082600</td>
      <td>-0.174571</td>
      <td>0.089989</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.181787</td>
      <td>-0.450782</td>
      <td>-0.931775</td>
      <td>-1.220020</td>
      <td>-0.511489</td>
      <td>-1.282945</td>
      <td>-0.321250</td>
      <td>-0.887876</td>
      <td>0.262864</td>
      <td>0.599507</td>
      <td>-0.431639</td>
      <td>0.108393</td>
      <td>-0.123965</td>
      <td>0.428248</td>
      <td>-0.108293</td>
      <td>0.324526</td>
      <td>0.030467</td>
      <td>1.020174</td>
      <td>1.209579</td>
      <td>-0.850042</td>
      <td>-0.000346</td>
      <td>0.521908</td>
      <td>0.220805</td>
      <td>0.716546</td>
      <td>0.691496</td>
      <td>0.105723</td>
      <td>0.901703</td>
      <td>0.297718</td>
      <td>0.313928</td>
      <td>-0.188859</td>
      <td>-1.076821</td>
      <td>0.088253</td>
      <td>1.083369</td>
      <td>0.703265</td>
      <td>0.531800</td>
      <td>0.427370</td>
      <td>0.503975</td>
      <td>-0.851692</td>
      <td>-0.964836</td>
      <td>-0.065555</td>
      <td>...</td>
      <td>0.622521</td>
      <td>0.694114</td>
      <td>0.801514</td>
      <td>0.501762</td>
      <td>-0.828088</td>
      <td>-0.368825</td>
      <td>-0.648250</td>
      <td>-0.856533</td>
      <td>-0.847598</td>
      <td>0.372922</td>
      <td>-0.618466</td>
      <td>0.055673</td>
      <td>-0.361015</td>
      <td>-0.719412</td>
      <td>-0.958119</td>
      <td>-0.513173</td>
      <td>-0.508692</td>
      <td>0.166711</td>
      <td>-0.026909</td>
      <td>0.274056</td>
      <td>-0.377086</td>
      <td>-0.212508</td>
      <td>-0.464735</td>
      <td>-0.162486</td>
      <td>1.127151</td>
      <td>0.202015</td>
      <td>0.930855</td>
      <td>0.128244</td>
      <td>0.246282</td>
      <td>0.109963</td>
      <td>0.382691</td>
      <td>1.193004</td>
      <td>0.696684</td>
      <td>-0.153743</td>
      <td>0.160399</td>
      <td>-0.851001</td>
      <td>0.240782</td>
      <td>-0.973550</td>
      <td>-1.155069</td>
      <td>-0.877495</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 103 columns</p>
</div>
</div>
<br />
<br /></section>
<section id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7fefa94bab80&gt;
</pre></div>
</div>
</section>
<section id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  0.985114  0.039377  25.017476  3.946110e-138  0.907937  1.062292
</pre></div>
</div>
</section>
<section id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<section id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</section>
<section id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.892 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>
</section>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.1e043a052b0af929e4d8.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>