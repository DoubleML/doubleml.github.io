
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.100724</td>
      <td>0.239586</td>
      <td>-0.266297</td>
      <td>0.220867</td>
      <td>1.571354</td>
      <td>1.225360</td>
      <td>0.775525</td>
      <td>0.505103</td>
      <td>0.916605</td>
      <td>-0.014528</td>
      <td>1.085041</td>
      <td>0.682550</td>
      <td>-0.847880</td>
      <td>0.018242</td>
      <td>-0.235174</td>
      <td>-0.034560</td>
      <td>-0.056930</td>
      <td>0.801433</td>
      <td>0.719257</td>
      <td>0.404994</td>
      <td>0.902965</td>
      <td>-0.305494</td>
      <td>-1.561004</td>
      <td>-1.107598</td>
      <td>-0.390274</td>
      <td>-0.985246</td>
      <td>0.780151</td>
      <td>0.734189</td>
      <td>-0.284075</td>
      <td>-0.977403</td>
      <td>0.371085</td>
      <td>-0.781108</td>
      <td>0.637147</td>
      <td>0.279183</td>
      <td>0.402672</td>
      <td>-0.137263</td>
      <td>-0.559928</td>
      <td>0.008333</td>
      <td>0.477403</td>
      <td>0.035043</td>
      <td>...</td>
      <td>-0.668196</td>
      <td>-0.793852</td>
      <td>0.352336</td>
      <td>0.133690</td>
      <td>0.687932</td>
      <td>0.277297</td>
      <td>-0.560091</td>
      <td>-0.451145</td>
      <td>-1.090473</td>
      <td>0.003008</td>
      <td>0.794048</td>
      <td>-0.331488</td>
      <td>-0.638158</td>
      <td>-0.941284</td>
      <td>0.192415</td>
      <td>-0.710077</td>
      <td>0.155806</td>
      <td>-0.093782</td>
      <td>0.367408</td>
      <td>0.081882</td>
      <td>0.051851</td>
      <td>0.213584</td>
      <td>-0.756129</td>
      <td>-0.083638</td>
      <td>-0.957986</td>
      <td>0.135710</td>
      <td>0.071933</td>
      <td>-0.209819</td>
      <td>0.293115</td>
      <td>-0.599771</td>
      <td>0.475226</td>
      <td>0.580597</td>
      <td>0.198149</td>
      <td>-0.531652</td>
      <td>0.224799</td>
      <td>1.234917</td>
      <td>-0.028296</td>
      <td>0.082062</td>
      <td>0.648075</td>
      <td>0.603597</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.280727</td>
      <td>0.049970</td>
      <td>0.067471</td>
      <td>-0.349123</td>
      <td>-0.475700</td>
      <td>-1.044181</td>
      <td>-0.052305</td>
      <td>0.031722</td>
      <td>0.071393</td>
      <td>-0.237205</td>
      <td>-0.301505</td>
      <td>-0.344624</td>
      <td>0.328130</td>
      <td>-0.361681</td>
      <td>0.204395</td>
      <td>0.472399</td>
      <td>-0.367640</td>
      <td>-0.493854</td>
      <td>0.159143</td>
      <td>-0.728450</td>
      <td>-0.357422</td>
      <td>1.015139</td>
      <td>0.534924</td>
      <td>-0.754398</td>
      <td>0.265338</td>
      <td>-0.606906</td>
      <td>0.865190</td>
      <td>-0.644748</td>
      <td>0.082233</td>
      <td>0.095986</td>
      <td>-0.127940</td>
      <td>-0.678736</td>
      <td>0.040360</td>
      <td>0.552110</td>
      <td>0.299275</td>
      <td>1.006468</td>
      <td>0.587593</td>
      <td>0.388530</td>
      <td>0.649524</td>
      <td>0.815236</td>
      <td>...</td>
      <td>-1.685233</td>
      <td>-0.059186</td>
      <td>0.126615</td>
      <td>0.041386</td>
      <td>-0.747968</td>
      <td>-0.366832</td>
      <td>-0.262094</td>
      <td>-0.369574</td>
      <td>-0.540057</td>
      <td>0.104774</td>
      <td>-0.135464</td>
      <td>0.377024</td>
      <td>0.107317</td>
      <td>0.064549</td>
      <td>1.058806</td>
      <td>0.604437</td>
      <td>0.331348</td>
      <td>-0.248718</td>
      <td>0.106359</td>
      <td>-0.150294</td>
      <td>-0.305098</td>
      <td>0.607231</td>
      <td>-0.952347</td>
      <td>-0.208924</td>
      <td>0.144627</td>
      <td>0.587201</td>
      <td>-0.438433</td>
      <td>0.263687</td>
      <td>0.231811</td>
      <td>0.834579</td>
      <td>-0.100651</td>
      <td>0.074011</td>
      <td>-0.354033</td>
      <td>0.193267</td>
      <td>-0.134519</td>
      <td>-0.631576</td>
      <td>-0.626986</td>
      <td>1.308412</td>
      <td>0.883199</td>
      <td>0.757866</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.576489</td>
      <td>-0.006084</td>
      <td>0.043357</td>
      <td>-1.141728</td>
      <td>0.219018</td>
      <td>-0.333391</td>
      <td>0.093087</td>
      <td>0.129909</td>
      <td>0.084808</td>
      <td>-0.977361</td>
      <td>0.177735</td>
      <td>-0.062011</td>
      <td>0.460793</td>
      <td>-0.193647</td>
      <td>-0.559928</td>
      <td>-0.923086</td>
      <td>-1.093733</td>
      <td>-0.308503</td>
      <td>0.741578</td>
      <td>-0.470144</td>
      <td>-0.639394</td>
      <td>0.235616</td>
      <td>-1.215397</td>
      <td>-0.450069</td>
      <td>0.547149</td>
      <td>-0.036954</td>
      <td>0.521282</td>
      <td>-0.003995</td>
      <td>0.557765</td>
      <td>-0.110076</td>
      <td>-0.185497</td>
      <td>-0.870089</td>
      <td>0.374978</td>
      <td>0.629108</td>
      <td>-0.359939</td>
      <td>-0.490283</td>
      <td>-0.441160</td>
      <td>0.216542</td>
      <td>0.363590</td>
      <td>0.894337</td>
      <td>...</td>
      <td>-0.011955</td>
      <td>-0.234094</td>
      <td>0.166835</td>
      <td>-0.182172</td>
      <td>-0.649959</td>
      <td>-0.163273</td>
      <td>-0.099451</td>
      <td>-0.297724</td>
      <td>0.216549</td>
      <td>1.054043</td>
      <td>0.316496</td>
      <td>-0.766287</td>
      <td>-0.633513</td>
      <td>0.142819</td>
      <td>0.057578</td>
      <td>-0.445848</td>
      <td>-0.192873</td>
      <td>-0.573505</td>
      <td>-0.778101</td>
      <td>-0.464799</td>
      <td>0.808399</td>
      <td>0.483426</td>
      <td>0.626261</td>
      <td>1.304423</td>
      <td>0.183474</td>
      <td>-0.924563</td>
      <td>-0.066325</td>
      <td>-0.386610</td>
      <td>0.117436</td>
      <td>-1.281064</td>
      <td>0.434546</td>
      <td>-0.650488</td>
      <td>0.534380</td>
      <td>0.014891</td>
      <td>-0.423607</td>
      <td>1.300722</td>
      <td>-0.298726</td>
      <td>-2.649673</td>
      <td>-2.057748</td>
      <td>-0.545548</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.717504</td>
      <td>-0.221361</td>
      <td>-0.716984</td>
      <td>-1.217128</td>
      <td>-0.831544</td>
      <td>-1.386063</td>
      <td>-1.379622</td>
      <td>-0.015617</td>
      <td>-0.141528</td>
      <td>-1.639757</td>
      <td>0.356866</td>
      <td>0.247394</td>
      <td>0.266023</td>
      <td>-0.463118</td>
      <td>0.178725</td>
      <td>0.481545</td>
      <td>-0.431805</td>
      <td>-0.120151</td>
      <td>-0.767918</td>
      <td>-0.425668</td>
      <td>-0.525071</td>
      <td>0.131183</td>
      <td>-0.122124</td>
      <td>0.350664</td>
      <td>-0.117059</td>
      <td>0.045553</td>
      <td>0.721662</td>
      <td>-0.268991</td>
      <td>-0.141825</td>
      <td>-0.402463</td>
      <td>-0.177641</td>
      <td>0.071324</td>
      <td>0.396000</td>
      <td>-0.334301</td>
      <td>-0.697699</td>
      <td>-0.026770</td>
      <td>-0.408772</td>
      <td>-0.441880</td>
      <td>0.101237</td>
      <td>0.495295</td>
      <td>...</td>
      <td>-0.965727</td>
      <td>-0.469376</td>
      <td>0.265785</td>
      <td>-0.294329</td>
      <td>-0.005373</td>
      <td>0.441715</td>
      <td>0.476925</td>
      <td>1.071932</td>
      <td>0.248886</td>
      <td>-0.150960</td>
      <td>0.142156</td>
      <td>-0.487412</td>
      <td>-0.013311</td>
      <td>-0.432975</td>
      <td>-0.760284</td>
      <td>-0.375628</td>
      <td>0.091254</td>
      <td>-0.188728</td>
      <td>0.838881</td>
      <td>0.382313</td>
      <td>0.581810</td>
      <td>-0.237280</td>
      <td>-0.174443</td>
      <td>0.375976</td>
      <td>0.632727</td>
      <td>0.053319</td>
      <td>0.564563</td>
      <td>0.301126</td>
      <td>-1.007170</td>
      <td>0.360425</td>
      <td>-0.396851</td>
      <td>-0.352324</td>
      <td>0.136233</td>
      <td>-0.913406</td>
      <td>-0.716461</td>
      <td>-0.034422</td>
      <td>0.011354</td>
      <td>-0.480693</td>
      <td>-0.533208</td>
      <td>-0.631707</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.044800</td>
      <td>0.456700</td>
      <td>-1.665958</td>
      <td>-0.928567</td>
      <td>0.137314</td>
      <td>-0.024485</td>
      <td>1.565502</td>
      <td>-0.278205</td>
      <td>0.487242</td>
      <td>0.298903</td>
      <td>0.243888</td>
      <td>0.850708</td>
      <td>0.186702</td>
      <td>-0.117455</td>
      <td>-0.498958</td>
      <td>-0.551185</td>
      <td>-0.808312</td>
      <td>-0.436318</td>
      <td>-1.389925</td>
      <td>-0.201972</td>
      <td>0.070142</td>
      <td>0.231517</td>
      <td>0.719582</td>
      <td>-0.190978</td>
      <td>-0.342980</td>
      <td>0.076726</td>
      <td>0.304068</td>
      <td>0.189092</td>
      <td>0.353942</td>
      <td>-0.320569</td>
      <td>-0.003672</td>
      <td>-0.606329</td>
      <td>-0.496661</td>
      <td>1.118602</td>
      <td>-0.216279</td>
      <td>-0.567410</td>
      <td>-0.167133</td>
      <td>0.725195</td>
      <td>0.699486</td>
      <td>1.581192</td>
      <td>...</td>
      <td>-0.187783</td>
      <td>0.537625</td>
      <td>0.232549</td>
      <td>-0.262440</td>
      <td>0.011428</td>
      <td>-0.298878</td>
      <td>0.567351</td>
      <td>-1.394139</td>
      <td>-1.238210</td>
      <td>0.588957</td>
      <td>0.091316</td>
      <td>-0.313377</td>
      <td>-0.695016</td>
      <td>-0.059191</td>
      <td>-0.482587</td>
      <td>0.321825</td>
      <td>0.171313</td>
      <td>0.146445</td>
      <td>-0.035496</td>
      <td>0.016349</td>
      <td>-0.723209</td>
      <td>-0.676737</td>
      <td>-1.122085</td>
      <td>-0.167304</td>
      <td>-0.856139</td>
      <td>-0.112599</td>
      <td>0.617260</td>
      <td>0.377258</td>
      <td>0.256416</td>
      <td>-0.372209</td>
      <td>-0.429848</td>
      <td>0.488333</td>
      <td>0.913330</td>
      <td>-0.199889</td>
      <td>-1.070321</td>
      <td>-0.009832</td>
      <td>0.287999</td>
      <td>-1.065529</td>
      <td>-0.466251</td>
      <td>-0.083490</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.454756</td>
      <td>0.361598</td>
      <td>-0.238259</td>
      <td>-0.773221</td>
      <td>-0.214484</td>
      <td>-0.845319</td>
      <td>0.180450</td>
      <td>-0.662586</td>
      <td>0.466574</td>
      <td>-0.807603</td>
      <td>-0.508695</td>
      <td>-0.095746</td>
      <td>0.565608</td>
      <td>0.222279</td>
      <td>0.108133</td>
      <td>-0.026028</td>
      <td>-0.616392</td>
      <td>-1.088837</td>
      <td>-0.010783</td>
      <td>0.432667</td>
      <td>-0.467602</td>
      <td>0.015110</td>
      <td>0.325949</td>
      <td>-0.087025</td>
      <td>-0.097339</td>
      <td>0.793985</td>
      <td>-0.448321</td>
      <td>0.612663</td>
      <td>-0.137104</td>
      <td>0.126928</td>
      <td>0.657627</td>
      <td>0.394683</td>
      <td>0.837972</td>
      <td>-0.413993</td>
      <td>0.185797</td>
      <td>0.828088</td>
      <td>1.322938</td>
      <td>0.066723</td>
      <td>0.761940</td>
      <td>1.208557</td>
      <td>...</td>
      <td>0.008502</td>
      <td>0.624323</td>
      <td>0.107349</td>
      <td>-0.832729</td>
      <td>0.267422</td>
      <td>0.323795</td>
      <td>-0.660494</td>
      <td>-0.154956</td>
      <td>-0.895024</td>
      <td>0.103490</td>
      <td>0.094068</td>
      <td>0.459419</td>
      <td>-0.449392</td>
      <td>-0.913368</td>
      <td>0.122744</td>
      <td>-0.903303</td>
      <td>-0.653436</td>
      <td>-0.991565</td>
      <td>0.072057</td>
      <td>0.662177</td>
      <td>1.376662</td>
      <td>0.453671</td>
      <td>-0.288739</td>
      <td>-0.335285</td>
      <td>0.796830</td>
      <td>0.113783</td>
      <td>0.409265</td>
      <td>0.462382</td>
      <td>0.503939</td>
      <td>0.578497</td>
      <td>-0.060685</td>
      <td>0.231024</td>
      <td>-0.042646</td>
      <td>-0.468881</td>
      <td>0.625423</td>
      <td>0.370042</td>
      <td>-0.126189</td>
      <td>1.294150</td>
      <td>0.997744</td>
      <td>0.904785</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.291869</td>
      <td>0.225268</td>
      <td>-1.072721</td>
      <td>-1.039636</td>
      <td>-0.140396</td>
      <td>-0.324973</td>
      <td>0.415871</td>
      <td>1.117233</td>
      <td>0.492460</td>
      <td>0.088252</td>
      <td>0.273455</td>
      <td>-0.010424</td>
      <td>-0.483222</td>
      <td>-1.093422</td>
      <td>-1.212462</td>
      <td>-0.313157</td>
      <td>0.140451</td>
      <td>-0.269403</td>
      <td>-0.359692</td>
      <td>-0.595901</td>
      <td>0.325109</td>
      <td>0.615166</td>
      <td>0.512607</td>
      <td>0.022700</td>
      <td>-0.842603</td>
      <td>-0.058605</td>
      <td>0.353475</td>
      <td>-0.077687</td>
      <td>0.077909</td>
      <td>-0.821198</td>
      <td>0.121924</td>
      <td>-0.325674</td>
      <td>0.078894</td>
      <td>-0.102435</td>
      <td>-0.384822</td>
      <td>-0.907021</td>
      <td>0.186433</td>
      <td>0.979077</td>
      <td>0.855646</td>
      <td>0.223740</td>
      <td>...</td>
      <td>0.319769</td>
      <td>-0.256676</td>
      <td>0.435193</td>
      <td>-0.906528</td>
      <td>-0.572689</td>
      <td>0.654408</td>
      <td>-0.142938</td>
      <td>-0.430135</td>
      <td>-1.313413</td>
      <td>0.308654</td>
      <td>0.459450</td>
      <td>0.038621</td>
      <td>-0.121462</td>
      <td>-0.303996</td>
      <td>0.245910</td>
      <td>0.091298</td>
      <td>0.084694</td>
      <td>-0.865274</td>
      <td>0.228666</td>
      <td>-0.165527</td>
      <td>0.710123</td>
      <td>0.520397</td>
      <td>0.329709</td>
      <td>0.289475</td>
      <td>0.583635</td>
      <td>0.535946</td>
      <td>0.181493</td>
      <td>0.782828</td>
      <td>0.120186</td>
      <td>-0.838333</td>
      <td>-0.698494</td>
      <td>0.381222</td>
      <td>0.774694</td>
      <td>0.683159</td>
      <td>0.820085</td>
      <td>0.799790</td>
      <td>0.851825</td>
      <td>0.224783</td>
      <td>0.146340</td>
      <td>0.021563</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.361173</td>
      <td>-0.619475</td>
      <td>0.418254</td>
      <td>0.034759</td>
      <td>0.569288</td>
      <td>0.044083</td>
      <td>1.059670</td>
      <td>0.474902</td>
      <td>-0.158480</td>
      <td>-0.018887</td>
      <td>0.503553</td>
      <td>-0.015849</td>
      <td>1.205656</td>
      <td>-0.317850</td>
      <td>-0.685716</td>
      <td>0.080843</td>
      <td>-0.251673</td>
      <td>-0.199767</td>
      <td>0.852154</td>
      <td>0.266180</td>
      <td>-0.231972</td>
      <td>0.841165</td>
      <td>1.092287</td>
      <td>-0.144133</td>
      <td>-0.480089</td>
      <td>0.287707</td>
      <td>0.144725</td>
      <td>0.051685</td>
      <td>0.422519</td>
      <td>-0.491786</td>
      <td>-0.148020</td>
      <td>0.022846</td>
      <td>0.426390</td>
      <td>-0.198546</td>
      <td>-0.522343</td>
      <td>0.200920</td>
      <td>0.066230</td>
      <td>0.290025</td>
      <td>0.136729</td>
      <td>0.597453</td>
      <td>...</td>
      <td>0.376585</td>
      <td>0.919037</td>
      <td>0.180065</td>
      <td>-0.494345</td>
      <td>0.088036</td>
      <td>-0.342064</td>
      <td>-0.167542</td>
      <td>0.127705</td>
      <td>0.330890</td>
      <td>-0.302123</td>
      <td>0.553287</td>
      <td>-0.791884</td>
      <td>-0.918713</td>
      <td>-0.300350</td>
      <td>-0.707062</td>
      <td>-0.606802</td>
      <td>-0.066763</td>
      <td>-0.282592</td>
      <td>1.058319</td>
      <td>0.781674</td>
      <td>2.007157</td>
      <td>1.437828</td>
      <td>-0.080324</td>
      <td>0.742754</td>
      <td>0.907097</td>
      <td>1.406089</td>
      <td>0.523979</td>
      <td>-0.095498</td>
      <td>0.215444</td>
      <td>-0.291051</td>
      <td>-0.366990</td>
      <td>-0.062974</td>
      <td>-0.127687</td>
      <td>0.197639</td>
      <td>0.314444</td>
      <td>0.557993</td>
      <td>-0.324169</td>
      <td>-0.061716</td>
      <td>0.069238</td>
      <td>0.005719</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.988819</td>
      <td>1.425817</td>
      <td>0.893588</td>
      <td>0.861711</td>
      <td>0.878114</td>
      <td>-0.433338</td>
      <td>0.037935</td>
      <td>0.109361</td>
      <td>0.328942</td>
      <td>0.273001</td>
      <td>0.325558</td>
      <td>0.350535</td>
      <td>-0.180987</td>
      <td>0.220080</td>
      <td>-0.924404</td>
      <td>-0.356607</td>
      <td>0.014637</td>
      <td>-0.813717</td>
      <td>-1.385905</td>
      <td>-0.179675</td>
      <td>0.709752</td>
      <td>-0.143380</td>
      <td>-1.422547</td>
      <td>-0.490553</td>
      <td>0.999210</td>
      <td>0.946492</td>
      <td>0.166130</td>
      <td>-0.969488</td>
      <td>0.016818</td>
      <td>-0.879125</td>
      <td>0.191707</td>
      <td>-0.819155</td>
      <td>0.605862</td>
      <td>-0.944794</td>
      <td>-0.450565</td>
      <td>0.327176</td>
      <td>0.003629</td>
      <td>-0.211443</td>
      <td>2.040693</td>
      <td>0.724364</td>
      <td>...</td>
      <td>-0.408660</td>
      <td>0.564734</td>
      <td>1.052635</td>
      <td>-0.415556</td>
      <td>-0.268575</td>
      <td>0.262870</td>
      <td>0.505632</td>
      <td>-0.178450</td>
      <td>-0.658882</td>
      <td>0.328262</td>
      <td>0.883190</td>
      <td>0.420486</td>
      <td>-0.126436</td>
      <td>-1.077000</td>
      <td>-1.333232</td>
      <td>-0.584811</td>
      <td>0.082566</td>
      <td>-0.936281</td>
      <td>0.580156</td>
      <td>0.160269</td>
      <td>0.204597</td>
      <td>-0.137636</td>
      <td>-0.839192</td>
      <td>-0.244556</td>
      <td>-0.198974</td>
      <td>0.873522</td>
      <td>0.784416</td>
      <td>0.062488</td>
      <td>0.430418</td>
      <td>0.228345</td>
      <td>1.311450</td>
      <td>-0.382617</td>
      <td>0.656248</td>
      <td>0.017103</td>
      <td>-0.169709</td>
      <td>0.587079</td>
      <td>-0.651609</td>
      <td>2.149253</td>
      <td>1.341900</td>
      <td>0.750085</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-1.211248</td>
      <td>0.276705</td>
      <td>0.571464</td>
      <td>-0.249791</td>
      <td>0.391371</td>
      <td>0.250446</td>
      <td>0.300167</td>
      <td>0.640414</td>
      <td>-0.026925</td>
      <td>0.140609</td>
      <td>1.230475</td>
      <td>-0.746670</td>
      <td>0.457116</td>
      <td>-1.088063</td>
      <td>0.573035</td>
      <td>1.036370</td>
      <td>-0.351509</td>
      <td>-0.112083</td>
      <td>0.439861</td>
      <td>1.024570</td>
      <td>0.438648</td>
      <td>0.850766</td>
      <td>0.198362</td>
      <td>0.569120</td>
      <td>0.106448</td>
      <td>0.236562</td>
      <td>0.358526</td>
      <td>-0.486689</td>
      <td>0.884864</td>
      <td>0.075181</td>
      <td>-0.092159</td>
      <td>-0.681201</td>
      <td>0.896968</td>
      <td>0.221538</td>
      <td>-1.134234</td>
      <td>-0.708752</td>
      <td>-0.519499</td>
      <td>-0.254648</td>
      <td>1.228650</td>
      <td>0.363592</td>
      <td>...</td>
      <td>0.827262</td>
      <td>0.586895</td>
      <td>0.887330</td>
      <td>-0.215650</td>
      <td>0.123823</td>
      <td>0.141101</td>
      <td>0.945279</td>
      <td>-0.906922</td>
      <td>-0.683278</td>
      <td>-0.350914</td>
      <td>0.782713</td>
      <td>-0.201879</td>
      <td>-0.693368</td>
      <td>-0.783578</td>
      <td>-0.452183</td>
      <td>-0.604015</td>
      <td>0.060480</td>
      <td>-0.902798</td>
      <td>-0.084927</td>
      <td>0.087151</td>
      <td>-0.510654</td>
      <td>0.153070</td>
      <td>-0.066629</td>
      <td>0.049677</td>
      <td>0.064382</td>
      <td>-0.089996</td>
      <td>0.419945</td>
      <td>0.630693</td>
      <td>-0.816398</td>
      <td>0.348302</td>
      <td>-0.227878</td>
      <td>0.356422</td>
      <td>-0.265376</td>
      <td>0.176247</td>
      <td>-0.361572</td>
      <td>-0.451377</td>
      <td>-0.116189</td>
      <td>-1.717121</td>
      <td>-1.281047</td>
      <td>-0.762054</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.589664</td>
      <td>0.109365</td>
      <td>0.190929</td>
      <td>-1.024634</td>
      <td>-0.712691</td>
      <td>-0.480450</td>
      <td>1.228025</td>
      <td>1.274767</td>
      <td>-0.119663</td>
      <td>-0.355209</td>
      <td>0.446200</td>
      <td>-0.389312</td>
      <td>-0.240647</td>
      <td>-1.289116</td>
      <td>-0.726626</td>
      <td>0.101878</td>
      <td>-0.341434</td>
      <td>-0.106573</td>
      <td>1.020131</td>
      <td>0.599257</td>
      <td>0.677987</td>
      <td>0.217963</td>
      <td>-0.691735</td>
      <td>-0.062234</td>
      <td>0.609187</td>
      <td>0.475418</td>
      <td>-0.389718</td>
      <td>0.465766</td>
      <td>1.111613</td>
      <td>0.622132</td>
      <td>-0.009862</td>
      <td>-0.805247</td>
      <td>0.492551</td>
      <td>1.182223</td>
      <td>-0.089308</td>
      <td>-0.220926</td>
      <td>-0.431693</td>
      <td>-0.394184</td>
      <td>1.067316</td>
      <td>0.205918</td>
      <td>...</td>
      <td>0.197716</td>
      <td>-0.361397</td>
      <td>0.580165</td>
      <td>0.466752</td>
      <td>0.186238</td>
      <td>-0.034319</td>
      <td>0.093553</td>
      <td>0.378905</td>
      <td>-1.493738</td>
      <td>-0.836392</td>
      <td>0.745881</td>
      <td>0.072401</td>
      <td>-1.408720</td>
      <td>-0.949486</td>
      <td>-0.056665</td>
      <td>-1.242401</td>
      <td>-0.781813</td>
      <td>-1.285044</td>
      <td>0.401963</td>
      <td>-0.055264</td>
      <td>-0.602868</td>
      <td>-0.229368</td>
      <td>-0.959289</td>
      <td>0.140773</td>
      <td>0.337389</td>
      <td>0.510379</td>
      <td>0.606028</td>
      <td>0.034445</td>
      <td>0.087106</td>
      <td>-0.146678</td>
      <td>0.564419</td>
      <td>0.323019</td>
      <td>1.109815</td>
      <td>0.690871</td>
      <td>-1.558252</td>
      <td>-0.916826</td>
      <td>-0.498791</td>
      <td>-0.246356</td>
      <td>-0.278768</td>
      <td>-0.098137</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.266270</td>
      <td>0.207244</td>
      <td>1.275897</td>
      <td>-0.495595</td>
      <td>0.448679</td>
      <td>-0.064259</td>
      <td>0.040886</td>
      <td>0.450538</td>
      <td>0.734074</td>
      <td>0.031080</td>
      <td>0.035021</td>
      <td>-0.001821</td>
      <td>-0.483257</td>
      <td>-0.258873</td>
      <td>-0.126326</td>
      <td>-0.812507</td>
      <td>-1.468968</td>
      <td>-0.594179</td>
      <td>0.052665</td>
      <td>0.568168</td>
      <td>-0.023155</td>
      <td>1.069440</td>
      <td>0.503663</td>
      <td>-0.309522</td>
      <td>0.761286</td>
      <td>0.027779</td>
      <td>-0.995242</td>
      <td>-0.082855</td>
      <td>1.531690</td>
      <td>-0.510569</td>
      <td>1.158954</td>
      <td>-0.545806</td>
      <td>0.029246</td>
      <td>-0.474332</td>
      <td>-1.927487</td>
      <td>-0.415763</td>
      <td>1.172591</td>
      <td>0.349522</td>
      <td>0.919131</td>
      <td>0.031397</td>
      <td>...</td>
      <td>-1.842457</td>
      <td>0.015507</td>
      <td>-0.138265</td>
      <td>-1.222032</td>
      <td>0.257435</td>
      <td>-0.628529</td>
      <td>0.208874</td>
      <td>-1.250482</td>
      <td>-1.146741</td>
      <td>-0.766960</td>
      <td>0.101583</td>
      <td>0.317981</td>
      <td>-0.135068</td>
      <td>-0.223190</td>
      <td>0.055396</td>
      <td>-0.031499</td>
      <td>-0.893074</td>
      <td>-1.030647</td>
      <td>-0.331311</td>
      <td>0.433181</td>
      <td>0.247102</td>
      <td>0.676250</td>
      <td>0.152050</td>
      <td>0.766724</td>
      <td>1.347623</td>
      <td>1.146517</td>
      <td>1.016700</td>
      <td>1.363394</td>
      <td>0.034383</td>
      <td>0.402876</td>
      <td>0.288806</td>
      <td>1.316057</td>
      <td>-0.334290</td>
      <td>1.296353</td>
      <td>-0.261215</td>
      <td>-0.349749</td>
      <td>-0.156393</td>
      <td>2.230307</td>
      <td>1.760813</td>
      <td>0.985718</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-0.226188</td>
      <td>0.718037</td>
      <td>-0.220190</td>
      <td>-0.509278</td>
      <td>0.775083</td>
      <td>-0.053156</td>
      <td>0.576421</td>
      <td>0.406881</td>
      <td>-0.593214</td>
      <td>-0.321689</td>
      <td>-0.336839</td>
      <td>0.470715</td>
      <td>0.477196</td>
      <td>0.108223</td>
      <td>0.081992</td>
      <td>0.086812</td>
      <td>0.723306</td>
      <td>-0.348218</td>
      <td>0.944158</td>
      <td>-0.602337</td>
      <td>-0.779054</td>
      <td>-0.306827</td>
      <td>-0.523990</td>
      <td>-0.124181</td>
      <td>0.572938</td>
      <td>-0.099628</td>
      <td>0.046495</td>
      <td>-0.251263</td>
      <td>-0.056141</td>
      <td>0.609945</td>
      <td>0.813990</td>
      <td>-0.328862</td>
      <td>1.007070</td>
      <td>0.557915</td>
      <td>-1.060506</td>
      <td>0.122103</td>
      <td>-0.351537</td>
      <td>0.213410</td>
      <td>-0.270233</td>
      <td>1.299124</td>
      <td>...</td>
      <td>0.585489</td>
      <td>0.214194</td>
      <td>-0.331172</td>
      <td>-1.016033</td>
      <td>0.345797</td>
      <td>0.639784</td>
      <td>0.453189</td>
      <td>0.710199</td>
      <td>0.476716</td>
      <td>0.226367</td>
      <td>0.082740</td>
      <td>-0.603899</td>
      <td>-0.656180</td>
      <td>-0.439201</td>
      <td>-0.425790</td>
      <td>-0.141287</td>
      <td>0.404455</td>
      <td>0.353719</td>
      <td>0.234679</td>
      <td>0.397364</td>
      <td>0.667536</td>
      <td>0.755450</td>
      <td>0.103622</td>
      <td>0.133363</td>
      <td>-0.404451</td>
      <td>0.156579</td>
      <td>0.595011</td>
      <td>-0.888786</td>
      <td>0.186323</td>
      <td>1.112324</td>
      <td>1.501849</td>
      <td>0.973971</td>
      <td>0.471628</td>
      <td>-0.872779</td>
      <td>0.416538</td>
      <td>0.320860</td>
      <td>-0.237653</td>
      <td>0.336454</td>
      <td>0.738580</td>
      <td>0.217623</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.295150</td>
      <td>-0.304424</td>
      <td>-0.425335</td>
      <td>-0.279071</td>
      <td>0.650335</td>
      <td>-0.139634</td>
      <td>0.398677</td>
      <td>0.345582</td>
      <td>-0.434893</td>
      <td>-0.677268</td>
      <td>0.028442</td>
      <td>-0.003164</td>
      <td>-0.512306</td>
      <td>-1.456173</td>
      <td>-0.144419</td>
      <td>0.892335</td>
      <td>-0.653659</td>
      <td>0.824197</td>
      <td>-0.519375</td>
      <td>0.615369</td>
      <td>-0.553754</td>
      <td>-0.286287</td>
      <td>-1.317869</td>
      <td>0.101268</td>
      <td>-0.443620</td>
      <td>1.157286</td>
      <td>-0.296319</td>
      <td>-0.503601</td>
      <td>-0.090249</td>
      <td>0.407931</td>
      <td>0.392668</td>
      <td>-0.113864</td>
      <td>0.150939</td>
      <td>-0.525745</td>
      <td>0.023641</td>
      <td>-0.599220</td>
      <td>0.714354</td>
      <td>-0.952353</td>
      <td>-0.021832</td>
      <td>0.344935</td>
      <td>...</td>
      <td>-0.169210</td>
      <td>0.087351</td>
      <td>0.368867</td>
      <td>0.424601</td>
      <td>-0.516793</td>
      <td>-0.091160</td>
      <td>-0.574991</td>
      <td>-0.004182</td>
      <td>0.232562</td>
      <td>0.476324</td>
      <td>0.559825</td>
      <td>0.284219</td>
      <td>0.234041</td>
      <td>0.509305</td>
      <td>0.771146</td>
      <td>-1.168599</td>
      <td>-0.872927</td>
      <td>-0.998400</td>
      <td>0.398978</td>
      <td>0.341623</td>
      <td>0.227808</td>
      <td>0.116204</td>
      <td>0.731894</td>
      <td>0.107681</td>
      <td>0.171788</td>
      <td>0.940664</td>
      <td>0.416554</td>
      <td>-0.086042</td>
      <td>-0.447354</td>
      <td>0.429817</td>
      <td>0.113628</td>
      <td>0.395647</td>
      <td>0.305271</td>
      <td>-0.144221</td>
      <td>-0.860657</td>
      <td>-0.108153</td>
      <td>-0.476939</td>
      <td>-1.038373</td>
      <td>-0.697887</td>
      <td>-0.479230</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.293690</td>
      <td>-0.983238</td>
      <td>-0.516452</td>
      <td>-0.450649</td>
      <td>-0.104046</td>
      <td>-0.874684</td>
      <td>0.737874</td>
      <td>-0.057299</td>
      <td>-0.935781</td>
      <td>-0.349951</td>
      <td>0.208840</td>
      <td>-0.642113</td>
      <td>-0.216101</td>
      <td>-0.484400</td>
      <td>-1.278798</td>
      <td>-0.760317</td>
      <td>0.078924</td>
      <td>0.319284</td>
      <td>0.173683</td>
      <td>0.025185</td>
      <td>-0.449832</td>
      <td>0.526433</td>
      <td>-0.199100</td>
      <td>-0.332333</td>
      <td>0.134649</td>
      <td>0.594529</td>
      <td>-0.436185</td>
      <td>-0.276977</td>
      <td>0.987723</td>
      <td>-0.232433</td>
      <td>-1.507980</td>
      <td>0.155237</td>
      <td>-0.077261</td>
      <td>-0.753902</td>
      <td>-0.389653</td>
      <td>-0.570050</td>
      <td>-0.037338</td>
      <td>0.839197</td>
      <td>0.599762</td>
      <td>0.170092</td>
      <td>...</td>
      <td>1.738115</td>
      <td>0.926929</td>
      <td>0.785027</td>
      <td>-0.481366</td>
      <td>0.155024</td>
      <td>0.011162</td>
      <td>0.320277</td>
      <td>-0.842354</td>
      <td>-0.818326</td>
      <td>0.737581</td>
      <td>0.058238</td>
      <td>-0.273524</td>
      <td>-1.034254</td>
      <td>-0.133751</td>
      <td>0.342691</td>
      <td>-0.512904</td>
      <td>0.160352</td>
      <td>-0.740943</td>
      <td>-0.649549</td>
      <td>0.468048</td>
      <td>0.375785</td>
      <td>0.739327</td>
      <td>0.690816</td>
      <td>1.175237</td>
      <td>-0.043625</td>
      <td>0.177802</td>
      <td>-0.041695</td>
      <td>1.067849</td>
      <td>-0.247359</td>
      <td>0.602064</td>
      <td>0.557116</td>
      <td>0.274305</td>
      <td>0.093155</td>
      <td>1.218988</td>
      <td>0.279810</td>
      <td>-0.696453</td>
      <td>0.580960</td>
      <td>-2.574247</td>
      <td>-2.151335</td>
      <td>-0.773356</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.193857</td>
      <td>-0.476094</td>
      <td>1.180628</td>
      <td>0.135414</td>
      <td>0.002868</td>
      <td>0.159284</td>
      <td>0.449673</td>
      <td>0.593801</td>
      <td>0.144158</td>
      <td>-0.713367</td>
      <td>-0.982838</td>
      <td>-1.319391</td>
      <td>0.362572</td>
      <td>-0.987229</td>
      <td>0.565761</td>
      <td>-0.014000</td>
      <td>0.604592</td>
      <td>-0.306186</td>
      <td>-0.368756</td>
      <td>1.361045</td>
      <td>0.689719</td>
      <td>0.124462</td>
      <td>0.019014</td>
      <td>-0.346698</td>
      <td>0.566118</td>
      <td>-0.027530</td>
      <td>-0.914600</td>
      <td>0.347471</td>
      <td>0.623931</td>
      <td>-0.417923</td>
      <td>-0.502093</td>
      <td>-0.495639</td>
      <td>0.191768</td>
      <td>-0.346388</td>
      <td>-1.200173</td>
      <td>0.190927</td>
      <td>0.492044</td>
      <td>0.250367</td>
      <td>0.627780</td>
      <td>-0.105393</td>
      <td>...</td>
      <td>-0.401576</td>
      <td>0.497117</td>
      <td>0.604059</td>
      <td>1.224378</td>
      <td>0.919967</td>
      <td>-0.585035</td>
      <td>-0.345902</td>
      <td>-0.528870</td>
      <td>-0.827963</td>
      <td>0.089331</td>
      <td>-0.030879</td>
      <td>0.081164</td>
      <td>-0.451105</td>
      <td>-0.750185</td>
      <td>-0.583829</td>
      <td>-0.683414</td>
      <td>-0.052081</td>
      <td>0.185414</td>
      <td>0.953300</td>
      <td>1.124936</td>
      <td>0.858505</td>
      <td>0.080426</td>
      <td>0.227112</td>
      <td>-0.157557</td>
      <td>-1.296784</td>
      <td>0.892299</td>
      <td>0.403642</td>
      <td>0.335273</td>
      <td>-0.442998</td>
      <td>0.261752</td>
      <td>0.324051</td>
      <td>0.375429</td>
      <td>0.595442</td>
      <td>-0.270469</td>
      <td>-1.046412</td>
      <td>0.048101</td>
      <td>0.016248</td>
      <td>0.890739</td>
      <td>0.418792</td>
      <td>0.146575</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.345805</td>
      <td>-0.787382</td>
      <td>-0.902440</td>
      <td>-0.126609</td>
      <td>1.157429</td>
      <td>-0.108792</td>
      <td>-0.055599</td>
      <td>0.490627</td>
      <td>-0.150138</td>
      <td>0.080441</td>
      <td>0.190748</td>
      <td>-0.139134</td>
      <td>-0.252557</td>
      <td>-0.901606</td>
      <td>-0.997491</td>
      <td>-0.559668</td>
      <td>-0.181554</td>
      <td>0.733355</td>
      <td>0.467840</td>
      <td>0.482563</td>
      <td>-0.252804</td>
      <td>-0.579769</td>
      <td>-0.970987</td>
      <td>-0.844914</td>
      <td>0.142169</td>
      <td>0.402829</td>
      <td>0.858734</td>
      <td>0.397651</td>
      <td>0.557446</td>
      <td>0.293564</td>
      <td>1.073897</td>
      <td>-0.372833</td>
      <td>0.807454</td>
      <td>-0.269106</td>
      <td>-0.426589</td>
      <td>0.021227</td>
      <td>0.158182</td>
      <td>-0.125699</td>
      <td>0.575465</td>
      <td>0.396341</td>
      <td>...</td>
      <td>0.223167</td>
      <td>0.178269</td>
      <td>1.299652</td>
      <td>-0.460609</td>
      <td>-0.040412</td>
      <td>0.382189</td>
      <td>-0.084378</td>
      <td>-0.283491</td>
      <td>1.099547</td>
      <td>0.045313</td>
      <td>0.472689</td>
      <td>0.039720</td>
      <td>-0.808641</td>
      <td>-0.066095</td>
      <td>-1.235338</td>
      <td>-1.179279</td>
      <td>0.069118</td>
      <td>-0.707522</td>
      <td>0.463164</td>
      <td>-0.251394</td>
      <td>0.874373</td>
      <td>0.877294</td>
      <td>0.129736</td>
      <td>-0.285707</td>
      <td>0.612954</td>
      <td>-0.290165</td>
      <td>-0.060045</td>
      <td>0.712379</td>
      <td>0.276981</td>
      <td>0.820254</td>
      <td>-0.166644</td>
      <td>-0.063466</td>
      <td>0.627407</td>
      <td>0.139176</td>
      <td>-0.247089</td>
      <td>1.266240</td>
      <td>0.795786</td>
      <td>-1.706154</td>
      <td>-0.444609</td>
      <td>-0.493667</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.186543</td>
      <td>-0.316370</td>
      <td>-0.191762</td>
      <td>-1.053656</td>
      <td>-1.576413</td>
      <td>0.489009</td>
      <td>1.033471</td>
      <td>0.084872</td>
      <td>-0.112630</td>
      <td>-0.580325</td>
      <td>0.018960</td>
      <td>0.086339</td>
      <td>-0.669882</td>
      <td>0.288350</td>
      <td>0.297443</td>
      <td>-0.660576</td>
      <td>-0.778434</td>
      <td>0.641967</td>
      <td>1.736772</td>
      <td>0.245138</td>
      <td>0.044958</td>
      <td>-0.097404</td>
      <td>-0.197053</td>
      <td>-0.031306</td>
      <td>-0.631124</td>
      <td>-0.964175</td>
      <td>-0.204949</td>
      <td>-0.416243</td>
      <td>0.010134</td>
      <td>-0.851013</td>
      <td>-0.416509</td>
      <td>-0.848086</td>
      <td>0.282459</td>
      <td>0.895227</td>
      <td>-0.024216</td>
      <td>-0.087286</td>
      <td>-0.067256</td>
      <td>0.592538</td>
      <td>1.065776</td>
      <td>1.503415</td>
      <td>...</td>
      <td>0.944463</td>
      <td>-0.163690</td>
      <td>0.297414</td>
      <td>-0.284851</td>
      <td>0.829355</td>
      <td>-0.497861</td>
      <td>0.516587</td>
      <td>0.916719</td>
      <td>0.054253</td>
      <td>-0.261119</td>
      <td>-0.154819</td>
      <td>0.418050</td>
      <td>-0.817278</td>
      <td>1.014746</td>
      <td>0.430196</td>
      <td>-0.695067</td>
      <td>-0.138264</td>
      <td>-0.186456</td>
      <td>-0.211926</td>
      <td>-0.749412</td>
      <td>-0.800197</td>
      <td>-0.119309</td>
      <td>0.476010</td>
      <td>-0.683825</td>
      <td>0.048454</td>
      <td>1.694553</td>
      <td>0.664862</td>
      <td>1.486310</td>
      <td>1.629818</td>
      <td>1.241042</td>
      <td>0.546137</td>
      <td>0.505560</td>
      <td>0.628586</td>
      <td>0.948160</td>
      <td>0.669213</td>
      <td>0.220350</td>
      <td>-0.739590</td>
      <td>-2.234486</td>
      <td>-1.357698</td>
      <td>-0.864429</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.756414</td>
      <td>0.216281</td>
      <td>1.024816</td>
      <td>-0.700801</td>
      <td>0.445290</td>
      <td>-0.118251</td>
      <td>0.262060</td>
      <td>0.079012</td>
      <td>-0.352525</td>
      <td>-0.886428</td>
      <td>0.748961</td>
      <td>0.204127</td>
      <td>1.087414</td>
      <td>0.138012</td>
      <td>0.102979</td>
      <td>0.415205</td>
      <td>-0.537837</td>
      <td>0.142778</td>
      <td>0.952258</td>
      <td>-1.079549</td>
      <td>-0.428948</td>
      <td>0.783697</td>
      <td>-0.143843</td>
      <td>-0.498463</td>
      <td>-1.031520</td>
      <td>0.159952</td>
      <td>-0.439079</td>
      <td>-0.238808</td>
      <td>-0.468045</td>
      <td>-1.029944</td>
      <td>-0.470071</td>
      <td>0.193553</td>
      <td>0.172218</td>
      <td>0.161148</td>
      <td>0.468988</td>
      <td>-0.582518</td>
      <td>-0.893802</td>
      <td>-0.064959</td>
      <td>0.777617</td>
      <td>0.877631</td>
      <td>...</td>
      <td>0.008900</td>
      <td>-0.144629</td>
      <td>0.359822</td>
      <td>-0.454043</td>
      <td>1.145556</td>
      <td>0.076006</td>
      <td>0.981924</td>
      <td>-0.591559</td>
      <td>0.233953</td>
      <td>0.857781</td>
      <td>0.736382</td>
      <td>-0.370967</td>
      <td>-0.245929</td>
      <td>-0.762860</td>
      <td>0.141112</td>
      <td>-0.469224</td>
      <td>-0.170718</td>
      <td>0.038028</td>
      <td>1.589142</td>
      <td>1.032107</td>
      <td>0.173882</td>
      <td>0.492647</td>
      <td>-0.040786</td>
      <td>1.136633</td>
      <td>0.553980</td>
      <td>-0.639256</td>
      <td>-0.688292</td>
      <td>0.966540</td>
      <td>0.768771</td>
      <td>0.200620</td>
      <td>0.094653</td>
      <td>0.942462</td>
      <td>0.858079</td>
      <td>0.433342</td>
      <td>0.088067</td>
      <td>-0.091964</td>
      <td>-0.353608</td>
      <td>1.522075</td>
      <td>1.374909</td>
      <td>1.332784</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.240639</td>
      <td>-0.325402</td>
      <td>0.115556</td>
      <td>-0.785085</td>
      <td>0.381923</td>
      <td>0.387084</td>
      <td>0.174236</td>
      <td>-0.409930</td>
      <td>-0.914930</td>
      <td>-0.119754</td>
      <td>0.226413</td>
      <td>0.317665</td>
      <td>0.395100</td>
      <td>0.080233</td>
      <td>-0.493875</td>
      <td>0.586980</td>
      <td>-0.140089</td>
      <td>-0.386603</td>
      <td>0.388976</td>
      <td>-0.472519</td>
      <td>-0.675946</td>
      <td>-0.528067</td>
      <td>-0.482424</td>
      <td>0.194066</td>
      <td>0.036443</td>
      <td>0.213727</td>
      <td>0.516552</td>
      <td>0.698446</td>
      <td>-0.302535</td>
      <td>-0.466494</td>
      <td>0.144850</td>
      <td>0.781886</td>
      <td>0.149032</td>
      <td>0.259090</td>
      <td>-0.586830</td>
      <td>-0.409998</td>
      <td>-0.533422</td>
      <td>-0.118476</td>
      <td>-0.006903</td>
      <td>-0.519694</td>
      <td>...</td>
      <td>0.607231</td>
      <td>0.938071</td>
      <td>1.040208</td>
      <td>-0.525778</td>
      <td>-0.193221</td>
      <td>0.566928</td>
      <td>-0.405142</td>
      <td>-0.833898</td>
      <td>-0.737877</td>
      <td>-0.371263</td>
      <td>0.304235</td>
      <td>-0.053065</td>
      <td>-0.671086</td>
      <td>-0.559048</td>
      <td>0.331727</td>
      <td>-0.061472</td>
      <td>0.040099</td>
      <td>-0.865843</td>
      <td>0.038546</td>
      <td>-0.298301</td>
      <td>1.132404</td>
      <td>0.985065</td>
      <td>-0.746157</td>
      <td>0.566348</td>
      <td>1.497890</td>
      <td>0.965097</td>
      <td>0.853202</td>
      <td>-0.299150</td>
      <td>0.015610</td>
      <td>0.435388</td>
      <td>-0.191678</td>
      <td>0.794668</td>
      <td>0.622794</td>
      <td>0.984550</td>
      <td>0.694782</td>
      <td>-0.029781</td>
      <td>-0.520759</td>
      <td>-0.522629</td>
      <td>-0.830632</td>
      <td>-0.835107</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.445141</td>
      <td>0.127731</td>
      <td>0.289358</td>
      <td>0.721501</td>
      <td>0.559088</td>
      <td>0.747569</td>
      <td>0.293428</td>
      <td>-0.642065</td>
      <td>0.779892</td>
      <td>-1.075659</td>
      <td>0.215215</td>
      <td>0.768772</td>
      <td>1.313868</td>
      <td>0.608129</td>
      <td>0.286742</td>
      <td>0.441693</td>
      <td>-0.513908</td>
      <td>0.210753</td>
      <td>0.151696</td>
      <td>0.616252</td>
      <td>-0.078652</td>
      <td>-0.151855</td>
      <td>-0.868991</td>
      <td>-0.246231</td>
      <td>-0.354143</td>
      <td>0.262419</td>
      <td>0.141593</td>
      <td>-0.251623</td>
      <td>0.648466</td>
      <td>-0.266646</td>
      <td>-0.464459</td>
      <td>-0.797293</td>
      <td>0.133857</td>
      <td>0.355063</td>
      <td>-0.067933</td>
      <td>0.170969</td>
      <td>-0.188038</td>
      <td>0.589388</td>
      <td>0.793892</td>
      <td>-0.203173</td>
      <td>...</td>
      <td>1.031973</td>
      <td>0.625005</td>
      <td>0.963251</td>
      <td>-0.760618</td>
      <td>0.590813</td>
      <td>0.682478</td>
      <td>0.683214</td>
      <td>-0.342190</td>
      <td>-0.747174</td>
      <td>-0.279644</td>
      <td>1.059906</td>
      <td>0.883026</td>
      <td>-1.019912</td>
      <td>-0.514773</td>
      <td>-0.234772</td>
      <td>-1.221456</td>
      <td>-0.667829</td>
      <td>-1.037942</td>
      <td>0.209842</td>
      <td>-0.618055</td>
      <td>-0.648572</td>
      <td>0.206095</td>
      <td>0.142580</td>
      <td>0.826485</td>
      <td>-0.150405</td>
      <td>0.686937</td>
      <td>1.137712</td>
      <td>-0.016194</td>
      <td>-1.745127</td>
      <td>0.076192</td>
      <td>-0.089970</td>
      <td>0.477633</td>
      <td>0.133807</td>
      <td>-0.498386</td>
      <td>-0.724784</td>
      <td>0.499269</td>
      <td>0.077576</td>
      <td>-0.296924</td>
      <td>-0.085484</td>
      <td>-0.448832</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.314681</td>
      <td>-0.412344</td>
      <td>-0.278830</td>
      <td>-0.846365</td>
      <td>0.518995</td>
      <td>0.035500</td>
      <td>0.271767</td>
      <td>0.463418</td>
      <td>0.956314</td>
      <td>-0.158292</td>
      <td>-0.324718</td>
      <td>-0.924757</td>
      <td>0.276357</td>
      <td>-1.511036</td>
      <td>0.538196</td>
      <td>-0.109213</td>
      <td>-1.271968</td>
      <td>-0.038959</td>
      <td>0.244317</td>
      <td>-0.427292</td>
      <td>-0.060827</td>
      <td>0.307473</td>
      <td>0.206995</td>
      <td>0.206663</td>
      <td>0.102560</td>
      <td>0.293544</td>
      <td>0.160361</td>
      <td>-0.534531</td>
      <td>-0.452941</td>
      <td>-0.412089</td>
      <td>-0.157903</td>
      <td>-0.356588</td>
      <td>0.759084</td>
      <td>0.713967</td>
      <td>0.703595</td>
      <td>0.444767</td>
      <td>0.265847</td>
      <td>0.353958</td>
      <td>0.012369</td>
      <td>0.175085</td>
      <td>...</td>
      <td>-0.284259</td>
      <td>-0.259000</td>
      <td>-0.160209</td>
      <td>0.133732</td>
      <td>-0.486713</td>
      <td>-0.745450</td>
      <td>-0.142355</td>
      <td>-0.183453</td>
      <td>-0.405073</td>
      <td>-0.198908</td>
      <td>1.085580</td>
      <td>-0.415183</td>
      <td>-0.250672</td>
      <td>-0.013892</td>
      <td>0.278815</td>
      <td>-1.255289</td>
      <td>0.307030</td>
      <td>0.657226</td>
      <td>1.549282</td>
      <td>-0.708014</td>
      <td>0.251130</td>
      <td>-0.181253</td>
      <td>-0.331302</td>
      <td>1.373777</td>
      <td>0.274645</td>
      <td>0.554051</td>
      <td>0.738431</td>
      <td>1.472100</td>
      <td>0.058153</td>
      <td>-1.036387</td>
      <td>-0.358364</td>
      <td>0.602408</td>
      <td>-0.060278</td>
      <td>-0.315344</td>
      <td>-0.450382</td>
      <td>-0.680819</td>
      <td>-0.440500</td>
      <td>-0.062146</td>
      <td>0.017013</td>
      <td>-0.283257</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-1.288125</td>
      <td>-0.862435</td>
      <td>-0.702912</td>
      <td>-0.495094</td>
      <td>0.307924</td>
      <td>-0.137971</td>
      <td>0.785075</td>
      <td>-0.243565</td>
      <td>-0.062785</td>
      <td>-1.070156</td>
      <td>-1.149665</td>
      <td>-1.193769</td>
      <td>0.027565</td>
      <td>-0.058298</td>
      <td>-0.181791</td>
      <td>-0.338915</td>
      <td>-0.442985</td>
      <td>-0.734429</td>
      <td>0.813433</td>
      <td>-0.693699</td>
      <td>-0.216102</td>
      <td>-0.648787</td>
      <td>0.294417</td>
      <td>-0.128247</td>
      <td>-0.866361</td>
      <td>-0.468341</td>
      <td>-0.359094</td>
      <td>-1.532494</td>
      <td>-0.015221</td>
      <td>0.284433</td>
      <td>0.031168</td>
      <td>0.179882</td>
      <td>-0.241479</td>
      <td>-0.231704</td>
      <td>-1.281165</td>
      <td>-2.013910</td>
      <td>-0.765649</td>
      <td>0.579074</td>
      <td>0.955100</td>
      <td>1.130293</td>
      <td>...</td>
      <td>-0.171298</td>
      <td>-0.448163</td>
      <td>-0.403071</td>
      <td>-0.910344</td>
      <td>1.151894</td>
      <td>0.691016</td>
      <td>-0.170580</td>
      <td>-0.317606</td>
      <td>0.058859</td>
      <td>0.137928</td>
      <td>0.453634</td>
      <td>0.152787</td>
      <td>-0.429761</td>
      <td>-0.483963</td>
      <td>-0.693346</td>
      <td>-0.530730</td>
      <td>-1.135849</td>
      <td>-1.975453</td>
      <td>0.705924</td>
      <td>0.324010</td>
      <td>0.179107</td>
      <td>-0.195003</td>
      <td>-0.227351</td>
      <td>0.307439</td>
      <td>0.074917</td>
      <td>-0.388922</td>
      <td>-0.062412</td>
      <td>0.005146</td>
      <td>0.318787</td>
      <td>0.248487</td>
      <td>1.512125</td>
      <td>-0.291468</td>
      <td>-0.569939</td>
      <td>-0.346131</td>
      <td>-0.574676</td>
      <td>0.050205</td>
      <td>0.953770</td>
      <td>-4.084956</td>
      <td>-2.304607</td>
      <td>-1.448812</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.084716</td>
      <td>-0.508724</td>
      <td>0.911328</td>
      <td>0.067889</td>
      <td>0.489513</td>
      <td>0.651506</td>
      <td>-0.095167</td>
      <td>0.562619</td>
      <td>0.334999</td>
      <td>-0.996340</td>
      <td>-0.903162</td>
      <td>-0.447059</td>
      <td>0.142863</td>
      <td>-0.265323</td>
      <td>-0.886758</td>
      <td>-0.343411</td>
      <td>-0.650470</td>
      <td>-0.567564</td>
      <td>0.539198</td>
      <td>0.620832</td>
      <td>-0.294065</td>
      <td>0.198856</td>
      <td>0.186292</td>
      <td>0.117588</td>
      <td>0.513483</td>
      <td>0.411591</td>
      <td>-0.629160</td>
      <td>-0.221231</td>
      <td>-0.448475</td>
      <td>-1.349344</td>
      <td>-0.206878</td>
      <td>-0.625217</td>
      <td>0.513933</td>
      <td>0.725760</td>
      <td>-0.303657</td>
      <td>-0.754657</td>
      <td>0.320925</td>
      <td>-0.049269</td>
      <td>0.338185</td>
      <td>-0.021458</td>
      <td>...</td>
      <td>-0.374844</td>
      <td>-1.166630</td>
      <td>0.734669</td>
      <td>0.063917</td>
      <td>0.100286</td>
      <td>-0.593241</td>
      <td>0.265140</td>
      <td>1.159197</td>
      <td>0.770064</td>
      <td>1.133044</td>
      <td>2.010640</td>
      <td>0.400679</td>
      <td>0.056513</td>
      <td>0.364587</td>
      <td>-0.381178</td>
      <td>0.073591</td>
      <td>-0.152255</td>
      <td>-0.855553</td>
      <td>0.184128</td>
      <td>-0.451802</td>
      <td>-0.346415</td>
      <td>-0.404981</td>
      <td>0.178539</td>
      <td>0.935669</td>
      <td>1.200332</td>
      <td>1.151612</td>
      <td>1.370120</td>
      <td>0.238826</td>
      <td>0.340551</td>
      <td>-0.376163</td>
      <td>-0.224996</td>
      <td>-0.138299</td>
      <td>-0.348289</td>
      <td>0.559454</td>
      <td>-0.421515</td>
      <td>0.466115</td>
      <td>-0.133229</td>
      <td>-0.366639</td>
      <td>0.262881</td>
      <td>0.336899</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.268057</td>
      <td>0.914584</td>
      <td>0.067609</td>
      <td>-1.019212</td>
      <td>-0.223519</td>
      <td>-0.063594</td>
      <td>0.628584</td>
      <td>1.162797</td>
      <td>0.269341</td>
      <td>-0.012599</td>
      <td>0.254773</td>
      <td>0.877755</td>
      <td>0.517068</td>
      <td>0.102663</td>
      <td>0.224187</td>
      <td>0.371474</td>
      <td>-0.911281</td>
      <td>-0.192928</td>
      <td>0.148524</td>
      <td>0.475555</td>
      <td>-0.108684</td>
      <td>-0.005406</td>
      <td>-0.685626</td>
      <td>-0.188434</td>
      <td>-0.452536</td>
      <td>0.860117</td>
      <td>-0.169329</td>
      <td>-0.206845</td>
      <td>0.590099</td>
      <td>-0.869187</td>
      <td>1.058888</td>
      <td>0.116506</td>
      <td>0.341065</td>
      <td>0.294839</td>
      <td>0.406731</td>
      <td>0.388261</td>
      <td>-1.051744</td>
      <td>-0.108575</td>
      <td>0.868910</td>
      <td>1.210560</td>
      <td>...</td>
      <td>-0.038199</td>
      <td>-0.854677</td>
      <td>0.072933</td>
      <td>-0.069341</td>
      <td>0.709925</td>
      <td>-0.391100</td>
      <td>-0.161504</td>
      <td>0.262792</td>
      <td>-0.510508</td>
      <td>-0.834850</td>
      <td>0.488754</td>
      <td>-0.314217</td>
      <td>-0.972502</td>
      <td>-0.414359</td>
      <td>0.755536</td>
      <td>-0.135345</td>
      <td>0.001156</td>
      <td>-0.569888</td>
      <td>0.692716</td>
      <td>-0.117216</td>
      <td>-0.016328</td>
      <td>0.916867</td>
      <td>-0.392439</td>
      <td>0.838561</td>
      <td>-0.021771</td>
      <td>0.036883</td>
      <td>0.084417</td>
      <td>0.493284</td>
      <td>0.352673</td>
      <td>-0.125150</td>
      <td>-0.605322</td>
      <td>-0.352938</td>
      <td>-0.031573</td>
      <td>0.223172</td>
      <td>-0.919368</td>
      <td>0.165368</td>
      <td>-0.441537</td>
      <td>1.061942</td>
      <td>0.628198</td>
      <td>-0.292630</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.374824</td>
      <td>-0.391815</td>
      <td>-0.464562</td>
      <td>-0.733442</td>
      <td>0.419886</td>
      <td>0.378593</td>
      <td>-0.131386</td>
      <td>0.024889</td>
      <td>0.386013</td>
      <td>0.155715</td>
      <td>0.436835</td>
      <td>0.604352</td>
      <td>-0.732347</td>
      <td>0.160111</td>
      <td>-1.452327</td>
      <td>-0.299449</td>
      <td>-0.399122</td>
      <td>0.843194</td>
      <td>0.011573</td>
      <td>0.263341</td>
      <td>0.028962</td>
      <td>-0.790744</td>
      <td>-0.522429</td>
      <td>-1.690831</td>
      <td>-0.547514</td>
      <td>-0.287863</td>
      <td>-0.095202</td>
      <td>0.077650</td>
      <td>-1.376968</td>
      <td>-1.384918</td>
      <td>-0.759733</td>
      <td>0.676315</td>
      <td>1.401852</td>
      <td>-0.410822</td>
      <td>0.659383</td>
      <td>0.218303</td>
      <td>0.515157</td>
      <td>0.610591</td>
      <td>-0.040762</td>
      <td>0.146111</td>
      <td>...</td>
      <td>-1.378952</td>
      <td>-0.009092</td>
      <td>-0.546714</td>
      <td>-0.243516</td>
      <td>-0.435752</td>
      <td>-0.049453</td>
      <td>-0.388242</td>
      <td>-0.801767</td>
      <td>0.381162</td>
      <td>0.507416</td>
      <td>-0.924130</td>
      <td>-1.407732</td>
      <td>-0.077206</td>
      <td>-0.447203</td>
      <td>0.239004</td>
      <td>-0.532340</td>
      <td>-0.368418</td>
      <td>-0.515892</td>
      <td>0.303572</td>
      <td>0.068570</td>
      <td>0.057157</td>
      <td>-0.350495</td>
      <td>0.267721</td>
      <td>-0.003043</td>
      <td>-0.906537</td>
      <td>-1.418711</td>
      <td>-1.188548</td>
      <td>0.045382</td>
      <td>0.918367</td>
      <td>0.699419</td>
      <td>0.466748</td>
      <td>-1.467121</td>
      <td>-0.626160</td>
      <td>-0.066895</td>
      <td>1.080718</td>
      <td>1.696082</td>
      <td>0.914825</td>
      <td>-2.466145</td>
      <td>-0.925046</td>
      <td>-0.017703</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.359518</td>
      <td>1.183133</td>
      <td>0.584217</td>
      <td>-0.299922</td>
      <td>-0.350167</td>
      <td>-0.762204</td>
      <td>-0.468988</td>
      <td>-0.556696</td>
      <td>0.232508</td>
      <td>0.063069</td>
      <td>-0.793152</td>
      <td>-0.317777</td>
      <td>-0.649120</td>
      <td>-0.571837</td>
      <td>-0.348737</td>
      <td>0.345951</td>
      <td>0.361844</td>
      <td>0.032838</td>
      <td>0.649008</td>
      <td>0.484729</td>
      <td>0.505629</td>
      <td>1.051955</td>
      <td>-0.258152</td>
      <td>-0.688507</td>
      <td>0.434014</td>
      <td>0.735551</td>
      <td>0.375788</td>
      <td>-0.343188</td>
      <td>0.161186</td>
      <td>0.102961</td>
      <td>-0.029258</td>
      <td>-0.117492</td>
      <td>0.457016</td>
      <td>0.323458</td>
      <td>-1.086099</td>
      <td>-0.598137</td>
      <td>1.026216</td>
      <td>0.339694</td>
      <td>0.519685</td>
      <td>0.675490</td>
      <td>...</td>
      <td>-1.981810</td>
      <td>0.288313</td>
      <td>-0.346780</td>
      <td>0.204996</td>
      <td>-0.907156</td>
      <td>-0.304633</td>
      <td>0.162423</td>
      <td>0.166609</td>
      <td>0.820944</td>
      <td>0.324712</td>
      <td>-0.152044</td>
      <td>-0.400200</td>
      <td>0.696309</td>
      <td>1.137877</td>
      <td>-0.140811</td>
      <td>0.631486</td>
      <td>0.614021</td>
      <td>-0.689989</td>
      <td>-1.457020</td>
      <td>-0.214167</td>
      <td>0.359128</td>
      <td>0.543488</td>
      <td>0.360178</td>
      <td>0.061772</td>
      <td>0.806044</td>
      <td>0.167927</td>
      <td>-0.208028</td>
      <td>0.165158</td>
      <td>0.569722</td>
      <td>0.375784</td>
      <td>0.186454</td>
      <td>-0.077900</td>
      <td>0.040221</td>
      <td>0.302581</td>
      <td>1.063509</td>
      <td>0.055808</td>
      <td>0.615226</td>
      <td>0.782477</td>
      <td>0.687024</td>
      <td>1.026742</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.115151</td>
      <td>-0.020748</td>
      <td>0.137948</td>
      <td>-0.758628</td>
      <td>-0.056219</td>
      <td>0.211289</td>
      <td>-0.473481</td>
      <td>0.872656</td>
      <td>-0.753079</td>
      <td>0.247866</td>
      <td>-0.805965</td>
      <td>-0.178103</td>
      <td>0.228676</td>
      <td>0.256341</td>
      <td>-1.382895</td>
      <td>-0.867397</td>
      <td>0.303247</td>
      <td>-0.358778</td>
      <td>-0.621246</td>
      <td>-0.919178</td>
      <td>0.483434</td>
      <td>-0.047174</td>
      <td>-0.360809</td>
      <td>0.386593</td>
      <td>0.666306</td>
      <td>0.809041</td>
      <td>-0.226397</td>
      <td>-0.211688</td>
      <td>0.212511</td>
      <td>-0.210777</td>
      <td>-0.181461</td>
      <td>-0.511995</td>
      <td>0.503615</td>
      <td>1.576869</td>
      <td>1.581968</td>
      <td>-0.387829</td>
      <td>0.399636</td>
      <td>0.128768</td>
      <td>-0.279438</td>
      <td>0.528886</td>
      <td>...</td>
      <td>-1.315210</td>
      <td>1.055103</td>
      <td>0.900128</td>
      <td>1.041898</td>
      <td>-0.083900</td>
      <td>0.374885</td>
      <td>1.551345</td>
      <td>0.799807</td>
      <td>0.469548</td>
      <td>0.098677</td>
      <td>0.457455</td>
      <td>0.947979</td>
      <td>-0.543876</td>
      <td>-0.212356</td>
      <td>0.188207</td>
      <td>-0.442044</td>
      <td>-1.007004</td>
      <td>-0.439898</td>
      <td>-0.363748</td>
      <td>-0.009361</td>
      <td>1.218844</td>
      <td>1.403132</td>
      <td>1.213852</td>
      <td>0.576540</td>
      <td>0.245706</td>
      <td>-0.748121</td>
      <td>0.321926</td>
      <td>0.670267</td>
      <td>0.104641</td>
      <td>-0.200487</td>
      <td>0.293039</td>
      <td>-0.443296</td>
      <td>0.897070</td>
      <td>-0.283561</td>
      <td>0.877558</td>
      <td>1.367606</td>
      <td>0.989010</td>
      <td>1.120932</td>
      <td>0.419176</td>
      <td>0.607130</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.206316</td>
      <td>-1.237582</td>
      <td>-0.436381</td>
      <td>-0.960517</td>
      <td>0.030500</td>
      <td>0.060280</td>
      <td>-0.346885</td>
      <td>0.169374</td>
      <td>-0.557777</td>
      <td>0.022403</td>
      <td>-0.978568</td>
      <td>-0.248258</td>
      <td>-0.153305</td>
      <td>0.825778</td>
      <td>0.255357</td>
      <td>-0.121446</td>
      <td>-0.470287</td>
      <td>0.496792</td>
      <td>0.533280</td>
      <td>0.533223</td>
      <td>-0.266494</td>
      <td>0.343713</td>
      <td>0.805592</td>
      <td>0.159674</td>
      <td>0.442307</td>
      <td>0.347351</td>
      <td>0.186707</td>
      <td>1.102618</td>
      <td>0.002414</td>
      <td>-0.102567</td>
      <td>-0.909312</td>
      <td>-0.019940</td>
      <td>0.274847</td>
      <td>0.132387</td>
      <td>0.530705</td>
      <td>-1.737181</td>
      <td>-0.015135</td>
      <td>0.221074</td>
      <td>0.033202</td>
      <td>-0.361068</td>
      <td>...</td>
      <td>-0.198373</td>
      <td>-0.535246</td>
      <td>-0.521969</td>
      <td>-0.395331</td>
      <td>-0.447192</td>
      <td>-0.619570</td>
      <td>0.756885</td>
      <td>0.708293</td>
      <td>1.227674</td>
      <td>1.102511</td>
      <td>-0.413123</td>
      <td>0.085669</td>
      <td>0.051566</td>
      <td>-0.352282</td>
      <td>-0.840284</td>
      <td>-0.073415</td>
      <td>-0.738734</td>
      <td>-0.678358</td>
      <td>-0.285072</td>
      <td>-0.122474</td>
      <td>-0.429956</td>
      <td>-0.519158</td>
      <td>-0.453278</td>
      <td>0.429191</td>
      <td>0.226649</td>
      <td>-0.339681</td>
      <td>0.182738</td>
      <td>1.300602</td>
      <td>0.900746</td>
      <td>0.745991</td>
      <td>0.229917</td>
      <td>0.801046</td>
      <td>0.203370</td>
      <td>0.575603</td>
      <td>0.085846</td>
      <td>-1.007822</td>
      <td>-0.085513</td>
      <td>-1.695016</td>
      <td>-2.172155</td>
      <td>-1.584365</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.907580</td>
      <td>-0.908291</td>
      <td>-0.363099</td>
      <td>0.106073</td>
      <td>-0.531206</td>
      <td>-0.419353</td>
      <td>0.187594</td>
      <td>-0.592711</td>
      <td>0.269882</td>
      <td>0.088526</td>
      <td>-1.115306</td>
      <td>-0.790180</td>
      <td>-0.441254</td>
      <td>-0.169144</td>
      <td>0.498125</td>
      <td>-0.419266</td>
      <td>-0.713717</td>
      <td>-0.086857</td>
      <td>-0.080448</td>
      <td>0.416695</td>
      <td>0.566005</td>
      <td>1.615658</td>
      <td>1.859363</td>
      <td>0.450688</td>
      <td>0.557029</td>
      <td>-0.048621</td>
      <td>-0.147216</td>
      <td>-0.559914</td>
      <td>-0.290148</td>
      <td>0.460534</td>
      <td>0.132567</td>
      <td>0.876093</td>
      <td>0.233781</td>
      <td>-0.205265</td>
      <td>0.318437</td>
      <td>-0.742985</td>
      <td>-0.500290</td>
      <td>0.134363</td>
      <td>-0.222856</td>
      <td>0.984016</td>
      <td>...</td>
      <td>0.001319</td>
      <td>0.590890</td>
      <td>0.060160</td>
      <td>-0.414401</td>
      <td>0.124669</td>
      <td>0.106717</td>
      <td>0.210856</td>
      <td>0.475763</td>
      <td>0.208543</td>
      <td>0.400191</td>
      <td>-0.264797</td>
      <td>0.102066</td>
      <td>-0.091470</td>
      <td>-0.113823</td>
      <td>0.204633</td>
      <td>-0.067398</td>
      <td>0.470313</td>
      <td>0.115160</td>
      <td>0.057044</td>
      <td>0.894540</td>
      <td>-0.141743</td>
      <td>0.428036</td>
      <td>-0.014101</td>
      <td>0.176047</td>
      <td>-1.348193</td>
      <td>-0.350117</td>
      <td>1.131470</td>
      <td>1.458885</td>
      <td>0.152037</td>
      <td>0.245160</td>
      <td>0.299338</td>
      <td>0.183933</td>
      <td>-0.096383</td>
      <td>-0.479369</td>
      <td>-0.505404</td>
      <td>-0.884862</td>
      <td>0.266104</td>
      <td>-2.966764</td>
      <td>-2.172903</td>
      <td>-0.765150</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f8350814100&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>      coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.08581  0.044556  24.369559  3.597143e-131  0.998482  1.173138
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  5.337 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.4.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>