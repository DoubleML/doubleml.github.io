
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.311709</td>
      <td>-0.509545</td>
      <td>-1.828730</td>
      <td>0.322983</td>
      <td>-1.306539</td>
      <td>-0.631431</td>
      <td>-0.013341</td>
      <td>-0.206149</td>
      <td>0.120683</td>
      <td>-1.319318</td>
      <td>-0.385787</td>
      <td>-0.399729</td>
      <td>-0.175969</td>
      <td>-0.209454</td>
      <td>-0.846956</td>
      <td>-0.868692</td>
      <td>0.230027</td>
      <td>-0.439248</td>
      <td>-0.354995</td>
      <td>-0.813181</td>
      <td>-0.197763</td>
      <td>0.048038</td>
      <td>-0.453117</td>
      <td>-0.519835</td>
      <td>0.046921</td>
      <td>0.240913</td>
      <td>-0.136360</td>
      <td>-0.026783</td>
      <td>0.491161</td>
      <td>-0.981484</td>
      <td>0.370902</td>
      <td>-0.886390</td>
      <td>-0.370150</td>
      <td>0.262819</td>
      <td>-1.419085</td>
      <td>0.704573</td>
      <td>0.460364</td>
      <td>0.767151</td>
      <td>0.047317</td>
      <td>-0.269321</td>
      <td>...</td>
      <td>-0.152952</td>
      <td>0.460452</td>
      <td>-0.044684</td>
      <td>-1.139823</td>
      <td>0.514169</td>
      <td>0.793279</td>
      <td>0.190364</td>
      <td>0.031835</td>
      <td>0.138384</td>
      <td>-0.148419</td>
      <td>0.286776</td>
      <td>1.060920</td>
      <td>0.077797</td>
      <td>0.275419</td>
      <td>0.716662</td>
      <td>-1.252396</td>
      <td>-0.464515</td>
      <td>0.122853</td>
      <td>-0.129496</td>
      <td>-1.087677</td>
      <td>-0.240415</td>
      <td>0.970756</td>
      <td>0.145534</td>
      <td>-0.397455</td>
      <td>1.124330</td>
      <td>1.188062</td>
      <td>0.735284</td>
      <td>-0.026240</td>
      <td>0.793470</td>
      <td>0.200856</td>
      <td>0.436802</td>
      <td>0.138080</td>
      <td>-0.234818</td>
      <td>-0.054426</td>
      <td>-0.671952</td>
      <td>-0.275483</td>
      <td>-0.788751</td>
      <td>-1.429195</td>
      <td>-0.769422</td>
      <td>-0.485762</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.502433</td>
      <td>-1.275954</td>
      <td>-0.332905</td>
      <td>0.410229</td>
      <td>1.035127</td>
      <td>0.705247</td>
      <td>0.242474</td>
      <td>-1.000157</td>
      <td>-0.606480</td>
      <td>-1.570967</td>
      <td>-0.435481</td>
      <td>0.460755</td>
      <td>0.787323</td>
      <td>1.011483</td>
      <td>0.799826</td>
      <td>-1.247194</td>
      <td>-0.684556</td>
      <td>-0.109588</td>
      <td>1.136942</td>
      <td>0.880961</td>
      <td>0.538293</td>
      <td>0.164253</td>
      <td>0.207023</td>
      <td>0.207202</td>
      <td>0.474664</td>
      <td>-0.299309</td>
      <td>-0.111426</td>
      <td>0.288561</td>
      <td>0.691103</td>
      <td>0.048226</td>
      <td>-0.198607</td>
      <td>-0.381349</td>
      <td>-0.470785</td>
      <td>-0.523427</td>
      <td>-1.015668</td>
      <td>-0.921490</td>
      <td>-0.649079</td>
      <td>0.593433</td>
      <td>0.600893</td>
      <td>0.096826</td>
      <td>...</td>
      <td>-1.564005</td>
      <td>-0.019145</td>
      <td>0.765115</td>
      <td>-1.175777</td>
      <td>0.174377</td>
      <td>0.425933</td>
      <td>0.877939</td>
      <td>-0.651474</td>
      <td>0.242724</td>
      <td>0.556782</td>
      <td>-0.250732</td>
      <td>0.023811</td>
      <td>0.666829</td>
      <td>0.101632</td>
      <td>0.980217</td>
      <td>0.726394</td>
      <td>0.530613</td>
      <td>-0.327306</td>
      <td>-0.007437</td>
      <td>-0.199847</td>
      <td>0.476567</td>
      <td>0.138773</td>
      <td>-0.486146</td>
      <td>0.402724</td>
      <td>-0.703244</td>
      <td>-0.524385</td>
      <td>-0.295399</td>
      <td>-0.711420</td>
      <td>-0.664804</td>
      <td>0.685545</td>
      <td>-0.653567</td>
      <td>0.970756</td>
      <td>0.772861</td>
      <td>1.036066</td>
      <td>0.373030</td>
      <td>-0.848568</td>
      <td>0.677010</td>
      <td>-1.446506</td>
      <td>0.397947</td>
      <td>1.002334</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.591313</td>
      <td>1.370603</td>
      <td>0.543536</td>
      <td>0.184453</td>
      <td>-0.532250</td>
      <td>-0.378951</td>
      <td>0.255738</td>
      <td>0.215555</td>
      <td>-0.727740</td>
      <td>0.256794</td>
      <td>-0.543656</td>
      <td>-0.317601</td>
      <td>-0.329063</td>
      <td>-1.086953</td>
      <td>-0.665421</td>
      <td>0.231605</td>
      <td>-0.176066</td>
      <td>0.340253</td>
      <td>-0.933561</td>
      <td>-0.424987</td>
      <td>-0.383729</td>
      <td>0.014015</td>
      <td>0.185329</td>
      <td>0.000842</td>
      <td>-1.025808</td>
      <td>-0.183571</td>
      <td>0.010024</td>
      <td>0.354182</td>
      <td>0.342943</td>
      <td>-0.591127</td>
      <td>-0.866524</td>
      <td>0.004924</td>
      <td>0.273130</td>
      <td>-0.374576</td>
      <td>-1.049021</td>
      <td>-0.020552</td>
      <td>0.296561</td>
      <td>0.446643</td>
      <td>0.844678</td>
      <td>-0.437126</td>
      <td>...</td>
      <td>1.049306</td>
      <td>0.492075</td>
      <td>-0.237749</td>
      <td>-0.546814</td>
      <td>-0.406959</td>
      <td>0.139690</td>
      <td>-0.103336</td>
      <td>0.209610</td>
      <td>-0.045728</td>
      <td>1.644732</td>
      <td>0.921343</td>
      <td>0.649105</td>
      <td>0.202397</td>
      <td>-0.538154</td>
      <td>0.338941</td>
      <td>0.159941</td>
      <td>1.140183</td>
      <td>0.304080</td>
      <td>0.553896</td>
      <td>-0.073614</td>
      <td>0.283082</td>
      <td>0.238254</td>
      <td>-0.022274</td>
      <td>-0.108295</td>
      <td>0.064737</td>
      <td>0.957075</td>
      <td>0.566406</td>
      <td>-0.058830</td>
      <td>-0.005103</td>
      <td>-0.346411</td>
      <td>0.399361</td>
      <td>1.500609</td>
      <td>-0.155772</td>
      <td>0.042104</td>
      <td>-0.487371</td>
      <td>-0.193348</td>
      <td>-1.287727</td>
      <td>4.326691</td>
      <td>3.051618</td>
      <td>2.104484</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.661659</td>
      <td>-0.271410</td>
      <td>-0.556180</td>
      <td>0.811118</td>
      <td>0.024846</td>
      <td>-0.082804</td>
      <td>-0.940981</td>
      <td>-1.125691</td>
      <td>0.286997</td>
      <td>-0.327538</td>
      <td>-0.660432</td>
      <td>-0.477381</td>
      <td>0.272195</td>
      <td>0.024050</td>
      <td>0.334962</td>
      <td>-0.039945</td>
      <td>0.323799</td>
      <td>0.524423</td>
      <td>-0.290203</td>
      <td>-0.160282</td>
      <td>0.185344</td>
      <td>0.376894</td>
      <td>0.558568</td>
      <td>-1.058480</td>
      <td>-0.446359</td>
      <td>0.015759</td>
      <td>-0.035693</td>
      <td>-1.223245</td>
      <td>0.279162</td>
      <td>0.487497</td>
      <td>-0.086572</td>
      <td>0.499059</td>
      <td>-0.906688</td>
      <td>-0.260782</td>
      <td>0.669797</td>
      <td>0.565178</td>
      <td>0.342385</td>
      <td>0.114497</td>
      <td>0.754231</td>
      <td>0.750992</td>
      <td>...</td>
      <td>-0.294540</td>
      <td>-0.233097</td>
      <td>0.115577</td>
      <td>-1.277999</td>
      <td>-0.635254</td>
      <td>0.447930</td>
      <td>0.592195</td>
      <td>1.055658</td>
      <td>0.242581</td>
      <td>0.191378</td>
      <td>0.846695</td>
      <td>-0.082722</td>
      <td>-0.561369</td>
      <td>-0.589933</td>
      <td>-0.215019</td>
      <td>0.525873</td>
      <td>0.287600</td>
      <td>0.344503</td>
      <td>0.179951</td>
      <td>0.056614</td>
      <td>-0.297069</td>
      <td>0.371891</td>
      <td>0.740952</td>
      <td>-0.292514</td>
      <td>-0.299441</td>
      <td>0.307554</td>
      <td>0.541508</td>
      <td>0.569460</td>
      <td>0.309674</td>
      <td>-0.190307</td>
      <td>-0.224808</td>
      <td>0.207144</td>
      <td>-0.694297</td>
      <td>-0.808485</td>
      <td>-0.359551</td>
      <td>0.065277</td>
      <td>0.800362</td>
      <td>0.400366</td>
      <td>0.400596</td>
      <td>0.602026</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.807539</td>
      <td>-0.048852</td>
      <td>-0.425404</td>
      <td>2.258614</td>
      <td>0.051977</td>
      <td>0.361078</td>
      <td>1.146643</td>
      <td>0.962119</td>
      <td>-0.343446</td>
      <td>0.273967</td>
      <td>0.261972</td>
      <td>-0.075930</td>
      <td>-0.678753</td>
      <td>-0.526019</td>
      <td>0.640473</td>
      <td>-0.300842</td>
      <td>0.226336</td>
      <td>-0.412258</td>
      <td>-0.288305</td>
      <td>0.805436</td>
      <td>0.329723</td>
      <td>-0.480295</td>
      <td>-0.542759</td>
      <td>-0.035664</td>
      <td>0.977127</td>
      <td>0.865692</td>
      <td>0.884895</td>
      <td>0.203398</td>
      <td>-0.248497</td>
      <td>-0.100713</td>
      <td>-0.424608</td>
      <td>-0.404375</td>
      <td>-0.468092</td>
      <td>-0.529498</td>
      <td>-0.650465</td>
      <td>-0.362550</td>
      <td>-0.625567</td>
      <td>-0.016206</td>
      <td>0.590112</td>
      <td>0.128504</td>
      <td>...</td>
      <td>-1.104247</td>
      <td>0.464792</td>
      <td>0.642014</td>
      <td>-0.768921</td>
      <td>-0.719687</td>
      <td>-0.032088</td>
      <td>-0.126438</td>
      <td>0.371588</td>
      <td>-1.088959</td>
      <td>-0.332954</td>
      <td>-0.017448</td>
      <td>0.087288</td>
      <td>-0.376240</td>
      <td>-1.408731</td>
      <td>-0.473504</td>
      <td>-0.331261</td>
      <td>0.275990</td>
      <td>-0.143628</td>
      <td>-0.311099</td>
      <td>-0.258027</td>
      <td>0.397043</td>
      <td>0.493161</td>
      <td>0.917039</td>
      <td>-0.294194</td>
      <td>0.096527</td>
      <td>0.383934</td>
      <td>0.311828</td>
      <td>0.497004</td>
      <td>-0.161500</td>
      <td>0.106194</td>
      <td>-0.350839</td>
      <td>0.152453</td>
      <td>0.989815</td>
      <td>0.599746</td>
      <td>-0.502927</td>
      <td>0.059405</td>
      <td>0.267182</td>
      <td>2.083718</td>
      <td>0.999533</td>
      <td>0.444028</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.947776</td>
      <td>-0.591970</td>
      <td>-0.603392</td>
      <td>0.292892</td>
      <td>0.137207</td>
      <td>-0.368898</td>
      <td>-0.135622</td>
      <td>0.154044</td>
      <td>-0.385576</td>
      <td>0.207668</td>
      <td>0.208436</td>
      <td>0.648814</td>
      <td>0.612722</td>
      <td>-0.911893</td>
      <td>-0.408494</td>
      <td>0.175659</td>
      <td>0.677232</td>
      <td>0.554660</td>
      <td>0.500215</td>
      <td>1.273505</td>
      <td>0.567084</td>
      <td>0.367779</td>
      <td>-0.775027</td>
      <td>-0.967983</td>
      <td>0.496000</td>
      <td>-0.649612</td>
      <td>-0.899635</td>
      <td>-0.974709</td>
      <td>0.919950</td>
      <td>0.987732</td>
      <td>0.075915</td>
      <td>-0.841384</td>
      <td>-1.111157</td>
      <td>0.698346</td>
      <td>-0.041414</td>
      <td>0.545760</td>
      <td>-0.503089</td>
      <td>-0.472627</td>
      <td>0.013615</td>
      <td>0.667014</td>
      <td>...</td>
      <td>0.022475</td>
      <td>0.821037</td>
      <td>0.501240</td>
      <td>-0.907125</td>
      <td>0.919720</td>
      <td>0.506636</td>
      <td>-0.047276</td>
      <td>0.491981</td>
      <td>-0.255527</td>
      <td>0.437516</td>
      <td>0.783482</td>
      <td>0.661605</td>
      <td>-0.723624</td>
      <td>0.077445</td>
      <td>1.392831</td>
      <td>-0.701705</td>
      <td>-0.294913</td>
      <td>0.935310</td>
      <td>-0.093754</td>
      <td>-0.513311</td>
      <td>0.187230</td>
      <td>0.552737</td>
      <td>0.469792</td>
      <td>0.239919</td>
      <td>0.424087</td>
      <td>0.067531</td>
      <td>0.153468</td>
      <td>0.258207</td>
      <td>0.076882</td>
      <td>1.090727</td>
      <td>0.169113</td>
      <td>-0.361116</td>
      <td>0.419615</td>
      <td>0.082186</td>
      <td>0.599978</td>
      <td>0.095490</td>
      <td>0.203779</td>
      <td>-3.310260</td>
      <td>-1.734932</td>
      <td>-0.625665</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1.694633</td>
      <td>0.576034</td>
      <td>-0.107806</td>
      <td>1.408040</td>
      <td>0.326892</td>
      <td>-0.723038</td>
      <td>-0.062797</td>
      <td>0.961466</td>
      <td>-0.822959</td>
      <td>-0.942009</td>
      <td>-0.806068</td>
      <td>-0.104356</td>
      <td>0.204353</td>
      <td>-0.743927</td>
      <td>-0.791568</td>
      <td>-1.338758</td>
      <td>-0.329014</td>
      <td>0.241028</td>
      <td>0.275386</td>
      <td>0.713669</td>
      <td>0.491282</td>
      <td>0.048109</td>
      <td>0.407289</td>
      <td>-0.058460</td>
      <td>-0.355624</td>
      <td>0.249943</td>
      <td>1.133989</td>
      <td>0.719719</td>
      <td>0.361871</td>
      <td>-0.174735</td>
      <td>0.270622</td>
      <td>0.481749</td>
      <td>-0.640971</td>
      <td>-0.811361</td>
      <td>-0.381896</td>
      <td>0.075378</td>
      <td>-0.406611</td>
      <td>0.624940</td>
      <td>0.156095</td>
      <td>-0.466775</td>
      <td>...</td>
      <td>0.441544</td>
      <td>-0.790468</td>
      <td>-0.268074</td>
      <td>-1.186387</td>
      <td>-0.235428</td>
      <td>1.728472</td>
      <td>0.400206</td>
      <td>0.331012</td>
      <td>0.435377</td>
      <td>-0.541412</td>
      <td>0.289670</td>
      <td>0.387622</td>
      <td>-0.357932</td>
      <td>0.017184</td>
      <td>-0.030722</td>
      <td>0.410320</td>
      <td>1.033946</td>
      <td>-0.261955</td>
      <td>0.428138</td>
      <td>-0.958358</td>
      <td>0.174841</td>
      <td>-0.346618</td>
      <td>-0.138897</td>
      <td>0.262280</td>
      <td>-1.286263</td>
      <td>-0.036116</td>
      <td>0.321911</td>
      <td>0.041670</td>
      <td>0.333131</td>
      <td>0.110811</td>
      <td>-0.093676</td>
      <td>-0.045329</td>
      <td>1.530335</td>
      <td>1.239611</td>
      <td>-0.961557</td>
      <td>0.970802</td>
      <td>0.289412</td>
      <td>2.948424</td>
      <td>2.547974</td>
      <td>1.258185</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.150882</td>
      <td>-0.213164</td>
      <td>0.003702</td>
      <td>1.345694</td>
      <td>-0.531973</td>
      <td>0.048237</td>
      <td>-0.398239</td>
      <td>0.076553</td>
      <td>-0.131977</td>
      <td>-0.476955</td>
      <td>0.062726</td>
      <td>0.952016</td>
      <td>0.449942</td>
      <td>-0.547990</td>
      <td>-0.058418</td>
      <td>-0.650936</td>
      <td>-0.086536</td>
      <td>0.093414</td>
      <td>0.510038</td>
      <td>-0.858808</td>
      <td>1.503320</td>
      <td>0.724548</td>
      <td>-0.660899</td>
      <td>-0.317436</td>
      <td>-0.242741</td>
      <td>-0.187570</td>
      <td>0.304311</td>
      <td>0.149318</td>
      <td>0.691741</td>
      <td>-0.806581</td>
      <td>-1.365233</td>
      <td>-0.987960</td>
      <td>0.494144</td>
      <td>-0.345014</td>
      <td>-0.463613</td>
      <td>0.071540</td>
      <td>-1.127441</td>
      <td>0.365021</td>
      <td>-0.107585</td>
      <td>-0.031215</td>
      <td>...</td>
      <td>-1.113722</td>
      <td>-0.377755</td>
      <td>0.119672</td>
      <td>-0.660717</td>
      <td>1.045869</td>
      <td>1.494890</td>
      <td>1.287284</td>
      <td>0.910934</td>
      <td>-0.234559</td>
      <td>-0.749241</td>
      <td>0.011044</td>
      <td>0.401351</td>
      <td>0.318356</td>
      <td>-0.344642</td>
      <td>-0.869026</td>
      <td>-0.277133</td>
      <td>-0.235983</td>
      <td>-0.192175</td>
      <td>0.942949</td>
      <td>0.544826</td>
      <td>1.397958</td>
      <td>-0.323243</td>
      <td>-0.551598</td>
      <td>0.125784</td>
      <td>0.656454</td>
      <td>1.039497</td>
      <td>0.896996</td>
      <td>0.772360</td>
      <td>0.360148</td>
      <td>1.344802</td>
      <td>-0.432314</td>
      <td>0.621527</td>
      <td>1.382536</td>
      <td>0.654123</td>
      <td>0.059919</td>
      <td>-0.401844</td>
      <td>1.136645</td>
      <td>-2.463941</td>
      <td>-1.186227</td>
      <td>-1.399836</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.242226</td>
      <td>0.251812</td>
      <td>0.156752</td>
      <td>0.012030</td>
      <td>0.351407</td>
      <td>1.402266</td>
      <td>-0.786863</td>
      <td>-0.029440</td>
      <td>-0.215030</td>
      <td>-0.394322</td>
      <td>0.000896</td>
      <td>0.208102</td>
      <td>-0.124117</td>
      <td>0.110636</td>
      <td>-0.198324</td>
      <td>-0.059991</td>
      <td>-0.669097</td>
      <td>-0.294915</td>
      <td>-0.325875</td>
      <td>0.714662</td>
      <td>0.424320</td>
      <td>0.231718</td>
      <td>0.338880</td>
      <td>0.504895</td>
      <td>1.231340</td>
      <td>0.721970</td>
      <td>-0.427948</td>
      <td>0.044633</td>
      <td>0.465117</td>
      <td>0.264995</td>
      <td>-0.896728</td>
      <td>-0.888538</td>
      <td>-0.384280</td>
      <td>0.700768</td>
      <td>-0.396437</td>
      <td>0.402461</td>
      <td>0.039412</td>
      <td>0.257921</td>
      <td>0.230607</td>
      <td>0.176780</td>
      <td>...</td>
      <td>-0.349949</td>
      <td>0.017585</td>
      <td>0.339010</td>
      <td>-0.490210</td>
      <td>0.470233</td>
      <td>0.873902</td>
      <td>0.658123</td>
      <td>0.433477</td>
      <td>-0.265166</td>
      <td>0.243887</td>
      <td>0.714285</td>
      <td>1.023672</td>
      <td>-0.511206</td>
      <td>-0.024922</td>
      <td>0.289058</td>
      <td>0.517381</td>
      <td>0.139278</td>
      <td>0.554586</td>
      <td>0.909216</td>
      <td>0.046054</td>
      <td>0.085149</td>
      <td>-0.029522</td>
      <td>-0.183190</td>
      <td>0.059821</td>
      <td>-0.339647</td>
      <td>1.227648</td>
      <td>1.757870</td>
      <td>0.506082</td>
      <td>0.366432</td>
      <td>0.912116</td>
      <td>0.448266</td>
      <td>0.595136</td>
      <td>1.117412</td>
      <td>0.590898</td>
      <td>-1.004293</td>
      <td>-0.228967</td>
      <td>1.344582</td>
      <td>-1.468222</td>
      <td>-0.173128</td>
      <td>-0.384174</td>
    </tr>
    <tr>
      <th>9</th>
      <td>1.243702</td>
      <td>0.027732</td>
      <td>-0.163435</td>
      <td>0.636141</td>
      <td>0.300266</td>
      <td>0.613456</td>
      <td>0.557938</td>
      <td>-0.701649</td>
      <td>-0.992174</td>
      <td>-0.676840</td>
      <td>0.093080</td>
      <td>0.660375</td>
      <td>-0.092148</td>
      <td>-0.764900</td>
      <td>-0.345119</td>
      <td>-0.744176</td>
      <td>0.338516</td>
      <td>0.559574</td>
      <td>0.786440</td>
      <td>0.065331</td>
      <td>0.537042</td>
      <td>-0.781014</td>
      <td>0.153596</td>
      <td>0.685225</td>
      <td>-0.317732</td>
      <td>-1.230197</td>
      <td>-0.815188</td>
      <td>-0.746913</td>
      <td>0.323281</td>
      <td>0.855389</td>
      <td>-0.070062</td>
      <td>-0.737305</td>
      <td>0.025511</td>
      <td>0.081031</td>
      <td>-0.314570</td>
      <td>-0.283297</td>
      <td>-0.596944</td>
      <td>0.240626</td>
      <td>0.281038</td>
      <td>0.602463</td>
      <td>...</td>
      <td>0.366629</td>
      <td>-0.335370</td>
      <td>0.156649</td>
      <td>-0.611789</td>
      <td>0.838787</td>
      <td>-0.089770</td>
      <td>0.774530</td>
      <td>1.159788</td>
      <td>0.106773</td>
      <td>-0.275762</td>
      <td>-0.219828</td>
      <td>1.552824</td>
      <td>0.685089</td>
      <td>0.282267</td>
      <td>-0.083378</td>
      <td>-1.086071</td>
      <td>-0.066670</td>
      <td>0.367493</td>
      <td>0.536377</td>
      <td>0.580711</td>
      <td>-0.040662</td>
      <td>-0.973126</td>
      <td>0.043314</td>
      <td>1.453831</td>
      <td>0.475192</td>
      <td>0.249442</td>
      <td>0.515430</td>
      <td>0.104084</td>
      <td>-0.195068</td>
      <td>0.465960</td>
      <td>0.719748</td>
      <td>-0.888793</td>
      <td>0.476355</td>
      <td>0.607102</td>
      <td>0.829410</td>
      <td>0.698648</td>
      <td>-0.601548</td>
      <td>2.405960</td>
      <td>1.824795</td>
      <td>1.068342</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.550772</td>
      <td>-0.769984</td>
      <td>-0.359257</td>
      <td>0.185529</td>
      <td>0.286764</td>
      <td>-0.652770</td>
      <td>0.351315</td>
      <td>-0.089646</td>
      <td>0.562418</td>
      <td>-0.554694</td>
      <td>-0.090385</td>
      <td>1.374429</td>
      <td>0.533739</td>
      <td>-0.622836</td>
      <td>-0.284165</td>
      <td>0.634716</td>
      <td>-0.090412</td>
      <td>-0.325212</td>
      <td>-0.095337</td>
      <td>0.547110</td>
      <td>0.755281</td>
      <td>0.796937</td>
      <td>0.108374</td>
      <td>0.277286</td>
      <td>0.146905</td>
      <td>-0.244397</td>
      <td>0.109503</td>
      <td>1.226917</td>
      <td>1.311794</td>
      <td>0.440652</td>
      <td>0.406598</td>
      <td>0.719562</td>
      <td>-0.453910</td>
      <td>-0.025645</td>
      <td>-0.799558</td>
      <td>-0.604003</td>
      <td>-0.495962</td>
      <td>0.840281</td>
      <td>1.039611</td>
      <td>-0.737101</td>
      <td>...</td>
      <td>-0.364305</td>
      <td>-0.165317</td>
      <td>-0.117952</td>
      <td>-0.499400</td>
      <td>1.158592</td>
      <td>0.979343</td>
      <td>0.034875</td>
      <td>1.053332</td>
      <td>0.017999</td>
      <td>0.643813</td>
      <td>0.135588</td>
      <td>-0.636223</td>
      <td>-0.892931</td>
      <td>0.055544</td>
      <td>-0.462533</td>
      <td>-0.806593</td>
      <td>-0.396427</td>
      <td>-0.337940</td>
      <td>0.563298</td>
      <td>-0.626549</td>
      <td>0.005971</td>
      <td>0.766601</td>
      <td>0.304008</td>
      <td>1.020426</td>
      <td>0.503723</td>
      <td>0.641616</td>
      <td>-0.326068</td>
      <td>0.242837</td>
      <td>0.034888</td>
      <td>0.292502</td>
      <td>-0.753835</td>
      <td>-0.379417</td>
      <td>0.029414</td>
      <td>0.620511</td>
      <td>-0.248326</td>
      <td>-0.215520</td>
      <td>0.085995</td>
      <td>-0.119579</td>
      <td>-0.079555</td>
      <td>0.499349</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.290705</td>
      <td>0.053258</td>
      <td>-0.852745</td>
      <td>1.172558</td>
      <td>0.701073</td>
      <td>-0.105256</td>
      <td>0.616252</td>
      <td>0.864299</td>
      <td>0.164466</td>
      <td>1.016531</td>
      <td>-0.185278</td>
      <td>0.319335</td>
      <td>0.004818</td>
      <td>0.703222</td>
      <td>-0.722886</td>
      <td>-0.823131</td>
      <td>-0.520691</td>
      <td>0.584175</td>
      <td>-0.088256</td>
      <td>-0.242718</td>
      <td>0.076261</td>
      <td>0.819192</td>
      <td>0.015784</td>
      <td>-0.897338</td>
      <td>0.762945</td>
      <td>0.033162</td>
      <td>0.134083</td>
      <td>0.149886</td>
      <td>0.581301</td>
      <td>0.093045</td>
      <td>0.253650</td>
      <td>-0.754572</td>
      <td>-0.222722</td>
      <td>-1.491457</td>
      <td>-1.001559</td>
      <td>-0.212055</td>
      <td>0.084051</td>
      <td>1.131038</td>
      <td>-0.287467</td>
      <td>-0.111743</td>
      <td>...</td>
      <td>-0.249506</td>
      <td>-0.253404</td>
      <td>-0.176931</td>
      <td>-0.661721</td>
      <td>0.996421</td>
      <td>1.123216</td>
      <td>0.492331</td>
      <td>1.013669</td>
      <td>0.397362</td>
      <td>-0.469837</td>
      <td>0.716234</td>
      <td>0.663880</td>
      <td>0.967028</td>
      <td>0.859433</td>
      <td>0.215125</td>
      <td>0.308939</td>
      <td>-0.055314</td>
      <td>-0.332811</td>
      <td>-0.337440</td>
      <td>-0.216862</td>
      <td>0.289106</td>
      <td>0.109770</td>
      <td>-0.683739</td>
      <td>-0.157344</td>
      <td>0.509646</td>
      <td>1.198691</td>
      <td>-0.096033</td>
      <td>-0.545255</td>
      <td>1.356535</td>
      <td>0.345462</td>
      <td>0.027019</td>
      <td>-0.843149</td>
      <td>0.347246</td>
      <td>0.116084</td>
      <td>-0.328414</td>
      <td>-0.652274</td>
      <td>-0.056972</td>
      <td>-0.919050</td>
      <td>-0.155741</td>
      <td>-0.337199</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.870393</td>
      <td>0.706675</td>
      <td>-0.338486</td>
      <td>0.178863</td>
      <td>0.358402</td>
      <td>-0.355963</td>
      <td>0.954202</td>
      <td>-1.104770</td>
      <td>-0.119808</td>
      <td>-0.083438</td>
      <td>-0.173679</td>
      <td>-0.484758</td>
      <td>-0.185586</td>
      <td>-1.036691</td>
      <td>-1.222700</td>
      <td>-0.145889</td>
      <td>0.468406</td>
      <td>-0.080142</td>
      <td>-1.024193</td>
      <td>-0.560954</td>
      <td>-0.502562</td>
      <td>0.186783</td>
      <td>-0.290698</td>
      <td>-0.730657</td>
      <td>-0.222400</td>
      <td>1.305892</td>
      <td>0.070851</td>
      <td>-0.477645</td>
      <td>0.045140</td>
      <td>-0.593099</td>
      <td>0.444552</td>
      <td>0.239866</td>
      <td>-1.086013</td>
      <td>-0.266105</td>
      <td>-0.914644</td>
      <td>-0.527713</td>
      <td>0.171879</td>
      <td>0.962704</td>
      <td>-0.147214</td>
      <td>-0.945456</td>
      <td>...</td>
      <td>0.136492</td>
      <td>-0.203070</td>
      <td>0.107031</td>
      <td>-0.619841</td>
      <td>0.383451</td>
      <td>1.539028</td>
      <td>0.484149</td>
      <td>0.470737</td>
      <td>-0.110798</td>
      <td>-0.116608</td>
      <td>0.262495</td>
      <td>-0.132754</td>
      <td>-0.566658</td>
      <td>-0.149315</td>
      <td>0.160106</td>
      <td>0.774989</td>
      <td>0.133538</td>
      <td>-0.066918</td>
      <td>0.439518</td>
      <td>0.130308</td>
      <td>0.508152</td>
      <td>0.127190</td>
      <td>0.402108</td>
      <td>-0.237089</td>
      <td>-0.306488</td>
      <td>-0.233247</td>
      <td>-0.071166</td>
      <td>0.061558</td>
      <td>-0.578288</td>
      <td>-0.254993</td>
      <td>-0.463871</td>
      <td>-0.405800</td>
      <td>1.046054</td>
      <td>0.911156</td>
      <td>0.060595</td>
      <td>-0.041136</td>
      <td>0.107962</td>
      <td>2.688417</td>
      <td>1.300591</td>
      <td>1.209881</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.255641</td>
      <td>0.564792</td>
      <td>-0.543856</td>
      <td>0.824070</td>
      <td>-0.305935</td>
      <td>-0.928459</td>
      <td>0.186481</td>
      <td>-0.254186</td>
      <td>-0.640499</td>
      <td>-0.153388</td>
      <td>-0.775038</td>
      <td>-0.180197</td>
      <td>-0.098490</td>
      <td>-0.341771</td>
      <td>0.204426</td>
      <td>-0.086989</td>
      <td>-0.058841</td>
      <td>0.198863</td>
      <td>0.410632</td>
      <td>0.865562</td>
      <td>-0.118831</td>
      <td>0.099241</td>
      <td>-0.801326</td>
      <td>-0.339784</td>
      <td>0.382441</td>
      <td>0.405949</td>
      <td>-0.131249</td>
      <td>-0.333837</td>
      <td>-0.148692</td>
      <td>0.959057</td>
      <td>0.867582</td>
      <td>-0.046524</td>
      <td>-0.042271</td>
      <td>0.087433</td>
      <td>-0.793507</td>
      <td>0.304206</td>
      <td>0.336806</td>
      <td>0.698875</td>
      <td>2.224681</td>
      <td>0.417958</td>
      <td>...</td>
      <td>0.582752</td>
      <td>-0.251983</td>
      <td>-1.065605</td>
      <td>-1.777873</td>
      <td>-0.041838</td>
      <td>0.307972</td>
      <td>0.459867</td>
      <td>-0.709041</td>
      <td>-0.443749</td>
      <td>-0.049754</td>
      <td>0.919451</td>
      <td>0.190718</td>
      <td>-0.051714</td>
      <td>-0.141113</td>
      <td>-0.174838</td>
      <td>-0.232682</td>
      <td>0.256000</td>
      <td>-0.255535</td>
      <td>0.495929</td>
      <td>0.041317</td>
      <td>0.928512</td>
      <td>0.262223</td>
      <td>-0.154478</td>
      <td>1.247446</td>
      <td>0.882326</td>
      <td>-0.508117</td>
      <td>0.859607</td>
      <td>0.592279</td>
      <td>-1.056714</td>
      <td>-0.608269</td>
      <td>-0.729976</td>
      <td>-0.262657</td>
      <td>0.009800</td>
      <td>0.045529</td>
      <td>0.995748</td>
      <td>0.112660</td>
      <td>1.545431</td>
      <td>-0.156318</td>
      <td>-0.143432</td>
      <td>0.616224</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.898239</td>
      <td>0.088750</td>
      <td>-0.714480</td>
      <td>-0.378314</td>
      <td>0.746467</td>
      <td>0.144796</td>
      <td>0.218722</td>
      <td>0.125280</td>
      <td>0.137374</td>
      <td>-0.948987</td>
      <td>-0.492906</td>
      <td>-0.343307</td>
      <td>-0.037897</td>
      <td>0.297087</td>
      <td>0.010033</td>
      <td>-0.394264</td>
      <td>-0.229436</td>
      <td>0.132423</td>
      <td>-0.075973</td>
      <td>0.627503</td>
      <td>0.860448</td>
      <td>0.378723</td>
      <td>0.538054</td>
      <td>0.804486</td>
      <td>-0.248031</td>
      <td>0.985346</td>
      <td>-0.763900</td>
      <td>1.096235</td>
      <td>1.419716</td>
      <td>0.279037</td>
      <td>0.105838</td>
      <td>-0.710746</td>
      <td>-0.836332</td>
      <td>0.117259</td>
      <td>0.344745</td>
      <td>1.043160</td>
      <td>0.624173</td>
      <td>1.479276</td>
      <td>0.879673</td>
      <td>-0.024937</td>
      <td>...</td>
      <td>-0.166067</td>
      <td>0.040838</td>
      <td>0.028356</td>
      <td>-0.006295</td>
      <td>-0.514341</td>
      <td>1.053831</td>
      <td>0.771661</td>
      <td>0.715918</td>
      <td>-0.111551</td>
      <td>0.589118</td>
      <td>0.025088</td>
      <td>0.673411</td>
      <td>0.325629</td>
      <td>-0.594713</td>
      <td>0.319329</td>
      <td>0.400773</td>
      <td>-0.224638</td>
      <td>1.098742</td>
      <td>0.589989</td>
      <td>0.119641</td>
      <td>-0.416172</td>
      <td>0.097046</td>
      <td>-0.196833</td>
      <td>-0.622457</td>
      <td>-0.861683</td>
      <td>0.311946</td>
      <td>0.095763</td>
      <td>-0.449776</td>
      <td>0.237823</td>
      <td>0.201146</td>
      <td>-0.029296</td>
      <td>0.929282</td>
      <td>1.413273</td>
      <td>1.249214</td>
      <td>-0.416934</td>
      <td>-0.032995</td>
      <td>0.302541</td>
      <td>2.172046</td>
      <td>1.853712</td>
      <td>0.640053</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.114292</td>
      <td>-1.029420</td>
      <td>-1.023579</td>
      <td>1.646669</td>
      <td>-0.165150</td>
      <td>0.682889</td>
      <td>-1.102270</td>
      <td>0.349795</td>
      <td>0.013865</td>
      <td>-0.160137</td>
      <td>-0.218344</td>
      <td>1.449127</td>
      <td>0.539545</td>
      <td>-0.498571</td>
      <td>-0.100375</td>
      <td>0.211940</td>
      <td>-0.342926</td>
      <td>1.086552</td>
      <td>0.623718</td>
      <td>0.220959</td>
      <td>-0.014794</td>
      <td>1.200488</td>
      <td>-1.091181</td>
      <td>-0.589496</td>
      <td>-1.090452</td>
      <td>-0.121482</td>
      <td>0.370886</td>
      <td>-0.278882</td>
      <td>0.641061</td>
      <td>0.342580</td>
      <td>1.644347</td>
      <td>1.370906</td>
      <td>-0.341605</td>
      <td>-0.386344</td>
      <td>0.173571</td>
      <td>-0.290599</td>
      <td>-0.404989</td>
      <td>0.971532</td>
      <td>1.223622</td>
      <td>1.068056</td>
      <td>...</td>
      <td>-0.459313</td>
      <td>-0.053511</td>
      <td>0.167140</td>
      <td>-1.279133</td>
      <td>-0.002027</td>
      <td>0.262948</td>
      <td>1.258695</td>
      <td>1.162399</td>
      <td>1.546521</td>
      <td>0.642353</td>
      <td>0.785782</td>
      <td>0.553618</td>
      <td>0.555071</td>
      <td>0.265563</td>
      <td>0.653776</td>
      <td>-0.964629</td>
      <td>-0.202195</td>
      <td>-0.164502</td>
      <td>0.329835</td>
      <td>-0.202244</td>
      <td>0.426298</td>
      <td>-0.225331</td>
      <td>0.182501</td>
      <td>1.362367</td>
      <td>0.717867</td>
      <td>0.278568</td>
      <td>0.164539</td>
      <td>0.522021</td>
      <td>-0.018347</td>
      <td>-0.478009</td>
      <td>0.666785</td>
      <td>-0.754923</td>
      <td>0.263872</td>
      <td>0.365807</td>
      <td>-0.984886</td>
      <td>-0.272637</td>
      <td>-0.065661</td>
      <td>-1.917911</td>
      <td>-0.757044</td>
      <td>-0.313314</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-0.683229</td>
      <td>0.325177</td>
      <td>-1.008016</td>
      <td>0.000054</td>
      <td>-0.059409</td>
      <td>0.713603</td>
      <td>-0.090393</td>
      <td>0.325185</td>
      <td>0.042391</td>
      <td>-0.392302</td>
      <td>-0.317001</td>
      <td>-0.144345</td>
      <td>-0.588954</td>
      <td>0.227925</td>
      <td>-0.199764</td>
      <td>-1.362567</td>
      <td>0.119683</td>
      <td>0.131983</td>
      <td>0.261740</td>
      <td>0.015674</td>
      <td>0.219050</td>
      <td>-0.104630</td>
      <td>0.166133</td>
      <td>0.699076</td>
      <td>0.603556</td>
      <td>-0.152099</td>
      <td>0.618333</td>
      <td>0.147147</td>
      <td>-0.609117</td>
      <td>-0.188761</td>
      <td>0.678290</td>
      <td>0.143081</td>
      <td>0.061459</td>
      <td>0.947206</td>
      <td>0.035315</td>
      <td>0.494744</td>
      <td>-0.317427</td>
      <td>0.366494</td>
      <td>0.512015</td>
      <td>-0.025217</td>
      <td>...</td>
      <td>-0.141433</td>
      <td>0.524380</td>
      <td>0.569570</td>
      <td>-0.870096</td>
      <td>-0.613284</td>
      <td>-0.119045</td>
      <td>1.049225</td>
      <td>0.652594</td>
      <td>0.822526</td>
      <td>0.829070</td>
      <td>1.016231</td>
      <td>1.028470</td>
      <td>0.368924</td>
      <td>0.071552</td>
      <td>0.059485</td>
      <td>0.022925</td>
      <td>0.393036</td>
      <td>0.039594</td>
      <td>-0.093962</td>
      <td>-0.277534</td>
      <td>0.214259</td>
      <td>-0.685338</td>
      <td>-1.084214</td>
      <td>-0.075366</td>
      <td>-0.629064</td>
      <td>1.126272</td>
      <td>0.498896</td>
      <td>1.115702</td>
      <td>-0.505085</td>
      <td>0.714054</td>
      <td>-0.152986</td>
      <td>-2.323781</td>
      <td>-0.435502</td>
      <td>-0.248830</td>
      <td>0.508024</td>
      <td>0.323948</td>
      <td>1.024360</td>
      <td>-1.243290</td>
      <td>-0.912477</td>
      <td>-0.223616</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-1.014482</td>
      <td>0.186541</td>
      <td>-0.432772</td>
      <td>0.445590</td>
      <td>0.560534</td>
      <td>0.289286</td>
      <td>1.248818</td>
      <td>0.289619</td>
      <td>0.121718</td>
      <td>0.651295</td>
      <td>-0.932016</td>
      <td>0.586993</td>
      <td>0.641325</td>
      <td>-1.116355</td>
      <td>-0.232825</td>
      <td>-0.536877</td>
      <td>0.043573</td>
      <td>0.285963</td>
      <td>0.304203</td>
      <td>0.419146</td>
      <td>1.154512</td>
      <td>1.941782</td>
      <td>0.853637</td>
      <td>0.424076</td>
      <td>0.301009</td>
      <td>0.060211</td>
      <td>-0.395291</td>
      <td>-0.533619</td>
      <td>0.194478</td>
      <td>0.267490</td>
      <td>0.155662</td>
      <td>-0.129918</td>
      <td>-0.663844</td>
      <td>0.000145</td>
      <td>0.172279</td>
      <td>-0.368281</td>
      <td>-0.201895</td>
      <td>0.193759</td>
      <td>0.727486</td>
      <td>0.385998</td>
      <td>...</td>
      <td>0.138684</td>
      <td>0.363596</td>
      <td>0.719429</td>
      <td>0.656517</td>
      <td>0.728373</td>
      <td>1.342305</td>
      <td>0.442060</td>
      <td>0.423831</td>
      <td>-0.352230</td>
      <td>-0.230606</td>
      <td>0.154681</td>
      <td>0.752126</td>
      <td>0.151932</td>
      <td>-0.104201</td>
      <td>-0.473839</td>
      <td>0.519538</td>
      <td>0.325038</td>
      <td>-0.890225</td>
      <td>0.343450</td>
      <td>-0.309928</td>
      <td>0.320605</td>
      <td>-0.061862</td>
      <td>-0.184006</td>
      <td>-0.098723</td>
      <td>0.483943</td>
      <td>0.600878</td>
      <td>0.488747</td>
      <td>0.508467</td>
      <td>-0.736721</td>
      <td>-0.344640</td>
      <td>-0.122008</td>
      <td>-1.461233</td>
      <td>-0.110089</td>
      <td>0.209006</td>
      <td>0.171540</td>
      <td>0.531673</td>
      <td>0.685811</td>
      <td>-2.328472</td>
      <td>-1.564718</td>
      <td>-0.326958</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.152489</td>
      <td>-0.300571</td>
      <td>-0.179073</td>
      <td>1.120993</td>
      <td>0.401262</td>
      <td>0.366031</td>
      <td>1.087968</td>
      <td>0.657907</td>
      <td>-0.299010</td>
      <td>-0.069641</td>
      <td>-0.839220</td>
      <td>0.049759</td>
      <td>0.069580</td>
      <td>0.011436</td>
      <td>-0.330228</td>
      <td>0.223722</td>
      <td>-0.060483</td>
      <td>-1.093182</td>
      <td>-0.309081</td>
      <td>0.385113</td>
      <td>0.550274</td>
      <td>0.643002</td>
      <td>-0.556248</td>
      <td>0.217072</td>
      <td>0.878667</td>
      <td>0.356217</td>
      <td>0.406512</td>
      <td>-0.074647</td>
      <td>0.563552</td>
      <td>-0.236033</td>
      <td>-0.053293</td>
      <td>-0.517696</td>
      <td>-0.007116</td>
      <td>-0.209524</td>
      <td>-0.614964</td>
      <td>-1.245696</td>
      <td>-0.213444</td>
      <td>0.249311</td>
      <td>0.608391</td>
      <td>0.466883</td>
      <td>...</td>
      <td>-1.032332</td>
      <td>-0.789721</td>
      <td>0.773937</td>
      <td>-0.483054</td>
      <td>-0.067185</td>
      <td>0.856682</td>
      <td>0.866850</td>
      <td>0.532659</td>
      <td>-0.448753</td>
      <td>0.312977</td>
      <td>0.637120</td>
      <td>1.747886</td>
      <td>-0.588707</td>
      <td>0.865542</td>
      <td>1.803608</td>
      <td>0.383225</td>
      <td>-0.065559</td>
      <td>0.197528</td>
      <td>0.552189</td>
      <td>-0.183482</td>
      <td>0.706814</td>
      <td>0.141793</td>
      <td>-0.204789</td>
      <td>0.761411</td>
      <td>-0.202141</td>
      <td>-0.000559</td>
      <td>0.031955</td>
      <td>-0.127908</td>
      <td>-0.197157</td>
      <td>0.153846</td>
      <td>0.445291</td>
      <td>-0.135465</td>
      <td>-0.301857</td>
      <td>0.022445</td>
      <td>-0.735346</td>
      <td>0.743545</td>
      <td>0.088861</td>
      <td>0.437148</td>
      <td>0.112493</td>
      <td>0.540950</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.496136</td>
      <td>-0.007238</td>
      <td>-0.038964</td>
      <td>0.036368</td>
      <td>0.233662</td>
      <td>-0.489162</td>
      <td>0.606226</td>
      <td>0.154099</td>
      <td>-1.102526</td>
      <td>-0.581441</td>
      <td>-0.008929</td>
      <td>0.835753</td>
      <td>0.093007</td>
      <td>-0.779350</td>
      <td>-0.790179</td>
      <td>-0.736000</td>
      <td>0.122152</td>
      <td>-0.862987</td>
      <td>-0.336545</td>
      <td>0.075057</td>
      <td>0.114613</td>
      <td>0.136232</td>
      <td>0.255904</td>
      <td>0.083971</td>
      <td>0.021673</td>
      <td>-0.555359</td>
      <td>-0.758729</td>
      <td>-0.523252</td>
      <td>-0.010844</td>
      <td>-0.848310</td>
      <td>0.714840</td>
      <td>-0.176123</td>
      <td>-0.560246</td>
      <td>-1.391539</td>
      <td>-0.885782</td>
      <td>-0.226458</td>
      <td>-0.183057</td>
      <td>1.156285</td>
      <td>0.887946</td>
      <td>-0.432728</td>
      <td>...</td>
      <td>-1.154318</td>
      <td>0.046266</td>
      <td>0.123818</td>
      <td>-0.437829</td>
      <td>0.875719</td>
      <td>0.763455</td>
      <td>-0.129593</td>
      <td>0.787898</td>
      <td>-1.091195</td>
      <td>-0.120406</td>
      <td>-0.420346</td>
      <td>0.304772</td>
      <td>0.930211</td>
      <td>1.279228</td>
      <td>0.274083</td>
      <td>-0.439989</td>
      <td>1.159011</td>
      <td>-0.491386</td>
      <td>-0.356686</td>
      <td>-0.847796</td>
      <td>0.398387</td>
      <td>-0.553905</td>
      <td>0.426887</td>
      <td>0.985017</td>
      <td>0.394654</td>
      <td>0.894114</td>
      <td>-0.658974</td>
      <td>0.067502</td>
      <td>-0.244005</td>
      <td>0.366747</td>
      <td>0.787789</td>
      <td>-0.187688</td>
      <td>-0.170969</td>
      <td>-0.131822</td>
      <td>-0.232436</td>
      <td>0.000697</td>
      <td>0.733409</td>
      <td>-0.178505</td>
      <td>-0.587370</td>
      <td>-0.091256</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.063128</td>
      <td>0.905101</td>
      <td>-1.844517</td>
      <td>-0.280469</td>
      <td>-0.788582</td>
      <td>0.052894</td>
      <td>0.672004</td>
      <td>0.377564</td>
      <td>-0.307164</td>
      <td>-0.141293</td>
      <td>0.154475</td>
      <td>0.607513</td>
      <td>0.369516</td>
      <td>-0.060313</td>
      <td>-1.455720</td>
      <td>-0.349714</td>
      <td>0.279182</td>
      <td>0.308782</td>
      <td>0.091064</td>
      <td>-0.576587</td>
      <td>0.118303</td>
      <td>0.619822</td>
      <td>0.942910</td>
      <td>-0.016580</td>
      <td>1.264962</td>
      <td>0.576253</td>
      <td>0.938400</td>
      <td>1.382069</td>
      <td>1.019412</td>
      <td>-0.477955</td>
      <td>-0.115957</td>
      <td>-0.625373</td>
      <td>-0.526676</td>
      <td>-0.449094</td>
      <td>-1.295719</td>
      <td>-0.382737</td>
      <td>-1.017974</td>
      <td>-0.600937</td>
      <td>1.104771</td>
      <td>-0.186141</td>
      <td>...</td>
      <td>0.492300</td>
      <td>0.395415</td>
      <td>0.466427</td>
      <td>-0.506560</td>
      <td>0.479988</td>
      <td>0.269114</td>
      <td>0.831476</td>
      <td>1.119491</td>
      <td>-0.566907</td>
      <td>0.794160</td>
      <td>0.539636</td>
      <td>0.884174</td>
      <td>0.132307</td>
      <td>0.793441</td>
      <td>0.227903</td>
      <td>-0.482350</td>
      <td>-0.334957</td>
      <td>-0.083187</td>
      <td>0.097138</td>
      <td>-0.746457</td>
      <td>-1.215908</td>
      <td>-0.869026</td>
      <td>-0.047407</td>
      <td>0.580922</td>
      <td>0.523683</td>
      <td>0.689853</td>
      <td>1.918237</td>
      <td>-0.039797</td>
      <td>-0.493900</td>
      <td>0.167169</td>
      <td>0.013431</td>
      <td>-1.001764</td>
      <td>0.105505</td>
      <td>-0.013567</td>
      <td>-0.991328</td>
      <td>-0.064911</td>
      <td>0.615485</td>
      <td>-0.318790</td>
      <td>-0.783694</td>
      <td>-0.941875</td>
    </tr>
    <tr>
      <th>21</th>
      <td>1.429230</td>
      <td>0.839040</td>
      <td>0.113624</td>
      <td>-0.121679</td>
      <td>0.576840</td>
      <td>0.723604</td>
      <td>0.550720</td>
      <td>0.707561</td>
      <td>-0.451691</td>
      <td>-0.483131</td>
      <td>-0.498774</td>
      <td>0.684846</td>
      <td>0.286999</td>
      <td>0.085251</td>
      <td>-1.380325</td>
      <td>0.100490</td>
      <td>-0.016915</td>
      <td>-0.805990</td>
      <td>0.065311</td>
      <td>0.323139</td>
      <td>0.099553</td>
      <td>-0.248798</td>
      <td>-0.058563</td>
      <td>-1.060297</td>
      <td>-0.629472</td>
      <td>-0.956583</td>
      <td>-0.448258</td>
      <td>-0.156771</td>
      <td>0.195575</td>
      <td>-0.125252</td>
      <td>-0.939101</td>
      <td>0.822102</td>
      <td>-0.046205</td>
      <td>-0.145042</td>
      <td>-0.181498</td>
      <td>-0.406354</td>
      <td>0.067075</td>
      <td>0.882889</td>
      <td>-0.531303</td>
      <td>0.559430</td>
      <td>...</td>
      <td>0.269526</td>
      <td>-0.035189</td>
      <td>-0.386816</td>
      <td>-0.318257</td>
      <td>-0.108781</td>
      <td>0.445680</td>
      <td>0.184914</td>
      <td>0.361738</td>
      <td>1.286491</td>
      <td>1.033826</td>
      <td>0.194699</td>
      <td>0.802511</td>
      <td>0.041940</td>
      <td>0.107372</td>
      <td>0.006763</td>
      <td>-0.585402</td>
      <td>-0.199899</td>
      <td>-0.206296</td>
      <td>-0.350041</td>
      <td>-0.280490</td>
      <td>-0.357398</td>
      <td>-0.484687</td>
      <td>-0.424659</td>
      <td>0.289910</td>
      <td>-0.087676</td>
      <td>0.203070</td>
      <td>0.870181</td>
      <td>1.436152</td>
      <td>0.530044</td>
      <td>0.187129</td>
      <td>-0.025224</td>
      <td>-0.624523</td>
      <td>0.389064</td>
      <td>0.495727</td>
      <td>-0.460067</td>
      <td>0.556412</td>
      <td>0.622421</td>
      <td>2.422388</td>
      <td>1.980097</td>
      <td>1.827781</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.150728</td>
      <td>-0.195885</td>
      <td>-1.174289</td>
      <td>-0.356431</td>
      <td>0.351921</td>
      <td>0.342025</td>
      <td>0.205484</td>
      <td>0.240081</td>
      <td>-0.666417</td>
      <td>-1.088439</td>
      <td>0.242463</td>
      <td>-0.228320</td>
      <td>0.269174</td>
      <td>0.056709</td>
      <td>-0.217075</td>
      <td>-0.926366</td>
      <td>-0.617807</td>
      <td>0.459510</td>
      <td>0.566791</td>
      <td>0.517558</td>
      <td>0.127401</td>
      <td>1.013402</td>
      <td>0.174764</td>
      <td>0.361011</td>
      <td>0.276692</td>
      <td>1.060995</td>
      <td>0.016960</td>
      <td>-0.853847</td>
      <td>1.442615</td>
      <td>0.319690</td>
      <td>-0.599529</td>
      <td>-1.097611</td>
      <td>-1.280010</td>
      <td>-0.515296</td>
      <td>-0.116787</td>
      <td>-0.374578</td>
      <td>0.303966</td>
      <td>-0.280164</td>
      <td>0.203001</td>
      <td>0.294563</td>
      <td>...</td>
      <td>-0.623801</td>
      <td>-0.065042</td>
      <td>-1.096796</td>
      <td>-1.543435</td>
      <td>-0.413274</td>
      <td>0.582186</td>
      <td>1.164007</td>
      <td>1.136464</td>
      <td>0.762643</td>
      <td>0.408556</td>
      <td>0.430281</td>
      <td>0.096507</td>
      <td>0.004309</td>
      <td>0.023451</td>
      <td>0.116155</td>
      <td>0.141585</td>
      <td>0.213967</td>
      <td>-0.368932</td>
      <td>-0.668832</td>
      <td>-0.112539</td>
      <td>0.041630</td>
      <td>0.063330</td>
      <td>-0.011819</td>
      <td>-0.096924</td>
      <td>-0.384161</td>
      <td>0.998739</td>
      <td>0.713944</td>
      <td>0.177723</td>
      <td>0.595257</td>
      <td>0.701915</td>
      <td>-0.760298</td>
      <td>0.087912</td>
      <td>0.253749</td>
      <td>0.564531</td>
      <td>0.350389</td>
      <td>0.168804</td>
      <td>1.362330</td>
      <td>-0.797039</td>
      <td>0.281892</td>
      <td>0.609722</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.417049</td>
      <td>0.100968</td>
      <td>-1.254031</td>
      <td>-0.251471</td>
      <td>-0.437013</td>
      <td>0.627868</td>
      <td>-0.090523</td>
      <td>-0.443326</td>
      <td>-0.811066</td>
      <td>-0.052605</td>
      <td>-1.440689</td>
      <td>-0.340232</td>
      <td>-0.258613</td>
      <td>-1.434627</td>
      <td>-0.917980</td>
      <td>-1.207336</td>
      <td>0.058099</td>
      <td>-0.723416</td>
      <td>0.101519</td>
      <td>0.929551</td>
      <td>0.070306</td>
      <td>0.843310</td>
      <td>0.269466</td>
      <td>0.516171</td>
      <td>0.167201</td>
      <td>-0.101719</td>
      <td>0.541684</td>
      <td>0.301150</td>
      <td>-0.326761</td>
      <td>0.728771</td>
      <td>0.494658</td>
      <td>0.133580</td>
      <td>-0.055390</td>
      <td>0.405986</td>
      <td>0.589067</td>
      <td>1.476892</td>
      <td>0.540626</td>
      <td>0.356757</td>
      <td>-0.780875</td>
      <td>-0.655086</td>
      <td>...</td>
      <td>0.272188</td>
      <td>0.083695</td>
      <td>0.410816</td>
      <td>-0.274080</td>
      <td>1.138736</td>
      <td>0.363963</td>
      <td>0.105666</td>
      <td>-0.222953</td>
      <td>0.597958</td>
      <td>0.444654</td>
      <td>1.054335</td>
      <td>0.530958</td>
      <td>0.713520</td>
      <td>1.281115</td>
      <td>0.042847</td>
      <td>0.339744</td>
      <td>0.966582</td>
      <td>-0.386565</td>
      <td>-0.530035</td>
      <td>-1.753933</td>
      <td>-0.360375</td>
      <td>-0.072133</td>
      <td>0.277013</td>
      <td>0.245943</td>
      <td>0.602715</td>
      <td>0.362428</td>
      <td>-0.124921</td>
      <td>0.684107</td>
      <td>1.157333</td>
      <td>0.602655</td>
      <td>-0.111154</td>
      <td>-0.676849</td>
      <td>-0.646290</td>
      <td>-0.635441</td>
      <td>0.580963</td>
      <td>0.443668</td>
      <td>0.432698</td>
      <td>0.224777</td>
      <td>0.161248</td>
      <td>-0.387212</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.502667</td>
      <td>-0.805243</td>
      <td>-0.249342</td>
      <td>-0.115305</td>
      <td>-1.071960</td>
      <td>-0.207147</td>
      <td>0.171200</td>
      <td>0.298318</td>
      <td>-0.064763</td>
      <td>-0.605653</td>
      <td>0.148103</td>
      <td>0.652702</td>
      <td>-0.346980</td>
      <td>-0.099144</td>
      <td>-0.325747</td>
      <td>-0.325462</td>
      <td>-0.279384</td>
      <td>0.363317</td>
      <td>-0.151906</td>
      <td>0.134016</td>
      <td>0.136368</td>
      <td>1.310035</td>
      <td>-0.850608</td>
      <td>-0.556341</td>
      <td>-0.361316</td>
      <td>0.341612</td>
      <td>0.229787</td>
      <td>-0.970413</td>
      <td>0.467674</td>
      <td>0.089100</td>
      <td>0.662954</td>
      <td>-0.270926</td>
      <td>0.396729</td>
      <td>0.218704</td>
      <td>-0.441536</td>
      <td>1.109168</td>
      <td>-0.226535</td>
      <td>1.149704</td>
      <td>-0.411717</td>
      <td>-0.000261</td>
      <td>...</td>
      <td>-0.242350</td>
      <td>0.044819</td>
      <td>1.106828</td>
      <td>-0.149940</td>
      <td>-0.216655</td>
      <td>1.486064</td>
      <td>1.362448</td>
      <td>0.707100</td>
      <td>-0.105064</td>
      <td>-0.186636</td>
      <td>0.094959</td>
      <td>0.593245</td>
      <td>-0.357320</td>
      <td>0.085229</td>
      <td>0.412116</td>
      <td>-0.442329</td>
      <td>0.328395</td>
      <td>0.407057</td>
      <td>-0.174320</td>
      <td>-0.299373</td>
      <td>-0.675083</td>
      <td>-0.063845</td>
      <td>-0.103255</td>
      <td>0.423046</td>
      <td>0.880437</td>
      <td>0.191065</td>
      <td>0.661983</td>
      <td>1.759128</td>
      <td>0.292039</td>
      <td>0.408713</td>
      <td>-0.118966</td>
      <td>0.375475</td>
      <td>0.338276</td>
      <td>-0.131414</td>
      <td>0.333192</td>
      <td>-0.439509</td>
      <td>0.748994</td>
      <td>0.054305</td>
      <td>-0.047628</td>
      <td>-0.020819</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.376253</td>
      <td>-0.338441</td>
      <td>-0.030534</td>
      <td>0.182062</td>
      <td>-0.216691</td>
      <td>0.109387</td>
      <td>-0.203972</td>
      <td>0.542148</td>
      <td>-0.190992</td>
      <td>-0.931953</td>
      <td>-0.365928</td>
      <td>-0.198395</td>
      <td>0.093382</td>
      <td>-0.369782</td>
      <td>-0.228782</td>
      <td>-0.134501</td>
      <td>-0.505806</td>
      <td>-0.524616</td>
      <td>-0.238794</td>
      <td>-0.019173</td>
      <td>-0.550151</td>
      <td>-0.427812</td>
      <td>-0.394440</td>
      <td>-1.199744</td>
      <td>-0.041077</td>
      <td>0.554024</td>
      <td>0.204357</td>
      <td>0.324881</td>
      <td>-0.319332</td>
      <td>-0.716528</td>
      <td>0.169093</td>
      <td>-0.171121</td>
      <td>0.630631</td>
      <td>-0.348142</td>
      <td>-0.212022</td>
      <td>0.495499</td>
      <td>-0.457436</td>
      <td>0.025271</td>
      <td>0.914957</td>
      <td>0.353817</td>
      <td>...</td>
      <td>-1.334152</td>
      <td>0.256875</td>
      <td>0.526373</td>
      <td>0.353224</td>
      <td>0.455645</td>
      <td>0.139863</td>
      <td>-0.561245</td>
      <td>0.242923</td>
      <td>0.444816</td>
      <td>-0.537849</td>
      <td>0.021205</td>
      <td>-0.741502</td>
      <td>0.612137</td>
      <td>0.124290</td>
      <td>-0.370131</td>
      <td>-0.061170</td>
      <td>0.755322</td>
      <td>0.677950</td>
      <td>-0.092761</td>
      <td>-0.339092</td>
      <td>-0.190224</td>
      <td>0.087699</td>
      <td>0.309503</td>
      <td>-0.077188</td>
      <td>-0.052685</td>
      <td>-0.376672</td>
      <td>0.132351</td>
      <td>-0.598766</td>
      <td>0.199682</td>
      <td>-0.365698</td>
      <td>-0.329341</td>
      <td>-1.552459</td>
      <td>-0.606758</td>
      <td>-0.234495</td>
      <td>-0.751420</td>
      <td>-0.306405</td>
      <td>-0.659490</td>
      <td>0.078209</td>
      <td>0.469408</td>
      <td>-0.766200</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.335678</td>
      <td>-0.352629</td>
      <td>-0.062350</td>
      <td>-1.398571</td>
      <td>0.562863</td>
      <td>-0.091686</td>
      <td>0.346634</td>
      <td>0.377649</td>
      <td>0.405714</td>
      <td>-0.564820</td>
      <td>-0.005452</td>
      <td>-0.219974</td>
      <td>-0.621922</td>
      <td>0.518865</td>
      <td>1.449925</td>
      <td>0.029404</td>
      <td>0.539430</td>
      <td>-0.534128</td>
      <td>0.241792</td>
      <td>1.110523</td>
      <td>0.406645</td>
      <td>-0.087810</td>
      <td>0.076618</td>
      <td>0.101828</td>
      <td>0.183632</td>
      <td>0.764113</td>
      <td>0.247669</td>
      <td>0.293115</td>
      <td>-0.348884</td>
      <td>-0.991755</td>
      <td>-0.635945</td>
      <td>-0.214595</td>
      <td>0.455354</td>
      <td>0.318828</td>
      <td>-1.084328</td>
      <td>-0.240689</td>
      <td>-0.076894</td>
      <td>-0.326480</td>
      <td>-0.321751</td>
      <td>-0.539772</td>
      <td>...</td>
      <td>-1.024837</td>
      <td>-0.258775</td>
      <td>0.542876</td>
      <td>-0.854775</td>
      <td>-0.758181</td>
      <td>-0.188808</td>
      <td>-0.190031</td>
      <td>-1.019005</td>
      <td>-0.096280</td>
      <td>-0.267062</td>
      <td>-0.304943</td>
      <td>-0.126801</td>
      <td>1.047969</td>
      <td>-0.610075</td>
      <td>-0.058850</td>
      <td>0.333898</td>
      <td>0.748730</td>
      <td>0.573817</td>
      <td>0.712550</td>
      <td>1.823265</td>
      <td>-0.288972</td>
      <td>-0.668337</td>
      <td>-0.290096</td>
      <td>0.624443</td>
      <td>-1.341181</td>
      <td>-0.678830</td>
      <td>-0.084580</td>
      <td>0.312192</td>
      <td>0.424886</td>
      <td>-0.209102</td>
      <td>-0.861333</td>
      <td>0.347740</td>
      <td>0.522544</td>
      <td>0.146673</td>
      <td>-0.861499</td>
      <td>-0.932394</td>
      <td>0.055277</td>
      <td>-2.005052</td>
      <td>-1.630286</td>
      <td>-1.271334</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.660889</td>
      <td>0.771573</td>
      <td>-0.141643</td>
      <td>-0.161342</td>
      <td>-0.395118</td>
      <td>0.180495</td>
      <td>0.457847</td>
      <td>1.118848</td>
      <td>-0.535400</td>
      <td>-0.758934</td>
      <td>-0.158374</td>
      <td>-0.331199</td>
      <td>0.057547</td>
      <td>0.198667</td>
      <td>0.285442</td>
      <td>0.420000</td>
      <td>0.128733</td>
      <td>0.780177</td>
      <td>-1.329848</td>
      <td>-0.347089</td>
      <td>-0.866914</td>
      <td>0.532764</td>
      <td>-0.327129</td>
      <td>-0.785618</td>
      <td>-0.624923</td>
      <td>1.109840</td>
      <td>-0.349009</td>
      <td>0.378539</td>
      <td>0.690592</td>
      <td>-0.109936</td>
      <td>-0.316469</td>
      <td>-0.459478</td>
      <td>-0.667214</td>
      <td>-0.100798</td>
      <td>-0.303224</td>
      <td>1.043612</td>
      <td>0.662728</td>
      <td>0.509835</td>
      <td>0.721333</td>
      <td>0.479044</td>
      <td>...</td>
      <td>-1.163211</td>
      <td>0.268120</td>
      <td>-0.054187</td>
      <td>-0.567682</td>
      <td>-0.231602</td>
      <td>-0.993829</td>
      <td>-0.910394</td>
      <td>-1.324396</td>
      <td>-0.201619</td>
      <td>0.754723</td>
      <td>0.167011</td>
      <td>-0.433762</td>
      <td>0.794140</td>
      <td>-0.093714</td>
      <td>0.436711</td>
      <td>0.019816</td>
      <td>0.171024</td>
      <td>0.108792</td>
      <td>-0.000389</td>
      <td>0.815659</td>
      <td>1.019457</td>
      <td>-0.038216</td>
      <td>-0.158161</td>
      <td>-0.485599</td>
      <td>0.333612</td>
      <td>0.004130</td>
      <td>0.811324</td>
      <td>-0.507726</td>
      <td>-0.500250</td>
      <td>-0.645031</td>
      <td>-0.803790</td>
      <td>-0.744187</td>
      <td>-0.859215</td>
      <td>-0.256684</td>
      <td>-0.763656</td>
      <td>-0.589944</td>
      <td>-0.880802</td>
      <td>-1.109568</td>
      <td>-0.941736</td>
      <td>-0.683559</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.675823</td>
      <td>-0.925829</td>
      <td>-0.790216</td>
      <td>-0.699462</td>
      <td>-0.050115</td>
      <td>0.094007</td>
      <td>-0.352891</td>
      <td>0.481793</td>
      <td>0.767125</td>
      <td>0.971635</td>
      <td>0.073153</td>
      <td>-0.259578</td>
      <td>0.699672</td>
      <td>0.340760</td>
      <td>0.892158</td>
      <td>1.421747</td>
      <td>-0.113566</td>
      <td>-0.377137</td>
      <td>0.664558</td>
      <td>-0.428573</td>
      <td>0.253353</td>
      <td>-0.488518</td>
      <td>-0.267463</td>
      <td>0.148882</td>
      <td>1.033483</td>
      <td>1.201513</td>
      <td>0.186886</td>
      <td>-0.533503</td>
      <td>1.072479</td>
      <td>0.496795</td>
      <td>0.325516</td>
      <td>-1.042407</td>
      <td>-0.129030</td>
      <td>0.516237</td>
      <td>0.130340</td>
      <td>0.150246</td>
      <td>-0.273519</td>
      <td>-0.655146</td>
      <td>0.594860</td>
      <td>-0.202231</td>
      <td>...</td>
      <td>-1.208357</td>
      <td>-0.058222</td>
      <td>-0.528335</td>
      <td>-0.913326</td>
      <td>0.010643</td>
      <td>0.537406</td>
      <td>0.391956</td>
      <td>0.474370</td>
      <td>-0.231288</td>
      <td>-0.800623</td>
      <td>0.164223</td>
      <td>-0.463532</td>
      <td>-1.294838</td>
      <td>-0.920125</td>
      <td>0.076211</td>
      <td>0.236313</td>
      <td>0.470838</td>
      <td>0.492153</td>
      <td>-0.373064</td>
      <td>0.786436</td>
      <td>-0.641481</td>
      <td>0.441311</td>
      <td>-0.159087</td>
      <td>-0.703160</td>
      <td>0.360650</td>
      <td>-0.621855</td>
      <td>0.061831</td>
      <td>-1.068158</td>
      <td>0.592170</td>
      <td>-0.109050</td>
      <td>-0.204282</td>
      <td>-0.256444</td>
      <td>0.151233</td>
      <td>-0.351425</td>
      <td>-1.270730</td>
      <td>-1.333362</td>
      <td>0.256210</td>
      <td>-0.974855</td>
      <td>-0.827020</td>
      <td>-0.234607</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.076188</td>
      <td>-0.704833</td>
      <td>-0.719792</td>
      <td>-0.443836</td>
      <td>0.345533</td>
      <td>1.792999</td>
      <td>0.305430</td>
      <td>0.749045</td>
      <td>0.188190</td>
      <td>-0.370224</td>
      <td>-1.245338</td>
      <td>-0.639698</td>
      <td>-0.818264</td>
      <td>-0.447804</td>
      <td>-0.170690</td>
      <td>0.115931</td>
      <td>-0.625655</td>
      <td>0.562578</td>
      <td>-0.052896</td>
      <td>0.288146</td>
      <td>0.158535</td>
      <td>-0.950917</td>
      <td>-0.414591</td>
      <td>-1.723970</td>
      <td>0.092204</td>
      <td>0.664043</td>
      <td>0.067614</td>
      <td>0.345040</td>
      <td>-0.116866</td>
      <td>0.103293</td>
      <td>0.305975</td>
      <td>-0.024086</td>
      <td>-1.025398</td>
      <td>-0.889058</td>
      <td>-1.206308</td>
      <td>-0.646622</td>
      <td>-0.427258</td>
      <td>-0.209049</td>
      <td>1.302445</td>
      <td>0.197814</td>
      <td>...</td>
      <td>-0.297366</td>
      <td>0.307293</td>
      <td>-0.853077</td>
      <td>-0.355412</td>
      <td>-1.004653</td>
      <td>-0.205108</td>
      <td>-0.155908</td>
      <td>-0.292730</td>
      <td>-0.400176</td>
      <td>0.554558</td>
      <td>0.682293</td>
      <td>-0.191869</td>
      <td>-0.061303</td>
      <td>-0.836267</td>
      <td>-1.233480</td>
      <td>-0.709489</td>
      <td>-0.223522</td>
      <td>0.065647</td>
      <td>-0.835453</td>
      <td>0.241663</td>
      <td>0.028877</td>
      <td>-0.123422</td>
      <td>0.049886</td>
      <td>-0.004905</td>
      <td>0.335852</td>
      <td>-0.584515</td>
      <td>0.137749</td>
      <td>-0.075889</td>
      <td>0.623571</td>
      <td>-0.538431</td>
      <td>0.389845</td>
      <td>-0.167618</td>
      <td>0.856245</td>
      <td>-0.348624</td>
      <td>-0.199802</td>
      <td>-0.841145</td>
      <td>-0.030792</td>
      <td>-1.574832</td>
      <td>-1.557831</td>
      <td>-1.014754</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7fa1d9be3940&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err         t          P&gt;|t|     2.5 %    97.5 %
D  1.017421  0.040863  24.89827  7.768181e-137  0.937331  1.097511
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.327 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.4.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>