
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.0.1 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="http://doubleml.org"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>     to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-0.092750</td>
      <td>1.437448</td>
      <td>-1.069666</td>
      <td>-0.397314</td>
      <td>-0.308117</td>
      <td>-0.486199</td>
      <td>0.270347</td>
      <td>0.308812</td>
      <td>0.580061</td>
      <td>-0.111948</td>
      <td>1.029554</td>
      <td>1.003999</td>
      <td>-0.361044</td>
      <td>0.745899</td>
      <td>-0.131474</td>
      <td>-0.075595</td>
      <td>0.751885</td>
      <td>0.282337</td>
      <td>0.279280</td>
      <td>1.238406</td>
      <td>-0.161112</td>
      <td>-0.246923</td>
      <td>0.122260</td>
      <td>-0.753730</td>
      <td>-0.766238</td>
      <td>0.322063</td>
      <td>-0.005110</td>
      <td>0.537974</td>
      <td>-0.078530</td>
      <td>0.928635</td>
      <td>0.883119</td>
      <td>1.595202</td>
      <td>0.282403</td>
      <td>1.703371</td>
      <td>0.366080</td>
      <td>1.400767</td>
      <td>0.233412</td>
      <td>0.039026</td>
      <td>-0.092795</td>
      <td>-1.148215</td>
      <td>...</td>
      <td>-0.720967</td>
      <td>-0.345358</td>
      <td>0.318168</td>
      <td>0.126850</td>
      <td>0.315666</td>
      <td>0.084899</td>
      <td>-0.436033</td>
      <td>-0.521032</td>
      <td>-1.224921</td>
      <td>-0.563185</td>
      <td>0.010734</td>
      <td>-0.401415</td>
      <td>-0.187111</td>
      <td>0.356759</td>
      <td>-0.343750</td>
      <td>-0.171301</td>
      <td>0.791591</td>
      <td>0.386490</td>
      <td>0.366935</td>
      <td>-0.138849</td>
      <td>-0.520447</td>
      <td>0.429057</td>
      <td>0.029324</td>
      <td>-0.085968</td>
      <td>-0.064442</td>
      <td>0.329754</td>
      <td>-0.636749</td>
      <td>-0.213075</td>
      <td>0.922374</td>
      <td>0.675855</td>
      <td>0.031217</td>
      <td>0.875696</td>
      <td>0.144444</td>
      <td>0.492737</td>
      <td>0.032736</td>
      <td>0.455368</td>
      <td>-0.313634</td>
      <td>-0.079812</td>
      <td>0.167087</td>
      <td>0.388676</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.821355</td>
      <td>0.150353</td>
      <td>-1.143159</td>
      <td>-0.820305</td>
      <td>0.085175</td>
      <td>-0.592383</td>
      <td>0.840604</td>
      <td>0.020923</td>
      <td>0.300696</td>
      <td>-0.330812</td>
      <td>0.726754</td>
      <td>0.270525</td>
      <td>-0.679793</td>
      <td>1.432226</td>
      <td>-0.777086</td>
      <td>-1.130502</td>
      <td>-0.584439</td>
      <td>0.178289</td>
      <td>-0.162968</td>
      <td>0.466087</td>
      <td>-0.035884</td>
      <td>0.766961</td>
      <td>-0.537536</td>
      <td>-0.936292</td>
      <td>-0.197509</td>
      <td>0.150363</td>
      <td>0.777962</td>
      <td>0.406898</td>
      <td>0.124017</td>
      <td>0.375468</td>
      <td>-0.708566</td>
      <td>1.214770</td>
      <td>0.567954</td>
      <td>0.233347</td>
      <td>-0.989134</td>
      <td>-0.494959</td>
      <td>-0.367223</td>
      <td>-0.686507</td>
      <td>0.982710</td>
      <td>-0.364138</td>
      <td>...</td>
      <td>0.125813</td>
      <td>-1.075257</td>
      <td>-0.223699</td>
      <td>0.752869</td>
      <td>0.398411</td>
      <td>0.462036</td>
      <td>-1.130746</td>
      <td>-0.192964</td>
      <td>-0.054765</td>
      <td>-0.591296</td>
      <td>0.228210</td>
      <td>0.223537</td>
      <td>0.121013</td>
      <td>0.687831</td>
      <td>-0.018531</td>
      <td>0.867474</td>
      <td>0.144382</td>
      <td>-0.059870</td>
      <td>0.721018</td>
      <td>-0.656908</td>
      <td>-1.364118</td>
      <td>-1.202312</td>
      <td>-0.196405</td>
      <td>-0.669961</td>
      <td>0.776999</td>
      <td>-0.313483</td>
      <td>-0.579777</td>
      <td>-0.276223</td>
      <td>-0.868338</td>
      <td>-0.561665</td>
      <td>0.267678</td>
      <td>0.169729</td>
      <td>0.550530</td>
      <td>0.502988</td>
      <td>1.226271</td>
      <td>0.253103</td>
      <td>0.497740</td>
      <td>-1.621017</td>
      <td>-0.800904</td>
      <td>-0.423764</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.078114</td>
      <td>-0.586448</td>
      <td>-0.358205</td>
      <td>-0.117007</td>
      <td>-1.377413</td>
      <td>0.022333</td>
      <td>0.780384</td>
      <td>0.650447</td>
      <td>-0.011081</td>
      <td>-0.496174</td>
      <td>-0.184853</td>
      <td>-0.665603</td>
      <td>-1.340299</td>
      <td>-0.230686</td>
      <td>-1.243120</td>
      <td>-0.246628</td>
      <td>-0.288936</td>
      <td>-0.952133</td>
      <td>0.265224</td>
      <td>-0.183568</td>
      <td>-0.959463</td>
      <td>-0.025984</td>
      <td>-0.681818</td>
      <td>-0.572670</td>
      <td>-0.113206</td>
      <td>-0.097440</td>
      <td>0.342682</td>
      <td>-0.721121</td>
      <td>-0.034747</td>
      <td>-0.093020</td>
      <td>0.672521</td>
      <td>-0.290400</td>
      <td>-0.745578</td>
      <td>0.512525</td>
      <td>0.373958</td>
      <td>-0.334707</td>
      <td>0.325319</td>
      <td>0.563565</td>
      <td>1.099795</td>
      <td>-0.516155</td>
      <td>...</td>
      <td>0.116592</td>
      <td>-0.602771</td>
      <td>-0.403810</td>
      <td>0.463654</td>
      <td>0.072347</td>
      <td>-0.131434</td>
      <td>-0.280629</td>
      <td>0.368860</td>
      <td>0.652470</td>
      <td>0.922148</td>
      <td>0.678849</td>
      <td>1.212756</td>
      <td>-0.141033</td>
      <td>0.699515</td>
      <td>0.560076</td>
      <td>1.191578</td>
      <td>1.040479</td>
      <td>1.612349</td>
      <td>1.477913</td>
      <td>0.326981</td>
      <td>-0.371436</td>
      <td>0.082085</td>
      <td>1.371765</td>
      <td>-0.081825</td>
      <td>0.171151</td>
      <td>0.625632</td>
      <td>0.133494</td>
      <td>-0.644577</td>
      <td>0.865357</td>
      <td>-0.119911</td>
      <td>0.251029</td>
      <td>0.516113</td>
      <td>0.898323</td>
      <td>0.506538</td>
      <td>0.221181</td>
      <td>0.465914</td>
      <td>-1.034527</td>
      <td>0.980146</td>
      <td>1.228676</td>
      <td>1.827082</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.175084</td>
      <td>0.503050</td>
      <td>0.267477</td>
      <td>-0.371891</td>
      <td>0.943735</td>
      <td>-0.404993</td>
      <td>0.251282</td>
      <td>-0.129698</td>
      <td>0.692939</td>
      <td>0.663145</td>
      <td>0.385028</td>
      <td>-0.313873</td>
      <td>-0.025999</td>
      <td>1.051705</td>
      <td>0.109019</td>
      <td>0.174728</td>
      <td>1.095473</td>
      <td>0.601354</td>
      <td>-0.449168</td>
      <td>0.055021</td>
      <td>-0.433262</td>
      <td>-0.493070</td>
      <td>-0.138092</td>
      <td>-0.083806</td>
      <td>-0.293948</td>
      <td>1.032170</td>
      <td>0.574251</td>
      <td>-0.391193</td>
      <td>-0.720931</td>
      <td>0.478360</td>
      <td>0.464828</td>
      <td>0.963087</td>
      <td>-0.262771</td>
      <td>0.707749</td>
      <td>-0.916787</td>
      <td>-0.534212</td>
      <td>-0.282899</td>
      <td>-0.228742</td>
      <td>-0.591230</td>
      <td>-0.154603</td>
      <td>...</td>
      <td>0.961569</td>
      <td>1.037636</td>
      <td>-0.158159</td>
      <td>0.959146</td>
      <td>1.496389</td>
      <td>0.445335</td>
      <td>0.553497</td>
      <td>-0.161438</td>
      <td>0.737923</td>
      <td>0.096572</td>
      <td>0.308492</td>
      <td>0.506209</td>
      <td>0.933031</td>
      <td>0.277923</td>
      <td>0.516157</td>
      <td>0.000975</td>
      <td>0.320545</td>
      <td>0.100861</td>
      <td>0.392876</td>
      <td>-0.311092</td>
      <td>-0.881496</td>
      <td>0.349574</td>
      <td>0.241987</td>
      <td>0.165804</td>
      <td>-0.514345</td>
      <td>0.228335</td>
      <td>-0.245312</td>
      <td>0.390769</td>
      <td>0.604384</td>
      <td>0.053823</td>
      <td>-0.647618</td>
      <td>-0.460793</td>
      <td>-0.247535</td>
      <td>-0.177878</td>
      <td>0.001596</td>
      <td>-0.640591</td>
      <td>-1.767595</td>
      <td>0.246656</td>
      <td>0.127115</td>
      <td>0.415078</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.817844</td>
      <td>-0.361596</td>
      <td>-0.286391</td>
      <td>-0.684347</td>
      <td>0.748747</td>
      <td>0.948366</td>
      <td>0.572521</td>
      <td>-0.298687</td>
      <td>0.865193</td>
      <td>0.032408</td>
      <td>0.161253</td>
      <td>-0.199103</td>
      <td>-1.058205</td>
      <td>-0.195648</td>
      <td>-0.283352</td>
      <td>-0.315679</td>
      <td>0.393273</td>
      <td>0.488748</td>
      <td>0.863157</td>
      <td>0.320936</td>
      <td>-0.789712</td>
      <td>-1.293399</td>
      <td>-0.156257</td>
      <td>-0.071810</td>
      <td>-0.287181</td>
      <td>-0.245755</td>
      <td>0.347866</td>
      <td>-1.026862</td>
      <td>0.195092</td>
      <td>0.007613</td>
      <td>-0.456695</td>
      <td>0.193784</td>
      <td>0.396402</td>
      <td>-0.076823</td>
      <td>-0.079854</td>
      <td>0.275538</td>
      <td>-0.183930</td>
      <td>0.752451</td>
      <td>1.967171</td>
      <td>0.595801</td>
      <td>...</td>
      <td>0.306198</td>
      <td>0.009807</td>
      <td>0.586073</td>
      <td>1.037354</td>
      <td>0.803969</td>
      <td>0.542455</td>
      <td>0.564765</td>
      <td>-0.462341</td>
      <td>0.022837</td>
      <td>-0.551841</td>
      <td>1.042244</td>
      <td>0.188820</td>
      <td>0.231509</td>
      <td>-0.030466</td>
      <td>-0.296259</td>
      <td>-0.357648</td>
      <td>-0.181242</td>
      <td>-0.253969</td>
      <td>1.089596</td>
      <td>-0.609298</td>
      <td>-0.541888</td>
      <td>0.094787</td>
      <td>0.586673</td>
      <td>-0.264298</td>
      <td>0.147626</td>
      <td>-0.467038</td>
      <td>-0.323967</td>
      <td>-0.713258</td>
      <td>0.923950</td>
      <td>-0.648892</td>
      <td>-1.297964</td>
      <td>-1.145249</td>
      <td>0.328301</td>
      <td>1.897726</td>
      <td>0.577869</td>
      <td>-0.808727</td>
      <td>-0.041968</td>
      <td>1.352070</td>
      <td>1.784152</td>
      <td>1.032459</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-1.014880</td>
      <td>-0.047269</td>
      <td>-0.390944</td>
      <td>0.122007</td>
      <td>0.179233</td>
      <td>-0.658054</td>
      <td>0.727183</td>
      <td>-0.917477</td>
      <td>-0.006346</td>
      <td>0.945717</td>
      <td>-0.369648</td>
      <td>-0.408030</td>
      <td>-0.055304</td>
      <td>0.639094</td>
      <td>0.081362</td>
      <td>-0.892115</td>
      <td>-0.103171</td>
      <td>-0.317015</td>
      <td>0.490350</td>
      <td>-0.305010</td>
      <td>0.189922</td>
      <td>-0.002539</td>
      <td>-0.001850</td>
      <td>0.314457</td>
      <td>-0.096787</td>
      <td>-0.746492</td>
      <td>-1.014595</td>
      <td>-0.055816</td>
      <td>-0.456443</td>
      <td>-0.675808</td>
      <td>-0.884410</td>
      <td>-0.202107</td>
      <td>-0.121657</td>
      <td>0.701769</td>
      <td>0.261927</td>
      <td>0.171083</td>
      <td>-0.094372</td>
      <td>0.573025</td>
      <td>0.650933</td>
      <td>0.051630</td>
      <td>...</td>
      <td>-0.150330</td>
      <td>-0.924352</td>
      <td>-0.276942</td>
      <td>0.756065</td>
      <td>0.419564</td>
      <td>0.603578</td>
      <td>0.076729</td>
      <td>0.601877</td>
      <td>0.111052</td>
      <td>-0.227423</td>
      <td>-0.627617</td>
      <td>-0.145321</td>
      <td>0.359449</td>
      <td>-0.045089</td>
      <td>-0.042391</td>
      <td>0.842602</td>
      <td>0.345255</td>
      <td>-0.373655</td>
      <td>0.484102</td>
      <td>0.467938</td>
      <td>-1.417669</td>
      <td>-0.428615</td>
      <td>0.858808</td>
      <td>0.181261</td>
      <td>0.120136</td>
      <td>-0.027031</td>
      <td>0.016818</td>
      <td>-0.053225</td>
      <td>-0.813823</td>
      <td>-0.447277</td>
      <td>-0.121910</td>
      <td>-0.273498</td>
      <td>0.064924</td>
      <td>1.065558</td>
      <td>-0.076210</td>
      <td>-0.113862</td>
      <td>-0.756503</td>
      <td>-4.054882</td>
      <td>-2.662299</td>
      <td>-0.983989</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.009212</td>
      <td>0.317106</td>
      <td>-0.408707</td>
      <td>-0.365899</td>
      <td>0.167849</td>
      <td>-0.120063</td>
      <td>-0.120343</td>
      <td>0.099810</td>
      <td>0.090612</td>
      <td>0.134949</td>
      <td>0.291673</td>
      <td>-0.666365</td>
      <td>-1.068654</td>
      <td>1.244315</td>
      <td>-0.300608</td>
      <td>0.167813</td>
      <td>0.954645</td>
      <td>-0.228720</td>
      <td>1.401493</td>
      <td>1.141838</td>
      <td>0.082827</td>
      <td>0.544393</td>
      <td>0.391876</td>
      <td>0.058971</td>
      <td>0.655565</td>
      <td>-0.033031</td>
      <td>0.938282</td>
      <td>-0.492140</td>
      <td>0.141089</td>
      <td>0.116469</td>
      <td>0.800414</td>
      <td>-0.155827</td>
      <td>-0.205676</td>
      <td>-0.034292</td>
      <td>0.033677</td>
      <td>-0.456546</td>
      <td>0.153566</td>
      <td>0.016604</td>
      <td>-0.094640</td>
      <td>0.038370</td>
      <td>...</td>
      <td>0.071788</td>
      <td>-0.001609</td>
      <td>0.226583</td>
      <td>0.740650</td>
      <td>0.224071</td>
      <td>0.101474</td>
      <td>-0.487949</td>
      <td>-1.035333</td>
      <td>-0.362517</td>
      <td>-0.561088</td>
      <td>0.276740</td>
      <td>0.233756</td>
      <td>0.687038</td>
      <td>0.487772</td>
      <td>-1.885188</td>
      <td>-0.595334</td>
      <td>-0.829697</td>
      <td>-0.465057</td>
      <td>0.155092</td>
      <td>-0.560758</td>
      <td>-1.128606</td>
      <td>-0.393195</td>
      <td>0.740558</td>
      <td>0.553001</td>
      <td>-0.377898</td>
      <td>0.412722</td>
      <td>-0.711664</td>
      <td>-0.577023</td>
      <td>0.099177</td>
      <td>0.428214</td>
      <td>-0.091757</td>
      <td>-0.371735</td>
      <td>0.569252</td>
      <td>0.557743</td>
      <td>-0.787659</td>
      <td>0.076157</td>
      <td>-0.334750</td>
      <td>-0.036494</td>
      <td>0.252151</td>
      <td>0.073535</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.556128</td>
      <td>-0.374682</td>
      <td>-0.290319</td>
      <td>0.231103</td>
      <td>0.466756</td>
      <td>0.033037</td>
      <td>0.651639</td>
      <td>-0.224589</td>
      <td>0.041895</td>
      <td>-0.776083</td>
      <td>-0.350433</td>
      <td>-1.003249</td>
      <td>0.503559</td>
      <td>0.010787</td>
      <td>-0.376765</td>
      <td>0.097878</td>
      <td>0.900119</td>
      <td>0.047605</td>
      <td>-0.475649</td>
      <td>0.445422</td>
      <td>-1.031659</td>
      <td>-0.107476</td>
      <td>0.693539</td>
      <td>-0.338764</td>
      <td>-0.062393</td>
      <td>-0.421598</td>
      <td>-0.024218</td>
      <td>0.427999</td>
      <td>0.035864</td>
      <td>0.042967</td>
      <td>-0.727675</td>
      <td>-0.852983</td>
      <td>0.025540</td>
      <td>1.401159</td>
      <td>-0.449252</td>
      <td>-1.353466</td>
      <td>-0.663951</td>
      <td>0.323919</td>
      <td>0.527285</td>
      <td>-0.088263</td>
      <td>...</td>
      <td>0.103242</td>
      <td>-0.679409</td>
      <td>-0.235203</td>
      <td>0.724018</td>
      <td>0.561375</td>
      <td>1.110793</td>
      <td>0.907326</td>
      <td>-0.462927</td>
      <td>-0.685398</td>
      <td>-1.002401</td>
      <td>-1.484247</td>
      <td>-1.207212</td>
      <td>0.232337</td>
      <td>0.102150</td>
      <td>0.904251</td>
      <td>0.180130</td>
      <td>0.328616</td>
      <td>-0.376242</td>
      <td>0.232552</td>
      <td>-0.293306</td>
      <td>-0.720460</td>
      <td>-0.485599</td>
      <td>-1.232561</td>
      <td>-1.443605</td>
      <td>-0.451350</td>
      <td>0.797197</td>
      <td>-0.563253</td>
      <td>0.042313</td>
      <td>0.108064</td>
      <td>0.819439</td>
      <td>0.118304</td>
      <td>0.041581</td>
      <td>-0.669232</td>
      <td>0.300756</td>
      <td>0.866977</td>
      <td>0.063094</td>
      <td>-0.370583</td>
      <td>-0.721014</td>
      <td>-0.561899</td>
      <td>0.012172</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.847274</td>
      <td>0.356876</td>
      <td>-0.332872</td>
      <td>0.109606</td>
      <td>-0.330042</td>
      <td>0.143824</td>
      <td>-0.290952</td>
      <td>0.133644</td>
      <td>0.303836</td>
      <td>-0.506000</td>
      <td>0.425876</td>
      <td>0.356469</td>
      <td>-1.069106</td>
      <td>1.039733</td>
      <td>0.026008</td>
      <td>-0.620987</td>
      <td>0.622354</td>
      <td>-0.346768</td>
      <td>0.044102</td>
      <td>0.212326</td>
      <td>-0.932595</td>
      <td>-0.108303</td>
      <td>-0.059300</td>
      <td>0.724765</td>
      <td>0.036269</td>
      <td>0.813949</td>
      <td>0.932445</td>
      <td>-0.104146</td>
      <td>0.446994</td>
      <td>0.133273</td>
      <td>-0.122960</td>
      <td>0.970501</td>
      <td>0.758704</td>
      <td>0.662312</td>
      <td>-0.226927</td>
      <td>-0.288256</td>
      <td>-0.364382</td>
      <td>-0.007220</td>
      <td>0.709735</td>
      <td>0.048365</td>
      <td>...</td>
      <td>-0.479418</td>
      <td>-0.110335</td>
      <td>-0.880808</td>
      <td>0.820587</td>
      <td>0.057852</td>
      <td>-0.039899</td>
      <td>-0.623703</td>
      <td>0.666708</td>
      <td>0.454540</td>
      <td>0.245427</td>
      <td>0.327646</td>
      <td>0.312081</td>
      <td>-0.488444</td>
      <td>-0.488261</td>
      <td>-1.054447</td>
      <td>0.126930</td>
      <td>0.298466</td>
      <td>0.161385</td>
      <td>0.163742</td>
      <td>0.397773</td>
      <td>-1.182933</td>
      <td>0.240048</td>
      <td>0.132357</td>
      <td>-0.084947</td>
      <td>0.445322</td>
      <td>0.458198</td>
      <td>-0.749112</td>
      <td>-0.807692</td>
      <td>-0.362263</td>
      <td>1.427920</td>
      <td>0.545064</td>
      <td>0.563453</td>
      <td>0.114213</td>
      <td>-0.148486</td>
      <td>-0.349062</td>
      <td>0.781328</td>
      <td>0.650129</td>
      <td>-1.891060</td>
      <td>-0.910774</td>
      <td>-0.335828</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.812885</td>
      <td>0.695671</td>
      <td>0.108402</td>
      <td>-0.373272</td>
      <td>-0.674675</td>
      <td>0.634013</td>
      <td>0.202710</td>
      <td>-0.199166</td>
      <td>-0.464639</td>
      <td>-0.676279</td>
      <td>-0.089964</td>
      <td>0.834365</td>
      <td>-0.984591</td>
      <td>-0.462712</td>
      <td>-0.259886</td>
      <td>-0.518116</td>
      <td>-0.637113</td>
      <td>-0.385127</td>
      <td>0.122999</td>
      <td>-0.231059</td>
      <td>-0.437062</td>
      <td>-0.005533</td>
      <td>0.614129</td>
      <td>0.461405</td>
      <td>-0.543726</td>
      <td>-0.829253</td>
      <td>-0.049731</td>
      <td>0.636516</td>
      <td>0.089581</td>
      <td>0.173968</td>
      <td>0.438046</td>
      <td>-0.509847</td>
      <td>-0.303946</td>
      <td>0.540739</td>
      <td>0.577984</td>
      <td>0.787844</td>
      <td>-0.175022</td>
      <td>0.389225</td>
      <td>0.880837</td>
      <td>-0.736828</td>
      <td>...</td>
      <td>0.455357</td>
      <td>0.360117</td>
      <td>-0.202174</td>
      <td>0.343351</td>
      <td>1.239542</td>
      <td>0.943330</td>
      <td>0.419751</td>
      <td>0.764627</td>
      <td>0.914199</td>
      <td>-0.579763</td>
      <td>-0.884781</td>
      <td>0.573558</td>
      <td>1.012258</td>
      <td>1.449948</td>
      <td>0.227502</td>
      <td>-0.053000</td>
      <td>0.329065</td>
      <td>-0.680496</td>
      <td>-0.394735</td>
      <td>0.210858</td>
      <td>-0.815824</td>
      <td>-0.438587</td>
      <td>0.690444</td>
      <td>0.321362</td>
      <td>1.222586</td>
      <td>0.781751</td>
      <td>0.115373</td>
      <td>-0.543853</td>
      <td>0.814020</td>
      <td>0.531036</td>
      <td>-0.036874</td>
      <td>0.675732</td>
      <td>0.211720</td>
      <td>0.562398</td>
      <td>0.228505</td>
      <td>-0.473121</td>
      <td>-0.361779</td>
      <td>0.676732</td>
      <td>0.603435</td>
      <td>0.010325</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-0.070259</td>
      <td>-0.016568</td>
      <td>-0.132350</td>
      <td>1.558419</td>
      <td>-0.074957</td>
      <td>-0.449222</td>
      <td>0.146801</td>
      <td>-0.231462</td>
      <td>0.118161</td>
      <td>-0.165592</td>
      <td>0.036071</td>
      <td>-1.073714</td>
      <td>0.399117</td>
      <td>0.464133</td>
      <td>-0.026732</td>
      <td>-0.295595</td>
      <td>-0.549359</td>
      <td>-0.485114</td>
      <td>-0.532070</td>
      <td>0.578573</td>
      <td>0.196151</td>
      <td>0.129846</td>
      <td>0.602074</td>
      <td>0.423167</td>
      <td>-0.359394</td>
      <td>-0.969823</td>
      <td>0.668870</td>
      <td>-0.151999</td>
      <td>0.252979</td>
      <td>0.452231</td>
      <td>0.544147</td>
      <td>0.179897</td>
      <td>-0.103990</td>
      <td>-0.273318</td>
      <td>0.064035</td>
      <td>-0.062986</td>
      <td>0.717693</td>
      <td>0.719561</td>
      <td>0.891804</td>
      <td>-0.731807</td>
      <td>...</td>
      <td>-0.032741</td>
      <td>0.794351</td>
      <td>-0.347616</td>
      <td>-0.163681</td>
      <td>1.001435</td>
      <td>0.441111</td>
      <td>0.778355</td>
      <td>-0.543083</td>
      <td>-0.523035</td>
      <td>-0.619161</td>
      <td>-0.680164</td>
      <td>-0.395481</td>
      <td>1.652516</td>
      <td>-0.073464</td>
      <td>-0.186392</td>
      <td>0.166163</td>
      <td>-0.561156</td>
      <td>-0.442865</td>
      <td>0.082799</td>
      <td>-0.251684</td>
      <td>-0.318317</td>
      <td>-0.489038</td>
      <td>0.345823</td>
      <td>0.143931</td>
      <td>-0.319914</td>
      <td>-0.770211</td>
      <td>-0.163304</td>
      <td>0.732456</td>
      <td>-0.022425</td>
      <td>0.258734</td>
      <td>-0.645737</td>
      <td>1.033005</td>
      <td>0.481394</td>
      <td>0.448079</td>
      <td>0.691403</td>
      <td>-0.417686</td>
      <td>0.012825</td>
      <td>0.893063</td>
      <td>0.925107</td>
      <td>1.159035</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.263128</td>
      <td>0.362820</td>
      <td>-0.351892</td>
      <td>-0.257363</td>
      <td>0.216131</td>
      <td>-0.779644</td>
      <td>-0.627723</td>
      <td>-1.160031</td>
      <td>0.256233</td>
      <td>0.007775</td>
      <td>-0.143058</td>
      <td>0.246150</td>
      <td>0.191820</td>
      <td>-0.154376</td>
      <td>-0.710958</td>
      <td>-0.161627</td>
      <td>0.704267</td>
      <td>-0.231338</td>
      <td>-0.855418</td>
      <td>0.658259</td>
      <td>-0.496756</td>
      <td>-0.224267</td>
      <td>0.042501</td>
      <td>-0.422662</td>
      <td>-0.596645</td>
      <td>0.531076</td>
      <td>-0.443552</td>
      <td>-0.111979</td>
      <td>0.146326</td>
      <td>0.943127</td>
      <td>0.726069</td>
      <td>-0.189882</td>
      <td>-0.481862</td>
      <td>-0.178029</td>
      <td>-0.031106</td>
      <td>0.659407</td>
      <td>0.980443</td>
      <td>0.922432</td>
      <td>0.201039</td>
      <td>-1.408692</td>
      <td>...</td>
      <td>0.416619</td>
      <td>-0.206679</td>
      <td>-0.189134</td>
      <td>0.924743</td>
      <td>-0.606927</td>
      <td>0.249150</td>
      <td>0.405312</td>
      <td>-0.433098</td>
      <td>-0.195670</td>
      <td>-0.581286</td>
      <td>-0.013294</td>
      <td>-0.972158</td>
      <td>0.673489</td>
      <td>0.357807</td>
      <td>-0.753485</td>
      <td>0.352536</td>
      <td>0.128868</td>
      <td>1.075701</td>
      <td>-0.055967</td>
      <td>-1.551690</td>
      <td>-1.000478</td>
      <td>-1.045443</td>
      <td>-0.102659</td>
      <td>-0.393676</td>
      <td>-0.017625</td>
      <td>0.456628</td>
      <td>-0.541979</td>
      <td>-0.739761</td>
      <td>0.046616</td>
      <td>0.395105</td>
      <td>-0.308824</td>
      <td>0.630984</td>
      <td>-0.446850</td>
      <td>-0.122209</td>
      <td>0.277736</td>
      <td>0.289941</td>
      <td>0.382210</td>
      <td>0.624242</td>
      <td>0.053281</td>
      <td>0.463782</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.086926</td>
      <td>0.418248</td>
      <td>-0.021430</td>
      <td>0.008267</td>
      <td>0.312046</td>
      <td>-0.128530</td>
      <td>0.185521</td>
      <td>1.123917</td>
      <td>0.090090</td>
      <td>-0.998466</td>
      <td>-0.646652</td>
      <td>-0.347595</td>
      <td>-0.226960</td>
      <td>0.189470</td>
      <td>-0.269251</td>
      <td>-0.490545</td>
      <td>0.343499</td>
      <td>0.420222</td>
      <td>0.201833</td>
      <td>-0.097048</td>
      <td>-0.246139</td>
      <td>0.486803</td>
      <td>0.423067</td>
      <td>0.783249</td>
      <td>0.481555</td>
      <td>1.523655</td>
      <td>0.329740</td>
      <td>0.087515</td>
      <td>0.451878</td>
      <td>0.596168</td>
      <td>0.309495</td>
      <td>-0.222231</td>
      <td>-0.268793</td>
      <td>-0.030655</td>
      <td>-0.900536</td>
      <td>-0.100921</td>
      <td>-0.144107</td>
      <td>0.195996</td>
      <td>0.538921</td>
      <td>-1.065297</td>
      <td>...</td>
      <td>-0.100343</td>
      <td>-0.455454</td>
      <td>0.794824</td>
      <td>0.970441</td>
      <td>1.619935</td>
      <td>0.369876</td>
      <td>0.428254</td>
      <td>-1.135565</td>
      <td>0.310325</td>
      <td>-0.682190</td>
      <td>-0.614511</td>
      <td>-0.705394</td>
      <td>-0.440793</td>
      <td>0.585268</td>
      <td>0.954927</td>
      <td>0.169184</td>
      <td>-0.354020</td>
      <td>0.657464</td>
      <td>-0.186125</td>
      <td>-1.195678</td>
      <td>-0.693692</td>
      <td>0.399531</td>
      <td>0.209350</td>
      <td>0.318841</td>
      <td>0.958086</td>
      <td>1.398119</td>
      <td>0.705749</td>
      <td>-1.600797</td>
      <td>0.270472</td>
      <td>-0.585848</td>
      <td>0.956300</td>
      <td>-0.024820</td>
      <td>0.203456</td>
      <td>0.458037</td>
      <td>-0.954577</td>
      <td>-0.647627</td>
      <td>-0.114282</td>
      <td>0.532829</td>
      <td>0.595130</td>
      <td>0.167679</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.053855</td>
      <td>-0.734584</td>
      <td>0.993540</td>
      <td>0.027399</td>
      <td>0.236668</td>
      <td>0.887271</td>
      <td>0.064087</td>
      <td>0.060176</td>
      <td>-0.440560</td>
      <td>-0.530388</td>
      <td>-0.141039</td>
      <td>0.494394</td>
      <td>-0.574557</td>
      <td>0.333592</td>
      <td>0.380481</td>
      <td>-1.085753</td>
      <td>-0.325785</td>
      <td>-1.323103</td>
      <td>0.667501</td>
      <td>0.410207</td>
      <td>-1.386865</td>
      <td>0.212505</td>
      <td>0.580773</td>
      <td>0.426534</td>
      <td>-0.254251</td>
      <td>1.004471</td>
      <td>-0.139769</td>
      <td>0.027065</td>
      <td>1.481495</td>
      <td>1.156073</td>
      <td>-0.204082</td>
      <td>-0.179393</td>
      <td>0.063400</td>
      <td>0.276085</td>
      <td>-0.344544</td>
      <td>-0.403132</td>
      <td>-0.013072</td>
      <td>-0.024053</td>
      <td>0.514531</td>
      <td>-0.123846</td>
      <td>...</td>
      <td>0.065929</td>
      <td>-0.422695</td>
      <td>-0.535892</td>
      <td>0.404618</td>
      <td>0.393225</td>
      <td>-0.450921</td>
      <td>0.309690</td>
      <td>-0.613229</td>
      <td>-0.311546</td>
      <td>-0.319438</td>
      <td>-0.436818</td>
      <td>-0.232451</td>
      <td>-0.534371</td>
      <td>1.185019</td>
      <td>0.812306</td>
      <td>0.288785</td>
      <td>0.310112</td>
      <td>-0.669031</td>
      <td>0.101184</td>
      <td>-0.279258</td>
      <td>-1.069169</td>
      <td>-0.662556</td>
      <td>-0.113821</td>
      <td>-0.244860</td>
      <td>-0.503314</td>
      <td>0.576706</td>
      <td>-0.297108</td>
      <td>-1.236273</td>
      <td>0.052247</td>
      <td>0.467128</td>
      <td>0.276933</td>
      <td>0.387062</td>
      <td>1.136974</td>
      <td>0.441901</td>
      <td>0.277096</td>
      <td>0.891742</td>
      <td>0.476135</td>
      <td>1.853118</td>
      <td>1.440585</td>
      <td>1.113392</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.358966</td>
      <td>0.064902</td>
      <td>-1.296207</td>
      <td>-0.711976</td>
      <td>-0.359449</td>
      <td>-0.518656</td>
      <td>-0.825590</td>
      <td>-1.121469</td>
      <td>-1.055650</td>
      <td>0.076213</td>
      <td>-0.212369</td>
      <td>0.782314</td>
      <td>0.318253</td>
      <td>0.556670</td>
      <td>-0.245688</td>
      <td>-0.083176</td>
      <td>0.392122</td>
      <td>-0.581994</td>
      <td>0.478743</td>
      <td>0.632870</td>
      <td>0.211235</td>
      <td>0.163131</td>
      <td>-0.514355</td>
      <td>-0.959608</td>
      <td>0.524751</td>
      <td>0.420620</td>
      <td>0.088541</td>
      <td>-0.349009</td>
      <td>-0.261167</td>
      <td>0.215110</td>
      <td>-0.259019</td>
      <td>-1.350636</td>
      <td>0.369400</td>
      <td>0.580875</td>
      <td>-0.574211</td>
      <td>0.711139</td>
      <td>0.950449</td>
      <td>0.252417</td>
      <td>0.882806</td>
      <td>-0.942181</td>
      <td>...</td>
      <td>-0.420467</td>
      <td>0.349014</td>
      <td>-1.090533</td>
      <td>1.214844</td>
      <td>0.408218</td>
      <td>0.290980</td>
      <td>-0.359006</td>
      <td>-0.511147</td>
      <td>-0.295070</td>
      <td>0.169321</td>
      <td>-0.280950</td>
      <td>0.239848</td>
      <td>-0.038888</td>
      <td>0.840762</td>
      <td>0.394641</td>
      <td>-0.443718</td>
      <td>-0.636514</td>
      <td>0.288016</td>
      <td>0.186087</td>
      <td>0.790324</td>
      <td>-0.598415</td>
      <td>0.601861</td>
      <td>0.284712</td>
      <td>0.487589</td>
      <td>0.212742</td>
      <td>0.372435</td>
      <td>0.722845</td>
      <td>-0.165936</td>
      <td>0.590985</td>
      <td>1.300362</td>
      <td>-0.710074</td>
      <td>0.659617</td>
      <td>-0.663426</td>
      <td>1.180876</td>
      <td>0.163225</td>
      <td>0.945033</td>
      <td>-0.123399</td>
      <td>-1.542851</td>
      <td>-0.689621</td>
      <td>0.064435</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.766771</td>
      <td>0.221428</td>
      <td>0.148707</td>
      <td>-0.376439</td>
      <td>0.105453</td>
      <td>0.317468</td>
      <td>0.142553</td>
      <td>-0.362269</td>
      <td>1.074059</td>
      <td>0.141495</td>
      <td>-0.101061</td>
      <td>-0.255775</td>
      <td>-1.006187</td>
      <td>1.052669</td>
      <td>0.795621</td>
      <td>-0.342322</td>
      <td>-0.140449</td>
      <td>-0.572836</td>
      <td>-0.378026</td>
      <td>0.339118</td>
      <td>-0.214477</td>
      <td>0.711334</td>
      <td>0.999431</td>
      <td>0.179794</td>
      <td>0.152436</td>
      <td>-0.320267</td>
      <td>0.282950</td>
      <td>-0.292395</td>
      <td>-0.906075</td>
      <td>-0.433911</td>
      <td>-0.789982</td>
      <td>-0.610340</td>
      <td>-1.105245</td>
      <td>-0.229533</td>
      <td>0.547796</td>
      <td>0.253529</td>
      <td>0.017719</td>
      <td>-0.239472</td>
      <td>0.241856</td>
      <td>-0.536013</td>
      <td>...</td>
      <td>0.185041</td>
      <td>0.673659</td>
      <td>1.106449</td>
      <td>0.923898</td>
      <td>0.066835</td>
      <td>0.076623</td>
      <td>0.601491</td>
      <td>-0.737530</td>
      <td>0.205512</td>
      <td>0.356201</td>
      <td>0.485903</td>
      <td>-0.758125</td>
      <td>-0.712894</td>
      <td>0.252701</td>
      <td>0.598031</td>
      <td>1.326248</td>
      <td>0.015944</td>
      <td>0.591508</td>
      <td>-0.119547</td>
      <td>-0.231952</td>
      <td>-0.841313</td>
      <td>-0.162335</td>
      <td>-0.458518</td>
      <td>-0.013358</td>
      <td>0.339311</td>
      <td>0.950290</td>
      <td>-0.822761</td>
      <td>-0.919545</td>
      <td>0.308636</td>
      <td>0.656469</td>
      <td>0.126717</td>
      <td>-0.003535</td>
      <td>-0.683474</td>
      <td>-0.085657</td>
      <td>-0.088346</td>
      <td>-0.422693</td>
      <td>-0.439554</td>
      <td>2.481368</td>
      <td>2.447759</td>
      <td>0.676381</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.036405</td>
      <td>0.157307</td>
      <td>-0.372591</td>
      <td>0.230394</td>
      <td>0.054829</td>
      <td>-0.305146</td>
      <td>-0.014494</td>
      <td>0.595193</td>
      <td>0.710075</td>
      <td>-0.126986</td>
      <td>0.075227</td>
      <td>-1.076771</td>
      <td>0.147903</td>
      <td>-0.276422</td>
      <td>-0.435712</td>
      <td>0.825369</td>
      <td>-0.166919</td>
      <td>-0.540546</td>
      <td>0.865637</td>
      <td>0.464317</td>
      <td>-0.774533</td>
      <td>0.161081</td>
      <td>-0.181775</td>
      <td>-0.153858</td>
      <td>-0.517308</td>
      <td>0.260625</td>
      <td>0.894530</td>
      <td>0.793328</td>
      <td>0.863429</td>
      <td>0.456443</td>
      <td>0.291735</td>
      <td>0.653091</td>
      <td>0.810084</td>
      <td>1.168463</td>
      <td>-0.666930</td>
      <td>0.426192</td>
      <td>-1.075569</td>
      <td>0.467465</td>
      <td>-0.246657</td>
      <td>-0.321558</td>
      <td>...</td>
      <td>1.476758</td>
      <td>0.353652</td>
      <td>-0.680017</td>
      <td>0.701220</td>
      <td>0.988892</td>
      <td>0.976574</td>
      <td>-0.039359</td>
      <td>0.642700</td>
      <td>0.163604</td>
      <td>-0.391365</td>
      <td>0.079074</td>
      <td>0.524268</td>
      <td>0.382362</td>
      <td>-0.200574</td>
      <td>-0.556640</td>
      <td>-0.165482</td>
      <td>-0.110547</td>
      <td>-1.619668</td>
      <td>-0.519347</td>
      <td>-0.851648</td>
      <td>-1.005766</td>
      <td>0.282872</td>
      <td>0.389913</td>
      <td>-0.423483</td>
      <td>-0.020095</td>
      <td>0.164627</td>
      <td>0.213404</td>
      <td>-0.392723</td>
      <td>0.392440</td>
      <td>-0.245290</td>
      <td>-0.551491</td>
      <td>0.107241</td>
      <td>0.191736</td>
      <td>0.136217</td>
      <td>1.113012</td>
      <td>-0.076191</td>
      <td>-1.074438</td>
      <td>2.286590</td>
      <td>1.412362</td>
      <td>0.484698</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.513176</td>
      <td>-0.371433</td>
      <td>-1.021419</td>
      <td>1.641393</td>
      <td>1.449351</td>
      <td>0.716261</td>
      <td>1.021677</td>
      <td>-0.114883</td>
      <td>-0.315947</td>
      <td>-0.463278</td>
      <td>0.404875</td>
      <td>-0.611238</td>
      <td>-0.694833</td>
      <td>0.218450</td>
      <td>-0.936818</td>
      <td>0.823295</td>
      <td>0.243782</td>
      <td>-0.121538</td>
      <td>0.731044</td>
      <td>0.308302</td>
      <td>-0.040603</td>
      <td>0.337514</td>
      <td>0.322762</td>
      <td>0.051487</td>
      <td>0.253444</td>
      <td>0.292265</td>
      <td>1.127940</td>
      <td>-1.384623</td>
      <td>-1.165998</td>
      <td>0.452132</td>
      <td>-0.053271</td>
      <td>-0.038418</td>
      <td>0.112135</td>
      <td>0.652604</td>
      <td>0.532772</td>
      <td>0.169635</td>
      <td>-0.327477</td>
      <td>0.164863</td>
      <td>0.469006</td>
      <td>0.159286</td>
      <td>...</td>
      <td>0.471305</td>
      <td>-0.655843</td>
      <td>0.360008</td>
      <td>0.354268</td>
      <td>1.035983</td>
      <td>0.897746</td>
      <td>-0.124172</td>
      <td>0.186961</td>
      <td>-1.339484</td>
      <td>-0.424507</td>
      <td>-0.584698</td>
      <td>-0.578926</td>
      <td>-0.020200</td>
      <td>0.233287</td>
      <td>0.078187</td>
      <td>1.101758</td>
      <td>-0.262822</td>
      <td>-0.087983</td>
      <td>0.123058</td>
      <td>0.120358</td>
      <td>-1.267289</td>
      <td>-0.022541</td>
      <td>0.153275</td>
      <td>-0.128314</td>
      <td>-0.133445</td>
      <td>1.047093</td>
      <td>0.615911</td>
      <td>-0.087002</td>
      <td>0.378086</td>
      <td>0.080291</td>
      <td>0.770336</td>
      <td>0.874300</td>
      <td>1.455416</td>
      <td>1.530419</td>
      <td>0.705065</td>
      <td>0.534722</td>
      <td>0.080984</td>
      <td>-1.487182</td>
      <td>-0.727929</td>
      <td>0.398500</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.979410</td>
      <td>0.430053</td>
      <td>0.038871</td>
      <td>-1.382609</td>
      <td>-0.690069</td>
      <td>-0.125752</td>
      <td>-0.201605</td>
      <td>-0.194981</td>
      <td>1.223809</td>
      <td>0.492922</td>
      <td>-0.603775</td>
      <td>-0.736989</td>
      <td>-0.593319</td>
      <td>0.285289</td>
      <td>-1.041890</td>
      <td>-0.696647</td>
      <td>0.783446</td>
      <td>-0.323873</td>
      <td>1.262727</td>
      <td>0.401891</td>
      <td>-1.412014</td>
      <td>0.190396</td>
      <td>0.410947</td>
      <td>0.535054</td>
      <td>-0.065235</td>
      <td>0.991609</td>
      <td>1.062646</td>
      <td>0.319443</td>
      <td>0.491859</td>
      <td>0.989863</td>
      <td>0.385257</td>
      <td>0.456284</td>
      <td>0.023776</td>
      <td>0.494202</td>
      <td>0.183895</td>
      <td>0.828989</td>
      <td>0.105759</td>
      <td>-0.335725</td>
      <td>1.060818</td>
      <td>-0.854540</td>
      <td>...</td>
      <td>-0.392422</td>
      <td>0.274451</td>
      <td>-1.177476</td>
      <td>0.386095</td>
      <td>0.919802</td>
      <td>0.239716</td>
      <td>0.049607</td>
      <td>-0.130320</td>
      <td>0.190784</td>
      <td>-0.539755</td>
      <td>-0.553600</td>
      <td>-0.137784</td>
      <td>0.545899</td>
      <td>0.561676</td>
      <td>-0.349614</td>
      <td>0.108760</td>
      <td>0.605297</td>
      <td>0.427144</td>
      <td>0.602596</td>
      <td>-0.182629</td>
      <td>-0.506470</td>
      <td>-1.318181</td>
      <td>-1.120665</td>
      <td>-0.491370</td>
      <td>-0.276169</td>
      <td>-0.683779</td>
      <td>-1.572571</td>
      <td>-0.975849</td>
      <td>0.103663</td>
      <td>0.452072</td>
      <td>-0.390782</td>
      <td>0.761273</td>
      <td>0.083577</td>
      <td>0.148258</td>
      <td>-0.299768</td>
      <td>1.016393</td>
      <td>0.759826</td>
      <td>-0.358798</td>
      <td>-1.067054</td>
      <td>-0.436788</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.247920</td>
      <td>0.974746</td>
      <td>1.013709</td>
      <td>0.617597</td>
      <td>-0.175951</td>
      <td>-0.095886</td>
      <td>-0.567117</td>
      <td>0.183765</td>
      <td>0.401348</td>
      <td>0.673580</td>
      <td>0.193529</td>
      <td>-0.280694</td>
      <td>-0.063715</td>
      <td>0.532147</td>
      <td>0.441222</td>
      <td>-0.666452</td>
      <td>0.510285</td>
      <td>-0.345721</td>
      <td>-0.267429</td>
      <td>0.431077</td>
      <td>0.089339</td>
      <td>0.640875</td>
      <td>0.504776</td>
      <td>-0.372548</td>
      <td>0.109956</td>
      <td>-0.377816</td>
      <td>0.838762</td>
      <td>-0.142766</td>
      <td>0.225483</td>
      <td>0.349444</td>
      <td>-0.092792</td>
      <td>-0.143377</td>
      <td>0.117603</td>
      <td>0.514596</td>
      <td>0.557984</td>
      <td>0.928832</td>
      <td>0.232686</td>
      <td>0.424377</td>
      <td>0.277390</td>
      <td>-0.433331</td>
      <td>...</td>
      <td>1.118396</td>
      <td>0.760200</td>
      <td>0.326100</td>
      <td>0.842825</td>
      <td>0.170524</td>
      <td>0.784905</td>
      <td>0.509427</td>
      <td>-0.850895</td>
      <td>0.718344</td>
      <td>0.422237</td>
      <td>-0.752847</td>
      <td>0.276650</td>
      <td>0.611413</td>
      <td>0.849398</td>
      <td>0.095115</td>
      <td>0.497524</td>
      <td>0.357904</td>
      <td>0.990371</td>
      <td>0.466531</td>
      <td>0.517397</td>
      <td>-1.018251</td>
      <td>-0.608745</td>
      <td>0.503244</td>
      <td>-0.791475</td>
      <td>0.861591</td>
      <td>2.104211</td>
      <td>0.147056</td>
      <td>-0.433283</td>
      <td>-0.449532</td>
      <td>1.195896</td>
      <td>-0.097419</td>
      <td>0.713301</td>
      <td>0.484500</td>
      <td>-0.335298</td>
      <td>-0.023917</td>
      <td>-0.348712</td>
      <td>0.944300</td>
      <td>0.692234</td>
      <td>0.740302</td>
      <td>0.638728</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.915099</td>
      <td>0.280228</td>
      <td>-1.141239</td>
      <td>-0.096659</td>
      <td>-1.213975</td>
      <td>-0.241916</td>
      <td>0.110751</td>
      <td>-0.226571</td>
      <td>0.166081</td>
      <td>1.841378</td>
      <td>0.480049</td>
      <td>-0.294274</td>
      <td>0.533957</td>
      <td>-0.336700</td>
      <td>0.269430</td>
      <td>-0.818571</td>
      <td>-0.176525</td>
      <td>0.438910</td>
      <td>0.590375</td>
      <td>0.789637</td>
      <td>-0.145402</td>
      <td>0.132223</td>
      <td>0.447343</td>
      <td>-0.281962</td>
      <td>0.423140</td>
      <td>0.130395</td>
      <td>-0.008976</td>
      <td>-0.311822</td>
      <td>-0.109384</td>
      <td>0.506423</td>
      <td>-0.263330</td>
      <td>0.650121</td>
      <td>0.862907</td>
      <td>0.633665</td>
      <td>-0.682354</td>
      <td>-0.768216</td>
      <td>-0.255817</td>
      <td>-0.305089</td>
      <td>0.919167</td>
      <td>-1.095194</td>
      <td>...</td>
      <td>0.619913</td>
      <td>1.026930</td>
      <td>-0.547083</td>
      <td>-0.355407</td>
      <td>0.032797</td>
      <td>-0.348399</td>
      <td>-0.068657</td>
      <td>0.388884</td>
      <td>1.285947</td>
      <td>0.086530</td>
      <td>-0.599819</td>
      <td>0.456303</td>
      <td>0.772098</td>
      <td>-0.059881</td>
      <td>0.271656</td>
      <td>-0.431652</td>
      <td>-0.750609</td>
      <td>-1.006481</td>
      <td>0.916956</td>
      <td>0.408265</td>
      <td>-0.323154</td>
      <td>0.369816</td>
      <td>0.191349</td>
      <td>0.175510</td>
      <td>0.520239</td>
      <td>1.363487</td>
      <td>-0.217024</td>
      <td>-1.220549</td>
      <td>0.356905</td>
      <td>0.944324</td>
      <td>-0.394132</td>
      <td>0.827642</td>
      <td>0.700464</td>
      <td>0.397812</td>
      <td>-0.014421</td>
      <td>0.115999</td>
      <td>-0.759650</td>
      <td>1.817955</td>
      <td>1.504435</td>
      <td>0.899163</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.004353</td>
      <td>1.380469</td>
      <td>0.801390</td>
      <td>0.636311</td>
      <td>0.044789</td>
      <td>-0.479341</td>
      <td>-0.549177</td>
      <td>-0.817839</td>
      <td>-0.216230</td>
      <td>-0.880135</td>
      <td>-0.483544</td>
      <td>-0.132904</td>
      <td>-0.480923</td>
      <td>0.881853</td>
      <td>0.769621</td>
      <td>-0.367962</td>
      <td>-0.105113</td>
      <td>-0.261212</td>
      <td>-0.777618</td>
      <td>-0.445283</td>
      <td>-1.054221</td>
      <td>-0.408617</td>
      <td>0.087007</td>
      <td>-0.494532</td>
      <td>-0.961556</td>
      <td>-0.456565</td>
      <td>0.013602</td>
      <td>-1.306859</td>
      <td>-0.126958</td>
      <td>-0.058750</td>
      <td>0.276173</td>
      <td>-0.145185</td>
      <td>-0.198287</td>
      <td>-0.008151</td>
      <td>-0.265696</td>
      <td>-0.205832</td>
      <td>-0.245018</td>
      <td>-0.447728</td>
      <td>0.538654</td>
      <td>-0.586464</td>
      <td>...</td>
      <td>1.626018</td>
      <td>0.347646</td>
      <td>0.288355</td>
      <td>2.064520</td>
      <td>0.215355</td>
      <td>0.220844</td>
      <td>-0.579147</td>
      <td>-0.333695</td>
      <td>1.195316</td>
      <td>-0.156211</td>
      <td>0.116422</td>
      <td>-0.468982</td>
      <td>-0.119075</td>
      <td>0.502506</td>
      <td>0.043649</td>
      <td>0.143018</td>
      <td>0.504933</td>
      <td>0.282122</td>
      <td>0.512649</td>
      <td>-0.726947</td>
      <td>-0.735756</td>
      <td>1.050939</td>
      <td>-0.689596</td>
      <td>-0.296137</td>
      <td>-0.452241</td>
      <td>0.079413</td>
      <td>0.261297</td>
      <td>0.137528</td>
      <td>1.268256</td>
      <td>0.348116</td>
      <td>-0.505394</td>
      <td>-0.378182</td>
      <td>-0.391329</td>
      <td>0.257356</td>
      <td>-0.024637</td>
      <td>-0.195740</td>
      <td>-0.450899</td>
      <td>0.177024</td>
      <td>-0.050502</td>
      <td>0.101315</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.663036</td>
      <td>0.149523</td>
      <td>0.548924</td>
      <td>0.098683</td>
      <td>-1.428323</td>
      <td>-0.481426</td>
      <td>0.030861</td>
      <td>-0.465237</td>
      <td>0.480675</td>
      <td>0.704376</td>
      <td>0.447774</td>
      <td>0.318651</td>
      <td>-0.864680</td>
      <td>0.740499</td>
      <td>-0.315139</td>
      <td>0.323042</td>
      <td>0.951385</td>
      <td>-0.579885</td>
      <td>-1.037405</td>
      <td>0.056594</td>
      <td>-0.775874</td>
      <td>0.279482</td>
      <td>-0.016100</td>
      <td>0.139756</td>
      <td>-0.171381</td>
      <td>-0.222036</td>
      <td>-0.103893</td>
      <td>0.936431</td>
      <td>1.416551</td>
      <td>0.707103</td>
      <td>0.884860</td>
      <td>0.335918</td>
      <td>0.252671</td>
      <td>0.578625</td>
      <td>0.343526</td>
      <td>0.534302</td>
      <td>0.140550</td>
      <td>-0.495490</td>
      <td>-0.473485</td>
      <td>-1.723576</td>
      <td>...</td>
      <td>0.620233</td>
      <td>0.682211</td>
      <td>-0.291863</td>
      <td>0.496740</td>
      <td>1.127407</td>
      <td>-0.645703</td>
      <td>-0.110966</td>
      <td>0.265907</td>
      <td>0.358106</td>
      <td>0.497319</td>
      <td>0.125190</td>
      <td>0.106215</td>
      <td>-0.994542</td>
      <td>0.042787</td>
      <td>0.104030</td>
      <td>0.028310</td>
      <td>0.115062</td>
      <td>-0.531886</td>
      <td>-0.211295</td>
      <td>-0.453761</td>
      <td>0.032157</td>
      <td>-0.201513</td>
      <td>0.117091</td>
      <td>0.809679</td>
      <td>0.220254</td>
      <td>0.459489</td>
      <td>-0.474587</td>
      <td>0.207980</td>
      <td>0.651675</td>
      <td>1.577424</td>
      <td>0.899658</td>
      <td>0.896582</td>
      <td>1.058085</td>
      <td>0.284415</td>
      <td>0.313197</td>
      <td>-0.521642</td>
      <td>-0.517517</td>
      <td>-1.209510</td>
      <td>-0.520845</td>
      <td>0.349864</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.168065</td>
      <td>-0.284265</td>
      <td>-1.094372</td>
      <td>-0.674674</td>
      <td>-0.469600</td>
      <td>0.411743</td>
      <td>0.813521</td>
      <td>0.631462</td>
      <td>0.800446</td>
      <td>-0.069474</td>
      <td>-0.143289</td>
      <td>-0.417779</td>
      <td>-0.305569</td>
      <td>0.252540</td>
      <td>-0.351460</td>
      <td>-0.021195</td>
      <td>0.310104</td>
      <td>-0.458519</td>
      <td>-0.097350</td>
      <td>0.390152</td>
      <td>-0.200416</td>
      <td>0.871576</td>
      <td>-0.353329</td>
      <td>-0.718580</td>
      <td>-0.011199</td>
      <td>-0.386611</td>
      <td>-0.323118</td>
      <td>-0.914459</td>
      <td>0.326226</td>
      <td>1.075659</td>
      <td>1.249191</td>
      <td>0.731437</td>
      <td>0.363625</td>
      <td>0.070469</td>
      <td>0.098117</td>
      <td>-0.348179</td>
      <td>-0.046589</td>
      <td>-0.282550</td>
      <td>0.098809</td>
      <td>-1.289825</td>
      <td>...</td>
      <td>0.828097</td>
      <td>1.086487</td>
      <td>0.137794</td>
      <td>0.319038</td>
      <td>0.424271</td>
      <td>-0.234000</td>
      <td>0.802544</td>
      <td>-0.438196</td>
      <td>0.019673</td>
      <td>0.629849</td>
      <td>0.397400</td>
      <td>-0.755599</td>
      <td>-0.288245</td>
      <td>-0.606073</td>
      <td>-1.184276</td>
      <td>0.083762</td>
      <td>-0.862370</td>
      <td>-0.196149</td>
      <td>0.639117</td>
      <td>0.184085</td>
      <td>-0.680410</td>
      <td>0.231269</td>
      <td>1.094941</td>
      <td>0.031858</td>
      <td>0.063563</td>
      <td>0.419663</td>
      <td>0.328552</td>
      <td>-0.683573</td>
      <td>0.150019</td>
      <td>0.100607</td>
      <td>0.786081</td>
      <td>0.112606</td>
      <td>0.649372</td>
      <td>1.166272</td>
      <td>0.032499</td>
      <td>-0.039698</td>
      <td>0.430708</td>
      <td>-1.534077</td>
      <td>-0.628337</td>
      <td>-0.276902</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.638021</td>
      <td>-0.811013</td>
      <td>-0.760161</td>
      <td>0.481734</td>
      <td>-0.264668</td>
      <td>-0.873588</td>
      <td>0.268272</td>
      <td>0.489690</td>
      <td>1.086386</td>
      <td>0.005500</td>
      <td>-0.409878</td>
      <td>0.266950</td>
      <td>-1.036806</td>
      <td>-0.042026</td>
      <td>-0.496410</td>
      <td>-0.284919</td>
      <td>-0.747370</td>
      <td>0.283307</td>
      <td>-0.050256</td>
      <td>0.666782</td>
      <td>0.211284</td>
      <td>-0.353099</td>
      <td>0.655793</td>
      <td>-0.636004</td>
      <td>0.411291</td>
      <td>-0.231689</td>
      <td>0.246710</td>
      <td>-0.026851</td>
      <td>0.238384</td>
      <td>-0.174626</td>
      <td>0.670201</td>
      <td>0.217087</td>
      <td>0.156625</td>
      <td>0.375837</td>
      <td>0.579048</td>
      <td>1.022245</td>
      <td>0.548078</td>
      <td>0.662006</td>
      <td>0.014995</td>
      <td>-0.907366</td>
      <td>...</td>
      <td>-0.016282</td>
      <td>-0.946640</td>
      <td>0.692139</td>
      <td>0.875487</td>
      <td>0.581761</td>
      <td>0.707958</td>
      <td>-0.178774</td>
      <td>0.397497</td>
      <td>0.334630</td>
      <td>-0.501181</td>
      <td>0.204379</td>
      <td>0.096768</td>
      <td>0.611204</td>
      <td>0.538288</td>
      <td>0.232831</td>
      <td>0.283047</td>
      <td>0.289532</td>
      <td>-0.469057</td>
      <td>0.345587</td>
      <td>-0.336594</td>
      <td>-0.393797</td>
      <td>-0.466286</td>
      <td>0.314121</td>
      <td>-0.119038</td>
      <td>0.344672</td>
      <td>-0.169578</td>
      <td>-0.903636</td>
      <td>0.182087</td>
      <td>1.625454</td>
      <td>-0.112664</td>
      <td>0.378572</td>
      <td>0.970783</td>
      <td>0.419737</td>
      <td>0.864078</td>
      <td>0.193649</td>
      <td>-0.392297</td>
      <td>-0.307855</td>
      <td>-2.056964</td>
      <td>-1.695797</td>
      <td>-0.764194</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>0.018538</td>
      <td>-0.357520</td>
      <td>-0.267147</td>
      <td>-0.519456</td>
      <td>0.117089</td>
      <td>0.142872</td>
      <td>0.537832</td>
      <td>-0.307866</td>
      <td>-0.570677</td>
      <td>-0.934386</td>
      <td>0.395397</td>
      <td>-0.010380</td>
      <td>-0.092945</td>
      <td>0.769013</td>
      <td>0.474952</td>
      <td>0.579348</td>
      <td>0.331195</td>
      <td>0.465671</td>
      <td>-0.171491</td>
      <td>0.361506</td>
      <td>0.080183</td>
      <td>-0.101856</td>
      <td>0.802506</td>
      <td>-0.497779</td>
      <td>-0.851396</td>
      <td>-0.590902</td>
      <td>-0.351113</td>
      <td>-0.071299</td>
      <td>0.070443</td>
      <td>-0.038692</td>
      <td>-0.070527</td>
      <td>0.349678</td>
      <td>0.929642</td>
      <td>-0.460888</td>
      <td>-0.590143</td>
      <td>0.355600</td>
      <td>0.076265</td>
      <td>0.571167</td>
      <td>1.018595</td>
      <td>0.274296</td>
      <td>...</td>
      <td>-1.209563</td>
      <td>-0.345371</td>
      <td>0.204453</td>
      <td>0.712085</td>
      <td>0.013923</td>
      <td>-0.498144</td>
      <td>-0.317021</td>
      <td>-0.973943</td>
      <td>-1.155763</td>
      <td>-0.558673</td>
      <td>-0.716406</td>
      <td>-0.473334</td>
      <td>0.292393</td>
      <td>1.183904</td>
      <td>0.058222</td>
      <td>0.310516</td>
      <td>0.020009</td>
      <td>0.901570</td>
      <td>-0.884809</td>
      <td>-0.646217</td>
      <td>-0.496489</td>
      <td>-0.161957</td>
      <td>-0.726199</td>
      <td>-0.971414</td>
      <td>0.094550</td>
      <td>1.076103</td>
      <td>-0.033393</td>
      <td>-0.489990</td>
      <td>-0.084170</td>
      <td>-0.630841</td>
      <td>-1.118372</td>
      <td>-0.220170</td>
      <td>-0.063433</td>
      <td>0.039974</td>
      <td>0.897945</td>
      <td>-0.700312</td>
      <td>-0.381950</td>
      <td>0.131880</td>
      <td>-0.349046</td>
      <td>-0.442069</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.981890</td>
      <td>-0.021225</td>
      <td>-0.206026</td>
      <td>-0.347653</td>
      <td>1.178875</td>
      <td>0.614731</td>
      <td>-0.677089</td>
      <td>-1.202879</td>
      <td>-0.051692</td>
      <td>0.928850</td>
      <td>0.803403</td>
      <td>0.588844</td>
      <td>0.863121</td>
      <td>0.394700</td>
      <td>-0.238347</td>
      <td>-0.550311</td>
      <td>-0.190127</td>
      <td>0.178258</td>
      <td>-0.620443</td>
      <td>0.251221</td>
      <td>-0.522927</td>
      <td>1.071840</td>
      <td>0.834740</td>
      <td>1.140374</td>
      <td>1.199978</td>
      <td>0.940042</td>
      <td>0.489459</td>
      <td>0.062267</td>
      <td>0.526831</td>
      <td>1.413959</td>
      <td>1.174237</td>
      <td>-0.191534</td>
      <td>-0.841764</td>
      <td>-0.628151</td>
      <td>0.306828</td>
      <td>0.198616</td>
      <td>0.457864</td>
      <td>-0.572899</td>
      <td>1.333577</td>
      <td>0.322448</td>
      <td>...</td>
      <td>0.010096</td>
      <td>-1.158467</td>
      <td>-0.893960</td>
      <td>0.346045</td>
      <td>-0.637347</td>
      <td>-0.399218</td>
      <td>0.281638</td>
      <td>-0.436398</td>
      <td>0.003967</td>
      <td>0.304324</td>
      <td>-0.219613</td>
      <td>0.572924</td>
      <td>0.685451</td>
      <td>0.478357</td>
      <td>-0.224418</td>
      <td>-0.273424</td>
      <td>-0.418168</td>
      <td>-0.023471</td>
      <td>-0.052718</td>
      <td>-0.425194</td>
      <td>-0.063211</td>
      <td>0.269590</td>
      <td>-0.870854</td>
      <td>-0.597128</td>
      <td>0.758202</td>
      <td>0.113980</td>
      <td>-1.035113</td>
      <td>-1.003816</td>
      <td>-0.239943</td>
      <td>-0.604390</td>
      <td>-0.188495</td>
      <td>-0.243283</td>
      <td>0.275578</td>
      <td>-0.194218</td>
      <td>-0.247003</td>
      <td>-0.471065</td>
      <td>-1.776080</td>
      <td>0.653546</td>
      <td>0.606283</td>
      <td>0.509308</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.332081</td>
      <td>-1.272290</td>
      <td>-0.570081</td>
      <td>-0.110495</td>
      <td>-0.491478</td>
      <td>0.060222</td>
      <td>-1.464629</td>
      <td>-0.454316</td>
      <td>0.490848</td>
      <td>0.471744</td>
      <td>0.534897</td>
      <td>-0.554880</td>
      <td>1.066912</td>
      <td>0.897645</td>
      <td>0.262031</td>
      <td>-0.290014</td>
      <td>-1.383776</td>
      <td>-0.440013</td>
      <td>-0.147735</td>
      <td>0.015125</td>
      <td>-1.620710</td>
      <td>0.069899</td>
      <td>-0.311285</td>
      <td>-0.671083</td>
      <td>-0.628155</td>
      <td>-0.490733</td>
      <td>-0.495021</td>
      <td>0.479068</td>
      <td>0.626881</td>
      <td>0.322141</td>
      <td>1.114566</td>
      <td>-0.590172</td>
      <td>0.475688</td>
      <td>0.660354</td>
      <td>0.234526</td>
      <td>1.062855</td>
      <td>0.378887</td>
      <td>1.132971</td>
      <td>0.947980</td>
      <td>0.438346</td>
      <td>...</td>
      <td>-0.513539</td>
      <td>0.135813</td>
      <td>0.219846</td>
      <td>0.240664</td>
      <td>0.285474</td>
      <td>0.295544</td>
      <td>-0.330493</td>
      <td>0.318693</td>
      <td>-0.497191</td>
      <td>-0.286177</td>
      <td>0.199130</td>
      <td>0.706259</td>
      <td>-0.638075</td>
      <td>-0.335896</td>
      <td>0.409835</td>
      <td>0.364032</td>
      <td>0.596899</td>
      <td>0.791397</td>
      <td>-0.094402</td>
      <td>0.387141</td>
      <td>-0.144104</td>
      <td>-0.302521</td>
      <td>0.863539</td>
      <td>-0.425010</td>
      <td>0.745026</td>
      <td>-0.248920</td>
      <td>-0.205014</td>
      <td>-0.487685</td>
      <td>0.458489</td>
      <td>0.635680</td>
      <td>-0.023441</td>
      <td>0.563211</td>
      <td>-0.325627</td>
      <td>-1.042226</td>
      <td>-0.077963</td>
      <td>0.246167</td>
      <td>-0.769983</td>
      <td>-0.756912</td>
      <td>-0.258697</td>
      <td>-0.503023</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.576520</td>
      <td>0.611881</td>
      <td>1.236412</td>
      <td>0.779603</td>
      <td>0.659064</td>
      <td>-0.487736</td>
      <td>-0.336610</td>
      <td>-2.347512</td>
      <td>-0.771891</td>
      <td>-0.757254</td>
      <td>-0.496707</td>
      <td>-0.380013</td>
      <td>1.032247</td>
      <td>-0.104080</td>
      <td>-0.045088</td>
      <td>1.136347</td>
      <td>0.042303</td>
      <td>0.110965</td>
      <td>-0.341249</td>
      <td>-0.466829</td>
      <td>0.113856</td>
      <td>-0.145979</td>
      <td>1.180378</td>
      <td>1.000032</td>
      <td>0.997116</td>
      <td>0.442669</td>
      <td>-0.035069</td>
      <td>0.061212</td>
      <td>0.339921</td>
      <td>-0.347989</td>
      <td>-0.506065</td>
      <td>-0.875380</td>
      <td>0.303758</td>
      <td>-0.819100</td>
      <td>-0.576133</td>
      <td>0.180791</td>
      <td>0.620158</td>
      <td>0.697974</td>
      <td>0.488248</td>
      <td>0.133278</td>
      <td>...</td>
      <td>-0.780308</td>
      <td>0.018049</td>
      <td>-0.026758</td>
      <td>1.092074</td>
      <td>0.783450</td>
      <td>-0.195879</td>
      <td>1.030081</td>
      <td>0.408414</td>
      <td>0.141600</td>
      <td>0.457470</td>
      <td>0.469427</td>
      <td>-0.162705</td>
      <td>-0.443584</td>
      <td>1.874250</td>
      <td>1.994874</td>
      <td>-0.070415</td>
      <td>-0.602979</td>
      <td>0.765739</td>
      <td>-0.667123</td>
      <td>0.220836</td>
      <td>1.155776</td>
      <td>-0.774046</td>
      <td>0.484986</td>
      <td>1.811536</td>
      <td>1.177146</td>
      <td>0.567084</td>
      <td>-0.313521</td>
      <td>0.015780</td>
      <td>0.768805</td>
      <td>0.854747</td>
      <td>-0.036395</td>
      <td>-0.112298</td>
      <td>0.075169</td>
      <td>-0.555483</td>
      <td>0.794078</td>
      <td>0.053365</td>
      <td>-1.223076</td>
      <td>0.595594</td>
      <td>0.492545</td>
      <td>-0.252400</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.363673</td>
      <td>0.426245</td>
      <td>0.898067</td>
      <td>0.874637</td>
      <td>1.357293</td>
      <td>0.548315</td>
      <td>-0.815024</td>
      <td>-1.729488</td>
      <td>-0.722035</td>
      <td>-0.781024</td>
      <td>0.449827</td>
      <td>-0.612874</td>
      <td>-0.239864</td>
      <td>0.252742</td>
      <td>0.026938</td>
      <td>0.643118</td>
      <td>-1.534496</td>
      <td>0.616947</td>
      <td>-0.042373</td>
      <td>0.409588</td>
      <td>0.346834</td>
      <td>0.457911</td>
      <td>0.553690</td>
      <td>-0.690422</td>
      <td>0.487242</td>
      <td>-1.219845</td>
      <td>-0.398704</td>
      <td>-1.103526</td>
      <td>0.212918</td>
      <td>-0.253828</td>
      <td>-0.929594</td>
      <td>0.087318</td>
      <td>-0.635602</td>
      <td>-0.213192</td>
      <td>1.176076</td>
      <td>1.921795</td>
      <td>0.836421</td>
      <td>0.333774</td>
      <td>0.751581</td>
      <td>0.369844</td>
      <td>...</td>
      <td>0.146890</td>
      <td>-0.566566</td>
      <td>-0.311949</td>
      <td>-0.035495</td>
      <td>-1.352664</td>
      <td>-0.029500</td>
      <td>0.660782</td>
      <td>0.324467</td>
      <td>-1.366412</td>
      <td>0.313373</td>
      <td>-0.049542</td>
      <td>-0.173375</td>
      <td>-0.217691</td>
      <td>-0.482701</td>
      <td>-1.058185</td>
      <td>-0.600320</td>
      <td>-0.241303</td>
      <td>-0.161277</td>
      <td>-0.738934</td>
      <td>-0.391211</td>
      <td>0.553361</td>
      <td>1.393598</td>
      <td>-0.824450</td>
      <td>-0.551904</td>
      <td>0.366315</td>
      <td>-1.038273</td>
      <td>0.318065</td>
      <td>0.240424</td>
      <td>0.263668</td>
      <td>-0.238541</td>
      <td>-0.855973</td>
      <td>-0.671650</td>
      <td>-1.419877</td>
      <td>-0.948021</td>
      <td>-0.031106</td>
      <td>1.017076</td>
      <td>-0.574190</td>
      <td>2.358292</td>
      <td>1.385042</td>
      <td>0.419021</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 103 columns</p>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7efe7149feb0&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.070663  0.038714  27.655711  2.382582e-168  0.994785  1.146541
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.941 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>