
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.0.1 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="http://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>     to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-0.243062</td>
      <td>-1.309826</td>
      <td>-0.481354</td>
      <td>-0.268368</td>
      <td>-0.547740</td>
      <td>1.384597</td>
      <td>0.665322</td>
      <td>0.685911</td>
      <td>0.408114</td>
      <td>0.857847</td>
      <td>-0.166136</td>
      <td>-0.095945</td>
      <td>-1.026523</td>
      <td>-0.146476</td>
      <td>-0.043071</td>
      <td>-0.205583</td>
      <td>-1.021835</td>
      <td>0.492844</td>
      <td>0.039559</td>
      <td>1.153492</td>
      <td>0.177616</td>
      <td>0.608249</td>
      <td>0.849767</td>
      <td>-0.063610</td>
      <td>0.171060</td>
      <td>0.348064</td>
      <td>-0.415141</td>
      <td>0.181408</td>
      <td>-0.368378</td>
      <td>0.467571</td>
      <td>-1.315435</td>
      <td>0.608334</td>
      <td>0.702436</td>
      <td>-0.385247</td>
      <td>-0.011475</td>
      <td>-0.990222</td>
      <td>-0.219182</td>
      <td>-0.065823</td>
      <td>-0.085880</td>
      <td>0.083050</td>
      <td>...</td>
      <td>1.000727</td>
      <td>0.134626</td>
      <td>0.625296</td>
      <td>0.795168</td>
      <td>0.584457</td>
      <td>-0.520952</td>
      <td>0.381948</td>
      <td>0.385134</td>
      <td>-1.522799</td>
      <td>0.535564</td>
      <td>1.505660</td>
      <td>0.342869</td>
      <td>1.037911</td>
      <td>0.842228</td>
      <td>1.550019</td>
      <td>0.744744</td>
      <td>0.963821</td>
      <td>0.853574</td>
      <td>0.564964</td>
      <td>-0.066833</td>
      <td>-0.022783</td>
      <td>-0.395612</td>
      <td>0.716131</td>
      <td>0.280257</td>
      <td>0.751273</td>
      <td>0.747935</td>
      <td>0.635085</td>
      <td>-0.370560</td>
      <td>-0.505840</td>
      <td>0.301642</td>
      <td>-0.216080</td>
      <td>-0.096228</td>
      <td>-0.576814</td>
      <td>-0.880397</td>
      <td>0.383725</td>
      <td>0.292849</td>
      <td>0.772744</td>
      <td>-2.290744</td>
      <td>-2.200416</td>
      <td>-1.029502</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.218839</td>
      <td>-0.038375</td>
      <td>0.510115</td>
      <td>0.003501</td>
      <td>-0.100608</td>
      <td>0.166950</td>
      <td>-0.153920</td>
      <td>0.121918</td>
      <td>-0.056823</td>
      <td>-0.295845</td>
      <td>0.291057</td>
      <td>-0.347737</td>
      <td>-0.490265</td>
      <td>-0.105281</td>
      <td>0.437595</td>
      <td>0.601223</td>
      <td>-0.369751</td>
      <td>0.042607</td>
      <td>-0.061324</td>
      <td>-0.908556</td>
      <td>-0.312911</td>
      <td>0.368664</td>
      <td>0.198815</td>
      <td>-0.901199</td>
      <td>-0.019075</td>
      <td>0.276480</td>
      <td>-0.249131</td>
      <td>0.524331</td>
      <td>1.074095</td>
      <td>-0.065437</td>
      <td>-0.782572</td>
      <td>-0.251722</td>
      <td>0.248662</td>
      <td>-0.016214</td>
      <td>0.255687</td>
      <td>-0.035747</td>
      <td>-0.293161</td>
      <td>0.120991</td>
      <td>-0.121289</td>
      <td>-0.393460</td>
      <td>...</td>
      <td>0.034439</td>
      <td>-0.625097</td>
      <td>-0.439695</td>
      <td>-0.378617</td>
      <td>-0.947843</td>
      <td>-0.495876</td>
      <td>0.418348</td>
      <td>0.154002</td>
      <td>-0.464189</td>
      <td>0.448152</td>
      <td>0.320853</td>
      <td>0.713971</td>
      <td>0.714055</td>
      <td>0.870482</td>
      <td>-0.205957</td>
      <td>0.875905</td>
      <td>-0.004290</td>
      <td>0.973471</td>
      <td>0.576420</td>
      <td>-0.287525</td>
      <td>1.221777</td>
      <td>-0.192485</td>
      <td>-0.228233</td>
      <td>0.284555</td>
      <td>0.921841</td>
      <td>1.265998</td>
      <td>0.938806</td>
      <td>-0.367765</td>
      <td>-0.285143</td>
      <td>0.217842</td>
      <td>0.917527</td>
      <td>0.269074</td>
      <td>0.420838</td>
      <td>0.205115</td>
      <td>0.297138</td>
      <td>-0.275406</td>
      <td>-0.652042</td>
      <td>-1.195956</td>
      <td>-0.415678</td>
      <td>-0.509676</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.552603</td>
      <td>-0.721406</td>
      <td>-0.600823</td>
      <td>-0.734354</td>
      <td>-0.189748</td>
      <td>0.038457</td>
      <td>1.020158</td>
      <td>-0.313354</td>
      <td>0.086745</td>
      <td>-0.491437</td>
      <td>0.540860</td>
      <td>-0.951907</td>
      <td>-0.841610</td>
      <td>-0.492645</td>
      <td>-0.375682</td>
      <td>0.084379</td>
      <td>-0.145253</td>
      <td>1.253890</td>
      <td>-0.019689</td>
      <td>-1.151998</td>
      <td>-0.519568</td>
      <td>0.737355</td>
      <td>-0.095124</td>
      <td>-0.536400</td>
      <td>-0.546715</td>
      <td>-0.736618</td>
      <td>-1.061584</td>
      <td>0.142475</td>
      <td>-0.188709</td>
      <td>-0.586340</td>
      <td>0.733950</td>
      <td>0.424156</td>
      <td>0.732778</td>
      <td>-0.413063</td>
      <td>0.292590</td>
      <td>-0.486417</td>
      <td>0.270448</td>
      <td>0.234211</td>
      <td>-0.034919</td>
      <td>-0.215112</td>
      <td>...</td>
      <td>-0.646828</td>
      <td>-0.905319</td>
      <td>0.266390</td>
      <td>-0.313672</td>
      <td>-1.052259</td>
      <td>-0.765698</td>
      <td>0.613884</td>
      <td>0.867406</td>
      <td>0.450232</td>
      <td>0.503315</td>
      <td>-0.091893</td>
      <td>0.446624</td>
      <td>-0.073699</td>
      <td>0.901188</td>
      <td>0.176982</td>
      <td>-0.532193</td>
      <td>-0.325019</td>
      <td>-0.549343</td>
      <td>0.352549</td>
      <td>1.336092</td>
      <td>0.187032</td>
      <td>-0.000833</td>
      <td>1.055922</td>
      <td>-0.034173</td>
      <td>0.688949</td>
      <td>0.124194</td>
      <td>0.169624</td>
      <td>0.002299</td>
      <td>-0.067749</td>
      <td>-0.212841</td>
      <td>-0.420929</td>
      <td>-0.687011</td>
      <td>-0.433269</td>
      <td>0.160745</td>
      <td>0.069841</td>
      <td>1.104122</td>
      <td>0.903448</td>
      <td>-2.076789</td>
      <td>-1.358332</td>
      <td>-0.768002</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.900412</td>
      <td>-0.066456</td>
      <td>-0.159277</td>
      <td>-0.119292</td>
      <td>0.290119</td>
      <td>0.176659</td>
      <td>1.434623</td>
      <td>1.088709</td>
      <td>0.102059</td>
      <td>-0.382700</td>
      <td>-0.017836</td>
      <td>-0.330709</td>
      <td>-0.516599</td>
      <td>-0.497374</td>
      <td>-0.420887</td>
      <td>0.014785</td>
      <td>-0.032681</td>
      <td>-1.079111</td>
      <td>-0.918968</td>
      <td>-1.078776</td>
      <td>0.631073</td>
      <td>0.202226</td>
      <td>-0.633749</td>
      <td>0.103486</td>
      <td>0.028724</td>
      <td>0.185621</td>
      <td>-0.536850</td>
      <td>0.111842</td>
      <td>-0.357792</td>
      <td>-0.157374</td>
      <td>-0.804494</td>
      <td>0.336000</td>
      <td>0.835773</td>
      <td>-0.433826</td>
      <td>0.198384</td>
      <td>0.050095</td>
      <td>-0.277297</td>
      <td>-0.160609</td>
      <td>0.560455</td>
      <td>-0.621246</td>
      <td>...</td>
      <td>0.440018</td>
      <td>0.503064</td>
      <td>0.582668</td>
      <td>-0.035218</td>
      <td>-0.653755</td>
      <td>-0.315998</td>
      <td>0.185462</td>
      <td>-0.199522</td>
      <td>0.412201</td>
      <td>0.582661</td>
      <td>-0.046687</td>
      <td>0.327442</td>
      <td>1.159138</td>
      <td>0.892176</td>
      <td>0.022812</td>
      <td>0.825137</td>
      <td>-0.123923</td>
      <td>-0.939012</td>
      <td>-0.181431</td>
      <td>0.271240</td>
      <td>1.350929</td>
      <td>0.934923</td>
      <td>0.387951</td>
      <td>0.740725</td>
      <td>0.695945</td>
      <td>0.417430</td>
      <td>0.024617</td>
      <td>0.396357</td>
      <td>0.125679</td>
      <td>0.115157</td>
      <td>1.303356</td>
      <td>-0.025908</td>
      <td>-0.252971</td>
      <td>0.730408</td>
      <td>0.810532</td>
      <td>0.962655</td>
      <td>-0.227770</td>
      <td>-1.477251</td>
      <td>-0.621085</td>
      <td>-0.667495</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.127218</td>
      <td>-0.122025</td>
      <td>-0.074772</td>
      <td>-0.337413</td>
      <td>-0.839034</td>
      <td>-1.569762</td>
      <td>0.364818</td>
      <td>-0.447407</td>
      <td>1.238475</td>
      <td>0.142666</td>
      <td>-1.094025</td>
      <td>-0.218053</td>
      <td>-0.043553</td>
      <td>0.167781</td>
      <td>-0.989681</td>
      <td>-0.096903</td>
      <td>0.055887</td>
      <td>0.152096</td>
      <td>0.380216</td>
      <td>-0.142319</td>
      <td>-0.277778</td>
      <td>-0.286922</td>
      <td>0.530870</td>
      <td>-0.666084</td>
      <td>0.748244</td>
      <td>-0.058886</td>
      <td>-0.090360</td>
      <td>0.721152</td>
      <td>-0.718698</td>
      <td>-0.686121</td>
      <td>-0.744841</td>
      <td>-0.183099</td>
      <td>-0.211576</td>
      <td>-0.605300</td>
      <td>0.755528</td>
      <td>0.169426</td>
      <td>0.186833</td>
      <td>0.469654</td>
      <td>-0.554282</td>
      <td>0.298219</td>
      <td>...</td>
      <td>0.053830</td>
      <td>0.727637</td>
      <td>0.047416</td>
      <td>0.514992</td>
      <td>-0.212250</td>
      <td>0.136821</td>
      <td>0.586663</td>
      <td>1.655479</td>
      <td>0.261299</td>
      <td>0.717361</td>
      <td>0.870431</td>
      <td>0.943440</td>
      <td>0.802074</td>
      <td>0.781065</td>
      <td>-0.538764</td>
      <td>-0.072869</td>
      <td>0.665589</td>
      <td>0.100759</td>
      <td>-0.004432</td>
      <td>0.550473</td>
      <td>0.292986</td>
      <td>-0.211674</td>
      <td>0.013389</td>
      <td>0.567498</td>
      <td>0.991222</td>
      <td>1.032401</td>
      <td>0.195054</td>
      <td>-0.518137</td>
      <td>-0.140084</td>
      <td>-0.893734</td>
      <td>0.189332</td>
      <td>-0.289049</td>
      <td>-0.408101</td>
      <td>0.304604</td>
      <td>1.281937</td>
      <td>0.419398</td>
      <td>1.099345</td>
      <td>-1.765068</td>
      <td>-1.452248</td>
      <td>-1.595001</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.777999</td>
      <td>-1.008144</td>
      <td>-0.171949</td>
      <td>-0.296572</td>
      <td>-0.317697</td>
      <td>0.899395</td>
      <td>1.382314</td>
      <td>0.826787</td>
      <td>0.366271</td>
      <td>1.246951</td>
      <td>0.135074</td>
      <td>-0.249164</td>
      <td>-0.816607</td>
      <td>-0.095917</td>
      <td>-0.827195</td>
      <td>-0.952152</td>
      <td>-1.384624</td>
      <td>-0.020368</td>
      <td>-0.183007</td>
      <td>-0.440886</td>
      <td>0.576194</td>
      <td>0.316189</td>
      <td>-0.143286</td>
      <td>0.231585</td>
      <td>-0.279509</td>
      <td>-0.262804</td>
      <td>0.071524</td>
      <td>0.902912</td>
      <td>0.655177</td>
      <td>1.142470</td>
      <td>0.861992</td>
      <td>0.792087</td>
      <td>0.177221</td>
      <td>0.509601</td>
      <td>1.067498</td>
      <td>0.112827</td>
      <td>0.260927</td>
      <td>0.882170</td>
      <td>-0.294764</td>
      <td>-0.226604</td>
      <td>...</td>
      <td>0.455041</td>
      <td>0.280443</td>
      <td>-0.076780</td>
      <td>0.556473</td>
      <td>0.024547</td>
      <td>-0.622987</td>
      <td>0.695776</td>
      <td>0.175332</td>
      <td>-0.438200</td>
      <td>0.609688</td>
      <td>0.322068</td>
      <td>0.706326</td>
      <td>0.382720</td>
      <td>0.148558</td>
      <td>0.122898</td>
      <td>-0.468936</td>
      <td>-0.014840</td>
      <td>1.018609</td>
      <td>0.998186</td>
      <td>2.305255</td>
      <td>1.366065</td>
      <td>1.723795</td>
      <td>1.029578</td>
      <td>0.675818</td>
      <td>0.629856</td>
      <td>0.611362</td>
      <td>0.448717</td>
      <td>-0.254713</td>
      <td>-0.550542</td>
      <td>0.509506</td>
      <td>1.392163</td>
      <td>0.530288</td>
      <td>0.180638</td>
      <td>0.740463</td>
      <td>-0.480523</td>
      <td>-0.382301</td>
      <td>-0.000155</td>
      <td>-4.666064</td>
      <td>-3.416394</td>
      <td>-2.303998</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.182696</td>
      <td>-0.318387</td>
      <td>-0.934171</td>
      <td>0.124064</td>
      <td>-0.592175</td>
      <td>0.553699</td>
      <td>0.245344</td>
      <td>0.622387</td>
      <td>0.800674</td>
      <td>-0.671582</td>
      <td>-0.218371</td>
      <td>-0.778388</td>
      <td>-0.660788</td>
      <td>0.578977</td>
      <td>-0.451275</td>
      <td>0.568102</td>
      <td>0.040886</td>
      <td>1.064199</td>
      <td>-0.470545</td>
      <td>-0.170148</td>
      <td>-0.818121</td>
      <td>0.537484</td>
      <td>-1.105580</td>
      <td>-0.275175</td>
      <td>-0.186719</td>
      <td>0.192214</td>
      <td>-0.263481</td>
      <td>0.851896</td>
      <td>-0.517604</td>
      <td>0.087677</td>
      <td>-0.442289</td>
      <td>1.121200</td>
      <td>0.549140</td>
      <td>-0.732836</td>
      <td>0.007763</td>
      <td>-0.275700</td>
      <td>-0.660179</td>
      <td>-0.588741</td>
      <td>-0.657250</td>
      <td>-0.873567</td>
      <td>...</td>
      <td>0.517571</td>
      <td>-0.371679</td>
      <td>-0.346796</td>
      <td>-0.313006</td>
      <td>-0.355607</td>
      <td>-0.519750</td>
      <td>-0.684599</td>
      <td>-1.316893</td>
      <td>-0.346396</td>
      <td>1.284383</td>
      <td>1.034091</td>
      <td>1.714341</td>
      <td>-0.011247</td>
      <td>0.147111</td>
      <td>0.566456</td>
      <td>0.252529</td>
      <td>-0.517630</td>
      <td>-1.076559</td>
      <td>-0.388358</td>
      <td>0.301399</td>
      <td>-0.248387</td>
      <td>-1.051025</td>
      <td>1.191660</td>
      <td>1.085104</td>
      <td>1.715016</td>
      <td>1.350024</td>
      <td>-0.042575</td>
      <td>-0.678446</td>
      <td>-0.416046</td>
      <td>0.652571</td>
      <td>0.213440</td>
      <td>0.614241</td>
      <td>-0.555185</td>
      <td>0.432997</td>
      <td>1.263974</td>
      <td>-0.001381</td>
      <td>0.780375</td>
      <td>-1.392279</td>
      <td>-0.831830</td>
      <td>-0.464789</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.135314</td>
      <td>-0.901850</td>
      <td>0.213327</td>
      <td>-0.030199</td>
      <td>-0.607462</td>
      <td>-0.444908</td>
      <td>-0.174397</td>
      <td>-0.744289</td>
      <td>0.228226</td>
      <td>-0.662199</td>
      <td>-0.354389</td>
      <td>0.260128</td>
      <td>-0.717147</td>
      <td>-0.042707</td>
      <td>-0.227434</td>
      <td>-0.104635</td>
      <td>0.811758</td>
      <td>-0.646438</td>
      <td>-1.040987</td>
      <td>-0.340891</td>
      <td>-0.461598</td>
      <td>-0.421981</td>
      <td>0.583770</td>
      <td>0.190474</td>
      <td>0.703530</td>
      <td>0.792725</td>
      <td>0.167144</td>
      <td>0.014621</td>
      <td>0.873674</td>
      <td>0.200231</td>
      <td>-1.273068</td>
      <td>-0.080553</td>
      <td>-0.010332</td>
      <td>-0.972632</td>
      <td>-0.826984</td>
      <td>-0.888696</td>
      <td>-0.961463</td>
      <td>-1.105369</td>
      <td>0.247159</td>
      <td>0.184323</td>
      <td>...</td>
      <td>0.654534</td>
      <td>0.611398</td>
      <td>-0.197604</td>
      <td>-0.071367</td>
      <td>0.493684</td>
      <td>-0.363937</td>
      <td>-0.138703</td>
      <td>-0.093873</td>
      <td>0.905449</td>
      <td>1.088442</td>
      <td>1.019798</td>
      <td>0.127518</td>
      <td>-0.058875</td>
      <td>-0.263435</td>
      <td>-0.265791</td>
      <td>0.279969</td>
      <td>-0.173527</td>
      <td>0.333926</td>
      <td>0.654262</td>
      <td>0.029647</td>
      <td>0.247824</td>
      <td>-0.460848</td>
      <td>0.264997</td>
      <td>-0.439359</td>
      <td>0.681701</td>
      <td>-0.390620</td>
      <td>-0.774476</td>
      <td>-0.943606</td>
      <td>-0.389613</td>
      <td>-1.071844</td>
      <td>-0.798601</td>
      <td>-0.829619</td>
      <td>1.052058</td>
      <td>-0.612900</td>
      <td>0.572709</td>
      <td>-0.473271</td>
      <td>-0.170576</td>
      <td>-1.896601</td>
      <td>-1.336676</td>
      <td>-0.726697</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.245319</td>
      <td>0.511948</td>
      <td>-0.743120</td>
      <td>0.040231</td>
      <td>-0.197870</td>
      <td>-1.151555</td>
      <td>0.179844</td>
      <td>-0.315542</td>
      <td>0.651151</td>
      <td>-0.990866</td>
      <td>-0.752416</td>
      <td>-0.674027</td>
      <td>0.572121</td>
      <td>0.291552</td>
      <td>-0.954405</td>
      <td>-0.653195</td>
      <td>0.102336</td>
      <td>0.124745</td>
      <td>-1.032808</td>
      <td>0.085433</td>
      <td>0.038267</td>
      <td>0.013261</td>
      <td>0.609946</td>
      <td>-0.042845</td>
      <td>0.324755</td>
      <td>-0.435892</td>
      <td>0.270658</td>
      <td>0.406962</td>
      <td>0.542823</td>
      <td>-0.299059</td>
      <td>-0.329593</td>
      <td>1.237447</td>
      <td>0.861238</td>
      <td>-0.203821</td>
      <td>0.186477</td>
      <td>-0.105893</td>
      <td>0.923219</td>
      <td>-0.746079</td>
      <td>-0.824079</td>
      <td>0.423975</td>
      <td>...</td>
      <td>-0.627226</td>
      <td>0.479060</td>
      <td>-0.225918</td>
      <td>0.448618</td>
      <td>-0.299039</td>
      <td>0.010898</td>
      <td>-0.976761</td>
      <td>-0.148903</td>
      <td>-0.075830</td>
      <td>-0.222903</td>
      <td>0.050798</td>
      <td>-0.877696</td>
      <td>0.322346</td>
      <td>-0.617323</td>
      <td>-0.194409</td>
      <td>0.301185</td>
      <td>-0.617851</td>
      <td>0.567556</td>
      <td>0.701976</td>
      <td>0.935825</td>
      <td>0.626205</td>
      <td>0.255791</td>
      <td>0.271107</td>
      <td>0.088511</td>
      <td>1.314869</td>
      <td>1.619176</td>
      <td>-0.501967</td>
      <td>-0.902535</td>
      <td>-0.660059</td>
      <td>-0.435188</td>
      <td>-0.784139</td>
      <td>-1.177694</td>
      <td>-0.528335</td>
      <td>-0.712189</td>
      <td>0.052705</td>
      <td>-0.242348</td>
      <td>-0.444145</td>
      <td>-2.623670</td>
      <td>-1.025481</td>
      <td>-0.315742</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.168559</td>
      <td>-0.269844</td>
      <td>-0.059375</td>
      <td>-1.187537</td>
      <td>-1.415713</td>
      <td>-0.240555</td>
      <td>1.104173</td>
      <td>0.470667</td>
      <td>-0.019667</td>
      <td>-0.380902</td>
      <td>-0.120349</td>
      <td>-0.439077</td>
      <td>-1.168101</td>
      <td>0.282473</td>
      <td>-0.818854</td>
      <td>-0.341956</td>
      <td>-0.384006</td>
      <td>0.177315</td>
      <td>-0.228105</td>
      <td>0.341733</td>
      <td>1.122801</td>
      <td>1.251960</td>
      <td>0.132044</td>
      <td>-0.175701</td>
      <td>0.514216</td>
      <td>0.272911</td>
      <td>-0.449519</td>
      <td>-0.400564</td>
      <td>0.476075</td>
      <td>-0.722935</td>
      <td>-0.571159</td>
      <td>0.037109</td>
      <td>0.187065</td>
      <td>0.174334</td>
      <td>0.341177</td>
      <td>0.093611</td>
      <td>0.098108</td>
      <td>0.601794</td>
      <td>0.313089</td>
      <td>0.458322</td>
      <td>...</td>
      <td>-0.385253</td>
      <td>-0.945061</td>
      <td>0.867110</td>
      <td>-0.099872</td>
      <td>-0.020442</td>
      <td>-0.635507</td>
      <td>-0.323004</td>
      <td>0.427074</td>
      <td>-0.051541</td>
      <td>-0.359823</td>
      <td>-0.219415</td>
      <td>-0.905161</td>
      <td>-0.216903</td>
      <td>-0.299430</td>
      <td>-0.494203</td>
      <td>0.355299</td>
      <td>-0.363710</td>
      <td>-0.077921</td>
      <td>0.380424</td>
      <td>0.612659</td>
      <td>-0.225360</td>
      <td>-0.019210</td>
      <td>0.427451</td>
      <td>0.417642</td>
      <td>0.725690</td>
      <td>0.630588</td>
      <td>0.256586</td>
      <td>-1.087410</td>
      <td>-0.706744</td>
      <td>0.582339</td>
      <td>1.026557</td>
      <td>0.140915</td>
      <td>0.027987</td>
      <td>0.130633</td>
      <td>-0.265018</td>
      <td>-0.684799</td>
      <td>0.148404</td>
      <td>-1.438976</td>
      <td>-0.270303</td>
      <td>-0.157252</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.034546</td>
      <td>0.084925</td>
      <td>-0.074498</td>
      <td>-0.257398</td>
      <td>-0.702811</td>
      <td>0.023969</td>
      <td>1.004699</td>
      <td>0.132426</td>
      <td>-0.796585</td>
      <td>0.087215</td>
      <td>1.445965</td>
      <td>-0.524359</td>
      <td>-0.740130</td>
      <td>-0.678793</td>
      <td>-1.192367</td>
      <td>0.877502</td>
      <td>0.139987</td>
      <td>1.191674</td>
      <td>-0.145909</td>
      <td>-0.497869</td>
      <td>1.253198</td>
      <td>0.732851</td>
      <td>0.365157</td>
      <td>0.897739</td>
      <td>0.869943</td>
      <td>0.338906</td>
      <td>0.434583</td>
      <td>0.528690</td>
      <td>-0.160923</td>
      <td>0.808821</td>
      <td>-0.275046</td>
      <td>-0.410096</td>
      <td>0.938555</td>
      <td>0.101294</td>
      <td>0.237851</td>
      <td>0.905458</td>
      <td>1.026132</td>
      <td>0.878484</td>
      <td>0.631726</td>
      <td>0.037606</td>
      <td>...</td>
      <td>1.012551</td>
      <td>1.160271</td>
      <td>0.890242</td>
      <td>0.308987</td>
      <td>0.464518</td>
      <td>-0.825926</td>
      <td>-0.508821</td>
      <td>-0.806191</td>
      <td>0.743882</td>
      <td>-0.528995</td>
      <td>-1.469423</td>
      <td>-1.269303</td>
      <td>-0.596278</td>
      <td>-0.209881</td>
      <td>-0.992511</td>
      <td>-0.018929</td>
      <td>0.327090</td>
      <td>-0.192293</td>
      <td>-0.754011</td>
      <td>-0.156837</td>
      <td>-0.826333</td>
      <td>-0.335476</td>
      <td>-0.135017</td>
      <td>0.082105</td>
      <td>0.587093</td>
      <td>1.186844</td>
      <td>0.142238</td>
      <td>-0.218618</td>
      <td>-0.226023</td>
      <td>0.192610</td>
      <td>-0.368829</td>
      <td>-0.460130</td>
      <td>-1.166124</td>
      <td>-0.573492</td>
      <td>0.361655</td>
      <td>-0.148026</td>
      <td>0.287329</td>
      <td>0.968305</td>
      <td>0.380054</td>
      <td>-0.121729</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.142910</td>
      <td>-0.132765</td>
      <td>-0.283983</td>
      <td>-0.876991</td>
      <td>-0.598771</td>
      <td>-0.203599</td>
      <td>0.408219</td>
      <td>1.497519</td>
      <td>-1.081340</td>
      <td>-0.567501</td>
      <td>0.320779</td>
      <td>0.274263</td>
      <td>-0.561702</td>
      <td>-0.793374</td>
      <td>-0.885392</td>
      <td>0.073529</td>
      <td>-0.204395</td>
      <td>-0.596261</td>
      <td>-0.606718</td>
      <td>-0.591221</td>
      <td>0.935314</td>
      <td>0.245302</td>
      <td>0.026935</td>
      <td>0.392728</td>
      <td>-0.148720</td>
      <td>0.206482</td>
      <td>0.433057</td>
      <td>0.708032</td>
      <td>0.191580</td>
      <td>0.252239</td>
      <td>0.514187</td>
      <td>-0.012506</td>
      <td>0.128150</td>
      <td>0.900508</td>
      <td>0.943713</td>
      <td>0.643393</td>
      <td>0.982496</td>
      <td>0.545336</td>
      <td>0.526912</td>
      <td>-0.507970</td>
      <td>...</td>
      <td>0.777245</td>
      <td>0.158419</td>
      <td>0.500952</td>
      <td>-0.070010</td>
      <td>-0.500410</td>
      <td>-0.112656</td>
      <td>-0.230514</td>
      <td>0.148082</td>
      <td>-0.132903</td>
      <td>-0.628237</td>
      <td>-0.656774</td>
      <td>-0.064160</td>
      <td>-0.620959</td>
      <td>-0.216644</td>
      <td>-0.150483</td>
      <td>-0.281057</td>
      <td>0.191541</td>
      <td>-0.143909</td>
      <td>-0.579520</td>
      <td>0.190272</td>
      <td>0.504125</td>
      <td>-0.835537</td>
      <td>-0.656149</td>
      <td>-0.467436</td>
      <td>0.658766</td>
      <td>1.194381</td>
      <td>-0.327641</td>
      <td>-0.694647</td>
      <td>-0.507415</td>
      <td>-0.410700</td>
      <td>-0.633424</td>
      <td>0.280849</td>
      <td>-0.098277</td>
      <td>-0.780386</td>
      <td>-0.329340</td>
      <td>0.109228</td>
      <td>0.868653</td>
      <td>0.375718</td>
      <td>0.015461</td>
      <td>0.216415</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.142255</td>
      <td>0.112611</td>
      <td>-0.261454</td>
      <td>-1.522850</td>
      <td>0.089896</td>
      <td>0.271149</td>
      <td>0.022033</td>
      <td>-0.129160</td>
      <td>0.563055</td>
      <td>0.010385</td>
      <td>0.271076</td>
      <td>0.088514</td>
      <td>0.965920</td>
      <td>0.096136</td>
      <td>0.516557</td>
      <td>0.171387</td>
      <td>-0.125458</td>
      <td>0.309969</td>
      <td>-0.820089</td>
      <td>-0.536052</td>
      <td>0.966595</td>
      <td>1.274694</td>
      <td>0.215756</td>
      <td>-0.485837</td>
      <td>-0.204591</td>
      <td>0.402751</td>
      <td>-0.123871</td>
      <td>0.418860</td>
      <td>-0.028202</td>
      <td>-0.192580</td>
      <td>-0.377866</td>
      <td>0.408553</td>
      <td>0.544215</td>
      <td>-1.296181</td>
      <td>0.675342</td>
      <td>0.446532</td>
      <td>0.264400</td>
      <td>-0.428717</td>
      <td>-0.105688</td>
      <td>-0.550635</td>
      <td>...</td>
      <td>1.258619</td>
      <td>-0.144934</td>
      <td>0.936715</td>
      <td>-0.162228</td>
      <td>-0.115224</td>
      <td>-0.876375</td>
      <td>-0.352222</td>
      <td>-0.210394</td>
      <td>-0.356770</td>
      <td>1.090686</td>
      <td>0.366901</td>
      <td>-0.940322</td>
      <td>0.836651</td>
      <td>0.249812</td>
      <td>0.500110</td>
      <td>0.754171</td>
      <td>-0.745555</td>
      <td>-0.344771</td>
      <td>-0.903272</td>
      <td>-1.156101</td>
      <td>-0.211749</td>
      <td>0.384714</td>
      <td>-0.500941</td>
      <td>0.141187</td>
      <td>0.969935</td>
      <td>1.141194</td>
      <td>-0.718721</td>
      <td>0.220868</td>
      <td>-0.251554</td>
      <td>-0.435760</td>
      <td>-0.207105</td>
      <td>0.281285</td>
      <td>-0.277746</td>
      <td>0.133899</td>
      <td>0.843374</td>
      <td>0.408059</td>
      <td>-0.583593</td>
      <td>-0.773437</td>
      <td>-0.888658</td>
      <td>-0.400550</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.338514</td>
      <td>-0.516587</td>
      <td>0.230603</td>
      <td>0.415762</td>
      <td>0.344195</td>
      <td>0.435067</td>
      <td>0.610651</td>
      <td>-1.340635</td>
      <td>-0.519419</td>
      <td>0.133339</td>
      <td>-0.900798</td>
      <td>0.306411</td>
      <td>-0.511889</td>
      <td>0.043295</td>
      <td>-0.481643</td>
      <td>-0.048761</td>
      <td>0.025512</td>
      <td>-0.046282</td>
      <td>-1.110580</td>
      <td>-0.882387</td>
      <td>-0.196894</td>
      <td>0.067079</td>
      <td>0.375690</td>
      <td>0.742407</td>
      <td>0.310929</td>
      <td>0.274266</td>
      <td>0.202565</td>
      <td>-0.446164</td>
      <td>0.400782</td>
      <td>0.129191</td>
      <td>0.367564</td>
      <td>0.185951</td>
      <td>0.624504</td>
      <td>-0.490993</td>
      <td>-0.641147</td>
      <td>0.294248</td>
      <td>-0.026056</td>
      <td>0.308406</td>
      <td>-0.021414</td>
      <td>-0.022879</td>
      <td>...</td>
      <td>-0.029087</td>
      <td>0.387669</td>
      <td>-0.221662</td>
      <td>-0.082748</td>
      <td>-0.070644</td>
      <td>1.153185</td>
      <td>0.483186</td>
      <td>0.187189</td>
      <td>0.415587</td>
      <td>0.813543</td>
      <td>0.395547</td>
      <td>-0.033988</td>
      <td>-0.149807</td>
      <td>0.117040</td>
      <td>0.850035</td>
      <td>0.494972</td>
      <td>0.073037</td>
      <td>-0.405612</td>
      <td>-0.087492</td>
      <td>-0.372112</td>
      <td>-0.664436</td>
      <td>0.189076</td>
      <td>0.475705</td>
      <td>0.277317</td>
      <td>1.046920</td>
      <td>0.192681</td>
      <td>-0.503060</td>
      <td>-0.121983</td>
      <td>0.076804</td>
      <td>0.165719</td>
      <td>-1.013117</td>
      <td>0.186812</td>
      <td>-1.759776</td>
      <td>-0.006807</td>
      <td>-0.868873</td>
      <td>-0.296559</td>
      <td>0.206317</td>
      <td>0.590512</td>
      <td>-0.111883</td>
      <td>-0.045431</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-1.076714</td>
      <td>0.424962</td>
      <td>0.197365</td>
      <td>-0.089002</td>
      <td>-0.084370</td>
      <td>-0.116706</td>
      <td>0.531603</td>
      <td>0.759734</td>
      <td>-0.816211</td>
      <td>0.651299</td>
      <td>-0.330492</td>
      <td>0.516403</td>
      <td>-0.751505</td>
      <td>-1.533564</td>
      <td>-1.340672</td>
      <td>-0.326591</td>
      <td>-0.223540</td>
      <td>-0.127414</td>
      <td>-0.175611</td>
      <td>0.221341</td>
      <td>-0.309714</td>
      <td>-0.349122</td>
      <td>-0.659834</td>
      <td>-1.022321</td>
      <td>-0.382835</td>
      <td>-0.294264</td>
      <td>-0.008852</td>
      <td>-0.111919</td>
      <td>0.027045</td>
      <td>-0.317422</td>
      <td>0.099298</td>
      <td>0.863976</td>
      <td>0.173877</td>
      <td>-0.236413</td>
      <td>-0.388169</td>
      <td>0.049158</td>
      <td>0.661550</td>
      <td>0.234624</td>
      <td>-0.456382</td>
      <td>0.660358</td>
      <td>...</td>
      <td>0.101194</td>
      <td>0.065233</td>
      <td>-0.793592</td>
      <td>-0.395241</td>
      <td>0.338875</td>
      <td>-0.985416</td>
      <td>0.033347</td>
      <td>-0.146255</td>
      <td>-0.088046</td>
      <td>0.769509</td>
      <td>0.575733</td>
      <td>-0.648737</td>
      <td>0.687210</td>
      <td>0.258757</td>
      <td>0.062499</td>
      <td>0.073014</td>
      <td>-0.308946</td>
      <td>0.667608</td>
      <td>0.072650</td>
      <td>0.071475</td>
      <td>0.040237</td>
      <td>0.487730</td>
      <td>0.647202</td>
      <td>0.596064</td>
      <td>0.874135</td>
      <td>0.571519</td>
      <td>0.088524</td>
      <td>-0.327499</td>
      <td>-0.320887</td>
      <td>0.562392</td>
      <td>-0.280474</td>
      <td>-0.133890</td>
      <td>-0.683878</td>
      <td>-0.205583</td>
      <td>-0.684284</td>
      <td>-0.000004</td>
      <td>0.382109</td>
      <td>-1.110382</td>
      <td>-0.812068</td>
      <td>-0.082843</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-0.407541</td>
      <td>-1.193080</td>
      <td>-1.100095</td>
      <td>-0.097748</td>
      <td>-0.213278</td>
      <td>0.241250</td>
      <td>0.698875</td>
      <td>0.019339</td>
      <td>-0.263303</td>
      <td>0.000626</td>
      <td>-0.517199</td>
      <td>-0.157175</td>
      <td>-0.938882</td>
      <td>0.290098</td>
      <td>0.056407</td>
      <td>0.007120</td>
      <td>-0.028773</td>
      <td>0.463270</td>
      <td>-0.074873</td>
      <td>-0.337389</td>
      <td>-0.995189</td>
      <td>-0.547611</td>
      <td>-0.661990</td>
      <td>-0.615808</td>
      <td>0.856296</td>
      <td>-0.666868</td>
      <td>-0.575030</td>
      <td>-0.463319</td>
      <td>-0.342972</td>
      <td>1.154820</td>
      <td>-0.177324</td>
      <td>-0.092870</td>
      <td>-0.227268</td>
      <td>-0.218139</td>
      <td>-0.301824</td>
      <td>-0.774775</td>
      <td>-0.513443</td>
      <td>0.017901</td>
      <td>-0.002329</td>
      <td>0.306525</td>
      <td>...</td>
      <td>0.023645</td>
      <td>0.039873</td>
      <td>0.475250</td>
      <td>0.465784</td>
      <td>-0.393878</td>
      <td>0.026804</td>
      <td>0.417114</td>
      <td>-0.212315</td>
      <td>1.153807</td>
      <td>1.300773</td>
      <td>-0.278863</td>
      <td>0.389261</td>
      <td>1.548436</td>
      <td>-0.280688</td>
      <td>-0.593991</td>
      <td>-0.305839</td>
      <td>0.201274</td>
      <td>0.162724</td>
      <td>0.830239</td>
      <td>-0.312689</td>
      <td>-1.233423</td>
      <td>0.086419</td>
      <td>0.244640</td>
      <td>-1.039790</td>
      <td>0.250913</td>
      <td>-0.254970</td>
      <td>-0.815956</td>
      <td>-1.137266</td>
      <td>-0.361592</td>
      <td>0.413278</td>
      <td>0.354404</td>
      <td>-0.728093</td>
      <td>-0.336928</td>
      <td>0.830782</td>
      <td>-0.397070</td>
      <td>-0.746115</td>
      <td>-0.039436</td>
      <td>-2.884546</td>
      <td>-1.526993</td>
      <td>-1.080602</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.475978</td>
      <td>-0.244953</td>
      <td>-0.023917</td>
      <td>0.121064</td>
      <td>-1.086859</td>
      <td>0.317862</td>
      <td>1.771660</td>
      <td>-0.319753</td>
      <td>-0.118640</td>
      <td>0.347142</td>
      <td>-0.074421</td>
      <td>0.406220</td>
      <td>-0.272196</td>
      <td>-0.764416</td>
      <td>-0.530055</td>
      <td>0.424553</td>
      <td>0.271487</td>
      <td>0.834991</td>
      <td>-0.974734</td>
      <td>-0.068982</td>
      <td>-0.635179</td>
      <td>-0.111859</td>
      <td>-0.032207</td>
      <td>0.006197</td>
      <td>0.041141</td>
      <td>-0.964152</td>
      <td>-0.017674</td>
      <td>0.098957</td>
      <td>-0.749448</td>
      <td>-0.829058</td>
      <td>-0.847898</td>
      <td>-0.480922</td>
      <td>-0.620163</td>
      <td>0.147060</td>
      <td>-0.574998</td>
      <td>-0.057520</td>
      <td>0.695745</td>
      <td>1.254746</td>
      <td>-0.129369</td>
      <td>-0.196225</td>
      <td>...</td>
      <td>-1.029247</td>
      <td>0.565116</td>
      <td>0.969920</td>
      <td>0.088833</td>
      <td>-0.376992</td>
      <td>-0.027235</td>
      <td>-0.288346</td>
      <td>0.307678</td>
      <td>-0.131835</td>
      <td>1.151596</td>
      <td>0.573880</td>
      <td>-0.327824</td>
      <td>1.148807</td>
      <td>0.838328</td>
      <td>0.568108</td>
      <td>0.056059</td>
      <td>-0.285080</td>
      <td>-0.967704</td>
      <td>0.262267</td>
      <td>0.385719</td>
      <td>-0.042045</td>
      <td>-0.358375</td>
      <td>1.104156</td>
      <td>-0.226993</td>
      <td>-0.385978</td>
      <td>0.311159</td>
      <td>-0.819915</td>
      <td>-0.445377</td>
      <td>-0.166261</td>
      <td>-0.415114</td>
      <td>-0.613211</td>
      <td>-1.375323</td>
      <td>0.068641</td>
      <td>0.346701</td>
      <td>-0.294268</td>
      <td>0.038763</td>
      <td>-0.032112</td>
      <td>-1.002475</td>
      <td>-0.113012</td>
      <td>-0.355277</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.459574</td>
      <td>0.008523</td>
      <td>-0.647421</td>
      <td>-0.215199</td>
      <td>-0.432138</td>
      <td>-0.845262</td>
      <td>0.335584</td>
      <td>-0.768027</td>
      <td>0.398653</td>
      <td>-0.042792</td>
      <td>-0.104437</td>
      <td>-0.161970</td>
      <td>-0.333450</td>
      <td>-0.040345</td>
      <td>-0.818336</td>
      <td>-0.209141</td>
      <td>0.498068</td>
      <td>0.774760</td>
      <td>-0.875733</td>
      <td>-0.103289</td>
      <td>0.638401</td>
      <td>-0.014910</td>
      <td>-0.339522</td>
      <td>-0.051453</td>
      <td>-0.091439</td>
      <td>-0.095153</td>
      <td>-0.017633</td>
      <td>0.067625</td>
      <td>-0.678022</td>
      <td>0.210710</td>
      <td>0.205531</td>
      <td>0.329699</td>
      <td>0.703256</td>
      <td>-0.221566</td>
      <td>-0.302687</td>
      <td>0.606353</td>
      <td>-0.649084</td>
      <td>-0.034395</td>
      <td>-0.645931</td>
      <td>-0.186495</td>
      <td>...</td>
      <td>0.364389</td>
      <td>-0.333566</td>
      <td>-0.033706</td>
      <td>0.098925</td>
      <td>-0.825901</td>
      <td>-0.181955</td>
      <td>-0.163536</td>
      <td>0.361141</td>
      <td>0.103352</td>
      <td>0.144710</td>
      <td>0.097953</td>
      <td>0.637638</td>
      <td>0.055771</td>
      <td>0.464019</td>
      <td>-0.852635</td>
      <td>0.050583</td>
      <td>-0.435901</td>
      <td>-0.119066</td>
      <td>-0.124663</td>
      <td>0.011281</td>
      <td>-0.354317</td>
      <td>-0.273492</td>
      <td>-0.502724</td>
      <td>0.321296</td>
      <td>1.061295</td>
      <td>0.834581</td>
      <td>-0.321426</td>
      <td>-0.340341</td>
      <td>-0.732735</td>
      <td>-0.402867</td>
      <td>-0.144425</td>
      <td>0.858045</td>
      <td>-0.366150</td>
      <td>-0.629617</td>
      <td>0.764503</td>
      <td>0.159592</td>
      <td>0.189773</td>
      <td>-0.110954</td>
      <td>0.066723</td>
      <td>0.613814</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.891858</td>
      <td>-0.919755</td>
      <td>-0.231048</td>
      <td>0.017483</td>
      <td>0.074944</td>
      <td>-0.128006</td>
      <td>0.261036</td>
      <td>0.021796</td>
      <td>-0.213120</td>
      <td>0.060336</td>
      <td>0.077401</td>
      <td>-1.103656</td>
      <td>0.009312</td>
      <td>-0.617715</td>
      <td>0.213954</td>
      <td>-0.578995</td>
      <td>-0.880719</td>
      <td>0.768970</td>
      <td>-0.503944</td>
      <td>-0.341963</td>
      <td>0.239741</td>
      <td>-0.042752</td>
      <td>0.021727</td>
      <td>-0.752440</td>
      <td>0.213698</td>
      <td>0.306703</td>
      <td>0.181548</td>
      <td>0.345473</td>
      <td>-0.175194</td>
      <td>-1.472309</td>
      <td>-0.507521</td>
      <td>0.423774</td>
      <td>0.355038</td>
      <td>-0.338816</td>
      <td>-0.416733</td>
      <td>-0.819756</td>
      <td>0.399332</td>
      <td>0.354670</td>
      <td>-0.724682</td>
      <td>-0.194873</td>
      <td>...</td>
      <td>0.512297</td>
      <td>0.798529</td>
      <td>-0.321919</td>
      <td>-0.101960</td>
      <td>0.562021</td>
      <td>-0.199256</td>
      <td>0.305023</td>
      <td>-0.665636</td>
      <td>-0.364786</td>
      <td>1.022513</td>
      <td>0.380055</td>
      <td>0.128371</td>
      <td>0.791366</td>
      <td>0.371460</td>
      <td>0.564552</td>
      <td>0.457798</td>
      <td>0.250701</td>
      <td>0.509684</td>
      <td>0.779778</td>
      <td>0.937204</td>
      <td>-0.156116</td>
      <td>0.103237</td>
      <td>0.623411</td>
      <td>-0.262253</td>
      <td>0.615581</td>
      <td>-0.580699</td>
      <td>-0.791917</td>
      <td>-1.082253</td>
      <td>0.135048</td>
      <td>-0.090385</td>
      <td>-0.748289</td>
      <td>-0.574581</td>
      <td>-0.601119</td>
      <td>-0.097549</td>
      <td>0.121514</td>
      <td>-0.513706</td>
      <td>0.361193</td>
      <td>-2.474889</td>
      <td>-2.249623</td>
      <td>-1.701774</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.711899</td>
      <td>-1.076368</td>
      <td>0.216271</td>
      <td>-0.551747</td>
      <td>-0.314121</td>
      <td>0.335665</td>
      <td>0.454529</td>
      <td>-0.370058</td>
      <td>0.003427</td>
      <td>0.271066</td>
      <td>0.271372</td>
      <td>-0.650269</td>
      <td>-0.323311</td>
      <td>0.133073</td>
      <td>-0.401959</td>
      <td>-0.133760</td>
      <td>-0.570351</td>
      <td>-0.128715</td>
      <td>-0.824423</td>
      <td>-1.381751</td>
      <td>0.683819</td>
      <td>0.271723</td>
      <td>-0.124833</td>
      <td>0.237817</td>
      <td>-0.308119</td>
      <td>-0.991155</td>
      <td>-0.188966</td>
      <td>0.687764</td>
      <td>0.428692</td>
      <td>-0.761935</td>
      <td>-1.475645</td>
      <td>0.355819</td>
      <td>1.509883</td>
      <td>0.397761</td>
      <td>-0.205079</td>
      <td>0.126515</td>
      <td>0.732484</td>
      <td>0.977596</td>
      <td>-0.393178</td>
      <td>0.237211</td>
      <td>...</td>
      <td>0.129395</td>
      <td>1.469374</td>
      <td>0.403154</td>
      <td>0.917518</td>
      <td>-0.082735</td>
      <td>-0.304337</td>
      <td>0.131553</td>
      <td>-0.219799</td>
      <td>-0.151738</td>
      <td>0.845713</td>
      <td>-0.437084</td>
      <td>0.025425</td>
      <td>0.436627</td>
      <td>-0.836609</td>
      <td>1.029836</td>
      <td>0.413825</td>
      <td>0.136657</td>
      <td>0.458260</td>
      <td>-0.298435</td>
      <td>-0.899680</td>
      <td>-0.406657</td>
      <td>-1.069583</td>
      <td>0.094076</td>
      <td>0.127813</td>
      <td>0.784648</td>
      <td>0.334338</td>
      <td>-0.076039</td>
      <td>0.178149</td>
      <td>0.337788</td>
      <td>0.014979</td>
      <td>0.176142</td>
      <td>-0.395079</td>
      <td>0.350745</td>
      <td>-0.246279</td>
      <td>-1.036056</td>
      <td>-0.935742</td>
      <td>0.883508</td>
      <td>-3.442137</td>
      <td>-2.802053</td>
      <td>-1.761493</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.308167</td>
      <td>-0.688688</td>
      <td>-1.374078</td>
      <td>-0.850415</td>
      <td>0.020103</td>
      <td>0.362511</td>
      <td>-0.075298</td>
      <td>-0.700907</td>
      <td>-1.309940</td>
      <td>-0.352089</td>
      <td>-0.776962</td>
      <td>-0.136516</td>
      <td>-0.311489</td>
      <td>0.753757</td>
      <td>-0.364534</td>
      <td>1.180556</td>
      <td>-0.036122</td>
      <td>0.070799</td>
      <td>-1.103108</td>
      <td>0.083378</td>
      <td>1.576360</td>
      <td>-0.088864</td>
      <td>0.107307</td>
      <td>-0.800719</td>
      <td>-0.149979</td>
      <td>0.868551</td>
      <td>-0.008327</td>
      <td>0.424669</td>
      <td>-0.294567</td>
      <td>-0.138696</td>
      <td>-0.509734</td>
      <td>0.403143</td>
      <td>0.131343</td>
      <td>0.197190</td>
      <td>0.762850</td>
      <td>0.420993</td>
      <td>-0.525867</td>
      <td>-1.315986</td>
      <td>-1.431924</td>
      <td>-0.389034</td>
      <td>...</td>
      <td>-1.091219</td>
      <td>0.435175</td>
      <td>1.035172</td>
      <td>0.815667</td>
      <td>0.124784</td>
      <td>-0.753910</td>
      <td>1.077752</td>
      <td>-0.157178</td>
      <td>-0.127515</td>
      <td>0.629171</td>
      <td>0.718342</td>
      <td>-0.084872</td>
      <td>0.145384</td>
      <td>0.726488</td>
      <td>0.431403</td>
      <td>0.754949</td>
      <td>-0.575760</td>
      <td>0.855237</td>
      <td>0.427857</td>
      <td>0.259681</td>
      <td>-1.045484</td>
      <td>-0.911548</td>
      <td>0.664341</td>
      <td>-0.252280</td>
      <td>1.026825</td>
      <td>-0.009775</td>
      <td>0.255463</td>
      <td>-0.432792</td>
      <td>-0.650004</td>
      <td>0.025405</td>
      <td>-0.420773</td>
      <td>-0.003417</td>
      <td>-0.443852</td>
      <td>-0.050729</td>
      <td>-0.570282</td>
      <td>-0.228064</td>
      <td>0.234007</td>
      <td>-1.136570</td>
      <td>-1.231982</td>
      <td>-0.891543</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.146561</td>
      <td>-0.282555</td>
      <td>-0.684762</td>
      <td>-0.519900</td>
      <td>-0.224911</td>
      <td>0.431577</td>
      <td>0.211698</td>
      <td>-0.382832</td>
      <td>-0.312987</td>
      <td>-0.781422</td>
      <td>-0.889738</td>
      <td>-0.321122</td>
      <td>-0.162796</td>
      <td>-0.009924</td>
      <td>0.911405</td>
      <td>0.090117</td>
      <td>0.429313</td>
      <td>0.155482</td>
      <td>-0.212308</td>
      <td>-0.136612</td>
      <td>-1.025346</td>
      <td>0.225566</td>
      <td>0.277765</td>
      <td>1.036447</td>
      <td>0.629642</td>
      <td>0.334620</td>
      <td>0.468044</td>
      <td>0.471036</td>
      <td>-0.198358</td>
      <td>-0.947767</td>
      <td>-1.053729</td>
      <td>-0.499727</td>
      <td>-0.901102</td>
      <td>-0.047003</td>
      <td>0.348223</td>
      <td>0.198977</td>
      <td>0.081543</td>
      <td>0.633613</td>
      <td>-0.713067</td>
      <td>-0.266623</td>
      <td>...</td>
      <td>-0.003490</td>
      <td>-0.439374</td>
      <td>-1.068019</td>
      <td>-0.275959</td>
      <td>0.344202</td>
      <td>-0.196714</td>
      <td>0.584560</td>
      <td>0.782155</td>
      <td>0.442877</td>
      <td>0.407240</td>
      <td>-0.188505</td>
      <td>0.542213</td>
      <td>-0.326502</td>
      <td>-0.190373</td>
      <td>1.053558</td>
      <td>0.220864</td>
      <td>-0.105361</td>
      <td>0.721487</td>
      <td>0.707788</td>
      <td>0.162959</td>
      <td>-0.098995</td>
      <td>-0.008564</td>
      <td>0.867523</td>
      <td>0.952129</td>
      <td>1.093369</td>
      <td>0.635360</td>
      <td>-0.456666</td>
      <td>-0.283011</td>
      <td>-0.843109</td>
      <td>-0.038605</td>
      <td>-0.048960</td>
      <td>0.520689</td>
      <td>-0.321434</td>
      <td>0.440904</td>
      <td>0.795318</td>
      <td>-0.209884</td>
      <td>-0.786136</td>
      <td>-0.538309</td>
      <td>-0.770960</td>
      <td>-0.618923</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-1.179112</td>
      <td>-0.147142</td>
      <td>-0.556612</td>
      <td>-0.764180</td>
      <td>-1.964183</td>
      <td>-0.093742</td>
      <td>0.161522</td>
      <td>0.823837</td>
      <td>-0.247650</td>
      <td>-0.798442</td>
      <td>-0.041205</td>
      <td>-0.034322</td>
      <td>0.216193</td>
      <td>-0.268594</td>
      <td>-0.029703</td>
      <td>-0.173283</td>
      <td>-0.922762</td>
      <td>-0.025892</td>
      <td>-0.343676</td>
      <td>0.140474</td>
      <td>-0.351549</td>
      <td>0.520261</td>
      <td>0.292580</td>
      <td>-0.909918</td>
      <td>-0.760646</td>
      <td>-0.484096</td>
      <td>-0.312888</td>
      <td>0.324363</td>
      <td>0.466728</td>
      <td>0.068699</td>
      <td>-0.484942</td>
      <td>0.470431</td>
      <td>0.762353</td>
      <td>-0.947859</td>
      <td>-0.030044</td>
      <td>0.159398</td>
      <td>-0.165127</td>
      <td>-0.411706</td>
      <td>-0.883700</td>
      <td>0.576145</td>
      <td>...</td>
      <td>0.378101</td>
      <td>0.264990</td>
      <td>0.023216</td>
      <td>-0.790360</td>
      <td>-0.309500</td>
      <td>0.025583</td>
      <td>1.663478</td>
      <td>0.513135</td>
      <td>0.283018</td>
      <td>1.414843</td>
      <td>0.915033</td>
      <td>-0.135044</td>
      <td>-0.318450</td>
      <td>-0.878737</td>
      <td>0.216628</td>
      <td>0.204091</td>
      <td>-0.732168</td>
      <td>0.061036</td>
      <td>0.432893</td>
      <td>0.965844</td>
      <td>1.069000</td>
      <td>0.028211</td>
      <td>-0.320100</td>
      <td>0.788031</td>
      <td>0.374002</td>
      <td>0.489218</td>
      <td>-0.745696</td>
      <td>-0.556565</td>
      <td>0.346530</td>
      <td>0.171054</td>
      <td>-0.924746</td>
      <td>-0.489070</td>
      <td>-0.266452</td>
      <td>-0.175754</td>
      <td>-0.481767</td>
      <td>0.138512</td>
      <td>0.948483</td>
      <td>-2.929425</td>
      <td>-2.787416</td>
      <td>-2.141159</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.795067</td>
      <td>-0.502541</td>
      <td>-1.944177</td>
      <td>-0.426926</td>
      <td>-0.370490</td>
      <td>0.094123</td>
      <td>1.423646</td>
      <td>-1.153601</td>
      <td>0.832641</td>
      <td>-0.134439</td>
      <td>0.411072</td>
      <td>0.598211</td>
      <td>0.884804</td>
      <td>0.525939</td>
      <td>0.056003</td>
      <td>1.198264</td>
      <td>0.259040</td>
      <td>0.876440</td>
      <td>0.735081</td>
      <td>-1.034340</td>
      <td>0.073126</td>
      <td>0.256406</td>
      <td>-0.336644</td>
      <td>-0.995641</td>
      <td>0.401615</td>
      <td>-0.518597</td>
      <td>-0.054720</td>
      <td>1.059618</td>
      <td>0.532829</td>
      <td>-0.917543</td>
      <td>0.265598</td>
      <td>-0.036596</td>
      <td>-0.329362</td>
      <td>-1.222773</td>
      <td>-0.790088</td>
      <td>-0.003216</td>
      <td>0.464219</td>
      <td>0.105170</td>
      <td>-1.090799</td>
      <td>-0.365959</td>
      <td>...</td>
      <td>0.468889</td>
      <td>0.190685</td>
      <td>1.017187</td>
      <td>0.106309</td>
      <td>-0.509118</td>
      <td>-0.107559</td>
      <td>-0.056021</td>
      <td>-0.541596</td>
      <td>-0.066008</td>
      <td>0.293099</td>
      <td>0.159172</td>
      <td>-0.095078</td>
      <td>0.271284</td>
      <td>-0.678318</td>
      <td>0.637312</td>
      <td>0.508429</td>
      <td>0.236025</td>
      <td>0.056904</td>
      <td>-0.761553</td>
      <td>-0.276727</td>
      <td>0.353658</td>
      <td>0.164336</td>
      <td>0.520818</td>
      <td>1.079486</td>
      <td>0.915420</td>
      <td>0.357672</td>
      <td>-0.162896</td>
      <td>-1.148984</td>
      <td>-0.633046</td>
      <td>-0.516829</td>
      <td>-1.288651</td>
      <td>-0.422603</td>
      <td>-1.038236</td>
      <td>1.379082</td>
      <td>0.106050</td>
      <td>-0.058522</td>
      <td>-0.188580</td>
      <td>-2.994551</td>
      <td>-2.027189</td>
      <td>-1.523703</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-1.330168</td>
      <td>-0.365490</td>
      <td>-1.086015</td>
      <td>0.472291</td>
      <td>-1.057512</td>
      <td>-0.198510</td>
      <td>0.613616</td>
      <td>0.513766</td>
      <td>-1.205902</td>
      <td>0.240578</td>
      <td>-0.269202</td>
      <td>-0.716992</td>
      <td>-1.292023</td>
      <td>-1.041068</td>
      <td>-0.350301</td>
      <td>0.294744</td>
      <td>-1.309610</td>
      <td>-0.201493</td>
      <td>-0.113742</td>
      <td>-1.053414</td>
      <td>0.277817</td>
      <td>0.185691</td>
      <td>-0.133290</td>
      <td>0.458305</td>
      <td>-0.015619</td>
      <td>-0.615654</td>
      <td>0.293502</td>
      <td>0.335555</td>
      <td>0.004724</td>
      <td>-0.971386</td>
      <td>-0.802110</td>
      <td>1.057799</td>
      <td>1.017910</td>
      <td>-0.465911</td>
      <td>1.082822</td>
      <td>0.858394</td>
      <td>0.585877</td>
      <td>0.175059</td>
      <td>-1.236061</td>
      <td>-1.207055</td>
      <td>...</td>
      <td>-0.948658</td>
      <td>-0.357625</td>
      <td>0.325057</td>
      <td>0.027165</td>
      <td>-0.863678</td>
      <td>-0.506513</td>
      <td>-0.493573</td>
      <td>-0.115860</td>
      <td>0.260912</td>
      <td>1.304026</td>
      <td>0.215231</td>
      <td>-0.794572</td>
      <td>0.480978</td>
      <td>0.594881</td>
      <td>-0.334702</td>
      <td>0.727497</td>
      <td>0.087584</td>
      <td>0.101139</td>
      <td>-1.125588</td>
      <td>-0.032535</td>
      <td>0.292105</td>
      <td>-0.546618</td>
      <td>0.053025</td>
      <td>0.119857</td>
      <td>2.325417</td>
      <td>1.663594</td>
      <td>-0.547472</td>
      <td>0.068508</td>
      <td>0.254252</td>
      <td>-0.772577</td>
      <td>-1.096982</td>
      <td>-0.742898</td>
      <td>0.000224</td>
      <td>0.563262</td>
      <td>0.431785</td>
      <td>0.242709</td>
      <td>0.393102</td>
      <td>-0.848409</td>
      <td>-0.575152</td>
      <td>-0.493433</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.628358</td>
      <td>0.298505</td>
      <td>-0.809351</td>
      <td>-0.462264</td>
      <td>0.602552</td>
      <td>0.322326</td>
      <td>-0.400832</td>
      <td>0.211921</td>
      <td>0.234891</td>
      <td>0.304391</td>
      <td>-0.524822</td>
      <td>0.815116</td>
      <td>-0.836817</td>
      <td>-0.669418</td>
      <td>-0.153834</td>
      <td>-0.794226</td>
      <td>0.504676</td>
      <td>-0.085132</td>
      <td>0.378199</td>
      <td>0.510403</td>
      <td>-0.409856</td>
      <td>0.383004</td>
      <td>-0.826475</td>
      <td>-0.439367</td>
      <td>-0.505225</td>
      <td>-0.691895</td>
      <td>-0.958644</td>
      <td>-0.223344</td>
      <td>-0.473494</td>
      <td>-0.074485</td>
      <td>-0.765086</td>
      <td>0.170774</td>
      <td>0.162056</td>
      <td>-0.038647</td>
      <td>-1.361059</td>
      <td>-1.061261</td>
      <td>-0.028958</td>
      <td>0.255329</td>
      <td>0.151676</td>
      <td>0.099346</td>
      <td>...</td>
      <td>1.084985</td>
      <td>0.476857</td>
      <td>0.955541</td>
      <td>0.053678</td>
      <td>0.117784</td>
      <td>1.120548</td>
      <td>-0.000535</td>
      <td>-0.627902</td>
      <td>-0.729957</td>
      <td>0.112268</td>
      <td>0.868766</td>
      <td>0.750693</td>
      <td>0.202760</td>
      <td>-0.162821</td>
      <td>0.841441</td>
      <td>0.333997</td>
      <td>0.171823</td>
      <td>2.040605</td>
      <td>1.717646</td>
      <td>1.187029</td>
      <td>0.884541</td>
      <td>-0.237221</td>
      <td>-0.259733</td>
      <td>-0.606102</td>
      <td>0.039451</td>
      <td>0.875071</td>
      <td>1.177093</td>
      <td>0.583908</td>
      <td>0.441456</td>
      <td>-0.782687</td>
      <td>-0.436738</td>
      <td>-0.230734</td>
      <td>0.277357</td>
      <td>-0.484780</td>
      <td>-1.052616</td>
      <td>-1.516821</td>
      <td>0.272891</td>
      <td>-1.848230</td>
      <td>-1.921279</td>
      <td>-0.389130</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.384750</td>
      <td>0.234601</td>
      <td>0.037452</td>
      <td>0.777018</td>
      <td>1.004460</td>
      <td>-0.237783</td>
      <td>-1.130176</td>
      <td>-0.243937</td>
      <td>0.098738</td>
      <td>1.407877</td>
      <td>0.881590</td>
      <td>-0.206613</td>
      <td>-1.006780</td>
      <td>-0.224483</td>
      <td>0.008800</td>
      <td>-0.046138</td>
      <td>-1.691991</td>
      <td>-0.294407</td>
      <td>-0.220141</td>
      <td>0.497414</td>
      <td>0.801384</td>
      <td>0.777679</td>
      <td>-0.377399</td>
      <td>-0.219346</td>
      <td>0.241621</td>
      <td>-0.039338</td>
      <td>0.322915</td>
      <td>0.199223</td>
      <td>-0.654290</td>
      <td>1.019804</td>
      <td>1.074897</td>
      <td>0.221919</td>
      <td>-0.421427</td>
      <td>0.309504</td>
      <td>-0.118334</td>
      <td>-0.255926</td>
      <td>-0.346495</td>
      <td>0.153657</td>
      <td>0.192134</td>
      <td>0.057163</td>
      <td>...</td>
      <td>-0.318663</td>
      <td>-0.127778</td>
      <td>-0.325997</td>
      <td>-0.300622</td>
      <td>-0.357547</td>
      <td>-0.615471</td>
      <td>0.607798</td>
      <td>-0.240111</td>
      <td>-0.154813</td>
      <td>-0.078835</td>
      <td>-0.142571</td>
      <td>0.156919</td>
      <td>-0.311970</td>
      <td>-0.220605</td>
      <td>-0.875774</td>
      <td>-0.084154</td>
      <td>-0.570128</td>
      <td>-0.063930</td>
      <td>0.804879</td>
      <td>-0.335254</td>
      <td>0.427926</td>
      <td>-0.783743</td>
      <td>-0.071870</td>
      <td>0.116702</td>
      <td>1.246988</td>
      <td>0.496411</td>
      <td>1.389530</td>
      <td>0.228069</td>
      <td>-0.322963</td>
      <td>-0.613176</td>
      <td>1.099649</td>
      <td>0.004100</td>
      <td>-0.323396</td>
      <td>0.108597</td>
      <td>0.096110</td>
      <td>-0.680951</td>
      <td>0.171256</td>
      <td>-0.909766</td>
      <td>-0.780939</td>
      <td>-0.246662</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.201400</td>
      <td>0.119188</td>
      <td>0.243806</td>
      <td>-0.508301</td>
      <td>0.521877</td>
      <td>-0.415144</td>
      <td>-0.235102</td>
      <td>0.118762</td>
      <td>-0.227129</td>
      <td>0.395501</td>
      <td>0.027898</td>
      <td>0.026243</td>
      <td>-1.149709</td>
      <td>-0.754502</td>
      <td>1.029524</td>
      <td>0.781872</td>
      <td>0.116863</td>
      <td>0.744930</td>
      <td>1.506615</td>
      <td>-0.563693</td>
      <td>-1.348774</td>
      <td>0.485487</td>
      <td>0.236460</td>
      <td>0.033029</td>
      <td>0.195713</td>
      <td>-0.199048</td>
      <td>-0.837079</td>
      <td>0.025705</td>
      <td>-0.130339</td>
      <td>0.670905</td>
      <td>-0.329783</td>
      <td>0.656821</td>
      <td>1.277206</td>
      <td>0.847529</td>
      <td>0.160357</td>
      <td>-0.428613</td>
      <td>-0.029159</td>
      <td>0.405579</td>
      <td>0.199194</td>
      <td>0.286439</td>
      <td>...</td>
      <td>0.140498</td>
      <td>0.014592</td>
      <td>-0.768848</td>
      <td>-0.041073</td>
      <td>-0.793638</td>
      <td>0.815705</td>
      <td>0.966314</td>
      <td>0.432577</td>
      <td>0.865015</td>
      <td>0.687867</td>
      <td>0.003803</td>
      <td>0.487610</td>
      <td>0.991117</td>
      <td>0.492589</td>
      <td>-0.754744</td>
      <td>-0.048442</td>
      <td>-0.746977</td>
      <td>-0.234911</td>
      <td>0.088825</td>
      <td>1.153813</td>
      <td>-0.519645</td>
      <td>-0.917881</td>
      <td>0.254908</td>
      <td>-0.585293</td>
      <td>0.316060</td>
      <td>0.083174</td>
      <td>0.675664</td>
      <td>-0.874387</td>
      <td>-0.071099</td>
      <td>-0.389598</td>
      <td>0.055239</td>
      <td>0.406565</td>
      <td>0.061842</td>
      <td>0.038470</td>
      <td>0.855072</td>
      <td>0.533719</td>
      <td>-0.883163</td>
      <td>-1.422025</td>
      <td>-1.091836</td>
      <td>0.258429</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.094341</td>
      <td>-0.350003</td>
      <td>-1.498352</td>
      <td>0.025821</td>
      <td>-0.143610</td>
      <td>-0.111369</td>
      <td>-0.487137</td>
      <td>0.534506</td>
      <td>0.008249</td>
      <td>0.235584</td>
      <td>0.248750</td>
      <td>-0.079348</td>
      <td>-0.007232</td>
      <td>-0.891630</td>
      <td>-0.625773</td>
      <td>-0.498353</td>
      <td>-0.584227</td>
      <td>-1.196940</td>
      <td>0.573762</td>
      <td>-0.122298</td>
      <td>0.276700</td>
      <td>0.124479</td>
      <td>0.332126</td>
      <td>-0.132040</td>
      <td>-0.964230</td>
      <td>-1.213466</td>
      <td>-0.859307</td>
      <td>0.714228</td>
      <td>-0.436098</td>
      <td>0.730465</td>
      <td>-1.309969</td>
      <td>-0.584145</td>
      <td>0.418664</td>
      <td>-0.237577</td>
      <td>-0.613853</td>
      <td>-0.625171</td>
      <td>1.072405</td>
      <td>0.337753</td>
      <td>0.129692</td>
      <td>-0.710506</td>
      <td>...</td>
      <td>0.019575</td>
      <td>0.149291</td>
      <td>-0.193190</td>
      <td>0.660164</td>
      <td>0.295893</td>
      <td>-0.736782</td>
      <td>-0.102007</td>
      <td>0.330421</td>
      <td>0.314769</td>
      <td>-1.755860</td>
      <td>0.153244</td>
      <td>0.410010</td>
      <td>0.881196</td>
      <td>-0.241677</td>
      <td>0.251754</td>
      <td>0.240306</td>
      <td>-0.564755</td>
      <td>0.113064</td>
      <td>-0.126067</td>
      <td>0.011943</td>
      <td>0.384345</td>
      <td>0.142745</td>
      <td>0.198169</td>
      <td>-0.281762</td>
      <td>-0.108712</td>
      <td>-0.260228</td>
      <td>-0.028088</td>
      <td>0.078275</td>
      <td>-0.069809</td>
      <td>-0.307355</td>
      <td>0.733824</td>
      <td>0.089625</td>
      <td>0.350731</td>
      <td>-0.175931</td>
      <td>0.093443</td>
      <td>0.508976</td>
      <td>0.519456</td>
      <td>-2.001715</td>
      <td>-1.165774</td>
      <td>-0.239347</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.762105</td>
      <td>0.452426</td>
      <td>-0.530219</td>
      <td>0.958327</td>
      <td>-0.096549</td>
      <td>-0.760172</td>
      <td>-0.382466</td>
      <td>-0.810666</td>
      <td>0.011155</td>
      <td>0.878425</td>
      <td>0.160958</td>
      <td>-0.332182</td>
      <td>-0.462818</td>
      <td>0.186856</td>
      <td>-0.308504</td>
      <td>-0.122182</td>
      <td>0.052557</td>
      <td>-0.450386</td>
      <td>0.211248</td>
      <td>-1.149841</td>
      <td>0.113962</td>
      <td>-0.477033</td>
      <td>-0.412808</td>
      <td>0.271380</td>
      <td>0.663514</td>
      <td>-0.878026</td>
      <td>-1.312751</td>
      <td>-0.025648</td>
      <td>-0.981818</td>
      <td>-0.586436</td>
      <td>-0.293807</td>
      <td>0.151191</td>
      <td>0.330745</td>
      <td>0.320872</td>
      <td>0.522369</td>
      <td>0.804378</td>
      <td>0.516453</td>
      <td>0.697290</td>
      <td>0.194179</td>
      <td>-0.525367</td>
      <td>...</td>
      <td>-0.794036</td>
      <td>0.651730</td>
      <td>0.135491</td>
      <td>0.086629</td>
      <td>-0.804394</td>
      <td>1.171323</td>
      <td>0.725261</td>
      <td>0.033501</td>
      <td>0.773435</td>
      <td>-0.168460</td>
      <td>-0.368467</td>
      <td>-0.270676</td>
      <td>0.880041</td>
      <td>0.144007</td>
      <td>-0.234892</td>
      <td>0.112889</td>
      <td>0.378191</td>
      <td>0.576707</td>
      <td>0.076635</td>
      <td>0.403891</td>
      <td>0.182720</td>
      <td>0.055305</td>
      <td>-0.632985</td>
      <td>-0.142697</td>
      <td>-0.190473</td>
      <td>-0.815669</td>
      <td>0.932065</td>
      <td>0.255335</td>
      <td>0.103260</td>
      <td>-0.992551</td>
      <td>0.194712</td>
      <td>-0.289950</td>
      <td>-0.208796</td>
      <td>0.108716</td>
      <td>0.282039</td>
      <td>-0.365655</td>
      <td>0.941497</td>
      <td>-1.756903</td>
      <td>-1.860492</td>
      <td>-0.666775</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f600d023ca0&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.175242  0.034085  34.480058  1.596636e-260  1.108438  1.242047
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.136 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>