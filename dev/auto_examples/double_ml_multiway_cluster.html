
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.337186</td>
      <td>0.118118</td>
      <td>0.220959</td>
      <td>-0.129128</td>
      <td>-0.970874</td>
      <td>-0.658806</td>
      <td>0.350543</td>
      <td>0.255250</td>
      <td>0.400029</td>
      <td>0.262795</td>
      <td>0.382286</td>
      <td>0.945649</td>
      <td>-1.106777</td>
      <td>-0.369709</td>
      <td>-0.174117</td>
      <td>-0.233469</td>
      <td>-1.174460</td>
      <td>0.773983</td>
      <td>-0.187804</td>
      <td>-0.575232</td>
      <td>-0.318869</td>
      <td>-0.726179</td>
      <td>-0.076410</td>
      <td>-0.524991</td>
      <td>0.536194</td>
      <td>0.098343</td>
      <td>-0.085814</td>
      <td>0.093893</td>
      <td>0.546948</td>
      <td>-0.428640</td>
      <td>-0.764169</td>
      <td>-1.080101</td>
      <td>-0.689923</td>
      <td>-0.049403</td>
      <td>0.002093</td>
      <td>0.096515</td>
      <td>0.942540</td>
      <td>0.564721</td>
      <td>0.670901</td>
      <td>-0.141782</td>
      <td>...</td>
      <td>1.214333</td>
      <td>0.178215</td>
      <td>-1.568541</td>
      <td>0.106277</td>
      <td>-0.795573</td>
      <td>-1.269555</td>
      <td>-0.159358</td>
      <td>0.041015</td>
      <td>-0.479469</td>
      <td>-0.337814</td>
      <td>-0.158973</td>
      <td>-0.270393</td>
      <td>-0.363701</td>
      <td>0.047666</td>
      <td>-0.835422</td>
      <td>0.270873</td>
      <td>0.816566</td>
      <td>0.436626</td>
      <td>1.278770</td>
      <td>-0.128442</td>
      <td>-0.435285</td>
      <td>0.508290</td>
      <td>-0.705966</td>
      <td>0.325348</td>
      <td>-0.638954</td>
      <td>-0.588624</td>
      <td>-0.380141</td>
      <td>0.078913</td>
      <td>0.087372</td>
      <td>-0.062870</td>
      <td>-0.104421</td>
      <td>-0.570052</td>
      <td>0.225713</td>
      <td>-0.668523</td>
      <td>0.169585</td>
      <td>-0.109054</td>
      <td>0.686772</td>
      <td>0.824310</td>
      <td>0.190482</td>
      <td>0.189840</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.950626</td>
      <td>-0.191650</td>
      <td>0.848108</td>
      <td>-0.105336</td>
      <td>0.045649</td>
      <td>-0.839826</td>
      <td>0.184505</td>
      <td>-0.613693</td>
      <td>-0.897622</td>
      <td>0.259575</td>
      <td>0.747572</td>
      <td>0.923911</td>
      <td>-0.933583</td>
      <td>-1.227856</td>
      <td>-1.549392</td>
      <td>-0.747114</td>
      <td>-0.278807</td>
      <td>-0.103095</td>
      <td>0.614760</td>
      <td>0.076150</td>
      <td>0.554353</td>
      <td>0.054315</td>
      <td>0.410140</td>
      <td>-0.173540</td>
      <td>-0.549305</td>
      <td>0.371000</td>
      <td>0.065192</td>
      <td>-0.060375</td>
      <td>0.201172</td>
      <td>0.167012</td>
      <td>-0.615488</td>
      <td>0.552507</td>
      <td>-0.333564</td>
      <td>-0.342115</td>
      <td>-0.016298</td>
      <td>0.700855</td>
      <td>0.363647</td>
      <td>0.026637</td>
      <td>0.960877</td>
      <td>1.265941</td>
      <td>...</td>
      <td>0.378292</td>
      <td>-0.624526</td>
      <td>-0.694850</td>
      <td>-0.252419</td>
      <td>0.594477</td>
      <td>-0.233722</td>
      <td>-0.253811</td>
      <td>0.235948</td>
      <td>-0.243739</td>
      <td>0.321234</td>
      <td>-0.246121</td>
      <td>-0.135978</td>
      <td>-0.286441</td>
      <td>0.074661</td>
      <td>0.267803</td>
      <td>0.604020</td>
      <td>0.270962</td>
      <td>-0.796419</td>
      <td>0.375168</td>
      <td>0.053526</td>
      <td>-0.425376</td>
      <td>1.141629</td>
      <td>0.345440</td>
      <td>0.451244</td>
      <td>-0.497820</td>
      <td>-1.487615</td>
      <td>-0.750500</td>
      <td>0.302596</td>
      <td>0.101802</td>
      <td>-0.531980</td>
      <td>0.068970</td>
      <td>-0.655513</td>
      <td>-0.085312</td>
      <td>0.249477</td>
      <td>-0.448427</td>
      <td>-0.159012</td>
      <td>0.775081</td>
      <td>0.877020</td>
      <td>1.255003</td>
      <td>0.921570</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.648468</td>
      <td>-0.800148</td>
      <td>0.352240</td>
      <td>0.065755</td>
      <td>-0.173509</td>
      <td>-0.472788</td>
      <td>-0.682557</td>
      <td>-0.705125</td>
      <td>-0.029125</td>
      <td>0.395111</td>
      <td>0.438207</td>
      <td>0.100261</td>
      <td>0.129798</td>
      <td>0.288451</td>
      <td>1.094692</td>
      <td>-0.336617</td>
      <td>0.340320</td>
      <td>0.697818</td>
      <td>0.282497</td>
      <td>-0.397183</td>
      <td>0.080308</td>
      <td>0.160700</td>
      <td>0.265529</td>
      <td>-0.746373</td>
      <td>0.437436</td>
      <td>1.040954</td>
      <td>0.262351</td>
      <td>1.194887</td>
      <td>0.720009</td>
      <td>0.058894</td>
      <td>-0.079710</td>
      <td>0.063516</td>
      <td>-0.420561</td>
      <td>-0.451189</td>
      <td>-0.449075</td>
      <td>0.436699</td>
      <td>0.853552</td>
      <td>-0.257615</td>
      <td>0.068506</td>
      <td>-0.289470</td>
      <td>...</td>
      <td>1.138492</td>
      <td>0.743163</td>
      <td>-0.177485</td>
      <td>-0.259988</td>
      <td>-0.441130</td>
      <td>-0.940998</td>
      <td>0.164983</td>
      <td>0.051297</td>
      <td>0.979855</td>
      <td>-0.215043</td>
      <td>0.202178</td>
      <td>0.790817</td>
      <td>0.388454</td>
      <td>0.141665</td>
      <td>0.069547</td>
      <td>-0.136148</td>
      <td>-0.353837</td>
      <td>-0.294297</td>
      <td>0.269658</td>
      <td>0.371797</td>
      <td>0.107603</td>
      <td>0.455809</td>
      <td>0.468232</td>
      <td>0.496975</td>
      <td>-0.319762</td>
      <td>0.002959</td>
      <td>0.748374</td>
      <td>0.071450</td>
      <td>0.221178</td>
      <td>-0.846496</td>
      <td>0.526389</td>
      <td>-1.277727</td>
      <td>-0.736254</td>
      <td>0.249101</td>
      <td>0.000255</td>
      <td>0.092434</td>
      <td>0.593003</td>
      <td>0.170635</td>
      <td>0.230307</td>
      <td>0.482560</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.042450</td>
      <td>0.262637</td>
      <td>0.202667</td>
      <td>-0.186838</td>
      <td>0.133824</td>
      <td>0.162364</td>
      <td>1.060191</td>
      <td>1.337674</td>
      <td>-0.205966</td>
      <td>0.708570</td>
      <td>1.199563</td>
      <td>1.134809</td>
      <td>0.441649</td>
      <td>-1.302544</td>
      <td>-0.788504</td>
      <td>-1.056257</td>
      <td>0.316604</td>
      <td>0.257627</td>
      <td>1.460378</td>
      <td>-0.001220</td>
      <td>-1.586809</td>
      <td>-1.989966</td>
      <td>-0.093903</td>
      <td>-0.649906</td>
      <td>0.454549</td>
      <td>0.353547</td>
      <td>0.006686</td>
      <td>0.675703</td>
      <td>0.871705</td>
      <td>1.168438</td>
      <td>0.103595</td>
      <td>-0.133779</td>
      <td>-0.277992</td>
      <td>-0.389839</td>
      <td>0.351888</td>
      <td>-0.385591</td>
      <td>1.056621</td>
      <td>0.114609</td>
      <td>0.941154</td>
      <td>0.835054</td>
      <td>...</td>
      <td>0.543530</td>
      <td>0.711207</td>
      <td>-0.792782</td>
      <td>-0.321907</td>
      <td>-0.271651</td>
      <td>-0.030691</td>
      <td>0.162177</td>
      <td>-0.458178</td>
      <td>-0.017713</td>
      <td>-0.134979</td>
      <td>0.021984</td>
      <td>0.188864</td>
      <td>0.495256</td>
      <td>-0.024368</td>
      <td>-0.288547</td>
      <td>0.010501</td>
      <td>0.449773</td>
      <td>-0.172497</td>
      <td>-1.056677</td>
      <td>0.427129</td>
      <td>-0.164267</td>
      <td>0.843291</td>
      <td>0.251651</td>
      <td>-0.185593</td>
      <td>-0.047535</td>
      <td>0.720789</td>
      <td>1.343246</td>
      <td>-0.359482</td>
      <td>0.043626</td>
      <td>0.063083</td>
      <td>-0.663147</td>
      <td>-0.051956</td>
      <td>-0.033972</td>
      <td>0.228387</td>
      <td>0.787411</td>
      <td>0.471161</td>
      <td>0.006003</td>
      <td>0.932887</td>
      <td>0.433893</td>
      <td>0.847053</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.476186</td>
      <td>0.921755</td>
      <td>1.691053</td>
      <td>0.378012</td>
      <td>-0.151336</td>
      <td>-0.079079</td>
      <td>0.366736</td>
      <td>0.187126</td>
      <td>0.915517</td>
      <td>-1.089325</td>
      <td>0.126539</td>
      <td>-0.112563</td>
      <td>0.273684</td>
      <td>-0.348607</td>
      <td>-0.004607</td>
      <td>-0.455150</td>
      <td>-0.026985</td>
      <td>-0.186037</td>
      <td>0.378752</td>
      <td>0.751287</td>
      <td>1.004412</td>
      <td>0.771567</td>
      <td>0.405549</td>
      <td>-0.010752</td>
      <td>1.109027</td>
      <td>1.488548</td>
      <td>-0.715621</td>
      <td>0.696153</td>
      <td>0.533801</td>
      <td>0.019987</td>
      <td>-0.077897</td>
      <td>0.224063</td>
      <td>-0.726143</td>
      <td>-0.383165</td>
      <td>-0.707149</td>
      <td>-0.206249</td>
      <td>0.458439</td>
      <td>-0.259612</td>
      <td>0.360704</td>
      <td>-0.522780</td>
      <td>...</td>
      <td>0.335454</td>
      <td>0.486071</td>
      <td>-0.549224</td>
      <td>0.176707</td>
      <td>1.954350</td>
      <td>0.924610</td>
      <td>0.748530</td>
      <td>-0.068177</td>
      <td>1.075587</td>
      <td>0.818965</td>
      <td>-0.231873</td>
      <td>-0.556666</td>
      <td>0.014657</td>
      <td>-0.241598</td>
      <td>-0.892593</td>
      <td>-0.513522</td>
      <td>0.565199</td>
      <td>0.040605</td>
      <td>0.008105</td>
      <td>0.242756</td>
      <td>-0.996957</td>
      <td>0.062628</td>
      <td>0.445565</td>
      <td>-0.104000</td>
      <td>-0.047683</td>
      <td>-0.296772</td>
      <td>-0.082440</td>
      <td>-0.690078</td>
      <td>0.195226</td>
      <td>0.611014</td>
      <td>0.209482</td>
      <td>-0.296524</td>
      <td>0.431535</td>
      <td>0.074509</td>
      <td>0.065988</td>
      <td>0.884875</td>
      <td>0.813489</td>
      <td>0.727422</td>
      <td>0.150544</td>
      <td>0.632523</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.251084</td>
      <td>-1.056855</td>
      <td>0.306669</td>
      <td>0.442744</td>
      <td>0.091437</td>
      <td>-0.088217</td>
      <td>-0.298902</td>
      <td>0.774666</td>
      <td>-0.098305</td>
      <td>0.811718</td>
      <td>1.137012</td>
      <td>1.311547</td>
      <td>0.304945</td>
      <td>0.457026</td>
      <td>0.284801</td>
      <td>-0.548270</td>
      <td>0.040641</td>
      <td>-0.173491</td>
      <td>0.682948</td>
      <td>0.114386</td>
      <td>-0.220271</td>
      <td>0.017231</td>
      <td>0.075067</td>
      <td>0.822999</td>
      <td>0.398175</td>
      <td>0.573949</td>
      <td>-0.064684</td>
      <td>1.257869</td>
      <td>-0.412209</td>
      <td>-1.404169</td>
      <td>-0.135429</td>
      <td>-0.099681</td>
      <td>-0.523765</td>
      <td>-0.618346</td>
      <td>-0.691781</td>
      <td>0.376618</td>
      <td>0.918836</td>
      <td>-0.813737</td>
      <td>0.283495</td>
      <td>0.202904</td>
      <td>...</td>
      <td>0.566063</td>
      <td>-0.392487</td>
      <td>-1.330472</td>
      <td>0.643476</td>
      <td>0.240686</td>
      <td>1.276315</td>
      <td>-0.711217</td>
      <td>-0.529025</td>
      <td>-1.143468</td>
      <td>-0.713768</td>
      <td>-0.087227</td>
      <td>-0.225136</td>
      <td>0.337059</td>
      <td>0.255370</td>
      <td>0.199099</td>
      <td>1.119718</td>
      <td>0.210710</td>
      <td>-0.324167</td>
      <td>0.474689</td>
      <td>0.796026</td>
      <td>-0.018768</td>
      <td>-0.138833</td>
      <td>0.688060</td>
      <td>0.220507</td>
      <td>-0.062083</td>
      <td>-0.734462</td>
      <td>0.549508</td>
      <td>-0.325195</td>
      <td>-0.018317</td>
      <td>-0.227139</td>
      <td>0.581941</td>
      <td>-0.417358</td>
      <td>-0.456943</td>
      <td>0.189993</td>
      <td>-0.001429</td>
      <td>-0.027092</td>
      <td>-0.320274</td>
      <td>-0.525654</td>
      <td>-0.362755</td>
      <td>-0.482232</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.203069</td>
      <td>-0.362636</td>
      <td>0.794021</td>
      <td>-0.297016</td>
      <td>-0.449205</td>
      <td>-0.636793</td>
      <td>0.076097</td>
      <td>-0.084871</td>
      <td>-0.865807</td>
      <td>-0.924305</td>
      <td>-0.654078</td>
      <td>-0.523391</td>
      <td>-1.054250</td>
      <td>-0.623452</td>
      <td>-0.580942</td>
      <td>-0.185201</td>
      <td>0.781658</td>
      <td>0.224771</td>
      <td>-0.112358</td>
      <td>0.187857</td>
      <td>-0.121810</td>
      <td>-0.672575</td>
      <td>-0.076622</td>
      <td>-1.193081</td>
      <td>0.598710</td>
      <td>1.182385</td>
      <td>0.511162</td>
      <td>0.628478</td>
      <td>-0.215638</td>
      <td>0.076353</td>
      <td>-0.848972</td>
      <td>0.854426</td>
      <td>0.274539</td>
      <td>0.627913</td>
      <td>-0.324136</td>
      <td>-0.155490</td>
      <td>1.487544</td>
      <td>0.096494</td>
      <td>0.658923</td>
      <td>0.020990</td>
      <td>...</td>
      <td>0.709073</td>
      <td>-0.420709</td>
      <td>-1.579625</td>
      <td>-0.379904</td>
      <td>0.005366</td>
      <td>-0.482818</td>
      <td>-0.173163</td>
      <td>-0.680651</td>
      <td>-0.197125</td>
      <td>0.002500</td>
      <td>0.435778</td>
      <td>-0.510590</td>
      <td>0.379068</td>
      <td>0.565202</td>
      <td>0.708957</td>
      <td>0.197542</td>
      <td>0.262177</td>
      <td>1.000439</td>
      <td>0.661100</td>
      <td>0.381208</td>
      <td>-0.298809</td>
      <td>0.052255</td>
      <td>0.095760</td>
      <td>0.560899</td>
      <td>-0.233926</td>
      <td>-0.537595</td>
      <td>-0.360296</td>
      <td>0.014298</td>
      <td>-0.039206</td>
      <td>0.153074</td>
      <td>-1.003186</td>
      <td>-0.120193</td>
      <td>-0.269921</td>
      <td>-0.636441</td>
      <td>-0.843687</td>
      <td>-0.253401</td>
      <td>0.718787</td>
      <td>1.546351</td>
      <td>-0.078241</td>
      <td>-0.048582</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.836826</td>
      <td>0.781476</td>
      <td>1.045482</td>
      <td>0.870822</td>
      <td>-0.335689</td>
      <td>-0.441173</td>
      <td>0.331558</td>
      <td>0.186596</td>
      <td>1.751862</td>
      <td>1.921646</td>
      <td>0.598797</td>
      <td>-0.072399</td>
      <td>0.362340</td>
      <td>-0.941454</td>
      <td>0.127693</td>
      <td>-0.069468</td>
      <td>-0.569418</td>
      <td>-0.506634</td>
      <td>0.739284</td>
      <td>0.219119</td>
      <td>-0.453007</td>
      <td>-0.779176</td>
      <td>-0.231818</td>
      <td>0.473824</td>
      <td>0.748565</td>
      <td>0.797665</td>
      <td>-0.119565</td>
      <td>0.444056</td>
      <td>-0.907137</td>
      <td>-0.053926</td>
      <td>-0.202065</td>
      <td>-0.167355</td>
      <td>-0.238560</td>
      <td>-0.223138</td>
      <td>0.182453</td>
      <td>0.606804</td>
      <td>0.107884</td>
      <td>0.067736</td>
      <td>0.441144</td>
      <td>-1.359927</td>
      <td>...</td>
      <td>0.390910</td>
      <td>0.455996</td>
      <td>-0.447871</td>
      <td>-0.264141</td>
      <td>0.109365</td>
      <td>-0.373377</td>
      <td>-0.922901</td>
      <td>-0.777054</td>
      <td>0.341528</td>
      <td>-0.215274</td>
      <td>-0.167891</td>
      <td>-0.139343</td>
      <td>-0.484306</td>
      <td>0.591427</td>
      <td>0.231803</td>
      <td>0.110974</td>
      <td>0.038036</td>
      <td>-0.101678</td>
      <td>0.065887</td>
      <td>0.496879</td>
      <td>0.251303</td>
      <td>0.629860</td>
      <td>-0.490728</td>
      <td>-0.089004</td>
      <td>-0.489797</td>
      <td>-1.388670</td>
      <td>-0.678524</td>
      <td>0.480262</td>
      <td>-0.379191</td>
      <td>-0.218554</td>
      <td>-0.265540</td>
      <td>-0.772788</td>
      <td>0.068303</td>
      <td>0.082604</td>
      <td>-0.533977</td>
      <td>-1.513702</td>
      <td>-0.156662</td>
      <td>1.322420</td>
      <td>1.289085</td>
      <td>1.083572</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1.236574</td>
      <td>0.245473</td>
      <td>0.526449</td>
      <td>0.730620</td>
      <td>1.100907</td>
      <td>-0.548274</td>
      <td>1.082595</td>
      <td>0.730451</td>
      <td>0.820594</td>
      <td>1.174787</td>
      <td>-0.012072</td>
      <td>-0.063049</td>
      <td>-0.480410</td>
      <td>0.626418</td>
      <td>0.986997</td>
      <td>-0.744392</td>
      <td>-0.381802</td>
      <td>0.955330</td>
      <td>0.003158</td>
      <td>0.459799</td>
      <td>0.284926</td>
      <td>-0.479719</td>
      <td>-0.352979</td>
      <td>0.031993</td>
      <td>0.319614</td>
      <td>0.543524</td>
      <td>0.476122</td>
      <td>0.303898</td>
      <td>0.364320</td>
      <td>-0.077558</td>
      <td>0.583044</td>
      <td>0.673101</td>
      <td>-0.024135</td>
      <td>0.288197</td>
      <td>-0.842646</td>
      <td>0.312899</td>
      <td>0.418253</td>
      <td>-0.197571</td>
      <td>0.095501</td>
      <td>0.023272</td>
      <td>...</td>
      <td>1.209098</td>
      <td>-0.124944</td>
      <td>-0.468292</td>
      <td>0.364825</td>
      <td>0.688386</td>
      <td>0.678149</td>
      <td>-0.079720</td>
      <td>0.758482</td>
      <td>-0.270568</td>
      <td>0.127203</td>
      <td>-0.621730</td>
      <td>-0.018343</td>
      <td>-0.132399</td>
      <td>-0.367767</td>
      <td>-0.119134</td>
      <td>-0.009814</td>
      <td>1.265359</td>
      <td>0.631065</td>
      <td>0.756549</td>
      <td>0.885996</td>
      <td>-0.029267</td>
      <td>0.167197</td>
      <td>-0.529156</td>
      <td>-0.444090</td>
      <td>0.621690</td>
      <td>-1.382083</td>
      <td>-0.207421</td>
      <td>0.881000</td>
      <td>-0.344185</td>
      <td>0.400059</td>
      <td>0.587638</td>
      <td>-1.054600</td>
      <td>0.402252</td>
      <td>0.107883</td>
      <td>-0.382359</td>
      <td>-0.879774</td>
      <td>0.535761</td>
      <td>2.703228</td>
      <td>1.241090</td>
      <td>2.058177</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-0.214582</td>
      <td>-1.174350</td>
      <td>-1.023885</td>
      <td>-0.141410</td>
      <td>-0.628520</td>
      <td>-1.131406</td>
      <td>0.638062</td>
      <td>-0.354771</td>
      <td>-0.304426</td>
      <td>-0.753677</td>
      <td>1.059807</td>
      <td>1.058584</td>
      <td>0.817395</td>
      <td>-0.056485</td>
      <td>0.079745</td>
      <td>0.012280</td>
      <td>0.134733</td>
      <td>0.260933</td>
      <td>0.234300</td>
      <td>0.368653</td>
      <td>0.084060</td>
      <td>0.437699</td>
      <td>-0.087156</td>
      <td>0.256896</td>
      <td>-0.385992</td>
      <td>-0.230697</td>
      <td>-1.502915</td>
      <td>-0.238455</td>
      <td>-0.232778</td>
      <td>0.530164</td>
      <td>-0.891217</td>
      <td>0.127000</td>
      <td>0.132952</td>
      <td>0.128088</td>
      <td>0.207504</td>
      <td>0.006807</td>
      <td>0.422001</td>
      <td>-0.558766</td>
      <td>0.525436</td>
      <td>-0.247980</td>
      <td>...</td>
      <td>0.501633</td>
      <td>-1.276473</td>
      <td>-0.592783</td>
      <td>-0.443704</td>
      <td>-1.263641</td>
      <td>0.075540</td>
      <td>-0.160270</td>
      <td>-0.401515</td>
      <td>0.144006</td>
      <td>0.130318</td>
      <td>0.474964</td>
      <td>0.410655</td>
      <td>0.808522</td>
      <td>-0.119675</td>
      <td>-0.698429</td>
      <td>0.575265</td>
      <td>-0.417416</td>
      <td>-1.130728</td>
      <td>-0.152219</td>
      <td>-0.035092</td>
      <td>0.819354</td>
      <td>-0.030453</td>
      <td>-0.244052</td>
      <td>0.794378</td>
      <td>0.688646</td>
      <td>-0.090819</td>
      <td>-0.784575</td>
      <td>0.185919</td>
      <td>0.341932</td>
      <td>-0.015737</td>
      <td>0.350084</td>
      <td>0.002839</td>
      <td>-0.145925</td>
      <td>-0.255959</td>
      <td>-0.777074</td>
      <td>-0.079189</td>
      <td>1.341053</td>
      <td>-1.471820</td>
      <td>-1.552744</td>
      <td>-1.021596</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.625921</td>
      <td>-0.165477</td>
      <td>-0.258464</td>
      <td>-0.123810</td>
      <td>-0.236603</td>
      <td>-0.064522</td>
      <td>-0.517034</td>
      <td>-0.119096</td>
      <td>-0.063478</td>
      <td>0.241229</td>
      <td>0.662917</td>
      <td>1.120035</td>
      <td>-0.457965</td>
      <td>-1.009444</td>
      <td>-0.482305</td>
      <td>-0.339750</td>
      <td>-0.775750</td>
      <td>-0.842905</td>
      <td>0.301057</td>
      <td>0.073643</td>
      <td>0.606655</td>
      <td>0.253437</td>
      <td>-0.731862</td>
      <td>0.121181</td>
      <td>-0.363071</td>
      <td>1.065266</td>
      <td>0.329757</td>
      <td>1.690549</td>
      <td>1.004431</td>
      <td>0.631951</td>
      <td>0.585907</td>
      <td>0.767954</td>
      <td>0.403405</td>
      <td>0.154361</td>
      <td>0.289577</td>
      <td>-0.336096</td>
      <td>0.291069</td>
      <td>-0.801416</td>
      <td>0.577525</td>
      <td>0.009158</td>
      <td>...</td>
      <td>0.604944</td>
      <td>-1.015293</td>
      <td>0.002972</td>
      <td>0.822467</td>
      <td>0.069419</td>
      <td>-0.217713</td>
      <td>-0.416306</td>
      <td>0.530602</td>
      <td>0.715767</td>
      <td>-0.930978</td>
      <td>-0.439135</td>
      <td>-0.464794</td>
      <td>0.797984</td>
      <td>0.965106</td>
      <td>1.650198</td>
      <td>0.525141</td>
      <td>2.131888</td>
      <td>1.076997</td>
      <td>0.683797</td>
      <td>0.324456</td>
      <td>0.016129</td>
      <td>-0.241966</td>
      <td>-0.308583</td>
      <td>-0.432106</td>
      <td>0.383335</td>
      <td>0.447368</td>
      <td>0.622186</td>
      <td>-0.306704</td>
      <td>-0.883701</td>
      <td>0.230940</td>
      <td>0.416416</td>
      <td>0.040918</td>
      <td>1.257280</td>
      <td>-0.268000</td>
      <td>0.544408</td>
      <td>-0.209237</td>
      <td>0.503572</td>
      <td>0.936250</td>
      <td>0.671893</td>
      <td>0.121713</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.402470</td>
      <td>-0.191322</td>
      <td>0.179981</td>
      <td>0.017421</td>
      <td>-0.259590</td>
      <td>-0.267743</td>
      <td>-0.249579</td>
      <td>0.743399</td>
      <td>-0.740804</td>
      <td>0.250394</td>
      <td>-0.038243</td>
      <td>-0.060915</td>
      <td>-0.848068</td>
      <td>0.209971</td>
      <td>0.011437</td>
      <td>-0.510300</td>
      <td>-0.251549</td>
      <td>-0.340771</td>
      <td>-0.073713</td>
      <td>0.507320</td>
      <td>0.077630</td>
      <td>0.697973</td>
      <td>0.297013</td>
      <td>-0.811796</td>
      <td>0.947043</td>
      <td>1.129017</td>
      <td>-0.469855</td>
      <td>-0.742146</td>
      <td>-1.410214</td>
      <td>-0.122418</td>
      <td>-0.257387</td>
      <td>0.349560</td>
      <td>-0.344727</td>
      <td>0.631374</td>
      <td>0.540465</td>
      <td>0.010676</td>
      <td>0.450184</td>
      <td>-0.088892</td>
      <td>0.895621</td>
      <td>0.014957</td>
      <td>...</td>
      <td>0.625602</td>
      <td>0.257290</td>
      <td>-0.168885</td>
      <td>1.381643</td>
      <td>0.901848</td>
      <td>-0.512045</td>
      <td>-0.208629</td>
      <td>0.435073</td>
      <td>0.130138</td>
      <td>0.534336</td>
      <td>0.826725</td>
      <td>1.325786</td>
      <td>0.037974</td>
      <td>0.184891</td>
      <td>-0.004187</td>
      <td>-0.415426</td>
      <td>-0.451308</td>
      <td>-0.098996</td>
      <td>0.917419</td>
      <td>-0.152028</td>
      <td>-0.501618</td>
      <td>-0.679319</td>
      <td>-0.214511</td>
      <td>-0.211624</td>
      <td>0.213518</td>
      <td>0.610738</td>
      <td>-0.699657</td>
      <td>-0.584516</td>
      <td>-0.611222</td>
      <td>-0.504238</td>
      <td>-1.329107</td>
      <td>-1.038580</td>
      <td>-0.950682</td>
      <td>-0.490433</td>
      <td>-0.514434</td>
      <td>0.502619</td>
      <td>-0.962772</td>
      <td>0.996892</td>
      <td>1.558184</td>
      <td>1.016762</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.115067</td>
      <td>-1.033669</td>
      <td>1.204843</td>
      <td>0.174114</td>
      <td>-0.760185</td>
      <td>-0.540638</td>
      <td>-0.319782</td>
      <td>0.361438</td>
      <td>0.064168</td>
      <td>1.007677</td>
      <td>0.808152</td>
      <td>-0.121181</td>
      <td>-0.293283</td>
      <td>-0.171518</td>
      <td>0.181969</td>
      <td>-0.498778</td>
      <td>0.431061</td>
      <td>1.511745</td>
      <td>1.208782</td>
      <td>0.659849</td>
      <td>-0.102130</td>
      <td>0.239186</td>
      <td>0.124491</td>
      <td>-0.167674</td>
      <td>-0.136431</td>
      <td>0.197375</td>
      <td>-0.149487</td>
      <td>-0.556326</td>
      <td>0.027473</td>
      <td>-0.983180</td>
      <td>-0.183019</td>
      <td>1.397264</td>
      <td>-0.553994</td>
      <td>0.206508</td>
      <td>0.338311</td>
      <td>0.226653</td>
      <td>0.346103</td>
      <td>-0.235698</td>
      <td>-0.336747</td>
      <td>-0.325727</td>
      <td>...</td>
      <td>-0.769325</td>
      <td>-0.170155</td>
      <td>-0.631333</td>
      <td>-1.174254</td>
      <td>-0.137618</td>
      <td>0.165227</td>
      <td>-0.203434</td>
      <td>-0.067143</td>
      <td>0.784843</td>
      <td>-0.210821</td>
      <td>0.208192</td>
      <td>-1.084873</td>
      <td>0.017532</td>
      <td>-0.534566</td>
      <td>-0.178617</td>
      <td>0.248048</td>
      <td>-0.074733</td>
      <td>1.181419</td>
      <td>1.199346</td>
      <td>0.011462</td>
      <td>0.172818</td>
      <td>0.515121</td>
      <td>0.457754</td>
      <td>0.924017</td>
      <td>0.049472</td>
      <td>-0.498974</td>
      <td>-0.208750</td>
      <td>0.885683</td>
      <td>0.434134</td>
      <td>-0.033543</td>
      <td>0.356230</td>
      <td>-1.034987</td>
      <td>0.288013</td>
      <td>-0.503581</td>
      <td>0.369172</td>
      <td>0.848475</td>
      <td>0.983230</td>
      <td>-1.681293</td>
      <td>-1.512300</td>
      <td>-0.973716</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.540690</td>
      <td>-0.354060</td>
      <td>-0.317794</td>
      <td>0.184407</td>
      <td>0.117495</td>
      <td>-0.022932</td>
      <td>0.039055</td>
      <td>-0.495517</td>
      <td>0.508958</td>
      <td>0.667594</td>
      <td>0.689249</td>
      <td>1.047017</td>
      <td>0.421299</td>
      <td>-0.401379</td>
      <td>0.601475</td>
      <td>-0.453072</td>
      <td>0.182354</td>
      <td>0.310555</td>
      <td>0.330000</td>
      <td>-0.159293</td>
      <td>0.578401</td>
      <td>-0.160625</td>
      <td>0.229176</td>
      <td>0.273374</td>
      <td>0.857349</td>
      <td>-0.122304</td>
      <td>-0.581020</td>
      <td>0.804749</td>
      <td>0.636367</td>
      <td>-0.712374</td>
      <td>0.827716</td>
      <td>-0.255811</td>
      <td>-0.108533</td>
      <td>-0.014621</td>
      <td>0.634613</td>
      <td>1.586522</td>
      <td>0.090470</td>
      <td>-0.677377</td>
      <td>0.092848</td>
      <td>-1.135539</td>
      <td>...</td>
      <td>-0.425958</td>
      <td>-0.210281</td>
      <td>-0.224744</td>
      <td>0.407142</td>
      <td>0.718188</td>
      <td>0.113760</td>
      <td>-0.022956</td>
      <td>-0.031728</td>
      <td>0.487288</td>
      <td>0.347431</td>
      <td>-0.048494</td>
      <td>-0.411500</td>
      <td>-0.151385</td>
      <td>-0.426529</td>
      <td>0.454176</td>
      <td>0.972101</td>
      <td>0.518697</td>
      <td>0.357390</td>
      <td>0.207245</td>
      <td>0.807962</td>
      <td>0.589673</td>
      <td>0.411420</td>
      <td>-0.011617</td>
      <td>0.992674</td>
      <td>0.699788</td>
      <td>0.404063</td>
      <td>0.894526</td>
      <td>0.665589</td>
      <td>0.010638</td>
      <td>0.512948</td>
      <td>-0.066763</td>
      <td>-0.136170</td>
      <td>0.351178</td>
      <td>-0.527041</td>
      <td>-0.435946</td>
      <td>-0.052551</td>
      <td>0.062393</td>
      <td>-0.746862</td>
      <td>-0.764432</td>
      <td>-0.834531</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.738035</td>
      <td>0.176325</td>
      <td>0.941072</td>
      <td>1.168900</td>
      <td>0.430466</td>
      <td>-0.388059</td>
      <td>-0.124748</td>
      <td>0.251437</td>
      <td>-1.204905</td>
      <td>-1.794228</td>
      <td>-0.830865</td>
      <td>1.418689</td>
      <td>-0.712706</td>
      <td>-0.231826</td>
      <td>0.790932</td>
      <td>-0.082170</td>
      <td>-0.472392</td>
      <td>0.534898</td>
      <td>-0.120599</td>
      <td>-0.788095</td>
      <td>-0.684741</td>
      <td>-0.124454</td>
      <td>-0.078205</td>
      <td>-0.213747</td>
      <td>0.109915</td>
      <td>-0.183801</td>
      <td>-0.205798</td>
      <td>0.713239</td>
      <td>0.656420</td>
      <td>-0.683937</td>
      <td>0.061402</td>
      <td>-0.016755</td>
      <td>-0.544765</td>
      <td>0.710636</td>
      <td>0.847618</td>
      <td>0.529192</td>
      <td>0.116572</td>
      <td>0.223905</td>
      <td>-0.656121</td>
      <td>0.463021</td>
      <td>...</td>
      <td>-0.158054</td>
      <td>-0.485536</td>
      <td>-0.294718</td>
      <td>0.452531</td>
      <td>0.501196</td>
      <td>-0.910154</td>
      <td>0.694177</td>
      <td>0.155669</td>
      <td>-0.219372</td>
      <td>-0.606060</td>
      <td>-0.199015</td>
      <td>0.308281</td>
      <td>-0.347223</td>
      <td>0.400234</td>
      <td>0.411070</td>
      <td>0.610674</td>
      <td>-0.202191</td>
      <td>1.244865</td>
      <td>0.752053</td>
      <td>-0.721393</td>
      <td>-0.472951</td>
      <td>0.375337</td>
      <td>-0.484115</td>
      <td>-0.416461</td>
      <td>-0.263624</td>
      <td>-0.042024</td>
      <td>0.421684</td>
      <td>-0.519384</td>
      <td>-0.644762</td>
      <td>-0.506532</td>
      <td>0.425677</td>
      <td>-0.499918</td>
      <td>-0.113495</td>
      <td>0.165049</td>
      <td>0.801570</td>
      <td>-0.258809</td>
      <td>-0.289039</td>
      <td>2.124404</td>
      <td>1.512497</td>
      <td>1.460579</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.765797</td>
      <td>-0.531493</td>
      <td>0.669039</td>
      <td>1.115381</td>
      <td>1.069464</td>
      <td>0.227065</td>
      <td>-0.531688</td>
      <td>0.053605</td>
      <td>-1.333616</td>
      <td>0.135146</td>
      <td>0.928494</td>
      <td>0.075467</td>
      <td>0.114669</td>
      <td>0.135165</td>
      <td>0.104515</td>
      <td>0.097801</td>
      <td>0.053528</td>
      <td>0.704617</td>
      <td>1.241511</td>
      <td>-0.176566</td>
      <td>0.021367</td>
      <td>0.002552</td>
      <td>0.509907</td>
      <td>0.053436</td>
      <td>1.003553</td>
      <td>0.487499</td>
      <td>0.004168</td>
      <td>0.359943</td>
      <td>-0.814795</td>
      <td>-1.160583</td>
      <td>0.247560</td>
      <td>0.578016</td>
      <td>0.533597</td>
      <td>0.356654</td>
      <td>0.029221</td>
      <td>0.253986</td>
      <td>0.257669</td>
      <td>-0.578917</td>
      <td>0.078841</td>
      <td>0.204283</td>
      <td>...</td>
      <td>1.433369</td>
      <td>-0.012521</td>
      <td>-0.672228</td>
      <td>-1.212597</td>
      <td>-1.213366</td>
      <td>-1.171017</td>
      <td>-0.834190</td>
      <td>0.195897</td>
      <td>0.133199</td>
      <td>-0.844836</td>
      <td>0.036466</td>
      <td>-0.282250</td>
      <td>0.410970</td>
      <td>-0.101942</td>
      <td>-1.246433</td>
      <td>-0.475011</td>
      <td>-0.386832</td>
      <td>0.333118</td>
      <td>1.601427</td>
      <td>-0.015728</td>
      <td>0.231725</td>
      <td>-0.186259</td>
      <td>-0.278748</td>
      <td>0.800457</td>
      <td>0.374162</td>
      <td>0.281131</td>
      <td>-0.291963</td>
      <td>0.816538</td>
      <td>-0.065654</td>
      <td>-0.213341</td>
      <td>-0.719513</td>
      <td>-1.194539</td>
      <td>-0.430513</td>
      <td>-0.761464</td>
      <td>-1.143347</td>
      <td>-0.721077</td>
      <td>0.098547</td>
      <td>1.428512</td>
      <td>1.427427</td>
      <td>1.063814</td>
    </tr>
    <tr>
      <th>16</th>
      <td>1.048245</td>
      <td>0.873882</td>
      <td>-0.161385</td>
      <td>0.892244</td>
      <td>-0.073644</td>
      <td>0.334832</td>
      <td>0.404098</td>
      <td>0.318488</td>
      <td>-0.319221</td>
      <td>0.991429</td>
      <td>0.806397</td>
      <td>-0.248389</td>
      <td>-0.414947</td>
      <td>0.728847</td>
      <td>0.176321</td>
      <td>-1.022931</td>
      <td>-0.023677</td>
      <td>-0.677074</td>
      <td>0.200458</td>
      <td>-0.240302</td>
      <td>0.502406</td>
      <td>0.106233</td>
      <td>0.611206</td>
      <td>0.846933</td>
      <td>0.557979</td>
      <td>-0.535550</td>
      <td>-0.768962</td>
      <td>0.670513</td>
      <td>-0.651231</td>
      <td>-0.143841</td>
      <td>0.244530</td>
      <td>0.295463</td>
      <td>0.234737</td>
      <td>-0.096998</td>
      <td>-0.186867</td>
      <td>-0.303074</td>
      <td>0.297455</td>
      <td>0.846935</td>
      <td>0.502662</td>
      <td>-0.232916</td>
      <td>...</td>
      <td>0.161329</td>
      <td>-0.481809</td>
      <td>-0.498401</td>
      <td>0.357304</td>
      <td>0.144094</td>
      <td>-0.161929</td>
      <td>-0.662294</td>
      <td>-0.579182</td>
      <td>0.107439</td>
      <td>0.437605</td>
      <td>0.172423</td>
      <td>0.787224</td>
      <td>-0.119068</td>
      <td>-0.651727</td>
      <td>0.128545</td>
      <td>-0.653669</td>
      <td>0.698073</td>
      <td>0.113114</td>
      <td>0.517884</td>
      <td>-0.045537</td>
      <td>-0.207381</td>
      <td>0.545493</td>
      <td>-0.091040</td>
      <td>-0.349292</td>
      <td>1.102875</td>
      <td>-0.505499</td>
      <td>-0.307167</td>
      <td>0.235040</td>
      <td>-0.510617</td>
      <td>-0.440187</td>
      <td>-0.362181</td>
      <td>-0.143040</td>
      <td>-0.112352</td>
      <td>0.011989</td>
      <td>-0.856858</td>
      <td>0.522970</td>
      <td>-0.414261</td>
      <td>2.146799</td>
      <td>1.733500</td>
      <td>1.472308</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.628260</td>
      <td>-1.006485</td>
      <td>-0.801814</td>
      <td>-0.342793</td>
      <td>-0.565330</td>
      <td>-0.793051</td>
      <td>0.693688</td>
      <td>-0.171620</td>
      <td>0.440028</td>
      <td>0.910097</td>
      <td>-0.272053</td>
      <td>0.575549</td>
      <td>0.280609</td>
      <td>-0.147270</td>
      <td>-0.345024</td>
      <td>-1.037961</td>
      <td>-0.802894</td>
      <td>0.427726</td>
      <td>0.148679</td>
      <td>0.357934</td>
      <td>-0.107253</td>
      <td>-0.090509</td>
      <td>0.330462</td>
      <td>-0.551250</td>
      <td>0.722367</td>
      <td>1.367974</td>
      <td>-0.621528</td>
      <td>0.697586</td>
      <td>0.775415</td>
      <td>0.113099</td>
      <td>-0.172576</td>
      <td>0.784768</td>
      <td>0.041489</td>
      <td>0.640513</td>
      <td>0.368597</td>
      <td>0.279298</td>
      <td>0.579893</td>
      <td>0.145630</td>
      <td>0.557891</td>
      <td>-0.717322</td>
      <td>...</td>
      <td>1.208784</td>
      <td>0.290299</td>
      <td>0.030514</td>
      <td>0.879591</td>
      <td>0.525817</td>
      <td>0.575456</td>
      <td>0.058748</td>
      <td>-0.474240</td>
      <td>-0.010287</td>
      <td>0.097171</td>
      <td>0.469241</td>
      <td>-0.233513</td>
      <td>0.134832</td>
      <td>0.230950</td>
      <td>-0.026250</td>
      <td>-0.296514</td>
      <td>-0.479978</td>
      <td>0.347228</td>
      <td>0.963032</td>
      <td>0.728397</td>
      <td>0.539400</td>
      <td>-0.082212</td>
      <td>0.027517</td>
      <td>0.211738</td>
      <td>0.506453</td>
      <td>-1.474873</td>
      <td>0.122090</td>
      <td>-0.545545</td>
      <td>0.174897</td>
      <td>0.307971</td>
      <td>-0.707161</td>
      <td>-0.545430</td>
      <td>0.135195</td>
      <td>-0.883305</td>
      <td>0.255176</td>
      <td>0.024877</td>
      <td>-0.257020</td>
      <td>0.268060</td>
      <td>0.097996</td>
      <td>-0.206770</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.197211</td>
      <td>-0.941482</td>
      <td>0.340425</td>
      <td>0.546378</td>
      <td>-0.393248</td>
      <td>-0.067421</td>
      <td>0.286366</td>
      <td>0.635555</td>
      <td>-0.224147</td>
      <td>0.345021</td>
      <td>0.852432</td>
      <td>0.671007</td>
      <td>-0.333227</td>
      <td>0.307703</td>
      <td>0.142353</td>
      <td>-0.268910</td>
      <td>0.261397</td>
      <td>0.294821</td>
      <td>0.547255</td>
      <td>-0.644999</td>
      <td>1.291073</td>
      <td>-0.128263</td>
      <td>0.215700</td>
      <td>0.847949</td>
      <td>1.185624</td>
      <td>-0.380515</td>
      <td>0.150974</td>
      <td>0.929207</td>
      <td>0.862442</td>
      <td>-0.108124</td>
      <td>-0.735320</td>
      <td>0.068872</td>
      <td>-0.392439</td>
      <td>0.188181</td>
      <td>1.273396</td>
      <td>1.621516</td>
      <td>1.465292</td>
      <td>0.945612</td>
      <td>0.596552</td>
      <td>0.246923</td>
      <td>...</td>
      <td>1.531105</td>
      <td>0.628310</td>
      <td>-0.197642</td>
      <td>-0.008990</td>
      <td>-0.298773</td>
      <td>-0.372790</td>
      <td>0.138750</td>
      <td>-0.361759</td>
      <td>-1.700388</td>
      <td>-0.198244</td>
      <td>0.283535</td>
      <td>1.269406</td>
      <td>0.361019</td>
      <td>0.033394</td>
      <td>0.086798</td>
      <td>-0.634222</td>
      <td>0.996117</td>
      <td>-0.095222</td>
      <td>0.934637</td>
      <td>1.663271</td>
      <td>1.451286</td>
      <td>-0.418082</td>
      <td>-0.112615</td>
      <td>-0.890095</td>
      <td>0.874425</td>
      <td>-0.226133</td>
      <td>-0.329947</td>
      <td>-0.319983</td>
      <td>-0.085237</td>
      <td>-0.015324</td>
      <td>-0.748726</td>
      <td>-1.303825</td>
      <td>0.093131</td>
      <td>0.202135</td>
      <td>0.036428</td>
      <td>-0.237490</td>
      <td>-0.157527</td>
      <td>0.798614</td>
      <td>0.183244</td>
      <td>-0.101835</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.082056</td>
      <td>-0.335119</td>
      <td>0.086612</td>
      <td>0.314053</td>
      <td>-0.231548</td>
      <td>-0.650944</td>
      <td>0.376415</td>
      <td>0.122044</td>
      <td>-0.154712</td>
      <td>0.210562</td>
      <td>0.122028</td>
      <td>-0.258119</td>
      <td>-0.418099</td>
      <td>-0.064396</td>
      <td>-0.300148</td>
      <td>-0.912472</td>
      <td>0.048694</td>
      <td>-0.633794</td>
      <td>-0.539602</td>
      <td>0.018016</td>
      <td>-0.191259</td>
      <td>-0.060939</td>
      <td>1.133961</td>
      <td>1.111621</td>
      <td>1.585633</td>
      <td>0.247818</td>
      <td>-0.296774</td>
      <td>-0.291754</td>
      <td>-0.245744</td>
      <td>0.153038</td>
      <td>-0.692703</td>
      <td>0.222236</td>
      <td>-0.524556</td>
      <td>0.117984</td>
      <td>-0.187778</td>
      <td>0.303991</td>
      <td>-0.130228</td>
      <td>-1.507193</td>
      <td>-1.012393</td>
      <td>0.052845</td>
      <td>...</td>
      <td>2.213461</td>
      <td>0.777526</td>
      <td>-0.650629</td>
      <td>-0.024675</td>
      <td>-0.045527</td>
      <td>-0.296626</td>
      <td>0.529375</td>
      <td>-0.633274</td>
      <td>-0.763166</td>
      <td>-0.274694</td>
      <td>0.861212</td>
      <td>0.448502</td>
      <td>0.315967</td>
      <td>0.496742</td>
      <td>-0.840209</td>
      <td>0.134242</td>
      <td>-0.982157</td>
      <td>0.818383</td>
      <td>1.438956</td>
      <td>1.060740</td>
      <td>-0.005527</td>
      <td>0.133664</td>
      <td>-0.231885</td>
      <td>-0.365180</td>
      <td>-0.090261</td>
      <td>0.456225</td>
      <td>-0.182120</td>
      <td>-0.461828</td>
      <td>-0.036508</td>
      <td>0.020907</td>
      <td>-1.146892</td>
      <td>-0.098496</td>
      <td>0.415776</td>
      <td>-0.111514</td>
      <td>-0.059962</td>
      <td>-0.004675</td>
      <td>0.485323</td>
      <td>-0.257542</td>
      <td>-0.467494</td>
      <td>-0.233668</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.844628</td>
      <td>0.155629</td>
      <td>0.693864</td>
      <td>0.209621</td>
      <td>-0.706619</td>
      <td>-0.868931</td>
      <td>1.224180</td>
      <td>0.624495</td>
      <td>0.777286</td>
      <td>-0.149303</td>
      <td>0.446817</td>
      <td>-0.647344</td>
      <td>-0.676428</td>
      <td>0.576789</td>
      <td>-0.020580</td>
      <td>-0.672306</td>
      <td>0.038131</td>
      <td>-0.310173</td>
      <td>-0.446167</td>
      <td>-0.640630</td>
      <td>0.044721</td>
      <td>0.703455</td>
      <td>1.236877</td>
      <td>0.387131</td>
      <td>0.344799</td>
      <td>1.111964</td>
      <td>-0.038891</td>
      <td>-0.383201</td>
      <td>0.863577</td>
      <td>-0.290085</td>
      <td>1.121998</td>
      <td>0.772068</td>
      <td>0.461126</td>
      <td>0.179860</td>
      <td>0.088022</td>
      <td>-0.242243</td>
      <td>0.093841</td>
      <td>0.640228</td>
      <td>0.782767</td>
      <td>-0.711531</td>
      <td>...</td>
      <td>1.105579</td>
      <td>1.277346</td>
      <td>-0.252066</td>
      <td>0.635724</td>
      <td>0.622312</td>
      <td>0.585321</td>
      <td>0.539260</td>
      <td>-1.046615</td>
      <td>-0.666609</td>
      <td>-0.539901</td>
      <td>-0.673761</td>
      <td>-0.564684</td>
      <td>0.046376</td>
      <td>0.210483</td>
      <td>0.194026</td>
      <td>-0.350719</td>
      <td>-0.372012</td>
      <td>-1.138019</td>
      <td>0.683570</td>
      <td>1.550080</td>
      <td>-0.066967</td>
      <td>-0.884342</td>
      <td>-0.802123</td>
      <td>0.186543</td>
      <td>0.233863</td>
      <td>0.767200</td>
      <td>0.156554</td>
      <td>0.302552</td>
      <td>-0.044519</td>
      <td>-0.986508</td>
      <td>-0.791190</td>
      <td>0.626028</td>
      <td>0.631028</td>
      <td>-0.352158</td>
      <td>-0.739926</td>
      <td>-0.484392</td>
      <td>0.040248</td>
      <td>0.642132</td>
      <td>0.221381</td>
      <td>0.397557</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.053833</td>
      <td>-0.560516</td>
      <td>-0.485355</td>
      <td>1.145274</td>
      <td>-0.576233</td>
      <td>-1.348382</td>
      <td>0.277872</td>
      <td>-0.382343</td>
      <td>-0.130509</td>
      <td>0.030623</td>
      <td>1.110367</td>
      <td>0.587034</td>
      <td>-0.565783</td>
      <td>0.212409</td>
      <td>-0.048797</td>
      <td>-0.368924</td>
      <td>-0.278520</td>
      <td>-0.442320</td>
      <td>0.434960</td>
      <td>-0.050459</td>
      <td>0.725204</td>
      <td>-0.103060</td>
      <td>0.489273</td>
      <td>-0.351909</td>
      <td>0.919734</td>
      <td>0.266834</td>
      <td>-0.514913</td>
      <td>1.114005</td>
      <td>0.138839</td>
      <td>-0.207877</td>
      <td>0.497217</td>
      <td>0.314034</td>
      <td>0.118101</td>
      <td>-0.681984</td>
      <td>-0.713731</td>
      <td>0.302600</td>
      <td>0.767935</td>
      <td>-0.019340</td>
      <td>-0.962171</td>
      <td>-0.436302</td>
      <td>...</td>
      <td>1.237536</td>
      <td>-0.657868</td>
      <td>-0.818017</td>
      <td>0.012094</td>
      <td>0.233620</td>
      <td>-0.311060</td>
      <td>-0.483924</td>
      <td>-1.410000</td>
      <td>-0.444260</td>
      <td>-0.723363</td>
      <td>-0.621864</td>
      <td>-0.777194</td>
      <td>-0.379249</td>
      <td>0.573841</td>
      <td>0.759232</td>
      <td>-0.142445</td>
      <td>1.002141</td>
      <td>-0.725410</td>
      <td>0.525723</td>
      <td>0.526569</td>
      <td>-0.460174</td>
      <td>-0.055475</td>
      <td>-0.719750</td>
      <td>0.196123</td>
      <td>1.601573</td>
      <td>0.122044</td>
      <td>-0.700006</td>
      <td>-0.049512</td>
      <td>-0.017214</td>
      <td>-0.932745</td>
      <td>0.279580</td>
      <td>-0.052142</td>
      <td>-0.138414</td>
      <td>-0.468462</td>
      <td>-0.547682</td>
      <td>-0.579666</td>
      <td>0.437815</td>
      <td>-0.037117</td>
      <td>0.385245</td>
      <td>-0.312376</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.683416</td>
      <td>1.787671</td>
      <td>1.583186</td>
      <td>1.532125</td>
      <td>-0.696808</td>
      <td>-0.609203</td>
      <td>-0.303485</td>
      <td>0.016128</td>
      <td>-0.907352</td>
      <td>-0.056244</td>
      <td>-0.129550</td>
      <td>-0.563163</td>
      <td>-0.795453</td>
      <td>0.364536</td>
      <td>-0.773902</td>
      <td>0.278609</td>
      <td>0.301646</td>
      <td>0.967710</td>
      <td>0.422052</td>
      <td>0.362744</td>
      <td>-0.034899</td>
      <td>0.080952</td>
      <td>1.082123</td>
      <td>0.809815</td>
      <td>1.629033</td>
      <td>1.088543</td>
      <td>-1.691197</td>
      <td>-0.384188</td>
      <td>-0.842315</td>
      <td>-0.004546</td>
      <td>-0.758116</td>
      <td>0.060862</td>
      <td>-0.610088</td>
      <td>1.236912</td>
      <td>0.079815</td>
      <td>-0.124412</td>
      <td>0.416554</td>
      <td>-0.185618</td>
      <td>1.172096</td>
      <td>0.792330</td>
      <td>...</td>
      <td>0.342180</td>
      <td>-0.451455</td>
      <td>0.103316</td>
      <td>0.976719</td>
      <td>-0.205122</td>
      <td>0.415590</td>
      <td>-0.291657</td>
      <td>0.896941</td>
      <td>0.993969</td>
      <td>0.786556</td>
      <td>-0.202231</td>
      <td>0.224356</td>
      <td>-0.161887</td>
      <td>0.933171</td>
      <td>0.095274</td>
      <td>0.372234</td>
      <td>1.087661</td>
      <td>-0.279332</td>
      <td>0.963059</td>
      <td>0.890395</td>
      <td>0.586871</td>
      <td>1.470517</td>
      <td>0.595671</td>
      <td>-0.290692</td>
      <td>-0.301003</td>
      <td>-0.267001</td>
      <td>0.124759</td>
      <td>-0.290267</td>
      <td>-0.693557</td>
      <td>-0.073993</td>
      <td>0.309408</td>
      <td>-0.640138</td>
      <td>0.243750</td>
      <td>-0.108772</td>
      <td>0.174124</td>
      <td>0.684039</td>
      <td>0.386313</td>
      <td>2.120401</td>
      <td>1.855439</td>
      <td>0.497176</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.875008</td>
      <td>-0.648069</td>
      <td>-0.197119</td>
      <td>0.353393</td>
      <td>-0.017775</td>
      <td>0.224059</td>
      <td>-0.498273</td>
      <td>0.569256</td>
      <td>-0.787463</td>
      <td>0.249336</td>
      <td>1.201548</td>
      <td>0.922303</td>
      <td>-0.162907</td>
      <td>-0.206111</td>
      <td>0.712671</td>
      <td>-1.624896</td>
      <td>0.554713</td>
      <td>0.350649</td>
      <td>0.877027</td>
      <td>-0.377417</td>
      <td>0.194579</td>
      <td>1.147972</td>
      <td>0.695020</td>
      <td>1.088345</td>
      <td>2.023085</td>
      <td>1.154476</td>
      <td>-1.057088</td>
      <td>-0.393136</td>
      <td>-0.331469</td>
      <td>-0.634167</td>
      <td>-0.482562</td>
      <td>-0.009297</td>
      <td>-0.169614</td>
      <td>-0.056824</td>
      <td>0.140573</td>
      <td>-0.279591</td>
      <td>0.075314</td>
      <td>0.143778</td>
      <td>0.375582</td>
      <td>-0.152733</td>
      <td>...</td>
      <td>0.435329</td>
      <td>0.399771</td>
      <td>0.170088</td>
      <td>-0.227016</td>
      <td>0.613048</td>
      <td>-1.172338</td>
      <td>-0.010684</td>
      <td>-0.580472</td>
      <td>-0.535273</td>
      <td>0.973824</td>
      <td>0.436124</td>
      <td>-0.329882</td>
      <td>-1.269388</td>
      <td>-0.718885</td>
      <td>-0.118037</td>
      <td>0.338496</td>
      <td>-0.128040</td>
      <td>-0.333501</td>
      <td>-0.543897</td>
      <td>-0.271741</td>
      <td>0.376613</td>
      <td>-0.469221</td>
      <td>0.821846</td>
      <td>0.077035</td>
      <td>-0.793761</td>
      <td>0.122444</td>
      <td>0.313370</td>
      <td>0.393697</td>
      <td>-0.493016</td>
      <td>-0.113045</td>
      <td>0.122086</td>
      <td>-0.459511</td>
      <td>0.228501</td>
      <td>-0.345480</td>
      <td>-0.023173</td>
      <td>-1.922033</td>
      <td>0.310301</td>
      <td>1.141359</td>
      <td>0.539362</td>
      <td>0.756534</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.623411</td>
      <td>0.262902</td>
      <td>0.793221</td>
      <td>-0.431330</td>
      <td>-0.524885</td>
      <td>-0.482518</td>
      <td>0.537262</td>
      <td>-0.033650</td>
      <td>-0.688076</td>
      <td>-0.525582</td>
      <td>-0.191456</td>
      <td>0.151199</td>
      <td>-0.126592</td>
      <td>0.511951</td>
      <td>0.481086</td>
      <td>-0.694256</td>
      <td>-0.873628</td>
      <td>-0.366442</td>
      <td>0.209201</td>
      <td>0.243594</td>
      <td>-0.206634</td>
      <td>-0.319766</td>
      <td>0.025244</td>
      <td>-0.045472</td>
      <td>0.062302</td>
      <td>0.090694</td>
      <td>0.929688</td>
      <td>0.665619</td>
      <td>-0.419239</td>
      <td>0.410061</td>
      <td>-0.061710</td>
      <td>0.012997</td>
      <td>0.184811</td>
      <td>-0.725106</td>
      <td>-0.178087</td>
      <td>0.549095</td>
      <td>0.651271</td>
      <td>0.233300</td>
      <td>1.024978</td>
      <td>0.474888</td>
      <td>...</td>
      <td>0.934220</td>
      <td>-0.066157</td>
      <td>-1.248528</td>
      <td>0.277614</td>
      <td>-0.864744</td>
      <td>-0.960092</td>
      <td>0.396103</td>
      <td>-0.177419</td>
      <td>-0.428472</td>
      <td>0.653093</td>
      <td>-0.024305</td>
      <td>-0.378439</td>
      <td>0.913842</td>
      <td>-0.994785</td>
      <td>-0.185660</td>
      <td>-0.074855</td>
      <td>0.483321</td>
      <td>0.625880</td>
      <td>-0.143165</td>
      <td>0.452206</td>
      <td>-0.497760</td>
      <td>0.002868</td>
      <td>0.074265</td>
      <td>-0.150774</td>
      <td>-0.424048</td>
      <td>-0.383856</td>
      <td>-0.878492</td>
      <td>-0.168077</td>
      <td>0.716713</td>
      <td>-0.055797</td>
      <td>0.565493</td>
      <td>-0.816224</td>
      <td>-0.257821</td>
      <td>0.691623</td>
      <td>0.741825</td>
      <td>0.017324</td>
      <td>1.734835</td>
      <td>2.225536</td>
      <td>1.051767</td>
      <td>0.560323</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>0.172808</td>
      <td>0.077626</td>
      <td>-0.661318</td>
      <td>-0.760004</td>
      <td>-0.728387</td>
      <td>0.503269</td>
      <td>0.382122</td>
      <td>-0.316768</td>
      <td>-0.148255</td>
      <td>-0.291273</td>
      <td>0.547315</td>
      <td>0.343334</td>
      <td>1.252827</td>
      <td>-0.101262</td>
      <td>0.283171</td>
      <td>0.031578</td>
      <td>-0.676175</td>
      <td>0.465089</td>
      <td>0.127586</td>
      <td>0.779991</td>
      <td>0.359479</td>
      <td>0.234034</td>
      <td>-0.627271</td>
      <td>-0.238502</td>
      <td>0.658520</td>
      <td>1.696550</td>
      <td>-1.068549</td>
      <td>-0.370300</td>
      <td>-0.431986</td>
      <td>0.833610</td>
      <td>-0.024812</td>
      <td>-0.154941</td>
      <td>-0.625857</td>
      <td>-0.363606</td>
      <td>0.373532</td>
      <td>-0.556765</td>
      <td>-0.510515</td>
      <td>-0.046809</td>
      <td>0.009916</td>
      <td>0.368037</td>
      <td>...</td>
      <td>0.353099</td>
      <td>0.092922</td>
      <td>-0.825467</td>
      <td>-0.516372</td>
      <td>-0.599142</td>
      <td>-0.943562</td>
      <td>-0.358332</td>
      <td>0.302011</td>
      <td>-0.642416</td>
      <td>-0.233044</td>
      <td>0.433286</td>
      <td>0.250309</td>
      <td>-0.286876</td>
      <td>-0.507710</td>
      <td>-1.094608</td>
      <td>-0.586810</td>
      <td>0.184964</td>
      <td>-0.004431</td>
      <td>0.388696</td>
      <td>-0.566855</td>
      <td>0.186778</td>
      <td>-0.402265</td>
      <td>0.133644</td>
      <td>-0.750241</td>
      <td>-1.213616</td>
      <td>-1.257900</td>
      <td>-0.519033</td>
      <td>0.083195</td>
      <td>-0.311052</td>
      <td>-0.081162</td>
      <td>0.088992</td>
      <td>-0.680230</td>
      <td>-1.238336</td>
      <td>0.259642</td>
      <td>0.545094</td>
      <td>-0.204661</td>
      <td>-0.477448</td>
      <td>1.639198</td>
      <td>0.569755</td>
      <td>0.552432</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.376872</td>
      <td>0.205806</td>
      <td>-0.593872</td>
      <td>0.717010</td>
      <td>-0.229717</td>
      <td>0.068068</td>
      <td>0.178803</td>
      <td>-0.180716</td>
      <td>0.183005</td>
      <td>0.063411</td>
      <td>0.386339</td>
      <td>0.071384</td>
      <td>0.416568</td>
      <td>-0.692875</td>
      <td>-1.284926</td>
      <td>-0.826535</td>
      <td>-0.679389</td>
      <td>-0.448190</td>
      <td>-0.361829</td>
      <td>-0.110117</td>
      <td>0.728187</td>
      <td>0.414810</td>
      <td>0.340767</td>
      <td>0.859675</td>
      <td>-0.232730</td>
      <td>-0.079063</td>
      <td>0.074769</td>
      <td>0.639130</td>
      <td>-0.101022</td>
      <td>-0.116967</td>
      <td>-1.182339</td>
      <td>-0.099403</td>
      <td>-0.710756</td>
      <td>-0.335998</td>
      <td>-1.224322</td>
      <td>0.145658</td>
      <td>0.510501</td>
      <td>0.852634</td>
      <td>0.119374</td>
      <td>0.098783</td>
      <td>...</td>
      <td>-0.087081</td>
      <td>-0.161762</td>
      <td>-0.250614</td>
      <td>-0.356241</td>
      <td>-0.526100</td>
      <td>-0.172855</td>
      <td>0.075229</td>
      <td>-0.095507</td>
      <td>0.598494</td>
      <td>1.142539</td>
      <td>-1.046038</td>
      <td>-0.093950</td>
      <td>-0.078643</td>
      <td>-0.956802</td>
      <td>0.161971</td>
      <td>-0.229265</td>
      <td>0.049485</td>
      <td>-0.827192</td>
      <td>-1.436770</td>
      <td>-0.223600</td>
      <td>0.603310</td>
      <td>-0.460185</td>
      <td>-0.565400</td>
      <td>1.192104</td>
      <td>-1.224531</td>
      <td>-0.974849</td>
      <td>0.030048</td>
      <td>0.172393</td>
      <td>-0.390806</td>
      <td>-0.881208</td>
      <td>-0.966888</td>
      <td>-0.535978</td>
      <td>0.308886</td>
      <td>0.848535</td>
      <td>-0.361618</td>
      <td>0.302196</td>
      <td>0.209042</td>
      <td>1.420770</td>
      <td>0.669964</td>
      <td>0.692982</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.634012</td>
      <td>-1.020512</td>
      <td>-0.928979</td>
      <td>-0.421504</td>
      <td>-0.726765</td>
      <td>0.431060</td>
      <td>-0.394678</td>
      <td>0.040849</td>
      <td>0.379037</td>
      <td>0.670126</td>
      <td>0.116247</td>
      <td>0.120632</td>
      <td>0.813849</td>
      <td>0.025758</td>
      <td>1.134124</td>
      <td>0.527296</td>
      <td>-0.178580</td>
      <td>0.001011</td>
      <td>-0.664633</td>
      <td>0.072911</td>
      <td>0.518409</td>
      <td>-0.049376</td>
      <td>-0.595448</td>
      <td>-0.851211</td>
      <td>0.512645</td>
      <td>1.137520</td>
      <td>0.905879</td>
      <td>0.095485</td>
      <td>0.206796</td>
      <td>0.071038</td>
      <td>0.066685</td>
      <td>0.912662</td>
      <td>-0.554818</td>
      <td>-0.463662</td>
      <td>-0.078637</td>
      <td>1.412903</td>
      <td>1.636571</td>
      <td>0.241288</td>
      <td>0.303062</td>
      <td>0.508537</td>
      <td>...</td>
      <td>-0.340969</td>
      <td>-0.610381</td>
      <td>-0.252185</td>
      <td>-0.553415</td>
      <td>1.213323</td>
      <td>-0.126825</td>
      <td>-1.173334</td>
      <td>0.681102</td>
      <td>-0.167728</td>
      <td>-0.190934</td>
      <td>0.596496</td>
      <td>0.003331</td>
      <td>0.290134</td>
      <td>-0.081357</td>
      <td>-1.079931</td>
      <td>-1.313476</td>
      <td>0.213292</td>
      <td>-0.637323</td>
      <td>-0.216247</td>
      <td>-0.501354</td>
      <td>1.118779</td>
      <td>0.582112</td>
      <td>0.654576</td>
      <td>0.622245</td>
      <td>-0.088439</td>
      <td>-0.380853</td>
      <td>-0.333800</td>
      <td>0.169544</td>
      <td>0.509565</td>
      <td>1.564907</td>
      <td>0.266428</td>
      <td>-0.850125</td>
      <td>-0.289101</td>
      <td>-0.457078</td>
      <td>-1.830046</td>
      <td>-0.482489</td>
      <td>-0.696300</td>
      <td>-0.701508</td>
      <td>-0.271750</td>
      <td>0.218228</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.609864</td>
      <td>1.374793</td>
      <td>0.199447</td>
      <td>1.065420</td>
      <td>-0.323427</td>
      <td>0.541692</td>
      <td>-0.545738</td>
      <td>0.399454</td>
      <td>0.183071</td>
      <td>-0.609234</td>
      <td>0.631339</td>
      <td>0.174607</td>
      <td>-0.490275</td>
      <td>-1.729619</td>
      <td>-1.462535</td>
      <td>0.139830</td>
      <td>0.185293</td>
      <td>-0.384847</td>
      <td>-0.648235</td>
      <td>0.390877</td>
      <td>-0.594664</td>
      <td>-0.251505</td>
      <td>1.056660</td>
      <td>-0.136240</td>
      <td>-0.034297</td>
      <td>0.099284</td>
      <td>-0.730080</td>
      <td>-0.359568</td>
      <td>-0.543244</td>
      <td>0.442078</td>
      <td>0.223554</td>
      <td>-0.833000</td>
      <td>-0.902198</td>
      <td>-0.630284</td>
      <td>0.551918</td>
      <td>0.125057</td>
      <td>0.703562</td>
      <td>0.092333</td>
      <td>0.786453</td>
      <td>0.182056</td>
      <td>...</td>
      <td>-0.022531</td>
      <td>-0.172275</td>
      <td>-1.591058</td>
      <td>-0.489148</td>
      <td>0.921032</td>
      <td>0.211572</td>
      <td>0.525886</td>
      <td>0.186095</td>
      <td>-1.129651</td>
      <td>1.290126</td>
      <td>0.232415</td>
      <td>0.202389</td>
      <td>-0.295925</td>
      <td>-0.263230</td>
      <td>-0.902220</td>
      <td>-1.229546</td>
      <td>-0.449439</td>
      <td>-0.489484</td>
      <td>-0.324241</td>
      <td>0.015072</td>
      <td>0.042837</td>
      <td>0.238818</td>
      <td>0.818764</td>
      <td>1.040348</td>
      <td>-0.302638</td>
      <td>-0.136654</td>
      <td>0.819049</td>
      <td>-0.572400</td>
      <td>-0.640449</td>
      <td>0.413522</td>
      <td>-0.318211</td>
      <td>0.213295</td>
      <td>-0.005502</td>
      <td>1.861076</td>
      <td>1.265139</td>
      <td>0.443911</td>
      <td>-0.401682</td>
      <td>1.511525</td>
      <td>0.992806</td>
      <td>1.217209</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.035970</td>
      <td>-0.296836</td>
      <td>0.203520</td>
      <td>0.736611</td>
      <td>-0.369061</td>
      <td>-1.084813</td>
      <td>-1.450543</td>
      <td>-0.479496</td>
      <td>0.682383</td>
      <td>-0.008177</td>
      <td>0.281792</td>
      <td>0.307728</td>
      <td>-0.007509</td>
      <td>0.332875</td>
      <td>0.400597</td>
      <td>-0.342767</td>
      <td>0.353632</td>
      <td>-0.889025</td>
      <td>0.258142</td>
      <td>-0.542276</td>
      <td>-0.974727</td>
      <td>0.169196</td>
      <td>-1.085023</td>
      <td>0.318448</td>
      <td>0.770048</td>
      <td>1.137036</td>
      <td>-0.514122</td>
      <td>0.156436</td>
      <td>-0.212933</td>
      <td>-0.595286</td>
      <td>1.041601</td>
      <td>0.524620</td>
      <td>-0.887753</td>
      <td>0.063836</td>
      <td>-0.862445</td>
      <td>1.003264</td>
      <td>0.727413</td>
      <td>-0.177408</td>
      <td>1.029591</td>
      <td>-0.300219</td>
      <td>...</td>
      <td>-0.097049</td>
      <td>0.046592</td>
      <td>-0.717344</td>
      <td>0.180612</td>
      <td>1.335689</td>
      <td>1.453235</td>
      <td>0.408267</td>
      <td>0.206471</td>
      <td>0.517704</td>
      <td>-0.455956</td>
      <td>-0.667990</td>
      <td>-0.514600</td>
      <td>0.299746</td>
      <td>0.084642</td>
      <td>-0.906858</td>
      <td>-1.734117</td>
      <td>-0.666672</td>
      <td>-1.260684</td>
      <td>0.269638</td>
      <td>1.553200</td>
      <td>-0.350459</td>
      <td>-0.923692</td>
      <td>-0.805133</td>
      <td>-0.447624</td>
      <td>0.064476</td>
      <td>0.034458</td>
      <td>0.289665</td>
      <td>-0.019024</td>
      <td>-0.390432</td>
      <td>0.238554</td>
      <td>0.228873</td>
      <td>0.151743</td>
      <td>0.698085</td>
      <td>0.663225</td>
      <td>0.021003</td>
      <td>1.125621</td>
      <td>-0.566783</td>
      <td>-1.403112</td>
      <td>-0.823786</td>
      <td>-0.831485</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f721c091040&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.000525  0.043768  22.859829  1.166865e-115  0.914742  1.086308
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  5.385 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>