
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.302748</td>
      <td>-0.092786</td>
      <td>0.062104</td>
      <td>-0.148613</td>
      <td>-0.639696</td>
      <td>-0.466127</td>
      <td>0.775006</td>
      <td>-0.273203</td>
      <td>0.408803</td>
      <td>0.079673</td>
      <td>0.596724</td>
      <td>0.930457</td>
      <td>0.268402</td>
      <td>0.110628</td>
      <td>0.223693</td>
      <td>0.572752</td>
      <td>0.245807</td>
      <td>-0.556564</td>
      <td>0.142864</td>
      <td>-0.141352</td>
      <td>0.121283</td>
      <td>0.093497</td>
      <td>0.509510</td>
      <td>-0.088779</td>
      <td>-0.231752</td>
      <td>-0.233102</td>
      <td>0.304309</td>
      <td>0.546834</td>
      <td>-0.149437</td>
      <td>-0.299713</td>
      <td>0.547344</td>
      <td>-0.134556</td>
      <td>-0.648850</td>
      <td>0.407285</td>
      <td>-0.745717</td>
      <td>-0.069474</td>
      <td>0.001838</td>
      <td>0.634076</td>
      <td>0.159294</td>
      <td>-0.077658</td>
      <td>...</td>
      <td>0.422173</td>
      <td>1.373966</td>
      <td>-0.017293</td>
      <td>0.899418</td>
      <td>0.510537</td>
      <td>0.075570</td>
      <td>-0.203316</td>
      <td>0.911275</td>
      <td>-0.025169</td>
      <td>0.531031</td>
      <td>0.622555</td>
      <td>0.587115</td>
      <td>0.478991</td>
      <td>-0.599827</td>
      <td>-0.669043</td>
      <td>-0.510572</td>
      <td>-0.564259</td>
      <td>0.646680</td>
      <td>0.120544</td>
      <td>0.034132</td>
      <td>0.093871</td>
      <td>0.383469</td>
      <td>-0.224167</td>
      <td>-0.084366</td>
      <td>-0.087009</td>
      <td>-0.715595</td>
      <td>0.718083</td>
      <td>0.338655</td>
      <td>0.570295</td>
      <td>-0.108099</td>
      <td>0.676832</td>
      <td>1.224032</td>
      <td>-0.982466</td>
      <td>0.582042</td>
      <td>-0.051256</td>
      <td>-0.701992</td>
      <td>0.045337</td>
      <td>0.142628</td>
      <td>0.098762</td>
      <td>0.462496</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.630643</td>
      <td>0.369802</td>
      <td>0.080403</td>
      <td>0.434610</td>
      <td>0.102845</td>
      <td>-0.152274</td>
      <td>0.445681</td>
      <td>0.318403</td>
      <td>-1.077622</td>
      <td>-0.260342</td>
      <td>-0.074242</td>
      <td>0.595624</td>
      <td>0.237512</td>
      <td>0.000776</td>
      <td>0.710155</td>
      <td>0.592513</td>
      <td>-0.463238</td>
      <td>-0.776915</td>
      <td>-0.187836</td>
      <td>0.414284</td>
      <td>-0.380898</td>
      <td>-0.593546</td>
      <td>-0.372448</td>
      <td>-1.301070</td>
      <td>-0.713501</td>
      <td>-0.065302</td>
      <td>-0.338482</td>
      <td>0.536663</td>
      <td>0.150834</td>
      <td>-0.457973</td>
      <td>0.101386</td>
      <td>0.005580</td>
      <td>0.011623</td>
      <td>0.565673</td>
      <td>0.436211</td>
      <td>0.113441</td>
      <td>-0.146734</td>
      <td>-0.022488</td>
      <td>0.133082</td>
      <td>-0.813511</td>
      <td>...</td>
      <td>-1.211299</td>
      <td>0.862004</td>
      <td>-0.605144</td>
      <td>0.150971</td>
      <td>1.534014</td>
      <td>0.150990</td>
      <td>-0.070619</td>
      <td>-0.314114</td>
      <td>0.072720</td>
      <td>0.524758</td>
      <td>0.209284</td>
      <td>-0.246753</td>
      <td>0.251205</td>
      <td>-0.304398</td>
      <td>-0.877636</td>
      <td>0.215185</td>
      <td>0.731194</td>
      <td>-0.056437</td>
      <td>0.980840</td>
      <td>0.436598</td>
      <td>0.451938</td>
      <td>0.352314</td>
      <td>-0.103611</td>
      <td>-0.216008</td>
      <td>0.493747</td>
      <td>-0.173733</td>
      <td>0.000515</td>
      <td>-0.516467</td>
      <td>-0.092768</td>
      <td>0.108539</td>
      <td>-0.074048</td>
      <td>0.943593</td>
      <td>-0.531620</td>
      <td>0.207784</td>
      <td>0.152240</td>
      <td>0.224664</td>
      <td>-0.219494</td>
      <td>3.377724</td>
      <td>1.994506</td>
      <td>1.123661</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.648926</td>
      <td>-0.568386</td>
      <td>0.129474</td>
      <td>-0.144491</td>
      <td>-1.293381</td>
      <td>-0.862193</td>
      <td>0.163099</td>
      <td>-1.144371</td>
      <td>-0.198081</td>
      <td>-0.332085</td>
      <td>-0.005269</td>
      <td>0.134506</td>
      <td>-0.072772</td>
      <td>-0.419207</td>
      <td>0.025403</td>
      <td>-0.681849</td>
      <td>0.041083</td>
      <td>-0.649676</td>
      <td>-0.932042</td>
      <td>-0.119539</td>
      <td>0.070102</td>
      <td>-0.071725</td>
      <td>0.416140</td>
      <td>-0.185915</td>
      <td>0.167785</td>
      <td>-1.278782</td>
      <td>0.074777</td>
      <td>0.090113</td>
      <td>-0.279711</td>
      <td>0.300983</td>
      <td>0.954175</td>
      <td>0.842146</td>
      <td>-0.727181</td>
      <td>-0.924229</td>
      <td>-0.693414</td>
      <td>-0.379013</td>
      <td>0.835754</td>
      <td>0.723658</td>
      <td>0.440739</td>
      <td>0.199849</td>
      <td>...</td>
      <td>0.126820</td>
      <td>0.993598</td>
      <td>0.574247</td>
      <td>1.192091</td>
      <td>0.665455</td>
      <td>-0.061368</td>
      <td>0.149132</td>
      <td>-0.792628</td>
      <td>0.268935</td>
      <td>0.222645</td>
      <td>-0.161040</td>
      <td>0.255694</td>
      <td>0.320196</td>
      <td>0.058392</td>
      <td>-0.329698</td>
      <td>0.267057</td>
      <td>-0.537644</td>
      <td>-0.073917</td>
      <td>0.261742</td>
      <td>-0.072196</td>
      <td>0.305460</td>
      <td>0.395055</td>
      <td>0.559267</td>
      <td>-0.949427</td>
      <td>-0.416600</td>
      <td>0.130475</td>
      <td>-0.153373</td>
      <td>-0.182030</td>
      <td>0.257486</td>
      <td>-0.097357</td>
      <td>0.745202</td>
      <td>-0.710195</td>
      <td>0.820562</td>
      <td>0.922148</td>
      <td>-0.648570</td>
      <td>-0.059162</td>
      <td>-0.521318</td>
      <td>-2.137872</td>
      <td>-1.345856</td>
      <td>-0.671385</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.513049</td>
      <td>0.071559</td>
      <td>1.135434</td>
      <td>1.126107</td>
      <td>0.675456</td>
      <td>-0.399286</td>
      <td>0.276762</td>
      <td>0.410421</td>
      <td>-0.542117</td>
      <td>0.539927</td>
      <td>-0.668907</td>
      <td>0.350003</td>
      <td>-0.943785</td>
      <td>0.123684</td>
      <td>0.163134</td>
      <td>0.765872</td>
      <td>-0.110471</td>
      <td>-0.052661</td>
      <td>-0.174245</td>
      <td>-0.435515</td>
      <td>0.006356</td>
      <td>-1.109214</td>
      <td>-0.087962</td>
      <td>0.019120</td>
      <td>-0.385313</td>
      <td>0.137347</td>
      <td>-0.474494</td>
      <td>0.654721</td>
      <td>0.154735</td>
      <td>0.309455</td>
      <td>0.769844</td>
      <td>-0.705311</td>
      <td>-0.409296</td>
      <td>-0.262458</td>
      <td>-0.774840</td>
      <td>-0.082143</td>
      <td>0.259021</td>
      <td>-0.453002</td>
      <td>-0.321333</td>
      <td>-0.523121</td>
      <td>...</td>
      <td>-0.261799</td>
      <td>0.315752</td>
      <td>-0.489739</td>
      <td>0.509534</td>
      <td>-1.362047</td>
      <td>-0.465901</td>
      <td>0.485026</td>
      <td>0.449792</td>
      <td>0.586529</td>
      <td>1.549572</td>
      <td>0.344834</td>
      <td>0.516625</td>
      <td>-0.869788</td>
      <td>-1.035748</td>
      <td>-0.180959</td>
      <td>0.119640</td>
      <td>-0.612433</td>
      <td>-1.155079</td>
      <td>0.367375</td>
      <td>0.213285</td>
      <td>-0.366820</td>
      <td>-0.906745</td>
      <td>-0.697880</td>
      <td>-0.197800</td>
      <td>0.197490</td>
      <td>-0.322472</td>
      <td>0.333551</td>
      <td>-0.651357</td>
      <td>-0.600644</td>
      <td>-1.129337</td>
      <td>-0.164438</td>
      <td>-0.207761</td>
      <td>0.341395</td>
      <td>-0.008785</td>
      <td>-0.564988</td>
      <td>-0.222373</td>
      <td>0.691529</td>
      <td>-0.216169</td>
      <td>-0.021117</td>
      <td>0.592284</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.462770</td>
      <td>-0.292117</td>
      <td>-0.142588</td>
      <td>-0.035670</td>
      <td>-0.134251</td>
      <td>-0.343173</td>
      <td>0.491082</td>
      <td>0.507975</td>
      <td>0.398886</td>
      <td>-0.162110</td>
      <td>-0.650563</td>
      <td>0.007554</td>
      <td>0.113820</td>
      <td>-0.112040</td>
      <td>-0.692576</td>
      <td>0.539572</td>
      <td>-0.094159</td>
      <td>0.234001</td>
      <td>-0.293305</td>
      <td>1.032055</td>
      <td>1.629052</td>
      <td>0.095875</td>
      <td>0.041310</td>
      <td>-0.048571</td>
      <td>-0.733128</td>
      <td>-0.272173</td>
      <td>0.130440</td>
      <td>-1.405100</td>
      <td>-0.207147</td>
      <td>0.054990</td>
      <td>0.726230</td>
      <td>0.388984</td>
      <td>0.210332</td>
      <td>-0.534580</td>
      <td>-1.172526</td>
      <td>-0.744772</td>
      <td>-0.532225</td>
      <td>0.362928</td>
      <td>0.704815</td>
      <td>0.265239</td>
      <td>...</td>
      <td>-0.571646</td>
      <td>0.577424</td>
      <td>-0.636591</td>
      <td>0.582373</td>
      <td>0.095776</td>
      <td>-0.825487</td>
      <td>-0.679668</td>
      <td>0.021494</td>
      <td>0.268297</td>
      <td>0.347144</td>
      <td>0.771959</td>
      <td>-0.169017</td>
      <td>-0.717654</td>
      <td>-0.863534</td>
      <td>0.027412</td>
      <td>0.603454</td>
      <td>-0.014017</td>
      <td>-0.157052</td>
      <td>0.627088</td>
      <td>-0.860042</td>
      <td>-1.050528</td>
      <td>0.614748</td>
      <td>-0.067900</td>
      <td>-1.145352</td>
      <td>0.240048</td>
      <td>-0.470417</td>
      <td>-0.703528</td>
      <td>-0.745967</td>
      <td>-0.266037</td>
      <td>0.545602</td>
      <td>0.505091</td>
      <td>0.163380</td>
      <td>-0.425971</td>
      <td>0.676494</td>
      <td>0.330631</td>
      <td>-0.572677</td>
      <td>0.144810</td>
      <td>-0.096086</td>
      <td>0.297003</td>
      <td>0.008046</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.730841</td>
      <td>-0.319689</td>
      <td>0.634646</td>
      <td>0.327166</td>
      <td>0.595295</td>
      <td>0.370034</td>
      <td>-0.386086</td>
      <td>-0.070449</td>
      <td>-0.769956</td>
      <td>-0.245262</td>
      <td>-0.505007</td>
      <td>0.692296</td>
      <td>-0.994480</td>
      <td>0.654909</td>
      <td>0.349338</td>
      <td>0.213221</td>
      <td>0.193919</td>
      <td>0.451109</td>
      <td>0.951592</td>
      <td>-0.070721</td>
      <td>-0.077196</td>
      <td>0.099171</td>
      <td>1.109663</td>
      <td>0.591484</td>
      <td>1.068653</td>
      <td>-0.564969</td>
      <td>-0.287567</td>
      <td>-0.426830</td>
      <td>-0.514853</td>
      <td>-0.311975</td>
      <td>0.733312</td>
      <td>-0.040544</td>
      <td>0.420358</td>
      <td>-0.338135</td>
      <td>-0.858330</td>
      <td>0.058488</td>
      <td>-1.100498</td>
      <td>-0.473659</td>
      <td>-0.205128</td>
      <td>-0.147668</td>
      <td>...</td>
      <td>-0.043040</td>
      <td>0.376727</td>
      <td>-0.196037</td>
      <td>0.927927</td>
      <td>0.072956</td>
      <td>-0.775870</td>
      <td>1.402108</td>
      <td>0.877770</td>
      <td>0.792183</td>
      <td>0.112871</td>
      <td>0.394857</td>
      <td>-0.438183</td>
      <td>0.233922</td>
      <td>-0.275030</td>
      <td>0.586204</td>
      <td>0.187958</td>
      <td>-1.083488</td>
      <td>0.083229</td>
      <td>0.665349</td>
      <td>0.738902</td>
      <td>-0.661019</td>
      <td>-0.312257</td>
      <td>0.577890</td>
      <td>-1.365456</td>
      <td>0.136952</td>
      <td>-1.203415</td>
      <td>0.257257</td>
      <td>-0.653215</td>
      <td>-0.507906</td>
      <td>-1.464518</td>
      <td>-0.077605</td>
      <td>-0.051094</td>
      <td>-0.482798</td>
      <td>-0.117260</td>
      <td>-0.145611</td>
      <td>-0.594881</td>
      <td>-0.314834</td>
      <td>-0.875963</td>
      <td>-0.655022</td>
      <td>-0.413846</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.415559</td>
      <td>-0.651687</td>
      <td>-0.422367</td>
      <td>-0.443677</td>
      <td>-1.317410</td>
      <td>-0.023092</td>
      <td>0.599407</td>
      <td>-1.463199</td>
      <td>-0.371025</td>
      <td>-0.175801</td>
      <td>0.854046</td>
      <td>0.361055</td>
      <td>0.584636</td>
      <td>1.086449</td>
      <td>0.052078</td>
      <td>0.015675</td>
      <td>0.307363</td>
      <td>0.133057</td>
      <td>-0.125469</td>
      <td>0.508827</td>
      <td>0.444332</td>
      <td>0.283041</td>
      <td>1.349518</td>
      <td>0.807003</td>
      <td>0.233182</td>
      <td>-0.764369</td>
      <td>-0.901831</td>
      <td>-1.014118</td>
      <td>-0.227633</td>
      <td>-0.218702</td>
      <td>-0.266363</td>
      <td>0.425404</td>
      <td>0.414819</td>
      <td>0.325227</td>
      <td>-0.655124</td>
      <td>-0.272701</td>
      <td>-1.001149</td>
      <td>-0.651229</td>
      <td>-0.228080</td>
      <td>-0.213747</td>
      <td>...</td>
      <td>0.308622</td>
      <td>1.124489</td>
      <td>0.855960</td>
      <td>1.262868</td>
      <td>-0.333734</td>
      <td>-0.483332</td>
      <td>0.357348</td>
      <td>0.493553</td>
      <td>0.507076</td>
      <td>-0.030890</td>
      <td>-0.312886</td>
      <td>-0.841305</td>
      <td>0.271639</td>
      <td>-0.800393</td>
      <td>-0.152489</td>
      <td>0.586144</td>
      <td>-0.523023</td>
      <td>-0.050907</td>
      <td>1.248380</td>
      <td>-0.145409</td>
      <td>-0.214613</td>
      <td>-0.499816</td>
      <td>-0.340001</td>
      <td>-1.278398</td>
      <td>-0.747589</td>
      <td>-0.050222</td>
      <td>0.152896</td>
      <td>-0.013541</td>
      <td>0.287520</td>
      <td>0.260737</td>
      <td>0.251191</td>
      <td>0.247515</td>
      <td>-0.738402</td>
      <td>-0.924234</td>
      <td>-0.522911</td>
      <td>0.161108</td>
      <td>-0.644032</td>
      <td>0.030861</td>
      <td>1.000761</td>
      <td>0.838403</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.576060</td>
      <td>-0.952677</td>
      <td>-1.087314</td>
      <td>-0.220981</td>
      <td>-0.969023</td>
      <td>0.000173</td>
      <td>1.208490</td>
      <td>0.427300</td>
      <td>0.438438</td>
      <td>1.515656</td>
      <td>0.699939</td>
      <td>1.493798</td>
      <td>0.630548</td>
      <td>-0.335185</td>
      <td>0.447304</td>
      <td>0.487177</td>
      <td>0.754856</td>
      <td>0.700325</td>
      <td>1.161683</td>
      <td>0.169744</td>
      <td>0.485562</td>
      <td>-0.733039</td>
      <td>-0.228138</td>
      <td>0.776409</td>
      <td>0.649957</td>
      <td>-0.293477</td>
      <td>0.289590</td>
      <td>0.707275</td>
      <td>-0.325252</td>
      <td>-1.248474</td>
      <td>-0.679016</td>
      <td>0.428248</td>
      <td>0.137143</td>
      <td>-0.465083</td>
      <td>0.269176</td>
      <td>-0.702778</td>
      <td>-0.890440</td>
      <td>-0.362720</td>
      <td>-0.518014</td>
      <td>0.922909</td>
      <td>...</td>
      <td>-0.844457</td>
      <td>1.817802</td>
      <td>-0.378277</td>
      <td>1.269761</td>
      <td>0.855850</td>
      <td>0.325766</td>
      <td>-0.346348</td>
      <td>-0.348283</td>
      <td>-0.736956</td>
      <td>0.944390</td>
      <td>0.938252</td>
      <td>0.141044</td>
      <td>0.861232</td>
      <td>-0.342031</td>
      <td>0.547241</td>
      <td>1.021476</td>
      <td>-0.120350</td>
      <td>-0.068840</td>
      <td>-0.211360</td>
      <td>-0.630458</td>
      <td>0.323007</td>
      <td>-0.392259</td>
      <td>-0.520276</td>
      <td>-0.008116</td>
      <td>1.262151</td>
      <td>0.345747</td>
      <td>0.732364</td>
      <td>-0.334258</td>
      <td>-0.757639</td>
      <td>-0.646622</td>
      <td>1.352720</td>
      <td>0.880420</td>
      <td>-0.527126</td>
      <td>-1.064185</td>
      <td>0.087675</td>
      <td>0.334725</td>
      <td>0.135823</td>
      <td>-1.907106</td>
      <td>-1.671568</td>
      <td>-0.714140</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.794640</td>
      <td>-0.124804</td>
      <td>-0.187774</td>
      <td>-0.905516</td>
      <td>-0.842663</td>
      <td>-0.590719</td>
      <td>1.320527</td>
      <td>0.062965</td>
      <td>-0.067474</td>
      <td>-0.237239</td>
      <td>0.368211</td>
      <td>0.280577</td>
      <td>1.381760</td>
      <td>1.218955</td>
      <td>0.396005</td>
      <td>-1.002436</td>
      <td>0.183653</td>
      <td>0.039579</td>
      <td>-0.978855</td>
      <td>0.529363</td>
      <td>0.578351</td>
      <td>-0.674258</td>
      <td>0.317965</td>
      <td>0.721630</td>
      <td>0.110751</td>
      <td>0.004878</td>
      <td>-0.183581</td>
      <td>0.284628</td>
      <td>-0.592341</td>
      <td>-0.437656</td>
      <td>-0.108155</td>
      <td>0.102589</td>
      <td>-0.277129</td>
      <td>-0.782973</td>
      <td>-1.375782</td>
      <td>0.124448</td>
      <td>-0.139319</td>
      <td>-0.005210</td>
      <td>0.746988</td>
      <td>0.097472</td>
      <td>...</td>
      <td>-0.287075</td>
      <td>0.538441</td>
      <td>-0.040269</td>
      <td>0.628080</td>
      <td>-0.038550</td>
      <td>-0.753627</td>
      <td>-1.455310</td>
      <td>0.468034</td>
      <td>-0.043520</td>
      <td>0.469583</td>
      <td>0.493464</td>
      <td>0.469753</td>
      <td>0.044360</td>
      <td>-0.864934</td>
      <td>-0.134977</td>
      <td>0.846478</td>
      <td>1.706600</td>
      <td>0.929059</td>
      <td>0.146883</td>
      <td>-0.922255</td>
      <td>0.283774</td>
      <td>0.284561</td>
      <td>0.272595</td>
      <td>-1.080808</td>
      <td>-0.010306</td>
      <td>-1.010081</td>
      <td>-0.257361</td>
      <td>-0.996501</td>
      <td>-0.651352</td>
      <td>0.161330</td>
      <td>0.682598</td>
      <td>-0.522219</td>
      <td>-0.754831</td>
      <td>-0.586772</td>
      <td>-0.494661</td>
      <td>0.248452</td>
      <td>1.122603</td>
      <td>-1.463890</td>
      <td>-0.881937</td>
      <td>0.132329</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-0.433211</td>
      <td>0.161404</td>
      <td>-0.062906</td>
      <td>0.245573</td>
      <td>0.319626</td>
      <td>0.116642</td>
      <td>0.948202</td>
      <td>-0.136705</td>
      <td>-0.605030</td>
      <td>0.287027</td>
      <td>1.185758</td>
      <td>0.770183</td>
      <td>1.160687</td>
      <td>0.688926</td>
      <td>1.177615</td>
      <td>0.181142</td>
      <td>0.071083</td>
      <td>-0.885647</td>
      <td>-0.498562</td>
      <td>0.168946</td>
      <td>-0.767514</td>
      <td>-0.257114</td>
      <td>-0.377106</td>
      <td>-0.216488</td>
      <td>0.035986</td>
      <td>-0.030399</td>
      <td>-0.371319</td>
      <td>-0.326248</td>
      <td>1.042293</td>
      <td>-0.023898</td>
      <td>0.090471</td>
      <td>0.360373</td>
      <td>-0.415901</td>
      <td>-1.370731</td>
      <td>-0.591080</td>
      <td>0.713128</td>
      <td>-0.089919</td>
      <td>-0.368138</td>
      <td>-0.620369</td>
      <td>-0.875270</td>
      <td>...</td>
      <td>0.024547</td>
      <td>0.297312</td>
      <td>-0.325585</td>
      <td>0.505958</td>
      <td>0.719745</td>
      <td>-0.292785</td>
      <td>-0.642854</td>
      <td>0.882607</td>
      <td>-0.487260</td>
      <td>0.016256</td>
      <td>0.630492</td>
      <td>-0.622474</td>
      <td>-0.341754</td>
      <td>-0.881650</td>
      <td>0.482923</td>
      <td>0.064743</td>
      <td>-0.112967</td>
      <td>-0.032257</td>
      <td>0.782501</td>
      <td>-0.878318</td>
      <td>-0.936852</td>
      <td>-1.223363</td>
      <td>-0.189560</td>
      <td>-0.248417</td>
      <td>-0.242512</td>
      <td>0.773055</td>
      <td>-1.148085</td>
      <td>-1.029429</td>
      <td>-0.640723</td>
      <td>-0.530469</td>
      <td>-0.462002</td>
      <td>0.237646</td>
      <td>0.336400</td>
      <td>-0.365646</td>
      <td>-0.994644</td>
      <td>-0.779133</td>
      <td>0.044627</td>
      <td>0.592201</td>
      <td>0.389700</td>
      <td>0.338679</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-0.778859</td>
      <td>-0.928352</td>
      <td>1.575904</td>
      <td>1.204644</td>
      <td>-1.230580</td>
      <td>-0.769768</td>
      <td>0.024658</td>
      <td>-0.476059</td>
      <td>-0.347506</td>
      <td>-0.362331</td>
      <td>0.550649</td>
      <td>0.256128</td>
      <td>1.070982</td>
      <td>0.310070</td>
      <td>0.186468</td>
      <td>0.029375</td>
      <td>-0.226054</td>
      <td>-1.562991</td>
      <td>-0.861106</td>
      <td>-0.082945</td>
      <td>0.003867</td>
      <td>-0.041976</td>
      <td>-0.041820</td>
      <td>0.273239</td>
      <td>0.948735</td>
      <td>0.521830</td>
      <td>-0.155585</td>
      <td>0.041861</td>
      <td>0.049917</td>
      <td>0.118550</td>
      <td>1.141876</td>
      <td>0.318646</td>
      <td>-0.035145</td>
      <td>-0.103484</td>
      <td>-0.360657</td>
      <td>-0.081663</td>
      <td>0.279319</td>
      <td>-1.014276</td>
      <td>-0.609832</td>
      <td>-0.909541</td>
      <td>...</td>
      <td>-1.485949</td>
      <td>-1.152154</td>
      <td>-0.299184</td>
      <td>0.411965</td>
      <td>-0.177892</td>
      <td>0.057809</td>
      <td>-0.090875</td>
      <td>-0.352823</td>
      <td>-0.859006</td>
      <td>-0.368788</td>
      <td>1.284723</td>
      <td>-0.670708</td>
      <td>0.776164</td>
      <td>0.629925</td>
      <td>0.258796</td>
      <td>1.097180</td>
      <td>0.701036</td>
      <td>-0.740447</td>
      <td>0.895817</td>
      <td>0.602663</td>
      <td>-0.289305</td>
      <td>0.279110</td>
      <td>0.128118</td>
      <td>-0.518185</td>
      <td>1.164405</td>
      <td>-0.101961</td>
      <td>1.654180</td>
      <td>0.891154</td>
      <td>1.045425</td>
      <td>-0.625594</td>
      <td>0.941739</td>
      <td>-0.279247</td>
      <td>-0.526224</td>
      <td>-2.104277</td>
      <td>-0.398786</td>
      <td>0.404404</td>
      <td>0.187786</td>
      <td>0.253443</td>
      <td>0.902537</td>
      <td>0.340399</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.703874</td>
      <td>-0.310335</td>
      <td>0.589907</td>
      <td>0.156613</td>
      <td>-0.530247</td>
      <td>0.115557</td>
      <td>0.779257</td>
      <td>0.027375</td>
      <td>0.340793</td>
      <td>0.232644</td>
      <td>0.631372</td>
      <td>1.105127</td>
      <td>0.482840</td>
      <td>1.088103</td>
      <td>0.052716</td>
      <td>0.432674</td>
      <td>-0.202402</td>
      <td>-0.028429</td>
      <td>-0.596657</td>
      <td>-0.646358</td>
      <td>0.563680</td>
      <td>-0.612727</td>
      <td>0.099283</td>
      <td>-0.537459</td>
      <td>-0.756317</td>
      <td>-1.398788</td>
      <td>0.182778</td>
      <td>0.731233</td>
      <td>-0.130834</td>
      <td>-0.447258</td>
      <td>0.732808</td>
      <td>-0.348959</td>
      <td>0.423316</td>
      <td>0.210152</td>
      <td>-0.756391</td>
      <td>0.170638</td>
      <td>-0.035672</td>
      <td>-0.047336</td>
      <td>-0.669434</td>
      <td>-0.639517</td>
      <td>...</td>
      <td>0.672193</td>
      <td>0.399403</td>
      <td>-0.720011</td>
      <td>0.703358</td>
      <td>-0.632582</td>
      <td>-0.327334</td>
      <td>0.122313</td>
      <td>-0.613636</td>
      <td>-0.393950</td>
      <td>0.920150</td>
      <td>1.174191</td>
      <td>0.321999</td>
      <td>0.211540</td>
      <td>-1.529202</td>
      <td>-1.642499</td>
      <td>-0.929810</td>
      <td>-0.622811</td>
      <td>0.416962</td>
      <td>-0.450050</td>
      <td>-0.361395</td>
      <td>-0.758279</td>
      <td>0.180994</td>
      <td>-0.905804</td>
      <td>-0.221559</td>
      <td>0.204360</td>
      <td>-0.513157</td>
      <td>-0.042022</td>
      <td>-0.375866</td>
      <td>0.001329</td>
      <td>-0.543448</td>
      <td>-0.170261</td>
      <td>0.693630</td>
      <td>-0.863054</td>
      <td>-0.048474</td>
      <td>-1.307493</td>
      <td>-0.855189</td>
      <td>0.599086</td>
      <td>1.620792</td>
      <td>0.542664</td>
      <td>-0.162581</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-1.133051</td>
      <td>-1.340201</td>
      <td>0.509261</td>
      <td>-0.259339</td>
      <td>-0.085749</td>
      <td>-1.267948</td>
      <td>-0.535709</td>
      <td>1.291079</td>
      <td>0.610738</td>
      <td>0.067657</td>
      <td>-0.625697</td>
      <td>0.816277</td>
      <td>0.591792</td>
      <td>0.431064</td>
      <td>0.223126</td>
      <td>-0.115357</td>
      <td>0.876710</td>
      <td>-0.843722</td>
      <td>0.130661</td>
      <td>0.126686</td>
      <td>-0.483762</td>
      <td>0.569310</td>
      <td>0.917657</td>
      <td>0.179368</td>
      <td>0.105549</td>
      <td>-0.481946</td>
      <td>-0.556401</td>
      <td>-0.860176</td>
      <td>-0.094999</td>
      <td>0.370383</td>
      <td>0.657148</td>
      <td>-0.515380</td>
      <td>-0.051215</td>
      <td>-1.130147</td>
      <td>-0.182342</td>
      <td>0.225278</td>
      <td>-0.953185</td>
      <td>0.229598</td>
      <td>-0.124314</td>
      <td>-0.492376</td>
      <td>...</td>
      <td>1.041009</td>
      <td>0.132063</td>
      <td>0.050247</td>
      <td>0.647104</td>
      <td>0.225788</td>
      <td>-0.158719</td>
      <td>0.026163</td>
      <td>-0.393574</td>
      <td>-0.268155</td>
      <td>0.564566</td>
      <td>-0.201539</td>
      <td>0.028333</td>
      <td>-0.121879</td>
      <td>0.020871</td>
      <td>-0.138870</td>
      <td>-0.029264</td>
      <td>-0.105626</td>
      <td>0.072322</td>
      <td>-0.286955</td>
      <td>-0.311598</td>
      <td>0.836164</td>
      <td>0.727043</td>
      <td>-0.311585</td>
      <td>-0.488390</td>
      <td>-0.442625</td>
      <td>-0.497731</td>
      <td>0.143456</td>
      <td>-0.850199</td>
      <td>-0.734147</td>
      <td>1.469376</td>
      <td>0.701794</td>
      <td>-0.361860</td>
      <td>0.253788</td>
      <td>-0.161634</td>
      <td>-0.030233</td>
      <td>0.801152</td>
      <td>0.305469</td>
      <td>-2.971766</td>
      <td>-1.648548</td>
      <td>-0.539327</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.609063</td>
      <td>0.375794</td>
      <td>0.892138</td>
      <td>-0.286286</td>
      <td>0.617040</td>
      <td>0.502787</td>
      <td>0.844407</td>
      <td>-0.177321</td>
      <td>-0.338600</td>
      <td>-0.649647</td>
      <td>-0.518563</td>
      <td>-1.061498</td>
      <td>0.097099</td>
      <td>0.304069</td>
      <td>-0.197249</td>
      <td>0.018864</td>
      <td>0.514715</td>
      <td>0.464996</td>
      <td>0.698932</td>
      <td>0.927255</td>
      <td>0.269306</td>
      <td>-0.462850</td>
      <td>-0.317286</td>
      <td>0.382096</td>
      <td>-0.539265</td>
      <td>-0.600494</td>
      <td>-0.066388</td>
      <td>0.590284</td>
      <td>-0.626713</td>
      <td>-0.553784</td>
      <td>0.515638</td>
      <td>0.705029</td>
      <td>-0.058749</td>
      <td>0.084870</td>
      <td>-0.209653</td>
      <td>-0.246167</td>
      <td>-1.330870</td>
      <td>-0.990126</td>
      <td>-1.148295</td>
      <td>-0.653171</td>
      <td>...</td>
      <td>-0.155266</td>
      <td>0.624386</td>
      <td>0.467277</td>
      <td>-0.208148</td>
      <td>-0.699000</td>
      <td>-1.689297</td>
      <td>-0.829115</td>
      <td>-0.199991</td>
      <td>0.564653</td>
      <td>-0.061308</td>
      <td>0.247137</td>
      <td>-1.106474</td>
      <td>0.191714</td>
      <td>-0.453511</td>
      <td>-1.130677</td>
      <td>-0.683745</td>
      <td>0.260486</td>
      <td>-0.046525</td>
      <td>-0.128923</td>
      <td>-0.945851</td>
      <td>0.243702</td>
      <td>-0.172867</td>
      <td>-0.619717</td>
      <td>-0.825322</td>
      <td>-0.319344</td>
      <td>-0.928705</td>
      <td>-0.264309</td>
      <td>-1.771545</td>
      <td>-0.878094</td>
      <td>0.269322</td>
      <td>0.656031</td>
      <td>-0.901563</td>
      <td>0.624419</td>
      <td>0.710676</td>
      <td>0.007759</td>
      <td>0.099814</td>
      <td>0.006834</td>
      <td>0.197845</td>
      <td>0.281190</td>
      <td>0.660987</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.020116</td>
      <td>-0.092369</td>
      <td>0.075103</td>
      <td>-1.393534</td>
      <td>0.253133</td>
      <td>-0.652420</td>
      <td>-0.372752</td>
      <td>-0.731253</td>
      <td>-0.681506</td>
      <td>0.395671</td>
      <td>0.170752</td>
      <td>0.145326</td>
      <td>-0.374707</td>
      <td>0.503325</td>
      <td>0.370516</td>
      <td>-0.419561</td>
      <td>1.130013</td>
      <td>-0.219286</td>
      <td>-0.992527</td>
      <td>0.623044</td>
      <td>0.673907</td>
      <td>-0.330198</td>
      <td>-0.457138</td>
      <td>0.213843</td>
      <td>-0.272082</td>
      <td>-0.943088</td>
      <td>-0.697077</td>
      <td>-0.300370</td>
      <td>0.131319</td>
      <td>-0.440052</td>
      <td>0.942224</td>
      <td>0.186260</td>
      <td>-0.384727</td>
      <td>-0.706167</td>
      <td>-0.746414</td>
      <td>-0.550795</td>
      <td>-0.215584</td>
      <td>-0.724585</td>
      <td>0.093075</td>
      <td>-1.287749</td>
      <td>...</td>
      <td>0.372757</td>
      <td>0.960648</td>
      <td>0.807623</td>
      <td>0.412032</td>
      <td>0.426671</td>
      <td>-0.437973</td>
      <td>0.311330</td>
      <td>-0.123316</td>
      <td>-0.417974</td>
      <td>-0.646960</td>
      <td>-0.553034</td>
      <td>-0.899776</td>
      <td>-0.583551</td>
      <td>-0.419156</td>
      <td>0.797003</td>
      <td>0.300726</td>
      <td>-0.408096</td>
      <td>0.310579</td>
      <td>0.089627</td>
      <td>0.015786</td>
      <td>0.682796</td>
      <td>-0.060657</td>
      <td>0.128896</td>
      <td>-1.005622</td>
      <td>-0.218327</td>
      <td>0.264388</td>
      <td>0.846413</td>
      <td>-0.709528</td>
      <td>-1.031125</td>
      <td>-0.052907</td>
      <td>-0.291005</td>
      <td>-1.339533</td>
      <td>-0.626519</td>
      <td>-0.404623</td>
      <td>-0.175381</td>
      <td>-0.550100</td>
      <td>0.571117</td>
      <td>0.237060</td>
      <td>0.490639</td>
      <td>0.097928</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-0.039780</td>
      <td>0.181287</td>
      <td>0.186951</td>
      <td>0.404982</td>
      <td>0.085710</td>
      <td>0.299148</td>
      <td>0.492696</td>
      <td>-0.021267</td>
      <td>-0.836626</td>
      <td>-0.103707</td>
      <td>0.683701</td>
      <td>0.889216</td>
      <td>0.802468</td>
      <td>0.507505</td>
      <td>1.055996</td>
      <td>-0.497336</td>
      <td>0.249489</td>
      <td>-0.076948</td>
      <td>-0.070928</td>
      <td>-0.050791</td>
      <td>0.831838</td>
      <td>0.701046</td>
      <td>-0.374876</td>
      <td>-0.310122</td>
      <td>-0.173572</td>
      <td>-0.599979</td>
      <td>-0.553216</td>
      <td>0.284067</td>
      <td>0.562250</td>
      <td>0.230715</td>
      <td>1.822086</td>
      <td>0.740742</td>
      <td>-0.193214</td>
      <td>-0.453530</td>
      <td>-0.523434</td>
      <td>-0.532221</td>
      <td>-0.554799</td>
      <td>-0.096816</td>
      <td>-0.933680</td>
      <td>-0.961608</td>
      <td>...</td>
      <td>0.407007</td>
      <td>0.142103</td>
      <td>0.180866</td>
      <td>-0.335536</td>
      <td>-0.175936</td>
      <td>-0.080971</td>
      <td>-0.225527</td>
      <td>-0.854963</td>
      <td>-0.316008</td>
      <td>-0.423048</td>
      <td>-0.291074</td>
      <td>-0.378184</td>
      <td>0.327770</td>
      <td>-0.706590</td>
      <td>-0.193664</td>
      <td>0.626155</td>
      <td>-0.084738</td>
      <td>-0.113573</td>
      <td>-0.046836</td>
      <td>0.394497</td>
      <td>-0.232306</td>
      <td>0.372691</td>
      <td>0.659946</td>
      <td>-0.283562</td>
      <td>0.500210</td>
      <td>-0.858737</td>
      <td>0.903690</td>
      <td>-0.268758</td>
      <td>-0.870892</td>
      <td>0.339323</td>
      <td>-0.151338</td>
      <td>-0.079333</td>
      <td>-0.355002</td>
      <td>0.615564</td>
      <td>0.054328</td>
      <td>0.583288</td>
      <td>-0.716530</td>
      <td>-0.351214</td>
      <td>0.234157</td>
      <td>0.596134</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-1.371257</td>
      <td>-0.727030</td>
      <td>-0.381965</td>
      <td>-0.280747</td>
      <td>-1.029244</td>
      <td>-0.672321</td>
      <td>0.336037</td>
      <td>-0.174973</td>
      <td>0.164323</td>
      <td>0.335470</td>
      <td>-0.830890</td>
      <td>-0.631203</td>
      <td>0.249148</td>
      <td>0.567671</td>
      <td>0.474048</td>
      <td>-0.676851</td>
      <td>0.816021</td>
      <td>0.119876</td>
      <td>-1.551426</td>
      <td>-0.391592</td>
      <td>-0.285197</td>
      <td>-0.254959</td>
      <td>0.121128</td>
      <td>0.133291</td>
      <td>-0.535093</td>
      <td>0.256695</td>
      <td>0.727991</td>
      <td>0.753312</td>
      <td>0.737429</td>
      <td>0.428371</td>
      <td>-0.253259</td>
      <td>0.310496</td>
      <td>0.284618</td>
      <td>0.458067</td>
      <td>0.193048</td>
      <td>-0.726845</td>
      <td>-0.888698</td>
      <td>0.162803</td>
      <td>0.720490</td>
      <td>-1.081749</td>
      <td>...</td>
      <td>-0.635295</td>
      <td>-0.055690</td>
      <td>0.569441</td>
      <td>1.005964</td>
      <td>-0.420558</td>
      <td>-0.532872</td>
      <td>-0.342434</td>
      <td>-0.360031</td>
      <td>0.155093</td>
      <td>-0.593921</td>
      <td>0.961964</td>
      <td>-0.161065</td>
      <td>0.349303</td>
      <td>0.006654</td>
      <td>-0.291669</td>
      <td>0.147568</td>
      <td>-0.087076</td>
      <td>-0.753323</td>
      <td>-0.497305</td>
      <td>-0.992466</td>
      <td>0.425705</td>
      <td>0.909972</td>
      <td>-0.355166</td>
      <td>0.323192</td>
      <td>0.196196</td>
      <td>0.106209</td>
      <td>-0.244161</td>
      <td>-2.267906</td>
      <td>0.008080</td>
      <td>0.271921</td>
      <td>1.304154</td>
      <td>0.728872</td>
      <td>-0.431978</td>
      <td>-0.024189</td>
      <td>-0.026514</td>
      <td>-0.507584</td>
      <td>0.121737</td>
      <td>-3.148162</td>
      <td>-2.772714</td>
      <td>-1.128423</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.514327</td>
      <td>-0.911314</td>
      <td>-0.661796</td>
      <td>0.506918</td>
      <td>-0.833888</td>
      <td>-0.482157</td>
      <td>0.199547</td>
      <td>-0.621143</td>
      <td>0.140405</td>
      <td>0.548610</td>
      <td>-0.716485</td>
      <td>1.323763</td>
      <td>0.316732</td>
      <td>1.533543</td>
      <td>0.229985</td>
      <td>0.574762</td>
      <td>-0.054801</td>
      <td>-1.033919</td>
      <td>0.033939</td>
      <td>-0.736535</td>
      <td>-0.176353</td>
      <td>-0.024623</td>
      <td>0.009794</td>
      <td>0.164970</td>
      <td>-0.738860</td>
      <td>-0.768856</td>
      <td>0.108854</td>
      <td>0.214646</td>
      <td>0.440122</td>
      <td>0.683362</td>
      <td>0.410382</td>
      <td>0.434235</td>
      <td>-0.082560</td>
      <td>-0.193870</td>
      <td>0.151806</td>
      <td>-0.668394</td>
      <td>-0.497227</td>
      <td>-0.131738</td>
      <td>0.046854</td>
      <td>-0.556286</td>
      <td>...</td>
      <td>-0.540566</td>
      <td>0.523727</td>
      <td>0.135379</td>
      <td>-0.574133</td>
      <td>-0.050469</td>
      <td>0.069466</td>
      <td>0.015449</td>
      <td>0.254695</td>
      <td>-0.028566</td>
      <td>1.102041</td>
      <td>1.174889</td>
      <td>-0.362122</td>
      <td>-0.163046</td>
      <td>-0.012731</td>
      <td>0.238107</td>
      <td>0.038262</td>
      <td>0.221556</td>
      <td>-1.025917</td>
      <td>-0.268843</td>
      <td>0.787964</td>
      <td>0.477075</td>
      <td>-0.321344</td>
      <td>-0.463350</td>
      <td>-1.103379</td>
      <td>-0.005318</td>
      <td>0.190349</td>
      <td>0.449673</td>
      <td>-0.264637</td>
      <td>-0.054746</td>
      <td>-0.087934</td>
      <td>-0.343622</td>
      <td>0.554918</td>
      <td>-0.189014</td>
      <td>-0.557205</td>
      <td>-0.053242</td>
      <td>0.668106</td>
      <td>-0.051897</td>
      <td>-0.673316</td>
      <td>-0.025860</td>
      <td>0.366327</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.038384</td>
      <td>0.352953</td>
      <td>-0.020151</td>
      <td>0.172950</td>
      <td>0.289142</td>
      <td>0.806909</td>
      <td>0.292425</td>
      <td>-0.073345</td>
      <td>0.984456</td>
      <td>0.528055</td>
      <td>-0.128839</td>
      <td>1.533581</td>
      <td>0.275689</td>
      <td>-0.721946</td>
      <td>0.049261</td>
      <td>-0.854029</td>
      <td>0.201390</td>
      <td>-0.788765</td>
      <td>-0.140202</td>
      <td>0.127610</td>
      <td>-0.020915</td>
      <td>0.106998</td>
      <td>0.190310</td>
      <td>0.999044</td>
      <td>-0.311146</td>
      <td>0.248336</td>
      <td>0.320594</td>
      <td>0.173705</td>
      <td>-0.300034</td>
      <td>-1.069610</td>
      <td>0.257137</td>
      <td>0.463315</td>
      <td>0.181777</td>
      <td>-0.328685</td>
      <td>-1.321811</td>
      <td>-0.465343</td>
      <td>0.560299</td>
      <td>-1.196742</td>
      <td>-0.267596</td>
      <td>-0.292031</td>
      <td>...</td>
      <td>-0.541726</td>
      <td>-0.003402</td>
      <td>-0.047003</td>
      <td>-0.013008</td>
      <td>-0.632713</td>
      <td>-0.848234</td>
      <td>-0.269101</td>
      <td>0.110893</td>
      <td>0.366819</td>
      <td>0.551045</td>
      <td>0.404156</td>
      <td>0.921808</td>
      <td>0.363792</td>
      <td>0.144361</td>
      <td>-0.683100</td>
      <td>0.151227</td>
      <td>0.118248</td>
      <td>0.351872</td>
      <td>0.795649</td>
      <td>0.509627</td>
      <td>0.770178</td>
      <td>-0.181501</td>
      <td>-0.521476</td>
      <td>0.180601</td>
      <td>0.763486</td>
      <td>-0.209959</td>
      <td>1.185764</td>
      <td>-0.759681</td>
      <td>0.264864</td>
      <td>-1.069364</td>
      <td>-0.185055</td>
      <td>-0.590163</td>
      <td>-0.262357</td>
      <td>-0.849410</td>
      <td>0.206706</td>
      <td>-0.025410</td>
      <td>-0.630711</td>
      <td>0.813707</td>
      <td>0.763455</td>
      <td>0.518030</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.795174</td>
      <td>-0.152747</td>
      <td>0.158662</td>
      <td>0.248310</td>
      <td>0.182140</td>
      <td>-0.182567</td>
      <td>-0.132131</td>
      <td>-1.227944</td>
      <td>-1.028780</td>
      <td>0.608989</td>
      <td>-0.170221</td>
      <td>0.672176</td>
      <td>-0.201269</td>
      <td>-0.261739</td>
      <td>0.179817</td>
      <td>0.584930</td>
      <td>0.363050</td>
      <td>-0.786187</td>
      <td>-0.531480</td>
      <td>-0.959343</td>
      <td>-0.667130</td>
      <td>-1.147107</td>
      <td>0.345289</td>
      <td>-0.383639</td>
      <td>-0.925037</td>
      <td>-0.249478</td>
      <td>-0.258437</td>
      <td>-0.296761</td>
      <td>-1.241381</td>
      <td>-0.568865</td>
      <td>-0.180955</td>
      <td>-0.614994</td>
      <td>-0.370832</td>
      <td>-0.314770</td>
      <td>0.033422</td>
      <td>-0.788751</td>
      <td>-0.330196</td>
      <td>-0.918152</td>
      <td>-0.443291</td>
      <td>-0.716297</td>
      <td>...</td>
      <td>1.277491</td>
      <td>0.657184</td>
      <td>-0.443557</td>
      <td>0.521458</td>
      <td>0.207555</td>
      <td>0.643916</td>
      <td>-0.494404</td>
      <td>0.170705</td>
      <td>-0.507188</td>
      <td>0.745761</td>
      <td>0.653230</td>
      <td>-0.902599</td>
      <td>-0.149843</td>
      <td>-1.285690</td>
      <td>-0.256787</td>
      <td>0.727511</td>
      <td>-0.118110</td>
      <td>0.138769</td>
      <td>-0.607295</td>
      <td>-1.462986</td>
      <td>-0.035234</td>
      <td>-0.943346</td>
      <td>-1.121155</td>
      <td>-0.512131</td>
      <td>0.077572</td>
      <td>0.864560</td>
      <td>-0.169684</td>
      <td>0.833308</td>
      <td>0.122290</td>
      <td>-1.110770</td>
      <td>0.522581</td>
      <td>0.479386</td>
      <td>0.828180</td>
      <td>-0.015788</td>
      <td>-0.370562</td>
      <td>0.082215</td>
      <td>0.798966</td>
      <td>1.127598</td>
      <td>1.203769</td>
      <td>0.538981</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.265330</td>
      <td>-0.699368</td>
      <td>-1.492769</td>
      <td>-0.338210</td>
      <td>-0.237592</td>
      <td>0.421376</td>
      <td>0.544527</td>
      <td>-0.137083</td>
      <td>-0.230203</td>
      <td>-0.015809</td>
      <td>-1.372252</td>
      <td>0.055071</td>
      <td>0.145029</td>
      <td>-0.089411</td>
      <td>-0.100278</td>
      <td>0.014056</td>
      <td>0.289137</td>
      <td>-0.943218</td>
      <td>0.298474</td>
      <td>0.460451</td>
      <td>0.284093</td>
      <td>0.426054</td>
      <td>0.678682</td>
      <td>-0.582316</td>
      <td>-0.104524</td>
      <td>-0.519382</td>
      <td>0.151579</td>
      <td>0.570194</td>
      <td>-0.301536</td>
      <td>-0.446971</td>
      <td>0.718462</td>
      <td>-0.125608</td>
      <td>0.171401</td>
      <td>0.235797</td>
      <td>0.204925</td>
      <td>-0.105189</td>
      <td>-0.082760</td>
      <td>-0.050251</td>
      <td>-0.693991</td>
      <td>-0.723692</td>
      <td>...</td>
      <td>-0.299415</td>
      <td>0.225513</td>
      <td>-0.388871</td>
      <td>0.439217</td>
      <td>-0.797090</td>
      <td>0.020182</td>
      <td>0.437865</td>
      <td>0.779217</td>
      <td>-0.290863</td>
      <td>0.283755</td>
      <td>-0.094726</td>
      <td>-0.649567</td>
      <td>-0.188856</td>
      <td>0.585566</td>
      <td>0.448478</td>
      <td>0.174978</td>
      <td>0.609927</td>
      <td>0.435314</td>
      <td>0.145025</td>
      <td>-0.317768</td>
      <td>0.713950</td>
      <td>1.102629</td>
      <td>-0.533607</td>
      <td>-0.393658</td>
      <td>-0.170909</td>
      <td>0.111372</td>
      <td>-0.137195</td>
      <td>-0.008410</td>
      <td>0.155102</td>
      <td>0.587325</td>
      <td>0.660822</td>
      <td>0.586666</td>
      <td>0.180236</td>
      <td>1.059931</td>
      <td>0.098392</td>
      <td>-0.053081</td>
      <td>0.321234</td>
      <td>-2.022990</td>
      <td>-1.386619</td>
      <td>0.192103</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.549561</td>
      <td>0.111809</td>
      <td>-0.012674</td>
      <td>0.347173</td>
      <td>0.697477</td>
      <td>0.050269</td>
      <td>0.346655</td>
      <td>0.579362</td>
      <td>-0.053975</td>
      <td>0.292020</td>
      <td>-0.590308</td>
      <td>-0.146626</td>
      <td>-0.230920</td>
      <td>0.053705</td>
      <td>0.096477</td>
      <td>-0.317617</td>
      <td>-0.887607</td>
      <td>-0.100231</td>
      <td>-0.853306</td>
      <td>-0.104268</td>
      <td>-0.382875</td>
      <td>-0.097366</td>
      <td>0.470197</td>
      <td>-0.587187</td>
      <td>-0.058714</td>
      <td>-0.803572</td>
      <td>-0.296525</td>
      <td>-0.211852</td>
      <td>0.069676</td>
      <td>-0.231756</td>
      <td>0.768873</td>
      <td>-0.534511</td>
      <td>-0.863648</td>
      <td>-0.699933</td>
      <td>-1.050080</td>
      <td>-0.019560</td>
      <td>-1.739268</td>
      <td>-0.305934</td>
      <td>-0.178771</td>
      <td>-0.509184</td>
      <td>...</td>
      <td>0.346217</td>
      <td>1.055156</td>
      <td>0.529957</td>
      <td>0.017919</td>
      <td>0.793790</td>
      <td>0.315560</td>
      <td>-0.035685</td>
      <td>0.262389</td>
      <td>-0.197995</td>
      <td>0.216734</td>
      <td>1.206603</td>
      <td>-0.529380</td>
      <td>-0.007321</td>
      <td>0.342605</td>
      <td>-0.216451</td>
      <td>-0.205220</td>
      <td>0.327110</td>
      <td>-0.046241</td>
      <td>1.290019</td>
      <td>0.411918</td>
      <td>0.296914</td>
      <td>-0.061236</td>
      <td>0.242170</td>
      <td>0.336238</td>
      <td>0.744483</td>
      <td>1.134598</td>
      <td>0.311692</td>
      <td>-0.730088</td>
      <td>-2.355469</td>
      <td>0.300969</td>
      <td>0.242049</td>
      <td>-1.004610</td>
      <td>-0.886809</td>
      <td>-0.381903</td>
      <td>0.157980</td>
      <td>-0.849366</td>
      <td>0.158042</td>
      <td>0.288032</td>
      <td>0.386684</td>
      <td>-0.214823</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.202390</td>
      <td>-0.879068</td>
      <td>-1.511515</td>
      <td>-1.317882</td>
      <td>-1.458824</td>
      <td>-0.784047</td>
      <td>0.562600</td>
      <td>0.320023</td>
      <td>-0.519062</td>
      <td>-0.123234</td>
      <td>-0.340290</td>
      <td>0.273721</td>
      <td>-0.695821</td>
      <td>0.499090</td>
      <td>0.405669</td>
      <td>1.203959</td>
      <td>-0.155115</td>
      <td>-0.001021</td>
      <td>0.703348</td>
      <td>0.596078</td>
      <td>-0.279516</td>
      <td>0.576316</td>
      <td>0.599024</td>
      <td>-0.175872</td>
      <td>-1.014181</td>
      <td>-1.004806</td>
      <td>-0.017042</td>
      <td>-0.337120</td>
      <td>0.257426</td>
      <td>0.280874</td>
      <td>0.891473</td>
      <td>0.551747</td>
      <td>0.607253</td>
      <td>0.461354</td>
      <td>-0.801059</td>
      <td>-0.342244</td>
      <td>-0.330808</td>
      <td>-0.597733</td>
      <td>-0.441700</td>
      <td>-0.029822</td>
      <td>...</td>
      <td>-0.636428</td>
      <td>0.655444</td>
      <td>-0.391040</td>
      <td>0.348469</td>
      <td>0.629366</td>
      <td>-0.481929</td>
      <td>0.318452</td>
      <td>0.504719</td>
      <td>0.422711</td>
      <td>0.481501</td>
      <td>-0.215637</td>
      <td>0.482183</td>
      <td>0.193870</td>
      <td>-0.616455</td>
      <td>0.014322</td>
      <td>0.094720</td>
      <td>-0.165731</td>
      <td>-0.228118</td>
      <td>0.345422</td>
      <td>-0.909559</td>
      <td>-0.325360</td>
      <td>0.143229</td>
      <td>-0.267558</td>
      <td>-0.236308</td>
      <td>0.163872</td>
      <td>-0.744530</td>
      <td>-0.627660</td>
      <td>-0.870163</td>
      <td>0.290030</td>
      <td>-0.161145</td>
      <td>-0.918029</td>
      <td>-0.613991</td>
      <td>-1.138553</td>
      <td>0.365520</td>
      <td>-0.059281</td>
      <td>-0.977155</td>
      <td>0.166365</td>
      <td>-1.583080</td>
      <td>-0.430632</td>
      <td>-0.366331</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.212873</td>
      <td>-0.315337</td>
      <td>0.121705</td>
      <td>-0.421256</td>
      <td>-0.021882</td>
      <td>0.389595</td>
      <td>1.258425</td>
      <td>0.069990</td>
      <td>-0.451351</td>
      <td>-0.211787</td>
      <td>0.005003</td>
      <td>-0.032935</td>
      <td>-0.192150</td>
      <td>-0.602387</td>
      <td>-0.661960</td>
      <td>0.303877</td>
      <td>-0.337614</td>
      <td>-0.225426</td>
      <td>-0.044239</td>
      <td>0.342132</td>
      <td>0.016721</td>
      <td>0.427562</td>
      <td>-0.581119</td>
      <td>0.842034</td>
      <td>1.050234</td>
      <td>-0.778337</td>
      <td>-1.280173</td>
      <td>-0.120772</td>
      <td>-0.209725</td>
      <td>-0.267222</td>
      <td>0.698568</td>
      <td>0.491199</td>
      <td>-0.387186</td>
      <td>0.178821</td>
      <td>-1.109574</td>
      <td>-0.859668</td>
      <td>0.043292</td>
      <td>-0.041079</td>
      <td>-0.735570</td>
      <td>-1.559588</td>
      <td>...</td>
      <td>-0.890166</td>
      <td>-0.325314</td>
      <td>0.205355</td>
      <td>0.422816</td>
      <td>0.466713</td>
      <td>0.207227</td>
      <td>0.470212</td>
      <td>0.950232</td>
      <td>-0.387362</td>
      <td>0.227280</td>
      <td>0.580025</td>
      <td>-0.580880</td>
      <td>-0.160283</td>
      <td>0.352612</td>
      <td>1.028502</td>
      <td>0.022341</td>
      <td>-0.256242</td>
      <td>-0.746621</td>
      <td>-0.231515</td>
      <td>-1.025478</td>
      <td>-0.070808</td>
      <td>0.439443</td>
      <td>-0.199974</td>
      <td>-0.392869</td>
      <td>-1.085490</td>
      <td>0.012689</td>
      <td>-0.167978</td>
      <td>-0.132532</td>
      <td>-0.131661</td>
      <td>-0.854933</td>
      <td>0.070087</td>
      <td>-0.522533</td>
      <td>1.011725</td>
      <td>0.868939</td>
      <td>0.820249</td>
      <td>-0.069708</td>
      <td>0.303886</td>
      <td>1.230833</td>
      <td>1.452401</td>
      <td>0.366119</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-0.308218</td>
      <td>-0.568558</td>
      <td>-0.260256</td>
      <td>-0.746984</td>
      <td>0.346264</td>
      <td>-0.066705</td>
      <td>0.174796</td>
      <td>0.456748</td>
      <td>-0.048097</td>
      <td>-0.054805</td>
      <td>-0.340342</td>
      <td>0.462618</td>
      <td>-0.123511</td>
      <td>0.432773</td>
      <td>1.102133</td>
      <td>0.503894</td>
      <td>0.452425</td>
      <td>-0.918991</td>
      <td>0.470692</td>
      <td>0.319899</td>
      <td>0.338348</td>
      <td>0.625352</td>
      <td>0.915489</td>
      <td>-0.717743</td>
      <td>-0.600495</td>
      <td>-0.098444</td>
      <td>-0.507814</td>
      <td>-0.652444</td>
      <td>-0.301566</td>
      <td>-0.091895</td>
      <td>-0.060872</td>
      <td>0.337362</td>
      <td>0.502218</td>
      <td>-0.037064</td>
      <td>-1.263885</td>
      <td>-1.665152</td>
      <td>-0.983182</td>
      <td>-0.842624</td>
      <td>-0.435927</td>
      <td>-1.107529</td>
      <td>...</td>
      <td>-0.668309</td>
      <td>0.511420</td>
      <td>0.494742</td>
      <td>-0.980237</td>
      <td>-0.007779</td>
      <td>-0.058278</td>
      <td>-0.567303</td>
      <td>-0.357040</td>
      <td>-0.075538</td>
      <td>-0.140508</td>
      <td>0.150111</td>
      <td>-0.247312</td>
      <td>1.332302</td>
      <td>-0.822589</td>
      <td>0.241913</td>
      <td>1.233275</td>
      <td>-0.508290</td>
      <td>-0.106346</td>
      <td>0.817909</td>
      <td>-0.598775</td>
      <td>0.128867</td>
      <td>-0.428943</td>
      <td>-0.973289</td>
      <td>-1.007088</td>
      <td>0.645365</td>
      <td>0.603582</td>
      <td>0.230743</td>
      <td>-0.581243</td>
      <td>0.597022</td>
      <td>1.208388</td>
      <td>0.671916</td>
      <td>-0.030771</td>
      <td>-0.239179</td>
      <td>-0.253320</td>
      <td>-1.344942</td>
      <td>-0.162298</td>
      <td>-0.233563</td>
      <td>-1.003968</td>
      <td>-0.807883</td>
      <td>-0.093976</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>0.503745</td>
      <td>0.184846</td>
      <td>-1.465850</td>
      <td>-0.002585</td>
      <td>0.289400</td>
      <td>-0.780440</td>
      <td>0.026435</td>
      <td>0.668474</td>
      <td>1.026399</td>
      <td>0.279995</td>
      <td>0.782793</td>
      <td>0.827584</td>
      <td>0.957817</td>
      <td>0.584688</td>
      <td>-0.581240</td>
      <td>-0.233316</td>
      <td>0.248683</td>
      <td>-0.367875</td>
      <td>-0.394351</td>
      <td>0.199111</td>
      <td>0.145490</td>
      <td>-0.170733</td>
      <td>-0.359136</td>
      <td>0.125762</td>
      <td>0.188498</td>
      <td>0.617986</td>
      <td>0.591907</td>
      <td>0.570216</td>
      <td>0.151466</td>
      <td>-0.647832</td>
      <td>-0.566233</td>
      <td>-0.709175</td>
      <td>-0.647072</td>
      <td>0.700283</td>
      <td>0.291247</td>
      <td>0.755667</td>
      <td>1.277456</td>
      <td>-0.010040</td>
      <td>0.314624</td>
      <td>0.954775</td>
      <td>...</td>
      <td>0.260506</td>
      <td>-0.682272</td>
      <td>-1.355411</td>
      <td>-0.510928</td>
      <td>0.395884</td>
      <td>0.423692</td>
      <td>0.012471</td>
      <td>-0.151113</td>
      <td>1.334265</td>
      <td>0.676806</td>
      <td>-0.038176</td>
      <td>-0.170570</td>
      <td>-1.186244</td>
      <td>0.126815</td>
      <td>0.190632</td>
      <td>0.854617</td>
      <td>0.674739</td>
      <td>-0.236563</td>
      <td>0.030423</td>
      <td>1.140672</td>
      <td>0.675125</td>
      <td>0.649914</td>
      <td>0.722478</td>
      <td>-0.039414</td>
      <td>-0.101307</td>
      <td>1.010778</td>
      <td>1.084234</td>
      <td>0.233436</td>
      <td>-1.157435</td>
      <td>-0.350853</td>
      <td>-0.554789</td>
      <td>-0.948251</td>
      <td>-0.330809</td>
      <td>0.600393</td>
      <td>0.288921</td>
      <td>0.261385</td>
      <td>0.078612</td>
      <td>1.136684</td>
      <td>0.633770</td>
      <td>-0.090452</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.562034</td>
      <td>0.100461</td>
      <td>-0.327360</td>
      <td>0.812432</td>
      <td>0.374854</td>
      <td>0.062427</td>
      <td>0.495324</td>
      <td>0.992061</td>
      <td>-1.050927</td>
      <td>-1.063962</td>
      <td>-1.270667</td>
      <td>-0.133471</td>
      <td>-0.364452</td>
      <td>0.305746</td>
      <td>0.109635</td>
      <td>0.225512</td>
      <td>0.252758</td>
      <td>-0.671637</td>
      <td>-0.657132</td>
      <td>0.023075</td>
      <td>-1.158049</td>
      <td>-1.096809</td>
      <td>-0.872458</td>
      <td>-0.880578</td>
      <td>-0.822742</td>
      <td>0.005345</td>
      <td>0.110063</td>
      <td>-0.493302</td>
      <td>0.128687</td>
      <td>-0.406174</td>
      <td>-0.796281</td>
      <td>0.660559</td>
      <td>0.252479</td>
      <td>0.070627</td>
      <td>0.241726</td>
      <td>-0.380177</td>
      <td>1.060302</td>
      <td>0.588907</td>
      <td>0.404934</td>
      <td>0.807784</td>
      <td>...</td>
      <td>-0.180992</td>
      <td>0.806263</td>
      <td>0.891331</td>
      <td>-0.060877</td>
      <td>1.484787</td>
      <td>0.064470</td>
      <td>-1.112007</td>
      <td>-0.214213</td>
      <td>-0.559739</td>
      <td>0.844675</td>
      <td>0.712793</td>
      <td>0.346234</td>
      <td>-1.214448</td>
      <td>1.097395</td>
      <td>-0.546514</td>
      <td>-0.185699</td>
      <td>1.246869</td>
      <td>0.888883</td>
      <td>-0.242089</td>
      <td>-0.307287</td>
      <td>-0.039610</td>
      <td>-0.223488</td>
      <td>-0.672487</td>
      <td>0.091308</td>
      <td>-0.467074</td>
      <td>-1.068025</td>
      <td>-0.640268</td>
      <td>-0.105869</td>
      <td>-0.890694</td>
      <td>-0.744979</td>
      <td>0.352491</td>
      <td>-1.552839</td>
      <td>-0.338475</td>
      <td>0.461513</td>
      <td>-0.035875</td>
      <td>0.338909</td>
      <td>-0.264194</td>
      <td>3.013418</td>
      <td>2.028084</td>
      <td>1.634384</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.128931</td>
      <td>0.911490</td>
      <td>-0.873462</td>
      <td>0.469340</td>
      <td>-0.117067</td>
      <td>-0.716193</td>
      <td>0.242315</td>
      <td>0.763864</td>
      <td>0.300379</td>
      <td>-0.740842</td>
      <td>-0.581584</td>
      <td>0.626153</td>
      <td>0.633778</td>
      <td>0.676066</td>
      <td>-0.429839</td>
      <td>-0.038202</td>
      <td>0.316771</td>
      <td>-0.835848</td>
      <td>-0.179675</td>
      <td>-0.543138</td>
      <td>-0.118582</td>
      <td>-0.773785</td>
      <td>-0.698746</td>
      <td>-0.239678</td>
      <td>0.468242</td>
      <td>0.165781</td>
      <td>0.344476</td>
      <td>0.086697</td>
      <td>0.016559</td>
      <td>-0.367454</td>
      <td>-0.179807</td>
      <td>-0.176186</td>
      <td>0.616950</td>
      <td>0.070723</td>
      <td>0.013945</td>
      <td>0.352435</td>
      <td>1.289375</td>
      <td>-0.314198</td>
      <td>-0.632043</td>
      <td>0.341772</td>
      <td>...</td>
      <td>0.334955</td>
      <td>-0.090530</td>
      <td>0.198510</td>
      <td>-0.252193</td>
      <td>0.091536</td>
      <td>0.014809</td>
      <td>-1.206588</td>
      <td>-0.280855</td>
      <td>-0.836705</td>
      <td>0.015184</td>
      <td>-0.652083</td>
      <td>-0.434992</td>
      <td>-0.087224</td>
      <td>0.636896</td>
      <td>0.000528</td>
      <td>0.451997</td>
      <td>1.126995</td>
      <td>0.979635</td>
      <td>0.415503</td>
      <td>-0.134979</td>
      <td>-0.128420</td>
      <td>0.945518</td>
      <td>-0.010229</td>
      <td>0.321970</td>
      <td>0.746492</td>
      <td>-0.020075</td>
      <td>1.555596</td>
      <td>0.142256</td>
      <td>-0.770666</td>
      <td>-0.264646</td>
      <td>0.211041</td>
      <td>-0.037265</td>
      <td>0.115964</td>
      <td>1.219338</td>
      <td>0.390977</td>
      <td>0.210529</td>
      <td>-0.108848</td>
      <td>2.028653</td>
      <td>1.797491</td>
      <td>0.088779</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.315238</td>
      <td>1.450782</td>
      <td>0.911592</td>
      <td>0.713893</td>
      <td>1.093638</td>
      <td>-0.131006</td>
      <td>0.701459</td>
      <td>1.183626</td>
      <td>0.415409</td>
      <td>-0.497420</td>
      <td>-0.784386</td>
      <td>-0.021281</td>
      <td>0.861125</td>
      <td>0.660303</td>
      <td>0.391575</td>
      <td>0.924912</td>
      <td>1.234919</td>
      <td>0.450538</td>
      <td>-1.003575</td>
      <td>-0.925865</td>
      <td>-1.114430</td>
      <td>-1.776175</td>
      <td>-0.673335</td>
      <td>-0.923749</td>
      <td>-1.015528</td>
      <td>-0.000869</td>
      <td>-0.598902</td>
      <td>0.036852</td>
      <td>-0.716007</td>
      <td>0.553729</td>
      <td>-0.733443</td>
      <td>-1.362832</td>
      <td>0.293862</td>
      <td>0.802968</td>
      <td>-0.037373</td>
      <td>-0.779859</td>
      <td>0.340371</td>
      <td>-0.363111</td>
      <td>0.276290</td>
      <td>0.355930</td>
      <td>...</td>
      <td>0.442060</td>
      <td>0.372568</td>
      <td>0.254321</td>
      <td>0.698386</td>
      <td>0.000253</td>
      <td>0.129401</td>
      <td>-0.080981</td>
      <td>0.575490</td>
      <td>-0.329195</td>
      <td>0.120115</td>
      <td>0.122098</td>
      <td>0.400394</td>
      <td>0.453894</td>
      <td>0.443615</td>
      <td>-0.468217</td>
      <td>0.183671</td>
      <td>-0.609168</td>
      <td>0.163351</td>
      <td>0.701425</td>
      <td>1.666344</td>
      <td>0.132412</td>
      <td>-0.022510</td>
      <td>0.228095</td>
      <td>-0.277052</td>
      <td>0.262986</td>
      <td>0.973047</td>
      <td>0.525410</td>
      <td>0.335416</td>
      <td>-0.049397</td>
      <td>0.470394</td>
      <td>0.698472</td>
      <td>0.269306</td>
      <td>-0.036855</td>
      <td>0.396868</td>
      <td>-0.473111</td>
      <td>0.831634</td>
      <td>-0.120077</td>
      <td>1.421979</td>
      <td>0.769352</td>
      <td>0.190170</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.246979</td>
      <td>0.124139</td>
      <td>-0.347166</td>
      <td>0.402035</td>
      <td>-0.409304</td>
      <td>-0.879837</td>
      <td>-0.418114</td>
      <td>0.539481</td>
      <td>0.818711</td>
      <td>0.042563</td>
      <td>-0.133219</td>
      <td>0.276448</td>
      <td>-1.343754</td>
      <td>0.869245</td>
      <td>0.380968</td>
      <td>0.028575</td>
      <td>0.065973</td>
      <td>0.098867</td>
      <td>0.287528</td>
      <td>-0.737312</td>
      <td>0.499502</td>
      <td>-0.354040</td>
      <td>0.534039</td>
      <td>-0.509196</td>
      <td>0.129540</td>
      <td>-0.448608</td>
      <td>-0.319500</td>
      <td>-0.027052</td>
      <td>0.535318</td>
      <td>0.149880</td>
      <td>-0.933263</td>
      <td>0.169663</td>
      <td>-0.245226</td>
      <td>0.053838</td>
      <td>-0.245100</td>
      <td>0.629079</td>
      <td>1.172373</td>
      <td>-0.252756</td>
      <td>-0.331614</td>
      <td>-0.396747</td>
      <td>...</td>
      <td>0.519859</td>
      <td>-0.205378</td>
      <td>-0.303907</td>
      <td>0.599298</td>
      <td>0.562902</td>
      <td>0.383086</td>
      <td>-0.901839</td>
      <td>-0.402460</td>
      <td>-0.048204</td>
      <td>1.219568</td>
      <td>0.330818</td>
      <td>-0.173312</td>
      <td>-0.435783</td>
      <td>-0.426335</td>
      <td>-0.357632</td>
      <td>-0.225848</td>
      <td>-0.655112</td>
      <td>0.023033</td>
      <td>0.457663</td>
      <td>-0.327060</td>
      <td>0.351021</td>
      <td>1.513074</td>
      <td>0.580148</td>
      <td>-0.162080</td>
      <td>-0.369009</td>
      <td>1.314512</td>
      <td>0.218786</td>
      <td>0.016044</td>
      <td>-1.147364</td>
      <td>0.874326</td>
      <td>0.397706</td>
      <td>-0.401146</td>
      <td>-1.072276</td>
      <td>0.661206</td>
      <td>-0.139879</td>
      <td>0.288423</td>
      <td>0.361394</td>
      <td>-0.111036</td>
      <td>0.509092</td>
      <td>-0.102401</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7fa940ae5be0&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err        t          P&gt;|t|     2.5 %    97.5 %
D  1.073169  0.048101  22.3109  2.896108e-110  0.978894  1.167445
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  5.799 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.4.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>