
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17: http://docutils.sourceforge.net/" />

    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.f6b7ca918bee2f46fd9abac01cfb07d5.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1e043a052b0af929e4d8.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">


    
    <a class="navbar-brand" href="../index.html">
      <p class="title">DoubleML</p>
    </a>
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  DoubleML
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/install.html">
  Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/intro.html">
  Getting started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../guide/guide.html">
  User guide
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api.html">
  Python API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference external nav-link" href="https://docs.doubleml.org/r/stable/">
  R API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../release/release.html">
  Release notes
 </a>
</li>

        
      </ul>

      <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><p class="logo" style="text-align:center;"><a href="../index.html">
    <img class="logo" src="../logo.png" alt="Logo" width="65%" height="65%">
</a></p><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l2 current active">
  <a class="current reference internal" href="#">
   Multiway Cluster Robust DML
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="double_ml_bonus_data.html">
   DML: Bonus Data
  </a>
 </li>
</ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulate-multiway-cluster-data">
   Simulate multiway cluster data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
   Initialize the objects of class DoubleMLData and DoubleMLPLIV
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#split-samples-and-transfer-the-sample-splitting-to-the-object">
   Split samples and transfer the sample splitting to the object
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fit-the-model-and-show-a-summary">
   Fit the model and show a summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing">
   Visualization of sample splitting with tuple and linear indexing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold">
     Visualize sample splitting with tuples (one plot per fold)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
     Visualize sample splitting with linear indexing (one column per fold)
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<section id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.446276</td>
      <td>1.135799</td>
      <td>-0.111392</td>
      <td>0.649730</td>
      <td>0.518396</td>
      <td>0.809553</td>
      <td>0.089631</td>
      <td>-1.230634</td>
      <td>0.041195</td>
      <td>-0.187670</td>
      <td>-1.488199</td>
      <td>-0.557617</td>
      <td>-0.160221</td>
      <td>-1.649457</td>
      <td>0.495497</td>
      <td>1.142814</td>
      <td>0.781146</td>
      <td>0.406171</td>
      <td>-0.934200</td>
      <td>-0.118134</td>
      <td>-0.175775</td>
      <td>0.551417</td>
      <td>-1.070706</td>
      <td>0.373164</td>
      <td>-0.367510</td>
      <td>0.308665</td>
      <td>0.067606</td>
      <td>-1.075434</td>
      <td>0.259805</td>
      <td>-0.570340</td>
      <td>0.313119</td>
      <td>-0.231610</td>
      <td>0.154557</td>
      <td>1.740585</td>
      <td>0.686214</td>
      <td>0.609075</td>
      <td>0.256955</td>
      <td>-0.879441</td>
      <td>-0.585219</td>
      <td>-0.557280</td>
      <td>...</td>
      <td>0.501515</td>
      <td>-0.782313</td>
      <td>-1.004184</td>
      <td>0.218389</td>
      <td>-0.989575</td>
      <td>0.335918</td>
      <td>0.429088</td>
      <td>0.641225</td>
      <td>0.620519</td>
      <td>-0.524446</td>
      <td>0.243174</td>
      <td>-0.032751</td>
      <td>-0.867898</td>
      <td>-0.619073</td>
      <td>-0.457762</td>
      <td>-1.336256</td>
      <td>-1.409992</td>
      <td>-0.470271</td>
      <td>0.092916</td>
      <td>-0.569029</td>
      <td>0.327289</td>
      <td>-0.447837</td>
      <td>0.659684</td>
      <td>0.389032</td>
      <td>0.495075</td>
      <td>0.173064</td>
      <td>-1.278608</td>
      <td>-0.738364</td>
      <td>-1.054398</td>
      <td>0.277961</td>
      <td>0.702927</td>
      <td>0.672252</td>
      <td>-0.188288</td>
      <td>0.837968</td>
      <td>0.515653</td>
      <td>0.245478</td>
      <td>-0.860859</td>
      <td>2.424747</td>
      <td>1.619485</td>
      <td>1.445302</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.625276</td>
      <td>0.621593</td>
      <td>-0.354061</td>
      <td>0.943533</td>
      <td>0.116034</td>
      <td>0.414612</td>
      <td>0.857026</td>
      <td>-0.543706</td>
      <td>0.386595</td>
      <td>0.302631</td>
      <td>-0.697344</td>
      <td>-0.036524</td>
      <td>-0.026389</td>
      <td>-0.388735</td>
      <td>-0.636920</td>
      <td>1.008219</td>
      <td>0.516162</td>
      <td>-0.821373</td>
      <td>-0.652624</td>
      <td>0.453174</td>
      <td>1.197810</td>
      <td>0.176610</td>
      <td>0.022865</td>
      <td>-0.083237</td>
      <td>-0.938109</td>
      <td>0.326171</td>
      <td>1.558973</td>
      <td>-0.024450</td>
      <td>0.236742</td>
      <td>1.236719</td>
      <td>0.774088</td>
      <td>-0.063272</td>
      <td>-0.220479</td>
      <td>-1.102184</td>
      <td>-0.028192</td>
      <td>0.274296</td>
      <td>0.222993</td>
      <td>-0.701649</td>
      <td>-0.841046</td>
      <td>-1.384480</td>
      <td>...</td>
      <td>0.371994</td>
      <td>0.030252</td>
      <td>0.010231</td>
      <td>-1.281502</td>
      <td>-0.353809</td>
      <td>0.386001</td>
      <td>-0.788695</td>
      <td>0.233001</td>
      <td>-0.063584</td>
      <td>-1.327264</td>
      <td>-1.033951</td>
      <td>0.061775</td>
      <td>-2.065610</td>
      <td>0.251765</td>
      <td>0.666352</td>
      <td>-0.401910</td>
      <td>-1.116379</td>
      <td>-0.241302</td>
      <td>-0.070481</td>
      <td>1.438706</td>
      <td>0.440112</td>
      <td>-0.766180</td>
      <td>-0.244678</td>
      <td>0.093848</td>
      <td>-0.980792</td>
      <td>0.522583</td>
      <td>-0.244008</td>
      <td>-0.201274</td>
      <td>-0.384706</td>
      <td>0.277833</td>
      <td>1.152479</td>
      <td>0.414851</td>
      <td>0.337958</td>
      <td>0.345398</td>
      <td>0.460065</td>
      <td>1.390904</td>
      <td>0.299347</td>
      <td>0.828353</td>
      <td>1.010359</td>
      <td>0.188632</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.434525</td>
      <td>0.044252</td>
      <td>0.109592</td>
      <td>0.421953</td>
      <td>0.007184</td>
      <td>1.406640</td>
      <td>0.840195</td>
      <td>0.509423</td>
      <td>0.227858</td>
      <td>0.176118</td>
      <td>0.220504</td>
      <td>0.133923</td>
      <td>-0.431682</td>
      <td>0.171224</td>
      <td>-0.239518</td>
      <td>0.756354</td>
      <td>0.897864</td>
      <td>-0.251428</td>
      <td>-0.181484</td>
      <td>-0.197812</td>
      <td>0.774547</td>
      <td>-0.532481</td>
      <td>-0.321472</td>
      <td>-0.386611</td>
      <td>0.175501</td>
      <td>0.624905</td>
      <td>0.461348</td>
      <td>0.012545</td>
      <td>-0.813347</td>
      <td>0.114351</td>
      <td>-1.010175</td>
      <td>-0.084093</td>
      <td>-0.362071</td>
      <td>-0.409874</td>
      <td>0.010135</td>
      <td>1.073720</td>
      <td>0.893803</td>
      <td>-0.735184</td>
      <td>-0.260452</td>
      <td>-0.642907</td>
      <td>...</td>
      <td>0.550491</td>
      <td>0.262489</td>
      <td>-0.259606</td>
      <td>-0.172411</td>
      <td>-0.880981</td>
      <td>-0.410848</td>
      <td>-0.669201</td>
      <td>0.723950</td>
      <td>-0.448267</td>
      <td>-1.084777</td>
      <td>-1.053120</td>
      <td>0.212679</td>
      <td>-0.740147</td>
      <td>-0.014697</td>
      <td>0.152090</td>
      <td>0.467430</td>
      <td>-0.090417</td>
      <td>-0.388889</td>
      <td>0.168837</td>
      <td>0.252521</td>
      <td>0.345421</td>
      <td>-1.546954</td>
      <td>0.114787</td>
      <td>0.040855</td>
      <td>0.347332</td>
      <td>0.339278</td>
      <td>0.751293</td>
      <td>-0.073395</td>
      <td>-0.431998</td>
      <td>0.781073</td>
      <td>1.310092</td>
      <td>1.025607</td>
      <td>0.185566</td>
      <td>0.371903</td>
      <td>0.517155</td>
      <td>0.689458</td>
      <td>-0.594091</td>
      <td>-1.392926</td>
      <td>-0.860233</td>
      <td>-0.645827</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.205395</td>
      <td>1.070843</td>
      <td>-0.142847</td>
      <td>0.441839</td>
      <td>0.130837</td>
      <td>0.345842</td>
      <td>-0.180449</td>
      <td>-0.191339</td>
      <td>0.270344</td>
      <td>0.307752</td>
      <td>-0.915054</td>
      <td>-0.805050</td>
      <td>-0.065528</td>
      <td>1.376739</td>
      <td>-0.266139</td>
      <td>-0.159670</td>
      <td>0.645456</td>
      <td>-0.531970</td>
      <td>-0.131043</td>
      <td>0.164035</td>
      <td>0.635997</td>
      <td>-0.087314</td>
      <td>-0.533610</td>
      <td>0.401427</td>
      <td>-0.184320</td>
      <td>0.266960</td>
      <td>-0.795018</td>
      <td>-0.267834</td>
      <td>0.369592</td>
      <td>0.734524</td>
      <td>-0.799663</td>
      <td>-0.741114</td>
      <td>-0.186506</td>
      <td>0.324924</td>
      <td>-0.233955</td>
      <td>0.016482</td>
      <td>0.534234</td>
      <td>-0.334541</td>
      <td>0.670444</td>
      <td>-0.839155</td>
      <td>...</td>
      <td>0.112619</td>
      <td>-0.682865</td>
      <td>-1.131245</td>
      <td>0.461224</td>
      <td>0.204793</td>
      <td>0.994540</td>
      <td>-0.227303</td>
      <td>-0.001982</td>
      <td>0.785443</td>
      <td>-0.355499</td>
      <td>-0.846927</td>
      <td>-0.007200</td>
      <td>-0.618999</td>
      <td>0.349478</td>
      <td>1.242850</td>
      <td>0.086883</td>
      <td>0.298422</td>
      <td>0.119259</td>
      <td>0.124782</td>
      <td>1.085003</td>
      <td>0.401285</td>
      <td>-0.654717</td>
      <td>-0.397921</td>
      <td>0.625384</td>
      <td>0.869400</td>
      <td>0.265326</td>
      <td>0.281166</td>
      <td>-0.136441</td>
      <td>-0.700025</td>
      <td>0.190058</td>
      <td>0.223991</td>
      <td>0.256725</td>
      <td>-0.611719</td>
      <td>0.054694</td>
      <td>-0.293522</td>
      <td>-0.258859</td>
      <td>-0.605832</td>
      <td>0.609230</td>
      <td>0.134204</td>
      <td>-0.344183</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.087248</td>
      <td>-0.386958</td>
      <td>-0.083821</td>
      <td>0.182836</td>
      <td>1.312963</td>
      <td>0.913989</td>
      <td>1.037370</td>
      <td>0.246456</td>
      <td>0.686641</td>
      <td>0.309912</td>
      <td>0.527309</td>
      <td>-0.602156</td>
      <td>0.272560</td>
      <td>0.161938</td>
      <td>0.479229</td>
      <td>0.079830</td>
      <td>-0.329804</td>
      <td>0.194771</td>
      <td>0.314627</td>
      <td>-0.738156</td>
      <td>-0.389729</td>
      <td>-0.038687</td>
      <td>-0.405504</td>
      <td>0.630027</td>
      <td>-0.281028</td>
      <td>0.488125</td>
      <td>0.207188</td>
      <td>-0.438186</td>
      <td>0.622103</td>
      <td>-0.249836</td>
      <td>-0.822262</td>
      <td>-0.650839</td>
      <td>-0.606812</td>
      <td>-0.546704</td>
      <td>-1.255978</td>
      <td>0.549442</td>
      <td>0.255921</td>
      <td>1.267202</td>
      <td>0.124125</td>
      <td>-1.072276</td>
      <td>...</td>
      <td>0.107750</td>
      <td>0.595041</td>
      <td>-0.084317</td>
      <td>0.079600</td>
      <td>0.252368</td>
      <td>0.728665</td>
      <td>0.629767</td>
      <td>1.418396</td>
      <td>-0.225543</td>
      <td>-0.389204</td>
      <td>0.379081</td>
      <td>0.615304</td>
      <td>-1.146001</td>
      <td>0.674559</td>
      <td>0.358556</td>
      <td>0.430407</td>
      <td>-0.731060</td>
      <td>0.251750</td>
      <td>-0.415625</td>
      <td>0.471371</td>
      <td>-0.193423</td>
      <td>-0.707031</td>
      <td>0.091444</td>
      <td>-0.465673</td>
      <td>-0.078063</td>
      <td>-0.585712</td>
      <td>0.855693</td>
      <td>-0.786865</td>
      <td>0.360127</td>
      <td>-0.818544</td>
      <td>-0.355291</td>
      <td>-0.267636</td>
      <td>0.600092</td>
      <td>0.921768</td>
      <td>1.463165</td>
      <td>1.308912</td>
      <td>-0.856154</td>
      <td>-0.554470</td>
      <td>-0.164763</td>
      <td>-0.541868</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.186014</td>
      <td>0.793916</td>
      <td>-0.159173</td>
      <td>-0.117866</td>
      <td>1.006690</td>
      <td>-0.274875</td>
      <td>0.797290</td>
      <td>0.467237</td>
      <td>0.185463</td>
      <td>0.547836</td>
      <td>-0.228064</td>
      <td>-0.023818</td>
      <td>-0.746510</td>
      <td>0.300897</td>
      <td>-0.313054</td>
      <td>-0.795991</td>
      <td>-0.328798</td>
      <td>0.624307</td>
      <td>-0.086430</td>
      <td>1.007253</td>
      <td>0.618900</td>
      <td>0.330468</td>
      <td>-0.789898</td>
      <td>0.632915</td>
      <td>0.976592</td>
      <td>1.149851</td>
      <td>0.718176</td>
      <td>0.352019</td>
      <td>0.079024</td>
      <td>0.986110</td>
      <td>-0.429540</td>
      <td>-0.099663</td>
      <td>1.532110</td>
      <td>0.622707</td>
      <td>1.491982</td>
      <td>1.032730</td>
      <td>0.948251</td>
      <td>0.588511</td>
      <td>-0.141599</td>
      <td>-1.023680</td>
      <td>...</td>
      <td>-0.096861</td>
      <td>0.205695</td>
      <td>-0.270959</td>
      <td>-0.819703</td>
      <td>-0.712368</td>
      <td>-0.330564</td>
      <td>-0.246221</td>
      <td>-0.621761</td>
      <td>-1.299289</td>
      <td>-0.437623</td>
      <td>0.029286</td>
      <td>1.355271</td>
      <td>-1.355954</td>
      <td>0.680492</td>
      <td>-0.425972</td>
      <td>0.376570</td>
      <td>0.236431</td>
      <td>0.874126</td>
      <td>-0.791075</td>
      <td>0.011205</td>
      <td>-1.124613</td>
      <td>-1.031109</td>
      <td>0.103945</td>
      <td>-0.111463</td>
      <td>-0.577948</td>
      <td>0.194686</td>
      <td>0.473144</td>
      <td>-0.136309</td>
      <td>-0.396267</td>
      <td>-0.037860</td>
      <td>0.295275</td>
      <td>-0.283352</td>
      <td>-0.747637</td>
      <td>0.475536</td>
      <td>0.747413</td>
      <td>0.925076</td>
      <td>-0.178354</td>
      <td>1.038008</td>
      <td>0.726585</td>
      <td>0.489261</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.633890</td>
      <td>0.938490</td>
      <td>-1.407821</td>
      <td>0.321893</td>
      <td>-0.580860</td>
      <td>0.207325</td>
      <td>0.300199</td>
      <td>-0.136548</td>
      <td>0.629069</td>
      <td>-0.899807</td>
      <td>-0.916773</td>
      <td>0.614552</td>
      <td>-0.068593</td>
      <td>0.317865</td>
      <td>-0.438274</td>
      <td>-0.786631</td>
      <td>0.667135</td>
      <td>-0.099809</td>
      <td>0.973633</td>
      <td>-0.700377</td>
      <td>0.403954</td>
      <td>0.176142</td>
      <td>-0.126664</td>
      <td>0.536535</td>
      <td>-0.948917</td>
      <td>-0.268706</td>
      <td>0.590127</td>
      <td>0.417731</td>
      <td>-0.522674</td>
      <td>0.417079</td>
      <td>0.099588</td>
      <td>0.734195</td>
      <td>0.293942</td>
      <td>-0.003502</td>
      <td>-0.064657</td>
      <td>-0.610808</td>
      <td>0.909420</td>
      <td>0.285986</td>
      <td>-0.078234</td>
      <td>0.044498</td>
      <td>...</td>
      <td>1.392475</td>
      <td>0.183892</td>
      <td>0.199817</td>
      <td>-0.577595</td>
      <td>0.298699</td>
      <td>0.626026</td>
      <td>-1.704488</td>
      <td>-0.562184</td>
      <td>-0.014047</td>
      <td>-0.960024</td>
      <td>-0.443363</td>
      <td>0.527177</td>
      <td>0.278049</td>
      <td>-0.503683</td>
      <td>0.100475</td>
      <td>-0.578427</td>
      <td>0.293983</td>
      <td>0.470784</td>
      <td>0.488515</td>
      <td>0.677567</td>
      <td>1.217394</td>
      <td>0.141561</td>
      <td>0.404391</td>
      <td>0.225370</td>
      <td>0.044175</td>
      <td>0.374146</td>
      <td>0.676202</td>
      <td>1.313326</td>
      <td>-0.809336</td>
      <td>0.161981</td>
      <td>-0.445330</td>
      <td>0.001432</td>
      <td>-0.142770</td>
      <td>0.325861</td>
      <td>0.211681</td>
      <td>1.246043</td>
      <td>0.034557</td>
      <td>-0.311179</td>
      <td>0.452458</td>
      <td>0.105710</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.125401</td>
      <td>0.532647</td>
      <td>0.090080</td>
      <td>0.608610</td>
      <td>0.033036</td>
      <td>0.833472</td>
      <td>1.013177</td>
      <td>0.311393</td>
      <td>0.677420</td>
      <td>0.187956</td>
      <td>-0.419798</td>
      <td>0.264038</td>
      <td>0.445154</td>
      <td>0.866935</td>
      <td>-0.632708</td>
      <td>-0.043535</td>
      <td>-0.051653</td>
      <td>-0.047329</td>
      <td>-0.762768</td>
      <td>-0.846809</td>
      <td>0.116559</td>
      <td>0.659094</td>
      <td>0.072894</td>
      <td>0.538138</td>
      <td>-0.336623</td>
      <td>-0.151051</td>
      <td>0.647094</td>
      <td>-0.629750</td>
      <td>0.563257</td>
      <td>-0.156381</td>
      <td>0.161833</td>
      <td>0.396987</td>
      <td>0.847588</td>
      <td>-0.309799</td>
      <td>0.458527</td>
      <td>1.695368</td>
      <td>0.133919</td>
      <td>0.251357</td>
      <td>0.343852</td>
      <td>0.132888</td>
      <td>...</td>
      <td>-0.394619</td>
      <td>-0.286136</td>
      <td>-1.003109</td>
      <td>0.243749</td>
      <td>0.061314</td>
      <td>-0.153368</td>
      <td>0.484157</td>
      <td>-0.771989</td>
      <td>-0.563480</td>
      <td>-1.141983</td>
      <td>-0.932079</td>
      <td>-0.423864</td>
      <td>-1.201990</td>
      <td>-0.207177</td>
      <td>0.235506</td>
      <td>0.398452</td>
      <td>-0.892296</td>
      <td>-0.188524</td>
      <td>0.147424</td>
      <td>-1.006949</td>
      <td>-0.188245</td>
      <td>-1.610409</td>
      <td>0.887699</td>
      <td>0.604691</td>
      <td>-0.161556</td>
      <td>1.043587</td>
      <td>-0.005276</td>
      <td>-0.228866</td>
      <td>-0.163141</td>
      <td>-0.287273</td>
      <td>0.854077</td>
      <td>0.060953</td>
      <td>-0.758615</td>
      <td>0.339784</td>
      <td>1.357241</td>
      <td>1.045459</td>
      <td>0.801029</td>
      <td>1.819992</td>
      <td>1.631303</td>
      <td>0.814759</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.126378</td>
      <td>0.755846</td>
      <td>-0.529737</td>
      <td>0.152348</td>
      <td>-1.167279</td>
      <td>0.558104</td>
      <td>0.105851</td>
      <td>-0.159239</td>
      <td>0.443184</td>
      <td>0.511412</td>
      <td>-0.539214</td>
      <td>-0.073677</td>
      <td>0.200539</td>
      <td>-0.257202</td>
      <td>0.898457</td>
      <td>0.663272</td>
      <td>-0.283776</td>
      <td>-0.323973</td>
      <td>-0.490690</td>
      <td>-0.444542</td>
      <td>-0.664207</td>
      <td>0.457575</td>
      <td>-0.024723</td>
      <td>-0.970988</td>
      <td>-0.672210</td>
      <td>0.331957</td>
      <td>0.530404</td>
      <td>-1.034409</td>
      <td>-0.100141</td>
      <td>0.474496</td>
      <td>0.280232</td>
      <td>-0.130652</td>
      <td>-0.269914</td>
      <td>-0.330573</td>
      <td>0.224559</td>
      <td>1.137944</td>
      <td>0.848970</td>
      <td>1.226773</td>
      <td>0.420016</td>
      <td>0.728947</td>
      <td>...</td>
      <td>0.770834</td>
      <td>0.394638</td>
      <td>-0.706845</td>
      <td>-0.023179</td>
      <td>-1.392847</td>
      <td>-0.766123</td>
      <td>-0.485417</td>
      <td>-0.779057</td>
      <td>0.773239</td>
      <td>-0.666545</td>
      <td>-1.099078</td>
      <td>0.024350</td>
      <td>0.421027</td>
      <td>0.765975</td>
      <td>-1.152812</td>
      <td>0.234119</td>
      <td>0.944941</td>
      <td>0.363953</td>
      <td>0.022754</td>
      <td>-0.428400</td>
      <td>0.550258</td>
      <td>0.630388</td>
      <td>0.253787</td>
      <td>0.976517</td>
      <td>0.522056</td>
      <td>0.592942</td>
      <td>0.585210</td>
      <td>1.215600</td>
      <td>0.133198</td>
      <td>-1.122949</td>
      <td>0.772559</td>
      <td>-0.014746</td>
      <td>-0.435325</td>
      <td>-0.413972</td>
      <td>-0.319652</td>
      <td>-0.070371</td>
      <td>-0.248162</td>
      <td>0.758583</td>
      <td>0.459158</td>
      <td>0.382134</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-0.289798</td>
      <td>-0.667021</td>
      <td>-0.847350</td>
      <td>-0.099361</td>
      <td>0.543452</td>
      <td>0.404219</td>
      <td>0.407603</td>
      <td>0.153092</td>
      <td>0.702552</td>
      <td>-1.215949</td>
      <td>0.050024</td>
      <td>-1.200241</td>
      <td>-0.122252</td>
      <td>0.128679</td>
      <td>-0.885979</td>
      <td>0.085921</td>
      <td>0.326914</td>
      <td>1.054014</td>
      <td>0.234959</td>
      <td>0.347013</td>
      <td>-0.138746</td>
      <td>0.538091</td>
      <td>0.372361</td>
      <td>0.275971</td>
      <td>-0.309571</td>
      <td>-0.225371</td>
      <td>0.708381</td>
      <td>0.393219</td>
      <td>0.526414</td>
      <td>1.074060</td>
      <td>-0.687055</td>
      <td>-0.163268</td>
      <td>0.160158</td>
      <td>0.401849</td>
      <td>-0.355416</td>
      <td>0.012901</td>
      <td>0.157390</td>
      <td>0.385926</td>
      <td>0.388864</td>
      <td>-0.278544</td>
      <td>...</td>
      <td>0.732838</td>
      <td>-0.401955</td>
      <td>0.436157</td>
      <td>-0.136494</td>
      <td>0.532923</td>
      <td>-0.216152</td>
      <td>-0.458418</td>
      <td>0.286581</td>
      <td>-0.596795</td>
      <td>-0.570336</td>
      <td>-0.271792</td>
      <td>0.835646</td>
      <td>-1.020779</td>
      <td>0.235164</td>
      <td>-0.421759</td>
      <td>0.279784</td>
      <td>-0.403430</td>
      <td>0.585661</td>
      <td>-0.499898</td>
      <td>0.505476</td>
      <td>0.338107</td>
      <td>-0.216657</td>
      <td>1.650136</td>
      <td>0.273817</td>
      <td>0.293047</td>
      <td>-0.731853</td>
      <td>0.995107</td>
      <td>1.606333</td>
      <td>-0.134574</td>
      <td>0.612011</td>
      <td>0.170589</td>
      <td>0.457622</td>
      <td>-0.221679</td>
      <td>-0.554433</td>
      <td>-0.091021</td>
      <td>-0.065450</td>
      <td>-1.111985</td>
      <td>-2.887753</td>
      <td>-1.510062</td>
      <td>-0.994135</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.875297</td>
      <td>1.415557</td>
      <td>-0.208138</td>
      <td>-0.824112</td>
      <td>-0.188374</td>
      <td>-0.174119</td>
      <td>0.728024</td>
      <td>-0.409014</td>
      <td>0.516962</td>
      <td>0.091349</td>
      <td>-0.303133</td>
      <td>0.429259</td>
      <td>0.036306</td>
      <td>0.720979</td>
      <td>0.968599</td>
      <td>0.159726</td>
      <td>0.861610</td>
      <td>0.867468</td>
      <td>0.255200</td>
      <td>0.148085</td>
      <td>0.345794</td>
      <td>0.882490</td>
      <td>-0.122145</td>
      <td>0.494459</td>
      <td>-0.318154</td>
      <td>1.359420</td>
      <td>0.494536</td>
      <td>-1.116828</td>
      <td>0.049526</td>
      <td>0.631633</td>
      <td>0.719571</td>
      <td>0.067166</td>
      <td>0.726577</td>
      <td>-0.239530</td>
      <td>-0.309706</td>
      <td>0.349181</td>
      <td>1.161270</td>
      <td>-0.020284</td>
      <td>-0.160613</td>
      <td>-0.304338</td>
      <td>...</td>
      <td>-0.269842</td>
      <td>0.049609</td>
      <td>-0.164167</td>
      <td>-0.186712</td>
      <td>-0.023908</td>
      <td>-0.323625</td>
      <td>0.207052</td>
      <td>0.055149</td>
      <td>0.306092</td>
      <td>-0.991279</td>
      <td>0.720030</td>
      <td>0.224327</td>
      <td>-0.063189</td>
      <td>0.437701</td>
      <td>0.261367</td>
      <td>-0.218675</td>
      <td>-0.260889</td>
      <td>0.969884</td>
      <td>0.515154</td>
      <td>0.598631</td>
      <td>1.035989</td>
      <td>-0.346635</td>
      <td>0.612969</td>
      <td>0.865616</td>
      <td>0.324919</td>
      <td>-0.234123</td>
      <td>-0.260540</td>
      <td>0.652875</td>
      <td>0.105839</td>
      <td>0.943007</td>
      <td>-0.175001</td>
      <td>0.163140</td>
      <td>-0.160036</td>
      <td>-0.388690</td>
      <td>0.611664</td>
      <td>0.330780</td>
      <td>-0.593877</td>
      <td>2.877989</td>
      <td>2.296332</td>
      <td>1.449708</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.417705</td>
      <td>-0.564146</td>
      <td>-0.391701</td>
      <td>-0.211075</td>
      <td>0.146639</td>
      <td>0.552395</td>
      <td>-0.255956</td>
      <td>-1.162901</td>
      <td>0.426750</td>
      <td>-0.562327</td>
      <td>-1.312333</td>
      <td>0.728458</td>
      <td>0.021301</td>
      <td>-0.101630</td>
      <td>0.172826</td>
      <td>0.166265</td>
      <td>1.520811</td>
      <td>-0.285474</td>
      <td>-0.498326</td>
      <td>0.493636</td>
      <td>-0.190267</td>
      <td>0.720578</td>
      <td>-0.168228</td>
      <td>-0.191999</td>
      <td>-0.269104</td>
      <td>0.595881</td>
      <td>1.044868</td>
      <td>0.002498</td>
      <td>0.106038</td>
      <td>0.081409</td>
      <td>0.147586</td>
      <td>0.550232</td>
      <td>-0.453855</td>
      <td>0.328890</td>
      <td>1.183146</td>
      <td>0.050760</td>
      <td>1.024907</td>
      <td>0.298770</td>
      <td>0.489382</td>
      <td>0.314430</td>
      <td>...</td>
      <td>-0.252085</td>
      <td>-0.252867</td>
      <td>-1.290247</td>
      <td>-1.550194</td>
      <td>-0.978213</td>
      <td>-0.612976</td>
      <td>0.512591</td>
      <td>1.278357</td>
      <td>-0.026294</td>
      <td>-0.375765</td>
      <td>-0.021856</td>
      <td>0.466497</td>
      <td>-0.023826</td>
      <td>0.455776</td>
      <td>-0.320473</td>
      <td>0.094324</td>
      <td>0.684979</td>
      <td>0.326196</td>
      <td>0.755232</td>
      <td>0.018706</td>
      <td>0.032807</td>
      <td>-0.356936</td>
      <td>0.791461</td>
      <td>0.329155</td>
      <td>0.209365</td>
      <td>0.955600</td>
      <td>-0.540026</td>
      <td>-0.917326</td>
      <td>0.261214</td>
      <td>0.678596</td>
      <td>0.247991</td>
      <td>-0.203953</td>
      <td>0.638915</td>
      <td>0.024263</td>
      <td>0.642731</td>
      <td>1.389214</td>
      <td>0.385064</td>
      <td>1.551227</td>
      <td>1.022196</td>
      <td>0.428462</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-0.574585</td>
      <td>-0.289432</td>
      <td>0.365159</td>
      <td>0.191251</td>
      <td>1.041961</td>
      <td>0.487728</td>
      <td>1.211069</td>
      <td>-0.230748</td>
      <td>1.376500</td>
      <td>0.947488</td>
      <td>-0.991710</td>
      <td>-0.906282</td>
      <td>-0.433421</td>
      <td>-0.724589</td>
      <td>-0.919866</td>
      <td>0.942252</td>
      <td>0.545600</td>
      <td>1.041973</td>
      <td>0.348150</td>
      <td>-0.156646</td>
      <td>1.189611</td>
      <td>-0.156399</td>
      <td>0.418804</td>
      <td>0.872930</td>
      <td>-0.095111</td>
      <td>-0.276914</td>
      <td>0.531572</td>
      <td>0.575075</td>
      <td>0.521278</td>
      <td>-0.161815</td>
      <td>-0.352785</td>
      <td>-0.490246</td>
      <td>-0.221315</td>
      <td>-0.653542</td>
      <td>-0.484489</td>
      <td>1.326428</td>
      <td>0.984298</td>
      <td>1.009158</td>
      <td>0.184270</td>
      <td>-0.595648</td>
      <td>...</td>
      <td>0.447569</td>
      <td>0.073400</td>
      <td>-1.538309</td>
      <td>-0.911586</td>
      <td>-0.313503</td>
      <td>-0.305200</td>
      <td>-0.625667</td>
      <td>0.164783</td>
      <td>0.337809</td>
      <td>0.660768</td>
      <td>-0.796721</td>
      <td>0.594678</td>
      <td>-0.223718</td>
      <td>0.742981</td>
      <td>-1.012008</td>
      <td>-0.306437</td>
      <td>0.024556</td>
      <td>-0.085887</td>
      <td>0.497673</td>
      <td>0.906847</td>
      <td>0.912541</td>
      <td>0.384350</td>
      <td>0.449248</td>
      <td>0.333486</td>
      <td>0.261139</td>
      <td>0.961401</td>
      <td>0.148514</td>
      <td>0.348809</td>
      <td>0.262645</td>
      <td>0.512053</td>
      <td>1.192401</td>
      <td>1.021469</td>
      <td>-0.558723</td>
      <td>-0.320279</td>
      <td>1.190166</td>
      <td>0.495773</td>
      <td>-0.095257</td>
      <td>1.120873</td>
      <td>0.734567</td>
      <td>0.164856</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.718421</td>
      <td>0.722309</td>
      <td>-0.511231</td>
      <td>0.214291</td>
      <td>0.566857</td>
      <td>-0.135370</td>
      <td>-0.576071</td>
      <td>-0.156658</td>
      <td>0.713951</td>
      <td>0.169530</td>
      <td>-0.124545</td>
      <td>-0.029884</td>
      <td>-0.400546</td>
      <td>0.885560</td>
      <td>0.357436</td>
      <td>0.445156</td>
      <td>0.152304</td>
      <td>0.621027</td>
      <td>-0.484394</td>
      <td>-0.109011</td>
      <td>0.693830</td>
      <td>0.813628</td>
      <td>0.551729</td>
      <td>0.508984</td>
      <td>1.340583</td>
      <td>0.035651</td>
      <td>0.832291</td>
      <td>-0.232525</td>
      <td>1.150967</td>
      <td>-0.516941</td>
      <td>0.271742</td>
      <td>0.684598</td>
      <td>0.422223</td>
      <td>-0.548154</td>
      <td>-0.220826</td>
      <td>0.134400</td>
      <td>-0.160044</td>
      <td>1.397096</td>
      <td>-0.401084</td>
      <td>-0.743818</td>
      <td>...</td>
      <td>-0.203312</td>
      <td>-0.848729</td>
      <td>-0.285480</td>
      <td>-0.478501</td>
      <td>-0.015902</td>
      <td>0.218433</td>
      <td>-0.867323</td>
      <td>-0.744071</td>
      <td>-0.435835</td>
      <td>-0.301620</td>
      <td>-0.187059</td>
      <td>-0.536279</td>
      <td>0.182468</td>
      <td>0.868771</td>
      <td>0.449418</td>
      <td>-0.106312</td>
      <td>0.136003</td>
      <td>0.407375</td>
      <td>-0.288990</td>
      <td>-0.920632</td>
      <td>-0.621001</td>
      <td>-1.008393</td>
      <td>-1.000379</td>
      <td>0.445778</td>
      <td>-0.093378</td>
      <td>-0.157377</td>
      <td>0.295121</td>
      <td>0.527734</td>
      <td>0.314976</td>
      <td>-0.275933</td>
      <td>-0.152114</td>
      <td>0.639660</td>
      <td>0.924712</td>
      <td>0.764088</td>
      <td>-0.344142</td>
      <td>-0.300998</td>
      <td>-0.485701</td>
      <td>1.037201</td>
      <td>0.611019</td>
      <td>0.437427</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.615184</td>
      <td>0.122043</td>
      <td>0.055227</td>
      <td>0.001495</td>
      <td>-0.178952</td>
      <td>0.785390</td>
      <td>0.388678</td>
      <td>-0.717831</td>
      <td>-0.238919</td>
      <td>-0.144246</td>
      <td>-0.706872</td>
      <td>0.432259</td>
      <td>0.035240</td>
      <td>-0.358075</td>
      <td>-0.191348</td>
      <td>0.758573</td>
      <td>0.936012</td>
      <td>-0.417050</td>
      <td>0.007119</td>
      <td>-0.395630</td>
      <td>0.414570</td>
      <td>0.738267</td>
      <td>-0.722611</td>
      <td>-0.252398</td>
      <td>-0.433555</td>
      <td>0.158871</td>
      <td>1.330019</td>
      <td>0.693920</td>
      <td>0.105559</td>
      <td>0.274190</td>
      <td>-0.127502</td>
      <td>-0.559265</td>
      <td>-0.366250</td>
      <td>0.185428</td>
      <td>-0.372840</td>
      <td>0.292816</td>
      <td>0.035722</td>
      <td>-0.114905</td>
      <td>-0.149032</td>
      <td>0.116333</td>
      <td>...</td>
      <td>0.988173</td>
      <td>0.219395</td>
      <td>0.163313</td>
      <td>0.637596</td>
      <td>0.140303</td>
      <td>-0.303574</td>
      <td>0.296904</td>
      <td>0.625187</td>
      <td>-0.116520</td>
      <td>-1.202959</td>
      <td>0.075123</td>
      <td>0.304327</td>
      <td>-0.095329</td>
      <td>-0.294096</td>
      <td>0.209605</td>
      <td>0.996733</td>
      <td>-0.151243</td>
      <td>0.553829</td>
      <td>0.842250</td>
      <td>-0.013618</td>
      <td>0.260350</td>
      <td>-0.181441</td>
      <td>-0.229877</td>
      <td>0.392995</td>
      <td>0.362104</td>
      <td>-0.173837</td>
      <td>-0.456385</td>
      <td>-0.290130</td>
      <td>0.037976</td>
      <td>-0.340300</td>
      <td>-0.201984</td>
      <td>0.540675</td>
      <td>0.361331</td>
      <td>0.762317</td>
      <td>-0.013154</td>
      <td>-0.133450</td>
      <td>-0.930342</td>
      <td>-1.637828</td>
      <td>-0.754425</td>
      <td>-1.401423</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.692750</td>
      <td>1.003991</td>
      <td>-0.246912</td>
      <td>-0.176544</td>
      <td>0.029134</td>
      <td>1.324980</td>
      <td>1.029646</td>
      <td>0.721810</td>
      <td>-0.327342</td>
      <td>0.890263</td>
      <td>0.136767</td>
      <td>-0.010322</td>
      <td>-0.861131</td>
      <td>0.502237</td>
      <td>0.780911</td>
      <td>0.963299</td>
      <td>0.074320</td>
      <td>-0.544770</td>
      <td>-0.081193</td>
      <td>-0.432273</td>
      <td>-0.269340</td>
      <td>0.718870</td>
      <td>-0.131393</td>
      <td>0.136146</td>
      <td>0.457011</td>
      <td>0.563357</td>
      <td>0.941775</td>
      <td>-0.883517</td>
      <td>0.794571</td>
      <td>-0.217984</td>
      <td>0.121555</td>
      <td>-0.174049</td>
      <td>0.019874</td>
      <td>1.038090</td>
      <td>1.410563</td>
      <td>0.277857</td>
      <td>0.100457</td>
      <td>-0.291560</td>
      <td>0.005074</td>
      <td>0.142202</td>
      <td>...</td>
      <td>0.911135</td>
      <td>-0.002234</td>
      <td>-1.137929</td>
      <td>0.042078</td>
      <td>-1.091713</td>
      <td>0.069285</td>
      <td>-0.706800</td>
      <td>-0.508723</td>
      <td>-0.332654</td>
      <td>-0.185003</td>
      <td>0.459658</td>
      <td>-0.867698</td>
      <td>-1.174040</td>
      <td>0.392288</td>
      <td>0.239320</td>
      <td>0.485075</td>
      <td>-0.564840</td>
      <td>0.341598</td>
      <td>0.964945</td>
      <td>0.491271</td>
      <td>0.344927</td>
      <td>-0.587347</td>
      <td>-0.508376</td>
      <td>0.957491</td>
      <td>-0.052543</td>
      <td>0.210888</td>
      <td>0.643794</td>
      <td>0.068457</td>
      <td>-0.239561</td>
      <td>1.275058</td>
      <td>0.260514</td>
      <td>0.576237</td>
      <td>0.261213</td>
      <td>0.059805</td>
      <td>1.119708</td>
      <td>1.156143</td>
      <td>0.830619</td>
      <td>1.382400</td>
      <td>0.142393</td>
      <td>-0.023483</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-0.586154</td>
      <td>0.399497</td>
      <td>-0.259109</td>
      <td>0.405818</td>
      <td>0.228869</td>
      <td>-0.259025</td>
      <td>-0.422053</td>
      <td>-0.545874</td>
      <td>0.381470</td>
      <td>-0.577494</td>
      <td>-0.262566</td>
      <td>1.108030</td>
      <td>-0.433314</td>
      <td>-0.589490</td>
      <td>0.345230</td>
      <td>-0.684151</td>
      <td>0.398043</td>
      <td>0.603470</td>
      <td>-0.907915</td>
      <td>0.828269</td>
      <td>1.563632</td>
      <td>-0.577927</td>
      <td>-0.692382</td>
      <td>0.251807</td>
      <td>-0.529495</td>
      <td>0.469755</td>
      <td>0.504047</td>
      <td>-1.246432</td>
      <td>-0.902566</td>
      <td>-0.330657</td>
      <td>0.354979</td>
      <td>-0.586605</td>
      <td>0.683334</td>
      <td>0.464540</td>
      <td>-0.054302</td>
      <td>0.953723</td>
      <td>0.914191</td>
      <td>-0.522381</td>
      <td>0.394315</td>
      <td>0.471499</td>
      <td>...</td>
      <td>0.394704</td>
      <td>1.372740</td>
      <td>0.077031</td>
      <td>-0.365170</td>
      <td>0.134320</td>
      <td>0.247996</td>
      <td>0.947482</td>
      <td>0.661241</td>
      <td>-0.027919</td>
      <td>-0.412161</td>
      <td>-0.525662</td>
      <td>0.073462</td>
      <td>-1.215570</td>
      <td>-0.039648</td>
      <td>-0.163893</td>
      <td>0.325439</td>
      <td>-0.674345</td>
      <td>0.505703</td>
      <td>0.971156</td>
      <td>0.483257</td>
      <td>0.340174</td>
      <td>-0.150854</td>
      <td>0.872089</td>
      <td>0.364921</td>
      <td>0.388906</td>
      <td>-0.021008</td>
      <td>0.259741</td>
      <td>0.475015</td>
      <td>-0.332048</td>
      <td>1.895515</td>
      <td>1.067675</td>
      <td>1.298164</td>
      <td>0.227159</td>
      <td>0.807561</td>
      <td>-0.150258</td>
      <td>0.082991</td>
      <td>-0.175638</td>
      <td>-0.454003</td>
      <td>-0.744699</td>
      <td>-0.486024</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.233780</td>
      <td>0.948084</td>
      <td>0.820429</td>
      <td>0.673108</td>
      <td>1.077134</td>
      <td>-0.871315</td>
      <td>-0.486502</td>
      <td>-0.379856</td>
      <td>0.649641</td>
      <td>0.564587</td>
      <td>-0.795429</td>
      <td>1.274070</td>
      <td>0.512731</td>
      <td>-0.379271</td>
      <td>-0.516045</td>
      <td>0.741511</td>
      <td>1.290238</td>
      <td>-0.192034</td>
      <td>-0.209441</td>
      <td>-0.030360</td>
      <td>-0.900276</td>
      <td>-0.616915</td>
      <td>-0.135705</td>
      <td>0.697006</td>
      <td>-0.267833</td>
      <td>0.329477</td>
      <td>1.185599</td>
      <td>0.209765</td>
      <td>1.060911</td>
      <td>0.787173</td>
      <td>-0.127690</td>
      <td>0.200241</td>
      <td>0.461770</td>
      <td>0.499508</td>
      <td>-0.345321</td>
      <td>-0.442944</td>
      <td>-0.306940</td>
      <td>-0.494160</td>
      <td>-0.589100</td>
      <td>-0.674728</td>
      <td>...</td>
      <td>0.813202</td>
      <td>0.017181</td>
      <td>0.126172</td>
      <td>0.284886</td>
      <td>-0.369394</td>
      <td>-0.838405</td>
      <td>-0.932270</td>
      <td>-0.267114</td>
      <td>0.219330</td>
      <td>-0.184270</td>
      <td>0.083213</td>
      <td>0.401724</td>
      <td>0.089709</td>
      <td>0.413680</td>
      <td>0.619478</td>
      <td>0.372186</td>
      <td>-1.020815</td>
      <td>0.091984</td>
      <td>0.378939</td>
      <td>0.332121</td>
      <td>0.460388</td>
      <td>-0.789029</td>
      <td>0.052978</td>
      <td>0.020465</td>
      <td>-0.731078</td>
      <td>0.308333</td>
      <td>0.370736</td>
      <td>0.876916</td>
      <td>-0.343335</td>
      <td>-1.066447</td>
      <td>0.866523</td>
      <td>0.275647</td>
      <td>-0.067060</td>
      <td>-0.515266</td>
      <td>0.088840</td>
      <td>-0.157622</td>
      <td>-0.771183</td>
      <td>0.796961</td>
      <td>-0.172446</td>
      <td>-0.591758</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.172605</td>
      <td>0.223049</td>
      <td>0.358952</td>
      <td>0.536350</td>
      <td>0.388247</td>
      <td>-0.192078</td>
      <td>-0.221692</td>
      <td>0.595297</td>
      <td>1.065405</td>
      <td>1.214346</td>
      <td>-1.317023</td>
      <td>0.568453</td>
      <td>-0.064285</td>
      <td>0.994633</td>
      <td>0.333369</td>
      <td>0.222921</td>
      <td>0.307487</td>
      <td>0.713103</td>
      <td>1.020440</td>
      <td>0.861079</td>
      <td>1.053519</td>
      <td>0.341286</td>
      <td>-0.338783</td>
      <td>0.419763</td>
      <td>-0.122911</td>
      <td>0.126914</td>
      <td>0.719999</td>
      <td>-0.586660</td>
      <td>-0.561495</td>
      <td>1.358874</td>
      <td>0.185458</td>
      <td>0.636104</td>
      <td>-0.038483</td>
      <td>-0.195904</td>
      <td>-0.384237</td>
      <td>0.251928</td>
      <td>1.005186</td>
      <td>0.091803</td>
      <td>0.333700</td>
      <td>0.646495</td>
      <td>...</td>
      <td>0.352772</td>
      <td>0.079619</td>
      <td>-0.457433</td>
      <td>-0.194964</td>
      <td>-0.919514</td>
      <td>-0.233568</td>
      <td>-0.027563</td>
      <td>0.317132</td>
      <td>-0.549207</td>
      <td>-0.549166</td>
      <td>-0.588049</td>
      <td>-0.379414</td>
      <td>-0.317300</td>
      <td>0.110381</td>
      <td>0.573551</td>
      <td>0.988057</td>
      <td>0.918233</td>
      <td>0.317479</td>
      <td>0.271580</td>
      <td>0.777880</td>
      <td>0.017648</td>
      <td>-0.866376</td>
      <td>-1.045050</td>
      <td>0.056387</td>
      <td>0.316966</td>
      <td>0.016899</td>
      <td>0.334243</td>
      <td>0.049503</td>
      <td>-0.179286</td>
      <td>1.457951</td>
      <td>0.710345</td>
      <td>-0.009273</td>
      <td>-0.292957</td>
      <td>1.485091</td>
      <td>1.964487</td>
      <td>1.250524</td>
      <td>-0.240649</td>
      <td>-0.383172</td>
      <td>-0.852391</td>
      <td>-0.528879</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.274727</td>
      <td>1.096233</td>
      <td>0.693962</td>
      <td>0.319237</td>
      <td>0.440006</td>
      <td>0.723220</td>
      <td>-0.277255</td>
      <td>0.255954</td>
      <td>0.170224</td>
      <td>0.031476</td>
      <td>-0.646592</td>
      <td>0.340860</td>
      <td>-0.937028</td>
      <td>0.907778</td>
      <td>1.221511</td>
      <td>-0.301030</td>
      <td>0.318417</td>
      <td>0.239233</td>
      <td>-0.111711</td>
      <td>0.845429</td>
      <td>1.449685</td>
      <td>0.760405</td>
      <td>-0.465901</td>
      <td>1.246571</td>
      <td>0.683849</td>
      <td>-0.076202</td>
      <td>0.305494</td>
      <td>-0.762945</td>
      <td>-0.574346</td>
      <td>0.029010</td>
      <td>-0.555281</td>
      <td>-0.461002</td>
      <td>-0.293688</td>
      <td>0.163505</td>
      <td>-0.712364</td>
      <td>1.277767</td>
      <td>-0.110877</td>
      <td>0.688825</td>
      <td>1.275864</td>
      <td>-0.084134</td>
      <td>...</td>
      <td>0.854403</td>
      <td>-0.178759</td>
      <td>-0.171033</td>
      <td>0.291219</td>
      <td>0.010473</td>
      <td>0.134838</td>
      <td>-0.334274</td>
      <td>-0.303637</td>
      <td>-0.252832</td>
      <td>0.056870</td>
      <td>-0.356209</td>
      <td>-1.387484</td>
      <td>0.198832</td>
      <td>0.751030</td>
      <td>-1.377516</td>
      <td>0.241930</td>
      <td>0.103639</td>
      <td>-0.422599</td>
      <td>-0.386471</td>
      <td>0.943939</td>
      <td>0.822637</td>
      <td>-0.969484</td>
      <td>0.063795</td>
      <td>-0.181548</td>
      <td>-0.551234</td>
      <td>-0.136358</td>
      <td>-0.861108</td>
      <td>0.560120</td>
      <td>-1.080826</td>
      <td>0.210457</td>
      <td>0.578965</td>
      <td>0.408448</td>
      <td>1.253171</td>
      <td>0.308065</td>
      <td>0.086410</td>
      <td>-0.326776</td>
      <td>-0.172588</td>
      <td>1.475424</td>
      <td>0.745607</td>
      <td>0.470720</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.447052</td>
      <td>-0.432070</td>
      <td>-0.287289</td>
      <td>0.503797</td>
      <td>-0.345779</td>
      <td>0.669737</td>
      <td>-0.254047</td>
      <td>0.093541</td>
      <td>1.125314</td>
      <td>0.681095</td>
      <td>-0.907069</td>
      <td>-0.456328</td>
      <td>0.010275</td>
      <td>1.525144</td>
      <td>-0.476294</td>
      <td>0.083462</td>
      <td>-0.059688</td>
      <td>0.194120</td>
      <td>-0.945007</td>
      <td>-1.655373</td>
      <td>0.700842</td>
      <td>0.154804</td>
      <td>-0.826641</td>
      <td>0.210483</td>
      <td>0.035393</td>
      <td>-0.032201</td>
      <td>0.921473</td>
      <td>-0.126297</td>
      <td>0.204350</td>
      <td>0.524220</td>
      <td>0.010223</td>
      <td>-0.249478</td>
      <td>0.687517</td>
      <td>-0.283971</td>
      <td>0.689810</td>
      <td>1.106636</td>
      <td>1.561732</td>
      <td>0.461881</td>
      <td>0.428942</td>
      <td>0.563732</td>
      <td>...</td>
      <td>0.549119</td>
      <td>-0.986963</td>
      <td>0.758769</td>
      <td>0.395921</td>
      <td>-0.076572</td>
      <td>-0.949273</td>
      <td>-0.907542</td>
      <td>0.086540</td>
      <td>0.078583</td>
      <td>-0.385460</td>
      <td>-0.118596</td>
      <td>0.735624</td>
      <td>-0.875966</td>
      <td>0.931251</td>
      <td>-0.438318</td>
      <td>-0.076883</td>
      <td>-0.528671</td>
      <td>0.641675</td>
      <td>0.393080</td>
      <td>-0.114830</td>
      <td>0.243520</td>
      <td>0.079156</td>
      <td>0.026628</td>
      <td>0.436530</td>
      <td>0.915838</td>
      <td>0.486248</td>
      <td>-0.548072</td>
      <td>-0.474670</td>
      <td>-0.402814</td>
      <td>0.577006</td>
      <td>0.771490</td>
      <td>0.003535</td>
      <td>-0.144385</td>
      <td>0.762949</td>
      <td>-0.570937</td>
      <td>0.661262</td>
      <td>0.449357</td>
      <td>-1.217669</td>
      <td>-1.472532</td>
      <td>-1.031450</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.429344</td>
      <td>0.593774</td>
      <td>-0.269785</td>
      <td>0.291886</td>
      <td>0.568720</td>
      <td>0.701728</td>
      <td>0.223256</td>
      <td>0.031537</td>
      <td>-0.014690</td>
      <td>0.310579</td>
      <td>0.035408</td>
      <td>0.071762</td>
      <td>-1.054509</td>
      <td>-0.304693</td>
      <td>0.717119</td>
      <td>0.776126</td>
      <td>0.687142</td>
      <td>0.027363</td>
      <td>-0.642772</td>
      <td>0.164437</td>
      <td>0.213853</td>
      <td>0.538756</td>
      <td>-0.529609</td>
      <td>-0.247743</td>
      <td>-0.255585</td>
      <td>-0.017713</td>
      <td>0.052936</td>
      <td>-0.392749</td>
      <td>0.285323</td>
      <td>0.602448</td>
      <td>-0.031761</td>
      <td>0.270671</td>
      <td>0.304022</td>
      <td>0.082873</td>
      <td>0.300013</td>
      <td>0.414728</td>
      <td>0.373158</td>
      <td>-0.127626</td>
      <td>0.596894</td>
      <td>-0.425408</td>
      <td>...</td>
      <td>-0.517159</td>
      <td>0.234821</td>
      <td>0.057123</td>
      <td>-0.290102</td>
      <td>-0.092371</td>
      <td>-0.422006</td>
      <td>-0.707663</td>
      <td>0.019871</td>
      <td>0.341485</td>
      <td>-0.245182</td>
      <td>-0.809678</td>
      <td>0.032871</td>
      <td>-0.812014</td>
      <td>0.227376</td>
      <td>0.273328</td>
      <td>-0.279982</td>
      <td>0.457425</td>
      <td>0.791512</td>
      <td>0.014374</td>
      <td>0.032177</td>
      <td>-1.170982</td>
      <td>-0.762360</td>
      <td>0.059521</td>
      <td>0.116545</td>
      <td>0.015996</td>
      <td>0.210351</td>
      <td>0.174124</td>
      <td>-0.039145</td>
      <td>0.706278</td>
      <td>0.457360</td>
      <td>0.739516</td>
      <td>0.789570</td>
      <td>-0.141107</td>
      <td>-0.083693</td>
      <td>0.306694</td>
      <td>1.056287</td>
      <td>0.391506</td>
      <td>1.055766</td>
      <td>0.096128</td>
      <td>-0.199585</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.640147</td>
      <td>0.370258</td>
      <td>-0.368669</td>
      <td>-0.161337</td>
      <td>0.420138</td>
      <td>0.181895</td>
      <td>-0.066950</td>
      <td>0.202034</td>
      <td>0.253749</td>
      <td>-1.117807</td>
      <td>-1.157234</td>
      <td>-0.190503</td>
      <td>-0.876739</td>
      <td>1.316099</td>
      <td>0.160677</td>
      <td>0.418749</td>
      <td>-0.255256</td>
      <td>0.047224</td>
      <td>0.149042</td>
      <td>0.816322</td>
      <td>0.086724</td>
      <td>0.598454</td>
      <td>-0.330426</td>
      <td>-0.898774</td>
      <td>-0.924102</td>
      <td>-0.238658</td>
      <td>0.282197</td>
      <td>-1.335684</td>
      <td>0.145988</td>
      <td>-0.349430</td>
      <td>0.044506</td>
      <td>0.065280</td>
      <td>-0.246686</td>
      <td>-0.390790</td>
      <td>-0.082172</td>
      <td>0.839333</td>
      <td>-0.198192</td>
      <td>0.475348</td>
      <td>0.088293</td>
      <td>0.430665</td>
      <td>...</td>
      <td>0.365371</td>
      <td>0.489229</td>
      <td>-1.101788</td>
      <td>-0.727776</td>
      <td>-0.085217</td>
      <td>-0.348403</td>
      <td>-1.082445</td>
      <td>-0.548498</td>
      <td>-0.027972</td>
      <td>-0.560138</td>
      <td>-0.308922</td>
      <td>0.214656</td>
      <td>-0.688178</td>
      <td>0.548644</td>
      <td>-0.492233</td>
      <td>-0.131518</td>
      <td>-0.252378</td>
      <td>-0.676083</td>
      <td>-0.171744</td>
      <td>-0.274424</td>
      <td>-0.361732</td>
      <td>0.452663</td>
      <td>-0.275556</td>
      <td>0.505384</td>
      <td>0.263498</td>
      <td>0.893705</td>
      <td>-0.166386</td>
      <td>-0.457939</td>
      <td>-0.929835</td>
      <td>0.124829</td>
      <td>-0.425914</td>
      <td>-0.650950</td>
      <td>0.551542</td>
      <td>0.606501</td>
      <td>0.563964</td>
      <td>0.444024</td>
      <td>-0.626751</td>
      <td>0.890004</td>
      <td>0.903719</td>
      <td>0.929290</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.741942</td>
      <td>0.535641</td>
      <td>0.291235</td>
      <td>0.615131</td>
      <td>-0.085136</td>
      <td>0.439240</td>
      <td>-0.091978</td>
      <td>-0.321654</td>
      <td>-0.377070</td>
      <td>-0.100639</td>
      <td>-0.978820</td>
      <td>0.135690</td>
      <td>-0.415163</td>
      <td>-0.225054</td>
      <td>0.164666</td>
      <td>0.287226</td>
      <td>-0.239807</td>
      <td>0.949724</td>
      <td>-0.003130</td>
      <td>0.299939</td>
      <td>-0.217328</td>
      <td>-0.236600</td>
      <td>-1.554017</td>
      <td>-0.292898</td>
      <td>-0.223878</td>
      <td>-0.113297</td>
      <td>-0.637460</td>
      <td>-1.045930</td>
      <td>-0.246337</td>
      <td>-0.433152</td>
      <td>-0.770814</td>
      <td>-0.188058</td>
      <td>-0.683759</td>
      <td>-0.297243</td>
      <td>0.561651</td>
      <td>-0.561493</td>
      <td>0.616473</td>
      <td>1.318892</td>
      <td>0.220042</td>
      <td>0.456826</td>
      <td>...</td>
      <td>0.529299</td>
      <td>0.085987</td>
      <td>0.056219</td>
      <td>-0.827779</td>
      <td>-0.098763</td>
      <td>-0.564313</td>
      <td>-0.511212</td>
      <td>1.180783</td>
      <td>-0.146686</td>
      <td>-1.232967</td>
      <td>0.299696</td>
      <td>0.700953</td>
      <td>-0.619729</td>
      <td>-0.410479</td>
      <td>-1.144659</td>
      <td>-0.528780</td>
      <td>0.133463</td>
      <td>-1.035090</td>
      <td>-0.661624</td>
      <td>0.169853</td>
      <td>0.537060</td>
      <td>0.089500</td>
      <td>0.593178</td>
      <td>0.184618</td>
      <td>0.638873</td>
      <td>-0.179357</td>
      <td>-0.659037</td>
      <td>0.120153</td>
      <td>-0.403293</td>
      <td>-0.455648</td>
      <td>0.671266</td>
      <td>0.313015</td>
      <td>0.741131</td>
      <td>0.656067</td>
      <td>0.893799</td>
      <td>0.626318</td>
      <td>-0.045699</td>
      <td>1.008041</td>
      <td>0.696373</td>
      <td>0.262104</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-1.028378</td>
      <td>0.443729</td>
      <td>0.347951</td>
      <td>-0.023518</td>
      <td>0.479747</td>
      <td>0.989058</td>
      <td>0.501449</td>
      <td>-0.490284</td>
      <td>0.125365</td>
      <td>-0.302552</td>
      <td>0.126180</td>
      <td>-0.106514</td>
      <td>-0.519325</td>
      <td>-0.477962</td>
      <td>0.370688</td>
      <td>1.162938</td>
      <td>1.067069</td>
      <td>-0.252988</td>
      <td>-0.328901</td>
      <td>-0.635907</td>
      <td>0.064180</td>
      <td>0.241945</td>
      <td>-1.279660</td>
      <td>0.514158</td>
      <td>0.192967</td>
      <td>0.047187</td>
      <td>0.842682</td>
      <td>-0.311650</td>
      <td>0.489456</td>
      <td>-0.011583</td>
      <td>0.133756</td>
      <td>-0.270436</td>
      <td>0.758094</td>
      <td>0.516047</td>
      <td>-0.138426</td>
      <td>0.728300</td>
      <td>0.710877</td>
      <td>1.082538</td>
      <td>0.301352</td>
      <td>-1.033195</td>
      <td>...</td>
      <td>-0.117459</td>
      <td>-0.652546</td>
      <td>-1.152868</td>
      <td>-0.653122</td>
      <td>0.780062</td>
      <td>-0.072495</td>
      <td>0.882197</td>
      <td>1.296046</td>
      <td>-0.376073</td>
      <td>0.095263</td>
      <td>1.068563</td>
      <td>-0.699643</td>
      <td>-1.239405</td>
      <td>-0.240497</td>
      <td>-1.482434</td>
      <td>-2.384541</td>
      <td>-0.195636</td>
      <td>-1.408490</td>
      <td>-0.285642</td>
      <td>0.930774</td>
      <td>0.809663</td>
      <td>-0.430583</td>
      <td>-0.233954</td>
      <td>0.014880</td>
      <td>-0.182359</td>
      <td>0.192021</td>
      <td>-0.201804</td>
      <td>0.003387</td>
      <td>0.076428</td>
      <td>0.133350</td>
      <td>-0.010245</td>
      <td>-0.083945</td>
      <td>-0.311423</td>
      <td>-0.657292</td>
      <td>1.191529</td>
      <td>0.919251</td>
      <td>0.606365</td>
      <td>-1.147501</td>
      <td>-0.148774</td>
      <td>0.659548</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>0.498869</td>
      <td>-0.714367</td>
      <td>0.293625</td>
      <td>-0.278452</td>
      <td>0.273745</td>
      <td>0.738396</td>
      <td>-0.181585</td>
      <td>-0.250195</td>
      <td>0.457700</td>
      <td>1.001849</td>
      <td>-0.168230</td>
      <td>-1.308950</td>
      <td>-0.228463</td>
      <td>-0.146306</td>
      <td>0.241509</td>
      <td>0.217976</td>
      <td>0.407778</td>
      <td>0.763520</td>
      <td>-0.988759</td>
      <td>-0.034761</td>
      <td>0.616355</td>
      <td>-0.238668</td>
      <td>-0.118135</td>
      <td>0.706177</td>
      <td>0.062507</td>
      <td>-0.589718</td>
      <td>-0.911545</td>
      <td>-0.505889</td>
      <td>-0.841098</td>
      <td>-0.966339</td>
      <td>-0.082787</td>
      <td>-0.735097</td>
      <td>-0.103045</td>
      <td>0.356246</td>
      <td>-1.105534</td>
      <td>-0.187189</td>
      <td>0.829421</td>
      <td>-0.859303</td>
      <td>-0.545791</td>
      <td>-0.225332</td>
      <td>...</td>
      <td>-0.484340</td>
      <td>-0.212386</td>
      <td>-0.119893</td>
      <td>-0.094616</td>
      <td>-1.047383</td>
      <td>-0.610303</td>
      <td>0.282399</td>
      <td>0.926717</td>
      <td>0.017109</td>
      <td>-0.099520</td>
      <td>0.365417</td>
      <td>-0.014434</td>
      <td>-0.429064</td>
      <td>-0.168056</td>
      <td>-0.543782</td>
      <td>-0.369131</td>
      <td>-1.225038</td>
      <td>-0.329170</td>
      <td>-0.493370</td>
      <td>-0.961693</td>
      <td>-1.464650</td>
      <td>0.252252</td>
      <td>0.782398</td>
      <td>0.367991</td>
      <td>0.253152</td>
      <td>1.091076</td>
      <td>0.392754</td>
      <td>-0.114612</td>
      <td>-1.050239</td>
      <td>-0.691298</td>
      <td>-0.292826</td>
      <td>-0.293134</td>
      <td>-0.158277</td>
      <td>0.026138</td>
      <td>-0.363636</td>
      <td>-0.051511</td>
      <td>0.162082</td>
      <td>1.419543</td>
      <td>0.377258</td>
      <td>0.305381</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.233946</td>
      <td>0.013761</td>
      <td>0.642597</td>
      <td>-0.320279</td>
      <td>0.709700</td>
      <td>-0.390075</td>
      <td>0.112197</td>
      <td>0.488787</td>
      <td>-0.386444</td>
      <td>-0.290840</td>
      <td>0.280864</td>
      <td>-0.131982</td>
      <td>-0.263726</td>
      <td>-0.863049</td>
      <td>-0.208612</td>
      <td>-0.477907</td>
      <td>0.402519</td>
      <td>1.385685</td>
      <td>-0.733761</td>
      <td>0.119065</td>
      <td>0.964385</td>
      <td>0.384268</td>
      <td>-0.301018</td>
      <td>0.321352</td>
      <td>-0.382686</td>
      <td>0.586093</td>
      <td>0.555342</td>
      <td>-0.041288</td>
      <td>-0.308096</td>
      <td>-0.107211</td>
      <td>0.395540</td>
      <td>0.019056</td>
      <td>-0.600176</td>
      <td>-0.399694</td>
      <td>-0.963778</td>
      <td>0.115090</td>
      <td>0.807362</td>
      <td>0.123887</td>
      <td>0.350039</td>
      <td>0.602316</td>
      <td>...</td>
      <td>-0.008902</td>
      <td>0.074459</td>
      <td>1.187710</td>
      <td>1.131037</td>
      <td>-0.456792</td>
      <td>1.285780</td>
      <td>-0.298613</td>
      <td>-0.421752</td>
      <td>0.259999</td>
      <td>0.341913</td>
      <td>0.469262</td>
      <td>0.075864</td>
      <td>-0.528553</td>
      <td>-1.520209</td>
      <td>-0.037673</td>
      <td>0.772584</td>
      <td>0.073952</td>
      <td>0.015078</td>
      <td>-0.155466</td>
      <td>0.348657</td>
      <td>0.644624</td>
      <td>1.120525</td>
      <td>0.114038</td>
      <td>0.406883</td>
      <td>-0.062663</td>
      <td>0.472536</td>
      <td>-0.401689</td>
      <td>-0.705648</td>
      <td>-0.496025</td>
      <td>1.292690</td>
      <td>0.542325</td>
      <td>0.224188</td>
      <td>0.035262</td>
      <td>-0.413419</td>
      <td>-0.466599</td>
      <td>0.133481</td>
      <td>-0.386185</td>
      <td>0.813772</td>
      <td>0.467894</td>
      <td>0.238874</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.412652</td>
      <td>-0.767077</td>
      <td>-0.677588</td>
      <td>-0.033054</td>
      <td>0.685130</td>
      <td>0.789000</td>
      <td>-0.147120</td>
      <td>0.272360</td>
      <td>0.302608</td>
      <td>-0.495550</td>
      <td>-0.924420</td>
      <td>-0.340174</td>
      <td>-0.358438</td>
      <td>0.541321</td>
      <td>0.561894</td>
      <td>1.545671</td>
      <td>0.233174</td>
      <td>-0.395684</td>
      <td>-0.663075</td>
      <td>-0.514678</td>
      <td>0.936013</td>
      <td>-0.309120</td>
      <td>-0.361732</td>
      <td>-0.641157</td>
      <td>-0.527526</td>
      <td>-0.632893</td>
      <td>0.320463</td>
      <td>0.467750</td>
      <td>-1.068777</td>
      <td>-1.256631</td>
      <td>-1.324988</td>
      <td>-0.666840</td>
      <td>0.440657</td>
      <td>0.491267</td>
      <td>-0.493151</td>
      <td>0.301943</td>
      <td>-0.003176</td>
      <td>-0.637660</td>
      <td>-0.481377</td>
      <td>-0.140350</td>
      <td>...</td>
      <td>-1.014145</td>
      <td>-1.399073</td>
      <td>-0.165526</td>
      <td>0.633138</td>
      <td>0.388297</td>
      <td>0.312450</td>
      <td>0.039449</td>
      <td>-0.374323</td>
      <td>-0.933199</td>
      <td>-0.737258</td>
      <td>-0.871713</td>
      <td>-1.416157</td>
      <td>-0.090901</td>
      <td>-0.750043</td>
      <td>0.189588</td>
      <td>0.480534</td>
      <td>-0.382852</td>
      <td>0.036850</td>
      <td>0.873897</td>
      <td>-0.425219</td>
      <td>-0.516123</td>
      <td>0.407782</td>
      <td>0.957873</td>
      <td>-0.339822</td>
      <td>-0.159260</td>
      <td>0.372917</td>
      <td>-0.140211</td>
      <td>1.076940</td>
      <td>-0.512303</td>
      <td>0.912225</td>
      <td>1.150359</td>
      <td>0.511623</td>
      <td>0.047076</td>
      <td>0.347209</td>
      <td>-0.068935</td>
      <td>0.366748</td>
      <td>0.445070</td>
      <td>1.356301</td>
      <td>0.770284</td>
      <td>0.705540</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.356676</td>
      <td>1.432152</td>
      <td>0.834141</td>
      <td>-0.570390</td>
      <td>-0.472993</td>
      <td>0.546129</td>
      <td>1.159438</td>
      <td>0.142582</td>
      <td>1.464025</td>
      <td>0.753419</td>
      <td>-0.178355</td>
      <td>-0.197420</td>
      <td>0.365674</td>
      <td>0.462311</td>
      <td>0.069639</td>
      <td>0.059528</td>
      <td>0.618738</td>
      <td>0.092107</td>
      <td>-0.298095</td>
      <td>-0.214605</td>
      <td>0.023552</td>
      <td>-0.727278</td>
      <td>0.394677</td>
      <td>0.254022</td>
      <td>0.499302</td>
      <td>-0.670536</td>
      <td>0.332563</td>
      <td>0.227122</td>
      <td>-0.616776</td>
      <td>0.936722</td>
      <td>0.029316</td>
      <td>-0.121477</td>
      <td>0.189593</td>
      <td>-0.111141</td>
      <td>0.159619</td>
      <td>0.107622</td>
      <td>0.522864</td>
      <td>0.125208</td>
      <td>-0.238440</td>
      <td>0.381163</td>
      <td>...</td>
      <td>0.083675</td>
      <td>1.228904</td>
      <td>0.824995</td>
      <td>0.487215</td>
      <td>-0.504519</td>
      <td>1.174291</td>
      <td>0.072019</td>
      <td>-0.176208</td>
      <td>0.064127</td>
      <td>-0.226522</td>
      <td>1.439623</td>
      <td>0.310639</td>
      <td>-0.022879</td>
      <td>-0.808636</td>
      <td>0.200434</td>
      <td>0.481283</td>
      <td>-0.142337</td>
      <td>0.372408</td>
      <td>0.041709</td>
      <td>0.418314</td>
      <td>-1.062920</td>
      <td>-0.270701</td>
      <td>0.288794</td>
      <td>0.340128</td>
      <td>1.227271</td>
      <td>0.597130</td>
      <td>0.659808</td>
      <td>0.181185</td>
      <td>-0.287559</td>
      <td>0.764290</td>
      <td>0.155904</td>
      <td>0.990631</td>
      <td>-0.617928</td>
      <td>0.150142</td>
      <td>-0.333779</td>
      <td>-0.532458</td>
      <td>0.379449</td>
      <td>1.921015</td>
      <td>1.749184</td>
      <td>0.537587</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.415706</td>
      <td>0.123667</td>
      <td>0.112831</td>
      <td>1.015791</td>
      <td>1.199324</td>
      <td>0.033675</td>
      <td>-0.492817</td>
      <td>0.179545</td>
      <td>0.544598</td>
      <td>0.553902</td>
      <td>-0.127012</td>
      <td>0.418068</td>
      <td>-0.874029</td>
      <td>-0.490479</td>
      <td>-0.506634</td>
      <td>0.634242</td>
      <td>-0.512197</td>
      <td>0.025076</td>
      <td>-0.876339</td>
      <td>-0.163639</td>
      <td>0.299565</td>
      <td>0.865531</td>
      <td>0.192050</td>
      <td>0.521561</td>
      <td>-0.481649</td>
      <td>0.130523</td>
      <td>-0.293741</td>
      <td>-1.568633</td>
      <td>-2.009454</td>
      <td>0.038947</td>
      <td>0.232082</td>
      <td>-0.607861</td>
      <td>-0.498583</td>
      <td>-0.173166</td>
      <td>0.075398</td>
      <td>-0.510255</td>
      <td>0.665948</td>
      <td>-0.658126</td>
      <td>-0.032176</td>
      <td>-0.343484</td>
      <td>...</td>
      <td>-0.183783</td>
      <td>1.169752</td>
      <td>0.938751</td>
      <td>-0.219812</td>
      <td>0.484994</td>
      <td>0.022254</td>
      <td>-0.440693</td>
      <td>0.626980</td>
      <td>-0.502073</td>
      <td>0.683003</td>
      <td>1.251350</td>
      <td>0.403669</td>
      <td>0.543094</td>
      <td>0.246936</td>
      <td>0.333714</td>
      <td>0.333927</td>
      <td>1.239402</td>
      <td>1.801258</td>
      <td>0.139675</td>
      <td>-0.384105</td>
      <td>0.277644</td>
      <td>0.725079</td>
      <td>1.227729</td>
      <td>0.231056</td>
      <td>0.231817</td>
      <td>-0.480866</td>
      <td>0.226243</td>
      <td>-0.150286</td>
      <td>-0.454375</td>
      <td>0.145338</td>
      <td>0.330615</td>
      <td>0.598004</td>
      <td>-0.513340</td>
      <td>-0.569111</td>
      <td>0.510422</td>
      <td>0.913642</td>
      <td>-0.047776</td>
      <td>0.114800</td>
      <td>0.076537</td>
      <td>0.641227</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
</div>
<br />
<br /></section>
<section id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f0b84643790&gt;
</pre></div>
</div>
</section>
<section id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.072868  0.039614  27.083221  1.552255e-161  0.995226  1.150509
</pre></div>
</div>
</section>
<section id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<section id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</section>
<section id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.585 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>
</section>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.1e043a052b0af929e4d8.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>