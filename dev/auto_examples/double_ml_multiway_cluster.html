
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-0.168574</td>
      <td>1.346674</td>
      <td>0.383592</td>
      <td>0.516501</td>
      <td>1.607681</td>
      <td>1.180754</td>
      <td>0.701963</td>
      <td>0.487208</td>
      <td>0.472752</td>
      <td>-0.839715</td>
      <td>-0.300019</td>
      <td>-0.022204</td>
      <td>-1.069298</td>
      <td>-0.130955</td>
      <td>0.362831</td>
      <td>0.574735</td>
      <td>-0.187605</td>
      <td>-0.296059</td>
      <td>0.016964</td>
      <td>-0.506908</td>
      <td>0.113199</td>
      <td>0.495300</td>
      <td>0.413377</td>
      <td>-0.307526</td>
      <td>0.406675</td>
      <td>0.241051</td>
      <td>1.112444</td>
      <td>0.298988</td>
      <td>0.981466</td>
      <td>1.659978</td>
      <td>-0.768871</td>
      <td>0.987527</td>
      <td>0.836236</td>
      <td>0.322859</td>
      <td>-0.067586</td>
      <td>1.362535</td>
      <td>-0.458098</td>
      <td>-0.065648</td>
      <td>-0.102617</td>
      <td>0.413487</td>
      <td>...</td>
      <td>0.258472</td>
      <td>-0.134772</td>
      <td>-0.756045</td>
      <td>0.827118</td>
      <td>0.275910</td>
      <td>0.881473</td>
      <td>-0.360487</td>
      <td>0.031719</td>
      <td>-0.204124</td>
      <td>-0.158022</td>
      <td>-1.341714</td>
      <td>-0.772472</td>
      <td>0.254220</td>
      <td>0.399650</td>
      <td>-0.199431</td>
      <td>-0.206218</td>
      <td>-0.478737</td>
      <td>0.229487</td>
      <td>0.078577</td>
      <td>-0.003062</td>
      <td>-0.302264</td>
      <td>-0.150527</td>
      <td>-0.225420</td>
      <td>-0.512402</td>
      <td>0.046458</td>
      <td>-0.053233</td>
      <td>-1.286777</td>
      <td>-1.053636</td>
      <td>-0.055041</td>
      <td>0.239728</td>
      <td>0.187746</td>
      <td>-0.772321</td>
      <td>-0.697320</td>
      <td>0.357445</td>
      <td>-0.399210</td>
      <td>-0.947979</td>
      <td>0.359155</td>
      <td>0.976132</td>
      <td>1.242995</td>
      <td>0.521712</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.270756</td>
      <td>2.010490</td>
      <td>0.441515</td>
      <td>0.624730</td>
      <td>0.710744</td>
      <td>0.605748</td>
      <td>-0.547707</td>
      <td>-0.388873</td>
      <td>0.251111</td>
      <td>-0.487541</td>
      <td>-0.479179</td>
      <td>-0.181653</td>
      <td>0.154562</td>
      <td>0.324368</td>
      <td>0.752474</td>
      <td>0.164828</td>
      <td>0.204247</td>
      <td>-0.634719</td>
      <td>0.430456</td>
      <td>-0.278820</td>
      <td>-0.088752</td>
      <td>0.301890</td>
      <td>-0.252613</td>
      <td>-0.091159</td>
      <td>0.119993</td>
      <td>-0.165299</td>
      <td>-0.949768</td>
      <td>0.125118</td>
      <td>-0.053322</td>
      <td>0.228222</td>
      <td>0.024697</td>
      <td>-0.252783</td>
      <td>0.224198</td>
      <td>-0.337247</td>
      <td>0.957213</td>
      <td>0.371074</td>
      <td>-0.228287</td>
      <td>0.625148</td>
      <td>1.233075</td>
      <td>-0.637753</td>
      <td>...</td>
      <td>0.248912</td>
      <td>0.048093</td>
      <td>0.588419</td>
      <td>-0.374970</td>
      <td>-0.108040</td>
      <td>0.379544</td>
      <td>-0.577285</td>
      <td>0.476602</td>
      <td>-0.713342</td>
      <td>0.077677</td>
      <td>-0.684060</td>
      <td>-0.433789</td>
      <td>0.329611</td>
      <td>-0.218063</td>
      <td>0.122563</td>
      <td>0.848089</td>
      <td>-0.260462</td>
      <td>-0.164885</td>
      <td>0.197144</td>
      <td>-0.878330</td>
      <td>-0.023474</td>
      <td>-0.678689</td>
      <td>-0.476186</td>
      <td>-0.225759</td>
      <td>0.560497</td>
      <td>0.060885</td>
      <td>-0.244256</td>
      <td>-0.362278</td>
      <td>0.698892</td>
      <td>-0.049482</td>
      <td>0.145433</td>
      <td>-0.436486</td>
      <td>-0.902206</td>
      <td>-0.538614</td>
      <td>0.312200</td>
      <td>0.214426</td>
      <td>0.673552</td>
      <td>3.071194</td>
      <td>2.565234</td>
      <td>1.957747</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.299666</td>
      <td>0.603521</td>
      <td>-0.226400</td>
      <td>0.539538</td>
      <td>0.240461</td>
      <td>0.726618</td>
      <td>1.121760</td>
      <td>-0.560656</td>
      <td>0.068934</td>
      <td>-0.048096</td>
      <td>-0.164492</td>
      <td>0.704368</td>
      <td>-0.538159</td>
      <td>-0.704450</td>
      <td>0.656735</td>
      <td>0.783046</td>
      <td>0.322236</td>
      <td>0.519216</td>
      <td>-0.067876</td>
      <td>0.241502</td>
      <td>-0.195388</td>
      <td>-0.091732</td>
      <td>0.036727</td>
      <td>0.713135</td>
      <td>-0.866709</td>
      <td>-0.086092</td>
      <td>0.928414</td>
      <td>-0.400016</td>
      <td>-0.366702</td>
      <td>-0.959250</td>
      <td>-0.658705</td>
      <td>0.026478</td>
      <td>-1.333032</td>
      <td>-0.672321</td>
      <td>0.212637</td>
      <td>1.069343</td>
      <td>0.074087</td>
      <td>-0.153788</td>
      <td>0.944748</td>
      <td>0.138617</td>
      <td>...</td>
      <td>-0.828239</td>
      <td>0.062783</td>
      <td>-0.718899</td>
      <td>0.015684</td>
      <td>0.257316</td>
      <td>1.113666</td>
      <td>-0.096316</td>
      <td>0.274705</td>
      <td>-0.178548</td>
      <td>-0.144005</td>
      <td>-0.196740</td>
      <td>0.556819</td>
      <td>0.203244</td>
      <td>-1.283189</td>
      <td>-0.456933</td>
      <td>0.118460</td>
      <td>0.182198</td>
      <td>-0.404593</td>
      <td>-0.241698</td>
      <td>0.634908</td>
      <td>0.384960</td>
      <td>0.347635</td>
      <td>0.512290</td>
      <td>0.164578</td>
      <td>-0.303339</td>
      <td>-1.051023</td>
      <td>-0.577108</td>
      <td>-0.243883</td>
      <td>0.033576</td>
      <td>-0.304451</td>
      <td>0.278333</td>
      <td>0.420804</td>
      <td>0.205727</td>
      <td>-0.800388</td>
      <td>0.428301</td>
      <td>0.656184</td>
      <td>-0.123757</td>
      <td>0.553415</td>
      <td>0.476747</td>
      <td>0.308097</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.393291</td>
      <td>0.310351</td>
      <td>0.837180</td>
      <td>-0.320562</td>
      <td>0.579465</td>
      <td>1.265125</td>
      <td>-0.325257</td>
      <td>-0.383572</td>
      <td>0.112494</td>
      <td>-1.039784</td>
      <td>-0.279026</td>
      <td>0.572182</td>
      <td>0.305693</td>
      <td>0.638602</td>
      <td>-0.467305</td>
      <td>0.098877</td>
      <td>0.023330</td>
      <td>-0.959274</td>
      <td>0.267282</td>
      <td>-0.934680</td>
      <td>-0.534992</td>
      <td>-0.351433</td>
      <td>-0.685089</td>
      <td>0.337553</td>
      <td>-0.663192</td>
      <td>0.145993</td>
      <td>0.342469</td>
      <td>-0.806166</td>
      <td>0.242966</td>
      <td>0.892004</td>
      <td>-0.373608</td>
      <td>0.164735</td>
      <td>-0.064088</td>
      <td>0.363025</td>
      <td>0.625417</td>
      <td>0.971188</td>
      <td>-0.037173</td>
      <td>0.412625</td>
      <td>1.179250</td>
      <td>0.240655</td>
      <td>...</td>
      <td>0.480232</td>
      <td>0.063569</td>
      <td>0.340025</td>
      <td>-0.618594</td>
      <td>0.138444</td>
      <td>0.135721</td>
      <td>0.280824</td>
      <td>-0.593592</td>
      <td>-0.932726</td>
      <td>-0.806217</td>
      <td>-0.250961</td>
      <td>0.778379</td>
      <td>1.987284</td>
      <td>0.005092</td>
      <td>0.260577</td>
      <td>-0.099014</td>
      <td>0.739316</td>
      <td>0.206760</td>
      <td>0.818263</td>
      <td>0.069616</td>
      <td>0.122545</td>
      <td>0.251594</td>
      <td>1.002932</td>
      <td>-0.108574</td>
      <td>-1.082707</td>
      <td>0.115425</td>
      <td>0.517191</td>
      <td>-0.446421</td>
      <td>-0.918746</td>
      <td>-0.606088</td>
      <td>-0.868746</td>
      <td>0.158712</td>
      <td>-0.013547</td>
      <td>0.310285</td>
      <td>-0.062474</td>
      <td>0.179453</td>
      <td>-0.331713</td>
      <td>2.110318</td>
      <td>1.867234</td>
      <td>1.126327</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.143662</td>
      <td>0.491839</td>
      <td>0.064309</td>
      <td>0.341544</td>
      <td>0.757390</td>
      <td>0.339978</td>
      <td>-0.583430</td>
      <td>-0.676792</td>
      <td>0.380262</td>
      <td>-0.396870</td>
      <td>0.542254</td>
      <td>1.355556</td>
      <td>-0.974711</td>
      <td>0.273599</td>
      <td>0.164756</td>
      <td>0.178214</td>
      <td>0.175534</td>
      <td>-0.765150</td>
      <td>-0.713807</td>
      <td>-0.539414</td>
      <td>-0.889052</td>
      <td>-0.901129</td>
      <td>-0.688572</td>
      <td>-0.637312</td>
      <td>0.235693</td>
      <td>-0.261318</td>
      <td>0.255399</td>
      <td>-1.506739</td>
      <td>-0.621020</td>
      <td>0.168089</td>
      <td>-0.705983</td>
      <td>0.415047</td>
      <td>-0.600950</td>
      <td>-0.555715</td>
      <td>1.319827</td>
      <td>0.513260</td>
      <td>-0.420545</td>
      <td>-0.836968</td>
      <td>1.065657</td>
      <td>-0.225060</td>
      <td>...</td>
      <td>-0.847265</td>
      <td>-0.210153</td>
      <td>1.794326</td>
      <td>0.186552</td>
      <td>-0.370090</td>
      <td>0.279924</td>
      <td>0.422037</td>
      <td>-0.026929</td>
      <td>0.132285</td>
      <td>-1.321318</td>
      <td>-0.876302</td>
      <td>-0.147205</td>
      <td>0.867540</td>
      <td>-0.039702</td>
      <td>0.119873</td>
      <td>-0.518518</td>
      <td>0.164583</td>
      <td>-0.536342</td>
      <td>-0.022809</td>
      <td>0.802411</td>
      <td>-0.388706</td>
      <td>0.424415</td>
      <td>0.469139</td>
      <td>0.251552</td>
      <td>-0.085091</td>
      <td>0.438141</td>
      <td>0.274870</td>
      <td>0.050645</td>
      <td>-1.378199</td>
      <td>-0.553492</td>
      <td>0.519452</td>
      <td>1.008682</td>
      <td>1.505692</td>
      <td>0.411277</td>
      <td>-0.471366</td>
      <td>0.015874</td>
      <td>-0.197403</td>
      <td>1.777715</td>
      <td>1.409174</td>
      <td>0.474694</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.613104</td>
      <td>1.187768</td>
      <td>-0.070608</td>
      <td>1.425293</td>
      <td>0.777777</td>
      <td>0.160959</td>
      <td>0.747726</td>
      <td>0.466610</td>
      <td>-0.219676</td>
      <td>-0.419821</td>
      <td>-1.380203</td>
      <td>-0.492036</td>
      <td>-0.066283</td>
      <td>0.394857</td>
      <td>0.719591</td>
      <td>0.814701</td>
      <td>0.468264</td>
      <td>0.107670</td>
      <td>0.389383</td>
      <td>-0.656561</td>
      <td>0.245464</td>
      <td>1.275670</td>
      <td>0.345955</td>
      <td>-0.200714</td>
      <td>0.482119</td>
      <td>-0.936256</td>
      <td>-0.037439</td>
      <td>-1.115208</td>
      <td>0.334165</td>
      <td>0.390392</td>
      <td>-0.413541</td>
      <td>0.174724</td>
      <td>0.535419</td>
      <td>-0.323415</td>
      <td>0.327399</td>
      <td>1.291809</td>
      <td>0.871035</td>
      <td>0.650829</td>
      <td>0.970778</td>
      <td>-0.260479</td>
      <td>...</td>
      <td>0.198098</td>
      <td>0.495234</td>
      <td>0.904042</td>
      <td>0.000929</td>
      <td>-0.222288</td>
      <td>-0.647633</td>
      <td>0.053721</td>
      <td>0.438927</td>
      <td>-1.772563</td>
      <td>-0.964939</td>
      <td>-0.393614</td>
      <td>0.180590</td>
      <td>1.016728</td>
      <td>0.847382</td>
      <td>1.207096</td>
      <td>-0.269898</td>
      <td>-0.118878</td>
      <td>-1.311999</td>
      <td>0.731792</td>
      <td>0.637131</td>
      <td>0.636895</td>
      <td>0.125378</td>
      <td>1.490046</td>
      <td>0.826623</td>
      <td>-0.339537</td>
      <td>-0.193111</td>
      <td>0.079295</td>
      <td>-0.302259</td>
      <td>-0.985214</td>
      <td>-0.609137</td>
      <td>-0.212245</td>
      <td>-1.926385</td>
      <td>-0.365864</td>
      <td>0.436254</td>
      <td>-0.182472</td>
      <td>0.708421</td>
      <td>0.360037</td>
      <td>4.144708</td>
      <td>2.734158</td>
      <td>1.252542</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.694164</td>
      <td>-0.002617</td>
      <td>-1.072840</td>
      <td>-0.095955</td>
      <td>0.283692</td>
      <td>-0.294060</td>
      <td>0.925515</td>
      <td>-0.042122</td>
      <td>0.593521</td>
      <td>-0.219121</td>
      <td>-0.443538</td>
      <td>-0.404630</td>
      <td>-0.910087</td>
      <td>0.664397</td>
      <td>-0.029224</td>
      <td>0.530747</td>
      <td>-0.325438</td>
      <td>-0.702659</td>
      <td>-0.512607</td>
      <td>-0.010716</td>
      <td>-0.382570</td>
      <td>-0.465341</td>
      <td>-0.627906</td>
      <td>-0.236564</td>
      <td>-0.552849</td>
      <td>-1.377625</td>
      <td>-0.574249</td>
      <td>-0.998428</td>
      <td>0.089739</td>
      <td>0.772024</td>
      <td>0.206629</td>
      <td>0.524110</td>
      <td>-0.105847</td>
      <td>-0.260711</td>
      <td>0.623486</td>
      <td>0.019937</td>
      <td>0.136498</td>
      <td>-0.745440</td>
      <td>0.881824</td>
      <td>-0.133946</td>
      <td>...</td>
      <td>-0.322116</td>
      <td>0.589585</td>
      <td>0.175175</td>
      <td>1.182335</td>
      <td>1.359899</td>
      <td>0.577808</td>
      <td>0.010703</td>
      <td>0.560381</td>
      <td>0.193501</td>
      <td>-0.667793</td>
      <td>-0.619385</td>
      <td>-0.915061</td>
      <td>0.922729</td>
      <td>-0.297845</td>
      <td>0.561574</td>
      <td>0.636810</td>
      <td>-0.444889</td>
      <td>-0.503657</td>
      <td>0.222371</td>
      <td>-0.162571</td>
      <td>-0.306406</td>
      <td>0.648182</td>
      <td>-0.283804</td>
      <td>-0.447620</td>
      <td>0.014469</td>
      <td>-0.001466</td>
      <td>0.109864</td>
      <td>-0.703822</td>
      <td>-1.190333</td>
      <td>-0.887268</td>
      <td>-0.859364</td>
      <td>-0.139259</td>
      <td>0.197071</td>
      <td>-0.585065</td>
      <td>-0.412913</td>
      <td>-0.340693</td>
      <td>1.059465</td>
      <td>-0.432444</td>
      <td>0.510041</td>
      <td>0.448136</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-1.702324</td>
      <td>-0.251208</td>
      <td>0.261123</td>
      <td>-0.029736</td>
      <td>1.573901</td>
      <td>0.250774</td>
      <td>-0.078326</td>
      <td>-0.071420</td>
      <td>-0.274371</td>
      <td>-0.341462</td>
      <td>-0.212702</td>
      <td>0.482333</td>
      <td>0.276432</td>
      <td>-0.212514</td>
      <td>-0.532877</td>
      <td>0.208839</td>
      <td>0.003937</td>
      <td>-0.218186</td>
      <td>0.703467</td>
      <td>-0.203414</td>
      <td>0.118184</td>
      <td>0.370287</td>
      <td>0.442463</td>
      <td>0.060013</td>
      <td>0.088825</td>
      <td>0.852537</td>
      <td>0.306234</td>
      <td>0.638625</td>
      <td>-0.643298</td>
      <td>-0.314480</td>
      <td>-0.489224</td>
      <td>0.631891</td>
      <td>-0.284132</td>
      <td>0.425328</td>
      <td>-0.464558</td>
      <td>0.042870</td>
      <td>0.053836</td>
      <td>0.933484</td>
      <td>1.045044</td>
      <td>0.245364</td>
      <td>...</td>
      <td>-1.650931</td>
      <td>-0.483466</td>
      <td>0.023606</td>
      <td>-0.491061</td>
      <td>-1.540062</td>
      <td>0.009856</td>
      <td>0.648024</td>
      <td>1.241813</td>
      <td>-0.158409</td>
      <td>-0.445929</td>
      <td>-1.370695</td>
      <td>-0.298997</td>
      <td>0.886387</td>
      <td>-0.201777</td>
      <td>-0.316218</td>
      <td>-0.544500</td>
      <td>-0.469925</td>
      <td>0.516681</td>
      <td>0.445789</td>
      <td>0.249919</td>
      <td>0.247249</td>
      <td>0.268087</td>
      <td>0.465795</td>
      <td>-0.524832</td>
      <td>0.178072</td>
      <td>-0.108231</td>
      <td>-0.594475</td>
      <td>-1.697551</td>
      <td>0.382988</td>
      <td>-0.010061</td>
      <td>0.145974</td>
      <td>0.010400</td>
      <td>-0.525302</td>
      <td>-0.710006</td>
      <td>-0.847143</td>
      <td>0.272162</td>
      <td>0.689622</td>
      <td>-3.025582</td>
      <td>-2.232784</td>
      <td>-0.823620</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.410060</td>
      <td>0.437314</td>
      <td>-0.325789</td>
      <td>0.222636</td>
      <td>0.454116</td>
      <td>0.867687</td>
      <td>1.061950</td>
      <td>-0.174580</td>
      <td>0.286131</td>
      <td>-0.062779</td>
      <td>-0.954674</td>
      <td>-0.506473</td>
      <td>-1.894417</td>
      <td>-1.398469</td>
      <td>-0.970167</td>
      <td>-0.267433</td>
      <td>0.468797</td>
      <td>0.638337</td>
      <td>0.272903</td>
      <td>-0.098636</td>
      <td>0.352559</td>
      <td>0.554766</td>
      <td>0.532110</td>
      <td>1.449303</td>
      <td>1.347041</td>
      <td>-0.295446</td>
      <td>-0.485721</td>
      <td>0.241148</td>
      <td>0.754484</td>
      <td>0.490460</td>
      <td>-0.909837</td>
      <td>0.715782</td>
      <td>0.513362</td>
      <td>0.055781</td>
      <td>0.408735</td>
      <td>0.957412</td>
      <td>-0.633561</td>
      <td>-0.523801</td>
      <td>1.878128</td>
      <td>-0.247829</td>
      <td>...</td>
      <td>-0.386829</td>
      <td>0.638958</td>
      <td>0.223991</td>
      <td>-0.212635</td>
      <td>-0.402492</td>
      <td>1.157484</td>
      <td>0.632490</td>
      <td>0.768927</td>
      <td>-0.734618</td>
      <td>-0.444221</td>
      <td>-0.332424</td>
      <td>-0.030213</td>
      <td>0.647620</td>
      <td>0.005634</td>
      <td>-0.288016</td>
      <td>-0.334744</td>
      <td>-0.004767</td>
      <td>0.028545</td>
      <td>-0.385088</td>
      <td>-0.015836</td>
      <td>0.103625</td>
      <td>-0.276949</td>
      <td>0.365275</td>
      <td>0.681902</td>
      <td>0.286273</td>
      <td>-0.595549</td>
      <td>-0.266914</td>
      <td>-0.352220</td>
      <td>-0.770952</td>
      <td>-0.449156</td>
      <td>0.602442</td>
      <td>0.079274</td>
      <td>-0.035506</td>
      <td>0.586886</td>
      <td>-0.002116</td>
      <td>-0.582269</td>
      <td>0.091354</td>
      <td>1.335061</td>
      <td>0.223929</td>
      <td>0.478006</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.021183</td>
      <td>0.303965</td>
      <td>-0.378960</td>
      <td>-0.010541</td>
      <td>0.262729</td>
      <td>-0.101792</td>
      <td>-0.821979</td>
      <td>-0.424095</td>
      <td>0.354955</td>
      <td>-0.269225</td>
      <td>-0.794881</td>
      <td>0.084144</td>
      <td>0.348608</td>
      <td>0.109137</td>
      <td>-0.098977</td>
      <td>0.265878</td>
      <td>0.340394</td>
      <td>0.596204</td>
      <td>1.092181</td>
      <td>0.007042</td>
      <td>0.410745</td>
      <td>-0.038478</td>
      <td>-0.583622</td>
      <td>0.432892</td>
      <td>0.251639</td>
      <td>0.591528</td>
      <td>1.488281</td>
      <td>0.348216</td>
      <td>0.188517</td>
      <td>0.739850</td>
      <td>-0.056017</td>
      <td>1.718345</td>
      <td>0.475870</td>
      <td>0.710778</td>
      <td>-0.079823</td>
      <td>0.513460</td>
      <td>-0.315232</td>
      <td>-0.322095</td>
      <td>-0.214869</td>
      <td>0.156032</td>
      <td>...</td>
      <td>0.411258</td>
      <td>-0.554407</td>
      <td>-0.365811</td>
      <td>0.065371</td>
      <td>1.403549</td>
      <td>0.517461</td>
      <td>0.486703</td>
      <td>-0.071583</td>
      <td>-0.512966</td>
      <td>-0.296372</td>
      <td>-0.312191</td>
      <td>0.777079</td>
      <td>1.613580</td>
      <td>0.592852</td>
      <td>0.370323</td>
      <td>-0.385064</td>
      <td>0.176723</td>
      <td>-0.620643</td>
      <td>-0.339159</td>
      <td>-1.289547</td>
      <td>-0.467918</td>
      <td>0.193374</td>
      <td>0.088030</td>
      <td>0.212329</td>
      <td>-0.270400</td>
      <td>-0.835875</td>
      <td>-0.871786</td>
      <td>-1.537853</td>
      <td>-1.234640</td>
      <td>-0.235717</td>
      <td>0.772510</td>
      <td>0.108344</td>
      <td>-1.135320</td>
      <td>-0.130154</td>
      <td>0.222448</td>
      <td>0.287968</td>
      <td>0.704621</td>
      <td>0.958346</td>
      <td>0.084129</td>
      <td>0.923343</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-0.677638</td>
      <td>-0.485470</td>
      <td>0.346523</td>
      <td>-0.220864</td>
      <td>0.702233</td>
      <td>0.261551</td>
      <td>0.894627</td>
      <td>0.748748</td>
      <td>0.462300</td>
      <td>0.410319</td>
      <td>-0.565228</td>
      <td>1.557504</td>
      <td>-0.125857</td>
      <td>-1.033004</td>
      <td>-0.246942</td>
      <td>-0.316723</td>
      <td>-0.860298</td>
      <td>-0.989409</td>
      <td>0.398483</td>
      <td>-0.446250</td>
      <td>-0.584425</td>
      <td>-0.206406</td>
      <td>0.084654</td>
      <td>1.213758</td>
      <td>-0.680308</td>
      <td>-0.419614</td>
      <td>-0.708558</td>
      <td>-1.495412</td>
      <td>-0.217677</td>
      <td>0.987927</td>
      <td>-0.162801</td>
      <td>-0.183363</td>
      <td>-0.627303</td>
      <td>-1.382461</td>
      <td>0.864725</td>
      <td>0.524044</td>
      <td>-0.539351</td>
      <td>-0.592252</td>
      <td>0.556741</td>
      <td>-0.844214</td>
      <td>...</td>
      <td>-0.585971</td>
      <td>-0.397917</td>
      <td>-0.045330</td>
      <td>-0.604196</td>
      <td>-0.801553</td>
      <td>0.396833</td>
      <td>0.235151</td>
      <td>0.164057</td>
      <td>0.808197</td>
      <td>-0.892834</td>
      <td>-0.400849</td>
      <td>-1.041271</td>
      <td>0.312459</td>
      <td>0.048817</td>
      <td>-0.567658</td>
      <td>-0.324436</td>
      <td>-0.239521</td>
      <td>-0.498866</td>
      <td>-0.291378</td>
      <td>-0.502220</td>
      <td>-0.141056</td>
      <td>0.677746</td>
      <td>1.300747</td>
      <td>1.105281</td>
      <td>-0.623862</td>
      <td>-0.686929</td>
      <td>1.378249</td>
      <td>-0.502858</td>
      <td>-1.612530</td>
      <td>0.223826</td>
      <td>0.187961</td>
      <td>-0.002596</td>
      <td>0.006491</td>
      <td>0.167290</td>
      <td>0.223626</td>
      <td>0.141658</td>
      <td>1.348189</td>
      <td>-2.593561</td>
      <td>-1.236120</td>
      <td>-0.098650</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.815484</td>
      <td>1.173984</td>
      <td>1.263528</td>
      <td>0.627742</td>
      <td>0.706412</td>
      <td>0.352728</td>
      <td>0.648274</td>
      <td>-0.630875</td>
      <td>-0.658090</td>
      <td>-0.828009</td>
      <td>0.198148</td>
      <td>1.317280</td>
      <td>1.870912</td>
      <td>0.598558</td>
      <td>-0.826590</td>
      <td>-1.153680</td>
      <td>-0.673292</td>
      <td>-0.789962</td>
      <td>-1.137677</td>
      <td>-1.802372</td>
      <td>-1.093545</td>
      <td>-0.671654</td>
      <td>0.223735</td>
      <td>-0.411745</td>
      <td>-0.377770</td>
      <td>-0.301034</td>
      <td>0.812698</td>
      <td>-0.519374</td>
      <td>0.296894</td>
      <td>-0.434822</td>
      <td>-0.079218</td>
      <td>0.645716</td>
      <td>-0.238174</td>
      <td>-0.774720</td>
      <td>-0.223217</td>
      <td>0.775060</td>
      <td>0.634249</td>
      <td>0.481852</td>
      <td>1.230801</td>
      <td>0.225273</td>
      <td>...</td>
      <td>0.114008</td>
      <td>0.199130</td>
      <td>-0.007294</td>
      <td>0.110208</td>
      <td>-0.315544</td>
      <td>-0.944135</td>
      <td>-0.242448</td>
      <td>-0.155523</td>
      <td>-0.246569</td>
      <td>-0.052011</td>
      <td>-0.055855</td>
      <td>0.134852</td>
      <td>0.801155</td>
      <td>0.142687</td>
      <td>-0.798589</td>
      <td>-0.157786</td>
      <td>0.243300</td>
      <td>0.102501</td>
      <td>-0.707567</td>
      <td>-0.961481</td>
      <td>-0.161308</td>
      <td>0.671466</td>
      <td>-0.128394</td>
      <td>-0.435749</td>
      <td>-0.696377</td>
      <td>-0.271610</td>
      <td>1.142212</td>
      <td>-0.326822</td>
      <td>-0.820616</td>
      <td>-0.376753</td>
      <td>-0.416748</td>
      <td>-1.287506</td>
      <td>-0.091905</td>
      <td>0.195365</td>
      <td>0.101827</td>
      <td>-0.126096</td>
      <td>0.650759</td>
      <td>2.213823</td>
      <td>1.575692</td>
      <td>0.749903</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.045775</td>
      <td>0.371799</td>
      <td>-0.049317</td>
      <td>-0.357219</td>
      <td>0.028782</td>
      <td>0.367445</td>
      <td>0.577498</td>
      <td>0.150580</td>
      <td>-0.265693</td>
      <td>-0.751635</td>
      <td>0.050777</td>
      <td>0.082553</td>
      <td>0.583862</td>
      <td>0.089806</td>
      <td>0.324736</td>
      <td>-0.178511</td>
      <td>0.216121</td>
      <td>-0.001136</td>
      <td>-0.027470</td>
      <td>0.608395</td>
      <td>-0.051553</td>
      <td>0.647372</td>
      <td>0.911252</td>
      <td>0.427534</td>
      <td>0.049886</td>
      <td>0.159312</td>
      <td>-0.319219</td>
      <td>0.334941</td>
      <td>-0.770121</td>
      <td>0.468846</td>
      <td>-0.812630</td>
      <td>0.558729</td>
      <td>0.662677</td>
      <td>0.014279</td>
      <td>0.508151</td>
      <td>0.294423</td>
      <td>1.151858</td>
      <td>-0.466073</td>
      <td>0.237989</td>
      <td>-0.063179</td>
      <td>...</td>
      <td>-0.029795</td>
      <td>0.161140</td>
      <td>0.081079</td>
      <td>-1.266081</td>
      <td>-0.154096</td>
      <td>0.328070</td>
      <td>-0.452122</td>
      <td>0.746755</td>
      <td>-0.067120</td>
      <td>-0.144260</td>
      <td>-0.268656</td>
      <td>-0.415018</td>
      <td>-0.178183</td>
      <td>0.213136</td>
      <td>-0.125397</td>
      <td>0.608941</td>
      <td>-0.037440</td>
      <td>-0.677409</td>
      <td>0.504592</td>
      <td>-0.175202</td>
      <td>1.520258</td>
      <td>0.313289</td>
      <td>0.184132</td>
      <td>-0.063309</td>
      <td>-0.464076</td>
      <td>-0.804478</td>
      <td>-0.671646</td>
      <td>-0.146316</td>
      <td>-0.106924</td>
      <td>-0.028348</td>
      <td>0.637405</td>
      <td>0.764740</td>
      <td>-0.225790</td>
      <td>0.107889</td>
      <td>0.444042</td>
      <td>0.107476</td>
      <td>-0.438280</td>
      <td>-1.624810</td>
      <td>-0.749914</td>
      <td>-0.889963</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.153097</td>
      <td>0.917223</td>
      <td>-0.013813</td>
      <td>0.212527</td>
      <td>0.737927</td>
      <td>0.012463</td>
      <td>0.119715</td>
      <td>-1.148906</td>
      <td>0.888388</td>
      <td>0.347232</td>
      <td>0.211114</td>
      <td>0.412131</td>
      <td>0.828918</td>
      <td>0.219784</td>
      <td>-1.098639</td>
      <td>0.101686</td>
      <td>-0.168812</td>
      <td>0.802889</td>
      <td>-0.621917</td>
      <td>-1.625223</td>
      <td>-0.593333</td>
      <td>-0.032216</td>
      <td>0.784081</td>
      <td>-0.280831</td>
      <td>-0.601543</td>
      <td>-0.492746</td>
      <td>0.051654</td>
      <td>-0.755358</td>
      <td>0.128137</td>
      <td>1.332591</td>
      <td>0.016815</td>
      <td>0.508400</td>
      <td>-0.633130</td>
      <td>-0.903414</td>
      <td>0.523651</td>
      <td>1.427117</td>
      <td>0.060850</td>
      <td>-0.066748</td>
      <td>-0.425209</td>
      <td>-0.334131</td>
      <td>...</td>
      <td>0.873832</td>
      <td>-0.126108</td>
      <td>1.043699</td>
      <td>-0.280487</td>
      <td>-0.182733</td>
      <td>0.153718</td>
      <td>0.022127</td>
      <td>0.591134</td>
      <td>-1.729883</td>
      <td>-1.555405</td>
      <td>-0.610671</td>
      <td>0.005366</td>
      <td>0.311587</td>
      <td>-0.437823</td>
      <td>-0.513380</td>
      <td>0.470621</td>
      <td>0.891012</td>
      <td>-1.057762</td>
      <td>-0.010956</td>
      <td>-0.041820</td>
      <td>-0.190106</td>
      <td>-0.335636</td>
      <td>-0.258059</td>
      <td>0.010360</td>
      <td>-0.743688</td>
      <td>-0.370838</td>
      <td>-0.310956</td>
      <td>-0.074313</td>
      <td>-0.751248</td>
      <td>0.902615</td>
      <td>-0.173139</td>
      <td>0.665559</td>
      <td>-0.279707</td>
      <td>-0.828367</td>
      <td>-0.329166</td>
      <td>-0.376987</td>
      <td>-0.374173</td>
      <td>1.251084</td>
      <td>1.542551</td>
      <td>1.446267</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.586691</td>
      <td>0.785136</td>
      <td>-0.041890</td>
      <td>0.314597</td>
      <td>-0.365590</td>
      <td>0.711135</td>
      <td>1.048897</td>
      <td>-0.438167</td>
      <td>-0.099402</td>
      <td>0.278626</td>
      <td>-0.201510</td>
      <td>-0.864013</td>
      <td>0.254785</td>
      <td>0.137680</td>
      <td>1.118799</td>
      <td>0.432152</td>
      <td>-0.075520</td>
      <td>-0.240465</td>
      <td>0.139162</td>
      <td>0.184865</td>
      <td>0.615919</td>
      <td>0.390294</td>
      <td>0.921405</td>
      <td>0.089701</td>
      <td>0.384928</td>
      <td>-0.105723</td>
      <td>-0.663772</td>
      <td>-1.394473</td>
      <td>0.505915</td>
      <td>0.390416</td>
      <td>0.045508</td>
      <td>0.565524</td>
      <td>-0.904730</td>
      <td>-0.889474</td>
      <td>0.130746</td>
      <td>-0.389644</td>
      <td>-0.847487</td>
      <td>-0.848649</td>
      <td>-0.137948</td>
      <td>-0.720013</td>
      <td>...</td>
      <td>-0.400268</td>
      <td>0.114679</td>
      <td>0.607765</td>
      <td>0.919275</td>
      <td>0.174441</td>
      <td>-0.733586</td>
      <td>0.788411</td>
      <td>0.191408</td>
      <td>-0.377774</td>
      <td>-0.264620</td>
      <td>-0.219170</td>
      <td>-0.087748</td>
      <td>-0.129366</td>
      <td>0.875578</td>
      <td>-0.590080</td>
      <td>-0.009868</td>
      <td>-1.167431</td>
      <td>0.325075</td>
      <td>0.505294</td>
      <td>0.338414</td>
      <td>0.488233</td>
      <td>-0.204546</td>
      <td>0.275973</td>
      <td>-0.331938</td>
      <td>-0.130275</td>
      <td>-0.795100</td>
      <td>-0.172164</td>
      <td>-0.219002</td>
      <td>-0.088873</td>
      <td>0.119793</td>
      <td>0.099130</td>
      <td>0.856621</td>
      <td>0.485031</td>
      <td>-0.043273</td>
      <td>-0.424380</td>
      <td>-0.278238</td>
      <td>0.769697</td>
      <td>-0.583043</td>
      <td>0.312203</td>
      <td>0.798835</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-0.275691</td>
      <td>-0.227593</td>
      <td>-0.344756</td>
      <td>-0.391395</td>
      <td>0.559724</td>
      <td>-0.199967</td>
      <td>-0.385295</td>
      <td>-1.026644</td>
      <td>0.901037</td>
      <td>-1.279282</td>
      <td>-0.355427</td>
      <td>0.298807</td>
      <td>0.379979</td>
      <td>-0.539233</td>
      <td>0.002386</td>
      <td>-0.248467</td>
      <td>-0.048693</td>
      <td>0.208658</td>
      <td>-0.448592</td>
      <td>-0.424849</td>
      <td>-0.010036</td>
      <td>1.122840</td>
      <td>-0.302450</td>
      <td>0.451286</td>
      <td>0.850388</td>
      <td>-0.463645</td>
      <td>1.272770</td>
      <td>0.016278</td>
      <td>-0.225084</td>
      <td>-0.443403</td>
      <td>0.327162</td>
      <td>0.558918</td>
      <td>-0.453018</td>
      <td>0.277744</td>
      <td>0.640042</td>
      <td>1.592678</td>
      <td>0.384507</td>
      <td>0.461656</td>
      <td>0.864185</td>
      <td>0.014208</td>
      <td>...</td>
      <td>-0.315151</td>
      <td>0.428527</td>
      <td>0.018997</td>
      <td>-0.185370</td>
      <td>-0.447241</td>
      <td>0.075921</td>
      <td>0.223517</td>
      <td>0.124982</td>
      <td>-0.878178</td>
      <td>0.488748</td>
      <td>0.037592</td>
      <td>0.110868</td>
      <td>0.458379</td>
      <td>0.611542</td>
      <td>1.315371</td>
      <td>0.747551</td>
      <td>-1.246708</td>
      <td>-0.278278</td>
      <td>-1.266646</td>
      <td>-0.213793</td>
      <td>0.601008</td>
      <td>1.645935</td>
      <td>0.218674</td>
      <td>0.040204</td>
      <td>0.341466</td>
      <td>-0.030439</td>
      <td>0.426622</td>
      <td>-0.361459</td>
      <td>-0.978691</td>
      <td>-0.295878</td>
      <td>-0.106099</td>
      <td>0.529479</td>
      <td>0.432063</td>
      <td>0.090409</td>
      <td>0.211308</td>
      <td>1.340544</td>
      <td>0.775167</td>
      <td>-0.039704</td>
      <td>-0.249282</td>
      <td>0.148299</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.057977</td>
      <td>0.808999</td>
      <td>0.286599</td>
      <td>0.717215</td>
      <td>0.520843</td>
      <td>0.059447</td>
      <td>-0.637107</td>
      <td>-0.236512</td>
      <td>0.629518</td>
      <td>-0.728150</td>
      <td>-0.426162</td>
      <td>-0.594008</td>
      <td>-0.094963</td>
      <td>0.442874</td>
      <td>0.469253</td>
      <td>0.002396</td>
      <td>0.239335</td>
      <td>0.057339</td>
      <td>1.345407</td>
      <td>0.069102</td>
      <td>0.673629</td>
      <td>-0.428757</td>
      <td>0.835299</td>
      <td>-0.216978</td>
      <td>0.555877</td>
      <td>1.486763</td>
      <td>0.805178</td>
      <td>-0.664316</td>
      <td>-0.287378</td>
      <td>0.913303</td>
      <td>-0.599790</td>
      <td>-0.218247</td>
      <td>-0.501536</td>
      <td>-0.186970</td>
      <td>2.201097</td>
      <td>2.169432</td>
      <td>0.589453</td>
      <td>0.072769</td>
      <td>0.079377</td>
      <td>0.216211</td>
      <td>...</td>
      <td>-0.325653</td>
      <td>0.419654</td>
      <td>0.113457</td>
      <td>-0.346808</td>
      <td>0.011164</td>
      <td>1.791034</td>
      <td>0.085062</td>
      <td>0.090530</td>
      <td>0.001639</td>
      <td>-0.627425</td>
      <td>-0.235479</td>
      <td>-0.080175</td>
      <td>1.096326</td>
      <td>0.408524</td>
      <td>0.300072</td>
      <td>-0.565517</td>
      <td>0.358438</td>
      <td>0.425817</td>
      <td>-0.258809</td>
      <td>0.374206</td>
      <td>-1.014552</td>
      <td>0.616750</td>
      <td>1.082078</td>
      <td>-0.231602</td>
      <td>-0.812901</td>
      <td>-0.946715</td>
      <td>0.194704</td>
      <td>-0.258045</td>
      <td>-0.530883</td>
      <td>-0.284658</td>
      <td>-0.309203</td>
      <td>-0.631258</td>
      <td>0.077238</td>
      <td>0.082425</td>
      <td>1.155742</td>
      <td>0.296171</td>
      <td>0.469388</td>
      <td>0.167931</td>
      <td>0.870439</td>
      <td>1.076093</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.032286</td>
      <td>1.015893</td>
      <td>-0.200362</td>
      <td>1.076689</td>
      <td>0.712406</td>
      <td>0.495643</td>
      <td>-0.526929</td>
      <td>-0.010318</td>
      <td>-0.011862</td>
      <td>-0.371259</td>
      <td>-0.780173</td>
      <td>-0.412353</td>
      <td>-0.397492</td>
      <td>-0.859115</td>
      <td>-0.027101</td>
      <td>-0.142537</td>
      <td>-0.904807</td>
      <td>-0.606640</td>
      <td>-0.256280</td>
      <td>-0.693373</td>
      <td>-0.560913</td>
      <td>-0.479647</td>
      <td>-0.058740</td>
      <td>0.464657</td>
      <td>0.166487</td>
      <td>-0.548310</td>
      <td>0.670656</td>
      <td>-0.218577</td>
      <td>-1.134603</td>
      <td>0.347990</td>
      <td>-0.467069</td>
      <td>0.106791</td>
      <td>0.554793</td>
      <td>0.475063</td>
      <td>1.814463</td>
      <td>1.185028</td>
      <td>1.197762</td>
      <td>-0.048246</td>
      <td>1.021297</td>
      <td>0.079419</td>
      <td>...</td>
      <td>0.041594</td>
      <td>-0.649290</td>
      <td>0.085603</td>
      <td>0.441750</td>
      <td>0.270764</td>
      <td>-0.109603</td>
      <td>-0.536329</td>
      <td>-0.230828</td>
      <td>-0.153889</td>
      <td>-1.103639</td>
      <td>-0.699230</td>
      <td>0.058678</td>
      <td>-0.105630</td>
      <td>-0.087842</td>
      <td>-0.567062</td>
      <td>-0.419259</td>
      <td>0.058566</td>
      <td>0.397712</td>
      <td>0.081867</td>
      <td>-1.526823</td>
      <td>-0.476053</td>
      <td>-0.203398</td>
      <td>-0.859964</td>
      <td>-0.181933</td>
      <td>0.385097</td>
      <td>-0.204228</td>
      <td>-0.358574</td>
      <td>-0.075843</td>
      <td>0.423322</td>
      <td>0.011397</td>
      <td>0.335171</td>
      <td>0.317308</td>
      <td>-0.160194</td>
      <td>-0.802502</td>
      <td>-0.092832</td>
      <td>-0.561518</td>
      <td>-0.191109</td>
      <td>0.191024</td>
      <td>0.903569</td>
      <td>0.493583</td>
    </tr>
    <tr>
      <th>18</th>
      <td>1.676980</td>
      <td>0.903289</td>
      <td>-0.337411</td>
      <td>0.797384</td>
      <td>0.747164</td>
      <td>0.116677</td>
      <td>0.429630</td>
      <td>0.161924</td>
      <td>0.620916</td>
      <td>-0.028824</td>
      <td>0.464349</td>
      <td>-0.396669</td>
      <td>-0.635799</td>
      <td>-0.242422</td>
      <td>0.286001</td>
      <td>0.439127</td>
      <td>-0.058723</td>
      <td>-0.974178</td>
      <td>0.033216</td>
      <td>0.326698</td>
      <td>-0.286877</td>
      <td>0.781495</td>
      <td>0.185398</td>
      <td>-0.474588</td>
      <td>0.256565</td>
      <td>-0.730583</td>
      <td>-0.118633</td>
      <td>-0.407897</td>
      <td>-0.194439</td>
      <td>1.352380</td>
      <td>0.814899</td>
      <td>0.933589</td>
      <td>-0.424298</td>
      <td>-0.727837</td>
      <td>0.419722</td>
      <td>0.939087</td>
      <td>-0.299270</td>
      <td>0.321937</td>
      <td>0.092319</td>
      <td>-0.820756</td>
      <td>...</td>
      <td>-0.519497</td>
      <td>0.452018</td>
      <td>-0.522996</td>
      <td>-0.169770</td>
      <td>0.267996</td>
      <td>0.415209</td>
      <td>-0.176007</td>
      <td>-0.558403</td>
      <td>-0.581001</td>
      <td>-0.108435</td>
      <td>-0.445825</td>
      <td>0.233654</td>
      <td>1.629627</td>
      <td>0.010279</td>
      <td>-0.158443</td>
      <td>-0.143982</td>
      <td>-0.543836</td>
      <td>-1.145158</td>
      <td>-0.392662</td>
      <td>-0.795769</td>
      <td>-0.656924</td>
      <td>-0.061466</td>
      <td>-0.335275</td>
      <td>-0.586886</td>
      <td>-0.949494</td>
      <td>-0.564687</td>
      <td>0.122781</td>
      <td>-0.259267</td>
      <td>-0.720862</td>
      <td>-0.157873</td>
      <td>0.274073</td>
      <td>0.349443</td>
      <td>0.104588</td>
      <td>0.027289</td>
      <td>-0.462411</td>
      <td>0.322354</td>
      <td>-0.205020</td>
      <td>2.667002</td>
      <td>1.875846</td>
      <td>0.714077</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.653041</td>
      <td>1.152453</td>
      <td>0.608770</td>
      <td>0.609889</td>
      <td>0.688000</td>
      <td>-0.440512</td>
      <td>-0.208660</td>
      <td>0.212973</td>
      <td>-0.111749</td>
      <td>0.349492</td>
      <td>-1.066481</td>
      <td>-0.830910</td>
      <td>0.320905</td>
      <td>0.133120</td>
      <td>-0.065636</td>
      <td>0.100716</td>
      <td>0.536474</td>
      <td>0.781373</td>
      <td>0.865234</td>
      <td>0.061548</td>
      <td>0.377124</td>
      <td>0.024705</td>
      <td>0.241781</td>
      <td>-0.151136</td>
      <td>-0.375316</td>
      <td>-0.597793</td>
      <td>0.647767</td>
      <td>-0.363820</td>
      <td>-0.567090</td>
      <td>0.572091</td>
      <td>-0.583421</td>
      <td>0.104638</td>
      <td>0.638657</td>
      <td>0.279390</td>
      <td>0.443153</td>
      <td>0.214756</td>
      <td>0.884673</td>
      <td>0.386260</td>
      <td>1.002562</td>
      <td>0.263118</td>
      <td>...</td>
      <td>0.155534</td>
      <td>-0.201804</td>
      <td>-0.566358</td>
      <td>-0.203470</td>
      <td>-0.589086</td>
      <td>-0.296328</td>
      <td>0.373633</td>
      <td>-0.365763</td>
      <td>-0.143060</td>
      <td>-0.988388</td>
      <td>-0.743463</td>
      <td>0.294188</td>
      <td>0.834946</td>
      <td>0.221510</td>
      <td>-0.558153</td>
      <td>-0.091586</td>
      <td>1.192787</td>
      <td>0.735351</td>
      <td>-0.399856</td>
      <td>-0.032091</td>
      <td>0.798585</td>
      <td>0.638411</td>
      <td>0.687454</td>
      <td>0.347550</td>
      <td>-0.021213</td>
      <td>0.178320</td>
      <td>0.816599</td>
      <td>-1.268653</td>
      <td>-0.168202</td>
      <td>0.968663</td>
      <td>-0.751857</td>
      <td>0.264155</td>
      <td>0.400844</td>
      <td>0.838991</td>
      <td>-0.288793</td>
      <td>0.813551</td>
      <td>0.131696</td>
      <td>2.560381</td>
      <td>2.670404</td>
      <td>1.597415</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.327193</td>
      <td>-0.206628</td>
      <td>-0.851512</td>
      <td>-0.639124</td>
      <td>-0.558511</td>
      <td>0.591650</td>
      <td>0.990697</td>
      <td>-0.391208</td>
      <td>1.177405</td>
      <td>0.058545</td>
      <td>0.031500</td>
      <td>0.284575</td>
      <td>0.603632</td>
      <td>0.619150</td>
      <td>0.920872</td>
      <td>-0.542819</td>
      <td>-0.735121</td>
      <td>-1.036577</td>
      <td>-0.204426</td>
      <td>-0.485782</td>
      <td>0.002319</td>
      <td>0.144343</td>
      <td>-0.030901</td>
      <td>-0.202440</td>
      <td>-0.705595</td>
      <td>-0.633293</td>
      <td>0.402609</td>
      <td>0.345318</td>
      <td>0.135607</td>
      <td>1.246356</td>
      <td>0.192124</td>
      <td>0.373454</td>
      <td>0.855684</td>
      <td>1.197218</td>
      <td>0.780273</td>
      <td>0.746752</td>
      <td>0.421511</td>
      <td>-0.341043</td>
      <td>0.147871</td>
      <td>0.621837</td>
      <td>...</td>
      <td>-0.500245</td>
      <td>-0.606282</td>
      <td>-0.702437</td>
      <td>-0.177533</td>
      <td>0.164868</td>
      <td>-0.488393</td>
      <td>-0.371884</td>
      <td>0.160616</td>
      <td>-0.204405</td>
      <td>-0.941357</td>
      <td>-0.983772</td>
      <td>0.065875</td>
      <td>0.430130</td>
      <td>0.247075</td>
      <td>0.227242</td>
      <td>-0.042823</td>
      <td>0.002198</td>
      <td>-1.116062</td>
      <td>-0.141132</td>
      <td>0.073847</td>
      <td>-0.275792</td>
      <td>-1.210712</td>
      <td>-0.262857</td>
      <td>-0.475131</td>
      <td>-0.737727</td>
      <td>-1.665658</td>
      <td>-1.009539</td>
      <td>-1.192627</td>
      <td>-1.360608</td>
      <td>-0.543823</td>
      <td>0.024262</td>
      <td>0.336257</td>
      <td>-0.038756</td>
      <td>-0.504982</td>
      <td>0.091360</td>
      <td>0.379502</td>
      <td>-0.068868</td>
      <td>-0.052417</td>
      <td>0.089152</td>
      <td>-0.668506</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.141129</td>
      <td>0.731469</td>
      <td>0.707789</td>
      <td>1.036121</td>
      <td>1.435186</td>
      <td>1.039008</td>
      <td>0.001964</td>
      <td>0.117436</td>
      <td>0.025026</td>
      <td>-0.075204</td>
      <td>-0.346355</td>
      <td>0.074673</td>
      <td>-0.750656</td>
      <td>0.247561</td>
      <td>0.064484</td>
      <td>0.497265</td>
      <td>0.290691</td>
      <td>0.490096</td>
      <td>0.504061</td>
      <td>-0.163697</td>
      <td>-0.237360</td>
      <td>-0.438615</td>
      <td>-0.497331</td>
      <td>-0.264876</td>
      <td>-0.131877</td>
      <td>0.115369</td>
      <td>0.303494</td>
      <td>-0.325613</td>
      <td>-0.547905</td>
      <td>0.933811</td>
      <td>-0.173572</td>
      <td>1.238664</td>
      <td>-0.185535</td>
      <td>0.337965</td>
      <td>-0.251387</td>
      <td>0.486774</td>
      <td>0.514324</td>
      <td>-0.174577</td>
      <td>1.142398</td>
      <td>-0.636083</td>
      <td>...</td>
      <td>-0.823360</td>
      <td>-0.722336</td>
      <td>-0.594250</td>
      <td>-0.259951</td>
      <td>-0.215670</td>
      <td>-0.725286</td>
      <td>0.475001</td>
      <td>0.641920</td>
      <td>-0.365948</td>
      <td>-0.277309</td>
      <td>-0.681010</td>
      <td>-0.504112</td>
      <td>0.765268</td>
      <td>0.348741</td>
      <td>-0.693230</td>
      <td>0.683811</td>
      <td>1.417587</td>
      <td>0.569167</td>
      <td>-0.090517</td>
      <td>-0.173055</td>
      <td>0.424503</td>
      <td>1.159627</td>
      <td>1.363109</td>
      <td>0.116789</td>
      <td>-0.377682</td>
      <td>-0.048499</td>
      <td>0.841379</td>
      <td>-0.821757</td>
      <td>-0.995951</td>
      <td>0.057226</td>
      <td>0.703928</td>
      <td>0.043758</td>
      <td>0.330572</td>
      <td>-0.812634</td>
      <td>-0.676241</td>
      <td>-2.197660</td>
      <td>-0.302066</td>
      <td>2.292116</td>
      <td>1.535516</td>
      <td>0.767339</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.018576</td>
      <td>0.306097</td>
      <td>-0.304838</td>
      <td>0.279578</td>
      <td>0.804338</td>
      <td>-0.091051</td>
      <td>0.135758</td>
      <td>-0.158296</td>
      <td>-0.432580</td>
      <td>-0.410005</td>
      <td>-0.128395</td>
      <td>0.484442</td>
      <td>0.555971</td>
      <td>-0.022491</td>
      <td>-0.064407</td>
      <td>0.252335</td>
      <td>-0.318271</td>
      <td>1.018851</td>
      <td>0.130893</td>
      <td>-0.745560</td>
      <td>-0.133151</td>
      <td>-0.917888</td>
      <td>-0.267998</td>
      <td>-0.464212</td>
      <td>-0.294479</td>
      <td>1.045366</td>
      <td>0.449096</td>
      <td>-0.431297</td>
      <td>-0.178316</td>
      <td>0.769300</td>
      <td>0.520548</td>
      <td>-0.287852</td>
      <td>0.085274</td>
      <td>-0.151692</td>
      <td>0.589053</td>
      <td>0.422280</td>
      <td>0.919963</td>
      <td>0.279970</td>
      <td>0.886626</td>
      <td>0.023738</td>
      <td>...</td>
      <td>-0.699683</td>
      <td>-1.647186</td>
      <td>-0.078504</td>
      <td>0.140295</td>
      <td>0.109712</td>
      <td>0.149919</td>
      <td>0.349964</td>
      <td>1.054982</td>
      <td>-0.249205</td>
      <td>-0.848166</td>
      <td>-0.216140</td>
      <td>-0.113363</td>
      <td>0.765746</td>
      <td>0.460388</td>
      <td>1.224173</td>
      <td>0.545876</td>
      <td>0.120962</td>
      <td>1.043492</td>
      <td>0.265477</td>
      <td>0.242865</td>
      <td>0.368640</td>
      <td>1.219302</td>
      <td>-0.344263</td>
      <td>-0.594824</td>
      <td>-0.439231</td>
      <td>0.686313</td>
      <td>0.380460</td>
      <td>-0.551742</td>
      <td>-1.323443</td>
      <td>0.027815</td>
      <td>-0.855088</td>
      <td>-0.140816</td>
      <td>0.351906</td>
      <td>-0.041527</td>
      <td>-0.293036</td>
      <td>0.248376</td>
      <td>0.591821</td>
      <td>1.002849</td>
      <td>1.139979</td>
      <td>1.251234</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.265723</td>
      <td>0.497441</td>
      <td>-0.515038</td>
      <td>-0.007348</td>
      <td>0.561997</td>
      <td>-0.406290</td>
      <td>0.133322</td>
      <td>-0.415462</td>
      <td>0.417787</td>
      <td>-0.648167</td>
      <td>-0.009198</td>
      <td>0.209653</td>
      <td>0.967168</td>
      <td>0.696109</td>
      <td>0.680894</td>
      <td>0.228619</td>
      <td>-0.420599</td>
      <td>-0.630027</td>
      <td>0.960402</td>
      <td>-0.341585</td>
      <td>-0.313593</td>
      <td>-0.258107</td>
      <td>-0.047305</td>
      <td>-0.712932</td>
      <td>-0.395460</td>
      <td>-0.307657</td>
      <td>-0.296779</td>
      <td>-1.132942</td>
      <td>-0.251181</td>
      <td>0.196586</td>
      <td>0.409452</td>
      <td>0.017574</td>
      <td>0.083055</td>
      <td>-0.555079</td>
      <td>0.827181</td>
      <td>1.496544</td>
      <td>0.341639</td>
      <td>0.475500</td>
      <td>1.160563</td>
      <td>0.572545</td>
      <td>...</td>
      <td>0.753211</td>
      <td>0.769129</td>
      <td>0.238746</td>
      <td>-0.054218</td>
      <td>0.250946</td>
      <td>0.705774</td>
      <td>-0.328973</td>
      <td>0.000660</td>
      <td>0.412540</td>
      <td>-0.389696</td>
      <td>-0.779784</td>
      <td>-1.165824</td>
      <td>0.901673</td>
      <td>0.209114</td>
      <td>0.055739</td>
      <td>-0.210517</td>
      <td>0.205074</td>
      <td>-0.336916</td>
      <td>-0.715619</td>
      <td>-0.644626</td>
      <td>-0.641352</td>
      <td>-0.042407</td>
      <td>1.596141</td>
      <td>0.321662</td>
      <td>-0.332161</td>
      <td>-0.580672</td>
      <td>0.603230</td>
      <td>0.560542</td>
      <td>0.140583</td>
      <td>-0.038364</td>
      <td>0.014181</td>
      <td>0.040007</td>
      <td>0.555526</td>
      <td>-1.041280</td>
      <td>-0.840027</td>
      <td>0.039132</td>
      <td>0.606651</td>
      <td>1.951670</td>
      <td>1.614302</td>
      <td>0.338026</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-0.202938</td>
      <td>0.507938</td>
      <td>0.038115</td>
      <td>1.147788</td>
      <td>1.304924</td>
      <td>0.793929</td>
      <td>-0.363010</td>
      <td>0.011111</td>
      <td>0.106535</td>
      <td>-0.783719</td>
      <td>0.691109</td>
      <td>0.328223</td>
      <td>0.589795</td>
      <td>0.050923</td>
      <td>-0.533888</td>
      <td>0.121506</td>
      <td>0.531566</td>
      <td>-0.075466</td>
      <td>1.296842</td>
      <td>0.022622</td>
      <td>-1.207449</td>
      <td>0.259788</td>
      <td>0.092678</td>
      <td>-0.859410</td>
      <td>-0.231708</td>
      <td>-0.822977</td>
      <td>-0.041829</td>
      <td>-0.195113</td>
      <td>-0.570551</td>
      <td>0.800779</td>
      <td>0.163357</td>
      <td>0.425429</td>
      <td>0.369589</td>
      <td>0.456164</td>
      <td>0.870137</td>
      <td>0.796467</td>
      <td>-0.132587</td>
      <td>-0.137322</td>
      <td>0.067919</td>
      <td>-0.721274</td>
      <td>...</td>
      <td>-1.045307</td>
      <td>-0.752398</td>
      <td>0.277232</td>
      <td>1.300618</td>
      <td>-0.647198</td>
      <td>-1.086080</td>
      <td>-1.312712</td>
      <td>-1.122069</td>
      <td>-1.329038</td>
      <td>-0.848062</td>
      <td>-1.001415</td>
      <td>-0.737185</td>
      <td>0.355787</td>
      <td>-0.546387</td>
      <td>0.258107</td>
      <td>-0.124842</td>
      <td>0.236099</td>
      <td>0.479317</td>
      <td>0.863414</td>
      <td>0.202520</td>
      <td>0.584295</td>
      <td>0.347540</td>
      <td>0.466039</td>
      <td>0.376326</td>
      <td>-0.091232</td>
      <td>0.544879</td>
      <td>0.305509</td>
      <td>0.235035</td>
      <td>-0.875204</td>
      <td>-0.702171</td>
      <td>-0.575352</td>
      <td>-0.611307</td>
      <td>-1.031109</td>
      <td>-0.592259</td>
      <td>1.152631</td>
      <td>0.792048</td>
      <td>-0.758727</td>
      <td>2.037618</td>
      <td>1.460720</td>
      <td>0.827260</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.747063</td>
      <td>0.184493</td>
      <td>0.000210</td>
      <td>0.244878</td>
      <td>0.273928</td>
      <td>0.374962</td>
      <td>-0.252295</td>
      <td>-0.396265</td>
      <td>0.289222</td>
      <td>-0.548918</td>
      <td>0.479946</td>
      <td>1.494686</td>
      <td>1.041277</td>
      <td>0.635939</td>
      <td>-0.259351</td>
      <td>-0.769938</td>
      <td>-1.053283</td>
      <td>0.268820</td>
      <td>-1.295089</td>
      <td>-1.173025</td>
      <td>-1.441496</td>
      <td>0.059597</td>
      <td>-0.258317</td>
      <td>0.596586</td>
      <td>-0.941877</td>
      <td>0.412522</td>
      <td>0.318669</td>
      <td>0.617191</td>
      <td>0.332823</td>
      <td>0.089319</td>
      <td>-0.346859</td>
      <td>-0.459428</td>
      <td>-0.765698</td>
      <td>0.649161</td>
      <td>-0.270376</td>
      <td>0.068072</td>
      <td>-0.751080</td>
      <td>0.149469</td>
      <td>-0.563803</td>
      <td>-0.681532</td>
      <td>...</td>
      <td>0.204674</td>
      <td>-0.833509</td>
      <td>-0.781223</td>
      <td>-1.011161</td>
      <td>0.052839</td>
      <td>0.585236</td>
      <td>-0.157607</td>
      <td>-0.546009</td>
      <td>-0.611997</td>
      <td>0.435278</td>
      <td>-0.553285</td>
      <td>0.073309</td>
      <td>-0.780663</td>
      <td>-0.139005</td>
      <td>0.344678</td>
      <td>0.719504</td>
      <td>0.777158</td>
      <td>-0.096164</td>
      <td>-0.128426</td>
      <td>-0.521363</td>
      <td>0.083872</td>
      <td>-0.306045</td>
      <td>1.155829</td>
      <td>0.941799</td>
      <td>0.985443</td>
      <td>0.093309</td>
      <td>0.040429</td>
      <td>0.382791</td>
      <td>0.143334</td>
      <td>0.956378</td>
      <td>0.251690</td>
      <td>-0.513445</td>
      <td>-0.345231</td>
      <td>-0.752853</td>
      <td>-1.181049</td>
      <td>-0.674466</td>
      <td>0.147716</td>
      <td>-0.494957</td>
      <td>-0.227370</td>
      <td>-0.348255</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.140134</td>
      <td>1.182890</td>
      <td>-0.111492</td>
      <td>0.883791</td>
      <td>-0.000738</td>
      <td>-0.141563</td>
      <td>-1.077165</td>
      <td>-0.090760</td>
      <td>-0.209887</td>
      <td>-0.056271</td>
      <td>-0.772396</td>
      <td>-0.820671</td>
      <td>-0.391087</td>
      <td>-0.459095</td>
      <td>-0.699758</td>
      <td>-0.039882</td>
      <td>0.175390</td>
      <td>0.537459</td>
      <td>-0.292836</td>
      <td>-0.867182</td>
      <td>-0.052027</td>
      <td>0.056810</td>
      <td>1.060223</td>
      <td>-0.268038</td>
      <td>0.217455</td>
      <td>0.287984</td>
      <td>-0.749169</td>
      <td>0.000197</td>
      <td>-0.127882</td>
      <td>-0.275160</td>
      <td>0.428889</td>
      <td>0.131694</td>
      <td>0.027090</td>
      <td>0.200519</td>
      <td>-0.549434</td>
      <td>-0.024266</td>
      <td>-0.355987</td>
      <td>0.232593</td>
      <td>0.000351</td>
      <td>-0.362288</td>
      <td>...</td>
      <td>-0.366874</td>
      <td>-0.510254</td>
      <td>-0.590978</td>
      <td>-0.082747</td>
      <td>0.291980</td>
      <td>1.068754</td>
      <td>-0.757391</td>
      <td>-0.643490</td>
      <td>-0.701823</td>
      <td>0.097037</td>
      <td>-0.510256</td>
      <td>0.644765</td>
      <td>-0.060818</td>
      <td>-0.859525</td>
      <td>0.777897</td>
      <td>1.363099</td>
      <td>-0.036778</td>
      <td>0.042400</td>
      <td>0.665767</td>
      <td>-0.006649</td>
      <td>0.527125</td>
      <td>-0.714354</td>
      <td>-1.812867</td>
      <td>0.303464</td>
      <td>0.169599</td>
      <td>0.046497</td>
      <td>0.634913</td>
      <td>0.482527</td>
      <td>0.835190</td>
      <td>0.745636</td>
      <td>0.274536</td>
      <td>0.196709</td>
      <td>0.273186</td>
      <td>-0.043151</td>
      <td>-0.562133</td>
      <td>-0.951709</td>
      <td>-0.306337</td>
      <td>2.015967</td>
      <td>1.450696</td>
      <td>1.037650</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.760281</td>
      <td>0.379350</td>
      <td>-0.476929</td>
      <td>-0.520154</td>
      <td>0.440647</td>
      <td>-0.095723</td>
      <td>-0.608079</td>
      <td>-1.210118</td>
      <td>-0.103574</td>
      <td>0.116589</td>
      <td>-1.052260</td>
      <td>0.989760</td>
      <td>0.361670</td>
      <td>0.125250</td>
      <td>0.441759</td>
      <td>0.573160</td>
      <td>-0.251912</td>
      <td>0.907739</td>
      <td>-0.670996</td>
      <td>0.815911</td>
      <td>-0.587812</td>
      <td>-0.870690</td>
      <td>-0.447973</td>
      <td>-0.354785</td>
      <td>-0.262517</td>
      <td>0.185774</td>
      <td>-0.017244</td>
      <td>-0.377241</td>
      <td>-0.392395</td>
      <td>-1.017437</td>
      <td>-0.775704</td>
      <td>0.516348</td>
      <td>0.223173</td>
      <td>-1.049594</td>
      <td>-0.747399</td>
      <td>0.345812</td>
      <td>-0.688723</td>
      <td>-0.341114</td>
      <td>-0.048612</td>
      <td>-0.527727</td>
      <td>...</td>
      <td>0.338509</td>
      <td>-0.008385</td>
      <td>-0.037166</td>
      <td>1.849589</td>
      <td>1.295029</td>
      <td>-0.085808</td>
      <td>-1.198794</td>
      <td>-0.042168</td>
      <td>0.346345</td>
      <td>0.717697</td>
      <td>0.121818</td>
      <td>0.717514</td>
      <td>0.005211</td>
      <td>-0.265956</td>
      <td>0.118684</td>
      <td>0.438758</td>
      <td>0.067856</td>
      <td>0.554129</td>
      <td>0.188054</td>
      <td>0.236418</td>
      <td>-0.013381</td>
      <td>0.722460</td>
      <td>0.716483</td>
      <td>0.316826</td>
      <td>0.709587</td>
      <td>-0.530858</td>
      <td>0.836330</td>
      <td>1.048301</td>
      <td>1.220790</td>
      <td>1.363516</td>
      <td>0.485812</td>
      <td>-0.154887</td>
      <td>0.026548</td>
      <td>-0.054941</td>
      <td>-0.581667</td>
      <td>-0.420632</td>
      <td>0.081857</td>
      <td>0.225908</td>
      <td>0.303323</td>
      <td>-0.343480</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.539921</td>
      <td>-0.312086</td>
      <td>0.208617</td>
      <td>0.451791</td>
      <td>1.044047</td>
      <td>0.455329</td>
      <td>-0.400755</td>
      <td>-0.205945</td>
      <td>-0.512433</td>
      <td>-0.414924</td>
      <td>0.481691</td>
      <td>0.681557</td>
      <td>0.294147</td>
      <td>0.437967</td>
      <td>0.411269</td>
      <td>0.243938</td>
      <td>-0.342728</td>
      <td>0.142915</td>
      <td>0.267086</td>
      <td>-0.337973</td>
      <td>0.034741</td>
      <td>-0.290295</td>
      <td>-1.142751</td>
      <td>-0.377782</td>
      <td>-0.265504</td>
      <td>-0.344828</td>
      <td>-0.598097</td>
      <td>0.006946</td>
      <td>-0.040567</td>
      <td>-0.422760</td>
      <td>0.509711</td>
      <td>0.955485</td>
      <td>-0.358231</td>
      <td>-0.618715</td>
      <td>0.894762</td>
      <td>-0.026529</td>
      <td>-0.678868</td>
      <td>-0.365322</td>
      <td>0.833119</td>
      <td>0.415576</td>
      <td>...</td>
      <td>0.351622</td>
      <td>0.658995</td>
      <td>0.407760</td>
      <td>0.421510</td>
      <td>0.463919</td>
      <td>0.716073</td>
      <td>-0.192011</td>
      <td>-0.693099</td>
      <td>0.319164</td>
      <td>-1.006188</td>
      <td>-0.232256</td>
      <td>-0.182737</td>
      <td>-0.374388</td>
      <td>-0.979418</td>
      <td>-0.703410</td>
      <td>0.685845</td>
      <td>0.429348</td>
      <td>-0.512797</td>
      <td>1.006255</td>
      <td>0.012854</td>
      <td>0.455845</td>
      <td>-0.817033</td>
      <td>-0.059814</td>
      <td>0.181404</td>
      <td>0.670176</td>
      <td>0.118097</td>
      <td>0.638682</td>
      <td>0.437682</td>
      <td>-0.666501</td>
      <td>-0.654942</td>
      <td>-0.263309</td>
      <td>-0.337443</td>
      <td>0.427521</td>
      <td>-0.426017</td>
      <td>0.529890</td>
      <td>0.020377</td>
      <td>0.044524</td>
      <td>1.116568</td>
      <td>1.244362</td>
      <td>0.107999</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.214576</td>
      <td>0.999462</td>
      <td>0.314460</td>
      <td>1.000259</td>
      <td>0.699392</td>
      <td>-0.900817</td>
      <td>-0.978768</td>
      <td>-0.301973</td>
      <td>-0.303113</td>
      <td>0.638007</td>
      <td>-0.244466</td>
      <td>0.040908</td>
      <td>0.362389</td>
      <td>0.450700</td>
      <td>0.515766</td>
      <td>0.100530</td>
      <td>-0.101144</td>
      <td>-0.323898</td>
      <td>-0.138890</td>
      <td>0.240960</td>
      <td>-0.128098</td>
      <td>-0.260426</td>
      <td>-0.132923</td>
      <td>-0.349898</td>
      <td>-0.664632</td>
      <td>-0.158085</td>
      <td>-0.144932</td>
      <td>0.082315</td>
      <td>-0.148640</td>
      <td>0.022676</td>
      <td>-0.791453</td>
      <td>-0.796378</td>
      <td>-1.317151</td>
      <td>-0.826529</td>
      <td>0.042729</td>
      <td>0.702330</td>
      <td>0.008530</td>
      <td>-0.173145</td>
      <td>0.800395</td>
      <td>1.260812</td>
      <td>...</td>
      <td>0.441979</td>
      <td>0.343927</td>
      <td>0.399654</td>
      <td>0.332839</td>
      <td>0.610537</td>
      <td>-0.213289</td>
      <td>-1.457371</td>
      <td>-1.143221</td>
      <td>-0.886847</td>
      <td>-0.215877</td>
      <td>0.270546</td>
      <td>0.468799</td>
      <td>-0.350994</td>
      <td>0.508428</td>
      <td>-0.323285</td>
      <td>-0.539633</td>
      <td>-0.947440</td>
      <td>-0.005148</td>
      <td>-0.137475</td>
      <td>1.358588</td>
      <td>0.535944</td>
      <td>0.365018</td>
      <td>1.578627</td>
      <td>0.239924</td>
      <td>-0.451995</td>
      <td>-0.256830</td>
      <td>-0.731552</td>
      <td>0.652273</td>
      <td>-0.968568</td>
      <td>0.722470</td>
      <td>-0.014931</td>
      <td>-0.037340</td>
      <td>0.821657</td>
      <td>-0.515878</td>
      <td>0.043744</td>
      <td>-0.180085</td>
      <td>-0.191297</td>
      <td>1.918724</td>
      <td>1.180218</td>
      <td>-0.339524</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f3859286070&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef  std err          t          P&gt;|t|    2.5 %    97.5 %
D  1.064434  0.04009  26.551394  2.474737e-155  0.98586  1.143008
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  6.074 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>