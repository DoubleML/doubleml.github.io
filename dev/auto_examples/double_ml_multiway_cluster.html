
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.f6b7ca918bee2f46fd9abac01cfb07d5.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1e043a052b0af929e4d8.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">


    
    <a class="navbar-brand" href="../index.html">
      <p class="title">DoubleML</p>
    </a>
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  DoubleML
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/install.html">
  Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/intro.html">
  Getting started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../guide/guide.html">
  User guide
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api.html">
  Python API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference external nav-link" href="https://docs.doubleml.org/r/stable/">
  R API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../release/release.html">
  Release notes
 </a>
</li>

        
      </ul>

      <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><p class="logo" style="text-align:center;"><a href="../index.html">
    <img class="logo" src="../logo.png" alt="Logo" width="65%" height="65%">
</a></p><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l2 current active">
  <a class="current reference internal" href="#">
   Multiway Cluster Robust DML
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="double_ml_bonus_data.html">
   DML: Bonus Data
  </a>
 </li>
</ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulate-multiway-cluster-data">
   Simulate multiway cluster data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
   Initialize the objects of class DoubleMLData and DoubleMLPLIV
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#split-samples-and-transfer-the-sample-splitting-to-the-object">
   Split samples and transfer the sample splitting to the object
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fit-the-model-and-show-a-summary">
   Fit the model and show a summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing">
   Visualization of sample splitting with tuple and linear indexing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold">
     Visualize sample splitting with tuples (one plot per fold)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
     Visualize sample splitting with linear indexing (one column per fold)
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-0.123202</td>
      <td>0.203285</td>
      <td>0.136615</td>
      <td>-0.089015</td>
      <td>-0.108411</td>
      <td>-0.688768</td>
      <td>-0.380762</td>
      <td>-0.062210</td>
      <td>0.457005</td>
      <td>0.210569</td>
      <td>-0.276818</td>
      <td>0.297055</td>
      <td>-0.490837</td>
      <td>0.624482</td>
      <td>0.369998</td>
      <td>-0.403890</td>
      <td>0.308336</td>
      <td>0.159449</td>
      <td>-0.297428</td>
      <td>-0.313960</td>
      <td>0.129396</td>
      <td>0.773937</td>
      <td>0.873692</td>
      <td>1.150594</td>
      <td>-0.070310</td>
      <td>-0.141431</td>
      <td>0.554381</td>
      <td>-1.425848</td>
      <td>-1.042787</td>
      <td>-0.389142</td>
      <td>0.558166</td>
      <td>0.149868</td>
      <td>-0.192628</td>
      <td>0.335294</td>
      <td>-0.554588</td>
      <td>-0.492452</td>
      <td>0.136160</td>
      <td>0.714102</td>
      <td>0.219043</td>
      <td>-0.322441</td>
      <td>...</td>
      <td>-0.162377</td>
      <td>0.085045</td>
      <td>0.052891</td>
      <td>0.424710</td>
      <td>-0.233345</td>
      <td>0.242310</td>
      <td>0.168616</td>
      <td>0.138571</td>
      <td>-0.879245</td>
      <td>-0.015261</td>
      <td>0.223152</td>
      <td>-0.918826</td>
      <td>-0.464480</td>
      <td>0.098672</td>
      <td>-0.009480</td>
      <td>0.992193</td>
      <td>-0.011755</td>
      <td>0.521244</td>
      <td>0.545045</td>
      <td>0.788593</td>
      <td>0.563094</td>
      <td>0.531871</td>
      <td>0.943915</td>
      <td>0.279779</td>
      <td>-0.388374</td>
      <td>0.486270</td>
      <td>-0.630134</td>
      <td>-0.250466</td>
      <td>-0.322822</td>
      <td>-0.433106</td>
      <td>-0.320717</td>
      <td>0.087998</td>
      <td>-0.521485</td>
      <td>-0.643191</td>
      <td>-0.606358</td>
      <td>0.121589</td>
      <td>0.301270</td>
      <td>-1.060713</td>
      <td>-0.532161</td>
      <td>-0.036918</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.217568</td>
      <td>0.791332</td>
      <td>0.794234</td>
      <td>-0.202628</td>
      <td>0.425295</td>
      <td>-0.468839</td>
      <td>1.349702</td>
      <td>0.845728</td>
      <td>0.372583</td>
      <td>0.034512</td>
      <td>-0.652802</td>
      <td>0.375977</td>
      <td>-0.870806</td>
      <td>0.942701</td>
      <td>0.327035</td>
      <td>0.140743</td>
      <td>0.335487</td>
      <td>-0.055339</td>
      <td>0.796633</td>
      <td>0.122350</td>
      <td>0.092847</td>
      <td>-0.283872</td>
      <td>0.689686</td>
      <td>0.352408</td>
      <td>0.190487</td>
      <td>0.395300</td>
      <td>-0.202010</td>
      <td>0.127782</td>
      <td>-0.285634</td>
      <td>-0.567333</td>
      <td>0.207327</td>
      <td>0.363336</td>
      <td>-0.583260</td>
      <td>0.070005</td>
      <td>0.291530</td>
      <td>-0.546307</td>
      <td>0.171888</td>
      <td>0.200331</td>
      <td>0.720997</td>
      <td>-0.079558</td>
      <td>...</td>
      <td>0.308732</td>
      <td>-0.907505</td>
      <td>-0.001347</td>
      <td>-1.053011</td>
      <td>0.208848</td>
      <td>0.243785</td>
      <td>-0.301853</td>
      <td>-0.881358</td>
      <td>-0.361180</td>
      <td>-0.310305</td>
      <td>0.691513</td>
      <td>-0.140789</td>
      <td>-0.183658</td>
      <td>-0.175850</td>
      <td>0.079764</td>
      <td>-0.074629</td>
      <td>-0.741772</td>
      <td>0.006415</td>
      <td>0.693009</td>
      <td>0.747858</td>
      <td>0.320381</td>
      <td>1.202736</td>
      <td>0.964640</td>
      <td>0.235678</td>
      <td>-0.338614</td>
      <td>-0.333475</td>
      <td>-0.695731</td>
      <td>-0.555352</td>
      <td>0.473916</td>
      <td>0.524596</td>
      <td>-0.260481</td>
      <td>-0.776463</td>
      <td>-0.635608</td>
      <td>-0.003708</td>
      <td>-0.021486</td>
      <td>-0.151612</td>
      <td>0.476151</td>
      <td>1.343550</td>
      <td>1.754850</td>
      <td>0.838496</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.669988</td>
      <td>0.188846</td>
      <td>0.893457</td>
      <td>-0.004717</td>
      <td>0.448427</td>
      <td>0.385259</td>
      <td>-0.338324</td>
      <td>0.809234</td>
      <td>0.134712</td>
      <td>-0.145710</td>
      <td>-0.786350</td>
      <td>-0.487918</td>
      <td>-1.002768</td>
      <td>-0.544420</td>
      <td>-0.689690</td>
      <td>-0.068177</td>
      <td>-0.652781</td>
      <td>0.837136</td>
      <td>-0.862415</td>
      <td>0.472158</td>
      <td>-0.023313</td>
      <td>-0.216134</td>
      <td>-0.167019</td>
      <td>0.911681</td>
      <td>-0.637306</td>
      <td>0.178906</td>
      <td>-0.135692</td>
      <td>0.344217</td>
      <td>0.027638</td>
      <td>-0.563205</td>
      <td>-0.565764</td>
      <td>0.983164</td>
      <td>-0.544800</td>
      <td>-0.600282</td>
      <td>0.319475</td>
      <td>0.458493</td>
      <td>0.373339</td>
      <td>-0.251925</td>
      <td>0.029392</td>
      <td>-0.078991</td>
      <td>...</td>
      <td>-0.330587</td>
      <td>0.097526</td>
      <td>0.228564</td>
      <td>-0.186079</td>
      <td>0.469353</td>
      <td>-0.308351</td>
      <td>0.292287</td>
      <td>0.983886</td>
      <td>-0.600527</td>
      <td>-0.790607</td>
      <td>-0.148175</td>
      <td>-0.342811</td>
      <td>0.076947</td>
      <td>0.286805</td>
      <td>0.340869</td>
      <td>-0.737509</td>
      <td>-0.033085</td>
      <td>0.492447</td>
      <td>0.666614</td>
      <td>0.449591</td>
      <td>1.045090</td>
      <td>1.502075</td>
      <td>0.330060</td>
      <td>1.097161</td>
      <td>0.309765</td>
      <td>-1.204356</td>
      <td>0.335139</td>
      <td>-0.416215</td>
      <td>-0.675923</td>
      <td>-0.113023</td>
      <td>0.572715</td>
      <td>0.679338</td>
      <td>0.490541</td>
      <td>0.178423</td>
      <td>0.443396</td>
      <td>0.750940</td>
      <td>0.751379</td>
      <td>-0.532936</td>
      <td>-0.136502</td>
      <td>-0.219650</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.154265</td>
      <td>0.811411</td>
      <td>0.938083</td>
      <td>0.124830</td>
      <td>1.403845</td>
      <td>0.653591</td>
      <td>0.370662</td>
      <td>0.326952</td>
      <td>-0.194009</td>
      <td>0.194397</td>
      <td>-0.495246</td>
      <td>-0.327327</td>
      <td>-0.701250</td>
      <td>0.521851</td>
      <td>0.069160</td>
      <td>0.125913</td>
      <td>0.065020</td>
      <td>-0.647554</td>
      <td>-0.140468</td>
      <td>0.678739</td>
      <td>-0.071711</td>
      <td>-0.970557</td>
      <td>0.878567</td>
      <td>-0.220322</td>
      <td>-0.844798</td>
      <td>0.096579</td>
      <td>-0.065739</td>
      <td>0.318054</td>
      <td>-0.061359</td>
      <td>-0.137324</td>
      <td>-1.019592</td>
      <td>-0.458429</td>
      <td>-0.567415</td>
      <td>-0.671514</td>
      <td>-0.908508</td>
      <td>-0.372152</td>
      <td>-1.041417</td>
      <td>-0.606190</td>
      <td>0.450943</td>
      <td>1.674047</td>
      <td>...</td>
      <td>-0.466846</td>
      <td>0.102613</td>
      <td>-0.803871</td>
      <td>0.647324</td>
      <td>0.362663</td>
      <td>1.071499</td>
      <td>0.361889</td>
      <td>0.574475</td>
      <td>0.116603</td>
      <td>-0.269431</td>
      <td>0.586308</td>
      <td>-1.168571</td>
      <td>-0.222189</td>
      <td>-0.957673</td>
      <td>0.201801</td>
      <td>0.134822</td>
      <td>-0.109115</td>
      <td>0.607735</td>
      <td>0.546027</td>
      <td>0.117812</td>
      <td>0.889826</td>
      <td>0.442917</td>
      <td>0.043355</td>
      <td>1.101739</td>
      <td>0.332117</td>
      <td>-0.394364</td>
      <td>-0.125988</td>
      <td>-0.449912</td>
      <td>-1.762746</td>
      <td>-0.504722</td>
      <td>0.308409</td>
      <td>1.051861</td>
      <td>-0.763480</td>
      <td>-0.317424</td>
      <td>0.110273</td>
      <td>-0.228594</td>
      <td>-0.281027</td>
      <td>0.154052</td>
      <td>0.078983</td>
      <td>-0.270504</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.195616</td>
      <td>0.258680</td>
      <td>0.106297</td>
      <td>0.311060</td>
      <td>1.481200</td>
      <td>0.082128</td>
      <td>-0.124400</td>
      <td>1.154340</td>
      <td>-0.037287</td>
      <td>-0.493777</td>
      <td>-0.377290</td>
      <td>0.572882</td>
      <td>-1.102481</td>
      <td>0.507635</td>
      <td>0.564105</td>
      <td>0.583339</td>
      <td>0.555621</td>
      <td>0.374801</td>
      <td>0.114361</td>
      <td>0.324665</td>
      <td>-0.001724</td>
      <td>-1.273953</td>
      <td>0.415230</td>
      <td>0.309252</td>
      <td>-0.664360</td>
      <td>-0.498887</td>
      <td>1.363365</td>
      <td>0.709129</td>
      <td>1.101212</td>
      <td>0.623367</td>
      <td>-2.007634</td>
      <td>-0.824085</td>
      <td>-0.000405</td>
      <td>-0.162461</td>
      <td>-0.108651</td>
      <td>-0.525894</td>
      <td>-0.472487</td>
      <td>-0.144180</td>
      <td>0.199851</td>
      <td>0.284885</td>
      <td>...</td>
      <td>0.210226</td>
      <td>0.407848</td>
      <td>0.267968</td>
      <td>-0.095075</td>
      <td>0.296718</td>
      <td>-0.566512</td>
      <td>0.319473</td>
      <td>0.256201</td>
      <td>-0.114413</td>
      <td>0.081729</td>
      <td>0.477592</td>
      <td>0.023613</td>
      <td>0.061244</td>
      <td>-0.302850</td>
      <td>0.177788</td>
      <td>0.480602</td>
      <td>-0.478732</td>
      <td>0.751716</td>
      <td>-0.014912</td>
      <td>0.435433</td>
      <td>0.402034</td>
      <td>-0.417056</td>
      <td>-0.275968</td>
      <td>0.158599</td>
      <td>-0.038175</td>
      <td>0.298562</td>
      <td>0.143768</td>
      <td>-0.178558</td>
      <td>-0.690698</td>
      <td>-1.819355</td>
      <td>-0.129084</td>
      <td>-0.370204</td>
      <td>-0.006367</td>
      <td>0.536339</td>
      <td>0.437487</td>
      <td>0.441621</td>
      <td>0.663583</td>
      <td>1.681320</td>
      <td>0.856089</td>
      <td>-0.198643</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.356361</td>
      <td>0.692458</td>
      <td>-0.462783</td>
      <td>-0.361881</td>
      <td>0.502257</td>
      <td>0.179087</td>
      <td>1.288542</td>
      <td>0.658667</td>
      <td>1.706421</td>
      <td>-0.249723</td>
      <td>-0.179629</td>
      <td>0.885642</td>
      <td>0.535859</td>
      <td>-0.989061</td>
      <td>-1.505335</td>
      <td>0.142196</td>
      <td>-0.044736</td>
      <td>-0.196988</td>
      <td>-0.088624</td>
      <td>0.208984</td>
      <td>-0.478801</td>
      <td>-0.867640</td>
      <td>0.469475</td>
      <td>0.596699</td>
      <td>1.054585</td>
      <td>0.187414</td>
      <td>0.154171</td>
      <td>-0.416644</td>
      <td>0.018949</td>
      <td>-0.328685</td>
      <td>-1.451980</td>
      <td>0.410873</td>
      <td>-0.608378</td>
      <td>0.434154</td>
      <td>0.235175</td>
      <td>-0.850642</td>
      <td>-0.209808</td>
      <td>0.103121</td>
      <td>0.901725</td>
      <td>-0.119871</td>
      <td>...</td>
      <td>-0.573355</td>
      <td>-0.443502</td>
      <td>-0.047806</td>
      <td>1.840507</td>
      <td>0.505918</td>
      <td>0.957045</td>
      <td>-0.361998</td>
      <td>0.010641</td>
      <td>0.120744</td>
      <td>1.334300</td>
      <td>1.511559</td>
      <td>0.474740</td>
      <td>0.280654</td>
      <td>-0.438135</td>
      <td>0.269111</td>
      <td>0.098348</td>
      <td>-0.095286</td>
      <td>0.170712</td>
      <td>-0.469801</td>
      <td>0.412588</td>
      <td>0.267024</td>
      <td>-0.692363</td>
      <td>-0.597217</td>
      <td>-0.110876</td>
      <td>-0.153872</td>
      <td>0.300823</td>
      <td>-0.554791</td>
      <td>-0.310326</td>
      <td>-0.195826</td>
      <td>-1.380656</td>
      <td>-0.123030</td>
      <td>1.050780</td>
      <td>-0.134170</td>
      <td>0.854240</td>
      <td>0.908322</td>
      <td>0.180844</td>
      <td>0.642068</td>
      <td>0.627971</td>
      <td>-0.588849</td>
      <td>-0.506355</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.572182</td>
      <td>1.712442</td>
      <td>0.088001</td>
      <td>0.543201</td>
      <td>0.392611</td>
      <td>-0.475032</td>
      <td>-0.423511</td>
      <td>1.071276</td>
      <td>0.158563</td>
      <td>-0.360134</td>
      <td>-0.299660</td>
      <td>-0.106677</td>
      <td>-0.618103</td>
      <td>0.156405</td>
      <td>0.799659</td>
      <td>0.536450</td>
      <td>1.077862</td>
      <td>0.690790</td>
      <td>-0.728084</td>
      <td>-0.648406</td>
      <td>-0.862954</td>
      <td>-0.306343</td>
      <td>0.948735</td>
      <td>0.397144</td>
      <td>-0.211796</td>
      <td>0.747544</td>
      <td>0.557321</td>
      <td>0.428096</td>
      <td>0.728567</td>
      <td>0.648895</td>
      <td>-1.407155</td>
      <td>0.050724</td>
      <td>-0.690169</td>
      <td>-0.669704</td>
      <td>0.371706</td>
      <td>-0.466455</td>
      <td>0.921331</td>
      <td>0.601018</td>
      <td>0.223971</td>
      <td>-0.036050</td>
      <td>...</td>
      <td>-0.448217</td>
      <td>0.621701</td>
      <td>-0.444536</td>
      <td>-0.132549</td>
      <td>-0.568823</td>
      <td>-0.181886</td>
      <td>-0.512021</td>
      <td>-0.555484</td>
      <td>0.195901</td>
      <td>-0.410882</td>
      <td>0.033697</td>
      <td>-0.795975</td>
      <td>0.212263</td>
      <td>-0.188958</td>
      <td>0.615066</td>
      <td>0.750000</td>
      <td>-0.496229</td>
      <td>0.848325</td>
      <td>0.273202</td>
      <td>0.377136</td>
      <td>1.137296</td>
      <td>0.462596</td>
      <td>-0.343938</td>
      <td>-0.453316</td>
      <td>-0.930139</td>
      <td>-0.728819</td>
      <td>0.848060</td>
      <td>-0.409336</td>
      <td>0.785800</td>
      <td>-0.436285</td>
      <td>-0.677823</td>
      <td>-0.497261</td>
      <td>0.777024</td>
      <td>-0.071642</td>
      <td>0.233863</td>
      <td>0.301358</td>
      <td>-0.514479</td>
      <td>1.376647</td>
      <td>1.474124</td>
      <td>1.220655</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.819663</td>
      <td>0.183428</td>
      <td>0.476246</td>
      <td>0.109035</td>
      <td>0.684801</td>
      <td>-0.274339</td>
      <td>0.417638</td>
      <td>-0.109585</td>
      <td>-0.247337</td>
      <td>-0.942795</td>
      <td>-0.231044</td>
      <td>-0.008778</td>
      <td>0.565876</td>
      <td>1.103801</td>
      <td>0.437695</td>
      <td>0.056255</td>
      <td>0.200308</td>
      <td>0.091737</td>
      <td>0.062087</td>
      <td>1.781816</td>
      <td>0.336491</td>
      <td>-1.139850</td>
      <td>0.504487</td>
      <td>0.043212</td>
      <td>0.068855</td>
      <td>0.793878</td>
      <td>1.312651</td>
      <td>-0.107292</td>
      <td>-0.563204</td>
      <td>-0.168175</td>
      <td>-0.319756</td>
      <td>0.203136</td>
      <td>-0.169953</td>
      <td>0.912277</td>
      <td>-0.382394</td>
      <td>0.016477</td>
      <td>0.849453</td>
      <td>0.294959</td>
      <td>0.109199</td>
      <td>-0.155057</td>
      <td>...</td>
      <td>0.351343</td>
      <td>0.039286</td>
      <td>-0.049227</td>
      <td>0.056825</td>
      <td>-0.392727</td>
      <td>-0.013377</td>
      <td>1.042891</td>
      <td>1.096955</td>
      <td>1.098951</td>
      <td>0.495112</td>
      <td>0.976290</td>
      <td>-0.529147</td>
      <td>0.574365</td>
      <td>-0.138995</td>
      <td>0.084418</td>
      <td>0.825164</td>
      <td>-0.354714</td>
      <td>0.006003</td>
      <td>0.115798</td>
      <td>1.896786</td>
      <td>1.940180</td>
      <td>-0.271597</td>
      <td>-0.662047</td>
      <td>0.021992</td>
      <td>-0.109902</td>
      <td>-0.232628</td>
      <td>-0.456862</td>
      <td>-0.740675</td>
      <td>-0.045973</td>
      <td>-0.307026</td>
      <td>0.503707</td>
      <td>0.499137</td>
      <td>-0.266945</td>
      <td>0.109879</td>
      <td>-0.122938</td>
      <td>0.469839</td>
      <td>-0.570039</td>
      <td>-0.107505</td>
      <td>0.141691</td>
      <td>0.630328</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.222102</td>
      <td>-0.140771</td>
      <td>0.569597</td>
      <td>-0.301710</td>
      <td>-1.368326</td>
      <td>-0.026104</td>
      <td>-0.898106</td>
      <td>-0.153095</td>
      <td>-0.499129</td>
      <td>0.329394</td>
      <td>1.134295</td>
      <td>0.404843</td>
      <td>0.394838</td>
      <td>0.234243</td>
      <td>-0.672361</td>
      <td>-0.395718</td>
      <td>0.755617</td>
      <td>0.024919</td>
      <td>-0.747775</td>
      <td>0.296122</td>
      <td>0.042091</td>
      <td>0.961313</td>
      <td>1.521335</td>
      <td>0.440150</td>
      <td>-0.585094</td>
      <td>-0.610825</td>
      <td>0.116387</td>
      <td>0.826270</td>
      <td>-0.512362</td>
      <td>-1.170893</td>
      <td>-0.782481</td>
      <td>-0.242444</td>
      <td>-0.456693</td>
      <td>-0.346805</td>
      <td>-1.209555</td>
      <td>-0.402651</td>
      <td>0.376908</td>
      <td>-0.718436</td>
      <td>-0.928871</td>
      <td>-0.035463</td>
      <td>...</td>
      <td>-0.642032</td>
      <td>-0.546032</td>
      <td>-0.377700</td>
      <td>-0.291985</td>
      <td>0.141144</td>
      <td>0.415730</td>
      <td>0.258028</td>
      <td>1.476262</td>
      <td>0.833285</td>
      <td>-0.078741</td>
      <td>-0.324102</td>
      <td>-0.677836</td>
      <td>-0.241962</td>
      <td>-0.210020</td>
      <td>0.398274</td>
      <td>0.456300</td>
      <td>-0.199569</td>
      <td>0.401320</td>
      <td>0.518621</td>
      <td>1.396595</td>
      <td>1.405836</td>
      <td>0.227715</td>
      <td>0.153382</td>
      <td>0.048989</td>
      <td>-0.218895</td>
      <td>-0.036603</td>
      <td>-0.119738</td>
      <td>-0.104471</td>
      <td>-1.384126</td>
      <td>-0.850208</td>
      <td>-0.691270</td>
      <td>-0.172339</td>
      <td>0.058380</td>
      <td>-0.788538</td>
      <td>0.473582</td>
      <td>1.184039</td>
      <td>1.019558</td>
      <td>-0.032152</td>
      <td>-0.644289</td>
      <td>-0.424888</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-0.719473</td>
      <td>0.572706</td>
      <td>0.541084</td>
      <td>-1.027607</td>
      <td>0.130248</td>
      <td>-0.917102</td>
      <td>0.811789</td>
      <td>0.648124</td>
      <td>1.126572</td>
      <td>0.482404</td>
      <td>0.338241</td>
      <td>-0.254158</td>
      <td>-0.558083</td>
      <td>-0.200847</td>
      <td>0.329408</td>
      <td>0.443622</td>
      <td>1.228813</td>
      <td>0.670103</td>
      <td>-0.073965</td>
      <td>-0.217824</td>
      <td>-0.566088</td>
      <td>0.295364</td>
      <td>0.617786</td>
      <td>0.351728</td>
      <td>-0.320599</td>
      <td>0.525320</td>
      <td>0.677845</td>
      <td>0.090227</td>
      <td>-1.189520</td>
      <td>0.051342</td>
      <td>0.392478</td>
      <td>-0.011480</td>
      <td>-0.217856</td>
      <td>0.273002</td>
      <td>-0.582736</td>
      <td>-1.204897</td>
      <td>0.234713</td>
      <td>-0.288243</td>
      <td>0.490160</td>
      <td>0.347446</td>
      <td>...</td>
      <td>0.246612</td>
      <td>0.592207</td>
      <td>-0.652771</td>
      <td>-0.706793</td>
      <td>-0.709312</td>
      <td>0.577032</td>
      <td>0.081034</td>
      <td>-0.076968</td>
      <td>0.594709</td>
      <td>0.145262</td>
      <td>-0.200493</td>
      <td>-0.538520</td>
      <td>0.425009</td>
      <td>0.376408</td>
      <td>0.964481</td>
      <td>0.258388</td>
      <td>-0.609797</td>
      <td>-0.262325</td>
      <td>-0.067349</td>
      <td>0.794015</td>
      <td>-0.084702</td>
      <td>-1.065191</td>
      <td>0.178679</td>
      <td>-0.084804</td>
      <td>0.402723</td>
      <td>-1.206472</td>
      <td>-0.204507</td>
      <td>0.384847</td>
      <td>-0.695241</td>
      <td>0.011110</td>
      <td>-0.025647</td>
      <td>0.553419</td>
      <td>0.544032</td>
      <td>0.341044</td>
      <td>-0.182743</td>
      <td>0.829591</td>
      <td>0.747890</td>
      <td>-2.225389</td>
      <td>-1.574064</td>
      <td>-0.597041</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-0.786294</td>
      <td>0.795029</td>
      <td>0.320274</td>
      <td>0.040394</td>
      <td>0.770298</td>
      <td>0.025928</td>
      <td>1.605483</td>
      <td>0.104328</td>
      <td>0.040913</td>
      <td>-0.794467</td>
      <td>-0.157884</td>
      <td>1.031899</td>
      <td>0.675804</td>
      <td>1.805819</td>
      <td>0.538418</td>
      <td>-0.532273</td>
      <td>-0.616885</td>
      <td>1.032074</td>
      <td>-0.427498</td>
      <td>-0.256953</td>
      <td>-0.734792</td>
      <td>-0.187362</td>
      <td>0.642053</td>
      <td>0.663061</td>
      <td>0.049848</td>
      <td>-0.205827</td>
      <td>-0.603937</td>
      <td>-0.322799</td>
      <td>0.290079</td>
      <td>-0.969204</td>
      <td>-0.688534</td>
      <td>0.184414</td>
      <td>-0.859820</td>
      <td>0.327749</td>
      <td>-0.451173</td>
      <td>-0.098369</td>
      <td>0.358318</td>
      <td>0.311503</td>
      <td>-0.101550</td>
      <td>0.586457</td>
      <td>...</td>
      <td>0.364969</td>
      <td>0.491806</td>
      <td>0.024389</td>
      <td>-0.119787</td>
      <td>0.148126</td>
      <td>-0.011407</td>
      <td>-0.492009</td>
      <td>-0.067979</td>
      <td>0.425517</td>
      <td>-0.842427</td>
      <td>0.826543</td>
      <td>-0.663547</td>
      <td>-0.085210</td>
      <td>0.924513</td>
      <td>0.623224</td>
      <td>-0.303584</td>
      <td>-0.111066</td>
      <td>0.382052</td>
      <td>-0.411480</td>
      <td>0.070313</td>
      <td>0.364240</td>
      <td>0.817038</td>
      <td>-0.213440</td>
      <td>1.147510</td>
      <td>0.201807</td>
      <td>0.193033</td>
      <td>-0.123304</td>
      <td>0.038488</td>
      <td>-0.136474</td>
      <td>-0.277057</td>
      <td>0.171403</td>
      <td>-0.550687</td>
      <td>0.506429</td>
      <td>0.446405</td>
      <td>1.483224</td>
      <td>0.814066</td>
      <td>-0.197479</td>
      <td>-1.013792</td>
      <td>0.155407</td>
      <td>0.410811</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.263723</td>
      <td>0.639241</td>
      <td>0.696408</td>
      <td>-0.195658</td>
      <td>0.885325</td>
      <td>-0.175076</td>
      <td>0.201589</td>
      <td>-0.276603</td>
      <td>-0.940648</td>
      <td>-1.291034</td>
      <td>-0.912823</td>
      <td>-0.121792</td>
      <td>-0.704842</td>
      <td>-0.072159</td>
      <td>0.671856</td>
      <td>0.424705</td>
      <td>-0.873646</td>
      <td>-0.130826</td>
      <td>0.444355</td>
      <td>-0.124804</td>
      <td>-0.198125</td>
      <td>0.530644</td>
      <td>-0.455665</td>
      <td>-0.390351</td>
      <td>-0.379833</td>
      <td>0.119227</td>
      <td>-1.422077</td>
      <td>0.226257</td>
      <td>-0.139445</td>
      <td>-0.279797</td>
      <td>-0.358989</td>
      <td>-0.425117</td>
      <td>-0.750960</td>
      <td>-0.419559</td>
      <td>-0.047971</td>
      <td>0.505561</td>
      <td>-0.249263</td>
      <td>-0.401349</td>
      <td>-0.667905</td>
      <td>-0.139337</td>
      <td>...</td>
      <td>0.266742</td>
      <td>0.091445</td>
      <td>-0.287691</td>
      <td>0.600352</td>
      <td>0.003599</td>
      <td>0.333377</td>
      <td>0.232928</td>
      <td>-0.656768</td>
      <td>0.806866</td>
      <td>0.748539</td>
      <td>1.016829</td>
      <td>-0.089718</td>
      <td>0.567169</td>
      <td>0.263490</td>
      <td>0.331147</td>
      <td>-0.139041</td>
      <td>-0.740095</td>
      <td>-0.557595</td>
      <td>-0.106500</td>
      <td>0.500512</td>
      <td>1.180071</td>
      <td>0.442494</td>
      <td>1.071790</td>
      <td>0.453228</td>
      <td>-0.610352</td>
      <td>-0.386380</td>
      <td>0.726684</td>
      <td>-0.756717</td>
      <td>0.147874</td>
      <td>-0.428503</td>
      <td>-0.266804</td>
      <td>1.026332</td>
      <td>0.567557</td>
      <td>0.241765</td>
      <td>0.848988</td>
      <td>0.581690</td>
      <td>-0.045669</td>
      <td>0.936609</td>
      <td>0.427863</td>
      <td>0.686493</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-0.089988</td>
      <td>0.728636</td>
      <td>-0.496150</td>
      <td>0.807151</td>
      <td>0.247721</td>
      <td>-0.877592</td>
      <td>-0.943158</td>
      <td>-0.048731</td>
      <td>0.555898</td>
      <td>0.632816</td>
      <td>0.593044</td>
      <td>1.704208</td>
      <td>-0.157364</td>
      <td>0.381194</td>
      <td>-0.689248</td>
      <td>-0.072143</td>
      <td>-0.470049</td>
      <td>-0.182248</td>
      <td>0.089182</td>
      <td>0.122363</td>
      <td>-0.089966</td>
      <td>-0.582141</td>
      <td>-0.066143</td>
      <td>0.812085</td>
      <td>0.500670</td>
      <td>0.597217</td>
      <td>-0.188714</td>
      <td>-0.919916</td>
      <td>-0.372726</td>
      <td>-0.647386</td>
      <td>-0.938836</td>
      <td>-0.067596</td>
      <td>-0.003907</td>
      <td>0.738435</td>
      <td>0.334559</td>
      <td>-0.398646</td>
      <td>-0.145265</td>
      <td>-0.579275</td>
      <td>-0.459494</td>
      <td>0.585912</td>
      <td>...</td>
      <td>0.436061</td>
      <td>0.416980</td>
      <td>-0.438161</td>
      <td>-0.924801</td>
      <td>-0.560203</td>
      <td>-0.078542</td>
      <td>-0.313879</td>
      <td>0.084026</td>
      <td>0.355020</td>
      <td>-0.347786</td>
      <td>0.141797</td>
      <td>-1.783937</td>
      <td>0.435669</td>
      <td>0.157752</td>
      <td>-0.588222</td>
      <td>-0.139755</td>
      <td>-0.011641</td>
      <td>-0.774391</td>
      <td>-0.545033</td>
      <td>0.133848</td>
      <td>0.275283</td>
      <td>0.324494</td>
      <td>0.347082</td>
      <td>0.200498</td>
      <td>-0.043373</td>
      <td>0.170928</td>
      <td>0.062085</td>
      <td>-1.179134</td>
      <td>-0.386660</td>
      <td>-0.418521</td>
      <td>1.640138</td>
      <td>-0.756120</td>
      <td>-1.046599</td>
      <td>0.509612</td>
      <td>0.343876</td>
      <td>-0.030569</td>
      <td>0.132233</td>
      <td>0.438124</td>
      <td>0.275400</td>
      <td>0.795607</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.447655</td>
      <td>0.869525</td>
      <td>0.927331</td>
      <td>-0.118614</td>
      <td>0.081943</td>
      <td>-0.623008</td>
      <td>-0.025122</td>
      <td>-0.243618</td>
      <td>-0.812938</td>
      <td>-0.147964</td>
      <td>-0.714146</td>
      <td>-0.044793</td>
      <td>0.440085</td>
      <td>0.031494</td>
      <td>-0.953135</td>
      <td>0.080047</td>
      <td>0.220488</td>
      <td>-0.054204</td>
      <td>-0.103554</td>
      <td>0.073472</td>
      <td>-0.035836</td>
      <td>-0.115393</td>
      <td>-0.384123</td>
      <td>0.438858</td>
      <td>-0.114228</td>
      <td>0.319703</td>
      <td>0.636527</td>
      <td>0.221791</td>
      <td>0.219223</td>
      <td>-0.259583</td>
      <td>-0.318376</td>
      <td>-0.689048</td>
      <td>-1.730982</td>
      <td>-0.380336</td>
      <td>-0.071928</td>
      <td>-0.399164</td>
      <td>0.316140</td>
      <td>0.647747</td>
      <td>0.919125</td>
      <td>0.507478</td>
      <td>...</td>
      <td>0.581311</td>
      <td>-0.073741</td>
      <td>-1.062095</td>
      <td>-1.395221</td>
      <td>0.000820</td>
      <td>-0.236638</td>
      <td>1.033103</td>
      <td>0.244988</td>
      <td>0.047991</td>
      <td>-0.232217</td>
      <td>1.388028</td>
      <td>-1.220841</td>
      <td>-0.145107</td>
      <td>-0.741384</td>
      <td>-0.183588</td>
      <td>0.193444</td>
      <td>0.060751</td>
      <td>-0.066232</td>
      <td>-0.149837</td>
      <td>0.798893</td>
      <td>0.261081</td>
      <td>-0.566702</td>
      <td>-0.596783</td>
      <td>-0.498115</td>
      <td>-0.214373</td>
      <td>-0.556967</td>
      <td>0.768365</td>
      <td>-0.606923</td>
      <td>-0.867953</td>
      <td>-0.861180</td>
      <td>1.049342</td>
      <td>0.756912</td>
      <td>0.550197</td>
      <td>-0.443572</td>
      <td>0.373845</td>
      <td>0.115310</td>
      <td>0.602424</td>
      <td>-0.838608</td>
      <td>-0.815992</td>
      <td>-0.556879</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.076512</td>
      <td>0.557692</td>
      <td>1.086199</td>
      <td>0.749096</td>
      <td>0.134172</td>
      <td>-0.487208</td>
      <td>0.338224</td>
      <td>-0.211522</td>
      <td>0.580665</td>
      <td>1.040788</td>
      <td>0.186538</td>
      <td>0.446968</td>
      <td>-0.298095</td>
      <td>0.390912</td>
      <td>-0.470242</td>
      <td>0.205710</td>
      <td>0.296654</td>
      <td>0.034345</td>
      <td>-0.295942</td>
      <td>0.846506</td>
      <td>-0.641787</td>
      <td>-0.196441</td>
      <td>1.010354</td>
      <td>0.790865</td>
      <td>-1.031260</td>
      <td>0.588632</td>
      <td>0.663223</td>
      <td>0.523672</td>
      <td>-0.105666</td>
      <td>0.043658</td>
      <td>0.733272</td>
      <td>-0.248415</td>
      <td>0.054431</td>
      <td>-0.494837</td>
      <td>-0.181841</td>
      <td>-0.977918</td>
      <td>-0.951502</td>
      <td>1.004410</td>
      <td>-0.126512</td>
      <td>0.977825</td>
      <td>...</td>
      <td>-0.133895</td>
      <td>0.476507</td>
      <td>-0.000649</td>
      <td>0.356266</td>
      <td>-0.085409</td>
      <td>0.756174</td>
      <td>0.875891</td>
      <td>-0.098652</td>
      <td>-0.440631</td>
      <td>-0.412053</td>
      <td>0.514911</td>
      <td>-0.646419</td>
      <td>-0.516261</td>
      <td>-0.315857</td>
      <td>0.405055</td>
      <td>-0.156503</td>
      <td>-0.365698</td>
      <td>0.228243</td>
      <td>-0.478645</td>
      <td>-0.431537</td>
      <td>0.592917</td>
      <td>0.761495</td>
      <td>0.919894</td>
      <td>0.350718</td>
      <td>-1.445373</td>
      <td>-0.097128</td>
      <td>0.297684</td>
      <td>-0.764711</td>
      <td>0.107454</td>
      <td>0.613118</td>
      <td>0.177011</td>
      <td>-0.022483</td>
      <td>-0.122011</td>
      <td>0.452524</td>
      <td>-0.037583</td>
      <td>0.698177</td>
      <td>0.345734</td>
      <td>1.322710</td>
      <td>0.133579</td>
      <td>0.192742</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-0.060764</td>
      <td>1.466732</td>
      <td>-0.347212</td>
      <td>-1.062321</td>
      <td>-0.136682</td>
      <td>-0.258078</td>
      <td>-0.182956</td>
      <td>-0.013118</td>
      <td>0.777884</td>
      <td>-0.128961</td>
      <td>-0.222578</td>
      <td>-0.032473</td>
      <td>0.915981</td>
      <td>0.057060</td>
      <td>0.006621</td>
      <td>-0.284913</td>
      <td>-0.130315</td>
      <td>0.424074</td>
      <td>-0.429766</td>
      <td>-0.160636</td>
      <td>0.406616</td>
      <td>-0.332333</td>
      <td>0.990330</td>
      <td>1.058192</td>
      <td>0.728196</td>
      <td>0.675766</td>
      <td>1.027722</td>
      <td>0.079545</td>
      <td>-0.135558</td>
      <td>0.574886</td>
      <td>-0.175554</td>
      <td>-0.671481</td>
      <td>-0.377158</td>
      <td>-0.270844</td>
      <td>0.570208</td>
      <td>-0.019686</td>
      <td>-0.383635</td>
      <td>-0.205998</td>
      <td>-0.349659</td>
      <td>-1.542228</td>
      <td>...</td>
      <td>-0.221109</td>
      <td>0.065533</td>
      <td>-0.228868</td>
      <td>0.454109</td>
      <td>-0.171159</td>
      <td>0.006662</td>
      <td>-0.248828</td>
      <td>-0.170899</td>
      <td>0.468834</td>
      <td>-0.191313</td>
      <td>-0.452777</td>
      <td>-0.257239</td>
      <td>0.915751</td>
      <td>1.383563</td>
      <td>0.296061</td>
      <td>0.613745</td>
      <td>0.116609</td>
      <td>-0.603668</td>
      <td>-0.082235</td>
      <td>0.545275</td>
      <td>0.242125</td>
      <td>-0.369498</td>
      <td>-0.525439</td>
      <td>0.462547</td>
      <td>-0.498182</td>
      <td>-0.363052</td>
      <td>0.364832</td>
      <td>-0.498394</td>
      <td>-0.059297</td>
      <td>-0.011280</td>
      <td>-0.182098</td>
      <td>0.049790</td>
      <td>-0.929401</td>
      <td>-1.272415</td>
      <td>1.036517</td>
      <td>0.721172</td>
      <td>0.519981</td>
      <td>-2.179083</td>
      <td>-1.590006</td>
      <td>-0.300290</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.034888</td>
      <td>0.257253</td>
      <td>-0.497996</td>
      <td>0.841427</td>
      <td>-0.391738</td>
      <td>-1.459720</td>
      <td>-0.236114</td>
      <td>1.235964</td>
      <td>0.198781</td>
      <td>-0.686902</td>
      <td>0.222814</td>
      <td>-0.386594</td>
      <td>-1.484897</td>
      <td>0.757084</td>
      <td>0.029356</td>
      <td>-0.287299</td>
      <td>-0.185800</td>
      <td>0.714401</td>
      <td>0.419948</td>
      <td>0.624703</td>
      <td>0.061892</td>
      <td>-1.071267</td>
      <td>-0.451683</td>
      <td>-0.545312</td>
      <td>-0.454517</td>
      <td>0.185833</td>
      <td>0.122841</td>
      <td>0.820358</td>
      <td>-0.381730</td>
      <td>0.081518</td>
      <td>-0.553241</td>
      <td>-0.195273</td>
      <td>0.768502</td>
      <td>0.772474</td>
      <td>0.350857</td>
      <td>-0.534004</td>
      <td>-0.640472</td>
      <td>0.245288</td>
      <td>0.892628</td>
      <td>0.095831</td>
      <td>...</td>
      <td>0.613301</td>
      <td>-0.480447</td>
      <td>-1.400862</td>
      <td>-0.123236</td>
      <td>-0.757185</td>
      <td>-0.717753</td>
      <td>0.610905</td>
      <td>1.214448</td>
      <td>0.057948</td>
      <td>-0.608342</td>
      <td>-0.578641</td>
      <td>-1.048698</td>
      <td>0.105506</td>
      <td>-0.534159</td>
      <td>-0.412354</td>
      <td>-0.267762</td>
      <td>-0.988001</td>
      <td>-0.358149</td>
      <td>-0.757773</td>
      <td>1.177505</td>
      <td>-0.098770</td>
      <td>-0.477789</td>
      <td>0.335300</td>
      <td>0.117861</td>
      <td>-0.273126</td>
      <td>-0.374752</td>
      <td>-0.891217</td>
      <td>-0.431559</td>
      <td>-0.524827</td>
      <td>-1.327055</td>
      <td>0.300990</td>
      <td>0.751455</td>
      <td>-0.111396</td>
      <td>-0.193264</td>
      <td>-0.555250</td>
      <td>1.337580</td>
      <td>0.753006</td>
      <td>0.248586</td>
      <td>0.261405</td>
      <td>0.589726</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.521472</td>
      <td>0.476142</td>
      <td>0.076275</td>
      <td>0.193875</td>
      <td>-0.124096</td>
      <td>-0.437755</td>
      <td>-0.202974</td>
      <td>0.436377</td>
      <td>-0.189172</td>
      <td>0.429971</td>
      <td>-0.104625</td>
      <td>-0.422345</td>
      <td>-0.006952</td>
      <td>1.142077</td>
      <td>0.567776</td>
      <td>0.143029</td>
      <td>-0.442891</td>
      <td>-0.818953</td>
      <td>0.453238</td>
      <td>0.473670</td>
      <td>-0.387000</td>
      <td>0.303183</td>
      <td>0.527831</td>
      <td>0.757922</td>
      <td>-0.238185</td>
      <td>0.915107</td>
      <td>0.500713</td>
      <td>0.243452</td>
      <td>-1.250084</td>
      <td>1.180834</td>
      <td>-0.932548</td>
      <td>-0.065018</td>
      <td>0.001320</td>
      <td>0.727792</td>
      <td>-0.118441</td>
      <td>-0.646510</td>
      <td>-0.128412</td>
      <td>-0.243835</td>
      <td>0.003422</td>
      <td>-0.483598</td>
      <td>...</td>
      <td>0.179203</td>
      <td>-0.044345</td>
      <td>-0.456766</td>
      <td>-0.180482</td>
      <td>0.582934</td>
      <td>0.850656</td>
      <td>-0.006557</td>
      <td>-0.125279</td>
      <td>0.203687</td>
      <td>-0.675078</td>
      <td>-0.130867</td>
      <td>-0.305992</td>
      <td>0.291709</td>
      <td>-0.139079</td>
      <td>-0.535515</td>
      <td>0.425594</td>
      <td>-0.319250</td>
      <td>-0.025444</td>
      <td>-0.850420</td>
      <td>0.206105</td>
      <td>-0.215229</td>
      <td>-0.418145</td>
      <td>-0.280538</td>
      <td>0.622992</td>
      <td>-0.215822</td>
      <td>-0.512420</td>
      <td>-1.047800</td>
      <td>-0.121338</td>
      <td>0.115307</td>
      <td>-0.059616</td>
      <td>-0.440252</td>
      <td>0.150742</td>
      <td>-0.167052</td>
      <td>0.321010</td>
      <td>0.787283</td>
      <td>0.818243</td>
      <td>0.119627</td>
      <td>0.474826</td>
      <td>0.539059</td>
      <td>0.066424</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.269721</td>
      <td>0.533419</td>
      <td>0.227581</td>
      <td>0.929447</td>
      <td>0.903510</td>
      <td>0.341844</td>
      <td>-0.309551</td>
      <td>0.266996</td>
      <td>0.480735</td>
      <td>0.126184</td>
      <td>-0.385953</td>
      <td>-0.348993</td>
      <td>-0.421267</td>
      <td>0.676936</td>
      <td>-0.218587</td>
      <td>0.508411</td>
      <td>0.200855</td>
      <td>-0.305882</td>
      <td>0.214937</td>
      <td>-0.517610</td>
      <td>-0.019914</td>
      <td>0.141689</td>
      <td>0.500427</td>
      <td>0.509025</td>
      <td>0.778076</td>
      <td>-0.462739</td>
      <td>-0.168226</td>
      <td>0.138035</td>
      <td>0.740905</td>
      <td>0.040787</td>
      <td>-0.546784</td>
      <td>0.429702</td>
      <td>-0.485954</td>
      <td>-0.542578</td>
      <td>-0.231477</td>
      <td>-0.064729</td>
      <td>0.079163</td>
      <td>0.116764</td>
      <td>-0.061101</td>
      <td>0.772153</td>
      <td>...</td>
      <td>-0.177194</td>
      <td>0.498280</td>
      <td>0.363052</td>
      <td>0.190934</td>
      <td>0.081073</td>
      <td>0.505489</td>
      <td>0.909325</td>
      <td>-0.356083</td>
      <td>-0.121264</td>
      <td>0.281814</td>
      <td>0.992662</td>
      <td>0.348593</td>
      <td>0.542015</td>
      <td>0.267203</td>
      <td>-0.258314</td>
      <td>-0.440080</td>
      <td>-0.013499</td>
      <td>1.142833</td>
      <td>0.351729</td>
      <td>0.319867</td>
      <td>-0.129085</td>
      <td>-0.256446</td>
      <td>0.039917</td>
      <td>0.261926</td>
      <td>-0.228733</td>
      <td>0.100933</td>
      <td>0.414489</td>
      <td>-1.009695</td>
      <td>-1.359847</td>
      <td>-0.662219</td>
      <td>1.256299</td>
      <td>1.255195</td>
      <td>-0.084277</td>
      <td>0.402009</td>
      <td>0.579275</td>
      <td>0.439996</td>
      <td>0.498841</td>
      <td>0.132696</td>
      <td>-0.542631</td>
      <td>-0.369413</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.053302</td>
      <td>1.335787</td>
      <td>0.411879</td>
      <td>-0.125677</td>
      <td>0.333613</td>
      <td>-0.022608</td>
      <td>0.209961</td>
      <td>0.126534</td>
      <td>-0.147682</td>
      <td>0.100122</td>
      <td>0.962423</td>
      <td>0.427871</td>
      <td>-0.255600</td>
      <td>-0.309703</td>
      <td>-0.906081</td>
      <td>0.317143</td>
      <td>0.702734</td>
      <td>-0.537295</td>
      <td>-0.072161</td>
      <td>1.030013</td>
      <td>-0.400962</td>
      <td>0.196994</td>
      <td>-0.401810</td>
      <td>0.018485</td>
      <td>0.233753</td>
      <td>-0.017076</td>
      <td>-0.200583</td>
      <td>0.142973</td>
      <td>-0.374880</td>
      <td>-0.213623</td>
      <td>-0.116407</td>
      <td>0.721540</td>
      <td>-0.997015</td>
      <td>-0.638152</td>
      <td>-1.313133</td>
      <td>-1.567727</td>
      <td>0.170069</td>
      <td>0.447750</td>
      <td>0.381310</td>
      <td>1.042429</td>
      <td>...</td>
      <td>0.249267</td>
      <td>0.747533</td>
      <td>0.193102</td>
      <td>-0.406109</td>
      <td>0.933233</td>
      <td>-0.131798</td>
      <td>-0.177271</td>
      <td>-0.257838</td>
      <td>1.084555</td>
      <td>-0.122420</td>
      <td>0.730505</td>
      <td>-0.480873</td>
      <td>0.173258</td>
      <td>-0.004842</td>
      <td>-0.107789</td>
      <td>0.581738</td>
      <td>0.501474</td>
      <td>-0.409463</td>
      <td>-0.348432</td>
      <td>1.484091</td>
      <td>1.686302</td>
      <td>0.068454</td>
      <td>0.277516</td>
      <td>0.644448</td>
      <td>0.413606</td>
      <td>0.024027</td>
      <td>0.738153</td>
      <td>-0.535493</td>
      <td>0.148664</td>
      <td>-0.374229</td>
      <td>1.507050</td>
      <td>0.600087</td>
      <td>-0.489725</td>
      <td>-1.106933</td>
      <td>-0.325101</td>
      <td>0.317647</td>
      <td>0.402715</td>
      <td>-0.194066</td>
      <td>-0.343744</td>
      <td>-0.221942</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.036319</td>
      <td>0.124414</td>
      <td>0.272258</td>
      <td>0.542764</td>
      <td>-0.547943</td>
      <td>0.188887</td>
      <td>-0.944701</td>
      <td>-0.261057</td>
      <td>0.084957</td>
      <td>0.312655</td>
      <td>-0.204779</td>
      <td>-0.473642</td>
      <td>0.049763</td>
      <td>-0.709738</td>
      <td>-0.046435</td>
      <td>-0.064744</td>
      <td>0.002201</td>
      <td>-1.354623</td>
      <td>0.227261</td>
      <td>0.179245</td>
      <td>0.220745</td>
      <td>-0.530949</td>
      <td>-0.095586</td>
      <td>-0.015836</td>
      <td>-0.494214</td>
      <td>-0.619899</td>
      <td>-0.807040</td>
      <td>-0.311573</td>
      <td>-0.518897</td>
      <td>-0.210192</td>
      <td>-0.165038</td>
      <td>0.006642</td>
      <td>-0.037396</td>
      <td>0.647240</td>
      <td>0.067356</td>
      <td>-0.570711</td>
      <td>-0.431949</td>
      <td>-0.523245</td>
      <td>0.141615</td>
      <td>0.410719</td>
      <td>...</td>
      <td>0.044212</td>
      <td>-0.380106</td>
      <td>-0.851241</td>
      <td>0.502304</td>
      <td>0.274819</td>
      <td>0.193981</td>
      <td>0.194661</td>
      <td>0.307819</td>
      <td>0.818366</td>
      <td>0.162378</td>
      <td>0.608724</td>
      <td>-1.194628</td>
      <td>0.193631</td>
      <td>-0.176673</td>
      <td>1.424263</td>
      <td>1.230402</td>
      <td>-0.261709</td>
      <td>1.281797</td>
      <td>0.159797</td>
      <td>0.424039</td>
      <td>0.867716</td>
      <td>0.319032</td>
      <td>-0.802524</td>
      <td>-0.420355</td>
      <td>-0.496847</td>
      <td>-0.104864</td>
      <td>0.277799</td>
      <td>-0.758707</td>
      <td>-0.762872</td>
      <td>-0.798893</td>
      <td>-0.100810</td>
      <td>0.787697</td>
      <td>-0.509656</td>
      <td>0.429933</td>
      <td>0.636420</td>
      <td>1.388946</td>
      <td>0.283588</td>
      <td>-0.483495</td>
      <td>-0.307654</td>
      <td>0.381918</td>
    </tr>
    <tr>
      <th>21</th>
      <td>1.093230</td>
      <td>0.627583</td>
      <td>0.670844</td>
      <td>-0.944250</td>
      <td>0.006504</td>
      <td>-1.601214</td>
      <td>0.491317</td>
      <td>-0.402503</td>
      <td>0.212534</td>
      <td>-0.708152</td>
      <td>-1.384295</td>
      <td>-0.317728</td>
      <td>0.218408</td>
      <td>0.154010</td>
      <td>-0.126369</td>
      <td>-0.156303</td>
      <td>-1.045648</td>
      <td>-0.389961</td>
      <td>1.141434</td>
      <td>0.893531</td>
      <td>0.870004</td>
      <td>-0.819500</td>
      <td>-0.342380</td>
      <td>-0.498574</td>
      <td>-0.214458</td>
      <td>-0.670784</td>
      <td>0.730452</td>
      <td>-0.189897</td>
      <td>0.433122</td>
      <td>0.236013</td>
      <td>-0.217405</td>
      <td>-0.648349</td>
      <td>-1.123483</td>
      <td>-0.845379</td>
      <td>-0.847756</td>
      <td>0.380298</td>
      <td>-0.861411</td>
      <td>-0.227268</td>
      <td>-0.599275</td>
      <td>0.374229</td>
      <td>...</td>
      <td>0.142080</td>
      <td>-0.072459</td>
      <td>-0.181165</td>
      <td>0.404786</td>
      <td>-0.429173</td>
      <td>0.281869</td>
      <td>0.033059</td>
      <td>-0.224959</td>
      <td>-0.003930</td>
      <td>-0.546270</td>
      <td>0.727706</td>
      <td>-0.124577</td>
      <td>0.825740</td>
      <td>0.316639</td>
      <td>0.503475</td>
      <td>0.752620</td>
      <td>0.077130</td>
      <td>0.583005</td>
      <td>-0.635429</td>
      <td>1.028686</td>
      <td>0.213948</td>
      <td>-0.200557</td>
      <td>0.261296</td>
      <td>0.542525</td>
      <td>0.526474</td>
      <td>-0.181195</td>
      <td>-1.367587</td>
      <td>-0.824928</td>
      <td>-0.429024</td>
      <td>-0.507457</td>
      <td>-0.328002</td>
      <td>-0.246584</td>
      <td>0.259657</td>
      <td>-0.945053</td>
      <td>-0.628299</td>
      <td>0.229574</td>
      <td>0.645026</td>
      <td>2.872658</td>
      <td>1.232759</td>
      <td>0.734046</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.856808</td>
      <td>0.964812</td>
      <td>0.223384</td>
      <td>0.750044</td>
      <td>0.544751</td>
      <td>0.486739</td>
      <td>0.026416</td>
      <td>0.314565</td>
      <td>-0.232708</td>
      <td>-0.026817</td>
      <td>0.040081</td>
      <td>-0.362008</td>
      <td>-1.606715</td>
      <td>0.247526</td>
      <td>-0.546696</td>
      <td>-0.295730</td>
      <td>-1.045305</td>
      <td>-0.195321</td>
      <td>0.068414</td>
      <td>-0.119087</td>
      <td>0.139039</td>
      <td>0.499315</td>
      <td>0.583657</td>
      <td>-0.435553</td>
      <td>-0.858288</td>
      <td>0.720330</td>
      <td>0.896609</td>
      <td>0.042184</td>
      <td>-0.978384</td>
      <td>-0.544533</td>
      <td>0.178684</td>
      <td>-1.178197</td>
      <td>-0.673313</td>
      <td>-0.711224</td>
      <td>0.520581</td>
      <td>-0.013849</td>
      <td>-0.451817</td>
      <td>-1.089412</td>
      <td>0.367688</td>
      <td>0.533743</td>
      <td>...</td>
      <td>0.604724</td>
      <td>0.746078</td>
      <td>-0.822319</td>
      <td>-0.365532</td>
      <td>0.518363</td>
      <td>-0.488378</td>
      <td>0.143860</td>
      <td>0.565321</td>
      <td>-0.303407</td>
      <td>0.426627</td>
      <td>1.104173</td>
      <td>0.066487</td>
      <td>-0.269579</td>
      <td>0.733178</td>
      <td>-0.927479</td>
      <td>-0.514935</td>
      <td>0.298306</td>
      <td>0.451696</td>
      <td>-0.790012</td>
      <td>0.609868</td>
      <td>0.380630</td>
      <td>-0.169626</td>
      <td>0.014524</td>
      <td>0.208494</td>
      <td>0.394508</td>
      <td>-0.465840</td>
      <td>0.093368</td>
      <td>-1.127736</td>
      <td>-0.479854</td>
      <td>0.537018</td>
      <td>0.259633</td>
      <td>-0.031887</td>
      <td>0.097996</td>
      <td>0.306089</td>
      <td>0.320803</td>
      <td>-0.692476</td>
      <td>0.241993</td>
      <td>1.176707</td>
      <td>0.649721</td>
      <td>0.526209</td>
    </tr>
    <tr>
      <th>23</th>
      <td>1.486616</td>
      <td>1.177627</td>
      <td>0.077434</td>
      <td>0.179414</td>
      <td>-0.212315</td>
      <td>-0.438294</td>
      <td>0.710123</td>
      <td>0.894700</td>
      <td>0.422120</td>
      <td>0.417562</td>
      <td>-0.623070</td>
      <td>0.402612</td>
      <td>0.477808</td>
      <td>0.004398</td>
      <td>0.453384</td>
      <td>0.560591</td>
      <td>-0.064220</td>
      <td>-0.931504</td>
      <td>-0.930812</td>
      <td>-0.343630</td>
      <td>-0.186859</td>
      <td>0.132831</td>
      <td>0.417305</td>
      <td>0.276633</td>
      <td>0.190337</td>
      <td>-0.093982</td>
      <td>-0.243915</td>
      <td>0.105671</td>
      <td>-0.243345</td>
      <td>0.112749</td>
      <td>-0.229841</td>
      <td>-0.180489</td>
      <td>-0.822171</td>
      <td>0.059614</td>
      <td>-1.051784</td>
      <td>-0.919062</td>
      <td>-0.761972</td>
      <td>0.417535</td>
      <td>0.186390</td>
      <td>0.029080</td>
      <td>...</td>
      <td>0.448801</td>
      <td>0.083922</td>
      <td>-0.859156</td>
      <td>-0.424383</td>
      <td>-0.103733</td>
      <td>0.371980</td>
      <td>0.639669</td>
      <td>-0.279174</td>
      <td>-0.520474</td>
      <td>-0.290688</td>
      <td>0.073613</td>
      <td>-0.654192</td>
      <td>0.586787</td>
      <td>-0.298131</td>
      <td>0.548527</td>
      <td>0.610374</td>
      <td>0.559296</td>
      <td>-0.220111</td>
      <td>-1.162634</td>
      <td>0.903983</td>
      <td>1.420571</td>
      <td>1.533560</td>
      <td>0.985134</td>
      <td>1.263095</td>
      <td>-0.050875</td>
      <td>0.671107</td>
      <td>-0.224259</td>
      <td>0.618611</td>
      <td>-0.705051</td>
      <td>0.303157</td>
      <td>1.045702</td>
      <td>-0.053350</td>
      <td>0.154126</td>
      <td>-1.309809</td>
      <td>0.208682</td>
      <td>0.239206</td>
      <td>0.719359</td>
      <td>4.486134</td>
      <td>3.066864</td>
      <td>1.185667</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-0.018018</td>
      <td>0.090371</td>
      <td>0.227819</td>
      <td>0.512242</td>
      <td>0.567577</td>
      <td>0.271437</td>
      <td>-0.307355</td>
      <td>0.432137</td>
      <td>0.431231</td>
      <td>-0.154034</td>
      <td>-1.186222</td>
      <td>-0.097187</td>
      <td>1.124706</td>
      <td>-0.599897</td>
      <td>-1.410512</td>
      <td>-0.303223</td>
      <td>0.241296</td>
      <td>-0.105699</td>
      <td>-0.120132</td>
      <td>-0.220609</td>
      <td>-0.369161</td>
      <td>-0.544227</td>
      <td>0.418506</td>
      <td>0.759430</td>
      <td>-0.119589</td>
      <td>0.631809</td>
      <td>0.035269</td>
      <td>-0.554631</td>
      <td>-0.328678</td>
      <td>0.373833</td>
      <td>0.069437</td>
      <td>-0.311131</td>
      <td>-0.123229</td>
      <td>0.439140</td>
      <td>0.089068</td>
      <td>0.762095</td>
      <td>0.968356</td>
      <td>0.287659</td>
      <td>0.060721</td>
      <td>0.043223</td>
      <td>...</td>
      <td>0.722121</td>
      <td>0.782594</td>
      <td>-0.470075</td>
      <td>-0.289249</td>
      <td>-0.350509</td>
      <td>0.517447</td>
      <td>0.480726</td>
      <td>0.301598</td>
      <td>-0.568277</td>
      <td>0.175295</td>
      <td>0.662729</td>
      <td>0.059942</td>
      <td>1.108320</td>
      <td>0.558725</td>
      <td>0.811464</td>
      <td>-0.556319</td>
      <td>0.430335</td>
      <td>0.951766</td>
      <td>0.086047</td>
      <td>-0.206316</td>
      <td>0.302779</td>
      <td>0.136893</td>
      <td>0.450164</td>
      <td>-0.030447</td>
      <td>0.362391</td>
      <td>-1.183827</td>
      <td>-0.108579</td>
      <td>-0.858091</td>
      <td>0.322013</td>
      <td>0.873951</td>
      <td>0.270173</td>
      <td>0.086655</td>
      <td>-0.753417</td>
      <td>-0.881542</td>
      <td>0.297799</td>
      <td>0.033035</td>
      <td>0.255439</td>
      <td>-0.265705</td>
      <td>-0.276289</td>
      <td>-0.344184</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.046558</td>
      <td>-0.687868</td>
      <td>0.273708</td>
      <td>0.832046</td>
      <td>0.674367</td>
      <td>1.314399</td>
      <td>0.505912</td>
      <td>0.355093</td>
      <td>-0.409262</td>
      <td>0.172159</td>
      <td>-0.603645</td>
      <td>-0.840957</td>
      <td>0.715645</td>
      <td>0.186054</td>
      <td>-0.009041</td>
      <td>-0.248107</td>
      <td>-0.711518</td>
      <td>-1.009310</td>
      <td>0.684023</td>
      <td>-0.142395</td>
      <td>-0.783100</td>
      <td>-0.349613</td>
      <td>0.558255</td>
      <td>1.378402</td>
      <td>0.549290</td>
      <td>0.199959</td>
      <td>-0.348870</td>
      <td>-1.785803</td>
      <td>-0.685977</td>
      <td>-0.525435</td>
      <td>-0.603711</td>
      <td>-0.244778</td>
      <td>0.220237</td>
      <td>-0.280944</td>
      <td>0.451562</td>
      <td>-0.359976</td>
      <td>-0.084588</td>
      <td>-0.863289</td>
      <td>-0.452579</td>
      <td>-1.471264</td>
      <td>...</td>
      <td>-0.482715</td>
      <td>-0.845009</td>
      <td>-1.054232</td>
      <td>-0.730389</td>
      <td>0.061090</td>
      <td>0.158553</td>
      <td>-0.082230</td>
      <td>0.377218</td>
      <td>0.969217</td>
      <td>0.072193</td>
      <td>-0.166665</td>
      <td>0.337649</td>
      <td>0.334029</td>
      <td>0.971346</td>
      <td>0.496315</td>
      <td>0.278803</td>
      <td>-0.319043</td>
      <td>0.115929</td>
      <td>-0.643819</td>
      <td>-0.589491</td>
      <td>-0.348212</td>
      <td>-1.096566</td>
      <td>-0.959464</td>
      <td>-1.009989</td>
      <td>0.197853</td>
      <td>-0.290445</td>
      <td>0.416860</td>
      <td>0.043502</td>
      <td>-0.231061</td>
      <td>0.226068</td>
      <td>0.332631</td>
      <td>-0.795673</td>
      <td>-0.341429</td>
      <td>-0.699537</td>
      <td>-0.759307</td>
      <td>-0.336342</td>
      <td>-0.539561</td>
      <td>1.447387</td>
      <td>1.145202</td>
      <td>0.474593</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.319486</td>
      <td>-0.646809</td>
      <td>1.052224</td>
      <td>0.340647</td>
      <td>-1.152927</td>
      <td>-0.080134</td>
      <td>0.169508</td>
      <td>1.287857</td>
      <td>0.110270</td>
      <td>-0.206589</td>
      <td>0.437549</td>
      <td>0.582788</td>
      <td>-0.286917</td>
      <td>-0.043845</td>
      <td>-0.974558</td>
      <td>0.229685</td>
      <td>0.236191</td>
      <td>-0.221551</td>
      <td>-0.123425</td>
      <td>-0.195973</td>
      <td>1.054325</td>
      <td>0.768753</td>
      <td>-0.453790</td>
      <td>0.534168</td>
      <td>0.269094</td>
      <td>0.420946</td>
      <td>0.043512</td>
      <td>-1.294734</td>
      <td>-0.812171</td>
      <td>-0.196808</td>
      <td>-0.226695</td>
      <td>-0.501359</td>
      <td>-0.699368</td>
      <td>-1.061082</td>
      <td>0.413579</td>
      <td>0.546999</td>
      <td>0.414918</td>
      <td>-0.414050</td>
      <td>-0.488131</td>
      <td>-0.438218</td>
      <td>...</td>
      <td>-1.048253</td>
      <td>-0.240356</td>
      <td>0.692458</td>
      <td>0.501416</td>
      <td>-0.195853</td>
      <td>0.086675</td>
      <td>0.928671</td>
      <td>0.686673</td>
      <td>-0.288852</td>
      <td>-0.752497</td>
      <td>-0.973900</td>
      <td>-0.776850</td>
      <td>0.970493</td>
      <td>0.044690</td>
      <td>0.477342</td>
      <td>-0.301619</td>
      <td>0.780281</td>
      <td>0.811167</td>
      <td>-1.049349</td>
      <td>-0.589937</td>
      <td>-0.614171</td>
      <td>0.967224</td>
      <td>-0.418556</td>
      <td>0.719952</td>
      <td>-0.407302</td>
      <td>-0.959751</td>
      <td>0.064381</td>
      <td>-0.037180</td>
      <td>0.141787</td>
      <td>-0.508624</td>
      <td>-0.205421</td>
      <td>-0.204782</td>
      <td>-1.584826</td>
      <td>-0.920798</td>
      <td>-0.375133</td>
      <td>-1.471037</td>
      <td>-1.240539</td>
      <td>-0.528946</td>
      <td>-0.346689</td>
      <td>-0.511163</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.313430</td>
      <td>0.341795</td>
      <td>0.251484</td>
      <td>0.661103</td>
      <td>-0.055071</td>
      <td>0.517958</td>
      <td>-0.084126</td>
      <td>0.508133</td>
      <td>0.159967</td>
      <td>-0.136329</td>
      <td>0.190033</td>
      <td>0.054002</td>
      <td>0.327234</td>
      <td>-0.936165</td>
      <td>-0.320244</td>
      <td>0.187650</td>
      <td>0.537603</td>
      <td>0.270383</td>
      <td>0.376219</td>
      <td>0.087498</td>
      <td>0.634575</td>
      <td>0.370569</td>
      <td>0.873788</td>
      <td>0.258881</td>
      <td>-0.334707</td>
      <td>-0.133011</td>
      <td>0.279772</td>
      <td>-0.145810</td>
      <td>-0.084134</td>
      <td>-0.301396</td>
      <td>-0.069003</td>
      <td>-0.351467</td>
      <td>-0.123556</td>
      <td>-0.770545</td>
      <td>0.751368</td>
      <td>0.401255</td>
      <td>-0.730109</td>
      <td>-1.283406</td>
      <td>-0.743026</td>
      <td>-0.374986</td>
      <td>...</td>
      <td>-0.495598</td>
      <td>0.340837</td>
      <td>0.824941</td>
      <td>-0.302683</td>
      <td>0.636663</td>
      <td>0.837709</td>
      <td>-0.059232</td>
      <td>0.587059</td>
      <td>-0.114970</td>
      <td>-0.939370</td>
      <td>-0.357891</td>
      <td>-0.171078</td>
      <td>0.434014</td>
      <td>0.630469</td>
      <td>0.363869</td>
      <td>-0.697497</td>
      <td>-0.000874</td>
      <td>-0.024584</td>
      <td>0.275110</td>
      <td>-0.289829</td>
      <td>0.570406</td>
      <td>-0.288048</td>
      <td>0.343765</td>
      <td>1.396777</td>
      <td>0.245142</td>
      <td>-0.342507</td>
      <td>0.342124</td>
      <td>-1.109016</td>
      <td>-0.593557</td>
      <td>-0.712444</td>
      <td>-0.703082</td>
      <td>-0.542471</td>
      <td>-1.242366</td>
      <td>0.044988</td>
      <td>-0.102461</td>
      <td>-0.700192</td>
      <td>-1.150856</td>
      <td>1.642893</td>
      <td>0.988634</td>
      <td>-0.354927</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.506703</td>
      <td>-0.356678</td>
      <td>0.076720</td>
      <td>0.761364</td>
      <td>0.320245</td>
      <td>0.547091</td>
      <td>0.773403</td>
      <td>0.234405</td>
      <td>0.249378</td>
      <td>0.414164</td>
      <td>-1.032904</td>
      <td>-1.500642</td>
      <td>-0.444437</td>
      <td>-0.208951</td>
      <td>-0.555208</td>
      <td>-0.760799</td>
      <td>-0.227682</td>
      <td>0.576963</td>
      <td>0.243342</td>
      <td>0.611932</td>
      <td>1.008522</td>
      <td>-0.231497</td>
      <td>-0.212690</td>
      <td>-0.284644</td>
      <td>-1.173785</td>
      <td>-0.445326</td>
      <td>0.106168</td>
      <td>0.024954</td>
      <td>-0.024974</td>
      <td>-0.619216</td>
      <td>-0.268184</td>
      <td>-0.552420</td>
      <td>0.303395</td>
      <td>-0.276263</td>
      <td>-0.051311</td>
      <td>-0.324843</td>
      <td>-0.429977</td>
      <td>0.166648</td>
      <td>0.075105</td>
      <td>0.299199</td>
      <td>...</td>
      <td>-1.450936</td>
      <td>-0.373691</td>
      <td>-0.072839</td>
      <td>-0.509176</td>
      <td>-0.246212</td>
      <td>0.060265</td>
      <td>0.234629</td>
      <td>0.230311</td>
      <td>0.909438</td>
      <td>-0.791396</td>
      <td>-0.557483</td>
      <td>0.006024</td>
      <td>0.139075</td>
      <td>-0.748942</td>
      <td>0.123181</td>
      <td>0.323856</td>
      <td>0.262370</td>
      <td>0.468330</td>
      <td>0.297039</td>
      <td>-0.767707</td>
      <td>0.208150</td>
      <td>0.721937</td>
      <td>-0.213915</td>
      <td>0.986873</td>
      <td>0.309450</td>
      <td>-0.176826</td>
      <td>-0.127277</td>
      <td>-0.311792</td>
      <td>-1.182783</td>
      <td>-0.770474</td>
      <td>-0.191456</td>
      <td>0.064711</td>
      <td>-0.375991</td>
      <td>0.249235</td>
      <td>-0.251152</td>
      <td>0.149945</td>
      <td>-0.296351</td>
      <td>-1.122882</td>
      <td>0.455358</td>
      <td>0.434797</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.835394</td>
      <td>-0.535163</td>
      <td>0.183758</td>
      <td>0.787344</td>
      <td>1.584978</td>
      <td>0.994574</td>
      <td>0.824967</td>
      <td>1.707777</td>
      <td>0.752465</td>
      <td>0.011044</td>
      <td>0.254755</td>
      <td>-1.305790</td>
      <td>-0.330985</td>
      <td>0.540593</td>
      <td>0.190265</td>
      <td>-0.931661</td>
      <td>-0.803817</td>
      <td>-0.283456</td>
      <td>-0.788781</td>
      <td>-0.060255</td>
      <td>-0.422109</td>
      <td>-0.135930</td>
      <td>-0.071483</td>
      <td>1.014342</td>
      <td>1.029106</td>
      <td>0.014727</td>
      <td>-0.491720</td>
      <td>-1.602963</td>
      <td>-0.412969</td>
      <td>-1.242104</td>
      <td>-0.919952</td>
      <td>-0.930219</td>
      <td>-0.254136</td>
      <td>0.958059</td>
      <td>1.113966</td>
      <td>-0.589910</td>
      <td>-0.894866</td>
      <td>-0.604581</td>
      <td>-2.022209</td>
      <td>-1.326236</td>
      <td>...</td>
      <td>-0.648262</td>
      <td>-0.269994</td>
      <td>-0.639512</td>
      <td>-1.240206</td>
      <td>0.349396</td>
      <td>0.158170</td>
      <td>0.918898</td>
      <td>0.885490</td>
      <td>0.316187</td>
      <td>0.236980</td>
      <td>0.443937</td>
      <td>0.945447</td>
      <td>-0.158353</td>
      <td>0.345100</td>
      <td>-0.281355</td>
      <td>-0.364270</td>
      <td>-0.670273</td>
      <td>0.484457</td>
      <td>-0.138105</td>
      <td>0.591890</td>
      <td>0.327620</td>
      <td>0.808111</td>
      <td>0.373909</td>
      <td>1.844000</td>
      <td>1.941373</td>
      <td>0.214551</td>
      <td>0.772490</td>
      <td>-0.630959</td>
      <td>-0.293161</td>
      <td>-0.903666</td>
      <td>-0.055722</td>
      <td>0.180450</td>
      <td>0.092623</td>
      <td>0.489124</td>
      <td>-0.392959</td>
      <td>-0.136244</td>
      <td>-0.402194</td>
      <td>-3.800230</td>
      <td>-2.185735</td>
      <td>-1.148989</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f4a10423fd0&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.119284  0.039483  28.348624  8.703246e-177  1.041899  1.196669
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.081 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.1e043a052b0af929e4d8.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>