
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.223445</td>
      <td>-0.163361</td>
      <td>-1.004004</td>
      <td>0.086103</td>
      <td>0.358999</td>
      <td>-0.893179</td>
      <td>-1.326454</td>
      <td>-1.215083</td>
      <td>-0.629209</td>
      <td>-0.419931</td>
      <td>-0.497184</td>
      <td>0.571613</td>
      <td>0.602384</td>
      <td>-0.430174</td>
      <td>-0.939933</td>
      <td>0.138087</td>
      <td>-0.693813</td>
      <td>0.164057</td>
      <td>0.644901</td>
      <td>-1.074163</td>
      <td>0.807819</td>
      <td>-0.614122</td>
      <td>1.501577</td>
      <td>-0.366868</td>
      <td>0.131631</td>
      <td>-0.316703</td>
      <td>0.510280</td>
      <td>-0.123658</td>
      <td>-0.405580</td>
      <td>-1.271821</td>
      <td>-0.513657</td>
      <td>1.369473</td>
      <td>0.221842</td>
      <td>-0.051712</td>
      <td>0.979290</td>
      <td>0.465100</td>
      <td>-0.418066</td>
      <td>-0.443473</td>
      <td>-0.227376</td>
      <td>-0.550561</td>
      <td>...</td>
      <td>0.351016</td>
      <td>1.041011</td>
      <td>-0.097727</td>
      <td>-0.460685</td>
      <td>0.030309</td>
      <td>-0.334010</td>
      <td>-0.095679</td>
      <td>0.028889</td>
      <td>-0.311007</td>
      <td>-0.720725</td>
      <td>-0.347237</td>
      <td>-0.591043</td>
      <td>-1.019813</td>
      <td>-0.721985</td>
      <td>-0.199350</td>
      <td>0.440937</td>
      <td>1.788257</td>
      <td>0.032039</td>
      <td>-0.480117</td>
      <td>-0.561407</td>
      <td>0.374739</td>
      <td>-0.608029</td>
      <td>-0.080032</td>
      <td>-0.181522</td>
      <td>-0.161081</td>
      <td>0.380047</td>
      <td>0.238310</td>
      <td>0.703887</td>
      <td>-0.076411</td>
      <td>-0.422761</td>
      <td>0.295626</td>
      <td>-0.075146</td>
      <td>-0.711408</td>
      <td>-1.094496</td>
      <td>0.022820</td>
      <td>-0.548222</td>
      <td>0.304026</td>
      <td>-0.286720</td>
      <td>-0.530847</td>
      <td>-0.853038</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.682256</td>
      <td>0.289622</td>
      <td>0.647571</td>
      <td>-0.191706</td>
      <td>-0.258794</td>
      <td>-0.585728</td>
      <td>0.097181</td>
      <td>-0.760916</td>
      <td>-0.995923</td>
      <td>-0.804222</td>
      <td>-0.633490</td>
      <td>0.286206</td>
      <td>0.740858</td>
      <td>1.120588</td>
      <td>0.121449</td>
      <td>0.560529</td>
      <td>0.981422</td>
      <td>0.905712</td>
      <td>1.417185</td>
      <td>0.151862</td>
      <td>0.111661</td>
      <td>0.798107</td>
      <td>0.618775</td>
      <td>-0.339411</td>
      <td>-0.222962</td>
      <td>-0.408914</td>
      <td>0.312208</td>
      <td>0.259389</td>
      <td>0.830286</td>
      <td>0.378155</td>
      <td>0.541280</td>
      <td>0.217009</td>
      <td>0.894746</td>
      <td>-0.354376</td>
      <td>-0.313437</td>
      <td>-0.832259</td>
      <td>-1.830977</td>
      <td>-0.838377</td>
      <td>0.014275</td>
      <td>0.399283</td>
      <td>...</td>
      <td>-0.083718</td>
      <td>-0.464353</td>
      <td>-1.504470</td>
      <td>-0.498617</td>
      <td>-1.399053</td>
      <td>-0.505217</td>
      <td>0.412016</td>
      <td>0.717347</td>
      <td>-0.012813</td>
      <td>-0.146363</td>
      <td>-0.383219</td>
      <td>0.484875</td>
      <td>0.136397</td>
      <td>-0.873302</td>
      <td>-0.381375</td>
      <td>1.093179</td>
      <td>-0.110641</td>
      <td>0.094930</td>
      <td>-0.469727</td>
      <td>0.145726</td>
      <td>0.574466</td>
      <td>-0.093553</td>
      <td>-1.172791</td>
      <td>-1.894780</td>
      <td>-0.626879</td>
      <td>0.363238</td>
      <td>0.352620</td>
      <td>-0.097990</td>
      <td>-0.055327</td>
      <td>-0.463121</td>
      <td>-0.360975</td>
      <td>0.557115</td>
      <td>0.260599</td>
      <td>-0.128831</td>
      <td>0.032523</td>
      <td>-0.267112</td>
      <td>-0.159854</td>
      <td>-0.022355</td>
      <td>-0.243442</td>
      <td>-0.063546</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.082202</td>
      <td>-0.505033</td>
      <td>0.245947</td>
      <td>0.491358</td>
      <td>-0.535269</td>
      <td>-0.438467</td>
      <td>-0.523385</td>
      <td>-0.347443</td>
      <td>-0.229529</td>
      <td>-0.572488</td>
      <td>-0.312750</td>
      <td>-0.217455</td>
      <td>-0.300956</td>
      <td>-0.541182</td>
      <td>0.208012</td>
      <td>0.173753</td>
      <td>-0.312679</td>
      <td>-0.782944</td>
      <td>-0.541945</td>
      <td>0.130510</td>
      <td>0.557373</td>
      <td>0.269559</td>
      <td>0.173464</td>
      <td>-0.275431</td>
      <td>-0.820433</td>
      <td>0.386818</td>
      <td>0.425025</td>
      <td>0.047181</td>
      <td>0.213719</td>
      <td>0.012398</td>
      <td>-0.058910</td>
      <td>0.534060</td>
      <td>0.510825</td>
      <td>-1.415410</td>
      <td>-0.330966</td>
      <td>-1.300426</td>
      <td>-0.572336</td>
      <td>-1.084723</td>
      <td>-0.007736</td>
      <td>-0.038759</td>
      <td>...</td>
      <td>0.097008</td>
      <td>0.199824</td>
      <td>0.311183</td>
      <td>-0.339367</td>
      <td>0.416787</td>
      <td>-0.108524</td>
      <td>0.485992</td>
      <td>-0.052228</td>
      <td>-0.520428</td>
      <td>-0.415539</td>
      <td>-0.432919</td>
      <td>0.410310</td>
      <td>-0.297217</td>
      <td>-1.108972</td>
      <td>-1.089003</td>
      <td>-0.375794</td>
      <td>0.902775</td>
      <td>0.215836</td>
      <td>0.088327</td>
      <td>0.409231</td>
      <td>0.252874</td>
      <td>-0.032267</td>
      <td>-0.951046</td>
      <td>-0.851074</td>
      <td>0.135196</td>
      <td>1.292914</td>
      <td>1.327744</td>
      <td>-0.232013</td>
      <td>-1.274504</td>
      <td>-1.349733</td>
      <td>-0.003564</td>
      <td>-0.119986</td>
      <td>-0.196747</td>
      <td>-0.223094</td>
      <td>-0.129740</td>
      <td>-0.575468</td>
      <td>-0.967817</td>
      <td>0.168948</td>
      <td>-0.986139</td>
      <td>-1.018238</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.149960</td>
      <td>0.223900</td>
      <td>0.184353</td>
      <td>0.182911</td>
      <td>0.062005</td>
      <td>-0.167697</td>
      <td>-0.354858</td>
      <td>-0.614068</td>
      <td>-0.996864</td>
      <td>-0.292079</td>
      <td>-0.471646</td>
      <td>-0.915335</td>
      <td>-0.497636</td>
      <td>-1.076361</td>
      <td>-0.032930</td>
      <td>0.628689</td>
      <td>0.191336</td>
      <td>-0.320978</td>
      <td>-0.264064</td>
      <td>-0.705062</td>
      <td>0.028319</td>
      <td>0.837947</td>
      <td>-0.025598</td>
      <td>-0.164449</td>
      <td>0.737813</td>
      <td>-0.335967</td>
      <td>-1.227073</td>
      <td>0.022571</td>
      <td>-0.150335</td>
      <td>-0.130328</td>
      <td>-1.045674</td>
      <td>0.052518</td>
      <td>1.688998</td>
      <td>0.372944</td>
      <td>0.837762</td>
      <td>-0.497294</td>
      <td>0.102407</td>
      <td>-0.637689</td>
      <td>-0.247503</td>
      <td>-0.173819</td>
      <td>...</td>
      <td>1.214991</td>
      <td>0.437113</td>
      <td>-1.110918</td>
      <td>-0.865789</td>
      <td>0.360942</td>
      <td>0.010627</td>
      <td>-0.172411</td>
      <td>0.040152</td>
      <td>0.607725</td>
      <td>0.251097</td>
      <td>-0.934075</td>
      <td>-0.819958</td>
      <td>-0.136589</td>
      <td>-1.079714</td>
      <td>-0.023970</td>
      <td>0.010485</td>
      <td>0.396756</td>
      <td>-0.245076</td>
      <td>-0.362746</td>
      <td>-0.662445</td>
      <td>0.157990</td>
      <td>0.138226</td>
      <td>-0.398778</td>
      <td>-0.055968</td>
      <td>-0.080358</td>
      <td>0.050708</td>
      <td>-0.079982</td>
      <td>-0.913229</td>
      <td>-0.310925</td>
      <td>-0.088774</td>
      <td>0.251054</td>
      <td>0.466459</td>
      <td>-0.310816</td>
      <td>-0.559398</td>
      <td>0.551026</td>
      <td>0.150477</td>
      <td>1.357832</td>
      <td>0.451004</td>
      <td>0.277812</td>
      <td>0.731828</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.522843</td>
      <td>-1.144453</td>
      <td>0.101196</td>
      <td>0.484973</td>
      <td>0.927305</td>
      <td>0.338303</td>
      <td>-0.021204</td>
      <td>0.922933</td>
      <td>0.358108</td>
      <td>-0.126689</td>
      <td>0.060287</td>
      <td>-0.380477</td>
      <td>-1.074057</td>
      <td>0.033959</td>
      <td>0.388730</td>
      <td>-1.069017</td>
      <td>-0.457549</td>
      <td>1.313844</td>
      <td>1.047429</td>
      <td>-0.559248</td>
      <td>-0.250213</td>
      <td>-0.859805</td>
      <td>0.122025</td>
      <td>-0.521384</td>
      <td>-0.909329</td>
      <td>0.475162</td>
      <td>0.785065</td>
      <td>0.449915</td>
      <td>0.074649</td>
      <td>-0.571150</td>
      <td>0.958939</td>
      <td>1.230520</td>
      <td>-0.070774</td>
      <td>-0.089837</td>
      <td>-0.067654</td>
      <td>-1.464799</td>
      <td>-0.747044</td>
      <td>-0.272643</td>
      <td>-0.064639</td>
      <td>1.367978</td>
      <td>...</td>
      <td>-0.150904</td>
      <td>-0.684221</td>
      <td>-0.494858</td>
      <td>-1.098640</td>
      <td>-0.296294</td>
      <td>-0.710914</td>
      <td>-0.133272</td>
      <td>-0.421724</td>
      <td>-0.055735</td>
      <td>-0.108626</td>
      <td>-0.868267</td>
      <td>-0.713928</td>
      <td>-0.149098</td>
      <td>-0.448798</td>
      <td>1.472564</td>
      <td>0.098971</td>
      <td>1.109544</td>
      <td>0.273668</td>
      <td>0.119766</td>
      <td>-0.399478</td>
      <td>-0.367609</td>
      <td>-0.375592</td>
      <td>0.634240</td>
      <td>-0.404280</td>
      <td>-0.677823</td>
      <td>0.737753</td>
      <td>0.619455</td>
      <td>0.112592</td>
      <td>-0.276919</td>
      <td>-0.128385</td>
      <td>0.386076</td>
      <td>0.081333</td>
      <td>-0.090014</td>
      <td>-1.169431</td>
      <td>-0.351613</td>
      <td>-0.051141</td>
      <td>0.497406</td>
      <td>0.621582</td>
      <td>-0.092710</td>
      <td>0.106104</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.065171</td>
      <td>0.241941</td>
      <td>-0.758219</td>
      <td>-0.122814</td>
      <td>0.625388</td>
      <td>-1.013384</td>
      <td>-0.243503</td>
      <td>-0.848815</td>
      <td>0.147178</td>
      <td>0.357452</td>
      <td>0.139925</td>
      <td>-0.805732</td>
      <td>-0.415094</td>
      <td>0.447547</td>
      <td>0.996967</td>
      <td>-0.109593</td>
      <td>-0.455528</td>
      <td>0.535969</td>
      <td>-0.404042</td>
      <td>-0.274270</td>
      <td>-0.323346</td>
      <td>0.338523</td>
      <td>-0.398045</td>
      <td>-0.451811</td>
      <td>-0.422815</td>
      <td>-0.123953</td>
      <td>0.365020</td>
      <td>0.451686</td>
      <td>1.852592</td>
      <td>-0.167165</td>
      <td>-0.752679</td>
      <td>0.557123</td>
      <td>0.218547</td>
      <td>0.501658</td>
      <td>-0.182197</td>
      <td>0.107354</td>
      <td>0.789265</td>
      <td>0.194534</td>
      <td>0.312222</td>
      <td>0.135954</td>
      <td>...</td>
      <td>0.304542</td>
      <td>-0.523937</td>
      <td>0.535344</td>
      <td>-0.061812</td>
      <td>-0.216550</td>
      <td>-0.090770</td>
      <td>0.735453</td>
      <td>-0.163611</td>
      <td>0.198950</td>
      <td>0.475247</td>
      <td>-0.672775</td>
      <td>-0.834445</td>
      <td>-0.492896</td>
      <td>-1.206279</td>
      <td>-0.189844</td>
      <td>1.045997</td>
      <td>1.020756</td>
      <td>-0.665839</td>
      <td>0.244976</td>
      <td>-0.984647</td>
      <td>-0.422706</td>
      <td>-0.183323</td>
      <td>1.197868</td>
      <td>-0.842567</td>
      <td>-0.327945</td>
      <td>1.052132</td>
      <td>0.803644</td>
      <td>0.708115</td>
      <td>-0.261826</td>
      <td>-0.174550</td>
      <td>0.704215</td>
      <td>0.651059</td>
      <td>-0.503246</td>
      <td>0.169065</td>
      <td>0.949967</td>
      <td>-0.509899</td>
      <td>-0.229527</td>
      <td>1.213665</td>
      <td>-0.196341</td>
      <td>0.589534</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.010693</td>
      <td>-0.337608</td>
      <td>0.264356</td>
      <td>-0.272190</td>
      <td>0.428589</td>
      <td>0.633936</td>
      <td>0.699694</td>
      <td>-0.017255</td>
      <td>-1.278811</td>
      <td>-0.204766</td>
      <td>0.230472</td>
      <td>0.286749</td>
      <td>0.157903</td>
      <td>0.801620</td>
      <td>0.373612</td>
      <td>-0.112437</td>
      <td>0.783448</td>
      <td>0.676298</td>
      <td>1.082887</td>
      <td>0.007817</td>
      <td>0.627092</td>
      <td>0.244677</td>
      <td>0.389840</td>
      <td>0.435332</td>
      <td>1.589820</td>
      <td>0.709745</td>
      <td>0.654989</td>
      <td>0.455280</td>
      <td>0.906439</td>
      <td>-0.283888</td>
      <td>0.115964</td>
      <td>-0.955342</td>
      <td>0.601181</td>
      <td>-0.421724</td>
      <td>0.761087</td>
      <td>0.472384</td>
      <td>-0.485084</td>
      <td>-1.123939</td>
      <td>0.038265</td>
      <td>-0.784227</td>
      <td>...</td>
      <td>0.752393</td>
      <td>0.287741</td>
      <td>-0.378538</td>
      <td>-0.604856</td>
      <td>0.402384</td>
      <td>0.790267</td>
      <td>1.568212</td>
      <td>0.338084</td>
      <td>-0.248336</td>
      <td>-0.154839</td>
      <td>-0.270904</td>
      <td>0.064046</td>
      <td>0.059861</td>
      <td>-1.955778</td>
      <td>-0.475835</td>
      <td>-0.037993</td>
      <td>0.398073</td>
      <td>-0.003243</td>
      <td>0.000093</td>
      <td>-0.133845</td>
      <td>-0.330492</td>
      <td>-0.494136</td>
      <td>-0.561763</td>
      <td>1.140869</td>
      <td>-0.731554</td>
      <td>0.273082</td>
      <td>-0.273218</td>
      <td>-0.010735</td>
      <td>0.556317</td>
      <td>-0.262827</td>
      <td>0.387993</td>
      <td>0.172342</td>
      <td>-0.104452</td>
      <td>-1.090697</td>
      <td>-0.854692</td>
      <td>-1.002626</td>
      <td>-0.461612</td>
      <td>-2.575815</td>
      <td>-2.099050</td>
      <td>-1.414769</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.485936</td>
      <td>-0.216555</td>
      <td>0.239262</td>
      <td>0.871597</td>
      <td>0.402113</td>
      <td>-0.602934</td>
      <td>-0.213385</td>
      <td>0.555566</td>
      <td>-0.169318</td>
      <td>0.021730</td>
      <td>1.057382</td>
      <td>-0.516657</td>
      <td>0.385423</td>
      <td>-0.011590</td>
      <td>-0.352360</td>
      <td>-0.764525</td>
      <td>0.058908</td>
      <td>0.778212</td>
      <td>1.507681</td>
      <td>-0.122895</td>
      <td>-0.898184</td>
      <td>0.877170</td>
      <td>0.468479</td>
      <td>-0.255508</td>
      <td>-0.235386</td>
      <td>0.135915</td>
      <td>0.836265</td>
      <td>-0.132278</td>
      <td>1.199937</td>
      <td>0.064050</td>
      <td>-0.058119</td>
      <td>0.431452</td>
      <td>0.414881</td>
      <td>-1.002590</td>
      <td>0.689705</td>
      <td>0.422982</td>
      <td>-0.995667</td>
      <td>-0.016343</td>
      <td>0.112328</td>
      <td>0.350282</td>
      <td>...</td>
      <td>0.378096</td>
      <td>0.188930</td>
      <td>-0.235520</td>
      <td>-0.229841</td>
      <td>-0.074291</td>
      <td>0.307188</td>
      <td>0.088758</td>
      <td>-0.293273</td>
      <td>-0.469744</td>
      <td>0.413190</td>
      <td>-1.419334</td>
      <td>-0.444398</td>
      <td>-0.704731</td>
      <td>0.223295</td>
      <td>-0.293994</td>
      <td>-0.166266</td>
      <td>0.722263</td>
      <td>0.728070</td>
      <td>0.901435</td>
      <td>0.847097</td>
      <td>0.879646</td>
      <td>1.056558</td>
      <td>-0.479823</td>
      <td>0.799654</td>
      <td>1.140735</td>
      <td>0.989741</td>
      <td>1.126093</td>
      <td>1.376455</td>
      <td>0.477265</td>
      <td>0.368623</td>
      <td>0.034334</td>
      <td>0.161425</td>
      <td>-0.850463</td>
      <td>-0.313195</td>
      <td>0.757711</td>
      <td>0.856188</td>
      <td>-0.126884</td>
      <td>1.213891</td>
      <td>-0.644221</td>
      <td>-0.318198</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1.146878</td>
      <td>0.961506</td>
      <td>-0.172014</td>
      <td>0.232630</td>
      <td>-0.911608</td>
      <td>-2.274038</td>
      <td>-0.455067</td>
      <td>-1.518062</td>
      <td>0.342133</td>
      <td>0.508723</td>
      <td>0.832863</td>
      <td>1.146907</td>
      <td>-0.063382</td>
      <td>-0.261691</td>
      <td>-0.246042</td>
      <td>0.404606</td>
      <td>-0.036811</td>
      <td>-0.311538</td>
      <td>0.342290</td>
      <td>-0.543354</td>
      <td>0.545424</td>
      <td>-0.090736</td>
      <td>0.368179</td>
      <td>-0.410123</td>
      <td>-0.995596</td>
      <td>-0.296023</td>
      <td>0.837439</td>
      <td>-0.584339</td>
      <td>-0.471874</td>
      <td>-0.161150</td>
      <td>-0.066281</td>
      <td>-0.483728</td>
      <td>0.784301</td>
      <td>-1.087027</td>
      <td>-0.489724</td>
      <td>-0.140372</td>
      <td>0.318541</td>
      <td>-0.864789</td>
      <td>-0.769801</td>
      <td>-0.557219</td>
      <td>...</td>
      <td>-0.797875</td>
      <td>0.195692</td>
      <td>-0.101361</td>
      <td>-1.270910</td>
      <td>-0.747286</td>
      <td>-1.620744</td>
      <td>-0.621162</td>
      <td>-0.261527</td>
      <td>-0.786965</td>
      <td>-0.906596</td>
      <td>-0.629818</td>
      <td>-0.337493</td>
      <td>-0.143896</td>
      <td>-0.233658</td>
      <td>1.137694</td>
      <td>-0.219351</td>
      <td>-0.019767</td>
      <td>-0.141613</td>
      <td>0.220129</td>
      <td>0.075014</td>
      <td>-0.316124</td>
      <td>-0.431991</td>
      <td>-1.164643</td>
      <td>-0.871590</td>
      <td>-0.859971</td>
      <td>-0.162368</td>
      <td>1.247640</td>
      <td>1.057934</td>
      <td>0.546001</td>
      <td>0.393103</td>
      <td>1.159152</td>
      <td>0.417641</td>
      <td>-0.286577</td>
      <td>-0.133577</td>
      <td>0.725855</td>
      <td>-0.113692</td>
      <td>-0.024494</td>
      <td>1.607220</td>
      <td>0.774464</td>
      <td>0.291664</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-0.409280</td>
      <td>0.842942</td>
      <td>0.012124</td>
      <td>-0.263337</td>
      <td>0.206631</td>
      <td>0.512824</td>
      <td>-1.074514</td>
      <td>-0.723354</td>
      <td>1.104252</td>
      <td>0.129866</td>
      <td>-0.005538</td>
      <td>0.437048</td>
      <td>0.489365</td>
      <td>-0.113308</td>
      <td>-0.154831</td>
      <td>-0.780907</td>
      <td>-0.973382</td>
      <td>0.572166</td>
      <td>0.262592</td>
      <td>-0.523557</td>
      <td>-0.004948</td>
      <td>0.015560</td>
      <td>-0.071683</td>
      <td>-0.481713</td>
      <td>-0.932667</td>
      <td>0.223503</td>
      <td>0.540159</td>
      <td>0.928067</td>
      <td>0.300756</td>
      <td>0.101519</td>
      <td>-0.311075</td>
      <td>-0.498771</td>
      <td>-0.679446</td>
      <td>0.364023</td>
      <td>-0.407659</td>
      <td>-0.447827</td>
      <td>-0.712916</td>
      <td>-1.195944</td>
      <td>-0.189511</td>
      <td>0.806146</td>
      <td>...</td>
      <td>-0.205690</td>
      <td>0.085758</td>
      <td>0.580720</td>
      <td>-1.402602</td>
      <td>0.255241</td>
      <td>-1.100402</td>
      <td>0.027631</td>
      <td>0.584775</td>
      <td>-0.716455</td>
      <td>0.279964</td>
      <td>-0.192413</td>
      <td>0.382075</td>
      <td>0.460893</td>
      <td>-0.521421</td>
      <td>-0.093110</td>
      <td>0.964654</td>
      <td>1.191475</td>
      <td>0.351033</td>
      <td>0.167904</td>
      <td>-0.098539</td>
      <td>-0.351020</td>
      <td>-0.662865</td>
      <td>-0.051219</td>
      <td>-0.941343</td>
      <td>-0.359220</td>
      <td>0.243463</td>
      <td>0.414086</td>
      <td>0.357351</td>
      <td>-0.004715</td>
      <td>-0.617968</td>
      <td>0.153857</td>
      <td>0.330355</td>
      <td>0.046995</td>
      <td>-0.143153</td>
      <td>-0.269468</td>
      <td>-0.213450</td>
      <td>0.033286</td>
      <td>-0.408044</td>
      <td>-1.237355</td>
      <td>-0.631459</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-0.223454</td>
      <td>-0.902416</td>
      <td>-0.519489</td>
      <td>-0.021759</td>
      <td>-0.320196</td>
      <td>-1.353786</td>
      <td>-0.683546</td>
      <td>-1.044700</td>
      <td>-0.659736</td>
      <td>-0.415373</td>
      <td>-0.745467</td>
      <td>-0.423577</td>
      <td>-0.314036</td>
      <td>-0.480987</td>
      <td>-1.036855</td>
      <td>1.066929</td>
      <td>0.120519</td>
      <td>0.111105</td>
      <td>-0.213187</td>
      <td>-0.488613</td>
      <td>0.421791</td>
      <td>0.297035</td>
      <td>-0.359354</td>
      <td>0.109249</td>
      <td>-0.017499</td>
      <td>0.884375</td>
      <td>-0.061959</td>
      <td>0.070229</td>
      <td>0.493764</td>
      <td>0.009271</td>
      <td>0.049364</td>
      <td>0.312823</td>
      <td>-0.926108</td>
      <td>-0.631324</td>
      <td>-0.837657</td>
      <td>0.667373</td>
      <td>0.387275</td>
      <td>0.023082</td>
      <td>-0.299087</td>
      <td>0.039491</td>
      <td>...</td>
      <td>0.189782</td>
      <td>-0.025052</td>
      <td>0.229009</td>
      <td>-0.404662</td>
      <td>-0.331661</td>
      <td>-0.445550</td>
      <td>-0.468685</td>
      <td>-0.927616</td>
      <td>-0.660876</td>
      <td>-0.420231</td>
      <td>-0.039202</td>
      <td>0.993236</td>
      <td>0.956390</td>
      <td>-0.736964</td>
      <td>-0.412711</td>
      <td>-0.496339</td>
      <td>1.516970</td>
      <td>0.314564</td>
      <td>0.599967</td>
      <td>-0.712606</td>
      <td>-0.281515</td>
      <td>0.017482</td>
      <td>0.216356</td>
      <td>-0.272557</td>
      <td>-1.417948</td>
      <td>0.166743</td>
      <td>-0.288264</td>
      <td>0.958638</td>
      <td>-0.094852</td>
      <td>1.178056</td>
      <td>0.734854</td>
      <td>-0.311775</td>
      <td>-0.275678</td>
      <td>-0.180341</td>
      <td>-0.765414</td>
      <td>0.133467</td>
      <td>-0.229818</td>
      <td>-1.758133</td>
      <td>-2.021293</td>
      <td>-0.636797</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.905626</td>
      <td>-0.306764</td>
      <td>-0.520715</td>
      <td>0.148185</td>
      <td>-0.195520</td>
      <td>-0.717935</td>
      <td>-0.285508</td>
      <td>-0.252253</td>
      <td>-0.112302</td>
      <td>-0.568073</td>
      <td>0.382494</td>
      <td>1.725108</td>
      <td>0.787894</td>
      <td>0.092812</td>
      <td>0.817839</td>
      <td>1.276015</td>
      <td>0.230224</td>
      <td>0.124653</td>
      <td>0.701133</td>
      <td>-0.654314</td>
      <td>1.593989</td>
      <td>0.751990</td>
      <td>1.428542</td>
      <td>-0.292194</td>
      <td>-0.216721</td>
      <td>-0.488536</td>
      <td>0.285407</td>
      <td>0.663715</td>
      <td>0.228378</td>
      <td>-0.975165</td>
      <td>-0.042213</td>
      <td>-0.802161</td>
      <td>0.186802</td>
      <td>0.236933</td>
      <td>0.211699</td>
      <td>0.850176</td>
      <td>0.269302</td>
      <td>-0.158754</td>
      <td>-0.464124</td>
      <td>-1.125055</td>
      <td>...</td>
      <td>0.226806</td>
      <td>-0.315264</td>
      <td>-0.356667</td>
      <td>-0.636264</td>
      <td>-0.530651</td>
      <td>0.317655</td>
      <td>-0.545259</td>
      <td>0.614856</td>
      <td>0.759855</td>
      <td>0.379642</td>
      <td>0.070999</td>
      <td>0.373930</td>
      <td>0.035322</td>
      <td>-0.767434</td>
      <td>-0.188901</td>
      <td>-0.131733</td>
      <td>0.798997</td>
      <td>-0.193030</td>
      <td>0.610038</td>
      <td>0.583915</td>
      <td>0.299603</td>
      <td>0.738343</td>
      <td>-0.333102</td>
      <td>0.016322</td>
      <td>-0.465839</td>
      <td>1.050775</td>
      <td>0.115197</td>
      <td>-0.190709</td>
      <td>1.118414</td>
      <td>0.890269</td>
      <td>0.672637</td>
      <td>-0.170234</td>
      <td>-0.218421</td>
      <td>-0.126495</td>
      <td>-0.548664</td>
      <td>-0.770478</td>
      <td>-1.008932</td>
      <td>-2.496016</td>
      <td>-1.339724</td>
      <td>-0.441084</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.787397</td>
      <td>0.106610</td>
      <td>0.222885</td>
      <td>0.438058</td>
      <td>0.214165</td>
      <td>-0.681323</td>
      <td>0.245280</td>
      <td>0.047525</td>
      <td>-0.627889</td>
      <td>-0.537535</td>
      <td>-0.665110</td>
      <td>-0.588266</td>
      <td>-0.902835</td>
      <td>0.766765</td>
      <td>0.305382</td>
      <td>1.079046</td>
      <td>0.067602</td>
      <td>-0.637181</td>
      <td>0.213228</td>
      <td>-0.867990</td>
      <td>0.870870</td>
      <td>0.188608</td>
      <td>1.056831</td>
      <td>-0.039474</td>
      <td>-0.337171</td>
      <td>0.293070</td>
      <td>0.133634</td>
      <td>-0.279555</td>
      <td>0.193837</td>
      <td>-0.495440</td>
      <td>-0.284452</td>
      <td>0.288867</td>
      <td>0.776551</td>
      <td>0.028125</td>
      <td>0.029908</td>
      <td>-0.287743</td>
      <td>-0.332284</td>
      <td>0.399236</td>
      <td>0.076618</td>
      <td>-0.239718</td>
      <td>...</td>
      <td>-0.360939</td>
      <td>-0.371667</td>
      <td>-0.367652</td>
      <td>-0.387601</td>
      <td>-0.118959</td>
      <td>0.424585</td>
      <td>0.109501</td>
      <td>0.327493</td>
      <td>-0.014521</td>
      <td>0.213816</td>
      <td>-0.841200</td>
      <td>-0.381472</td>
      <td>-0.487767</td>
      <td>-0.846288</td>
      <td>0.305850</td>
      <td>-1.068680</td>
      <td>0.761393</td>
      <td>0.367853</td>
      <td>0.980860</td>
      <td>0.083708</td>
      <td>0.130245</td>
      <td>0.110667</td>
      <td>0.056335</td>
      <td>-0.332029</td>
      <td>-0.850426</td>
      <td>0.905006</td>
      <td>-0.112507</td>
      <td>0.393502</td>
      <td>0.441001</td>
      <td>0.331447</td>
      <td>-0.161959</td>
      <td>-0.156551</td>
      <td>0.293228</td>
      <td>-0.208594</td>
      <td>1.252550</td>
      <td>0.678416</td>
      <td>0.817625</td>
      <td>1.224497</td>
      <td>0.082165</td>
      <td>0.119438</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.065185</td>
      <td>-0.845580</td>
      <td>-0.194474</td>
      <td>0.408336</td>
      <td>-0.707486</td>
      <td>-0.483693</td>
      <td>0.289545</td>
      <td>0.414951</td>
      <td>-0.015724</td>
      <td>0.196169</td>
      <td>-0.473999</td>
      <td>-0.548350</td>
      <td>-0.749203</td>
      <td>-0.597696</td>
      <td>0.464431</td>
      <td>-0.516505</td>
      <td>-1.200715</td>
      <td>0.577326</td>
      <td>0.267438</td>
      <td>-0.976317</td>
      <td>0.370462</td>
      <td>0.410333</td>
      <td>0.634192</td>
      <td>-0.456451</td>
      <td>-1.072941</td>
      <td>0.074271</td>
      <td>0.890849</td>
      <td>0.878162</td>
      <td>0.583616</td>
      <td>0.176841</td>
      <td>0.965330</td>
      <td>-0.012390</td>
      <td>0.279175</td>
      <td>-0.407305</td>
      <td>-0.426078</td>
      <td>-0.257253</td>
      <td>-0.337993</td>
      <td>-1.594019</td>
      <td>0.017833</td>
      <td>0.288621</td>
      <td>...</td>
      <td>0.025698</td>
      <td>0.247973</td>
      <td>-0.653611</td>
      <td>-0.357016</td>
      <td>-0.122491</td>
      <td>0.502197</td>
      <td>0.196693</td>
      <td>0.088538</td>
      <td>-0.225596</td>
      <td>-0.925527</td>
      <td>-0.941849</td>
      <td>-0.192674</td>
      <td>-0.641465</td>
      <td>-0.488422</td>
      <td>-0.826029</td>
      <td>0.128820</td>
      <td>1.365100</td>
      <td>0.587031</td>
      <td>-0.017861</td>
      <td>0.127594</td>
      <td>0.108414</td>
      <td>0.150944</td>
      <td>0.535870</td>
      <td>0.685176</td>
      <td>-0.506101</td>
      <td>0.831573</td>
      <td>-0.424235</td>
      <td>0.155432</td>
      <td>-1.051122</td>
      <td>-0.910185</td>
      <td>-0.346773</td>
      <td>-0.329643</td>
      <td>0.235035</td>
      <td>-0.421411</td>
      <td>0.821912</td>
      <td>0.504854</td>
      <td>0.100717</td>
      <td>-1.738632</td>
      <td>-1.523637</td>
      <td>-0.793517</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.093399</td>
      <td>-0.722428</td>
      <td>0.420661</td>
      <td>-0.162872</td>
      <td>-0.788658</td>
      <td>-0.390513</td>
      <td>0.177015</td>
      <td>-0.112880</td>
      <td>0.202341</td>
      <td>0.179052</td>
      <td>0.885632</td>
      <td>0.330636</td>
      <td>-0.186828</td>
      <td>-1.062171</td>
      <td>0.559074</td>
      <td>0.346255</td>
      <td>0.517899</td>
      <td>0.274401</td>
      <td>1.170811</td>
      <td>0.026855</td>
      <td>1.384578</td>
      <td>0.548562</td>
      <td>1.040635</td>
      <td>0.010833</td>
      <td>-0.244026</td>
      <td>-0.446769</td>
      <td>-0.465897</td>
      <td>0.360940</td>
      <td>-0.509840</td>
      <td>-1.137278</td>
      <td>-1.537680</td>
      <td>-0.399661</td>
      <td>0.243552</td>
      <td>-0.542305</td>
      <td>0.060447</td>
      <td>0.590100</td>
      <td>-0.249195</td>
      <td>-0.392944</td>
      <td>-0.499895</td>
      <td>0.392734</td>
      <td>...</td>
      <td>0.884941</td>
      <td>-0.343940</td>
      <td>-0.069217</td>
      <td>0.065994</td>
      <td>0.004356</td>
      <td>0.175910</td>
      <td>-0.100779</td>
      <td>0.040348</td>
      <td>-0.609100</td>
      <td>-0.248235</td>
      <td>-0.501100</td>
      <td>0.061111</td>
      <td>0.350419</td>
      <td>-0.278031</td>
      <td>0.434040</td>
      <td>0.398336</td>
      <td>0.821499</td>
      <td>0.441967</td>
      <td>-0.295919</td>
      <td>0.185134</td>
      <td>-0.090520</td>
      <td>-0.842423</td>
      <td>-0.251419</td>
      <td>-1.866094</td>
      <td>-0.267183</td>
      <td>0.863013</td>
      <td>0.156556</td>
      <td>-0.131368</td>
      <td>-0.301478</td>
      <td>0.090875</td>
      <td>0.177120</td>
      <td>0.463549</td>
      <td>-0.482945</td>
      <td>-0.385475</td>
      <td>-0.149210</td>
      <td>-0.400440</td>
      <td>-0.335310</td>
      <td>0.024703</td>
      <td>-0.537450</td>
      <td>-0.314762</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.855885</td>
      <td>0.061908</td>
      <td>0.401163</td>
      <td>0.789956</td>
      <td>0.275979</td>
      <td>-0.063439</td>
      <td>-0.258155</td>
      <td>-0.263305</td>
      <td>-0.536788</td>
      <td>-0.361670</td>
      <td>0.897942</td>
      <td>-0.651971</td>
      <td>0.725024</td>
      <td>0.189494</td>
      <td>-1.208785</td>
      <td>-0.161758</td>
      <td>-0.521993</td>
      <td>0.267060</td>
      <td>1.188257</td>
      <td>0.404228</td>
      <td>0.225566</td>
      <td>0.537196</td>
      <td>-0.816898</td>
      <td>-0.814949</td>
      <td>-0.419901</td>
      <td>-0.495430</td>
      <td>-0.095713</td>
      <td>-0.656680</td>
      <td>-0.787604</td>
      <td>0.136032</td>
      <td>0.756263</td>
      <td>0.609928</td>
      <td>0.122373</td>
      <td>-0.359058</td>
      <td>-0.522666</td>
      <td>0.176194</td>
      <td>0.606343</td>
      <td>-0.038197</td>
      <td>-0.728584</td>
      <td>-0.084932</td>
      <td>...</td>
      <td>0.222152</td>
      <td>1.122103</td>
      <td>0.401889</td>
      <td>-0.446948</td>
      <td>-0.481684</td>
      <td>0.459153</td>
      <td>0.723788</td>
      <td>0.408343</td>
      <td>-0.279039</td>
      <td>0.325820</td>
      <td>0.170161</td>
      <td>-0.871118</td>
      <td>-0.100071</td>
      <td>-0.294775</td>
      <td>0.820585</td>
      <td>0.187919</td>
      <td>0.597917</td>
      <td>0.419625</td>
      <td>1.303603</td>
      <td>-0.764838</td>
      <td>-0.655052</td>
      <td>-1.239459</td>
      <td>0.150744</td>
      <td>-0.272324</td>
      <td>0.861396</td>
      <td>0.220048</td>
      <td>0.419283</td>
      <td>-0.188274</td>
      <td>0.282210</td>
      <td>-0.220182</td>
      <td>0.928494</td>
      <td>0.171091</td>
      <td>0.083785</td>
      <td>-2.114905</td>
      <td>0.055070</td>
      <td>-0.849488</td>
      <td>-0.215820</td>
      <td>0.676787</td>
      <td>0.327630</td>
      <td>0.479444</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-0.593385</td>
      <td>-0.179785</td>
      <td>0.177675</td>
      <td>-0.504582</td>
      <td>0.426041</td>
      <td>-0.857540</td>
      <td>0.044280</td>
      <td>0.149876</td>
      <td>0.287286</td>
      <td>-0.527506</td>
      <td>-0.620432</td>
      <td>-0.014278</td>
      <td>0.081207</td>
      <td>-0.527085</td>
      <td>0.114786</td>
      <td>-0.374853</td>
      <td>-0.168816</td>
      <td>0.621974</td>
      <td>0.030517</td>
      <td>-0.269177</td>
      <td>0.364746</td>
      <td>0.886133</td>
      <td>-0.359364</td>
      <td>0.195808</td>
      <td>-0.064081</td>
      <td>-0.466819</td>
      <td>-0.149790</td>
      <td>-0.283228</td>
      <td>0.457292</td>
      <td>0.513576</td>
      <td>0.662351</td>
      <td>0.443034</td>
      <td>0.250444</td>
      <td>-1.011005</td>
      <td>-0.304862</td>
      <td>-0.090700</td>
      <td>-0.625313</td>
      <td>-1.001517</td>
      <td>-1.013469</td>
      <td>-0.793458</td>
      <td>...</td>
      <td>0.144313</td>
      <td>0.222888</td>
      <td>0.757163</td>
      <td>-0.204414</td>
      <td>0.074817</td>
      <td>-0.681239</td>
      <td>-0.092043</td>
      <td>-0.381010</td>
      <td>-0.870622</td>
      <td>-0.670842</td>
      <td>-0.337234</td>
      <td>-0.577830</td>
      <td>-0.414654</td>
      <td>-0.617538</td>
      <td>0.252614</td>
      <td>0.316200</td>
      <td>0.718051</td>
      <td>1.383851</td>
      <td>-0.544618</td>
      <td>0.078032</td>
      <td>0.425111</td>
      <td>0.488594</td>
      <td>-0.683850</td>
      <td>0.029245</td>
      <td>-0.737403</td>
      <td>1.622418</td>
      <td>0.843211</td>
      <td>-0.162127</td>
      <td>-0.793739</td>
      <td>-0.348898</td>
      <td>0.455884</td>
      <td>-0.341089</td>
      <td>-1.052781</td>
      <td>-1.166704</td>
      <td>0.660434</td>
      <td>0.042220</td>
      <td>-0.202278</td>
      <td>-1.120530</td>
      <td>-0.234652</td>
      <td>0.098416</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.048588</td>
      <td>-0.283470</td>
      <td>-0.171924</td>
      <td>-0.972588</td>
      <td>-0.259578</td>
      <td>-0.354358</td>
      <td>-0.302840</td>
      <td>0.393565</td>
      <td>-0.591636</td>
      <td>-0.483737</td>
      <td>0.084678</td>
      <td>-0.596465</td>
      <td>-0.274290</td>
      <td>0.024476</td>
      <td>0.595272</td>
      <td>-0.411001</td>
      <td>-0.618609</td>
      <td>-0.396305</td>
      <td>-0.097598</td>
      <td>-0.684516</td>
      <td>0.117413</td>
      <td>0.920922</td>
      <td>0.053241</td>
      <td>-0.229561</td>
      <td>-0.859129</td>
      <td>0.590412</td>
      <td>0.175715</td>
      <td>-0.346049</td>
      <td>0.834691</td>
      <td>0.149286</td>
      <td>-0.699302</td>
      <td>-0.272149</td>
      <td>-0.407682</td>
      <td>-0.586558</td>
      <td>-0.271521</td>
      <td>-0.222769</td>
      <td>-0.158353</td>
      <td>-1.155674</td>
      <td>-0.167251</td>
      <td>-1.362913</td>
      <td>...</td>
      <td>0.555525</td>
      <td>-0.568771</td>
      <td>-0.217424</td>
      <td>0.328850</td>
      <td>-0.085261</td>
      <td>0.006635</td>
      <td>-1.131250</td>
      <td>1.360875</td>
      <td>1.147709</td>
      <td>0.525543</td>
      <td>0.394064</td>
      <td>-0.028174</td>
      <td>0.006368</td>
      <td>-0.667107</td>
      <td>0.613209</td>
      <td>-0.442590</td>
      <td>0.406269</td>
      <td>0.312773</td>
      <td>0.302562</td>
      <td>-0.147314</td>
      <td>-0.196538</td>
      <td>-0.709761</td>
      <td>-0.516985</td>
      <td>-0.432542</td>
      <td>-0.853164</td>
      <td>-0.377988</td>
      <td>-0.134710</td>
      <td>-0.679837</td>
      <td>-0.315412</td>
      <td>-0.901571</td>
      <td>0.514156</td>
      <td>-0.017924</td>
      <td>0.267583</td>
      <td>0.372739</td>
      <td>0.184933</td>
      <td>-0.285962</td>
      <td>0.164502</td>
      <td>-1.617614</td>
      <td>-1.288851</td>
      <td>-0.276184</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.263648</td>
      <td>-0.055812</td>
      <td>0.057730</td>
      <td>0.616852</td>
      <td>0.615732</td>
      <td>-0.346309</td>
      <td>0.521415</td>
      <td>-0.715227</td>
      <td>-0.776699</td>
      <td>-0.525993</td>
      <td>0.323784</td>
      <td>0.508374</td>
      <td>0.799614</td>
      <td>-1.023558</td>
      <td>-0.815376</td>
      <td>0.033622</td>
      <td>-0.570138</td>
      <td>-0.142977</td>
      <td>0.929791</td>
      <td>0.072850</td>
      <td>0.898537</td>
      <td>0.324859</td>
      <td>-0.064140</td>
      <td>-0.225882</td>
      <td>-0.435915</td>
      <td>0.340252</td>
      <td>1.095972</td>
      <td>0.566570</td>
      <td>1.359465</td>
      <td>1.232283</td>
      <td>-0.116844</td>
      <td>0.762527</td>
      <td>-0.152287</td>
      <td>-0.209223</td>
      <td>-0.635104</td>
      <td>-0.489567</td>
      <td>-0.351714</td>
      <td>-0.062581</td>
      <td>0.308356</td>
      <td>1.327071</td>
      <td>...</td>
      <td>0.613748</td>
      <td>1.001739</td>
      <td>-0.075670</td>
      <td>-1.618499</td>
      <td>-0.610465</td>
      <td>0.314805</td>
      <td>0.155686</td>
      <td>0.092702</td>
      <td>-0.204377</td>
      <td>0.367369</td>
      <td>-0.098515</td>
      <td>0.031720</td>
      <td>-0.142453</td>
      <td>-0.872062</td>
      <td>-0.539764</td>
      <td>0.802186</td>
      <td>1.038270</td>
      <td>0.975884</td>
      <td>0.873035</td>
      <td>0.025967</td>
      <td>-0.715673</td>
      <td>-0.111572</td>
      <td>-0.076873</td>
      <td>-0.172415</td>
      <td>-0.102887</td>
      <td>0.530194</td>
      <td>0.230285</td>
      <td>-0.482410</td>
      <td>0.671525</td>
      <td>-0.598496</td>
      <td>0.910691</td>
      <td>0.428469</td>
      <td>0.198203</td>
      <td>0.277903</td>
      <td>1.450912</td>
      <td>-0.144211</td>
      <td>0.754980</td>
      <td>-0.560873</td>
      <td>-0.444377</td>
      <td>0.732089</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.188093</td>
      <td>-0.340772</td>
      <td>-1.892994</td>
      <td>-0.802994</td>
      <td>0.055167</td>
      <td>0.347013</td>
      <td>0.435080</td>
      <td>0.253289</td>
      <td>-0.027253</td>
      <td>-1.160337</td>
      <td>0.567836</td>
      <td>-0.662399</td>
      <td>-0.666110</td>
      <td>-0.697361</td>
      <td>-0.317023</td>
      <td>0.513985</td>
      <td>-0.197281</td>
      <td>0.474138</td>
      <td>0.356603</td>
      <td>-0.340436</td>
      <td>-0.200577</td>
      <td>-0.303695</td>
      <td>0.943606</td>
      <td>-0.302696</td>
      <td>-0.483572</td>
      <td>0.295956</td>
      <td>0.390420</td>
      <td>0.036678</td>
      <td>0.749650</td>
      <td>0.235265</td>
      <td>-0.351928</td>
      <td>1.010644</td>
      <td>1.185910</td>
      <td>1.057428</td>
      <td>0.748026</td>
      <td>0.481099</td>
      <td>0.584871</td>
      <td>-0.895209</td>
      <td>-0.273777</td>
      <td>0.072797</td>
      <td>...</td>
      <td>0.397194</td>
      <td>1.073838</td>
      <td>0.396613</td>
      <td>0.175181</td>
      <td>0.545261</td>
      <td>0.010949</td>
      <td>0.752803</td>
      <td>0.418139</td>
      <td>0.212147</td>
      <td>-0.510500</td>
      <td>0.205045</td>
      <td>-0.933431</td>
      <td>1.402069</td>
      <td>0.807176</td>
      <td>0.644942</td>
      <td>0.495519</td>
      <td>1.028881</td>
      <td>0.000513</td>
      <td>-0.066171</td>
      <td>-0.576482</td>
      <td>0.640114</td>
      <td>-0.380658</td>
      <td>0.152605</td>
      <td>0.325125</td>
      <td>-0.014434</td>
      <td>0.949621</td>
      <td>-0.080894</td>
      <td>-0.158598</td>
      <td>-0.477896</td>
      <td>-0.688081</td>
      <td>0.461485</td>
      <td>-0.578620</td>
      <td>-0.318965</td>
      <td>-0.365420</td>
      <td>-0.058280</td>
      <td>-0.773876</td>
      <td>0.173825</td>
      <td>-1.835050</td>
      <td>-2.027854</td>
      <td>-0.870791</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.280434</td>
      <td>0.109840</td>
      <td>-0.240355</td>
      <td>0.079784</td>
      <td>0.142613</td>
      <td>-0.185274</td>
      <td>0.555557</td>
      <td>-0.822493</td>
      <td>0.425811</td>
      <td>-0.120692</td>
      <td>-0.250717</td>
      <td>-0.793866</td>
      <td>-0.658756</td>
      <td>-0.678914</td>
      <td>-0.380645</td>
      <td>-0.235739</td>
      <td>0.400963</td>
      <td>-0.365521</td>
      <td>1.044550</td>
      <td>-0.213671</td>
      <td>0.680079</td>
      <td>0.364272</td>
      <td>-0.231447</td>
      <td>-0.114450</td>
      <td>-0.620039</td>
      <td>0.770723</td>
      <td>0.510523</td>
      <td>0.053494</td>
      <td>-0.197118</td>
      <td>-1.036179</td>
      <td>-0.259468</td>
      <td>0.993356</td>
      <td>-0.156134</td>
      <td>0.842853</td>
      <td>0.483425</td>
      <td>-0.162449</td>
      <td>-0.113071</td>
      <td>-0.844646</td>
      <td>-0.272004</td>
      <td>0.674042</td>
      <td>...</td>
      <td>-0.065223</td>
      <td>0.511846</td>
      <td>-0.251698</td>
      <td>-0.015432</td>
      <td>0.285843</td>
      <td>0.373372</td>
      <td>-0.974924</td>
      <td>-0.336909</td>
      <td>-0.641397</td>
      <td>-0.343688</td>
      <td>0.136169</td>
      <td>-0.062337</td>
      <td>-0.117043</td>
      <td>-1.971591</td>
      <td>-0.875029</td>
      <td>-0.637595</td>
      <td>0.488472</td>
      <td>0.599399</td>
      <td>0.333472</td>
      <td>0.401391</td>
      <td>0.122149</td>
      <td>0.147564</td>
      <td>0.292492</td>
      <td>0.480976</td>
      <td>0.280538</td>
      <td>-0.533181</td>
      <td>0.771061</td>
      <td>-1.093805</td>
      <td>0.357968</td>
      <td>0.451634</td>
      <td>-0.004713</td>
      <td>-0.544403</td>
      <td>-0.516493</td>
      <td>0.277607</td>
      <td>0.525578</td>
      <td>-0.512994</td>
      <td>-0.167941</td>
      <td>-2.519768</td>
      <td>-1.659732</td>
      <td>-0.783672</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.068149</td>
      <td>0.255320</td>
      <td>-0.327637</td>
      <td>-0.325207</td>
      <td>0.121535</td>
      <td>0.112853</td>
      <td>0.361272</td>
      <td>-0.808725</td>
      <td>0.099392</td>
      <td>0.207017</td>
      <td>0.768684</td>
      <td>-0.536044</td>
      <td>-0.221421</td>
      <td>0.164054</td>
      <td>-0.413764</td>
      <td>0.089626</td>
      <td>0.167955</td>
      <td>1.608046</td>
      <td>-0.144511</td>
      <td>-0.475445</td>
      <td>0.589420</td>
      <td>0.422760</td>
      <td>1.735485</td>
      <td>-0.876401</td>
      <td>-1.071249</td>
      <td>0.171493</td>
      <td>0.424155</td>
      <td>-0.066302</td>
      <td>0.105427</td>
      <td>0.054966</td>
      <td>-0.260111</td>
      <td>-0.029834</td>
      <td>-0.356546</td>
      <td>0.261816</td>
      <td>0.572735</td>
      <td>0.519746</td>
      <td>-0.193084</td>
      <td>-0.979997</td>
      <td>-0.459985</td>
      <td>0.847557</td>
      <td>...</td>
      <td>0.877469</td>
      <td>-0.186341</td>
      <td>1.019220</td>
      <td>-0.421643</td>
      <td>0.422455</td>
      <td>-1.533999</td>
      <td>-0.176647</td>
      <td>0.673665</td>
      <td>0.482886</td>
      <td>-0.206314</td>
      <td>-0.921562</td>
      <td>0.079001</td>
      <td>-0.306622</td>
      <td>0.254398</td>
      <td>-0.038150</td>
      <td>-0.032908</td>
      <td>-0.847046</td>
      <td>0.657657</td>
      <td>0.385128</td>
      <td>-0.727956</td>
      <td>0.153351</td>
      <td>-0.831306</td>
      <td>-0.089288</td>
      <td>-0.225646</td>
      <td>-0.416404</td>
      <td>0.287575</td>
      <td>1.222775</td>
      <td>0.063228</td>
      <td>0.105994</td>
      <td>-0.367998</td>
      <td>0.675886</td>
      <td>0.117413</td>
      <td>-0.080765</td>
      <td>-0.485122</td>
      <td>0.490046</td>
      <td>-0.372052</td>
      <td>-0.485465</td>
      <td>0.407074</td>
      <td>0.348893</td>
      <td>0.275076</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.025121</td>
      <td>0.052931</td>
      <td>-0.053106</td>
      <td>-0.217539</td>
      <td>-0.225125</td>
      <td>-0.957047</td>
      <td>0.282554</td>
      <td>-0.126175</td>
      <td>0.406509</td>
      <td>0.072353</td>
      <td>0.292385</td>
      <td>0.258340</td>
      <td>-0.211393</td>
      <td>0.180086</td>
      <td>1.035071</td>
      <td>-0.037286</td>
      <td>0.382024</td>
      <td>1.182973</td>
      <td>0.311123</td>
      <td>-0.546949</td>
      <td>0.902805</td>
      <td>0.426050</td>
      <td>0.635180</td>
      <td>-0.067328</td>
      <td>-0.168682</td>
      <td>-0.345018</td>
      <td>0.938438</td>
      <td>0.377218</td>
      <td>1.141920</td>
      <td>0.023652</td>
      <td>0.221616</td>
      <td>0.328512</td>
      <td>-0.196088</td>
      <td>0.540891</td>
      <td>0.286971</td>
      <td>0.605825</td>
      <td>-0.327917</td>
      <td>-0.800370</td>
      <td>-0.592770</td>
      <td>-0.771444</td>
      <td>...</td>
      <td>0.000012</td>
      <td>0.003686</td>
      <td>0.314147</td>
      <td>-1.769912</td>
      <td>-0.339225</td>
      <td>-1.006431</td>
      <td>-0.731189</td>
      <td>0.016457</td>
      <td>-0.095058</td>
      <td>-0.719563</td>
      <td>-0.447747</td>
      <td>-0.424787</td>
      <td>-0.218501</td>
      <td>-0.802787</td>
      <td>-1.075860</td>
      <td>0.443703</td>
      <td>1.025478</td>
      <td>0.652907</td>
      <td>0.467329</td>
      <td>0.279369</td>
      <td>0.094864</td>
      <td>-0.594788</td>
      <td>0.224444</td>
      <td>-0.384054</td>
      <td>-0.760512</td>
      <td>0.489115</td>
      <td>0.631536</td>
      <td>0.156571</td>
      <td>0.158118</td>
      <td>0.445795</td>
      <td>0.100825</td>
      <td>0.467772</td>
      <td>-0.005699</td>
      <td>-0.469429</td>
      <td>1.088885</td>
      <td>0.098655</td>
      <td>0.292314</td>
      <td>-2.041533</td>
      <td>-1.386449</td>
      <td>-0.873579</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.434351</td>
      <td>0.823169</td>
      <td>-0.615783</td>
      <td>-0.171136</td>
      <td>-0.210118</td>
      <td>-1.283485</td>
      <td>-0.552719</td>
      <td>-0.388476</td>
      <td>0.510814</td>
      <td>-0.668677</td>
      <td>0.582447</td>
      <td>0.025117</td>
      <td>0.484599</td>
      <td>-0.438210</td>
      <td>0.648919</td>
      <td>0.799981</td>
      <td>-0.481268</td>
      <td>0.493198</td>
      <td>1.115844</td>
      <td>-0.073441</td>
      <td>-0.363745</td>
      <td>0.069177</td>
      <td>0.423663</td>
      <td>-0.429054</td>
      <td>-0.278242</td>
      <td>0.815118</td>
      <td>0.080949</td>
      <td>0.336585</td>
      <td>-0.174493</td>
      <td>-0.105656</td>
      <td>-0.687327</td>
      <td>0.643837</td>
      <td>-0.824442</td>
      <td>0.503327</td>
      <td>-0.402261</td>
      <td>-0.565932</td>
      <td>1.215342</td>
      <td>1.042434</td>
      <td>0.501274</td>
      <td>-0.003866</td>
      <td>...</td>
      <td>0.815243</td>
      <td>0.396393</td>
      <td>0.175777</td>
      <td>-1.623615</td>
      <td>-0.124567</td>
      <td>-0.016957</td>
      <td>0.317232</td>
      <td>0.600108</td>
      <td>0.090586</td>
      <td>-0.915548</td>
      <td>-2.014164</td>
      <td>-1.004114</td>
      <td>-0.669887</td>
      <td>-1.078845</td>
      <td>0.766839</td>
      <td>0.924220</td>
      <td>0.696903</td>
      <td>0.429635</td>
      <td>1.066164</td>
      <td>0.746390</td>
      <td>1.676376</td>
      <td>1.060241</td>
      <td>0.795335</td>
      <td>0.497209</td>
      <td>-0.416263</td>
      <td>0.955929</td>
      <td>0.442753</td>
      <td>0.711411</td>
      <td>0.018850</td>
      <td>-1.532006</td>
      <td>0.250222</td>
      <td>0.465220</td>
      <td>0.654161</td>
      <td>-1.043654</td>
      <td>-0.182479</td>
      <td>0.599120</td>
      <td>0.050168</td>
      <td>1.103850</td>
      <td>-0.171562</td>
      <td>0.290022</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.585721</td>
      <td>-0.183424</td>
      <td>0.032461</td>
      <td>-0.538233</td>
      <td>-0.259514</td>
      <td>0.140586</td>
      <td>-0.254142</td>
      <td>-0.323829</td>
      <td>0.106182</td>
      <td>-0.674738</td>
      <td>-0.041425</td>
      <td>-0.424000</td>
      <td>-0.414911</td>
      <td>0.377889</td>
      <td>-0.414916</td>
      <td>0.400486</td>
      <td>-0.311784</td>
      <td>0.093330</td>
      <td>-0.650196</td>
      <td>-1.378826</td>
      <td>0.346112</td>
      <td>0.646350</td>
      <td>0.561230</td>
      <td>0.178127</td>
      <td>-0.242263</td>
      <td>-0.313873</td>
      <td>0.124797</td>
      <td>-0.222378</td>
      <td>0.031303</td>
      <td>-0.536147</td>
      <td>0.562733</td>
      <td>0.390540</td>
      <td>-0.130338</td>
      <td>-0.246010</td>
      <td>0.530351</td>
      <td>0.757387</td>
      <td>0.052170</td>
      <td>-0.647582</td>
      <td>-0.447506</td>
      <td>0.853700</td>
      <td>...</td>
      <td>-0.621082</td>
      <td>-0.734865</td>
      <td>-0.539934</td>
      <td>-0.591373</td>
      <td>-0.832033</td>
      <td>0.321849</td>
      <td>0.087971</td>
      <td>1.221183</td>
      <td>0.437191</td>
      <td>0.134911</td>
      <td>-0.162298</td>
      <td>0.070172</td>
      <td>0.056201</td>
      <td>-0.327685</td>
      <td>1.148019</td>
      <td>0.714593</td>
      <td>0.141274</td>
      <td>0.367089</td>
      <td>0.275756</td>
      <td>-0.206780</td>
      <td>0.624882</td>
      <td>0.576680</td>
      <td>-0.261062</td>
      <td>0.339803</td>
      <td>-0.023341</td>
      <td>0.617409</td>
      <td>0.979059</td>
      <td>0.065956</td>
      <td>-0.368578</td>
      <td>-0.651918</td>
      <td>0.699828</td>
      <td>0.511740</td>
      <td>0.686445</td>
      <td>0.554429</td>
      <td>0.654263</td>
      <td>0.507203</td>
      <td>1.052407</td>
      <td>0.121920</td>
      <td>-0.585962</td>
      <td>-0.470784</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.412692</td>
      <td>-0.163982</td>
      <td>-0.352118</td>
      <td>-0.112706</td>
      <td>-0.923957</td>
      <td>-1.036147</td>
      <td>-0.952044</td>
      <td>0.152939</td>
      <td>-0.028262</td>
      <td>0.505674</td>
      <td>-0.475154</td>
      <td>0.848083</td>
      <td>-0.099316</td>
      <td>0.307157</td>
      <td>-0.137088</td>
      <td>0.635315</td>
      <td>0.115389</td>
      <td>0.157983</td>
      <td>0.024211</td>
      <td>-0.516791</td>
      <td>-0.724518</td>
      <td>-0.555575</td>
      <td>-0.505728</td>
      <td>-0.443593</td>
      <td>1.024335</td>
      <td>-1.089700</td>
      <td>-0.200538</td>
      <td>-0.630236</td>
      <td>0.262761</td>
      <td>-0.726691</td>
      <td>0.169303</td>
      <td>0.437078</td>
      <td>-0.061081</td>
      <td>-0.336353</td>
      <td>0.091021</td>
      <td>-0.151246</td>
      <td>-0.534074</td>
      <td>-0.456924</td>
      <td>0.183610</td>
      <td>0.278033</td>
      <td>...</td>
      <td>-1.247770</td>
      <td>0.707170</td>
      <td>0.098748</td>
      <td>-0.096909</td>
      <td>-0.104760</td>
      <td>0.073637</td>
      <td>0.086787</td>
      <td>0.519256</td>
      <td>0.317034</td>
      <td>0.276772</td>
      <td>0.018716</td>
      <td>0.381367</td>
      <td>-0.111641</td>
      <td>0.932524</td>
      <td>-0.093939</td>
      <td>0.400441</td>
      <td>0.814625</td>
      <td>0.682439</td>
      <td>-0.431146</td>
      <td>-0.271850</td>
      <td>0.815420</td>
      <td>-0.385556</td>
      <td>0.539454</td>
      <td>0.537369</td>
      <td>-0.298076</td>
      <td>0.909573</td>
      <td>-0.176414</td>
      <td>-0.429003</td>
      <td>-1.463650</td>
      <td>-1.007398</td>
      <td>-0.543177</td>
      <td>-0.773535</td>
      <td>0.490210</td>
      <td>1.227290</td>
      <td>0.544906</td>
      <td>0.498925</td>
      <td>-0.129740</td>
      <td>-1.671205</td>
      <td>-1.125239</td>
      <td>-1.062414</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.963194</td>
      <td>0.037187</td>
      <td>-0.028983</td>
      <td>0.527183</td>
      <td>-0.022412</td>
      <td>-0.458362</td>
      <td>0.861811</td>
      <td>0.602996</td>
      <td>0.550359</td>
      <td>0.070164</td>
      <td>-0.398745</td>
      <td>-0.465319</td>
      <td>-0.101938</td>
      <td>0.919661</td>
      <td>-0.060522</td>
      <td>-0.054115</td>
      <td>-0.352509</td>
      <td>0.714775</td>
      <td>0.342307</td>
      <td>-0.064293</td>
      <td>0.731653</td>
      <td>-0.072128</td>
      <td>0.584032</td>
      <td>-0.098522</td>
      <td>-0.155734</td>
      <td>-0.859366</td>
      <td>0.802594</td>
      <td>0.567734</td>
      <td>0.727541</td>
      <td>-0.352262</td>
      <td>0.729087</td>
      <td>-0.220504</td>
      <td>0.109702</td>
      <td>-0.299789</td>
      <td>-0.972033</td>
      <td>-1.608125</td>
      <td>-0.306023</td>
      <td>-0.313698</td>
      <td>-0.487994</td>
      <td>-0.125206</td>
      <td>...</td>
      <td>-0.698514</td>
      <td>-0.223688</td>
      <td>0.062898</td>
      <td>-0.089037</td>
      <td>0.355348</td>
      <td>0.817791</td>
      <td>0.326557</td>
      <td>0.740079</td>
      <td>-1.042033</td>
      <td>-0.625250</td>
      <td>0.230747</td>
      <td>0.163894</td>
      <td>0.311482</td>
      <td>0.756861</td>
      <td>-0.415669</td>
      <td>0.620794</td>
      <td>-0.648080</td>
      <td>-0.270612</td>
      <td>-0.046848</td>
      <td>0.168104</td>
      <td>0.345499</td>
      <td>0.520957</td>
      <td>0.836371</td>
      <td>0.066695</td>
      <td>0.356320</td>
      <td>0.750201</td>
      <td>-0.004446</td>
      <td>0.450705</td>
      <td>0.046056</td>
      <td>-0.143893</td>
      <td>0.535836</td>
      <td>-0.058658</td>
      <td>0.799247</td>
      <td>0.933966</td>
      <td>0.573556</td>
      <td>0.295889</td>
      <td>-0.417113</td>
      <td>1.456872</td>
      <td>0.750365</td>
      <td>0.077980</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.352530</td>
      <td>-0.631857</td>
      <td>0.199645</td>
      <td>0.576477</td>
      <td>0.681821</td>
      <td>0.297170</td>
      <td>0.905422</td>
      <td>0.397955</td>
      <td>0.942900</td>
      <td>0.545415</td>
      <td>0.320615</td>
      <td>-0.744253</td>
      <td>0.697760</td>
      <td>-0.068341</td>
      <td>0.771404</td>
      <td>1.133455</td>
      <td>0.599920</td>
      <td>0.378692</td>
      <td>0.863343</td>
      <td>1.302282</td>
      <td>1.341753</td>
      <td>0.308870</td>
      <td>0.243390</td>
      <td>-0.548615</td>
      <td>0.322406</td>
      <td>-0.027101</td>
      <td>0.198156</td>
      <td>0.691398</td>
      <td>-0.690164</td>
      <td>-0.361376</td>
      <td>0.585227</td>
      <td>-0.792840</td>
      <td>0.012457</td>
      <td>-0.573754</td>
      <td>0.062558</td>
      <td>-0.363678</td>
      <td>-0.081710</td>
      <td>0.571481</td>
      <td>0.214905</td>
      <td>1.258097</td>
      <td>...</td>
      <td>1.047406</td>
      <td>0.797728</td>
      <td>1.088924</td>
      <td>-0.072157</td>
      <td>0.136889</td>
      <td>0.736397</td>
      <td>-1.106653</td>
      <td>0.093748</td>
      <td>-0.085669</td>
      <td>-0.989169</td>
      <td>-0.570826</td>
      <td>0.345628</td>
      <td>-0.036557</td>
      <td>-1.273848</td>
      <td>-0.504548</td>
      <td>-0.257398</td>
      <td>-0.245543</td>
      <td>-0.876701</td>
      <td>0.579505</td>
      <td>-0.715934</td>
      <td>-0.800939</td>
      <td>-0.753470</td>
      <td>0.074259</td>
      <td>-1.524393</td>
      <td>-0.373459</td>
      <td>-0.575289</td>
      <td>0.490939</td>
      <td>-0.323163</td>
      <td>-1.203065</td>
      <td>-0.234607</td>
      <td>-0.930725</td>
      <td>-0.932845</td>
      <td>-0.091045</td>
      <td>-0.054160</td>
      <td>-0.840785</td>
      <td>0.191846</td>
      <td>-0.849568</td>
      <td>3.247975</td>
      <td>1.635276</td>
      <td>1.419031</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.042049</td>
      <td>-0.573902</td>
      <td>-0.132786</td>
      <td>-1.281028</td>
      <td>-0.377888</td>
      <td>-0.749913</td>
      <td>0.123582</td>
      <td>0.259899</td>
      <td>-0.208229</td>
      <td>0.305026</td>
      <td>0.060975</td>
      <td>0.126399</td>
      <td>0.331396</td>
      <td>1.027921</td>
      <td>0.855162</td>
      <td>0.875056</td>
      <td>-0.138303</td>
      <td>-0.631110</td>
      <td>1.350453</td>
      <td>0.079819</td>
      <td>0.548901</td>
      <td>-0.127319</td>
      <td>0.096969</td>
      <td>0.201343</td>
      <td>-0.299787</td>
      <td>-0.476647</td>
      <td>-0.169500</td>
      <td>0.444772</td>
      <td>-0.836608</td>
      <td>-0.188055</td>
      <td>-0.053646</td>
      <td>-0.379871</td>
      <td>1.004089</td>
      <td>-0.887671</td>
      <td>-1.158456</td>
      <td>-1.332634</td>
      <td>-0.244743</td>
      <td>0.973240</td>
      <td>0.321309</td>
      <td>0.036010</td>
      <td>...</td>
      <td>0.409038</td>
      <td>0.681779</td>
      <td>-1.001113</td>
      <td>-0.938084</td>
      <td>0.008408</td>
      <td>-0.433685</td>
      <td>0.010245</td>
      <td>1.149917</td>
      <td>-0.173608</td>
      <td>0.461424</td>
      <td>-0.134646</td>
      <td>0.992214</td>
      <td>-0.397390</td>
      <td>-0.292758</td>
      <td>-1.050178</td>
      <td>-0.344508</td>
      <td>-0.714084</td>
      <td>-0.977921</td>
      <td>-0.990138</td>
      <td>-0.279226</td>
      <td>1.114187</td>
      <td>0.377732</td>
      <td>0.703692</td>
      <td>0.116594</td>
      <td>-0.092098</td>
      <td>-0.512542</td>
      <td>-0.104715</td>
      <td>-1.021707</td>
      <td>-0.163429</td>
      <td>-0.327049</td>
      <td>0.306612</td>
      <td>0.042560</td>
      <td>-0.287110</td>
      <td>0.605185</td>
      <td>-0.070282</td>
      <td>0.186263</td>
      <td>0.151479</td>
      <td>-1.765775</td>
      <td>-1.091673</td>
      <td>-0.515742</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.473961</td>
      <td>0.128411</td>
      <td>-0.831174</td>
      <td>-1.057996</td>
      <td>-0.415172</td>
      <td>1.243773</td>
      <td>0.800617</td>
      <td>0.851209</td>
      <td>2.279090</td>
      <td>0.558371</td>
      <td>0.314284</td>
      <td>0.641906</td>
      <td>-0.196693</td>
      <td>1.409512</td>
      <td>0.769964</td>
      <td>0.125271</td>
      <td>0.888480</td>
      <td>-0.087661</td>
      <td>1.746732</td>
      <td>0.681577</td>
      <td>0.738194</td>
      <td>0.981669</td>
      <td>-0.138877</td>
      <td>0.062864</td>
      <td>0.496909</td>
      <td>0.916957</td>
      <td>0.762080</td>
      <td>0.276945</td>
      <td>0.163266</td>
      <td>0.178737</td>
      <td>-0.072740</td>
      <td>-0.269136</td>
      <td>-0.347787</td>
      <td>-0.334868</td>
      <td>0.164490</td>
      <td>0.164332</td>
      <td>0.253293</td>
      <td>0.537719</td>
      <td>0.233081</td>
      <td>0.749115</td>
      <td>...</td>
      <td>-0.176176</td>
      <td>0.377066</td>
      <td>0.065346</td>
      <td>0.559602</td>
      <td>-0.077092</td>
      <td>-0.204410</td>
      <td>0.622847</td>
      <td>0.510879</td>
      <td>-0.215342</td>
      <td>0.573012</td>
      <td>-0.462035</td>
      <td>0.654903</td>
      <td>-0.526540</td>
      <td>-0.608326</td>
      <td>0.017826</td>
      <td>0.049910</td>
      <td>0.328825</td>
      <td>-0.636205</td>
      <td>0.102186</td>
      <td>0.205741</td>
      <td>0.848977</td>
      <td>0.540674</td>
      <td>0.182999</td>
      <td>0.897229</td>
      <td>-0.429570</td>
      <td>-0.125979</td>
      <td>0.394692</td>
      <td>-0.259519</td>
      <td>0.420774</td>
      <td>-0.098162</td>
      <td>-0.795412</td>
      <td>0.202557</td>
      <td>-0.033983</td>
      <td>-0.679332</td>
      <td>0.620568</td>
      <td>0.735324</td>
      <td>-1.038771</td>
      <td>-0.749723</td>
      <td>-0.547986</td>
      <td>-0.939653</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f0204de1100&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err         t          P&gt;|t|     2.5 %   97.5 %
D  1.030703  0.045372  22.71671  3.063090e-114  0.941775  1.11963
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.409 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.4.0.<br/>
    </p>
  </div>
</footer>
  </body>
</html>