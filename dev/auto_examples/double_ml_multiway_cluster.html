
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="http://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>     to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-0.039932</td>
      <td>0.489216</td>
      <td>-0.094793</td>
      <td>0.739464</td>
      <td>-0.063458</td>
      <td>0.445694</td>
      <td>0.349741</td>
      <td>-0.129576</td>
      <td>0.076776</td>
      <td>-1.598478</td>
      <td>-0.082594</td>
      <td>-0.314299</td>
      <td>-0.189108</td>
      <td>-0.321287</td>
      <td>-1.025059</td>
      <td>0.259590</td>
      <td>0.491599</td>
      <td>0.006149</td>
      <td>-0.392871</td>
      <td>-0.389840</td>
      <td>-0.660796</td>
      <td>-0.109707</td>
      <td>0.773486</td>
      <td>0.299069</td>
      <td>-0.388304</td>
      <td>0.015503</td>
      <td>0.015491</td>
      <td>0.301974</td>
      <td>-0.247660</td>
      <td>0.827454</td>
      <td>-0.272097</td>
      <td>1.214637</td>
      <td>0.277457</td>
      <td>-0.612402</td>
      <td>-0.633704</td>
      <td>-0.276576</td>
      <td>0.145660</td>
      <td>-0.603635</td>
      <td>0.367702</td>
      <td>-0.280182</td>
      <td>...</td>
      <td>0.284290</td>
      <td>0.661952</td>
      <td>-0.195022</td>
      <td>-0.330487</td>
      <td>-0.108597</td>
      <td>0.145757</td>
      <td>0.412816</td>
      <td>0.562006</td>
      <td>1.322829</td>
      <td>1.664121</td>
      <td>-0.065587</td>
      <td>-0.501863</td>
      <td>-0.187532</td>
      <td>-0.335809</td>
      <td>0.768475</td>
      <td>0.341047</td>
      <td>-0.133319</td>
      <td>-0.458703</td>
      <td>1.136085</td>
      <td>-0.476318</td>
      <td>-0.782289</td>
      <td>0.125183</td>
      <td>-0.566534</td>
      <td>0.745831</td>
      <td>-0.156154</td>
      <td>-0.834773</td>
      <td>-0.291418</td>
      <td>-0.881012</td>
      <td>-1.432896</td>
      <td>-0.394354</td>
      <td>-0.491320</td>
      <td>-0.441558</td>
      <td>0.094235</td>
      <td>-0.317059</td>
      <td>-0.166269</td>
      <td>-0.731314</td>
      <td>-0.242292</td>
      <td>-0.674686</td>
      <td>0.636445</td>
      <td>-0.032298</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.365257</td>
      <td>-0.307036</td>
      <td>0.192824</td>
      <td>0.924880</td>
      <td>-0.084040</td>
      <td>0.113048</td>
      <td>1.086003</td>
      <td>-0.011018</td>
      <td>-0.817941</td>
      <td>-0.115983</td>
      <td>-0.329482</td>
      <td>-0.686336</td>
      <td>-0.629816</td>
      <td>-0.035654</td>
      <td>-0.368329</td>
      <td>0.764121</td>
      <td>-0.549650</td>
      <td>-0.070849</td>
      <td>0.348098</td>
      <td>0.074317</td>
      <td>-0.586348</td>
      <td>0.649829</td>
      <td>-0.666859</td>
      <td>-0.809667</td>
      <td>0.707339</td>
      <td>0.991678</td>
      <td>-0.593277</td>
      <td>-0.720127</td>
      <td>-0.684403</td>
      <td>0.237655</td>
      <td>-0.375457</td>
      <td>-0.203423</td>
      <td>0.854683</td>
      <td>-0.597264</td>
      <td>0.460453</td>
      <td>-0.295528</td>
      <td>-1.400371</td>
      <td>-0.493945</td>
      <td>0.901639</td>
      <td>0.772591</td>
      <td>...</td>
      <td>1.060287</td>
      <td>1.240172</td>
      <td>-0.878594</td>
      <td>-0.414203</td>
      <td>0.300425</td>
      <td>0.080389</td>
      <td>-0.754386</td>
      <td>0.645904</td>
      <td>0.558850</td>
      <td>0.783073</td>
      <td>0.555037</td>
      <td>0.328336</td>
      <td>0.622745</td>
      <td>-0.415230</td>
      <td>0.813883</td>
      <td>1.490478</td>
      <td>-0.037521</td>
      <td>-0.546999</td>
      <td>-0.128030</td>
      <td>-0.478219</td>
      <td>-0.650883</td>
      <td>1.018189</td>
      <td>1.025709</td>
      <td>-0.901784</td>
      <td>-0.683940</td>
      <td>-1.079906</td>
      <td>-0.220535</td>
      <td>0.173944</td>
      <td>-0.419597</td>
      <td>-1.570840</td>
      <td>-0.003568</td>
      <td>0.841709</td>
      <td>0.445689</td>
      <td>-1.004306</td>
      <td>-0.206973</td>
      <td>-0.290267</td>
      <td>-0.486598</td>
      <td>-1.014362</td>
      <td>-0.551413</td>
      <td>-0.954889</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.458638</td>
      <td>0.126958</td>
      <td>-0.828411</td>
      <td>0.819240</td>
      <td>0.332663</td>
      <td>0.026037</td>
      <td>0.095300</td>
      <td>-1.251344</td>
      <td>-1.035209</td>
      <td>-1.070228</td>
      <td>-0.907854</td>
      <td>-0.307092</td>
      <td>-0.219434</td>
      <td>-0.226347</td>
      <td>-0.161373</td>
      <td>0.634786</td>
      <td>0.107470</td>
      <td>0.979330</td>
      <td>0.060241</td>
      <td>0.058510</td>
      <td>-0.799483</td>
      <td>0.411000</td>
      <td>0.335233</td>
      <td>1.228163</td>
      <td>-0.263499</td>
      <td>0.584559</td>
      <td>0.128278</td>
      <td>0.540937</td>
      <td>-0.542482</td>
      <td>-0.279237</td>
      <td>0.230298</td>
      <td>1.495122</td>
      <td>1.694494</td>
      <td>-0.114916</td>
      <td>-0.060126</td>
      <td>-0.235598</td>
      <td>1.167038</td>
      <td>0.025434</td>
      <td>0.196078</td>
      <td>0.180768</td>
      <td>...</td>
      <td>0.604952</td>
      <td>0.483905</td>
      <td>0.377251</td>
      <td>0.282518</td>
      <td>1.013598</td>
      <td>0.777282</td>
      <td>0.555470</td>
      <td>0.117589</td>
      <td>-0.723104</td>
      <td>1.260047</td>
      <td>0.184961</td>
      <td>-1.069130</td>
      <td>0.867532</td>
      <td>-0.239828</td>
      <td>-0.466872</td>
      <td>-0.172058</td>
      <td>-0.667991</td>
      <td>0.182857</td>
      <td>0.287230</td>
      <td>-0.210531</td>
      <td>-0.414161</td>
      <td>0.510882</td>
      <td>1.256018</td>
      <td>1.607283</td>
      <td>-0.335777</td>
      <td>-0.095645</td>
      <td>-0.424996</td>
      <td>-0.239839</td>
      <td>-0.545568</td>
      <td>-0.769445</td>
      <td>0.033029</td>
      <td>0.271814</td>
      <td>-0.290583</td>
      <td>-0.047084</td>
      <td>-0.846304</td>
      <td>0.409870</td>
      <td>0.450231</td>
      <td>-0.044745</td>
      <td>-0.150582</td>
      <td>-0.259587</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.757119</td>
      <td>-0.868409</td>
      <td>-0.023637</td>
      <td>0.149935</td>
      <td>-0.323051</td>
      <td>-0.059656</td>
      <td>0.087099</td>
      <td>0.383687</td>
      <td>0.023367</td>
      <td>0.087521</td>
      <td>0.028148</td>
      <td>-0.976448</td>
      <td>0.369593</td>
      <td>0.303473</td>
      <td>0.190650</td>
      <td>0.459272</td>
      <td>0.478429</td>
      <td>1.356793</td>
      <td>0.451837</td>
      <td>0.193039</td>
      <td>-0.706407</td>
      <td>-0.183140</td>
      <td>0.146806</td>
      <td>-0.127151</td>
      <td>0.385804</td>
      <td>0.374716</td>
      <td>0.359975</td>
      <td>-0.196680</td>
      <td>0.306099</td>
      <td>-0.217801</td>
      <td>0.694151</td>
      <td>-0.123532</td>
      <td>0.346578</td>
      <td>0.044281</td>
      <td>-1.021511</td>
      <td>-0.760361</td>
      <td>-0.625318</td>
      <td>-0.141111</td>
      <td>-0.417937</td>
      <td>0.135354</td>
      <td>...</td>
      <td>-0.526917</td>
      <td>-0.596396</td>
      <td>0.198848</td>
      <td>-1.263074</td>
      <td>-0.294130</td>
      <td>-0.044860</td>
      <td>-0.389174</td>
      <td>0.274685</td>
      <td>-0.702117</td>
      <td>-0.339199</td>
      <td>0.042491</td>
      <td>-0.325316</td>
      <td>0.002243</td>
      <td>-0.664610</td>
      <td>0.295649</td>
      <td>0.217143</td>
      <td>-0.024699</td>
      <td>-0.013406</td>
      <td>0.516746</td>
      <td>0.206930</td>
      <td>0.564191</td>
      <td>-0.305940</td>
      <td>-0.104797</td>
      <td>0.311774</td>
      <td>-0.464519</td>
      <td>-0.154090</td>
      <td>0.025715</td>
      <td>0.692124</td>
      <td>-0.124663</td>
      <td>-0.164331</td>
      <td>-0.333121</td>
      <td>-0.516161</td>
      <td>-0.289926</td>
      <td>-0.151096</td>
      <td>0.485061</td>
      <td>-0.213600</td>
      <td>-0.423822</td>
      <td>1.244974</td>
      <td>0.372871</td>
      <td>0.308220</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.090967</td>
      <td>0.603280</td>
      <td>0.150287</td>
      <td>0.476122</td>
      <td>0.493919</td>
      <td>0.320784</td>
      <td>0.226903</td>
      <td>0.213785</td>
      <td>-0.192392</td>
      <td>0.449631</td>
      <td>-0.062568</td>
      <td>0.278176</td>
      <td>-1.058906</td>
      <td>-0.505370</td>
      <td>-0.827296</td>
      <td>-0.119778</td>
      <td>0.274880</td>
      <td>-0.545221</td>
      <td>-0.089186</td>
      <td>0.112412</td>
      <td>-0.982958</td>
      <td>0.562894</td>
      <td>0.119948</td>
      <td>0.213165</td>
      <td>0.582019</td>
      <td>-0.054187</td>
      <td>0.677604</td>
      <td>0.153740</td>
      <td>-0.911603</td>
      <td>-0.039735</td>
      <td>1.671345</td>
      <td>0.622041</td>
      <td>-0.042577</td>
      <td>-0.706895</td>
      <td>-1.091339</td>
      <td>0.284284</td>
      <td>1.058657</td>
      <td>0.228136</td>
      <td>0.499117</td>
      <td>0.277430</td>
      <td>...</td>
      <td>-0.203201</td>
      <td>-0.082432</td>
      <td>0.444443</td>
      <td>-1.062837</td>
      <td>-1.595570</td>
      <td>-0.378274</td>
      <td>-0.591826</td>
      <td>0.520117</td>
      <td>-0.033310</td>
      <td>0.603081</td>
      <td>-0.096875</td>
      <td>0.695616</td>
      <td>1.339279</td>
      <td>-0.354616</td>
      <td>1.239571</td>
      <td>0.573590</td>
      <td>1.105265</td>
      <td>0.564419</td>
      <td>0.299990</td>
      <td>0.525706</td>
      <td>0.534753</td>
      <td>0.432350</td>
      <td>-0.187423</td>
      <td>0.890804</td>
      <td>-1.028149</td>
      <td>-1.349728</td>
      <td>-0.432694</td>
      <td>0.822866</td>
      <td>0.469124</td>
      <td>-0.196757</td>
      <td>-0.304209</td>
      <td>-0.135642</td>
      <td>-0.784088</td>
      <td>0.566376</td>
      <td>-0.031825</td>
      <td>-0.466286</td>
      <td>0.984212</td>
      <td>1.251698</td>
      <td>1.329557</td>
      <td>1.223967</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.034587</td>
      <td>-0.324514</td>
      <td>0.079872</td>
      <td>0.838729</td>
      <td>-0.412984</td>
      <td>-0.284953</td>
      <td>-0.124784</td>
      <td>-0.853814</td>
      <td>0.246589</td>
      <td>0.763206</td>
      <td>-0.052325</td>
      <td>-0.429433</td>
      <td>-0.821545</td>
      <td>0.311674</td>
      <td>0.613626</td>
      <td>-0.271536</td>
      <td>0.146586</td>
      <td>-0.725237</td>
      <td>-0.807494</td>
      <td>-1.315704</td>
      <td>-0.802173</td>
      <td>-0.549272</td>
      <td>-0.874608</td>
      <td>-1.289915</td>
      <td>0.047391</td>
      <td>0.560780</td>
      <td>0.098736</td>
      <td>0.315874</td>
      <td>-0.141131</td>
      <td>-0.075599</td>
      <td>0.992347</td>
      <td>-0.525931</td>
      <td>1.114330</td>
      <td>-0.167435</td>
      <td>-0.393183</td>
      <td>-0.794110</td>
      <td>-0.277821</td>
      <td>1.274879</td>
      <td>0.736157</td>
      <td>-0.441779</td>
      <td>...</td>
      <td>-0.062822</td>
      <td>0.964494</td>
      <td>0.437412</td>
      <td>0.067742</td>
      <td>0.788395</td>
      <td>1.135799</td>
      <td>-0.338538</td>
      <td>0.525340</td>
      <td>0.128468</td>
      <td>-0.519219</td>
      <td>0.592763</td>
      <td>1.747575</td>
      <td>1.408563</td>
      <td>-0.001182</td>
      <td>-0.090302</td>
      <td>-0.298218</td>
      <td>-0.141877</td>
      <td>-0.307846</td>
      <td>-0.618025</td>
      <td>-1.439136</td>
      <td>-0.712993</td>
      <td>0.693121</td>
      <td>-0.669929</td>
      <td>0.314456</td>
      <td>-0.472264</td>
      <td>-0.057410</td>
      <td>-0.795103</td>
      <td>0.562837</td>
      <td>-0.142862</td>
      <td>-0.357032</td>
      <td>0.775054</td>
      <td>0.307204</td>
      <td>-0.864654</td>
      <td>-0.195104</td>
      <td>0.332974</td>
      <td>-0.712923</td>
      <td>0.128906</td>
      <td>-0.768747</td>
      <td>-0.561851</td>
      <td>0.556284</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.773787</td>
      <td>0.329516</td>
      <td>0.937448</td>
      <td>0.869041</td>
      <td>0.181758</td>
      <td>-0.185718</td>
      <td>-0.965502</td>
      <td>-0.767501</td>
      <td>-1.077166</td>
      <td>0.681736</td>
      <td>0.680567</td>
      <td>0.570245</td>
      <td>0.171416</td>
      <td>-0.851508</td>
      <td>-0.482986</td>
      <td>-0.212097</td>
      <td>-0.721901</td>
      <td>-0.645815</td>
      <td>-0.309381</td>
      <td>0.815467</td>
      <td>-1.153111</td>
      <td>-1.231899</td>
      <td>-1.262645</td>
      <td>0.123814</td>
      <td>0.533049</td>
      <td>0.476450</td>
      <td>0.144462</td>
      <td>0.678787</td>
      <td>0.132050</td>
      <td>-0.028901</td>
      <td>0.277132</td>
      <td>-0.244585</td>
      <td>1.047713</td>
      <td>0.728227</td>
      <td>-0.362860</td>
      <td>-0.013856</td>
      <td>-0.839490</td>
      <td>0.358787</td>
      <td>0.470352</td>
      <td>0.499940</td>
      <td>...</td>
      <td>0.788145</td>
      <td>1.870718</td>
      <td>-1.026379</td>
      <td>-0.873859</td>
      <td>-0.379660</td>
      <td>-0.318392</td>
      <td>-0.358090</td>
      <td>-0.452940</td>
      <td>0.017626</td>
      <td>-0.115164</td>
      <td>-0.487136</td>
      <td>0.635087</td>
      <td>1.375017</td>
      <td>0.243938</td>
      <td>0.552805</td>
      <td>0.216513</td>
      <td>0.472099</td>
      <td>-0.395760</td>
      <td>0.259326</td>
      <td>-0.111006</td>
      <td>-0.620958</td>
      <td>-0.355822</td>
      <td>0.172493</td>
      <td>-0.193375</td>
      <td>0.392259</td>
      <td>-1.027678</td>
      <td>0.594764</td>
      <td>1.325747</td>
      <td>0.511312</td>
      <td>0.050903</td>
      <td>-0.659855</td>
      <td>-0.506840</td>
      <td>-0.243822</td>
      <td>0.174228</td>
      <td>-0.903558</td>
      <td>-0.030686</td>
      <td>-0.543398</td>
      <td>2.468439</td>
      <td>2.441679</td>
      <td>1.327851</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.248980</td>
      <td>0.427977</td>
      <td>1.752917</td>
      <td>1.296091</td>
      <td>0.395597</td>
      <td>0.633653</td>
      <td>0.614788</td>
      <td>0.620234</td>
      <td>0.536038</td>
      <td>0.244382</td>
      <td>-0.116301</td>
      <td>0.906764</td>
      <td>-0.299258</td>
      <td>-0.728322</td>
      <td>-0.375648</td>
      <td>-0.279548</td>
      <td>-0.100280</td>
      <td>1.113154</td>
      <td>-0.867523</td>
      <td>-1.241039</td>
      <td>-0.986990</td>
      <td>-0.470240</td>
      <td>-0.625050</td>
      <td>0.610027</td>
      <td>1.169224</td>
      <td>-0.303992</td>
      <td>0.193514</td>
      <td>0.359785</td>
      <td>-1.053462</td>
      <td>-0.213750</td>
      <td>0.340354</td>
      <td>0.518124</td>
      <td>-0.090958</td>
      <td>0.038666</td>
      <td>-0.412821</td>
      <td>0.177186</td>
      <td>0.421982</td>
      <td>0.504851</td>
      <td>0.031110</td>
      <td>-0.124034</td>
      <td>...</td>
      <td>-0.337363</td>
      <td>0.122299</td>
      <td>-0.319811</td>
      <td>-1.884988</td>
      <td>-0.039531</td>
      <td>-0.175798</td>
      <td>-0.411018</td>
      <td>0.118826</td>
      <td>0.347236</td>
      <td>0.996668</td>
      <td>1.310628</td>
      <td>-0.161605</td>
      <td>0.007798</td>
      <td>-0.379619</td>
      <td>-0.166201</td>
      <td>-0.395170</td>
      <td>-0.073259</td>
      <td>-0.267326</td>
      <td>0.426912</td>
      <td>-0.357060</td>
      <td>0.990740</td>
      <td>1.050982</td>
      <td>-0.006407</td>
      <td>0.133040</td>
      <td>0.308256</td>
      <td>-0.305240</td>
      <td>0.329948</td>
      <td>0.584185</td>
      <td>0.486571</td>
      <td>-0.727406</td>
      <td>-1.015596</td>
      <td>-0.851000</td>
      <td>-0.409395</td>
      <td>-0.278702</td>
      <td>-0.730661</td>
      <td>-0.003891</td>
      <td>0.518650</td>
      <td>1.341615</td>
      <td>0.848649</td>
      <td>0.226694</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.334593</td>
      <td>0.105243</td>
      <td>-0.099037</td>
      <td>0.429540</td>
      <td>0.694980</td>
      <td>0.094787</td>
      <td>-0.505631</td>
      <td>-0.375305</td>
      <td>0.015593</td>
      <td>-0.556927</td>
      <td>0.664146</td>
      <td>0.353929</td>
      <td>0.631785</td>
      <td>0.028705</td>
      <td>1.441681</td>
      <td>0.083493</td>
      <td>0.168915</td>
      <td>0.183686</td>
      <td>-0.304581</td>
      <td>-0.568864</td>
      <td>-1.379485</td>
      <td>0.202930</td>
      <td>0.338667</td>
      <td>-0.504654</td>
      <td>-0.000015</td>
      <td>0.450841</td>
      <td>0.504056</td>
      <td>-0.359436</td>
      <td>-0.473797</td>
      <td>0.020277</td>
      <td>0.537746</td>
      <td>-0.176278</td>
      <td>0.475436</td>
      <td>-0.180923</td>
      <td>-1.582913</td>
      <td>-0.643713</td>
      <td>-0.473384</td>
      <td>-0.227577</td>
      <td>0.606153</td>
      <td>-0.240306</td>
      <td>...</td>
      <td>-0.601687</td>
      <td>0.126534</td>
      <td>-1.119757</td>
      <td>-0.413774</td>
      <td>-0.147528</td>
      <td>-0.462685</td>
      <td>-0.463139</td>
      <td>-0.284437</td>
      <td>-0.888644</td>
      <td>-0.355009</td>
      <td>-0.108823</td>
      <td>1.152561</td>
      <td>0.025450</td>
      <td>0.427439</td>
      <td>0.704009</td>
      <td>0.464030</td>
      <td>0.032478</td>
      <td>1.100761</td>
      <td>1.013471</td>
      <td>-0.168097</td>
      <td>0.022243</td>
      <td>-1.291362</td>
      <td>-1.000465</td>
      <td>-1.992922</td>
      <td>-1.798533</td>
      <td>-1.268036</td>
      <td>-0.858203</td>
      <td>-0.018761</td>
      <td>-0.310039</td>
      <td>-0.731351</td>
      <td>-0.303767</td>
      <td>-1.208652</td>
      <td>-0.056552</td>
      <td>0.047733</td>
      <td>-0.272374</td>
      <td>-0.506961</td>
      <td>-0.224240</td>
      <td>0.333796</td>
      <td>-0.116043</td>
      <td>0.072262</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.619048</td>
      <td>-0.191508</td>
      <td>-0.461414</td>
      <td>-0.380549</td>
      <td>0.032972</td>
      <td>-0.045509</td>
      <td>-0.256894</td>
      <td>0.062387</td>
      <td>-0.046265</td>
      <td>-0.119416</td>
      <td>-0.133393</td>
      <td>0.039990</td>
      <td>0.057685</td>
      <td>-0.326623</td>
      <td>-0.254459</td>
      <td>0.066243</td>
      <td>-0.329903</td>
      <td>0.757314</td>
      <td>-0.315625</td>
      <td>-0.030521</td>
      <td>-1.750860</td>
      <td>0.414474</td>
      <td>0.685060</td>
      <td>0.995221</td>
      <td>0.818264</td>
      <td>0.607391</td>
      <td>0.018808</td>
      <td>0.522631</td>
      <td>0.250605</td>
      <td>0.895461</td>
      <td>0.691893</td>
      <td>0.667382</td>
      <td>0.500290</td>
      <td>0.279424</td>
      <td>-0.109313</td>
      <td>-0.964784</td>
      <td>0.342381</td>
      <td>0.609239</td>
      <td>0.420899</td>
      <td>0.247573</td>
      <td>...</td>
      <td>0.151022</td>
      <td>1.206899</td>
      <td>-0.163331</td>
      <td>-0.188836</td>
      <td>-0.928047</td>
      <td>-0.773729</td>
      <td>-0.201281</td>
      <td>-0.412246</td>
      <td>0.841395</td>
      <td>0.008580</td>
      <td>-0.432277</td>
      <td>-0.619820</td>
      <td>0.540552</td>
      <td>0.420445</td>
      <td>0.401148</td>
      <td>0.615894</td>
      <td>-0.110465</td>
      <td>0.112699</td>
      <td>1.317013</td>
      <td>0.505093</td>
      <td>0.585613</td>
      <td>1.251249</td>
      <td>0.353588</td>
      <td>0.174377</td>
      <td>-0.857311</td>
      <td>-1.619868</td>
      <td>-0.801973</td>
      <td>-0.101081</td>
      <td>-0.138030</td>
      <td>-0.513446</td>
      <td>-0.403538</td>
      <td>1.154827</td>
      <td>-0.121250</td>
      <td>-0.675771</td>
      <td>0.435236</td>
      <td>-0.005165</td>
      <td>0.014055</td>
      <td>1.280332</td>
      <td>0.080614</td>
      <td>0.416202</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.408641</td>
      <td>-1.145045</td>
      <td>-0.763134</td>
      <td>0.787967</td>
      <td>0.730998</td>
      <td>1.054568</td>
      <td>0.276496</td>
      <td>-0.161215</td>
      <td>-0.386638</td>
      <td>-0.939735</td>
      <td>0.106582</td>
      <td>-0.162905</td>
      <td>0.430839</td>
      <td>-0.456550</td>
      <td>-0.419389</td>
      <td>0.522377</td>
      <td>0.563035</td>
      <td>0.464451</td>
      <td>0.498706</td>
      <td>0.086503</td>
      <td>-0.255206</td>
      <td>0.668887</td>
      <td>0.033522</td>
      <td>-0.188105</td>
      <td>-1.350341</td>
      <td>0.279391</td>
      <td>0.687487</td>
      <td>-0.338317</td>
      <td>-0.868511</td>
      <td>-0.335720</td>
      <td>0.257075</td>
      <td>-0.315930</td>
      <td>0.205642</td>
      <td>-0.491957</td>
      <td>-0.074460</td>
      <td>-0.142685</td>
      <td>-0.204369</td>
      <td>0.355576</td>
      <td>0.738350</td>
      <td>0.801870</td>
      <td>...</td>
      <td>0.499094</td>
      <td>-0.086429</td>
      <td>0.287856</td>
      <td>-0.691640</td>
      <td>-0.302390</td>
      <td>0.163189</td>
      <td>-1.055496</td>
      <td>-0.055084</td>
      <td>-0.083286</td>
      <td>0.195089</td>
      <td>0.751383</td>
      <td>0.329675</td>
      <td>0.897851</td>
      <td>1.014183</td>
      <td>0.126927</td>
      <td>0.013129</td>
      <td>-0.090604</td>
      <td>-0.103212</td>
      <td>0.911580</td>
      <td>0.025209</td>
      <td>0.018452</td>
      <td>-0.285718</td>
      <td>-0.854147</td>
      <td>0.606765</td>
      <td>0.522040</td>
      <td>-0.431800</td>
      <td>-0.044030</td>
      <td>-0.085724</td>
      <td>0.017011</td>
      <td>-0.988507</td>
      <td>-0.924166</td>
      <td>-0.158223</td>
      <td>0.057687</td>
      <td>-0.229361</td>
      <td>0.054119</td>
      <td>-0.464074</td>
      <td>-0.060602</td>
      <td>0.881338</td>
      <td>0.868071</td>
      <td>-0.022658</td>
    </tr>
    <tr>
      <th>11</th>
      <td>1.238520</td>
      <td>-0.303672</td>
      <td>-0.346819</td>
      <td>0.380783</td>
      <td>0.726717</td>
      <td>0.189040</td>
      <td>0.170494</td>
      <td>0.816501</td>
      <td>-0.615921</td>
      <td>-0.439106</td>
      <td>-0.037631</td>
      <td>0.875169</td>
      <td>-0.294862</td>
      <td>-0.301352</td>
      <td>0.226087</td>
      <td>0.245025</td>
      <td>0.037596</td>
      <td>0.396465</td>
      <td>0.166236</td>
      <td>-0.616572</td>
      <td>-0.536502</td>
      <td>-0.136362</td>
      <td>0.440565</td>
      <td>-1.109655</td>
      <td>-0.061357</td>
      <td>0.786672</td>
      <td>1.302072</td>
      <td>1.040278</td>
      <td>-0.899493</td>
      <td>0.430231</td>
      <td>-0.739480</td>
      <td>-0.282417</td>
      <td>0.751388</td>
      <td>-0.039652</td>
      <td>-0.318935</td>
      <td>-0.128235</td>
      <td>0.945955</td>
      <td>0.555718</td>
      <td>0.154825</td>
      <td>-0.070485</td>
      <td>...</td>
      <td>0.825946</td>
      <td>0.065376</td>
      <td>0.250581</td>
      <td>-0.201271</td>
      <td>-0.397115</td>
      <td>-0.766078</td>
      <td>0.203116</td>
      <td>1.145235</td>
      <td>0.352334</td>
      <td>0.952953</td>
      <td>-0.091832</td>
      <td>0.021815</td>
      <td>0.950041</td>
      <td>-0.055954</td>
      <td>0.742307</td>
      <td>-0.157411</td>
      <td>0.755789</td>
      <td>0.327059</td>
      <td>0.473393</td>
      <td>0.204770</td>
      <td>-0.082798</td>
      <td>-0.204249</td>
      <td>0.242465</td>
      <td>-0.929531</td>
      <td>-1.069178</td>
      <td>0.123856</td>
      <td>0.447394</td>
      <td>0.811835</td>
      <td>0.407437</td>
      <td>-0.449284</td>
      <td>0.057233</td>
      <td>0.470727</td>
      <td>0.226732</td>
      <td>0.003676</td>
      <td>-1.145868</td>
      <td>-1.464914</td>
      <td>-0.265019</td>
      <td>2.931703</td>
      <td>1.903827</td>
      <td>1.666225</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-0.275804</td>
      <td>0.032357</td>
      <td>0.533106</td>
      <td>0.022835</td>
      <td>0.714300</td>
      <td>-0.080740</td>
      <td>-0.476577</td>
      <td>-0.343407</td>
      <td>-0.217453</td>
      <td>0.070172</td>
      <td>0.280272</td>
      <td>0.034234</td>
      <td>1.099879</td>
      <td>-0.209964</td>
      <td>-0.751905</td>
      <td>0.967121</td>
      <td>0.438967</td>
      <td>0.511464</td>
      <td>0.683847</td>
      <td>-1.014325</td>
      <td>-1.421437</td>
      <td>-0.137370</td>
      <td>-0.758086</td>
      <td>-0.268924</td>
      <td>-0.299145</td>
      <td>0.328493</td>
      <td>0.183856</td>
      <td>-0.010537</td>
      <td>-0.604138</td>
      <td>-0.338550</td>
      <td>0.183223</td>
      <td>0.472128</td>
      <td>0.059462</td>
      <td>-0.916244</td>
      <td>-0.482682</td>
      <td>-1.011780</td>
      <td>-0.555488</td>
      <td>-0.210922</td>
      <td>-0.909368</td>
      <td>-0.296564</td>
      <td>...</td>
      <td>0.572281</td>
      <td>0.431210</td>
      <td>0.109745</td>
      <td>-0.165807</td>
      <td>-0.034200</td>
      <td>0.348153</td>
      <td>0.419474</td>
      <td>0.186429</td>
      <td>0.530262</td>
      <td>0.328746</td>
      <td>1.342977</td>
      <td>1.207231</td>
      <td>-1.019629</td>
      <td>-0.239452</td>
      <td>0.606720</td>
      <td>-0.119597</td>
      <td>-0.804542</td>
      <td>-0.640707</td>
      <td>0.525205</td>
      <td>-0.027668</td>
      <td>-0.465794</td>
      <td>0.975632</td>
      <td>0.225228</td>
      <td>-0.330091</td>
      <td>-0.205244</td>
      <td>-0.156738</td>
      <td>0.295138</td>
      <td>0.130101</td>
      <td>0.428335</td>
      <td>-0.900930</td>
      <td>-0.805877</td>
      <td>-0.784548</td>
      <td>0.037243</td>
      <td>0.129586</td>
      <td>-0.038952</td>
      <td>0.009442</td>
      <td>0.223274</td>
      <td>-0.510905</td>
      <td>0.080412</td>
      <td>-0.105693</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.941358</td>
      <td>-0.378897</td>
      <td>-0.446492</td>
      <td>0.550656</td>
      <td>0.999242</td>
      <td>0.252370</td>
      <td>-0.126302</td>
      <td>0.741344</td>
      <td>-0.116721</td>
      <td>0.638249</td>
      <td>0.508634</td>
      <td>0.513863</td>
      <td>-0.926674</td>
      <td>0.238562</td>
      <td>0.349836</td>
      <td>0.392401</td>
      <td>-0.389828</td>
      <td>-0.700403</td>
      <td>0.817986</td>
      <td>0.178444</td>
      <td>-0.812840</td>
      <td>-0.116661</td>
      <td>0.234774</td>
      <td>0.144734</td>
      <td>1.085449</td>
      <td>1.162742</td>
      <td>0.033522</td>
      <td>0.902258</td>
      <td>-0.103790</td>
      <td>0.786658</td>
      <td>0.971322</td>
      <td>0.151430</td>
      <td>1.024372</td>
      <td>-0.566546</td>
      <td>-0.923134</td>
      <td>-0.787047</td>
      <td>-0.784084</td>
      <td>-1.115669</td>
      <td>0.695383</td>
      <td>-0.238076</td>
      <td>...</td>
      <td>-0.508257</td>
      <td>-0.486834</td>
      <td>0.067378</td>
      <td>-0.357277</td>
      <td>-0.520838</td>
      <td>0.357031</td>
      <td>-0.468496</td>
      <td>0.015601</td>
      <td>-0.904031</td>
      <td>0.510204</td>
      <td>0.830731</td>
      <td>0.461060</td>
      <td>0.685636</td>
      <td>0.089274</td>
      <td>0.910876</td>
      <td>-0.170440</td>
      <td>-0.507559</td>
      <td>-0.561135</td>
      <td>0.307663</td>
      <td>0.040663</td>
      <td>-0.359586</td>
      <td>-0.446672</td>
      <td>-1.004825</td>
      <td>0.419587</td>
      <td>-0.669405</td>
      <td>-0.832278</td>
      <td>-0.153266</td>
      <td>0.491476</td>
      <td>1.281299</td>
      <td>0.113288</td>
      <td>0.108611</td>
      <td>1.202494</td>
      <td>0.055352</td>
      <td>0.440365</td>
      <td>0.385369</td>
      <td>0.048244</td>
      <td>0.150268</td>
      <td>2.056466</td>
      <td>1.100528</td>
      <td>0.465945</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.067905</td>
      <td>-0.494548</td>
      <td>-0.407776</td>
      <td>1.162322</td>
      <td>0.136841</td>
      <td>0.085061</td>
      <td>-1.062666</td>
      <td>-0.584976</td>
      <td>-0.143718</td>
      <td>0.113086</td>
      <td>0.078333</td>
      <td>-0.624759</td>
      <td>-0.630157</td>
      <td>-0.792750</td>
      <td>-0.026803</td>
      <td>0.378642</td>
      <td>0.404090</td>
      <td>0.540957</td>
      <td>-0.379387</td>
      <td>-0.850820</td>
      <td>-0.024804</td>
      <td>0.445618</td>
      <td>0.487331</td>
      <td>-0.625086</td>
      <td>0.089861</td>
      <td>0.571278</td>
      <td>1.551333</td>
      <td>0.532600</td>
      <td>-0.093939</td>
      <td>0.713459</td>
      <td>0.418938</td>
      <td>0.130767</td>
      <td>0.442262</td>
      <td>-0.483854</td>
      <td>-0.159767</td>
      <td>-0.264628</td>
      <td>-0.512492</td>
      <td>-0.431627</td>
      <td>-1.024565</td>
      <td>-0.264832</td>
      <td>...</td>
      <td>0.215599</td>
      <td>1.195006</td>
      <td>-1.375952</td>
      <td>-0.932189</td>
      <td>-0.414304</td>
      <td>-1.072756</td>
      <td>-0.648417</td>
      <td>0.209823</td>
      <td>-0.314601</td>
      <td>-0.803998</td>
      <td>0.395697</td>
      <td>-0.038320</td>
      <td>-0.050083</td>
      <td>0.743548</td>
      <td>1.410333</td>
      <td>1.173736</td>
      <td>-0.326562</td>
      <td>-0.217786</td>
      <td>-1.083132</td>
      <td>0.274067</td>
      <td>-1.181632</td>
      <td>-0.632303</td>
      <td>0.204739</td>
      <td>-0.147234</td>
      <td>0.116138</td>
      <td>1.097346</td>
      <td>0.954971</td>
      <td>0.013826</td>
      <td>0.742983</td>
      <td>-0.077396</td>
      <td>-0.733578</td>
      <td>-1.333520</td>
      <td>-1.238022</td>
      <td>-0.422268</td>
      <td>-0.552239</td>
      <td>0.260070</td>
      <td>-0.637254</td>
      <td>-1.866361</td>
      <td>-0.996373</td>
      <td>-0.045016</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-0.158724</td>
      <td>0.137316</td>
      <td>0.901042</td>
      <td>-0.242391</td>
      <td>-0.749271</td>
      <td>0.936993</td>
      <td>0.923708</td>
      <td>0.617775</td>
      <td>-0.270338</td>
      <td>-0.596726</td>
      <td>1.656106</td>
      <td>0.531589</td>
      <td>-0.337419</td>
      <td>0.003134</td>
      <td>0.505224</td>
      <td>0.875663</td>
      <td>-0.276094</td>
      <td>-0.333015</td>
      <td>0.102141</td>
      <td>0.185785</td>
      <td>0.800134</td>
      <td>1.220750</td>
      <td>-0.526660</td>
      <td>0.008958</td>
      <td>-0.386094</td>
      <td>-0.251043</td>
      <td>0.438704</td>
      <td>-0.913602</td>
      <td>-0.900847</td>
      <td>0.071460</td>
      <td>0.387273</td>
      <td>0.013448</td>
      <td>0.793838</td>
      <td>1.201702</td>
      <td>-0.372818</td>
      <td>-1.196614</td>
      <td>-0.144054</td>
      <td>1.432155</td>
      <td>0.957832</td>
      <td>0.697730</td>
      <td>...</td>
      <td>0.545444</td>
      <td>0.279844</td>
      <td>0.586086</td>
      <td>-0.750721</td>
      <td>-0.589777</td>
      <td>0.173289</td>
      <td>0.281502</td>
      <td>0.273628</td>
      <td>0.023930</td>
      <td>0.911745</td>
      <td>0.952567</td>
      <td>0.430083</td>
      <td>-0.090429</td>
      <td>-0.627736</td>
      <td>0.904785</td>
      <td>1.017672</td>
      <td>0.088779</td>
      <td>-0.147329</td>
      <td>-0.858708</td>
      <td>-0.547326</td>
      <td>-1.303046</td>
      <td>-0.840755</td>
      <td>-0.230763</td>
      <td>-0.281738</td>
      <td>1.167487</td>
      <td>-0.354756</td>
      <td>-1.390020</td>
      <td>0.560678</td>
      <td>-0.081074</td>
      <td>-0.009231</td>
      <td>-0.327956</td>
      <td>-0.001450</td>
      <td>0.081872</td>
      <td>-0.348257</td>
      <td>0.229115</td>
      <td>-0.525075</td>
      <td>-1.355906</td>
      <td>1.152166</td>
      <td>0.153724</td>
      <td>0.659901</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-0.156632</td>
      <td>0.667596</td>
      <td>1.086099</td>
      <td>-0.166544</td>
      <td>0.100557</td>
      <td>0.372271</td>
      <td>0.096571</td>
      <td>0.810564</td>
      <td>0.685249</td>
      <td>-0.323873</td>
      <td>0.050850</td>
      <td>-0.538272</td>
      <td>-0.534160</td>
      <td>0.085786</td>
      <td>0.093410</td>
      <td>0.551725</td>
      <td>-0.380774</td>
      <td>-0.274611</td>
      <td>-0.262463</td>
      <td>-1.091516</td>
      <td>-0.521232</td>
      <td>-0.137809</td>
      <td>-0.261749</td>
      <td>0.138641</td>
      <td>-0.329486</td>
      <td>-0.364498</td>
      <td>-0.053588</td>
      <td>-0.327354</td>
      <td>-0.647008</td>
      <td>-0.865142</td>
      <td>-0.854487</td>
      <td>0.599044</td>
      <td>0.843421</td>
      <td>-0.766186</td>
      <td>-0.965956</td>
      <td>-0.216958</td>
      <td>-0.244436</td>
      <td>-0.657194</td>
      <td>0.280227</td>
      <td>0.452732</td>
      <td>...</td>
      <td>-0.575588</td>
      <td>0.172293</td>
      <td>-0.668248</td>
      <td>-0.671939</td>
      <td>-0.306870</td>
      <td>-0.346414</td>
      <td>-0.492704</td>
      <td>0.115221</td>
      <td>-0.283417</td>
      <td>1.055381</td>
      <td>1.018957</td>
      <td>-0.542310</td>
      <td>-0.123353</td>
      <td>-0.475736</td>
      <td>-0.262898</td>
      <td>-0.278322</td>
      <td>-0.346158</td>
      <td>-0.281433</td>
      <td>-0.049991</td>
      <td>0.365132</td>
      <td>-0.594872</td>
      <td>0.621412</td>
      <td>0.807258</td>
      <td>0.343148</td>
      <td>0.193934</td>
      <td>-0.262445</td>
      <td>-0.157854</td>
      <td>-0.316127</td>
      <td>-0.418203</td>
      <td>-0.279357</td>
      <td>0.096995</td>
      <td>0.451882</td>
      <td>0.468643</td>
      <td>0.027623</td>
      <td>-0.574586</td>
      <td>-0.899078</td>
      <td>-0.402228</td>
      <td>1.869535</td>
      <td>1.506879</td>
      <td>0.250122</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.360361</td>
      <td>-0.559264</td>
      <td>0.737666</td>
      <td>1.449551</td>
      <td>1.199126</td>
      <td>0.530009</td>
      <td>-0.162380</td>
      <td>-0.136957</td>
      <td>-0.645153</td>
      <td>-0.446305</td>
      <td>-0.296178</td>
      <td>-0.843473</td>
      <td>-1.624344</td>
      <td>-0.609856</td>
      <td>0.428686</td>
      <td>-0.290946</td>
      <td>0.000883</td>
      <td>-0.828099</td>
      <td>-0.229974</td>
      <td>0.138445</td>
      <td>-1.077113</td>
      <td>0.013758</td>
      <td>-0.947131</td>
      <td>-0.141662</td>
      <td>-0.817863</td>
      <td>-0.612342</td>
      <td>0.218887</td>
      <td>0.259172</td>
      <td>0.375947</td>
      <td>0.870880</td>
      <td>0.306073</td>
      <td>0.632337</td>
      <td>-0.136417</td>
      <td>-0.300994</td>
      <td>-0.365684</td>
      <td>-0.316278</td>
      <td>0.096603</td>
      <td>0.031179</td>
      <td>0.575887</td>
      <td>0.066499</td>
      <td>...</td>
      <td>-1.340395</td>
      <td>0.173342</td>
      <td>0.113746</td>
      <td>-1.059639</td>
      <td>-0.256166</td>
      <td>0.648378</td>
      <td>0.121731</td>
      <td>0.669141</td>
      <td>0.095111</td>
      <td>-0.352456</td>
      <td>-0.683373</td>
      <td>-0.758583</td>
      <td>0.587850</td>
      <td>0.581151</td>
      <td>0.727345</td>
      <td>0.340449</td>
      <td>-0.381401</td>
      <td>-0.239103</td>
      <td>-0.416348</td>
      <td>0.004826</td>
      <td>-0.508171</td>
      <td>0.230373</td>
      <td>0.059908</td>
      <td>0.248076</td>
      <td>-0.198446</td>
      <td>-0.027728</td>
      <td>0.048657</td>
      <td>-0.059736</td>
      <td>0.454256</td>
      <td>-0.010842</td>
      <td>-0.253842</td>
      <td>-0.529247</td>
      <td>-1.293354</td>
      <td>1.176670</td>
      <td>1.151882</td>
      <td>0.277402</td>
      <td>-1.338007</td>
      <td>-0.177182</td>
      <td>-1.256784</td>
      <td>-0.084174</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.045320</td>
      <td>0.078555</td>
      <td>-0.605882</td>
      <td>0.121916</td>
      <td>0.546482</td>
      <td>0.040222</td>
      <td>-0.310611</td>
      <td>0.406574</td>
      <td>0.534656</td>
      <td>0.698339</td>
      <td>0.137365</td>
      <td>0.569756</td>
      <td>-0.283040</td>
      <td>0.242947</td>
      <td>0.804761</td>
      <td>0.150264</td>
      <td>-0.116828</td>
      <td>1.028348</td>
      <td>-0.149122</td>
      <td>-1.384537</td>
      <td>-1.218955</td>
      <td>-0.741872</td>
      <td>-0.966473</td>
      <td>-0.339676</td>
      <td>0.106448</td>
      <td>-0.806284</td>
      <td>-0.121734</td>
      <td>0.403466</td>
      <td>-0.915250</td>
      <td>-0.537188</td>
      <td>-0.258732</td>
      <td>0.160423</td>
      <td>-0.368692</td>
      <td>-0.726820</td>
      <td>-0.098616</td>
      <td>-0.608922</td>
      <td>0.368258</td>
      <td>0.654756</td>
      <td>0.264620</td>
      <td>0.096984</td>
      <td>...</td>
      <td>0.895370</td>
      <td>-0.154579</td>
      <td>0.657801</td>
      <td>-0.155994</td>
      <td>-0.049763</td>
      <td>0.000389</td>
      <td>-0.273909</td>
      <td>-0.401395</td>
      <td>-0.566194</td>
      <td>0.478320</td>
      <td>-0.425090</td>
      <td>-0.211892</td>
      <td>-0.919212</td>
      <td>-0.911454</td>
      <td>0.246000</td>
      <td>-0.016840</td>
      <td>0.665494</td>
      <td>0.051507</td>
      <td>0.441180</td>
      <td>0.514184</td>
      <td>0.726664</td>
      <td>-0.630554</td>
      <td>0.289789</td>
      <td>0.706803</td>
      <td>-0.084926</td>
      <td>-0.955301</td>
      <td>-0.452264</td>
      <td>0.070926</td>
      <td>-0.352026</td>
      <td>-0.700212</td>
      <td>-0.418535</td>
      <td>-0.138616</td>
      <td>-0.086172</td>
      <td>-1.079520</td>
      <td>-0.395812</td>
      <td>0.131494</td>
      <td>0.121159</td>
      <td>-1.838804</td>
      <td>-0.838344</td>
      <td>-0.014800</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.014069</td>
      <td>0.524960</td>
      <td>-0.683062</td>
      <td>0.348072</td>
      <td>-0.047004</td>
      <td>1.576951</td>
      <td>0.567277</td>
      <td>-0.027567</td>
      <td>0.921902</td>
      <td>0.268206</td>
      <td>-0.429971</td>
      <td>-0.119792</td>
      <td>0.108841</td>
      <td>-0.788172</td>
      <td>-0.785788</td>
      <td>0.098200</td>
      <td>0.778774</td>
      <td>-0.469418</td>
      <td>0.522875</td>
      <td>-0.738623</td>
      <td>-0.438470</td>
      <td>0.342884</td>
      <td>0.498540</td>
      <td>0.015003</td>
      <td>-0.721119</td>
      <td>-0.065704</td>
      <td>0.150295</td>
      <td>0.933361</td>
      <td>0.607558</td>
      <td>-0.339574</td>
      <td>-0.757116</td>
      <td>-0.562332</td>
      <td>-0.237698</td>
      <td>-0.232703</td>
      <td>-1.980734</td>
      <td>-1.633311</td>
      <td>-1.817005</td>
      <td>-0.099459</td>
      <td>0.623732</td>
      <td>-0.009728</td>
      <td>...</td>
      <td>0.127423</td>
      <td>0.557674</td>
      <td>0.628266</td>
      <td>-0.589060</td>
      <td>-0.629545</td>
      <td>-0.044513</td>
      <td>-0.060620</td>
      <td>0.272980</td>
      <td>0.178728</td>
      <td>0.550735</td>
      <td>0.223057</td>
      <td>0.509201</td>
      <td>0.772866</td>
      <td>0.092334</td>
      <td>-0.083610</td>
      <td>-0.108903</td>
      <td>0.138543</td>
      <td>0.322109</td>
      <td>-0.845668</td>
      <td>-1.296310</td>
      <td>-0.858963</td>
      <td>-0.497329</td>
      <td>0.176450</td>
      <td>-0.638199</td>
      <td>0.510465</td>
      <td>-0.458510</td>
      <td>0.175416</td>
      <td>-0.176450</td>
      <td>-0.343506</td>
      <td>-0.567805</td>
      <td>0.786110</td>
      <td>-0.352156</td>
      <td>0.690513</td>
      <td>-0.025986</td>
      <td>-0.548699</td>
      <td>-0.707359</td>
      <td>0.043244</td>
      <td>-1.230786</td>
      <td>-0.669344</td>
      <td>0.032720</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.508351</td>
      <td>-0.091260</td>
      <td>-0.942388</td>
      <td>-0.599308</td>
      <td>0.036507</td>
      <td>0.517670</td>
      <td>1.170535</td>
      <td>0.292242</td>
      <td>-0.176438</td>
      <td>-0.007463</td>
      <td>0.792419</td>
      <td>1.048788</td>
      <td>0.313000</td>
      <td>-0.254633</td>
      <td>-0.528868</td>
      <td>0.237667</td>
      <td>0.543653</td>
      <td>0.680404</td>
      <td>0.013557</td>
      <td>-1.181716</td>
      <td>-0.976744</td>
      <td>0.037854</td>
      <td>0.319908</td>
      <td>0.258610</td>
      <td>0.979528</td>
      <td>0.639934</td>
      <td>1.324312</td>
      <td>0.522180</td>
      <td>-0.806227</td>
      <td>-0.522956</td>
      <td>0.212467</td>
      <td>0.809067</td>
      <td>1.490338</td>
      <td>0.409735</td>
      <td>-0.869534</td>
      <td>0.839436</td>
      <td>-0.075737</td>
      <td>0.095996</td>
      <td>0.372369</td>
      <td>0.215106</td>
      <td>...</td>
      <td>-0.736217</td>
      <td>0.151822</td>
      <td>-0.540082</td>
      <td>0.001780</td>
      <td>-1.027130</td>
      <td>-0.422895</td>
      <td>-1.387456</td>
      <td>0.089171</td>
      <td>-0.582645</td>
      <td>0.796639</td>
      <td>0.888345</td>
      <td>-0.556445</td>
      <td>0.673628</td>
      <td>0.282347</td>
      <td>0.003609</td>
      <td>0.283884</td>
      <td>0.554729</td>
      <td>-0.999682</td>
      <td>0.073871</td>
      <td>0.521368</td>
      <td>0.165792</td>
      <td>-1.034339</td>
      <td>-0.740052</td>
      <td>-1.037879</td>
      <td>-1.363010</td>
      <td>-0.534989</td>
      <td>-1.108930</td>
      <td>-0.429271</td>
      <td>-0.356750</td>
      <td>0.150634</td>
      <td>-0.618624</td>
      <td>-0.178510</td>
      <td>0.662543</td>
      <td>-0.948047</td>
      <td>-1.061641</td>
      <td>-1.072283</td>
      <td>-0.579713</td>
      <td>-2.419530</td>
      <td>-1.992623</td>
      <td>-0.477143</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.377502</td>
      <td>-0.470575</td>
      <td>0.367650</td>
      <td>1.575682</td>
      <td>-0.069382</td>
      <td>0.850438</td>
      <td>-0.131308</td>
      <td>-0.325417</td>
      <td>0.290394</td>
      <td>0.104774</td>
      <td>0.193264</td>
      <td>-0.342431</td>
      <td>-0.801264</td>
      <td>-1.050240</td>
      <td>-1.163232</td>
      <td>-0.772300</td>
      <td>-0.717235</td>
      <td>-0.510349</td>
      <td>0.171112</td>
      <td>0.242676</td>
      <td>-0.539791</td>
      <td>-0.253279</td>
      <td>0.251633</td>
      <td>-0.084932</td>
      <td>-0.126716</td>
      <td>-0.350294</td>
      <td>0.601132</td>
      <td>0.270520</td>
      <td>-1.084472</td>
      <td>0.251089</td>
      <td>-0.183993</td>
      <td>-0.017415</td>
      <td>0.448106</td>
      <td>-0.068649</td>
      <td>0.246014</td>
      <td>-1.222771</td>
      <td>-0.246524</td>
      <td>0.378146</td>
      <td>-0.027462</td>
      <td>0.614308</td>
      <td>...</td>
      <td>1.093476</td>
      <td>-0.146222</td>
      <td>-0.021869</td>
      <td>-0.743815</td>
      <td>-0.925753</td>
      <td>-0.984589</td>
      <td>0.605933</td>
      <td>-0.363859</td>
      <td>-0.049943</td>
      <td>-0.775014</td>
      <td>-0.435848</td>
      <td>-0.092398</td>
      <td>0.247878</td>
      <td>0.409074</td>
      <td>-0.238702</td>
      <td>-1.018643</td>
      <td>-0.171922</td>
      <td>0.561397</td>
      <td>0.476340</td>
      <td>-0.701216</td>
      <td>-0.462919</td>
      <td>0.128029</td>
      <td>-0.636512</td>
      <td>-0.627752</td>
      <td>-0.932682</td>
      <td>-0.910628</td>
      <td>-0.597370</td>
      <td>-0.646338</td>
      <td>0.194216</td>
      <td>-0.701445</td>
      <td>0.024388</td>
      <td>1.073968</td>
      <td>-0.100620</td>
      <td>-0.275564</td>
      <td>0.302002</td>
      <td>0.032612</td>
      <td>-0.185911</td>
      <td>0.695092</td>
      <td>0.828291</td>
      <td>1.223687</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.757697</td>
      <td>-0.433899</td>
      <td>0.438631</td>
      <td>0.518102</td>
      <td>-0.228780</td>
      <td>0.124709</td>
      <td>0.336906</td>
      <td>0.188769</td>
      <td>0.228579</td>
      <td>0.081250</td>
      <td>-0.215054</td>
      <td>-0.587702</td>
      <td>-0.623334</td>
      <td>0.556217</td>
      <td>-0.270248</td>
      <td>-0.027666</td>
      <td>-0.513283</td>
      <td>-0.462806</td>
      <td>-0.452107</td>
      <td>-0.633829</td>
      <td>-0.409335</td>
      <td>-0.337771</td>
      <td>0.108735</td>
      <td>-0.328918</td>
      <td>0.328276</td>
      <td>0.777964</td>
      <td>-0.165107</td>
      <td>-0.267981</td>
      <td>-0.227770</td>
      <td>-0.747495</td>
      <td>-0.407752</td>
      <td>0.101536</td>
      <td>-0.102763</td>
      <td>0.768795</td>
      <td>-0.358222</td>
      <td>0.577516</td>
      <td>-0.366375</td>
      <td>0.107284</td>
      <td>0.659194</td>
      <td>0.669872</td>
      <td>...</td>
      <td>-0.810180</td>
      <td>-1.398936</td>
      <td>-0.603582</td>
      <td>-0.887919</td>
      <td>-0.788206</td>
      <td>-0.208896</td>
      <td>-0.309031</td>
      <td>0.406735</td>
      <td>-1.045196</td>
      <td>0.900361</td>
      <td>-0.315528</td>
      <td>-0.347113</td>
      <td>0.819213</td>
      <td>0.703481</td>
      <td>0.597578</td>
      <td>0.222452</td>
      <td>0.111920</td>
      <td>0.048661</td>
      <td>-0.965708</td>
      <td>-0.672686</td>
      <td>-0.083100</td>
      <td>-0.434324</td>
      <td>-0.783556</td>
      <td>-0.018121</td>
      <td>-0.609847</td>
      <td>-1.265585</td>
      <td>-0.357218</td>
      <td>0.822335</td>
      <td>-0.178683</td>
      <td>-1.587046</td>
      <td>-0.721972</td>
      <td>-1.054585</td>
      <td>0.605608</td>
      <td>1.457106</td>
      <td>0.020166</td>
      <td>-1.271051</td>
      <td>-0.434983</td>
      <td>0.479835</td>
      <td>1.095174</td>
      <td>0.837086</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.366474</td>
      <td>-0.464051</td>
      <td>1.155039</td>
      <td>0.079218</td>
      <td>0.243426</td>
      <td>-0.961909</td>
      <td>0.276761</td>
      <td>0.058755</td>
      <td>-1.223500</td>
      <td>-0.414724</td>
      <td>-0.223698</td>
      <td>-0.236918</td>
      <td>-0.027744</td>
      <td>0.300741</td>
      <td>-0.456017</td>
      <td>-0.240643</td>
      <td>0.580617</td>
      <td>0.712708</td>
      <td>1.380595</td>
      <td>-0.270000</td>
      <td>-1.608372</td>
      <td>-0.259727</td>
      <td>-0.414202</td>
      <td>-0.403360</td>
      <td>-0.001206</td>
      <td>0.817778</td>
      <td>0.095738</td>
      <td>-0.301089</td>
      <td>0.219608</td>
      <td>-0.084070</td>
      <td>0.064702</td>
      <td>0.578511</td>
      <td>1.133900</td>
      <td>0.085646</td>
      <td>0.414865</td>
      <td>-1.194020</td>
      <td>-0.853029</td>
      <td>0.223590</td>
      <td>-0.709306</td>
      <td>-0.207712</td>
      <td>...</td>
      <td>0.659626</td>
      <td>0.279358</td>
      <td>0.110354</td>
      <td>-0.082885</td>
      <td>0.081189</td>
      <td>-0.689069</td>
      <td>-0.338650</td>
      <td>1.020174</td>
      <td>0.570928</td>
      <td>0.752688</td>
      <td>0.044285</td>
      <td>-0.123597</td>
      <td>0.957497</td>
      <td>0.940105</td>
      <td>0.986504</td>
      <td>0.040603</td>
      <td>-0.506947</td>
      <td>0.043519</td>
      <td>0.190427</td>
      <td>-0.153129</td>
      <td>0.144321</td>
      <td>-0.891456</td>
      <td>-0.144277</td>
      <td>0.047944</td>
      <td>-0.967650</td>
      <td>-0.430981</td>
      <td>0.509139</td>
      <td>-0.158490</td>
      <td>-0.057280</td>
      <td>-0.614061</td>
      <td>-0.580636</td>
      <td>-0.258095</td>
      <td>-0.500373</td>
      <td>0.031969</td>
      <td>0.689825</td>
      <td>0.584075</td>
      <td>1.424250</td>
      <td>1.216527</td>
      <td>0.363179</td>
      <td>-0.290380</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.901497</td>
      <td>-0.369966</td>
      <td>0.580158</td>
      <td>0.556550</td>
      <td>-0.753817</td>
      <td>-0.872875</td>
      <td>0.046253</td>
      <td>-0.097778</td>
      <td>0.074547</td>
      <td>-0.708755</td>
      <td>-0.561174</td>
      <td>-0.441311</td>
      <td>-0.162662</td>
      <td>0.238347</td>
      <td>0.397220</td>
      <td>0.432964</td>
      <td>-0.138307</td>
      <td>-0.934934</td>
      <td>-0.471111</td>
      <td>-0.995131</td>
      <td>-1.261626</td>
      <td>0.399397</td>
      <td>0.189828</td>
      <td>0.214066</td>
      <td>0.286868</td>
      <td>-0.218715</td>
      <td>-0.208776</td>
      <td>-0.124685</td>
      <td>0.620759</td>
      <td>-0.329575</td>
      <td>-0.217812</td>
      <td>0.435229</td>
      <td>1.326696</td>
      <td>0.658313</td>
      <td>-0.403272</td>
      <td>-0.199295</td>
      <td>-0.625257</td>
      <td>-0.324940</td>
      <td>-0.012356</td>
      <td>-0.305431</td>
      <td>...</td>
      <td>-0.559082</td>
      <td>0.289138</td>
      <td>0.050824</td>
      <td>-1.027958</td>
      <td>-0.978807</td>
      <td>-0.406587</td>
      <td>-1.044890</td>
      <td>-0.641914</td>
      <td>-0.108397</td>
      <td>0.058711</td>
      <td>0.303795</td>
      <td>-0.593789</td>
      <td>0.730218</td>
      <td>-0.528809</td>
      <td>0.061233</td>
      <td>-0.418766</td>
      <td>-0.027040</td>
      <td>0.415108</td>
      <td>1.006755</td>
      <td>-0.283075</td>
      <td>0.711119</td>
      <td>0.338962</td>
      <td>0.257094</td>
      <td>-0.399623</td>
      <td>-0.789649</td>
      <td>0.289331</td>
      <td>0.531839</td>
      <td>0.621087</td>
      <td>0.089830</td>
      <td>0.045588</td>
      <td>0.094085</td>
      <td>-0.100845</td>
      <td>-0.425136</td>
      <td>-0.229192</td>
      <td>-0.338337</td>
      <td>-0.303617</td>
      <td>0.574635</td>
      <td>1.037885</td>
      <td>0.516951</td>
      <td>0.010551</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-1.071995</td>
      <td>-1.071187</td>
      <td>-0.866408</td>
      <td>0.277685</td>
      <td>0.854241</td>
      <td>0.977877</td>
      <td>-0.350789</td>
      <td>0.190161</td>
      <td>-0.341970</td>
      <td>0.218409</td>
      <td>-0.414173</td>
      <td>0.914502</td>
      <td>0.166492</td>
      <td>0.335882</td>
      <td>-1.449143</td>
      <td>0.613425</td>
      <td>0.466937</td>
      <td>0.723028</td>
      <td>0.607851</td>
      <td>-0.562260</td>
      <td>-0.471589</td>
      <td>-1.174278</td>
      <td>-1.134891</td>
      <td>-0.832383</td>
      <td>-0.595405</td>
      <td>1.517908</td>
      <td>0.312434</td>
      <td>0.369073</td>
      <td>1.114440</td>
      <td>0.116916</td>
      <td>-0.137869</td>
      <td>-0.240591</td>
      <td>0.828906</td>
      <td>1.169210</td>
      <td>-0.022375</td>
      <td>0.294827</td>
      <td>0.650717</td>
      <td>0.410218</td>
      <td>0.782743</td>
      <td>-0.046324</td>
      <td>...</td>
      <td>0.148466</td>
      <td>0.300978</td>
      <td>0.248804</td>
      <td>-0.212671</td>
      <td>0.561256</td>
      <td>-0.241833</td>
      <td>0.020641</td>
      <td>0.419456</td>
      <td>-1.246195</td>
      <td>-0.146536</td>
      <td>-0.780627</td>
      <td>1.395039</td>
      <td>0.463771</td>
      <td>-0.524319</td>
      <td>0.747385</td>
      <td>-0.040344</td>
      <td>0.133832</td>
      <td>0.184732</td>
      <td>0.347511</td>
      <td>-0.167399</td>
      <td>-0.201283</td>
      <td>0.190132</td>
      <td>0.065732</td>
      <td>-0.147248</td>
      <td>-0.168071</td>
      <td>0.350986</td>
      <td>-0.556540</td>
      <td>-0.872906</td>
      <td>-0.233515</td>
      <td>0.485571</td>
      <td>-0.654643</td>
      <td>-0.239905</td>
      <td>0.802859</td>
      <td>0.478227</td>
      <td>0.957236</td>
      <td>0.204992</td>
      <td>-0.315157</td>
      <td>-1.780789</td>
      <td>0.011767</td>
      <td>-0.446588</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.979460</td>
      <td>-0.047396</td>
      <td>-0.786046</td>
      <td>-0.460709</td>
      <td>-0.336257</td>
      <td>1.058152</td>
      <td>0.439252</td>
      <td>-0.847753</td>
      <td>0.061213</td>
      <td>-0.946474</td>
      <td>0.282128</td>
      <td>0.880576</td>
      <td>0.052180</td>
      <td>0.583262</td>
      <td>-0.437754</td>
      <td>0.862055</td>
      <td>0.046874</td>
      <td>0.513642</td>
      <td>0.261667</td>
      <td>0.270730</td>
      <td>0.537526</td>
      <td>-0.235679</td>
      <td>0.488224</td>
      <td>-0.967416</td>
      <td>-0.951533</td>
      <td>0.504899</td>
      <td>0.058837</td>
      <td>-0.125051</td>
      <td>-1.078822</td>
      <td>0.660993</td>
      <td>-0.581868</td>
      <td>0.376213</td>
      <td>1.300608</td>
      <td>-0.677229</td>
      <td>-1.610203</td>
      <td>0.259188</td>
      <td>0.825723</td>
      <td>0.302911</td>
      <td>-0.007463</td>
      <td>-0.938984</td>
      <td>...</td>
      <td>1.181022</td>
      <td>-0.778041</td>
      <td>-1.580339</td>
      <td>-0.334892</td>
      <td>-0.957456</td>
      <td>0.700573</td>
      <td>1.179722</td>
      <td>0.271286</td>
      <td>0.255124</td>
      <td>-0.189789</td>
      <td>0.413787</td>
      <td>0.415350</td>
      <td>0.017642</td>
      <td>-0.761776</td>
      <td>0.152388</td>
      <td>-0.324120</td>
      <td>-0.358299</td>
      <td>-0.035572</td>
      <td>0.272838</td>
      <td>-0.431008</td>
      <td>-0.132785</td>
      <td>0.520627</td>
      <td>-0.469403</td>
      <td>-0.965775</td>
      <td>-0.597525</td>
      <td>-1.204033</td>
      <td>-0.544502</td>
      <td>-0.557862</td>
      <td>0.327702</td>
      <td>-0.220910</td>
      <td>0.567997</td>
      <td>0.761098</td>
      <td>0.510785</td>
      <td>1.865143</td>
      <td>0.305691</td>
      <td>-0.697487</td>
      <td>-0.333647</td>
      <td>-3.213574</td>
      <td>-1.783010</td>
      <td>-1.324794</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.315177</td>
      <td>0.512088</td>
      <td>-0.875130</td>
      <td>-0.230762</td>
      <td>0.033032</td>
      <td>1.143921</td>
      <td>0.889748</td>
      <td>-0.571652</td>
      <td>-0.587247</td>
      <td>0.036761</td>
      <td>-0.535376</td>
      <td>0.233908</td>
      <td>-0.101740</td>
      <td>-0.468435</td>
      <td>0.282402</td>
      <td>1.527297</td>
      <td>1.882812</td>
      <td>1.142380</td>
      <td>0.504075</td>
      <td>0.427049</td>
      <td>0.325045</td>
      <td>-0.708773</td>
      <td>-1.028451</td>
      <td>-0.601802</td>
      <td>-0.321455</td>
      <td>0.237016</td>
      <td>-0.221531</td>
      <td>-0.424055</td>
      <td>0.750509</td>
      <td>-0.349367</td>
      <td>0.116185</td>
      <td>-0.004829</td>
      <td>0.616042</td>
      <td>0.722609</td>
      <td>0.662635</td>
      <td>0.618046</td>
      <td>0.454625</td>
      <td>0.835061</td>
      <td>0.205311</td>
      <td>-0.611203</td>
      <td>...</td>
      <td>1.031228</td>
      <td>-0.261045</td>
      <td>0.418902</td>
      <td>-0.503454</td>
      <td>-0.519820</td>
      <td>0.126558</td>
      <td>-0.902160</td>
      <td>0.565786</td>
      <td>0.366305</td>
      <td>-0.528763</td>
      <td>-0.027881</td>
      <td>-1.320370</td>
      <td>-0.271175</td>
      <td>0.565612</td>
      <td>0.374731</td>
      <td>-0.553057</td>
      <td>0.462392</td>
      <td>0.479549</td>
      <td>0.945216</td>
      <td>0.021016</td>
      <td>-0.392655</td>
      <td>-0.211907</td>
      <td>0.646340</td>
      <td>-0.916029</td>
      <td>-0.238727</td>
      <td>-0.336624</td>
      <td>-0.051354</td>
      <td>-0.346407</td>
      <td>0.290197</td>
      <td>-0.004059</td>
      <td>-1.023842</td>
      <td>-0.721558</td>
      <td>0.420498</td>
      <td>-0.422784</td>
      <td>-0.361529</td>
      <td>-0.513986</td>
      <td>0.348845</td>
      <td>-0.438075</td>
      <td>-0.125230</td>
      <td>-0.057853</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.110751</td>
      <td>0.481312</td>
      <td>0.867920</td>
      <td>-0.113414</td>
      <td>0.667342</td>
      <td>0.913193</td>
      <td>0.364600</td>
      <td>0.053267</td>
      <td>0.975568</td>
      <td>1.050406</td>
      <td>1.299098</td>
      <td>0.189586</td>
      <td>0.563061</td>
      <td>1.222163</td>
      <td>0.592679</td>
      <td>-0.338402</td>
      <td>0.263125</td>
      <td>0.589562</td>
      <td>0.693332</td>
      <td>-0.165934</td>
      <td>-0.020188</td>
      <td>0.289008</td>
      <td>-0.856722</td>
      <td>0.432101</td>
      <td>0.744489</td>
      <td>0.245910</td>
      <td>-0.749685</td>
      <td>-1.159608</td>
      <td>0.418096</td>
      <td>0.305546</td>
      <td>-0.265441</td>
      <td>-0.366104</td>
      <td>0.668849</td>
      <td>0.370793</td>
      <td>-0.137163</td>
      <td>0.065962</td>
      <td>0.137676</td>
      <td>0.500622</td>
      <td>0.166403</td>
      <td>0.327026</td>
      <td>...</td>
      <td>-0.359847</td>
      <td>0.330386</td>
      <td>1.150158</td>
      <td>-0.483681</td>
      <td>-0.582998</td>
      <td>0.810587</td>
      <td>0.387068</td>
      <td>0.498123</td>
      <td>-0.252212</td>
      <td>-0.634827</td>
      <td>-0.272817</td>
      <td>0.354188</td>
      <td>-1.073352</td>
      <td>-0.307688</td>
      <td>-0.374315</td>
      <td>0.823114</td>
      <td>-0.085751</td>
      <td>-0.362532</td>
      <td>-1.182030</td>
      <td>0.640944</td>
      <td>0.994722</td>
      <td>0.560333</td>
      <td>0.470730</td>
      <td>-1.411034</td>
      <td>-1.015038</td>
      <td>-0.309301</td>
      <td>-0.840190</td>
      <td>-0.173990</td>
      <td>0.108278</td>
      <td>-0.041199</td>
      <td>0.028450</td>
      <td>-0.845364</td>
      <td>-0.560352</td>
      <td>-0.338539</td>
      <td>0.053509</td>
      <td>-0.215745</td>
      <td>-0.438743</td>
      <td>-0.658914</td>
      <td>-0.509591</td>
      <td>-0.092773</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.199879</td>
      <td>0.151429</td>
      <td>-0.171285</td>
      <td>0.899474</td>
      <td>0.695131</td>
      <td>0.150920</td>
      <td>-1.290840</td>
      <td>0.050574</td>
      <td>-0.431534</td>
      <td>-0.035607</td>
      <td>-0.331139</td>
      <td>-0.097094</td>
      <td>-0.404218</td>
      <td>0.437239</td>
      <td>0.711513</td>
      <td>0.435125</td>
      <td>-0.167968</td>
      <td>-0.089948</td>
      <td>-0.834586</td>
      <td>-0.058901</td>
      <td>-0.024342</td>
      <td>-0.008699</td>
      <td>-0.302703</td>
      <td>-0.479050</td>
      <td>-0.310731</td>
      <td>-0.223748</td>
      <td>0.558804</td>
      <td>-0.315485</td>
      <td>0.342461</td>
      <td>0.067499</td>
      <td>0.047971</td>
      <td>0.376824</td>
      <td>-0.479079</td>
      <td>-0.861349</td>
      <td>-0.554948</td>
      <td>0.459971</td>
      <td>0.663172</td>
      <td>-0.270451</td>
      <td>0.573499</td>
      <td>0.123039</td>
      <td>...</td>
      <td>0.471606</td>
      <td>0.152846</td>
      <td>0.264791</td>
      <td>0.118676</td>
      <td>-0.220585</td>
      <td>-0.702616</td>
      <td>0.225374</td>
      <td>0.661867</td>
      <td>-0.134203</td>
      <td>-1.168751</td>
      <td>-0.556501</td>
      <td>0.630065</td>
      <td>0.315054</td>
      <td>-0.839558</td>
      <td>0.054013</td>
      <td>0.464727</td>
      <td>0.411210</td>
      <td>-0.935382</td>
      <td>0.544792</td>
      <td>0.998776</td>
      <td>-0.300248</td>
      <td>-0.071697</td>
      <td>0.134650</td>
      <td>0.426171</td>
      <td>-0.470810</td>
      <td>-1.169097</td>
      <td>-0.162768</td>
      <td>0.196993</td>
      <td>0.277139</td>
      <td>-0.886775</td>
      <td>-1.015977</td>
      <td>0.270805</td>
      <td>-1.063730</td>
      <td>0.431815</td>
      <td>0.356866</td>
      <td>-0.958423</td>
      <td>1.064232</td>
      <td>-0.734018</td>
      <td>-0.730924</td>
      <td>-0.008839</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 103 columns</p>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7fbd70fb0640&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err         t          P&gt;|t|     2.5 %    97.5 %
D  1.077352  0.041166  26.17078  5.717875e-151  0.996668  1.158037
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  5.428 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>