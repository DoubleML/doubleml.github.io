
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.137090</td>
      <td>-0.600175</td>
      <td>-0.344356</td>
      <td>0.738952</td>
      <td>0.097010</td>
      <td>0.158793</td>
      <td>-1.141058</td>
      <td>-0.108285</td>
      <td>0.115629</td>
      <td>0.092044</td>
      <td>1.072911</td>
      <td>0.242947</td>
      <td>0.625127</td>
      <td>-0.251682</td>
      <td>-0.215097</td>
      <td>-0.055493</td>
      <td>-0.541710</td>
      <td>-1.097472</td>
      <td>0.408378</td>
      <td>0.115404</td>
      <td>-0.630912</td>
      <td>0.019856</td>
      <td>0.494284</td>
      <td>-0.217237</td>
      <td>-0.834432</td>
      <td>-1.141247</td>
      <td>-1.074105</td>
      <td>-1.100033</td>
      <td>0.170179</td>
      <td>-0.015116</td>
      <td>0.049359</td>
      <td>0.739226</td>
      <td>-0.219313</td>
      <td>0.198174</td>
      <td>0.579561</td>
      <td>1.458066</td>
      <td>0.948528</td>
      <td>0.095906</td>
      <td>-0.145702</td>
      <td>-0.766897</td>
      <td>...</td>
      <td>0.352640</td>
      <td>0.268247</td>
      <td>-0.549688</td>
      <td>-1.052317</td>
      <td>0.657602</td>
      <td>0.509432</td>
      <td>0.643929</td>
      <td>0.369586</td>
      <td>0.261273</td>
      <td>-0.771208</td>
      <td>-0.829896</td>
      <td>-0.042061</td>
      <td>-0.428776</td>
      <td>-0.612108</td>
      <td>0.252214</td>
      <td>0.201725</td>
      <td>-0.728708</td>
      <td>-0.379981</td>
      <td>-0.419516</td>
      <td>-1.034299</td>
      <td>0.337480</td>
      <td>0.460263</td>
      <td>0.767184</td>
      <td>0.691536</td>
      <td>0.347311</td>
      <td>0.482936</td>
      <td>0.202344</td>
      <td>0.915293</td>
      <td>1.699021</td>
      <td>-0.210749</td>
      <td>-0.489151</td>
      <td>0.122884</td>
      <td>-1.050475</td>
      <td>-0.507969</td>
      <td>-1.196929</td>
      <td>-0.272915</td>
      <td>0.321771</td>
      <td>-0.540392</td>
      <td>-0.508913</td>
      <td>-0.389841</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.288416</td>
      <td>0.960454</td>
      <td>0.650585</td>
      <td>0.471811</td>
      <td>0.759773</td>
      <td>-0.282449</td>
      <td>0.073092</td>
      <td>0.084929</td>
      <td>-0.680670</td>
      <td>-0.093959</td>
      <td>-0.548018</td>
      <td>-0.964155</td>
      <td>-1.157674</td>
      <td>-0.645001</td>
      <td>-0.013340</td>
      <td>0.196063</td>
      <td>-1.349433</td>
      <td>-0.972916</td>
      <td>-0.218684</td>
      <td>-0.866859</td>
      <td>-0.688904</td>
      <td>1.214419</td>
      <td>0.527958</td>
      <td>1.317441</td>
      <td>0.230617</td>
      <td>-0.374677</td>
      <td>-0.331711</td>
      <td>-0.679588</td>
      <td>0.371131</td>
      <td>-0.220161</td>
      <td>0.003082</td>
      <td>0.612986</td>
      <td>0.841198</td>
      <td>-0.571485</td>
      <td>0.294202</td>
      <td>-0.070332</td>
      <td>0.706089</td>
      <td>0.477521</td>
      <td>1.372765</td>
      <td>1.632260</td>
      <td>...</td>
      <td>0.376676</td>
      <td>-0.074943</td>
      <td>-0.689682</td>
      <td>-1.204817</td>
      <td>-0.750905</td>
      <td>-1.187493</td>
      <td>-0.171705</td>
      <td>-0.089159</td>
      <td>0.826343</td>
      <td>-0.128140</td>
      <td>-0.257753</td>
      <td>1.226034</td>
      <td>0.034709</td>
      <td>0.751364</td>
      <td>0.110002</td>
      <td>0.787025</td>
      <td>-0.576346</td>
      <td>-1.772972</td>
      <td>-0.610338</td>
      <td>0.578063</td>
      <td>0.703925</td>
      <td>-0.823880</td>
      <td>-0.852601</td>
      <td>-0.204996</td>
      <td>-0.590529</td>
      <td>-0.039938</td>
      <td>0.581525</td>
      <td>-0.382057</td>
      <td>-1.045090</td>
      <td>-0.995068</td>
      <td>-0.452006</td>
      <td>0.372470</td>
      <td>0.290894</td>
      <td>0.544437</td>
      <td>-0.343696</td>
      <td>-0.099052</td>
      <td>0.429348</td>
      <td>-0.129239</td>
      <td>0.341361</td>
      <td>0.299496</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.898955</td>
      <td>-0.814141</td>
      <td>0.631043</td>
      <td>0.578989</td>
      <td>0.440803</td>
      <td>-0.216688</td>
      <td>-0.088441</td>
      <td>1.635514</td>
      <td>0.864464</td>
      <td>-0.225544</td>
      <td>-0.496376</td>
      <td>0.116929</td>
      <td>-0.770785</td>
      <td>-0.222029</td>
      <td>0.185816</td>
      <td>0.150937</td>
      <td>0.024275</td>
      <td>1.212059</td>
      <td>0.789799</td>
      <td>0.002881</td>
      <td>-0.345364</td>
      <td>0.592045</td>
      <td>-0.575828</td>
      <td>0.322644</td>
      <td>0.247758</td>
      <td>0.912852</td>
      <td>-1.387117</td>
      <td>-0.200650</td>
      <td>-0.482513</td>
      <td>-0.074422</td>
      <td>0.411665</td>
      <td>-0.476520</td>
      <td>0.287946</td>
      <td>-0.151491</td>
      <td>-0.101205</td>
      <td>-0.782384</td>
      <td>-0.074201</td>
      <td>-0.623979</td>
      <td>-0.074621</td>
      <td>0.821793</td>
      <td>...</td>
      <td>-0.121107</td>
      <td>0.470231</td>
      <td>0.247840</td>
      <td>0.071894</td>
      <td>-0.627635</td>
      <td>-0.388667</td>
      <td>1.259804</td>
      <td>0.048514</td>
      <td>0.217584</td>
      <td>1.126939</td>
      <td>-0.352762</td>
      <td>1.449191</td>
      <td>1.379787</td>
      <td>0.359151</td>
      <td>-0.012821</td>
      <td>-0.848158</td>
      <td>-0.994131</td>
      <td>-0.310116</td>
      <td>0.121594</td>
      <td>-0.416565</td>
      <td>-1.175179</td>
      <td>-0.433659</td>
      <td>-1.006148</td>
      <td>-0.446210</td>
      <td>0.225121</td>
      <td>0.142617</td>
      <td>-0.070400</td>
      <td>0.359696</td>
      <td>-0.292310</td>
      <td>0.233094</td>
      <td>-0.213489</td>
      <td>0.942879</td>
      <td>-0.220769</td>
      <td>0.750853</td>
      <td>0.029630</td>
      <td>0.499272</td>
      <td>-0.294843</td>
      <td>1.160554</td>
      <td>1.105366</td>
      <td>0.367666</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.035335</td>
      <td>-0.023966</td>
      <td>0.090974</td>
      <td>0.134036</td>
      <td>0.019177</td>
      <td>-0.194063</td>
      <td>-0.145504</td>
      <td>0.132416</td>
      <td>-0.570776</td>
      <td>-0.237179</td>
      <td>-0.076889</td>
      <td>0.366693</td>
      <td>-0.882522</td>
      <td>-0.588147</td>
      <td>-0.184283</td>
      <td>0.689176</td>
      <td>0.035207</td>
      <td>0.019963</td>
      <td>-0.690572</td>
      <td>-0.887901</td>
      <td>0.035892</td>
      <td>-0.752197</td>
      <td>0.257083</td>
      <td>-0.109727</td>
      <td>-0.329901</td>
      <td>0.030082</td>
      <td>-0.309457</td>
      <td>-0.434922</td>
      <td>-0.065574</td>
      <td>-0.261806</td>
      <td>-0.046138</td>
      <td>-0.506541</td>
      <td>0.863385</td>
      <td>-0.079430</td>
      <td>0.573964</td>
      <td>0.393849</td>
      <td>0.568436</td>
      <td>0.083460</td>
      <td>-0.224032</td>
      <td>0.316068</td>
      <td>...</td>
      <td>1.036807</td>
      <td>-0.042106</td>
      <td>-0.499378</td>
      <td>0.016140</td>
      <td>0.132636</td>
      <td>0.088711</td>
      <td>0.413165</td>
      <td>-0.187447</td>
      <td>-0.440977</td>
      <td>-0.252806</td>
      <td>-0.394327</td>
      <td>0.504329</td>
      <td>0.361062</td>
      <td>-0.283299</td>
      <td>-0.431211</td>
      <td>0.118694</td>
      <td>-0.441493</td>
      <td>0.552666</td>
      <td>0.127616</td>
      <td>-0.715207</td>
      <td>-0.410198</td>
      <td>-1.064327</td>
      <td>-0.692912</td>
      <td>0.301871</td>
      <td>-0.497662</td>
      <td>0.195460</td>
      <td>0.673799</td>
      <td>0.430281</td>
      <td>-0.308565</td>
      <td>0.476313</td>
      <td>0.474183</td>
      <td>0.666572</td>
      <td>0.478354</td>
      <td>1.076601</td>
      <td>-0.084810</td>
      <td>0.261845</td>
      <td>1.035069</td>
      <td>0.510664</td>
      <td>0.501355</td>
      <td>0.246245</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.612480</td>
      <td>-0.431318</td>
      <td>-0.132413</td>
      <td>-0.215833</td>
      <td>0.584285</td>
      <td>0.287739</td>
      <td>0.875575</td>
      <td>0.438003</td>
      <td>-0.545501</td>
      <td>-1.360732</td>
      <td>-0.146344</td>
      <td>0.003476</td>
      <td>-0.657293</td>
      <td>0.725821</td>
      <td>0.636700</td>
      <td>1.204176</td>
      <td>-0.159967</td>
      <td>-0.163920</td>
      <td>0.284718</td>
      <td>0.097775</td>
      <td>-0.627284</td>
      <td>-0.139692</td>
      <td>0.258656</td>
      <td>0.991102</td>
      <td>0.738479</td>
      <td>0.092184</td>
      <td>-0.795918</td>
      <td>-0.810587</td>
      <td>0.330620</td>
      <td>-1.102439</td>
      <td>-0.508333</td>
      <td>-1.276824</td>
      <td>-0.399079</td>
      <td>-0.861262</td>
      <td>1.391914</td>
      <td>0.437909</td>
      <td>1.181112</td>
      <td>0.080168</td>
      <td>0.365418</td>
      <td>0.062439</td>
      <td>...</td>
      <td>-0.795732</td>
      <td>0.594689</td>
      <td>0.536405</td>
      <td>0.039939</td>
      <td>-0.277421</td>
      <td>0.093925</td>
      <td>0.008360</td>
      <td>0.231853</td>
      <td>-0.110293</td>
      <td>1.107213</td>
      <td>-0.160328</td>
      <td>0.593454</td>
      <td>-0.704024</td>
      <td>-0.379975</td>
      <td>-0.330977</td>
      <td>-0.578002</td>
      <td>-0.981246</td>
      <td>-0.985462</td>
      <td>-0.115184</td>
      <td>0.459991</td>
      <td>0.296324</td>
      <td>-0.270117</td>
      <td>0.044238</td>
      <td>-1.004336</td>
      <td>0.867039</td>
      <td>-0.256004</td>
      <td>0.235096</td>
      <td>-0.140091</td>
      <td>-0.294587</td>
      <td>-1.513427</td>
      <td>-1.092153</td>
      <td>0.514278</td>
      <td>-0.213634</td>
      <td>0.492724</td>
      <td>-0.781974</td>
      <td>-0.555677</td>
      <td>-0.429110</td>
      <td>0.122338</td>
      <td>-0.305313</td>
      <td>-0.163783</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.042841</td>
      <td>-0.230308</td>
      <td>-0.286425</td>
      <td>-0.684513</td>
      <td>0.552282</td>
      <td>-0.816014</td>
      <td>-0.274030</td>
      <td>1.024598</td>
      <td>1.117241</td>
      <td>-0.376789</td>
      <td>-0.788512</td>
      <td>-0.008944</td>
      <td>-0.805497</td>
      <td>-0.642513</td>
      <td>0.252493</td>
      <td>0.225467</td>
      <td>0.526538</td>
      <td>-0.872627</td>
      <td>-0.686609</td>
      <td>0.882500</td>
      <td>0.308059</td>
      <td>-0.201373</td>
      <td>0.631803</td>
      <td>0.625092</td>
      <td>0.595399</td>
      <td>0.328601</td>
      <td>0.394588</td>
      <td>0.663667</td>
      <td>0.196355</td>
      <td>0.241370</td>
      <td>-0.181775</td>
      <td>-0.367540</td>
      <td>0.991379</td>
      <td>0.801370</td>
      <td>0.281852</td>
      <td>-0.085715</td>
      <td>0.879817</td>
      <td>-0.198780</td>
      <td>0.465502</td>
      <td>0.626004</td>
      <td>...</td>
      <td>0.577850</td>
      <td>1.137302</td>
      <td>1.360641</td>
      <td>-0.209611</td>
      <td>-0.857205</td>
      <td>-0.406316</td>
      <td>-0.626913</td>
      <td>0.051971</td>
      <td>0.236513</td>
      <td>0.796497</td>
      <td>-0.377150</td>
      <td>0.286903</td>
      <td>-0.306058</td>
      <td>0.776960</td>
      <td>0.492511</td>
      <td>-0.390681</td>
      <td>-1.006211</td>
      <td>0.047906</td>
      <td>-0.985293</td>
      <td>-0.315160</td>
      <td>0.186042</td>
      <td>-0.213545</td>
      <td>-0.225483</td>
      <td>-0.030748</td>
      <td>-0.409557</td>
      <td>0.662362</td>
      <td>0.175991</td>
      <td>-0.803284</td>
      <td>-0.565551</td>
      <td>0.637925</td>
      <td>-0.125526</td>
      <td>0.340346</td>
      <td>0.292339</td>
      <td>0.909996</td>
      <td>-0.354596</td>
      <td>-0.089618</td>
      <td>-0.611227</td>
      <td>0.243603</td>
      <td>0.011109</td>
      <td>0.021116</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.356249</td>
      <td>-0.086885</td>
      <td>0.457583</td>
      <td>0.590157</td>
      <td>-0.357345</td>
      <td>-0.935036</td>
      <td>-0.031499</td>
      <td>0.743378</td>
      <td>0.022358</td>
      <td>-0.255065</td>
      <td>-0.246417</td>
      <td>-0.753007</td>
      <td>-1.085079</td>
      <td>-0.587061</td>
      <td>-0.307968</td>
      <td>0.363162</td>
      <td>0.249996</td>
      <td>-0.749073</td>
      <td>-0.522112</td>
      <td>0.123543</td>
      <td>-1.777371</td>
      <td>-0.955275</td>
      <td>-0.496912</td>
      <td>-0.091369</td>
      <td>0.663315</td>
      <td>0.499900</td>
      <td>-0.118469</td>
      <td>-0.284366</td>
      <td>-1.324351</td>
      <td>0.126397</td>
      <td>0.074777</td>
      <td>-0.660313</td>
      <td>-0.344985</td>
      <td>0.075275</td>
      <td>-0.036738</td>
      <td>-0.794531</td>
      <td>1.061745</td>
      <td>0.416693</td>
      <td>0.716543</td>
      <td>-0.423423</td>
      <td>...</td>
      <td>0.696609</td>
      <td>0.793800</td>
      <td>0.945927</td>
      <td>-0.172914</td>
      <td>-0.580303</td>
      <td>-0.251363</td>
      <td>-0.247906</td>
      <td>-0.600615</td>
      <td>-1.905634</td>
      <td>-0.459973</td>
      <td>-0.159054</td>
      <td>0.061258</td>
      <td>-1.007970</td>
      <td>-0.425973</td>
      <td>-0.582122</td>
      <td>-0.056977</td>
      <td>-0.426294</td>
      <td>0.870206</td>
      <td>-0.623704</td>
      <td>-1.064572</td>
      <td>0.226927</td>
      <td>0.219891</td>
      <td>0.079099</td>
      <td>-0.223292</td>
      <td>0.166135</td>
      <td>0.234665</td>
      <td>0.025517</td>
      <td>-0.152501</td>
      <td>1.130333</td>
      <td>0.930705</td>
      <td>-0.039207</td>
      <td>1.049262</td>
      <td>-1.314374</td>
      <td>-0.494425</td>
      <td>-0.587548</td>
      <td>-0.498409</td>
      <td>-0.408949</td>
      <td>0.623749</td>
      <td>0.059745</td>
      <td>-0.095949</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.210110</td>
      <td>-0.518493</td>
      <td>0.482147</td>
      <td>0.208909</td>
      <td>-0.215519</td>
      <td>-0.628302</td>
      <td>0.289518</td>
      <td>-0.001574</td>
      <td>-0.263438</td>
      <td>-1.272984</td>
      <td>-0.376458</td>
      <td>-0.514370</td>
      <td>0.180903</td>
      <td>-0.085358</td>
      <td>0.352851</td>
      <td>0.687936</td>
      <td>0.110108</td>
      <td>-0.207675</td>
      <td>0.621831</td>
      <td>0.381278</td>
      <td>0.141961</td>
      <td>-0.499720</td>
      <td>-0.611136</td>
      <td>0.589141</td>
      <td>0.125906</td>
      <td>0.093987</td>
      <td>-1.608514</td>
      <td>-0.349812</td>
      <td>0.331735</td>
      <td>0.432520</td>
      <td>-0.297600</td>
      <td>-0.972254</td>
      <td>-0.149872</td>
      <td>-0.079082</td>
      <td>0.882924</td>
      <td>-0.508579</td>
      <td>0.877651</td>
      <td>-0.437826</td>
      <td>1.290529</td>
      <td>0.479835</td>
      <td>...</td>
      <td>0.987923</td>
      <td>0.446560</td>
      <td>1.095785</td>
      <td>-0.337944</td>
      <td>-0.320620</td>
      <td>-0.087862</td>
      <td>0.791873</td>
      <td>-0.297892</td>
      <td>-0.113809</td>
      <td>-0.618892</td>
      <td>-0.900215</td>
      <td>0.356802</td>
      <td>0.609441</td>
      <td>1.074562</td>
      <td>0.266397</td>
      <td>0.655370</td>
      <td>-0.433486</td>
      <td>0.827780</td>
      <td>-0.037572</td>
      <td>-0.468188</td>
      <td>-0.184588</td>
      <td>0.011187</td>
      <td>0.126008</td>
      <td>0.866785</td>
      <td>-0.117250</td>
      <td>0.257328</td>
      <td>1.716186</td>
      <td>-0.327709</td>
      <td>0.337559</td>
      <td>-0.831760</td>
      <td>0.389868</td>
      <td>1.172075</td>
      <td>0.897501</td>
      <td>0.717759</td>
      <td>0.063687</td>
      <td>-0.642806</td>
      <td>-0.794937</td>
      <td>0.340888</td>
      <td>0.422347</td>
      <td>0.170048</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.114561</td>
      <td>-0.653187</td>
      <td>-0.828260</td>
      <td>0.431595</td>
      <td>1.508601</td>
      <td>-0.425076</td>
      <td>0.526607</td>
      <td>-0.184542</td>
      <td>0.254275</td>
      <td>-0.670481</td>
      <td>0.162417</td>
      <td>-0.405908</td>
      <td>-0.276673</td>
      <td>0.603809</td>
      <td>-0.240670</td>
      <td>-0.604513</td>
      <td>0.530458</td>
      <td>0.571116</td>
      <td>-0.389593</td>
      <td>-0.835779</td>
      <td>-0.805978</td>
      <td>-0.437166</td>
      <td>-0.001431</td>
      <td>0.273520</td>
      <td>1.182127</td>
      <td>0.011684</td>
      <td>-0.407384</td>
      <td>-0.387522</td>
      <td>-0.259241</td>
      <td>-0.291113</td>
      <td>-0.732444</td>
      <td>-0.473155</td>
      <td>0.892880</td>
      <td>-0.205222</td>
      <td>-0.038131</td>
      <td>-0.109264</td>
      <td>-1.114316</td>
      <td>-1.079815</td>
      <td>-0.172202</td>
      <td>-0.234846</td>
      <td>...</td>
      <td>-0.716112</td>
      <td>-0.073650</td>
      <td>0.239776</td>
      <td>0.194922</td>
      <td>-1.112242</td>
      <td>0.513953</td>
      <td>-0.519295</td>
      <td>0.708477</td>
      <td>0.259607</td>
      <td>0.820849</td>
      <td>0.320696</td>
      <td>1.725704</td>
      <td>0.176102</td>
      <td>-0.550538</td>
      <td>0.033751</td>
      <td>-0.017450</td>
      <td>-1.921373</td>
      <td>-0.339033</td>
      <td>-0.400134</td>
      <td>-0.505959</td>
      <td>0.452945</td>
      <td>-0.194398</td>
      <td>0.007037</td>
      <td>-0.037341</td>
      <td>0.468222</td>
      <td>-0.855359</td>
      <td>0.537129</td>
      <td>-0.064897</td>
      <td>0.854021</td>
      <td>0.792798</td>
      <td>-0.039875</td>
      <td>-0.773125</td>
      <td>0.278500</td>
      <td>1.024460</td>
      <td>-0.572071</td>
      <td>0.028728</td>
      <td>0.558189</td>
      <td>-0.211586</td>
      <td>-0.360159</td>
      <td>-0.018326</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.273155</td>
      <td>-0.472122</td>
      <td>-0.674230</td>
      <td>1.023652</td>
      <td>1.289967</td>
      <td>-0.299462</td>
      <td>0.338721</td>
      <td>0.193720</td>
      <td>0.227833</td>
      <td>0.015642</td>
      <td>0.488079</td>
      <td>1.034662</td>
      <td>0.680197</td>
      <td>-0.885933</td>
      <td>0.294083</td>
      <td>0.618772</td>
      <td>0.149523</td>
      <td>0.663930</td>
      <td>-0.348696</td>
      <td>0.637257</td>
      <td>-0.047651</td>
      <td>0.778669</td>
      <td>0.987138</td>
      <td>1.988046</td>
      <td>0.562449</td>
      <td>-0.014114</td>
      <td>-1.633504</td>
      <td>-0.299159</td>
      <td>-0.440207</td>
      <td>0.370263</td>
      <td>0.590391</td>
      <td>0.466308</td>
      <td>0.952735</td>
      <td>0.444613</td>
      <td>1.130485</td>
      <td>-0.223123</td>
      <td>0.096181</td>
      <td>0.345514</td>
      <td>-0.043921</td>
      <td>-0.430134</td>
      <td>...</td>
      <td>0.296963</td>
      <td>0.739655</td>
      <td>0.007953</td>
      <td>-1.024566</td>
      <td>-1.417037</td>
      <td>-0.350594</td>
      <td>-0.864740</td>
      <td>-0.820709</td>
      <td>-0.616827</td>
      <td>0.505167</td>
      <td>0.923807</td>
      <td>1.308015</td>
      <td>-0.113440</td>
      <td>-0.273242</td>
      <td>0.301116</td>
      <td>0.784838</td>
      <td>-0.563143</td>
      <td>-0.118346</td>
      <td>-1.497937</td>
      <td>-0.759240</td>
      <td>-0.880092</td>
      <td>-0.657405</td>
      <td>-0.150770</td>
      <td>-0.430723</td>
      <td>0.614988</td>
      <td>0.075697</td>
      <td>-0.100655</td>
      <td>-0.396302</td>
      <td>0.693051</td>
      <td>-0.173834</td>
      <td>-0.723794</td>
      <td>-0.087912</td>
      <td>-1.384680</td>
      <td>0.164450</td>
      <td>-0.287861</td>
      <td>-0.426818</td>
      <td>-0.010236</td>
      <td>0.673243</td>
      <td>0.783010</td>
      <td>0.437896</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.225744</td>
      <td>0.744713</td>
      <td>-0.036693</td>
      <td>1.049724</td>
      <td>0.190953</td>
      <td>-0.468739</td>
      <td>-0.129659</td>
      <td>0.492530</td>
      <td>0.181874</td>
      <td>0.674355</td>
      <td>-1.790509</td>
      <td>0.294261</td>
      <td>-0.894995</td>
      <td>-1.226109</td>
      <td>-0.601012</td>
      <td>-0.434751</td>
      <td>1.556032</td>
      <td>1.001168</td>
      <td>-0.809670</td>
      <td>0.504366</td>
      <td>-0.537763</td>
      <td>-0.563255</td>
      <td>0.356646</td>
      <td>0.199915</td>
      <td>0.353826</td>
      <td>0.334032</td>
      <td>-0.199858</td>
      <td>-0.478460</td>
      <td>1.027957</td>
      <td>-0.282145</td>
      <td>-1.076535</td>
      <td>-0.048695</td>
      <td>-0.268820</td>
      <td>-0.577383</td>
      <td>0.043549</td>
      <td>-0.313932</td>
      <td>-0.854290</td>
      <td>0.522121</td>
      <td>0.322835</td>
      <td>0.186291</td>
      <td>...</td>
      <td>-0.057201</td>
      <td>0.831135</td>
      <td>0.577556</td>
      <td>0.143484</td>
      <td>-1.029723</td>
      <td>-1.277346</td>
      <td>-1.252806</td>
      <td>-0.583929</td>
      <td>-0.642243</td>
      <td>-0.462794</td>
      <td>-0.296868</td>
      <td>0.235835</td>
      <td>-0.534265</td>
      <td>0.538887</td>
      <td>1.175603</td>
      <td>0.768748</td>
      <td>-0.868505</td>
      <td>-0.319532</td>
      <td>-1.377536</td>
      <td>-0.555165</td>
      <td>-0.245235</td>
      <td>-0.241597</td>
      <td>-1.054340</td>
      <td>-0.566538</td>
      <td>0.023076</td>
      <td>-0.796129</td>
      <td>-0.396673</td>
      <td>-0.370213</td>
      <td>0.459724</td>
      <td>1.161400</td>
      <td>0.736439</td>
      <td>0.916487</td>
      <td>0.681492</td>
      <td>1.160927</td>
      <td>0.422614</td>
      <td>0.259556</td>
      <td>1.308894</td>
      <td>-0.783448</td>
      <td>0.227152</td>
      <td>0.066190</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.633830</td>
      <td>-0.388287</td>
      <td>0.179972</td>
      <td>0.313338</td>
      <td>-0.376613</td>
      <td>-0.820493</td>
      <td>0.700667</td>
      <td>0.783999</td>
      <td>-0.898359</td>
      <td>-0.626830</td>
      <td>-0.297078</td>
      <td>-0.754256</td>
      <td>-1.373627</td>
      <td>-0.391745</td>
      <td>-0.069566</td>
      <td>0.249647</td>
      <td>-0.139385</td>
      <td>0.172234</td>
      <td>-0.066635</td>
      <td>0.616538</td>
      <td>-0.577268</td>
      <td>-0.218131</td>
      <td>0.065979</td>
      <td>0.331522</td>
      <td>0.630233</td>
      <td>-0.464426</td>
      <td>-0.279554</td>
      <td>0.282715</td>
      <td>-1.355375</td>
      <td>0.614992</td>
      <td>-0.650392</td>
      <td>-0.057514</td>
      <td>0.199931</td>
      <td>0.403079</td>
      <td>-0.381789</td>
      <td>0.199883</td>
      <td>-0.362005</td>
      <td>-0.206677</td>
      <td>1.156906</td>
      <td>0.563015</td>
      <td>...</td>
      <td>-0.950030</td>
      <td>-0.312337</td>
      <td>0.520332</td>
      <td>0.113728</td>
      <td>-0.357216</td>
      <td>1.100599</td>
      <td>0.948468</td>
      <td>-0.148695</td>
      <td>-0.736885</td>
      <td>-0.489726</td>
      <td>-0.810978</td>
      <td>0.254121</td>
      <td>-0.513731</td>
      <td>-0.220812</td>
      <td>0.290163</td>
      <td>-0.522306</td>
      <td>-0.411564</td>
      <td>-0.611782</td>
      <td>-0.546272</td>
      <td>-0.483717</td>
      <td>0.206378</td>
      <td>-0.818182</td>
      <td>-0.365882</td>
      <td>-0.861080</td>
      <td>-0.200261</td>
      <td>-0.305306</td>
      <td>-0.798484</td>
      <td>-0.690851</td>
      <td>0.223389</td>
      <td>0.304289</td>
      <td>0.686377</td>
      <td>0.352448</td>
      <td>-0.222847</td>
      <td>-1.065455</td>
      <td>-1.193600</td>
      <td>-0.906081</td>
      <td>-0.729659</td>
      <td>-2.257924</td>
      <td>-1.145435</td>
      <td>-0.455415</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-0.673778</td>
      <td>-0.285032</td>
      <td>0.601538</td>
      <td>0.040507</td>
      <td>-0.198828</td>
      <td>0.087894</td>
      <td>-0.972055</td>
      <td>-0.827769</td>
      <td>0.023113</td>
      <td>-0.264453</td>
      <td>-0.572246</td>
      <td>-0.566201</td>
      <td>-0.959656</td>
      <td>-0.529678</td>
      <td>-0.726042</td>
      <td>0.487978</td>
      <td>0.818683</td>
      <td>0.698532</td>
      <td>-0.947587</td>
      <td>0.426547</td>
      <td>1.217015</td>
      <td>0.135727</td>
      <td>0.466680</td>
      <td>0.535574</td>
      <td>0.659092</td>
      <td>0.477625</td>
      <td>-1.292519</td>
      <td>-0.214555</td>
      <td>0.551172</td>
      <td>-0.519904</td>
      <td>-0.190946</td>
      <td>0.325950</td>
      <td>0.114889</td>
      <td>-0.332286</td>
      <td>0.487226</td>
      <td>-0.558438</td>
      <td>0.601508</td>
      <td>-0.409065</td>
      <td>0.542664</td>
      <td>0.305308</td>
      <td>...</td>
      <td>-0.753722</td>
      <td>1.357743</td>
      <td>0.117947</td>
      <td>-0.174749</td>
      <td>-0.318462</td>
      <td>0.264301</td>
      <td>-0.175652</td>
      <td>-0.267847</td>
      <td>0.428045</td>
      <td>-0.157896</td>
      <td>-0.408867</td>
      <td>0.672031</td>
      <td>-0.444156</td>
      <td>-0.455271</td>
      <td>-0.174826</td>
      <td>0.792067</td>
      <td>-0.570264</td>
      <td>-0.058021</td>
      <td>0.136071</td>
      <td>-0.592155</td>
      <td>0.708987</td>
      <td>0.107658</td>
      <td>-0.793036</td>
      <td>-0.315863</td>
      <td>0.605936</td>
      <td>0.437760</td>
      <td>0.240723</td>
      <td>-0.258714</td>
      <td>-0.522964</td>
      <td>-0.098384</td>
      <td>-0.108965</td>
      <td>0.145166</td>
      <td>-0.713590</td>
      <td>-0.067959</td>
      <td>-1.069763</td>
      <td>-0.488447</td>
      <td>-0.520307</td>
      <td>-1.589498</td>
      <td>-0.372713</td>
      <td>-0.114669</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.903480</td>
      <td>-0.183526</td>
      <td>0.238474</td>
      <td>0.118474</td>
      <td>0.232419</td>
      <td>0.624492</td>
      <td>0.046134</td>
      <td>0.155025</td>
      <td>-0.106678</td>
      <td>0.355994</td>
      <td>0.350073</td>
      <td>1.087954</td>
      <td>0.391906</td>
      <td>0.144230</td>
      <td>-0.559668</td>
      <td>0.372774</td>
      <td>1.101863</td>
      <td>0.786635</td>
      <td>-0.484014</td>
      <td>0.045585</td>
      <td>0.115230</td>
      <td>0.404348</td>
      <td>-0.452083</td>
      <td>-0.911052</td>
      <td>0.383468</td>
      <td>0.413140</td>
      <td>-0.498951</td>
      <td>0.059254</td>
      <td>-0.705555</td>
      <td>0.100054</td>
      <td>-0.640711</td>
      <td>-0.578064</td>
      <td>-0.246062</td>
      <td>0.003969</td>
      <td>0.605174</td>
      <td>0.285972</td>
      <td>0.495429</td>
      <td>0.479916</td>
      <td>0.089383</td>
      <td>0.649770</td>
      <td>...</td>
      <td>-0.150154</td>
      <td>1.257307</td>
      <td>-0.039670</td>
      <td>-0.697943</td>
      <td>-0.916779</td>
      <td>-0.208355</td>
      <td>0.126021</td>
      <td>-0.743831</td>
      <td>0.157068</td>
      <td>-0.340477</td>
      <td>-0.052472</td>
      <td>1.060218</td>
      <td>1.322968</td>
      <td>1.056977</td>
      <td>0.371153</td>
      <td>-0.308654</td>
      <td>0.647302</td>
      <td>0.797388</td>
      <td>-1.016269</td>
      <td>-1.099793</td>
      <td>-0.093691</td>
      <td>-0.344899</td>
      <td>-0.139365</td>
      <td>0.288887</td>
      <td>0.517381</td>
      <td>0.364759</td>
      <td>-0.053239</td>
      <td>-0.361858</td>
      <td>0.168421</td>
      <td>-0.014386</td>
      <td>0.280282</td>
      <td>0.449155</td>
      <td>0.140769</td>
      <td>0.226015</td>
      <td>-0.407954</td>
      <td>-0.314053</td>
      <td>0.019315</td>
      <td>-1.054641</td>
      <td>-0.581459</td>
      <td>0.105572</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.553710</td>
      <td>-0.142198</td>
      <td>0.057874</td>
      <td>0.624764</td>
      <td>1.163058</td>
      <td>0.610299</td>
      <td>0.589320</td>
      <td>1.036116</td>
      <td>-0.276817</td>
      <td>-0.646925</td>
      <td>0.190152</td>
      <td>-0.268093</td>
      <td>-0.166766</td>
      <td>0.243094</td>
      <td>0.560056</td>
      <td>1.146532</td>
      <td>0.610709</td>
      <td>1.074331</td>
      <td>0.354832</td>
      <td>0.317217</td>
      <td>-0.835123</td>
      <td>-0.501753</td>
      <td>0.536771</td>
      <td>1.178779</td>
      <td>0.654298</td>
      <td>1.011605</td>
      <td>0.462893</td>
      <td>0.438963</td>
      <td>0.003614</td>
      <td>-0.150147</td>
      <td>0.209818</td>
      <td>1.044252</td>
      <td>0.157697</td>
      <td>0.383899</td>
      <td>0.070254</td>
      <td>0.046550</td>
      <td>0.837359</td>
      <td>-0.411153</td>
      <td>0.237578</td>
      <td>-0.191455</td>
      <td>...</td>
      <td>0.749217</td>
      <td>0.271743</td>
      <td>1.307753</td>
      <td>0.732252</td>
      <td>-0.465166</td>
      <td>-0.359027</td>
      <td>0.162089</td>
      <td>0.954221</td>
      <td>0.666806</td>
      <td>0.115487</td>
      <td>0.181333</td>
      <td>1.463776</td>
      <td>0.473167</td>
      <td>-0.857900</td>
      <td>0.791709</td>
      <td>0.270297</td>
      <td>-1.394780</td>
      <td>-1.396978</td>
      <td>-1.239362</td>
      <td>-0.491313</td>
      <td>-0.135381</td>
      <td>0.474677</td>
      <td>-0.108150</td>
      <td>0.245629</td>
      <td>-0.130454</td>
      <td>0.167520</td>
      <td>-0.167037</td>
      <td>0.489844</td>
      <td>0.212898</td>
      <td>-0.968948</td>
      <td>-1.329550</td>
      <td>-0.836392</td>
      <td>-0.519512</td>
      <td>-0.086110</td>
      <td>0.840378</td>
      <td>-0.295841</td>
      <td>-0.115304</td>
      <td>-1.393695</td>
      <td>-0.112150</td>
      <td>-0.170338</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-0.038852</td>
      <td>0.479096</td>
      <td>0.398434</td>
      <td>0.600048</td>
      <td>0.171731</td>
      <td>-0.821158</td>
      <td>-0.176608</td>
      <td>0.451687</td>
      <td>-0.100208</td>
      <td>-0.523639</td>
      <td>-0.182676</td>
      <td>0.425545</td>
      <td>-1.164064</td>
      <td>-0.350518</td>
      <td>-0.644669</td>
      <td>-0.068512</td>
      <td>0.189325</td>
      <td>-0.951349</td>
      <td>0.247607</td>
      <td>0.056908</td>
      <td>-0.696722</td>
      <td>-0.522478</td>
      <td>0.787260</td>
      <td>1.066640</td>
      <td>0.672218</td>
      <td>-0.129883</td>
      <td>-0.645150</td>
      <td>0.781354</td>
      <td>0.481709</td>
      <td>0.256824</td>
      <td>-0.462602</td>
      <td>0.895066</td>
      <td>1.106084</td>
      <td>-0.088750</td>
      <td>-0.611820</td>
      <td>-0.340693</td>
      <td>0.767099</td>
      <td>0.665865</td>
      <td>0.264554</td>
      <td>0.021572</td>
      <td>...</td>
      <td>0.401335</td>
      <td>0.421495</td>
      <td>0.802268</td>
      <td>0.368345</td>
      <td>-0.668977</td>
      <td>0.036773</td>
      <td>-0.914943</td>
      <td>-0.140971</td>
      <td>0.260723</td>
      <td>-0.411350</td>
      <td>-1.057825</td>
      <td>0.195302</td>
      <td>0.013332</td>
      <td>-0.093437</td>
      <td>0.534197</td>
      <td>-0.975177</td>
      <td>-0.577641</td>
      <td>0.123993</td>
      <td>-0.411601</td>
      <td>-0.822412</td>
      <td>-0.046561</td>
      <td>-0.794292</td>
      <td>-0.134001</td>
      <td>-0.244161</td>
      <td>0.181723</td>
      <td>0.021338</td>
      <td>0.557190</td>
      <td>-0.585141</td>
      <td>0.358504</td>
      <td>0.416359</td>
      <td>-0.205756</td>
      <td>-0.099717</td>
      <td>0.572163</td>
      <td>0.551111</td>
      <td>-0.245761</td>
      <td>0.271121</td>
      <td>0.584031</td>
      <td>0.870870</td>
      <td>0.267874</td>
      <td>0.208577</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-0.056239</td>
      <td>0.283131</td>
      <td>0.730448</td>
      <td>0.389263</td>
      <td>-0.982724</td>
      <td>-0.622550</td>
      <td>-0.077986</td>
      <td>0.548390</td>
      <td>-0.107534</td>
      <td>-0.626053</td>
      <td>-0.785950</td>
      <td>0.289333</td>
      <td>-0.123831</td>
      <td>0.135948</td>
      <td>1.267017</td>
      <td>-0.150347</td>
      <td>0.724163</td>
      <td>-0.159419</td>
      <td>0.403354</td>
      <td>-0.160282</td>
      <td>0.273794</td>
      <td>-0.343017</td>
      <td>-0.339120</td>
      <td>-0.209203</td>
      <td>0.343140</td>
      <td>1.470970</td>
      <td>-0.547074</td>
      <td>-1.364081</td>
      <td>-0.035329</td>
      <td>0.327421</td>
      <td>-0.562100</td>
      <td>-0.185859</td>
      <td>1.818840</td>
      <td>0.410390</td>
      <td>-0.346921</td>
      <td>0.150483</td>
      <td>-0.270910</td>
      <td>-0.518386</td>
      <td>0.137437</td>
      <td>-0.142152</td>
      <td>...</td>
      <td>0.598641</td>
      <td>0.234465</td>
      <td>0.269516</td>
      <td>0.673800</td>
      <td>0.502247</td>
      <td>-0.146007</td>
      <td>0.519588</td>
      <td>-0.032598</td>
      <td>0.669610</td>
      <td>-0.123764</td>
      <td>-0.413281</td>
      <td>-0.922531</td>
      <td>-0.608840</td>
      <td>-0.115192</td>
      <td>0.201806</td>
      <td>0.728640</td>
      <td>-1.147759</td>
      <td>-0.433379</td>
      <td>-0.704712</td>
      <td>-0.575680</td>
      <td>-1.011665</td>
      <td>-0.582328</td>
      <td>0.051763</td>
      <td>0.131443</td>
      <td>-0.541667</td>
      <td>-0.228739</td>
      <td>-0.555739</td>
      <td>-0.010739</td>
      <td>-0.182539</td>
      <td>0.255335</td>
      <td>0.314422</td>
      <td>0.936192</td>
      <td>-0.406129</td>
      <td>0.930159</td>
      <td>-0.427019</td>
      <td>-0.201641</td>
      <td>0.291545</td>
      <td>2.413225</td>
      <td>1.941708</td>
      <td>0.691354</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.690312</td>
      <td>0.107625</td>
      <td>-0.294887</td>
      <td>0.575533</td>
      <td>-0.147258</td>
      <td>-0.841370</td>
      <td>0.495056</td>
      <td>0.253214</td>
      <td>0.413410</td>
      <td>-0.335578</td>
      <td>-0.443190</td>
      <td>-0.610003</td>
      <td>-1.091529</td>
      <td>-0.651508</td>
      <td>-0.228399</td>
      <td>-0.362890</td>
      <td>0.159640</td>
      <td>0.295801</td>
      <td>0.123300</td>
      <td>0.038013</td>
      <td>-0.204700</td>
      <td>-1.233362</td>
      <td>-0.188873</td>
      <td>0.284989</td>
      <td>0.602008</td>
      <td>0.358513</td>
      <td>-0.847723</td>
      <td>-0.810415</td>
      <td>0.098933</td>
      <td>0.923908</td>
      <td>-0.097613</td>
      <td>1.029001</td>
      <td>0.289729</td>
      <td>0.695422</td>
      <td>0.206295</td>
      <td>-0.576155</td>
      <td>0.206763</td>
      <td>-1.077146</td>
      <td>0.109199</td>
      <td>-0.958404</td>
      <td>...</td>
      <td>0.584595</td>
      <td>1.303807</td>
      <td>0.289247</td>
      <td>-0.917431</td>
      <td>-0.977026</td>
      <td>-0.609471</td>
      <td>0.570075</td>
      <td>0.203025</td>
      <td>-0.034318</td>
      <td>-0.194123</td>
      <td>-0.390400</td>
      <td>0.127581</td>
      <td>-0.221193</td>
      <td>0.477738</td>
      <td>0.818047</td>
      <td>0.780933</td>
      <td>-0.497539</td>
      <td>0.238809</td>
      <td>0.102598</td>
      <td>-0.545684</td>
      <td>0.436057</td>
      <td>1.015270</td>
      <td>-0.329126</td>
      <td>-0.305502</td>
      <td>-0.738604</td>
      <td>-0.244388</td>
      <td>0.363209</td>
      <td>0.222278</td>
      <td>1.441819</td>
      <td>-0.176891</td>
      <td>0.995293</td>
      <td>0.694534</td>
      <td>0.798079</td>
      <td>-0.750046</td>
      <td>-0.028470</td>
      <td>-0.296157</td>
      <td>-0.232948</td>
      <td>0.923655</td>
      <td>0.592929</td>
      <td>-0.126672</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.411025</td>
      <td>-0.251298</td>
      <td>0.108866</td>
      <td>-0.066029</td>
      <td>-0.523046</td>
      <td>-0.859687</td>
      <td>0.657323</td>
      <td>0.363803</td>
      <td>-0.578729</td>
      <td>-1.591871</td>
      <td>-0.969168</td>
      <td>-0.693048</td>
      <td>-1.408607</td>
      <td>0.326410</td>
      <td>0.551009</td>
      <td>1.364366</td>
      <td>1.332871</td>
      <td>1.111938</td>
      <td>0.292362</td>
      <td>-0.638772</td>
      <td>0.447673</td>
      <td>0.166244</td>
      <td>0.964078</td>
      <td>0.635791</td>
      <td>1.133942</td>
      <td>0.040899</td>
      <td>-1.109135</td>
      <td>-0.762161</td>
      <td>0.126616</td>
      <td>0.223142</td>
      <td>0.445371</td>
      <td>-0.052178</td>
      <td>-0.173204</td>
      <td>-0.409279</td>
      <td>0.162615</td>
      <td>0.223187</td>
      <td>0.758539</td>
      <td>-0.124975</td>
      <td>1.054284</td>
      <td>0.115333</td>
      <td>...</td>
      <td>0.744385</td>
      <td>-0.243705</td>
      <td>0.696494</td>
      <td>-0.206425</td>
      <td>-0.682857</td>
      <td>0.126902</td>
      <td>1.012178</td>
      <td>1.156545</td>
      <td>0.890816</td>
      <td>-0.901158</td>
      <td>0.461423</td>
      <td>1.292037</td>
      <td>-0.047853</td>
      <td>0.526752</td>
      <td>0.344254</td>
      <td>-0.730080</td>
      <td>-0.933586</td>
      <td>-0.301711</td>
      <td>1.161791</td>
      <td>-0.231122</td>
      <td>-0.290688</td>
      <td>-0.167870</td>
      <td>-0.196800</td>
      <td>0.917877</td>
      <td>-0.053266</td>
      <td>-0.596731</td>
      <td>0.426513</td>
      <td>-0.160457</td>
      <td>0.402783</td>
      <td>-0.189430</td>
      <td>-0.274097</td>
      <td>0.830582</td>
      <td>0.331909</td>
      <td>0.743684</td>
      <td>0.559036</td>
      <td>0.952257</td>
      <td>1.023272</td>
      <td>-2.065782</td>
      <td>-1.389205</td>
      <td>-0.576868</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.003009</td>
      <td>0.273773</td>
      <td>0.970127</td>
      <td>-0.032990</td>
      <td>-0.418656</td>
      <td>-0.810244</td>
      <td>-0.267411</td>
      <td>0.867530</td>
      <td>0.651739</td>
      <td>0.383277</td>
      <td>0.535304</td>
      <td>0.278766</td>
      <td>-0.245607</td>
      <td>-0.993223</td>
      <td>-0.355360</td>
      <td>1.075747</td>
      <td>-0.136438</td>
      <td>0.353499</td>
      <td>-0.982892</td>
      <td>0.977286</td>
      <td>0.155568</td>
      <td>-0.189097</td>
      <td>1.165622</td>
      <td>0.765469</td>
      <td>0.253951</td>
      <td>0.328380</td>
      <td>-0.983197</td>
      <td>-0.642443</td>
      <td>-0.109416</td>
      <td>0.061326</td>
      <td>-0.046306</td>
      <td>0.104348</td>
      <td>-0.036119</td>
      <td>0.669573</td>
      <td>0.443458</td>
      <td>0.543849</td>
      <td>1.008416</td>
      <td>-0.588899</td>
      <td>-0.365638</td>
      <td>-0.280571</td>
      <td>...</td>
      <td>-0.948283</td>
      <td>0.260033</td>
      <td>0.704749</td>
      <td>-0.151218</td>
      <td>-0.918054</td>
      <td>0.589078</td>
      <td>-0.211169</td>
      <td>-0.060435</td>
      <td>0.387903</td>
      <td>-0.312420</td>
      <td>-0.054589</td>
      <td>0.223765</td>
      <td>-0.875829</td>
      <td>-0.731798</td>
      <td>0.234340</td>
      <td>-0.493969</td>
      <td>0.049617</td>
      <td>0.132646</td>
      <td>-0.538910</td>
      <td>-0.414897</td>
      <td>0.780269</td>
      <td>-0.720630</td>
      <td>0.359360</td>
      <td>0.305672</td>
      <td>0.592457</td>
      <td>0.904739</td>
      <td>1.097387</td>
      <td>-0.200108</td>
      <td>-0.662239</td>
      <td>0.789996</td>
      <td>0.562035</td>
      <td>0.725159</td>
      <td>0.773664</td>
      <td>0.338134</td>
      <td>-1.352776</td>
      <td>0.901986</td>
      <td>-0.908362</td>
      <td>1.468616</td>
      <td>0.976097</td>
      <td>0.994438</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.237753</td>
      <td>0.209984</td>
      <td>-0.132155</td>
      <td>-0.722388</td>
      <td>-0.143579</td>
      <td>-0.601959</td>
      <td>0.091214</td>
      <td>0.559688</td>
      <td>-1.157105</td>
      <td>-1.325450</td>
      <td>-0.142340</td>
      <td>-0.396797</td>
      <td>0.324302</td>
      <td>0.732607</td>
      <td>0.317359</td>
      <td>0.750835</td>
      <td>0.338011</td>
      <td>-0.401165</td>
      <td>-1.364536</td>
      <td>-0.264167</td>
      <td>0.297169</td>
      <td>0.220871</td>
      <td>-0.165071</td>
      <td>0.579803</td>
      <td>-0.484341</td>
      <td>-0.661154</td>
      <td>-0.811800</td>
      <td>-0.005933</td>
      <td>-0.087863</td>
      <td>0.132768</td>
      <td>-0.596636</td>
      <td>-0.123320</td>
      <td>-0.207272</td>
      <td>-0.204975</td>
      <td>0.202810</td>
      <td>-0.452246</td>
      <td>0.262170</td>
      <td>-0.589537</td>
      <td>-1.080284</td>
      <td>0.173324</td>
      <td>...</td>
      <td>-0.176895</td>
      <td>0.993727</td>
      <td>-0.339703</td>
      <td>0.084844</td>
      <td>-0.970691</td>
      <td>-0.426156</td>
      <td>0.702554</td>
      <td>0.801957</td>
      <td>1.112104</td>
      <td>0.508261</td>
      <td>0.300495</td>
      <td>0.097432</td>
      <td>-0.148017</td>
      <td>0.153419</td>
      <td>0.656623</td>
      <td>0.266745</td>
      <td>-0.729516</td>
      <td>0.416505</td>
      <td>0.182605</td>
      <td>1.115495</td>
      <td>-0.342131</td>
      <td>-0.741470</td>
      <td>-0.491567</td>
      <td>0.062634</td>
      <td>-0.830183</td>
      <td>-0.696522</td>
      <td>0.411660</td>
      <td>-0.443986</td>
      <td>0.084898</td>
      <td>-0.001526</td>
      <td>-0.009089</td>
      <td>-0.318974</td>
      <td>0.714367</td>
      <td>0.365454</td>
      <td>-1.138053</td>
      <td>0.516378</td>
      <td>0.657994</td>
      <td>0.876517</td>
      <td>1.667861</td>
      <td>1.532765</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.079276</td>
      <td>-0.398378</td>
      <td>-0.136286</td>
      <td>0.678400</td>
      <td>0.374904</td>
      <td>-0.028053</td>
      <td>0.355114</td>
      <td>1.250491</td>
      <td>-0.114544</td>
      <td>-0.183978</td>
      <td>-0.270320</td>
      <td>0.154842</td>
      <td>0.361645</td>
      <td>-1.073027</td>
      <td>0.059754</td>
      <td>0.374770</td>
      <td>0.610371</td>
      <td>0.991299</td>
      <td>-0.002301</td>
      <td>0.380299</td>
      <td>0.078503</td>
      <td>0.476185</td>
      <td>0.439017</td>
      <td>-0.331471</td>
      <td>0.100694</td>
      <td>-0.271655</td>
      <td>-0.336257</td>
      <td>-0.828521</td>
      <td>-0.693864</td>
      <td>-0.045769</td>
      <td>0.313893</td>
      <td>-0.730433</td>
      <td>-0.489803</td>
      <td>0.358602</td>
      <td>0.486857</td>
      <td>-0.748702</td>
      <td>0.063087</td>
      <td>0.562959</td>
      <td>0.080119</td>
      <td>0.494383</td>
      <td>...</td>
      <td>-0.364073</td>
      <td>1.323672</td>
      <td>-0.359500</td>
      <td>-0.598772</td>
      <td>-0.161952</td>
      <td>-0.148511</td>
      <td>0.177349</td>
      <td>-0.219606</td>
      <td>0.458536</td>
      <td>1.133880</td>
      <td>0.319336</td>
      <td>0.345720</td>
      <td>-0.099359</td>
      <td>0.640673</td>
      <td>0.322040</td>
      <td>0.564407</td>
      <td>-0.535532</td>
      <td>0.095996</td>
      <td>-1.264194</td>
      <td>-0.578609</td>
      <td>0.432876</td>
      <td>-0.642569</td>
      <td>-0.070828</td>
      <td>-1.021370</td>
      <td>0.847918</td>
      <td>0.607852</td>
      <td>1.136066</td>
      <td>-0.730201</td>
      <td>0.817719</td>
      <td>1.154118</td>
      <td>-0.025533</td>
      <td>0.625593</td>
      <td>0.204526</td>
      <td>0.877838</td>
      <td>-0.054823</td>
      <td>0.237993</td>
      <td>-0.232407</td>
      <td>-0.161326</td>
      <td>-0.067964</td>
      <td>-0.863755</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.393056</td>
      <td>0.450181</td>
      <td>-0.388629</td>
      <td>-0.384682</td>
      <td>0.409045</td>
      <td>-0.756431</td>
      <td>-0.322525</td>
      <td>0.906574</td>
      <td>0.250190</td>
      <td>-0.783515</td>
      <td>-0.492868</td>
      <td>0.122599</td>
      <td>-0.383936</td>
      <td>0.190971</td>
      <td>-0.710406</td>
      <td>-0.108884</td>
      <td>0.287394</td>
      <td>-0.416450</td>
      <td>-0.342777</td>
      <td>-0.646922</td>
      <td>-0.994433</td>
      <td>0.371723</td>
      <td>0.239164</td>
      <td>-0.200140</td>
      <td>-0.261735</td>
      <td>0.012357</td>
      <td>-0.893601</td>
      <td>-0.680885</td>
      <td>-0.866745</td>
      <td>-0.093929</td>
      <td>-0.374979</td>
      <td>0.129437</td>
      <td>0.282780</td>
      <td>-0.108784</td>
      <td>0.157567</td>
      <td>-0.771177</td>
      <td>0.049289</td>
      <td>0.237367</td>
      <td>-0.463734</td>
      <td>0.103333</td>
      <td>...</td>
      <td>1.012543</td>
      <td>1.174344</td>
      <td>0.686313</td>
      <td>0.371316</td>
      <td>0.345051</td>
      <td>-0.284840</td>
      <td>0.053595</td>
      <td>-0.522776</td>
      <td>-0.247658</td>
      <td>-0.246858</td>
      <td>-0.411779</td>
      <td>1.076458</td>
      <td>0.425287</td>
      <td>-0.128709</td>
      <td>-0.320989</td>
      <td>0.270118</td>
      <td>0.034679</td>
      <td>-0.267309</td>
      <td>-0.531660</td>
      <td>0.138802</td>
      <td>0.581824</td>
      <td>0.328114</td>
      <td>-0.572488</td>
      <td>0.425256</td>
      <td>-0.502336</td>
      <td>0.609652</td>
      <td>0.454165</td>
      <td>-0.057992</td>
      <td>0.768266</td>
      <td>0.742608</td>
      <td>0.354635</td>
      <td>0.331558</td>
      <td>-0.307874</td>
      <td>0.249796</td>
      <td>0.117911</td>
      <td>0.393552</td>
      <td>0.029375</td>
      <td>0.706936</td>
      <td>0.615201</td>
      <td>0.426231</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.580767</td>
      <td>-0.593519</td>
      <td>-0.153676</td>
      <td>1.397439</td>
      <td>-0.285020</td>
      <td>-1.287798</td>
      <td>0.785000</td>
      <td>0.046149</td>
      <td>-1.018823</td>
      <td>-0.293355</td>
      <td>0.488153</td>
      <td>1.053335</td>
      <td>-0.265438</td>
      <td>-0.743571</td>
      <td>0.232027</td>
      <td>-0.105413</td>
      <td>-0.000282</td>
      <td>-0.083786</td>
      <td>-0.025795</td>
      <td>-0.259139</td>
      <td>0.437835</td>
      <td>0.307291</td>
      <td>0.172084</td>
      <td>0.742361</td>
      <td>0.895758</td>
      <td>0.500136</td>
      <td>-0.421646</td>
      <td>0.513144</td>
      <td>-0.274941</td>
      <td>0.125113</td>
      <td>-0.370222</td>
      <td>-0.842627</td>
      <td>1.110174</td>
      <td>1.196635</td>
      <td>0.528615</td>
      <td>0.166189</td>
      <td>-0.630328</td>
      <td>-0.180561</td>
      <td>0.915060</td>
      <td>0.368830</td>
      <td>...</td>
      <td>-0.514967</td>
      <td>0.339620</td>
      <td>0.197631</td>
      <td>0.099671</td>
      <td>-0.008488</td>
      <td>0.184134</td>
      <td>-0.455928</td>
      <td>0.414804</td>
      <td>0.138170</td>
      <td>0.930329</td>
      <td>0.422791</td>
      <td>-0.000908</td>
      <td>0.157218</td>
      <td>0.176540</td>
      <td>0.729731</td>
      <td>0.297872</td>
      <td>-0.317865</td>
      <td>1.132750</td>
      <td>-0.165009</td>
      <td>0.241737</td>
      <td>-0.083228</td>
      <td>0.109606</td>
      <td>-0.469848</td>
      <td>0.103974</td>
      <td>1.126105</td>
      <td>-0.219988</td>
      <td>1.693236</td>
      <td>1.165859</td>
      <td>-0.578892</td>
      <td>-0.375232</td>
      <td>-1.167961</td>
      <td>0.582685</td>
      <td>-0.118261</td>
      <td>-0.209538</td>
      <td>-0.407713</td>
      <td>-0.294587</td>
      <td>-0.633194</td>
      <td>-0.323613</td>
      <td>-0.496503</td>
      <td>-0.544986</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.431403</td>
      <td>0.450857</td>
      <td>0.852000</td>
      <td>0.161695</td>
      <td>1.524669</td>
      <td>-0.502282</td>
      <td>-0.157485</td>
      <td>0.644061</td>
      <td>-0.234038</td>
      <td>-0.649827</td>
      <td>-0.504297</td>
      <td>-0.919731</td>
      <td>-1.106398</td>
      <td>-0.441295</td>
      <td>-0.913929</td>
      <td>-0.083359</td>
      <td>0.396201</td>
      <td>0.634057</td>
      <td>-0.411137</td>
      <td>0.648470</td>
      <td>-0.163255</td>
      <td>-0.002663</td>
      <td>0.058305</td>
      <td>0.482784</td>
      <td>0.177156</td>
      <td>-0.209280</td>
      <td>0.148796</td>
      <td>0.214714</td>
      <td>-0.041390</td>
      <td>0.996998</td>
      <td>1.140152</td>
      <td>0.964469</td>
      <td>1.627719</td>
      <td>0.281638</td>
      <td>-0.135131</td>
      <td>0.063388</td>
      <td>0.190502</td>
      <td>0.502063</td>
      <td>-0.017819</td>
      <td>0.764396</td>
      <td>...</td>
      <td>-0.672506</td>
      <td>0.926194</td>
      <td>0.569847</td>
      <td>0.230943</td>
      <td>-0.746872</td>
      <td>0.197037</td>
      <td>-0.327513</td>
      <td>-0.548017</td>
      <td>-0.252136</td>
      <td>-0.329136</td>
      <td>-0.021501</td>
      <td>-0.255752</td>
      <td>-0.470881</td>
      <td>-0.174259</td>
      <td>0.186076</td>
      <td>-0.105846</td>
      <td>0.579555</td>
      <td>0.944059</td>
      <td>-0.268974</td>
      <td>-0.462029</td>
      <td>-0.007220</td>
      <td>-0.717810</td>
      <td>-0.092006</td>
      <td>-0.443565</td>
      <td>0.481982</td>
      <td>0.664826</td>
      <td>1.683780</td>
      <td>-0.504278</td>
      <td>0.261429</td>
      <td>-0.295505</td>
      <td>0.413101</td>
      <td>0.198683</td>
      <td>-0.049232</td>
      <td>0.600931</td>
      <td>1.423784</td>
      <td>-0.631660</td>
      <td>-0.150060</td>
      <td>0.380526</td>
      <td>0.410606</td>
      <td>0.486078</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.443461</td>
      <td>0.487478</td>
      <td>0.075628</td>
      <td>0.616184</td>
      <td>-0.154889</td>
      <td>0.516017</td>
      <td>0.871474</td>
      <td>0.712474</td>
      <td>0.206930</td>
      <td>0.103157</td>
      <td>0.649528</td>
      <td>-1.103573</td>
      <td>-0.038282</td>
      <td>-0.194277</td>
      <td>0.022445</td>
      <td>-0.689443</td>
      <td>0.368472</td>
      <td>-0.568990</td>
      <td>0.866756</td>
      <td>0.472235</td>
      <td>-0.862498</td>
      <td>-0.789405</td>
      <td>-0.400206</td>
      <td>0.176577</td>
      <td>-0.074267</td>
      <td>0.161561</td>
      <td>0.196755</td>
      <td>1.121409</td>
      <td>0.047681</td>
      <td>-0.234615</td>
      <td>0.166362</td>
      <td>0.423506</td>
      <td>-1.480302</td>
      <td>-1.053789</td>
      <td>-0.289412</td>
      <td>-0.075412</td>
      <td>-0.331802</td>
      <td>0.383797</td>
      <td>1.033797</td>
      <td>-1.174218</td>
      <td>...</td>
      <td>0.235791</td>
      <td>1.008620</td>
      <td>-0.582084</td>
      <td>-1.151105</td>
      <td>0.674908</td>
      <td>0.364150</td>
      <td>1.196014</td>
      <td>0.828355</td>
      <td>0.685791</td>
      <td>1.178517</td>
      <td>0.501774</td>
      <td>-1.089883</td>
      <td>0.887837</td>
      <td>0.369424</td>
      <td>0.312102</td>
      <td>0.106437</td>
      <td>0.555863</td>
      <td>0.687122</td>
      <td>-0.004544</td>
      <td>-0.741631</td>
      <td>-0.223725</td>
      <td>-0.162611</td>
      <td>-0.128251</td>
      <td>0.926348</td>
      <td>0.519683</td>
      <td>0.479664</td>
      <td>-0.209135</td>
      <td>0.491967</td>
      <td>0.913871</td>
      <td>-0.060586</td>
      <td>0.079377</td>
      <td>0.187926</td>
      <td>-0.118645</td>
      <td>-0.383011</td>
      <td>0.283298</td>
      <td>0.211190</td>
      <td>1.688088</td>
      <td>0.377155</td>
      <td>-0.295725</td>
      <td>-0.368124</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.621807</td>
      <td>0.368166</td>
      <td>0.437260</td>
      <td>0.451865</td>
      <td>-0.148226</td>
      <td>-1.455510</td>
      <td>-0.247823</td>
      <td>0.166428</td>
      <td>-0.731945</td>
      <td>-0.140982</td>
      <td>-0.021166</td>
      <td>-0.794212</td>
      <td>-1.410035</td>
      <td>-0.354387</td>
      <td>0.172145</td>
      <td>-0.237905</td>
      <td>-1.072337</td>
      <td>0.620065</td>
      <td>-0.704174</td>
      <td>-0.300160</td>
      <td>-0.041081</td>
      <td>0.882669</td>
      <td>-0.907773</td>
      <td>0.648106</td>
      <td>0.180516</td>
      <td>-0.215296</td>
      <td>0.437304</td>
      <td>0.319733</td>
      <td>-0.805248</td>
      <td>-0.725742</td>
      <td>0.224610</td>
      <td>0.214122</td>
      <td>-0.155790</td>
      <td>0.059075</td>
      <td>0.566854</td>
      <td>1.332465</td>
      <td>0.421694</td>
      <td>0.600076</td>
      <td>0.652918</td>
      <td>-0.455298</td>
      <td>...</td>
      <td>0.575644</td>
      <td>-0.263687</td>
      <td>-0.626745</td>
      <td>-0.805851</td>
      <td>0.330510</td>
      <td>1.023550</td>
      <td>0.629237</td>
      <td>0.437024</td>
      <td>0.330257</td>
      <td>0.539707</td>
      <td>0.016692</td>
      <td>-0.489377</td>
      <td>-0.579033</td>
      <td>0.266135</td>
      <td>0.714875</td>
      <td>0.713840</td>
      <td>0.103719</td>
      <td>-0.036412</td>
      <td>0.399664</td>
      <td>0.016701</td>
      <td>1.207858</td>
      <td>1.220330</td>
      <td>-0.080880</td>
      <td>0.100252</td>
      <td>-1.213674</td>
      <td>0.083011</td>
      <td>-0.169209</td>
      <td>-0.120976</td>
      <td>0.342425</td>
      <td>-0.490499</td>
      <td>-0.114326</td>
      <td>-0.063108</td>
      <td>0.305970</td>
      <td>1.090432</td>
      <td>0.249854</td>
      <td>0.860327</td>
      <td>0.656954</td>
      <td>-0.917183</td>
      <td>-1.003154</td>
      <td>-1.549258</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.118507</td>
      <td>0.348250</td>
      <td>-0.166816</td>
      <td>0.891569</td>
      <td>0.761159</td>
      <td>0.253878</td>
      <td>0.003214</td>
      <td>0.757939</td>
      <td>0.055267</td>
      <td>0.171807</td>
      <td>0.751780</td>
      <td>-0.931321</td>
      <td>0.537162</td>
      <td>-0.066075</td>
      <td>0.502267</td>
      <td>0.837871</td>
      <td>1.003752</td>
      <td>0.174837</td>
      <td>0.465205</td>
      <td>-0.858500</td>
      <td>-0.077595</td>
      <td>-0.298536</td>
      <td>-0.154058</td>
      <td>1.600164</td>
      <td>-0.025529</td>
      <td>0.286980</td>
      <td>0.356630</td>
      <td>0.647119</td>
      <td>0.263869</td>
      <td>-0.252565</td>
      <td>1.343286</td>
      <td>-0.312124</td>
      <td>-0.234010</td>
      <td>0.100292</td>
      <td>-0.950985</td>
      <td>-0.159623</td>
      <td>-0.018676</td>
      <td>0.194592</td>
      <td>-0.026101</td>
      <td>-0.527389</td>
      <td>...</td>
      <td>-0.974974</td>
      <td>0.040077</td>
      <td>-0.294971</td>
      <td>-0.274309</td>
      <td>0.710535</td>
      <td>1.737455</td>
      <td>1.221442</td>
      <td>0.887641</td>
      <td>-0.835798</td>
      <td>1.101688</td>
      <td>0.279944</td>
      <td>-0.880304</td>
      <td>0.591633</td>
      <td>-0.218222</td>
      <td>-0.447677</td>
      <td>0.193637</td>
      <td>0.308112</td>
      <td>-0.482732</td>
      <td>-0.391743</td>
      <td>-0.191342</td>
      <td>-0.452759</td>
      <td>0.635954</td>
      <td>0.448823</td>
      <td>-0.201150</td>
      <td>-0.215931</td>
      <td>-0.266535</td>
      <td>-0.975024</td>
      <td>-0.693241</td>
      <td>-0.533586</td>
      <td>0.153734</td>
      <td>-0.151612</td>
      <td>0.180975</td>
      <td>-0.111701</td>
      <td>0.416301</td>
      <td>-0.618988</td>
      <td>-0.299636</td>
      <td>0.383994</td>
      <td>1.510429</td>
      <td>1.618112</td>
      <td>0.658096</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.674776</td>
      <td>-0.135990</td>
      <td>0.403814</td>
      <td>0.158089</td>
      <td>0.341346</td>
      <td>-0.798553</td>
      <td>-0.077938</td>
      <td>-0.809927</td>
      <td>-0.776840</td>
      <td>-1.281634</td>
      <td>-1.183218</td>
      <td>-0.791275</td>
      <td>-0.084436</td>
      <td>-0.620807</td>
      <td>-0.215476</td>
      <td>0.998156</td>
      <td>-0.486630</td>
      <td>-1.161750</td>
      <td>-0.201299</td>
      <td>0.302246</td>
      <td>0.325741</td>
      <td>0.352142</td>
      <td>0.630084</td>
      <td>0.859966</td>
      <td>0.087368</td>
      <td>-0.177199</td>
      <td>-0.115694</td>
      <td>1.138955</td>
      <td>-1.651797</td>
      <td>-0.802364</td>
      <td>-0.892940</td>
      <td>-0.655364</td>
      <td>-0.166976</td>
      <td>-0.482261</td>
      <td>-0.135208</td>
      <td>-0.099708</td>
      <td>1.350529</td>
      <td>1.118919</td>
      <td>0.396112</td>
      <td>1.103579</td>
      <td>...</td>
      <td>0.056181</td>
      <td>-0.781182</td>
      <td>-0.568306</td>
      <td>-0.275094</td>
      <td>-0.579078</td>
      <td>0.225499</td>
      <td>-0.329980</td>
      <td>0.193902</td>
      <td>-0.375664</td>
      <td>1.104937</td>
      <td>0.186246</td>
      <td>0.258739</td>
      <td>1.068129</td>
      <td>-0.647262</td>
      <td>-0.540466</td>
      <td>0.238070</td>
      <td>-0.122136</td>
      <td>-0.174623</td>
      <td>1.225802</td>
      <td>0.366756</td>
      <td>-0.057807</td>
      <td>-0.733749</td>
      <td>-0.041351</td>
      <td>0.175160</td>
      <td>0.242268</td>
      <td>1.339764</td>
      <td>0.369118</td>
      <td>0.364561</td>
      <td>0.980099</td>
      <td>0.247540</td>
      <td>-0.179987</td>
      <td>0.549654</td>
      <td>-0.597195</td>
      <td>0.457127</td>
      <td>-0.620052</td>
      <td>0.434985</td>
      <td>-0.109772</td>
      <td>-0.778198</td>
      <td>0.059469</td>
      <td>-0.296990</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.741108</td>
      <td>-0.690834</td>
      <td>0.152434</td>
      <td>0.008115</td>
      <td>-0.823255</td>
      <td>0.099197</td>
      <td>0.518956</td>
      <td>0.284373</td>
      <td>-0.271431</td>
      <td>0.287423</td>
      <td>0.500328</td>
      <td>-0.610513</td>
      <td>0.016806</td>
      <td>0.782258</td>
      <td>0.616613</td>
      <td>0.285012</td>
      <td>-0.324512</td>
      <td>0.436596</td>
      <td>-0.469226</td>
      <td>-0.915867</td>
      <td>-0.172784</td>
      <td>-0.216703</td>
      <td>-0.550847</td>
      <td>1.323146</td>
      <td>0.771480</td>
      <td>-0.328730</td>
      <td>-0.421147</td>
      <td>-0.761159</td>
      <td>-0.391314</td>
      <td>-0.318646</td>
      <td>-0.009619</td>
      <td>-0.644445</td>
      <td>-1.084624</td>
      <td>-0.378768</td>
      <td>0.538230</td>
      <td>0.267002</td>
      <td>0.499108</td>
      <td>-0.046271</td>
      <td>0.187380</td>
      <td>-0.477260</td>
      <td>...</td>
      <td>0.930314</td>
      <td>0.065527</td>
      <td>0.108061</td>
      <td>-0.174197</td>
      <td>-0.264503</td>
      <td>-0.798303</td>
      <td>-0.455823</td>
      <td>-0.353210</td>
      <td>-0.934323</td>
      <td>0.645680</td>
      <td>-0.078597</td>
      <td>-0.355742</td>
      <td>-0.789647</td>
      <td>-0.134569</td>
      <td>-0.308058</td>
      <td>0.658322</td>
      <td>-0.231298</td>
      <td>-1.167430</td>
      <td>-0.752637</td>
      <td>1.102142</td>
      <td>1.015142</td>
      <td>0.822358</td>
      <td>0.744121</td>
      <td>-0.862317</td>
      <td>0.304287</td>
      <td>-0.014880</td>
      <td>0.030124</td>
      <td>-0.883995</td>
      <td>0.725443</td>
      <td>-0.707337</td>
      <td>0.172741</td>
      <td>0.488466</td>
      <td>-0.064600</td>
      <td>0.109563</td>
      <td>-0.605967</td>
      <td>0.497033</td>
      <td>0.274937</td>
      <td>1.239977</td>
      <td>0.180179</td>
      <td>-0.401282</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f16b52590d0&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.105785  0.038057  29.056261  1.282586e-185  1.031196  1.180375
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.823 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>