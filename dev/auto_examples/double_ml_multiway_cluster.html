
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.0.1 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="http://doubleml.org"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>     to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-0.207324</td>
      <td>0.025804</td>
      <td>-0.660177</td>
      <td>-0.441634</td>
      <td>-0.483043</td>
      <td>0.153366</td>
      <td>0.583573</td>
      <td>0.735321</td>
      <td>0.785956</td>
      <td>0.788814</td>
      <td>0.226328</td>
      <td>-0.194028</td>
      <td>0.266447</td>
      <td>0.612509</td>
      <td>-1.291891</td>
      <td>0.075868</td>
      <td>-0.050522</td>
      <td>-0.657965</td>
      <td>0.005681</td>
      <td>-0.186239</td>
      <td>-0.909460</td>
      <td>-1.293395</td>
      <td>-0.957965</td>
      <td>-0.639488</td>
      <td>-1.055796</td>
      <td>0.072126</td>
      <td>0.765189</td>
      <td>-0.519921</td>
      <td>-0.221315</td>
      <td>1.115472</td>
      <td>0.753276</td>
      <td>-0.157224</td>
      <td>0.546390</td>
      <td>-0.589049</td>
      <td>-0.581416</td>
      <td>-0.264574</td>
      <td>-1.592811</td>
      <td>-0.981204</td>
      <td>0.138786</td>
      <td>0.123426</td>
      <td>...</td>
      <td>0.737820</td>
      <td>-0.256825</td>
      <td>-0.370527</td>
      <td>-0.365508</td>
      <td>-0.606829</td>
      <td>0.640349</td>
      <td>0.768824</td>
      <td>-0.540582</td>
      <td>-0.057566</td>
      <td>0.534449</td>
      <td>1.194199</td>
      <td>0.925091</td>
      <td>1.037747</td>
      <td>0.906576</td>
      <td>-0.021241</td>
      <td>0.116432</td>
      <td>1.126042</td>
      <td>0.759106</td>
      <td>-0.727175</td>
      <td>-0.886272</td>
      <td>-0.806326</td>
      <td>-0.675587</td>
      <td>0.865222</td>
      <td>-0.249349</td>
      <td>0.127712</td>
      <td>-0.367885</td>
      <td>0.041351</td>
      <td>-0.076168</td>
      <td>-1.071411</td>
      <td>-0.702274</td>
      <td>-0.293323</td>
      <td>-0.267253</td>
      <td>-0.118775</td>
      <td>0.054068</td>
      <td>-0.225477</td>
      <td>-1.026657</td>
      <td>-1.132745</td>
      <td>-2.209459</td>
      <td>-1.591907</td>
      <td>-1.594450</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.246313</td>
      <td>-0.000848</td>
      <td>0.041967</td>
      <td>-1.125212</td>
      <td>-0.622554</td>
      <td>0.659056</td>
      <td>-0.333362</td>
      <td>0.563535</td>
      <td>0.396588</td>
      <td>-0.059660</td>
      <td>-0.518207</td>
      <td>-0.599462</td>
      <td>0.235477</td>
      <td>0.824313</td>
      <td>-0.466553</td>
      <td>0.406770</td>
      <td>0.527968</td>
      <td>-0.702538</td>
      <td>0.179287</td>
      <td>-0.526908</td>
      <td>-0.837172</td>
      <td>-1.245694</td>
      <td>-0.442327</td>
      <td>0.027240</td>
      <td>-0.657081</td>
      <td>-0.362729</td>
      <td>-1.392203</td>
      <td>0.485682</td>
      <td>0.238509</td>
      <td>0.739436</td>
      <td>0.091840</td>
      <td>0.625217</td>
      <td>0.061142</td>
      <td>0.258868</td>
      <td>-0.343428</td>
      <td>-0.966131</td>
      <td>-0.163450</td>
      <td>-0.333823</td>
      <td>-0.484792</td>
      <td>0.585221</td>
      <td>...</td>
      <td>-0.646068</td>
      <td>-0.169896</td>
      <td>-0.509632</td>
      <td>0.433487</td>
      <td>0.250122</td>
      <td>0.287546</td>
      <td>0.209962</td>
      <td>-0.187631</td>
      <td>-0.043372</td>
      <td>0.590669</td>
      <td>0.247571</td>
      <td>-0.075707</td>
      <td>-0.208144</td>
      <td>-0.316609</td>
      <td>-0.267052</td>
      <td>-0.811884</td>
      <td>0.177783</td>
      <td>-0.547958</td>
      <td>-0.035647</td>
      <td>-1.075504</td>
      <td>0.475467</td>
      <td>-0.273941</td>
      <td>1.359790</td>
      <td>1.083920</td>
      <td>0.362807</td>
      <td>-0.139795</td>
      <td>-0.891243</td>
      <td>-0.148568</td>
      <td>-0.594837</td>
      <td>-0.704344</td>
      <td>-0.419921</td>
      <td>-0.205524</td>
      <td>-0.239438</td>
      <td>0.310893</td>
      <td>-0.546024</td>
      <td>0.701812</td>
      <td>0.050645</td>
      <td>-0.879293</td>
      <td>-1.222885</td>
      <td>-0.476893</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.362473</td>
      <td>-0.432151</td>
      <td>0.419456</td>
      <td>0.145678</td>
      <td>0.941744</td>
      <td>0.677774</td>
      <td>-0.533888</td>
      <td>-0.609389</td>
      <td>-0.416265</td>
      <td>0.042709</td>
      <td>-0.622361</td>
      <td>0.062369</td>
      <td>-0.084646</td>
      <td>0.383075</td>
      <td>-0.758336</td>
      <td>0.080288</td>
      <td>0.692309</td>
      <td>-0.479996</td>
      <td>-0.651114</td>
      <td>-0.816313</td>
      <td>-1.650087</td>
      <td>-1.764889</td>
      <td>-0.528054</td>
      <td>-0.561370</td>
      <td>0.205703</td>
      <td>-0.743551</td>
      <td>0.575763</td>
      <td>-0.331111</td>
      <td>1.196771</td>
      <td>-0.567831</td>
      <td>0.574613</td>
      <td>0.463585</td>
      <td>-0.530014</td>
      <td>0.468587</td>
      <td>-0.034426</td>
      <td>-1.036688</td>
      <td>-1.401259</td>
      <td>-0.735261</td>
      <td>0.001523</td>
      <td>-0.159171</td>
      <td>...</td>
      <td>0.613284</td>
      <td>0.644474</td>
      <td>0.719736</td>
      <td>1.219959</td>
      <td>0.807449</td>
      <td>-0.035938</td>
      <td>-0.142684</td>
      <td>-0.263904</td>
      <td>-0.150184</td>
      <td>-0.459070</td>
      <td>0.795342</td>
      <td>-0.333220</td>
      <td>1.183302</td>
      <td>0.838597</td>
      <td>-0.213030</td>
      <td>-0.390247</td>
      <td>0.730316</td>
      <td>0.852312</td>
      <td>-0.941168</td>
      <td>-0.530199</td>
      <td>0.370901</td>
      <td>-0.843292</td>
      <td>0.247769</td>
      <td>0.844962</td>
      <td>0.166252</td>
      <td>0.854373</td>
      <td>0.070722</td>
      <td>-0.276184</td>
      <td>-0.054159</td>
      <td>-0.348474</td>
      <td>-0.326224</td>
      <td>-0.564810</td>
      <td>-0.458155</td>
      <td>-0.487930</td>
      <td>0.616378</td>
      <td>0.377299</td>
      <td>0.100743</td>
      <td>1.640485</td>
      <td>1.293480</td>
      <td>0.672514</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.426646</td>
      <td>-0.755947</td>
      <td>-0.811755</td>
      <td>-1.735645</td>
      <td>0.949863</td>
      <td>1.480166</td>
      <td>0.349331</td>
      <td>0.636108</td>
      <td>-0.099745</td>
      <td>-0.148962</td>
      <td>-0.243915</td>
      <td>0.698966</td>
      <td>-0.613830</td>
      <td>1.226431</td>
      <td>-0.034856</td>
      <td>-0.076869</td>
      <td>-0.060536</td>
      <td>-0.254385</td>
      <td>0.368935</td>
      <td>1.450209</td>
      <td>-0.229329</td>
      <td>0.882177</td>
      <td>0.374796</td>
      <td>0.612234</td>
      <td>-0.469284</td>
      <td>0.170649</td>
      <td>-0.317584</td>
      <td>-0.287742</td>
      <td>0.632439</td>
      <td>1.301166</td>
      <td>0.075855</td>
      <td>0.022506</td>
      <td>-0.436238</td>
      <td>-0.102441</td>
      <td>0.053532</td>
      <td>-0.696486</td>
      <td>0.422292</td>
      <td>-0.212832</td>
      <td>0.858815</td>
      <td>-0.391722</td>
      <td>...</td>
      <td>-0.746631</td>
      <td>-1.149700</td>
      <td>-0.550479</td>
      <td>0.288104</td>
      <td>0.178415</td>
      <td>0.762952</td>
      <td>0.561214</td>
      <td>0.256604</td>
      <td>-0.324043</td>
      <td>-0.333929</td>
      <td>-0.019414</td>
      <td>1.142364</td>
      <td>0.077910</td>
      <td>-0.644302</td>
      <td>-0.785971</td>
      <td>0.277559</td>
      <td>0.388778</td>
      <td>0.453575</td>
      <td>1.094348</td>
      <td>-0.221223</td>
      <td>0.186490</td>
      <td>-1.117310</td>
      <td>-0.174595</td>
      <td>0.164024</td>
      <td>0.357148</td>
      <td>0.688901</td>
      <td>-0.558273</td>
      <td>0.072623</td>
      <td>-0.276361</td>
      <td>-0.318308</td>
      <td>-0.438338</td>
      <td>-1.156330</td>
      <td>-1.217425</td>
      <td>-0.507377</td>
      <td>0.048955</td>
      <td>-0.423202</td>
      <td>0.865294</td>
      <td>-3.082224</td>
      <td>-2.429706</td>
      <td>-1.232465</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.207867</td>
      <td>-0.107949</td>
      <td>-1.210789</td>
      <td>-0.695987</td>
      <td>1.384959</td>
      <td>0.850689</td>
      <td>0.429074</td>
      <td>0.269984</td>
      <td>1.316368</td>
      <td>0.465061</td>
      <td>-0.403748</td>
      <td>-1.114275</td>
      <td>0.112500</td>
      <td>0.514293</td>
      <td>-0.407840</td>
      <td>0.705428</td>
      <td>0.891741</td>
      <td>0.431879</td>
      <td>0.291761</td>
      <td>0.439201</td>
      <td>0.686204</td>
      <td>-0.951136</td>
      <td>0.088290</td>
      <td>0.122763</td>
      <td>-1.112025</td>
      <td>-0.909872</td>
      <td>-0.213563</td>
      <td>-0.064093</td>
      <td>0.217179</td>
      <td>0.929784</td>
      <td>0.569810</td>
      <td>0.564571</td>
      <td>0.202714</td>
      <td>1.004452</td>
      <td>-0.580708</td>
      <td>-0.136741</td>
      <td>-0.427450</td>
      <td>-0.869497</td>
      <td>-0.154344</td>
      <td>0.014116</td>
      <td>...</td>
      <td>-0.615110</td>
      <td>0.751806</td>
      <td>1.657689</td>
      <td>0.603843</td>
      <td>0.087986</td>
      <td>0.014148</td>
      <td>0.153176</td>
      <td>0.247496</td>
      <td>0.050649</td>
      <td>0.485882</td>
      <td>-0.127819</td>
      <td>-0.144987</td>
      <td>-0.034074</td>
      <td>0.058167</td>
      <td>-0.534748</td>
      <td>0.214370</td>
      <td>0.285918</td>
      <td>0.484654</td>
      <td>0.003578</td>
      <td>0.074115</td>
      <td>0.314305</td>
      <td>-1.204984</td>
      <td>0.408847</td>
      <td>-0.003265</td>
      <td>-0.068121</td>
      <td>-0.802208</td>
      <td>-0.596637</td>
      <td>0.355114</td>
      <td>-0.662230</td>
      <td>-0.589182</td>
      <td>-0.755121</td>
      <td>-1.073962</td>
      <td>-0.742639</td>
      <td>0.738036</td>
      <td>-0.374503</td>
      <td>-0.614199</td>
      <td>-0.254437</td>
      <td>-1.370855</td>
      <td>-0.497894</td>
      <td>-0.484157</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.855377</td>
      <td>0.117649</td>
      <td>-0.439153</td>
      <td>-0.182255</td>
      <td>0.406358</td>
      <td>0.059785</td>
      <td>-0.105093</td>
      <td>1.140453</td>
      <td>1.773529</td>
      <td>1.460149</td>
      <td>0.206142</td>
      <td>0.509605</td>
      <td>-0.115375</td>
      <td>0.727301</td>
      <td>0.450330</td>
      <td>0.158676</td>
      <td>0.119692</td>
      <td>0.714483</td>
      <td>0.617111</td>
      <td>0.705499</td>
      <td>0.214432</td>
      <td>-0.325533</td>
      <td>-0.590431</td>
      <td>-0.114171</td>
      <td>-0.437471</td>
      <td>-1.855433</td>
      <td>-0.781375</td>
      <td>-0.471703</td>
      <td>-0.236990</td>
      <td>-0.083014</td>
      <td>0.453831</td>
      <td>-0.242679</td>
      <td>0.743860</td>
      <td>0.031604</td>
      <td>-0.425890</td>
      <td>-0.151915</td>
      <td>-1.040557</td>
      <td>-0.109031</td>
      <td>1.440244</td>
      <td>0.143737</td>
      <td>...</td>
      <td>-0.039418</td>
      <td>-0.070844</td>
      <td>1.006278</td>
      <td>0.938663</td>
      <td>0.840083</td>
      <td>0.238963</td>
      <td>-0.478530</td>
      <td>0.266654</td>
      <td>-0.665638</td>
      <td>-0.218232</td>
      <td>-0.009851</td>
      <td>-0.751649</td>
      <td>-0.240663</td>
      <td>0.343472</td>
      <td>0.357578</td>
      <td>0.447060</td>
      <td>0.245496</td>
      <td>0.027191</td>
      <td>0.365109</td>
      <td>0.738634</td>
      <td>0.325383</td>
      <td>0.155278</td>
      <td>0.682524</td>
      <td>0.282967</td>
      <td>0.668194</td>
      <td>-0.255547</td>
      <td>-0.983521</td>
      <td>-0.073329</td>
      <td>-0.761024</td>
      <td>-1.135338</td>
      <td>-1.098909</td>
      <td>0.211132</td>
      <td>-0.129262</td>
      <td>0.622386</td>
      <td>0.172739</td>
      <td>-0.129552</td>
      <td>-0.001519</td>
      <td>0.225667</td>
      <td>-0.392973</td>
      <td>-0.559419</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.230681</td>
      <td>0.017692</td>
      <td>-0.619664</td>
      <td>-0.918488</td>
      <td>0.087324</td>
      <td>0.270633</td>
      <td>-0.451171</td>
      <td>-0.107650</td>
      <td>1.226352</td>
      <td>0.661958</td>
      <td>0.034285</td>
      <td>0.367633</td>
      <td>0.284021</td>
      <td>-0.139012</td>
      <td>-1.303532</td>
      <td>0.102077</td>
      <td>-0.405475</td>
      <td>-0.163320</td>
      <td>-0.265604</td>
      <td>0.293873</td>
      <td>-0.000693</td>
      <td>0.918669</td>
      <td>-0.564449</td>
      <td>-1.507117</td>
      <td>-0.154301</td>
      <td>-0.150974</td>
      <td>0.073501</td>
      <td>-0.401515</td>
      <td>-0.164798</td>
      <td>0.366264</td>
      <td>0.340536</td>
      <td>0.362088</td>
      <td>-0.193016</td>
      <td>-0.149935</td>
      <td>-0.414585</td>
      <td>-0.109879</td>
      <td>-0.075610</td>
      <td>-1.224799</td>
      <td>-1.040619</td>
      <td>-0.102479</td>
      <td>...</td>
      <td>-0.029298</td>
      <td>0.380804</td>
      <td>-0.224433</td>
      <td>0.113843</td>
      <td>-0.239535</td>
      <td>0.437032</td>
      <td>0.473335</td>
      <td>-0.134419</td>
      <td>0.167115</td>
      <td>0.477490</td>
      <td>0.962782</td>
      <td>0.207539</td>
      <td>0.091304</td>
      <td>-0.224054</td>
      <td>0.380225</td>
      <td>1.481400</td>
      <td>-0.591257</td>
      <td>0.735595</td>
      <td>-0.745694</td>
      <td>0.277934</td>
      <td>-0.112568</td>
      <td>0.495145</td>
      <td>0.279289</td>
      <td>-0.702793</td>
      <td>0.781584</td>
      <td>-0.121514</td>
      <td>-0.582016</td>
      <td>-0.464789</td>
      <td>-0.133191</td>
      <td>-0.645444</td>
      <td>-0.079758</td>
      <td>-0.353955</td>
      <td>0.328049</td>
      <td>-0.319302</td>
      <td>-0.309393</td>
      <td>-0.005646</td>
      <td>-0.553037</td>
      <td>-1.784905</td>
      <td>-1.122538</td>
      <td>-0.463733</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.136614</td>
      <td>-0.321844</td>
      <td>0.297031</td>
      <td>-0.155453</td>
      <td>0.294545</td>
      <td>-0.355209</td>
      <td>1.098715</td>
      <td>1.749901</td>
      <td>0.426705</td>
      <td>0.821604</td>
      <td>0.323273</td>
      <td>0.593973</td>
      <td>-0.097532</td>
      <td>-0.493039</td>
      <td>-0.346589</td>
      <td>0.474945</td>
      <td>0.987957</td>
      <td>0.108264</td>
      <td>-0.437283</td>
      <td>0.077086</td>
      <td>-0.677183</td>
      <td>-0.804417</td>
      <td>-0.242282</td>
      <td>-0.701290</td>
      <td>-1.280882</td>
      <td>-0.697764</td>
      <td>-0.202302</td>
      <td>-0.163554</td>
      <td>-0.583711</td>
      <td>0.137766</td>
      <td>-0.109245</td>
      <td>0.292191</td>
      <td>0.887606</td>
      <td>0.746907</td>
      <td>-0.156162</td>
      <td>-0.274930</td>
      <td>-0.922799</td>
      <td>-0.558643</td>
      <td>-0.206077</td>
      <td>-0.662336</td>
      <td>...</td>
      <td>0.101838</td>
      <td>-0.139922</td>
      <td>-0.399321</td>
      <td>0.196372</td>
      <td>-0.278914</td>
      <td>0.578800</td>
      <td>-0.063938</td>
      <td>-0.778802</td>
      <td>-0.516232</td>
      <td>-0.237826</td>
      <td>0.153849</td>
      <td>0.412048</td>
      <td>0.152479</td>
      <td>0.372312</td>
      <td>-0.299345</td>
      <td>0.729966</td>
      <td>-0.292456</td>
      <td>-0.059105</td>
      <td>-1.259571</td>
      <td>0.137106</td>
      <td>0.547150</td>
      <td>0.532131</td>
      <td>1.046243</td>
      <td>0.290918</td>
      <td>0.029467</td>
      <td>0.124524</td>
      <td>0.256729</td>
      <td>-0.539624</td>
      <td>0.742725</td>
      <td>-1.169261</td>
      <td>0.620672</td>
      <td>-0.714934</td>
      <td>0.336955</td>
      <td>0.339764</td>
      <td>-1.274132</td>
      <td>-1.690885</td>
      <td>-0.571421</td>
      <td>-0.454578</td>
      <td>-0.307802</td>
      <td>0.179597</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1.166071</td>
      <td>0.289209</td>
      <td>0.036133</td>
      <td>-0.943037</td>
      <td>0.085474</td>
      <td>0.425613</td>
      <td>0.609392</td>
      <td>0.437279</td>
      <td>-0.121620</td>
      <td>-0.299051</td>
      <td>0.273372</td>
      <td>-0.293561</td>
      <td>0.408790</td>
      <td>1.513490</td>
      <td>-0.001110</td>
      <td>-0.501798</td>
      <td>1.124248</td>
      <td>0.631497</td>
      <td>0.646562</td>
      <td>0.037322</td>
      <td>0.498877</td>
      <td>-0.831608</td>
      <td>-0.837136</td>
      <td>-0.342864</td>
      <td>-0.351970</td>
      <td>0.117495</td>
      <td>-0.058881</td>
      <td>-0.874927</td>
      <td>-0.252551</td>
      <td>-0.045876</td>
      <td>-0.146605</td>
      <td>-0.077052</td>
      <td>-0.173200</td>
      <td>-0.289582</td>
      <td>-0.151526</td>
      <td>-0.739903</td>
      <td>-0.460874</td>
      <td>-0.285975</td>
      <td>-0.040229</td>
      <td>-0.654113</td>
      <td>...</td>
      <td>-0.146786</td>
      <td>0.385288</td>
      <td>-0.137798</td>
      <td>0.537554</td>
      <td>-0.436519</td>
      <td>0.852217</td>
      <td>-1.212447</td>
      <td>-0.998984</td>
      <td>-0.656032</td>
      <td>-0.084374</td>
      <td>-0.511325</td>
      <td>0.128213</td>
      <td>1.070750</td>
      <td>0.435588</td>
      <td>-0.922395</td>
      <td>0.217205</td>
      <td>0.933107</td>
      <td>0.489065</td>
      <td>-0.487309</td>
      <td>-0.934806</td>
      <td>0.134596</td>
      <td>-0.260100</td>
      <td>-0.013568</td>
      <td>0.177665</td>
      <td>-0.415375</td>
      <td>-0.263585</td>
      <td>-0.312968</td>
      <td>0.171573</td>
      <td>-1.171672</td>
      <td>-1.663968</td>
      <td>-0.402593</td>
      <td>0.348331</td>
      <td>-0.972810</td>
      <td>-0.899481</td>
      <td>0.113673</td>
      <td>0.340342</td>
      <td>-0.197538</td>
      <td>1.565056</td>
      <td>0.888256</td>
      <td>-0.602756</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-0.382419</td>
      <td>-0.119221</td>
      <td>-0.012729</td>
      <td>-0.316983</td>
      <td>1.070510</td>
      <td>1.303238</td>
      <td>-0.107183</td>
      <td>0.212548</td>
      <td>0.139062</td>
      <td>-0.596274</td>
      <td>-0.014971</td>
      <td>-0.434326</td>
      <td>-0.260462</td>
      <td>-1.080454</td>
      <td>-2.026210</td>
      <td>-0.422257</td>
      <td>0.379815</td>
      <td>0.663159</td>
      <td>-0.137822</td>
      <td>0.289330</td>
      <td>-0.872095</td>
      <td>-0.846060</td>
      <td>-0.699464</td>
      <td>-0.326772</td>
      <td>-0.268430</td>
      <td>0.098860</td>
      <td>-0.752611</td>
      <td>-0.627746</td>
      <td>0.491355</td>
      <td>0.496003</td>
      <td>-0.662996</td>
      <td>-0.343201</td>
      <td>0.499451</td>
      <td>0.416245</td>
      <td>-0.086210</td>
      <td>0.353681</td>
      <td>-0.310373</td>
      <td>-0.051681</td>
      <td>0.577347</td>
      <td>-0.569197</td>
      <td>...</td>
      <td>-0.793692</td>
      <td>0.083815</td>
      <td>1.032668</td>
      <td>0.636747</td>
      <td>0.102163</td>
      <td>-1.046019</td>
      <td>1.042540</td>
      <td>-0.481897</td>
      <td>-0.051952</td>
      <td>-0.363004</td>
      <td>0.911220</td>
      <td>0.128949</td>
      <td>0.945510</td>
      <td>0.854277</td>
      <td>0.645959</td>
      <td>0.515374</td>
      <td>-0.056344</td>
      <td>0.508047</td>
      <td>-0.553743</td>
      <td>-0.904285</td>
      <td>1.318054</td>
      <td>-0.228789</td>
      <td>0.473645</td>
      <td>0.853669</td>
      <td>-0.417070</td>
      <td>0.453525</td>
      <td>-0.844432</td>
      <td>-1.616885</td>
      <td>0.288326</td>
      <td>0.429396</td>
      <td>0.009105</td>
      <td>-0.954285</td>
      <td>-0.293235</td>
      <td>-0.024344</td>
      <td>0.919316</td>
      <td>0.393561</td>
      <td>-0.043399</td>
      <td>0.905865</td>
      <td>0.902339</td>
      <td>0.513975</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.211218</td>
      <td>0.378545</td>
      <td>0.100084</td>
      <td>0.116230</td>
      <td>0.375674</td>
      <td>0.113612</td>
      <td>0.361379</td>
      <td>-0.369026</td>
      <td>0.584354</td>
      <td>0.174666</td>
      <td>0.298995</td>
      <td>0.499345</td>
      <td>-0.059841</td>
      <td>-0.497393</td>
      <td>-0.086239</td>
      <td>0.530858</td>
      <td>0.401993</td>
      <td>1.195340</td>
      <td>0.624695</td>
      <td>-0.118258</td>
      <td>-0.784933</td>
      <td>0.027775</td>
      <td>0.260969</td>
      <td>0.798733</td>
      <td>-1.046028</td>
      <td>-0.095190</td>
      <td>0.069629</td>
      <td>-0.042177</td>
      <td>0.290326</td>
      <td>-0.630804</td>
      <td>-0.599902</td>
      <td>0.207706</td>
      <td>-0.064324</td>
      <td>-0.171976</td>
      <td>0.262414</td>
      <td>-0.789768</td>
      <td>0.340833</td>
      <td>-0.426049</td>
      <td>0.336755</td>
      <td>0.491776</td>
      <td>...</td>
      <td>0.205089</td>
      <td>-0.494862</td>
      <td>0.480336</td>
      <td>0.271627</td>
      <td>0.148814</td>
      <td>-0.131203</td>
      <td>-0.601895</td>
      <td>-0.781027</td>
      <td>-0.497825</td>
      <td>0.058514</td>
      <td>0.328268</td>
      <td>-0.302145</td>
      <td>-0.091577</td>
      <td>0.200922</td>
      <td>1.218823</td>
      <td>0.826323</td>
      <td>0.577346</td>
      <td>-0.485601</td>
      <td>-1.115478</td>
      <td>-0.659712</td>
      <td>0.155623</td>
      <td>-0.147383</td>
      <td>0.370690</td>
      <td>1.121476</td>
      <td>0.334820</td>
      <td>0.515576</td>
      <td>0.239959</td>
      <td>-1.041348</td>
      <td>0.090856</td>
      <td>0.476255</td>
      <td>0.333928</td>
      <td>-0.423908</td>
      <td>-0.159400</td>
      <td>-0.155376</td>
      <td>-0.021355</td>
      <td>-0.231947</td>
      <td>0.315683</td>
      <td>1.408869</td>
      <td>1.251883</td>
      <td>0.700429</td>
    </tr>
    <tr>
      <th>11</th>
      <td>1.839697</td>
      <td>0.135290</td>
      <td>-0.096922</td>
      <td>0.159714</td>
      <td>-0.160433</td>
      <td>0.215663</td>
      <td>0.321795</td>
      <td>0.472957</td>
      <td>0.810902</td>
      <td>1.052340</td>
      <td>0.318295</td>
      <td>0.478954</td>
      <td>-0.232052</td>
      <td>0.033365</td>
      <td>0.116806</td>
      <td>-1.799870</td>
      <td>-0.416154</td>
      <td>0.443448</td>
      <td>0.489890</td>
      <td>0.005802</td>
      <td>-0.928653</td>
      <td>0.485802</td>
      <td>-0.002281</td>
      <td>-0.274435</td>
      <td>-1.048260</td>
      <td>-0.486754</td>
      <td>0.526153</td>
      <td>-0.193130</td>
      <td>-0.252759</td>
      <td>-0.262359</td>
      <td>-0.923570</td>
      <td>-0.377086</td>
      <td>-0.590157</td>
      <td>-0.696453</td>
      <td>-1.404818</td>
      <td>-0.504958</td>
      <td>-0.062773</td>
      <td>-1.010921</td>
      <td>-0.185417</td>
      <td>0.103814</td>
      <td>...</td>
      <td>0.593781</td>
      <td>-0.248037</td>
      <td>0.919923</td>
      <td>0.570436</td>
      <td>-0.466241</td>
      <td>0.200086</td>
      <td>0.567141</td>
      <td>0.548621</td>
      <td>0.720219</td>
      <td>0.024788</td>
      <td>-0.308789</td>
      <td>0.625276</td>
      <td>-0.329021</td>
      <td>0.259529</td>
      <td>0.667678</td>
      <td>0.334503</td>
      <td>0.683180</td>
      <td>0.755258</td>
      <td>-0.355574</td>
      <td>-0.519363</td>
      <td>0.065174</td>
      <td>-0.902628</td>
      <td>0.368746</td>
      <td>-0.508079</td>
      <td>-0.554876</td>
      <td>-0.695251</td>
      <td>-0.550134</td>
      <td>-0.221346</td>
      <td>-1.097029</td>
      <td>-0.167552</td>
      <td>0.106008</td>
      <td>-0.555179</td>
      <td>-1.308519</td>
      <td>-0.549534</td>
      <td>0.476471</td>
      <td>0.439509</td>
      <td>0.000808</td>
      <td>4.620820</td>
      <td>2.857318</td>
      <td>1.194149</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.256261</td>
      <td>0.013890</td>
      <td>-0.903091</td>
      <td>-0.431417</td>
      <td>0.916635</td>
      <td>0.757303</td>
      <td>0.944645</td>
      <td>0.876329</td>
      <td>0.752149</td>
      <td>-0.212516</td>
      <td>-0.142793</td>
      <td>-0.058526</td>
      <td>-0.422958</td>
      <td>0.270847</td>
      <td>-0.460019</td>
      <td>0.056092</td>
      <td>0.107948</td>
      <td>0.049337</td>
      <td>0.448662</td>
      <td>0.004969</td>
      <td>-0.164897</td>
      <td>-0.793067</td>
      <td>-1.415875</td>
      <td>-0.053773</td>
      <td>0.058332</td>
      <td>-0.536668</td>
      <td>-0.459964</td>
      <td>-0.332774</td>
      <td>-0.411845</td>
      <td>0.059998</td>
      <td>0.295432</td>
      <td>0.086736</td>
      <td>0.404522</td>
      <td>0.110691</td>
      <td>-1.451180</td>
      <td>-0.670608</td>
      <td>-0.706658</td>
      <td>0.223741</td>
      <td>0.358540</td>
      <td>-0.431053</td>
      <td>...</td>
      <td>0.326525</td>
      <td>0.405126</td>
      <td>-0.288416</td>
      <td>0.532602</td>
      <td>-0.161332</td>
      <td>-0.218389</td>
      <td>0.216494</td>
      <td>0.374060</td>
      <td>-0.703564</td>
      <td>-0.418754</td>
      <td>-0.003923</td>
      <td>0.215057</td>
      <td>0.465203</td>
      <td>-0.920394</td>
      <td>-0.421125</td>
      <td>0.231015</td>
      <td>0.675757</td>
      <td>-0.304767</td>
      <td>-0.142189</td>
      <td>-0.730793</td>
      <td>-0.905780</td>
      <td>-0.649463</td>
      <td>0.397530</td>
      <td>0.748425</td>
      <td>1.796239</td>
      <td>0.732844</td>
      <td>-0.590445</td>
      <td>0.465706</td>
      <td>-0.661732</td>
      <td>-0.078827</td>
      <td>0.490554</td>
      <td>0.589897</td>
      <td>0.917121</td>
      <td>0.293730</td>
      <td>-0.156829</td>
      <td>-0.078574</td>
      <td>-0.440194</td>
      <td>0.995162</td>
      <td>0.648102</td>
      <td>1.341986</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.641106</td>
      <td>-0.404663</td>
      <td>-0.644920</td>
      <td>0.076568</td>
      <td>-0.017007</td>
      <td>0.289317</td>
      <td>0.867611</td>
      <td>0.947296</td>
      <td>1.183584</td>
      <td>-0.275143</td>
      <td>-0.437005</td>
      <td>0.349229</td>
      <td>0.888362</td>
      <td>0.699284</td>
      <td>0.146197</td>
      <td>-0.514467</td>
      <td>-0.330615</td>
      <td>-0.344508</td>
      <td>0.116914</td>
      <td>-0.012818</td>
      <td>-1.427482</td>
      <td>-0.879899</td>
      <td>-0.781045</td>
      <td>-0.221426</td>
      <td>0.047002</td>
      <td>0.133520</td>
      <td>0.628215</td>
      <td>0.207509</td>
      <td>-0.404987</td>
      <td>0.054379</td>
      <td>0.040572</td>
      <td>-0.026278</td>
      <td>-0.404770</td>
      <td>0.403501</td>
      <td>-0.169020</td>
      <td>-0.541632</td>
      <td>-1.354808</td>
      <td>-0.977859</td>
      <td>0.102253</td>
      <td>-0.187675</td>
      <td>...</td>
      <td>0.385876</td>
      <td>0.326295</td>
      <td>0.304368</td>
      <td>-0.114356</td>
      <td>-1.152489</td>
      <td>-0.211039</td>
      <td>0.604974</td>
      <td>-0.588348</td>
      <td>-1.645535</td>
      <td>-0.769669</td>
      <td>0.318570</td>
      <td>0.163742</td>
      <td>-0.670647</td>
      <td>0.219010</td>
      <td>0.693323</td>
      <td>0.234084</td>
      <td>0.724197</td>
      <td>0.114583</td>
      <td>-1.341938</td>
      <td>-0.931069</td>
      <td>-0.191579</td>
      <td>0.104099</td>
      <td>-0.397483</td>
      <td>0.396866</td>
      <td>0.489345</td>
      <td>0.255277</td>
      <td>-1.049091</td>
      <td>-0.838703</td>
      <td>-0.188197</td>
      <td>0.363553</td>
      <td>0.006125</td>
      <td>0.130575</td>
      <td>-0.842334</td>
      <td>0.422275</td>
      <td>0.197526</td>
      <td>0.620739</td>
      <td>-0.822923</td>
      <td>1.672930</td>
      <td>1.559802</td>
      <td>0.812844</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.107616</td>
      <td>0.699367</td>
      <td>-0.466869</td>
      <td>-1.097299</td>
      <td>-1.180089</td>
      <td>0.178877</td>
      <td>0.611222</td>
      <td>0.645815</td>
      <td>0.928461</td>
      <td>1.339298</td>
      <td>-0.006529</td>
      <td>0.514106</td>
      <td>-0.934516</td>
      <td>-0.080949</td>
      <td>-0.362395</td>
      <td>-0.336097</td>
      <td>0.699223</td>
      <td>0.051507</td>
      <td>0.557146</td>
      <td>1.038967</td>
      <td>-0.347689</td>
      <td>-0.191536</td>
      <td>-0.757780</td>
      <td>-0.287144</td>
      <td>-0.620335</td>
      <td>-0.290899</td>
      <td>-0.095228</td>
      <td>-0.745196</td>
      <td>0.280360</td>
      <td>0.233875</td>
      <td>0.356106</td>
      <td>0.987358</td>
      <td>0.089036</td>
      <td>-0.024172</td>
      <td>-0.987151</td>
      <td>-0.866462</td>
      <td>-0.713934</td>
      <td>-0.616823</td>
      <td>-0.015419</td>
      <td>0.150626</td>
      <td>...</td>
      <td>-0.813029</td>
      <td>0.101913</td>
      <td>0.822878</td>
      <td>1.451508</td>
      <td>0.339619</td>
      <td>1.585344</td>
      <td>0.753742</td>
      <td>0.078151</td>
      <td>-0.837390</td>
      <td>0.138562</td>
      <td>-1.492182</td>
      <td>-0.567277</td>
      <td>0.321676</td>
      <td>-0.064311</td>
      <td>-0.399510</td>
      <td>-0.434264</td>
      <td>-0.356933</td>
      <td>0.255736</td>
      <td>-0.405109</td>
      <td>-0.767492</td>
      <td>0.030160</td>
      <td>0.292902</td>
      <td>-0.173731</td>
      <td>0.451180</td>
      <td>0.804952</td>
      <td>0.211841</td>
      <td>-0.970191</td>
      <td>-0.219237</td>
      <td>-1.215883</td>
      <td>-0.393326</td>
      <td>-0.698453</td>
      <td>0.302499</td>
      <td>0.415969</td>
      <td>0.163618</td>
      <td>-0.241963</td>
      <td>-1.101892</td>
      <td>-0.626840</td>
      <td>0.537843</td>
      <td>0.306129</td>
      <td>-0.338499</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.356055</td>
      <td>-0.504252</td>
      <td>0.848217</td>
      <td>-0.980774</td>
      <td>-0.317781</td>
      <td>-0.092946</td>
      <td>0.405857</td>
      <td>0.427645</td>
      <td>0.358355</td>
      <td>-0.109335</td>
      <td>-0.992457</td>
      <td>-0.882444</td>
      <td>-1.242263</td>
      <td>0.206340</td>
      <td>-0.769805</td>
      <td>-0.250217</td>
      <td>0.151616</td>
      <td>0.228002</td>
      <td>0.742719</td>
      <td>-0.927141</td>
      <td>-1.074105</td>
      <td>-0.604756</td>
      <td>-0.198178</td>
      <td>0.495189</td>
      <td>-0.865723</td>
      <td>0.003658</td>
      <td>-0.239256</td>
      <td>-0.253617</td>
      <td>-0.527339</td>
      <td>-1.709651</td>
      <td>-0.546656</td>
      <td>-0.323087</td>
      <td>0.229815</td>
      <td>-0.011171</td>
      <td>-0.396426</td>
      <td>-1.041252</td>
      <td>-1.450412</td>
      <td>-0.378810</td>
      <td>0.520559</td>
      <td>0.240828</td>
      <td>...</td>
      <td>-0.458549</td>
      <td>-0.574475</td>
      <td>1.419385</td>
      <td>0.558423</td>
      <td>0.195630</td>
      <td>0.860490</td>
      <td>0.536252</td>
      <td>0.925254</td>
      <td>-1.243034</td>
      <td>-0.551823</td>
      <td>0.381295</td>
      <td>0.255054</td>
      <td>0.178765</td>
      <td>0.369703</td>
      <td>-0.087262</td>
      <td>0.675211</td>
      <td>0.895228</td>
      <td>0.172328</td>
      <td>0.340778</td>
      <td>0.881477</td>
      <td>-0.574534</td>
      <td>0.178171</td>
      <td>0.113728</td>
      <td>0.524987</td>
      <td>1.031436</td>
      <td>0.802099</td>
      <td>0.482043</td>
      <td>0.076136</td>
      <td>-1.161233</td>
      <td>-0.156430</td>
      <td>0.024697</td>
      <td>0.471589</td>
      <td>0.092226</td>
      <td>0.088255</td>
      <td>-0.435418</td>
      <td>-0.617010</td>
      <td>0.479618</td>
      <td>-0.375765</td>
      <td>-0.048442</td>
      <td>0.222989</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.680118</td>
      <td>-0.411550</td>
      <td>-0.694451</td>
      <td>-1.351836</td>
      <td>0.059927</td>
      <td>1.098596</td>
      <td>-0.500395</td>
      <td>0.459442</td>
      <td>-0.004938</td>
      <td>-0.376126</td>
      <td>-0.151247</td>
      <td>0.311120</td>
      <td>1.472989</td>
      <td>-0.140943</td>
      <td>-0.549480</td>
      <td>-0.065229</td>
      <td>-1.291670</td>
      <td>-0.715752</td>
      <td>0.568503</td>
      <td>0.719396</td>
      <td>0.010578</td>
      <td>0.103664</td>
      <td>0.083560</td>
      <td>-0.630386</td>
      <td>-1.052913</td>
      <td>-1.028005</td>
      <td>0.378801</td>
      <td>-0.282021</td>
      <td>0.275140</td>
      <td>0.048515</td>
      <td>-0.039007</td>
      <td>0.194111</td>
      <td>0.092837</td>
      <td>1.164739</td>
      <td>-0.543387</td>
      <td>-0.916741</td>
      <td>-0.250635</td>
      <td>-0.187307</td>
      <td>-0.040194</td>
      <td>0.332646</td>
      <td>...</td>
      <td>0.054570</td>
      <td>0.111900</td>
      <td>-0.114247</td>
      <td>0.422380</td>
      <td>0.684770</td>
      <td>1.169638</td>
      <td>1.444499</td>
      <td>0.382025</td>
      <td>0.600138</td>
      <td>0.429282</td>
      <td>0.079432</td>
      <td>0.332056</td>
      <td>0.536768</td>
      <td>-0.089845</td>
      <td>0.374150</td>
      <td>0.560336</td>
      <td>0.612147</td>
      <td>1.315894</td>
      <td>0.176472</td>
      <td>-0.314009</td>
      <td>0.387264</td>
      <td>-0.025427</td>
      <td>1.548119</td>
      <td>0.847229</td>
      <td>1.098860</td>
      <td>0.339677</td>
      <td>0.019666</td>
      <td>0.191002</td>
      <td>-0.045099</td>
      <td>0.631073</td>
      <td>1.071894</td>
      <td>-0.391197</td>
      <td>-0.178103</td>
      <td>-0.085541</td>
      <td>-0.952576</td>
      <td>-1.135867</td>
      <td>-0.671486</td>
      <td>-0.898658</td>
      <td>-0.164512</td>
      <td>0.310084</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.526556</td>
      <td>0.047971</td>
      <td>0.085239</td>
      <td>0.271604</td>
      <td>1.798910</td>
      <td>0.609449</td>
      <td>1.089850</td>
      <td>0.559717</td>
      <td>1.593692</td>
      <td>-0.081620</td>
      <td>-0.689590</td>
      <td>-0.039131</td>
      <td>-1.302676</td>
      <td>-0.624051</td>
      <td>0.122781</td>
      <td>-0.261929</td>
      <td>-0.273848</td>
      <td>-0.403187</td>
      <td>-0.103584</td>
      <td>0.357556</td>
      <td>-0.730352</td>
      <td>-1.146528</td>
      <td>-0.977831</td>
      <td>-1.196134</td>
      <td>-1.058415</td>
      <td>0.094105</td>
      <td>0.136844</td>
      <td>0.112706</td>
      <td>0.205368</td>
      <td>0.481963</td>
      <td>0.765866</td>
      <td>0.840155</td>
      <td>-0.256077</td>
      <td>0.743009</td>
      <td>0.167808</td>
      <td>-0.196842</td>
      <td>0.210378</td>
      <td>-0.110321</td>
      <td>-0.005876</td>
      <td>0.117077</td>
      <td>...</td>
      <td>0.232344</td>
      <td>-0.641213</td>
      <td>0.734963</td>
      <td>-0.316954</td>
      <td>-0.175441</td>
      <td>-0.515099</td>
      <td>-0.039766</td>
      <td>-0.569625</td>
      <td>0.627787</td>
      <td>0.545212</td>
      <td>1.593245</td>
      <td>0.220311</td>
      <td>-0.037359</td>
      <td>-0.177265</td>
      <td>0.162352</td>
      <td>0.253819</td>
      <td>-0.278679</td>
      <td>0.464165</td>
      <td>0.613905</td>
      <td>0.125592</td>
      <td>-0.394740</td>
      <td>0.296954</td>
      <td>-0.678558</td>
      <td>0.367252</td>
      <td>-0.231063</td>
      <td>0.841850</td>
      <td>0.048166</td>
      <td>-0.588234</td>
      <td>0.437029</td>
      <td>0.827956</td>
      <td>-0.049780</td>
      <td>-1.107482</td>
      <td>-0.559284</td>
      <td>-1.069683</td>
      <td>0.420606</td>
      <td>-0.105237</td>
      <td>-0.163062</td>
      <td>2.229152</td>
      <td>1.040730</td>
      <td>0.178940</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.064355</td>
      <td>-1.060841</td>
      <td>-0.058643</td>
      <td>0.631735</td>
      <td>-0.427231</td>
      <td>0.227329</td>
      <td>0.153326</td>
      <td>-0.006108</td>
      <td>-0.246644</td>
      <td>-0.882892</td>
      <td>-0.789836</td>
      <td>-0.476963</td>
      <td>-0.954969</td>
      <td>-0.285649</td>
      <td>-0.947562</td>
      <td>0.041055</td>
      <td>0.658411</td>
      <td>-0.326180</td>
      <td>0.052571</td>
      <td>-0.980932</td>
      <td>-0.299541</td>
      <td>-0.647948</td>
      <td>-1.123916</td>
      <td>-1.271341</td>
      <td>-0.356828</td>
      <td>0.091441</td>
      <td>0.412892</td>
      <td>0.063022</td>
      <td>0.649850</td>
      <td>0.197080</td>
      <td>0.836421</td>
      <td>0.893869</td>
      <td>0.913694</td>
      <td>0.518034</td>
      <td>-0.722662</td>
      <td>-0.730373</td>
      <td>-0.230446</td>
      <td>-0.039640</td>
      <td>-0.322881</td>
      <td>-0.762091</td>
      <td>...</td>
      <td>-1.794043</td>
      <td>-1.448280</td>
      <td>0.121055</td>
      <td>0.195091</td>
      <td>-0.643794</td>
      <td>0.267513</td>
      <td>-0.017343</td>
      <td>-0.280602</td>
      <td>-0.489722</td>
      <td>0.464867</td>
      <td>0.540546</td>
      <td>-0.460436</td>
      <td>0.897394</td>
      <td>2.193057</td>
      <td>0.125780</td>
      <td>0.018646</td>
      <td>0.903299</td>
      <td>0.759291</td>
      <td>-0.690186</td>
      <td>-0.384707</td>
      <td>-0.130223</td>
      <td>0.092634</td>
      <td>0.510521</td>
      <td>1.381607</td>
      <td>0.484783</td>
      <td>0.405076</td>
      <td>0.054066</td>
      <td>-0.754073</td>
      <td>-0.067770</td>
      <td>-0.526971</td>
      <td>0.456027</td>
      <td>-0.746347</td>
      <td>0.368992</td>
      <td>-0.333241</td>
      <td>-0.093109</td>
      <td>-0.426899</td>
      <td>-1.396849</td>
      <td>1.546616</td>
      <td>0.908211</td>
      <td>0.660646</td>
    </tr>
    <tr>
      <th>19</th>
      <td>1.061368</td>
      <td>0.519327</td>
      <td>0.059176</td>
      <td>0.995567</td>
      <td>-0.311330</td>
      <td>-0.917273</td>
      <td>-0.340040</td>
      <td>-0.546906</td>
      <td>1.205573</td>
      <td>0.868236</td>
      <td>-0.028414</td>
      <td>-0.202364</td>
      <td>-0.627632</td>
      <td>0.471804</td>
      <td>0.194656</td>
      <td>0.137554</td>
      <td>0.685558</td>
      <td>0.754370</td>
      <td>0.872255</td>
      <td>1.132190</td>
      <td>0.160613</td>
      <td>0.038282</td>
      <td>-0.618485</td>
      <td>-0.815361</td>
      <td>-1.275370</td>
      <td>-1.276558</td>
      <td>0.606761</td>
      <td>-0.093544</td>
      <td>-0.239194</td>
      <td>-0.548335</td>
      <td>-0.151176</td>
      <td>-0.106934</td>
      <td>0.918394</td>
      <td>0.603349</td>
      <td>-1.112500</td>
      <td>0.407969</td>
      <td>-0.689881</td>
      <td>-0.099527</td>
      <td>0.223948</td>
      <td>-0.109483</td>
      <td>...</td>
      <td>-0.815189</td>
      <td>0.131920</td>
      <td>0.360153</td>
      <td>-0.339303</td>
      <td>-0.502317</td>
      <td>-0.001432</td>
      <td>0.226898</td>
      <td>0.261305</td>
      <td>-0.135648</td>
      <td>-1.208465</td>
      <td>-0.257248</td>
      <td>-0.380405</td>
      <td>0.878490</td>
      <td>-0.413653</td>
      <td>-0.486732</td>
      <td>-0.573912</td>
      <td>1.023472</td>
      <td>0.826287</td>
      <td>1.248803</td>
      <td>0.004939</td>
      <td>-0.257407</td>
      <td>-0.384011</td>
      <td>0.249650</td>
      <td>0.190494</td>
      <td>0.758926</td>
      <td>-0.165735</td>
      <td>-0.444306</td>
      <td>0.720676</td>
      <td>-0.726831</td>
      <td>-1.307023</td>
      <td>-0.879091</td>
      <td>0.967850</td>
      <td>-0.331926</td>
      <td>-0.027014</td>
      <td>-0.046701</td>
      <td>-0.403580</td>
      <td>0.038096</td>
      <td>1.668940</td>
      <td>1.424997</td>
      <td>0.752002</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.282153</td>
      <td>0.630278</td>
      <td>-1.198493</td>
      <td>-1.010413</td>
      <td>-0.611985</td>
      <td>0.572610</td>
      <td>0.799076</td>
      <td>0.924666</td>
      <td>0.333684</td>
      <td>0.403314</td>
      <td>-0.813626</td>
      <td>-0.008182</td>
      <td>-0.716020</td>
      <td>0.946757</td>
      <td>-1.245877</td>
      <td>-0.018168</td>
      <td>0.287177</td>
      <td>0.555407</td>
      <td>0.359576</td>
      <td>0.406823</td>
      <td>-0.393709</td>
      <td>-0.133999</td>
      <td>0.441816</td>
      <td>-0.507810</td>
      <td>-1.078595</td>
      <td>-0.805814</td>
      <td>-0.315194</td>
      <td>-0.404644</td>
      <td>-0.719324</td>
      <td>-0.381788</td>
      <td>0.175092</td>
      <td>-0.987767</td>
      <td>0.028663</td>
      <td>0.476476</td>
      <td>-0.476814</td>
      <td>-0.062745</td>
      <td>-0.121978</td>
      <td>-0.457038</td>
      <td>0.275134</td>
      <td>-0.260952</td>
      <td>...</td>
      <td>0.275575</td>
      <td>-0.718608</td>
      <td>0.587808</td>
      <td>0.529514</td>
      <td>0.652205</td>
      <td>0.988321</td>
      <td>1.476768</td>
      <td>-0.303474</td>
      <td>-0.108587</td>
      <td>0.067943</td>
      <td>0.872407</td>
      <td>0.513172</td>
      <td>-0.077034</td>
      <td>1.187892</td>
      <td>1.070309</td>
      <td>-0.093137</td>
      <td>0.070145</td>
      <td>0.278074</td>
      <td>-0.377183</td>
      <td>-0.130214</td>
      <td>0.301165</td>
      <td>-0.000810</td>
      <td>0.581406</td>
      <td>0.439554</td>
      <td>0.700934</td>
      <td>0.575738</td>
      <td>0.070847</td>
      <td>0.372274</td>
      <td>0.058151</td>
      <td>-0.406142</td>
      <td>-0.173868</td>
      <td>-0.529202</td>
      <td>-0.458795</td>
      <td>-0.410758</td>
      <td>-0.513313</td>
      <td>-0.003303</td>
      <td>-0.055298</td>
      <td>0.389552</td>
      <td>0.519845</td>
      <td>0.137098</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.156927</td>
      <td>-0.072270</td>
      <td>0.364385</td>
      <td>-0.313917</td>
      <td>1.081405</td>
      <td>-0.089821</td>
      <td>0.867134</td>
      <td>1.292444</td>
      <td>1.583025</td>
      <td>0.059390</td>
      <td>0.228386</td>
      <td>-0.206910</td>
      <td>-0.438132</td>
      <td>0.375935</td>
      <td>-0.127218</td>
      <td>0.636045</td>
      <td>0.539490</td>
      <td>0.089577</td>
      <td>-0.596899</td>
      <td>-0.128562</td>
      <td>-0.051584</td>
      <td>-0.959714</td>
      <td>-1.430786</td>
      <td>0.300107</td>
      <td>-0.259010</td>
      <td>0.614402</td>
      <td>-0.758500</td>
      <td>-0.918276</td>
      <td>-0.810882</td>
      <td>0.253341</td>
      <td>1.829608</td>
      <td>0.019581</td>
      <td>0.286366</td>
      <td>0.082126</td>
      <td>-0.089320</td>
      <td>1.262539</td>
      <td>0.455209</td>
      <td>-0.242782</td>
      <td>0.676917</td>
      <td>-1.001426</td>
      <td>...</td>
      <td>-0.591783</td>
      <td>-1.332047</td>
      <td>-0.709696</td>
      <td>0.470222</td>
      <td>-0.148517</td>
      <td>0.661142</td>
      <td>-0.185427</td>
      <td>-0.677983</td>
      <td>-0.394511</td>
      <td>-0.004304</td>
      <td>-0.129567</td>
      <td>0.412290</td>
      <td>0.148425</td>
      <td>0.583376</td>
      <td>0.850969</td>
      <td>0.757305</td>
      <td>0.838107</td>
      <td>0.816618</td>
      <td>-0.612328</td>
      <td>-0.914820</td>
      <td>-0.862150</td>
      <td>-0.602496</td>
      <td>-0.312918</td>
      <td>-1.057108</td>
      <td>-0.937769</td>
      <td>0.114778</td>
      <td>-0.425308</td>
      <td>0.543497</td>
      <td>-0.679491</td>
      <td>-0.770491</td>
      <td>-0.478599</td>
      <td>-0.397146</td>
      <td>-0.344240</td>
      <td>0.090724</td>
      <td>-0.316041</td>
      <td>-0.650762</td>
      <td>-0.011745</td>
      <td>1.260259</td>
      <td>0.089790</td>
      <td>0.222245</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.170286</td>
      <td>-0.077506</td>
      <td>-0.141857</td>
      <td>-0.393185</td>
      <td>0.256970</td>
      <td>-0.299244</td>
      <td>-0.567192</td>
      <td>0.080109</td>
      <td>0.898867</td>
      <td>0.506363</td>
      <td>-0.179810</td>
      <td>0.010696</td>
      <td>0.182786</td>
      <td>-0.452166</td>
      <td>-1.095644</td>
      <td>-1.437418</td>
      <td>-0.131045</td>
      <td>-0.026940</td>
      <td>0.543395</td>
      <td>-0.083206</td>
      <td>-0.322777</td>
      <td>-0.859762</td>
      <td>-0.379949</td>
      <td>0.704529</td>
      <td>0.054223</td>
      <td>-0.055807</td>
      <td>-0.277059</td>
      <td>-0.908895</td>
      <td>0.662330</td>
      <td>1.034747</td>
      <td>0.712043</td>
      <td>-0.664626</td>
      <td>0.106180</td>
      <td>0.096133</td>
      <td>-0.115822</td>
      <td>0.215962</td>
      <td>-0.204972</td>
      <td>-1.039189</td>
      <td>0.392860</td>
      <td>-0.059689</td>
      <td>...</td>
      <td>-1.051262</td>
      <td>-0.655274</td>
      <td>-0.236711</td>
      <td>-0.016559</td>
      <td>0.869360</td>
      <td>0.139958</td>
      <td>0.191605</td>
      <td>-0.088562</td>
      <td>-0.012210</td>
      <td>-0.211786</td>
      <td>0.461878</td>
      <td>-0.157072</td>
      <td>1.648481</td>
      <td>0.025007</td>
      <td>-0.593527</td>
      <td>0.449341</td>
      <td>0.645903</td>
      <td>1.424059</td>
      <td>0.211944</td>
      <td>-0.261103</td>
      <td>0.067425</td>
      <td>-0.507084</td>
      <td>-0.188567</td>
      <td>0.676215</td>
      <td>0.127279</td>
      <td>0.256902</td>
      <td>-0.423448</td>
      <td>-0.648322</td>
      <td>-0.059818</td>
      <td>-0.770101</td>
      <td>-0.947176</td>
      <td>-0.251652</td>
      <td>0.729721</td>
      <td>0.959206</td>
      <td>-0.351001</td>
      <td>-0.873980</td>
      <td>-0.871257</td>
      <td>0.574808</td>
      <td>0.444516</td>
      <td>1.325299</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.748970</td>
      <td>-0.146712</td>
      <td>-0.328302</td>
      <td>-0.188175</td>
      <td>-0.055711</td>
      <td>0.510453</td>
      <td>-0.589378</td>
      <td>-0.154441</td>
      <td>1.044449</td>
      <td>0.042031</td>
      <td>0.586260</td>
      <td>0.887682</td>
      <td>0.239745</td>
      <td>-0.873413</td>
      <td>-0.319123</td>
      <td>0.234264</td>
      <td>0.855816</td>
      <td>0.298760</td>
      <td>-0.423985</td>
      <td>-0.006154</td>
      <td>-1.171107</td>
      <td>-0.617625</td>
      <td>-0.269815</td>
      <td>0.581957</td>
      <td>-0.029806</td>
      <td>0.449357</td>
      <td>0.706302</td>
      <td>0.963082</td>
      <td>0.507274</td>
      <td>0.904394</td>
      <td>-0.316189</td>
      <td>0.435179</td>
      <td>1.563936</td>
      <td>1.143500</td>
      <td>-0.636629</td>
      <td>0.471915</td>
      <td>0.405392</td>
      <td>-0.433472</td>
      <td>0.631666</td>
      <td>-0.131686</td>
      <td>...</td>
      <td>0.102114</td>
      <td>0.152581</td>
      <td>-0.028424</td>
      <td>-0.133520</td>
      <td>0.662400</td>
      <td>0.617942</td>
      <td>1.771677</td>
      <td>0.874905</td>
      <td>0.314708</td>
      <td>0.595561</td>
      <td>0.644726</td>
      <td>-0.492246</td>
      <td>0.246021</td>
      <td>0.753076</td>
      <td>0.547751</td>
      <td>0.436789</td>
      <td>0.238698</td>
      <td>0.413156</td>
      <td>-0.313294</td>
      <td>-0.911346</td>
      <td>0.754692</td>
      <td>0.755095</td>
      <td>0.591565</td>
      <td>0.290417</td>
      <td>-0.305555</td>
      <td>0.775733</td>
      <td>0.774443</td>
      <td>1.251553</td>
      <td>-0.530965</td>
      <td>-0.760352</td>
      <td>-0.248629</td>
      <td>-1.428953</td>
      <td>-0.413420</td>
      <td>0.381824</td>
      <td>-0.231972</td>
      <td>-0.109316</td>
      <td>-0.982110</td>
      <td>-0.150287</td>
      <td>-0.165883</td>
      <td>-0.415405</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.173072</td>
      <td>-1.219463</td>
      <td>-1.316766</td>
      <td>-0.820657</td>
      <td>0.121899</td>
      <td>-0.001602</td>
      <td>0.729621</td>
      <td>0.415815</td>
      <td>1.343837</td>
      <td>0.062194</td>
      <td>0.438968</td>
      <td>0.353376</td>
      <td>0.875698</td>
      <td>0.417335</td>
      <td>-0.405853</td>
      <td>-0.230888</td>
      <td>0.881614</td>
      <td>-0.213412</td>
      <td>-0.395847</td>
      <td>-0.175164</td>
      <td>0.342037</td>
      <td>-0.611758</td>
      <td>-0.585210</td>
      <td>-0.885071</td>
      <td>-1.436300</td>
      <td>-1.069164</td>
      <td>-0.232132</td>
      <td>-0.588144</td>
      <td>-0.192226</td>
      <td>0.143359</td>
      <td>-0.443918</td>
      <td>-0.261086</td>
      <td>0.578924</td>
      <td>0.262952</td>
      <td>-0.537213</td>
      <td>-0.249831</td>
      <td>-0.006492</td>
      <td>0.824736</td>
      <td>0.887337</td>
      <td>0.450565</td>
      <td>...</td>
      <td>-0.652453</td>
      <td>0.237493</td>
      <td>0.842736</td>
      <td>1.182698</td>
      <td>0.959836</td>
      <td>1.284742</td>
      <td>0.730587</td>
      <td>0.465988</td>
      <td>0.100472</td>
      <td>-0.110201</td>
      <td>0.538613</td>
      <td>0.102587</td>
      <td>0.427158</td>
      <td>0.726186</td>
      <td>-0.186598</td>
      <td>-0.049132</td>
      <td>1.182073</td>
      <td>1.501962</td>
      <td>0.103470</td>
      <td>0.616251</td>
      <td>-0.254435</td>
      <td>0.223769</td>
      <td>0.792931</td>
      <td>-1.004851</td>
      <td>0.456484</td>
      <td>0.751413</td>
      <td>-0.005281</td>
      <td>0.652773</td>
      <td>-0.336935</td>
      <td>-0.146862</td>
      <td>0.072745</td>
      <td>0.792055</td>
      <td>0.164451</td>
      <td>0.242456</td>
      <td>-0.490229</td>
      <td>-0.444912</td>
      <td>-0.165327</td>
      <td>-0.434917</td>
      <td>0.389336</td>
      <td>0.390148</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.360384</td>
      <td>-1.490468</td>
      <td>-0.647613</td>
      <td>-0.440842</td>
      <td>-0.136151</td>
      <td>0.126009</td>
      <td>0.283038</td>
      <td>0.869943</td>
      <td>0.054028</td>
      <td>-0.361255</td>
      <td>-0.952031</td>
      <td>0.163389</td>
      <td>-0.543224</td>
      <td>-0.457453</td>
      <td>-0.098150</td>
      <td>-1.128397</td>
      <td>-0.435631</td>
      <td>0.298440</td>
      <td>0.754491</td>
      <td>-0.197042</td>
      <td>0.316646</td>
      <td>-0.707057</td>
      <td>-0.328812</td>
      <td>-0.357472</td>
      <td>0.577467</td>
      <td>0.382096</td>
      <td>2.018686</td>
      <td>-0.296838</td>
      <td>0.431348</td>
      <td>-0.185632</td>
      <td>-0.521943</td>
      <td>-0.315479</td>
      <td>-0.085727</td>
      <td>-0.245527</td>
      <td>0.305599</td>
      <td>0.677155</td>
      <td>0.177469</td>
      <td>-0.434641</td>
      <td>-0.524690</td>
      <td>-0.314016</td>
      <td>...</td>
      <td>0.589736</td>
      <td>0.854280</td>
      <td>0.427433</td>
      <td>-0.275943</td>
      <td>1.523659</td>
      <td>-0.892213</td>
      <td>0.009512</td>
      <td>0.459194</td>
      <td>0.641743</td>
      <td>-0.026468</td>
      <td>0.693122</td>
      <td>0.283709</td>
      <td>0.226631</td>
      <td>0.751912</td>
      <td>-0.323370</td>
      <td>-0.575592</td>
      <td>-0.646970</td>
      <td>0.141384</td>
      <td>-0.072233</td>
      <td>-0.262904</td>
      <td>0.034104</td>
      <td>-0.955974</td>
      <td>0.502590</td>
      <td>0.041180</td>
      <td>-0.077582</td>
      <td>-0.257190</td>
      <td>-0.723988</td>
      <td>-0.677190</td>
      <td>-0.277701</td>
      <td>-0.520019</td>
      <td>0.066067</td>
      <td>0.357114</td>
      <td>0.148716</td>
      <td>0.085834</td>
      <td>-0.660645</td>
      <td>-0.240040</td>
      <td>-0.156273</td>
      <td>-1.617179</td>
      <td>-1.004843</td>
      <td>-0.630736</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.146491</td>
      <td>0.397023</td>
      <td>0.459912</td>
      <td>-0.981535</td>
      <td>-0.275260</td>
      <td>0.063578</td>
      <td>0.580298</td>
      <td>0.306389</td>
      <td>-0.389640</td>
      <td>-0.751251</td>
      <td>-0.429533</td>
      <td>-0.341190</td>
      <td>-0.817177</td>
      <td>0.481399</td>
      <td>0.638997</td>
      <td>0.228487</td>
      <td>-0.841066</td>
      <td>-0.396099</td>
      <td>0.498675</td>
      <td>-1.309581</td>
      <td>-1.161385</td>
      <td>-0.322322</td>
      <td>0.185421</td>
      <td>0.317172</td>
      <td>0.655024</td>
      <td>1.537559</td>
      <td>0.419349</td>
      <td>-0.362060</td>
      <td>-0.639379</td>
      <td>-0.740797</td>
      <td>0.414833</td>
      <td>0.815217</td>
      <td>-0.113290</td>
      <td>-0.294839</td>
      <td>0.849944</td>
      <td>1.325811</td>
      <td>1.009570</td>
      <td>0.047500</td>
      <td>-0.353381</td>
      <td>-0.803973</td>
      <td>...</td>
      <td>-0.078044</td>
      <td>0.045623</td>
      <td>-0.268500</td>
      <td>-0.249497</td>
      <td>-0.473571</td>
      <td>-0.656825</td>
      <td>-0.093633</td>
      <td>0.886657</td>
      <td>0.225123</td>
      <td>-0.176209</td>
      <td>-0.407683</td>
      <td>0.513059</td>
      <td>-0.500139</td>
      <td>0.861008</td>
      <td>-0.040377</td>
      <td>0.101174</td>
      <td>0.149474</td>
      <td>0.550403</td>
      <td>-0.251602</td>
      <td>-0.084032</td>
      <td>0.087882</td>
      <td>-0.270777</td>
      <td>0.088774</td>
      <td>-0.131436</td>
      <td>-0.395057</td>
      <td>-0.001105</td>
      <td>-0.344764</td>
      <td>-0.613095</td>
      <td>0.469025</td>
      <td>-0.813956</td>
      <td>-0.033318</td>
      <td>0.225964</td>
      <td>0.785061</td>
      <td>0.118057</td>
      <td>-0.237640</td>
      <td>0.639953</td>
      <td>0.104196</td>
      <td>0.828443</td>
      <td>0.439370</td>
      <td>0.005556</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.376856</td>
      <td>0.563999</td>
      <td>0.050080</td>
      <td>-0.601910</td>
      <td>-0.471084</td>
      <td>1.005629</td>
      <td>1.188810</td>
      <td>1.478004</td>
      <td>1.066601</td>
      <td>-0.329308</td>
      <td>-1.581510</td>
      <td>-0.784068</td>
      <td>-0.017688</td>
      <td>0.047359</td>
      <td>-0.446143</td>
      <td>-0.727487</td>
      <td>0.286798</td>
      <td>-0.385413</td>
      <td>-0.953697</td>
      <td>-0.330085</td>
      <td>-1.020869</td>
      <td>-0.544151</td>
      <td>0.145581</td>
      <td>-0.681072</td>
      <td>0.299324</td>
      <td>-0.095858</td>
      <td>0.558384</td>
      <td>-1.220983</td>
      <td>-0.275152</td>
      <td>-0.751871</td>
      <td>0.408002</td>
      <td>0.817567</td>
      <td>0.753862</td>
      <td>0.695662</td>
      <td>0.234324</td>
      <td>-0.100496</td>
      <td>-0.348699</td>
      <td>-0.314816</td>
      <td>-0.507572</td>
      <td>-0.193402</td>
      <td>...</td>
      <td>-0.367368</td>
      <td>-0.591546</td>
      <td>0.383446</td>
      <td>1.158340</td>
      <td>0.241587</td>
      <td>-0.388611</td>
      <td>-0.395802</td>
      <td>-1.259223</td>
      <td>-0.943834</td>
      <td>-0.185979</td>
      <td>0.245262</td>
      <td>-0.761397</td>
      <td>-0.108068</td>
      <td>-0.066957</td>
      <td>0.167402</td>
      <td>-0.831401</td>
      <td>0.599287</td>
      <td>0.572922</td>
      <td>-0.869426</td>
      <td>0.174902</td>
      <td>-0.183897</td>
      <td>-0.224677</td>
      <td>0.025328</td>
      <td>-0.340926</td>
      <td>-0.394738</td>
      <td>-0.374324</td>
      <td>1.117357</td>
      <td>0.029339</td>
      <td>-0.068124</td>
      <td>0.561087</td>
      <td>0.331299</td>
      <td>0.304207</td>
      <td>0.811914</td>
      <td>-0.456208</td>
      <td>0.232782</td>
      <td>-0.431680</td>
      <td>0.245960</td>
      <td>3.025453</td>
      <td>2.824963</td>
      <td>1.436283</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.544096</td>
      <td>0.719350</td>
      <td>0.525965</td>
      <td>-0.068803</td>
      <td>0.199824</td>
      <td>1.619331</td>
      <td>0.420268</td>
      <td>1.153932</td>
      <td>-0.711459</td>
      <td>-0.400445</td>
      <td>-1.096307</td>
      <td>0.534811</td>
      <td>-0.668406</td>
      <td>0.270258</td>
      <td>0.290350</td>
      <td>-0.675705</td>
      <td>-1.088379</td>
      <td>0.033790</td>
      <td>0.547240</td>
      <td>1.249549</td>
      <td>-0.985141</td>
      <td>0.942220</td>
      <td>1.128322</td>
      <td>0.881591</td>
      <td>1.544920</td>
      <td>1.167333</td>
      <td>0.388613</td>
      <td>-0.447138</td>
      <td>0.711554</td>
      <td>0.120318</td>
      <td>0.096370</td>
      <td>0.271799</td>
      <td>-0.148369</td>
      <td>0.724821</td>
      <td>1.003861</td>
      <td>0.951570</td>
      <td>0.718022</td>
      <td>-0.029134</td>
      <td>-0.984352</td>
      <td>-0.389824</td>
      <td>...</td>
      <td>-1.197829</td>
      <td>-0.354213</td>
      <td>-0.895472</td>
      <td>-0.082640</td>
      <td>0.593401</td>
      <td>-0.862141</td>
      <td>-0.708866</td>
      <td>0.084035</td>
      <td>0.475137</td>
      <td>-0.675472</td>
      <td>0.134118</td>
      <td>-0.283131</td>
      <td>-0.206822</td>
      <td>-0.652236</td>
      <td>-1.607511</td>
      <td>-0.140123</td>
      <td>-1.191388</td>
      <td>-0.266585</td>
      <td>0.506622</td>
      <td>1.095941</td>
      <td>1.165006</td>
      <td>-0.392943</td>
      <td>0.041032</td>
      <td>0.029063</td>
      <td>0.553864</td>
      <td>0.156816</td>
      <td>0.672258</td>
      <td>0.728084</td>
      <td>1.182221</td>
      <td>0.159428</td>
      <td>0.107085</td>
      <td>0.158234</td>
      <td>0.062341</td>
      <td>-0.086071</td>
      <td>0.583096</td>
      <td>-0.336481</td>
      <td>0.108495</td>
      <td>0.365609</td>
      <td>0.481570</td>
      <td>-0.115124</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.514201</td>
      <td>-0.872296</td>
      <td>0.458812</td>
      <td>-0.715371</td>
      <td>0.393984</td>
      <td>0.280061</td>
      <td>-0.215993</td>
      <td>1.086598</td>
      <td>0.374925</td>
      <td>0.234231</td>
      <td>-0.156168</td>
      <td>-0.030402</td>
      <td>-1.150709</td>
      <td>-0.398150</td>
      <td>0.249605</td>
      <td>0.376915</td>
      <td>-0.391215</td>
      <td>-0.182940</td>
      <td>-0.014685</td>
      <td>-0.192289</td>
      <td>0.138893</td>
      <td>0.427019</td>
      <td>0.328932</td>
      <td>0.277708</td>
      <td>0.222482</td>
      <td>0.429761</td>
      <td>0.721329</td>
      <td>-0.502433</td>
      <td>0.393198</td>
      <td>-0.196881</td>
      <td>-0.174915</td>
      <td>0.438299</td>
      <td>-0.621049</td>
      <td>0.238914</td>
      <td>1.109314</td>
      <td>0.598306</td>
      <td>0.222785</td>
      <td>-0.542745</td>
      <td>-0.359178</td>
      <td>-0.630238</td>
      <td>...</td>
      <td>0.025749</td>
      <td>1.045614</td>
      <td>0.480262</td>
      <td>0.481282</td>
      <td>1.043483</td>
      <td>-0.945469</td>
      <td>0.175229</td>
      <td>-0.003739</td>
      <td>0.762043</td>
      <td>0.819980</td>
      <td>-0.117951</td>
      <td>-1.055939</td>
      <td>-1.379455</td>
      <td>0.157726</td>
      <td>0.780466</td>
      <td>-0.707335</td>
      <td>-0.080918</td>
      <td>-0.722795</td>
      <td>-0.076835</td>
      <td>0.182124</td>
      <td>0.598883</td>
      <td>-0.888268</td>
      <td>-0.393288</td>
      <td>-0.028907</td>
      <td>0.330914</td>
      <td>-0.427656</td>
      <td>-0.306150</td>
      <td>-0.067832</td>
      <td>-0.653648</td>
      <td>0.275700</td>
      <td>0.148109</td>
      <td>0.472269</td>
      <td>0.711103</td>
      <td>-1.030940</td>
      <td>-1.135592</td>
      <td>-0.703162</td>
      <td>0.396889</td>
      <td>-0.230120</td>
      <td>-0.147473</td>
      <td>-0.417215</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 103 columns</p>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7fb160104cd0&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %   97.5 %
D  1.071933  0.035979  29.793205  4.784397e-195  1.001415  1.14245
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  5.657 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>