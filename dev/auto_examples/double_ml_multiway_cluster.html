
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.321816</td>
      <td>-0.464026</td>
      <td>-0.375993</td>
      <td>0.064755</td>
      <td>-0.150560</td>
      <td>0.284934</td>
      <td>-0.063296</td>
      <td>1.290684</td>
      <td>-0.411048</td>
      <td>0.027664</td>
      <td>-1.373853</td>
      <td>-0.677830</td>
      <td>-1.337611</td>
      <td>-0.723993</td>
      <td>1.376861</td>
      <td>0.582181</td>
      <td>0.249736</td>
      <td>-0.301658</td>
      <td>0.420602</td>
      <td>0.244247</td>
      <td>0.107143</td>
      <td>0.378254</td>
      <td>0.411004</td>
      <td>0.817264</td>
      <td>1.222389</td>
      <td>-0.070652</td>
      <td>0.453101</td>
      <td>0.925412</td>
      <td>-0.601367</td>
      <td>-0.111992</td>
      <td>0.109418</td>
      <td>-0.178977</td>
      <td>0.499931</td>
      <td>0.662267</td>
      <td>-0.078339</td>
      <td>-0.000208</td>
      <td>0.158826</td>
      <td>0.052044</td>
      <td>-0.725764</td>
      <td>0.013894</td>
      <td>...</td>
      <td>-0.007362</td>
      <td>0.281674</td>
      <td>0.262142</td>
      <td>0.742564</td>
      <td>0.259755</td>
      <td>0.887968</td>
      <td>-0.263941</td>
      <td>0.184469</td>
      <td>-0.181463</td>
      <td>0.179939</td>
      <td>0.029558</td>
      <td>0.073810</td>
      <td>0.853104</td>
      <td>1.313314</td>
      <td>-0.221758</td>
      <td>0.778484</td>
      <td>0.712314</td>
      <td>0.991849</td>
      <td>-0.394416</td>
      <td>0.937314</td>
      <td>0.692299</td>
      <td>0.117709</td>
      <td>0.098120</td>
      <td>0.140121</td>
      <td>-0.976995</td>
      <td>-0.482289</td>
      <td>-0.802065</td>
      <td>-0.378491</td>
      <td>-0.316423</td>
      <td>-0.633969</td>
      <td>0.811659</td>
      <td>0.498418</td>
      <td>0.013195</td>
      <td>-0.088092</td>
      <td>0.655024</td>
      <td>1.553584</td>
      <td>0.339956</td>
      <td>0.150959</td>
      <td>0.231937</td>
      <td>0.336982</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.219127</td>
      <td>-0.690054</td>
      <td>0.100860</td>
      <td>-0.112829</td>
      <td>0.319078</td>
      <td>-0.211467</td>
      <td>0.936367</td>
      <td>0.854066</td>
      <td>0.504042</td>
      <td>0.913395</td>
      <td>0.934093</td>
      <td>0.599310</td>
      <td>0.677757</td>
      <td>1.066162</td>
      <td>-0.281130</td>
      <td>-0.440612</td>
      <td>0.011060</td>
      <td>1.042412</td>
      <td>0.490495</td>
      <td>-0.222679</td>
      <td>0.109972</td>
      <td>0.049335</td>
      <td>0.355495</td>
      <td>0.653057</td>
      <td>-0.808104</td>
      <td>-0.808627</td>
      <td>-0.522603</td>
      <td>-0.921616</td>
      <td>0.075290</td>
      <td>-0.233436</td>
      <td>0.960545</td>
      <td>-0.358287</td>
      <td>-1.529738</td>
      <td>0.180035</td>
      <td>-0.343541</td>
      <td>0.185735</td>
      <td>1.182844</td>
      <td>0.634330</td>
      <td>-0.528124</td>
      <td>0.920633</td>
      <td>...</td>
      <td>-0.000288</td>
      <td>-0.173198</td>
      <td>1.048886</td>
      <td>-0.029155</td>
      <td>0.573494</td>
      <td>0.011094</td>
      <td>-0.481214</td>
      <td>0.608681</td>
      <td>0.219277</td>
      <td>-0.316816</td>
      <td>-0.598220</td>
      <td>0.357172</td>
      <td>0.474319</td>
      <td>0.050658</td>
      <td>0.931374</td>
      <td>-0.219746</td>
      <td>0.361404</td>
      <td>0.045744</td>
      <td>0.490192</td>
      <td>-0.637048</td>
      <td>0.575326</td>
      <td>-0.023278</td>
      <td>-0.492845</td>
      <td>0.025295</td>
      <td>0.745636</td>
      <td>0.518456</td>
      <td>0.278602</td>
      <td>0.291594</td>
      <td>0.645415</td>
      <td>1.222220</td>
      <td>0.007760</td>
      <td>0.879963</td>
      <td>0.799480</td>
      <td>1.081065</td>
      <td>-0.134149</td>
      <td>0.086944</td>
      <td>-0.329485</td>
      <td>2.297009</td>
      <td>1.618670</td>
      <td>0.414444</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.693124</td>
      <td>-0.351717</td>
      <td>-0.894584</td>
      <td>-0.384969</td>
      <td>0.472298</td>
      <td>-0.670456</td>
      <td>-0.922502</td>
      <td>-1.061510</td>
      <td>-0.855404</td>
      <td>-0.361751</td>
      <td>0.127051</td>
      <td>-0.464434</td>
      <td>-0.213124</td>
      <td>-0.250937</td>
      <td>-0.348845</td>
      <td>-0.143453</td>
      <td>-0.786841</td>
      <td>0.303615</td>
      <td>0.091523</td>
      <td>-1.251035</td>
      <td>-0.619184</td>
      <td>-0.818773</td>
      <td>-0.473984</td>
      <td>0.308253</td>
      <td>-0.836217</td>
      <td>-0.464364</td>
      <td>0.086075</td>
      <td>0.215727</td>
      <td>0.572998</td>
      <td>0.568075</td>
      <td>0.263636</td>
      <td>-0.109107</td>
      <td>-0.611172</td>
      <td>-0.382340</td>
      <td>0.163508</td>
      <td>0.301615</td>
      <td>0.630550</td>
      <td>0.386526</td>
      <td>1.637767</td>
      <td>-0.536963</td>
      <td>...</td>
      <td>0.647557</td>
      <td>-0.429699</td>
      <td>-0.120720</td>
      <td>0.887924</td>
      <td>0.630747</td>
      <td>-0.113290</td>
      <td>0.510103</td>
      <td>0.735541</td>
      <td>0.826683</td>
      <td>-0.197381</td>
      <td>-1.294987</td>
      <td>-0.974025</td>
      <td>0.966341</td>
      <td>1.010938</td>
      <td>-0.131187</td>
      <td>0.562097</td>
      <td>0.306525</td>
      <td>0.146154</td>
      <td>-0.167256</td>
      <td>0.365892</td>
      <td>0.240005</td>
      <td>0.353862</td>
      <td>0.153818</td>
      <td>0.472239</td>
      <td>-0.330382</td>
      <td>1.098701</td>
      <td>0.173986</td>
      <td>0.409514</td>
      <td>0.104219</td>
      <td>0.775257</td>
      <td>-0.008442</td>
      <td>0.229231</td>
      <td>-0.000680</td>
      <td>0.528447</td>
      <td>0.684900</td>
      <td>-0.049213</td>
      <td>0.179487</td>
      <td>1.408417</td>
      <td>0.910947</td>
      <td>0.049117</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.387172</td>
      <td>-0.197428</td>
      <td>-0.848827</td>
      <td>-0.729620</td>
      <td>1.018108</td>
      <td>-0.205477</td>
      <td>-0.890581</td>
      <td>-0.241167</td>
      <td>-0.000113</td>
      <td>0.725932</td>
      <td>0.038418</td>
      <td>-0.160316</td>
      <td>0.836103</td>
      <td>0.039516</td>
      <td>0.844673</td>
      <td>0.902233</td>
      <td>0.525400</td>
      <td>1.080677</td>
      <td>0.531689</td>
      <td>-0.157338</td>
      <td>0.005310</td>
      <td>-0.455229</td>
      <td>-0.147880</td>
      <td>0.945127</td>
      <td>-1.036750</td>
      <td>0.267407</td>
      <td>-0.511929</td>
      <td>-0.040434</td>
      <td>0.686351</td>
      <td>-0.861435</td>
      <td>-1.146782</td>
      <td>-0.211331</td>
      <td>0.052765</td>
      <td>1.032422</td>
      <td>-0.218329</td>
      <td>-0.014241</td>
      <td>0.168583</td>
      <td>-0.683050</td>
      <td>-0.154927</td>
      <td>-0.744968</td>
      <td>...</td>
      <td>0.189394</td>
      <td>-0.611909</td>
      <td>0.160628</td>
      <td>0.547868</td>
      <td>1.024555</td>
      <td>0.132147</td>
      <td>1.354386</td>
      <td>0.329716</td>
      <td>0.013420</td>
      <td>-0.397981</td>
      <td>0.199553</td>
      <td>0.157965</td>
      <td>-0.045439</td>
      <td>0.506042</td>
      <td>0.656689</td>
      <td>0.326867</td>
      <td>0.108928</td>
      <td>0.051481</td>
      <td>-0.008758</td>
      <td>0.905428</td>
      <td>-0.128155</td>
      <td>-0.368348</td>
      <td>-0.582477</td>
      <td>-0.375722</td>
      <td>-0.865850</td>
      <td>-0.322358</td>
      <td>0.571225</td>
      <td>0.176194</td>
      <td>0.456195</td>
      <td>-0.224817</td>
      <td>0.139571</td>
      <td>0.949679</td>
      <td>0.775474</td>
      <td>-0.088359</td>
      <td>0.166668</td>
      <td>0.703181</td>
      <td>-0.528480</td>
      <td>-0.191021</td>
      <td>-0.022336</td>
      <td>-0.928646</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.206759</td>
      <td>0.021800</td>
      <td>-0.039334</td>
      <td>0.328483</td>
      <td>-1.568803</td>
      <td>-0.763720</td>
      <td>-0.194640</td>
      <td>-0.406373</td>
      <td>-0.365160</td>
      <td>0.201603</td>
      <td>0.355100</td>
      <td>0.326266</td>
      <td>0.105731</td>
      <td>-0.036601</td>
      <td>1.316029</td>
      <td>0.488484</td>
      <td>0.135973</td>
      <td>-0.147786</td>
      <td>0.648955</td>
      <td>-0.319371</td>
      <td>0.550415</td>
      <td>0.078464</td>
      <td>0.838140</td>
      <td>-0.168856</td>
      <td>0.015320</td>
      <td>-0.697666</td>
      <td>-0.482329</td>
      <td>0.231060</td>
      <td>0.612577</td>
      <td>-0.190152</td>
      <td>0.330619</td>
      <td>0.991211</td>
      <td>-1.015890</td>
      <td>1.215960</td>
      <td>0.760454</td>
      <td>-0.544302</td>
      <td>0.687167</td>
      <td>0.038775</td>
      <td>-0.476264</td>
      <td>0.199691</td>
      <td>...</td>
      <td>-0.686770</td>
      <td>-0.880887</td>
      <td>0.068882</td>
      <td>0.096683</td>
      <td>-0.296680</td>
      <td>0.023047</td>
      <td>0.045439</td>
      <td>0.337644</td>
      <td>-0.057138</td>
      <td>1.025739</td>
      <td>0.651253</td>
      <td>0.398477</td>
      <td>1.122610</td>
      <td>1.206279</td>
      <td>1.100914</td>
      <td>-0.428724</td>
      <td>0.330384</td>
      <td>-0.816008</td>
      <td>-0.689389</td>
      <td>0.073655</td>
      <td>0.326974</td>
      <td>0.938186</td>
      <td>-0.273108</td>
      <td>-1.124323</td>
      <td>-0.158946</td>
      <td>0.000322</td>
      <td>0.420595</td>
      <td>0.613105</td>
      <td>-0.331157</td>
      <td>-0.605649</td>
      <td>0.154281</td>
      <td>0.933639</td>
      <td>-0.173837</td>
      <td>-0.546544</td>
      <td>0.311670</td>
      <td>0.754176</td>
      <td>0.313479</td>
      <td>-0.339405</td>
      <td>-0.263652</td>
      <td>-0.301763</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.951969</td>
      <td>0.287019</td>
      <td>1.143278</td>
      <td>-0.261654</td>
      <td>0.536262</td>
      <td>-0.463182</td>
      <td>0.245466</td>
      <td>-0.311955</td>
      <td>-0.129333</td>
      <td>0.616210</td>
      <td>0.444246</td>
      <td>0.041894</td>
      <td>0.123627</td>
      <td>0.079089</td>
      <td>1.232832</td>
      <td>0.271819</td>
      <td>0.194033</td>
      <td>0.305932</td>
      <td>-0.053795</td>
      <td>0.312241</td>
      <td>-0.095905</td>
      <td>-1.357355</td>
      <td>-0.732986</td>
      <td>-0.313566</td>
      <td>-1.034858</td>
      <td>-0.509267</td>
      <td>0.851836</td>
      <td>0.802269</td>
      <td>1.362820</td>
      <td>-0.127218</td>
      <td>0.450072</td>
      <td>0.117495</td>
      <td>0.595208</td>
      <td>0.839990</td>
      <td>0.559955</td>
      <td>-0.186635</td>
      <td>0.063081</td>
      <td>0.088599</td>
      <td>0.381016</td>
      <td>0.291319</td>
      <td>...</td>
      <td>0.698653</td>
      <td>0.135652</td>
      <td>0.343653</td>
      <td>-0.945380</td>
      <td>0.826852</td>
      <td>-0.206284</td>
      <td>0.815074</td>
      <td>0.012207</td>
      <td>0.349223</td>
      <td>0.195888</td>
      <td>-0.808405</td>
      <td>-0.251952</td>
      <td>0.906693</td>
      <td>1.226847</td>
      <td>-0.138810</td>
      <td>-0.812681</td>
      <td>0.040922</td>
      <td>0.329569</td>
      <td>-0.750488</td>
      <td>0.275928</td>
      <td>0.664017</td>
      <td>0.332504</td>
      <td>0.296106</td>
      <td>-0.045396</td>
      <td>-1.033445</td>
      <td>0.150898</td>
      <td>-0.967842</td>
      <td>-0.801144</td>
      <td>0.248099</td>
      <td>-1.168282</td>
      <td>-1.059954</td>
      <td>0.053730</td>
      <td>-0.172930</td>
      <td>-0.626016</td>
      <td>0.261210</td>
      <td>0.502278</td>
      <td>-0.528838</td>
      <td>1.985167</td>
      <td>1.430276</td>
      <td>0.705827</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.112880</td>
      <td>-0.322612</td>
      <td>-1.119560</td>
      <td>-0.566198</td>
      <td>-0.195829</td>
      <td>-0.954126</td>
      <td>-0.585450</td>
      <td>-0.028287</td>
      <td>-0.157533</td>
      <td>-0.315162</td>
      <td>-0.359480</td>
      <td>0.131748</td>
      <td>1.159767</td>
      <td>0.402327</td>
      <td>0.100540</td>
      <td>0.818613</td>
      <td>1.127070</td>
      <td>1.159507</td>
      <td>0.162318</td>
      <td>-0.193678</td>
      <td>0.357174</td>
      <td>-1.231311</td>
      <td>0.035595</td>
      <td>1.168241</td>
      <td>-0.753292</td>
      <td>-0.172703</td>
      <td>0.967963</td>
      <td>0.185127</td>
      <td>0.321543</td>
      <td>-0.144178</td>
      <td>-0.776573</td>
      <td>0.134127</td>
      <td>-0.937674</td>
      <td>-0.366332</td>
      <td>0.264282</td>
      <td>-0.764259</td>
      <td>0.330395</td>
      <td>0.137093</td>
      <td>-0.091999</td>
      <td>0.340054</td>
      <td>...</td>
      <td>0.802688</td>
      <td>-0.420175</td>
      <td>0.116800</td>
      <td>0.242946</td>
      <td>1.506584</td>
      <td>1.074209</td>
      <td>0.849290</td>
      <td>-0.123838</td>
      <td>-0.170068</td>
      <td>-0.550564</td>
      <td>-0.524124</td>
      <td>0.166061</td>
      <td>-0.060921</td>
      <td>0.681397</td>
      <td>-0.646777</td>
      <td>0.192887</td>
      <td>-0.280267</td>
      <td>0.737093</td>
      <td>0.439824</td>
      <td>-0.007715</td>
      <td>0.468741</td>
      <td>0.419676</td>
      <td>0.377508</td>
      <td>-0.034482</td>
      <td>0.440332</td>
      <td>-0.639237</td>
      <td>-1.163910</td>
      <td>0.258038</td>
      <td>-1.171799</td>
      <td>-0.279303</td>
      <td>0.626319</td>
      <td>0.548927</td>
      <td>-0.816932</td>
      <td>-0.856081</td>
      <td>-0.166299</td>
      <td>1.200294</td>
      <td>1.256989</td>
      <td>-0.410078</td>
      <td>-1.018673</td>
      <td>-1.018485</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.669807</td>
      <td>1.076649</td>
      <td>0.486418</td>
      <td>-0.184117</td>
      <td>-0.091268</td>
      <td>0.093568</td>
      <td>-0.118294</td>
      <td>0.342035</td>
      <td>0.566395</td>
      <td>0.403582</td>
      <td>0.599585</td>
      <td>0.595987</td>
      <td>0.049973</td>
      <td>-0.039806</td>
      <td>0.215273</td>
      <td>-0.792471</td>
      <td>0.800028</td>
      <td>-0.260392</td>
      <td>-0.526431</td>
      <td>-0.889262</td>
      <td>-0.468434</td>
      <td>-0.131061</td>
      <td>-0.660874</td>
      <td>1.031270</td>
      <td>0.277374</td>
      <td>0.499248</td>
      <td>-0.035293</td>
      <td>-0.471869</td>
      <td>0.688378</td>
      <td>0.062825</td>
      <td>0.643333</td>
      <td>-0.014752</td>
      <td>0.369691</td>
      <td>0.871170</td>
      <td>0.680001</td>
      <td>-0.741520</td>
      <td>-0.227938</td>
      <td>-0.376421</td>
      <td>-0.496855</td>
      <td>-0.315767</td>
      <td>...</td>
      <td>-0.074174</td>
      <td>-0.612168</td>
      <td>0.040572</td>
      <td>0.025167</td>
      <td>0.713105</td>
      <td>0.672385</td>
      <td>0.044598</td>
      <td>0.252074</td>
      <td>-0.121913</td>
      <td>0.072368</td>
      <td>0.806494</td>
      <td>0.078414</td>
      <td>0.963254</td>
      <td>0.697984</td>
      <td>-0.302280</td>
      <td>-0.859950</td>
      <td>-0.707696</td>
      <td>-0.858341</td>
      <td>0.309155</td>
      <td>0.288403</td>
      <td>0.785382</td>
      <td>0.150118</td>
      <td>-0.729855</td>
      <td>-0.466127</td>
      <td>-0.176911</td>
      <td>-0.341425</td>
      <td>0.622062</td>
      <td>0.643248</td>
      <td>-0.134256</td>
      <td>-0.451354</td>
      <td>-0.014722</td>
      <td>0.904944</td>
      <td>0.783298</td>
      <td>0.233383</td>
      <td>-0.641103</td>
      <td>0.778722</td>
      <td>0.028062</td>
      <td>1.524658</td>
      <td>1.244904</td>
      <td>0.382456</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.934341</td>
      <td>0.534450</td>
      <td>-0.528637</td>
      <td>0.469725</td>
      <td>-0.401413</td>
      <td>-0.615789</td>
      <td>0.125704</td>
      <td>-0.280835</td>
      <td>-1.124738</td>
      <td>-0.057824</td>
      <td>-0.723878</td>
      <td>-0.595157</td>
      <td>0.115729</td>
      <td>0.585835</td>
      <td>0.591438</td>
      <td>0.644031</td>
      <td>-0.437432</td>
      <td>0.452630</td>
      <td>0.103090</td>
      <td>-0.174223</td>
      <td>-0.208832</td>
      <td>-0.275452</td>
      <td>-1.149315</td>
      <td>1.230768</td>
      <td>-0.351320</td>
      <td>-0.324271</td>
      <td>0.850299</td>
      <td>-0.475485</td>
      <td>-0.097753</td>
      <td>-1.271746</td>
      <td>-0.507971</td>
      <td>-0.462946</td>
      <td>0.143497</td>
      <td>0.710820</td>
      <td>0.318090</td>
      <td>1.136904</td>
      <td>-0.208055</td>
      <td>-0.218480</td>
      <td>-0.849276</td>
      <td>0.958159</td>
      <td>...</td>
      <td>0.006507</td>
      <td>0.428223</td>
      <td>0.807622</td>
      <td>0.183046</td>
      <td>-0.922788</td>
      <td>0.245963</td>
      <td>0.323986</td>
      <td>0.297567</td>
      <td>0.889057</td>
      <td>0.333430</td>
      <td>0.701044</td>
      <td>-0.605716</td>
      <td>0.016049</td>
      <td>1.698915</td>
      <td>0.348947</td>
      <td>-0.263529</td>
      <td>0.357331</td>
      <td>-0.086489</td>
      <td>-0.874491</td>
      <td>0.432230</td>
      <td>-0.117136</td>
      <td>0.050817</td>
      <td>-0.132215</td>
      <td>-0.805595</td>
      <td>-0.584753</td>
      <td>-0.952384</td>
      <td>-0.541445</td>
      <td>0.829726</td>
      <td>-0.191813</td>
      <td>0.324363</td>
      <td>1.553701</td>
      <td>0.653946</td>
      <td>0.057069</td>
      <td>-0.105306</td>
      <td>0.404027</td>
      <td>0.935464</td>
      <td>0.508492</td>
      <td>2.859681</td>
      <td>1.301588</td>
      <td>0.293094</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-0.015223</td>
      <td>0.055930</td>
      <td>0.376974</td>
      <td>0.262342</td>
      <td>-0.182723</td>
      <td>-0.571972</td>
      <td>-0.769024</td>
      <td>0.300339</td>
      <td>0.464331</td>
      <td>0.199239</td>
      <td>-0.600839</td>
      <td>-1.015638</td>
      <td>-0.068630</td>
      <td>0.072505</td>
      <td>0.766266</td>
      <td>-0.038902</td>
      <td>0.733863</td>
      <td>1.506906</td>
      <td>-0.259446</td>
      <td>-0.883544</td>
      <td>-0.041973</td>
      <td>0.353401</td>
      <td>0.169480</td>
      <td>0.299773</td>
      <td>-0.848245</td>
      <td>0.792872</td>
      <td>-0.543896</td>
      <td>-0.080682</td>
      <td>0.261636</td>
      <td>-0.233749</td>
      <td>0.708567</td>
      <td>-1.041646</td>
      <td>-0.308851</td>
      <td>0.916095</td>
      <td>1.134709</td>
      <td>0.644091</td>
      <td>0.590662</td>
      <td>0.467933</td>
      <td>-0.639514</td>
      <td>-0.184256</td>
      <td>...</td>
      <td>-0.768393</td>
      <td>-0.437190</td>
      <td>0.130062</td>
      <td>0.923964</td>
      <td>-0.229840</td>
      <td>0.280576</td>
      <td>-0.530368</td>
      <td>-0.118906</td>
      <td>0.585329</td>
      <td>-0.386554</td>
      <td>-0.464014</td>
      <td>1.393867</td>
      <td>0.695270</td>
      <td>0.935817</td>
      <td>0.840242</td>
      <td>-0.089930</td>
      <td>0.482012</td>
      <td>0.037443</td>
      <td>0.088661</td>
      <td>-0.702616</td>
      <td>0.251690</td>
      <td>0.737832</td>
      <td>-1.344417</td>
      <td>-0.737647</td>
      <td>0.479744</td>
      <td>0.335621</td>
      <td>-0.284814</td>
      <td>-0.554900</td>
      <td>0.217970</td>
      <td>-0.259303</td>
      <td>0.715327</td>
      <td>0.457200</td>
      <td>-0.226887</td>
      <td>0.710588</td>
      <td>-0.472022</td>
      <td>0.354008</td>
      <td>0.819356</td>
      <td>-0.718542</td>
      <td>-0.335716</td>
      <td>-0.267031</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.042919</td>
      <td>0.407700</td>
      <td>-0.152552</td>
      <td>-0.471511</td>
      <td>-0.044909</td>
      <td>-0.790478</td>
      <td>-0.958973</td>
      <td>-0.438997</td>
      <td>-0.704843</td>
      <td>0.952925</td>
      <td>0.412734</td>
      <td>-0.537203</td>
      <td>-0.886072</td>
      <td>1.173766</td>
      <td>0.838768</td>
      <td>0.702001</td>
      <td>0.344558</td>
      <td>0.856846</td>
      <td>0.681823</td>
      <td>-0.429173</td>
      <td>0.306800</td>
      <td>-0.209957</td>
      <td>0.068023</td>
      <td>0.539623</td>
      <td>0.081820</td>
      <td>-0.388966</td>
      <td>-0.490215</td>
      <td>0.015833</td>
      <td>-0.170611</td>
      <td>-0.699120</td>
      <td>-0.326084</td>
      <td>-0.860142</td>
      <td>-1.178372</td>
      <td>1.090231</td>
      <td>0.776487</td>
      <td>-0.051882</td>
      <td>0.041184</td>
      <td>0.055492</td>
      <td>0.183365</td>
      <td>0.437272</td>
      <td>...</td>
      <td>0.163737</td>
      <td>-0.570841</td>
      <td>1.195168</td>
      <td>1.127353</td>
      <td>0.369984</td>
      <td>-1.066834</td>
      <td>-0.168270</td>
      <td>0.050107</td>
      <td>-0.452398</td>
      <td>0.201672</td>
      <td>-0.295654</td>
      <td>-0.405833</td>
      <td>0.570560</td>
      <td>0.224647</td>
      <td>-0.946820</td>
      <td>0.139827</td>
      <td>-0.374823</td>
      <td>-0.481066</td>
      <td>0.107709</td>
      <td>0.074047</td>
      <td>-0.330241</td>
      <td>-0.534034</td>
      <td>-1.102532</td>
      <td>0.761485</td>
      <td>0.619065</td>
      <td>0.546560</td>
      <td>0.363585</td>
      <td>0.744533</td>
      <td>0.206707</td>
      <td>0.464407</td>
      <td>0.720508</td>
      <td>0.255395</td>
      <td>0.497242</td>
      <td>-0.379860</td>
      <td>-0.238088</td>
      <td>-0.222675</td>
      <td>-0.469668</td>
      <td>-0.583577</td>
      <td>0.122342</td>
      <td>0.240846</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.825154</td>
      <td>0.632916</td>
      <td>-0.133024</td>
      <td>-0.743311</td>
      <td>0.502783</td>
      <td>0.406108</td>
      <td>0.564684</td>
      <td>0.341079</td>
      <td>0.439125</td>
      <td>1.235584</td>
      <td>0.050713</td>
      <td>0.735192</td>
      <td>-0.152657</td>
      <td>-0.327994</td>
      <td>0.930403</td>
      <td>0.228292</td>
      <td>0.137638</td>
      <td>0.863904</td>
      <td>-0.235847</td>
      <td>-0.480331</td>
      <td>-0.455749</td>
      <td>-0.166704</td>
      <td>-0.556373</td>
      <td>0.569696</td>
      <td>-0.861015</td>
      <td>0.140835</td>
      <td>0.877264</td>
      <td>1.236560</td>
      <td>0.896236</td>
      <td>1.186396</td>
      <td>0.635503</td>
      <td>0.543869</td>
      <td>-0.197547</td>
      <td>-0.233073</td>
      <td>0.378410</td>
      <td>-0.073136</td>
      <td>1.107652</td>
      <td>0.443333</td>
      <td>-1.118759</td>
      <td>-0.666047</td>
      <td>...</td>
      <td>0.154804</td>
      <td>0.084568</td>
      <td>1.019232</td>
      <td>1.453750</td>
      <td>0.863349</td>
      <td>0.139511</td>
      <td>0.360890</td>
      <td>0.205002</td>
      <td>0.067258</td>
      <td>-0.043177</td>
      <td>0.194462</td>
      <td>0.056074</td>
      <td>0.895547</td>
      <td>1.768046</td>
      <td>-0.490276</td>
      <td>-0.729019</td>
      <td>1.378900</td>
      <td>0.009684</td>
      <td>0.167573</td>
      <td>-0.141238</td>
      <td>0.448208</td>
      <td>0.140607</td>
      <td>-0.115373</td>
      <td>1.197870</td>
      <td>1.385098</td>
      <td>0.633657</td>
      <td>-0.663148</td>
      <td>-0.333706</td>
      <td>-0.196560</td>
      <td>-0.385484</td>
      <td>0.759270</td>
      <td>1.025723</td>
      <td>0.650904</td>
      <td>0.636989</td>
      <td>0.193913</td>
      <td>-0.700049</td>
      <td>-1.069335</td>
      <td>1.056847</td>
      <td>0.148554</td>
      <td>-0.707764</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-0.593954</td>
      <td>-0.950278</td>
      <td>-0.622343</td>
      <td>-0.733334</td>
      <td>-0.645622</td>
      <td>-0.504358</td>
      <td>-0.077919</td>
      <td>0.895468</td>
      <td>-0.063606</td>
      <td>-0.433542</td>
      <td>0.012420</td>
      <td>-0.957631</td>
      <td>0.294191</td>
      <td>-0.258048</td>
      <td>0.344572</td>
      <td>0.118785</td>
      <td>1.593003</td>
      <td>0.416404</td>
      <td>0.304210</td>
      <td>-0.457049</td>
      <td>0.117229</td>
      <td>-0.176134</td>
      <td>-0.970180</td>
      <td>0.210725</td>
      <td>0.018026</td>
      <td>-0.033825</td>
      <td>-0.065635</td>
      <td>-0.044580</td>
      <td>-0.084906</td>
      <td>0.477551</td>
      <td>1.484107</td>
      <td>-0.370026</td>
      <td>-0.392162</td>
      <td>0.167822</td>
      <td>-0.312125</td>
      <td>-0.148080</td>
      <td>0.533224</td>
      <td>0.686150</td>
      <td>-1.065122</td>
      <td>-0.753932</td>
      <td>...</td>
      <td>0.544977</td>
      <td>1.244170</td>
      <td>0.886986</td>
      <td>1.189384</td>
      <td>0.334759</td>
      <td>0.637788</td>
      <td>0.030963</td>
      <td>-0.485155</td>
      <td>0.740076</td>
      <td>0.349004</td>
      <td>-0.648320</td>
      <td>0.109452</td>
      <td>0.321549</td>
      <td>1.241587</td>
      <td>-0.419282</td>
      <td>-0.635150</td>
      <td>-0.147972</td>
      <td>0.120016</td>
      <td>-0.860938</td>
      <td>-0.018386</td>
      <td>0.058884</td>
      <td>-0.042546</td>
      <td>0.043595</td>
      <td>-0.260611</td>
      <td>0.938190</td>
      <td>-0.503594</td>
      <td>1.106916</td>
      <td>0.405990</td>
      <td>-0.529485</td>
      <td>0.074782</td>
      <td>-0.438006</td>
      <td>0.941692</td>
      <td>1.174593</td>
      <td>1.423909</td>
      <td>-0.427856</td>
      <td>0.759747</td>
      <td>0.152132</td>
      <td>-2.895154</td>
      <td>-1.877073</td>
      <td>-0.812015</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.345223</td>
      <td>-0.489931</td>
      <td>-0.730930</td>
      <td>-1.107242</td>
      <td>0.903912</td>
      <td>-1.432071</td>
      <td>-0.557449</td>
      <td>0.494310</td>
      <td>-0.018581</td>
      <td>0.240998</td>
      <td>0.681202</td>
      <td>0.248508</td>
      <td>-0.315274</td>
      <td>0.088474</td>
      <td>-0.012916</td>
      <td>0.191902</td>
      <td>1.002911</td>
      <td>0.181535</td>
      <td>1.094754</td>
      <td>-0.056674</td>
      <td>-0.236352</td>
      <td>0.306607</td>
      <td>-0.823972</td>
      <td>-0.179797</td>
      <td>-0.693052</td>
      <td>-0.252894</td>
      <td>-0.489303</td>
      <td>0.391775</td>
      <td>0.360599</td>
      <td>-0.457747</td>
      <td>0.362740</td>
      <td>-0.048302</td>
      <td>-0.820080</td>
      <td>0.445611</td>
      <td>-0.239910</td>
      <td>0.398752</td>
      <td>-0.437254</td>
      <td>0.620788</td>
      <td>0.462939</td>
      <td>0.074354</td>
      <td>...</td>
      <td>-0.254069</td>
      <td>-0.836735</td>
      <td>-0.804414</td>
      <td>0.376814</td>
      <td>0.353230</td>
      <td>-0.211950</td>
      <td>0.343151</td>
      <td>-0.120767</td>
      <td>0.631783</td>
      <td>-0.532559</td>
      <td>0.151812</td>
      <td>-0.246380</td>
      <td>0.921842</td>
      <td>1.063708</td>
      <td>-0.863909</td>
      <td>-0.010197</td>
      <td>-0.442513</td>
      <td>-0.671751</td>
      <td>-0.131703</td>
      <td>0.618565</td>
      <td>0.706156</td>
      <td>1.191065</td>
      <td>-0.036604</td>
      <td>-0.321684</td>
      <td>0.923248</td>
      <td>0.844194</td>
      <td>0.264793</td>
      <td>-0.275112</td>
      <td>-0.502702</td>
      <td>0.537617</td>
      <td>0.710960</td>
      <td>0.120334</td>
      <td>0.606192</td>
      <td>-0.296166</td>
      <td>-0.277240</td>
      <td>0.166298</td>
      <td>0.424412</td>
      <td>-0.637412</td>
      <td>-0.710922</td>
      <td>-1.004436</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.364945</td>
      <td>-0.762637</td>
      <td>-0.609337</td>
      <td>0.305464</td>
      <td>0.071225</td>
      <td>-0.381573</td>
      <td>-0.414072</td>
      <td>0.594155</td>
      <td>-1.060322</td>
      <td>0.416338</td>
      <td>-0.099714</td>
      <td>0.140325</td>
      <td>0.425035</td>
      <td>0.118783</td>
      <td>0.313777</td>
      <td>0.106086</td>
      <td>0.468420</td>
      <td>0.694487</td>
      <td>1.275467</td>
      <td>-0.139053</td>
      <td>-0.058371</td>
      <td>-0.208075</td>
      <td>-0.615783</td>
      <td>0.328569</td>
      <td>0.564161</td>
      <td>-0.066473</td>
      <td>-1.187155</td>
      <td>0.345775</td>
      <td>0.377525</td>
      <td>0.207146</td>
      <td>-0.006799</td>
      <td>-0.535233</td>
      <td>-0.639089</td>
      <td>1.145553</td>
      <td>0.010974</td>
      <td>-0.523383</td>
      <td>-0.091672</td>
      <td>1.488670</td>
      <td>-0.950471</td>
      <td>-0.970594</td>
      <td>...</td>
      <td>-0.619910</td>
      <td>-1.424508</td>
      <td>-0.144060</td>
      <td>-0.627311</td>
      <td>-0.861330</td>
      <td>0.423841</td>
      <td>-0.413560</td>
      <td>-0.051832</td>
      <td>-0.632816</td>
      <td>-0.459251</td>
      <td>0.175027</td>
      <td>0.414217</td>
      <td>-0.453034</td>
      <td>0.718966</td>
      <td>-0.867108</td>
      <td>-1.292706</td>
      <td>0.483606</td>
      <td>0.737947</td>
      <td>-0.328856</td>
      <td>-0.497529</td>
      <td>-0.031821</td>
      <td>0.488628</td>
      <td>-0.897673</td>
      <td>-0.028085</td>
      <td>0.449352</td>
      <td>-0.384420</td>
      <td>-0.940193</td>
      <td>0.570017</td>
      <td>0.058755</td>
      <td>1.109966</td>
      <td>0.003589</td>
      <td>-0.276484</td>
      <td>-0.523406</td>
      <td>-0.286150</td>
      <td>-0.192440</td>
      <td>0.903688</td>
      <td>-0.526442</td>
      <td>-0.921011</td>
      <td>-0.365450</td>
      <td>-0.083272</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.735148</td>
      <td>-0.289541</td>
      <td>-0.712399</td>
      <td>-0.708453</td>
      <td>-0.592292</td>
      <td>0.271640</td>
      <td>1.097042</td>
      <td>0.612048</td>
      <td>-0.267250</td>
      <td>0.373941</td>
      <td>0.610829</td>
      <td>0.086313</td>
      <td>0.350541</td>
      <td>0.130333</td>
      <td>0.492136</td>
      <td>-0.562422</td>
      <td>-0.657796</td>
      <td>1.198571</td>
      <td>0.648807</td>
      <td>-0.399818</td>
      <td>0.583302</td>
      <td>0.045083</td>
      <td>0.231125</td>
      <td>0.892377</td>
      <td>-0.182678</td>
      <td>0.814862</td>
      <td>-0.874735</td>
      <td>-0.247507</td>
      <td>0.034631</td>
      <td>-0.002021</td>
      <td>-0.346729</td>
      <td>-0.468545</td>
      <td>-0.084246</td>
      <td>1.002185</td>
      <td>0.793118</td>
      <td>0.015505</td>
      <td>0.972408</td>
      <td>-0.491807</td>
      <td>-0.715669</td>
      <td>-0.532576</td>
      <td>...</td>
      <td>1.802232</td>
      <td>0.181676</td>
      <td>0.304888</td>
      <td>-0.011964</td>
      <td>1.276532</td>
      <td>0.007526</td>
      <td>0.180109</td>
      <td>0.382790</td>
      <td>0.433564</td>
      <td>0.667772</td>
      <td>-0.073632</td>
      <td>0.159860</td>
      <td>0.806870</td>
      <td>1.170385</td>
      <td>-1.355398</td>
      <td>-1.317416</td>
      <td>-0.128780</td>
      <td>0.158646</td>
      <td>0.250917</td>
      <td>-0.325241</td>
      <td>0.530233</td>
      <td>-0.039530</td>
      <td>-0.282380</td>
      <td>-0.800653</td>
      <td>-0.019308</td>
      <td>-0.381456</td>
      <td>-0.110669</td>
      <td>0.661197</td>
      <td>0.117938</td>
      <td>0.110049</td>
      <td>-0.237778</td>
      <td>0.431002</td>
      <td>-0.412492</td>
      <td>-0.310652</td>
      <td>0.548916</td>
      <td>0.465527</td>
      <td>0.940619</td>
      <td>1.746217</td>
      <td>1.210048</td>
      <td>0.424040</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-0.345260</td>
      <td>0.582935</td>
      <td>1.002409</td>
      <td>-0.283715</td>
      <td>-0.428161</td>
      <td>0.240830</td>
      <td>0.581451</td>
      <td>-0.226238</td>
      <td>-0.605962</td>
      <td>0.566480</td>
      <td>-0.608438</td>
      <td>0.065064</td>
      <td>0.275345</td>
      <td>-1.508208</td>
      <td>-0.009655</td>
      <td>0.276236</td>
      <td>-0.375929</td>
      <td>-0.054924</td>
      <td>-0.353751</td>
      <td>-1.399490</td>
      <td>-0.126508</td>
      <td>-0.615892</td>
      <td>0.326269</td>
      <td>-0.161410</td>
      <td>-0.930874</td>
      <td>-0.162836</td>
      <td>-0.362209</td>
      <td>-1.264546</td>
      <td>0.540922</td>
      <td>-1.094093</td>
      <td>-0.491103</td>
      <td>-0.067366</td>
      <td>-0.451728</td>
      <td>0.869058</td>
      <td>0.384535</td>
      <td>-0.691811</td>
      <td>0.229931</td>
      <td>0.183866</td>
      <td>-0.258224</td>
      <td>0.109694</td>
      <td>...</td>
      <td>0.313937</td>
      <td>0.163582</td>
      <td>-0.645582</td>
      <td>0.290003</td>
      <td>0.323855</td>
      <td>-0.167239</td>
      <td>0.687310</td>
      <td>-0.356000</td>
      <td>0.128346</td>
      <td>0.110409</td>
      <td>0.127268</td>
      <td>0.078711</td>
      <td>0.493202</td>
      <td>1.443107</td>
      <td>1.150368</td>
      <td>-0.149997</td>
      <td>-0.264780</td>
      <td>-0.074676</td>
      <td>0.358069</td>
      <td>0.416146</td>
      <td>-0.634763</td>
      <td>-0.025411</td>
      <td>-0.429388</td>
      <td>-0.553421</td>
      <td>0.296020</td>
      <td>0.465481</td>
      <td>0.310484</td>
      <td>-0.150470</td>
      <td>-0.146102</td>
      <td>0.342272</td>
      <td>0.724583</td>
      <td>0.431555</td>
      <td>-0.137842</td>
      <td>-0.033642</td>
      <td>0.617282</td>
      <td>-0.458145</td>
      <td>-0.258747</td>
      <td>1.182470</td>
      <td>0.632866</td>
      <td>-0.275574</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.417701</td>
      <td>0.193378</td>
      <td>0.028413</td>
      <td>0.415853</td>
      <td>-0.034782</td>
      <td>0.368597</td>
      <td>0.173735</td>
      <td>0.102123</td>
      <td>-0.260721</td>
      <td>0.634152</td>
      <td>-1.349947</td>
      <td>0.076535</td>
      <td>1.147180</td>
      <td>1.213404</td>
      <td>0.494202</td>
      <td>0.809967</td>
      <td>0.495196</td>
      <td>0.835316</td>
      <td>0.915688</td>
      <td>0.321192</td>
      <td>-0.373743</td>
      <td>-1.489072</td>
      <td>-0.699649</td>
      <td>-0.540119</td>
      <td>-0.952052</td>
      <td>0.478365</td>
      <td>0.327755</td>
      <td>-0.100903</td>
      <td>0.377908</td>
      <td>-0.321384</td>
      <td>0.753375</td>
      <td>-0.106403</td>
      <td>0.853760</td>
      <td>-0.203827</td>
      <td>-0.645445</td>
      <td>-0.292488</td>
      <td>-0.582006</td>
      <td>-0.458762</td>
      <td>-0.785512</td>
      <td>-0.748899</td>
      <td>...</td>
      <td>-0.598495</td>
      <td>-0.048971</td>
      <td>-0.373823</td>
      <td>0.048297</td>
      <td>-0.269007</td>
      <td>0.056682</td>
      <td>0.041227</td>
      <td>0.944324</td>
      <td>1.002014</td>
      <td>-0.265052</td>
      <td>0.047475</td>
      <td>0.167249</td>
      <td>0.152089</td>
      <td>0.404792</td>
      <td>-0.726719</td>
      <td>-0.471380</td>
      <td>-0.652222</td>
      <td>-0.024834</td>
      <td>0.003486</td>
      <td>-0.472817</td>
      <td>0.406911</td>
      <td>1.002699</td>
      <td>-0.062444</td>
      <td>-0.764387</td>
      <td>-0.482748</td>
      <td>-0.404973</td>
      <td>-0.425932</td>
      <td>0.394013</td>
      <td>0.207079</td>
      <td>1.079252</td>
      <td>0.459034</td>
      <td>0.067171</td>
      <td>-0.231757</td>
      <td>0.454336</td>
      <td>0.463791</td>
      <td>0.097495</td>
      <td>0.731161</td>
      <td>2.427304</td>
      <td>1.531367</td>
      <td>0.682795</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.263029</td>
      <td>-0.087646</td>
      <td>0.239164</td>
      <td>0.355554</td>
      <td>-0.067311</td>
      <td>0.321835</td>
      <td>0.939622</td>
      <td>0.859965</td>
      <td>0.322352</td>
      <td>0.809748</td>
      <td>0.504067</td>
      <td>0.886700</td>
      <td>-0.190631</td>
      <td>0.751343</td>
      <td>1.403358</td>
      <td>-0.210673</td>
      <td>-0.682085</td>
      <td>0.294117</td>
      <td>0.681105</td>
      <td>-0.439129</td>
      <td>-0.873458</td>
      <td>0.367060</td>
      <td>0.464820</td>
      <td>1.222558</td>
      <td>-0.576525</td>
      <td>-1.044345</td>
      <td>-0.053918</td>
      <td>0.321969</td>
      <td>0.308946</td>
      <td>0.059308</td>
      <td>-0.322695</td>
      <td>-1.368146</td>
      <td>-1.024215</td>
      <td>-0.441396</td>
      <td>0.449022</td>
      <td>0.003429</td>
      <td>0.772952</td>
      <td>0.445489</td>
      <td>-0.768929</td>
      <td>-1.726021</td>
      <td>...</td>
      <td>-0.650355</td>
      <td>0.205435</td>
      <td>-1.206321</td>
      <td>-0.249129</td>
      <td>-0.043154</td>
      <td>0.638682</td>
      <td>0.703856</td>
      <td>-0.459089</td>
      <td>0.041068</td>
      <td>-0.910347</td>
      <td>-0.617578</td>
      <td>1.204719</td>
      <td>1.090480</td>
      <td>0.877204</td>
      <td>0.457773</td>
      <td>0.402430</td>
      <td>-0.167184</td>
      <td>-0.327595</td>
      <td>-0.755584</td>
      <td>-1.138006</td>
      <td>0.161103</td>
      <td>0.238280</td>
      <td>-1.028471</td>
      <td>-0.640389</td>
      <td>-0.533910</td>
      <td>-1.048126</td>
      <td>-0.673135</td>
      <td>0.184217</td>
      <td>0.523099</td>
      <td>0.851411</td>
      <td>0.681028</td>
      <td>1.348202</td>
      <td>0.624043</td>
      <td>0.688182</td>
      <td>0.742912</td>
      <td>-0.588010</td>
      <td>-0.466700</td>
      <td>-0.432173</td>
      <td>0.215697</td>
      <td>-0.240209</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.628631</td>
      <td>0.551291</td>
      <td>-0.988314</td>
      <td>-0.991547</td>
      <td>-0.223050</td>
      <td>-0.009896</td>
      <td>0.384208</td>
      <td>0.988028</td>
      <td>1.061481</td>
      <td>0.925005</td>
      <td>1.074446</td>
      <td>0.244874</td>
      <td>0.188014</td>
      <td>-0.704383</td>
      <td>0.349563</td>
      <td>-0.460266</td>
      <td>-0.112445</td>
      <td>0.683827</td>
      <td>-0.603702</td>
      <td>-1.464709</td>
      <td>-0.479411</td>
      <td>-0.735101</td>
      <td>-0.879836</td>
      <td>0.450121</td>
      <td>-0.126969</td>
      <td>-0.570319</td>
      <td>-0.627101</td>
      <td>0.007122</td>
      <td>-0.043037</td>
      <td>-0.431474</td>
      <td>-1.230634</td>
      <td>-0.646007</td>
      <td>-0.555212</td>
      <td>0.330422</td>
      <td>0.282330</td>
      <td>-0.617530</td>
      <td>-0.558041</td>
      <td>0.212974</td>
      <td>-1.554902</td>
      <td>-0.375255</td>
      <td>...</td>
      <td>-0.106180</td>
      <td>0.274037</td>
      <td>-0.061202</td>
      <td>0.810958</td>
      <td>0.435880</td>
      <td>-0.025791</td>
      <td>0.870732</td>
      <td>0.361423</td>
      <td>1.172500</td>
      <td>0.346116</td>
      <td>-1.083641</td>
      <td>-0.635079</td>
      <td>0.479929</td>
      <td>0.790985</td>
      <td>-0.063705</td>
      <td>-0.061181</td>
      <td>0.620006</td>
      <td>-0.406754</td>
      <td>-0.367604</td>
      <td>-0.044585</td>
      <td>1.173896</td>
      <td>0.574181</td>
      <td>0.003005</td>
      <td>-0.577690</td>
      <td>1.135504</td>
      <td>0.420261</td>
      <td>0.177907</td>
      <td>0.337191</td>
      <td>0.587726</td>
      <td>-0.247440</td>
      <td>-0.547633</td>
      <td>-0.027847</td>
      <td>1.535721</td>
      <td>-0.308477</td>
      <td>0.627568</td>
      <td>0.154592</td>
      <td>-0.206815</td>
      <td>1.683850</td>
      <td>0.869907</td>
      <td>-0.761376</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.200337</td>
      <td>0.084508</td>
      <td>0.817194</td>
      <td>0.204665</td>
      <td>-0.374150</td>
      <td>-0.661484</td>
      <td>-0.318067</td>
      <td>0.857353</td>
      <td>-1.600146</td>
      <td>-0.670410</td>
      <td>0.192970</td>
      <td>0.097313</td>
      <td>0.409437</td>
      <td>0.113149</td>
      <td>0.305700</td>
      <td>0.394086</td>
      <td>1.115909</td>
      <td>0.735514</td>
      <td>0.188083</td>
      <td>-0.423065</td>
      <td>0.390066</td>
      <td>0.254809</td>
      <td>0.248598</td>
      <td>0.998293</td>
      <td>-0.193450</td>
      <td>-0.457442</td>
      <td>-0.667939</td>
      <td>0.757653</td>
      <td>1.290687</td>
      <td>-0.055175</td>
      <td>-0.171936</td>
      <td>-0.713891</td>
      <td>-0.555009</td>
      <td>0.822247</td>
      <td>0.005238</td>
      <td>0.006923</td>
      <td>-0.118488</td>
      <td>-0.756208</td>
      <td>-1.168383</td>
      <td>-1.211524</td>
      <td>...</td>
      <td>0.915434</td>
      <td>-0.515701</td>
      <td>-0.010763</td>
      <td>0.283015</td>
      <td>0.322882</td>
      <td>0.055991</td>
      <td>0.138722</td>
      <td>1.353528</td>
      <td>-0.123191</td>
      <td>-0.808783</td>
      <td>-0.871974</td>
      <td>0.414391</td>
      <td>0.864980</td>
      <td>1.345500</td>
      <td>0.321431</td>
      <td>-0.550843</td>
      <td>-0.011287</td>
      <td>-0.491437</td>
      <td>0.314756</td>
      <td>0.763128</td>
      <td>0.787775</td>
      <td>0.656379</td>
      <td>-0.015447</td>
      <td>0.821996</td>
      <td>0.457954</td>
      <td>0.369769</td>
      <td>-0.179100</td>
      <td>0.950908</td>
      <td>0.212226</td>
      <td>0.072390</td>
      <td>-0.554661</td>
      <td>0.810602</td>
      <td>1.289023</td>
      <td>0.570999</td>
      <td>0.283178</td>
      <td>0.243326</td>
      <td>-0.164606</td>
      <td>-0.059480</td>
      <td>-0.786850</td>
      <td>-1.175583</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.055166</td>
      <td>0.213120</td>
      <td>-1.168119</td>
      <td>-0.509254</td>
      <td>0.600189</td>
      <td>0.464371</td>
      <td>0.910130</td>
      <td>0.945505</td>
      <td>0.418131</td>
      <td>0.754784</td>
      <td>-0.001414</td>
      <td>-0.245486</td>
      <td>-0.477053</td>
      <td>0.230634</td>
      <td>-0.508108</td>
      <td>-0.300917</td>
      <td>-0.160170</td>
      <td>0.372083</td>
      <td>0.841663</td>
      <td>-0.359075</td>
      <td>0.065635</td>
      <td>0.270526</td>
      <td>0.127654</td>
      <td>0.030525</td>
      <td>-1.140385</td>
      <td>0.260885</td>
      <td>0.199934</td>
      <td>-1.461039</td>
      <td>0.560377</td>
      <td>0.029201</td>
      <td>0.219485</td>
      <td>-0.171675</td>
      <td>-0.563421</td>
      <td>0.865447</td>
      <td>0.144781</td>
      <td>-0.945017</td>
      <td>0.824746</td>
      <td>0.149473</td>
      <td>-0.649301</td>
      <td>-1.216296</td>
      <td>...</td>
      <td>-0.217955</td>
      <td>-0.213690</td>
      <td>0.286030</td>
      <td>0.720623</td>
      <td>0.289135</td>
      <td>-1.208349</td>
      <td>-0.320400</td>
      <td>-0.223965</td>
      <td>-1.221181</td>
      <td>-0.122016</td>
      <td>-0.136626</td>
      <td>-1.007228</td>
      <td>0.484671</td>
      <td>-0.081249</td>
      <td>-0.173952</td>
      <td>0.820487</td>
      <td>0.264390</td>
      <td>-0.498864</td>
      <td>-0.451271</td>
      <td>-0.378130</td>
      <td>-0.141344</td>
      <td>0.945477</td>
      <td>-0.286677</td>
      <td>-0.731944</td>
      <td>-0.482351</td>
      <td>-0.022570</td>
      <td>-0.294539</td>
      <td>0.619746</td>
      <td>-0.155487</td>
      <td>-0.690215</td>
      <td>0.519179</td>
      <td>-0.245383</td>
      <td>0.921858</td>
      <td>0.928509</td>
      <td>1.008765</td>
      <td>-0.054510</td>
      <td>-0.140182</td>
      <td>0.193497</td>
      <td>-0.020317</td>
      <td>-1.099412</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.634288</td>
      <td>0.103823</td>
      <td>-0.173464</td>
      <td>0.323055</td>
      <td>0.496546</td>
      <td>-0.247596</td>
      <td>-0.136803</td>
      <td>1.002654</td>
      <td>0.242179</td>
      <td>0.624278</td>
      <td>1.211370</td>
      <td>0.577407</td>
      <td>-0.307365</td>
      <td>1.448867</td>
      <td>0.279770</td>
      <td>-0.545856</td>
      <td>0.068786</td>
      <td>0.302404</td>
      <td>0.549464</td>
      <td>0.625694</td>
      <td>-0.828126</td>
      <td>-1.378107</td>
      <td>-1.545497</td>
      <td>-1.002649</td>
      <td>-0.560031</td>
      <td>-0.434777</td>
      <td>-1.503016</td>
      <td>0.498607</td>
      <td>0.445969</td>
      <td>0.014554</td>
      <td>0.402064</td>
      <td>0.190200</td>
      <td>0.122601</td>
      <td>0.418636</td>
      <td>0.516458</td>
      <td>-0.453900</td>
      <td>0.723566</td>
      <td>0.645747</td>
      <td>-0.772721</td>
      <td>-0.202359</td>
      <td>...</td>
      <td>-0.468661</td>
      <td>-0.676852</td>
      <td>-0.043632</td>
      <td>0.702364</td>
      <td>0.263498</td>
      <td>-0.243958</td>
      <td>0.232769</td>
      <td>0.952681</td>
      <td>0.237904</td>
      <td>-0.454706</td>
      <td>-0.770961</td>
      <td>0.147291</td>
      <td>0.463951</td>
      <td>-0.127521</td>
      <td>-0.074389</td>
      <td>0.234753</td>
      <td>-0.561386</td>
      <td>0.221972</td>
      <td>0.513001</td>
      <td>0.078484</td>
      <td>1.013996</td>
      <td>-0.110493</td>
      <td>-0.078177</td>
      <td>-0.539656</td>
      <td>-0.406152</td>
      <td>0.139897</td>
      <td>-0.032903</td>
      <td>-0.049144</td>
      <td>-0.153823</td>
      <td>-0.183114</td>
      <td>-0.873893</td>
      <td>0.099069</td>
      <td>0.215423</td>
      <td>-0.153173</td>
      <td>0.413338</td>
      <td>-0.307914</td>
      <td>0.781701</td>
      <td>2.171851</td>
      <td>0.856292</td>
      <td>0.555418</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.650088</td>
      <td>-0.466248</td>
      <td>-1.206242</td>
      <td>-0.860840</td>
      <td>-0.274886</td>
      <td>-0.018924</td>
      <td>0.519587</td>
      <td>0.168128</td>
      <td>-0.231699</td>
      <td>-0.004420</td>
      <td>0.197070</td>
      <td>0.235722</td>
      <td>-0.649090</td>
      <td>-0.731311</td>
      <td>-0.925726</td>
      <td>0.739101</td>
      <td>-0.041087</td>
      <td>0.295694</td>
      <td>0.212967</td>
      <td>-0.429522</td>
      <td>-0.010454</td>
      <td>0.477715</td>
      <td>0.026747</td>
      <td>0.681286</td>
      <td>-0.379134</td>
      <td>-1.185073</td>
      <td>-0.299346</td>
      <td>-0.924899</td>
      <td>-0.412387</td>
      <td>-0.132649</td>
      <td>-0.257815</td>
      <td>-0.248314</td>
      <td>-0.858899</td>
      <td>0.737642</td>
      <td>0.894574</td>
      <td>0.037075</td>
      <td>0.109208</td>
      <td>-0.163458</td>
      <td>-0.332826</td>
      <td>-1.023430</td>
      <td>...</td>
      <td>-0.558120</td>
      <td>-0.586372</td>
      <td>-0.750168</td>
      <td>-0.180565</td>
      <td>-0.495097</td>
      <td>-0.345201</td>
      <td>-0.556726</td>
      <td>0.582565</td>
      <td>0.356133</td>
      <td>-0.634269</td>
      <td>0.576376</td>
      <td>0.939414</td>
      <td>0.587090</td>
      <td>-0.017025</td>
      <td>-0.512979</td>
      <td>-0.475401</td>
      <td>-0.454208</td>
      <td>-0.141155</td>
      <td>-0.795302</td>
      <td>-0.376676</td>
      <td>0.054729</td>
      <td>-0.887885</td>
      <td>0.481942</td>
      <td>0.667451</td>
      <td>0.700134</td>
      <td>0.562887</td>
      <td>-0.774893</td>
      <td>0.478754</td>
      <td>0.667404</td>
      <td>0.185778</td>
      <td>0.464346</td>
      <td>1.013279</td>
      <td>-0.130799</td>
      <td>-0.831915</td>
      <td>-0.089307</td>
      <td>-0.687970</td>
      <td>-0.096305</td>
      <td>1.750009</td>
      <td>0.652195</td>
      <td>-0.183701</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-0.232744</td>
      <td>-0.010380</td>
      <td>0.470678</td>
      <td>-0.426268</td>
      <td>-1.249951</td>
      <td>-0.417223</td>
      <td>-0.029895</td>
      <td>0.581606</td>
      <td>-0.044233</td>
      <td>0.811637</td>
      <td>-0.151836</td>
      <td>-0.185357</td>
      <td>-0.094285</td>
      <td>-0.311608</td>
      <td>-0.135329</td>
      <td>-0.047204</td>
      <td>0.973621</td>
      <td>0.421064</td>
      <td>-0.280203</td>
      <td>-0.668008</td>
      <td>0.465276</td>
      <td>0.094624</td>
      <td>-0.046261</td>
      <td>-0.585183</td>
      <td>-0.524313</td>
      <td>0.092996</td>
      <td>-0.387815</td>
      <td>1.143708</td>
      <td>0.537057</td>
      <td>-0.410849</td>
      <td>-0.147356</td>
      <td>0.316241</td>
      <td>-0.349665</td>
      <td>0.097632</td>
      <td>0.008539</td>
      <td>-0.565001</td>
      <td>-0.725691</td>
      <td>-0.139284</td>
      <td>-0.468298</td>
      <td>-0.529531</td>
      <td>...</td>
      <td>-0.426690</td>
      <td>0.003121</td>
      <td>0.981065</td>
      <td>0.638353</td>
      <td>0.513763</td>
      <td>-0.352723</td>
      <td>-1.096719</td>
      <td>0.209617</td>
      <td>1.388620</td>
      <td>0.478623</td>
      <td>-0.239536</td>
      <td>0.330600</td>
      <td>0.868249</td>
      <td>0.247417</td>
      <td>0.551869</td>
      <td>0.281590</td>
      <td>-0.664878</td>
      <td>0.298289</td>
      <td>-0.510701</td>
      <td>-0.305608</td>
      <td>-0.119795</td>
      <td>0.086125</td>
      <td>0.592551</td>
      <td>0.150597</td>
      <td>0.267003</td>
      <td>-0.227033</td>
      <td>0.330218</td>
      <td>-0.168154</td>
      <td>-0.544578</td>
      <td>-0.683214</td>
      <td>-0.098692</td>
      <td>0.304197</td>
      <td>0.066821</td>
      <td>-0.379851</td>
      <td>-0.192391</td>
      <td>-0.615839</td>
      <td>-1.043614</td>
      <td>-0.299884</td>
      <td>0.078896</td>
      <td>-0.430272</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.192810</td>
      <td>-0.248168</td>
      <td>-0.970458</td>
      <td>-0.031936</td>
      <td>-0.544943</td>
      <td>-1.404378</td>
      <td>-0.079813</td>
      <td>0.130816</td>
      <td>-0.179834</td>
      <td>-0.456988</td>
      <td>-1.597401</td>
      <td>-0.191681</td>
      <td>-0.606969</td>
      <td>-1.183068</td>
      <td>0.669000</td>
      <td>-0.005980</td>
      <td>0.276012</td>
      <td>-0.008364</td>
      <td>0.561378</td>
      <td>0.070711</td>
      <td>0.457869</td>
      <td>-0.147996</td>
      <td>-0.316595</td>
      <td>-0.193427</td>
      <td>0.866127</td>
      <td>0.104974</td>
      <td>1.212941</td>
      <td>0.113020</td>
      <td>-0.119713</td>
      <td>-0.060250</td>
      <td>-0.493614</td>
      <td>-0.277693</td>
      <td>0.611574</td>
      <td>-0.946996</td>
      <td>0.380173</td>
      <td>0.307845</td>
      <td>0.507510</td>
      <td>0.203659</td>
      <td>0.023715</td>
      <td>0.640524</td>
      <td>...</td>
      <td>-0.090849</td>
      <td>0.690074</td>
      <td>0.433476</td>
      <td>1.284402</td>
      <td>0.143069</td>
      <td>1.492315</td>
      <td>-0.516828</td>
      <td>-1.145995</td>
      <td>-0.144489</td>
      <td>0.386343</td>
      <td>1.326920</td>
      <td>-0.407770</td>
      <td>0.012972</td>
      <td>-0.145218</td>
      <td>-0.254270</td>
      <td>0.569884</td>
      <td>-0.225306</td>
      <td>0.004726</td>
      <td>-0.294382</td>
      <td>-0.307442</td>
      <td>-0.374957</td>
      <td>0.378452</td>
      <td>0.529279</td>
      <td>-0.072880</td>
      <td>0.177391</td>
      <td>-0.358814</td>
      <td>-0.410894</td>
      <td>0.110451</td>
      <td>0.276188</td>
      <td>-1.087248</td>
      <td>-0.784987</td>
      <td>-0.441150</td>
      <td>-0.739561</td>
      <td>-0.571490</td>
      <td>-0.447689</td>
      <td>0.308358</td>
      <td>0.367779</td>
      <td>-0.993759</td>
      <td>-1.108636</td>
      <td>-0.171831</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.058744</td>
      <td>0.617722</td>
      <td>-0.098201</td>
      <td>-0.246320</td>
      <td>0.054437</td>
      <td>0.048258</td>
      <td>-0.720206</td>
      <td>-0.152275</td>
      <td>0.074517</td>
      <td>1.679911</td>
      <td>0.126331</td>
      <td>-0.704972</td>
      <td>-0.363102</td>
      <td>-0.608128</td>
      <td>0.338001</td>
      <td>-0.091277</td>
      <td>0.304230</td>
      <td>0.375434</td>
      <td>0.227686</td>
      <td>-0.231326</td>
      <td>0.004417</td>
      <td>0.393490</td>
      <td>-0.277409</td>
      <td>-0.672785</td>
      <td>-0.902700</td>
      <td>-0.339181</td>
      <td>0.397200</td>
      <td>-0.161836</td>
      <td>-0.856430</td>
      <td>-0.623874</td>
      <td>0.602213</td>
      <td>0.416146</td>
      <td>-0.070682</td>
      <td>-0.373482</td>
      <td>0.034123</td>
      <td>0.395317</td>
      <td>0.527612</td>
      <td>0.858666</td>
      <td>-0.407004</td>
      <td>0.781030</td>
      <td>...</td>
      <td>0.643454</td>
      <td>-0.279344</td>
      <td>0.576363</td>
      <td>0.374341</td>
      <td>0.367444</td>
      <td>-0.458172</td>
      <td>-0.058864</td>
      <td>0.943464</td>
      <td>-0.454931</td>
      <td>-0.448863</td>
      <td>-0.518775</td>
      <td>-0.457373</td>
      <td>0.466025</td>
      <td>0.590270</td>
      <td>-0.455456</td>
      <td>0.701912</td>
      <td>0.396751</td>
      <td>0.178883</td>
      <td>0.863960</td>
      <td>0.514876</td>
      <td>-1.475978</td>
      <td>-1.037637</td>
      <td>-0.228555</td>
      <td>-0.352461</td>
      <td>0.187019</td>
      <td>0.364597</td>
      <td>0.595138</td>
      <td>-0.054798</td>
      <td>0.480908</td>
      <td>-0.925028</td>
      <td>-0.687673</td>
      <td>-0.610093</td>
      <td>0.102190</td>
      <td>-0.923810</td>
      <td>-1.126565</td>
      <td>0.031492</td>
      <td>0.130297</td>
      <td>2.774112</td>
      <td>1.566416</td>
      <td>1.017338</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.099280</td>
      <td>-0.385076</td>
      <td>0.076052</td>
      <td>0.676394</td>
      <td>-0.039864</td>
      <td>-1.109544</td>
      <td>0.356892</td>
      <td>-0.050819</td>
      <td>-0.293535</td>
      <td>-0.103004</td>
      <td>-0.359874</td>
      <td>-0.109858</td>
      <td>-0.441829</td>
      <td>-0.565314</td>
      <td>1.348369</td>
      <td>1.012003</td>
      <td>0.283004</td>
      <td>0.709794</td>
      <td>-0.017327</td>
      <td>-0.318244</td>
      <td>0.159395</td>
      <td>0.225454</td>
      <td>-0.244698</td>
      <td>0.005171</td>
      <td>-0.342033</td>
      <td>1.069314</td>
      <td>1.515161</td>
      <td>-0.691239</td>
      <td>-1.055573</td>
      <td>0.540321</td>
      <td>-0.353786</td>
      <td>0.056883</td>
      <td>0.792112</td>
      <td>-0.237918</td>
      <td>0.510120</td>
      <td>-0.038878</td>
      <td>-0.378659</td>
      <td>0.934027</td>
      <td>0.310773</td>
      <td>0.350346</td>
      <td>...</td>
      <td>0.496791</td>
      <td>0.439261</td>
      <td>-0.437845</td>
      <td>0.462757</td>
      <td>-0.414635</td>
      <td>0.386294</td>
      <td>0.579345</td>
      <td>0.310459</td>
      <td>0.412672</td>
      <td>0.251649</td>
      <td>-0.247800</td>
      <td>-0.841123</td>
      <td>-0.290025</td>
      <td>-0.940080</td>
      <td>-0.170304</td>
      <td>0.623273</td>
      <td>1.286359</td>
      <td>0.635354</td>
      <td>0.340870</td>
      <td>0.353237</td>
      <td>-0.473023</td>
      <td>-0.299044</td>
      <td>-0.368058</td>
      <td>0.204876</td>
      <td>0.006192</td>
      <td>0.615684</td>
      <td>-0.271185</td>
      <td>0.035346</td>
      <td>-0.262480</td>
      <td>-0.966410</td>
      <td>-0.343077</td>
      <td>0.622522</td>
      <td>-0.487162</td>
      <td>-0.741940</td>
      <td>-0.801216</td>
      <td>-0.562535</td>
      <td>0.051886</td>
      <td>-1.113813</td>
      <td>-1.318134</td>
      <td>-1.358611</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.041850</td>
      <td>-0.753987</td>
      <td>-0.731803</td>
      <td>-0.857418</td>
      <td>-0.399570</td>
      <td>-1.393449</td>
      <td>-0.121547</td>
      <td>-0.044721</td>
      <td>0.337840</td>
      <td>0.329967</td>
      <td>-0.572357</td>
      <td>0.036862</td>
      <td>-0.346842</td>
      <td>0.221812</td>
      <td>0.833374</td>
      <td>-0.206852</td>
      <td>-0.121489</td>
      <td>0.627642</td>
      <td>0.523870</td>
      <td>-0.400799</td>
      <td>0.328514</td>
      <td>0.690873</td>
      <td>1.403096</td>
      <td>0.706185</td>
      <td>0.078966</td>
      <td>-0.153726</td>
      <td>-0.341149</td>
      <td>-0.173996</td>
      <td>0.238874</td>
      <td>-1.002171</td>
      <td>-0.194946</td>
      <td>-0.580774</td>
      <td>-0.227449</td>
      <td>-0.507590</td>
      <td>0.340928</td>
      <td>0.042619</td>
      <td>0.166168</td>
      <td>0.254522</td>
      <td>1.070360</td>
      <td>0.674454</td>
      <td>...</td>
      <td>0.460163</td>
      <td>0.083048</td>
      <td>0.189457</td>
      <td>-0.386936</td>
      <td>0.019173</td>
      <td>0.746033</td>
      <td>-0.118961</td>
      <td>-0.197253</td>
      <td>-0.087957</td>
      <td>-0.552914</td>
      <td>-0.170461</td>
      <td>-0.569053</td>
      <td>0.130148</td>
      <td>-0.747584</td>
      <td>0.905553</td>
      <td>0.543116</td>
      <td>0.176802</td>
      <td>0.230964</td>
      <td>-0.628681</td>
      <td>0.339192</td>
      <td>-0.358032</td>
      <td>-1.089572</td>
      <td>0.567248</td>
      <td>0.148469</td>
      <td>0.076954</td>
      <td>1.330375</td>
      <td>1.672765</td>
      <td>0.248932</td>
      <td>0.256116</td>
      <td>-1.093500</td>
      <td>-0.255623</td>
      <td>-0.505825</td>
      <td>0.255887</td>
      <td>0.007434</td>
      <td>0.005158</td>
      <td>0.321040</td>
      <td>-0.182821</td>
      <td>-1.846861</td>
      <td>-1.582740</td>
      <td>-0.893423</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.133776</td>
      <td>0.923515</td>
      <td>0.302138</td>
      <td>-1.166633</td>
      <td>-2.198499</td>
      <td>-1.769843</td>
      <td>0.484131</td>
      <td>0.397806</td>
      <td>-0.206020</td>
      <td>-0.083508</td>
      <td>-1.039632</td>
      <td>0.455047</td>
      <td>-0.522900</td>
      <td>-0.583143</td>
      <td>-0.394610</td>
      <td>0.110883</td>
      <td>0.294983</td>
      <td>-0.635985</td>
      <td>-0.251611</td>
      <td>-0.234824</td>
      <td>-0.334848</td>
      <td>0.940192</td>
      <td>0.665881</td>
      <td>-0.286424</td>
      <td>-0.737568</td>
      <td>-0.482764</td>
      <td>0.325758</td>
      <td>0.220635</td>
      <td>-0.254780</td>
      <td>0.613601</td>
      <td>0.870807</td>
      <td>0.336138</td>
      <td>-0.148329</td>
      <td>0.026466</td>
      <td>0.233934</td>
      <td>-1.240799</td>
      <td>-0.751623</td>
      <td>0.649429</td>
      <td>1.124723</td>
      <td>1.235274</td>
      <td>...</td>
      <td>-0.692636</td>
      <td>0.241819</td>
      <td>0.065130</td>
      <td>-0.029634</td>
      <td>0.472120</td>
      <td>0.611284</td>
      <td>0.769945</td>
      <td>0.949507</td>
      <td>1.644123</td>
      <td>0.023070</td>
      <td>-0.697471</td>
      <td>0.045625</td>
      <td>-0.220736</td>
      <td>0.429032</td>
      <td>-0.572388</td>
      <td>0.004768</td>
      <td>-0.469759</td>
      <td>-1.241997</td>
      <td>-0.598188</td>
      <td>-0.556460</td>
      <td>-1.208220</td>
      <td>-1.021019</td>
      <td>-0.942171</td>
      <td>0.232593</td>
      <td>0.048680</td>
      <td>0.439489</td>
      <td>0.041213</td>
      <td>-0.215466</td>
      <td>0.416467</td>
      <td>-0.807272</td>
      <td>0.200348</td>
      <td>0.455365</td>
      <td>0.302396</td>
      <td>-0.336476</td>
      <td>0.272950</td>
      <td>-1.283214</td>
      <td>-1.049150</td>
      <td>1.984379</td>
      <td>1.148263</td>
      <td>-0.098777</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7ff391744310&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.072387  0.041364  25.925557  3.430935e-148  0.991315  1.153459
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  5.336 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.4.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>