
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.0.1 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="http://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>     to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>1.242195</td>
      <td>-0.796409</td>
      <td>-0.700675</td>
      <td>0.358602</td>
      <td>0.034630</td>
      <td>-0.475019</td>
      <td>-0.758457</td>
      <td>-1.838686</td>
      <td>0.138870</td>
      <td>-1.039370</td>
      <td>-1.190047</td>
      <td>-0.877118</td>
      <td>-0.585710</td>
      <td>-0.217343</td>
      <td>-0.034724</td>
      <td>0.986913</td>
      <td>0.909785</td>
      <td>-0.655876</td>
      <td>-0.272945</td>
      <td>-0.436554</td>
      <td>-0.274036</td>
      <td>-0.014417</td>
      <td>0.048958</td>
      <td>-0.025034</td>
      <td>0.569560</td>
      <td>0.265006</td>
      <td>0.924549</td>
      <td>0.339476</td>
      <td>-0.505698</td>
      <td>0.087221</td>
      <td>-0.666349</td>
      <td>0.112834</td>
      <td>1.068232</td>
      <td>0.422769</td>
      <td>-1.481776</td>
      <td>0.228407</td>
      <td>-1.275164</td>
      <td>-1.079157</td>
      <td>-0.456035</td>
      <td>0.335134</td>
      <td>...</td>
      <td>-0.088277</td>
      <td>-0.556788</td>
      <td>-0.591107</td>
      <td>-0.044287</td>
      <td>0.847940</td>
      <td>0.592505</td>
      <td>0.935587</td>
      <td>-1.009937</td>
      <td>0.430795</td>
      <td>0.013076</td>
      <td>-0.272014</td>
      <td>-0.026532</td>
      <td>-0.689491</td>
      <td>-1.088976</td>
      <td>0.108046</td>
      <td>0.799457</td>
      <td>-0.779720</td>
      <td>-0.288066</td>
      <td>0.914269</td>
      <td>-0.382381</td>
      <td>-0.809136</td>
      <td>0.264753</td>
      <td>0.049737</td>
      <td>0.356044</td>
      <td>0.309317</td>
      <td>-1.063424</td>
      <td>-0.268316</td>
      <td>0.219746</td>
      <td>-0.300822</td>
      <td>0.043009</td>
      <td>-0.100585</td>
      <td>0.704239</td>
      <td>0.582294</td>
      <td>-0.288988</td>
      <td>0.046353</td>
      <td>0.741218</td>
      <td>-0.112909</td>
      <td>3.074207</td>
      <td>2.033002</td>
      <td>1.304117</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.272614</td>
      <td>-1.121192</td>
      <td>0.041352</td>
      <td>0.723428</td>
      <td>0.425554</td>
      <td>-0.802601</td>
      <td>-1.182074</td>
      <td>0.038257</td>
      <td>0.539544</td>
      <td>0.127425</td>
      <td>-0.044201</td>
      <td>-1.008963</td>
      <td>-0.492227</td>
      <td>0.237530</td>
      <td>0.240711</td>
      <td>0.226520</td>
      <td>-0.255174</td>
      <td>0.185773</td>
      <td>-0.378691</td>
      <td>-0.432089</td>
      <td>-0.665248</td>
      <td>-0.330417</td>
      <td>-0.583404</td>
      <td>-0.079309</td>
      <td>-0.096865</td>
      <td>0.611373</td>
      <td>-0.271276</td>
      <td>1.132146</td>
      <td>-0.049695</td>
      <td>-0.358728</td>
      <td>-0.681117</td>
      <td>0.977665</td>
      <td>0.071003</td>
      <td>1.053855</td>
      <td>-1.114809</td>
      <td>-0.628198</td>
      <td>-1.477073</td>
      <td>-0.390866</td>
      <td>-0.061612</td>
      <td>-0.091822</td>
      <td>...</td>
      <td>-0.677907</td>
      <td>0.010491</td>
      <td>-0.182738</td>
      <td>-0.010780</td>
      <td>1.091078</td>
      <td>-0.177586</td>
      <td>-0.579395</td>
      <td>0.214514</td>
      <td>0.216558</td>
      <td>0.236913</td>
      <td>-1.134609</td>
      <td>-0.691867</td>
      <td>-0.821796</td>
      <td>-1.111711</td>
      <td>0.076168</td>
      <td>0.764850</td>
      <td>1.246373</td>
      <td>-0.262393</td>
      <td>-0.227466</td>
      <td>-0.551058</td>
      <td>0.721718</td>
      <td>0.398565</td>
      <td>0.419785</td>
      <td>0.271081</td>
      <td>0.160049</td>
      <td>-0.696918</td>
      <td>0.185102</td>
      <td>0.110306</td>
      <td>0.888710</td>
      <td>-0.068817</td>
      <td>-0.224512</td>
      <td>-0.106608</td>
      <td>-0.697256</td>
      <td>-0.102948</td>
      <td>-1.341019</td>
      <td>0.297239</td>
      <td>-0.319055</td>
      <td>-2.802702</td>
      <td>-2.387539</td>
      <td>-1.079010</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.557040</td>
      <td>0.033498</td>
      <td>0.268652</td>
      <td>-0.192602</td>
      <td>-0.046619</td>
      <td>-0.153654</td>
      <td>-0.150810</td>
      <td>-0.974583</td>
      <td>1.019217</td>
      <td>-0.013851</td>
      <td>-0.505600</td>
      <td>-0.470116</td>
      <td>-1.115133</td>
      <td>-0.623367</td>
      <td>-0.483016</td>
      <td>-0.313494</td>
      <td>0.582912</td>
      <td>0.405737</td>
      <td>0.454380</td>
      <td>0.573192</td>
      <td>1.105629</td>
      <td>0.019808</td>
      <td>0.689428</td>
      <td>-0.191690</td>
      <td>-0.781101</td>
      <td>1.235561</td>
      <td>-0.549973</td>
      <td>1.091762</td>
      <td>0.086417</td>
      <td>1.298283</td>
      <td>0.974185</td>
      <td>-0.437955</td>
      <td>0.171360</td>
      <td>0.912729</td>
      <td>-0.501317</td>
      <td>0.024278</td>
      <td>-0.378581</td>
      <td>0.149218</td>
      <td>0.568396</td>
      <td>-0.022513</td>
      <td>...</td>
      <td>-1.471613</td>
      <td>-0.800585</td>
      <td>-0.415240</td>
      <td>-0.069810</td>
      <td>1.131675</td>
      <td>0.999521</td>
      <td>0.428150</td>
      <td>1.204634</td>
      <td>0.230976</td>
      <td>-0.009861</td>
      <td>-0.705690</td>
      <td>0.452307</td>
      <td>0.116154</td>
      <td>-0.998404</td>
      <td>-0.719486</td>
      <td>0.767142</td>
      <td>-1.029591</td>
      <td>0.291789</td>
      <td>0.720111</td>
      <td>0.744599</td>
      <td>-0.094452</td>
      <td>-0.199060</td>
      <td>-0.354152</td>
      <td>0.566986</td>
      <td>0.297032</td>
      <td>-1.029398</td>
      <td>0.679363</td>
      <td>0.307428</td>
      <td>-0.057837</td>
      <td>-0.289565</td>
      <td>0.360210</td>
      <td>-0.703600</td>
      <td>-1.682270</td>
      <td>-1.145468</td>
      <td>0.271837</td>
      <td>0.724834</td>
      <td>-0.079511</td>
      <td>1.207840</td>
      <td>1.739984</td>
      <td>0.757844</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.340083</td>
      <td>-0.975532</td>
      <td>-0.182232</td>
      <td>-0.086217</td>
      <td>-0.169618</td>
      <td>0.684624</td>
      <td>0.148625</td>
      <td>-0.158827</td>
      <td>0.229977</td>
      <td>1.081906</td>
      <td>0.155930</td>
      <td>-0.250257</td>
      <td>-0.424073</td>
      <td>-0.712753</td>
      <td>0.083728</td>
      <td>-0.058235</td>
      <td>-0.154380</td>
      <td>0.546926</td>
      <td>0.881983</td>
      <td>-0.201119</td>
      <td>-0.310849</td>
      <td>0.284690</td>
      <td>-0.673929</td>
      <td>0.016559</td>
      <td>-0.436540</td>
      <td>-0.800607</td>
      <td>0.077443</td>
      <td>0.415712</td>
      <td>-0.189584</td>
      <td>-0.816631</td>
      <td>-0.591815</td>
      <td>-0.197954</td>
      <td>0.007882</td>
      <td>0.899509</td>
      <td>-0.758300</td>
      <td>0.164262</td>
      <td>0.016785</td>
      <td>-0.244116</td>
      <td>0.192284</td>
      <td>0.129391</td>
      <td>...</td>
      <td>0.207182</td>
      <td>0.575252</td>
      <td>-0.535590</td>
      <td>-0.848828</td>
      <td>-0.080626</td>
      <td>-0.287886</td>
      <td>0.252335</td>
      <td>0.146512</td>
      <td>-0.203944</td>
      <td>0.703156</td>
      <td>0.634438</td>
      <td>0.476788</td>
      <td>0.744420</td>
      <td>-0.119987</td>
      <td>0.355824</td>
      <td>0.622885</td>
      <td>0.746067</td>
      <td>-0.845909</td>
      <td>0.269768</td>
      <td>0.279169</td>
      <td>-0.900286</td>
      <td>-0.408694</td>
      <td>-0.433264</td>
      <td>-0.657844</td>
      <td>-0.512830</td>
      <td>-0.930169</td>
      <td>0.199049</td>
      <td>0.211812</td>
      <td>-0.091087</td>
      <td>-0.135152</td>
      <td>-0.133197</td>
      <td>0.220191</td>
      <td>-0.722143</td>
      <td>-0.888347</td>
      <td>-0.230744</td>
      <td>-0.143241</td>
      <td>-1.280726</td>
      <td>-3.656342</td>
      <td>-1.740184</td>
      <td>-0.733733</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.358806</td>
      <td>-0.692557</td>
      <td>-0.808502</td>
      <td>-0.304169</td>
      <td>-0.321828</td>
      <td>0.454864</td>
      <td>-0.615344</td>
      <td>-1.413163</td>
      <td>-0.223550</td>
      <td>0.160378</td>
      <td>0.522859</td>
      <td>-0.846255</td>
      <td>-0.588492</td>
      <td>0.451755</td>
      <td>0.166417</td>
      <td>0.162960</td>
      <td>0.707435</td>
      <td>0.072872</td>
      <td>-0.246840</td>
      <td>-0.034663</td>
      <td>0.094274</td>
      <td>-0.749741</td>
      <td>0.076620</td>
      <td>-0.244819</td>
      <td>0.300299</td>
      <td>0.480001</td>
      <td>-0.395681</td>
      <td>-0.343207</td>
      <td>0.245990</td>
      <td>1.415525</td>
      <td>0.120407</td>
      <td>0.578153</td>
      <td>-0.293813</td>
      <td>-0.249866</td>
      <td>0.330689</td>
      <td>-0.341353</td>
      <td>-0.684691</td>
      <td>-0.302322</td>
      <td>0.793859</td>
      <td>1.309585</td>
      <td>...</td>
      <td>-1.442576</td>
      <td>-0.078444</td>
      <td>-0.017198</td>
      <td>-0.547967</td>
      <td>-0.241717</td>
      <td>-0.157285</td>
      <td>-0.252869</td>
      <td>-0.408942</td>
      <td>-0.154511</td>
      <td>0.525328</td>
      <td>-0.687157</td>
      <td>-0.432931</td>
      <td>-1.213681</td>
      <td>-0.147653</td>
      <td>0.019569</td>
      <td>1.128046</td>
      <td>-0.103941</td>
      <td>0.055735</td>
      <td>-0.081640</td>
      <td>-0.419213</td>
      <td>0.431806</td>
      <td>-0.210644</td>
      <td>-0.931045</td>
      <td>0.300950</td>
      <td>-0.430133</td>
      <td>-0.784686</td>
      <td>0.348551</td>
      <td>0.309181</td>
      <td>0.238447</td>
      <td>-0.188440</td>
      <td>-1.265743</td>
      <td>-0.122467</td>
      <td>0.235658</td>
      <td>0.280006</td>
      <td>-0.395499</td>
      <td>-0.076499</td>
      <td>-0.780784</td>
      <td>0.543307</td>
      <td>0.719283</td>
      <td>0.118877</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.440263</td>
      <td>-0.979386</td>
      <td>-0.273104</td>
      <td>-0.039077</td>
      <td>-0.262857</td>
      <td>-0.905092</td>
      <td>0.828553</td>
      <td>-0.448858</td>
      <td>-0.296501</td>
      <td>-0.416195</td>
      <td>-0.614794</td>
      <td>-0.015300</td>
      <td>-0.124250</td>
      <td>0.307403</td>
      <td>-0.307293</td>
      <td>-0.328539</td>
      <td>-0.342806</td>
      <td>-0.240092</td>
      <td>-0.249383</td>
      <td>0.886791</td>
      <td>0.211839</td>
      <td>0.977526</td>
      <td>1.189580</td>
      <td>-0.050523</td>
      <td>-0.158469</td>
      <td>-0.108564</td>
      <td>0.105143</td>
      <td>0.388326</td>
      <td>-0.624512</td>
      <td>-0.047652</td>
      <td>0.356050</td>
      <td>0.731313</td>
      <td>0.052797</td>
      <td>0.637670</td>
      <td>0.105860</td>
      <td>0.390095</td>
      <td>-0.895414</td>
      <td>-0.676032</td>
      <td>-0.210655</td>
      <td>0.497741</td>
      <td>...</td>
      <td>-0.404451</td>
      <td>-0.063886</td>
      <td>-0.156554</td>
      <td>-1.193730</td>
      <td>0.063860</td>
      <td>0.885011</td>
      <td>0.329930</td>
      <td>0.406317</td>
      <td>-0.599092</td>
      <td>0.431433</td>
      <td>0.001695</td>
      <td>0.495770</td>
      <td>-0.076517</td>
      <td>-0.544482</td>
      <td>-0.260680</td>
      <td>0.989102</td>
      <td>0.654385</td>
      <td>0.107721</td>
      <td>0.523560</td>
      <td>-0.007856</td>
      <td>-0.296473</td>
      <td>-0.685393</td>
      <td>-1.460918</td>
      <td>0.261412</td>
      <td>0.146346</td>
      <td>-0.334978</td>
      <td>1.058090</td>
      <td>0.822594</td>
      <td>-0.441272</td>
      <td>-1.429860</td>
      <td>-1.435705</td>
      <td>-0.783409</td>
      <td>-0.440024</td>
      <td>0.390255</td>
      <td>0.338384</td>
      <td>-0.094031</td>
      <td>-0.754040</td>
      <td>-1.071501</td>
      <td>-0.590544</td>
      <td>-0.603417</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.092250</td>
      <td>-0.141902</td>
      <td>-0.252687</td>
      <td>-0.121801</td>
      <td>-0.234021</td>
      <td>0.341140</td>
      <td>0.315931</td>
      <td>0.063788</td>
      <td>0.477768</td>
      <td>-0.187466</td>
      <td>0.342574</td>
      <td>-0.272548</td>
      <td>-0.165610</td>
      <td>0.620370</td>
      <td>0.185806</td>
      <td>-0.376755</td>
      <td>-0.697756</td>
      <td>0.188417</td>
      <td>-0.120575</td>
      <td>0.378873</td>
      <td>-0.091613</td>
      <td>-0.225361</td>
      <td>0.710713</td>
      <td>0.180416</td>
      <td>-0.150665</td>
      <td>0.337276</td>
      <td>-0.627657</td>
      <td>0.181275</td>
      <td>0.353629</td>
      <td>0.076115</td>
      <td>0.376443</td>
      <td>0.497056</td>
      <td>-0.090955</td>
      <td>0.744280</td>
      <td>-0.208400</td>
      <td>0.295953</td>
      <td>0.349443</td>
      <td>0.440477</td>
      <td>0.473205</td>
      <td>-0.635958</td>
      <td>...</td>
      <td>0.930961</td>
      <td>0.643451</td>
      <td>-0.770599</td>
      <td>-1.187833</td>
      <td>1.318599</td>
      <td>-0.447958</td>
      <td>-0.291793</td>
      <td>0.494449</td>
      <td>-0.561474</td>
      <td>-0.402480</td>
      <td>-0.495274</td>
      <td>-0.059552</td>
      <td>0.975047</td>
      <td>-0.321802</td>
      <td>0.295077</td>
      <td>0.738685</td>
      <td>0.382972</td>
      <td>-0.324716</td>
      <td>-0.045944</td>
      <td>-0.310755</td>
      <td>-1.047335</td>
      <td>-0.672587</td>
      <td>-1.233381</td>
      <td>-0.819188</td>
      <td>0.230245</td>
      <td>-0.171239</td>
      <td>-0.440627</td>
      <td>-0.527027</td>
      <td>0.109144</td>
      <td>1.580042</td>
      <td>0.143559</td>
      <td>0.032797</td>
      <td>-0.158518</td>
      <td>-0.748686</td>
      <td>-0.049040</td>
      <td>0.562588</td>
      <td>0.914812</td>
      <td>-0.966990</td>
      <td>0.196673</td>
      <td>0.254220</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.028222</td>
      <td>-1.081133</td>
      <td>-0.219816</td>
      <td>0.899787</td>
      <td>-0.637331</td>
      <td>0.160239</td>
      <td>0.510981</td>
      <td>-0.476298</td>
      <td>-0.312050</td>
      <td>-0.797428</td>
      <td>-0.876857</td>
      <td>-0.756512</td>
      <td>-0.731489</td>
      <td>-0.428572</td>
      <td>-0.745568</td>
      <td>0.574418</td>
      <td>-0.131682</td>
      <td>0.238955</td>
      <td>1.022932</td>
      <td>0.315304</td>
      <td>-0.198309</td>
      <td>0.373544</td>
      <td>-0.597668</td>
      <td>-0.120614</td>
      <td>0.874538</td>
      <td>-0.320313</td>
      <td>-0.007343</td>
      <td>0.582879</td>
      <td>-0.177944</td>
      <td>0.451094</td>
      <td>0.321617</td>
      <td>-0.253088</td>
      <td>1.229149</td>
      <td>0.675627</td>
      <td>1.053513</td>
      <td>0.049252</td>
      <td>-0.827489</td>
      <td>-0.485286</td>
      <td>-0.119460</td>
      <td>-0.181043</td>
      <td>...</td>
      <td>0.237172</td>
      <td>-0.535033</td>
      <td>-1.213389</td>
      <td>-0.831602</td>
      <td>1.156390</td>
      <td>0.241871</td>
      <td>-0.859368</td>
      <td>0.223275</td>
      <td>-0.037605</td>
      <td>0.741652</td>
      <td>-0.162996</td>
      <td>0.509224</td>
      <td>0.015439</td>
      <td>-1.047978</td>
      <td>0.699672</td>
      <td>1.129396</td>
      <td>-0.217860</td>
      <td>0.743849</td>
      <td>0.315849</td>
      <td>-0.236268</td>
      <td>-0.829305</td>
      <td>-0.247076</td>
      <td>-0.433638</td>
      <td>-0.198227</td>
      <td>0.602858</td>
      <td>0.346759</td>
      <td>0.877343</td>
      <td>-0.562478</td>
      <td>-0.768426</td>
      <td>-0.606659</td>
      <td>0.011727</td>
      <td>0.571893</td>
      <td>-0.210214</td>
      <td>-0.831067</td>
      <td>-0.531085</td>
      <td>-0.778024</td>
      <td>-0.786648</td>
      <td>-1.210187</td>
      <td>0.047022</td>
      <td>-0.091625</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.522151</td>
      <td>0.027251</td>
      <td>-0.379711</td>
      <td>-0.170569</td>
      <td>-0.190941</td>
      <td>0.061459</td>
      <td>-0.337411</td>
      <td>-0.391444</td>
      <td>-0.279692</td>
      <td>-0.742333</td>
      <td>0.016747</td>
      <td>0.060574</td>
      <td>-0.397758</td>
      <td>0.148158</td>
      <td>1.009278</td>
      <td>1.245373</td>
      <td>0.678691</td>
      <td>0.350215</td>
      <td>0.313827</td>
      <td>0.221235</td>
      <td>0.269453</td>
      <td>0.442021</td>
      <td>0.076157</td>
      <td>0.217218</td>
      <td>-0.338573</td>
      <td>-0.169814</td>
      <td>-0.597121</td>
      <td>0.340568</td>
      <td>-0.189499</td>
      <td>0.344704</td>
      <td>-0.281015</td>
      <td>0.498823</td>
      <td>0.367098</td>
      <td>0.805617</td>
      <td>0.265675</td>
      <td>-0.173022</td>
      <td>-0.364690</td>
      <td>-0.050245</td>
      <td>0.158267</td>
      <td>1.022328</td>
      <td>...</td>
      <td>-1.226339</td>
      <td>0.087555</td>
      <td>-0.869982</td>
      <td>-0.192360</td>
      <td>1.065965</td>
      <td>0.910514</td>
      <td>-0.036621</td>
      <td>0.884790</td>
      <td>0.231796</td>
      <td>0.092459</td>
      <td>-1.381709</td>
      <td>0.529192</td>
      <td>1.021213</td>
      <td>-0.317457</td>
      <td>0.884066</td>
      <td>1.731640</td>
      <td>-0.009628</td>
      <td>0.159665</td>
      <td>1.138867</td>
      <td>0.793038</td>
      <td>-1.210832</td>
      <td>-0.526220</td>
      <td>-0.374619</td>
      <td>-0.611632</td>
      <td>-0.199084</td>
      <td>-0.312997</td>
      <td>-0.268957</td>
      <td>-0.020575</td>
      <td>0.624131</td>
      <td>-0.083384</td>
      <td>-0.223964</td>
      <td>-0.492590</td>
      <td>-1.675615</td>
      <td>-1.169198</td>
      <td>0.023010</td>
      <td>-0.622946</td>
      <td>-0.217576</td>
      <td>-1.005944</td>
      <td>-0.517654</td>
      <td>-0.466434</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-0.275457</td>
      <td>-0.376319</td>
      <td>-0.176326</td>
      <td>-0.067086</td>
      <td>-0.530128</td>
      <td>-0.159249</td>
      <td>0.140211</td>
      <td>-0.616166</td>
      <td>-0.011529</td>
      <td>-0.414473</td>
      <td>-0.139101</td>
      <td>0.418783</td>
      <td>-0.141875</td>
      <td>-0.340756</td>
      <td>-0.166738</td>
      <td>0.056765</td>
      <td>0.009462</td>
      <td>0.289206</td>
      <td>-0.055621</td>
      <td>0.073110</td>
      <td>-0.242445</td>
      <td>-0.026746</td>
      <td>-0.185531</td>
      <td>0.116601</td>
      <td>-0.251588</td>
      <td>-0.220466</td>
      <td>-0.125202</td>
      <td>0.685465</td>
      <td>-0.292638</td>
      <td>0.304957</td>
      <td>0.646020</td>
      <td>0.025052</td>
      <td>0.838054</td>
      <td>0.911732</td>
      <td>0.866659</td>
      <td>-0.231924</td>
      <td>-0.896308</td>
      <td>-0.882561</td>
      <td>0.229120</td>
      <td>1.495054</td>
      <td>...</td>
      <td>0.182633</td>
      <td>0.533741</td>
      <td>-0.514892</td>
      <td>-1.608695</td>
      <td>0.123645</td>
      <td>-0.319725</td>
      <td>-0.681118</td>
      <td>-0.383536</td>
      <td>-1.337949</td>
      <td>-1.071417</td>
      <td>-0.109398</td>
      <td>1.363227</td>
      <td>-0.102494</td>
      <td>-0.292884</td>
      <td>-0.040420</td>
      <td>1.149457</td>
      <td>0.212063</td>
      <td>0.164438</td>
      <td>0.471511</td>
      <td>-0.726845</td>
      <td>-0.003292</td>
      <td>-1.110073</td>
      <td>0.473959</td>
      <td>0.020248</td>
      <td>0.475143</td>
      <td>0.046147</td>
      <td>0.209134</td>
      <td>0.357636</td>
      <td>-0.046858</td>
      <td>-0.194876</td>
      <td>0.266525</td>
      <td>-0.437861</td>
      <td>-0.694697</td>
      <td>0.486668</td>
      <td>-0.200253</td>
      <td>-0.636802</td>
      <td>-0.532379</td>
      <td>-1.846451</td>
      <td>-0.618402</td>
      <td>0.023168</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-0.883433</td>
      <td>-0.035146</td>
      <td>-0.086407</td>
      <td>-0.468594</td>
      <td>0.975859</td>
      <td>0.656365</td>
      <td>0.090369</td>
      <td>0.077511</td>
      <td>0.367113</td>
      <td>0.025887</td>
      <td>-1.163920</td>
      <td>-1.186711</td>
      <td>-1.812581</td>
      <td>0.122518</td>
      <td>-0.185509</td>
      <td>0.016356</td>
      <td>0.688621</td>
      <td>-0.653065</td>
      <td>0.761998</td>
      <td>1.437927</td>
      <td>-0.009709</td>
      <td>0.559345</td>
      <td>0.527656</td>
      <td>-0.393201</td>
      <td>-0.846080</td>
      <td>0.948282</td>
      <td>0.306347</td>
      <td>0.721610</td>
      <td>0.257569</td>
      <td>0.326923</td>
      <td>0.183336</td>
      <td>-0.253330</td>
      <td>0.159421</td>
      <td>0.166498</td>
      <td>0.219283</td>
      <td>1.412459</td>
      <td>-0.048219</td>
      <td>0.045978</td>
      <td>0.429066</td>
      <td>-0.598499</td>
      <td>...</td>
      <td>-0.510416</td>
      <td>-1.262622</td>
      <td>-1.176129</td>
      <td>-0.412074</td>
      <td>0.581220</td>
      <td>0.582187</td>
      <td>-0.734470</td>
      <td>0.106981</td>
      <td>0.828733</td>
      <td>0.359635</td>
      <td>0.926777</td>
      <td>-0.326011</td>
      <td>0.048298</td>
      <td>-0.179448</td>
      <td>-0.348655</td>
      <td>0.412055</td>
      <td>-0.237680</td>
      <td>0.211480</td>
      <td>0.212314</td>
      <td>0.035021</td>
      <td>0.139019</td>
      <td>-0.060740</td>
      <td>0.115083</td>
      <td>0.280769</td>
      <td>1.028251</td>
      <td>-0.110126</td>
      <td>0.298410</td>
      <td>-0.119414</td>
      <td>-0.228885</td>
      <td>0.783405</td>
      <td>0.073232</td>
      <td>0.624011</td>
      <td>-0.276710</td>
      <td>0.525596</td>
      <td>-0.195000</td>
      <td>0.057460</td>
      <td>-0.291427</td>
      <td>-0.278242</td>
      <td>-0.901737</td>
      <td>-0.557496</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.516261</td>
      <td>-0.258762</td>
      <td>-0.134556</td>
      <td>0.430827</td>
      <td>0.412838</td>
      <td>1.292247</td>
      <td>0.135757</td>
      <td>-1.402514</td>
      <td>-0.805690</td>
      <td>-0.072927</td>
      <td>-0.636366</td>
      <td>-0.227012</td>
      <td>-0.658328</td>
      <td>-0.578407</td>
      <td>-0.403376</td>
      <td>-0.655650</td>
      <td>-0.442876</td>
      <td>0.669624</td>
      <td>-0.024015</td>
      <td>-0.244610</td>
      <td>0.084887</td>
      <td>1.847972</td>
      <td>0.516689</td>
      <td>-0.119175</td>
      <td>-0.001962</td>
      <td>-0.381701</td>
      <td>0.038420</td>
      <td>0.783321</td>
      <td>-0.242904</td>
      <td>-0.710942</td>
      <td>0.049569</td>
      <td>0.316975</td>
      <td>0.367867</td>
      <td>0.422100</td>
      <td>0.465000</td>
      <td>0.416618</td>
      <td>-1.504212</td>
      <td>0.814312</td>
      <td>0.566621</td>
      <td>-0.385283</td>
      <td>...</td>
      <td>0.182301</td>
      <td>0.120762</td>
      <td>0.738681</td>
      <td>-0.547737</td>
      <td>0.343207</td>
      <td>0.728411</td>
      <td>0.277081</td>
      <td>2.215277</td>
      <td>0.778458</td>
      <td>0.927668</td>
      <td>-0.042634</td>
      <td>0.395619</td>
      <td>0.232540</td>
      <td>0.148728</td>
      <td>-0.086000</td>
      <td>1.238399</td>
      <td>-0.347315</td>
      <td>-0.899684</td>
      <td>0.379635</td>
      <td>-0.051516</td>
      <td>0.531217</td>
      <td>-0.328594</td>
      <td>-0.686010</td>
      <td>-0.197956</td>
      <td>-0.788379</td>
      <td>-1.031918</td>
      <td>0.514506</td>
      <td>0.144587</td>
      <td>1.042158</td>
      <td>0.259356</td>
      <td>-0.489328</td>
      <td>-0.242487</td>
      <td>-0.351645</td>
      <td>0.260221</td>
      <td>-0.051265</td>
      <td>0.383197</td>
      <td>0.578718</td>
      <td>-1.209572</td>
      <td>-0.277600</td>
      <td>0.237761</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-0.772323</td>
      <td>-0.520668</td>
      <td>-0.663728</td>
      <td>-0.191579</td>
      <td>0.635942</td>
      <td>0.337758</td>
      <td>0.057140</td>
      <td>-0.406170</td>
      <td>0.059807</td>
      <td>0.283875</td>
      <td>-0.360096</td>
      <td>0.018865</td>
      <td>-0.100271</td>
      <td>0.958275</td>
      <td>0.596056</td>
      <td>-0.240312</td>
      <td>0.450607</td>
      <td>0.454433</td>
      <td>0.200731</td>
      <td>0.098699</td>
      <td>-0.833234</td>
      <td>0.660372</td>
      <td>0.325655</td>
      <td>0.398147</td>
      <td>0.594167</td>
      <td>0.837582</td>
      <td>0.039299</td>
      <td>-0.276851</td>
      <td>-1.357790</td>
      <td>-0.284190</td>
      <td>0.324399</td>
      <td>0.039196</td>
      <td>0.323257</td>
      <td>-0.442212</td>
      <td>-1.577386</td>
      <td>-0.214418</td>
      <td>-1.128975</td>
      <td>-0.353618</td>
      <td>0.186807</td>
      <td>-0.459324</td>
      <td>...</td>
      <td>-0.125126</td>
      <td>-0.394063</td>
      <td>-0.059795</td>
      <td>-0.375338</td>
      <td>0.842508</td>
      <td>0.113210</td>
      <td>0.472309</td>
      <td>0.131040</td>
      <td>-0.487310</td>
      <td>0.283023</td>
      <td>-0.020332</td>
      <td>0.105385</td>
      <td>-0.238208</td>
      <td>-0.806683</td>
      <td>-0.060305</td>
      <td>1.842900</td>
      <td>-0.683256</td>
      <td>-0.643769</td>
      <td>-0.285585</td>
      <td>0.413605</td>
      <td>-0.498285</td>
      <td>-0.782674</td>
      <td>-0.197732</td>
      <td>0.220182</td>
      <td>0.406168</td>
      <td>0.775767</td>
      <td>0.458770</td>
      <td>-0.206913</td>
      <td>0.414181</td>
      <td>0.146578</td>
      <td>-0.070535</td>
      <td>-0.001467</td>
      <td>0.272841</td>
      <td>0.004965</td>
      <td>-0.121455</td>
      <td>-0.624881</td>
      <td>-0.190733</td>
      <td>-2.907669</td>
      <td>-0.759701</td>
      <td>-0.643729</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.012758</td>
      <td>0.471492</td>
      <td>-0.236143</td>
      <td>0.551259</td>
      <td>0.381190</td>
      <td>-0.492003</td>
      <td>-0.229998</td>
      <td>-0.061634</td>
      <td>0.376969</td>
      <td>0.219858</td>
      <td>-0.113665</td>
      <td>-0.451093</td>
      <td>0.650337</td>
      <td>-0.403957</td>
      <td>0.503178</td>
      <td>-0.274695</td>
      <td>0.225310</td>
      <td>0.267611</td>
      <td>0.261989</td>
      <td>0.186376</td>
      <td>0.835115</td>
      <td>1.282963</td>
      <td>-0.251267</td>
      <td>-1.197076</td>
      <td>-0.654357</td>
      <td>-0.095441</td>
      <td>-0.005856</td>
      <td>0.417442</td>
      <td>-1.358646</td>
      <td>0.357160</td>
      <td>-0.051040</td>
      <td>0.329910</td>
      <td>0.410954</td>
      <td>-0.064969</td>
      <td>0.046311</td>
      <td>0.750520</td>
      <td>0.419483</td>
      <td>-1.754726</td>
      <td>0.079213</td>
      <td>-0.456407</td>
      <td>...</td>
      <td>1.097589</td>
      <td>0.137675</td>
      <td>0.672642</td>
      <td>-0.131879</td>
      <td>0.485787</td>
      <td>-0.658202</td>
      <td>-0.661198</td>
      <td>0.226961</td>
      <td>-0.624392</td>
      <td>-1.074567</td>
      <td>-0.432724</td>
      <td>-0.073354</td>
      <td>0.515807</td>
      <td>-0.165807</td>
      <td>0.615642</td>
      <td>0.938931</td>
      <td>0.142145</td>
      <td>0.425093</td>
      <td>0.604992</td>
      <td>-0.399501</td>
      <td>-0.879718</td>
      <td>-0.696900</td>
      <td>-0.833029</td>
      <td>-1.113871</td>
      <td>-1.195753</td>
      <td>-0.821521</td>
      <td>0.714692</td>
      <td>-0.464784</td>
      <td>-0.160515</td>
      <td>-1.179516</td>
      <td>-1.629566</td>
      <td>-0.117286</td>
      <td>-1.209097</td>
      <td>-0.757849</td>
      <td>-0.631495</td>
      <td>-0.624201</td>
      <td>-0.159208</td>
      <td>1.099756</td>
      <td>0.689563</td>
      <td>-0.347824</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-0.973679</td>
      <td>-0.122550</td>
      <td>-0.000684</td>
      <td>0.481191</td>
      <td>0.705861</td>
      <td>0.904479</td>
      <td>0.433825</td>
      <td>0.738089</td>
      <td>0.290445</td>
      <td>-0.216578</td>
      <td>0.464638</td>
      <td>-0.860382</td>
      <td>-0.222986</td>
      <td>0.689886</td>
      <td>1.153374</td>
      <td>0.113790</td>
      <td>0.547012</td>
      <td>-0.274714</td>
      <td>0.230995</td>
      <td>-1.458703</td>
      <td>-0.500403</td>
      <td>-0.051073</td>
      <td>-0.174870</td>
      <td>-0.903763</td>
      <td>-0.148725</td>
      <td>0.015230</td>
      <td>-0.093188</td>
      <td>0.473737</td>
      <td>0.143963</td>
      <td>0.375087</td>
      <td>0.511441</td>
      <td>-0.414081</td>
      <td>-0.188419</td>
      <td>-0.520021</td>
      <td>-0.737142</td>
      <td>0.190223</td>
      <td>-0.437861</td>
      <td>0.048048</td>
      <td>-0.005158</td>
      <td>0.574659</td>
      <td>...</td>
      <td>-0.985735</td>
      <td>-0.524505</td>
      <td>0.044025</td>
      <td>-0.399452</td>
      <td>0.648331</td>
      <td>0.766598</td>
      <td>0.051433</td>
      <td>0.129310</td>
      <td>-0.128438</td>
      <td>1.043906</td>
      <td>-0.128047</td>
      <td>0.412627</td>
      <td>0.406346</td>
      <td>0.245982</td>
      <td>0.228984</td>
      <td>0.105413</td>
      <td>-0.503627</td>
      <td>-0.522792</td>
      <td>0.485030</td>
      <td>0.312029</td>
      <td>1.098102</td>
      <td>0.698208</td>
      <td>0.377655</td>
      <td>-0.195760</td>
      <td>1.404699</td>
      <td>0.069151</td>
      <td>0.372732</td>
      <td>0.865487</td>
      <td>0.549016</td>
      <td>0.678692</td>
      <td>0.404227</td>
      <td>0.146959</td>
      <td>-0.828561</td>
      <td>-0.817909</td>
      <td>-1.307529</td>
      <td>-0.703264</td>
      <td>-0.130294</td>
      <td>-1.839231</td>
      <td>-0.959618</td>
      <td>-0.890571</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-0.213704</td>
      <td>-0.781728</td>
      <td>-0.175012</td>
      <td>-0.356222</td>
      <td>0.245418</td>
      <td>-0.662803</td>
      <td>-0.111500</td>
      <td>-1.849200</td>
      <td>0.112074</td>
      <td>-0.939837</td>
      <td>-1.083742</td>
      <td>0.352192</td>
      <td>-0.005083</td>
      <td>0.185482</td>
      <td>-0.593851</td>
      <td>-0.158048</td>
      <td>0.469651</td>
      <td>0.543592</td>
      <td>0.954457</td>
      <td>0.013465</td>
      <td>1.095065</td>
      <td>1.270377</td>
      <td>0.017494</td>
      <td>-0.080558</td>
      <td>0.372295</td>
      <td>1.074238</td>
      <td>0.702961</td>
      <td>0.757220</td>
      <td>0.125406</td>
      <td>0.114520</td>
      <td>-0.215050</td>
      <td>0.309617</td>
      <td>-0.735174</td>
      <td>-0.453774</td>
      <td>-0.240890</td>
      <td>0.653691</td>
      <td>-0.109442</td>
      <td>0.019151</td>
      <td>-1.156161</td>
      <td>-0.947722</td>
      <td>...</td>
      <td>-0.104793</td>
      <td>-0.195074</td>
      <td>-0.777445</td>
      <td>-1.188812</td>
      <td>-0.688759</td>
      <td>-0.207285</td>
      <td>-0.135477</td>
      <td>0.454072</td>
      <td>0.203470</td>
      <td>-0.329038</td>
      <td>0.264899</td>
      <td>0.148686</td>
      <td>-0.235112</td>
      <td>-1.233734</td>
      <td>-0.055903</td>
      <td>1.819982</td>
      <td>1.174527</td>
      <td>0.629643</td>
      <td>-0.160571</td>
      <td>-0.572650</td>
      <td>0.218411</td>
      <td>-0.792785</td>
      <td>0.085975</td>
      <td>-1.095693</td>
      <td>-0.628453</td>
      <td>0.090450</td>
      <td>0.456925</td>
      <td>-0.618499</td>
      <td>0.235816</td>
      <td>-0.206320</td>
      <td>0.974851</td>
      <td>-0.386714</td>
      <td>0.176924</td>
      <td>-0.602480</td>
      <td>-0.335554</td>
      <td>0.625928</td>
      <td>0.749501</td>
      <td>-0.151778</td>
      <td>0.446583</td>
      <td>-0.184909</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.016814</td>
      <td>-0.614495</td>
      <td>-0.029485</td>
      <td>-0.036715</td>
      <td>-0.526264</td>
      <td>0.650970</td>
      <td>-0.145177</td>
      <td>-1.169267</td>
      <td>-0.173818</td>
      <td>0.072630</td>
      <td>-0.192511</td>
      <td>-0.412610</td>
      <td>-0.452584</td>
      <td>-0.411280</td>
      <td>0.103223</td>
      <td>0.478391</td>
      <td>0.010789</td>
      <td>0.364327</td>
      <td>-0.054271</td>
      <td>-0.666915</td>
      <td>0.834583</td>
      <td>0.404696</td>
      <td>0.429161</td>
      <td>-0.202935</td>
      <td>-0.598749</td>
      <td>0.270458</td>
      <td>0.406473</td>
      <td>0.759737</td>
      <td>-0.065834</td>
      <td>0.134786</td>
      <td>0.216840</td>
      <td>0.339584</td>
      <td>0.395804</td>
      <td>0.317066</td>
      <td>0.340307</td>
      <td>0.873995</td>
      <td>-0.649587</td>
      <td>-0.142421</td>
      <td>-0.080506</td>
      <td>0.731941</td>
      <td>...</td>
      <td>-0.517390</td>
      <td>0.155284</td>
      <td>-0.545929</td>
      <td>-0.704610</td>
      <td>-0.663294</td>
      <td>-0.045180</td>
      <td>-0.705941</td>
      <td>-0.106240</td>
      <td>-0.506707</td>
      <td>-0.899142</td>
      <td>-0.708684</td>
      <td>-1.632880</td>
      <td>-0.069738</td>
      <td>-1.064847</td>
      <td>-1.131894</td>
      <td>0.631094</td>
      <td>0.233338</td>
      <td>0.696659</td>
      <td>-0.245701</td>
      <td>-0.072710</td>
      <td>0.270350</td>
      <td>-0.761941</td>
      <td>-0.431495</td>
      <td>0.876798</td>
      <td>0.105110</td>
      <td>-0.360678</td>
      <td>0.278618</td>
      <td>-1.047310</td>
      <td>-0.915679</td>
      <td>-1.276070</td>
      <td>-0.696537</td>
      <td>0.286089</td>
      <td>-0.588381</td>
      <td>-0.422992</td>
      <td>0.789273</td>
      <td>0.397204</td>
      <td>-0.184335</td>
      <td>0.920739</td>
      <td>-0.100609</td>
      <td>-0.739426</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.728578</td>
      <td>0.163557</td>
      <td>0.204751</td>
      <td>0.482661</td>
      <td>0.563488</td>
      <td>0.629177</td>
      <td>-0.281835</td>
      <td>-1.519307</td>
      <td>-0.170236</td>
      <td>-0.074706</td>
      <td>-1.095910</td>
      <td>-0.368471</td>
      <td>-1.082813</td>
      <td>-0.153305</td>
      <td>-0.546244</td>
      <td>-0.228391</td>
      <td>0.455760</td>
      <td>0.843198</td>
      <td>-0.507731</td>
      <td>-1.019652</td>
      <td>-0.023385</td>
      <td>0.977338</td>
      <td>0.656812</td>
      <td>-0.893356</td>
      <td>0.746818</td>
      <td>1.453458</td>
      <td>0.485630</td>
      <td>0.201285</td>
      <td>-0.138475</td>
      <td>-0.125629</td>
      <td>0.025470</td>
      <td>0.075375</td>
      <td>0.509828</td>
      <td>-0.369332</td>
      <td>-1.350157</td>
      <td>0.452657</td>
      <td>-0.509391</td>
      <td>0.457883</td>
      <td>-0.300043</td>
      <td>0.188611</td>
      <td>...</td>
      <td>0.329812</td>
      <td>0.093850</td>
      <td>0.119919</td>
      <td>-0.723233</td>
      <td>-0.004784</td>
      <td>-0.127778</td>
      <td>-0.166102</td>
      <td>0.470893</td>
      <td>0.237876</td>
      <td>-0.404719</td>
      <td>-1.131769</td>
      <td>0.564144</td>
      <td>-0.832279</td>
      <td>0.073184</td>
      <td>-0.222222</td>
      <td>0.240066</td>
      <td>0.182648</td>
      <td>0.193305</td>
      <td>0.293547</td>
      <td>-0.210776</td>
      <td>0.544393</td>
      <td>-0.705216</td>
      <td>0.314252</td>
      <td>0.329428</td>
      <td>-0.451091</td>
      <td>-0.257853</td>
      <td>-0.567996</td>
      <td>-0.026754</td>
      <td>0.039633</td>
      <td>1.370311</td>
      <td>-0.577330</td>
      <td>-0.215641</td>
      <td>-0.424115</td>
      <td>0.322830</td>
      <td>-0.507270</td>
      <td>0.775550</td>
      <td>0.189680</td>
      <td>-1.934802</td>
      <td>-1.127670</td>
      <td>-0.150656</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.503250</td>
      <td>-1.630115</td>
      <td>0.201663</td>
      <td>-0.278585</td>
      <td>0.370585</td>
      <td>0.843511</td>
      <td>-0.351256</td>
      <td>-0.286573</td>
      <td>0.744454</td>
      <td>-0.401447</td>
      <td>-0.139092</td>
      <td>1.249389</td>
      <td>0.349028</td>
      <td>-0.211922</td>
      <td>0.534137</td>
      <td>-0.012149</td>
      <td>0.437446</td>
      <td>0.444819</td>
      <td>-0.507201</td>
      <td>0.040539</td>
      <td>0.567943</td>
      <td>1.145605</td>
      <td>-0.089533</td>
      <td>-0.118006</td>
      <td>-0.113306</td>
      <td>0.662938</td>
      <td>0.809043</td>
      <td>0.512128</td>
      <td>-0.733412</td>
      <td>-0.107986</td>
      <td>0.566466</td>
      <td>0.394122</td>
      <td>0.826479</td>
      <td>1.325451</td>
      <td>-0.469226</td>
      <td>0.296602</td>
      <td>-0.430070</td>
      <td>-0.345417</td>
      <td>0.104365</td>
      <td>0.271623</td>
      <td>...</td>
      <td>0.571226</td>
      <td>0.462408</td>
      <td>-0.345382</td>
      <td>0.152280</td>
      <td>0.341317</td>
      <td>0.104822</td>
      <td>-0.282170</td>
      <td>-0.476787</td>
      <td>-0.071155</td>
      <td>0.276351</td>
      <td>-0.441634</td>
      <td>-0.153998</td>
      <td>-0.990100</td>
      <td>-0.904212</td>
      <td>-0.235878</td>
      <td>1.496433</td>
      <td>0.010063</td>
      <td>0.905907</td>
      <td>0.724821</td>
      <td>0.154618</td>
      <td>-0.005152</td>
      <td>0.159934</td>
      <td>0.077484</td>
      <td>0.346739</td>
      <td>0.450177</td>
      <td>-0.587725</td>
      <td>-0.416227</td>
      <td>-0.806461</td>
      <td>0.202016</td>
      <td>0.604636</td>
      <td>-0.031521</td>
      <td>0.038284</td>
      <td>-0.433160</td>
      <td>0.006546</td>
      <td>0.256362</td>
      <td>0.165978</td>
      <td>1.296601</td>
      <td>-0.474813</td>
      <td>-0.418675</td>
      <td>-0.491076</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.046420</td>
      <td>-0.735754</td>
      <td>-0.473120</td>
      <td>-1.595206</td>
      <td>0.449712</td>
      <td>0.617238</td>
      <td>-0.378822</td>
      <td>-0.316513</td>
      <td>0.128384</td>
      <td>0.580166</td>
      <td>-0.270174</td>
      <td>-0.325157</td>
      <td>0.631673</td>
      <td>0.297673</td>
      <td>-0.228791</td>
      <td>0.597369</td>
      <td>1.294782</td>
      <td>1.249452</td>
      <td>0.063747</td>
      <td>-0.325078</td>
      <td>0.441936</td>
      <td>0.264974</td>
      <td>0.292768</td>
      <td>-0.642458</td>
      <td>-0.062240</td>
      <td>-0.586662</td>
      <td>-0.000061</td>
      <td>-0.066608</td>
      <td>-1.742072</td>
      <td>-0.188976</td>
      <td>0.912976</td>
      <td>0.194142</td>
      <td>-0.902349</td>
      <td>-0.677648</td>
      <td>-0.029596</td>
      <td>0.397225</td>
      <td>0.018674</td>
      <td>-0.631077</td>
      <td>0.339740</td>
      <td>-0.085782</td>
      <td>...</td>
      <td>-0.704103</td>
      <td>-0.324027</td>
      <td>0.060673</td>
      <td>-1.190594</td>
      <td>0.112282</td>
      <td>-0.125231</td>
      <td>-0.365000</td>
      <td>0.183781</td>
      <td>-0.776323</td>
      <td>-1.137791</td>
      <td>-0.500020</td>
      <td>-0.330249</td>
      <td>-0.249408</td>
      <td>-1.009614</td>
      <td>-0.011544</td>
      <td>0.831865</td>
      <td>-0.353924</td>
      <td>0.948902</td>
      <td>-0.226717</td>
      <td>0.180370</td>
      <td>-1.386274</td>
      <td>-1.094805</td>
      <td>0.032593</td>
      <td>-0.201726</td>
      <td>-0.174774</td>
      <td>0.918615</td>
      <td>-0.080005</td>
      <td>-0.564466</td>
      <td>0.363107</td>
      <td>-0.419090</td>
      <td>0.457146</td>
      <td>0.292379</td>
      <td>-0.979344</td>
      <td>-1.380431</td>
      <td>-0.053167</td>
      <td>0.025816</td>
      <td>-0.671784</td>
      <td>-1.071299</td>
      <td>-0.388215</td>
      <td>-0.516298</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.969158</td>
      <td>-1.732849</td>
      <td>-0.052865</td>
      <td>-0.523991</td>
      <td>-0.832873</td>
      <td>-0.858400</td>
      <td>-0.227207</td>
      <td>0.388054</td>
      <td>-0.539654</td>
      <td>0.013262</td>
      <td>-0.460539</td>
      <td>-0.751232</td>
      <td>-0.365075</td>
      <td>0.290258</td>
      <td>0.427095</td>
      <td>-0.309423</td>
      <td>0.723217</td>
      <td>0.866321</td>
      <td>0.355549</td>
      <td>0.251055</td>
      <td>0.277217</td>
      <td>0.530415</td>
      <td>0.794902</td>
      <td>-0.061652</td>
      <td>0.241952</td>
      <td>0.196136</td>
      <td>-0.864992</td>
      <td>-0.080374</td>
      <td>0.476175</td>
      <td>0.269017</td>
      <td>-0.042224</td>
      <td>0.482813</td>
      <td>-0.235180</td>
      <td>-0.062385</td>
      <td>-0.112709</td>
      <td>0.486299</td>
      <td>-0.470190</td>
      <td>-0.131290</td>
      <td>0.287388</td>
      <td>-0.489415</td>
      <td>...</td>
      <td>-0.460477</td>
      <td>0.114375</td>
      <td>0.152487</td>
      <td>-0.533315</td>
      <td>0.189038</td>
      <td>-0.003642</td>
      <td>0.098738</td>
      <td>-0.296786</td>
      <td>0.317242</td>
      <td>-0.900458</td>
      <td>-0.721868</td>
      <td>0.160041</td>
      <td>-0.671567</td>
      <td>0.593563</td>
      <td>0.645765</td>
      <td>0.587354</td>
      <td>0.270656</td>
      <td>0.670951</td>
      <td>1.138762</td>
      <td>1.258895</td>
      <td>0.707141</td>
      <td>0.385854</td>
      <td>0.364994</td>
      <td>-0.335413</td>
      <td>-0.409187</td>
      <td>0.174702</td>
      <td>0.406414</td>
      <td>0.807707</td>
      <td>-0.792780</td>
      <td>-0.880069</td>
      <td>-0.197138</td>
      <td>0.105413</td>
      <td>-0.705637</td>
      <td>0.559280</td>
      <td>-0.487609</td>
      <td>-0.049461</td>
      <td>-0.462538</td>
      <td>-0.797657</td>
      <td>0.361912</td>
      <td>0.736596</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.313072</td>
      <td>0.232171</td>
      <td>0.459857</td>
      <td>0.666918</td>
      <td>-0.077089</td>
      <td>0.108745</td>
      <td>-0.839519</td>
      <td>-1.284155</td>
      <td>-0.872368</td>
      <td>0.486911</td>
      <td>0.134298</td>
      <td>-0.340634</td>
      <td>-0.061201</td>
      <td>-0.283309</td>
      <td>-0.007472</td>
      <td>-1.269424</td>
      <td>0.464081</td>
      <td>0.653873</td>
      <td>1.023348</td>
      <td>-0.517169</td>
      <td>-0.121704</td>
      <td>0.191715</td>
      <td>0.560016</td>
      <td>0.120972</td>
      <td>0.425748</td>
      <td>-0.080971</td>
      <td>1.746274</td>
      <td>0.795848</td>
      <td>-0.698280</td>
      <td>-0.285435</td>
      <td>0.880954</td>
      <td>0.201303</td>
      <td>1.120952</td>
      <td>0.754355</td>
      <td>0.701092</td>
      <td>-0.872807</td>
      <td>-1.328003</td>
      <td>-0.265856</td>
      <td>0.303977</td>
      <td>0.101878</td>
      <td>...</td>
      <td>-0.710346</td>
      <td>0.272794</td>
      <td>0.127198</td>
      <td>-1.035355</td>
      <td>0.175144</td>
      <td>-0.140165</td>
      <td>-1.406324</td>
      <td>0.942453</td>
      <td>-0.185046</td>
      <td>-0.143878</td>
      <td>-0.430565</td>
      <td>-0.577807</td>
      <td>-0.418506</td>
      <td>-0.133088</td>
      <td>0.744288</td>
      <td>0.833057</td>
      <td>-0.701939</td>
      <td>-0.373261</td>
      <td>-0.933160</td>
      <td>0.873056</td>
      <td>0.436826</td>
      <td>-0.541258</td>
      <td>-0.295788</td>
      <td>-0.037463</td>
      <td>1.568143</td>
      <td>-0.041938</td>
      <td>0.241283</td>
      <td>0.472842</td>
      <td>-0.354455</td>
      <td>-0.222208</td>
      <td>0.482955</td>
      <td>1.154715</td>
      <td>0.100874</td>
      <td>-0.459754</td>
      <td>-0.191659</td>
      <td>0.234950</td>
      <td>-0.338328</td>
      <td>0.589093</td>
      <td>1.285500</td>
      <td>0.488175</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-1.101520</td>
      <td>-0.385157</td>
      <td>0.346521</td>
      <td>-0.207679</td>
      <td>-0.493557</td>
      <td>-0.974499</td>
      <td>-0.190995</td>
      <td>-0.493546</td>
      <td>0.273333</td>
      <td>0.506461</td>
      <td>-0.147941</td>
      <td>-1.171738</td>
      <td>-1.203175</td>
      <td>-1.316045</td>
      <td>-1.076815</td>
      <td>-0.121137</td>
      <td>0.241842</td>
      <td>0.350414</td>
      <td>-0.170391</td>
      <td>-0.176063</td>
      <td>0.483385</td>
      <td>0.733295</td>
      <td>0.121068</td>
      <td>0.491179</td>
      <td>0.159978</td>
      <td>0.357509</td>
      <td>0.245125</td>
      <td>0.544878</td>
      <td>0.029707</td>
      <td>-0.226453</td>
      <td>-0.563790</td>
      <td>0.168301</td>
      <td>0.280151</td>
      <td>-0.222861</td>
      <td>-1.025352</td>
      <td>0.171722</td>
      <td>0.146818</td>
      <td>-0.747320</td>
      <td>0.531491</td>
      <td>0.948991</td>
      <td>...</td>
      <td>0.669748</td>
      <td>-0.459263</td>
      <td>0.080188</td>
      <td>-0.294929</td>
      <td>0.904069</td>
      <td>0.289997</td>
      <td>0.392198</td>
      <td>0.259891</td>
      <td>-0.237495</td>
      <td>0.207652</td>
      <td>-0.409419</td>
      <td>0.547845</td>
      <td>1.116429</td>
      <td>0.381893</td>
      <td>0.669391</td>
      <td>0.418903</td>
      <td>-0.951357</td>
      <td>-0.484453</td>
      <td>0.745356</td>
      <td>0.300085</td>
      <td>0.282758</td>
      <td>0.015470</td>
      <td>0.188158</td>
      <td>0.515232</td>
      <td>0.262518</td>
      <td>-0.431680</td>
      <td>-0.784792</td>
      <td>-0.472016</td>
      <td>0.288251</td>
      <td>-0.031566</td>
      <td>0.237860</td>
      <td>0.597250</td>
      <td>0.991388</td>
      <td>0.175885</td>
      <td>0.484863</td>
      <td>0.639735</td>
      <td>0.831491</td>
      <td>-1.718504</td>
      <td>-0.708912</td>
      <td>0.363274</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.464210</td>
      <td>-0.346509</td>
      <td>-0.024665</td>
      <td>-0.360911</td>
      <td>-0.721920</td>
      <td>0.263463</td>
      <td>0.026286</td>
      <td>-0.263804</td>
      <td>0.267881</td>
      <td>-1.215836</td>
      <td>-0.401870</td>
      <td>0.050433</td>
      <td>-0.952310</td>
      <td>-0.774527</td>
      <td>-1.030406</td>
      <td>-0.080190</td>
      <td>0.077106</td>
      <td>0.629059</td>
      <td>0.056604</td>
      <td>0.114225</td>
      <td>0.524321</td>
      <td>0.625502</td>
      <td>-0.036606</td>
      <td>-0.342585</td>
      <td>0.229471</td>
      <td>0.819683</td>
      <td>0.641334</td>
      <td>0.720504</td>
      <td>0.229340</td>
      <td>-0.713222</td>
      <td>-0.426673</td>
      <td>0.767323</td>
      <td>2.075530</td>
      <td>1.571500</td>
      <td>-0.115461</td>
      <td>-0.484695</td>
      <td>-0.817264</td>
      <td>-0.719813</td>
      <td>-0.041861</td>
      <td>0.252654</td>
      <td>...</td>
      <td>-0.354359</td>
      <td>-0.666377</td>
      <td>-0.834483</td>
      <td>-0.761980</td>
      <td>0.402283</td>
      <td>0.369805</td>
      <td>0.782792</td>
      <td>0.514310</td>
      <td>-0.262857</td>
      <td>-0.145412</td>
      <td>-0.936218</td>
      <td>0.203202</td>
      <td>-1.213089</td>
      <td>0.717963</td>
      <td>-1.492073</td>
      <td>0.148676</td>
      <td>-0.533480</td>
      <td>0.293166</td>
      <td>-0.368034</td>
      <td>-0.529780</td>
      <td>-0.833844</td>
      <td>-1.098832</td>
      <td>-0.251599</td>
      <td>-0.274967</td>
      <td>0.921027</td>
      <td>0.152166</td>
      <td>-0.204278</td>
      <td>0.477886</td>
      <td>-0.176132</td>
      <td>-0.880628</td>
      <td>0.015761</td>
      <td>0.619113</td>
      <td>-1.237641</td>
      <td>0.127831</td>
      <td>-0.034570</td>
      <td>-0.099393</td>
      <td>-0.429154</td>
      <td>-0.004266</td>
      <td>0.213711</td>
      <td>0.123606</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-0.163449</td>
      <td>0.234756</td>
      <td>0.812882</td>
      <td>1.088573</td>
      <td>-0.885845</td>
      <td>-0.013256</td>
      <td>-0.224760</td>
      <td>-0.333456</td>
      <td>0.356679</td>
      <td>-0.093866</td>
      <td>-0.491539</td>
      <td>-0.805205</td>
      <td>0.162141</td>
      <td>0.476431</td>
      <td>-1.026412</td>
      <td>-0.600114</td>
      <td>-0.474429</td>
      <td>0.126528</td>
      <td>-0.715996</td>
      <td>-0.065342</td>
      <td>0.585828</td>
      <td>1.037392</td>
      <td>0.343749</td>
      <td>0.104239</td>
      <td>1.328715</td>
      <td>0.120369</td>
      <td>0.390046</td>
      <td>0.605098</td>
      <td>1.328345</td>
      <td>0.056888</td>
      <td>0.222068</td>
      <td>-0.200961</td>
      <td>1.266470</td>
      <td>1.041403</td>
      <td>-1.069804</td>
      <td>-0.499027</td>
      <td>-0.858297</td>
      <td>-0.373234</td>
      <td>0.518129</td>
      <td>0.452396</td>
      <td>...</td>
      <td>-0.518911</td>
      <td>0.727517</td>
      <td>-0.536977</td>
      <td>-1.084431</td>
      <td>0.817071</td>
      <td>0.583777</td>
      <td>-0.506068</td>
      <td>-0.815552</td>
      <td>-0.427096</td>
      <td>-0.310674</td>
      <td>-1.492447</td>
      <td>-0.069592</td>
      <td>-0.067030</td>
      <td>-0.351669</td>
      <td>0.390967</td>
      <td>1.354870</td>
      <td>-0.382252</td>
      <td>-0.589431</td>
      <td>0.087553</td>
      <td>0.240207</td>
      <td>-0.399498</td>
      <td>-0.330650</td>
      <td>-0.132837</td>
      <td>-0.812254</td>
      <td>-0.685469</td>
      <td>-0.865870</td>
      <td>-0.145354</td>
      <td>-0.119685</td>
      <td>0.539480</td>
      <td>-0.145130</td>
      <td>-0.162836</td>
      <td>0.266902</td>
      <td>-0.165302</td>
      <td>-0.087544</td>
      <td>-0.698694</td>
      <td>0.157754</td>
      <td>-0.790114</td>
      <td>1.773975</td>
      <td>0.918422</td>
      <td>-0.483103</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.316845</td>
      <td>-1.418277</td>
      <td>-0.562481</td>
      <td>-0.107450</td>
      <td>-0.033167</td>
      <td>-0.088071</td>
      <td>1.072119</td>
      <td>0.148224</td>
      <td>0.456899</td>
      <td>-0.325877</td>
      <td>-0.313148</td>
      <td>-0.184024</td>
      <td>0.051750</td>
      <td>-0.166518</td>
      <td>0.516163</td>
      <td>1.045743</td>
      <td>0.303140</td>
      <td>0.189698</td>
      <td>-0.327591</td>
      <td>-0.163655</td>
      <td>0.273728</td>
      <td>-0.158154</td>
      <td>0.191616</td>
      <td>-0.010988</td>
      <td>0.400794</td>
      <td>-0.137732</td>
      <td>0.827094</td>
      <td>0.127059</td>
      <td>-0.269002</td>
      <td>0.318178</td>
      <td>-0.304989</td>
      <td>-1.802226</td>
      <td>-0.458421</td>
      <td>-0.412285</td>
      <td>0.129632</td>
      <td>0.505803</td>
      <td>1.040661</td>
      <td>-0.810851</td>
      <td>-0.097245</td>
      <td>0.377863</td>
      <td>...</td>
      <td>0.128328</td>
      <td>0.248117</td>
      <td>0.621007</td>
      <td>0.555193</td>
      <td>-0.469811</td>
      <td>-0.674591</td>
      <td>0.713674</td>
      <td>-0.028044</td>
      <td>0.055234</td>
      <td>-0.516143</td>
      <td>-0.551291</td>
      <td>-0.306164</td>
      <td>1.099386</td>
      <td>-0.776978</td>
      <td>0.164296</td>
      <td>1.024842</td>
      <td>-0.527985</td>
      <td>0.653172</td>
      <td>-0.411703</td>
      <td>-0.515304</td>
      <td>-0.412106</td>
      <td>-0.920421</td>
      <td>-0.575097</td>
      <td>-0.862318</td>
      <td>-0.920433</td>
      <td>-1.738473</td>
      <td>-0.988786</td>
      <td>1.129017</td>
      <td>0.361954</td>
      <td>0.664340</td>
      <td>0.143953</td>
      <td>0.146411</td>
      <td>-0.270353</td>
      <td>-0.156189</td>
      <td>0.692750</td>
      <td>0.708890</td>
      <td>-0.085526</td>
      <td>-1.477535</td>
      <td>-1.257171</td>
      <td>-0.386835</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.520008</td>
      <td>0.126921</td>
      <td>0.392295</td>
      <td>0.738788</td>
      <td>1.682773</td>
      <td>-0.133545</td>
      <td>0.104943</td>
      <td>-0.042205</td>
      <td>1.360445</td>
      <td>-1.008391</td>
      <td>-0.551641</td>
      <td>0.072646</td>
      <td>0.406861</td>
      <td>0.123261</td>
      <td>-0.474388</td>
      <td>0.305251</td>
      <td>-0.669684</td>
      <td>-0.156817</td>
      <td>-0.288813</td>
      <td>0.681697</td>
      <td>0.459671</td>
      <td>0.005318</td>
      <td>-0.093848</td>
      <td>0.865127</td>
      <td>1.087370</td>
      <td>1.044805</td>
      <td>-0.150435</td>
      <td>-0.311533</td>
      <td>0.317028</td>
      <td>-0.487503</td>
      <td>-0.455175</td>
      <td>0.394809</td>
      <td>-0.506747</td>
      <td>0.172745</td>
      <td>-0.914396</td>
      <td>0.268420</td>
      <td>0.210056</td>
      <td>0.591922</td>
      <td>0.969076</td>
      <td>-0.208553</td>
      <td>...</td>
      <td>0.547261</td>
      <td>0.450121</td>
      <td>0.693535</td>
      <td>0.769148</td>
      <td>0.290681</td>
      <td>-0.643707</td>
      <td>0.803426</td>
      <td>0.460069</td>
      <td>1.174341</td>
      <td>-0.100149</td>
      <td>-0.236140</td>
      <td>0.240198</td>
      <td>-0.887610</td>
      <td>-0.115905</td>
      <td>-0.219065</td>
      <td>0.171106</td>
      <td>0.398773</td>
      <td>-0.056498</td>
      <td>-0.018027</td>
      <td>-0.017969</td>
      <td>-0.297898</td>
      <td>0.123588</td>
      <td>-1.224404</td>
      <td>-0.351934</td>
      <td>0.080229</td>
      <td>-0.495891</td>
      <td>-0.231249</td>
      <td>-1.153500</td>
      <td>0.174909</td>
      <td>-0.123904</td>
      <td>-0.010437</td>
      <td>0.182141</td>
      <td>-0.950666</td>
      <td>-0.586138</td>
      <td>-0.095775</td>
      <td>0.440297</td>
      <td>-1.552653</td>
      <td>0.978396</td>
      <td>0.176474</td>
      <td>-0.535856</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.548285</td>
      <td>-0.217791</td>
      <td>0.091435</td>
      <td>-0.427838</td>
      <td>-0.044106</td>
      <td>0.462177</td>
      <td>0.163144</td>
      <td>-0.190558</td>
      <td>2.012075</td>
      <td>0.440538</td>
      <td>-0.267535</td>
      <td>-0.583548</td>
      <td>0.489033</td>
      <td>-0.144055</td>
      <td>-1.306225</td>
      <td>-1.239020</td>
      <td>-0.545934</td>
      <td>1.005601</td>
      <td>-0.349294</td>
      <td>-0.210497</td>
      <td>0.380636</td>
      <td>-0.478978</td>
      <td>-0.343263</td>
      <td>0.841276</td>
      <td>0.183771</td>
      <td>0.002492</td>
      <td>-1.250002</td>
      <td>-0.160755</td>
      <td>-0.578159</td>
      <td>-0.045137</td>
      <td>0.165216</td>
      <td>0.100999</td>
      <td>0.342883</td>
      <td>0.597872</td>
      <td>0.069217</td>
      <td>-0.883006</td>
      <td>-0.217063</td>
      <td>-0.267024</td>
      <td>0.049552</td>
      <td>0.075943</td>
      <td>...</td>
      <td>-0.813809</td>
      <td>-0.609553</td>
      <td>0.371379</td>
      <td>0.628544</td>
      <td>0.281622</td>
      <td>0.380651</td>
      <td>0.840086</td>
      <td>0.147517</td>
      <td>0.522637</td>
      <td>0.146601</td>
      <td>0.357069</td>
      <td>0.686676</td>
      <td>0.679425</td>
      <td>0.363174</td>
      <td>0.643232</td>
      <td>1.048727</td>
      <td>-0.291464</td>
      <td>0.343130</td>
      <td>-0.144019</td>
      <td>-0.701224</td>
      <td>-0.384268</td>
      <td>-0.304365</td>
      <td>-0.191058</td>
      <td>0.011347</td>
      <td>-0.651436</td>
      <td>0.026450</td>
      <td>-0.173750</td>
      <td>-0.603492</td>
      <td>0.013828</td>
      <td>0.350191</td>
      <td>0.191186</td>
      <td>-0.369286</td>
      <td>-0.276714</td>
      <td>0.088484</td>
      <td>0.480143</td>
      <td>1.342056</td>
      <td>0.644847</td>
      <td>0.778684</td>
      <td>0.199922</td>
      <td>0.317224</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.218653</td>
      <td>0.156791</td>
      <td>0.962966</td>
      <td>0.923574</td>
      <td>0.446836</td>
      <td>0.814073</td>
      <td>1.459199</td>
      <td>-0.335624</td>
      <td>0.396800</td>
      <td>-0.333700</td>
      <td>0.499343</td>
      <td>0.465704</td>
      <td>1.067565</td>
      <td>0.066140</td>
      <td>-0.443710</td>
      <td>0.104271</td>
      <td>-0.115173</td>
      <td>-0.104754</td>
      <td>-0.245313</td>
      <td>0.622866</td>
      <td>-0.541530</td>
      <td>-0.220364</td>
      <td>0.280665</td>
      <td>0.534200</td>
      <td>0.227545</td>
      <td>-0.814306</td>
      <td>-1.019030</td>
      <td>0.689924</td>
      <td>0.768326</td>
      <td>-0.753861</td>
      <td>-0.651520</td>
      <td>0.314342</td>
      <td>-0.796719</td>
      <td>-0.679280</td>
      <td>-0.694425</td>
      <td>0.195573</td>
      <td>0.187795</td>
      <td>0.894941</td>
      <td>-0.469966</td>
      <td>0.603312</td>
      <td>...</td>
      <td>1.770402</td>
      <td>0.468384</td>
      <td>0.341718</td>
      <td>0.336293</td>
      <td>-0.132136</td>
      <td>0.074430</td>
      <td>-0.843204</td>
      <td>-0.471483</td>
      <td>0.733525</td>
      <td>0.015452</td>
      <td>0.513392</td>
      <td>0.096324</td>
      <td>0.307374</td>
      <td>-0.667453</td>
      <td>0.018733</td>
      <td>-1.513694</td>
      <td>-0.162632</td>
      <td>0.270280</td>
      <td>-0.200670</td>
      <td>-0.435009</td>
      <td>-0.154877</td>
      <td>-0.717318</td>
      <td>-0.408564</td>
      <td>-0.593581</td>
      <td>0.109199</td>
      <td>0.222510</td>
      <td>-0.991140</td>
      <td>0.393434</td>
      <td>0.627336</td>
      <td>0.425957</td>
      <td>-0.857956</td>
      <td>-0.027021</td>
      <td>0.267230</td>
      <td>-1.014124</td>
      <td>-0.201470</td>
      <td>0.299310</td>
      <td>-0.597726</td>
      <td>1.570597</td>
      <td>0.643537</td>
      <td>-0.860818</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.088354</td>
      <td>-0.256555</td>
      <td>-0.799413</td>
      <td>0.364079</td>
      <td>-0.170016</td>
      <td>0.322783</td>
      <td>0.322568</td>
      <td>0.841618</td>
      <td>-0.396327</td>
      <td>-0.281411</td>
      <td>0.772723</td>
      <td>-0.265717</td>
      <td>0.452979</td>
      <td>-0.461813</td>
      <td>-0.683759</td>
      <td>0.027753</td>
      <td>0.494568</td>
      <td>0.016802</td>
      <td>-0.043624</td>
      <td>0.302439</td>
      <td>-0.133616</td>
      <td>-0.108382</td>
      <td>0.520288</td>
      <td>0.830246</td>
      <td>0.785080</td>
      <td>0.191611</td>
      <td>-0.283348</td>
      <td>0.085239</td>
      <td>0.226721</td>
      <td>0.574035</td>
      <td>-0.216033</td>
      <td>0.860677</td>
      <td>0.926726</td>
      <td>-0.270236</td>
      <td>-0.410110</td>
      <td>0.447336</td>
      <td>1.169528</td>
      <td>1.013110</td>
      <td>0.229004</td>
      <td>0.451112</td>
      <td>...</td>
      <td>-0.181946</td>
      <td>-0.275377</td>
      <td>-0.170721</td>
      <td>0.274971</td>
      <td>0.313676</td>
      <td>-0.450376</td>
      <td>-0.193462</td>
      <td>0.129508</td>
      <td>0.617245</td>
      <td>0.893863</td>
      <td>1.522610</td>
      <td>0.364574</td>
      <td>0.227094</td>
      <td>-0.245976</td>
      <td>-0.112699</td>
      <td>0.660468</td>
      <td>0.651653</td>
      <td>0.614609</td>
      <td>1.002560</td>
      <td>-0.088660</td>
      <td>-0.044161</td>
      <td>-0.617359</td>
      <td>-0.567154</td>
      <td>-0.349215</td>
      <td>-0.951960</td>
      <td>-0.239352</td>
      <td>-0.125839</td>
      <td>-0.270338</td>
      <td>-0.342815</td>
      <td>-0.135128</td>
      <td>-0.138732</td>
      <td>-1.314391</td>
      <td>-0.600211</td>
      <td>0.779929</td>
      <td>0.600599</td>
      <td>0.151686</td>
      <td>-0.115451</td>
      <td>-1.412721</td>
      <td>-0.653401</td>
      <td>-0.626868</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 103 columns</p>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f4dc68d0fd0&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.132683  0.040728  27.811263  3.170119e-170  1.052859  1.212508
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.549 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>