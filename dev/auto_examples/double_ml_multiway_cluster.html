
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.0.1 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="http://doubleml.org"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>     to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.576307</td>
      <td>0.272603</td>
      <td>-0.081173</td>
      <td>0.263116</td>
      <td>-0.637588</td>
      <td>-0.693243</td>
      <td>-0.477677</td>
      <td>0.625858</td>
      <td>1.213725</td>
      <td>-0.006776</td>
      <td>-0.404789</td>
      <td>-0.369346</td>
      <td>1.023826</td>
      <td>1.210718</td>
      <td>-0.064328</td>
      <td>-0.107194</td>
      <td>-0.375979</td>
      <td>0.871253</td>
      <td>0.129564</td>
      <td>-0.213021</td>
      <td>-0.325712</td>
      <td>-0.133342</td>
      <td>-0.311753</td>
      <td>0.837813</td>
      <td>0.674729</td>
      <td>0.903604</td>
      <td>-0.858588</td>
      <td>-0.081575</td>
      <td>-0.802518</td>
      <td>-1.146107</td>
      <td>0.333823</td>
      <td>0.908069</td>
      <td>0.896655</td>
      <td>0.148572</td>
      <td>-0.752305</td>
      <td>0.257200</td>
      <td>0.041073</td>
      <td>-0.430206</td>
      <td>-0.919511</td>
      <td>-0.007375</td>
      <td>...</td>
      <td>0.043573</td>
      <td>1.061494</td>
      <td>-0.451380</td>
      <td>-0.026657</td>
      <td>-0.690691</td>
      <td>-0.998678</td>
      <td>0.329446</td>
      <td>0.429288</td>
      <td>0.730368</td>
      <td>-0.464037</td>
      <td>-0.278683</td>
      <td>-0.817076</td>
      <td>0.047568</td>
      <td>0.864049</td>
      <td>-0.145152</td>
      <td>-0.750831</td>
      <td>0.678937</td>
      <td>0.440477</td>
      <td>0.688915</td>
      <td>0.493648</td>
      <td>0.140561</td>
      <td>-0.419797</td>
      <td>-0.343612</td>
      <td>-0.047691</td>
      <td>-0.129633</td>
      <td>0.475759</td>
      <td>0.355901</td>
      <td>0.619545</td>
      <td>0.472917</td>
      <td>0.652213</td>
      <td>-0.230168</td>
      <td>-0.510480</td>
      <td>0.483432</td>
      <td>-0.716582</td>
      <td>0.132412</td>
      <td>0.624241</td>
      <td>0.909669</td>
      <td>1.150663</td>
      <td>0.791522</td>
      <td>0.592213</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.393936</td>
      <td>0.139720</td>
      <td>0.075671</td>
      <td>1.188279</td>
      <td>0.052579</td>
      <td>-1.057868</td>
      <td>-0.937466</td>
      <td>-0.403414</td>
      <td>-0.153078</td>
      <td>-0.232659</td>
      <td>-0.967867</td>
      <td>0.543365</td>
      <td>1.142432</td>
      <td>1.258769</td>
      <td>0.020430</td>
      <td>-0.495456</td>
      <td>-0.488562</td>
      <td>0.105848</td>
      <td>0.821825</td>
      <td>-0.262311</td>
      <td>0.446284</td>
      <td>-0.259245</td>
      <td>-0.068000</td>
      <td>-0.084612</td>
      <td>1.160721</td>
      <td>0.461267</td>
      <td>-0.113220</td>
      <td>0.226372</td>
      <td>0.725708</td>
      <td>0.241679</td>
      <td>0.965375</td>
      <td>1.079684</td>
      <td>0.364078</td>
      <td>-0.904146</td>
      <td>-0.640882</td>
      <td>-0.139511</td>
      <td>0.034948</td>
      <td>-0.847250</td>
      <td>-0.120270</td>
      <td>-0.561031</td>
      <td>...</td>
      <td>1.092993</td>
      <td>0.232054</td>
      <td>0.117679</td>
      <td>0.481657</td>
      <td>-0.481194</td>
      <td>0.451651</td>
      <td>0.084281</td>
      <td>0.480568</td>
      <td>0.562088</td>
      <td>-0.190427</td>
      <td>-0.170085</td>
      <td>-0.231432</td>
      <td>0.773065</td>
      <td>-0.035214</td>
      <td>-0.264758</td>
      <td>0.300750</td>
      <td>0.490723</td>
      <td>0.281889</td>
      <td>-0.932883</td>
      <td>0.325951</td>
      <td>-0.052984</td>
      <td>-0.348957</td>
      <td>0.005675</td>
      <td>-0.363431</td>
      <td>-1.138421</td>
      <td>-0.076192</td>
      <td>0.088931</td>
      <td>0.404061</td>
      <td>-0.078502</td>
      <td>0.605553</td>
      <td>0.133091</td>
      <td>-0.834428</td>
      <td>-1.010175</td>
      <td>-0.334727</td>
      <td>-0.259436</td>
      <td>0.149020</td>
      <td>-0.140652</td>
      <td>0.032376</td>
      <td>-0.997519</td>
      <td>-0.241483</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.516675</td>
      <td>0.285303</td>
      <td>-0.203237</td>
      <td>0.032424</td>
      <td>0.061923</td>
      <td>0.229646</td>
      <td>-0.447648</td>
      <td>-0.585921</td>
      <td>-0.762778</td>
      <td>-0.956445</td>
      <td>-0.377465</td>
      <td>-0.460719</td>
      <td>0.251169</td>
      <td>0.678117</td>
      <td>0.709173</td>
      <td>-0.481374</td>
      <td>-0.136857</td>
      <td>1.338874</td>
      <td>0.216157</td>
      <td>0.207940</td>
      <td>-0.726431</td>
      <td>0.510174</td>
      <td>-0.831826</td>
      <td>0.050765</td>
      <td>0.656774</td>
      <td>0.099596</td>
      <td>-0.368709</td>
      <td>1.098563</td>
      <td>0.535750</td>
      <td>0.202029</td>
      <td>0.573201</td>
      <td>0.134219</td>
      <td>0.949021</td>
      <td>-0.779956</td>
      <td>-0.011322</td>
      <td>-0.504272</td>
      <td>-0.290282</td>
      <td>0.591463</td>
      <td>-0.493674</td>
      <td>0.747249</td>
      <td>...</td>
      <td>1.613684</td>
      <td>0.113682</td>
      <td>0.112319</td>
      <td>-0.045718</td>
      <td>1.250117</td>
      <td>0.252737</td>
      <td>-0.744228</td>
      <td>-0.080163</td>
      <td>-0.598410</td>
      <td>-0.099226</td>
      <td>-0.948862</td>
      <td>-0.244753</td>
      <td>-0.314470</td>
      <td>-0.321055</td>
      <td>0.033736</td>
      <td>0.041853</td>
      <td>-0.193461</td>
      <td>-0.130740</td>
      <td>0.364257</td>
      <td>0.023510</td>
      <td>0.701109</td>
      <td>-0.173468</td>
      <td>0.262979</td>
      <td>-0.161668</td>
      <td>-0.220953</td>
      <td>0.203090</td>
      <td>-0.353501</td>
      <td>0.439516</td>
      <td>-0.099408</td>
      <td>0.175901</td>
      <td>-0.952809</td>
      <td>-1.368894</td>
      <td>0.151417</td>
      <td>-0.287238</td>
      <td>-0.397169</td>
      <td>-1.172493</td>
      <td>-0.465695</td>
      <td>0.023211</td>
      <td>-0.671519</td>
      <td>-0.175597</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.314162</td>
      <td>1.098743</td>
      <td>-1.386047</td>
      <td>1.070486</td>
      <td>-0.787036</td>
      <td>-0.087889</td>
      <td>-0.235478</td>
      <td>-0.959759</td>
      <td>0.186220</td>
      <td>0.020581</td>
      <td>-0.408926</td>
      <td>0.264020</td>
      <td>-0.771553</td>
      <td>-0.227579</td>
      <td>-0.292533</td>
      <td>0.490806</td>
      <td>0.438161</td>
      <td>-0.140817</td>
      <td>0.212938</td>
      <td>0.435515</td>
      <td>0.471628</td>
      <td>1.417577</td>
      <td>-0.500228</td>
      <td>0.090825</td>
      <td>-0.245782</td>
      <td>-0.335428</td>
      <td>0.462642</td>
      <td>1.060188</td>
      <td>0.505884</td>
      <td>-0.238070</td>
      <td>0.072526</td>
      <td>-0.282981</td>
      <td>0.163090</td>
      <td>-0.792363</td>
      <td>-0.681618</td>
      <td>0.853326</td>
      <td>0.074360</td>
      <td>0.218835</td>
      <td>-0.011977</td>
      <td>0.103178</td>
      <td>...</td>
      <td>0.064771</td>
      <td>-0.130408</td>
      <td>-0.512713</td>
      <td>-0.069755</td>
      <td>0.068090</td>
      <td>-0.095970</td>
      <td>-0.736981</td>
      <td>-0.250663</td>
      <td>-0.478583</td>
      <td>-0.223540</td>
      <td>-0.081245</td>
      <td>0.091255</td>
      <td>0.782144</td>
      <td>-0.326954</td>
      <td>-0.357894</td>
      <td>-0.930332</td>
      <td>-1.795692</td>
      <td>-0.418371</td>
      <td>0.742216</td>
      <td>-0.359895</td>
      <td>-0.407931</td>
      <td>-0.771262</td>
      <td>0.338135</td>
      <td>-0.762826</td>
      <td>-0.176684</td>
      <td>0.610532</td>
      <td>0.352545</td>
      <td>0.883372</td>
      <td>0.131890</td>
      <td>-0.221522</td>
      <td>-0.193540</td>
      <td>-0.624281</td>
      <td>-0.195722</td>
      <td>-0.652636</td>
      <td>0.428451</td>
      <td>-0.133015</td>
      <td>-0.130232</td>
      <td>-2.251426</td>
      <td>-1.862317</td>
      <td>-0.461968</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.295588</td>
      <td>-0.137756</td>
      <td>-0.164606</td>
      <td>0.243413</td>
      <td>0.217037</td>
      <td>-0.881956</td>
      <td>-1.107567</td>
      <td>-0.503030</td>
      <td>0.115551</td>
      <td>-0.854130</td>
      <td>0.201105</td>
      <td>0.707298</td>
      <td>0.632987</td>
      <td>-0.264544</td>
      <td>-0.139461</td>
      <td>-0.390203</td>
      <td>0.005940</td>
      <td>0.423302</td>
      <td>0.551977</td>
      <td>-0.433442</td>
      <td>-0.408618</td>
      <td>-0.294999</td>
      <td>0.304134</td>
      <td>1.406413</td>
      <td>1.005015</td>
      <td>0.595832</td>
      <td>0.262378</td>
      <td>0.792165</td>
      <td>1.288038</td>
      <td>0.349356</td>
      <td>0.736907</td>
      <td>1.042031</td>
      <td>0.679507</td>
      <td>0.306351</td>
      <td>0.534830</td>
      <td>0.846252</td>
      <td>-0.198475</td>
      <td>-0.042190</td>
      <td>-0.275506</td>
      <td>0.603119</td>
      <td>...</td>
      <td>0.755719</td>
      <td>0.871928</td>
      <td>0.429696</td>
      <td>0.756599</td>
      <td>0.863249</td>
      <td>-0.105724</td>
      <td>0.364012</td>
      <td>0.191152</td>
      <td>-1.088828</td>
      <td>-0.099898</td>
      <td>-0.399953</td>
      <td>-0.327104</td>
      <td>1.186789</td>
      <td>-0.822388</td>
      <td>0.493901</td>
      <td>-0.424110</td>
      <td>-0.065894</td>
      <td>-0.119374</td>
      <td>0.192177</td>
      <td>0.249338</td>
      <td>-0.344768</td>
      <td>0.185893</td>
      <td>-0.458430</td>
      <td>0.631291</td>
      <td>-0.606769</td>
      <td>1.202083</td>
      <td>0.118202</td>
      <td>0.261702</td>
      <td>-0.633744</td>
      <td>0.230713</td>
      <td>0.451394</td>
      <td>0.132634</td>
      <td>0.080830</td>
      <td>-0.870837</td>
      <td>0.184470</td>
      <td>-0.058555</td>
      <td>0.401453</td>
      <td>-1.568312</td>
      <td>-0.947174</td>
      <td>-0.575721</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.083108</td>
      <td>-0.895696</td>
      <td>-0.145010</td>
      <td>-0.274010</td>
      <td>0.038358</td>
      <td>-0.633854</td>
      <td>0.350515</td>
      <td>0.368448</td>
      <td>0.538916</td>
      <td>-0.766712</td>
      <td>-1.450344</td>
      <td>-0.167079</td>
      <td>1.051650</td>
      <td>-0.275415</td>
      <td>-0.159155</td>
      <td>0.181822</td>
      <td>0.628058</td>
      <td>1.343449</td>
      <td>1.383150</td>
      <td>0.876758</td>
      <td>1.421566</td>
      <td>0.622317</td>
      <td>1.131835</td>
      <td>-0.311215</td>
      <td>0.666043</td>
      <td>0.575735</td>
      <td>0.832727</td>
      <td>0.413368</td>
      <td>-1.553521</td>
      <td>-0.193716</td>
      <td>-0.293414</td>
      <td>0.632505</td>
      <td>-0.854302</td>
      <td>-0.589209</td>
      <td>0.034631</td>
      <td>-0.565989</td>
      <td>-0.030417</td>
      <td>-0.438356</td>
      <td>-0.389956</td>
      <td>-1.163212</td>
      <td>...</td>
      <td>0.630848</td>
      <td>0.236664</td>
      <td>0.938843</td>
      <td>1.371988</td>
      <td>0.962806</td>
      <td>0.484568</td>
      <td>-0.330222</td>
      <td>-0.582232</td>
      <td>0.182627</td>
      <td>-0.755863</td>
      <td>-0.421257</td>
      <td>0.213961</td>
      <td>0.249593</td>
      <td>0.076158</td>
      <td>1.081396</td>
      <td>-0.117505</td>
      <td>0.108107</td>
      <td>0.068800</td>
      <td>1.018778</td>
      <td>0.049994</td>
      <td>-0.593369</td>
      <td>-0.433528</td>
      <td>-0.485574</td>
      <td>-0.275289</td>
      <td>-0.557923</td>
      <td>1.057976</td>
      <td>-0.414745</td>
      <td>0.027054</td>
      <td>0.261166</td>
      <td>0.318528</td>
      <td>0.226934</td>
      <td>-0.670700</td>
      <td>-0.659533</td>
      <td>0.101344</td>
      <td>-0.120742</td>
      <td>-0.014903</td>
      <td>0.692741</td>
      <td>0.332361</td>
      <td>0.257946</td>
      <td>-0.279543</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.504329</td>
      <td>-0.342936</td>
      <td>0.269975</td>
      <td>-0.279082</td>
      <td>-0.680272</td>
      <td>-0.052233</td>
      <td>0.291879</td>
      <td>0.546310</td>
      <td>-0.242313</td>
      <td>-0.017046</td>
      <td>-0.807132</td>
      <td>0.071155</td>
      <td>0.795323</td>
      <td>1.518306</td>
      <td>1.025032</td>
      <td>0.890581</td>
      <td>0.536560</td>
      <td>1.330461</td>
      <td>1.641237</td>
      <td>1.346613</td>
      <td>0.668001</td>
      <td>0.951952</td>
      <td>-0.073386</td>
      <td>0.159089</td>
      <td>0.660071</td>
      <td>1.153510</td>
      <td>0.402793</td>
      <td>1.259196</td>
      <td>0.412085</td>
      <td>0.550500</td>
      <td>1.253959</td>
      <td>1.110910</td>
      <td>-0.061805</td>
      <td>-0.875387</td>
      <td>-0.145549</td>
      <td>0.543074</td>
      <td>1.002809</td>
      <td>-0.884094</td>
      <td>-0.694160</td>
      <td>-0.136738</td>
      <td>...</td>
      <td>0.226833</td>
      <td>-0.202810</td>
      <td>-0.788808</td>
      <td>0.219881</td>
      <td>0.229848</td>
      <td>-0.127822</td>
      <td>-0.138182</td>
      <td>-0.768000</td>
      <td>0.211637</td>
      <td>-0.124018</td>
      <td>-0.879088</td>
      <td>0.053220</td>
      <td>-0.439199</td>
      <td>-0.027460</td>
      <td>0.530044</td>
      <td>0.252701</td>
      <td>0.218759</td>
      <td>-0.019024</td>
      <td>0.439583</td>
      <td>-1.340085</td>
      <td>-0.065197</td>
      <td>-0.842979</td>
      <td>-0.943045</td>
      <td>0.403880</td>
      <td>-0.637354</td>
      <td>0.378468</td>
      <td>0.724211</td>
      <td>-0.152517</td>
      <td>-0.663066</td>
      <td>0.210028</td>
      <td>0.588235</td>
      <td>-0.585299</td>
      <td>-0.509868</td>
      <td>-0.798399</td>
      <td>-0.234640</td>
      <td>-0.633157</td>
      <td>-0.262517</td>
      <td>-1.440569</td>
      <td>-1.524314</td>
      <td>-0.315688</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.009174</td>
      <td>0.680135</td>
      <td>-1.366378</td>
      <td>0.415888</td>
      <td>-0.430990</td>
      <td>0.365384</td>
      <td>0.047316</td>
      <td>0.076634</td>
      <td>0.420558</td>
      <td>-0.392132</td>
      <td>-0.100778</td>
      <td>-0.544864</td>
      <td>0.149601</td>
      <td>0.345085</td>
      <td>0.719763</td>
      <td>0.925830</td>
      <td>0.431847</td>
      <td>0.393632</td>
      <td>0.500476</td>
      <td>0.777737</td>
      <td>0.138055</td>
      <td>0.478597</td>
      <td>-0.348761</td>
      <td>-0.709905</td>
      <td>0.024722</td>
      <td>-0.405767</td>
      <td>0.575661</td>
      <td>0.417314</td>
      <td>0.190954</td>
      <td>-0.618073</td>
      <td>0.535707</td>
      <td>0.301144</td>
      <td>0.116681</td>
      <td>0.349059</td>
      <td>-0.215085</td>
      <td>-0.873288</td>
      <td>0.311431</td>
      <td>0.161891</td>
      <td>0.983833</td>
      <td>-0.030507</td>
      <td>...</td>
      <td>0.012139</td>
      <td>0.231334</td>
      <td>0.103597</td>
      <td>0.085260</td>
      <td>0.463786</td>
      <td>0.894086</td>
      <td>0.346782</td>
      <td>0.279656</td>
      <td>0.490004</td>
      <td>-0.663566</td>
      <td>0.040777</td>
      <td>-0.533884</td>
      <td>-1.586607</td>
      <td>-0.064174</td>
      <td>0.181165</td>
      <td>0.946969</td>
      <td>0.032244</td>
      <td>-0.143397</td>
      <td>0.254550</td>
      <td>1.335618</td>
      <td>0.257958</td>
      <td>-0.606514</td>
      <td>-0.513034</td>
      <td>0.687021</td>
      <td>-0.148641</td>
      <td>-0.036037</td>
      <td>1.292390</td>
      <td>0.854572</td>
      <td>-0.838366</td>
      <td>-0.294854</td>
      <td>0.822162</td>
      <td>0.236607</td>
      <td>-0.082822</td>
      <td>-0.221589</td>
      <td>-0.473337</td>
      <td>-0.270965</td>
      <td>-0.309735</td>
      <td>0.066689</td>
      <td>-0.555890</td>
      <td>-0.301522</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.935333</td>
      <td>0.096258</td>
      <td>-0.015253</td>
      <td>0.435039</td>
      <td>-0.219344</td>
      <td>-0.437132</td>
      <td>-1.657965</td>
      <td>0.154644</td>
      <td>0.044658</td>
      <td>0.385043</td>
      <td>-0.984521</td>
      <td>0.018760</td>
      <td>-0.995571</td>
      <td>-0.245783</td>
      <td>0.094453</td>
      <td>0.097676</td>
      <td>-0.439767</td>
      <td>0.306416</td>
      <td>0.751712</td>
      <td>0.423696</td>
      <td>-0.299371</td>
      <td>-0.976919</td>
      <td>-0.563709</td>
      <td>-0.118748</td>
      <td>0.166739</td>
      <td>-0.262887</td>
      <td>0.929037</td>
      <td>0.245890</td>
      <td>0.607176</td>
      <td>1.181663</td>
      <td>0.588418</td>
      <td>1.242491</td>
      <td>1.044500</td>
      <td>0.299683</td>
      <td>0.817172</td>
      <td>0.255959</td>
      <td>0.992261</td>
      <td>0.325452</td>
      <td>-0.722564</td>
      <td>-0.902854</td>
      <td>...</td>
      <td>0.694248</td>
      <td>-0.577648</td>
      <td>-1.121897</td>
      <td>-0.003788</td>
      <td>-0.146858</td>
      <td>-1.059281</td>
      <td>-0.399267</td>
      <td>-0.113004</td>
      <td>0.020939</td>
      <td>-0.835445</td>
      <td>-0.500707</td>
      <td>-0.755889</td>
      <td>-0.171200</td>
      <td>0.098702</td>
      <td>1.002068</td>
      <td>0.503976</td>
      <td>0.189235</td>
      <td>0.655612</td>
      <td>-0.394868</td>
      <td>0.647584</td>
      <td>0.730582</td>
      <td>0.622727</td>
      <td>-0.063282</td>
      <td>0.301211</td>
      <td>-0.527843</td>
      <td>0.653949</td>
      <td>0.208505</td>
      <td>1.194245</td>
      <td>1.534540</td>
      <td>0.831185</td>
      <td>-0.130871</td>
      <td>-1.260408</td>
      <td>0.174142</td>
      <td>-0.630844</td>
      <td>-0.445068</td>
      <td>-0.704856</td>
      <td>1.219423</td>
      <td>0.215761</td>
      <td>0.096900</td>
      <td>0.004256</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.543529</td>
      <td>0.368945</td>
      <td>-0.282735</td>
      <td>-0.244277</td>
      <td>-0.847077</td>
      <td>-0.171161</td>
      <td>-0.771896</td>
      <td>0.472552</td>
      <td>-0.025595</td>
      <td>-0.619206</td>
      <td>-0.172585</td>
      <td>0.237513</td>
      <td>-0.053593</td>
      <td>0.282161</td>
      <td>0.874298</td>
      <td>0.572652</td>
      <td>1.264484</td>
      <td>0.041607</td>
      <td>0.305752</td>
      <td>0.677594</td>
      <td>0.190019</td>
      <td>0.501024</td>
      <td>0.427265</td>
      <td>0.437534</td>
      <td>0.359777</td>
      <td>0.724298</td>
      <td>0.076383</td>
      <td>0.285507</td>
      <td>0.078318</td>
      <td>0.180037</td>
      <td>0.557159</td>
      <td>0.985743</td>
      <td>1.284359</td>
      <td>0.550207</td>
      <td>0.994913</td>
      <td>0.091053</td>
      <td>0.574758</td>
      <td>-0.058197</td>
      <td>-1.604674</td>
      <td>-1.645575</td>
      <td>...</td>
      <td>-0.052693</td>
      <td>-0.624035</td>
      <td>-0.887593</td>
      <td>0.015859</td>
      <td>0.714182</td>
      <td>-0.454374</td>
      <td>-0.250840</td>
      <td>-0.545245</td>
      <td>-0.158155</td>
      <td>-0.129305</td>
      <td>0.215010</td>
      <td>1.382393</td>
      <td>0.793037</td>
      <td>1.008824</td>
      <td>0.873542</td>
      <td>0.397956</td>
      <td>-0.323157</td>
      <td>-0.426664</td>
      <td>0.103137</td>
      <td>-0.872111</td>
      <td>-0.644520</td>
      <td>-0.501245</td>
      <td>-0.043075</td>
      <td>0.156644</td>
      <td>-0.847202</td>
      <td>0.739123</td>
      <td>-0.837437</td>
      <td>1.062823</td>
      <td>0.353581</td>
      <td>1.328609</td>
      <td>0.408207</td>
      <td>-0.086470</td>
      <td>0.533715</td>
      <td>-0.441584</td>
      <td>0.130593</td>
      <td>-0.170984</td>
      <td>-0.077148</td>
      <td>3.215016</td>
      <td>1.772248</td>
      <td>0.623082</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-0.177129</td>
      <td>0.779071</td>
      <td>0.086237</td>
      <td>0.347493</td>
      <td>0.024311</td>
      <td>-0.095358</td>
      <td>0.707655</td>
      <td>1.417294</td>
      <td>0.387364</td>
      <td>-0.110683</td>
      <td>0.128560</td>
      <td>-0.980907</td>
      <td>0.208950</td>
      <td>0.312433</td>
      <td>0.262099</td>
      <td>0.454290</td>
      <td>-0.658643</td>
      <td>-0.649213</td>
      <td>1.090037</td>
      <td>0.146302</td>
      <td>0.011265</td>
      <td>-0.481257</td>
      <td>-0.215112</td>
      <td>-0.525740</td>
      <td>0.418923</td>
      <td>1.014033</td>
      <td>1.816156</td>
      <td>1.349339</td>
      <td>0.379227</td>
      <td>0.754016</td>
      <td>0.236761</td>
      <td>0.499280</td>
      <td>-0.047428</td>
      <td>-0.403261</td>
      <td>-0.950445</td>
      <td>0.299232</td>
      <td>0.570657</td>
      <td>-0.059589</td>
      <td>-0.148670</td>
      <td>-0.941156</td>
      <td>...</td>
      <td>0.994649</td>
      <td>-0.573032</td>
      <td>0.140009</td>
      <td>0.498949</td>
      <td>0.149398</td>
      <td>-0.427185</td>
      <td>0.317274</td>
      <td>0.872913</td>
      <td>0.538512</td>
      <td>-0.489259</td>
      <td>-1.155664</td>
      <td>0.286655</td>
      <td>0.099707</td>
      <td>0.354498</td>
      <td>-0.029132</td>
      <td>0.404423</td>
      <td>0.184504</td>
      <td>-0.876388</td>
      <td>-0.583877</td>
      <td>0.043454</td>
      <td>0.119199</td>
      <td>0.289477</td>
      <td>-0.586861</td>
      <td>-0.204225</td>
      <td>-0.927633</td>
      <td>-0.150541</td>
      <td>0.435662</td>
      <td>-0.018418</td>
      <td>-0.767392</td>
      <td>-0.075993</td>
      <td>0.207946</td>
      <td>-0.289458</td>
      <td>-0.664665</td>
      <td>-0.019783</td>
      <td>0.038258</td>
      <td>-0.244024</td>
      <td>-0.103392</td>
      <td>-1.063035</td>
      <td>-0.758998</td>
      <td>0.335477</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.199302</td>
      <td>-0.346834</td>
      <td>-0.239492</td>
      <td>0.488043</td>
      <td>-0.525073</td>
      <td>0.940907</td>
      <td>0.410055</td>
      <td>-0.289555</td>
      <td>0.210478</td>
      <td>-0.656398</td>
      <td>-0.992407</td>
      <td>-0.206316</td>
      <td>-0.077257</td>
      <td>-0.291965</td>
      <td>-0.446311</td>
      <td>-0.263736</td>
      <td>-0.918315</td>
      <td>-0.261121</td>
      <td>0.421435</td>
      <td>0.878106</td>
      <td>-0.023001</td>
      <td>0.013310</td>
      <td>-0.474226</td>
      <td>0.677639</td>
      <td>0.361178</td>
      <td>0.476471</td>
      <td>1.017545</td>
      <td>0.655383</td>
      <td>1.517099</td>
      <td>-0.768033</td>
      <td>0.759946</td>
      <td>0.186912</td>
      <td>0.726763</td>
      <td>0.219470</td>
      <td>-1.411108</td>
      <td>0.928480</td>
      <td>0.206472</td>
      <td>0.211870</td>
      <td>-0.546134</td>
      <td>0.248179</td>
      <td>...</td>
      <td>1.381816</td>
      <td>0.589865</td>
      <td>0.181567</td>
      <td>-0.170389</td>
      <td>0.083439</td>
      <td>-0.063401</td>
      <td>-0.351531</td>
      <td>0.477049</td>
      <td>-0.063111</td>
      <td>-0.394912</td>
      <td>-0.975854</td>
      <td>-1.294642</td>
      <td>-0.593962</td>
      <td>-0.598871</td>
      <td>0.339572</td>
      <td>0.315497</td>
      <td>0.243000</td>
      <td>0.306812</td>
      <td>0.048591</td>
      <td>-0.884443</td>
      <td>0.046964</td>
      <td>-0.748055</td>
      <td>0.527912</td>
      <td>0.327775</td>
      <td>-0.589895</td>
      <td>0.196563</td>
      <td>0.668901</td>
      <td>0.881168</td>
      <td>0.066247</td>
      <td>0.473687</td>
      <td>-0.338717</td>
      <td>-0.209620</td>
      <td>-0.335762</td>
      <td>-0.866498</td>
      <td>-0.177820</td>
      <td>-0.458437</td>
      <td>-0.163750</td>
      <td>-0.662170</td>
      <td>-0.821975</td>
      <td>-0.988971</td>
    </tr>
    <tr>
      <th>12</th>
      <td>1.010029</td>
      <td>0.406333</td>
      <td>-0.251052</td>
      <td>0.256733</td>
      <td>0.483079</td>
      <td>-0.736701</td>
      <td>0.285048</td>
      <td>0.543026</td>
      <td>0.796925</td>
      <td>-0.619581</td>
      <td>-1.057729</td>
      <td>0.327966</td>
      <td>0.563914</td>
      <td>-0.081368</td>
      <td>0.152829</td>
      <td>-0.096820</td>
      <td>-0.941469</td>
      <td>0.146876</td>
      <td>0.635140</td>
      <td>-0.282331</td>
      <td>0.107831</td>
      <td>0.272740</td>
      <td>-0.556037</td>
      <td>-0.481014</td>
      <td>-0.238791</td>
      <td>-0.556143</td>
      <td>1.120399</td>
      <td>0.920701</td>
      <td>-0.295776</td>
      <td>-0.225771</td>
      <td>0.473883</td>
      <td>0.582306</td>
      <td>-0.256774</td>
      <td>-0.707108</td>
      <td>-0.795171</td>
      <td>0.081369</td>
      <td>0.837166</td>
      <td>-0.106648</td>
      <td>-0.464340</td>
      <td>-0.575253</td>
      <td>...</td>
      <td>-0.114531</td>
      <td>0.162576</td>
      <td>-0.397309</td>
      <td>0.179040</td>
      <td>0.024703</td>
      <td>0.069422</td>
      <td>0.897020</td>
      <td>0.325252</td>
      <td>-0.269093</td>
      <td>-0.727401</td>
      <td>-0.702926</td>
      <td>-0.779623</td>
      <td>-0.620658</td>
      <td>0.004217</td>
      <td>0.263903</td>
      <td>0.218140</td>
      <td>0.183091</td>
      <td>0.185668</td>
      <td>0.519441</td>
      <td>-0.341125</td>
      <td>-1.051111</td>
      <td>-0.799439</td>
      <td>-0.235573</td>
      <td>-0.676006</td>
      <td>0.018989</td>
      <td>0.364365</td>
      <td>-0.824760</td>
      <td>-0.344457</td>
      <td>0.402295</td>
      <td>-0.438239</td>
      <td>-0.749215</td>
      <td>-1.344778</td>
      <td>0.146114</td>
      <td>0.730522</td>
      <td>-0.179657</td>
      <td>-0.137030</td>
      <td>0.090727</td>
      <td>2.155201</td>
      <td>1.578931</td>
      <td>0.606611</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.390622</td>
      <td>0.587135</td>
      <td>0.117652</td>
      <td>1.129759</td>
      <td>0.714171</td>
      <td>0.643955</td>
      <td>-0.369754</td>
      <td>-0.367766</td>
      <td>0.500603</td>
      <td>-0.506469</td>
      <td>-0.065668</td>
      <td>-0.237660</td>
      <td>0.657224</td>
      <td>0.559484</td>
      <td>0.470154</td>
      <td>-0.038631</td>
      <td>-0.141219</td>
      <td>0.656866</td>
      <td>0.509859</td>
      <td>0.854313</td>
      <td>-0.529591</td>
      <td>0.158012</td>
      <td>-1.040331</td>
      <td>0.276402</td>
      <td>0.934536</td>
      <td>0.010496</td>
      <td>-0.340039</td>
      <td>-0.062464</td>
      <td>-0.093362</td>
      <td>0.230009</td>
      <td>-0.572274</td>
      <td>-0.624766</td>
      <td>0.012145</td>
      <td>-0.156996</td>
      <td>0.325264</td>
      <td>0.619072</td>
      <td>-0.044982</td>
      <td>-0.223602</td>
      <td>-1.141340</td>
      <td>0.070431</td>
      <td>...</td>
      <td>0.803239</td>
      <td>-0.266813</td>
      <td>0.879125</td>
      <td>0.149815</td>
      <td>0.534809</td>
      <td>-0.932165</td>
      <td>-0.464258</td>
      <td>-0.187774</td>
      <td>0.220243</td>
      <td>-1.021723</td>
      <td>-0.956785</td>
      <td>-0.207958</td>
      <td>-0.205145</td>
      <td>-0.746680</td>
      <td>0.195347</td>
      <td>0.236813</td>
      <td>-0.539044</td>
      <td>-0.356106</td>
      <td>-0.302821</td>
      <td>-1.099833</td>
      <td>0.114979</td>
      <td>0.130531</td>
      <td>0.046359</td>
      <td>-0.152990</td>
      <td>-0.355493</td>
      <td>0.876921</td>
      <td>0.198943</td>
      <td>-0.017952</td>
      <td>0.998027</td>
      <td>-1.010634</td>
      <td>0.045379</td>
      <td>-0.770530</td>
      <td>-0.107491</td>
      <td>0.675597</td>
      <td>-0.408303</td>
      <td>-0.656693</td>
      <td>-0.259096</td>
      <td>-0.267282</td>
      <td>-0.506370</td>
      <td>-0.327796</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.887516</td>
      <td>0.467979</td>
      <td>0.567902</td>
      <td>0.246267</td>
      <td>0.224756</td>
      <td>-0.040312</td>
      <td>-0.772586</td>
      <td>0.289836</td>
      <td>0.453332</td>
      <td>-0.401105</td>
      <td>-0.771165</td>
      <td>-0.041756</td>
      <td>-0.232732</td>
      <td>-0.624848</td>
      <td>-0.649800</td>
      <td>0.179943</td>
      <td>-0.482731</td>
      <td>0.107557</td>
      <td>-0.645725</td>
      <td>-0.848113</td>
      <td>-0.556231</td>
      <td>-0.915271</td>
      <td>-0.266428</td>
      <td>-1.092800</td>
      <td>-0.008066</td>
      <td>-0.630382</td>
      <td>0.409163</td>
      <td>0.826576</td>
      <td>-0.322582</td>
      <td>-1.035586</td>
      <td>1.333197</td>
      <td>0.669223</td>
      <td>0.352596</td>
      <td>-0.836234</td>
      <td>-0.538862</td>
      <td>-0.003482</td>
      <td>0.253465</td>
      <td>-1.621978</td>
      <td>-1.723330</td>
      <td>0.065474</td>
      <td>...</td>
      <td>-0.316640</td>
      <td>0.200765</td>
      <td>-0.134881</td>
      <td>-0.290715</td>
      <td>-0.127827</td>
      <td>0.414079</td>
      <td>1.485400</td>
      <td>0.722418</td>
      <td>0.257212</td>
      <td>0.545433</td>
      <td>-0.119242</td>
      <td>-0.530152</td>
      <td>1.658109</td>
      <td>-0.576893</td>
      <td>0.437165</td>
      <td>-0.264916</td>
      <td>-0.534675</td>
      <td>0.021139</td>
      <td>0.056460</td>
      <td>-0.146657</td>
      <td>-0.949234</td>
      <td>0.041254</td>
      <td>1.141083</td>
      <td>0.512914</td>
      <td>-0.640539</td>
      <td>1.185928</td>
      <td>-0.161004</td>
      <td>0.116262</td>
      <td>-0.491839</td>
      <td>0.237465</td>
      <td>0.174426</td>
      <td>-0.776409</td>
      <td>0.212395</td>
      <td>0.364497</td>
      <td>0.406741</td>
      <td>0.144852</td>
      <td>-0.152982</td>
      <td>2.564383</td>
      <td>1.389293</td>
      <td>0.339122</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.015049</td>
      <td>-0.374677</td>
      <td>0.188891</td>
      <td>1.181140</td>
      <td>0.015624</td>
      <td>-0.110929</td>
      <td>0.101268</td>
      <td>0.960550</td>
      <td>0.372841</td>
      <td>-0.071594</td>
      <td>-0.674495</td>
      <td>0.129253</td>
      <td>0.569522</td>
      <td>0.237420</td>
      <td>-0.523849</td>
      <td>0.283308</td>
      <td>1.099587</td>
      <td>0.361116</td>
      <td>0.184451</td>
      <td>-0.172530</td>
      <td>0.086330</td>
      <td>0.151208</td>
      <td>-0.731949</td>
      <td>0.068056</td>
      <td>0.148352</td>
      <td>0.232088</td>
      <td>0.014924</td>
      <td>0.287668</td>
      <td>-0.139712</td>
      <td>0.599385</td>
      <td>0.881075</td>
      <td>0.812600</td>
      <td>0.070306</td>
      <td>-0.495150</td>
      <td>-1.410665</td>
      <td>0.528022</td>
      <td>0.455826</td>
      <td>0.082109</td>
      <td>-0.831180</td>
      <td>-1.025628</td>
      <td>...</td>
      <td>0.860621</td>
      <td>-0.167826</td>
      <td>-0.694405</td>
      <td>-0.285661</td>
      <td>0.755918</td>
      <td>0.225065</td>
      <td>-0.041897</td>
      <td>0.032187</td>
      <td>-0.382032</td>
      <td>-0.509337</td>
      <td>-0.192658</td>
      <td>-0.246084</td>
      <td>0.500916</td>
      <td>-0.268539</td>
      <td>0.019078</td>
      <td>0.644932</td>
      <td>0.670900</td>
      <td>1.180034</td>
      <td>-0.742643</td>
      <td>-0.071913</td>
      <td>-0.293131</td>
      <td>0.027462</td>
      <td>-0.362096</td>
      <td>0.031188</td>
      <td>-0.884318</td>
      <td>0.132872</td>
      <td>0.045171</td>
      <td>0.576750</td>
      <td>-0.137047</td>
      <td>-0.459154</td>
      <td>0.155703</td>
      <td>-0.133350</td>
      <td>-0.242761</td>
      <td>-0.412275</td>
      <td>-0.294556</td>
      <td>0.239589</td>
      <td>0.600681</td>
      <td>0.124582</td>
      <td>-0.797737</td>
      <td>-1.552005</td>
    </tr>
    <tr>
      <th>16</th>
      <td>1.431408</td>
      <td>1.391204</td>
      <td>0.379537</td>
      <td>0.668408</td>
      <td>-0.220735</td>
      <td>0.183513</td>
      <td>-0.793874</td>
      <td>-0.074179</td>
      <td>-0.226683</td>
      <td>-0.216938</td>
      <td>-0.387269</td>
      <td>-1.335578</td>
      <td>-1.172957</td>
      <td>-0.709836</td>
      <td>-1.197211</td>
      <td>1.018882</td>
      <td>-0.896639</td>
      <td>-0.040608</td>
      <td>-1.145373</td>
      <td>-1.149987</td>
      <td>0.101034</td>
      <td>-0.605526</td>
      <td>-0.566653</td>
      <td>-0.561701</td>
      <td>0.102733</td>
      <td>0.990852</td>
      <td>0.056953</td>
      <td>-0.242384</td>
      <td>0.629501</td>
      <td>-0.194793</td>
      <td>1.068499</td>
      <td>-0.259928</td>
      <td>-0.594973</td>
      <td>-1.115433</td>
      <td>-0.563224</td>
      <td>-0.181249</td>
      <td>0.631331</td>
      <td>1.523891</td>
      <td>0.896588</td>
      <td>-0.644167</td>
      <td>...</td>
      <td>0.026116</td>
      <td>0.840018</td>
      <td>0.509433</td>
      <td>0.881627</td>
      <td>0.308243</td>
      <td>-0.058703</td>
      <td>-0.658286</td>
      <td>-0.727791</td>
      <td>-0.402348</td>
      <td>-0.993650</td>
      <td>-1.581041</td>
      <td>-0.504036</td>
      <td>0.601173</td>
      <td>0.235980</td>
      <td>-0.228228</td>
      <td>-0.357587</td>
      <td>0.175876</td>
      <td>1.520559</td>
      <td>0.385708</td>
      <td>-1.048460</td>
      <td>-0.250917</td>
      <td>-1.688081</td>
      <td>-0.142540</td>
      <td>-0.093639</td>
      <td>-1.746680</td>
      <td>0.366739</td>
      <td>0.251251</td>
      <td>0.257245</td>
      <td>0.226186</td>
      <td>0.811132</td>
      <td>0.467424</td>
      <td>-0.379820</td>
      <td>-0.457396</td>
      <td>-0.636617</td>
      <td>-0.397360</td>
      <td>-0.449488</td>
      <td>0.392442</td>
      <td>3.846657</td>
      <td>2.418218</td>
      <td>1.664065</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.221933</td>
      <td>-0.215218</td>
      <td>-0.263885</td>
      <td>0.232363</td>
      <td>0.915686</td>
      <td>0.742537</td>
      <td>-0.494791</td>
      <td>0.758937</td>
      <td>0.460416</td>
      <td>0.544312</td>
      <td>-0.331635</td>
      <td>-0.638517</td>
      <td>-0.374257</td>
      <td>0.020843</td>
      <td>-0.554062</td>
      <td>0.427257</td>
      <td>-0.545447</td>
      <td>0.255083</td>
      <td>1.251096</td>
      <td>1.491151</td>
      <td>0.703926</td>
      <td>0.381175</td>
      <td>0.190261</td>
      <td>-0.129588</td>
      <td>0.296654</td>
      <td>0.861051</td>
      <td>0.785479</td>
      <td>1.466412</td>
      <td>-0.050808</td>
      <td>0.965556</td>
      <td>0.225195</td>
      <td>0.663585</td>
      <td>1.187149</td>
      <td>-0.201451</td>
      <td>-0.307730</td>
      <td>0.610227</td>
      <td>1.521590</td>
      <td>-0.171279</td>
      <td>0.082308</td>
      <td>0.202860</td>
      <td>...</td>
      <td>0.504529</td>
      <td>0.527615</td>
      <td>-0.419859</td>
      <td>0.628842</td>
      <td>-0.430638</td>
      <td>-0.879453</td>
      <td>-0.765719</td>
      <td>-0.839523</td>
      <td>0.160758</td>
      <td>-0.768922</td>
      <td>-1.141134</td>
      <td>-1.995646</td>
      <td>0.148208</td>
      <td>1.074819</td>
      <td>-0.630155</td>
      <td>0.153496</td>
      <td>0.441677</td>
      <td>0.085133</td>
      <td>-0.085011</td>
      <td>-0.827192</td>
      <td>-0.656194</td>
      <td>-1.417835</td>
      <td>-0.793796</td>
      <td>-0.129393</td>
      <td>-0.225227</td>
      <td>0.674540</td>
      <td>-0.434509</td>
      <td>0.353265</td>
      <td>1.132523</td>
      <td>-0.009206</td>
      <td>0.346583</td>
      <td>-0.368931</td>
      <td>-0.591471</td>
      <td>-0.509101</td>
      <td>-0.096589</td>
      <td>-0.071723</td>
      <td>1.093437</td>
      <td>1.323691</td>
      <td>0.778134</td>
      <td>-0.160430</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.308457</td>
      <td>0.086699</td>
      <td>0.208605</td>
      <td>-0.008111</td>
      <td>-1.138083</td>
      <td>-1.197564</td>
      <td>-1.063534</td>
      <td>-0.323120</td>
      <td>-0.027383</td>
      <td>-1.446310</td>
      <td>-0.722460</td>
      <td>0.073328</td>
      <td>-1.138229</td>
      <td>-0.093348</td>
      <td>-0.886470</td>
      <td>-0.057508</td>
      <td>0.201911</td>
      <td>-0.254565</td>
      <td>1.068751</td>
      <td>-0.771345</td>
      <td>0.297624</td>
      <td>-0.149274</td>
      <td>-0.001555</td>
      <td>-0.911730</td>
      <td>0.222454</td>
      <td>0.961739</td>
      <td>-0.126389</td>
      <td>0.119722</td>
      <td>-0.603356</td>
      <td>-0.041263</td>
      <td>0.646400</td>
      <td>-0.097449</td>
      <td>-0.452193</td>
      <td>-0.075808</td>
      <td>0.841053</td>
      <td>0.011809</td>
      <td>0.701965</td>
      <td>-0.600929</td>
      <td>-0.572453</td>
      <td>0.275567</td>
      <td>...</td>
      <td>0.324372</td>
      <td>-0.650692</td>
      <td>-0.070303</td>
      <td>0.671468</td>
      <td>0.298348</td>
      <td>-0.719642</td>
      <td>-0.077092</td>
      <td>0.530345</td>
      <td>0.897605</td>
      <td>0.308199</td>
      <td>0.448713</td>
      <td>0.029209</td>
      <td>-0.259241</td>
      <td>0.022777</td>
      <td>-0.007830</td>
      <td>0.138272</td>
      <td>1.176132</td>
      <td>-0.666704</td>
      <td>-0.647952</td>
      <td>0.594552</td>
      <td>1.035368</td>
      <td>-0.326436</td>
      <td>0.137389</td>
      <td>-1.080297</td>
      <td>-1.454594</td>
      <td>0.296741</td>
      <td>0.154117</td>
      <td>0.957718</td>
      <td>0.976108</td>
      <td>0.568384</td>
      <td>0.118777</td>
      <td>0.690115</td>
      <td>-0.191509</td>
      <td>-0.718340</td>
      <td>0.702165</td>
      <td>0.489236</td>
      <td>1.158244</td>
      <td>0.187937</td>
      <td>-0.830542</td>
      <td>-0.588419</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.128944</td>
      <td>-0.886049</td>
      <td>-0.670554</td>
      <td>0.107485</td>
      <td>0.424406</td>
      <td>-0.265693</td>
      <td>-1.209953</td>
      <td>-0.622624</td>
      <td>-0.395806</td>
      <td>-0.922434</td>
      <td>-1.189472</td>
      <td>-1.563370</td>
      <td>-0.437772</td>
      <td>-0.150753</td>
      <td>0.023317</td>
      <td>-0.027187</td>
      <td>0.206064</td>
      <td>0.217005</td>
      <td>-0.291896</td>
      <td>-0.025912</td>
      <td>0.051556</td>
      <td>-0.362911</td>
      <td>-0.365486</td>
      <td>-0.441304</td>
      <td>-0.611216</td>
      <td>0.178651</td>
      <td>0.486302</td>
      <td>0.071702</td>
      <td>0.747711</td>
      <td>0.627046</td>
      <td>0.431673</td>
      <td>0.477343</td>
      <td>-0.662003</td>
      <td>0.018343</td>
      <td>-0.592102</td>
      <td>-0.363053</td>
      <td>0.915417</td>
      <td>-0.261196</td>
      <td>-0.146871</td>
      <td>0.027474</td>
      <td>...</td>
      <td>0.320294</td>
      <td>-0.076071</td>
      <td>0.111521</td>
      <td>0.789851</td>
      <td>-0.476242</td>
      <td>-0.138406</td>
      <td>-0.077069</td>
      <td>0.873586</td>
      <td>0.810248</td>
      <td>-0.944261</td>
      <td>-0.849664</td>
      <td>-0.341478</td>
      <td>0.238001</td>
      <td>1.630062</td>
      <td>1.303584</td>
      <td>0.514476</td>
      <td>0.540861</td>
      <td>1.036655</td>
      <td>-0.278777</td>
      <td>0.066351</td>
      <td>-0.416112</td>
      <td>-0.408563</td>
      <td>0.765007</td>
      <td>-0.404020</td>
      <td>-0.171894</td>
      <td>0.418665</td>
      <td>-0.137644</td>
      <td>-0.759399</td>
      <td>0.562201</td>
      <td>0.775987</td>
      <td>1.276493</td>
      <td>0.061949</td>
      <td>-0.715376</td>
      <td>-1.170091</td>
      <td>-1.151212</td>
      <td>-0.764720</td>
      <td>0.019567</td>
      <td>0.587221</td>
      <td>0.049412</td>
      <td>0.032178</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.741811</td>
      <td>0.707352</td>
      <td>-0.571438</td>
      <td>1.015650</td>
      <td>-1.417221</td>
      <td>-0.050976</td>
      <td>-0.997899</td>
      <td>-0.318346</td>
      <td>-0.231638</td>
      <td>-0.172339</td>
      <td>0.611870</td>
      <td>0.364097</td>
      <td>-0.792923</td>
      <td>-0.259814</td>
      <td>-0.231013</td>
      <td>-0.401887</td>
      <td>-0.807710</td>
      <td>0.306666</td>
      <td>-0.083447</td>
      <td>-0.377270</td>
      <td>0.221410</td>
      <td>0.517280</td>
      <td>0.564619</td>
      <td>0.511019</td>
      <td>0.559350</td>
      <td>1.551746</td>
      <td>0.649715</td>
      <td>0.435318</td>
      <td>-0.310537</td>
      <td>0.073942</td>
      <td>0.769369</td>
      <td>0.396474</td>
      <td>0.879586</td>
      <td>0.891465</td>
      <td>-0.260653</td>
      <td>0.539448</td>
      <td>0.533267</td>
      <td>-0.024739</td>
      <td>0.105933</td>
      <td>-0.426216</td>
      <td>...</td>
      <td>0.694555</td>
      <td>1.078365</td>
      <td>0.996761</td>
      <td>0.648642</td>
      <td>-0.393747</td>
      <td>-0.759065</td>
      <td>-0.223042</td>
      <td>-0.472818</td>
      <td>-0.007232</td>
      <td>0.504963</td>
      <td>0.000241</td>
      <td>0.384585</td>
      <td>1.064585</td>
      <td>0.667122</td>
      <td>0.142988</td>
      <td>0.297552</td>
      <td>-0.154141</td>
      <td>-0.111437</td>
      <td>0.614808</td>
      <td>0.536483</td>
      <td>-0.276218</td>
      <td>-0.496172</td>
      <td>-0.853949</td>
      <td>0.299925</td>
      <td>-0.096166</td>
      <td>-0.109949</td>
      <td>-0.538199</td>
      <td>0.117697</td>
      <td>-0.046437</td>
      <td>-0.794232</td>
      <td>-0.049722</td>
      <td>-1.060859</td>
      <td>0.020370</td>
      <td>-0.985611</td>
      <td>-0.765960</td>
      <td>-0.847344</td>
      <td>0.110382</td>
      <td>1.648369</td>
      <td>0.515904</td>
      <td>0.315769</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.751661</td>
      <td>-0.662322</td>
      <td>0.338743</td>
      <td>0.322198</td>
      <td>-0.590365</td>
      <td>-0.918427</td>
      <td>0.692181</td>
      <td>1.195071</td>
      <td>0.211597</td>
      <td>-0.267717</td>
      <td>-1.193439</td>
      <td>-0.964875</td>
      <td>0.312633</td>
      <td>-0.263484</td>
      <td>-0.237649</td>
      <td>0.543319</td>
      <td>-0.278755</td>
      <td>0.138915</td>
      <td>0.431309</td>
      <td>-0.000030</td>
      <td>0.183847</td>
      <td>-0.477549</td>
      <td>-1.014583</td>
      <td>0.109070</td>
      <td>1.005282</td>
      <td>0.430713</td>
      <td>0.930394</td>
      <td>0.332258</td>
      <td>-0.077512</td>
      <td>-0.266051</td>
      <td>0.410756</td>
      <td>0.782857</td>
      <td>-0.897859</td>
      <td>0.041113</td>
      <td>-0.572322</td>
      <td>-0.201117</td>
      <td>1.115415</td>
      <td>0.085126</td>
      <td>-0.465408</td>
      <td>-0.033364</td>
      <td>...</td>
      <td>0.480095</td>
      <td>-0.633096</td>
      <td>0.476190</td>
      <td>0.818674</td>
      <td>-0.505669</td>
      <td>-0.611299</td>
      <td>-0.050641</td>
      <td>0.288932</td>
      <td>-0.173727</td>
      <td>-0.747465</td>
      <td>-1.670775</td>
      <td>0.717498</td>
      <td>0.059217</td>
      <td>0.351970</td>
      <td>-0.196255</td>
      <td>-1.001196</td>
      <td>-0.685569</td>
      <td>-0.792062</td>
      <td>0.512731</td>
      <td>-0.446906</td>
      <td>0.461058</td>
      <td>0.848307</td>
      <td>-0.439780</td>
      <td>0.039210</td>
      <td>-0.635212</td>
      <td>-0.013320</td>
      <td>0.040400</td>
      <td>1.325050</td>
      <td>0.295882</td>
      <td>-0.172021</td>
      <td>-0.017374</td>
      <td>-1.007930</td>
      <td>-0.730293</td>
      <td>0.072259</td>
      <td>0.001223</td>
      <td>-0.398403</td>
      <td>0.292619</td>
      <td>0.707627</td>
      <td>-0.271198</td>
      <td>0.089828</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.463850</td>
      <td>0.584722</td>
      <td>-0.340630</td>
      <td>0.243356</td>
      <td>-0.256879</td>
      <td>-0.288105</td>
      <td>0.510815</td>
      <td>0.359037</td>
      <td>0.308216</td>
      <td>-0.428825</td>
      <td>0.053901</td>
      <td>-0.709900</td>
      <td>-0.196460</td>
      <td>0.558365</td>
      <td>-0.997843</td>
      <td>-0.307355</td>
      <td>0.381899</td>
      <td>0.628602</td>
      <td>0.434316</td>
      <td>-0.127671</td>
      <td>0.559157</td>
      <td>0.294798</td>
      <td>0.316950</td>
      <td>0.185838</td>
      <td>-0.468565</td>
      <td>0.064035</td>
      <td>0.777912</td>
      <td>0.405086</td>
      <td>0.359207</td>
      <td>-0.875218</td>
      <td>0.494778</td>
      <td>0.344608</td>
      <td>1.369916</td>
      <td>0.267425</td>
      <td>-0.694945</td>
      <td>0.272721</td>
      <td>-0.290798</td>
      <td>-0.477265</td>
      <td>0.269708</td>
      <td>0.138169</td>
      <td>...</td>
      <td>-0.293853</td>
      <td>-0.864504</td>
      <td>-0.798916</td>
      <td>-0.205872</td>
      <td>-1.130164</td>
      <td>-0.256964</td>
      <td>-0.485464</td>
      <td>-0.466594</td>
      <td>0.289153</td>
      <td>0.004790</td>
      <td>-0.191879</td>
      <td>0.492476</td>
      <td>-0.464511</td>
      <td>-0.419473</td>
      <td>-0.059627</td>
      <td>0.138593</td>
      <td>-0.527427</td>
      <td>1.278691</td>
      <td>0.009458</td>
      <td>-0.316261</td>
      <td>-0.717946</td>
      <td>-0.156238</td>
      <td>0.450450</td>
      <td>0.362576</td>
      <td>-0.369459</td>
      <td>-0.113346</td>
      <td>0.569573</td>
      <td>-0.166652</td>
      <td>0.327546</td>
      <td>1.086687</td>
      <td>0.226686</td>
      <td>-1.290722</td>
      <td>-0.009241</td>
      <td>-1.073555</td>
      <td>-1.071501</td>
      <td>-1.081730</td>
      <td>0.610463</td>
      <td>-1.441632</td>
      <td>-1.999212</td>
      <td>-0.529635</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.077548</td>
      <td>0.611844</td>
      <td>-0.287724</td>
      <td>-0.989066</td>
      <td>-0.432040</td>
      <td>-0.758490</td>
      <td>0.234082</td>
      <td>-0.383095</td>
      <td>0.390426</td>
      <td>-1.146296</td>
      <td>-0.567422</td>
      <td>-0.634272</td>
      <td>-0.980243</td>
      <td>-0.424685</td>
      <td>-0.296274</td>
      <td>0.906672</td>
      <td>0.311322</td>
      <td>1.082100</td>
      <td>0.692917</td>
      <td>-0.656864</td>
      <td>-0.536414</td>
      <td>0.716909</td>
      <td>0.289324</td>
      <td>0.342790</td>
      <td>-0.428928</td>
      <td>0.168801</td>
      <td>-0.083047</td>
      <td>1.628066</td>
      <td>1.187128</td>
      <td>-0.189415</td>
      <td>0.914133</td>
      <td>0.499481</td>
      <td>-0.477688</td>
      <td>-1.086918</td>
      <td>-1.619047</td>
      <td>-0.476247</td>
      <td>0.847817</td>
      <td>-0.708052</td>
      <td>-1.434877</td>
      <td>-0.363390</td>
      <td>...</td>
      <td>0.656200</td>
      <td>0.249935</td>
      <td>-0.543311</td>
      <td>-0.000905</td>
      <td>0.991791</td>
      <td>-0.778563</td>
      <td>-0.481602</td>
      <td>0.597834</td>
      <td>0.270551</td>
      <td>-0.934955</td>
      <td>-0.998987</td>
      <td>0.110834</td>
      <td>0.370673</td>
      <td>-0.692309</td>
      <td>-0.344988</td>
      <td>-0.145921</td>
      <td>-0.280015</td>
      <td>0.644045</td>
      <td>0.354055</td>
      <td>0.863762</td>
      <td>-0.142128</td>
      <td>-0.423500</td>
      <td>-0.503649</td>
      <td>-0.647030</td>
      <td>-0.401497</td>
      <td>0.483439</td>
      <td>-1.005165</td>
      <td>0.011219</td>
      <td>-0.409616</td>
      <td>-0.063648</td>
      <td>-0.488899</td>
      <td>-0.427761</td>
      <td>0.398820</td>
      <td>-0.257727</td>
      <td>0.506048</td>
      <td>-0.128943</td>
      <td>0.321657</td>
      <td>-0.808438</td>
      <td>-0.638271</td>
      <td>-0.382384</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.220866</td>
      <td>0.414401</td>
      <td>0.037131</td>
      <td>-0.477356</td>
      <td>-0.855088</td>
      <td>-0.947561</td>
      <td>0.589306</td>
      <td>-0.451668</td>
      <td>0.464174</td>
      <td>-0.440963</td>
      <td>-0.846222</td>
      <td>-1.921579</td>
      <td>-0.683702</td>
      <td>-0.325731</td>
      <td>0.711278</td>
      <td>-0.330586</td>
      <td>-0.660671</td>
      <td>0.069190</td>
      <td>0.165182</td>
      <td>0.130230</td>
      <td>0.276060</td>
      <td>0.198727</td>
      <td>-0.186926</td>
      <td>-0.970713</td>
      <td>0.527003</td>
      <td>1.080353</td>
      <td>1.184879</td>
      <td>0.342410</td>
      <td>0.206502</td>
      <td>-0.682012</td>
      <td>0.079311</td>
      <td>1.327919</td>
      <td>0.671651</td>
      <td>1.558118</td>
      <td>0.004103</td>
      <td>0.210125</td>
      <td>0.799261</td>
      <td>0.039861</td>
      <td>-0.763976</td>
      <td>0.109494</td>
      <td>...</td>
      <td>0.029695</td>
      <td>-0.269867</td>
      <td>-0.229764</td>
      <td>0.630930</td>
      <td>0.382431</td>
      <td>0.441557</td>
      <td>0.117204</td>
      <td>-0.307893</td>
      <td>0.040374</td>
      <td>0.075235</td>
      <td>-1.353765</td>
      <td>-0.049129</td>
      <td>0.387273</td>
      <td>0.661355</td>
      <td>0.764200</td>
      <td>0.227563</td>
      <td>-0.134367</td>
      <td>-0.078595</td>
      <td>-0.657627</td>
      <td>-0.837579</td>
      <td>-0.553917</td>
      <td>-0.601240</td>
      <td>0.042649</td>
      <td>-0.436930</td>
      <td>-0.025094</td>
      <td>-1.028680</td>
      <td>0.194972</td>
      <td>-0.856384</td>
      <td>-0.150509</td>
      <td>0.336676</td>
      <td>0.644993</td>
      <td>0.124587</td>
      <td>0.158699</td>
      <td>0.478610</td>
      <td>0.422408</td>
      <td>0.461036</td>
      <td>0.198222</td>
      <td>0.046398</td>
      <td>-0.177704</td>
      <td>-0.030220</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.014327</td>
      <td>-0.070189</td>
      <td>-0.174281</td>
      <td>0.208390</td>
      <td>0.256998</td>
      <td>0.318162</td>
      <td>1.251424</td>
      <td>0.401031</td>
      <td>-0.697319</td>
      <td>-0.119711</td>
      <td>-0.000113</td>
      <td>-0.599991</td>
      <td>0.144517</td>
      <td>0.026060</td>
      <td>-1.148423</td>
      <td>-0.270541</td>
      <td>-0.343326</td>
      <td>-0.187246</td>
      <td>0.171945</td>
      <td>1.131950</td>
      <td>0.735702</td>
      <td>0.230495</td>
      <td>0.180405</td>
      <td>0.195382</td>
      <td>-0.472363</td>
      <td>-0.862181</td>
      <td>-1.429847</td>
      <td>-0.702401</td>
      <td>-0.861649</td>
      <td>0.636239</td>
      <td>0.874136</td>
      <td>0.524579</td>
      <td>0.594096</td>
      <td>-0.283387</td>
      <td>-0.794352</td>
      <td>-0.924949</td>
      <td>-0.679939</td>
      <td>-0.754009</td>
      <td>-0.816370</td>
      <td>-0.724064</td>
      <td>...</td>
      <td>-0.471187</td>
      <td>0.690114</td>
      <td>-0.346190</td>
      <td>0.577022</td>
      <td>0.564965</td>
      <td>-0.948708</td>
      <td>-0.044512</td>
      <td>-0.449863</td>
      <td>-0.144979</td>
      <td>-0.987617</td>
      <td>-0.584166</td>
      <td>-0.166706</td>
      <td>-0.612079</td>
      <td>-0.153942</td>
      <td>0.246332</td>
      <td>-0.707877</td>
      <td>0.531011</td>
      <td>-0.293757</td>
      <td>-0.615400</td>
      <td>0.198044</td>
      <td>-0.285554</td>
      <td>-0.347034</td>
      <td>-0.549419</td>
      <td>-0.993911</td>
      <td>-0.580543</td>
      <td>-0.913418</td>
      <td>-0.894492</td>
      <td>-0.903570</td>
      <td>-0.262542</td>
      <td>-0.191668</td>
      <td>-0.321313</td>
      <td>0.232914</td>
      <td>-0.506608</td>
      <td>-0.785680</td>
      <td>-0.283782</td>
      <td>-0.235051</td>
      <td>0.342565</td>
      <td>0.563225</td>
      <td>0.063911</td>
      <td>0.013869</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.611184</td>
      <td>-1.010115</td>
      <td>0.095362</td>
      <td>0.071147</td>
      <td>0.242063</td>
      <td>0.126912</td>
      <td>-0.539928</td>
      <td>-0.895680</td>
      <td>0.159946</td>
      <td>0.064668</td>
      <td>0.099088</td>
      <td>-0.245796</td>
      <td>0.247696</td>
      <td>0.968779</td>
      <td>-0.140231</td>
      <td>-0.387735</td>
      <td>-0.091162</td>
      <td>-0.697793</td>
      <td>-0.568748</td>
      <td>0.187170</td>
      <td>-0.176463</td>
      <td>-0.324119</td>
      <td>-1.001497</td>
      <td>-0.421201</td>
      <td>1.473983</td>
      <td>0.295290</td>
      <td>0.312362</td>
      <td>0.031557</td>
      <td>0.627953</td>
      <td>0.720260</td>
      <td>1.119686</td>
      <td>0.315030</td>
      <td>0.988216</td>
      <td>1.152585</td>
      <td>-0.312153</td>
      <td>-0.118443</td>
      <td>0.754453</td>
      <td>-1.162059</td>
      <td>-1.590146</td>
      <td>0.547322</td>
      <td>...</td>
      <td>0.004944</td>
      <td>-0.534077</td>
      <td>0.409133</td>
      <td>1.685085</td>
      <td>0.422938</td>
      <td>-0.446880</td>
      <td>0.096138</td>
      <td>0.619763</td>
      <td>0.379927</td>
      <td>-0.629249</td>
      <td>-0.700429</td>
      <td>-0.209239</td>
      <td>0.242892</td>
      <td>-0.580392</td>
      <td>0.335601</td>
      <td>0.116416</td>
      <td>0.351922</td>
      <td>0.414020</td>
      <td>-0.823018</td>
      <td>-0.103535</td>
      <td>-0.051812</td>
      <td>-0.225830</td>
      <td>-1.606132</td>
      <td>-0.584399</td>
      <td>-0.600350</td>
      <td>-0.683106</td>
      <td>0.275251</td>
      <td>0.438171</td>
      <td>-0.259973</td>
      <td>0.932437</td>
      <td>0.022527</td>
      <td>-0.361721</td>
      <td>-0.005988</td>
      <td>-0.518693</td>
      <td>0.495694</td>
      <td>0.041376</td>
      <td>-0.404900</td>
      <td>-0.263353</td>
      <td>-0.304849</td>
      <td>0.030948</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.064582</td>
      <td>0.712436</td>
      <td>-0.598600</td>
      <td>-0.769564</td>
      <td>-0.715480</td>
      <td>1.514840</td>
      <td>-0.030024</td>
      <td>-0.198832</td>
      <td>-0.856485</td>
      <td>-0.459191</td>
      <td>0.078038</td>
      <td>0.496636</td>
      <td>-0.144812</td>
      <td>-0.057095</td>
      <td>-0.086030</td>
      <td>0.886622</td>
      <td>0.666522</td>
      <td>0.305706</td>
      <td>-1.132278</td>
      <td>0.027010</td>
      <td>-0.569026</td>
      <td>0.563012</td>
      <td>0.376783</td>
      <td>-1.292180</td>
      <td>0.723971</td>
      <td>0.793102</td>
      <td>-0.256008</td>
      <td>0.392350</td>
      <td>0.219687</td>
      <td>0.469653</td>
      <td>-0.027382</td>
      <td>-0.502546</td>
      <td>0.356798</td>
      <td>-0.519176</td>
      <td>0.419319</td>
      <td>-0.607784</td>
      <td>0.209349</td>
      <td>-0.283585</td>
      <td>-0.615869</td>
      <td>-0.360524</td>
      <td>...</td>
      <td>0.001317</td>
      <td>-0.408323</td>
      <td>-0.378895</td>
      <td>-0.021814</td>
      <td>0.692247</td>
      <td>-0.674358</td>
      <td>0.364402</td>
      <td>0.760460</td>
      <td>0.893362</td>
      <td>1.365308</td>
      <td>-0.137085</td>
      <td>-0.303725</td>
      <td>0.036585</td>
      <td>-0.296044</td>
      <td>-0.535966</td>
      <td>-1.181816</td>
      <td>-0.746083</td>
      <td>-0.104437</td>
      <td>-0.746296</td>
      <td>-0.150831</td>
      <td>-0.096255</td>
      <td>0.703742</td>
      <td>-0.037960</td>
      <td>-1.670307</td>
      <td>-0.133378</td>
      <td>-0.367016</td>
      <td>0.045785</td>
      <td>0.487464</td>
      <td>-0.022851</td>
      <td>0.060682</td>
      <td>0.379937</td>
      <td>0.564690</td>
      <td>1.944804</td>
      <td>0.098483</td>
      <td>-0.618557</td>
      <td>0.521099</td>
      <td>0.111703</td>
      <td>1.391880</td>
      <td>0.854092</td>
      <td>0.864928</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.145588</td>
      <td>0.731127</td>
      <td>-0.301311</td>
      <td>-0.500329</td>
      <td>-0.385816</td>
      <td>-0.203620</td>
      <td>0.291170</td>
      <td>0.258742</td>
      <td>-1.029872</td>
      <td>-0.679942</td>
      <td>0.937442</td>
      <td>-0.554679</td>
      <td>-0.993338</td>
      <td>-0.706727</td>
      <td>-0.364035</td>
      <td>0.638852</td>
      <td>0.211138</td>
      <td>-0.145467</td>
      <td>0.524575</td>
      <td>0.416788</td>
      <td>0.175696</td>
      <td>1.160882</td>
      <td>-0.667194</td>
      <td>-0.122273</td>
      <td>0.804309</td>
      <td>-0.264478</td>
      <td>0.342077</td>
      <td>-0.407676</td>
      <td>-0.028569</td>
      <td>0.369003</td>
      <td>0.383251</td>
      <td>-0.709300</td>
      <td>0.755048</td>
      <td>-0.949356</td>
      <td>0.470394</td>
      <td>-0.656810</td>
      <td>-1.046055</td>
      <td>-0.175258</td>
      <td>-0.268216</td>
      <td>-0.523074</td>
      <td>...</td>
      <td>-0.700131</td>
      <td>-1.397198</td>
      <td>0.302580</td>
      <td>-0.314365</td>
      <td>0.662541</td>
      <td>-0.067232</td>
      <td>-0.141766</td>
      <td>-0.312038</td>
      <td>-0.409744</td>
      <td>0.287231</td>
      <td>0.838158</td>
      <td>-0.212302</td>
      <td>0.404085</td>
      <td>-0.562290</td>
      <td>0.608851</td>
      <td>0.064651</td>
      <td>0.050530</td>
      <td>-0.252645</td>
      <td>0.581775</td>
      <td>0.346267</td>
      <td>-0.673556</td>
      <td>-0.973382</td>
      <td>-0.525023</td>
      <td>-0.568487</td>
      <td>-0.930438</td>
      <td>-1.291512</td>
      <td>-0.099487</td>
      <td>-0.350140</td>
      <td>-0.635019</td>
      <td>-0.779319</td>
      <td>-0.140191</td>
      <td>0.187356</td>
      <td>0.019662</td>
      <td>-1.333987</td>
      <td>-0.690285</td>
      <td>-0.050592</td>
      <td>-0.380188</td>
      <td>0.680529</td>
      <td>0.955177</td>
      <td>0.301027</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.704029</td>
      <td>-0.650170</td>
      <td>-0.026816</td>
      <td>0.154168</td>
      <td>-0.681527</td>
      <td>-1.776487</td>
      <td>-0.583046</td>
      <td>0.110083</td>
      <td>-0.854614</td>
      <td>-0.008995</td>
      <td>0.294157</td>
      <td>-0.241192</td>
      <td>-0.579560</td>
      <td>-0.537756</td>
      <td>-0.592983</td>
      <td>0.131237</td>
      <td>-0.133850</td>
      <td>-0.585889</td>
      <td>0.178922</td>
      <td>2.060248</td>
      <td>-0.741617</td>
      <td>0.470273</td>
      <td>-0.082332</td>
      <td>0.339896</td>
      <td>0.852348</td>
      <td>-0.066372</td>
      <td>0.632774</td>
      <td>0.501077</td>
      <td>2.225640</td>
      <td>0.914145</td>
      <td>-0.154725</td>
      <td>-0.828116</td>
      <td>-0.235193</td>
      <td>-0.988689</td>
      <td>-0.868013</td>
      <td>0.477482</td>
      <td>0.285984</td>
      <td>-0.821544</td>
      <td>-1.807560</td>
      <td>-0.113760</td>
      <td>...</td>
      <td>-0.682787</td>
      <td>-0.909870</td>
      <td>-0.043044</td>
      <td>0.512333</td>
      <td>0.648765</td>
      <td>-0.664986</td>
      <td>-0.247137</td>
      <td>-0.051770</td>
      <td>-0.539232</td>
      <td>-1.142134</td>
      <td>-0.085759</td>
      <td>-0.087610</td>
      <td>0.393672</td>
      <td>-0.244550</td>
      <td>0.322138</td>
      <td>-0.548995</td>
      <td>0.211356</td>
      <td>0.354313</td>
      <td>0.432901</td>
      <td>0.902650</td>
      <td>-0.800939</td>
      <td>-0.841398</td>
      <td>-1.445338</td>
      <td>-0.945568</td>
      <td>-0.141085</td>
      <td>-0.445565</td>
      <td>-0.665256</td>
      <td>0.196891</td>
      <td>0.280388</td>
      <td>0.465015</td>
      <td>0.089349</td>
      <td>0.513578</td>
      <td>-0.117704</td>
      <td>-0.118574</td>
      <td>0.285266</td>
      <td>0.292713</td>
      <td>-0.923075</td>
      <td>-3.147557</td>
      <td>-1.396460</td>
      <td>-0.445507</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7fa7e651d9d0&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>      coef   std err          t          P&gt;|t|     2.5 %    97.5 %
D  1.05677  0.040758  25.927779  3.238589e-148  0.976885  1.136654
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  5.398 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>