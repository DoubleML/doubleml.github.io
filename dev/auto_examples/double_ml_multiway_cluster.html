
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.0.1 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="http://doubleml.org"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>     to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-0.854339</td>
      <td>0.933782</td>
      <td>-0.335311</td>
      <td>1.463254</td>
      <td>0.688511</td>
      <td>0.550098</td>
      <td>0.119877</td>
      <td>-0.206446</td>
      <td>-1.652373</td>
      <td>0.502626</td>
      <td>0.020994</td>
      <td>0.246508</td>
      <td>0.542816</td>
      <td>0.681715</td>
      <td>0.864860</td>
      <td>-0.422810</td>
      <td>-0.678681</td>
      <td>1.063886</td>
      <td>0.423680</td>
      <td>0.242792</td>
      <td>0.021630</td>
      <td>-0.352925</td>
      <td>0.568565</td>
      <td>0.427599</td>
      <td>-0.660880</td>
      <td>-0.140136</td>
      <td>-0.517400</td>
      <td>0.358323</td>
      <td>0.062091</td>
      <td>0.989979</td>
      <td>0.244085</td>
      <td>0.148066</td>
      <td>-0.506196</td>
      <td>0.834074</td>
      <td>-0.057668</td>
      <td>0.649083</td>
      <td>0.818055</td>
      <td>1.112308</td>
      <td>0.858941</td>
      <td>-0.391147</td>
      <td>...</td>
      <td>-0.860816</td>
      <td>-0.761273</td>
      <td>-0.925316</td>
      <td>-0.312922</td>
      <td>-0.074107</td>
      <td>0.086136</td>
      <td>-0.206937</td>
      <td>-0.226576</td>
      <td>-0.218312</td>
      <td>-0.175819</td>
      <td>0.790691</td>
      <td>-0.194059</td>
      <td>0.641888</td>
      <td>0.484655</td>
      <td>-1.142039</td>
      <td>-1.146566</td>
      <td>-0.180714</td>
      <td>-0.889729</td>
      <td>0.238589</td>
      <td>-0.994691</td>
      <td>0.413172</td>
      <td>0.005111</td>
      <td>1.025848</td>
      <td>-0.161413</td>
      <td>0.295725</td>
      <td>-0.476923</td>
      <td>0.312874</td>
      <td>-0.181326</td>
      <td>-0.639221</td>
      <td>-0.423847</td>
      <td>-0.400307</td>
      <td>-0.477094</td>
      <td>-0.409500</td>
      <td>0.406383</td>
      <td>0.761829</td>
      <td>0.210501</td>
      <td>0.534355</td>
      <td>0.705338</td>
      <td>0.587126</td>
      <td>0.584215</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.166431</td>
      <td>0.565185</td>
      <td>-0.172836</td>
      <td>0.771321</td>
      <td>-0.356449</td>
      <td>0.643498</td>
      <td>-0.480904</td>
      <td>1.228831</td>
      <td>-0.281764</td>
      <td>1.502561</td>
      <td>0.221204</td>
      <td>0.247836</td>
      <td>0.763485</td>
      <td>-0.211883</td>
      <td>-0.468621</td>
      <td>0.084852</td>
      <td>-0.780320</td>
      <td>-0.364443</td>
      <td>0.367525</td>
      <td>0.025356</td>
      <td>0.660665</td>
      <td>1.377957</td>
      <td>0.045175</td>
      <td>-0.170332</td>
      <td>-1.358679</td>
      <td>-0.109801</td>
      <td>-0.657146</td>
      <td>-1.004129</td>
      <td>-0.356641</td>
      <td>-0.529280</td>
      <td>-0.703087</td>
      <td>-0.653338</td>
      <td>-1.110915</td>
      <td>0.520277</td>
      <td>0.639680</td>
      <td>-0.415273</td>
      <td>0.484860</td>
      <td>0.512631</td>
      <td>-0.700612</td>
      <td>0.054291</td>
      <td>...</td>
      <td>-0.129621</td>
      <td>-0.752758</td>
      <td>-0.171943</td>
      <td>0.171205</td>
      <td>0.785250</td>
      <td>0.217144</td>
      <td>0.555663</td>
      <td>0.105138</td>
      <td>-0.027329</td>
      <td>0.408378</td>
      <td>1.106829</td>
      <td>1.021325</td>
      <td>1.166012</td>
      <td>-0.004174</td>
      <td>0.868599</td>
      <td>0.810118</td>
      <td>0.805049</td>
      <td>-0.096592</td>
      <td>-0.037224</td>
      <td>-0.290761</td>
      <td>-0.743453</td>
      <td>-1.522624</td>
      <td>-0.058587</td>
      <td>0.389915</td>
      <td>0.392821</td>
      <td>-0.606255</td>
      <td>-0.479161</td>
      <td>-0.130472</td>
      <td>0.690809</td>
      <td>0.553580</td>
      <td>-0.315904</td>
      <td>0.276071</td>
      <td>-0.276136</td>
      <td>-0.222977</td>
      <td>-1.040114</td>
      <td>-0.770067</td>
      <td>0.703523</td>
      <td>-1.282869</td>
      <td>-1.100161</td>
      <td>-0.709331</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.108362</td>
      <td>0.481202</td>
      <td>0.893296</td>
      <td>0.915098</td>
      <td>0.803646</td>
      <td>0.966129</td>
      <td>0.484605</td>
      <td>-0.458908</td>
      <td>-0.573978</td>
      <td>-0.917635</td>
      <td>0.111703</td>
      <td>-0.297884</td>
      <td>0.094204</td>
      <td>0.098353</td>
      <td>0.188158</td>
      <td>-0.787661</td>
      <td>0.150088</td>
      <td>0.626376</td>
      <td>-1.140735</td>
      <td>-0.187121</td>
      <td>0.760376</td>
      <td>0.415017</td>
      <td>-0.421705</td>
      <td>0.439543</td>
      <td>-0.250312</td>
      <td>-0.180304</td>
      <td>-1.213587</td>
      <td>0.414256</td>
      <td>-0.161632</td>
      <td>1.087591</td>
      <td>0.160169</td>
      <td>0.103178</td>
      <td>-1.122157</td>
      <td>0.206683</td>
      <td>-0.359633</td>
      <td>0.055781</td>
      <td>0.383918</td>
      <td>0.704285</td>
      <td>-0.346683</td>
      <td>-0.944075</td>
      <td>...</td>
      <td>-0.759235</td>
      <td>-0.554472</td>
      <td>0.117370</td>
      <td>-0.574625</td>
      <td>-0.337652</td>
      <td>-0.027339</td>
      <td>-0.091424</td>
      <td>-0.298970</td>
      <td>-0.356338</td>
      <td>-1.018737</td>
      <td>0.340836</td>
      <td>-0.233583</td>
      <td>0.550785</td>
      <td>0.278722</td>
      <td>0.383712</td>
      <td>0.774528</td>
      <td>1.482853</td>
      <td>0.630693</td>
      <td>0.431140</td>
      <td>-0.217397</td>
      <td>-0.818680</td>
      <td>0.024207</td>
      <td>0.328752</td>
      <td>-0.793715</td>
      <td>0.700788</td>
      <td>0.322950</td>
      <td>1.300104</td>
      <td>0.303341</td>
      <td>0.773252</td>
      <td>-0.205495</td>
      <td>-1.156808</td>
      <td>-0.104762</td>
      <td>-0.010855</td>
      <td>0.348969</td>
      <td>-0.409386</td>
      <td>1.517368</td>
      <td>1.078729</td>
      <td>-0.867635</td>
      <td>-0.765464</td>
      <td>0.134109</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.489638</td>
      <td>0.283466</td>
      <td>-0.643723</td>
      <td>0.598159</td>
      <td>0.207324</td>
      <td>1.017468</td>
      <td>0.491209</td>
      <td>0.080083</td>
      <td>-1.225518</td>
      <td>0.346019</td>
      <td>0.786746</td>
      <td>0.976508</td>
      <td>-0.632596</td>
      <td>-0.106266</td>
      <td>-0.110412</td>
      <td>0.103724</td>
      <td>0.274791</td>
      <td>1.186910</td>
      <td>-0.403018</td>
      <td>0.206573</td>
      <td>-0.098868</td>
      <td>-1.269744</td>
      <td>0.400413</td>
      <td>0.847182</td>
      <td>0.209152</td>
      <td>0.003727</td>
      <td>-0.560591</td>
      <td>-0.288595</td>
      <td>-0.064442</td>
      <td>0.256986</td>
      <td>-0.175954</td>
      <td>0.589713</td>
      <td>-0.350593</td>
      <td>0.195427</td>
      <td>-0.644973</td>
      <td>-1.239236</td>
      <td>1.100184</td>
      <td>-0.253936</td>
      <td>-0.551031</td>
      <td>-0.355883</td>
      <td>...</td>
      <td>-0.193307</td>
      <td>-0.477514</td>
      <td>-0.108184</td>
      <td>0.010617</td>
      <td>0.183826</td>
      <td>-1.069369</td>
      <td>0.746997</td>
      <td>0.513160</td>
      <td>-0.570859</td>
      <td>-0.444727</td>
      <td>-0.404528</td>
      <td>0.585346</td>
      <td>1.199977</td>
      <td>0.231361</td>
      <td>0.150824</td>
      <td>0.125079</td>
      <td>-1.057739</td>
      <td>-1.061595</td>
      <td>-0.447030</td>
      <td>-0.488932</td>
      <td>-0.646614</td>
      <td>-0.369108</td>
      <td>0.311887</td>
      <td>0.820300</td>
      <td>0.819025</td>
      <td>-0.350068</td>
      <td>-0.140821</td>
      <td>0.302189</td>
      <td>-0.135399</td>
      <td>0.006079</td>
      <td>-0.882058</td>
      <td>-0.112857</td>
      <td>-0.324471</td>
      <td>-0.045916</td>
      <td>-0.289339</td>
      <td>0.561483</td>
      <td>0.213144</td>
      <td>0.520641</td>
      <td>0.030560</td>
      <td>0.367163</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.311086</td>
      <td>-0.190773</td>
      <td>-0.041737</td>
      <td>0.588734</td>
      <td>0.785638</td>
      <td>0.333951</td>
      <td>0.213777</td>
      <td>0.288182</td>
      <td>-0.449798</td>
      <td>0.682959</td>
      <td>0.133841</td>
      <td>-0.435093</td>
      <td>-0.011672</td>
      <td>-0.352718</td>
      <td>0.227652</td>
      <td>-0.095513</td>
      <td>-0.948881</td>
      <td>-0.511124</td>
      <td>-0.802566</td>
      <td>-0.811836</td>
      <td>-0.332702</td>
      <td>-0.640735</td>
      <td>-0.491266</td>
      <td>0.651289</td>
      <td>0.133249</td>
      <td>-0.239638</td>
      <td>0.288438</td>
      <td>-0.207351</td>
      <td>0.130449</td>
      <td>-0.130162</td>
      <td>-0.107731</td>
      <td>0.004119</td>
      <td>-1.915029</td>
      <td>-0.662348</td>
      <td>-0.576676</td>
      <td>-0.251279</td>
      <td>0.777621</td>
      <td>-0.229210</td>
      <td>-0.005636</td>
      <td>-0.514546</td>
      <td>...</td>
      <td>0.641421</td>
      <td>0.156803</td>
      <td>0.376921</td>
      <td>-0.298954</td>
      <td>-0.229433</td>
      <td>-0.359899</td>
      <td>0.896635</td>
      <td>-0.675092</td>
      <td>-0.090289</td>
      <td>-1.722624</td>
      <td>-0.850764</td>
      <td>-0.449691</td>
      <td>-0.463198</td>
      <td>-0.557568</td>
      <td>-0.135972</td>
      <td>0.116640</td>
      <td>0.701044</td>
      <td>1.549414</td>
      <td>-0.706077</td>
      <td>-1.708941</td>
      <td>-0.415507</td>
      <td>0.203924</td>
      <td>0.477303</td>
      <td>0.021785</td>
      <td>0.303241</td>
      <td>0.606483</td>
      <td>1.467890</td>
      <td>1.189520</td>
      <td>0.763164</td>
      <td>-0.059263</td>
      <td>-0.410650</td>
      <td>-0.211344</td>
      <td>-0.257748</td>
      <td>0.824247</td>
      <td>1.761055</td>
      <td>1.167020</td>
      <td>0.531283</td>
      <td>-0.906850</td>
      <td>-0.180987</td>
      <td>0.195017</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.198391</td>
      <td>-0.908924</td>
      <td>-0.488256</td>
      <td>-0.051225</td>
      <td>0.229941</td>
      <td>1.184169</td>
      <td>0.026266</td>
      <td>0.059872</td>
      <td>-0.090649</td>
      <td>0.314032</td>
      <td>-0.511870</td>
      <td>0.166370</td>
      <td>-0.023855</td>
      <td>0.001522</td>
      <td>0.086160</td>
      <td>-0.212535</td>
      <td>0.480779</td>
      <td>0.923296</td>
      <td>-0.641723</td>
      <td>-0.419301</td>
      <td>-1.024328</td>
      <td>0.191697</td>
      <td>-0.754147</td>
      <td>0.013157</td>
      <td>-0.091411</td>
      <td>0.100095</td>
      <td>0.263032</td>
      <td>0.861763</td>
      <td>-0.442075</td>
      <td>0.250360</td>
      <td>-0.158576</td>
      <td>0.851441</td>
      <td>-0.665919</td>
      <td>0.005818</td>
      <td>-0.051494</td>
      <td>-0.627630</td>
      <td>0.564094</td>
      <td>0.393332</td>
      <td>-0.230327</td>
      <td>-0.406014</td>
      <td>...</td>
      <td>0.185093</td>
      <td>-1.250644</td>
      <td>-0.276174</td>
      <td>-0.971163</td>
      <td>-0.131897</td>
      <td>-0.359397</td>
      <td>-0.223316</td>
      <td>0.303930</td>
      <td>0.119911</td>
      <td>0.009772</td>
      <td>0.457321</td>
      <td>0.688795</td>
      <td>0.655917</td>
      <td>0.861083</td>
      <td>0.655544</td>
      <td>-0.162014</td>
      <td>-0.325193</td>
      <td>-1.055070</td>
      <td>-0.147230</td>
      <td>-0.589995</td>
      <td>-0.725155</td>
      <td>0.458392</td>
      <td>0.314943</td>
      <td>-0.474215</td>
      <td>0.138937</td>
      <td>-0.651846</td>
      <td>-0.576663</td>
      <td>0.050594</td>
      <td>-0.416543</td>
      <td>0.704477</td>
      <td>-0.569043</td>
      <td>0.921375</td>
      <td>-0.444667</td>
      <td>0.816402</td>
      <td>0.173850</td>
      <td>0.188616</td>
      <td>0.257531</td>
      <td>-1.494881</td>
      <td>-1.472168</td>
      <td>-0.565696</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-1.248019</td>
      <td>-0.057656</td>
      <td>-0.220721</td>
      <td>1.101232</td>
      <td>0.892638</td>
      <td>0.410583</td>
      <td>0.771725</td>
      <td>0.390407</td>
      <td>-0.450502</td>
      <td>0.221678</td>
      <td>1.039947</td>
      <td>-0.179165</td>
      <td>0.589518</td>
      <td>-0.429028</td>
      <td>-1.330467</td>
      <td>-1.134236</td>
      <td>0.308573</td>
      <td>1.132757</td>
      <td>0.942675</td>
      <td>0.740055</td>
      <td>-0.664593</td>
      <td>-1.031596</td>
      <td>-0.843846</td>
      <td>-0.596877</td>
      <td>-1.586444</td>
      <td>-0.203554</td>
      <td>-0.685280</td>
      <td>-0.334256</td>
      <td>-0.624157</td>
      <td>-0.193779</td>
      <td>-0.033508</td>
      <td>-0.490356</td>
      <td>-0.661072</td>
      <td>0.026243</td>
      <td>0.071896</td>
      <td>0.683097</td>
      <td>0.254831</td>
      <td>-0.344839</td>
      <td>-0.877605</td>
      <td>-0.282751</td>
      <td>...</td>
      <td>-0.002851</td>
      <td>-1.321643</td>
      <td>-0.662055</td>
      <td>-0.085277</td>
      <td>-0.499960</td>
      <td>0.245680</td>
      <td>-0.413781</td>
      <td>0.792472</td>
      <td>0.019169</td>
      <td>0.578812</td>
      <td>-0.156611</td>
      <td>-1.447799</td>
      <td>0.048950</td>
      <td>-1.064001</td>
      <td>0.125676</td>
      <td>-0.702508</td>
      <td>0.167729</td>
      <td>0.441622</td>
      <td>-0.318650</td>
      <td>-0.722314</td>
      <td>-0.654133</td>
      <td>-0.774241</td>
      <td>0.169533</td>
      <td>-0.387122</td>
      <td>-1.368144</td>
      <td>1.429887</td>
      <td>-0.089994</td>
      <td>-1.265240</td>
      <td>0.733296</td>
      <td>0.160265</td>
      <td>-0.956931</td>
      <td>-0.158501</td>
      <td>0.642575</td>
      <td>0.806208</td>
      <td>-0.479463</td>
      <td>-0.126763</td>
      <td>0.710954</td>
      <td>-4.620684</td>
      <td>-3.351348</td>
      <td>-1.368772</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.151664</td>
      <td>0.033387</td>
      <td>0.568507</td>
      <td>0.609699</td>
      <td>0.862918</td>
      <td>0.054206</td>
      <td>-0.448674</td>
      <td>0.396555</td>
      <td>-0.455706</td>
      <td>0.976781</td>
      <td>-0.657528</td>
      <td>-1.097458</td>
      <td>0.318193</td>
      <td>-0.687126</td>
      <td>0.344732</td>
      <td>0.422657</td>
      <td>-0.567914</td>
      <td>0.927987</td>
      <td>-0.074136</td>
      <td>0.282647</td>
      <td>-0.440926</td>
      <td>-0.631830</td>
      <td>0.216708</td>
      <td>0.860505</td>
      <td>-0.086907</td>
      <td>-0.904147</td>
      <td>0.328775</td>
      <td>-0.172897</td>
      <td>0.084771</td>
      <td>-0.093330</td>
      <td>0.102476</td>
      <td>-0.150199</td>
      <td>-0.680465</td>
      <td>-0.624983</td>
      <td>-1.469681</td>
      <td>0.438281</td>
      <td>0.329667</td>
      <td>-1.280757</td>
      <td>-0.305457</td>
      <td>0.019514</td>
      <td>...</td>
      <td>-0.475159</td>
      <td>-0.716863</td>
      <td>-0.939203</td>
      <td>-0.621581</td>
      <td>0.363184</td>
      <td>0.556596</td>
      <td>0.067265</td>
      <td>0.035306</td>
      <td>1.547832</td>
      <td>0.574705</td>
      <td>0.862159</td>
      <td>0.657570</td>
      <td>0.743272</td>
      <td>-0.031699</td>
      <td>0.001601</td>
      <td>-0.309197</td>
      <td>0.252366</td>
      <td>-0.574101</td>
      <td>-0.434221</td>
      <td>-1.555826</td>
      <td>0.160829</td>
      <td>0.474223</td>
      <td>0.442744</td>
      <td>1.035851</td>
      <td>0.394361</td>
      <td>0.228417</td>
      <td>0.913960</td>
      <td>-0.376954</td>
      <td>0.464220</td>
      <td>1.118201</td>
      <td>0.403059</td>
      <td>0.097295</td>
      <td>0.732537</td>
      <td>0.749090</td>
      <td>0.734410</td>
      <td>0.171627</td>
      <td>0.102563</td>
      <td>-0.223807</td>
      <td>-0.770362</td>
      <td>0.122479</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.474650</td>
      <td>-0.086913</td>
      <td>-0.455491</td>
      <td>0.484196</td>
      <td>0.914366</td>
      <td>0.829932</td>
      <td>-1.274735</td>
      <td>-0.244983</td>
      <td>0.156940</td>
      <td>1.826057</td>
      <td>0.233780</td>
      <td>0.673048</td>
      <td>-0.802409</td>
      <td>-0.103977</td>
      <td>-0.695415</td>
      <td>-1.098968</td>
      <td>-0.356343</td>
      <td>-0.518847</td>
      <td>-0.168454</td>
      <td>0.455846</td>
      <td>0.052349</td>
      <td>0.150206</td>
      <td>0.422800</td>
      <td>-0.110500</td>
      <td>-0.728644</td>
      <td>-0.263556</td>
      <td>0.538037</td>
      <td>-0.466825</td>
      <td>-0.132524</td>
      <td>-0.283190</td>
      <td>0.399185</td>
      <td>-0.010048</td>
      <td>-0.524901</td>
      <td>-0.061881</td>
      <td>-0.650120</td>
      <td>0.211166</td>
      <td>1.258602</td>
      <td>0.091713</td>
      <td>-0.275381</td>
      <td>0.311582</td>
      <td>...</td>
      <td>-0.965317</td>
      <td>1.051132</td>
      <td>-1.233472</td>
      <td>-0.822986</td>
      <td>-0.185773</td>
      <td>-0.375837</td>
      <td>0.669948</td>
      <td>-0.572194</td>
      <td>-1.456005</td>
      <td>-0.865173</td>
      <td>-1.030576</td>
      <td>0.165611</td>
      <td>-0.247257</td>
      <td>0.256780</td>
      <td>-0.288514</td>
      <td>0.151727</td>
      <td>0.753831</td>
      <td>0.961123</td>
      <td>1.193930</td>
      <td>1.236784</td>
      <td>0.715991</td>
      <td>0.509106</td>
      <td>-0.013334</td>
      <td>0.621839</td>
      <td>-0.284505</td>
      <td>-0.545935</td>
      <td>-0.288848</td>
      <td>0.742595</td>
      <td>0.167259</td>
      <td>-0.729190</td>
      <td>-0.759917</td>
      <td>-0.790302</td>
      <td>0.531024</td>
      <td>1.710975</td>
      <td>0.778547</td>
      <td>-0.170810</td>
      <td>0.239648</td>
      <td>-3.033575</td>
      <td>-2.026329</td>
      <td>-0.239056</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-1.168729</td>
      <td>-0.123617</td>
      <td>-0.569786</td>
      <td>0.068782</td>
      <td>0.591085</td>
      <td>1.044787</td>
      <td>0.516196</td>
      <td>0.111218</td>
      <td>-0.894306</td>
      <td>-0.149916</td>
      <td>-1.780605</td>
      <td>-0.687014</td>
      <td>-0.384340</td>
      <td>-0.744633</td>
      <td>-0.122120</td>
      <td>-0.635752</td>
      <td>-0.637368</td>
      <td>1.965378</td>
      <td>0.084605</td>
      <td>0.234082</td>
      <td>0.081872</td>
      <td>-0.095015</td>
      <td>0.679452</td>
      <td>0.609587</td>
      <td>-1.051673</td>
      <td>-0.520579</td>
      <td>-0.790278</td>
      <td>-1.782048</td>
      <td>-1.051641</td>
      <td>0.093573</td>
      <td>0.221065</td>
      <td>0.837048</td>
      <td>-0.731409</td>
      <td>-0.444825</td>
      <td>-0.171501</td>
      <td>-0.037100</td>
      <td>0.493882</td>
      <td>0.609096</td>
      <td>0.127850</td>
      <td>0.320081</td>
      <td>...</td>
      <td>-0.399774</td>
      <td>-1.340378</td>
      <td>-0.590244</td>
      <td>-0.077193</td>
      <td>-0.568851</td>
      <td>-0.393124</td>
      <td>-0.766632</td>
      <td>-0.660359</td>
      <td>-0.348482</td>
      <td>-0.631824</td>
      <td>-0.228449</td>
      <td>-0.474440</td>
      <td>0.346029</td>
      <td>-0.864501</td>
      <td>0.133893</td>
      <td>-0.531238</td>
      <td>0.316254</td>
      <td>-0.037940</td>
      <td>0.872123</td>
      <td>-0.910075</td>
      <td>0.263221</td>
      <td>0.436263</td>
      <td>-0.395194</td>
      <td>0.234415</td>
      <td>-0.150879</td>
      <td>-0.990297</td>
      <td>-0.060777</td>
      <td>0.487587</td>
      <td>0.101931</td>
      <td>-0.491934</td>
      <td>-0.618730</td>
      <td>0.096089</td>
      <td>-0.272608</td>
      <td>0.040213</td>
      <td>-0.453478</td>
      <td>-0.263907</td>
      <td>0.611415</td>
      <td>-2.149541</td>
      <td>-1.503752</td>
      <td>-1.002575</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-0.640437</td>
      <td>0.091135</td>
      <td>1.440273</td>
      <td>0.457268</td>
      <td>0.743798</td>
      <td>-0.122133</td>
      <td>0.553270</td>
      <td>-0.301328</td>
      <td>-0.893152</td>
      <td>0.998719</td>
      <td>0.174559</td>
      <td>-0.716385</td>
      <td>-0.606959</td>
      <td>-0.333463</td>
      <td>-0.150389</td>
      <td>-0.486963</td>
      <td>-0.630826</td>
      <td>-0.092356</td>
      <td>-0.381563</td>
      <td>-0.020267</td>
      <td>-0.288822</td>
      <td>0.002261</td>
      <td>0.080220</td>
      <td>-0.643411</td>
      <td>-1.285853</td>
      <td>-0.342117</td>
      <td>-0.152864</td>
      <td>0.581271</td>
      <td>0.923961</td>
      <td>0.204909</td>
      <td>0.501987</td>
      <td>-0.002973</td>
      <td>0.079165</td>
      <td>-0.325349</td>
      <td>0.698785</td>
      <td>0.846148</td>
      <td>0.658954</td>
      <td>-0.159603</td>
      <td>0.724364</td>
      <td>0.608580</td>
      <td>...</td>
      <td>0.131266</td>
      <td>0.078269</td>
      <td>0.464615</td>
      <td>-0.622428</td>
      <td>-0.344483</td>
      <td>0.395966</td>
      <td>0.393070</td>
      <td>0.604526</td>
      <td>0.796397</td>
      <td>0.284345</td>
      <td>0.802924</td>
      <td>0.342761</td>
      <td>-0.255428</td>
      <td>-0.446283</td>
      <td>0.244022</td>
      <td>-0.152168</td>
      <td>-0.131665</td>
      <td>0.132230</td>
      <td>0.285494</td>
      <td>1.053787</td>
      <td>-0.037599</td>
      <td>0.388508</td>
      <td>0.216308</td>
      <td>1.740703</td>
      <td>0.115007</td>
      <td>0.903574</td>
      <td>0.175885</td>
      <td>-0.493635</td>
      <td>-0.204083</td>
      <td>-0.169786</td>
      <td>-0.430173</td>
      <td>0.438287</td>
      <td>0.865951</td>
      <td>0.813343</td>
      <td>0.927955</td>
      <td>-0.389424</td>
      <td>1.163095</td>
      <td>-1.531337</td>
      <td>-0.612151</td>
      <td>0.803872</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.871502</td>
      <td>-0.768971</td>
      <td>0.099257</td>
      <td>-0.300557</td>
      <td>-0.264060</td>
      <td>0.277427</td>
      <td>-0.822468</td>
      <td>-0.575841</td>
      <td>-0.349658</td>
      <td>1.326289</td>
      <td>-0.064440</td>
      <td>0.525411</td>
      <td>-0.009725</td>
      <td>1.114059</td>
      <td>1.426422</td>
      <td>-0.912195</td>
      <td>-0.594487</td>
      <td>0.676506</td>
      <td>0.319995</td>
      <td>-0.285927</td>
      <td>0.440320</td>
      <td>-0.558231</td>
      <td>-0.533076</td>
      <td>0.131458</td>
      <td>-0.212279</td>
      <td>-0.402203</td>
      <td>-0.136678</td>
      <td>-0.592109</td>
      <td>-0.086891</td>
      <td>1.066699</td>
      <td>0.208859</td>
      <td>0.400920</td>
      <td>-0.508199</td>
      <td>0.453726</td>
      <td>-0.490091</td>
      <td>-0.494532</td>
      <td>1.325691</td>
      <td>1.445484</td>
      <td>1.174698</td>
      <td>0.021381</td>
      <td>...</td>
      <td>-0.502841</td>
      <td>-0.206759</td>
      <td>0.375114</td>
      <td>-0.047389</td>
      <td>0.153367</td>
      <td>0.104751</td>
      <td>-0.512411</td>
      <td>-0.794893</td>
      <td>0.131327</td>
      <td>0.248922</td>
      <td>0.525134</td>
      <td>0.256655</td>
      <td>0.899683</td>
      <td>-0.555416</td>
      <td>0.560950</td>
      <td>0.105091</td>
      <td>0.725491</td>
      <td>0.611230</td>
      <td>0.652580</td>
      <td>-0.354670</td>
      <td>-0.559877</td>
      <td>-0.951317</td>
      <td>0.419851</td>
      <td>0.076860</td>
      <td>0.447581</td>
      <td>0.767343</td>
      <td>0.823144</td>
      <td>0.295853</td>
      <td>0.695067</td>
      <td>0.794870</td>
      <td>0.742732</td>
      <td>-0.579004</td>
      <td>-0.970959</td>
      <td>0.282060</td>
      <td>0.382690</td>
      <td>-0.835351</td>
      <td>-0.321893</td>
      <td>-3.768439</td>
      <td>-2.559370</td>
      <td>-1.254866</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-0.335832</td>
      <td>0.159571</td>
      <td>0.491291</td>
      <td>0.858185</td>
      <td>0.472050</td>
      <td>0.687135</td>
      <td>0.376103</td>
      <td>0.147064</td>
      <td>-0.013276</td>
      <td>0.383014</td>
      <td>0.033906</td>
      <td>-0.301498</td>
      <td>-0.600241</td>
      <td>0.103825</td>
      <td>1.366893</td>
      <td>0.130578</td>
      <td>-0.685870</td>
      <td>0.342541</td>
      <td>-0.334743</td>
      <td>-0.378829</td>
      <td>-0.307977</td>
      <td>0.146652</td>
      <td>1.139367</td>
      <td>0.819057</td>
      <td>1.108197</td>
      <td>0.171920</td>
      <td>-0.465538</td>
      <td>-0.295323</td>
      <td>0.580556</td>
      <td>1.194908</td>
      <td>0.795812</td>
      <td>0.739795</td>
      <td>-0.647910</td>
      <td>0.020322</td>
      <td>0.639104</td>
      <td>0.409817</td>
      <td>0.445242</td>
      <td>0.045629</td>
      <td>-0.610911</td>
      <td>-0.852181</td>
      <td>...</td>
      <td>-1.422062</td>
      <td>-1.134329</td>
      <td>-1.453869</td>
      <td>-0.683531</td>
      <td>-0.494727</td>
      <td>-0.574023</td>
      <td>0.640262</td>
      <td>-0.249477</td>
      <td>0.298699</td>
      <td>0.271164</td>
      <td>0.053645</td>
      <td>-0.127258</td>
      <td>0.615164</td>
      <td>0.553098</td>
      <td>-0.447737</td>
      <td>0.187372</td>
      <td>1.103495</td>
      <td>0.690100</td>
      <td>0.363947</td>
      <td>-1.323325</td>
      <td>-0.038292</td>
      <td>0.047324</td>
      <td>-0.295348</td>
      <td>1.072340</td>
      <td>0.407182</td>
      <td>1.281225</td>
      <td>0.051801</td>
      <td>1.308014</td>
      <td>0.369557</td>
      <td>0.387517</td>
      <td>-0.590956</td>
      <td>0.124639</td>
      <td>0.029896</td>
      <td>0.498643</td>
      <td>0.117314</td>
      <td>0.406733</td>
      <td>0.134816</td>
      <td>-0.023317</td>
      <td>0.111708</td>
      <td>0.390075</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.839919</td>
      <td>0.967179</td>
      <td>0.186886</td>
      <td>-0.336967</td>
      <td>-0.043500</td>
      <td>0.432842</td>
      <td>0.165023</td>
      <td>0.207341</td>
      <td>-0.702283</td>
      <td>-0.285069</td>
      <td>-0.673538</td>
      <td>-0.418250</td>
      <td>-0.649353</td>
      <td>-0.101340</td>
      <td>0.489102</td>
      <td>-0.101405</td>
      <td>0.252534</td>
      <td>0.902490</td>
      <td>0.583270</td>
      <td>0.450948</td>
      <td>0.730827</td>
      <td>0.237348</td>
      <td>-0.232686</td>
      <td>-0.058410</td>
      <td>-1.143473</td>
      <td>0.004469</td>
      <td>0.941495</td>
      <td>0.326317</td>
      <td>1.355489</td>
      <td>-0.064240</td>
      <td>0.774872</td>
      <td>0.438729</td>
      <td>-1.183552</td>
      <td>-0.580016</td>
      <td>0.442580</td>
      <td>-0.190945</td>
      <td>0.784460</td>
      <td>1.017878</td>
      <td>0.337855</td>
      <td>-0.105480</td>
      <td>...</td>
      <td>-0.478127</td>
      <td>-1.096764</td>
      <td>-0.403179</td>
      <td>-0.231885</td>
      <td>-0.196940</td>
      <td>0.476364</td>
      <td>1.088322</td>
      <td>-1.465454</td>
      <td>-0.910066</td>
      <td>-0.672343</td>
      <td>0.144352</td>
      <td>0.411466</td>
      <td>0.495588</td>
      <td>0.155343</td>
      <td>0.738137</td>
      <td>-0.137674</td>
      <td>0.388931</td>
      <td>0.709352</td>
      <td>-0.409641</td>
      <td>-0.656253</td>
      <td>0.531746</td>
      <td>0.128826</td>
      <td>-0.060745</td>
      <td>-0.543963</td>
      <td>-1.101475</td>
      <td>-0.269123</td>
      <td>-0.021010</td>
      <td>0.645652</td>
      <td>-0.290141</td>
      <td>-0.367922</td>
      <td>0.203088</td>
      <td>0.727549</td>
      <td>0.499684</td>
      <td>0.509790</td>
      <td>0.609116</td>
      <td>1.914359</td>
      <td>-0.491255</td>
      <td>2.530710</td>
      <td>0.617196</td>
      <td>0.640032</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.216988</td>
      <td>-0.713157</td>
      <td>-0.378820</td>
      <td>0.233420</td>
      <td>-0.459075</td>
      <td>0.443300</td>
      <td>0.713668</td>
      <td>0.002536</td>
      <td>-0.806480</td>
      <td>0.887565</td>
      <td>-0.075478</td>
      <td>0.115422</td>
      <td>-0.281316</td>
      <td>-0.203262</td>
      <td>0.181617</td>
      <td>-0.866575</td>
      <td>-0.097488</td>
      <td>-0.172000</td>
      <td>-0.560362</td>
      <td>-0.180154</td>
      <td>-0.322174</td>
      <td>-0.059135</td>
      <td>0.501449</td>
      <td>-0.159466</td>
      <td>-0.934227</td>
      <td>-0.415726</td>
      <td>0.220817</td>
      <td>-0.792882</td>
      <td>0.197907</td>
      <td>0.605604</td>
      <td>0.962066</td>
      <td>0.657826</td>
      <td>-1.480550</td>
      <td>-0.434066</td>
      <td>-0.700117</td>
      <td>0.050737</td>
      <td>1.095713</td>
      <td>-0.826775</td>
      <td>-1.329213</td>
      <td>-0.123647</td>
      <td>...</td>
      <td>-0.606186</td>
      <td>-0.467447</td>
      <td>-0.481641</td>
      <td>-0.100975</td>
      <td>0.095204</td>
      <td>-0.364056</td>
      <td>0.064215</td>
      <td>0.732238</td>
      <td>0.140276</td>
      <td>-0.568621</td>
      <td>-0.135292</td>
      <td>0.449842</td>
      <td>0.627024</td>
      <td>-0.318355</td>
      <td>-0.186537</td>
      <td>0.253795</td>
      <td>0.276642</td>
      <td>0.050843</td>
      <td>0.940839</td>
      <td>0.923991</td>
      <td>-0.134889</td>
      <td>-0.505165</td>
      <td>-0.777259</td>
      <td>-0.729237</td>
      <td>-0.611849</td>
      <td>0.319999</td>
      <td>0.129606</td>
      <td>0.395521</td>
      <td>-0.611672</td>
      <td>0.436062</td>
      <td>-0.835968</td>
      <td>0.194995</td>
      <td>0.988627</td>
      <td>1.058825</td>
      <td>-0.511039</td>
      <td>0.958844</td>
      <td>0.293382</td>
      <td>-1.650390</td>
      <td>-2.573515</td>
      <td>-1.676444</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.217916</td>
      <td>-0.079079</td>
      <td>-0.508149</td>
      <td>0.059955</td>
      <td>0.521474</td>
      <td>0.990606</td>
      <td>0.232063</td>
      <td>0.419301</td>
      <td>-0.830735</td>
      <td>0.574157</td>
      <td>0.381833</td>
      <td>1.042713</td>
      <td>0.101593</td>
      <td>-0.319602</td>
      <td>-0.151197</td>
      <td>-0.980488</td>
      <td>0.072401</td>
      <td>0.450162</td>
      <td>-0.410335</td>
      <td>0.078061</td>
      <td>0.391052</td>
      <td>-0.510120</td>
      <td>-0.237406</td>
      <td>0.734271</td>
      <td>-0.166227</td>
      <td>0.192491</td>
      <td>-0.330602</td>
      <td>-0.586168</td>
      <td>0.573031</td>
      <td>-0.233999</td>
      <td>1.114607</td>
      <td>0.640660</td>
      <td>1.151969</td>
      <td>1.038211</td>
      <td>0.828759</td>
      <td>-0.088087</td>
      <td>0.614532</td>
      <td>-0.052082</td>
      <td>0.583237</td>
      <td>1.111923</td>
      <td>...</td>
      <td>0.117570</td>
      <td>0.124596</td>
      <td>-0.199403</td>
      <td>0.022240</td>
      <td>0.196061</td>
      <td>0.156421</td>
      <td>-0.033845</td>
      <td>0.262713</td>
      <td>1.279382</td>
      <td>1.359864</td>
      <td>0.130524</td>
      <td>-0.211452</td>
      <td>0.844311</td>
      <td>-0.519906</td>
      <td>0.118422</td>
      <td>-0.289040</td>
      <td>1.106028</td>
      <td>0.605596</td>
      <td>-0.040558</td>
      <td>0.107118</td>
      <td>-0.561499</td>
      <td>0.359345</td>
      <td>1.208359</td>
      <td>-0.012861</td>
      <td>-0.307311</td>
      <td>-0.939785</td>
      <td>-0.082014</td>
      <td>0.528192</td>
      <td>0.272526</td>
      <td>-0.559528</td>
      <td>-0.946758</td>
      <td>0.310510</td>
      <td>-1.371842</td>
      <td>-0.052246</td>
      <td>0.539119</td>
      <td>0.351993</td>
      <td>0.612796</td>
      <td>-0.329063</td>
      <td>-0.218718</td>
      <td>0.135834</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.140792</td>
      <td>-0.448318</td>
      <td>-0.341432</td>
      <td>0.371732</td>
      <td>0.466675</td>
      <td>0.904987</td>
      <td>-0.169378</td>
      <td>-0.389414</td>
      <td>0.060623</td>
      <td>0.476334</td>
      <td>-0.215470</td>
      <td>-0.971711</td>
      <td>-1.109206</td>
      <td>0.221290</td>
      <td>-0.712826</td>
      <td>-1.276345</td>
      <td>-0.664069</td>
      <td>0.545639</td>
      <td>-0.289444</td>
      <td>-0.085906</td>
      <td>0.572152</td>
      <td>-0.726238</td>
      <td>0.351212</td>
      <td>0.566203</td>
      <td>0.064538</td>
      <td>-0.053388</td>
      <td>-0.910245</td>
      <td>-0.414781</td>
      <td>0.638057</td>
      <td>-0.214798</td>
      <td>0.024693</td>
      <td>-0.122906</td>
      <td>-1.160289</td>
      <td>-0.276914</td>
      <td>0.534244</td>
      <td>0.814601</td>
      <td>0.852725</td>
      <td>-0.489247</td>
      <td>-0.910010</td>
      <td>-0.263226</td>
      <td>...</td>
      <td>0.099301</td>
      <td>-0.243613</td>
      <td>-0.378345</td>
      <td>-0.276972</td>
      <td>-0.306221</td>
      <td>-0.108845</td>
      <td>-0.382864</td>
      <td>0.138457</td>
      <td>-0.470641</td>
      <td>0.736239</td>
      <td>0.702239</td>
      <td>0.540308</td>
      <td>-0.077242</td>
      <td>0.462862</td>
      <td>0.042012</td>
      <td>0.208480</td>
      <td>0.097092</td>
      <td>0.804921</td>
      <td>0.209796</td>
      <td>-0.369194</td>
      <td>-0.757989</td>
      <td>-0.481398</td>
      <td>-0.277519</td>
      <td>-0.358216</td>
      <td>-1.473667</td>
      <td>-0.534068</td>
      <td>-0.472514</td>
      <td>0.850557</td>
      <td>-0.028778</td>
      <td>0.640608</td>
      <td>-0.624373</td>
      <td>0.035497</td>
      <td>-0.522849</td>
      <td>-0.384314</td>
      <td>0.371016</td>
      <td>0.448671</td>
      <td>0.575119</td>
      <td>-1.471928</td>
      <td>-0.652939</td>
      <td>-0.013203</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.084654</td>
      <td>0.600577</td>
      <td>-0.330355</td>
      <td>-0.715952</td>
      <td>-0.376506</td>
      <td>0.406084</td>
      <td>0.333524</td>
      <td>1.283813</td>
      <td>-0.377957</td>
      <td>0.053209</td>
      <td>-1.378143</td>
      <td>-0.823106</td>
      <td>-0.476330</td>
      <td>-0.387486</td>
      <td>-1.111228</td>
      <td>-0.359868</td>
      <td>0.160822</td>
      <td>1.176155</td>
      <td>-0.532008</td>
      <td>0.066016</td>
      <td>0.057343</td>
      <td>-0.264658</td>
      <td>-0.821080</td>
      <td>0.742301</td>
      <td>-0.884707</td>
      <td>-0.060068</td>
      <td>0.549522</td>
      <td>-0.295037</td>
      <td>0.080892</td>
      <td>-0.388706</td>
      <td>0.857372</td>
      <td>-0.233788</td>
      <td>-1.955253</td>
      <td>-0.655639</td>
      <td>0.552517</td>
      <td>-0.466192</td>
      <td>0.668553</td>
      <td>-0.187495</td>
      <td>-0.196956</td>
      <td>0.170186</td>
      <td>...</td>
      <td>-0.084578</td>
      <td>0.045040</td>
      <td>1.538365</td>
      <td>0.053022</td>
      <td>-0.764327</td>
      <td>-0.457493</td>
      <td>-0.331516</td>
      <td>0.504507</td>
      <td>0.169666</td>
      <td>-0.661594</td>
      <td>0.062987</td>
      <td>-0.867426</td>
      <td>0.455756</td>
      <td>-0.340456</td>
      <td>0.421869</td>
      <td>0.083371</td>
      <td>0.325222</td>
      <td>0.038459</td>
      <td>1.268510</td>
      <td>-0.652368</td>
      <td>0.227293</td>
      <td>-0.173804</td>
      <td>0.659110</td>
      <td>0.042357</td>
      <td>0.177871</td>
      <td>0.030078</td>
      <td>-0.269438</td>
      <td>-0.281507</td>
      <td>-0.130793</td>
      <td>0.413753</td>
      <td>-0.138470</td>
      <td>0.147153</td>
      <td>0.607989</td>
      <td>0.802386</td>
      <td>0.679810</td>
      <td>1.130524</td>
      <td>1.132942</td>
      <td>1.050436</td>
      <td>0.659093</td>
      <td>0.659628</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.869630</td>
      <td>0.108192</td>
      <td>-0.046316</td>
      <td>0.055234</td>
      <td>0.354219</td>
      <td>0.604688</td>
      <td>0.448513</td>
      <td>0.823121</td>
      <td>-0.558871</td>
      <td>1.151752</td>
      <td>-0.330475</td>
      <td>-0.481640</td>
      <td>-0.955511</td>
      <td>-0.276864</td>
      <td>0.737209</td>
      <td>-0.764004</td>
      <td>-1.032785</td>
      <td>-0.192357</td>
      <td>-0.453564</td>
      <td>-0.567346</td>
      <td>0.094681</td>
      <td>0.508271</td>
      <td>-0.036144</td>
      <td>0.521101</td>
      <td>-0.176755</td>
      <td>0.027958</td>
      <td>-0.089339</td>
      <td>0.398579</td>
      <td>0.697642</td>
      <td>-0.154716</td>
      <td>-0.418714</td>
      <td>0.545809</td>
      <td>-0.182516</td>
      <td>-0.398543</td>
      <td>0.214984</td>
      <td>-0.213334</td>
      <td>0.592550</td>
      <td>0.686496</td>
      <td>-0.537830</td>
      <td>-0.982846</td>
      <td>...</td>
      <td>-1.016892</td>
      <td>-0.461825</td>
      <td>-0.181867</td>
      <td>-1.083872</td>
      <td>-0.602519</td>
      <td>-0.660097</td>
      <td>-0.316589</td>
      <td>-0.337119</td>
      <td>-0.291140</td>
      <td>-0.681887</td>
      <td>0.004068</td>
      <td>0.161461</td>
      <td>0.004972</td>
      <td>-0.035999</td>
      <td>0.824458</td>
      <td>-0.625618</td>
      <td>0.302555</td>
      <td>0.487063</td>
      <td>-0.106610</td>
      <td>-0.441565</td>
      <td>-0.274515</td>
      <td>-1.021037</td>
      <td>0.350393</td>
      <td>-1.269944</td>
      <td>-0.634214</td>
      <td>0.002996</td>
      <td>0.273358</td>
      <td>-1.139064</td>
      <td>-0.284500</td>
      <td>0.066502</td>
      <td>-0.754592</td>
      <td>0.839863</td>
      <td>-0.182448</td>
      <td>-1.122480</td>
      <td>-0.182678</td>
      <td>-0.351300</td>
      <td>-0.224811</td>
      <td>-1.195720</td>
      <td>-1.158717</td>
      <td>0.320611</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.590456</td>
      <td>0.046352</td>
      <td>0.149286</td>
      <td>-0.487445</td>
      <td>0.369964</td>
      <td>0.355805</td>
      <td>0.176052</td>
      <td>0.455150</td>
      <td>-0.734947</td>
      <td>0.203322</td>
      <td>0.065897</td>
      <td>0.149960</td>
      <td>-0.020772</td>
      <td>-0.771854</td>
      <td>0.139483</td>
      <td>-1.254964</td>
      <td>-0.077264</td>
      <td>0.810454</td>
      <td>-0.275710</td>
      <td>-0.034744</td>
      <td>-1.386316</td>
      <td>-1.215093</td>
      <td>-0.444520</td>
      <td>1.466290</td>
      <td>-0.238431</td>
      <td>-1.209030</td>
      <td>-0.064472</td>
      <td>0.492777</td>
      <td>-0.605832</td>
      <td>0.094226</td>
      <td>0.084103</td>
      <td>-0.031078</td>
      <td>-0.927547</td>
      <td>-0.422543</td>
      <td>0.167925</td>
      <td>-0.366781</td>
      <td>0.224474</td>
      <td>0.436244</td>
      <td>-0.343725</td>
      <td>-0.049656</td>
      <td>...</td>
      <td>0.405892</td>
      <td>-0.202073</td>
      <td>-0.857243</td>
      <td>-0.392001</td>
      <td>-0.696907</td>
      <td>-0.597423</td>
      <td>0.081731</td>
      <td>-0.488495</td>
      <td>-0.474681</td>
      <td>-0.571435</td>
      <td>-0.181949</td>
      <td>1.121804</td>
      <td>1.764811</td>
      <td>0.803669</td>
      <td>1.009728</td>
      <td>0.236328</td>
      <td>-0.058276</td>
      <td>-0.110360</td>
      <td>-0.949157</td>
      <td>-0.782908</td>
      <td>-0.459096</td>
      <td>-0.356659</td>
      <td>-0.272524</td>
      <td>0.669186</td>
      <td>-0.320709</td>
      <td>0.235318</td>
      <td>-0.320764</td>
      <td>-0.017520</td>
      <td>0.395785</td>
      <td>-0.694359</td>
      <td>-0.778595</td>
      <td>-0.047142</td>
      <td>0.270079</td>
      <td>-0.121164</td>
      <td>-0.383453</td>
      <td>0.505640</td>
      <td>1.047141</td>
      <td>-2.319108</td>
      <td>-1.458212</td>
      <td>0.028726</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-1.114356</td>
      <td>-0.282687</td>
      <td>0.006484</td>
      <td>1.082514</td>
      <td>0.613417</td>
      <td>0.123357</td>
      <td>-0.638306</td>
      <td>0.043300</td>
      <td>-1.242904</td>
      <td>0.914729</td>
      <td>0.252729</td>
      <td>0.445233</td>
      <td>-0.529385</td>
      <td>0.434529</td>
      <td>-0.253709</td>
      <td>-0.252859</td>
      <td>-0.264261</td>
      <td>-0.309934</td>
      <td>-0.436221</td>
      <td>-0.323748</td>
      <td>-0.742628</td>
      <td>-0.378211</td>
      <td>-0.294483</td>
      <td>0.243132</td>
      <td>-0.421955</td>
      <td>0.024042</td>
      <td>-0.162592</td>
      <td>-0.496855</td>
      <td>-0.558151</td>
      <td>0.135139</td>
      <td>-0.986897</td>
      <td>-0.059084</td>
      <td>-0.511900</td>
      <td>0.282595</td>
      <td>0.263037</td>
      <td>0.790707</td>
      <td>0.127765</td>
      <td>0.080767</td>
      <td>0.102392</td>
      <td>0.202124</td>
      <td>...</td>
      <td>-0.321792</td>
      <td>-0.657327</td>
      <td>-0.572472</td>
      <td>-0.594990</td>
      <td>-0.101534</td>
      <td>-0.148681</td>
      <td>0.603136</td>
      <td>0.111750</td>
      <td>-0.074266</td>
      <td>-0.159497</td>
      <td>0.286142</td>
      <td>0.274892</td>
      <td>0.587538</td>
      <td>0.323753</td>
      <td>1.202617</td>
      <td>-0.435480</td>
      <td>-0.285237</td>
      <td>0.005250</td>
      <td>0.298063</td>
      <td>-0.111373</td>
      <td>0.002467</td>
      <td>-0.085025</td>
      <td>0.266595</td>
      <td>0.203948</td>
      <td>0.071784</td>
      <td>-0.031992</td>
      <td>-0.874791</td>
      <td>-0.151641</td>
      <td>0.089053</td>
      <td>-0.430215</td>
      <td>-0.501173</td>
      <td>-0.394820</td>
      <td>-1.099421</td>
      <td>0.251082</td>
      <td>-0.197021</td>
      <td>-0.073996</td>
      <td>1.706198</td>
      <td>-2.871818</td>
      <td>-1.896838</td>
      <td>-1.259730</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-1.132393</td>
      <td>-1.133678</td>
      <td>-0.100174</td>
      <td>0.150741</td>
      <td>0.101424</td>
      <td>0.940472</td>
      <td>0.676064</td>
      <td>-0.316765</td>
      <td>-0.906656</td>
      <td>0.410504</td>
      <td>0.422709</td>
      <td>-0.511250</td>
      <td>0.167917</td>
      <td>-0.752335</td>
      <td>-0.120577</td>
      <td>-0.153730</td>
      <td>-0.199972</td>
      <td>0.498027</td>
      <td>-0.203727</td>
      <td>-0.092101</td>
      <td>-0.366813</td>
      <td>-0.183320</td>
      <td>-0.904168</td>
      <td>0.207983</td>
      <td>-0.324284</td>
      <td>0.037331</td>
      <td>-0.090918</td>
      <td>0.105595</td>
      <td>0.223575</td>
      <td>-0.656490</td>
      <td>0.721082</td>
      <td>0.354785</td>
      <td>-1.084166</td>
      <td>0.592961</td>
      <td>0.110421</td>
      <td>0.427642</td>
      <td>0.795162</td>
      <td>0.977042</td>
      <td>0.118689</td>
      <td>0.200092</td>
      <td>...</td>
      <td>-0.028202</td>
      <td>-0.116697</td>
      <td>0.182643</td>
      <td>-0.868053</td>
      <td>0.207817</td>
      <td>-0.098078</td>
      <td>-0.397622</td>
      <td>-0.527971</td>
      <td>0.308370</td>
      <td>0.070988</td>
      <td>-0.139214</td>
      <td>0.276303</td>
      <td>-0.096924</td>
      <td>0.234070</td>
      <td>1.203913</td>
      <td>-0.166847</td>
      <td>0.041520</td>
      <td>0.054454</td>
      <td>-1.977462</td>
      <td>-0.890717</td>
      <td>-1.403590</td>
      <td>-0.727120</td>
      <td>-0.674607</td>
      <td>0.176583</td>
      <td>-0.742005</td>
      <td>-0.442110</td>
      <td>0.289790</td>
      <td>0.141386</td>
      <td>0.384352</td>
      <td>0.243773</td>
      <td>-1.060891</td>
      <td>0.155204</td>
      <td>0.452497</td>
      <td>0.288253</td>
      <td>0.732326</td>
      <td>-0.522443</td>
      <td>1.612301</td>
      <td>-3.633485</td>
      <td>-2.764001</td>
      <td>-0.328289</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.907490</td>
      <td>-0.013524</td>
      <td>0.906946</td>
      <td>-0.571170</td>
      <td>0.309932</td>
      <td>0.343927</td>
      <td>0.211321</td>
      <td>0.919091</td>
      <td>-0.617501</td>
      <td>0.545487</td>
      <td>0.049138</td>
      <td>0.823903</td>
      <td>-0.299746</td>
      <td>0.234624</td>
      <td>0.795821</td>
      <td>-0.444199</td>
      <td>-0.596456</td>
      <td>0.052739</td>
      <td>-0.571984</td>
      <td>-0.131374</td>
      <td>-0.142598</td>
      <td>0.336911</td>
      <td>-0.945829</td>
      <td>0.146650</td>
      <td>0.013965</td>
      <td>0.392504</td>
      <td>0.075942</td>
      <td>-0.192385</td>
      <td>1.107813</td>
      <td>-0.394339</td>
      <td>-0.199491</td>
      <td>-0.389063</td>
      <td>-0.920356</td>
      <td>-0.605705</td>
      <td>-0.059159</td>
      <td>0.243093</td>
      <td>1.120068</td>
      <td>0.745936</td>
      <td>0.812839</td>
      <td>0.196726</td>
      <td>...</td>
      <td>0.365155</td>
      <td>0.339607</td>
      <td>-0.204973</td>
      <td>-0.512019</td>
      <td>0.773614</td>
      <td>0.266415</td>
      <td>0.221016</td>
      <td>-0.502023</td>
      <td>-0.468470</td>
      <td>-0.088179</td>
      <td>-0.263685</td>
      <td>0.650750</td>
      <td>0.273405</td>
      <td>0.178642</td>
      <td>-0.171056</td>
      <td>0.304391</td>
      <td>-0.328097</td>
      <td>-0.703398</td>
      <td>-1.151027</td>
      <td>-0.532774</td>
      <td>-0.231379</td>
      <td>0.054889</td>
      <td>-0.519259</td>
      <td>0.372922</td>
      <td>0.198780</td>
      <td>0.948856</td>
      <td>0.529643</td>
      <td>0.553965</td>
      <td>-0.406821</td>
      <td>-0.338743</td>
      <td>-1.005552</td>
      <td>0.360776</td>
      <td>0.561596</td>
      <td>0.495050</td>
      <td>0.583389</td>
      <td>0.438875</td>
      <td>0.118705</td>
      <td>2.135807</td>
      <td>0.818546</td>
      <td>-0.056405</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.596881</td>
      <td>0.267333</td>
      <td>0.872034</td>
      <td>1.039050</td>
      <td>1.290263</td>
      <td>0.245061</td>
      <td>0.578728</td>
      <td>0.738366</td>
      <td>-0.144151</td>
      <td>-0.065259</td>
      <td>-0.542877</td>
      <td>-0.723036</td>
      <td>0.542372</td>
      <td>-0.017269</td>
      <td>-0.287172</td>
      <td>-1.250680</td>
      <td>-0.728714</td>
      <td>0.038080</td>
      <td>-0.363533</td>
      <td>0.066984</td>
      <td>0.679267</td>
      <td>-0.547333</td>
      <td>-0.655091</td>
      <td>0.682177</td>
      <td>-1.240138</td>
      <td>0.111327</td>
      <td>0.476178</td>
      <td>-0.765070</td>
      <td>-0.187711</td>
      <td>0.447432</td>
      <td>0.255378</td>
      <td>0.498258</td>
      <td>-0.951385</td>
      <td>-0.185165</td>
      <td>-0.177881</td>
      <td>0.600721</td>
      <td>0.576755</td>
      <td>0.100763</td>
      <td>-0.482931</td>
      <td>0.481162</td>
      <td>...</td>
      <td>1.028479</td>
      <td>0.078919</td>
      <td>0.170557</td>
      <td>-0.192570</td>
      <td>-0.131386</td>
      <td>-0.540982</td>
      <td>-0.578360</td>
      <td>-0.462489</td>
      <td>-0.201776</td>
      <td>-0.414077</td>
      <td>0.335648</td>
      <td>0.065096</td>
      <td>0.089349</td>
      <td>-0.273076</td>
      <td>-0.287511</td>
      <td>-0.204264</td>
      <td>-0.109706</td>
      <td>0.570547</td>
      <td>0.566829</td>
      <td>-0.122490</td>
      <td>-0.324597</td>
      <td>-0.387397</td>
      <td>1.094904</td>
      <td>-0.755965</td>
      <td>-0.543599</td>
      <td>-0.140167</td>
      <td>-0.768152</td>
      <td>0.030428</td>
      <td>-0.265840</td>
      <td>-0.831146</td>
      <td>-0.149535</td>
      <td>-0.674159</td>
      <td>-0.082750</td>
      <td>0.490190</td>
      <td>0.234832</td>
      <td>1.210639</td>
      <td>1.241145</td>
      <td>-0.667562</td>
      <td>-0.881302</td>
      <td>0.096296</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.049787</td>
      <td>-0.455501</td>
      <td>0.187722</td>
      <td>0.110762</td>
      <td>0.250238</td>
      <td>1.149463</td>
      <td>0.013198</td>
      <td>-0.082275</td>
      <td>-0.249222</td>
      <td>0.026923</td>
      <td>-0.749703</td>
      <td>-1.174904</td>
      <td>-1.042570</td>
      <td>-0.642760</td>
      <td>-0.624905</td>
      <td>-0.116983</td>
      <td>-0.146905</td>
      <td>-0.058828</td>
      <td>0.273378</td>
      <td>0.201608</td>
      <td>-0.660500</td>
      <td>0.061344</td>
      <td>0.939045</td>
      <td>1.340153</td>
      <td>1.296685</td>
      <td>1.072002</td>
      <td>0.542784</td>
      <td>0.244155</td>
      <td>0.030662</td>
      <td>0.265459</td>
      <td>-0.124039</td>
      <td>-0.030611</td>
      <td>-0.143059</td>
      <td>-0.343912</td>
      <td>0.121778</td>
      <td>-0.684137</td>
      <td>0.128468</td>
      <td>0.622036</td>
      <td>0.673311</td>
      <td>0.201353</td>
      <td>...</td>
      <td>0.297417</td>
      <td>-0.549327</td>
      <td>-0.154752</td>
      <td>-1.307134</td>
      <td>-0.556575</td>
      <td>-0.353358</td>
      <td>0.588847</td>
      <td>0.236129</td>
      <td>-0.435326</td>
      <td>0.222119</td>
      <td>0.525021</td>
      <td>0.233724</td>
      <td>-0.188969</td>
      <td>-1.613396</td>
      <td>-0.796298</td>
      <td>-0.983317</td>
      <td>-0.161852</td>
      <td>0.545620</td>
      <td>-0.773924</td>
      <td>-0.794194</td>
      <td>0.570243</td>
      <td>0.897524</td>
      <td>-0.683866</td>
      <td>0.461394</td>
      <td>-0.171901</td>
      <td>0.068273</td>
      <td>-1.299239</td>
      <td>-0.865593</td>
      <td>0.273961</td>
      <td>1.021883</td>
      <td>0.274167</td>
      <td>0.099576</td>
      <td>-0.132002</td>
      <td>0.127178</td>
      <td>-0.141308</td>
      <td>0.506090</td>
      <td>0.808850</td>
      <td>-0.089084</td>
      <td>0.023750</td>
      <td>0.292971</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.131462</td>
      <td>0.181459</td>
      <td>-0.262473</td>
      <td>0.380322</td>
      <td>0.014242</td>
      <td>-0.254811</td>
      <td>0.250850</td>
      <td>0.512475</td>
      <td>0.766204</td>
      <td>-0.042727</td>
      <td>-0.126256</td>
      <td>-0.472384</td>
      <td>-0.039649</td>
      <td>0.587933</td>
      <td>-0.038118</td>
      <td>1.263998</td>
      <td>0.682300</td>
      <td>-0.665642</td>
      <td>0.121120</td>
      <td>0.348376</td>
      <td>-0.103776</td>
      <td>-1.113376</td>
      <td>-0.415346</td>
      <td>-0.752629</td>
      <td>-1.015023</td>
      <td>-0.025359</td>
      <td>-0.087122</td>
      <td>0.170445</td>
      <td>0.332259</td>
      <td>1.499169</td>
      <td>-0.690466</td>
      <td>-0.569390</td>
      <td>-0.070590</td>
      <td>0.824116</td>
      <td>-0.146911</td>
      <td>-0.203161</td>
      <td>0.785427</td>
      <td>1.388103</td>
      <td>0.410467</td>
      <td>-0.426346</td>
      <td>...</td>
      <td>-0.326195</td>
      <td>0.842012</td>
      <td>0.132936</td>
      <td>-0.312175</td>
      <td>0.297161</td>
      <td>0.534929</td>
      <td>-0.102593</td>
      <td>0.829337</td>
      <td>0.383603</td>
      <td>-0.442019</td>
      <td>0.539539</td>
      <td>0.286427</td>
      <td>1.213296</td>
      <td>0.578517</td>
      <td>-0.014872</td>
      <td>-0.493579</td>
      <td>-0.028743</td>
      <td>-1.038638</td>
      <td>-0.165435</td>
      <td>-0.084770</td>
      <td>1.163634</td>
      <td>-0.208104</td>
      <td>-0.118966</td>
      <td>0.011861</td>
      <td>-0.157002</td>
      <td>-1.158168</td>
      <td>0.652186</td>
      <td>-0.852440</td>
      <td>-0.722612</td>
      <td>-0.659329</td>
      <td>-0.214632</td>
      <td>0.227162</td>
      <td>0.136926</td>
      <td>-0.022640</td>
      <td>0.572958</td>
      <td>0.311587</td>
      <td>0.531891</td>
      <td>0.019791</td>
      <td>-0.162682</td>
      <td>0.366873</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.536339</td>
      <td>0.358575</td>
      <td>0.259089</td>
      <td>0.743041</td>
      <td>-0.430567</td>
      <td>-0.297564</td>
      <td>-0.308917</td>
      <td>0.063202</td>
      <td>0.269118</td>
      <td>0.277220</td>
      <td>0.071964</td>
      <td>-0.747569</td>
      <td>0.631726</td>
      <td>0.374031</td>
      <td>-0.871022</td>
      <td>0.580005</td>
      <td>0.361559</td>
      <td>-0.884841</td>
      <td>0.285651</td>
      <td>-0.565145</td>
      <td>-0.498306</td>
      <td>-0.394526</td>
      <td>0.195281</td>
      <td>0.506582</td>
      <td>0.121035</td>
      <td>-0.316305</td>
      <td>0.700190</td>
      <td>-0.132006</td>
      <td>1.275754</td>
      <td>-0.373972</td>
      <td>0.068141</td>
      <td>0.145931</td>
      <td>0.897371</td>
      <td>0.936903</td>
      <td>0.529710</td>
      <td>-0.233578</td>
      <td>0.361007</td>
      <td>0.027031</td>
      <td>-0.712050</td>
      <td>-0.574354</td>
      <td>...</td>
      <td>-0.359974</td>
      <td>1.079033</td>
      <td>-0.030840</td>
      <td>-1.161185</td>
      <td>-0.518297</td>
      <td>-0.085293</td>
      <td>-0.444863</td>
      <td>0.320641</td>
      <td>-1.284227</td>
      <td>0.254621</td>
      <td>-0.141211</td>
      <td>-0.152597</td>
      <td>-0.023392</td>
      <td>0.478973</td>
      <td>0.622740</td>
      <td>0.752219</td>
      <td>0.104281</td>
      <td>-0.027392</td>
      <td>0.121065</td>
      <td>-0.504169</td>
      <td>1.067927</td>
      <td>0.073432</td>
      <td>0.133345</td>
      <td>-0.518333</td>
      <td>-0.617138</td>
      <td>-0.232437</td>
      <td>-0.093127</td>
      <td>-0.097078</td>
      <td>0.783060</td>
      <td>0.082730</td>
      <td>1.127021</td>
      <td>1.008850</td>
      <td>0.056585</td>
      <td>0.522375</td>
      <td>-0.686850</td>
      <td>-0.021735</td>
      <td>-0.669404</td>
      <td>1.627636</td>
      <td>0.471722</td>
      <td>0.804480</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.526469</td>
      <td>-0.520511</td>
      <td>-0.316741</td>
      <td>-0.252532</td>
      <td>0.329898</td>
      <td>-0.140226</td>
      <td>0.055095</td>
      <td>0.367130</td>
      <td>1.536935</td>
      <td>0.328496</td>
      <td>0.264660</td>
      <td>-1.437345</td>
      <td>-0.698183</td>
      <td>-0.740427</td>
      <td>-1.232064</td>
      <td>0.367764</td>
      <td>0.985181</td>
      <td>0.043465</td>
      <td>-0.985451</td>
      <td>-0.022965</td>
      <td>0.311409</td>
      <td>-1.339715</td>
      <td>-0.257136</td>
      <td>0.866054</td>
      <td>0.038108</td>
      <td>-0.281405</td>
      <td>-0.374201</td>
      <td>0.421840</td>
      <td>0.161210</td>
      <td>-0.772587</td>
      <td>0.410055</td>
      <td>0.028261</td>
      <td>-0.066989</td>
      <td>0.094108</td>
      <td>0.311814</td>
      <td>0.031986</td>
      <td>-0.686252</td>
      <td>-0.876762</td>
      <td>-0.947331</td>
      <td>-0.477236</td>
      <td>...</td>
      <td>0.251506</td>
      <td>-0.005759</td>
      <td>-0.699429</td>
      <td>-1.095899</td>
      <td>0.575194</td>
      <td>-0.172529</td>
      <td>-0.201251</td>
      <td>0.309503</td>
      <td>0.683233</td>
      <td>0.053602</td>
      <td>-0.060773</td>
      <td>0.728735</td>
      <td>-0.218097</td>
      <td>0.616039</td>
      <td>-0.704842</td>
      <td>0.460624</td>
      <td>0.559825</td>
      <td>0.120358</td>
      <td>-0.560076</td>
      <td>-0.147921</td>
      <td>0.770798</td>
      <td>0.476418</td>
      <td>1.216492</td>
      <td>-0.097944</td>
      <td>0.255803</td>
      <td>-0.424373</td>
      <td>1.094829</td>
      <td>-0.211920</td>
      <td>-0.959678</td>
      <td>0.069088</td>
      <td>-0.419037</td>
      <td>0.315116</td>
      <td>-0.776361</td>
      <td>0.328150</td>
      <td>-0.232720</td>
      <td>0.822333</td>
      <td>0.573830</td>
      <td>0.206213</td>
      <td>-0.678032</td>
      <td>-0.271516</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.400693</td>
      <td>0.013061</td>
      <td>0.048459</td>
      <td>-0.301460</td>
      <td>0.649589</td>
      <td>0.743311</td>
      <td>0.593350</td>
      <td>-0.258132</td>
      <td>0.554815</td>
      <td>0.048973</td>
      <td>1.042427</td>
      <td>0.537823</td>
      <td>0.242987</td>
      <td>0.504652</td>
      <td>-0.713028</td>
      <td>-0.779379</td>
      <td>0.096782</td>
      <td>-0.260997</td>
      <td>-0.244143</td>
      <td>0.961896</td>
      <td>0.024170</td>
      <td>0.352673</td>
      <td>0.465795</td>
      <td>0.421293</td>
      <td>0.645631</td>
      <td>-0.208190</td>
      <td>-0.190186</td>
      <td>-0.501325</td>
      <td>1.228892</td>
      <td>0.761726</td>
      <td>0.287668</td>
      <td>-0.391307</td>
      <td>-0.316996</td>
      <td>0.843354</td>
      <td>0.921130</td>
      <td>-0.433891</td>
      <td>0.010313</td>
      <td>0.542956</td>
      <td>-0.119982</td>
      <td>-0.183347</td>
      <td>...</td>
      <td>-0.944581</td>
      <td>0.128757</td>
      <td>-0.280467</td>
      <td>-0.148076</td>
      <td>0.845110</td>
      <td>-0.586246</td>
      <td>-0.538583</td>
      <td>0.305556</td>
      <td>-0.417470</td>
      <td>-0.231647</td>
      <td>-0.879826</td>
      <td>0.492671</td>
      <td>1.356428</td>
      <td>-0.244885</td>
      <td>0.746141</td>
      <td>-1.197559</td>
      <td>-1.087976</td>
      <td>-1.018003</td>
      <td>-0.173303</td>
      <td>0.274595</td>
      <td>-0.059037</td>
      <td>-1.069659</td>
      <td>-0.699635</td>
      <td>0.868680</td>
      <td>0.573664</td>
      <td>-0.278458</td>
      <td>0.087671</td>
      <td>-0.697460</td>
      <td>-0.262712</td>
      <td>-0.892146</td>
      <td>-1.641250</td>
      <td>-0.215302</td>
      <td>-0.896923</td>
      <td>-0.055303</td>
      <td>-0.756300</td>
      <td>-0.216016</td>
      <td>-0.585551</td>
      <td>0.352612</td>
      <td>0.628408</td>
      <td>0.478300</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.451504</td>
      <td>0.144455</td>
      <td>0.249079</td>
      <td>0.013629</td>
      <td>-1.463885</td>
      <td>-1.451894</td>
      <td>0.187573</td>
      <td>0.061797</td>
      <td>0.438504</td>
      <td>-0.262872</td>
      <td>0.372141</td>
      <td>0.510329</td>
      <td>-0.681520</td>
      <td>-0.322088</td>
      <td>-0.224386</td>
      <td>0.795248</td>
      <td>-0.128117</td>
      <td>-0.908536</td>
      <td>0.552466</td>
      <td>0.877027</td>
      <td>0.297010</td>
      <td>-0.120495</td>
      <td>0.418373</td>
      <td>1.223943</td>
      <td>0.615484</td>
      <td>0.565852</td>
      <td>0.894548</td>
      <td>-0.272794</td>
      <td>0.026680</td>
      <td>0.356982</td>
      <td>0.230256</td>
      <td>0.381162</td>
      <td>0.190932</td>
      <td>1.215857</td>
      <td>0.880783</td>
      <td>-0.414880</td>
      <td>0.953007</td>
      <td>-0.045159</td>
      <td>0.164780</td>
      <td>-0.066151</td>
      <td>...</td>
      <td>-0.502095</td>
      <td>0.097009</td>
      <td>-0.011755</td>
      <td>0.218900</td>
      <td>-0.031411</td>
      <td>-0.215669</td>
      <td>-1.538661</td>
      <td>0.211417</td>
      <td>0.797619</td>
      <td>-0.864916</td>
      <td>0.028973</td>
      <td>-0.815984</td>
      <td>-0.146776</td>
      <td>0.314173</td>
      <td>-0.344976</td>
      <td>0.127836</td>
      <td>0.360275</td>
      <td>0.225057</td>
      <td>0.230118</td>
      <td>-0.232795</td>
      <td>0.193208</td>
      <td>0.081779</td>
      <td>-0.476238</td>
      <td>0.422380</td>
      <td>-0.473621</td>
      <td>-0.510785</td>
      <td>-0.321891</td>
      <td>0.223729</td>
      <td>-1.021776</td>
      <td>-0.579640</td>
      <td>-0.563006</td>
      <td>-0.524778</td>
      <td>0.284208</td>
      <td>1.216266</td>
      <td>0.117652</td>
      <td>-0.617498</td>
      <td>-0.343579</td>
      <td>3.512725</td>
      <td>2.260027</td>
      <td>0.668496</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7fe6f91ddd60&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|     2.5 %   97.5 %
D  1.056652  0.032948  32.069922  1.158389e-225  0.992075  1.12123
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  5.677 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>