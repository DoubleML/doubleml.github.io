
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.101715efdecc9b59cb6e1ddfa685c31f.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d8bbf5861d671d414e1a.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">


    
    <a class="navbar-brand" href="../index.html">
      <p class="title">DoubleML</p>
    </a>
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  DoubleML
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/install.html">
  Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/intro.html">
  Getting started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../guide/guide.html">
  User guide
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api.html">
  Python API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference external nav-link" href="https://docs.doubleml.org/r/stable/">
  R API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../release/release.html">
  Release notes
 </a>
</li>

        
      </ul>

      <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><p class="logo" style="text-align:center;"><a href="../index.html">
    <img class="logo" src="../logo.png" alt="Logo" width="65%" height="65%">
</a></p><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l2 current active">
  <a class="current reference internal" href="#">
   Multiway Cluster Robust DML
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="double_ml_bonus_data.html">
   DML: Bonus Data
  </a>
 </li>
</ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulate-multiway-cluster-data">
   Simulate multiway cluster data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
   Initialize the objects of class DoubleMLData and DoubleMLPLIV
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#split-samples-and-transfer-the-sample-splitting-to-the-object">
   Split samples and transfer the sample splitting to the object
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fit-the-model-and-show-a-summary">
   Fit the model and show a summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing">
   Visualization of sample splitting with tuple and linear indexing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold">
     Visualize sample splitting with tuples (one plot per fold)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
     Visualize sample splitting with linear indexing (one column per fold)
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">Â¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">Â¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>0.167459</td>
      <td>-1.060572</td>
      <td>0.032631</td>
      <td>-0.641045</td>
      <td>1.043044</td>
      <td>-0.384930</td>
      <td>0.474664</td>
      <td>-0.737897</td>
      <td>-0.362336</td>
      <td>-0.755506</td>
      <td>-0.698569</td>
      <td>0.338964</td>
      <td>0.449673</td>
      <td>0.639346</td>
      <td>-0.091948</td>
      <td>-0.133842</td>
      <td>-0.428502</td>
      <td>1.026401</td>
      <td>-0.079797</td>
      <td>0.539996</td>
      <td>1.175250</td>
      <td>0.837475</td>
      <td>0.480323</td>
      <td>-1.183825</td>
      <td>0.334989</td>
      <td>0.156629</td>
      <td>0.544018</td>
      <td>-0.011501</td>
      <td>-0.656721</td>
      <td>-0.073792</td>
      <td>0.376484</td>
      <td>0.555060</td>
      <td>-0.446475</td>
      <td>-0.088520</td>
      <td>-0.815227</td>
      <td>-1.161153</td>
      <td>-0.550893</td>
      <td>-0.138026</td>
      <td>-0.200191</td>
      <td>-0.158413</td>
      <td>...</td>
      <td>0.257579</td>
      <td>-0.157847</td>
      <td>0.349638</td>
      <td>0.893688</td>
      <td>0.079848</td>
      <td>-0.267352</td>
      <td>0.686759</td>
      <td>1.135185</td>
      <td>0.650102</td>
      <td>0.223456</td>
      <td>0.239307</td>
      <td>-0.239361</td>
      <td>0.498379</td>
      <td>-0.929202</td>
      <td>0.013440</td>
      <td>-0.810929</td>
      <td>0.180785</td>
      <td>-0.427363</td>
      <td>-0.789685</td>
      <td>0.964059</td>
      <td>-0.183430</td>
      <td>-0.590573</td>
      <td>1.187690</td>
      <td>0.657420</td>
      <td>-0.128955</td>
      <td>-0.995487</td>
      <td>-0.868526</td>
      <td>0.075471</td>
      <td>0.509135</td>
      <td>-0.461849</td>
      <td>0.358104</td>
      <td>0.037873</td>
      <td>0.165573</td>
      <td>-1.261943</td>
      <td>-0.532599</td>
      <td>-0.350972</td>
      <td>-0.629585</td>
      <td>-0.757034</td>
      <td>-0.447801</td>
      <td>-0.614187</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.091569</td>
      <td>-0.496075</td>
      <td>-0.552331</td>
      <td>-0.564533</td>
      <td>-0.601671</td>
      <td>-0.207260</td>
      <td>0.123689</td>
      <td>-0.014566</td>
      <td>0.095011</td>
      <td>-0.521026</td>
      <td>0.246841</td>
      <td>-0.082466</td>
      <td>-0.092058</td>
      <td>-1.079220</td>
      <td>0.149487</td>
      <td>0.669700</td>
      <td>1.099846</td>
      <td>-0.069738</td>
      <td>-0.079009</td>
      <td>-0.276015</td>
      <td>1.230091</td>
      <td>0.825799</td>
      <td>-0.010138</td>
      <td>-0.005728</td>
      <td>-0.127081</td>
      <td>-0.414301</td>
      <td>-0.496695</td>
      <td>0.771689</td>
      <td>-0.204115</td>
      <td>1.152606</td>
      <td>-0.237847</td>
      <td>0.132894</td>
      <td>1.247683</td>
      <td>0.775151</td>
      <td>-1.102561</td>
      <td>-0.929707</td>
      <td>-0.138123</td>
      <td>-0.615793</td>
      <td>-0.130080</td>
      <td>1.489756</td>
      <td>...</td>
      <td>0.113874</td>
      <td>-0.220847</td>
      <td>-0.080113</td>
      <td>0.422403</td>
      <td>0.634474</td>
      <td>-0.284558</td>
      <td>-0.377201</td>
      <td>0.019340</td>
      <td>-0.455863</td>
      <td>-0.312798</td>
      <td>-0.034578</td>
      <td>0.299536</td>
      <td>0.684610</td>
      <td>-0.101229</td>
      <td>0.160721</td>
      <td>0.094954</td>
      <td>0.067161</td>
      <td>-0.599033</td>
      <td>-0.360194</td>
      <td>-1.492698</td>
      <td>-0.775385</td>
      <td>0.488034</td>
      <td>1.380691</td>
      <td>-0.260366</td>
      <td>0.197194</td>
      <td>0.684621</td>
      <td>0.363968</td>
      <td>-0.160071</td>
      <td>0.848128</td>
      <td>-0.140963</td>
      <td>0.080844</td>
      <td>0.349694</td>
      <td>1.408884</td>
      <td>0.755178</td>
      <td>0.231962</td>
      <td>0.756308</td>
      <td>0.255195</td>
      <td>-1.842315</td>
      <td>-1.055558</td>
      <td>-0.203561</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.076201</td>
      <td>-0.555171</td>
      <td>0.065097</td>
      <td>-0.472403</td>
      <td>0.768223</td>
      <td>0.148480</td>
      <td>-0.067834</td>
      <td>0.521733</td>
      <td>-0.102702</td>
      <td>0.346871</td>
      <td>0.395332</td>
      <td>-0.166081</td>
      <td>0.460362</td>
      <td>0.008255</td>
      <td>-0.202246</td>
      <td>-0.131205</td>
      <td>0.522024</td>
      <td>0.448851</td>
      <td>0.139131</td>
      <td>-0.280764</td>
      <td>0.858189</td>
      <td>0.058438</td>
      <td>-0.245181</td>
      <td>-0.521419</td>
      <td>-0.618861</td>
      <td>-0.476639</td>
      <td>-0.811155</td>
      <td>-0.954360</td>
      <td>0.393385</td>
      <td>0.013282</td>
      <td>-0.245311</td>
      <td>-1.508058</td>
      <td>-0.159644</td>
      <td>0.438058</td>
      <td>-0.278059</td>
      <td>-1.005884</td>
      <td>-0.342264</td>
      <td>0.339793</td>
      <td>0.973998</td>
      <td>1.045610</td>
      <td>...</td>
      <td>-0.586217</td>
      <td>-0.327409</td>
      <td>0.563463</td>
      <td>1.175928</td>
      <td>0.604447</td>
      <td>0.410162</td>
      <td>-0.081157</td>
      <td>0.780821</td>
      <td>-0.137238</td>
      <td>-1.698993</td>
      <td>-0.622537</td>
      <td>-0.798172</td>
      <td>0.308033</td>
      <td>-0.114551</td>
      <td>-0.761863</td>
      <td>0.108863</td>
      <td>0.747313</td>
      <td>-0.163670</td>
      <td>0.444436</td>
      <td>0.442600</td>
      <td>0.003306</td>
      <td>-0.462287</td>
      <td>0.278780</td>
      <td>-0.352168</td>
      <td>0.161445</td>
      <td>0.154745</td>
      <td>-0.209903</td>
      <td>1.435779</td>
      <td>0.259123</td>
      <td>-0.415482</td>
      <td>-0.399649</td>
      <td>-0.374134</td>
      <td>0.258899</td>
      <td>0.587690</td>
      <td>-0.539849</td>
      <td>0.875609</td>
      <td>-1.134018</td>
      <td>-1.635386</td>
      <td>-1.697756</td>
      <td>-1.228794</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.210830</td>
      <td>-1.312206</td>
      <td>-1.120885</td>
      <td>-1.354078</td>
      <td>0.895861</td>
      <td>-0.792723</td>
      <td>0.505951</td>
      <td>-0.095984</td>
      <td>1.004198</td>
      <td>-0.772055</td>
      <td>-0.188488</td>
      <td>0.185679</td>
      <td>1.558343</td>
      <td>0.318369</td>
      <td>0.018285</td>
      <td>-0.669668</td>
      <td>-0.376638</td>
      <td>-0.307058</td>
      <td>1.157941</td>
      <td>0.891551</td>
      <td>0.135620</td>
      <td>0.767962</td>
      <td>0.610000</td>
      <td>-0.478967</td>
      <td>0.395793</td>
      <td>0.254300</td>
      <td>-0.188994</td>
      <td>-0.512855</td>
      <td>-0.199500</td>
      <td>-0.246197</td>
      <td>-0.253290</td>
      <td>0.606483</td>
      <td>1.628358</td>
      <td>0.062520</td>
      <td>-0.185348</td>
      <td>0.522602</td>
      <td>1.039106</td>
      <td>-0.072539</td>
      <td>-0.051210</td>
      <td>1.148748</td>
      <td>...</td>
      <td>-0.394780</td>
      <td>0.389042</td>
      <td>1.047152</td>
      <td>0.770893</td>
      <td>-0.031894</td>
      <td>0.256632</td>
      <td>1.198423</td>
      <td>0.836826</td>
      <td>-0.646733</td>
      <td>-0.725737</td>
      <td>0.553556</td>
      <td>-0.103035</td>
      <td>-0.741584</td>
      <td>0.127014</td>
      <td>1.200630</td>
      <td>0.253789</td>
      <td>0.860271</td>
      <td>-0.424933</td>
      <td>0.151649</td>
      <td>1.339533</td>
      <td>0.917844</td>
      <td>0.367958</td>
      <td>-0.255892</td>
      <td>-0.404079</td>
      <td>0.021266</td>
      <td>-0.292108</td>
      <td>0.376142</td>
      <td>0.175974</td>
      <td>0.148581</td>
      <td>0.860410</td>
      <td>1.053543</td>
      <td>0.509219</td>
      <td>-0.884946</td>
      <td>-0.471868</td>
      <td>0.541625</td>
      <td>0.736605</td>
      <td>0.027605</td>
      <td>-1.799490</td>
      <td>-1.175773</td>
      <td>-1.395423</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.226051</td>
      <td>0.238861</td>
      <td>1.049842</td>
      <td>0.206884</td>
      <td>0.402331</td>
      <td>-0.479345</td>
      <td>-0.228364</td>
      <td>-1.030039</td>
      <td>-0.324789</td>
      <td>-0.388431</td>
      <td>0.949500</td>
      <td>0.623695</td>
      <td>0.563231</td>
      <td>-0.218790</td>
      <td>0.411512</td>
      <td>-0.809151</td>
      <td>-1.138248</td>
      <td>0.347525</td>
      <td>0.003901</td>
      <td>0.354243</td>
      <td>-0.391013</td>
      <td>-0.125796</td>
      <td>-0.161917</td>
      <td>-0.258639</td>
      <td>-0.482602</td>
      <td>-0.070595</td>
      <td>-0.672443</td>
      <td>0.406508</td>
      <td>0.853041</td>
      <td>0.156343</td>
      <td>-0.802208</td>
      <td>-0.516617</td>
      <td>-0.311444</td>
      <td>0.193534</td>
      <td>-0.360029</td>
      <td>0.848662</td>
      <td>0.634891</td>
      <td>-0.046917</td>
      <td>0.233002</td>
      <td>1.291985</td>
      <td>...</td>
      <td>-0.678716</td>
      <td>-0.357002</td>
      <td>-0.135574</td>
      <td>0.314512</td>
      <td>-0.088279</td>
      <td>0.048620</td>
      <td>1.598235</td>
      <td>0.420325</td>
      <td>0.430949</td>
      <td>0.109713</td>
      <td>0.067996</td>
      <td>0.680089</td>
      <td>1.650026</td>
      <td>0.595403</td>
      <td>0.087035</td>
      <td>0.302468</td>
      <td>-0.538415</td>
      <td>-0.759594</td>
      <td>-1.219420</td>
      <td>0.509964</td>
      <td>0.321002</td>
      <td>0.015480</td>
      <td>-0.222973</td>
      <td>-0.319969</td>
      <td>0.195638</td>
      <td>-0.186766</td>
      <td>-0.391597</td>
      <td>0.813688</td>
      <td>0.126881</td>
      <td>0.477120</td>
      <td>0.426424</td>
      <td>0.336318</td>
      <td>-0.407796</td>
      <td>-0.773595</td>
      <td>0.249654</td>
      <td>0.302599</td>
      <td>-0.261715</td>
      <td>-0.432691</td>
      <td>-0.367189</td>
      <td>0.061813</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.252518</td>
      <td>0.446957</td>
      <td>-0.785236</td>
      <td>-0.867921</td>
      <td>1.114129</td>
      <td>-0.497849</td>
      <td>-0.291153</td>
      <td>-1.527984</td>
      <td>1.157631</td>
      <td>0.190416</td>
      <td>-0.245055</td>
      <td>0.706810</td>
      <td>1.026560</td>
      <td>-0.736499</td>
      <td>1.209051</td>
      <td>-0.042501</td>
      <td>0.227694</td>
      <td>0.193485</td>
      <td>0.776229</td>
      <td>-0.555330</td>
      <td>-0.250699</td>
      <td>-0.552869</td>
      <td>0.216034</td>
      <td>-0.417243</td>
      <td>0.970019</td>
      <td>0.591861</td>
      <td>-1.195639</td>
      <td>-0.446791</td>
      <td>0.052831</td>
      <td>0.499829</td>
      <td>0.965149</td>
      <td>-0.399733</td>
      <td>0.553937</td>
      <td>1.044031</td>
      <td>-0.259607</td>
      <td>0.073896</td>
      <td>-0.190097</td>
      <td>-0.406519</td>
      <td>0.807918</td>
      <td>0.351296</td>
      <td>...</td>
      <td>0.024664</td>
      <td>0.191905</td>
      <td>-0.143329</td>
      <td>0.243926</td>
      <td>0.248204</td>
      <td>-0.862537</td>
      <td>0.721107</td>
      <td>0.084214</td>
      <td>0.020677</td>
      <td>-0.364893</td>
      <td>-0.475504</td>
      <td>0.266404</td>
      <td>0.035035</td>
      <td>0.107726</td>
      <td>-0.425709</td>
      <td>-0.474444</td>
      <td>-0.394827</td>
      <td>0.440411</td>
      <td>-1.450892</td>
      <td>0.380476</td>
      <td>-0.379138</td>
      <td>-1.706959</td>
      <td>-0.835434</td>
      <td>-0.752038</td>
      <td>-1.925977</td>
      <td>-1.731968</td>
      <td>-0.176926</td>
      <td>0.638215</td>
      <td>0.293106</td>
      <td>-0.337873</td>
      <td>-1.253804</td>
      <td>0.768006</td>
      <td>-0.509511</td>
      <td>-1.004640</td>
      <td>-1.265880</td>
      <td>-0.094251</td>
      <td>0.229381</td>
      <td>0.090864</td>
      <td>-0.272439</td>
      <td>0.041059</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.337802</td>
      <td>0.133006</td>
      <td>0.435734</td>
      <td>-0.164863</td>
      <td>-0.289171</td>
      <td>-0.065666</td>
      <td>1.127894</td>
      <td>-1.000576</td>
      <td>-0.031368</td>
      <td>-0.487164</td>
      <td>0.278922</td>
      <td>0.821078</td>
      <td>0.599974</td>
      <td>0.082573</td>
      <td>-0.311512</td>
      <td>0.463814</td>
      <td>0.349245</td>
      <td>0.124753</td>
      <td>-0.053398</td>
      <td>-0.653979</td>
      <td>-1.210675</td>
      <td>0.110612</td>
      <td>-0.207171</td>
      <td>-0.032250</td>
      <td>0.060376</td>
      <td>-0.654163</td>
      <td>-1.000433</td>
      <td>-0.218389</td>
      <td>-0.376388</td>
      <td>0.874941</td>
      <td>1.113026</td>
      <td>0.890958</td>
      <td>1.132535</td>
      <td>-0.143625</td>
      <td>-1.211698</td>
      <td>0.001369</td>
      <td>0.211421</td>
      <td>-0.295723</td>
      <td>0.130226</td>
      <td>0.107097</td>
      <td>...</td>
      <td>1.147833</td>
      <td>0.881286</td>
      <td>-0.482414</td>
      <td>0.725208</td>
      <td>-0.486184</td>
      <td>0.966919</td>
      <td>0.674885</td>
      <td>0.473444</td>
      <td>0.536717</td>
      <td>0.575950</td>
      <td>-0.476923</td>
      <td>-0.973442</td>
      <td>-0.845766</td>
      <td>-0.199768</td>
      <td>-0.367495</td>
      <td>0.300602</td>
      <td>-0.042342</td>
      <td>0.552552</td>
      <td>0.174349</td>
      <td>1.138492</td>
      <td>-0.716187</td>
      <td>0.106157</td>
      <td>-0.056019</td>
      <td>0.109216</td>
      <td>0.571398</td>
      <td>0.638958</td>
      <td>-0.304806</td>
      <td>0.641947</td>
      <td>0.811158</td>
      <td>-0.349953</td>
      <td>0.052192</td>
      <td>0.629339</td>
      <td>-0.554750</td>
      <td>-0.085069</td>
      <td>-0.159627</td>
      <td>0.230420</td>
      <td>-0.401433</td>
      <td>0.426536</td>
      <td>-0.076138</td>
      <td>0.184021</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.336583</td>
      <td>0.227016</td>
      <td>-0.404122</td>
      <td>-0.202348</td>
      <td>0.476874</td>
      <td>-1.345457</td>
      <td>0.429147</td>
      <td>0.514239</td>
      <td>0.546094</td>
      <td>-0.296512</td>
      <td>0.010686</td>
      <td>0.247023</td>
      <td>1.067683</td>
      <td>-0.484093</td>
      <td>0.459885</td>
      <td>-0.213496</td>
      <td>0.517148</td>
      <td>1.034299</td>
      <td>0.222424</td>
      <td>0.339038</td>
      <td>0.358817</td>
      <td>0.447670</td>
      <td>0.117622</td>
      <td>-0.632109</td>
      <td>-0.452797</td>
      <td>-1.031907</td>
      <td>-0.166953</td>
      <td>1.025994</td>
      <td>-0.199905</td>
      <td>-0.395290</td>
      <td>-0.819949</td>
      <td>-1.237758</td>
      <td>-0.141872</td>
      <td>0.440819</td>
      <td>0.110236</td>
      <td>0.683175</td>
      <td>1.004295</td>
      <td>-0.360532</td>
      <td>0.800934</td>
      <td>1.465732</td>
      <td>...</td>
      <td>-0.580141</td>
      <td>-0.695386</td>
      <td>0.318096</td>
      <td>1.222712</td>
      <td>1.007839</td>
      <td>0.648421</td>
      <td>0.351960</td>
      <td>0.655312</td>
      <td>0.263814</td>
      <td>0.449600</td>
      <td>0.563995</td>
      <td>0.099610</td>
      <td>0.417894</td>
      <td>0.345761</td>
      <td>-0.654526</td>
      <td>-0.576573</td>
      <td>-0.140803</td>
      <td>1.037119</td>
      <td>0.142238</td>
      <td>0.861160</td>
      <td>0.433813</td>
      <td>0.660534</td>
      <td>0.321679</td>
      <td>-0.021314</td>
      <td>-0.864706</td>
      <td>0.079782</td>
      <td>0.034066</td>
      <td>1.116691</td>
      <td>1.760693</td>
      <td>0.823165</td>
      <td>0.263618</td>
      <td>1.184323</td>
      <td>0.152656</td>
      <td>0.183411</td>
      <td>-0.753998</td>
      <td>0.205504</td>
      <td>0.331172</td>
      <td>-1.097180</td>
      <td>-1.302538</td>
      <td>-0.546239</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.080497</td>
      <td>0.061080</td>
      <td>0.519808</td>
      <td>0.140760</td>
      <td>0.878071</td>
      <td>-0.975700</td>
      <td>0.074294</td>
      <td>0.327728</td>
      <td>0.303953</td>
      <td>-0.520276</td>
      <td>-0.035559</td>
      <td>1.401840</td>
      <td>0.693319</td>
      <td>-0.557295</td>
      <td>-0.093600</td>
      <td>0.131976</td>
      <td>-0.410422</td>
      <td>0.401084</td>
      <td>0.578598</td>
      <td>-0.653821</td>
      <td>0.435005</td>
      <td>0.563941</td>
      <td>0.759347</td>
      <td>-0.302231</td>
      <td>0.428486</td>
      <td>0.505315</td>
      <td>-0.922711</td>
      <td>-0.333769</td>
      <td>-0.096756</td>
      <td>-0.470851</td>
      <td>-0.280745</td>
      <td>0.236301</td>
      <td>-0.530657</td>
      <td>-0.183226</td>
      <td>-0.206341</td>
      <td>-1.027222</td>
      <td>0.678848</td>
      <td>-0.401304</td>
      <td>0.035777</td>
      <td>-0.289879</td>
      <td>...</td>
      <td>0.724931</td>
      <td>0.273082</td>
      <td>0.211860</td>
      <td>0.723439</td>
      <td>0.931319</td>
      <td>-0.314031</td>
      <td>-0.166193</td>
      <td>0.153543</td>
      <td>-0.370187</td>
      <td>-0.487260</td>
      <td>0.211902</td>
      <td>0.173014</td>
      <td>-0.070810</td>
      <td>0.106328</td>
      <td>0.043035</td>
      <td>-0.094742</td>
      <td>-0.088345</td>
      <td>-0.619409</td>
      <td>-0.654499</td>
      <td>-0.011334</td>
      <td>-0.338118</td>
      <td>-0.509184</td>
      <td>-0.253229</td>
      <td>-2.005501</td>
      <td>-1.430497</td>
      <td>-0.647308</td>
      <td>-1.117832</td>
      <td>0.060847</td>
      <td>1.162703</td>
      <td>1.064909</td>
      <td>-0.000249</td>
      <td>0.102931</td>
      <td>0.199350</td>
      <td>-0.277830</td>
      <td>-0.015811</td>
      <td>0.738699</td>
      <td>-0.161217</td>
      <td>1.623646</td>
      <td>0.953651</td>
      <td>0.545526</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-0.126925</td>
      <td>-0.128723</td>
      <td>0.408447</td>
      <td>0.105386</td>
      <td>0.942913</td>
      <td>-0.373861</td>
      <td>-0.135636</td>
      <td>-0.020743</td>
      <td>-0.575874</td>
      <td>0.293279</td>
      <td>-0.095611</td>
      <td>-0.063970</td>
      <td>0.454737</td>
      <td>0.054691</td>
      <td>0.168291</td>
      <td>0.305410</td>
      <td>-0.850297</td>
      <td>-0.084333</td>
      <td>-0.256900</td>
      <td>0.127486</td>
      <td>0.428154</td>
      <td>0.549339</td>
      <td>0.100515</td>
      <td>0.608037</td>
      <td>0.522661</td>
      <td>0.490965</td>
      <td>0.429945</td>
      <td>-0.230545</td>
      <td>-0.590231</td>
      <td>-0.869709</td>
      <td>0.455668</td>
      <td>-0.742000</td>
      <td>-0.346768</td>
      <td>0.276523</td>
      <td>-0.258408</td>
      <td>-0.699306</td>
      <td>-0.090729</td>
      <td>-0.171313</td>
      <td>0.615452</td>
      <td>1.025012</td>
      <td>...</td>
      <td>0.213031</td>
      <td>-0.036908</td>
      <td>-0.658565</td>
      <td>0.188702</td>
      <td>0.281188</td>
      <td>-0.163091</td>
      <td>-0.043710</td>
      <td>0.129842</td>
      <td>0.845328</td>
      <td>-0.223511</td>
      <td>-0.390171</td>
      <td>0.211608</td>
      <td>-0.501858</td>
      <td>0.108216</td>
      <td>-0.626979</td>
      <td>-0.572120</td>
      <td>-0.116273</td>
      <td>-0.779679</td>
      <td>0.039741</td>
      <td>0.093069</td>
      <td>0.200138</td>
      <td>-0.104052</td>
      <td>0.301107</td>
      <td>0.003135</td>
      <td>-0.234042</td>
      <td>-0.312515</td>
      <td>0.428247</td>
      <td>1.329237</td>
      <td>-0.284070</td>
      <td>-0.669923</td>
      <td>-0.259329</td>
      <td>0.782058</td>
      <td>0.623172</td>
      <td>-0.048989</td>
      <td>0.089109</td>
      <td>0.852273</td>
      <td>-0.595512</td>
      <td>-0.517687</td>
      <td>-0.035629</td>
      <td>0.146543</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.005948</td>
      <td>0.150077</td>
      <td>0.055632</td>
      <td>0.408226</td>
      <td>0.806755</td>
      <td>0.887562</td>
      <td>-0.409871</td>
      <td>-0.551588</td>
      <td>0.203300</td>
      <td>0.029068</td>
      <td>0.800858</td>
      <td>0.377254</td>
      <td>0.981251</td>
      <td>-0.308478</td>
      <td>1.017151</td>
      <td>0.859836</td>
      <td>0.848201</td>
      <td>0.615744</td>
      <td>0.297055</td>
      <td>-0.597480</td>
      <td>0.913154</td>
      <td>0.723859</td>
      <td>0.856708</td>
      <td>-0.170835</td>
      <td>0.028788</td>
      <td>0.043468</td>
      <td>0.126329</td>
      <td>-0.178953</td>
      <td>-0.345396</td>
      <td>0.281302</td>
      <td>-0.676772</td>
      <td>-1.419828</td>
      <td>0.549053</td>
      <td>0.164161</td>
      <td>-1.470208</td>
      <td>-1.102594</td>
      <td>-0.828058</td>
      <td>-0.554508</td>
      <td>-0.774427</td>
      <td>0.019313</td>
      <td>...</td>
      <td>-0.490704</td>
      <td>-0.146492</td>
      <td>0.003573</td>
      <td>0.847871</td>
      <td>0.897317</td>
      <td>0.254173</td>
      <td>-0.348075</td>
      <td>-0.878199</td>
      <td>-0.986564</td>
      <td>-0.004190</td>
      <td>-0.161456</td>
      <td>0.231791</td>
      <td>-0.418139</td>
      <td>-0.241320</td>
      <td>-0.670353</td>
      <td>0.450917</td>
      <td>-0.319771</td>
      <td>0.148918</td>
      <td>0.008298</td>
      <td>0.840773</td>
      <td>1.217063</td>
      <td>0.348388</td>
      <td>-0.037840</td>
      <td>0.421698</td>
      <td>-1.268918</td>
      <td>0.261362</td>
      <td>0.403659</td>
      <td>0.717378</td>
      <td>0.513260</td>
      <td>-0.252716</td>
      <td>-0.058253</td>
      <td>-0.150967</td>
      <td>-0.362540</td>
      <td>-0.510330</td>
      <td>-0.019630</td>
      <td>0.834461</td>
      <td>0.145762</td>
      <td>0.561578</td>
      <td>-0.330127</td>
      <td>-0.276533</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.281812</td>
      <td>0.105098</td>
      <td>-0.277676</td>
      <td>-0.866823</td>
      <td>0.277046</td>
      <td>-0.325827</td>
      <td>0.226421</td>
      <td>0.696439</td>
      <td>0.911522</td>
      <td>0.478418</td>
      <td>-0.209106</td>
      <td>0.273957</td>
      <td>-0.686488</td>
      <td>0.353937</td>
      <td>0.549194</td>
      <td>-0.259473</td>
      <td>-0.635354</td>
      <td>0.072201</td>
      <td>0.166816</td>
      <td>0.349205</td>
      <td>-0.295712</td>
      <td>0.286330</td>
      <td>-1.140718</td>
      <td>-0.179218</td>
      <td>-0.196902</td>
      <td>-0.057055</td>
      <td>-0.667570</td>
      <td>0.096214</td>
      <td>-0.027423</td>
      <td>1.000901</td>
      <td>0.613068</td>
      <td>-0.161706</td>
      <td>0.148297</td>
      <td>-0.832164</td>
      <td>-0.098505</td>
      <td>-0.654765</td>
      <td>0.650052</td>
      <td>-0.506684</td>
      <td>-0.544609</td>
      <td>0.418630</td>
      <td>...</td>
      <td>0.298405</td>
      <td>0.276661</td>
      <td>0.913720</td>
      <td>0.956088</td>
      <td>1.533192</td>
      <td>0.059928</td>
      <td>0.446015</td>
      <td>-0.309146</td>
      <td>-0.190400</td>
      <td>-1.130583</td>
      <td>-0.184204</td>
      <td>0.268122</td>
      <td>-0.282934</td>
      <td>0.612395</td>
      <td>-0.079285</td>
      <td>0.204783</td>
      <td>-1.010896</td>
      <td>-0.385409</td>
      <td>-0.645509</td>
      <td>0.560634</td>
      <td>0.109147</td>
      <td>0.272669</td>
      <td>0.311346</td>
      <td>-0.878488</td>
      <td>-0.112875</td>
      <td>-0.758671</td>
      <td>-0.699666</td>
      <td>0.593809</td>
      <td>0.448210</td>
      <td>0.043135</td>
      <td>0.184946</td>
      <td>0.450444</td>
      <td>-0.512003</td>
      <td>-0.219875</td>
      <td>-1.266798</td>
      <td>0.060592</td>
      <td>-0.018751</td>
      <td>1.254965</td>
      <td>0.136116</td>
      <td>0.684849</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-0.112855</td>
      <td>-0.056303</td>
      <td>0.544583</td>
      <td>0.104166</td>
      <td>0.253822</td>
      <td>-0.719139</td>
      <td>0.916345</td>
      <td>-0.475260</td>
      <td>-0.068098</td>
      <td>0.031936</td>
      <td>-0.331087</td>
      <td>0.597014</td>
      <td>0.867667</td>
      <td>-1.300151</td>
      <td>-0.864735</td>
      <td>-0.058537</td>
      <td>-0.269895</td>
      <td>0.911687</td>
      <td>0.516038</td>
      <td>-0.203323</td>
      <td>-0.356354</td>
      <td>-0.947407</td>
      <td>0.314926</td>
      <td>0.284159</td>
      <td>0.412064</td>
      <td>-0.107797</td>
      <td>-0.664469</td>
      <td>-0.283391</td>
      <td>-0.384848</td>
      <td>-0.999605</td>
      <td>-0.208545</td>
      <td>-0.495675</td>
      <td>0.384349</td>
      <td>-0.609077</td>
      <td>-0.942644</td>
      <td>-0.357106</td>
      <td>-0.842907</td>
      <td>-1.137116</td>
      <td>0.097856</td>
      <td>0.402281</td>
      <td>...</td>
      <td>0.238810</td>
      <td>-0.736613</td>
      <td>-0.459312</td>
      <td>-0.329188</td>
      <td>-0.428897</td>
      <td>0.204246</td>
      <td>0.665003</td>
      <td>-0.408887</td>
      <td>-0.057206</td>
      <td>-0.190813</td>
      <td>-0.039661</td>
      <td>0.069276</td>
      <td>0.071086</td>
      <td>0.346535</td>
      <td>0.472435</td>
      <td>1.021768</td>
      <td>0.776897</td>
      <td>0.470954</td>
      <td>0.034703</td>
      <td>0.722634</td>
      <td>-0.256382</td>
      <td>-0.301518</td>
      <td>0.332066</td>
      <td>0.487774</td>
      <td>0.229347</td>
      <td>-0.483196</td>
      <td>-0.255418</td>
      <td>0.744671</td>
      <td>1.016713</td>
      <td>-0.148397</td>
      <td>0.706381</td>
      <td>0.226177</td>
      <td>0.167606</td>
      <td>0.487742</td>
      <td>-0.537587</td>
      <td>-0.167591</td>
      <td>0.831453</td>
      <td>-1.638455</td>
      <td>-1.639058</td>
      <td>-0.991124</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.591102</td>
      <td>0.229140</td>
      <td>-0.267714</td>
      <td>-0.621872</td>
      <td>-0.162922</td>
      <td>-0.193026</td>
      <td>1.340386</td>
      <td>0.628820</td>
      <td>-0.003736</td>
      <td>-0.170406</td>
      <td>-0.204279</td>
      <td>1.079344</td>
      <td>0.331361</td>
      <td>-0.299680</td>
      <td>0.286830</td>
      <td>1.038219</td>
      <td>-0.743617</td>
      <td>0.884351</td>
      <td>0.824338</td>
      <td>-0.220712</td>
      <td>1.414732</td>
      <td>1.983464</td>
      <td>-0.063442</td>
      <td>-0.182281</td>
      <td>-0.049868</td>
      <td>0.145636</td>
      <td>-0.812158</td>
      <td>0.914137</td>
      <td>0.339234</td>
      <td>-0.033114</td>
      <td>0.088367</td>
      <td>-0.748359</td>
      <td>-0.978912</td>
      <td>-0.303444</td>
      <td>0.265593</td>
      <td>-0.218530</td>
      <td>0.402730</td>
      <td>0.053808</td>
      <td>0.161278</td>
      <td>0.152317</td>
      <td>...</td>
      <td>-0.596940</td>
      <td>-0.201142</td>
      <td>-1.169594</td>
      <td>-0.027577</td>
      <td>0.635130</td>
      <td>-0.220185</td>
      <td>0.801880</td>
      <td>-0.256747</td>
      <td>0.277139</td>
      <td>-0.535069</td>
      <td>-0.353931</td>
      <td>-0.015024</td>
      <td>-0.128553</td>
      <td>0.710850</td>
      <td>-0.453605</td>
      <td>0.014983</td>
      <td>-0.562804</td>
      <td>-0.256912</td>
      <td>-0.646759</td>
      <td>0.057364</td>
      <td>-0.211206</td>
      <td>0.713102</td>
      <td>0.024933</td>
      <td>-0.770229</td>
      <td>-0.460591</td>
      <td>0.909351</td>
      <td>1.217610</td>
      <td>0.773824</td>
      <td>0.919498</td>
      <td>-0.448540</td>
      <td>-1.285845</td>
      <td>0.504501</td>
      <td>0.027504</td>
      <td>-0.439527</td>
      <td>-0.433228</td>
      <td>-0.465552</td>
      <td>-0.436089</td>
      <td>0.917008</td>
      <td>-0.138567</td>
      <td>0.087023</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.160030</td>
      <td>-0.767694</td>
      <td>-0.492890</td>
      <td>-1.071998</td>
      <td>-1.014895</td>
      <td>0.294869</td>
      <td>0.523315</td>
      <td>-0.539480</td>
      <td>0.521338</td>
      <td>-0.192326</td>
      <td>0.192406</td>
      <td>1.124032</td>
      <td>0.921912</td>
      <td>-0.353711</td>
      <td>-0.224608</td>
      <td>-0.132951</td>
      <td>0.650563</td>
      <td>0.309995</td>
      <td>-0.322950</td>
      <td>0.032102</td>
      <td>0.243257</td>
      <td>0.667205</td>
      <td>-0.228672</td>
      <td>0.826111</td>
      <td>-0.189639</td>
      <td>0.070873</td>
      <td>0.283283</td>
      <td>0.366920</td>
      <td>-0.115863</td>
      <td>0.455204</td>
      <td>-0.273344</td>
      <td>-0.036154</td>
      <td>0.848748</td>
      <td>-0.287387</td>
      <td>-0.130224</td>
      <td>-0.689614</td>
      <td>-0.647501</td>
      <td>1.080518</td>
      <td>-0.491310</td>
      <td>-0.483848</td>
      <td>...</td>
      <td>0.302434</td>
      <td>0.428113</td>
      <td>-0.437468</td>
      <td>-0.144411</td>
      <td>0.281307</td>
      <td>-0.807960</td>
      <td>-0.602153</td>
      <td>0.312018</td>
      <td>-0.605401</td>
      <td>-1.639167</td>
      <td>-0.970932</td>
      <td>-0.162978</td>
      <td>0.069412</td>
      <td>-0.155893</td>
      <td>-1.150659</td>
      <td>-0.645253</td>
      <td>-0.317216</td>
      <td>-0.095995</td>
      <td>-0.946171</td>
      <td>0.088624</td>
      <td>-0.638149</td>
      <td>-0.064744</td>
      <td>0.302558</td>
      <td>-0.488588</td>
      <td>0.706614</td>
      <td>0.437428</td>
      <td>0.262991</td>
      <td>1.014985</td>
      <td>-0.440411</td>
      <td>-0.389676</td>
      <td>0.539339</td>
      <td>-0.694049</td>
      <td>-0.436249</td>
      <td>-0.664384</td>
      <td>0.120722</td>
      <td>0.212184</td>
      <td>0.354834</td>
      <td>-0.109767</td>
      <td>-0.596578</td>
      <td>-0.024024</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.810307</td>
      <td>1.363881</td>
      <td>-0.319220</td>
      <td>-0.352104</td>
      <td>-0.038071</td>
      <td>0.810402</td>
      <td>0.909389</td>
      <td>0.110043</td>
      <td>0.194912</td>
      <td>0.015550</td>
      <td>0.350557</td>
      <td>-0.019134</td>
      <td>-0.360664</td>
      <td>-0.844998</td>
      <td>-0.309821</td>
      <td>0.068186</td>
      <td>-0.474999</td>
      <td>0.350288</td>
      <td>-0.477618</td>
      <td>-0.251162</td>
      <td>-0.504820</td>
      <td>-0.574704</td>
      <td>0.160371</td>
      <td>0.253824</td>
      <td>0.730907</td>
      <td>-0.029047</td>
      <td>-0.775329</td>
      <td>0.485021</td>
      <td>0.280234</td>
      <td>0.428793</td>
      <td>-0.229272</td>
      <td>0.444023</td>
      <td>-0.131569</td>
      <td>0.395893</td>
      <td>0.375034</td>
      <td>-0.299856</td>
      <td>0.288327</td>
      <td>-0.060510</td>
      <td>-0.303065</td>
      <td>0.452021</td>
      <td>...</td>
      <td>-0.544386</td>
      <td>0.032768</td>
      <td>-0.169890</td>
      <td>0.572382</td>
      <td>-1.157627</td>
      <td>-1.034189</td>
      <td>-0.530751</td>
      <td>0.013155</td>
      <td>0.697492</td>
      <td>0.073905</td>
      <td>-0.309952</td>
      <td>-0.665940</td>
      <td>0.417647</td>
      <td>-0.274026</td>
      <td>-0.830576</td>
      <td>-0.261517</td>
      <td>-1.107970</td>
      <td>-0.880232</td>
      <td>-0.260405</td>
      <td>-0.046150</td>
      <td>-0.153013</td>
      <td>-1.027759</td>
      <td>-0.635144</td>
      <td>-0.030219</td>
      <td>0.468149</td>
      <td>-0.042724</td>
      <td>0.162275</td>
      <td>0.688690</td>
      <td>0.604684</td>
      <td>-0.012353</td>
      <td>-0.844800</td>
      <td>-0.560696</td>
      <td>-0.208675</td>
      <td>-0.380926</td>
      <td>-0.154015</td>
      <td>0.499820</td>
      <td>0.050592</td>
      <td>2.190735</td>
      <td>0.904471</td>
      <td>0.631553</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.006344</td>
      <td>-0.429643</td>
      <td>-0.604735</td>
      <td>-0.286155</td>
      <td>0.755621</td>
      <td>0.008514</td>
      <td>0.627481</td>
      <td>0.314444</td>
      <td>0.516853</td>
      <td>-0.562972</td>
      <td>-0.589704</td>
      <td>0.514365</td>
      <td>1.200681</td>
      <td>-0.014223</td>
      <td>1.006088</td>
      <td>0.133063</td>
      <td>0.513764</td>
      <td>0.208648</td>
      <td>-0.283418</td>
      <td>-0.280739</td>
      <td>1.090012</td>
      <td>0.498426</td>
      <td>0.331911</td>
      <td>-0.088374</td>
      <td>0.732673</td>
      <td>-0.243093</td>
      <td>-0.832550</td>
      <td>1.168523</td>
      <td>-0.240153</td>
      <td>-0.615846</td>
      <td>-0.743006</td>
      <td>-0.649899</td>
      <td>1.077724</td>
      <td>0.568471</td>
      <td>0.034676</td>
      <td>-0.970505</td>
      <td>0.358055</td>
      <td>1.038654</td>
      <td>0.638639</td>
      <td>-0.480421</td>
      <td>...</td>
      <td>-0.159710</td>
      <td>-0.713100</td>
      <td>-0.614771</td>
      <td>0.610323</td>
      <td>-0.788119</td>
      <td>-0.456516</td>
      <td>-0.119334</td>
      <td>-0.734401</td>
      <td>0.076354</td>
      <td>-0.050413</td>
      <td>0.103645</td>
      <td>-0.459777</td>
      <td>0.607156</td>
      <td>-0.021854</td>
      <td>-1.008502</td>
      <td>0.006086</td>
      <td>0.197845</td>
      <td>-0.554082</td>
      <td>-0.549615</td>
      <td>0.977848</td>
      <td>-0.149409</td>
      <td>0.223017</td>
      <td>0.057268</td>
      <td>0.242708</td>
      <td>0.180998</td>
      <td>0.081899</td>
      <td>-0.747358</td>
      <td>1.010018</td>
      <td>-0.702476</td>
      <td>-0.984841</td>
      <td>-0.231245</td>
      <td>-0.025333</td>
      <td>0.719277</td>
      <td>0.412631</td>
      <td>-0.175580</td>
      <td>-0.210212</td>
      <td>-0.055788</td>
      <td>-1.119253</td>
      <td>-1.384828</td>
      <td>-0.520805</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.144559</td>
      <td>-0.741824</td>
      <td>-0.473857</td>
      <td>-0.382124</td>
      <td>0.278589</td>
      <td>0.403583</td>
      <td>-0.520293</td>
      <td>-0.688062</td>
      <td>-0.820459</td>
      <td>-0.287364</td>
      <td>-0.342940</td>
      <td>-0.690228</td>
      <td>1.526176</td>
      <td>0.099671</td>
      <td>0.420762</td>
      <td>0.507868</td>
      <td>-0.267980</td>
      <td>0.606425</td>
      <td>0.105658</td>
      <td>-0.379960</td>
      <td>-0.830015</td>
      <td>0.572628</td>
      <td>0.325382</td>
      <td>-0.526609</td>
      <td>-0.005762</td>
      <td>-0.389831</td>
      <td>0.152670</td>
      <td>-1.229644</td>
      <td>-1.120767</td>
      <td>1.227236</td>
      <td>0.593732</td>
      <td>0.205019</td>
      <td>0.093106</td>
      <td>0.162546</td>
      <td>0.027688</td>
      <td>-0.510699</td>
      <td>0.620364</td>
      <td>-0.112131</td>
      <td>0.767062</td>
      <td>0.952885</td>
      <td>...</td>
      <td>0.372664</td>
      <td>-0.305426</td>
      <td>0.849130</td>
      <td>0.711966</td>
      <td>0.374528</td>
      <td>-0.258611</td>
      <td>0.526762</td>
      <td>-0.937344</td>
      <td>-0.033376</td>
      <td>-0.769654</td>
      <td>-0.043464</td>
      <td>-0.114514</td>
      <td>1.392619</td>
      <td>-0.755007</td>
      <td>0.204673</td>
      <td>0.027586</td>
      <td>-0.250245</td>
      <td>-0.036729</td>
      <td>-0.690240</td>
      <td>0.336875</td>
      <td>0.322192</td>
      <td>0.751618</td>
      <td>-0.524762</td>
      <td>-0.377632</td>
      <td>-0.156866</td>
      <td>0.532724</td>
      <td>0.341866</td>
      <td>0.619067</td>
      <td>0.354497</td>
      <td>-0.405209</td>
      <td>0.025313</td>
      <td>0.516220</td>
      <td>0.146049</td>
      <td>0.032718</td>
      <td>-0.519626</td>
      <td>0.519661</td>
      <td>0.138517</td>
      <td>2.088937</td>
      <td>1.221158</td>
      <td>0.078080</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.687040</td>
      <td>-0.500174</td>
      <td>-0.305429</td>
      <td>-0.699680</td>
      <td>0.841921</td>
      <td>-0.214700</td>
      <td>0.293373</td>
      <td>-0.301780</td>
      <td>-0.272019</td>
      <td>0.014499</td>
      <td>0.473718</td>
      <td>1.249206</td>
      <td>0.406008</td>
      <td>-0.004726</td>
      <td>1.178736</td>
      <td>0.214639</td>
      <td>0.281324</td>
      <td>0.159299</td>
      <td>0.439528</td>
      <td>-0.002513</td>
      <td>0.132788</td>
      <td>0.228131</td>
      <td>0.033830</td>
      <td>-0.362517</td>
      <td>0.368648</td>
      <td>0.585855</td>
      <td>-0.180366</td>
      <td>-0.518967</td>
      <td>-0.761306</td>
      <td>-0.281341</td>
      <td>0.234200</td>
      <td>-0.636722</td>
      <td>0.744267</td>
      <td>0.949797</td>
      <td>0.520612</td>
      <td>0.259343</td>
      <td>-0.328401</td>
      <td>0.031048</td>
      <td>0.083039</td>
      <td>0.215342</td>
      <td>...</td>
      <td>-0.123511</td>
      <td>0.117087</td>
      <td>0.607590</td>
      <td>0.728499</td>
      <td>0.028544</td>
      <td>-0.464870</td>
      <td>0.026714</td>
      <td>0.268479</td>
      <td>0.499388</td>
      <td>0.398665</td>
      <td>-0.950385</td>
      <td>-0.590349</td>
      <td>1.499080</td>
      <td>0.484221</td>
      <td>0.196303</td>
      <td>-0.833465</td>
      <td>-1.010957</td>
      <td>-0.560179</td>
      <td>-0.723957</td>
      <td>-0.414964</td>
      <td>-0.241954</td>
      <td>0.407789</td>
      <td>0.560979</td>
      <td>0.332278</td>
      <td>-0.144441</td>
      <td>0.315520</td>
      <td>0.215303</td>
      <td>0.674635</td>
      <td>0.528797</td>
      <td>0.276679</td>
      <td>-0.312107</td>
      <td>-1.148950</td>
      <td>-1.544938</td>
      <td>-0.316634</td>
      <td>0.888386</td>
      <td>-0.098230</td>
      <td>0.729313</td>
      <td>-1.591790</td>
      <td>-1.469395</td>
      <td>-0.738319</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.098156</td>
      <td>0.357089</td>
      <td>-0.399519</td>
      <td>-1.152962</td>
      <td>0.556336</td>
      <td>-0.167611</td>
      <td>0.621306</td>
      <td>0.257011</td>
      <td>0.555545</td>
      <td>-0.216626</td>
      <td>0.045156</td>
      <td>0.228062</td>
      <td>0.618470</td>
      <td>-0.484683</td>
      <td>-0.368070</td>
      <td>-1.289368</td>
      <td>-0.939703</td>
      <td>-0.196730</td>
      <td>-0.004190</td>
      <td>0.119805</td>
      <td>0.860545</td>
      <td>0.649215</td>
      <td>-0.264511</td>
      <td>-0.395870</td>
      <td>-0.119972</td>
      <td>-0.638330</td>
      <td>-0.314132</td>
      <td>0.077586</td>
      <td>0.633475</td>
      <td>-0.208679</td>
      <td>-0.172794</td>
      <td>0.331446</td>
      <td>0.887240</td>
      <td>0.153340</td>
      <td>-1.042986</td>
      <td>0.221221</td>
      <td>-0.132614</td>
      <td>-0.160470</td>
      <td>-0.321055</td>
      <td>-0.278256</td>
      <td>...</td>
      <td>-0.107711</td>
      <td>-0.233216</td>
      <td>0.738168</td>
      <td>-0.534531</td>
      <td>0.248145</td>
      <td>-0.708572</td>
      <td>0.697999</td>
      <td>0.437727</td>
      <td>-0.294433</td>
      <td>-0.836132</td>
      <td>-0.082634</td>
      <td>-0.971623</td>
      <td>1.088429</td>
      <td>-0.623516</td>
      <td>-0.813609</td>
      <td>-0.564198</td>
      <td>0.473902</td>
      <td>-0.778422</td>
      <td>-1.747040</td>
      <td>0.097035</td>
      <td>0.221612</td>
      <td>0.764328</td>
      <td>-0.042166</td>
      <td>-0.723149</td>
      <td>0.170983</td>
      <td>0.276926</td>
      <td>-0.550801</td>
      <td>0.543812</td>
      <td>0.053855</td>
      <td>-0.244354</td>
      <td>-0.189354</td>
      <td>0.084527</td>
      <td>-0.113233</td>
      <td>0.559557</td>
      <td>1.105027</td>
      <td>1.259349</td>
      <td>0.170044</td>
      <td>0.235219</td>
      <td>-0.537216</td>
      <td>-0.403068</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.367162</td>
      <td>0.417662</td>
      <td>0.777021</td>
      <td>0.499540</td>
      <td>0.986544</td>
      <td>1.134154</td>
      <td>-0.228230</td>
      <td>-0.275093</td>
      <td>0.562762</td>
      <td>0.069679</td>
      <td>-0.187067</td>
      <td>-0.128392</td>
      <td>0.607688</td>
      <td>0.699801</td>
      <td>-0.339842</td>
      <td>-0.303965</td>
      <td>0.131817</td>
      <td>1.141876</td>
      <td>-0.145451</td>
      <td>-0.475309</td>
      <td>0.253973</td>
      <td>-0.504077</td>
      <td>0.488461</td>
      <td>-0.742696</td>
      <td>-0.504800</td>
      <td>0.193658</td>
      <td>-0.562418</td>
      <td>-0.102581</td>
      <td>-0.639381</td>
      <td>-0.176919</td>
      <td>-0.241490</td>
      <td>-0.986595</td>
      <td>-0.940568</td>
      <td>-0.673217</td>
      <td>-0.947213</td>
      <td>-1.573973</td>
      <td>-0.662030</td>
      <td>0.644047</td>
      <td>-0.222222</td>
      <td>0.047322</td>
      <td>...</td>
      <td>-0.114550</td>
      <td>0.138277</td>
      <td>-0.615157</td>
      <td>0.348316</td>
      <td>0.016598</td>
      <td>-0.000390</td>
      <td>-0.056557</td>
      <td>0.374588</td>
      <td>0.079280</td>
      <td>-0.858904</td>
      <td>-0.445038</td>
      <td>-0.495724</td>
      <td>0.458230</td>
      <td>0.305565</td>
      <td>-0.535186</td>
      <td>-1.251780</td>
      <td>-0.587194</td>
      <td>0.041516</td>
      <td>-0.796481</td>
      <td>-0.175673</td>
      <td>-0.394703</td>
      <td>0.647540</td>
      <td>-0.101374</td>
      <td>-0.045299</td>
      <td>-0.473755</td>
      <td>0.272957</td>
      <td>0.669824</td>
      <td>0.729265</td>
      <td>0.890485</td>
      <td>-0.061894</td>
      <td>0.331919</td>
      <td>-0.574129</td>
      <td>0.074903</td>
      <td>-0.292790</td>
      <td>0.897056</td>
      <td>0.009449</td>
      <td>-0.800938</td>
      <td>1.907602</td>
      <td>1.185285</td>
      <td>0.338741</td>
    </tr>
    <tr>
      <th>21</th>
      <td>-0.312459</td>
      <td>-0.208633</td>
      <td>0.573081</td>
      <td>-0.980985</td>
      <td>0.332110</td>
      <td>-0.262794</td>
      <td>-0.106663</td>
      <td>-0.608988</td>
      <td>0.894032</td>
      <td>-0.395945</td>
      <td>-1.044647</td>
      <td>-0.791708</td>
      <td>0.439964</td>
      <td>-0.889057</td>
      <td>-0.027751</td>
      <td>-0.401983</td>
      <td>-0.158984</td>
      <td>1.472960</td>
      <td>-0.276086</td>
      <td>-0.625204</td>
      <td>0.290048</td>
      <td>-0.605185</td>
      <td>-0.080940</td>
      <td>-0.097603</td>
      <td>-0.395186</td>
      <td>-0.688625</td>
      <td>-0.811664</td>
      <td>0.715776</td>
      <td>-0.629625</td>
      <td>-0.483873</td>
      <td>0.521282</td>
      <td>0.139339</td>
      <td>0.023283</td>
      <td>-1.403482</td>
      <td>-1.263058</td>
      <td>-0.434535</td>
      <td>0.115133</td>
      <td>-0.398976</td>
      <td>0.832664</td>
      <td>0.256363</td>
      <td>...</td>
      <td>0.338815</td>
      <td>-0.189463</td>
      <td>0.930674</td>
      <td>0.025814</td>
      <td>0.617591</td>
      <td>-0.656823</td>
      <td>-0.302592</td>
      <td>0.567117</td>
      <td>-0.452270</td>
      <td>-1.015017</td>
      <td>-0.441374</td>
      <td>-0.051226</td>
      <td>0.470042</td>
      <td>-0.148346</td>
      <td>-0.712682</td>
      <td>-0.263413</td>
      <td>0.392066</td>
      <td>-0.347024</td>
      <td>-0.467311</td>
      <td>1.015256</td>
      <td>-0.490008</td>
      <td>-0.986600</td>
      <td>-0.386268</td>
      <td>-0.660777</td>
      <td>0.098465</td>
      <td>-0.903067</td>
      <td>-1.009152</td>
      <td>0.395101</td>
      <td>0.582816</td>
      <td>-0.152901</td>
      <td>0.095916</td>
      <td>0.843033</td>
      <td>0.783722</td>
      <td>0.423228</td>
      <td>-0.826458</td>
      <td>-0.035861</td>
      <td>-0.444599</td>
      <td>-0.706697</td>
      <td>-0.399666</td>
      <td>0.860844</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.775705</td>
      <td>0.308717</td>
      <td>-0.366527</td>
      <td>-0.858622</td>
      <td>0.418410</td>
      <td>-0.250698</td>
      <td>0.966063</td>
      <td>0.503372</td>
      <td>-0.427428</td>
      <td>-0.104588</td>
      <td>-0.920395</td>
      <td>0.133457</td>
      <td>0.344330</td>
      <td>-0.313928</td>
      <td>-0.476582</td>
      <td>-0.589256</td>
      <td>-0.688864</td>
      <td>0.661884</td>
      <td>0.572622</td>
      <td>-0.097417</td>
      <td>-0.413802</td>
      <td>0.689755</td>
      <td>0.118172</td>
      <td>0.099556</td>
      <td>0.147646</td>
      <td>-1.034933</td>
      <td>-0.275647</td>
      <td>-0.013721</td>
      <td>-0.459010</td>
      <td>-0.012728</td>
      <td>-0.362354</td>
      <td>-0.550157</td>
      <td>0.102827</td>
      <td>0.104234</td>
      <td>1.057663</td>
      <td>-0.892996</td>
      <td>0.312202</td>
      <td>0.324863</td>
      <td>0.104925</td>
      <td>0.113847</td>
      <td>...</td>
      <td>-0.518774</td>
      <td>-0.768013</td>
      <td>-0.591909</td>
      <td>0.634093</td>
      <td>0.883472</td>
      <td>-1.049314</td>
      <td>0.966687</td>
      <td>-0.100876</td>
      <td>-0.319228</td>
      <td>-0.754538</td>
      <td>-0.621027</td>
      <td>-1.063372</td>
      <td>-0.162404</td>
      <td>0.472145</td>
      <td>-0.458703</td>
      <td>-1.468378</td>
      <td>-0.765311</td>
      <td>0.116699</td>
      <td>0.643592</td>
      <td>0.854198</td>
      <td>-0.547644</td>
      <td>-0.298008</td>
      <td>-0.129767</td>
      <td>0.072161</td>
      <td>-0.369454</td>
      <td>-0.271690</td>
      <td>-0.004709</td>
      <td>0.351104</td>
      <td>0.784535</td>
      <td>-0.543944</td>
      <td>-0.116013</td>
      <td>0.329469</td>
      <td>0.035734</td>
      <td>-0.158206</td>
      <td>0.469781</td>
      <td>0.315494</td>
      <td>-0.065583</td>
      <td>-2.500106</td>
      <td>-2.001045</td>
      <td>-0.905394</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-0.177881</td>
      <td>-0.674715</td>
      <td>0.131749</td>
      <td>1.330524</td>
      <td>0.689764</td>
      <td>-0.443796</td>
      <td>1.103116</td>
      <td>-0.402552</td>
      <td>-0.227325</td>
      <td>-0.895946</td>
      <td>0.124060</td>
      <td>1.013606</td>
      <td>0.872437</td>
      <td>0.192277</td>
      <td>-0.075896</td>
      <td>-0.912030</td>
      <td>0.726026</td>
      <td>0.237739</td>
      <td>-0.169663</td>
      <td>-0.454357</td>
      <td>0.685719</td>
      <td>-0.117060</td>
      <td>0.138292</td>
      <td>-0.197179</td>
      <td>0.347546</td>
      <td>-0.257307</td>
      <td>-0.034034</td>
      <td>-0.807077</td>
      <td>-0.318363</td>
      <td>-0.130455</td>
      <td>0.124563</td>
      <td>1.153435</td>
      <td>1.185523</td>
      <td>1.615969</td>
      <td>-0.313008</td>
      <td>-0.811921</td>
      <td>-0.706370</td>
      <td>0.004404</td>
      <td>-0.028330</td>
      <td>0.834677</td>
      <td>...</td>
      <td>-1.304130</td>
      <td>-0.814434</td>
      <td>-0.575717</td>
      <td>0.618823</td>
      <td>1.086990</td>
      <td>0.111085</td>
      <td>0.034344</td>
      <td>0.216514</td>
      <td>0.727702</td>
      <td>-0.534611</td>
      <td>0.074523</td>
      <td>0.111713</td>
      <td>0.328693</td>
      <td>-0.757478</td>
      <td>-0.487386</td>
      <td>-0.338914</td>
      <td>-0.127052</td>
      <td>-0.272553</td>
      <td>-0.504911</td>
      <td>0.454252</td>
      <td>-0.003061</td>
      <td>0.245526</td>
      <td>-0.071304</td>
      <td>-0.330196</td>
      <td>-0.390784</td>
      <td>-0.955159</td>
      <td>-1.112144</td>
      <td>0.499016</td>
      <td>-0.261417</td>
      <td>-0.031397</td>
      <td>0.081588</td>
      <td>0.611964</td>
      <td>-0.218196</td>
      <td>0.213764</td>
      <td>-0.513477</td>
      <td>0.162292</td>
      <td>0.072512</td>
      <td>-0.819442</td>
      <td>-0.457069</td>
      <td>-0.224307</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-1.125070</td>
      <td>-0.583367</td>
      <td>-1.338806</td>
      <td>-1.148073</td>
      <td>0.198039</td>
      <td>0.780751</td>
      <td>0.418752</td>
      <td>0.063539</td>
      <td>-0.441314</td>
      <td>0.001385</td>
      <td>0.571025</td>
      <td>0.481279</td>
      <td>0.714956</td>
      <td>-0.263354</td>
      <td>0.187760</td>
      <td>-0.064780</td>
      <td>0.280658</td>
      <td>-0.255903</td>
      <td>-0.944630</td>
      <td>-0.837819</td>
      <td>0.183112</td>
      <td>-1.090012</td>
      <td>0.272836</td>
      <td>-0.725646</td>
      <td>0.012527</td>
      <td>-0.048655</td>
      <td>-0.731625</td>
      <td>-1.216136</td>
      <td>-0.551188</td>
      <td>-1.239440</td>
      <td>-0.418530</td>
      <td>-0.605146</td>
      <td>-1.207473</td>
      <td>-1.008543</td>
      <td>-0.628407</td>
      <td>0.007912</td>
      <td>-0.224909</td>
      <td>-0.562488</td>
      <td>-0.190453</td>
      <td>0.357684</td>
      <td>...</td>
      <td>0.088834</td>
      <td>0.365246</td>
      <td>0.751514</td>
      <td>0.605577</td>
      <td>-0.336448</td>
      <td>-0.345362</td>
      <td>0.051640</td>
      <td>-0.677232</td>
      <td>0.766104</td>
      <td>-0.201815</td>
      <td>-0.120336</td>
      <td>0.209593</td>
      <td>0.960378</td>
      <td>0.502350</td>
      <td>0.115062</td>
      <td>-0.886719</td>
      <td>-0.001940</td>
      <td>-0.204632</td>
      <td>0.184703</td>
      <td>-0.150038</td>
      <td>0.444595</td>
      <td>0.039062</td>
      <td>-0.049898</td>
      <td>-0.130228</td>
      <td>0.023927</td>
      <td>-0.081489</td>
      <td>-0.110864</td>
      <td>-0.434862</td>
      <td>-0.373587</td>
      <td>-0.450362</td>
      <td>-0.824274</td>
      <td>0.104700</td>
      <td>0.561267</td>
      <td>0.137590</td>
      <td>-0.494833</td>
      <td>-0.284300</td>
      <td>-0.245970</td>
      <td>-2.174761</td>
      <td>-1.405998</td>
      <td>-0.635084</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>-0.166381</td>
      <td>-0.169308</td>
      <td>-0.175077</td>
      <td>0.007615</td>
      <td>0.331345</td>
      <td>1.470617</td>
      <td>0.197623</td>
      <td>0.004884</td>
      <td>-0.565696</td>
      <td>0.001070</td>
      <td>-0.340889</td>
      <td>0.466212</td>
      <td>0.023213</td>
      <td>0.348337</td>
      <td>-0.630121</td>
      <td>0.882315</td>
      <td>1.108850</td>
      <td>0.311131</td>
      <td>0.649753</td>
      <td>0.321761</td>
      <td>0.452108</td>
      <td>1.125334</td>
      <td>-0.212712</td>
      <td>0.264598</td>
      <td>0.736390</td>
      <td>-0.591724</td>
      <td>-0.048592</td>
      <td>-0.170294</td>
      <td>-0.273869</td>
      <td>-0.132061</td>
      <td>1.045731</td>
      <td>-0.917555</td>
      <td>-0.569807</td>
      <td>0.021639</td>
      <td>0.090436</td>
      <td>0.139125</td>
      <td>-1.047283</td>
      <td>0.012292</td>
      <td>-0.144956</td>
      <td>0.231676</td>
      <td>...</td>
      <td>-0.089270</td>
      <td>-0.045447</td>
      <td>0.131303</td>
      <td>0.706352</td>
      <td>0.259088</td>
      <td>-0.054535</td>
      <td>-0.100901</td>
      <td>0.309770</td>
      <td>-0.813285</td>
      <td>0.470703</td>
      <td>0.895509</td>
      <td>-0.423646</td>
      <td>1.140602</td>
      <td>-0.239104</td>
      <td>0.205190</td>
      <td>-0.843507</td>
      <td>-0.759740</td>
      <td>0.658831</td>
      <td>-0.235513</td>
      <td>-0.057677</td>
      <td>-0.603223</td>
      <td>-0.953685</td>
      <td>0.535504</td>
      <td>-0.026873</td>
      <td>0.478922</td>
      <td>0.329675</td>
      <td>0.408078</td>
      <td>0.494441</td>
      <td>0.228775</td>
      <td>0.557352</td>
      <td>0.665688</td>
      <td>-0.083073</td>
      <td>0.635609</td>
      <td>-0.268781</td>
      <td>-0.006366</td>
      <td>-0.114629</td>
      <td>-0.378574</td>
      <td>0.443510</td>
      <td>0.502730</td>
      <td>-0.058765</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.056777</td>
      <td>-0.961179</td>
      <td>-0.317981</td>
      <td>-0.734091</td>
      <td>-0.045639</td>
      <td>-0.785631</td>
      <td>-0.465910</td>
      <td>-0.558350</td>
      <td>-0.263772</td>
      <td>-0.677878</td>
      <td>-0.335770</td>
      <td>-0.242372</td>
      <td>0.502897</td>
      <td>-1.188134</td>
      <td>-0.684891</td>
      <td>0.594347</td>
      <td>0.107804</td>
      <td>0.578153</td>
      <td>0.370327</td>
      <td>0.053742</td>
      <td>-0.394012</td>
      <td>0.690363</td>
      <td>0.973828</td>
      <td>0.558157</td>
      <td>0.213807</td>
      <td>0.072138</td>
      <td>0.841798</td>
      <td>-0.205060</td>
      <td>0.334461</td>
      <td>1.772448</td>
      <td>1.413101</td>
      <td>0.578854</td>
      <td>-0.413550</td>
      <td>0.323025</td>
      <td>-0.154311</td>
      <td>0.617667</td>
      <td>0.623226</td>
      <td>-1.198501</td>
      <td>0.069849</td>
      <td>0.069478</td>
      <td>...</td>
      <td>0.037214</td>
      <td>-0.583255</td>
      <td>-0.191179</td>
      <td>-0.334772</td>
      <td>0.538268</td>
      <td>0.342408</td>
      <td>0.241593</td>
      <td>0.096827</td>
      <td>-0.774980</td>
      <td>-1.060704</td>
      <td>0.742172</td>
      <td>1.689661</td>
      <td>0.765935</td>
      <td>-0.228797</td>
      <td>0.754246</td>
      <td>-1.564124</td>
      <td>0.009119</td>
      <td>0.479808</td>
      <td>0.069101</td>
      <td>-1.162198</td>
      <td>1.030772</td>
      <td>-0.204843</td>
      <td>-0.619328</td>
      <td>0.221737</td>
      <td>0.942495</td>
      <td>0.452874</td>
      <td>0.425907</td>
      <td>0.399734</td>
      <td>-0.539761</td>
      <td>0.098617</td>
      <td>0.382464</td>
      <td>-0.760898</td>
      <td>-0.438208</td>
      <td>-0.127291</td>
      <td>0.611200</td>
      <td>-0.198991</td>
      <td>-0.101271</td>
      <td>-3.876653</td>
      <td>-3.139189</td>
      <td>-1.534861</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.063420</td>
      <td>0.326842</td>
      <td>0.900116</td>
      <td>-0.411236</td>
      <td>-0.449563</td>
      <td>0.055842</td>
      <td>-1.487074</td>
      <td>-0.233905</td>
      <td>-0.425119</td>
      <td>0.899636</td>
      <td>-0.177686</td>
      <td>-0.368147</td>
      <td>-0.161190</td>
      <td>0.212497</td>
      <td>-0.337307</td>
      <td>-0.871956</td>
      <td>-0.223158</td>
      <td>0.523836</td>
      <td>0.355244</td>
      <td>-0.462401</td>
      <td>-1.506730</td>
      <td>-0.198881</td>
      <td>-0.686223</td>
      <td>-0.382495</td>
      <td>0.860639</td>
      <td>-0.589188</td>
      <td>-0.135437</td>
      <td>-0.448683</td>
      <td>-0.004966</td>
      <td>-0.110281</td>
      <td>0.455786</td>
      <td>-0.647008</td>
      <td>0.741017</td>
      <td>0.509349</td>
      <td>1.349352</td>
      <td>2.105570</td>
      <td>0.622146</td>
      <td>0.717224</td>
      <td>0.809469</td>
      <td>-0.805412</td>
      <td>...</td>
      <td>0.031815</td>
      <td>0.177715</td>
      <td>1.258343</td>
      <td>0.472737</td>
      <td>0.567206</td>
      <td>0.586259</td>
      <td>0.249644</td>
      <td>1.015646</td>
      <td>-0.424173</td>
      <td>-0.328390</td>
      <td>0.147154</td>
      <td>0.505293</td>
      <td>0.147404</td>
      <td>-1.231534</td>
      <td>-0.300223</td>
      <td>0.845826</td>
      <td>0.318462</td>
      <td>0.759192</td>
      <td>1.283050</td>
      <td>-0.366736</td>
      <td>-0.431629</td>
      <td>0.276053</td>
      <td>0.167811</td>
      <td>-0.001940</td>
      <td>-0.915043</td>
      <td>-0.850643</td>
      <td>0.122017</td>
      <td>0.641436</td>
      <td>-0.742596</td>
      <td>-1.333760</td>
      <td>0.081902</td>
      <td>-0.504214</td>
      <td>-0.097918</td>
      <td>-0.741879</td>
      <td>-0.824557</td>
      <td>-0.584881</td>
      <td>-0.117345</td>
      <td>3.116897</td>
      <td>1.560307</td>
      <td>1.034077</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.147541</td>
      <td>-0.867383</td>
      <td>-0.236542</td>
      <td>-0.968536</td>
      <td>-0.153106</td>
      <td>0.223169</td>
      <td>-0.207409</td>
      <td>-0.906177</td>
      <td>-0.191472</td>
      <td>1.026214</td>
      <td>0.556162</td>
      <td>1.044939</td>
      <td>-0.046769</td>
      <td>0.102076</td>
      <td>0.365776</td>
      <td>1.000655</td>
      <td>0.967426</td>
      <td>-0.131016</td>
      <td>0.434174</td>
      <td>-0.156104</td>
      <td>-1.223489</td>
      <td>-0.505770</td>
      <td>-0.210151</td>
      <td>-0.270404</td>
      <td>0.753858</td>
      <td>0.319945</td>
      <td>0.493297</td>
      <td>-0.048685</td>
      <td>-0.599791</td>
      <td>0.032684</td>
      <td>0.255843</td>
      <td>-0.195349</td>
      <td>0.251909</td>
      <td>0.812025</td>
      <td>0.871847</td>
      <td>0.831234</td>
      <td>1.075521</td>
      <td>0.351281</td>
      <td>0.426604</td>
      <td>-0.196673</td>
      <td>...</td>
      <td>-0.042233</td>
      <td>0.132670</td>
      <td>0.442519</td>
      <td>0.175962</td>
      <td>-0.352201</td>
      <td>-0.628927</td>
      <td>0.002220</td>
      <td>0.112418</td>
      <td>-0.673471</td>
      <td>-0.203610</td>
      <td>-0.500669</td>
      <td>0.686458</td>
      <td>0.884672</td>
      <td>0.031264</td>
      <td>-0.136948</td>
      <td>-0.429175</td>
      <td>0.097677</td>
      <td>-0.005514</td>
      <td>-0.171809</td>
      <td>-0.201845</td>
      <td>0.017916</td>
      <td>0.152599</td>
      <td>0.230083</td>
      <td>-0.016095</td>
      <td>0.359600</td>
      <td>0.333653</td>
      <td>0.424912</td>
      <td>-0.712785</td>
      <td>-0.324456</td>
      <td>1.289231</td>
      <td>1.394077</td>
      <td>0.834111</td>
      <td>-0.589256</td>
      <td>-0.671874</td>
      <td>1.077514</td>
      <td>0.229449</td>
      <td>0.604683</td>
      <td>0.078386</td>
      <td>0.202838</td>
      <td>-0.213218</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.200336</td>
      <td>-0.460380</td>
      <td>-0.655901</td>
      <td>-0.402896</td>
      <td>-0.328043</td>
      <td>0.218969</td>
      <td>0.450027</td>
      <td>0.312863</td>
      <td>-0.182782</td>
      <td>-1.148618</td>
      <td>1.308767</td>
      <td>0.951790</td>
      <td>-0.313567</td>
      <td>-0.728537</td>
      <td>0.057610</td>
      <td>0.267448</td>
      <td>-0.196768</td>
      <td>-0.350933</td>
      <td>-0.961253</td>
      <td>0.178117</td>
      <td>0.325659</td>
      <td>1.332356</td>
      <td>1.076677</td>
      <td>0.609296</td>
      <td>-0.025000</td>
      <td>-0.663836</td>
      <td>-0.675744</td>
      <td>-0.585410</td>
      <td>0.152311</td>
      <td>1.534352</td>
      <td>0.647884</td>
      <td>0.376968</td>
      <td>0.247637</td>
      <td>1.540433</td>
      <td>1.476652</td>
      <td>1.331831</td>
      <td>-0.119236</td>
      <td>-1.158047</td>
      <td>-0.013250</td>
      <td>-0.507647</td>
      <td>...</td>
      <td>-1.117694</td>
      <td>0.040969</td>
      <td>0.091439</td>
      <td>-0.123984</td>
      <td>0.460537</td>
      <td>0.690628</td>
      <td>-1.280482</td>
      <td>-1.001907</td>
      <td>-0.746752</td>
      <td>-1.549250</td>
      <td>-0.605389</td>
      <td>-0.636117</td>
      <td>0.434135</td>
      <td>-0.443242</td>
      <td>-0.013603</td>
      <td>-0.057549</td>
      <td>-0.566024</td>
      <td>-0.878655</td>
      <td>-0.905103</td>
      <td>-1.008248</td>
      <td>-0.001571</td>
      <td>-0.014411</td>
      <td>1.063274</td>
      <td>-0.055419</td>
      <td>-0.090100</td>
      <td>-0.616367</td>
      <td>0.313659</td>
      <td>0.534591</td>
      <td>0.185202</td>
      <td>0.528672</td>
      <td>0.291528</td>
      <td>-0.184475</td>
      <td>-0.064377</td>
      <td>-1.299254</td>
      <td>0.122660</td>
      <td>-0.368315</td>
      <td>-0.548401</td>
      <td>0.572666</td>
      <td>0.446106</td>
      <td>0.755925</td>
    </tr>
  </tbody>
</table>
<p>30 rows Ã 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f1910306d00&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t          P&gt;|t|    2.5 %    97.5 %
D  1.126189  0.038913  28.940878  3.655375e-184  1.04992  1.202458
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  6.058 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d8bbf5861d671d414e1a.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>