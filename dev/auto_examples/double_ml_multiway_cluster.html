
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiway Cluster Robust DML &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DML: Bonus Data" href="double_ml_bonus_data.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../guide/guide.html"> User guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="active">
                    <a href="">Multiway Cluster Robust DML</a>
                </li>
            
          
            
                <li class="">
                    <a href="double_ml_bonus_data.html">DML: Bonus Data</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#simulate-multiway-cluster-data" class="nav-link">Simulate multiway cluster data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" class="nav-link">Initialize the objects of class DoubleMLData and DoubleMLPLIV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#split-samples-and-transfer-the-sample-splitting-to-the-object" class="nav-link">Split samples and transfer the sample splitting to the object</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#fit-the-model-and-show-a-summary" class="nav-link">Fit the model and show a summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" class="nav-link">Visualization of sample splitting with tuple and linear indexing</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" class="nav-link">Visualize sample splitting with tuples (one plot per fold)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" class="nav-link">Visualize sample splitting with linear indexing (one column per fold)</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-double-ml-multiway-cluster-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="multiway-cluster-robust-dml">
<span id="sphx-glr-auto-examples-double-ml-multiway-cluster-py"></span><h1>Multiway Cluster Robust DML<a class="headerlink" href="#multiway-cluster-robust-dml" title="Permalink to this headline">¶</a></h1>
<p>This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML
package.
Chiang et al. (2020) consider double-indexed data</p>
<div class="math notranslate nohighlight">
\[\lbrace W_{ij}: i \in \lbrace 1, \ldots, N \rbrace, j \in \lbrace 1, \ldots, M \rbrace \rbrace\]</div>
<p>and the partially linear IV regression model (PLIV)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y_{ij} = D_{ij} \theta_0 +  g_0(X_{ij}) + \epsilon_{ij}, &amp; &amp;\mathbb{E}(\epsilon_{ij} | X_{ij}, Z_{ij}) = 0,\\Z_{ij} = m_0(X_{ij}) + v_{ij}, &amp; &amp;\mathbb{E}(v_{ij} | X_{ij}) = 0.\end{aligned}\end{align} \]</div>
<p>TODO: Add a few more details and the reference!
<a class="reference external" href="https://arxiv.org/pdf/1909.03489.pdf">https://arxiv.org/pdf/1909.03489.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span><span class="p">,</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a>
<span class="kn">from</span> <span class="nn">doubleml.double_ml_resampling</span> <span class="kn">import</span> <span class="n">DoubleMLMultiwayResampling</span>

<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span>
</pre></div>
</div>
<div class="section" id="simulate-multiway-cluster-data">
<h2>Simulate multiway cluster data<a class="headerlink" href="#simulate-multiway-cluster-data" title="Permalink to this headline">¶</a></h2>
<p>We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the simulation parameters</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (first dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a> <span class="o">=</span> <span class="mi">25</span>  <span class="c1"># number of observations (second dimension)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># dimension of X</span>

<span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_pliv_multiway_cluster_CKMS2019</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dim_X</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data comes with multi index for rows (tuples with two entries)</span>
<span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>X5</th>
      <th>X6</th>
      <th>X7</th>
      <th>X8</th>
      <th>X9</th>
      <th>X10</th>
      <th>X11</th>
      <th>X12</th>
      <th>X13</th>
      <th>X14</th>
      <th>X15</th>
      <th>X16</th>
      <th>X17</th>
      <th>X18</th>
      <th>X19</th>
      <th>X20</th>
      <th>X21</th>
      <th>X22</th>
      <th>X23</th>
      <th>X24</th>
      <th>X25</th>
      <th>X26</th>
      <th>X27</th>
      <th>X28</th>
      <th>X29</th>
      <th>X30</th>
      <th>X31</th>
      <th>X32</th>
      <th>X33</th>
      <th>X34</th>
      <th>X35</th>
      <th>X36</th>
      <th>X37</th>
      <th>X38</th>
      <th>X39</th>
      <th>X40</th>
      <th>...</th>
      <th>X64</th>
      <th>X65</th>
      <th>X66</th>
      <th>X67</th>
      <th>X68</th>
      <th>X69</th>
      <th>X70</th>
      <th>X71</th>
      <th>X72</th>
      <th>X73</th>
      <th>X74</th>
      <th>X75</th>
      <th>X76</th>
      <th>X77</th>
      <th>X78</th>
      <th>X79</th>
      <th>X80</th>
      <th>X81</th>
      <th>X82</th>
      <th>X83</th>
      <th>X84</th>
      <th>X85</th>
      <th>X86</th>
      <th>X87</th>
      <th>X88</th>
      <th>X89</th>
      <th>X90</th>
      <th>X91</th>
      <th>X92</th>
      <th>X93</th>
      <th>X94</th>
      <th>X95</th>
      <th>X96</th>
      <th>X97</th>
      <th>X98</th>
      <th>X99</th>
      <th>X100</th>
      <th>Y</th>
      <th>D</th>
      <th>Z</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="25" valign="top">0</th>
      <th>0</th>
      <td>-0.039370</td>
      <td>-0.926080</td>
      <td>-0.310822</td>
      <td>-0.062434</td>
      <td>-0.407213</td>
      <td>0.787350</td>
      <td>0.014300</td>
      <td>-0.298912</td>
      <td>0.334898</td>
      <td>0.112702</td>
      <td>-0.014290</td>
      <td>-0.458398</td>
      <td>-0.055329</td>
      <td>1.242296</td>
      <td>0.367875</td>
      <td>0.182020</td>
      <td>0.087789</td>
      <td>0.497431</td>
      <td>1.447113</td>
      <td>-0.191174</td>
      <td>0.293976</td>
      <td>0.562583</td>
      <td>0.667211</td>
      <td>1.095661</td>
      <td>-0.194816</td>
      <td>-0.676030</td>
      <td>-1.090588</td>
      <td>-0.744534</td>
      <td>0.063975</td>
      <td>0.770281</td>
      <td>0.769362</td>
      <td>0.019086</td>
      <td>0.542585</td>
      <td>-0.145997</td>
      <td>0.405468</td>
      <td>0.262616</td>
      <td>0.269648</td>
      <td>-0.369282</td>
      <td>-0.777469</td>
      <td>-0.095470</td>
      <td>...</td>
      <td>-0.321992</td>
      <td>0.281819</td>
      <td>0.891530</td>
      <td>-0.163319</td>
      <td>-0.266772</td>
      <td>0.068550</td>
      <td>-0.043416</td>
      <td>-0.960268</td>
      <td>-0.592285</td>
      <td>-0.198289</td>
      <td>-0.367864</td>
      <td>0.749338</td>
      <td>0.170399</td>
      <td>-0.333168</td>
      <td>0.501224</td>
      <td>-0.155213</td>
      <td>0.054321</td>
      <td>0.273448</td>
      <td>0.403346</td>
      <td>0.106271</td>
      <td>0.142273</td>
      <td>0.034592</td>
      <td>0.167302</td>
      <td>0.096629</td>
      <td>0.349696</td>
      <td>-0.094217</td>
      <td>-0.368529</td>
      <td>-0.886450</td>
      <td>-1.122827</td>
      <td>-1.426474</td>
      <td>-0.240041</td>
      <td>-0.584062</td>
      <td>0.573520</td>
      <td>0.286798</td>
      <td>0.717306</td>
      <td>-0.485366</td>
      <td>0.062496</td>
      <td>-0.721429</td>
      <td>-0.108298</td>
      <td>-0.188093</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.313092</td>
      <td>-0.244827</td>
      <td>0.832149</td>
      <td>0.302351</td>
      <td>-0.513915</td>
      <td>-0.533598</td>
      <td>0.157826</td>
      <td>0.191806</td>
      <td>0.588633</td>
      <td>1.110823</td>
      <td>0.325161</td>
      <td>0.594048</td>
      <td>-0.175183</td>
      <td>0.892002</td>
      <td>-0.368070</td>
      <td>0.283979</td>
      <td>0.206880</td>
      <td>0.392994</td>
      <td>-0.474482</td>
      <td>-0.923920</td>
      <td>-0.457305</td>
      <td>-0.789959</td>
      <td>-0.648862</td>
      <td>0.331925</td>
      <td>0.334205</td>
      <td>0.491658</td>
      <td>0.155834</td>
      <td>0.305670</td>
      <td>-0.321152</td>
      <td>0.516553</td>
      <td>0.085247</td>
      <td>-0.107536</td>
      <td>-0.090231</td>
      <td>-0.870121</td>
      <td>0.326180</td>
      <td>1.221149</td>
      <td>0.296142</td>
      <td>0.328146</td>
      <td>0.110482</td>
      <td>1.145837</td>
      <td>...</td>
      <td>-0.530183</td>
      <td>0.176107</td>
      <td>0.379440</td>
      <td>-0.323728</td>
      <td>-0.369502</td>
      <td>-0.302375</td>
      <td>0.685967</td>
      <td>-0.657666</td>
      <td>-0.082821</td>
      <td>-0.823868</td>
      <td>-0.722906</td>
      <td>-0.170829</td>
      <td>-0.224302</td>
      <td>-0.031824</td>
      <td>0.555855</td>
      <td>0.306379</td>
      <td>1.102530</td>
      <td>-0.063305</td>
      <td>0.548749</td>
      <td>-0.124182</td>
      <td>0.211724</td>
      <td>1.076268</td>
      <td>-0.692807</td>
      <td>-0.294405</td>
      <td>-0.021454</td>
      <td>0.177224</td>
      <td>0.692842</td>
      <td>1.067159</td>
      <td>-0.284979</td>
      <td>0.311945</td>
      <td>-0.419556</td>
      <td>-0.483176</td>
      <td>0.178027</td>
      <td>-0.533348</td>
      <td>-0.947228</td>
      <td>-0.256610</td>
      <td>1.086191</td>
      <td>2.517263</td>
      <td>1.553596</td>
      <td>0.183577</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.670368</td>
      <td>-0.557672</td>
      <td>-0.603428</td>
      <td>0.576897</td>
      <td>-0.824350</td>
      <td>0.006793</td>
      <td>0.340989</td>
      <td>0.154737</td>
      <td>0.118041</td>
      <td>-0.081125</td>
      <td>0.998360</td>
      <td>0.855857</td>
      <td>0.162086</td>
      <td>0.418350</td>
      <td>-0.088037</td>
      <td>1.230239</td>
      <td>-0.596033</td>
      <td>-0.034474</td>
      <td>0.951900</td>
      <td>-1.140266</td>
      <td>-0.388878</td>
      <td>-0.665416</td>
      <td>0.189108</td>
      <td>0.075637</td>
      <td>0.192150</td>
      <td>0.594575</td>
      <td>-0.174620</td>
      <td>-0.178047</td>
      <td>-0.846277</td>
      <td>-0.564424</td>
      <td>-0.455906</td>
      <td>-0.210856</td>
      <td>0.217673</td>
      <td>0.395089</td>
      <td>0.659740</td>
      <td>1.486524</td>
      <td>1.756715</td>
      <td>-0.619288</td>
      <td>0.129471</td>
      <td>0.699791</td>
      <td>...</td>
      <td>-0.627441</td>
      <td>0.560761</td>
      <td>0.203926</td>
      <td>0.114824</td>
      <td>0.802741</td>
      <td>-0.240301</td>
      <td>-0.320670</td>
      <td>0.242631</td>
      <td>-0.214192</td>
      <td>0.255286</td>
      <td>-0.532265</td>
      <td>0.668398</td>
      <td>0.437409</td>
      <td>-0.632531</td>
      <td>1.076895</td>
      <td>0.525117</td>
      <td>0.731511</td>
      <td>-0.290321</td>
      <td>0.266612</td>
      <td>0.207693</td>
      <td>-0.105915</td>
      <td>-0.034958</td>
      <td>0.686633</td>
      <td>-0.330127</td>
      <td>-0.409526</td>
      <td>0.530621</td>
      <td>0.252826</td>
      <td>0.172398</td>
      <td>-0.358494</td>
      <td>0.148073</td>
      <td>-0.407766</td>
      <td>-0.070215</td>
      <td>0.226520</td>
      <td>-0.046885</td>
      <td>-0.594217</td>
      <td>0.194798</td>
      <td>0.141255</td>
      <td>0.496411</td>
      <td>-0.585034</td>
      <td>-0.287639</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.078437</td>
      <td>-0.086488</td>
      <td>0.480111</td>
      <td>1.660285</td>
      <td>-0.106671</td>
      <td>0.054613</td>
      <td>0.170322</td>
      <td>-0.675425</td>
      <td>0.882687</td>
      <td>0.285841</td>
      <td>0.239454</td>
      <td>0.219712</td>
      <td>1.251282</td>
      <td>1.002043</td>
      <td>-0.131083</td>
      <td>-0.234747</td>
      <td>-0.518680</td>
      <td>0.406890</td>
      <td>-0.081879</td>
      <td>-1.227291</td>
      <td>-0.501227</td>
      <td>-0.126830</td>
      <td>-0.224259</td>
      <td>-0.070133</td>
      <td>0.576183</td>
      <td>0.434648</td>
      <td>0.350075</td>
      <td>0.150054</td>
      <td>-0.199565</td>
      <td>0.318912</td>
      <td>0.019609</td>
      <td>-0.479689</td>
      <td>0.300662</td>
      <td>0.465932</td>
      <td>0.808860</td>
      <td>1.811192</td>
      <td>0.795393</td>
      <td>-0.602518</td>
      <td>-0.346814</td>
      <td>-0.422801</td>
      <td>...</td>
      <td>0.249612</td>
      <td>0.771507</td>
      <td>0.616663</td>
      <td>-0.685291</td>
      <td>-0.083841</td>
      <td>-1.213573</td>
      <td>-1.122365</td>
      <td>-0.348630</td>
      <td>-0.008127</td>
      <td>0.722249</td>
      <td>-0.299551</td>
      <td>-0.176310</td>
      <td>0.346021</td>
      <td>-0.265700</td>
      <td>0.464399</td>
      <td>0.033086</td>
      <td>-0.978118</td>
      <td>-0.225230</td>
      <td>-0.074758</td>
      <td>0.390888</td>
      <td>0.346438</td>
      <td>0.065155</td>
      <td>-0.298302</td>
      <td>-0.942176</td>
      <td>-1.166463</td>
      <td>0.182465</td>
      <td>0.983619</td>
      <td>-0.483396</td>
      <td>-0.576139</td>
      <td>0.253959</td>
      <td>-0.208290</td>
      <td>0.094557</td>
      <td>-0.301450</td>
      <td>-0.442311</td>
      <td>0.325838</td>
      <td>1.418318</td>
      <td>0.900760</td>
      <td>1.989841</td>
      <td>0.880118</td>
      <td>0.283675</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.284447</td>
      <td>-0.324242</td>
      <td>-0.399094</td>
      <td>-0.198510</td>
      <td>-1.534118</td>
      <td>-1.037649</td>
      <td>-0.088182</td>
      <td>-0.744020</td>
      <td>0.293099</td>
      <td>0.272160</td>
      <td>1.357356</td>
      <td>0.285759</td>
      <td>-1.581568</td>
      <td>0.362202</td>
      <td>0.196314</td>
      <td>-0.271048</td>
      <td>-0.475583</td>
      <td>-0.169510</td>
      <td>0.041110</td>
      <td>-1.013500</td>
      <td>-0.861528</td>
      <td>-0.196994</td>
      <td>0.191702</td>
      <td>0.734526</td>
      <td>-0.110111</td>
      <td>0.855074</td>
      <td>0.808856</td>
      <td>-0.455010</td>
      <td>-0.500330</td>
      <td>-0.065280</td>
      <td>-0.451159</td>
      <td>-0.412568</td>
      <td>-0.479006</td>
      <td>-0.633765</td>
      <td>0.199594</td>
      <td>0.609351</td>
      <td>0.094041</td>
      <td>-1.166241</td>
      <td>0.866384</td>
      <td>0.399259</td>
      <td>...</td>
      <td>-0.708215</td>
      <td>0.417557</td>
      <td>0.903287</td>
      <td>1.225253</td>
      <td>-0.017905</td>
      <td>-0.423460</td>
      <td>0.754508</td>
      <td>-0.553882</td>
      <td>-0.364447</td>
      <td>0.499383</td>
      <td>-0.393822</td>
      <td>0.522726</td>
      <td>0.075546</td>
      <td>-1.180171</td>
      <td>0.902681</td>
      <td>-0.227115</td>
      <td>1.694746</td>
      <td>0.200274</td>
      <td>1.075614</td>
      <td>-0.208554</td>
      <td>-0.637798</td>
      <td>0.123422</td>
      <td>0.046722</td>
      <td>-0.119171</td>
      <td>0.158308</td>
      <td>-0.859704</td>
      <td>-0.823259</td>
      <td>-0.352654</td>
      <td>-0.455303</td>
      <td>0.643928</td>
      <td>-0.033754</td>
      <td>0.117093</td>
      <td>-0.626081</td>
      <td>-0.606389</td>
      <td>0.455558</td>
      <td>0.761348</td>
      <td>0.336844</td>
      <td>-2.376278</td>
      <td>-1.125997</td>
      <td>-0.847023</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.668138</td>
      <td>-1.493549</td>
      <td>-0.373468</td>
      <td>-0.021903</td>
      <td>-0.998310</td>
      <td>0.162373</td>
      <td>0.714299</td>
      <td>-0.658918</td>
      <td>0.604658</td>
      <td>0.071447</td>
      <td>1.379249</td>
      <td>-0.298349</td>
      <td>-0.715117</td>
      <td>0.436024</td>
      <td>0.326331</td>
      <td>0.227909</td>
      <td>1.129977</td>
      <td>-0.067222</td>
      <td>-1.129085</td>
      <td>-1.688178</td>
      <td>-0.854319</td>
      <td>-0.120520</td>
      <td>0.649343</td>
      <td>0.969946</td>
      <td>0.544080</td>
      <td>0.130238</td>
      <td>-0.007205</td>
      <td>-0.378740</td>
      <td>-0.011083</td>
      <td>0.362990</td>
      <td>-0.665560</td>
      <td>0.713317</td>
      <td>-0.861770</td>
      <td>-0.561779</td>
      <td>0.165694</td>
      <td>-0.070664</td>
      <td>-0.490408</td>
      <td>-0.310989</td>
      <td>-0.855027</td>
      <td>-0.728056</td>
      <td>...</td>
      <td>-0.097029</td>
      <td>-0.735209</td>
      <td>-0.185334</td>
      <td>-0.531714</td>
      <td>0.507203</td>
      <td>0.077715</td>
      <td>0.181726</td>
      <td>-1.335699</td>
      <td>-0.468901</td>
      <td>-0.310579</td>
      <td>-0.128782</td>
      <td>-0.252110</td>
      <td>-0.463871</td>
      <td>0.584861</td>
      <td>-0.483916</td>
      <td>-0.969844</td>
      <td>-0.097098</td>
      <td>-0.620164</td>
      <td>0.948247</td>
      <td>0.086875</td>
      <td>0.111947</td>
      <td>0.068408</td>
      <td>-1.075477</td>
      <td>-0.415078</td>
      <td>-0.262200</td>
      <td>0.917406</td>
      <td>0.113798</td>
      <td>-1.264923</td>
      <td>-0.509866</td>
      <td>-0.327906</td>
      <td>-0.283688</td>
      <td>1.004375</td>
      <td>0.379471</td>
      <td>0.153045</td>
      <td>-0.040850</td>
      <td>0.778720</td>
      <td>-0.130537</td>
      <td>-1.375067</td>
      <td>-1.819059</td>
      <td>-1.574617</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.010415</td>
      <td>-0.912494</td>
      <td>-0.015781</td>
      <td>0.065923</td>
      <td>-0.287276</td>
      <td>-0.368047</td>
      <td>0.556718</td>
      <td>-0.805262</td>
      <td>0.267096</td>
      <td>-0.293437</td>
      <td>0.488232</td>
      <td>-0.218039</td>
      <td>0.584750</td>
      <td>0.471971</td>
      <td>0.207332</td>
      <td>0.108457</td>
      <td>0.803958</td>
      <td>-0.679873</td>
      <td>0.219173</td>
      <td>-0.720917</td>
      <td>-0.298091</td>
      <td>0.077099</td>
      <td>0.412648</td>
      <td>1.304166</td>
      <td>0.625642</td>
      <td>0.411928</td>
      <td>0.426967</td>
      <td>-0.551463</td>
      <td>0.594921</td>
      <td>-0.120802</td>
      <td>-0.762256</td>
      <td>0.635271</td>
      <td>0.328334</td>
      <td>-0.312397</td>
      <td>-0.193702</td>
      <td>0.483213</td>
      <td>-0.033137</td>
      <td>-0.333638</td>
      <td>-0.594414</td>
      <td>-0.239970</td>
      <td>...</td>
      <td>-0.106477</td>
      <td>-0.740296</td>
      <td>-0.862088</td>
      <td>-0.563635</td>
      <td>0.153592</td>
      <td>-0.428453</td>
      <td>0.399943</td>
      <td>1.032022</td>
      <td>1.003786</td>
      <td>0.217509</td>
      <td>0.967317</td>
      <td>0.393271</td>
      <td>-0.075910</td>
      <td>-0.076849</td>
      <td>0.600466</td>
      <td>-0.620423</td>
      <td>0.664615</td>
      <td>-0.693724</td>
      <td>1.165831</td>
      <td>-0.300670</td>
      <td>0.249269</td>
      <td>0.616222</td>
      <td>0.325852</td>
      <td>-0.634637</td>
      <td>-0.220486</td>
      <td>-0.521068</td>
      <td>0.045839</td>
      <td>-0.724933</td>
      <td>-0.259069</td>
      <td>-0.325358</td>
      <td>-0.914925</td>
      <td>-0.894883</td>
      <td>0.039171</td>
      <td>0.279537</td>
      <td>0.614561</td>
      <td>0.760101</td>
      <td>0.519081</td>
      <td>-1.153859</td>
      <td>-1.071690</td>
      <td>-0.134161</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-0.126100</td>
      <td>0.399416</td>
      <td>0.066066</td>
      <td>0.261713</td>
      <td>-0.272494</td>
      <td>0.295932</td>
      <td>0.626090</td>
      <td>-1.361278</td>
      <td>-0.018847</td>
      <td>0.781882</td>
      <td>0.373081</td>
      <td>0.169668</td>
      <td>-0.467749</td>
      <td>-0.140703</td>
      <td>-0.440066</td>
      <td>-0.933696</td>
      <td>0.052416</td>
      <td>0.095905</td>
      <td>0.016657</td>
      <td>-0.660538</td>
      <td>-0.204939</td>
      <td>-0.863176</td>
      <td>0.081868</td>
      <td>-0.106000</td>
      <td>0.480181</td>
      <td>0.550605</td>
      <td>0.296590</td>
      <td>-0.125422</td>
      <td>0.917715</td>
      <td>0.479517</td>
      <td>-0.164987</td>
      <td>-0.807156</td>
      <td>-0.747340</td>
      <td>-1.474389</td>
      <td>0.619388</td>
      <td>0.134091</td>
      <td>0.503317</td>
      <td>-0.279520</td>
      <td>-0.171447</td>
      <td>-0.075726</td>
      <td>...</td>
      <td>-0.099151</td>
      <td>1.164594</td>
      <td>0.682344</td>
      <td>0.981030</td>
      <td>0.678336</td>
      <td>-0.054978</td>
      <td>0.422270</td>
      <td>0.428602</td>
      <td>-0.453729</td>
      <td>0.368677</td>
      <td>0.099383</td>
      <td>-0.241229</td>
      <td>-0.191318</td>
      <td>0.552296</td>
      <td>0.410053</td>
      <td>-0.903802</td>
      <td>0.423468</td>
      <td>-0.233188</td>
      <td>0.593375</td>
      <td>-0.398226</td>
      <td>-0.004912</td>
      <td>0.186619</td>
      <td>0.226707</td>
      <td>-0.366024</td>
      <td>-0.399669</td>
      <td>-0.220994</td>
      <td>-0.461056</td>
      <td>0.202003</td>
      <td>0.365454</td>
      <td>1.320555</td>
      <td>0.343355</td>
      <td>-0.128216</td>
      <td>0.299678</td>
      <td>0.662152</td>
      <td>-1.071314</td>
      <td>-0.668398</td>
      <td>0.534401</td>
      <td>0.301071</td>
      <td>0.501900</td>
      <td>0.010667</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.501794</td>
      <td>-0.271400</td>
      <td>-0.380383</td>
      <td>0.871454</td>
      <td>-0.271942</td>
      <td>0.492729</td>
      <td>0.770441</td>
      <td>-0.989075</td>
      <td>0.063521</td>
      <td>0.813844</td>
      <td>1.132583</td>
      <td>0.853306</td>
      <td>0.053783</td>
      <td>-0.107161</td>
      <td>0.450556</td>
      <td>-0.116267</td>
      <td>-0.613700</td>
      <td>0.074530</td>
      <td>0.050893</td>
      <td>-0.147922</td>
      <td>0.670975</td>
      <td>0.367933</td>
      <td>0.804035</td>
      <td>1.758209</td>
      <td>0.546137</td>
      <td>0.062421</td>
      <td>0.214086</td>
      <td>0.969984</td>
      <td>0.697405</td>
      <td>0.116795</td>
      <td>-0.244930</td>
      <td>0.599216</td>
      <td>0.337681</td>
      <td>-0.432926</td>
      <td>-0.908715</td>
      <td>-0.306372</td>
      <td>0.645054</td>
      <td>0.457940</td>
      <td>0.399348</td>
      <td>0.244306</td>
      <td>...</td>
      <td>-0.579462</td>
      <td>0.206312</td>
      <td>0.419968</td>
      <td>-0.458735</td>
      <td>-0.223930</td>
      <td>0.434933</td>
      <td>1.170453</td>
      <td>-0.795144</td>
      <td>-0.139160</td>
      <td>-0.417290</td>
      <td>-1.272733</td>
      <td>-0.836944</td>
      <td>-0.894092</td>
      <td>0.936448</td>
      <td>0.877284</td>
      <td>0.575514</td>
      <td>1.981535</td>
      <td>-0.160312</td>
      <td>1.092556</td>
      <td>-0.313000</td>
      <td>1.126639</td>
      <td>0.939668</td>
      <td>-0.882505</td>
      <td>-0.557754</td>
      <td>-0.359650</td>
      <td>0.197526</td>
      <td>0.178410</td>
      <td>-0.132791</td>
      <td>-0.134191</td>
      <td>-0.259879</td>
      <td>0.162860</td>
      <td>-0.382432</td>
      <td>-0.487254</td>
      <td>-0.509314</td>
      <td>-0.059977</td>
      <td>0.238312</td>
      <td>-0.108925</td>
      <td>0.063512</td>
      <td>-0.165646</td>
      <td>-0.762333</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-1.212428</td>
      <td>-1.241198</td>
      <td>-0.618015</td>
      <td>0.891929</td>
      <td>-0.291175</td>
      <td>1.023901</td>
      <td>0.124949</td>
      <td>-0.376461</td>
      <td>1.485805</td>
      <td>-0.554966</td>
      <td>0.812944</td>
      <td>0.404132</td>
      <td>-1.007036</td>
      <td>0.297084</td>
      <td>0.043514</td>
      <td>0.031376</td>
      <td>-0.105180</td>
      <td>-0.863135</td>
      <td>-0.564480</td>
      <td>-0.150134</td>
      <td>0.116033</td>
      <td>-0.722297</td>
      <td>0.608597</td>
      <td>0.073406</td>
      <td>0.630795</td>
      <td>0.410819</td>
      <td>0.184773</td>
      <td>0.684078</td>
      <td>0.868516</td>
      <td>-0.032422</td>
      <td>-0.514844</td>
      <td>0.086592</td>
      <td>-0.829035</td>
      <td>-0.272785</td>
      <td>-0.184887</td>
      <td>1.095057</td>
      <td>0.419125</td>
      <td>0.389886</td>
      <td>0.189197</td>
      <td>-0.453914</td>
      <td>...</td>
      <td>-0.683062</td>
      <td>-0.711387</td>
      <td>-0.742212</td>
      <td>0.213027</td>
      <td>0.255449</td>
      <td>0.531124</td>
      <td>-0.533268</td>
      <td>-0.497598</td>
      <td>-0.127769</td>
      <td>-0.313015</td>
      <td>-0.178336</td>
      <td>-0.268774</td>
      <td>-0.953442</td>
      <td>-0.779394</td>
      <td>0.086005</td>
      <td>-0.288435</td>
      <td>-0.078734</td>
      <td>-1.353950</td>
      <td>-0.427032</td>
      <td>-0.180388</td>
      <td>0.368980</td>
      <td>1.007419</td>
      <td>-0.090032</td>
      <td>-1.123517</td>
      <td>-0.009362</td>
      <td>-0.317999</td>
      <td>-1.355971</td>
      <td>-1.182920</td>
      <td>0.122212</td>
      <td>1.156648</td>
      <td>0.275292</td>
      <td>0.462565</td>
      <td>0.530270</td>
      <td>-0.762192</td>
      <td>0.015948</td>
      <td>0.899082</td>
      <td>0.259217</td>
      <td>-3.485031</td>
      <td>-2.107335</td>
      <td>-0.775753</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-0.175423</td>
      <td>-0.406100</td>
      <td>-0.245851</td>
      <td>-0.439892</td>
      <td>-0.469180</td>
      <td>0.143899</td>
      <td>0.569232</td>
      <td>0.231812</td>
      <td>0.345384</td>
      <td>-0.240475</td>
      <td>0.098704</td>
      <td>-0.758932</td>
      <td>0.318475</td>
      <td>0.671685</td>
      <td>-0.292369</td>
      <td>0.021741</td>
      <td>-0.171468</td>
      <td>0.114946</td>
      <td>-0.445867</td>
      <td>0.059414</td>
      <td>-0.805393</td>
      <td>-0.500382</td>
      <td>0.285581</td>
      <td>0.340715</td>
      <td>0.448257</td>
      <td>0.082602</td>
      <td>-0.958901</td>
      <td>-1.050289</td>
      <td>-0.141783</td>
      <td>-0.559525</td>
      <td>0.222043</td>
      <td>-0.626956</td>
      <td>-0.334582</td>
      <td>0.365761</td>
      <td>-0.242297</td>
      <td>-0.588048</td>
      <td>0.507127</td>
      <td>-0.502009</td>
      <td>-0.648333</td>
      <td>-0.071111</td>
      <td>...</td>
      <td>-0.493700</td>
      <td>-0.329140</td>
      <td>-0.587545</td>
      <td>0.261379</td>
      <td>0.007420</td>
      <td>0.441735</td>
      <td>0.443921</td>
      <td>-0.015229</td>
      <td>-0.426362</td>
      <td>0.123026</td>
      <td>0.255592</td>
      <td>-0.365371</td>
      <td>-0.087290</td>
      <td>-0.224231</td>
      <td>0.230701</td>
      <td>-0.114346</td>
      <td>0.316518</td>
      <td>-0.190346</td>
      <td>0.347719</td>
      <td>-0.192013</td>
      <td>0.383869</td>
      <td>0.576655</td>
      <td>-0.395065</td>
      <td>-0.840509</td>
      <td>-1.324535</td>
      <td>0.290919</td>
      <td>1.553576</td>
      <td>-0.962657</td>
      <td>-0.287286</td>
      <td>-0.142259</td>
      <td>-0.382595</td>
      <td>-0.411708</td>
      <td>0.294217</td>
      <td>-0.319383</td>
      <td>0.327423</td>
      <td>0.455466</td>
      <td>0.158808</td>
      <td>-2.024561</td>
      <td>-1.164461</td>
      <td>-0.370567</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.217455</td>
      <td>-1.721213</td>
      <td>0.404476</td>
      <td>-0.028688</td>
      <td>-0.488024</td>
      <td>-1.380526</td>
      <td>-0.299687</td>
      <td>-0.140178</td>
      <td>0.476971</td>
      <td>1.001818</td>
      <td>1.656568</td>
      <td>0.659558</td>
      <td>0.068135</td>
      <td>0.581150</td>
      <td>0.606964</td>
      <td>0.356781</td>
      <td>0.005515</td>
      <td>-0.746514</td>
      <td>-0.881032</td>
      <td>0.065416</td>
      <td>-0.095840</td>
      <td>-1.106054</td>
      <td>0.230541</td>
      <td>1.204107</td>
      <td>0.856385</td>
      <td>0.267885</td>
      <td>-0.063970</td>
      <td>0.940100</td>
      <td>0.719738</td>
      <td>-0.794051</td>
      <td>0.877889</td>
      <td>0.213281</td>
      <td>0.188368</td>
      <td>-0.080852</td>
      <td>-0.354390</td>
      <td>-0.080352</td>
      <td>-0.416622</td>
      <td>-0.162290</td>
      <td>0.227439</td>
      <td>-0.066623</td>
      <td>...</td>
      <td>-0.812197</td>
      <td>-0.263237</td>
      <td>0.766176</td>
      <td>-0.444747</td>
      <td>-0.051388</td>
      <td>-0.134423</td>
      <td>0.531530</td>
      <td>-0.101936</td>
      <td>0.234575</td>
      <td>0.234892</td>
      <td>0.434726</td>
      <td>-0.277432</td>
      <td>0.134398</td>
      <td>-0.493240</td>
      <td>0.108826</td>
      <td>-1.236814</td>
      <td>0.299999</td>
      <td>-0.885236</td>
      <td>0.923156</td>
      <td>-0.041324</td>
      <td>-0.060149</td>
      <td>-0.071793</td>
      <td>0.089830</td>
      <td>-0.196777</td>
      <td>-0.354092</td>
      <td>0.297959</td>
      <td>-0.184428</td>
      <td>-0.943747</td>
      <td>-0.008469</td>
      <td>0.220909</td>
      <td>-0.406750</td>
      <td>-0.427802</td>
      <td>-0.057614</td>
      <td>0.777731</td>
      <td>1.059056</td>
      <td>1.134404</td>
      <td>0.532071</td>
      <td>-1.350291</td>
      <td>-0.887275</td>
      <td>-0.413235</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.204705</td>
      <td>-0.472588</td>
      <td>-0.136102</td>
      <td>0.173867</td>
      <td>-0.876212</td>
      <td>0.019908</td>
      <td>0.183088</td>
      <td>-0.814437</td>
      <td>0.165636</td>
      <td>0.597581</td>
      <td>1.066897</td>
      <td>0.511245</td>
      <td>-0.401603</td>
      <td>-0.089211</td>
      <td>0.041480</td>
      <td>-0.613204</td>
      <td>0.479548</td>
      <td>0.262573</td>
      <td>0.198677</td>
      <td>-0.840089</td>
      <td>-0.776673</td>
      <td>-0.403586</td>
      <td>0.211894</td>
      <td>0.959831</td>
      <td>0.636966</td>
      <td>-0.792905</td>
      <td>0.396385</td>
      <td>0.639697</td>
      <td>1.066931</td>
      <td>0.406437</td>
      <td>0.277499</td>
      <td>-1.565324</td>
      <td>-1.229443</td>
      <td>-0.313181</td>
      <td>0.009467</td>
      <td>0.460971</td>
      <td>0.113884</td>
      <td>1.130072</td>
      <td>0.133364</td>
      <td>-0.570300</td>
      <td>...</td>
      <td>-0.903770</td>
      <td>0.993684</td>
      <td>0.066212</td>
      <td>-0.085643</td>
      <td>0.054640</td>
      <td>0.119233</td>
      <td>0.797640</td>
      <td>0.580457</td>
      <td>0.604001</td>
      <td>-0.773914</td>
      <td>-0.409380</td>
      <td>0.372505</td>
      <td>-0.520993</td>
      <td>0.198579</td>
      <td>0.539578</td>
      <td>-0.275956</td>
      <td>0.094011</td>
      <td>0.139212</td>
      <td>0.054835</td>
      <td>-0.136745</td>
      <td>-0.317058</td>
      <td>0.424672</td>
      <td>0.252046</td>
      <td>0.781653</td>
      <td>-0.269990</td>
      <td>0.224178</td>
      <td>-0.315562</td>
      <td>-0.122522</td>
      <td>-0.398565</td>
      <td>0.355431</td>
      <td>-1.056518</td>
      <td>0.775276</td>
      <td>0.279651</td>
      <td>0.663985</td>
      <td>0.762992</td>
      <td>1.020454</td>
      <td>0.711808</td>
      <td>0.146704</td>
      <td>0.209209</td>
      <td>-0.347004</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.364395</td>
      <td>0.078396</td>
      <td>0.475564</td>
      <td>0.140305</td>
      <td>-0.600780</td>
      <td>-0.238436</td>
      <td>-0.791165</td>
      <td>-0.446730</td>
      <td>0.213569</td>
      <td>-0.113095</td>
      <td>0.867140</td>
      <td>-0.923253</td>
      <td>-0.077236</td>
      <td>0.906059</td>
      <td>0.824818</td>
      <td>0.932207</td>
      <td>0.150613</td>
      <td>-0.773692</td>
      <td>0.581837</td>
      <td>0.459403</td>
      <td>-0.113098</td>
      <td>0.677925</td>
      <td>-0.513244</td>
      <td>-0.686402</td>
      <td>0.107301</td>
      <td>-0.238165</td>
      <td>0.268007</td>
      <td>-0.494260</td>
      <td>-0.285247</td>
      <td>0.471340</td>
      <td>-1.360839</td>
      <td>-0.445920</td>
      <td>0.061290</td>
      <td>-0.350583</td>
      <td>-0.800895</td>
      <td>-0.790258</td>
      <td>-0.437393</td>
      <td>-0.109426</td>
      <td>0.139318</td>
      <td>0.269410</td>
      <td>...</td>
      <td>0.214194</td>
      <td>-0.365592</td>
      <td>-0.414229</td>
      <td>0.777692</td>
      <td>-0.266692</td>
      <td>-0.829291</td>
      <td>0.664623</td>
      <td>-0.325704</td>
      <td>-1.005772</td>
      <td>-0.459584</td>
      <td>-1.112668</td>
      <td>-0.467116</td>
      <td>-0.856860</td>
      <td>-0.809736</td>
      <td>0.630832</td>
      <td>-0.896023</td>
      <td>-0.219786</td>
      <td>-0.547294</td>
      <td>0.007151</td>
      <td>-0.800317</td>
      <td>0.315965</td>
      <td>-0.172663</td>
      <td>0.666420</td>
      <td>0.033810</td>
      <td>-0.646206</td>
      <td>0.371520</td>
      <td>0.271098</td>
      <td>0.208139</td>
      <td>0.030983</td>
      <td>0.067393</td>
      <td>-0.022061</td>
      <td>0.483381</td>
      <td>-0.337955</td>
      <td>0.327006</td>
      <td>-0.573938</td>
      <td>1.495704</td>
      <td>-0.435545</td>
      <td>-1.304932</td>
      <td>-0.750475</td>
      <td>-0.316648</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.330298</td>
      <td>-0.321123</td>
      <td>-0.704451</td>
      <td>-0.359543</td>
      <td>-1.064601</td>
      <td>-0.286727</td>
      <td>0.261795</td>
      <td>0.315513</td>
      <td>1.164133</td>
      <td>0.402078</td>
      <td>1.805448</td>
      <td>-0.352984</td>
      <td>-0.565469</td>
      <td>1.193884</td>
      <td>1.153954</td>
      <td>-0.550146</td>
      <td>0.052165</td>
      <td>0.835501</td>
      <td>0.968370</td>
      <td>0.171119</td>
      <td>0.159870</td>
      <td>0.323718</td>
      <td>-0.044278</td>
      <td>0.200461</td>
      <td>-0.207655</td>
      <td>-0.011400</td>
      <td>-0.117874</td>
      <td>1.236518</td>
      <td>-0.155379</td>
      <td>-0.552013</td>
      <td>-0.011825</td>
      <td>0.628899</td>
      <td>-0.772634</td>
      <td>-0.649422</td>
      <td>-0.581780</td>
      <td>-0.103457</td>
      <td>0.320861</td>
      <td>-1.504621</td>
      <td>-0.677126</td>
      <td>0.000368</td>
      <td>...</td>
      <td>-0.046180</td>
      <td>-0.426216</td>
      <td>-0.595116</td>
      <td>-0.286991</td>
      <td>-0.485731</td>
      <td>0.657634</td>
      <td>1.537450</td>
      <td>0.341875</td>
      <td>-0.132577</td>
      <td>-0.047124</td>
      <td>0.139462</td>
      <td>-0.412388</td>
      <td>0.000949</td>
      <td>-0.656979</td>
      <td>0.354766</td>
      <td>-0.746699</td>
      <td>-0.007613</td>
      <td>-1.033587</td>
      <td>-0.408004</td>
      <td>0.175314</td>
      <td>0.447893</td>
      <td>-0.878701</td>
      <td>-0.003577</td>
      <td>-0.258313</td>
      <td>0.371524</td>
      <td>0.022063</td>
      <td>0.242342</td>
      <td>-0.575879</td>
      <td>-0.381983</td>
      <td>0.999069</td>
      <td>0.633691</td>
      <td>0.641633</td>
      <td>-1.198010</td>
      <td>-0.479663</td>
      <td>0.901287</td>
      <td>-0.589764</td>
      <td>-0.243013</td>
      <td>2.138309</td>
      <td>0.814652</td>
      <td>0.857440</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.267872</td>
      <td>-0.636053</td>
      <td>-0.106199</td>
      <td>0.957660</td>
      <td>0.647112</td>
      <td>-0.450817</td>
      <td>-0.607482</td>
      <td>-0.756489</td>
      <td>-0.096292</td>
      <td>0.373716</td>
      <td>0.989728</td>
      <td>0.428302</td>
      <td>-0.400197</td>
      <td>-0.006816</td>
      <td>0.551535</td>
      <td>-0.290553</td>
      <td>-0.427423</td>
      <td>0.243099</td>
      <td>0.310053</td>
      <td>0.654529</td>
      <td>0.596882</td>
      <td>-0.535510</td>
      <td>0.958557</td>
      <td>1.253516</td>
      <td>0.176202</td>
      <td>-0.019548</td>
      <td>0.115298</td>
      <td>0.053594</td>
      <td>0.354508</td>
      <td>-0.461686</td>
      <td>0.388476</td>
      <td>-0.583851</td>
      <td>-0.313821</td>
      <td>-0.157964</td>
      <td>0.497307</td>
      <td>-0.342699</td>
      <td>-0.237140</td>
      <td>-0.147412</td>
      <td>-1.060462</td>
      <td>-0.159786</td>
      <td>...</td>
      <td>0.181619</td>
      <td>0.527801</td>
      <td>-0.087414</td>
      <td>-0.532873</td>
      <td>-0.165521</td>
      <td>-0.108374</td>
      <td>0.952909</td>
      <td>-0.372464</td>
      <td>-1.025256</td>
      <td>-0.705814</td>
      <td>0.280398</td>
      <td>0.204323</td>
      <td>0.506385</td>
      <td>-0.134163</td>
      <td>-0.424064</td>
      <td>-0.779799</td>
      <td>0.066345</td>
      <td>0.052964</td>
      <td>-0.068277</td>
      <td>-0.338109</td>
      <td>0.023771</td>
      <td>0.583018</td>
      <td>0.410434</td>
      <td>0.263312</td>
      <td>0.415226</td>
      <td>-0.232488</td>
      <td>-0.110821</td>
      <td>-0.957758</td>
      <td>-0.203110</td>
      <td>-0.288029</td>
      <td>-0.737279</td>
      <td>0.587460</td>
      <td>0.396426</td>
      <td>0.002570</td>
      <td>-0.655503</td>
      <td>-0.292825</td>
      <td>-0.839407</td>
      <td>0.209328</td>
      <td>-0.349567</td>
      <td>-1.263647</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.343664</td>
      <td>-1.139152</td>
      <td>-0.242410</td>
      <td>-0.565064</td>
      <td>-0.869165</td>
      <td>0.401610</td>
      <td>0.123104</td>
      <td>-0.287070</td>
      <td>0.243686</td>
      <td>-0.110790</td>
      <td>0.755370</td>
      <td>0.477098</td>
      <td>-0.437335</td>
      <td>-0.234448</td>
      <td>0.485500</td>
      <td>-0.043305</td>
      <td>0.600788</td>
      <td>-0.212100</td>
      <td>-0.728474</td>
      <td>-0.132162</td>
      <td>-0.731257</td>
      <td>-0.761667</td>
      <td>0.091913</td>
      <td>0.292362</td>
      <td>0.533496</td>
      <td>0.401443</td>
      <td>0.612145</td>
      <td>-0.105475</td>
      <td>0.248672</td>
      <td>0.718152</td>
      <td>-0.428893</td>
      <td>0.249869</td>
      <td>-0.281139</td>
      <td>-0.628411</td>
      <td>-0.777477</td>
      <td>-0.349628</td>
      <td>-0.974872</td>
      <td>0.188248</td>
      <td>-0.839936</td>
      <td>-0.572432</td>
      <td>...</td>
      <td>0.341732</td>
      <td>-0.376636</td>
      <td>0.819941</td>
      <td>0.026305</td>
      <td>0.005155</td>
      <td>0.066152</td>
      <td>1.400535</td>
      <td>0.040833</td>
      <td>0.282390</td>
      <td>0.964633</td>
      <td>0.721797</td>
      <td>0.501462</td>
      <td>-0.027743</td>
      <td>-0.902430</td>
      <td>1.474224</td>
      <td>0.273942</td>
      <td>-0.030646</td>
      <td>0.355737</td>
      <td>-0.492644</td>
      <td>-0.463360</td>
      <td>0.436574</td>
      <td>0.651699</td>
      <td>0.192263</td>
      <td>0.102904</td>
      <td>0.342492</td>
      <td>0.444436</td>
      <td>0.843309</td>
      <td>0.789214</td>
      <td>0.920808</td>
      <td>-0.085873</td>
      <td>0.309966</td>
      <td>0.095994</td>
      <td>-0.928999</td>
      <td>-0.515388</td>
      <td>0.244908</td>
      <td>0.317320</td>
      <td>0.548062</td>
      <td>-0.663234</td>
      <td>-1.010330</td>
      <td>-0.966938</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-1.097208</td>
      <td>-0.275098</td>
      <td>-0.343728</td>
      <td>-0.944224</td>
      <td>-1.549213</td>
      <td>-0.885769</td>
      <td>-0.857161</td>
      <td>-2.144110</td>
      <td>1.052241</td>
      <td>0.675084</td>
      <td>0.916113</td>
      <td>-1.311760</td>
      <td>-0.258713</td>
      <td>0.416343</td>
      <td>-0.006207</td>
      <td>1.056215</td>
      <td>1.008050</td>
      <td>-1.093471</td>
      <td>0.249497</td>
      <td>-0.407639</td>
      <td>0.115732</td>
      <td>0.348756</td>
      <td>0.135273</td>
      <td>0.690367</td>
      <td>-0.002081</td>
      <td>-0.175348</td>
      <td>-0.871324</td>
      <td>0.013409</td>
      <td>-0.173670</td>
      <td>-0.280629</td>
      <td>0.383345</td>
      <td>0.595010</td>
      <td>-0.606564</td>
      <td>-0.675527</td>
      <td>-0.624449</td>
      <td>0.036506</td>
      <td>0.343979</td>
      <td>-0.560772</td>
      <td>-1.185699</td>
      <td>-0.329013</td>
      <td>...</td>
      <td>-1.270704</td>
      <td>-1.856430</td>
      <td>-0.794368</td>
      <td>-0.274641</td>
      <td>-0.415767</td>
      <td>-0.162418</td>
      <td>0.107556</td>
      <td>-1.153821</td>
      <td>-0.181703</td>
      <td>-1.033154</td>
      <td>-1.148482</td>
      <td>0.316156</td>
      <td>-0.442364</td>
      <td>-0.493533</td>
      <td>1.116460</td>
      <td>0.261650</td>
      <td>0.945896</td>
      <td>-0.272977</td>
      <td>0.717108</td>
      <td>0.076336</td>
      <td>1.146858</td>
      <td>0.455592</td>
      <td>-0.245049</td>
      <td>-0.428927</td>
      <td>0.007726</td>
      <td>0.487437</td>
      <td>-0.012086</td>
      <td>-0.540129</td>
      <td>-0.262475</td>
      <td>0.328991</td>
      <td>-0.530098</td>
      <td>0.988190</td>
      <td>0.495199</td>
      <td>0.709747</td>
      <td>-0.017188</td>
      <td>-0.702946</td>
      <td>-0.049930</td>
      <td>-2.937006</td>
      <td>-2.036546</td>
      <td>-0.632807</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.051489</td>
      <td>-0.079675</td>
      <td>0.938235</td>
      <td>1.313524</td>
      <td>-0.883189</td>
      <td>0.108941</td>
      <td>0.895399</td>
      <td>-0.463687</td>
      <td>0.719124</td>
      <td>-0.507006</td>
      <td>-0.169386</td>
      <td>0.109453</td>
      <td>0.042079</td>
      <td>0.226662</td>
      <td>-0.392693</td>
      <td>0.292111</td>
      <td>-0.293365</td>
      <td>-0.880359</td>
      <td>-0.349944</td>
      <td>0.041089</td>
      <td>-0.194880</td>
      <td>0.402258</td>
      <td>0.239854</td>
      <td>1.244440</td>
      <td>0.409082</td>
      <td>-0.165446</td>
      <td>0.733358</td>
      <td>0.162190</td>
      <td>0.587464</td>
      <td>0.143224</td>
      <td>-0.046384</td>
      <td>-0.483071</td>
      <td>-0.624833</td>
      <td>0.623017</td>
      <td>-0.075320</td>
      <td>0.683090</td>
      <td>0.567239</td>
      <td>-0.609551</td>
      <td>-0.019881</td>
      <td>0.869519</td>
      <td>...</td>
      <td>0.558701</td>
      <td>0.830283</td>
      <td>-0.136041</td>
      <td>0.116365</td>
      <td>-0.218300</td>
      <td>0.312720</td>
      <td>-0.174943</td>
      <td>-0.614743</td>
      <td>0.510817</td>
      <td>0.262760</td>
      <td>0.543098</td>
      <td>1.072693</td>
      <td>-0.236702</td>
      <td>0.133377</td>
      <td>0.877984</td>
      <td>-0.677917</td>
      <td>-0.814605</td>
      <td>-0.721574</td>
      <td>0.276928</td>
      <td>0.136860</td>
      <td>0.385348</td>
      <td>-0.056818</td>
      <td>-0.640819</td>
      <td>-0.915081</td>
      <td>-0.751745</td>
      <td>-0.500915</td>
      <td>0.543747</td>
      <td>-0.521691</td>
      <td>-1.268331</td>
      <td>0.711107</td>
      <td>0.514219</td>
      <td>0.835069</td>
      <td>1.674075</td>
      <td>0.705411</td>
      <td>-0.313029</td>
      <td>0.679249</td>
      <td>-0.208146</td>
      <td>0.885845</td>
      <td>0.643597</td>
      <td>0.593786</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.000874</td>
      <td>-0.709565</td>
      <td>0.474035</td>
      <td>0.700846</td>
      <td>-0.992343</td>
      <td>-0.165794</td>
      <td>-1.056555</td>
      <td>0.001186</td>
      <td>-0.366777</td>
      <td>-0.165213</td>
      <td>1.320991</td>
      <td>0.226801</td>
      <td>-0.142980</td>
      <td>0.575457</td>
      <td>0.703146</td>
      <td>-0.244211</td>
      <td>-0.020435</td>
      <td>0.736607</td>
      <td>0.643259</td>
      <td>0.475688</td>
      <td>-0.756301</td>
      <td>-0.806097</td>
      <td>-0.648275</td>
      <td>0.587376</td>
      <td>0.660824</td>
      <td>0.784393</td>
      <td>-0.314088</td>
      <td>0.595389</td>
      <td>0.010439</td>
      <td>0.485099</td>
      <td>0.355455</td>
      <td>0.477997</td>
      <td>-0.128740</td>
      <td>-1.404709</td>
      <td>-0.255777</td>
      <td>1.028552</td>
      <td>0.934852</td>
      <td>-0.039625</td>
      <td>-1.567094</td>
      <td>0.165727</td>
      <td>...</td>
      <td>-0.124754</td>
      <td>0.546932</td>
      <td>0.307149</td>
      <td>0.018226</td>
      <td>-0.300598</td>
      <td>0.616074</td>
      <td>0.706147</td>
      <td>-0.199003</td>
      <td>-0.452776</td>
      <td>-0.180530</td>
      <td>0.017765</td>
      <td>0.519535</td>
      <td>-0.278591</td>
      <td>1.262434</td>
      <td>0.880444</td>
      <td>-0.484942</td>
      <td>0.362388</td>
      <td>-0.852630</td>
      <td>0.268111</td>
      <td>-0.231005</td>
      <td>-0.379103</td>
      <td>-0.327267</td>
      <td>-0.096287</td>
      <td>0.092361</td>
      <td>-0.181016</td>
      <td>0.692539</td>
      <td>1.049514</td>
      <td>0.363252</td>
      <td>-0.261463</td>
      <td>0.287833</td>
      <td>0.107210</td>
      <td>0.852349</td>
      <td>0.434051</td>
      <td>0.216142</td>
      <td>-0.777516</td>
      <td>0.181521</td>
      <td>-0.454617</td>
      <td>0.610405</td>
      <td>1.127496</td>
      <td>0.664366</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.812465</td>
      <td>-0.825756</td>
      <td>0.062768</td>
      <td>-0.375351</td>
      <td>-0.579107</td>
      <td>0.616862</td>
      <td>1.535464</td>
      <td>-0.316704</td>
      <td>-0.724204</td>
      <td>0.311392</td>
      <td>0.532496</td>
      <td>-0.151684</td>
      <td>0.174887</td>
      <td>0.081518</td>
      <td>0.836867</td>
      <td>0.892480</td>
      <td>0.677291</td>
      <td>-0.168163</td>
      <td>-0.077128</td>
      <td>0.682723</td>
      <td>-0.355588</td>
      <td>1.419474</td>
      <td>2.213825</td>
      <td>1.217084</td>
      <td>0.203716</td>
      <td>-0.543945</td>
      <td>-0.078651</td>
      <td>-0.865214</td>
      <td>0.288676</td>
      <td>-0.639875</td>
      <td>0.396517</td>
      <td>0.969339</td>
      <td>1.013250</td>
      <td>0.541115</td>
      <td>-0.055217</td>
      <td>-0.847863</td>
      <td>-0.178161</td>
      <td>0.512794</td>
      <td>-0.694498</td>
      <td>0.287586</td>
      <td>...</td>
      <td>-0.297047</td>
      <td>0.553130</td>
      <td>0.978008</td>
      <td>-0.059347</td>
      <td>-0.414244</td>
      <td>-0.993428</td>
      <td>0.605797</td>
      <td>0.719867</td>
      <td>-0.356738</td>
      <td>0.614771</td>
      <td>0.891369</td>
      <td>0.646876</td>
      <td>-0.301623</td>
      <td>0.944049</td>
      <td>0.754778</td>
      <td>0.278064</td>
      <td>0.810539</td>
      <td>-0.318892</td>
      <td>1.214077</td>
      <td>0.417731</td>
      <td>-0.003302</td>
      <td>0.717089</td>
      <td>-0.747649</td>
      <td>0.562080</td>
      <td>0.282853</td>
      <td>0.230849</td>
      <td>0.318603</td>
      <td>-0.727075</td>
      <td>-0.506945</td>
      <td>0.029415</td>
      <td>0.047778</td>
      <td>0.068031</td>
      <td>-0.403954</td>
      <td>-0.491062</td>
      <td>0.344125</td>
      <td>-0.288619</td>
      <td>0.580680</td>
      <td>-1.721228</td>
      <td>-0.483233</td>
      <td>-0.441715</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.011958</td>
      <td>-0.788493</td>
      <td>0.247651</td>
      <td>0.692571</td>
      <td>0.654754</td>
      <td>-0.390645</td>
      <td>0.071095</td>
      <td>-0.127530</td>
      <td>0.024208</td>
      <td>-0.540898</td>
      <td>0.378219</td>
      <td>-0.314801</td>
      <td>0.210737</td>
      <td>-0.080497</td>
      <td>0.117526</td>
      <td>-0.088816</td>
      <td>0.021990</td>
      <td>-0.271348</td>
      <td>0.164342</td>
      <td>-0.150917</td>
      <td>0.080111</td>
      <td>-0.497874</td>
      <td>1.220635</td>
      <td>0.733758</td>
      <td>0.113811</td>
      <td>-0.416015</td>
      <td>-0.533817</td>
      <td>-0.621259</td>
      <td>-0.039991</td>
      <td>0.077457</td>
      <td>-0.007402</td>
      <td>0.219608</td>
      <td>-0.808218</td>
      <td>-1.636413</td>
      <td>-0.492901</td>
      <td>-1.274776</td>
      <td>-0.380707</td>
      <td>-0.741319</td>
      <td>-0.040193</td>
      <td>0.395365</td>
      <td>...</td>
      <td>0.459677</td>
      <td>0.290090</td>
      <td>-0.608203</td>
      <td>0.042330</td>
      <td>0.721026</td>
      <td>-0.252253</td>
      <td>0.021655</td>
      <td>0.360869</td>
      <td>-0.241756</td>
      <td>0.008493</td>
      <td>-0.366707</td>
      <td>0.974566</td>
      <td>0.371239</td>
      <td>-0.113983</td>
      <td>-0.082653</td>
      <td>-0.227622</td>
      <td>-0.510550</td>
      <td>-1.478338</td>
      <td>-0.312603</td>
      <td>-0.779868</td>
      <td>-0.241752</td>
      <td>-0.520803</td>
      <td>0.005009</td>
      <td>0.494865</td>
      <td>0.319269</td>
      <td>0.038353</td>
      <td>0.382007</td>
      <td>0.477238</td>
      <td>-0.156488</td>
      <td>-0.195993</td>
      <td>-0.791301</td>
      <td>-0.546149</td>
      <td>-1.338093</td>
      <td>-1.193160</td>
      <td>-0.924273</td>
      <td>-0.007133</td>
      <td>-0.736047</td>
      <td>0.782370</td>
      <td>0.484539</td>
      <td>0.027738</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.683500</td>
      <td>-0.921521</td>
      <td>-0.682771</td>
      <td>-1.248844</td>
      <td>-1.160350</td>
      <td>-0.779169</td>
      <td>0.557499</td>
      <td>-0.658914</td>
      <td>-0.766003</td>
      <td>-1.154998</td>
      <td>-0.004321</td>
      <td>0.727720</td>
      <td>0.669902</td>
      <td>0.950196</td>
      <td>0.292102</td>
      <td>-0.783769</td>
      <td>-0.311439</td>
      <td>-0.569655</td>
      <td>-0.601808</td>
      <td>-0.767017</td>
      <td>-1.396559</td>
      <td>0.190422</td>
      <td>0.481994</td>
      <td>1.159931</td>
      <td>0.175992</td>
      <td>-0.423880</td>
      <td>-0.671117</td>
      <td>0.002392</td>
      <td>0.127839</td>
      <td>0.361594</td>
      <td>0.287754</td>
      <td>-0.040957</td>
      <td>0.395618</td>
      <td>-1.388118</td>
      <td>-1.171955</td>
      <td>0.337375</td>
      <td>-0.612339</td>
      <td>0.354151</td>
      <td>-0.276849</td>
      <td>0.281135</td>
      <td>...</td>
      <td>0.411861</td>
      <td>-0.272554</td>
      <td>-0.332471</td>
      <td>0.612673</td>
      <td>0.608740</td>
      <td>0.459338</td>
      <td>-0.700532</td>
      <td>-0.779599</td>
      <td>-0.036809</td>
      <td>-0.746297</td>
      <td>0.430501</td>
      <td>-0.114198</td>
      <td>0.565897</td>
      <td>-0.206323</td>
      <td>0.256961</td>
      <td>-0.488635</td>
      <td>0.278364</td>
      <td>-0.882422</td>
      <td>-0.951597</td>
      <td>-0.219728</td>
      <td>0.367682</td>
      <td>-0.039073</td>
      <td>-0.580213</td>
      <td>-0.398848</td>
      <td>-0.303063</td>
      <td>0.834578</td>
      <td>0.771692</td>
      <td>-0.880125</td>
      <td>-0.516962</td>
      <td>0.000414</td>
      <td>-0.094900</td>
      <td>0.558486</td>
      <td>-0.157203</td>
      <td>-0.606874</td>
      <td>0.145322</td>
      <td>-0.167590</td>
      <td>-1.298540</td>
      <td>-0.858209</td>
      <td>-0.804555</td>
      <td>0.060882</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-1.002955</td>
      <td>-0.124282</td>
      <td>-0.069072</td>
      <td>0.608389</td>
      <td>-0.187814</td>
      <td>0.942804</td>
      <td>0.248601</td>
      <td>-1.054931</td>
      <td>0.458003</td>
      <td>0.252116</td>
      <td>1.918149</td>
      <td>0.735587</td>
      <td>1.153786</td>
      <td>0.205492</td>
      <td>-0.551261</td>
      <td>0.831717</td>
      <td>0.772630</td>
      <td>0.936474</td>
      <td>0.609152</td>
      <td>0.604572</td>
      <td>0.123789</td>
      <td>-0.013581</td>
      <td>-0.016417</td>
      <td>-0.145159</td>
      <td>0.348336</td>
      <td>-0.238107</td>
      <td>-0.093905</td>
      <td>-0.520745</td>
      <td>-0.047782</td>
      <td>-1.160082</td>
      <td>-0.358318</td>
      <td>-0.569293</td>
      <td>-0.355322</td>
      <td>0.455380</td>
      <td>-0.102904</td>
      <td>-0.380238</td>
      <td>-0.696539</td>
      <td>0.197995</td>
      <td>0.772734</td>
      <td>1.100638</td>
      <td>...</td>
      <td>0.198639</td>
      <td>1.081215</td>
      <td>-0.449791</td>
      <td>1.111217</td>
      <td>1.237150</td>
      <td>0.827296</td>
      <td>0.655462</td>
      <td>-1.068247</td>
      <td>-1.481887</td>
      <td>0.304010</td>
      <td>0.035657</td>
      <td>-0.832156</td>
      <td>-0.783760</td>
      <td>-0.339433</td>
      <td>0.751785</td>
      <td>-0.490945</td>
      <td>0.282414</td>
      <td>-0.134901</td>
      <td>-0.220858</td>
      <td>0.004044</td>
      <td>-0.477833</td>
      <td>-0.801570</td>
      <td>-0.551585</td>
      <td>-0.911878</td>
      <td>-0.019513</td>
      <td>0.802121</td>
      <td>0.359806</td>
      <td>0.056559</td>
      <td>0.194338</td>
      <td>0.486356</td>
      <td>-0.204595</td>
      <td>-0.280910</td>
      <td>0.118030</td>
      <td>0.621877</td>
      <td>-1.067356</td>
      <td>-0.373335</td>
      <td>0.193248</td>
      <td>-1.245431</td>
      <td>-0.744037</td>
      <td>-0.136298</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-1.085686</td>
      <td>-0.471261</td>
      <td>0.881256</td>
      <td>0.087293</td>
      <td>0.555506</td>
      <td>0.775153</td>
      <td>0.579646</td>
      <td>-0.222248</td>
      <td>0.478892</td>
      <td>-0.081404</td>
      <td>0.600656</td>
      <td>0.422141</td>
      <td>-0.733453</td>
      <td>0.069790</td>
      <td>-0.168200</td>
      <td>-1.318677</td>
      <td>0.135320</td>
      <td>0.072672</td>
      <td>0.379995</td>
      <td>-0.177578</td>
      <td>-0.666431</td>
      <td>0.172706</td>
      <td>0.923817</td>
      <td>0.437332</td>
      <td>0.090814</td>
      <td>-0.593813</td>
      <td>-0.231192</td>
      <td>-0.082123</td>
      <td>-0.060171</td>
      <td>0.556422</td>
      <td>0.768903</td>
      <td>0.262966</td>
      <td>1.304669</td>
      <td>-0.440402</td>
      <td>0.145186</td>
      <td>0.177514</td>
      <td>0.744486</td>
      <td>-0.623129</td>
      <td>-0.557526</td>
      <td>0.332557</td>
      <td>...</td>
      <td>-0.089446</td>
      <td>0.478039</td>
      <td>0.785641</td>
      <td>0.331191</td>
      <td>-0.432461</td>
      <td>0.069484</td>
      <td>0.982477</td>
      <td>-0.405865</td>
      <td>-0.158836</td>
      <td>-0.805933</td>
      <td>0.213452</td>
      <td>-0.436855</td>
      <td>-0.631747</td>
      <td>0.013226</td>
      <td>1.179377</td>
      <td>-0.794371</td>
      <td>-0.346826</td>
      <td>-0.141735</td>
      <td>0.124166</td>
      <td>0.284641</td>
      <td>-0.372794</td>
      <td>0.521697</td>
      <td>1.145654</td>
      <td>0.479180</td>
      <td>1.017168</td>
      <td>0.334129</td>
      <td>-0.208655</td>
      <td>-0.223968</td>
      <td>-1.291573</td>
      <td>0.112479</td>
      <td>-0.997874</td>
      <td>-0.424714</td>
      <td>-0.228524</td>
      <td>0.045058</td>
      <td>0.064415</td>
      <td>-0.129571</td>
      <td>0.299020</td>
      <td>-0.566808</td>
      <td>-0.064088</td>
      <td>-0.537085</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">1</th>
      <th>0</th>
      <td>0.000125</td>
      <td>-0.726483</td>
      <td>-0.895492</td>
      <td>0.080485</td>
      <td>0.624526</td>
      <td>0.394158</td>
      <td>-0.042838</td>
      <td>0.565624</td>
      <td>-0.011081</td>
      <td>-1.099303</td>
      <td>-0.479706</td>
      <td>-0.900355</td>
      <td>-0.013653</td>
      <td>-0.098976</td>
      <td>-0.224941</td>
      <td>-0.455219</td>
      <td>-0.758622</td>
      <td>-0.620741</td>
      <td>-0.564731</td>
      <td>-0.407038</td>
      <td>0.556896</td>
      <td>0.605399</td>
      <td>-0.288697</td>
      <td>0.549782</td>
      <td>-0.446407</td>
      <td>-0.390814</td>
      <td>-0.581817</td>
      <td>-1.573922</td>
      <td>-0.524390</td>
      <td>0.429924</td>
      <td>0.499304</td>
      <td>0.819742</td>
      <td>-0.586959</td>
      <td>-1.267629</td>
      <td>0.264485</td>
      <td>-0.187921</td>
      <td>0.640349</td>
      <td>-0.173976</td>
      <td>0.274543</td>
      <td>0.153185</td>
      <td>...</td>
      <td>0.277561</td>
      <td>-0.831506</td>
      <td>0.730610</td>
      <td>0.233568</td>
      <td>0.189235</td>
      <td>1.063274</td>
      <td>-0.636296</td>
      <td>-0.662711</td>
      <td>-0.016731</td>
      <td>0.274306</td>
      <td>-0.092780</td>
      <td>1.305091</td>
      <td>0.962264</td>
      <td>0.554978</td>
      <td>0.161791</td>
      <td>-0.182656</td>
      <td>0.231535</td>
      <td>-0.588666</td>
      <td>0.500544</td>
      <td>-0.629794</td>
      <td>-0.131533</td>
      <td>-0.783664</td>
      <td>-1.085124</td>
      <td>-0.252007</td>
      <td>0.896401</td>
      <td>-0.251424</td>
      <td>-0.149367</td>
      <td>-0.787341</td>
      <td>0.284779</td>
      <td>0.343106</td>
      <td>0.611922</td>
      <td>0.024073</td>
      <td>-0.189073</td>
      <td>0.559803</td>
      <td>0.346000</td>
      <td>-0.469243</td>
      <td>-0.708283</td>
      <td>-2.722419</td>
      <td>-2.353917</td>
      <td>-0.774582</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.535116</td>
      <td>-0.249625</td>
      <td>-0.265521</td>
      <td>-0.470161</td>
      <td>0.720580</td>
      <td>-1.096248</td>
      <td>-0.215553</td>
      <td>-0.470918</td>
      <td>-0.519016</td>
      <td>-0.967365</td>
      <td>-0.063375</td>
      <td>0.493644</td>
      <td>0.296710</td>
      <td>0.221478</td>
      <td>-0.791451</td>
      <td>-0.834351</td>
      <td>-1.688107</td>
      <td>-0.234478</td>
      <td>-0.537845</td>
      <td>0.348217</td>
      <td>0.211972</td>
      <td>-0.026199</td>
      <td>-0.419801</td>
      <td>-0.543124</td>
      <td>-0.323552</td>
      <td>0.596510</td>
      <td>0.387029</td>
      <td>-1.067341</td>
      <td>-0.092575</td>
      <td>-0.370124</td>
      <td>-0.079240</td>
      <td>0.068440</td>
      <td>-0.173488</td>
      <td>0.101807</td>
      <td>0.103069</td>
      <td>0.179874</td>
      <td>0.703506</td>
      <td>-0.631475</td>
      <td>0.572920</td>
      <td>1.091222</td>
      <td>...</td>
      <td>0.209128</td>
      <td>-0.116587</td>
      <td>0.364462</td>
      <td>0.460697</td>
      <td>0.756485</td>
      <td>-0.222941</td>
      <td>-0.939488</td>
      <td>0.086753</td>
      <td>0.558198</td>
      <td>-0.213819</td>
      <td>-0.573288</td>
      <td>0.615710</td>
      <td>-0.388612</td>
      <td>-0.873894</td>
      <td>0.338364</td>
      <td>0.183830</td>
      <td>0.126343</td>
      <td>-0.610181</td>
      <td>0.735932</td>
      <td>0.452591</td>
      <td>0.964397</td>
      <td>0.005054</td>
      <td>-0.503492</td>
      <td>-0.323199</td>
      <td>0.673213</td>
      <td>-1.182303</td>
      <td>-0.957658</td>
      <td>-0.869480</td>
      <td>-1.264257</td>
      <td>-1.864004</td>
      <td>-0.203163</td>
      <td>0.491738</td>
      <td>1.363750</td>
      <td>0.519501</td>
      <td>1.489991</td>
      <td>0.632483</td>
      <td>1.109014</td>
      <td>-2.463664</td>
      <td>-1.030615</td>
      <td>-0.435877</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.102479</td>
      <td>-0.965152</td>
      <td>-0.743412</td>
      <td>0.420244</td>
      <td>1.220498</td>
      <td>0.214761</td>
      <td>-0.207032</td>
      <td>0.369359</td>
      <td>-0.829979</td>
      <td>-0.278291</td>
      <td>0.337878</td>
      <td>1.168323</td>
      <td>0.756446</td>
      <td>-0.386579</td>
      <td>-0.396112</td>
      <td>-1.035349</td>
      <td>0.333056</td>
      <td>-0.276849</td>
      <td>0.474656</td>
      <td>-0.316744</td>
      <td>0.527303</td>
      <td>0.300412</td>
      <td>-0.361994</td>
      <td>0.150391</td>
      <td>0.622519</td>
      <td>-0.730694</td>
      <td>-0.757985</td>
      <td>-0.591113</td>
      <td>-0.145845</td>
      <td>-0.511305</td>
      <td>-0.242493</td>
      <td>0.116549</td>
      <td>0.516407</td>
      <td>0.236178</td>
      <td>0.202124</td>
      <td>0.353494</td>
      <td>1.363023</td>
      <td>-0.028528</td>
      <td>0.542290</td>
      <td>0.354285</td>
      <td>...</td>
      <td>0.352691</td>
      <td>0.108146</td>
      <td>0.033940</td>
      <td>0.393491</td>
      <td>-0.077583</td>
      <td>0.681259</td>
      <td>-0.194333</td>
      <td>-0.718941</td>
      <td>-0.015305</td>
      <td>-0.810797</td>
      <td>-0.294738</td>
      <td>-0.295678</td>
      <td>0.099350</td>
      <td>-0.270515</td>
      <td>0.640618</td>
      <td>-0.914733</td>
      <td>-0.160320</td>
      <td>-0.102147</td>
      <td>0.785411</td>
      <td>0.134480</td>
      <td>0.116094</td>
      <td>0.241616</td>
      <td>-0.013123</td>
      <td>-0.480517</td>
      <td>-0.287924</td>
      <td>-0.257277</td>
      <td>-0.610916</td>
      <td>0.878813</td>
      <td>0.754029</td>
      <td>-0.176288</td>
      <td>-0.158166</td>
      <td>0.541015</td>
      <td>0.245012</td>
      <td>-0.209441</td>
      <td>0.361760</td>
      <td>0.280809</td>
      <td>-0.543489</td>
      <td>-0.550961</td>
      <td>-0.203767</td>
      <td>-0.064926</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.460934</td>
      <td>-0.310932</td>
      <td>-1.212403</td>
      <td>0.444425</td>
      <td>0.128127</td>
      <td>-0.615483</td>
      <td>-1.101454</td>
      <td>0.436709</td>
      <td>-0.246546</td>
      <td>-1.170246</td>
      <td>-1.372230</td>
      <td>-0.398051</td>
      <td>0.795159</td>
      <td>1.256620</td>
      <td>-0.131418</td>
      <td>-1.297368</td>
      <td>-0.720620</td>
      <td>0.310862</td>
      <td>-0.255870</td>
      <td>-0.288272</td>
      <td>0.364738</td>
      <td>0.308743</td>
      <td>-0.436683</td>
      <td>0.038345</td>
      <td>-0.137232</td>
      <td>-1.253752</td>
      <td>-0.196004</td>
      <td>0.183245</td>
      <td>-1.200560</td>
      <td>-0.282842</td>
      <td>-0.534038</td>
      <td>0.090345</td>
      <td>-0.681391</td>
      <td>0.261896</td>
      <td>0.759517</td>
      <td>1.082301</td>
      <td>0.888311</td>
      <td>0.321449</td>
      <td>-0.576738</td>
      <td>-0.548182</td>
      <td>...</td>
      <td>-0.125727</td>
      <td>0.875091</td>
      <td>0.209267</td>
      <td>0.572006</td>
      <td>0.468749</td>
      <td>0.990948</td>
      <td>-0.040448</td>
      <td>0.764579</td>
      <td>0.722634</td>
      <td>0.691830</td>
      <td>0.383823</td>
      <td>0.486856</td>
      <td>-0.488875</td>
      <td>-0.772939</td>
      <td>-0.016337</td>
      <td>-0.217564</td>
      <td>0.450738</td>
      <td>-0.312482</td>
      <td>-0.185034</td>
      <td>0.558913</td>
      <td>0.032620</td>
      <td>-0.059322</td>
      <td>0.004766</td>
      <td>-1.062633</td>
      <td>0.668201</td>
      <td>-0.330959</td>
      <td>-0.523211</td>
      <td>-0.131201</td>
      <td>0.310657</td>
      <td>-0.150016</td>
      <td>0.504295</td>
      <td>0.832654</td>
      <td>0.688434</td>
      <td>-0.516126</td>
      <td>0.218389</td>
      <td>-0.108385</td>
      <td>-0.167480</td>
      <td>-1.988553</td>
      <td>-0.835017</td>
      <td>0.462277</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.075986</td>
      <td>-1.059426</td>
      <td>-0.912059</td>
      <td>-0.366934</td>
      <td>0.226968</td>
      <td>-0.386068</td>
      <td>0.547469</td>
      <td>-0.223434</td>
      <td>0.514634</td>
      <td>-0.704503</td>
      <td>0.685660</td>
      <td>0.504605</td>
      <td>-0.056281</td>
      <td>0.725029</td>
      <td>-0.381210</td>
      <td>-0.537004</td>
      <td>-0.582206</td>
      <td>-0.227079</td>
      <td>-0.377125</td>
      <td>-1.278200</td>
      <td>0.429192</td>
      <td>0.262301</td>
      <td>0.122627</td>
      <td>0.614417</td>
      <td>-1.183162</td>
      <td>0.359337</td>
      <td>0.355237</td>
      <td>-0.006907</td>
      <td>-0.210816</td>
      <td>-0.208924</td>
      <td>-0.546358</td>
      <td>-0.586055</td>
      <td>-0.514889</td>
      <td>0.050504</td>
      <td>0.097015</td>
      <td>-1.053627</td>
      <td>0.250282</td>
      <td>-1.408599</td>
      <td>-0.555471</td>
      <td>0.026563</td>
      <td>...</td>
      <td>1.172412</td>
      <td>-0.323461</td>
      <td>0.367525</td>
      <td>0.010780</td>
      <td>-0.009139</td>
      <td>1.123576</td>
      <td>-0.167978</td>
      <td>-0.866724</td>
      <td>0.155211</td>
      <td>1.060482</td>
      <td>0.234268</td>
      <td>-0.888237</td>
      <td>-0.001716</td>
      <td>-0.169578</td>
      <td>0.083739</td>
      <td>0.624579</td>
      <td>0.126594</td>
      <td>0.383943</td>
      <td>0.808187</td>
      <td>0.193583</td>
      <td>-0.298172</td>
      <td>-0.232590</td>
      <td>-0.713840</td>
      <td>0.602595</td>
      <td>0.748782</td>
      <td>0.810053</td>
      <td>-0.096781</td>
      <td>-0.031181</td>
      <td>-0.207885</td>
      <td>-0.517353</td>
      <td>0.297718</td>
      <td>0.277216</td>
      <td>0.543408</td>
      <td>1.374852</td>
      <td>1.082740</td>
      <td>-0.226473</td>
      <td>-0.651504</td>
      <td>-2.732667</td>
      <td>-1.751805</td>
      <td>-0.763315</td>
    </tr>
  </tbody>
</table>
<p>30 rows × 103 columns</p>
</div>
</div>
<br />
<br /></div>
<div class="section" id="initialize-the-objects-of-class-doublemldata-and-doublemlpliv">
<h2>Initialize the objects of class DoubleMLData and DoubleMLPLIV<a class="headerlink" href="#initialize-the-objects-of-class-doublemldata-and-doublemlpliv" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set machine learning methods for m &amp; g</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class"><span class="n">RandomForestRegressor</span></a><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-function"><span class="n">clone</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learner</span></a><span class="p">)</span>

<span class="c1"># initialize the DoubleMLPLIV object</span>
<span class="n">dml_pliv_obj</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/abc.html#abc.ABC" title="abc.ABC" class="sphx-glr-backref-module-abc sphx-glr-backref-type-py-class"><span class="n">DoubleMLPLIV</span></a><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_g</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_m</span></a><span class="p">,</span>
                            <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor" class="sphx-glr-backref-module-sklearn-ensemble sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ml_r</span></a><span class="p">,</span>
                            <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                            <span class="n">dml_procedure</span><span class="o">=</span><span class="s1">&#39;dml1&#39;</span><span class="p">,</span>
                            <span class="n">draw_sample_splitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-samples-and-transfer-the-sample-splitting-to-the-object">
<h2>Split samples and transfer the sample splitting to the object<a class="headerlink" href="#split-samples-and-transfer-the-sample-splitting-to-the-object" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of folds</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]</span>
<span class="n">obj_dml_multiway_resampling</span> <span class="o">=</span> <span class="n">DoubleMLMultiwayResampling</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpl_sizes</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a> <span class="o">=</span> <span class="n">obj_dml_multiway_resampling</span><span class="o">.</span><span class="n">split_samples</span><span class="p">()</span>

<span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">([</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;doubleml.double_ml_pliv.DoubleMLPLIV object at 0x7f1240f2ba60&gt;
</pre></div>
</div>
</div>
<div class="section" id="fit-the-model-and-show-a-summary">
<h2>Fit the model and show a summary<a class="headerlink" href="#fit-the-model-and-show-a-summary" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dml_pliv_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>       coef   std err          t         P&gt;|t|     2.5 %    97.5 %
D  0.960522  0.049526  19.394112  8.653458e-84  0.863452  1.057592
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-sample-splitting-with-tuple-and-linear-indexing">
<h2>Visualization of sample splitting with tuple and linear indexing<a class="headerlink" href="#visualization-of-sample-splitting-with-tuple-and-linear-indexing" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#discrete color scheme</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;RdBu_r&quot;</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">cMap</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">12</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="visualize-sample-splitting-with-tuples-one-plot-per-fold">
<h3>Visualize sample splitting with tuples (one plot per fold)<a class="headerlink" href="#visualize-sample-splitting-with-tuples-one-plot-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_multi_ind</span></a><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]))</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="o">*</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_train</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind_array_test</span></a><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
    <span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
    <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a> <span class="o">%</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">==</span> <span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_001.png" />
</div>
<div class="section" id="visualize-sample-splitting-with-linear-indexing-one-column-per-fold">
<h3>Visualize sample splitting with linear indexing (one column per fold)<a class="headerlink" href="#visualize-sample-splitting-with-linear-indexing-one-column-per-fold" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">K</span></a><span class="p">]))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">smpls_lin_ind</span></a><span class="p">):</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc" title="pandas.DataFrame.loc" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">df</span><span class="o">.</span><span class="n">loc</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">this_split_ind</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i_split</span></a><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">df</span></a><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cMap</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">();</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="o">*</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">M</span></a><span class="p">]);</span>
<span class="n">colorbar</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span><span class="o">.</span><span class="n">collections</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">colorbar</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.667</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.667</span><span class="p">])</span>
<span class="n">colorbar</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s1">&#39;Nuisance&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<img alt="double ml multiway cluster" class="sphx-glr-single-img" src="../_images/sphx_glr_double_ml_multiway_cluster_002.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  5.078 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-double-ml-multiway-cluster-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/37a6f8eaae0ef71ab5c0872dbf2e2103/double_ml_multiway_cluster.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">double_ml_multiway_cluster.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c2885c0f3b83a65dbf637ec513a2e9e7/double_ml_multiway_cluster.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">double_ml_multiway_cluster.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Examples</a>
    <a class='right-next' id="next-link" href="double_ml_bonus_data.html" title="next page">DML: Bonus Data</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.4.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>