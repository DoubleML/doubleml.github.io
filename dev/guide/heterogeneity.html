

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>4. Heterogeneous treatment effects &#8212; DoubleML  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="../_static/design-tabs.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'guide/heterogeneity';</script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5. Score functions" href="scores.html" />
    <link rel="prev" title="3. Models" href="models.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  <div class="navbar-header-items__start">
    
      <div class="navbar-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    <p class="title logo__title">DoubleML  documentation</p>
  
</a></div>
    
  </div>
  
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../intro/install.html">
                         Install
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../intro/intro.html">
                         Getting started
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../workflow/workflow.html">
                         Workflow
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="guide.html">
                         User guide
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../examples/index.html">
                         Examples
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../api/api.html">
                         Python API
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-external" href="https://docs.doubleml.org/r/stable/">
                         R API
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../literature/literature.html">
                         Literature
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../release/release.html">
                         Release notes
                      </a>
                    </li>
                
                </div>
            </div>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
        </div>
      
      
        <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/DoubleML/doubleml-for-py" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
    </div>
  

  
    <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
    </label>
  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../intro/install.html">
                         Install
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../intro/intro.html">
                         Getting started
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../workflow/workflow.html">
                         Workflow
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="guide.html">
                         User guide
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../examples/index.html">
                         Examples
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../api/api.html">
                         Python API
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-external" href="https://docs.doubleml.org/r/stable/">
                         R API
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../literature/literature.html">
                         Literature
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../release/release.html">
                         Release notes
                      </a>
                    </li>
                
                </div>
            </div>
            
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/DoubleML/doubleml-for-py" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item"><p class="logo" style="text-align:center;"><a href="../index.html">
    <img class="logo" src="../logo.png" alt="Logo" width="65%" height="65%">
</a></p>

<script type="text/javascript">
    // Change the logo depending on the theme
    var logo = document.querySelector('img.logo');
    var observer = new MutationObserver(function(mutations) {
        const dark = document.documentElement.dataset.theme == 'dark';
        if (dark) {
            logo.src = "../logo_dark.png";
        } else {
            logo.src = "../logo.png";
        }
    });
    observer.observe(document.documentElement, {attributes: true, attributeFilter: ['data-theme']});
</script></div>
        <div class="sidebar-primary-item">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
        <div class="sidebar-primary-item"><nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="basics.html">1. The basics of double/debiased machine learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_backend.html">2. The data-backend DoubleMLData</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">3. Models</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">4. Heterogeneous Treatment Effects</a></li>
<li class="toctree-l1"><a class="reference internal" href="scores.html">5. Score functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="algorithms.html">6. Double machine learning algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="learners.html">7. Learners, hyperparameters and hyperparameter tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="se_confint.html">8. Variance estimation and confidence intervals</a></li>
<li class="toctree-l1"><a class="reference internal" href="resampling.html">9. Sample-splitting, cross-fitting and repeated cross-fitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="sensitivity.html">10. Sensitivity Analysis</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumbs">
  <ul class="bd-breadcrumbs" role="navigation" aria-label="Breadcrumb">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="guide.html" class="nav-link">User guide</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="section-number">4. </span>Heterogeneous treatment effects</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="heterogeneous-treatment-effects">
<span id="heterogeneity"></span><h1><span class="section-number">4. </span>Heterogeneous treatment effects<a class="headerlink" href="#heterogeneous-treatment-effects" title="Permalink to this heading">#</a></h1>
<p>Most implemented solutions focus on the <a class="reference internal" href="models.html#irm-model"><span class="std std-ref">IRM</span></a> or <a class="reference internal" href="models.html#iivm-model"><span class="std std-ref">IIVM</span></a> models, as for
the <a class="reference internal" href="models.html#plr-model"><span class="std std-ref">PLR</span></a> and <a class="reference internal" href="models.html#pliv-model"><span class="std std-ref">PLIV</span></a> models heterogeneous treatment effects can be usually modelled
via feature construction.</p>
<section id="group-average-treatment-effects-gates">
<span id="gates"></span><h2><span class="section-number">4.1. </span>Group average treatment effects (GATEs)<a class="headerlink" href="#group-average-treatment-effects-gates" title="Permalink to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code> and <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code> classes contain the <code class="docutils literal notranslate"><span class="pre">gate()</span></code> method, which enables the estimation and construction of confidence intervals
for GATEs after fitting the <code class="docutils literal notranslate"><span class="pre">DoubleML</span></code> object. To estimate GATEs, the user has to specify a pandas <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> containing
the groups (dummy coded or one column with strings).
This will construct and fit a <code class="docutils literal notranslate"><span class="pre">DoubleMLBLP</span></code> object. Confidence intervals can then be constructed via
the <code class="docutils literal notranslate"><span class="pre">confint()</span></code> method. Jointly valid confidence intervals will be based on a gaussian multiplier bootstrap.</p>
<section id="gates-for-irm-models">
<h3><span class="section-number">4.1.1. </span>GATEs for IRM models<a class="headerlink" href="#gates-for-irm-models" title="Permalink to this heading">#</a></h3>
<p><strong>Group Average Treatment Effects (GATEs)</strong> for <code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code> models consider the target parameters</p>
<div class="math notranslate nohighlight">
\[\theta_{0,k} = \mathbb{E}[Y(1) - Y(0)| G_k],\quad k=1,\dots, K.\]</div>
<p>where <span class="math notranslate nohighlight">\(G_k\)</span> denotes a group indicator and <span class="math notranslate nohighlight">\(Y(d)\)</span> the potential outcome with <span class="math notranslate nohighlight">\(d \in \{0, 1\}\)</span>.</p>
<p>Point estimates and confidence intervals can be obtained via the <code class="docutils literal notranslate"><span class="pre">gate()</span></code> and <code class="docutils literal notranslate"><span class="pre">confint()</span></code> methods.
Remark that for straightforward interpretation, the groups have to be mutually exclusive.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
</input><label class="sd-tab-label" data-sync-id="py" for="sd-tab-item-0">
Python</label><div class="sd-tab-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="gp">In [2]: </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="gp">In [3]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [4]: </span><span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_irm_data</span>

<span class="gp">In [5]: </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span><span class="p">,</span> <span class="n">RandomForestClassifier</span>

<span class="gp">In [6]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [7]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [8]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3333</span><span class="p">)</span>

<span class="gp">In [9]: </span><span class="n">data</span> <span class="o">=</span> <span class="n">make_irm_data</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">dim_x</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;DataFrame&#39;</span><span class="p">)</span>

<span class="gp">In [10]: </span><span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

<span class="gp">In [11]: </span><span class="n">dml_irm_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLIRM</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">)</span>

<span class="gp">In [12]: </span><span class="n">_</span> <span class="o">=</span> <span class="n">dml_irm_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="go"># define groups</span>
<span class="gp">In [13]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="gp">In [14]: </span><span class="n">groups</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Group&#39;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>

<span class="gp">In [15]: </span><span class="nb">print</span><span class="p">(</span><span class="n">groups</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="go">  Group</span>
<span class="go">0     2</span>
<span class="go">1     0</span>
<span class="go">2     2</span>
<span class="go">3     2</span>
<span class="go">4     0</span>

<span class="gp">In [16]: </span><span class="n">gate_obj</span> <span class="o">=</span> <span class="n">dml_irm_obj</span><span class="o">.</span><span class="n">gate</span><span class="p">(</span><span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">)</span>

<span class="gp">In [17]: </span><span class="n">ci</span> <span class="o">=</span> <span class="n">gate_obj</span><span class="o">.</span><span class="n">confint</span><span class="p">()</span>

<span class="gp">In [18]: </span><span class="nb">print</span><span class="p">(</span><span class="n">ci</span><span class="p">)</span>
<span class="go">            2.5 %    effect    97.5 %</span>
<span class="go">Group_0  0.231638  0.645582  1.059525</span>
<span class="go">Group_1 -0.625448  0.363870  1.353188</span>
<span class="go">Group_2  0.362418  0.771480  1.180542</span>
</pre></div>
</div>
</div>
</div>
<p>A more detailed notebook on GATEs with <code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code> models is available in the <a class="reference internal" href="../examples/index.html#examplegallery"><span class="std std-ref">example gallery</span></a>.</p>
</section>
<section id="gates-for-plr-models">
<h3><span class="section-number">4.1.2. </span>GATEs for PLR models<a class="headerlink" href="#gates-for-plr-models" title="Permalink to this heading">#</a></h3>
<p><strong>Group Average Treatment Effects (GATEs)</strong> for <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code> models consider a slightly adjusted version of the <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code> model.
Instead of considering a constant treatment effect <span class="math notranslate nohighlight">\(\theta_0\)</span> for all observations, the adjusted model allows for a different effect based on groups.</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y = D \theta_0(G_k) + g_0(X) + \zeta, &amp; &amp;\mathbb{E}(\zeta | D,X) = 0,\\D = m_0(X) + V, &amp; &amp;\mathbb{E}(V | X) = 0,\end{aligned}\end{align} \]</div>
<p>where <span class="math notranslate nohighlight">\(G_k\)</span> for <span class="math notranslate nohighlight">\(k=1,\dots, K\)</span> denotes a group indicator where the groups can depend on the counfounding features <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>Point estimates and confidence intervals can be obtained via the <code class="docutils literal notranslate"><span class="pre">gate()</span></code> and <code class="docutils literal notranslate"><span class="pre">confint()</span></code> methods.
Remark that for straightforward interpretation, the groups have to be mutually exclusive.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-1" name="sd-tab-set-1" type="radio">
</input><label class="sd-tab-label" data-sync-id="py" for="sd-tab-item-1">
Python</label><div class="sd-tab-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [19]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="gp">In [20]: </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="gp">In [21]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [22]: </span><span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_plr_CCDDHNR2018</span>

<span class="gp">In [23]: </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="gp">In [24]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [25]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [26]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3333</span><span class="p">)</span>

<span class="gp">In [27]: </span><span class="n">dml_data</span> <span class="o">=</span> <span class="n">make_plr_CCDDHNR2018</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">dim_x</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="gp">In [28]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">)</span>

<span class="gp">In [29]: </span><span class="n">_</span> <span class="o">=</span> <span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="go"># define groups</span>
<span class="gp">In [30]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="gp">In [31]: </span><span class="n">groups</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Group&#39;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>

<span class="gp">In [32]: </span><span class="nb">print</span><span class="p">(</span><span class="n">groups</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="go">  Group</span>
<span class="go">0     2</span>
<span class="go">1     0</span>
<span class="go">2     2</span>
<span class="go">3     2</span>
<span class="go">4     0</span>

<span class="gp">In [33]: </span><span class="n">gate_obj</span> <span class="o">=</span> <span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">gate</span><span class="p">(</span><span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">)</span>

<span class="gp">In [34]: </span><span class="n">ci</span> <span class="o">=</span> <span class="n">gate_obj</span><span class="o">.</span><span class="n">confint</span><span class="p">()</span>

<span class="gp">In [35]: </span><span class="nb">print</span><span class="p">(</span><span class="n">ci</span><span class="p">)</span>
<span class="go">            2.5 %    effect    97.5 %</span>
<span class="go">Group_0  0.498119  0.644565  0.791012</span>
<span class="go">Group_1  0.247555  0.395402  0.543248</span>
<span class="go">Group_2  0.451385  0.593896  0.736407</span>
</pre></div>
</div>
</div>
</div>
<p>A more detailed notebook on GATEs with <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code> models is available in the <a class="reference internal" href="../examples/index.html#examplegallery"><span class="std std-ref">example gallery</span></a>.</p>
</section>
</section>
<section id="conditional-average-treatment-effects-cates">
<span id="cates"></span><h2><span class="section-number">4.2. </span>Conditional average treatment effects (CATEs)<a class="headerlink" href="#conditional-average-treatment-effects-cates" title="Permalink to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code> and <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code> classes contain the <code class="docutils literal notranslate"><span class="pre">cate()</span></code> method, which enables the estimation and construction of confidence intervals
for CATEs after fitting the <code class="docutils literal notranslate"><span class="pre">DoubleML</span></code> object. To estimate CATEs, the user has to specify a pandas <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> containing
the basis (e.g. B-splines) for the conditional treatment effects.
This will construct and fit a <code class="docutils literal notranslate"><span class="pre">DoubleMLBLP</span></code> object. Confidence intervals can then be constructed via
the <code class="docutils literal notranslate"><span class="pre">confint()</span></code> method. Jointly valid confidence intervals will be based on a gaussian multiplier bootstrap.</p>
<section id="cates-for-irm-models">
<h3><span class="section-number">4.2.1. </span>CATEs for IRM models<a class="headerlink" href="#cates-for-irm-models" title="Permalink to this heading">#</a></h3>
<p><strong>Conditional Average Treatment Effects (CATEs)</strong> for <code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code> models consider the target parameters</p>
<div class="math notranslate nohighlight">
\[\theta_{0}(x) = \mathbb{E}[Y(1) - Y(0)| X=x]\]</div>
<p>for a low-dimensional feature <span class="math notranslate nohighlight">\(X\)</span>, where <span class="math notranslate nohighlight">\(Y(d)\)</span> the potential outcome with <span class="math notranslate nohighlight">\(d \in \{0, 1\}\)</span>.</p>
<p>Point estimates and confidence intervals can be obtained via the <code class="docutils literal notranslate"><span class="pre">gate()</span></code> and <code class="docutils literal notranslate"><span class="pre">confint()</span></code> methods.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-2" name="sd-tab-set-2" type="radio">
</input><label class="sd-tab-label" data-sync-id="py" for="sd-tab-item-2">
Python</label><div class="sd-tab-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [36]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="gp">In [37]: </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="gp">In [38]: </span><span class="kn">import</span> <span class="nn">patsy</span>

<span class="gp">In [39]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [40]: </span><span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_irm_data</span>

<span class="gp">In [41]: </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="gp">In [42]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [43]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [44]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3333</span><span class="p">)</span>

<span class="gp">In [45]: </span><span class="n">data</span> <span class="o">=</span> <span class="n">make_irm_data</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">dim_x</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;DataFrame&#39;</span><span class="p">)</span>

<span class="gp">In [46]: </span><span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

<span class="gp">In [47]: </span><span class="n">dml_irm_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLIRM</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">)</span>

<span class="gp">In [48]: </span><span class="n">_</span> <span class="o">=</span> <span class="n">dml_irm_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="go"># define a basis with respect to the first variable</span>
<span class="gp">In [49]: </span><span class="n">design_matrix</span> <span class="o">=</span> <span class="n">patsy</span><span class="o">.</span><span class="n">dmatrix</span><span class="p">(</span><span class="s2">&quot;bs(x, df=5, degree=2)&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span><span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;X1&quot;</span><span class="p">]})</span>

<span class="gp">In [50]: </span><span class="n">spline_basis</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">design_matrix</span><span class="p">)</span>

<span class="gp">In [51]: </span><span class="nb">print</span><span class="p">(</span><span class="n">spline_basis</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="go">     0         1         2         3         4    5</span>
<span class="go">0  1.0  0.000000  0.191397  0.782646  0.025958  0.0</span>
<span class="go">1  1.0  0.342467  0.653991  0.000000  0.000000  0.0</span>
<span class="go">2  1.0  0.460535  0.511022  0.000000  0.000000  0.0</span>
<span class="go">3  1.0  0.000000  0.456552  0.543358  0.000091  0.0</span>
<span class="go">4  1.0  0.046405  0.778852  0.174743  0.000000  0.0</span>

<span class="gp">In [52]: </span><span class="n">cate_obj</span> <span class="o">=</span> <span class="n">dml_irm_obj</span><span class="o">.</span><span class="n">cate</span><span class="p">(</span><span class="n">basis</span><span class="o">=</span><span class="n">spline_basis</span><span class="p">)</span>

<span class="gp">In [53]: </span><span class="n">ci</span> <span class="o">=</span> <span class="n">cate_obj</span><span class="o">.</span><span class="n">confint</span><span class="p">(</span><span class="n">basis</span><span class="o">=</span><span class="n">spline_basis</span><span class="p">)</span>

<span class="gp">In [54]: </span><span class="nb">print</span><span class="p">(</span><span class="n">ci</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="go">      2.5 %    effect    97.5 %</span>
<span class="go">0  0.253949  0.741076  1.228203</span>
<span class="go">1 -1.093401 -0.115761  0.861879</span>
<span class="go">2 -1.937669 -0.406249  1.125172</span>
<span class="go">3  0.269999  0.691113  1.112227</span>
<span class="go">4  0.000768  0.571317  1.141866</span>
</pre></div>
</div>
</div>
</div>
<p>A more detailed notebook on CATEs for <code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code> models is available in the <a class="reference internal" href="../examples/index.html#examplegallery"><span class="std std-ref">example gallery</span></a>.
The examples also include the construction of a two-dimensional basis with B-splines.</p>
</section>
<section id="cates-for-plr-models">
<h3><span class="section-number">4.2.2. </span>CATEs for PLR models<a class="headerlink" href="#cates-for-plr-models" title="Permalink to this heading">#</a></h3>
<p><strong>Conditional Average Treatment Effects (CATEs)</strong> for <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code> models consider a slightly adjusted version of the <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code> model.
Instead of considering a constant treatment effect <span class="math notranslate nohighlight">\(\theta_0\)</span> for all observations, the adjusted model allows for a different effect based on groups.</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Y = D \theta_0(X) + g_0(X) + \zeta, &amp; &amp;\mathbb{E}(\zeta | D,X) = 0,\\D = m_0(X) + V, &amp; &amp;\mathbb{E}(V | X) = 0,\end{aligned}\end{align} \]</div>
<p>where <span class="math notranslate nohighlight">\(\theta_0(X)\)</span> denotes the heterogeneous treatment effect.</p>
<p>Point estimates and confidence intervals can be obtained via the <code class="docutils literal notranslate"><span class="pre">gate()</span></code> and <code class="docutils literal notranslate"><span class="pre">confint()</span></code> methods.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-3" name="sd-tab-set-3" type="radio">
</input><label class="sd-tab-label" data-sync-id="py" for="sd-tab-item-3">
Python</label><div class="sd-tab-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [55]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="gp">In [56]: </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="gp">In [57]: </span><span class="kn">import</span> <span class="nn">patsy</span>

<span class="gp">In [58]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [59]: </span><span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_plr_CCDDHNR2018</span>

<span class="gp">In [60]: </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span><span class="p">,</span> <span class="n">RandomForestClassifier</span>

<span class="gp">In [61]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [62]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [63]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3333</span><span class="p">)</span>

<span class="gp">In [64]: </span><span class="n">dml_data</span> <span class="o">=</span> <span class="n">make_plr_CCDDHNR2018</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">dim_x</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="gp">In [65]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">)</span>

<span class="gp">In [66]: </span><span class="n">_</span> <span class="o">=</span> <span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="go"># define a basis with respect to the first variable</span>
<span class="gp">In [67]: </span><span class="n">design_matrix</span> <span class="o">=</span> <span class="n">patsy</span><span class="o">.</span><span class="n">dmatrix</span><span class="p">(</span><span class="s2">&quot;bs(x, df=5, degree=2)&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span><span class="n">obj_dml_data</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;X1&quot;</span><span class="p">]})</span>

<span class="gp">In [68]: </span><span class="n">spline_basis</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">design_matrix</span><span class="p">)</span>

<span class="gp">In [69]: </span><span class="nb">print</span><span class="p">(</span><span class="n">spline_basis</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="go">     0         1         2         3         4    5</span>
<span class="go">0  1.0  0.000000  0.191397  0.782646  0.025958  0.0</span>
<span class="go">1  1.0  0.342467  0.653991  0.000000  0.000000  0.0</span>
<span class="go">2  1.0  0.460535  0.511022  0.000000  0.000000  0.0</span>
<span class="go">3  1.0  0.000000  0.456552  0.543358  0.000091  0.0</span>
<span class="go">4  1.0  0.046405  0.778852  0.174743  0.000000  0.0</span>

<span class="gp">In [70]: </span><span class="n">cate_obj</span> <span class="o">=</span> <span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">cate</span><span class="p">(</span><span class="n">basis</span><span class="o">=</span><span class="n">spline_basis</span><span class="p">)</span>

<span class="gp">In [71]: </span><span class="n">ci</span> <span class="o">=</span> <span class="n">cate_obj</span><span class="o">.</span><span class="n">confint</span><span class="p">(</span><span class="n">basis</span><span class="o">=</span><span class="n">spline_basis</span><span class="p">)</span>

<span class="gp">In [72]: </span><span class="nb">print</span><span class="p">(</span><span class="n">ci</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="go">      2.5 %    effect    97.5 %</span>
<span class="go">0  0.391971  0.548740  0.705509</span>
<span class="go">1  0.433640  0.600482  0.767324</span>
<span class="go">2  0.381653  0.587828  0.794002</span>
<span class="go">3  0.438942  0.570852  0.702763</span>
<span class="go">4  0.419818  0.592956  0.766095</span>
</pre></div>
</div>
</div>
</div>
<p>A more detailed notebook on CATEs for <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code> models is available in the <a class="reference internal" href="../examples/index.html#examplegallery"><span class="std std-ref">example gallery</span></a>.</p>
<p><strong>Theory:</strong> In the model above, it holds</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbb{E}[Y|X] &amp;= \mathbb{E}[\theta_0(X) D|X] + \mathbb{E}[g(X)|X] + \underbrace{\mathbb{E}[\varepsilon|X]}_{=\mathbb{E}[\mathbb{E}[\varepsilon|D, X]|X]=0}\\
&amp;=\theta(X) \mathbb{E}[D|X] + g(X)\end{split}\]</div>
<p>such that</p>
<div class="math notranslate nohighlight">
\[\underbrace{Y - \mathbb{E}[Y|X]}_{=:\tilde{Y}} = \theta_0(X) (\underbrace{D - \mathbb{E}[D|X]}_{=:\tilde{D}}) + \varepsilon.\]</div>
<p>Remark that for the generated <span class="math notranslate nohighlight">\(\sigma\)</span>-agebras <span class="math notranslate nohighlight">\(\sigma(\tilde{D})\subseteq \sigma(D,X)\)</span> implying</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}[\epsilon|\tilde{D}] = \mathbb{E}[\mathbb{E}[\epsilon|X, D]|\tilde{D}] = 0\]</div>
<p>and consequently</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}[\tilde{Y}|\tilde{D}] = \theta(X)\tilde{D}.\]</div>
<p>Consequently, <span class="math notranslate nohighlight">\(\theta_0(X)\)</span> can be estimated by regressing <span class="math notranslate nohighlight">\(\tilde{Y}\)</span> on <span class="math notranslate nohighlight">\(\tilde{D}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\theta_0(X) = \arg\min_{\theta(X) \in \Theta}\mathbb{E}[(\tilde{Y} - \theta(X)\tilde{D})^2]\]</div>
<p>The <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> implementation approximates the effect <span class="math notranslate nohighlight">\(\theta(X)\)</span> by a linear projection on a supplied basis <span class="math notranslate nohighlight">\(\phi(X)\)</span>:</p>
<div class="math notranslate nohighlight">
\[\theta_0(X) \approx \beta_0^T \phi(X)\]</div>
<p>where <span class="math notranslate nohighlight">\(\beta_0\)</span> are coefficients to be estimated.
The coverage of the confidence intervals is meant to include the the approximation <span class="math notranslate nohighlight">\(\beta_0^T\phi(X)\)</span>.</p>
</section>
</section>
<section id="weighted-average-treatment-effects">
<span id="weighted-cates"></span><h2><span class="section-number">4.3. </span>Weighted Average Treatment Effects<a class="headerlink" href="#weighted-average-treatment-effects" title="Permalink to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code> class allows to specify weights via the <code class="docutils literal notranslate"><span class="pre">weights</span></code> argument in the initialization of the <code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code> object.
Given some weights, <span class="math notranslate nohighlight">\(\omega(Y,D,X)\)</span> the model identifies the weighted average treatment effect</p>
<div class="math notranslate nohighlight">
\[\theta_0 = \mathbb{E}[(g_0(1,X) - g_0(0,X))\omega(Y,D,X)].\]</div>
<p>The interpretation depends on the choice of weights. The simplest examples include</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\omega(Y,D,X) = 1\)</span> which corresponds to the average treatment effect (ATE)</p></li>
<li><p><span class="math notranslate nohighlight">\(\omega(Y,D,X) = \frac{1\{X\in G\}}{P(X\in G)}\)</span> which corresponds to the group average treatment effect (GATE) for group <span class="math notranslate nohighlight">\(G\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\omega(Y,D,X) = \pi(X)\)</span> which corresponds to the average value of policy <span class="math notranslate nohighlight">\(\pi\)</span>, where <span class="math notranslate nohighlight">\(0\le \pi \le 1\)</span></p></li>
</ul>
<p>where the weights <span class="math notranslate nohighlight">\(\omega(Y,D,X)\)</span> only depend on the features <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>In these cases the weights can be specified as an array via the <code class="docutils literal notranslate"><span class="pre">weights</span></code> argument in the initialization of the <code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code> object.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-4" name="sd-tab-set-4" type="radio">
</input><label class="sd-tab-label" data-sync-id="py" for="sd-tab-item-4">
Python</label><div class="sd-tab-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [73]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="gp">In [74]: </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="gp">In [75]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [76]: </span><span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_irm_data</span>

<span class="gp">In [77]: </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="gp">In [78]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [79]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [80]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3333</span><span class="p">)</span>

<span class="gp">In [81]: </span><span class="n">data</span> <span class="o">=</span> <span class="n">make_irm_data</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">dim_x</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;DataFrame&#39;</span><span class="p">)</span>

<span class="gp">In [82]: </span><span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

<span class="gp">In [83]: </span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span>

<span class="gp">In [84]: </span><span class="n">dml_irm_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLIRM</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>

<span class="gp">In [85]: </span><span class="n">_</span> <span class="o">=</span> <span class="n">dml_irm_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="gp">In [86]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_irm_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err         t     P&gt;|t|     2.5 %   97.5 %</span>
<span class="go">d  0.593036  0.195602  3.031848  0.002431  0.209663  0.97641</span>
</pre></div>
</div>
</div>
</div>
<p>If the weights do not only depend on the features <span class="math notranslate nohighlight">\(X\)</span>, but e.g. also on the treatment <span class="math notranslate nohighlight">\(D\)</span> estimation becomes more involved.
To identifiy the correct parameter not only the weights <span class="math notranslate nohighlight">\(\omega(Y,D,X)\)</span> but also their conditional expectation</p>
<div class="math notranslate nohighlight">
\[\bar{\omega}(X) = \mathbb{E}[\omega(Y,D,X)|X]\]</div>
<p>has to be specified. A common example is the average treatment effect on the treated (ATTE) which can be identified by setting</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\omega(Y,D,X) = \frac{D}{P(D=1)}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\bar{\omega}(X) = \frac{\mathbb{E}[D|X]}{P(D=1)} = \frac{m_0(X)}{P(D=1)}\)</span></p></li>
</ul>
<p>which depends on the propensity score <span class="math notranslate nohighlight">\(m_0(X)\)</span>.
In this case the weights can be specified as a <code class="docutils literal notranslate"><span class="pre">dictionary</span></code> the <code class="docutils literal notranslate"><span class="pre">weights</span></code> argument in the initialization of the <code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code> object.</p>
<p>One other important example would be the sensitivity analysis for group average treatment effects on the treated (GATET).
In this case the weights would take the following form</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\omega(Y,D,X) = \frac{1\{D=1, X\in G\}}{P(D=1, X\in G)}= \frac{D \cdot 1\{X\in G\}}{P(D=1, X\in G)}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\bar{\omega}(X) = \frac{\mathbb{E}[D|X]1\{X\in G\}}{P(D=1, X\in G)} = \frac{m_0(X)1\{X\in G\}}{P(D=1, X\in G)}.\)</span></p></li>
</ul>
<p>To simplify the specification of the weights, the <code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code> with <code class="docutils literal notranslate"><span class="pre">score='ATTE'</span></code> accepts binary weights, which should correspond to <span class="math notranslate nohighlight">\(1\{X\in G\}\)</span>.
This automatically relies on the propensity score <span class="math notranslate nohighlight">\(m(X)\)</span> to construct the weights mentioned above (e.g. for weights equal to one this refers to the average treatment effect on the treated).</p>
<p>A more detailed notebook on weighted average treatment effects for on GATE sensitivity analysis is available in the <a class="reference internal" href="../examples/index.html#examplegallery"><span class="std std-ref">example gallery</span></a>.</p>
</section>
<section id="quantiles">
<span id="qtes"></span><h2><span class="section-number">4.4. </span>Quantiles<a class="headerlink" href="#quantiles" title="Permalink to this heading">#</a></h2>
<p>The <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> package includes (local) quantile estimation for potential outcomes for
<a class="reference internal" href="models.html#irm-model"><span class="std std-ref">IRM</span></a> and <a class="reference internal" href="models.html#iivm-model"><span class="std std-ref">IIVM</span></a> models.</p>
<section id="potential-quantiles-pqs">
<h3><span class="section-number">4.4.1. </span>Potential quantiles (PQs)<a class="headerlink" href="#potential-quantiles-pqs" title="Permalink to this heading">#</a></h3>
<p>For a quantile <span class="math notranslate nohighlight">\(\tau \in (0,1)\)</span> the target parameters <span class="math notranslate nohighlight">\(\theta_{\tau}(d)\)</span> of interest are the <strong>potential quantiles (PQs)</strong>,</p>
<div class="math notranslate nohighlight">
\[P(Y(d) \le \theta_{\tau}(d)) = \tau,\]</div>
<p>and <strong>local potential quantiles (LPQs)</strong>,</p>
<div class="math notranslate nohighlight">
\[P(Y(d) \le \theta_{\tau}(d)|\text{Compliers}) = \tau.\]</div>
<p>where <span class="math notranslate nohighlight">\(Y(d)\)</span> denotes the potential outcome with <span class="math notranslate nohighlight">\(d \in \{0, 1\}\)</span>.</p>
<p><code class="docutils literal notranslate"><span class="pre">DoubleMLPQ</span></code> implements potential quantile estimation. Estimation is conducted via its <code class="docutils literal notranslate"><span class="pre">fit()</span></code> method:</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-5" name="sd-tab-set-5" type="radio">
</input><label class="sd-tab-label" data-sync-id="py" for="sd-tab-item-5">
Python</label><div class="sd-tab-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [87]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="gp">In [88]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [89]: </span><span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_irm_data</span>

<span class="gp">In [90]: </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="gp">In [91]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3141</span><span class="p">)</span>

<span class="gp">In [92]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [93]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [94]: </span><span class="n">data</span> <span class="o">=</span> <span class="n">make_irm_data</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">dim_x</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;DataFrame&#39;</span><span class="p">)</span>

<span class="gp">In [95]: </span><span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

<span class="gp">In [96]: </span><span class="n">dml_pq_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPQ</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span> <span class="n">treatment</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">quantile</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="gp">In [97]: </span><span class="n">dml_pq_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span>
<span class="gh">Out[97]: </span>
<span class="go">       coef   std err         t     P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.553878  0.149858  3.696011  0.000219  0.260161  0.847595</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">DoubleMLLPQ</span></code> implements local potential quantile estimation, where the argument <code class="docutils literal notranslate"><span class="pre">treatment</span></code> indicates the potential outcome.
Estimation is conducted via its <code class="docutils literal notranslate"><span class="pre">fit()</span></code> method:</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-6" name="sd-tab-set-6" type="radio">
</input><label class="sd-tab-label" data-sync-id="py" for="sd-tab-item-6">
Python</label><div class="sd-tab-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [98]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="gp">In [99]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [100]: </span><span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_iivm_data</span>

<span class="gp">In [101]: </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="gp">In [102]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3141</span><span class="p">)</span>

<span class="gp">In [103]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [104]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [105]: </span><span class="n">data</span> <span class="o">=</span> <span class="n">make_iivm_data</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">dim_x</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;DataFrame&#39;</span><span class="p">)</span>

<span class="gp">In [106]: </span><span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="n">z_cols</span><span class="o">=</span><span class="s1">&#39;z&#39;</span><span class="p">)</span>

<span class="gp">In [107]: </span><span class="n">dml_lpq_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLLPQ</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span> <span class="n">treatment</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">quantile</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="gp">In [108]: </span><span class="n">dml_lpq_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span>
<span class="gh">Out[108]: </span>
<span class="go">       coef   std err       t     P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.327341  0.548862  0.5964  0.550908 -0.748408  1.403091</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="quantile-treatment-effects-qtes">
<h3><span class="section-number">4.4.2. </span>Quantile treatment effects (QTEs)<a class="headerlink" href="#quantile-treatment-effects-qtes" title="Permalink to this heading">#</a></h3>
<p>For a quantile <span class="math notranslate nohighlight">\(\tau \in (0,1)\)</span> the target parameter <span class="math notranslate nohighlight">\(\theta_{\tau}\)</span> of interest are the <strong>quantile treatment effect (QTE)</strong>,</p>
<div class="math notranslate nohighlight">
\[\theta_{\tau} = \theta_{\tau}(1) - \theta_{\tau}(0)\]</div>
<p>where <span class="math notranslate nohighlight">\(\theta_{\tau}(d)\)</span> denotes the corresponding potential quantile.</p>
<p>Analogously, the <strong>local quantile treatment effect (LQTE)</strong> can be defined as the difference of
the corresponding local potential quantiles.</p>
<p><code class="docutils literal notranslate"><span class="pre">DoubleMLQTE</span></code> implements quantile treatment effect estimation. Estimation is conducted via its <code class="docutils literal notranslate"><span class="pre">fit()</span></code> method:</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-7" name="sd-tab-set-7" type="radio">
</input><label class="sd-tab-label" data-sync-id="py" for="sd-tab-item-7">
Python</label><div class="sd-tab-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [109]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="gp">In [110]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [111]: </span><span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_irm_data</span>

<span class="gp">In [112]: </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="gp">In [113]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3141</span><span class="p">)</span>

<span class="gp">In [114]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [115]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [116]: </span><span class="n">data</span> <span class="o">=</span> <span class="n">make_irm_data</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">dim_x</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;DataFrame&#39;</span><span class="p">)</span>

<span class="gp">In [117]: </span><span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

<span class="gp">In [118]: </span><span class="n">dml_qte_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLQTE</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span> <span class="n">score</span><span class="o">=</span><span class="s1">&#39;PQ&#39;</span><span class="p">,</span> <span class="n">quantiles</span><span class="o">=</span><span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">])</span>

<span class="gp">In [119]: </span><span class="n">dml_qte_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span>
<span class="gh">Out[119]: </span>
<span class="go">          coef   std err         t     P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">0.25  0.274825  0.347310  0.791297  0.428771 -0.405890  0.955541</span>
<span class="go">0.50  0.449150  0.192539  2.332782  0.019660  0.071782  0.826519</span>
<span class="go">0.75  0.709606  0.193308  3.670867  0.000242  0.330731  1.088482</span>
</pre></div>
</div>
</div>
</div>
<p>To estimate local quantile effects the <code class="docutils literal notranslate"><span class="pre">score</span></code> argument has to be set to <code class="docutils literal notranslate"><span class="pre">'LPQ'</span></code>.
A detailed notebook on PQs and QTEs is available in the <a class="reference internal" href="../examples/index.html#examplegallery"><span class="std std-ref">example gallery</span></a>.</p>
</section>
</section>
<section id="conditional-value-at-risk-cvar">
<h2><span class="section-number">4.5. </span>Conditional value at risk (CVaR)<a class="headerlink" href="#conditional-value-at-risk-cvar" title="Permalink to this heading">#</a></h2>
<p>The <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> package includes conditional value at risk estimation for
<a class="reference internal" href="models.html#irm-model"><span class="std std-ref">IRM</span></a> models.</p>
<section id="cvar-of-potential-outcomes">
<h3><span class="section-number">4.5.1. </span>CVaR of potential outcomes<a class="headerlink" href="#cvar-of-potential-outcomes" title="Permalink to this heading">#</a></h3>
<p>For a quantile <span class="math notranslate nohighlight">\(\tau \in (0,1)\)</span> the target parameters <span class="math notranslate nohighlight">\(\theta_{\tau}(d)\)</span> of interest are
the <strong>conditional values at risk (CVaRs)</strong> of the potential outcomes,</p>
<div class="math notranslate nohighlight">
\[\theta_{\tau}(d) = \frac{\mathbb{E}[Y(d) 1\{F_{Y(d)}(Y(d) \ge \tau)]}{1-\tau},\]</div>
<p>where <span class="math notranslate nohighlight">\(Y(d)\)</span> denotes the potential outcome with <span class="math notranslate nohighlight">\(d \in \{0, 1\}\)</span> and
<span class="math notranslate nohighlight">\(F_{Y(d)}(x)\)</span> the corresponding cdf of <span class="math notranslate nohighlight">\(Y(d)\)</span>.</p>
<p><code class="docutils literal notranslate"><span class="pre">DoubleMLCVAR</span></code> implements conditional value at risk estimation for potential outcomes, where the argument <code class="docutils literal notranslate"><span class="pre">treatment</span></code> indicates the potential outcome.
Estimation is conducted via its <code class="docutils literal notranslate"><span class="pre">fit()</span></code> method:</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-8" name="sd-tab-set-8" type="radio">
</input><label class="sd-tab-label" data-sync-id="py" for="sd-tab-item-8">
Python</label><div class="sd-tab-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [120]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="gp">In [121]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [122]: </span><span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_irm_data</span>

<span class="gp">In [123]: </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">RandomForestRegressor</span>

<span class="gp">In [124]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3141</span><span class="p">)</span>

<span class="gp">In [125]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [126]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [127]: </span><span class="n">data</span> <span class="o">=</span> <span class="n">make_irm_data</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">dim_x</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;DataFrame&#39;</span><span class="p">)</span>

<span class="gp">In [128]: </span><span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

<span class="gp">In [129]: </span><span class="n">dml_cvar_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLCVAR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span> <span class="n">treatment</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">quantile</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="gp">In [130]: </span><span class="n">dml_cvar_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span>
<span class="gh">Out[130]: </span>
<span class="go">       coef   std err          t         P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  1.585192  0.096897  16.359623  3.714182e-60  1.395278  1.775106</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="cvar-treatment-effects">
<h3><span class="section-number">4.5.2. </span>CVaR treatment effects<a class="headerlink" href="#cvar-treatment-effects" title="Permalink to this heading">#</a></h3>
<p>For a quantile <span class="math notranslate nohighlight">\(\tau \in (0,1)\)</span> the target parameter <span class="math notranslate nohighlight">\(\theta_{\tau}\)</span> of interest are the
<strong>treatment effects on the conditional value at risk</strong>,</p>
<div class="math notranslate nohighlight">
\[\theta_{\tau} = \theta_{\tau}(1) - \theta_{\tau}(0)\]</div>
<p>where <span class="math notranslate nohighlight">\(\theta_{\tau}(d)\)</span> denotes the corresponding conditional values at risk
of the potential outcomes.</p>
<p><code class="docutils literal notranslate"><span class="pre">DoubleMLQTE</span></code> implements CVaR treatment effect estimation, if the <code class="docutils literal notranslate"><span class="pre">score</span></code> argument has been set to <code class="docutils literal notranslate"><span class="pre">'CVaR'</span></code> (default is <code class="docutils literal notranslate"><span class="pre">'PQ'</span></code>).
Estimation is conducted via its <code class="docutils literal notranslate"><span class="pre">fit()</span></code> method:</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-9" name="sd-tab-set-9" type="radio">
</input><label class="sd-tab-label" data-sync-id="py" for="sd-tab-item-9">
Python</label><div class="sd-tab-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [131]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="gp">In [132]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [133]: </span><span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_irm_data</span>

<span class="gp">In [134]: </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">RandomForestRegressor</span>

<span class="gp">In [135]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3141</span><span class="p">)</span>

<span class="gp">In [136]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [137]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [138]: </span><span class="n">data</span> <span class="o">=</span> <span class="n">make_irm_data</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">dim_x</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;DataFrame&#39;</span><span class="p">)</span>

<span class="gp">In [139]: </span><span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

<span class="gp">In [140]: </span><span class="n">dml_cvar_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLQTE</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span> <span class="n">score</span><span class="o">=</span><span class="s1">&#39;CVaR&#39;</span><span class="p">,</span> <span class="n">quantiles</span><span class="o">=</span><span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">])</span>

<span class="gp">In [141]: </span><span class="n">dml_cvar_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span>
<span class="gh">Out[141]: </span>
<span class="go">          coef   std err         t         P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">0.25  0.473428  0.244647  1.935145  5.297245e-02 -0.006072  0.952927</span>
<span class="go">0.50  0.694323  0.142952  4.857027  1.191614e-06  0.414142  0.974505</span>
<span class="go">0.75  1.001638  0.165765  6.042534  1.517128e-09  0.676745  1.326530</span>
</pre></div>
</div>
</div>
</div>
<p>A detailed notebook on CVaR estimation for potential outcomes and treatment effects
is available in the <a class="reference internal" href="../examples/index.html#examplegallery"><span class="std std-ref">example gallery</span></a>.</p>
</section>
</section>
<section id="policy-learning-with-trees">
<h2><span class="section-number">4.6. </span>Policy Learning with Trees<a class="headerlink" href="#policy-learning-with-trees" title="Permalink to this heading">#</a></h2>
<p><strong>Policy Learning</strong> considers to find an optimal decision policy. We consider deterministic binary policies, which are defined as mapping</p>
<div class="math notranslate nohighlight">
\[\pi: X\mapsto \{0,1\}.\]</div>
<p>Using the score component <span class="math notranslate nohighlight">\(\psi_b(W_i,\hat{\eta})\)</span> of the <a class="reference internal" href="models.html#irm-model"><span class="std std-ref">IRM</span></a> score,
we can find the optimal treatment policy by solving the weighted classification problem</p>
<div class="math notranslate nohighlight">
\[\hat{\pi} = \mathop{\arg \max}\limits_{\pi\in\Pi} \frac{1}{n}\sum_{i=1}^n(2\pi(X_i)-1)\hat{\psi_b(W_i,\hat{\eta})},\]</div>
<p>where <span class="math notranslate nohighlight">\(\Pi\)</span> denotes a policy class, which we define as depth-<span class="math notranslate nohighlight">\(m\)</span> classification trees.
Thus, we estimate splits in the features <span class="math notranslate nohighlight">\(X\)</span> that reflect the heterogeneity of the treatment effect
and consequently maximize the sum of the estimated individual treatment effects of all individuals by assigning different treatments.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code> class contains the <code class="docutils literal notranslate"><span class="pre">policy_tree()</span></code> method, which enables the estimation of a policy tree
using weighted classification after fitting the <code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code> object. To estimate a policy tree, the user has to specify a pandas <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> containing
the covariates on based on which the policy will make treatment decisions. These can be either the original covariates used in the
<code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code> estimation, or a subset, or new covariates.
This will construct and fit a <code class="docutils literal notranslate"><span class="pre">DoubleMLPolicyTree</span></code> object. A plot of the decision rules can be displayed by the
<code class="docutils literal notranslate"><span class="pre">plot_tree()</span></code> method. The <code class="docutils literal notranslate"><span class="pre">predict()</span></code> method enables the application of the estimated policy on new data.
The <code class="docutils literal notranslate"><span class="pre">depth</span></code> parameter, which defaults to <code class="docutils literal notranslate"><span class="pre">2</span></code>, can be used to adjust the maximum depth of the tree.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-10" name="sd-tab-set-10" type="radio">
</input><label class="sd-tab-label" data-sync-id="py" for="sd-tab-item-10">
Python</label><div class="sd-tab-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [142]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="gp">In [143]: </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="gp">In [144]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [145]: </span><span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_irm_data</span>

<span class="gp">In [146]: </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span><span class="p">,</span> <span class="n">RandomForestClassifier</span>

<span class="gp">In [147]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [148]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [149]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3333</span><span class="p">)</span>

<span class="gp">In [150]: </span><span class="n">data</span> <span class="o">=</span> <span class="n">make_irm_data</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">dim_x</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;DataFrame&#39;</span><span class="p">)</span>

<span class="gp">In [151]: </span><span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

<span class="gp">In [152]: </span><span class="n">dml_irm_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLIRM</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">)</span>

<span class="gp">In [153]: </span><span class="n">_</span> <span class="o">=</span> <span class="n">dml_irm_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="go"># define features to learn policy on</span>
<span class="gp">In [154]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="gp">In [155]: </span><span class="n">features</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s2">&quot;X1&quot;</span><span class="p">,</span><span class="s2">&quot;X2&quot;</span><span class="p">,</span><span class="s2">&quot;X3&quot;</span><span class="p">]]</span>

<span class="gp">In [156]: </span><span class="nb">print</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="go">         X1        X2        X3</span>
<span class="go">0  0.305133  0.497298 -0.811398</span>
<span class="go">1 -0.696770 -1.717860 -2.030087</span>
<span class="go">2 -0.903135  0.174940  0.185585</span>
<span class="go">3  0.095475 -0.653820 -1.800272</span>
<span class="go">4 -0.198953  0.203893  0.204653</span>

<span class="go"># fits a tree of depth 2</span>
<span class="gp">In [157]: </span><span class="n">policy_tree_obj</span> <span class="o">=</span> <span class="n">dml_irm_obj</span><span class="o">.</span><span class="n">policy_tree</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">)</span>

<span class="gp">In [158]: </span><span class="n">policy_tree_obj</span><span class="o">.</span><span class="n">plot_tree</span><span class="p">();</span>
</pre></div>
</div>
</div>
</div>
<p>A more detailed notebook on Policy Trees is available in the <a class="reference internal" href="../examples/index.html#examplegallery"><span class="std std-ref">example gallery</span></a>.</p>
</section>
</section>


                </article>
              
              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="models.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">3. </span>Models</p>
      </div>
    </a>
    <a class="right-next"
       href="scores.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">5. </span>Score functions</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#group-average-treatment-effects-gates">4.1. Group average treatment effects (GATEs)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gates-for-irm-models">4.1.1. GATEs for IRM models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gates-for-plr-models">4.1.2. GATEs for PLR models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-average-treatment-effects-cates">4.2. Conditional average treatment effects (CATEs)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cates-for-irm-models">4.2.1. CATEs for IRM models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cates-for-plr-models">4.2.2. CATEs for PLR models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#weighted-average-treatment-effects">4.3. Weighted Average Treatment Effects</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quantiles">4.4. Quantiles</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#potential-quantiles-pqs">4.4.1. Potential quantiles (PQs)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quantile-treatment-effects-qtes">4.4.2. Quantile treatment effects (QTEs)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-value-at-risk-cvar">4.5. Conditional value at risk (CVaR)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cvar-of-potential-outcomes">4.5.1. CVaR of potential outcomes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cvar-treatment-effects">4.5.2. CVaR treatment effects</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#policy-learning-with-trees">4.6. Policy Learning with Trees</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div class="tocsection sourcelink">
    <a href="../_sources/guide/heterogeneity.rst.txt">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
  <p class="copyright">
    
       Copyright 2023, Bach, P., Chernozhukov, V., Klaassen, S., Kurz, M. S., and Spindler, M..
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">
  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 6.1.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
    <div class="footer-items__end">
      
        <div class="footer-item"><p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.13.3.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>