
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>4. Score functions &#8212; DoubleML  documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "document", "processHtmlClass": "math|output_area"}}</script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5. Double machine learning algorithms" href="algorithms.html" />
    <link rel="prev" title="3. Models" href="models.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
<a class="navbar-brand" href="../index.html">
<p class="title">DoubleML</p>
</a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  DoubleML
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/install.html">
  Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/intro.html">
  Getting started
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="guide.html">
  User guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../examples/index.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api.html">
  Python API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference external nav-link" href="https://docs.doubleml.org/r/stable/">
  R API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../release/release.html">
  Release notes
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><p class="logo" style="text-align:center;"><a href="../index.html">
    <img class="logo" src="../logo.png" alt="Logo" width="65%" height="65%">
</a></p><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="basics.html">
   1.  The basics of double/debiased machine learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="data_backend.html">
   2.  The data-backend DoubleMLData
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="models.html">
   3.  Models
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   4.  Score functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="algorithms.html">
   5.  Double machine learning algorithms
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="learners.html">
   6.  Learners, hyperparameters and hyperparameter tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="se_confint.html">
   7.  Variance estimation and confidence intervals for a causal parameter of interest
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="sim_inf.html">
   8.  Confidence bands and multiplier bootstrap for valid simultaneous inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="resampling.html">
   9.  Sample-splitting, cross-fitting and repeated cross-fitting
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#implementation-of-the-score-function-and-the-estimate-of-the-causal-parameter">
   4.1. Implementation of the score function and the estimate of the causal parameter
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#implemented-neyman-orthogonal-score-functions">
   4.2. Implemented Neyman orthogonal score functions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#partially-linear-regression-model-plr">
     4.2.1. Partially linear regression model (PLR)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#partially-linear-iv-regression-model-pliv">
     4.2.2. Partially linear IV regression model (PLIV)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interactive-regression-model-irm">
     4.2.3. Interactive regression model (IRM)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interactive-iv-model-iivm">
     4.2.4. Interactive IV model (IIVM)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#specifying-alternative-score-functions-via-callables">
   4.3. Specifying alternative score functions via callables
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="score-functions">
<span id="scores"></span><h1><span class="section-number">4. </span>Score functions<a class="headerlink" href="#score-functions" title="Permalink to this headline">¶</a></h1>
<p>We use method-of-moments estimators for the target parameter <span class="math notranslate nohighlight">\(\theta_0\)</span> based upon the empirical analog of the
moment condition</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}[ \psi(W; \theta_0, \eta_0)] = 0,\]</div>
<p>where we call <span class="math notranslate nohighlight">\(\psi\)</span> the <strong>score function</strong>, <span class="math notranslate nohighlight">\(W=(Y,D,X,Z)\)</span>,
<span class="math notranslate nohighlight">\(\theta_0\)</span> is the parameter of interest and
<span class="math notranslate nohighlight">\(\eta\)</span> denotes nuisance functions with population value <span class="math notranslate nohighlight">\(\eta_0\)</span>.
We use score functions <span class="math notranslate nohighlight">\(\psi(W; \theta, \eta)\)</span> that satisfy
<span class="math notranslate nohighlight">\(\mathbb{E}[ \psi(W; \theta_0, \eta_0)] = 0\)</span> with <span class="math notranslate nohighlight">\(\theta_0\)</span> being the unique solution
and that obey the <strong>Neyman orthogonality condition</strong></p>
<div class="math notranslate nohighlight">
\[\partial_{\eta} \mathbb{E}[ \psi(W; \theta_0, \eta)] \bigg|_{\eta=\eta_0} = 0.\]</div>
<p>An integral component for the object-oriented (OOP) implementation of
<code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code>,
<code class="docutils literal notranslate"><span class="pre">DoubleMLPLIV</span></code>,
<code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code>,
and <code class="docutils literal notranslate"><span class="pre">DoubleMLIIVM</span></code>
is the linearity of the score function in the parameter <span class="math notranslate nohighlight">\(\theta\)</span></p>
<div class="math notranslate nohighlight">
\[\psi(W; \theta, \eta) = \psi_a(W; \eta) \theta + \psi_b(W; \eta).\]</div>
<p>Hence the estimator can be written as</p>
<div class="math notranslate nohighlight">
\[\tilde{\theta}_0 = - \frac{\mathbb{E}_N[\psi_b(W; \eta)]}{\mathbb{E}_N[\psi_a(W; \eta)]}.\]</div>
<p>The linearity of the score function in the parameter <span class="math notranslate nohighlight">\(\theta\)</span> allows the implementation of key components in a very
general way.
The methods and algorithms to estimate the causal parameters, to estimate their standard errors, to perform a multiplier
bootstrap, to obtain confidence intervals and many more are implemented in the abstract base class <code class="docutils literal notranslate"><span class="pre">DoubleML</span></code>.
The object-oriented architecture therefore allows for easy extension to new model classes for double machine learning.
This is doable with very minor effort whenever the linearity of the score function is satisfied.</p>
<div class="section" id="implementation-of-the-score-function-and-the-estimate-of-the-causal-parameter">
<h2><span class="section-number">4.1. </span>Implementation of the score function and the estimate of the causal parameter<a class="headerlink" href="#implementation-of-the-score-function-and-the-estimate-of-the-causal-parameter" title="Permalink to this headline">¶</a></h2>
<p>As an example we consider a partially linear regression model (PLR)
implemented in <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code>.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="0b1d4925-d973-47f0-921d-faf679c0dec1" name="493d0c15-8c77-47d0-87cb-13e54d925d8e" type="radio">
</input><label class="tabbed-label" for="0b1d4925-d973-47f0-921d-faf679c0dec1">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [2]: </span><span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_plr_CCDDHNR2018</span>

<span class="gp">In [3]: </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="gp">In [4]: </span><span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">clone</span>

<span class="gp">In [5]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3141</span><span class="p">)</span>

<span class="gp">In [6]: </span><span class="n">learner</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [7]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">learner</span><span class="p">)</span>

<span class="gp">In [8]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">learner</span><span class="p">)</span>

<span class="gp">In [9]: </span><span class="n">data</span> <span class="o">=</span> <span class="n">make_plr_CCDDHNR2018</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;DataFrame&#39;</span><span class="p">)</span>

<span class="gp">In [10]: </span><span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

<span class="gp">In [11]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">)</span>

<span class="gp">In [12]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">();</span>

<span class="gp">In [13]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="p">)</span>
<span class="go">================== DoubleMLPLR Object ==================</span>

<span class="go">------------------ Data summary      ------------------</span>
<span class="go">Outcome variable: y</span>
<span class="go">Treatment variable(s): [&#39;d&#39;]</span>
<span class="go">Covariates: [&#39;X1&#39;, &#39;X2&#39;, &#39;X3&#39;, &#39;X4&#39;, &#39;X5&#39;, &#39;X6&#39;, &#39;X7&#39;, &#39;X8&#39;, &#39;X9&#39;, &#39;X10&#39;, &#39;X11&#39;, &#39;X12&#39;, &#39;X13&#39;, &#39;X14&#39;, &#39;X15&#39;, &#39;X16&#39;, &#39;X17&#39;, &#39;X18&#39;, &#39;X19&#39;, &#39;X20&#39;]</span>
<span class="go">Instrument variable(s): None</span>
<span class="go">No. Observations: 500</span>

<span class="go">------------------ Score &amp; algorithm ------------------</span>
<span class="go">Score function: partialling out</span>
<span class="go">DML algorithm: dml2</span>

<span class="go">------------------ Machine learner   ------------------</span>
<span class="go">Learner ml_g: RandomForestRegressor(max_depth=5, max_features=20, min_samples_leaf=2)</span>
<span class="go">Learner ml_m: RandomForestRegressor(max_depth=5, max_features=20, min_samples_leaf=2)</span>

<span class="go">------------------ Resampling        ------------------</span>
<span class="go">No. folds: 5</span>
<span class="go">No. repeated sample splits: 1</span>
<span class="go">Apply cross-fitting: True</span>

<span class="go">------------------ Fit summary       ------------------</span>
<span class="go">      coef   std err          t         P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.46281  0.041056  11.272759  1.788763e-29  0.382342  0.543277</span>
</pre></div>
</div>
</div>
<input id="08ed0775-8191-49c5-a739-b869c52d0874" name="493d0c15-8c77-47d0-87cb-13e54d925d8e" type="radio">
</input><label class="tabbed-label" for="08ed0775-8191-49c5-a739-b869c52d0874">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span>library(DoubleML)
<span class="linenos"> 2</span>library(mlr3)
<span class="linenos"> 3</span>library(mlr3learners)
<span class="linenos"> 4</span>library(data.table)
<span class="linenos"> 5</span>lgr::get_logger(&quot;mlr3&quot;)$set_threshold(&quot;warn&quot;)
<span class="linenos"> 6</span>
<span class="linenos"> 7</span>learner = lrn(&quot;regr.ranger&quot;, num.trees = 100, mtry = 20, min.node.size = 2, max.depth = 5)
<span class="linenos"> 8</span>ml_g = learner$clone()
<span class="linenos"> 9</span>ml_m = learner$clone()
<span class="linenos">10</span>set.seed(3141)
<span class="linenos">11</span>data = make_plr_CCDDHNR2018(alpha=0.5, return_type=&#39;data.table&#39;)
<span class="linenos">12</span>obj_dml_data = DoubleMLData$new(data, y_col=&quot;y&quot;, d_cols=&quot;d&quot;)
<span class="linenos">13</span>dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m)
<span class="linenos">14</span>dml_plr_obj$fit()
<span class="linenos">15</span>print(dml_plr_obj)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>================= DoubleMLPLR Object ==================


------------------ Data summary      ------------------
Outcome variable: y
Treatment variable(s): d
Covariates: X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15, X16, X17, X18, X19, X20
Instrument(s): 
No. Observations: 500

------------------ Score &amp; algorithm ------------------
Score function: partialling out
DML algorithm: dml2

------------------ Machine learner   ------------------
ml_g: regr.ranger
ml_m: regr.ranger

------------------ Resampling        ------------------
No. folds: 5
No. repeated sample splits: 1
Apply cross-fitting: TRUE

------------------ Fit summary       ------------------
 [1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.54440    0.04512   12.06   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">fit()</span></code> method of <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code>
stores the estimate <span class="math notranslate nohighlight">\(\tilde{\theta}_0\)</span> in its <code class="docutils literal notranslate"><span class="pre">coef</span></code> attribute.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="c39a879f-1e6e-4e45-a784-3e9c92dc9a68" name="f8567451-f65c-46f4-b219-2c697ccb276c" type="radio">
</input><label class="tabbed-label" for="c39a879f-1e6e-4e45-a784-3e9c92dc9a68">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [14]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">coef</span><span class="p">)</span>
<span class="go">[0.46280962]</span>
</pre></div>
</div>
</div>
<input id="81b76b46-1ea9-418a-a290-254aa6317a3b" name="f8567451-f65c-46f4-b219-2c697ccb276c" type="radio">
</input><label class="tabbed-label" for="81b76b46-1ea9-418a-a290-254aa6317a3b">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span>print(dml_plr_obj$coef)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>        d 
0.5443965 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>The values of the score function components <span class="math notranslate nohighlight">\(\psi_a(W_i; \hat{\eta}_0)\)</span> and <span class="math notranslate nohighlight">\(\psi_b(W_i; \hat{\eta}_0)\)</span>
are stored in the attributes <code class="docutils literal notranslate"><span class="pre">psi_a</span></code> and <code class="docutils literal notranslate"><span class="pre">psi_b</span></code>.
In the attribute <code class="docutils literal notranslate"><span class="pre">psi</span></code> the values of the score function <span class="math notranslate nohighlight">\(\psi(W_i; \tilde{\theta}_0, \hat{\eta}_0)\)</span> are stored.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="e91f692d-8b45-433c-bf0d-bbef734c4040" name="f19be037-4c72-4cd2-a585-58f22db1583a" type="radio">
</input><label class="tabbed-label" for="e91f692d-8b45-433c-bf0d-bbef734c4040">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [15]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">psi</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="go">[[[-0.1535136 ]]</span>

<span class="go"> [[ 0.02031477]]</span>

<span class="go"> [[ 0.00576119]]</span>

<span class="go"> [[ 0.07983212]]</span>

<span class="go"> [[-0.23144641]]]</span>
</pre></div>
</div>
</div>
<input id="bcc2605e-7af1-4dae-aa54-cf3fa9ea1f26" name="f19be037-4c72-4cd2-a585-58f22db1583a" type="radio">
</input><label class="tabbed-label" for="bcc2605e-7af1-4dae-aa54-cf3fa9ea1f26">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span>print(dml_plr_obj$psi[1:5, ,1])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] -0.0009695237  0.7811465543  0.0090193584 -0.4037269089  0.8646627426
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="implemented-neyman-orthogonal-score-functions">
<h2><span class="section-number">4.2. </span>Implemented Neyman orthogonal score functions<a class="headerlink" href="#implemented-neyman-orthogonal-score-functions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="partially-linear-regression-model-plr">
<h3><span class="section-number">4.2.1. </span>Partially linear regression model (PLR)<a class="headerlink" href="#partially-linear-regression-model-plr" title="Permalink to this headline">¶</a></h3>
<p>For the PLR model implemented in <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code> one can choose between
<code class="docutils literal notranslate"><span class="pre">score='IV-type'</span></code> and <code class="docutils literal notranslate"><span class="pre">score='partialling</span> <span class="pre">out'</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">score='IV-type'</span></code> implements the score function:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\psi(W; \theta, \eta) &amp;:= [Y - D \theta - g(X)] [D - m(X)]\\&amp;= - D (D - m(X)) \theta + (Y - g(X)) (D - m(X))\\&amp;= \psi_a(W; \eta) \theta + \psi_b(W; \eta)\end{aligned}\end{align} \]</div>
<p>with <span class="math notranslate nohighlight">\(\eta=(g,m)\)</span> and where the components of the linear score are</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\psi_a(W; \eta) &amp;=  - D (D - m(X)),\\\psi_b(W; \eta) &amp;= (Y - g(X)) (D - m(X)).\end{aligned}\end{align} \]</div>
<p><code class="docutils literal notranslate"><span class="pre">score='partialling</span> <span class="pre">out'</span></code> implements the score function:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\psi(W; \theta, \eta) &amp;:= [Y - \ell(X) - \theta (D - m(X))] [D - m(X)]\\&amp;= - (D - m(X)) (D - m(X)) \theta + (Y - \ell(X)) (D - m(X))\\&amp;= \psi_a(W; \eta) \theta + \psi_b(W; \eta)\end{aligned}\end{align} \]</div>
<p>with <span class="math notranslate nohighlight">\(\eta=(\ell,m)\)</span> and where the components of the linear score are</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\psi_a(W; \eta) &amp;=  - (D - m(X)) (D - m(X)),\\\psi_b(W; \eta) &amp;= (Y - \ell(X)) (D - m(X)).\end{aligned}\end{align} \]</div>
</div>
<div class="section" id="partially-linear-iv-regression-model-pliv">
<h3><span class="section-number">4.2.2. </span>Partially linear IV regression model (PLIV)<a class="headerlink" href="#partially-linear-iv-regression-model-pliv" title="Permalink to this headline">¶</a></h3>
<p>For the PLIV model implemented in <code class="docutils literal notranslate"><span class="pre">DoubleMLPLIV</span></code>
we employ for <code class="docutils literal notranslate"><span class="pre">score='partialling</span> <span class="pre">out'</span></code> the score function:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\psi(W; \theta, \eta) &amp;:= [Y - \ell(X) - \theta (D - r(X))] [Z - m(X)]\\&amp;= - (D - r(X)) (Z - m(X)) \theta + (Y - \ell(X)) (Z - m(X))\\&amp;= \psi_a(W; \eta) \theta + \psi_b(W; \eta)\end{aligned}\end{align} \]</div>
<p>with <span class="math notranslate nohighlight">\(\eta=(\ell, m, r)\)</span> and where the components of the linear score are</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\psi_a(W; \eta) &amp;=  - (D - r(X)) (Z - m(X)),\\\psi_b(W; \eta) &amp;= (Y - \ell(X)) (Z - m(X)).\end{aligned}\end{align} \]</div>
</div>
<div class="section" id="interactive-regression-model-irm">
<h3><span class="section-number">4.2.3. </span>Interactive regression model (IRM)<a class="headerlink" href="#interactive-regression-model-irm" title="Permalink to this headline">¶</a></h3>
<p>For the IRM model implemented in <code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code> one can choose between
<code class="docutils literal notranslate"><span class="pre">score='ATE'</span></code> and <code class="docutils literal notranslate"><span class="pre">score='ATTE'</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">score='ATE'</span></code> implements the score function:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\psi(W; \theta, \eta) &amp;:= g(1,X) - g(0,X) + \frac{D (Y - g(1,X))}{m(X)} - \frac{(1 - D)(Y - g(0,X))}{1 - m(x)} - \theta\\&amp;= \psi_a(W; \eta) \theta + \psi_b(W; \eta)\end{aligned}\end{align} \]</div>
<p>with <span class="math notranslate nohighlight">\(\eta=(g,m)\)</span> and where the components of the linear score are</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\psi_a(W; \eta) &amp;=  - 1,\\\psi_b(W; \eta) &amp;= g(1,X) - g(0,X) + \frac{D (Y - g(1,X))}{m(X)} - \frac{(1 - D)(Y - g(0,X))}{1 - m(x)}.\end{aligned}\end{align} \]</div>
<p><code class="docutils literal notranslate"><span class="pre">score='ATTE'</span></code> implements the score function:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\psi(W; \theta, \eta) &amp;:= \frac{D (Y - g(0,X))}{p} - \frac{m(X) (1 - D) (Y - g(0,X))}{p(1 - m(x))} - \frac{D}{p} \theta\\&amp;= \psi_a(W; \eta) \theta + \psi_b(W; \eta)\end{aligned}\end{align} \]</div>
<p>with <span class="math notranslate nohighlight">\(\eta=(g, m, p)\)</span> and where the components of the linear score are</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\psi_a(W; \eta) &amp;=  - \frac{D}{p},\\\psi_b(W; \eta) &amp;= \frac{D (Y - g(0,X))}{p} - \frac{m(X) (1 - D) (Y - g(0,X))}{p(1 - m(X))}.\end{aligned}\end{align} \]</div>
</div>
<div class="section" id="interactive-iv-model-iivm">
<h3><span class="section-number">4.2.4. </span>Interactive IV model (IIVM)<a class="headerlink" href="#interactive-iv-model-iivm" title="Permalink to this headline">¶</a></h3>
<p>For the IIVM model implemented in <code class="docutils literal notranslate"><span class="pre">DoubleMLIIVM</span></code>
we employ for <code class="docutils literal notranslate"><span class="pre">score='LATE'</span></code> the score function:</p>
<p><code class="docutils literal notranslate"><span class="pre">score='LATE'</span></code> implements the score function:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\psi(W; \theta, \eta) :=\; &amp;g(1,X) - g(0,X)
+ \frac{Z (Y - g(1,X))}{m(X)} - \frac{(1 - Z)(Y - g(0,X))}{1 - m(x)}\\&amp;- \bigg(r(1,X) - r(0,X) + \frac{Z (D - r(1,X))}{m(X)} - \frac{(1 - Z)(D - r(0,X))}{1 - m(x)} \bigg) \theta\\=\; &amp;\psi_a(W; \eta) \theta + \psi_b(W; \eta)\end{aligned}\end{align} \]</div>
<p>with <span class="math notranslate nohighlight">\(\eta=(g, m, r)\)</span> and where the components of the linear score are</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\psi_a(W; \eta) &amp;=  - \bigg(r(1,X) - r(0,X) + \frac{Z (D - r(1,X))}{m(X)} - \frac{(1 - Z)(D - r(0,X))}{1 - m(x)} \bigg),\\\psi_b(W; \eta) &amp;= g(1,X) - g(0,X) + \frac{Z (Y - g(1,X))}{m(X)} - \frac{(1 - Z)(Y - g(0,X))}{1 - m(x)}.\end{aligned}\end{align} \]</div>
</div>
</div>
<div class="section" id="specifying-alternative-score-functions-via-callables">
<h2><span class="section-number">4.3. </span>Specifying alternative score functions via callables<a class="headerlink" href="#specifying-alternative-score-functions-via-callables" title="Permalink to this headline">¶</a></h2>
<p>Via callables user-written score functions can be used.
This functionality is at the moment only implemented for specific model classes in Python.
For the PLR model implemented in <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code> an alternative score function can be
set via <code class="docutils literal notranslate"><span class="pre">score</span></code>.
Choose a callable object / function with signature <code class="docutils literal notranslate"><span class="pre">score(y,</span> <span class="pre">d,</span> <span class="pre">g_hat,</span> <span class="pre">m_hat,</span> <span class="pre">smpls)</span></code> which returns
the two score components <span class="math notranslate nohighlight">\(\psi_a()\)</span> and <span class="math notranslate nohighlight">\(\psi_b()\)</span>.</p>
<p>For example, the non-orthogonal score function</p>
<div class="math notranslate nohighlight">
\[\psi(W; \theta, \eta) = [Y - D \theta - g(X)] D\]</div>
<p>can be obtained with</p>
<div class="tabbed-set docutils">
<input checked="checked" id="7ef2832c-3f3d-4708-9bcb-b4eb51d35980" name="1b2fb270-b2d0-467e-a859-a80c3bcf5cba" type="radio">
</input><label class="tabbed-label" for="7ef2832c-3f3d-4708-9bcb-b4eb51d35980">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [16]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="gp">In [17]: </span><span class="k">def</span> <span class="nf">non_orth_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">g_hat</span><span class="p">,</span> <span class="n">m_hat</span><span class="p">,</span> <span class="n">smpls</span><span class="p">):</span>
<span class="gp">   ....: </span>    <span class="n">u_hat</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">g_hat</span>
<span class="gp">   ....: </span>    <span class="n">psi_a</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
<span class="gp">   ....: </span>    <span class="n">psi_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">u_hat</span><span class="p">)</span>
<span class="gp">   ....: </span>    <span class="k">return</span> <span class="n">psi_a</span><span class="p">,</span> <span class="n">psi_b</span>
<span class="gp">   ....: </span>
</pre></div>
</div>
</div>
<input id="8e541d5c-cf0b-461c-ad76-e3da5b62fe10" name="1b2fb270-b2d0-467e-a859-a80c3bcf5cba" type="radio">
</input><label class="tabbed-label" for="8e541d5c-cf0b-461c-ad76-e3da5b62fe10">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="n">non_orth_score</span> <span class="o">=</span> <span class="n">function</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">g_hat</span><span class="p">,</span> <span class="n">m_hat</span><span class="p">,</span> <span class="n">smpls</span><span class="p">)</span> <span class="p">{</span>
<span class="linenos">2</span>    <span class="n">u_hat</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">g_hat</span>
<span class="linenos">3</span>    <span class="n">psi_a</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">d</span><span class="o">*</span><span class="n">d</span>
<span class="linenos">4</span>    <span class="n">psi_b</span> <span class="o">=</span> <span class="n">d</span><span class="o">*</span><span class="n">u_hat</span>
<span class="linenos">5</span>    <span class="n">psis</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">psi_a</span> <span class="o">=</span> <span class="n">psi_a</span><span class="p">,</span> <span class="n">psi_b</span> <span class="o">=</span> <span class="n">psi_b</span><span class="p">)</span>
<span class="linenos">6</span>    <span class="k">return</span><span class="p">(</span><span class="n">psis</span><span class="p">)</span>
<span class="linenos">7</span><span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
</div>
</div>
<p>Use <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code> with <code class="docutils literal notranslate"><span class="pre">inf_model=non_orth_score</span></code> in order to obtain the estimator</p>
<div class="math notranslate nohighlight">
\[\tilde{\theta}_0 = - \frac{\mathbb{E}_N[D (Y-g(X))]}{\mathbb{E}_N[D^2]}\]</div>
<p>when applying <code class="docutils literal notranslate"><span class="pre">fit()</span></code>.
Note that this estimate will in general be prone to a regularization bias, see also <a class="reference internal" href="basics.html#bias-non-orth"><span class="std std-ref">Overcoming regularization bias by orthogonalization</span></a>.</p>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="models.html" title="previous page"><span class="section-number">3. </span>Models</a>
    <a class='right-next' id="next-link" href="algorithms.html" title="next page"><span class="section-number">5. </span>Double machine learning algorithms</a>

              </div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.0.3.<br/>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>