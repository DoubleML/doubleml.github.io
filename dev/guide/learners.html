
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>6. Learners, hyperparameters and hyperparameter tuning &#8212; DoubleML 0.0.1 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="7. Variance estimation, confidence intervals and multiplier bootstrap" href="se_confint.html" />
    <link rel="prev" title="5. Double machine learning algorithms" href="algorithms.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="guide.html"> User guide</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../auto_examples/index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="http://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
          
            
                <li class="">
                    <a href="basics.html"> The basics of double/debiased machine learning</a>
                </li>
            
          
            
                <li class="">
                    <a href="data_backend.html"> The data-backend DoubleMLData</a>
                </li>
            
          
            
                <li class="">
                    <a href="models.html"> Models</a>
                </li>
            
          
            
                <li class="">
                    <a href="scores.html"> Score functions</a>
                </li>
            
          
            
                <li class="">
                    <a href="algorithms.html"> Double machine learning algorithms</a>
                </li>
            
          
            
                <li class="active">
                    <a href=""> Machine learners, hyperparameters and hyperparameter tuning</a>
                </li>
            
          
            
                <li class="">
                    <a href="se_confint.html"> Variance estimation, confidence intervals and boostrap standard errors</a>
                </li>
            
          
            
                <li class="">
                    <a href="resampling.html"> Sample-splitting, cross-fitting and repeated cross-fitting</a>
                </li>
            
          
        
        
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#python-learners-and-hyperparameters" class="nav-link">Python: Learners and hyperparameters</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#minimum-requirements-for-learners" class="nav-link">Minimum requirements for learners</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#specifying-learners-and-set-hyperparameters" class="nav-link">Specifying learners and set hyperparameters</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#hyperparameter-tuning" class="nav-link">Hyperparameter tuning</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#r-learners-and-hyperparameters" class="nav-link">R: Learners and hyperparameters</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#id2" class="nav-link">Minimum requirements for learners</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#id6" class="nav-link">Specifying learners and set hyperparameters</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#id7" class="nav-link">Hyperparameter tuning</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#references" class="nav-link">References</a>
        </li>
    
            </ul>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="learners-hyperparameters-and-hyperparameter-tuning">
<span id="learners"></span><h1><span class="section-number">6. </span>Learners, hyperparameters and hyperparameter tuning<a class="headerlink" href="#learners-hyperparameters-and-hyperparameter-tuning" title="Permalink to this headline">¶</a></h1>
<p>The estimation of a double/debiased machine learning model involves the estimation of several nuisance function with
machine learning estimators.
Such learners are implemented in various Python and R packages.
The implementation of <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> is based on the meta-packages
<a class="reference external" href="https://scikit-learn.org/">scikit-learn</a> for Python and <a class="reference external" href="https://mlr3.mlr-org.com/">mlr3</a> for R.
The interfaces to specify the learners, set hyperparameters and tune hyperparameters are described in the following
separately for <a class="reference internal" href="#learners-python"><span class="std std-ref">Python</span></a> and <a class="reference internal" href="#learners-r"><span class="std std-ref">R</span></a>.</p>
<div class="section" id="python-learners-and-hyperparameters">
<span id="learners-python"></span><h2><span class="section-number">6.1. </span>Python: Learners and hyperparameters<a class="headerlink" href="#python-learners-and-hyperparameters" title="Permalink to this headline">¶</a></h2>
<div class="section" id="minimum-requirements-for-learners">
<h3><span class="section-number">6.1.1. </span>Minimum requirements for learners<a class="headerlink" href="#minimum-requirements-for-learners" title="Permalink to this headline">¶</a></h3>
<p>The minimum requirement for a learner to be used for nuisance models in the <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a>
package is</p>
<blockquote>
<div><ul class="simple">
<li><p>The implementation of a <code class="docutils literal notranslate"><span class="pre">fit()</span></code> and <code class="docutils literal notranslate"><span class="pre">predict()</span></code> method.
Some models, like <a class="reference internal" href="../api/generated/doubleml.DoubleMLIRM.html#doubleml.DoubleMLIRM" title="doubleml.DoubleMLIRM"><code class="xref py py-class docutils literal notranslate"><span class="pre">doubleml.DoubleMLIRM</span></code></a> and <a class="reference internal" href="../api/generated/doubleml.DoubleMLIIVM.html#doubleml.DoubleMLIIVM" title="doubleml.DoubleMLIIVM"><code class="xref py py-class docutils literal notranslate"><span class="pre">doubleml.DoubleMLIIVM</span></code></a> require classifiers.</p></li>
<li><p>In case of classifiers, the learner needs to come with a <code class="docutils literal notranslate"><span class="pre">predict_proba()</span></code> instead of, or in addition to, a
<code class="docutils literal notranslate"><span class="pre">predict()</span></code> method, see for example <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict_proba" title="(in scikit-learn v0.23)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sklearn.ensemble.RandomForestClassifier.predict_proba()</span></code></a>.</p></li>
<li><p>In order to be able to use the <code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params()</span></code> method of <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> classes the
learner additionally needs to come with a <code class="docutils literal notranslate"><span class="pre">set_params()</span></code> method,
see for example <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor.set_params" title="(in scikit-learn v0.23)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sklearn.ensemble.RandomForestRegressor.set_params()</span></code></a>.</p></li>
<li><p>We further rely on the function <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="(in scikit-learn v0.23)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.base.clone()</span></code></a> which adds the requirement of a <code class="docutils literal notranslate"><span class="pre">get_params()</span></code>
method for a learner in order to be used for nuisance models of <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> model classes.</p></li>
</ul>
</div></blockquote>
<p>Most learners from <a class="reference external" href="https://scikit-learn.org/">scikit-learn</a> satisfy all these minimum requirements.</p>
</div>
<div class="section" id="specifying-learners-and-set-hyperparameters">
<h3><span class="section-number">6.1.2. </span>Specifying learners and set hyperparameters<a class="headerlink" href="#specifying-learners-and-set-hyperparameters" title="Permalink to this headline">¶</a></h3>
<p>The learners are set during initialization of the <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> model classes
<a class="reference internal" href="../api/generated/doubleml.DoubleMLPLR.html#doubleml.DoubleMLPLR" title="doubleml.DoubleMLPLR"><code class="xref py py-class docutils literal notranslate"><span class="pre">doubleml.DoubleMLPLR</span></code></a>, <a class="reference internal" href="../api/generated/doubleml.DoubleMLPLIV.html#doubleml.DoubleMLPLIV" title="doubleml.DoubleMLPLIV"><code class="xref py py-class docutils literal notranslate"><span class="pre">doubleml.DoubleMLPLIV</span></code></a>,
<a class="reference internal" href="../api/generated/doubleml.DoubleMLIRM.html#doubleml.DoubleMLIRM" title="doubleml.DoubleMLIRM"><code class="xref py py-class docutils literal notranslate"><span class="pre">doubleml.DoubleMLIRM</span></code></a> and <a class="reference internal" href="../api/generated/doubleml.DoubleMLIIVM.html#doubleml.DoubleMLIIVM" title="doubleml.DoubleMLIIVM"><code class="xref py py-class docutils literal notranslate"><span class="pre">doubleml.DoubleMLIIVM</span></code></a>.
Lets simulate some data and consider the partially linear regression model.
We need to specify learners for the nuisance functions <span class="math notranslate nohighlight">\(g_0(X) = E[Y|X]\)</span> and <span class="math notranslate nohighlight">\(m_0(X) = E[D|X]\)</span>,
for example <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="(in scikit-learn v0.23)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.ensemble.RandomForestRegressor</span></code></a>.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="a6a6098d-f33c-4366-b238-8d1fe3dfb01d" name="5a205d09-f31b-48e8-8afa-cac3d3d7854b" type="radio">
</input><label class="tabbed-label" for="a6a6098d-f33c-4366-b238-8d1fe3dfb01d">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [2]: </span><span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_plr_CCDDHNR2018</span>

<span class="gp">In [3]: </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="gp">In [4]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="gp">In [5]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span>

<span class="gp">In [6]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span>

<span class="gp">In [7]: </span><span class="n">data</span> <span class="o">=</span> <span class="n">make_plr_CCDDHNR2018</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;DataFrame&#39;</span><span class="p">)</span>

<span class="gp">In [8]: </span><span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

<span class="gp">In [9]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">)</span>

<span class="gp">In [10]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span>
<span class="gh">Out[10]: </span><span class="go"></span>
<span class="go">       coef   std err          t         P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.542965  0.044017  12.335291  5.847747e-35  0.456693  0.629238</span>
</pre></div>
</div>
</div>
</div>
<p>Setting hyperparameters:</p>
<blockquote>
<div><ul class="simple">
<li><p>We can also use pre-parametrized learners, like <code class="docutils literal notranslate"><span class="pre">RandomForestRegressor(n_estimators=10)</span></code>.</p></li>
<li><p>Alternatively, hyperparameters can also be set after initialization via the method
<code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params(learner,</span> <span class="pre">treat_var,</span> <span class="pre">params)</span></code></p></li>
</ul>
</div></blockquote>
<div class="tabbed-set docutils">
<input checked="checked" id="d9431679-a07d-4e94-91b7-9310dfcb9179" name="08710295-20da-4a5c-8eee-28d09162fb5f" type="radio">
</input><label class="tabbed-label" for="d9431679-a07d-4e94-91b7-9310dfcb9179">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [11]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="gp">In [12]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
<span class="gp">   ....: </span>                              <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
<span class="gp">   ....: </span>                              <span class="n">RandomForestRegressor</span><span class="p">())</span>
<span class="gp">   ....: </span>

<span class="gp">In [13]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err          t         P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.566931  0.042581  13.314033  1.918401e-40  0.483473  0.650389</span>

<span class="gp">In [14]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="gp">In [15]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
<span class="gp">   ....: </span>                              <span class="n">RandomForestRegressor</span><span class="p">(),</span>
<span class="gp">   ....: </span>                              <span class="n">RandomForestRegressor</span><span class="p">())</span>
<span class="gp">   ....: </span>

<span class="gp">In [16]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">set_ml_nuisance_params</span><span class="p">(</span><span class="s1">&#39;ml_g&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">});</span>

<span class="gp">In [17]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err          t         P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.566931  0.042581  13.314033  1.918401e-40  0.483473  0.650389</span>
</pre></div>
</div>
</div>
</div>
<p>Setting treatment-variable-specific or fold-specific hyperparameters:</p>
<blockquote>
<div><ul class="simple">
<li><p>In the multiple-treatment case, the method <code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params(learner,</span> <span class="pre">treat_var,</span> <span class="pre">params)</span></code> allows to set
different hyperparameters for different treatment variables.</p></li>
<li><p>The method <code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params(learner,</span> <span class="pre">treat_var,</span> <span class="pre">params)</span></code> accepts dicts and lists for <code class="docutils literal notranslate"><span class="pre">params</span></code>.
A dict should be provided if for each fold the same hyperparameters should be used.
Fold-specific parameters are supported. To do so,  provide a nested list as <code class="docutils literal notranslate"><span class="pre">params</span></code>, where the outer list is of
length <code class="docutils literal notranslate"><span class="pre">n_rep</span></code> and the inner list of length <code class="docutils literal notranslate"><span class="pre">n_folds</span></code>.</p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="hyperparameter-tuning">
<h3><span class="section-number">6.1.3. </span>Hyperparameter tuning<a class="headerlink" href="#hyperparameter-tuning" title="Permalink to this headline">¶</a></h3>
<p>Parameter tuning of learners for the nuisance functions of <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> models can be done via
the <code class="docutils literal notranslate"><span class="pre">tune()</span></code> method.
To illustrate the parameter tuning, we generate data from a sparse partially linear regression model.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="43775c4e-2dd9-4981-b8e5-2df511da0c95" name="5eafb100-d862-4bd6-89ca-5b1c0d9d9c06" type="radio">
</input><label class="tabbed-label" for="43775c4e-2dd9-4981-b8e5-2df511da0c95">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [18]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [19]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="gp">In [20]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3141</span><span class="p">)</span>

<span class="gp">In [21]: </span><span class="n">n_obs</span> <span class="o">=</span> <span class="mi">200</span>

<span class="gp">In [22]: </span><span class="n">n_vars</span> <span class="o">=</span> <span class="mi">200</span>

<span class="gp">In [23]: </span><span class="n">theta</span> <span class="o">=</span> <span class="mi">3</span>

<span class="gp">In [24]: </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_obs</span><span class="p">,</span> <span class="n">n_vars</span><span class="p">))</span>

<span class="gp">In [25]: </span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]))</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_obs</span><span class="p">,))</span>

<span class="gp">In [26]: </span><span class="n">y</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">*</span> <span class="n">d</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]))</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_obs</span><span class="p">,))</span>

<span class="gp">In [27]: </span><span class="n">dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The hyperparameter-tuning is performed using either an exhaustive search over specified parameter values
implemented in <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="(in scikit-learn v0.23)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection.GridSearchCV</span></code></a> or via a randomized search implemented in
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV" title="(in scikit-learn v0.23)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection.RandomizedSearchCV</span></code></a>.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="b976b73f-5096-437a-9200-9da5433fa935" name="121fb5dd-e37a-4454-a617-85979fdcec0c" type="radio">
</input><label class="tabbed-label" for="b976b73f-5096-437a-9200-9da5433fa935">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [28]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [29]: </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span>

<span class="gp">In [30]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">()</span>

<span class="gp">In [31]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">()</span>

<span class="gp">In [32]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">)</span>

<span class="gp">In [33]: </span><span class="n">par_grids</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;ml_g&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)},</span>
<span class="gp">   ....: </span>             <span class="s1">&#39;ml_m&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)}}</span>
<span class="gp">   ....: </span>

<span class="gp">In [34]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span><span class="n">par_grids</span><span class="p">,</span> <span class="n">search_mode</span><span class="o">=</span><span class="s1">&#39;grid_search&#39;</span><span class="p">);</span>

<span class="gp">In [35]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
<span class="go">{&#39;ml_g&#39;: {&#39;d&#39;: [[{&#39;alpha&#39;: 0.45000000000000007}, {&#39;alpha&#39;: 0.45000000000000007}, {&#39;alpha&#39;: 0.45000000000000007}, {&#39;alpha&#39;: 0.45000000000000007}, {&#39;alpha&#39;: 0.45000000000000007}]]}, &#39;ml_m&#39;: {&#39;d&#39;: [[{&#39;alpha&#39;: 0.15000000000000002}, {&#39;alpha&#39;: 0.15000000000000002}, {&#39;alpha&#39;: 0.15000000000000002}, {&#39;alpha&#39;: 0.15000000000000002}, {&#39;alpha&#39;: 0.15000000000000002}]]}}</span>

<span class="gp">In [36]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err          t  P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  3.031134  0.071777  42.229759    0.0  2.890454  3.171815</span>

<span class="gp">In [37]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="gp">In [38]: </span><span class="n">par_grids</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;ml_g&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)},</span>
<span class="gp">   ....: </span>             <span class="s1">&#39;ml_m&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)}}</span>
<span class="gp">   ....: </span>

<span class="gp">In [39]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span><span class="n">par_grids</span><span class="p">,</span> <span class="n">search_mode</span><span class="o">=</span><span class="s1">&#39;randomized_search&#39;</span><span class="p">,</span> <span class="n">n_iter_randomized_search</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span>

<span class="gp">In [40]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
<span class="go">{&#39;ml_g&#39;: {&#39;d&#39;: [[{&#39;alpha&#39;: 0.4000000000000001}, {&#39;alpha&#39;: 0.4000000000000001}, {&#39;alpha&#39;: 0.4000000000000001}, {&#39;alpha&#39;: 0.4000000000000001}, {&#39;alpha&#39;: 0.4000000000000001}]]}, &#39;ml_m&#39;: {&#39;d&#39;: [[{&#39;alpha&#39;: 0.09000000000000001}, {&#39;alpha&#39;: 0.09000000000000001}, {&#39;alpha&#39;: 0.09000000000000001}, {&#39;alpha&#39;: 0.09000000000000001}, {&#39;alpha&#39;: 0.09000000000000001}]]}}</span>

<span class="gp">In [41]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">      coef   std err          t          P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  2.96582  0.086679  34.216207  1.388216e-256  2.795932  3.135707</span>
</pre></div>
</div>
</div>
</div>
<p>Hyperparameter tuning can also be done with more sophisticated methods, like for example an iterative fitting along
a regularization path implemented in <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV" title="(in scikit-learn v0.23)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.linear_model.LassoCV</span></code></a>.
In this case the tuning should be done externally and the parameters can then be set via the
<code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params()</span></code> method.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="ea154843-0946-4b65-a3eb-dac3cb7107ae" name="20721e1a-b478-469f-958d-975705d3b972" type="radio">
</input><label class="tabbed-label" for="ea154843-0946-4b65-a3eb-dac3cb7107ae">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [42]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [43]: </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LassoCV</span>

<span class="gp">In [44]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="gp">In [45]: </span><span class="n">ml_g_tune</span> <span class="o">=</span> <span class="n">LassoCV</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dml_data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">dml_data</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>

<span class="gp">In [46]: </span><span class="n">ml_m_tune</span> <span class="o">=</span> <span class="n">LassoCV</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dml_data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">dml_data</span><span class="o">.</span><span class="n">d</span><span class="p">)</span>

<span class="gp">In [47]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">()</span>

<span class="gp">In [48]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">()</span>

<span class="gp">In [49]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">)</span>

<span class="gp">In [50]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">set_ml_nuisance_params</span><span class="p">(</span><span class="s1">&#39;ml_g&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">ml_g_tune</span><span class="o">.</span><span class="n">alpha_</span><span class="p">});</span>

<span class="gp">In [51]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">set_ml_nuisance_params</span><span class="p">(</span><span class="s1">&#39;ml_m&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">ml_m_tune</span><span class="o">.</span><span class="n">alpha_</span><span class="p">});</span>

<span class="gp">In [52]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
<span class="go">{&#39;ml_g&#39;: {&#39;d&#39;: [[{&#39;alpha&#39;: 0.4311947070055128}, {&#39;alpha&#39;: 0.4311947070055128}, {&#39;alpha&#39;: 0.4311947070055128}, {&#39;alpha&#39;: 0.4311947070055128}, {&#39;alpha&#39;: 0.4311947070055128}]]}, &#39;ml_m&#39;: {&#39;d&#39;: [[{&#39;alpha&#39;: 0.14281403493938027}, {&#39;alpha&#39;: 0.14281403493938027}, {&#39;alpha&#39;: 0.14281403493938027}, {&#39;alpha&#39;: 0.14281403493938027}, {&#39;alpha&#39;: 0.14281403493938027}]]}}</span>

<span class="gp">In [53]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err          t  P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  3.048723  0.075869  40.183855    0.0  2.900021  3.197424</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="r-learners-and-hyperparameters">
<span id="learners-r"></span><h2><span class="section-number">6.2. </span>R: Learners and hyperparameters<a class="headerlink" href="#r-learners-and-hyperparameters" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id2">
<h3><span class="section-number">6.2.1. </span>Minimum requirements for learners<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>The minimum requirement for a learner to be used for nuisance models in the <code class="docutils literal notranslate"><span class="pre">DoubleML</span></code> package is</p>
<blockquote>
<div><ul class="simple">
<li><p>The implementation as a learner for regression or classification in the <a class="reference external" href="https://mlr3.mlr-org.com/">mlr3</a> package
or its extension packages <a class="reference external" href="https://mlr3learners.mlr-org.com/">mlr3learners</a> and
<a class="reference external" href="https://mlr3extralearners.mlr-org.com/">mlr3extralearners</a> . A guide how to add a learner is provided in the
<a class="reference external" href="https://mlr3book.mlr-org.com/extending-learners.html">chapter on extending learners in the mlr3 book</a> .</p></li>
<li><p>The <a class="reference external" href="https://mlr3.mlr-org.com/">mlr3</a> package makes sure that the learners satisfy some core functionalities.
To specify a specific learner in <code class="docutils literal notranslate"><span class="pre">DoubleML</span></code> users can either enter their name as used for instantiation in
<a class="reference external" href="https://mlr3.mlr-org.com/">mlr3</a> or pass objects of the class <a class="reference external" href="https://mlr3.mlr-org.com/reference/Learner.html">Learner</a> directly.</p></li>
<li><p>The models <code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code> and <code class="docutils literal notranslate"><span class="pre">DoubleMLIIVM</span></code> require classifiers.
Choosing learners for a model in <code class="docutils literal notranslate"><span class="pre">DoubleML</span></code>, users have to be careful whether a nuisance part is a classification
tasks (dependent variable is binary) or a regression problem (dependent variable is continuous) and specify the learners
accordingly.</p></li>
<li><p>Hyperparameters of learners can either be set at instantiation in mlr3 or after instantiation using the
<code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params()</span></code> method.</p></li>
</ul>
</div></blockquote>
<p>A list of provided learners in the mlr3 and extension packages can be found on the package websites</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="https://mlr3book.mlr-org.com/learners.html#learners-predefined">learners provided in mlr3</a>,</p></li>
<li><p><a class="reference external" href="https://mlr3learners.mlr-org.com/#classification-learners">learners provided in mlr3learners</a>,</p></li>
<li><p><a class="reference external" href="https://mlr3extralearners.mlr-org.com/articles/learners/list_learners.html">learners provided in mlr3extralearners</a>.</p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="id6">
<h3><span class="section-number">6.2.2. </span>Specifying learners and set hyperparameters<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p>The learners are set during initialization of the <code class="docutils literal notranslate"><span class="pre">DoubleML</span></code> model classes <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code>,
<code class="docutils literal notranslate"><span class="pre">DoubleMLPLIV</span></code>, <code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code> and <code class="docutils literal notranslate"><span class="pre">DoubleMLIIVM</span></code>. Lets simulate some data and consider the partially linear regression model.
We need to specify learners for the nuisance functions <span class="math notranslate nohighlight">\(g_0(X) = E[Y|X]\)</span> and <span class="math notranslate nohighlight">\(m_0(X) = E[D|X]\)</span>,
for example <code class="docutils literal notranslate"><span class="pre">LearnerRegrRanger</span></code> (<code class="docutils literal notranslate"><span class="pre">&quot;regr.ranger&quot;</span></code>) for regression with random forests based on the  <a class="reference external" href="https://github.com/imbs-hl/ranger">ranger</a>
package for R.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="b71faaa9-bdd1-49b6-a7bc-3ccc8ecf5c22" name="f94bb5e7-cf45-454e-af7e-1dd6a4c95df7" type="radio">
</input><label class="tabbed-label" for="b71faaa9-bdd1-49b6-a7bc-3ccc8ecf5c22">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16</pre></div></td><td class="code"><div class="highlight"><pre><span></span>library(DoubleML)
library(mlr3)
library(mlr3learners)
library(data.table)
lgr::get_logger(&quot;mlr3&quot;)$set_threshold(&quot;warn&quot;)

# set up a mlr3 learner
learner = lrn(&quot;regr.ranger&quot;)
ml_g = learner$clone()
ml_m = learner$clone()
set.seed(3141)
data = make_plr_CCDDHNR2018(alpha=0.5, return_type=&#39;data.table&#39;)
obj_dml_data = DoubleMLData$new(data, y_col=&quot;y&quot;, d_cols=&quot;d&quot;)
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m)
dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>Error in loadNamespace(name): there is no package called ‘mvtnorm’
Traceback:

1. make_plr_CCDDHNR2018(alpha = 0.5, return_type = &quot;data.table&quot;)
2. mvtnorm::rmvnorm
3. getExportedValue(pkg, name)
4. asNamespace(ns)
5. getNamespace(ns)
6. loadNamespace(name)
7. withRestarts(stop(cond), retry_loadNamespace = function() NULL)
8. withOneRestart(expr, restarts[[1L]])
9. doWithOneRestart(return(expr), restart)
</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>Setting hyperparameters:</p>
<blockquote>
<div><ul class="simple">
<li><p>We can also use pre-parametrized learners <code class="docutils literal notranslate"><span class="pre">lrn(&quot;regr.ranger&quot;,</span> <span class="pre">num.trees=10)</span></code>.</p></li>
<li><p>Alternatively, hyperparameters can be set after initialization via the method
<code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params(learner,</span> <span class="pre">treat_var,</span> <span class="pre">params,</span> <span class="pre">set_fold_specific)</span></code>.</p></li>
</ul>
</div></blockquote>
<div class="tabbed-set docutils">
<input checked="checked" id="a1e3127b-5779-4fda-a209-64c7602bea1c" name="837cef3d-1b33-41df-ab32-a18c73b943d3" type="radio">
</input><label class="tabbed-label" for="a1e3127b-5779-4fda-a209-64c7602bea1c">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14</pre></div></td><td class="code"><div class="highlight"><pre><span></span>set.seed(3141)
ml_g = lrn(&quot;regr.ranger&quot;, num.trees=10)
ml_m = lrn(&quot;regr.ranger&quot;)
obj_dml_data = DoubleMLData$new(data, y_col=&quot;y&quot;, d_cols=&quot;d&quot;)
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m)
dml_plr_obj$fit()
dml_plr_obj$summary()

set.seed(3141)
ml_g = lrn(&quot;regr.ranger&quot;)
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g , ml_m)
dml_plr_obj$set_ml_nuisance_params(&quot;ml_g&quot;, &quot;d&quot;, list(&quot;num.trees&quot;=10))
dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>Error in initialize(...): Assertion on &#39;data&#39; failed: Must inherit from class &#39;data.table&#39;, but has class &#39;function&#39;.
Traceback:

1. DoubleMLData$new(data, y_col = &quot;y&quot;, d_cols = &quot;d&quot;)
2. initialize(...)
3. checkmate::assert_class(data, &quot;data.table&quot;)
4. makeAssertion(x, res, .var.name, add)
5. mstop(&quot;Assertion on &#39;%s&#39; failed: %s.&quot;, var.name, res, call. = sys.call(-2L))
</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>Setting treatment-variable-specific or fold-specific hyperparameters:</p>
<blockquote>
<div><ul class="simple">
<li><p>In the multiple-treatment case, the method <code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params(learner,</span> <span class="pre">treat_var,</span> <span class="pre">params,</span> <span class="pre">set_fold_specific)</span></code>
allows to set different hyperparameters for different treatment variables.</p></li>
<li><p>The method <code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params(learner,</span> <span class="pre">treat_var,</span> <span class="pre">params,</span> <span class="pre">set_fold_specific)</span></code> accepts lists for <code class="docutils literal notranslate"><span class="pre">params</span></code>.
The structure of the list depends on whether the same parameters should be provided for all folds or separate values
are passed for specific folds.</p></li>
<li><p>Global parameter passing: The named list in the argument <code class="docutils literal notranslate"><span class="pre">params</span></code> should have entries with names corresponding to
the parameters of the learners. The values in <code class="docutils literal notranslate"><span class="pre">params</span></code> are used for estimation on all folds.
It is required that option <code class="docutils literal notranslate"><span class="pre">set_fold_specific</span></code> is set to <code class="docutils literal notranslate"><span class="pre">FALSE</span></code> (default).</p></li>
<li><p>Fold-specific parameter passing: <code class="docutils literal notranslate"><span class="pre">params</span></code> is a nested list. The outer list needs to be of length <code class="docutils literal notranslate"><span class="pre">n_rep</span></code> and the inner
list of length <code class="docutils literal notranslate"><span class="pre">n_folds</span></code>. The innermost list must have named entries that correspond to the parameters of the learner.
It is required that option <code class="docutils literal notranslate"><span class="pre">set_fold_specific</span></code> is set to <code class="docutils literal notranslate"><span class="pre">TRUE</span></code>. Moreover, fold-specific
parameter passing is only supported, if all parameters are set fold-specific.</p></li>
<li><p>External setting of parameters will override previously set parameters. To assert the choice of parameters, access the
fields <code class="docutils literal notranslate"><span class="pre">$learner</span></code> and <code class="docutils literal notranslate"><span class="pre">$params</span></code>.</p></li>
</ul>
</div></blockquote>
<div class="tabbed-set docutils">
<input checked="checked" id="91ecaf87-07eb-4b4b-9c08-6a06f2119feb" name="634f095b-55ac-4006-b6c8-5594951a9fdd" type="radio">
</input><label class="tabbed-label" for="91ecaf87-07eb-4b4b-9c08-6a06f2119feb">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17</pre></div></td><td class="code"><div class="highlight"><pre><span></span>set.seed(3141)
ml_g = lrn(&quot;regr.ranger&quot;)
ml_m = lrn(&quot;regr.ranger&quot;)
obj_dml_data = DoubleMLData$new(data, y_col=&quot;y&quot;, d_cols=&quot;d&quot;)

n_rep = 2
n_folds = 3
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m, n_rep = n_rep, n_folds = n_folds)

# Set globally
params = list(&quot;num.trees&quot;=10)
dml_plr_obj$set_ml_nuisance_params(&quot;ml_g&quot;, &quot;d&quot;, params=params)
dml_plr_obj$set_ml_nuisance_params(&quot;ml_m&quot;, &quot;d&quot;, params=params)
dml_plr_obj$learner
dml_plr_obj$params
dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>Error in initialize(...): Assertion on &#39;data&#39; failed: Must inherit from class &#39;data.table&#39;, but has class &#39;function&#39;.
Traceback:

1. DoubleMLData$new(data, y_col = &quot;y&quot;, d_cols = &quot;d&quot;)
2. initialize(...)
3. checkmate::assert_class(data, &quot;data.table&quot;)
4. makeAssertion(x, res, .var.name, add)
5. mstop(&quot;Assertion on &#39;%s&#39; failed: %s.&quot;, var.name, res, call. = sys.call(-2L))
</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>The following example illustrates how to set parameters for each fold.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="4d47b6f8-8e2b-4aba-9240-9865f23ea653" name="4f33020f-f6bf-4aad-a741-5d4dd5136b8c" type="radio">
</input><label class="tabbed-label" for="4d47b6f8-8e2b-4aba-9240-9865f23ea653">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15</pre></div></td><td class="code"><div class="highlight"><pre><span></span>learner = lrn(&quot;regr.ranger&quot;)
ml_g = learner$clone()
ml_m = learner$clone()
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m, n_rep = n_rep, n_folds = n_folds)

# Set values for each fold
params_exact = rep(list(rep(list(params), n_folds)), n_rep)
dml_plr_obj$set_ml_nuisance_params(&quot;ml_g&quot;, &quot;d&quot;, params=params_exact,
                                     set_fold_specific=TRUE)
dml_plr_obj$set_ml_nuisance_params(&quot;ml_m&quot;, &quot;d&quot;, params=params_exact,
                                     set_fold_specific=TRUE)
dml_plr_obj$learner
dml_plr_obj$params
dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>Error in checkClass(x, classes, ordered, null.ok): object &#39;obj_dml_data&#39; not found
Traceback:

1. DoubleMLPLR$new(obj_dml_data, ml_g, ml_m, n_rep = n_rep, n_folds = n_folds)
2. initialize(...)
3. super$initialize_double_ml(data, n_folds, n_rep, score, dml_procedure, 
 .     draw_sample_splitting, apply_cross_fitting)
4. checkmate::assert_class(data, &quot;DoubleMLData&quot;)
5. checkClass(x, classes, ordered, null.ok)
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="id7">
<h3><span class="section-number">6.2.3. </span>Hyperparameter tuning<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>Parameter tuning of learners for the nuisance functions of <code class="docutils literal notranslate"><span class="pre">DoubleML</span></code> models can be done via the <code class="docutils literal notranslate"><span class="pre">tune()</span></code> method.
The <code class="docutils literal notranslate"><span class="pre">tune()</span></code> method passes various options and parameters to tuning interface as provided by the
<a class="reference external" href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a> package. The <a class="reference external" href="https://mlr3book.mlr-org.com/">mlr3 book</a> provides a
<a class="reference external" href="https://mlr3book.mlr-org.com/optimization.html">step-by-step introduction to parameter tuning</a>.</p>
<p>To illustrate the parameter tuning, we generate data from a sparse partially linear regression model.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="36635549-8bc1-4208-a964-df7a6674e778" name="a098de45-5b4b-4b33-8e83-d1b00fbef506" type="radio">
</input><label class="tabbed-label" for="36635549-8bc1-4208-a964-df7a6674e778">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="n">library</span><span class="p">(</span><span class="n">DoubleML</span><span class="p">)</span>
<span class="n">library</span><span class="p">(</span><span class="n">mlr3</span><span class="p">)</span>
<span class="n">library</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">table</span><span class="p">)</span>

<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3141</span><span class="p">)</span>
<span class="n">n_obs</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">n_vars</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">theta</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="n">stats</span><span class="p">::</span><span class="n">rnorm</span><span class="p">(</span><span class="n">n_obs</span> <span class="o">*</span> <span class="n">n_vars</span><span class="p">),</span> <span class="n">nrow</span> <span class="o">=</span> <span class="n">n_obs</span><span class="p">,</span> <span class="n">ncol</span> <span class="o">=</span> <span class="n">n_vars</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="p">[,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="n">drop</span> <span class="o">=</span> <span class="n">FALSE</span><span class="p">]</span> <span class="o">%*%</span> <span class="n">c</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span> <span class="o">+</span> <span class="n">stats</span><span class="p">::</span><span class="n">rnorm</span><span class="p">(</span><span class="n">n_obs</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">*</span> <span class="n">d</span> <span class="o">+</span> <span class="n">X</span><span class="p">[,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="n">drop</span> <span class="o">=</span> <span class="n">FALSE</span><span class="p">]</span> <span class="o">%*%</span> <span class="n">c</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>  <span class="o">+</span> <span class="n">stats</span><span class="p">::</span><span class="n">rnorm</span><span class="p">(</span><span class="n">n_obs</span><span class="p">)</span>
<span class="n">dml_data</span> <span class="o">=</span> <span class="n">double_ml_data_from_matrix</span><span class="p">(</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">d</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
</div>
</div>
</div>
</div>
<p>The hyperparameter-tuning is performed according to options passed through a named list <code class="docutils literal notranslate"><span class="pre">tune_settings</span></code>.
The entries in the list specify options during parameter tuning with <a class="reference external" href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a>:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">algorithm</span></code>  sets the tuning algorithm, i.e., an argument used to initiate the
<a class="reference external" href="https://mlr3book.mlr-org.com/tuning.html#the-tuner-class">Tuner class</a>. <code class="docutils literal notranslate"><span class="pre">algorithm</span></code> is a <code class="docutils literal notranslate"><span class="pre">character()</span></code> that
is used as an argument in the wrapper <a class="reference external" href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a> call <code class="docutils literal notranslate"><span class="pre">tnr(algorithm)</span></code>.
<code class="docutils literal notranslate"><span class="pre">resolution</span></code>  sets the number of grid points.
<a class="reference external" href="https://mlr3book.mlr-org.com/tuning.html#the-tuner-class">The Tuner class in mlr3tuning</a> supports grid search,
random search, generalized simulated annealing and non-linear optimization.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rsmp_tune</span></code> specifies the resampling method for evaluation, for example <span class="math notranslate nohighlight">\(k\)</span>-fold cross-validation (<code class="docutils literal notranslate"><span class="pre">cv</span></code>)
with <span class="math notranslate nohighlight">\(k=\)</span> <code class="docutils literal notranslate"><span class="pre">n_folds_tune</span></code> or evaluation on a hold-out sample <code class="docutils literal notranslate"><span class="pre">holdout</span></code>. Directly passing of a
<a class="reference external" href="https://mlr3.mlr-org.com/reference/Resampling.html">mlr3 resampling object</a> is supported,
for example by setting <cite>rsmp_tune=smp(“holdout”, ratio=0.8)</cite>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">terminator</span></code> is a <a class="reference external" href="https://bbotk.mlr-org.com/reference/Terminator.html">Terminator object</a> passed to
<a class="reference external" href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a> that manages the budget to solve the tuning problem.</p></li>
</ul>
</div></blockquote>
<p>In the following example we tune the penalty parameter <span class="math notranslate nohighlight">\(\lambda\)</span> (<code class="docutils literal notranslate"><span class="pre">lambda</span></code>) for lasso with the R package
<a class="reference external" href="https://glmnet.stanford.edu/">glmnet</a>. To tune the value of <code class="docutils literal notranslate"><span class="pre">lambda</span></code> a grid search over a grid of values that range from <cite>0.05</cite>
to <cite>0.1</cite> at a resolution of 10. To evaluate the predictive performance in both nuisance parts, the cross-validated mean squared error is used.</p>
<p>Setting the option <code class="docutils literal notranslate"><span class="pre">tune_on_folds=FALSE</span></code>, the tuning is performed on the whole sample. Hence, the cross-validated errors
are obtained from a random split of the whole sample into 5 folds and, as a result, one set of <code class="docutils literal notranslate"><span class="pre">lambda</span></code> values are obtained
which are later used in the fitting stage for all folds.</p>
<p>Alternatively, setting the option <code class="docutils literal notranslate"><span class="pre">tune_on_folds=TRUE</span></code> would assign the tuning resampling scheme <code class="docutils literal notranslate"><span class="pre">rsmp_tune</span></code> to each fold.
For example, if we set <code class="docutils literal notranslate"><span class="pre">n_folds=2</span></code> at initialization of the <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code> object and use a 5-fold cross-validated error
for tuning, each of the two folds would be split up into 5 subfolds and the error would be evaluated on these subfolds.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="ffc288ed-0150-4c2b-802f-950c751c3f19" name="ed1810f6-c8d4-418c-82f0-3978eec6b0ee" type="radio">
</input><label class="tabbed-label" for="ffc288ed-0150-4c2b-802f-950c751c3f19">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31</pre></div></td><td class="code"><div class="highlight"><pre><span></span>library(DoubleML)
library(mlr3)
library(data.table)
library(mlr3learners)
library(paradox)
library(mlr3tuning)
lgr::get_logger(&quot;mlr3&quot;)$set_threshold(&quot;warn&quot;)
lgr::get_logger(&quot;bbotk&quot;)$set_threshold(&quot;warn&quot;)

set.seed(1234)
ml_g = lrn(&quot;regr.glmnet&quot;)
ml_m = lrn(&quot;regr.glmnet&quot;)
dml_plr_obj = DoubleMLPLR$new(dml_data, ml_g, ml_m)

par_grids = list(&quot;ml_g&quot; = ParamSet$new(list(
                                  ParamDbl$new(&quot;lambda&quot;, lower = 0.05, upper = 0.1))),
                 &quot;ml_m&quot; =  ParamSet$new(list(
                                  ParamDbl$new(&quot;lambda&quot;, lower = 0.05, upper = 0.1))))

tune_settings = list(n_folds_tune = 5,
                      rsmp_tune = &quot;cv&quot;,
                      measure = list(&quot;ml_g&quot; = &quot;regr.mse&quot;,
                                     &quot;ml_m&quot; = &quot;regr.mse&quot;),
                      terminator = mlr3tuning::trm(&quot;evals&quot;, n_evals = 100),
                      algorithm = &quot;grid_search&quot;,
                      resolution = 10)
dml_plr_obj$tune(param_set=par_grids, tune_settings=tune_settings, tune_on_fold=TRUE)
dml_plr_obj$params

dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>Error: The following packages could not be loaded: glmnet
Traceback:

1. dml_plr_obj$tune(param_set = par_grids, tune_settings = tune_settings, 
 .     tune_on_fold = TRUE)
2. private$ml_nuisance_tuning(private$get__smpls(), param_set, tune_settings, 
 .     tune_on_folds)
3. lapply(tuning_instance_g, function(x) tune_instance(tuner, x))
4. FUN(X[[i]], ...)
5. tune_instance(tuner, x)
6. tuner$optimize(tuning_instance)
7. .__TunerFromOptimizer__optimize(self = self, private = private, 
 .     super = super, inst = inst)
8. private$.optimizer$optimize(inst)
9. .__Optimizer__optimize(self = self, private = private, super = super, 
 .     inst = inst)
10. optimize_default(inst, self, private)
11. tryCatch({
  .     private$.optimize(inst)
  . }, terminated_error = function(cond) {
  . })
12. tryCatchList(expr, classes, parentenv, handlers)
13. tryCatchOne(expr, names, parentenv, handlers[[1L]])
14. doTryCatch(return(expr), name, parentenv, handler)
15. private$.optimize(inst)
16. .__OptimizerGridSearch__.optimize(self = self, private = private, 
  .     super = super, inst = inst)
17. inst$eval_batch(g$data[inds])
18. .__OptimInstance__eval_batch(self = self, private = private, 
  .     super = super, xdt = xdt)
19. self$objective$eval_many(xss_trafoed)
20. .__Objective__eval_many(self = self, private = private, super = super, 
  .     xss = xss)
21. private$.eval_many(xss)
22. .__ObjectiveTuning__.eval_many(self = self, private = private, 
  .     super = super, xss = xss)
23. benchmark(design, store_models = self$store_models)
24. future.apply::future_mapply(workhorse, task = grid$task, learner = grid$learner, 
  .     resampling = grid$resampling, iteration = grid$iteration, 
  .     MoreArgs = list(store_models = store_models, lgr_threshold = lg$threshold, 
  .         pb = pb), SIMPLIFY = FALSE, USE.NAMES = FALSE, future.globals = FALSE, 
  .     future.scheduling = structure(TRUE, ordering = &quot;random&quot;), 
  .     future.packages = &quot;mlr3&quot;, future.seed = TRUE)
25. future_xapply(FUN = FUN, nX = nX, chunk_args = dots, MoreArgs = MoreArgs, 
  .     get_chunk = function(X, chunk) lapply(X, FUN = `[`, chunk), 
  .     expr = expr, envir = envir, future.globals = future.globals, 
  .     future.packages = future.packages, future.scheduling = future.scheduling, 
  .     future.chunk.size = future.chunk.size, future.stdout = future.stdout, 
  .     future.conditions = future.conditions, future.seed = future.seed, 
  .     future.lazy = future.lazy, future.label = future.label, fcn_name = fcn_name, 
  .     args_name = args_name, debug = debug)
26. value(fs)
27. value.list(fs)
28. resolve(y, result = TRUE, stdout = stdout, signal = signal, force = TRUE)
29. resolve.list(y, result = TRUE, stdout = stdout, signal = signal, 
  .     force = TRUE)
30. signalConditionsASAP(obj, resignal = FALSE, pos = ii)
31. signalConditions(obj, exclude = getOption(&quot;future.relay.immediate&quot;, 
  .     &quot;immediateCondition&quot;), resignal = resignal, ...)
</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>Hyperparameter tuning can also be done with more sophisticated methods, for example by using built-in tuning
paths of learners. For example, the learner <a class="reference external" href="https://mlr3learners.mlr-org.com/reference/mlr_learners_regr.cv_glmnet.html">regr.cv_glmnet</a>
performs an internal cross-validated choice of the parameter <code class="docutils literal notranslate"><span class="pre">lambda</span></code>.
Alternatively, the powerful functionalities of the <a class="reference external" href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a> package can be used for
external parameter tuning of the nuisance parts. The optimally chosen parameters can then be passed to the
<code class="docutils literal notranslate"><span class="pre">DoubleML</span></code> models using the <code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params()</span></code> method.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="3b1cff1d-8e49-46ea-95a1-3727052e1858" name="9e25680e-9649-464b-a826-f0257a978048" type="radio">
</input><label class="tabbed-label" for="3b1cff1d-8e49-46ea-95a1-3727052e1858">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16</pre></div></td><td class="code"><div class="highlight"><pre><span></span>library(DoubleML)
library(mlr3)
library(data.table)
library(mlr3learners)
library(paradox)
library(mlr3tuning)
lgr::get_logger(&quot;mlr3&quot;)$set_threshold(&quot;warn&quot;)
lgr::get_logger(&quot;bbotk&quot;)$set_threshold(&quot;warn&quot;)

set.seed(1234)
ml_g = lrn(&quot;regr.cv_glmnet&quot;, s=&quot;lambda.min&quot;)
ml_m = lrn(&quot;regr.cv_glmnet&quot;, s=&quot;lambda.min&quot;)
dml_plr_obj = DoubleMLPLR$new(dml_data, ml_g, ml_m)

dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>Error: The following packages could not be loaded: glmnet
Traceback:

1. dml_plr_obj$fit()
2. private$ml_nuisance_and_score_elements(private$get__smpls())
3. mlr3::resample(task_g, ml_g, resampling_g, store_models = TRUE)
4. future.apply::future_lapply(seq_len(n), workhorse, task = task, 
 .     learner = learner, resampling = instance, store_models = store_models, 
 .     lgr_threshold = lg$threshold, pb = pb, future.globals = FALSE, 
 .     future.scheduling = structure(TRUE, ordering = &quot;random&quot;), 
 .     future.packages = &quot;mlr3&quot;, future.seed = TRUE)
5. future_xapply(FUN = FUN, nX = nX, chunk_args = X, args = list(...), 
 .     get_chunk = `[`, expr = expr, envir = envir, future.globals = future.globals, 
 .     future.packages = future.packages, future.scheduling = future.scheduling, 
 .     future.chunk.size = future.chunk.size, future.stdout = future.stdout, 
 .     future.conditions = future.conditions, future.seed = future.seed, 
 .     future.lazy = future.lazy, future.label = future.label, fcn_name = fcn_name, 
 .     args_name = args_name, debug = debug)
6. value(fs)
7. value.list(fs)
8. resolve(y, result = TRUE, stdout = stdout, signal = signal, force = TRUE)
9. resolve.list(y, result = TRUE, stdout = stdout, signal = signal, 
 .     force = TRUE)
10. signalConditionsASAP(obj, resignal = FALSE, pos = ii)
11. signalConditions(obj, exclude = getOption(&quot;future.relay.immediate&quot;, 
  .     &quot;immediateCondition&quot;), resignal = resignal, ...)
</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>The following code chunk illustrates another example for global parameter tuning with random forests
as provided by the <code class="docutils literal notranslate"><span class="pre">ranger</span></code> package.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="dcc188d0-ae6b-44bc-97ed-36b821988721" name="50f3892b-4aa8-4ef3-a606-6a514e963190" type="radio">
</input><label class="tabbed-label" for="dcc188d0-ae6b-44bc-97ed-36b821988721">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37</pre></div></td><td class="code"><div class="highlight"><pre><span></span>library(DoubleML)
library(mlr3)
library(mlr3learners)
library(data.table)
library(paradox)
library(mlr3tuning)
lgr::get_logger(&quot;mlr3&quot;)$set_threshold(&quot;warn&quot;)
lgr::get_logger(&quot;bbotk&quot;)$set_threshold(&quot;warn&quot;)

# set up a list of parameter grids
param_grid = list(&quot;ml_g&quot; = ParamSet$new(list(
                                  ParamInt$new(&quot;num.trees&quot;, lower = 50 , upper = 500),
                                  ParamInt$new(&quot;max.depth&quot;, lower = 2, upper = 5))),
                  &quot;ml_m&quot; = ParamSet$new(list(
                                  ParamInt$new(&quot;num.trees&quot;, lower = 50 , upper = 500),
                                  ParamInt$new(&quot;max.depth&quot;, lower = 2, upper = 5))))
tune_settings = list(n_folds_tune = 2,
                      rsmp_tune = &quot;cv&quot;,
                      measure = list(&quot;ml_g&quot; = &quot;regr.mse&quot;,
                                     &quot;ml_m&quot; = &quot;regr.mse&quot;),
                      terminator = mlr3tuning::trm(&quot;evals&quot;, n_evals = 20),
                      algorithm = &quot;grid_search&quot;,
                      resolution = 5)

# set up a mlr3 learner
learner = lrn(&quot;regr.ranger&quot;)
ml_g = learner$clone()
ml_m = learner$clone()

set.seed(3141)
obj_dml_data = make_plr_CCDDHNR2018(alpha=0.5)
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m)
dml_plr_obj$tune(param_set=param_grid, tune_settings=tune_settings, tune_on_folds=FALSE)
dml_plr_obj$params

dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>Error in loadNamespace(name): there is no package called ‘mvtnorm’
Traceback:

1. make_plr_CCDDHNR2018(alpha = 0.5)
2. mvtnorm::rmvnorm
3. getExportedValue(pkg, name)
4. asNamespace(ns)
5. getNamespace(ns)
6. loadNamespace(name)
7. withRestarts(stop(cond), retry_loadNamespace = function() NULL)
8. withOneRestart(expr, restarts[[1L]])
9. doWithOneRestart(return(expr), restart)
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="references">
<h4><span class="section-number">6.2.3.1. </span>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>Lang, M., Binder, M., Richter, J., Schratz, P., Pfisterer, F., Coors, S., Au, Q., Casalicchio, G., Kotthoff, L., Bischl, B. (2019), mlr3: A modern object-oriented machine learing framework in R. Journal of Open Source Software, <a class="reference external" href="(doi:10.21105/joss.01903)[10.21105/joss.01903]">doi:10.21105/joss.01903</a>.</p></li>
<li><p>Becker, M., Binder, M., Bischl, B., Lang, M., Pfisterer, F., Reich, N.G., Richter, J., Schratz, P., Sonabend, R. (2020), mlr3 book, available at <a class="reference external" href="https://mlr3book.mlr-org.com">https://mlr3book.mlr-org.com</a>.</p></li>
</ul>
</div>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="algorithms.html" title="previous page"><span class="section-number">5. </span>Double machine learning algorithms</a>
    <a class='right-next' id="next-link" href="se_confint.html" title="next page"><span class="section-number">7. </span>Variance estimation, confidence intervals and multiplier bootstrap</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>