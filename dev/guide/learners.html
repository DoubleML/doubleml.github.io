
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>6. Learners, hyperparameters and hyperparameter tuning &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.101715efdecc9b59cb6e1ddfa685c31f.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d8bbf5861d671d414e1a.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="7. Variance estimation and confidence intervals for a causal parameter of interest" href="se_confint.html" />
    <link rel="prev" title="5. Double machine learning algorithms" href="algorithms.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">


    
    <a class="navbar-brand" href="../index.html">
      <p class="title">DoubleML</p>
    </a>
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  DoubleML
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/install.html">
  Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/intro.html">
  Getting started
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="guide.html">
  User guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../auto_examples/index.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api.html">
  Python API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference external nav-link" href="https://docs.doubleml.org/r/stable/">
  R API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../release/release.html">
  Release notes
 </a>
</li>

        
      </ul>

      <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><p class="logo" style="text-align:center;"><a href="../index.html">
    <img class="logo" src="../logo.png" alt="Logo" width="65%" height="65%">
</a></p><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l2">
  <a class="reference internal" href="basics.html">
   1.  The basics of double/debiased machine learning
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="data_backend.html">
   2.  The data-backend DoubleMLData
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="models.html">
   3.  Models
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="scores.html">
   4.  Score functions
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="algorithms.html">
   5.  Double machine learning algorithms
  </a>
 </li>
 <li class="toctree-l2 current active">
  <a class="current reference internal" href="#">
   6.  Learners, hyperparameters and hyperparameter tuning
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="se_confint.html">
   7.  Variance estimation and confidence intervals for a causal parameter of interest
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="sim_inf.html">
   8.  Confidence bands and multiplier bootstrap for valid simultaneous inference
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="resampling.html">
   9.  Sample-splitting, cross-fitting and repeated cross-fitting
  </a>
 </li>
</ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#python-learners-and-hyperparameters">
   6.1. Python: Learners and hyperparameters
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#minimum-requirements-for-learners">
     6.1.1. Minimum requirements for learners
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#specifying-learners-and-set-hyperparameters">
     6.1.2. Specifying learners and set hyperparameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hyperparameter-tuning">
     6.1.3. Hyperparameter tuning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#r-learners-and-hyperparameters">
   6.2. R: Learners and hyperparameters
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     6.2.1. Minimum requirements for learners
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     6.2.2. Specifying learners and set hyperparameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id11">
     6.2.3. Hyperparameter tuning
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#references">
       6.2.3.1. References
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="learners-hyperparameters-and-hyperparameter-tuning">
<span id="learners"></span><h1><span class="section-number">6. </span>Learners, hyperparameters and hyperparameter tuning<a class="headerlink" href="#learners-hyperparameters-and-hyperparameter-tuning" title="Permalink to this headline">¶</a></h1>
<p>The estimation of a double/debiased machine learning model involves the estimation of several nuisance function with
machine learning estimators.
Such learners are implemented in various Python and R packages.
The implementation of <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> is based on the meta-packages
<a class="reference external" href="https://scikit-learn.org/">scikit-learn</a> for Python and <a class="reference external" href="https://mlr3.mlr-org.com/">mlr3</a> for R.
The interfaces to specify the learners, set hyperparameters and tune hyperparameters are described in the following
separately for <a class="reference internal" href="#learners-python"><span class="std std-ref">Python</span></a> and <a class="reference internal" href="#learners-r"><span class="std std-ref">R</span></a>.</p>
<div class="section" id="python-learners-and-hyperparameters">
<span id="learners-python"></span><h2><span class="section-number">6.1. </span>Python: Learners and hyperparameters<a class="headerlink" href="#python-learners-and-hyperparameters" title="Permalink to this headline">¶</a></h2>
<div class="section" id="minimum-requirements-for-learners">
<h3><span class="section-number">6.1.1. </span>Minimum requirements for learners<a class="headerlink" href="#minimum-requirements-for-learners" title="Permalink to this headline">¶</a></h3>
<p>The minimum requirement for a learner to be used for nuisance models in the <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a>
package is</p>
<blockquote>
<div><ul class="simple">
<li><p>The implementation of a <code class="docutils literal notranslate"><span class="pre">fit()</span></code> and <code class="docutils literal notranslate"><span class="pre">predict()</span></code> method.
Some models, like <a class="reference internal" href="../api/generated/doubleml.DoubleMLIRM.html#doubleml.DoubleMLIRM" title="doubleml.DoubleMLIRM"><code class="xref py py-class docutils literal notranslate"><span class="pre">doubleml.DoubleMLIRM</span></code></a> and <a class="reference internal" href="../api/generated/doubleml.DoubleMLIIVM.html#doubleml.DoubleMLIIVM" title="doubleml.DoubleMLIIVM"><code class="xref py py-class docutils literal notranslate"><span class="pre">doubleml.DoubleMLIIVM</span></code></a> require classifiers.</p></li>
<li><p>In case of classifiers, the learner needs to come with a <code class="docutils literal notranslate"><span class="pre">predict_proba()</span></code> instead of, or in addition to, a
<code class="docutils literal notranslate"><span class="pre">predict()</span></code> method, see for example <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict_proba" title="(in scikit-learn v0.24)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sklearn.ensemble.RandomForestClassifier.predict_proba()</span></code></a>.</p></li>
<li><p>In order to be able to use the <code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params()</span></code> method of <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> classes the
learner additionally needs to come with a <code class="docutils literal notranslate"><span class="pre">set_params()</span></code> method,
see for example <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor.set_params" title="(in scikit-learn v0.24)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sklearn.ensemble.RandomForestRegressor.set_params()</span></code></a>.</p></li>
<li><p>We further rely on the function <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="(in scikit-learn v0.24)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.base.clone()</span></code></a> which adds the requirement of a <code class="docutils literal notranslate"><span class="pre">get_params()</span></code>
method for a learner in order to be used for nuisance models of <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> model classes.</p></li>
</ul>
</div></blockquote>
<p>Most learners from <a class="reference external" href="https://scikit-learn.org/">scikit-learn</a> satisfy all these minimum requirements.</p>
</div>
<div class="section" id="specifying-learners-and-set-hyperparameters">
<h3><span class="section-number">6.1.2. </span>Specifying learners and set hyperparameters<a class="headerlink" href="#specifying-learners-and-set-hyperparameters" title="Permalink to this headline">¶</a></h3>
<p>The learners are set during initialization of the <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> model classes
<a class="reference internal" href="../api/generated/doubleml.DoubleMLPLR.html#doubleml.DoubleMLPLR" title="doubleml.DoubleMLPLR"><code class="xref py py-class docutils literal notranslate"><span class="pre">doubleml.DoubleMLPLR</span></code></a>, <a class="reference internal" href="../api/generated/doubleml.DoubleMLPLIV.html#doubleml.DoubleMLPLIV" title="doubleml.DoubleMLPLIV"><code class="xref py py-class docutils literal notranslate"><span class="pre">doubleml.DoubleMLPLIV</span></code></a>,
<a class="reference internal" href="../api/generated/doubleml.DoubleMLIRM.html#doubleml.DoubleMLIRM" title="doubleml.DoubleMLIRM"><code class="xref py py-class docutils literal notranslate"><span class="pre">doubleml.DoubleMLIRM</span></code></a> and <a class="reference internal" href="../api/generated/doubleml.DoubleMLIIVM.html#doubleml.DoubleMLIIVM" title="doubleml.DoubleMLIIVM"><code class="xref py py-class docutils literal notranslate"><span class="pre">doubleml.DoubleMLIIVM</span></code></a>.
Lets simulate some data and consider the partially linear regression model.
We need to specify learners for the nuisance functions <span class="math notranslate nohighlight">\(g_0(X) = E[Y|X]\)</span> and <span class="math notranslate nohighlight">\(m_0(X) = E[D|X]\)</span>,
for example <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.ensemble.RandomForestRegressor</span></code></a>.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="425ef745-e5d7-422f-899a-2d034c6443f2" name="c8c261cd-d04c-420f-956d-22b62ddae0eb" type="radio">
</input><label class="tabbed-label" for="425ef745-e5d7-422f-899a-2d034c6443f2">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [2]: </span><span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_plr_CCDDHNR2018</span>

<span class="gp">In [3]: </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="gp">In [4]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="gp">In [5]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span>

<span class="gp">In [6]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span>

<span class="gp">In [7]: </span><span class="n">data</span> <span class="o">=</span> <span class="n">make_plr_CCDDHNR2018</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;DataFrame&#39;</span><span class="p">)</span>

<span class="gp">In [8]: </span><span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

<span class="gp">In [9]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">)</span>

<span class="gp">In [10]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span>
<span class="gh">Out[10]: </span><span class="go"></span>
<span class="go">       coef   std err         t         P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.543694  0.044073  12.33621  5.781357e-35  0.457313  0.630076</span>
</pre></div>
</div>
</div>
</div>
<p>Without further specification of the hyperparameters, default values are used. To set hyperparameters:</p>
<blockquote>
<div><ul class="simple">
<li><p>We can also use pre-parametrized learners, like <code class="docutils literal notranslate"><span class="pre">RandomForestRegressor(n_estimators=10)</span></code>.</p></li>
<li><p>Alternatively, hyperparameters can also be set after initialization via the method
<code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params(learner,</span> <span class="pre">treat_var,</span> <span class="pre">params)</span></code></p></li>
</ul>
</div></blockquote>
<div class="tabbed-set docutils">
<input checked="checked" id="8ddf5fbe-bb7f-487d-92a8-8f417bc696c2" name="9ca81d7e-2e3b-471e-8ffe-c23f29bc18ec" type="radio">
</input><label class="tabbed-label" for="8ddf5fbe-bb7f-487d-92a8-8f417bc696c2">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [11]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="gp">In [12]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
<span class="gp">   ....: </span>                              <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
<span class="gp">   ....: </span>                              <span class="n">RandomForestRegressor</span><span class="p">())</span>
<span class="gp">   ....: </span>

<span class="gp">In [13]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err         t         P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.568324  0.042163  13.47916  2.074547e-41  0.485686  0.650962</span>

<span class="gp">In [14]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="gp">In [15]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
<span class="gp">   ....: </span>                              <span class="n">RandomForestRegressor</span><span class="p">(),</span>
<span class="gp">   ....: </span>                              <span class="n">RandomForestRegressor</span><span class="p">())</span>
<span class="gp">   ....: </span>

<span class="gp">In [16]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">set_ml_nuisance_params</span><span class="p">(</span><span class="s1">&#39;ml_g&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">});</span>

<span class="gp">In [17]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err         t         P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.568324  0.042163  13.47916  2.074547e-41  0.485686  0.650962</span>
</pre></div>
</div>
</div>
</div>
<p>Setting treatment-variable-specific or fold-specific hyperparameters:</p>
<blockquote>
<div><ul class="simple">
<li><p>In the multiple-treatment case, the method <code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params(learner,</span> <span class="pre">treat_var,</span> <span class="pre">params)</span></code> can be used to set
different hyperparameters for different treatment variables.</p></li>
<li><p>The method <code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params(learner,</span> <span class="pre">treat_var,</span> <span class="pre">params)</span></code> accepts dicts and lists for <code class="docutils literal notranslate"><span class="pre">params</span></code>.
A dict should be provided if for each fold the same hyperparameters should be used.
Fold-specific parameters are supported. To do so,  provide a nested list as <code class="docutils literal notranslate"><span class="pre">params</span></code>, where the outer list is of
length <code class="docutils literal notranslate"><span class="pre">n_rep</span></code> and the inner list of length <code class="docutils literal notranslate"><span class="pre">n_folds</span></code>.</p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="hyperparameter-tuning">
<h3><span class="section-number">6.1.3. </span>Hyperparameter tuning<a class="headerlink" href="#hyperparameter-tuning" title="Permalink to this headline">¶</a></h3>
<p>Parameter tuning of learners for the nuisance functions of <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> models can be done via
the <code class="docutils literal notranslate"><span class="pre">tune()</span></code> method.
To illustrate the parameter tuning, we generate data from a sparse partially linear regression model.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="dd52f89a-e90d-4248-96a2-23ebce16b133" name="750a374a-4561-4dec-b331-4a1ac423a9d0" type="radio">
</input><label class="tabbed-label" for="dd52f89a-e90d-4248-96a2-23ebce16b133">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [18]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [19]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="gp">In [20]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3141</span><span class="p">)</span>

<span class="gp">In [21]: </span><span class="n">n_obs</span> <span class="o">=</span> <span class="mi">200</span>

<span class="gp">In [22]: </span><span class="n">n_vars</span> <span class="o">=</span> <span class="mi">200</span>

<span class="gp">In [23]: </span><span class="n">theta</span> <span class="o">=</span> <span class="mi">3</span>

<span class="gp">In [24]: </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_obs</span><span class="p">,</span> <span class="n">n_vars</span><span class="p">))</span>

<span class="gp">In [25]: </span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]))</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_obs</span><span class="p">,))</span>

<span class="gp">In [26]: </span><span class="n">y</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">*</span> <span class="n">d</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]))</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_obs</span><span class="p">,))</span>

<span class="gp">In [27]: </span><span class="n">dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The hyperparameter-tuning is performed using either an exhaustive search over specified parameter values
implemented in <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection.GridSearchCV</span></code></a> or via a randomized search implemented in
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection.RandomizedSearchCV</span></code></a>.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="b7b2895f-c65d-4d38-bdbc-c8560750deca" name="ac8af0b0-bd47-4000-a933-5de51f3a50a7" type="radio">
</input><label class="tabbed-label" for="b7b2895f-c65d-4d38-bdbc-c8560750deca">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [28]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [29]: </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span>

<span class="gp">In [30]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">()</span>

<span class="gp">In [31]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">()</span>

<span class="gp">In [32]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">)</span>

<span class="gp">In [33]: </span><span class="n">par_grids</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;ml_g&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)},</span>
<span class="gp">   ....: </span>             <span class="s1">&#39;ml_m&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)}}</span>
<span class="gp">   ....: </span>

<span class="gp">In [34]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span><span class="n">par_grids</span><span class="p">,</span> <span class="n">search_mode</span><span class="o">=</span><span class="s1">&#39;grid_search&#39;</span><span class="p">);</span>

<span class="gp">In [35]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
<span class="go">{&#39;ml_g&#39;: {&#39;d&#39;: [[{&#39;alpha&#39;: 0.45000000000000007}, {&#39;alpha&#39;: 0.45000000000000007}, {&#39;alpha&#39;: 0.45000000000000007}, {&#39;alpha&#39;: 0.45000000000000007}, {&#39;alpha&#39;: 0.45000000000000007}]]}, &#39;ml_m&#39;: {&#39;d&#39;: [[{&#39;alpha&#39;: 0.15000000000000002}, {&#39;alpha&#39;: 0.15000000000000002}, {&#39;alpha&#39;: 0.15000000000000002}, {&#39;alpha&#39;: 0.15000000000000002}, {&#39;alpha&#39;: 0.15000000000000002}]]}}</span>

<span class="gp">In [36]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err          t  P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  3.031134  0.071777  42.229759    0.0  2.890454  3.171815</span>

<span class="gp">In [37]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="gp">In [38]: </span><span class="n">par_grids</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;ml_g&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)},</span>
<span class="gp">   ....: </span>             <span class="s1">&#39;ml_m&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)}}</span>
<span class="gp">   ....: </span>

<span class="gp">In [39]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span><span class="n">par_grids</span><span class="p">,</span> <span class="n">search_mode</span><span class="o">=</span><span class="s1">&#39;randomized_search&#39;</span><span class="p">,</span> <span class="n">n_iter_randomized_search</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span>

<span class="gp">In [40]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
<span class="go">{&#39;ml_g&#39;: {&#39;d&#39;: [[{&#39;alpha&#39;: 0.4000000000000001}, {&#39;alpha&#39;: 0.4000000000000001}, {&#39;alpha&#39;: 0.4000000000000001}, {&#39;alpha&#39;: 0.4000000000000001}, {&#39;alpha&#39;: 0.4000000000000001}]]}, &#39;ml_m&#39;: {&#39;d&#39;: [[{&#39;alpha&#39;: 0.09000000000000001}, {&#39;alpha&#39;: 0.09000000000000001}, {&#39;alpha&#39;: 0.09000000000000001}, {&#39;alpha&#39;: 0.09000000000000001}, {&#39;alpha&#39;: 0.09000000000000001}]]}}</span>

<span class="gp">In [41]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">      coef   std err          t          P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  2.96582  0.086679  34.216207  1.388216e-256  2.795932  3.135707</span>
</pre></div>
</div>
</div>
</div>
<p>Hyperparameter tuning can also be done with more sophisticated methods, like for example an iterative fitting along
a regularization path implemented in <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.linear_model.LassoCV</span></code></a>.
In this case the tuning should be done externally and the parameters can then be set via the
<code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params()</span></code> method.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="e5be25c7-57df-4e12-a558-9c2132b24ce1" name="b12c20b8-d513-4518-b50d-7118c0d779eb" type="radio">
</input><label class="tabbed-label" for="e5be25c7-57df-4e12-a558-9c2132b24ce1">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [42]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [43]: </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LassoCV</span>

<span class="gp">In [44]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="gp">In [45]: </span><span class="n">ml_g_tune</span> <span class="o">=</span> <span class="n">LassoCV</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dml_data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">dml_data</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>

<span class="gp">In [46]: </span><span class="n">ml_m_tune</span> <span class="o">=</span> <span class="n">LassoCV</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dml_data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">dml_data</span><span class="o">.</span><span class="n">d</span><span class="p">)</span>

<span class="gp">In [47]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">()</span>

<span class="gp">In [48]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">()</span>

<span class="gp">In [49]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">)</span>

<span class="gp">In [50]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">set_ml_nuisance_params</span><span class="p">(</span><span class="s1">&#39;ml_g&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">ml_g_tune</span><span class="o">.</span><span class="n">alpha_</span><span class="p">});</span>

<span class="gp">In [51]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">set_ml_nuisance_params</span><span class="p">(</span><span class="s1">&#39;ml_m&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">ml_m_tune</span><span class="o">.</span><span class="n">alpha_</span><span class="p">});</span>

<span class="gp">In [52]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
<span class="go">{&#39;ml_g&#39;: {&#39;d&#39;: [[{&#39;alpha&#39;: 0.4311947070055128}, {&#39;alpha&#39;: 0.4311947070055128}, {&#39;alpha&#39;: 0.4311947070055128}, {&#39;alpha&#39;: 0.4311947070055128}, {&#39;alpha&#39;: 0.4311947070055128}]]}, &#39;ml_m&#39;: {&#39;d&#39;: [[{&#39;alpha&#39;: 0.14281403493938027}, {&#39;alpha&#39;: 0.14281403493938027}, {&#39;alpha&#39;: 0.14281403493938027}, {&#39;alpha&#39;: 0.14281403493938027}, {&#39;alpha&#39;: 0.14281403493938027}]]}}</span>

<span class="gp">In [53]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err          t  P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  3.048723  0.075869  40.183855    0.0  2.900021  3.197424</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="r-learners-and-hyperparameters">
<span id="learners-r"></span><h2><span class="section-number">6.2. </span>R: Learners and hyperparameters<a class="headerlink" href="#r-learners-and-hyperparameters" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id2">
<h3><span class="section-number">6.2.1. </span>Minimum requirements for learners<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>The minimum requirement for a learner to be used for nuisance models in the <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> package is</p>
<blockquote>
<div><ul class="simple">
<li><p>The implementation as a learner for regression or classification in the <a class="reference external" href="https://mlr3.mlr-org.com/">mlr3</a> package
or its extension packages <a class="reference external" href="https://mlr3learners.mlr-org.com/">mlr3learners</a> and
<a class="reference external" href="https://mlr3extralearners.mlr-org.com/">mlr3extralearners</a> . A guide on how to add a learner is provided in the
<a class="reference external" href="https://mlr3book.mlr-org.com/extending-learners.html">chapter on extending learners in the mlr3 book</a> .</p></li>
<li><p>The <a class="reference external" href="https://mlr3.mlr-org.com/">mlr3</a> package makes sure that the learners satisfy some core functionalities.
To specify a specific learner in <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> users can pass objects of the class
<a class="reference external" href="https://mlr3.mlr-org.com/reference/Learner.html">Learner</a>. A fast way to construct these objects is to use the
<a class="reference external" href="https://mlr3.mlr-org.com/">mlr3</a>  function <a class="reference external" href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn()</a>.
An introduction to learners in <a class="reference external" href="https://mlr3.mlr-org.com/">mlr3</a>  is provided in the <a class="reference external" href="https://mlr3book.mlr-org.com/learners.html">chapter on learners of the mlr3 book</a>.</p></li>
<li><p>The models <a class="reference external" href="https://docs.doubleml.org/r/stable/reference/DoubleMLIRM.html">DoubleML::DoubleMLIRM</a> and
<a class="reference external" href="https://docs.doubleml.org/r/stable/reference/DoubleMLIIVM.html">DoubleML::DoubleMLIIVM</a> require classifiers.</p></li>
<li><p>Hyperparameters of learners can either be set at instantiation in mlr3 or after instantiation using the
<code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params()</span></code> method.</p></li>
</ul>
</div></blockquote>
<p>An interactive list of provided learners in the <a class="reference external" href="https://mlr3.mlr-org.com/">mlr3</a> and extension packages can be found on the
<a class="reference external" href="https://mlr3extralearners.mlr-org.com/articles/learners/list_learners.html">website of the mlr3extralearners package</a>.</p>
</div>
<div class="section" id="id8">
<h3><span class="section-number">6.2.2. </span>Specifying learners and set hyperparameters<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>The learners are set during initialization of the <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> model classes
<a class="reference external" href="https://docs.doubleml.org/r/stable/reference/DoubleMLPLR.html">DoubleML::DoubleMLPLR</a>,
<a class="reference external" href="https://docs.doubleml.org/r/stable/reference/DoubleMLPLIV.html">DoubleML::DoubleMLPLIV</a> ,
<a class="reference external" href="https://docs.doubleml.org/r/stable/reference/DoubleMLIRM.html">DoubleML::DoubleMLIRM</a>
and <a class="reference external" href="https://docs.doubleml.org/r/stable/reference/DoubleMLIIVM.html">DoubleML::DoubleMLIIVM</a>.
Lets simulate some data and consider the partially linear regression model.
We need to specify learners for the nuisance functions <span class="math notranslate nohighlight">\(g_0(X) = E[Y|X]\)</span> and <span class="math notranslate nohighlight">\(m_0(X) = E[D|X]\)</span>,
for example <a class="reference external" href="https://mlr3learners.mlr-org.com/reference/mlr_learners_regr.ranger.html">LearnerRegrRanger</a>
(<code class="docutils literal notranslate"><span class="pre">lrn(&quot;regr.ranger&quot;)</span></code>) for regression with random forests based on the  <a class="reference external" href="https://github.com/imbs-hl/ranger">ranger</a>
package for R.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="c0e0a870-a1d7-4506-8489-8d55e4cc97e3" name="513c89b1-7433-4e1e-9394-88171afbae23" type="radio">
</input><label class="tabbed-label" for="c0e0a870-a1d7-4506-8489-8d55e4cc97e3">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span>library(DoubleML)
library(mlr3)
library(mlr3learners)
library(data.table)
lgr::get_logger(&quot;mlr3&quot;)$set_threshold(&quot;warn&quot;)

# set up a mlr3 learner
learner = lrn(&quot;regr.ranger&quot;)
ml_g = learner$clone()
ml_m = learner$clone()
set.seed(3141)
data = make_plr_CCDDHNR2018(alpha=0.5, return_type=&#39;data.table&#39;)
obj_dml_data = DoubleMLData$new(data, y_col=&quot;y&quot;, d_cols=&quot;d&quot;)
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m)
dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.57505    0.04458    12.9   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>Without further specification of the hyperparameters, default values are used. To set hyperparameters:</p>
<blockquote>
<div><ul class="simple">
<li><p>We can also use pre-parametrized learners <code class="docutils literal notranslate"><span class="pre">lrn(&quot;regr.ranger&quot;,</span> <span class="pre">num.trees=10)</span></code>.</p></li>
<li><p>Alternatively, hyperparameters can be set after initialization via the method
<code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params(learner,</span> <span class="pre">treat_var,</span> <span class="pre">params,</span> <span class="pre">set_fold_specific)</span></code>.</p></li>
</ul>
</div></blockquote>
<div class="tabbed-set docutils">
<input checked="checked" id="0ae17910-104d-40ba-8411-b04b45cc569a" name="9d5bc0ca-a795-48dd-8176-f32c103b5996" type="radio">
</input><label class="tabbed-label" for="0ae17910-104d-40ba-8411-b04b45cc569a">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span>set.seed(3141)
ml_g = lrn(&quot;regr.ranger&quot;, num.trees=10)
ml_m = lrn(&quot;regr.ranger&quot;)
obj_dml_data = DoubleMLData$new(data, y_col=&quot;y&quot;, d_cols=&quot;d&quot;)
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m)
dml_plr_obj$fit()
dml_plr_obj$summary()

set.seed(3141)
ml_g = lrn(&quot;regr.ranger&quot;)
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g , ml_m)
dml_plr_obj$set_ml_nuisance_params(&quot;ml_g&quot;, &quot;d&quot;, list(&quot;num.trees&quot;=10))
dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.58765    0.04532   12.97   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.58765    0.04532   12.97   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>Setting treatment-variable-specific or fold-specific hyperparameters:</p>
<blockquote>
<div><ul class="simple">
<li><p>In the multiple-treatment case, the method <code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params(learner,</span> <span class="pre">treat_var,</span> <span class="pre">params,</span> <span class="pre">set_fold_specific)</span></code>
can be used to set different hyperparameters for different treatment variables.</p></li>
<li><p>The method <code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params(learner,</span> <span class="pre">treat_var,</span> <span class="pre">params,</span> <span class="pre">set_fold_specific)</span></code> accepts lists for <code class="docutils literal notranslate"><span class="pre">params</span></code>.
The structure of the list depends on whether the same parameters should be provided for all folds or separate values
are passed for specific folds.</p></li>
<li><p>Global parameter passing: The values in <code class="docutils literal notranslate"><span class="pre">params</span></code> are used for estimation on all folds.
The named list in the argument <code class="docutils literal notranslate"><span class="pre">params</span></code> should have entries with names corresponding to
the parameters of the learners. It is required that option <code class="docutils literal notranslate"><span class="pre">set_fold_specific</span></code> is set to <code class="docutils literal notranslate"><span class="pre">FALSE</span></code> (default).</p></li>
<li><p>Fold-specific parameter passing: <code class="docutils literal notranslate"><span class="pre">params</span></code> is a nested list. The outer list needs to be of length <code class="docutils literal notranslate"><span class="pre">n_rep</span></code> and the inner
list of length <code class="docutils literal notranslate"><span class="pre">n_folds</span></code>. The innermost list must have named entries that correspond to the parameters of the learner.
It is required that option <code class="docutils literal notranslate"><span class="pre">set_fold_specific</span></code> is set to <code class="docutils literal notranslate"><span class="pre">TRUE</span></code>. Moreover, fold-specific
parameter passing is only supported, if all parameters are set fold-specific.</p></li>
<li><p>External setting of parameters will override previously set parameters. To assert the choice of parameters, access the
fields <code class="docutils literal notranslate"><span class="pre">$learner</span></code> and <code class="docutils literal notranslate"><span class="pre">$params</span></code>.</p></li>
</ul>
</div></blockquote>
<div class="tabbed-set docutils">
<input checked="checked" id="24a1d51b-82c9-4dbc-9296-dc09ae43937a" name="e57e8f6a-c4d3-4ab1-9f08-b72c594865ac" type="radio">
</input><label class="tabbed-label" for="24a1d51b-82c9-4dbc-9296-dc09ae43937a">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span>set.seed(3141)
ml_g = lrn(&quot;regr.ranger&quot;)
ml_m = lrn(&quot;regr.ranger&quot;)
obj_dml_data = DoubleMLData$new(data, y_col=&quot;y&quot;, d_cols=&quot;d&quot;)

n_rep = 2
n_folds = 3
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m, n_rep=n_rep, n_folds=n_folds)

# Set globally
params = list(&quot;num.trees&quot;=10)
dml_plr_obj$set_ml_nuisance_params(&quot;ml_g&quot;, &quot;d&quot;, params=params)
dml_plr_obj$set_ml_nuisance_params(&quot;ml_m&quot;, &quot;d&quot;, params=params)
dml_plr_obj$learner
dml_plr_obj$params
dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>$ml_g
&lt;LearnerRegrRanger:regr.ranger&gt;
* Model: -
* Parameters: num.threads=1
* Packages: ranger
* Predict Type: response
* Feature types: logical, integer, numeric, character, factor, ordered
* Properties: importance, oob_error, weights

$ml_m
&lt;LearnerRegrRanger:regr.ranger&gt;
* Model: -
* Parameters: num.threads=1
* Packages: ranger
* Predict Type: response
* Feature types: logical, integer, numeric, character, factor, ordered
* Properties: importance, oob_error, weights
</pre></div>
</div>
<div class="output text_html"><dl>
	<dt>$ml_g</dt>
		<dd><strong>$d</strong> = <strong>$num.trees</strong> = 10</dd>
	<dt>$ml_m</dt>
		<dd><strong>$d</strong> = <strong>$num.trees</strong> = 10</dd>
</dl>
</div><div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.52486    0.04593   11.43   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>The following example illustrates how to set parameters for each fold.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="5f51f151-880e-463e-ac17-77722aaaac02" name="b5c34e7b-0b44-444a-a9b9-98061d6e9773" type="radio">
</input><label class="tabbed-label" for="5f51f151-880e-463e-ac17-77722aaaac02">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span>learner = lrn(&quot;regr.ranger&quot;)
ml_g = learner$clone()
ml_m = learner$clone()
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m, n_rep=n_rep, n_folds=n_folds)

# Set values for each fold
params_exact = rep(list(rep(list(params), n_folds)), n_rep)
dml_plr_obj$set_ml_nuisance_params(&quot;ml_g&quot;, &quot;d&quot;, params=params_exact,
                                     set_fold_specific=TRUE)
dml_plr_obj$set_ml_nuisance_params(&quot;ml_m&quot;, &quot;d&quot;, params=params_exact,
                                     set_fold_specific=TRUE)
dml_plr_obj$learner
dml_plr_obj$params
dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>$ml_g
&lt;LearnerRegrRanger:regr.ranger&gt;
* Model: -
* Parameters: num.threads=1
* Packages: ranger
* Predict Type: response
* Feature types: logical, integer, numeric, character, factor, ordered
* Properties: importance, oob_error, weights

$ml_m
&lt;LearnerRegrRanger:regr.ranger&gt;
* Model: -
* Parameters: num.threads=1
* Packages: ranger
* Predict Type: response
* Feature types: logical, integer, numeric, character, factor, ordered
* Properties: importance, oob_error, weights
</pre></div>
</div>
<div class="output text_html"><dl>
	<dt>$ml_g</dt>
		<dd><strong>$d</strong> = <ol>
	<li><ol>
	<li><strong>$num.trees</strong> = 10</li>
	<li><strong>$num.trees</strong> = 10</li>
	<li><strong>$num.trees</strong> = 10</li>
</ol>
</li>
	<li><ol>
	<li><strong>$num.trees</strong> = 10</li>
	<li><strong>$num.trees</strong> = 10</li>
	<li><strong>$num.trees</strong> = 10</li>
</ol>
</li>
</ol>
</dd>
	<dt>$ml_m</dt>
		<dd><strong>$d</strong> = <ol>
	<li><ol>
	<li><strong>$num.trees</strong> = 10</li>
	<li><strong>$num.trees</strong> = 10</li>
	<li><strong>$num.trees</strong> = 10</li>
</ol>
</li>
	<li><ol>
	<li><strong>$num.trees</strong> = 10</li>
	<li><strong>$num.trees</strong> = 10</li>
	<li><strong>$num.trees</strong> = 10</li>
</ol>
</li>
</ol>
</dd>
</dl>
</div><div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.49098    0.06137       8 1.24e-15 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="id11">
<h3><span class="section-number">6.2.3. </span>Hyperparameter tuning<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<p>Parameter tuning of learners for the nuisance functions of <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> models can be done via the <code class="docutils literal notranslate"><span class="pre">tune()</span></code> method.
The <code class="docutils literal notranslate"><span class="pre">tune()</span></code> method passes various options and parameters to the tuning interface provided by the
<a class="reference external" href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a> package. The <a class="reference external" href="https://mlr3book.mlr-org.com/">mlr3 book</a> provides a
<a class="reference external" href="https://mlr3book.mlr-org.com/optimization.html">step-by-step introduction to parameter tuning</a>.</p>
<p>To illustrate the parameter tuning, we generate data from a sparse partially linear regression model.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="85b2d783-bcbd-4779-a27f-645a088a00f6" name="b5838d3d-b59f-44b8-b95c-471c070f559f" type="radio">
</input><label class="tabbed-label" for="85b2d783-bcbd-4779-a27f-645a088a00f6">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="n">library</span><span class="p">(</span><span class="n">DoubleML</span><span class="p">)</span>
<span class="n">library</span><span class="p">(</span><span class="n">mlr3</span><span class="p">)</span>
<span class="n">library</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">table</span><span class="p">)</span>

<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3141</span><span class="p">)</span>
<span class="n">n_obs</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">n_vars</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">theta</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="n">stats</span><span class="p">::</span><span class="n">rnorm</span><span class="p">(</span><span class="n">n_obs</span> <span class="o">*</span> <span class="n">n_vars</span><span class="p">),</span> <span class="n">nrow</span> <span class="o">=</span> <span class="n">n_obs</span><span class="p">,</span> <span class="n">ncol</span> <span class="o">=</span> <span class="n">n_vars</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="p">[,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="n">drop</span> <span class="o">=</span> <span class="n">FALSE</span><span class="p">]</span> <span class="o">%*%</span> <span class="n">c</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span> <span class="o">+</span> <span class="n">stats</span><span class="p">::</span><span class="n">rnorm</span><span class="p">(</span><span class="n">n_obs</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">*</span> <span class="n">d</span> <span class="o">+</span> <span class="n">X</span><span class="p">[,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="n">drop</span> <span class="o">=</span> <span class="n">FALSE</span><span class="p">]</span> <span class="o">%*%</span> <span class="n">c</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>  <span class="o">+</span> <span class="n">stats</span><span class="p">::</span><span class="n">rnorm</span><span class="p">(</span><span class="n">n_obs</span><span class="p">)</span>
<span class="n">dml_data</span> <span class="o">=</span> <span class="n">double_ml_data_from_matrix</span><span class="p">(</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">d</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
</div>
</div>
</div>
</div>
<p>The hyperparameter-tuning is performed according to options passed through a named list <code class="docutils literal notranslate"><span class="pre">tune_settings</span></code>.
The entries in the list specify options during parameter tuning with <a class="reference external" href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a>:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">terminator</span></code> is a <a class="reference external" href="https://bbotk.mlr-org.com/reference/Terminator.html">Terminator object</a> passed to
<a class="reference external" href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a> that manages the budget to solve the tuning problem.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">algorithm</span></code> is an object of class
<a class="reference external" href="https://mlr3tuning.mlr-org.com/reference/Tuner.html">Tuner</a> and specifies the tuning algorithm.
Alternatively, <code class="docutils literal notranslate"><span class="pre">algorithm</span></code> can be a <code class="docutils literal notranslate"><span class="pre">character()</span></code> that is used as an argument in the wrapper
<a class="reference external" href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a> call
<a class="reference external" href="https://mlr3tuning.mlr-org.com/reference/tnr.html">tnr(algorithm)</a>.
<a class="reference external" href="https://mlr3book.mlr-org.com/tuning.html#the-tuner-class">The corresponding chapter in the mlr3book</a> illustrates
how the <a class="reference external" href="https://mlr3tuning.mlr-org.com/reference/Tuner.html">Tuner</a> class supports grid search, random search,
generalized simulated annealing and non-linear optimization.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rsmp_tune</span></code> is an object of class <a class="reference external" href="https://mlr3.mlr-org.com/reference/Resampling.html">mlr3 resampling</a>
that specifies the resampling method for evaluation, for example <cite>rsmp(“cv”, folds = 5)</cite> implements 5-fold cross-validation.
<cite>rsmp(“holdout”, ratio = 0.8)</cite> implements an evaluation based on a hold-out sample that contains 20 percent of the observations.
By default, 5-fold cross-validation is performed.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">measure</span></code> is a named list containing the measures used for tuning of the nuisance components.
The names of the entries must match the learner names (see method <code class="docutils literal notranslate"><span class="pre">learner_names()</span></code>).  The entries in the list must either be
objects of class <a class="reference external" href="https://mlr3.mlr-org.com/reference/Measure.html">Measure</a> or keys passed to <a class="reference external" href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr()</a>.
If <code class="docutils literal notranslate"><span class="pre">measure</span></code> is not provided by the user, default measures are used, i.e., mean squared error for regression models
and classification error for binary outcomes.</p></li>
</ul>
</div></blockquote>
<p>In the following example, we tune the penalty parameter <span class="math notranslate nohighlight">\(\lambda\)</span> (<code class="docutils literal notranslate"><span class="pre">lambda</span></code>) for lasso with the R package
<a class="reference external" href="https://glmnet.stanford.edu/">glmnet</a>. To tune the value of <code class="docutils literal notranslate"><span class="pre">lambda</span></code>, a grid search  is performed over a grid of values that range from 0.05
to 0.1 at a resolution of 10. Using a resolution of 10 splits the grid of values in 10 equally spaced values ranging from a minimum of 0.05
to a maximum of 0.1. To evaluate the predictive performance in both nuisance parts, the cross-validated mean squared error is used.</p>
<p>Setting the option <code class="docutils literal notranslate"><span class="pre">tune_on_folds=FALSE</span></code>, the tuning is performed on the whole sample. Hence, the cross-validated errors
are obtained from a random split of the whole sample into 5 folds. As a result, one set of <code class="docutils literal notranslate"><span class="pre">lambda</span></code> values are obtained
which are later used in the fitting stage for all folds.</p>
<p>Alternatively, setting the option <code class="docutils literal notranslate"><span class="pre">tune_on_folds=TRUE</span></code> would assign the tuning resampling scheme <code class="docutils literal notranslate"><span class="pre">rsmp_tune</span></code> to each fold.
For example, if we set <code class="docutils literal notranslate"><span class="pre">n_folds=2</span></code> at initialization of the <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code> object and use a 5-fold cross-validated error
for tuning, each of the two folds would be split up into 5 subfolds and the error would be evaluated on these subfolds.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="7cbc6d07-7c37-44ab-a0db-32971bc13a14" name="fd05e8a2-d86c-491d-9c6c-ab22ad8240a1" type="radio">
</input><label class="tabbed-label" for="7cbc6d07-7c37-44ab-a0db-32971bc13a14">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span>library(DoubleML)
library(mlr3)
library(data.table)
library(mlr3learners)
library(mlr3tuning)
library(paradox)
lgr::get_logger(&quot;mlr3&quot;)$set_threshold(&quot;warn&quot;)
lgr::get_logger(&quot;bbotk&quot;)$set_threshold(&quot;warn&quot;)

set.seed(1234)
ml_g = lrn(&quot;regr.glmnet&quot;)
ml_m = lrn(&quot;regr.glmnet&quot;)
dml_plr_obj = DoubleMLPLR$new(dml_data, ml_g, ml_m)

par_grids = list(&quot;ml_g&quot; = ParamSet$new(list(
                                  ParamDbl$new(&quot;lambda&quot;, lower = 0.05, upper = 0.1))),
                 &quot;ml_m&quot; =  ParamSet$new(list(
                                  ParamDbl$new(&quot;lambda&quot;, lower = 0.05, upper = 0.1))))

tune_settings = list(terminator = trm(&quot;evals&quot;, n_evals = 100),
                      algorithm = tnr(&quot;grid_search&quot;, resolution = 10),
                      rsmp_tune = rsmp(&quot;cv&quot;, folds = 5),
                      measure = list(&quot;ml_g&quot; = msr(&quot;regr.mse&quot;),
                                     &quot;ml_m&quot; = msr(&quot;regr.mse&quot;)))
dml_plr_obj$tune(param_set=par_grids, tune_settings=tune_settings, tune_on_fold=TRUE)
dml_plr_obj$params

dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><dl>
	<dt>$ml_g</dt>
		<dd><strong>$d</strong> = <ol>
	<li><ol>
	<li><strong>$lambda</strong> = 0.1</li>
	<li><strong>$lambda</strong> = 0.0777777777777778</li>
	<li><strong>$lambda</strong> = 0.1</li>
	<li><strong>$lambda</strong> = 0.1</li>
	<li><strong>$lambda</strong> = 0.1</li>
</ol>
</li>
</ol>
</dd>
	<dt>$ml_m</dt>
		<dd><strong>$d</strong> = <ol>
	<li><ol>
	<li><strong>$lambda</strong> = 0.1</li>
	<li><strong>$lambda</strong> = 0.1</li>
	<li><strong>$lambda</strong> = 0.1</li>
	<li><strong>$lambda</strong> = 0.1</li>
	<li><strong>$lambda</strong> = 0.1</li>
</ol>
</li>
</ol>
</dd>
</dl>
</div><div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)    
d    3.0425     0.1424   21.37   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>Hyperparameter tuning can also be done with more sophisticated methods, for example by using built-in tuning
paths of learners. For example, the learner <a class="reference external" href="https://mlr3learners.mlr-org.com/reference/mlr_learners_regr.cv_glmnet.html">regr.cv_glmnet</a>
performs an internal cross-validated choice of the parameter <code class="docutils literal notranslate"><span class="pre">lambda</span></code>.
Alternatively, the powerful functionalities of the <a class="reference external" href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a> package can be used for
external parameter tuning of the nuisance parts. The optimally chosen parameters can then be passed to the
<a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> models using the <code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params()</span></code> method.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="19429a15-665c-43ad-b990-a4d169162b22" name="612eec5c-2456-4ada-bb76-8cfaf518877a" type="radio">
</input><label class="tabbed-label" for="19429a15-665c-43ad-b990-a4d169162b22">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span>library(DoubleML)
library(mlr3)
library(data.table)
library(mlr3learners)
library(mlr3tuning)
lgr::get_logger(&quot;mlr3&quot;)$set_threshold(&quot;warn&quot;)
lgr::get_logger(&quot;bbotk&quot;)$set_threshold(&quot;warn&quot;)

set.seed(1234)
ml_g = lrn(&quot;regr.cv_glmnet&quot;, s=&quot;lambda.min&quot;)
ml_m = lrn(&quot;regr.cv_glmnet&quot;, s=&quot;lambda.min&quot;)
dml_plr_obj = DoubleMLPLR$new(dml_data, ml_g, ml_m)

dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   3.08848    0.07366   41.93   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>The following code chunk illustrates another example for global parameter tuning with random forests
as provided by the  <a class="reference external" href="https://github.com/imbs-hl/ranger">ranger</a> package. In this example, we use random search to find optimal
parameters <code class="docutils literal notranslate"><span class="pre">mtry</span></code> and <code class="docutils literal notranslate"><span class="pre">max.depth</span></code> of a random forest. Evaluation is based on 3-fold cross-validation.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="ccd94405-3ae4-4b35-88ed-1de2bd4a8fd2" name="7c799904-6d54-45c4-8052-43bca75d1b60" type="radio">
</input><label class="tabbed-label" for="ccd94405-3ae4-4b35-88ed-1de2bd4a8fd2">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span>library(DoubleML)
library(mlr3)
library(mlr3learners)
library(data.table)
library(mlr3tuning)
library(paradox)
lgr::get_logger(&quot;mlr3&quot;)$set_threshold(&quot;warn&quot;)
lgr::get_logger(&quot;bbotk&quot;)$set_threshold(&quot;warn&quot;)

# set up a mlr3 learner
learner = lrn(&quot;regr.ranger&quot;)
ml_g = learner$clone()
ml_m = learner$clone()

set.seed(3141)
obj_dml_data = make_plr_CCDDHNR2018(alpha=0.5)
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m)

# set up a list of parameter grids
param_grid = list(&quot;ml_g&quot; = ParamSet$new(list(
                                  ParamInt$new(&quot;mtry&quot;, lower = 2 , upper = 20),
                                  ParamInt$new(&quot;max.depth&quot;, lower = 2, upper = 5))),
                  &quot;ml_m&quot; = ParamSet$new(list(
                                  ParamInt$new(&quot;mtry&quot;, lower = 2 , upper = 20),
                                  ParamInt$new(&quot;max.depth&quot;, lower = 2, upper = 5))))
tune_settings = list(terminator = mlr3tuning::trm(&quot;evals&quot;, n_evals = 20),
                      algorithm = tnr(&quot;random_search&quot;),
                      rsmp_tune = rsmp(&quot;cv&quot;, folds = 3),
                      measure = list(&quot;ml_g&quot; = msr(&quot;regr.mse&quot;),
                                     &quot;ml_m&quot; = msr(&quot;regr.mse&quot;)))
dml_plr_obj$tune(param_set=param_grid, tune_settings=tune_settings, tune_on_folds=FALSE)
dml_plr_obj$params

dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><dl>
	<dt>$ml_g</dt>
		<dd><strong>$d</strong> = <dl>
	<dt>$mtry</dt>
		<dd>10</dd>
	<dt>$max.depth</dt>
		<dd>5</dd>
</dl>
</dd>
	<dt>$ml_m</dt>
		<dd><strong>$d</strong> = <dl>
	<dt>$mtry</dt>
		<dd>17</dd>
	<dt>$max.depth</dt>
		<dd>3</dd>
</dl>
</dd>
</dl>
</div><div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.55348    0.04559   12.14   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="references">
<h4><span class="section-number">6.2.3.1. </span>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>Lang, M., Binder, M., Richter, J., Schratz, P., Pfisterer, F., Coors, S., Au, Q., Casalicchio, G., Kotthoff, L., Bischl, B. (2019), mlr3: A modern object-oriented machine learing framework in R. Journal of Open Source Software, <a class="reference external" href="(doi:10.21105/joss.01903)[10.21105/joss.01903]">doi:10.21105/joss.01903</a>.</p></li>
<li><p>Becker, M., Binder, M., Bischl, B., Lang, M., Pfisterer, F., Reich, N.G., Richter, J., Schratz, P., Sonabend, R. (2020), mlr3 book, available at <a class="reference external" href="https://mlr3book.mlr-org.com">https://mlr3book.mlr-org.com</a>.</p></li>
</ul>
</div>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="algorithms.html" title="previous page"><span class="section-number">5. </span>Double machine learning algorithms</a>
    <a class='right-next' id="next-link" href="se_confint.html" title="next page"><span class="section-number">7. </span>Variance estimation and confidence intervals for a causal parameter of interest</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d8bbf5861d671d414e1a.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>