
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>6. Learners, hyperparameters and hyperparameter tuning &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.101715efdecc9b59cb6e1ddfa685c31f.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d8bbf5861d671d414e1a.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="7. Variance estimation, confidence intervals and multiplier bootstrap" href="se_confint.html" />
    <link rel="prev" title="5. Double machine learning algorithms" href="algorithms.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">


    
    <a class="navbar-brand" href="../index.html">
      <p class="title">DoubleML</p>
    </a>
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  DoubleML
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/install.html">
  Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/intro.html">
  Getting started
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="guide.html">
  User guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../auto_examples/index.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api.html">
  Python API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference external nav-link" href="https://docs.doubleml.org/r/stable/">
  R API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../release/release.html">
  Release notes
 </a>
</li>

        
      </ul>

      <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><p class="logo" style="text-align:center;"><a href="../index.html">
    <img class="logo" src="../logo.png" alt="Logo" width="65%" height="65%">
</a></p><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l2">
  <a class="reference internal" href="basics.html">
   1.  The basics of double/debiased machine learning
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="data_backend.html">
   2.  The data-backend DoubleMLData
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="models.html">
   3.  Models
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="scores.html">
   4.  Score functions
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="algorithms.html">
   5.  Double machine learning algorithms
  </a>
 </li>
 <li class="toctree-l2 current active">
  <a class="current reference internal" href="#">
   6.  Machine learners, hyperparameters and hyperparameter tuning
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="se_confint.html">
   7.  Variance estimation, confidence intervals and boostrap standard errors
  </a>
 </li>
 <li class="toctree-l2">
  <a class="reference internal" href="resampling.html">
   8.  Sample-splitting, cross-fitting and repeated cross-fitting
  </a>
 </li>
</ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#python-learners-and-hyperparameters">
   6.1. Python: Learners and hyperparameters
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#minimum-requirements-for-learners">
     6.1.1. Minimum requirements for learners
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#specifying-learners-and-set-hyperparameters">
     6.1.2. Specifying learners and set hyperparameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hyperparameter-tuning">
     6.1.3. Hyperparameter tuning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#r-learners-and-hyperparameters">
   6.2. R: Learners and hyperparameters
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     6.2.1. Minimum requirements for learners
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     6.2.2. Specifying learners and set hyperparameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     6.2.3. Hyperparameter tuning
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#references">
       6.2.3.1. References
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="learners-hyperparameters-and-hyperparameter-tuning">
<span id="learners"></span><h1><span class="section-number">6. </span>Learners, hyperparameters and hyperparameter tuning<a class="headerlink" href="#learners-hyperparameters-and-hyperparameter-tuning" title="Permalink to this headline">¶</a></h1>
<p>The estimation of a double/debiased machine learning model involves the estimation of several nuisance function with
machine learning estimators.
Such learners are implemented in various Python and R packages.
The implementation of <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> is based on the meta-packages
<a class="reference external" href="https://scikit-learn.org/">scikit-learn</a> for Python and <a class="reference external" href="https://mlr3.mlr-org.com/">mlr3</a> for R.
The interfaces to specify the learners, set hyperparameters and tune hyperparameters are described in the following
separately for <a class="reference internal" href="#learners-python"><span class="std std-ref">Python</span></a> and <a class="reference internal" href="#learners-r"><span class="std std-ref">R</span></a>.</p>
<div class="section" id="python-learners-and-hyperparameters">
<span id="learners-python"></span><h2><span class="section-number">6.1. </span>Python: Learners and hyperparameters<a class="headerlink" href="#python-learners-and-hyperparameters" title="Permalink to this headline">¶</a></h2>
<div class="section" id="minimum-requirements-for-learners">
<h3><span class="section-number">6.1.1. </span>Minimum requirements for learners<a class="headerlink" href="#minimum-requirements-for-learners" title="Permalink to this headline">¶</a></h3>
<p>The minimum requirement for a learner to be used for nuisance models in the <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a>
package is</p>
<blockquote>
<div><ul class="simple">
<li><p>The implementation of a <code class="docutils literal notranslate"><span class="pre">fit()</span></code> and <code class="docutils literal notranslate"><span class="pre">predict()</span></code> method.
Some models, like <a class="reference internal" href="../api/generated/doubleml.DoubleMLIRM.html#doubleml.DoubleMLIRM" title="doubleml.DoubleMLIRM"><code class="xref py py-class docutils literal notranslate"><span class="pre">doubleml.DoubleMLIRM</span></code></a> and <a class="reference internal" href="../api/generated/doubleml.DoubleMLIIVM.html#doubleml.DoubleMLIIVM" title="doubleml.DoubleMLIIVM"><code class="xref py py-class docutils literal notranslate"><span class="pre">doubleml.DoubleMLIIVM</span></code></a> require classifiers.</p></li>
<li><p>In case of classifiers, the learner needs to come with a <code class="docutils literal notranslate"><span class="pre">predict_proba()</span></code> instead of, or in addition to, a
<code class="docutils literal notranslate"><span class="pre">predict()</span></code> method, see for example <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict_proba" title="(in scikit-learn v0.24)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sklearn.ensemble.RandomForestClassifier.predict_proba()</span></code></a>.</p></li>
<li><p>In order to be able to use the <code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params()</span></code> method of <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> classes the
learner additionally needs to come with a <code class="docutils literal notranslate"><span class="pre">set_params()</span></code> method,
see for example <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor.set_params" title="(in scikit-learn v0.24)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sklearn.ensemble.RandomForestRegressor.set_params()</span></code></a>.</p></li>
<li><p>We further rely on the function <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="(in scikit-learn v0.24)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.base.clone()</span></code></a> which adds the requirement of a <code class="docutils literal notranslate"><span class="pre">get_params()</span></code>
method for a learner in order to be used for nuisance models of <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> model classes.</p></li>
</ul>
</div></blockquote>
<p>Most learners from <a class="reference external" href="https://scikit-learn.org/">scikit-learn</a> satisfy all these minimum requirements.</p>
</div>
<div class="section" id="specifying-learners-and-set-hyperparameters">
<h3><span class="section-number">6.1.2. </span>Specifying learners and set hyperparameters<a class="headerlink" href="#specifying-learners-and-set-hyperparameters" title="Permalink to this headline">¶</a></h3>
<p>The learners are set during initialization of the <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> model classes
<a class="reference internal" href="../api/generated/doubleml.DoubleMLPLR.html#doubleml.DoubleMLPLR" title="doubleml.DoubleMLPLR"><code class="xref py py-class docutils literal notranslate"><span class="pre">doubleml.DoubleMLPLR</span></code></a>, <a class="reference internal" href="../api/generated/doubleml.DoubleMLPLIV.html#doubleml.DoubleMLPLIV" title="doubleml.DoubleMLPLIV"><code class="xref py py-class docutils literal notranslate"><span class="pre">doubleml.DoubleMLPLIV</span></code></a>,
<a class="reference internal" href="../api/generated/doubleml.DoubleMLIRM.html#doubleml.DoubleMLIRM" title="doubleml.DoubleMLIRM"><code class="xref py py-class docutils literal notranslate"><span class="pre">doubleml.DoubleMLIRM</span></code></a> and <a class="reference internal" href="../api/generated/doubleml.DoubleMLIIVM.html#doubleml.DoubleMLIIVM" title="doubleml.DoubleMLIIVM"><code class="xref py py-class docutils literal notranslate"><span class="pre">doubleml.DoubleMLIIVM</span></code></a>.
Lets simulate some data and consider the partially linear regression model.
We need to specify learners for the nuisance functions <span class="math notranslate nohighlight">\(g_0(X) = E[Y|X]\)</span> and <span class="math notranslate nohighlight">\(m_0(X) = E[D|X]\)</span>,
for example <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.ensemble.RandomForestRegressor</span></code></a>.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="42a0a80d-2d0a-4e93-b27b-ad4cd14c2fc7" name="f289bb6b-787f-4f70-bffc-384e45092f35" type="radio">
</input><label class="tabbed-label" for="42a0a80d-2d0a-4e93-b27b-ad4cd14c2fc7">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [2]: </span><span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_plr_CCDDHNR2018</span>

<span class="gp">In [3]: </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="gp">In [4]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="gp">In [5]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span>

<span class="gp">In [6]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span>

<span class="gp">In [7]: </span><span class="n">data</span> <span class="o">=</span> <span class="n">make_plr_CCDDHNR2018</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;DataFrame&#39;</span><span class="p">)</span>

<span class="gp">In [8]: </span><span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

<span class="gp">In [9]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">)</span>

<span class="gp">In [10]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span>
<span class="gh">Out[10]: </span><span class="go"></span>
<span class="go">       coef   std err          t         P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.541552  0.044175  12.259346  1.497029e-34  0.454971  0.628133</span>
</pre></div>
</div>
</div>
</div>
<p>Setting hyperparameters:</p>
<blockquote>
<div><ul class="simple">
<li><p>We can also use pre-parametrized learners, like <code class="docutils literal notranslate"><span class="pre">RandomForestRegressor(n_estimators=10)</span></code>.</p></li>
<li><p>Alternatively, hyperparameters can also be set after initialization via the method
<code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params(learner,</span> <span class="pre">treat_var,</span> <span class="pre">params)</span></code></p></li>
</ul>
</div></blockquote>
<div class="tabbed-set docutils">
<input checked="checked" id="0f5e12cf-2890-402d-8ef1-37d61f2c0641" name="7e97b2c1-0160-4e43-88f4-6be2c8123632" type="radio">
</input><label class="tabbed-label" for="0f5e12cf-2890-402d-8ef1-37d61f2c0641">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [11]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="gp">In [12]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
<span class="gp">   ....: </span>                              <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
<span class="gp">   ....: </span>                              <span class="n">RandomForestRegressor</span><span class="p">())</span>
<span class="gp">   ....: </span>

<span class="gp">In [13]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err          t         P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.571865  0.041953  13.631007  2.619424e-42  0.489638  0.654092</span>

<span class="gp">In [14]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="gp">In [15]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
<span class="gp">   ....: </span>                              <span class="n">RandomForestRegressor</span><span class="p">(),</span>
<span class="gp">   ....: </span>                              <span class="n">RandomForestRegressor</span><span class="p">())</span>
<span class="gp">   ....: </span>

<span class="gp">In [16]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">set_ml_nuisance_params</span><span class="p">(</span><span class="s1">&#39;ml_g&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">});</span>

<span class="gp">In [17]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err          t         P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.571865  0.041953  13.631007  2.619424e-42  0.489638  0.654092</span>
</pre></div>
</div>
</div>
</div>
<p>Setting treatment-variable-specific or fold-specific hyperparameters:</p>
<blockquote>
<div><ul class="simple">
<li><p>In the multiple-treatment case, the method <code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params(learner,</span> <span class="pre">treat_var,</span> <span class="pre">params)</span></code> allows to set
different hyperparameters for different treatment variables.</p></li>
<li><p>The method <code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params(learner,</span> <span class="pre">treat_var,</span> <span class="pre">params)</span></code> accepts dicts and lists for <code class="docutils literal notranslate"><span class="pre">params</span></code>.
A dict should be provided if for each fold the same hyperparameters should be used.
Fold-specific parameters are supported. To do so,  provide a nested list as <code class="docutils literal notranslate"><span class="pre">params</span></code>, where the outer list is of
length <code class="docutils literal notranslate"><span class="pre">n_rep</span></code> and the inner list of length <code class="docutils literal notranslate"><span class="pre">n_folds</span></code>.</p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="hyperparameter-tuning">
<h3><span class="section-number">6.1.3. </span>Hyperparameter tuning<a class="headerlink" href="#hyperparameter-tuning" title="Permalink to this headline">¶</a></h3>
<p>Parameter tuning of learners for the nuisance functions of <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> models can be done via
the <code class="docutils literal notranslate"><span class="pre">tune()</span></code> method.
To illustrate the parameter tuning, we generate data from a sparse partially linear regression model.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="6c6fb630-0cb7-4b33-bffa-b6ae5647628b" name="3d7c453c-18e3-4e91-b202-120521d3f693" type="radio">
</input><label class="tabbed-label" for="6c6fb630-0cb7-4b33-bffa-b6ae5647628b">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [18]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [19]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="gp">In [20]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3141</span><span class="p">)</span>

<span class="gp">In [21]: </span><span class="n">n_obs</span> <span class="o">=</span> <span class="mi">200</span>

<span class="gp">In [22]: </span><span class="n">n_vars</span> <span class="o">=</span> <span class="mi">200</span>

<span class="gp">In [23]: </span><span class="n">theta</span> <span class="o">=</span> <span class="mi">3</span>

<span class="gp">In [24]: </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_obs</span><span class="p">,</span> <span class="n">n_vars</span><span class="p">))</span>

<span class="gp">In [25]: </span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]))</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_obs</span><span class="p">,))</span>

<span class="gp">In [26]: </span><span class="n">y</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">*</span> <span class="n">d</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]))</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_obs</span><span class="p">,))</span>

<span class="gp">In [27]: </span><span class="n">dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The hyperparameter-tuning is performed using either an exhaustive search over specified parameter values
implemented in <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection.GridSearchCV</span></code></a> or via a randomized search implemented in
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.model_selection.RandomizedSearchCV</span></code></a>.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="ae59714a-3a67-4ab0-b09a-bd2420213925" name="9ea2738c-d24a-43eb-9d9d-bd6271725ce2" type="radio">
</input><label class="tabbed-label" for="ae59714a-3a67-4ab0-b09a-bd2420213925">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [28]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [29]: </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span>

<span class="gp">In [30]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">()</span>

<span class="gp">In [31]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">()</span>

<span class="gp">In [32]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">)</span>

<span class="gp">In [33]: </span><span class="n">par_grids</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;ml_g&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)},</span>
<span class="gp">   ....: </span>             <span class="s1">&#39;ml_m&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)}}</span>
<span class="gp">   ....: </span>

<span class="gp">In [34]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span><span class="n">par_grids</span><span class="p">,</span> <span class="n">search_mode</span><span class="o">=</span><span class="s1">&#39;grid_search&#39;</span><span class="p">);</span>

<span class="gp">In [35]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
<span class="go">{&#39;ml_g&#39;: {&#39;d&#39;: [[{&#39;alpha&#39;: 0.45000000000000007}, {&#39;alpha&#39;: 0.45000000000000007}, {&#39;alpha&#39;: 0.45000000000000007}, {&#39;alpha&#39;: 0.45000000000000007}, {&#39;alpha&#39;: 0.45000000000000007}]]}, &#39;ml_m&#39;: {&#39;d&#39;: [[{&#39;alpha&#39;: 0.15000000000000002}, {&#39;alpha&#39;: 0.15000000000000002}, {&#39;alpha&#39;: 0.15000000000000002}, {&#39;alpha&#39;: 0.15000000000000002}, {&#39;alpha&#39;: 0.15000000000000002}]]}}</span>

<span class="gp">In [36]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err          t  P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  3.031134  0.071777  42.229759    0.0  2.890454  3.171815</span>

<span class="gp">In [37]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="gp">In [38]: </span><span class="n">par_grids</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;ml_g&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)},</span>
<span class="gp">   ....: </span>             <span class="s1">&#39;ml_m&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)}}</span>
<span class="gp">   ....: </span>

<span class="gp">In [39]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span><span class="n">par_grids</span><span class="p">,</span> <span class="n">search_mode</span><span class="o">=</span><span class="s1">&#39;randomized_search&#39;</span><span class="p">,</span> <span class="n">n_iter_randomized_search</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span>

<span class="gp">In [40]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
<span class="go">{&#39;ml_g&#39;: {&#39;d&#39;: [[{&#39;alpha&#39;: 0.4000000000000001}, {&#39;alpha&#39;: 0.4000000000000001}, {&#39;alpha&#39;: 0.4000000000000001}, {&#39;alpha&#39;: 0.4000000000000001}, {&#39;alpha&#39;: 0.4000000000000001}]]}, &#39;ml_m&#39;: {&#39;d&#39;: [[{&#39;alpha&#39;: 0.09000000000000001}, {&#39;alpha&#39;: 0.09000000000000001}, {&#39;alpha&#39;: 0.09000000000000001}, {&#39;alpha&#39;: 0.09000000000000001}, {&#39;alpha&#39;: 0.09000000000000001}]]}}</span>

<span class="gp">In [41]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">      coef   std err          t          P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  2.96582  0.086679  34.216207  1.388216e-256  2.795932  3.135707</span>
</pre></div>
</div>
</div>
</div>
<p>Hyperparameter tuning can also be done with more sophisticated methods, like for example an iterative fitting along
a regularization path implemented in <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.linear_model.LassoCV</span></code></a>.
In this case the tuning should be done externally and the parameters can then be set via the
<code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params()</span></code> method.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="6ab0c680-fe8c-4bfa-ab40-2bf3c37941a9" name="92448f41-4f48-4298-aa2b-50e903f07f7d" type="radio">
</input><label class="tabbed-label" for="6ab0c680-fe8c-4bfa-ab40-2bf3c37941a9">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [42]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [43]: </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LassoCV</span>

<span class="gp">In [44]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="gp">In [45]: </span><span class="n">ml_g_tune</span> <span class="o">=</span> <span class="n">LassoCV</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dml_data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">dml_data</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>

<span class="gp">In [46]: </span><span class="n">ml_m_tune</span> <span class="o">=</span> <span class="n">LassoCV</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dml_data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">dml_data</span><span class="o">.</span><span class="n">d</span><span class="p">)</span>

<span class="gp">In [47]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">()</span>

<span class="gp">In [48]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">()</span>

<span class="gp">In [49]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">)</span>

<span class="gp">In [50]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">set_ml_nuisance_params</span><span class="p">(</span><span class="s1">&#39;ml_g&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">ml_g_tune</span><span class="o">.</span><span class="n">alpha_</span><span class="p">});</span>

<span class="gp">In [51]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">set_ml_nuisance_params</span><span class="p">(</span><span class="s1">&#39;ml_m&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="n">ml_m_tune</span><span class="o">.</span><span class="n">alpha_</span><span class="p">});</span>

<span class="gp">In [52]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
<span class="go">{&#39;ml_g&#39;: {&#39;d&#39;: [[{&#39;alpha&#39;: 0.4311947070055128}, {&#39;alpha&#39;: 0.4311947070055128}, {&#39;alpha&#39;: 0.4311947070055128}, {&#39;alpha&#39;: 0.4311947070055128}, {&#39;alpha&#39;: 0.4311947070055128}]]}, &#39;ml_m&#39;: {&#39;d&#39;: [[{&#39;alpha&#39;: 0.14281403493938027}, {&#39;alpha&#39;: 0.14281403493938027}, {&#39;alpha&#39;: 0.14281403493938027}, {&#39;alpha&#39;: 0.14281403493938027}, {&#39;alpha&#39;: 0.14281403493938027}]]}}</span>

<span class="gp">In [53]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err          t  P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  3.048723  0.075869  40.183855    0.0  2.900021  3.197424</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="r-learners-and-hyperparameters">
<span id="learners-r"></span><h2><span class="section-number">6.2. </span>R: Learners and hyperparameters<a class="headerlink" href="#r-learners-and-hyperparameters" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id2">
<h3><span class="section-number">6.2.1. </span>Minimum requirements for learners<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>The minimum requirement for a learner to be used for nuisance models in the <code class="docutils literal notranslate"><span class="pre">DoubleML</span></code> package is</p>
<blockquote>
<div><ul class="simple">
<li><p>The implementation as a learner for regression or classification in the <a class="reference external" href="https://mlr3.mlr-org.com/">mlr3</a> package
or its extension packages <a class="reference external" href="https://mlr3learners.mlr-org.com/">mlr3learners</a> and
<a class="reference external" href="https://mlr3extralearners.mlr-org.com/">mlr3extralearners</a> . A guide how to add a learner is provided in the
<a class="reference external" href="https://mlr3book.mlr-org.com/extending-learners.html">chapter on extending learners in the mlr3 book</a> .</p></li>
<li><p>The <a class="reference external" href="https://mlr3.mlr-org.com/">mlr3</a> package makes sure that the learners satisfy some core functionalities.
To specify a specific learner in <code class="docutils literal notranslate"><span class="pre">DoubleML</span></code> users can either enter their name as used for instantiation in
<a class="reference external" href="https://mlr3.mlr-org.com/">mlr3</a> or pass objects of the class <a class="reference external" href="https://mlr3.mlr-org.com/reference/Learner.html">Learner</a> directly.</p></li>
<li><p>The models <code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code> and <code class="docutils literal notranslate"><span class="pre">DoubleMLIIVM</span></code> require classifiers.
Choosing learners for a model in <code class="docutils literal notranslate"><span class="pre">DoubleML</span></code>, users have to be careful whether a nuisance part is a classification
tasks (dependent variable is binary) or a regression problem (dependent variable is continuous) and specify the learners
accordingly.</p></li>
<li><p>Hyperparameters of learners can either be set at instantiation in mlr3 or after instantiation using the
<code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params()</span></code> method.</p></li>
</ul>
</div></blockquote>
<p>A list of provided learners in the mlr3 and extension packages can be found on the package websites</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="https://mlr3book.mlr-org.com/learners.html#learners-predefined">learners provided in mlr3</a>,</p></li>
<li><p><a class="reference external" href="https://mlr3learners.mlr-org.com/#classification-learners">learners provided in mlr3learners</a>,</p></li>
<li><p><a class="reference external" href="https://mlr3extralearners.mlr-org.com/articles/learners/list_learners.html">learners provided in mlr3extralearners</a>.</p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="id6">
<h3><span class="section-number">6.2.2. </span>Specifying learners and set hyperparameters<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p>The learners are set during initialization of the <code class="docutils literal notranslate"><span class="pre">DoubleML</span></code> model classes <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code>,
<code class="docutils literal notranslate"><span class="pre">DoubleMLPLIV</span></code>, <code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code> and <code class="docutils literal notranslate"><span class="pre">DoubleMLIIVM</span></code>. Lets simulate some data and consider the partially linear regression model.
We need to specify learners for the nuisance functions <span class="math notranslate nohighlight">\(g_0(X) = E[Y|X]\)</span> and <span class="math notranslate nohighlight">\(m_0(X) = E[D|X]\)</span>,
for example <code class="docutils literal notranslate"><span class="pre">LearnerRegrRanger</span></code> (<code class="docutils literal notranslate"><span class="pre">&quot;regr.ranger&quot;</span></code>) for regression with random forests based on the  <a class="reference external" href="https://github.com/imbs-hl/ranger">ranger</a>
package for R.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="fb209aa5-9daa-4e4c-a53a-9084a05433ac" name="534a7f0a-605c-408d-8645-f18c4a243d54" type="radio">
</input><label class="tabbed-label" for="fb209aa5-9daa-4e4c-a53a-9084a05433ac">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span>library(DoubleML)
library(mlr3)
library(mlr3learners)
library(data.table)
lgr::get_logger(&quot;mlr3&quot;)$set_threshold(&quot;warn&quot;)

# set up a mlr3 learner
learner = lrn(&quot;regr.ranger&quot;)
ml_g = learner$clone()
ml_m = learner$clone()
set.seed(3141)
data = make_plr_CCDDHNR2018(alpha=0.5, return_type=&#39;data.table&#39;)
obj_dml_data = DoubleMLData$new(data, y_col=&quot;y&quot;, d_cols=&quot;d&quot;)
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m)
dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.57505    0.04458    12.9   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>Setting hyperparameters:</p>
<blockquote>
<div><ul class="simple">
<li><p>We can also use pre-parametrized learners <code class="docutils literal notranslate"><span class="pre">lrn(&quot;regr.ranger&quot;,</span> <span class="pre">num.trees=10)</span></code>.</p></li>
<li><p>Alternatively, hyperparameters can be set after initialization via the method
<code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params(learner,</span> <span class="pre">treat_var,</span> <span class="pre">params,</span> <span class="pre">set_fold_specific)</span></code>.</p></li>
</ul>
</div></blockquote>
<div class="tabbed-set docutils">
<input checked="checked" id="e1bc2111-be53-4395-a02c-aee5a1b97023" name="04bed0b4-0dc9-439f-bf6e-ba4059664a9d" type="radio">
</input><label class="tabbed-label" for="e1bc2111-be53-4395-a02c-aee5a1b97023">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span>set.seed(3141)
ml_g = lrn(&quot;regr.ranger&quot;, num.trees=10)
ml_m = lrn(&quot;regr.ranger&quot;)
obj_dml_data = DoubleMLData$new(data, y_col=&quot;y&quot;, d_cols=&quot;d&quot;)
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m)
dml_plr_obj$fit()
dml_plr_obj$summary()

set.seed(3141)
ml_g = lrn(&quot;regr.ranger&quot;)
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g , ml_m)
dml_plr_obj$set_ml_nuisance_params(&quot;ml_g&quot;, &quot;d&quot;, list(&quot;num.trees&quot;=10))
dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.58765    0.04532   12.97   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.58765    0.04532   12.97   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>Setting treatment-variable-specific or fold-specific hyperparameters:</p>
<blockquote>
<div><ul class="simple">
<li><p>In the multiple-treatment case, the method <code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params(learner,</span> <span class="pre">treat_var,</span> <span class="pre">params,</span> <span class="pre">set_fold_specific)</span></code>
allows to set different hyperparameters for different treatment variables.</p></li>
<li><p>The method <code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params(learner,</span> <span class="pre">treat_var,</span> <span class="pre">params,</span> <span class="pre">set_fold_specific)</span></code> accepts lists for <code class="docutils literal notranslate"><span class="pre">params</span></code>.
The structure of the list depends on whether the same parameters should be provided for all folds or separate values
are passed for specific folds.</p></li>
<li><p>Global parameter passing: The named list in the argument <code class="docutils literal notranslate"><span class="pre">params</span></code> should have entries with names corresponding to
the parameters of the learners. The values in <code class="docutils literal notranslate"><span class="pre">params</span></code> are used for estimation on all folds.
It is required that option <code class="docutils literal notranslate"><span class="pre">set_fold_specific</span></code> is set to <code class="docutils literal notranslate"><span class="pre">FALSE</span></code> (default).</p></li>
<li><p>Fold-specific parameter passing: <code class="docutils literal notranslate"><span class="pre">params</span></code> is a nested list. The outer list needs to be of length <code class="docutils literal notranslate"><span class="pre">n_rep</span></code> and the inner
list of length <code class="docutils literal notranslate"><span class="pre">n_folds</span></code>. The innermost list must have named entries that correspond to the parameters of the learner.
It is required that option <code class="docutils literal notranslate"><span class="pre">set_fold_specific</span></code> is set to <code class="docutils literal notranslate"><span class="pre">TRUE</span></code>. Moreover, fold-specific
parameter passing is only supported, if all parameters are set fold-specific.</p></li>
<li><p>External setting of parameters will override previously set parameters. To assert the choice of parameters, access the
fields <code class="docutils literal notranslate"><span class="pre">$learner</span></code> and <code class="docutils literal notranslate"><span class="pre">$params</span></code>.</p></li>
</ul>
</div></blockquote>
<div class="tabbed-set docutils">
<input checked="checked" id="cd69b2d1-48a6-4bff-9af8-a14d95a70e55" name="697ca3da-ea2b-4403-b9dc-977e124b82ae" type="radio">
</input><label class="tabbed-label" for="cd69b2d1-48a6-4bff-9af8-a14d95a70e55">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span>set.seed(3141)
ml_g = lrn(&quot;regr.ranger&quot;)
ml_m = lrn(&quot;regr.ranger&quot;)
obj_dml_data = DoubleMLData$new(data, y_col=&quot;y&quot;, d_cols=&quot;d&quot;)

n_rep = 2
n_folds = 3
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m, n_rep = n_rep, n_folds = n_folds)

# Set globally
params = list(&quot;num.trees&quot;=10)
dml_plr_obj$set_ml_nuisance_params(&quot;ml_g&quot;, &quot;d&quot;, params=params)
dml_plr_obj$set_ml_nuisance_params(&quot;ml_m&quot;, &quot;d&quot;, params=params)
dml_plr_obj$learner
dml_plr_obj$params
dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>$ml_g
&lt;LearnerRegrRanger:regr.ranger&gt;
* Model: -
* Parameters: list()
* Packages: ranger
* Predict Type: response
* Feature types: logical, integer, numeric, character, factor, ordered
* Properties: importance, oob_error, weights

$ml_m
&lt;LearnerRegrRanger:regr.ranger&gt;
* Model: -
* Parameters: list()
* Packages: ranger
* Predict Type: response
* Feature types: logical, integer, numeric, character, factor, ordered
* Properties: importance, oob_error, weights
</pre></div>
</div>
<div class="output text_html"><dl>
	<dt>$ml_g</dt>
		<dd><strong>$d</strong> = <strong>$num.trees</strong> = 10</dd>
	<dt>$ml_m</dt>
		<dd><strong>$d</strong> = <strong>$num.trees</strong> = 10</dd>
</dl>
</div><div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.52486    0.04593   11.43   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>The following example illustrates how to set parameters for each fold.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="a54dadf3-5af4-4af2-904e-d4e5fbabf687" name="bdecd185-f6be-46e7-911c-96a5942a69ca" type="radio">
</input><label class="tabbed-label" for="a54dadf3-5af4-4af2-904e-d4e5fbabf687">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span>learner = lrn(&quot;regr.ranger&quot;)
ml_g = learner$clone()
ml_m = learner$clone()
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m, n_rep = n_rep, n_folds = n_folds)

# Set values for each fold
params_exact = rep(list(rep(list(params), n_folds)), n_rep)
dml_plr_obj$set_ml_nuisance_params(&quot;ml_g&quot;, &quot;d&quot;, params=params_exact,
                                     set_fold_specific=TRUE)
dml_plr_obj$set_ml_nuisance_params(&quot;ml_m&quot;, &quot;d&quot;, params=params_exact,
                                     set_fold_specific=TRUE)
dml_plr_obj$learner
dml_plr_obj$params
dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>$ml_g
&lt;LearnerRegrRanger:regr.ranger&gt;
* Model: -
* Parameters: list()
* Packages: ranger
* Predict Type: response
* Feature types: logical, integer, numeric, character, factor, ordered
* Properties: importance, oob_error, weights

$ml_m
&lt;LearnerRegrRanger:regr.ranger&gt;
* Model: -
* Parameters: list()
* Packages: ranger
* Predict Type: response
* Feature types: logical, integer, numeric, character, factor, ordered
* Properties: importance, oob_error, weights
</pre></div>
</div>
<div class="output text_html"><dl>
	<dt>$ml_g</dt>
		<dd><strong>$d</strong> = <ol>
	<li><ol>
	<li><strong>$num.trees</strong> = 10</li>
	<li><strong>$num.trees</strong> = 10</li>
	<li><strong>$num.trees</strong> = 10</li>
</ol>
</li>
	<li><ol>
	<li><strong>$num.trees</strong> = 10</li>
	<li><strong>$num.trees</strong> = 10</li>
	<li><strong>$num.trees</strong> = 10</li>
</ol>
</li>
</ol>
</dd>
	<dt>$ml_m</dt>
		<dd><strong>$d</strong> = <ol>
	<li><ol>
	<li><strong>$num.trees</strong> = 10</li>
	<li><strong>$num.trees</strong> = 10</li>
	<li><strong>$num.trees</strong> = 10</li>
</ol>
</li>
	<li><ol>
	<li><strong>$num.trees</strong> = 10</li>
	<li><strong>$num.trees</strong> = 10</li>
	<li><strong>$num.trees</strong> = 10</li>
</ol>
</li>
</ol>
</dd>
</dl>
</div><div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.49098    0.06137       8 1.24e-15 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="id7">
<h3><span class="section-number">6.2.3. </span>Hyperparameter tuning<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>Parameter tuning of learners for the nuisance functions of <code class="docutils literal notranslate"><span class="pre">DoubleML</span></code> models can be done via the <code class="docutils literal notranslate"><span class="pre">tune()</span></code> method.
The <code class="docutils literal notranslate"><span class="pre">tune()</span></code> method passes various options and parameters to tuning interface as provided by the
<a class="reference external" href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a> package. The <a class="reference external" href="https://mlr3book.mlr-org.com/">mlr3 book</a> provides a
<a class="reference external" href="https://mlr3book.mlr-org.com/optimization.html">step-by-step introduction to parameter tuning</a>.</p>
<p>To illustrate the parameter tuning, we generate data from a sparse partially linear regression model.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="75ec1fbe-dba1-4016-98fd-0d84bb489e6d" name="5f049d11-0dd8-4260-a4f8-7e99490eaf64" type="radio">
</input><label class="tabbed-label" for="75ec1fbe-dba1-4016-98fd-0d84bb489e6d">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="n">library</span><span class="p">(</span><span class="n">DoubleML</span><span class="p">)</span>
<span class="n">library</span><span class="p">(</span><span class="n">mlr3</span><span class="p">)</span>
<span class="n">library</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">table</span><span class="p">)</span>

<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3141</span><span class="p">)</span>
<span class="n">n_obs</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">n_vars</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">theta</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">(</span><span class="n">stats</span><span class="p">::</span><span class="n">rnorm</span><span class="p">(</span><span class="n">n_obs</span> <span class="o">*</span> <span class="n">n_vars</span><span class="p">),</span> <span class="n">nrow</span> <span class="o">=</span> <span class="n">n_obs</span><span class="p">,</span> <span class="n">ncol</span> <span class="o">=</span> <span class="n">n_vars</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="p">[,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="n">drop</span> <span class="o">=</span> <span class="n">FALSE</span><span class="p">]</span> <span class="o">%*%</span> <span class="n">c</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span> <span class="o">+</span> <span class="n">stats</span><span class="p">::</span><span class="n">rnorm</span><span class="p">(</span><span class="n">n_obs</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">*</span> <span class="n">d</span> <span class="o">+</span> <span class="n">X</span><span class="p">[,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="n">drop</span> <span class="o">=</span> <span class="n">FALSE</span><span class="p">]</span> <span class="o">%*%</span> <span class="n">c</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>  <span class="o">+</span> <span class="n">stats</span><span class="p">::</span><span class="n">rnorm</span><span class="p">(</span><span class="n">n_obs</span><span class="p">)</span>
<span class="n">dml_data</span> <span class="o">=</span> <span class="n">double_ml_data_from_matrix</span><span class="p">(</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">d</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
</div>
</div>
</div>
</div>
<p>The hyperparameter-tuning is performed according to options passed through a named list <code class="docutils literal notranslate"><span class="pre">tune_settings</span></code>.
The entries in the list specify options during parameter tuning with <a class="reference external" href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a>:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">algorithm</span></code>  sets the tuning algorithm, i.e., an argument used to initiate the
<a class="reference external" href="https://mlr3book.mlr-org.com/tuning.html#the-tuner-class">Tuner class</a>. <code class="docutils literal notranslate"><span class="pre">algorithm</span></code> is a <code class="docutils literal notranslate"><span class="pre">character()</span></code> that
is used as an argument in the wrapper <a class="reference external" href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a> call <code class="docutils literal notranslate"><span class="pre">tnr(algorithm)</span></code>.
<code class="docutils literal notranslate"><span class="pre">resolution</span></code>  sets the number of grid points.
<a class="reference external" href="https://mlr3book.mlr-org.com/tuning.html#the-tuner-class">The Tuner class in mlr3tuning</a> supports grid search,
random search, generalized simulated annealing and non-linear optimization.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rsmp_tune</span></code> specifies the resampling method for evaluation, for example <span class="math notranslate nohighlight">\(k\)</span>-fold cross-validation (<code class="docutils literal notranslate"><span class="pre">cv</span></code>)
with <span class="math notranslate nohighlight">\(k=\)</span> <code class="docutils literal notranslate"><span class="pre">n_folds_tune</span></code> or evaluation on a hold-out sample <code class="docutils literal notranslate"><span class="pre">holdout</span></code>. Directly passing of a
<a class="reference external" href="https://mlr3.mlr-org.com/reference/Resampling.html">mlr3 resampling object</a> is supported,
for example by setting <cite>rsmp_tune=smp(“holdout”, ratio=0.8)</cite>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">terminator</span></code> is a <a class="reference external" href="https://bbotk.mlr-org.com/reference/Terminator.html">Terminator object</a> passed to
<a class="reference external" href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a> that manages the budget to solve the tuning problem.</p></li>
</ul>
</div></blockquote>
<p>In the following example we tune the penalty parameter <span class="math notranslate nohighlight">\(\lambda\)</span> (<code class="docutils literal notranslate"><span class="pre">lambda</span></code>) for lasso with the R package
<a class="reference external" href="https://glmnet.stanford.edu/">glmnet</a>. To tune the value of <code class="docutils literal notranslate"><span class="pre">lambda</span></code> a grid search over a grid of values that range from <cite>0.05</cite>
to <cite>0.1</cite> at a resolution of 10. To evaluate the predictive performance in both nuisance parts, the cross-validated mean squared error is used.</p>
<p>Setting the option <code class="docutils literal notranslate"><span class="pre">tune_on_folds=FALSE</span></code>, the tuning is performed on the whole sample. Hence, the cross-validated errors
are obtained from a random split of the whole sample into 5 folds and, as a result, one set of <code class="docutils literal notranslate"><span class="pre">lambda</span></code> values are obtained
which are later used in the fitting stage for all folds.</p>
<p>Alternatively, setting the option <code class="docutils literal notranslate"><span class="pre">tune_on_folds=TRUE</span></code> would assign the tuning resampling scheme <code class="docutils literal notranslate"><span class="pre">rsmp_tune</span></code> to each fold.
For example, if we set <code class="docutils literal notranslate"><span class="pre">n_folds=2</span></code> at initialization of the <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code> object and use a 5-fold cross-validated error
for tuning, each of the two folds would be split up into 5 subfolds and the error would be evaluated on these subfolds.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="6a242783-08d6-4ef8-9918-c30164555281" name="309a67ca-4316-42f7-9292-7d602894126b" type="radio">
</input><label class="tabbed-label" for="6a242783-08d6-4ef8-9918-c30164555281">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span>library(DoubleML)
library(mlr3)
library(data.table)
library(mlr3learners)
library(paradox)
library(mlr3tuning)
lgr::get_logger(&quot;mlr3&quot;)$set_threshold(&quot;warn&quot;)
lgr::get_logger(&quot;bbotk&quot;)$set_threshold(&quot;warn&quot;)

set.seed(1234)
ml_g = lrn(&quot;regr.glmnet&quot;)
ml_m = lrn(&quot;regr.glmnet&quot;)
dml_plr_obj = DoubleMLPLR$new(dml_data, ml_g, ml_m)

par_grids = list(&quot;ml_g&quot; = ParamSet$new(list(
                                  ParamDbl$new(&quot;lambda&quot;, lower = 0.05, upper = 0.1))),
                 &quot;ml_m&quot; =  ParamSet$new(list(
                                  ParamDbl$new(&quot;lambda&quot;, lower = 0.05, upper = 0.1))))

tune_settings = list(n_folds_tune = 5,
                      rsmp_tune = &quot;cv&quot;,
                      measure = list(&quot;ml_g&quot; = &quot;regr.mse&quot;,
                                     &quot;ml_m&quot; = &quot;regr.mse&quot;),
                      terminator = mlr3tuning::trm(&quot;evals&quot;, n_evals = 100),
                      algorithm = &quot;grid_search&quot;,
                      resolution = 10)
dml_plr_obj$tune(param_set=par_grids, tune_settings=tune_settings, tune_on_fold=TRUE)
dml_plr_obj$params

dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><dl>
	<dt>$ml_g</dt>
		<dd><strong>$d</strong> = <ol>
	<li><ol>
	<li><strong>$lambda</strong> = 0.1</li>
	<li><strong>$lambda</strong> = 0.0777777777777778</li>
	<li><strong>$lambda</strong> = 0.1</li>
	<li><strong>$lambda</strong> = 0.1</li>
	<li><strong>$lambda</strong> = 0.1</li>
</ol>
</li>
</ol>
</dd>
	<dt>$ml_m</dt>
		<dd><strong>$d</strong> = <ol>
	<li><ol>
	<li><strong>$lambda</strong> = 0.1</li>
	<li><strong>$lambda</strong> = 0.1</li>
	<li><strong>$lambda</strong> = 0.1</li>
	<li><strong>$lambda</strong> = 0.1</li>
	<li><strong>$lambda</strong> = 0.1</li>
</ol>
</li>
</ol>
</dd>
</dl>
</div><div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)    
d    3.0425     0.1424   21.37   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>Hyperparameter tuning can also be done with more sophisticated methods, for example by using built-in tuning
paths of learners. For example, the learner <a class="reference external" href="https://mlr3learners.mlr-org.com/reference/mlr_learners_regr.cv_glmnet.html">regr.cv_glmnet</a>
performs an internal cross-validated choice of the parameter <code class="docutils literal notranslate"><span class="pre">lambda</span></code>.
Alternatively, the powerful functionalities of the <a class="reference external" href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a> package can be used for
external parameter tuning of the nuisance parts. The optimally chosen parameters can then be passed to the
<code class="docutils literal notranslate"><span class="pre">DoubleML</span></code> models using the <code class="docutils literal notranslate"><span class="pre">set_ml_nuisance_params()</span></code> method.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="e5c66962-7def-437d-9562-06624febcccc" name="b287e822-8291-48ba-8480-cba1128cb5c0" type="radio">
</input><label class="tabbed-label" for="e5c66962-7def-437d-9562-06624febcccc">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span>library(DoubleML)
library(mlr3)
library(data.table)
library(mlr3learners)
library(paradox)
library(mlr3tuning)
lgr::get_logger(&quot;mlr3&quot;)$set_threshold(&quot;warn&quot;)
lgr::get_logger(&quot;bbotk&quot;)$set_threshold(&quot;warn&quot;)

set.seed(1234)
ml_g = lrn(&quot;regr.cv_glmnet&quot;, s=&quot;lambda.min&quot;)
ml_m = lrn(&quot;regr.cv_glmnet&quot;, s=&quot;lambda.min&quot;)
dml_plr_obj = DoubleMLPLR$new(dml_data, ml_g, ml_m)

dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   3.08848    0.07366   41.93   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>The following code chunk illustrates another example for global parameter tuning with random forests
as provided by the <code class="docutils literal notranslate"><span class="pre">ranger</span></code> package.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="dbe5d329-1710-44ee-a7ba-be2af2c367fb" name="608856aa-b602-4b4d-b753-cbb1aa9ff681" type="radio">
</input><label class="tabbed-label" for="dbe5d329-1710-44ee-a7ba-be2af2c367fb">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span>library(DoubleML)
library(mlr3)
library(mlr3learners)
library(data.table)
library(paradox)
library(mlr3tuning)
lgr::get_logger(&quot;mlr3&quot;)$set_threshold(&quot;warn&quot;)
lgr::get_logger(&quot;bbotk&quot;)$set_threshold(&quot;warn&quot;)

# set up a list of parameter grids
param_grid = list(&quot;ml_g&quot; = ParamSet$new(list(
                                  ParamInt$new(&quot;num.trees&quot;, lower = 50 , upper = 500),
                                  ParamInt$new(&quot;max.depth&quot;, lower = 2, upper = 5))),
                  &quot;ml_m&quot; = ParamSet$new(list(
                                  ParamInt$new(&quot;num.trees&quot;, lower = 50 , upper = 500),
                                  ParamInt$new(&quot;max.depth&quot;, lower = 2, upper = 5))))
tune_settings = list(n_folds_tune = 2,
                      rsmp_tune = &quot;cv&quot;,
                      measure = list(&quot;ml_g&quot; = &quot;regr.mse&quot;,
                                     &quot;ml_m&quot; = &quot;regr.mse&quot;),
                      terminator = mlr3tuning::trm(&quot;evals&quot;, n_evals = 20),
                      algorithm = &quot;grid_search&quot;,
                      resolution = 5)

# set up a mlr3 learner
learner = lrn(&quot;regr.ranger&quot;)
ml_g = learner$clone()
ml_m = learner$clone()

set.seed(3141)
obj_dml_data = make_plr_CCDDHNR2018(alpha=0.5)
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m)
dml_plr_obj$tune(param_set=param_grid, tune_settings=tune_settings, tune_on_folds=FALSE)
dml_plr_obj$params

dml_plr_obj$fit()
dml_plr_obj$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><dl>
	<dt>$ml_g</dt>
		<dd><strong>$d</strong> = <dl>
	<dt>$num.trees</dt>
		<dd>275</dd>
	<dt>$max.depth</dt>
		<dd>5</dd>
</dl>
</dd>
	<dt>$ml_m</dt>
		<dd><strong>$d</strong> = <dl>
	<dt>$num.trees</dt>
		<dd>162</dd>
	<dt>$max.depth</dt>
		<dd>5</dd>
</dl>
</dd>
</dl>
</div><div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.57610    0.04364    13.2   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="references">
<h4><span class="section-number">6.2.3.1. </span>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>Lang, M., Binder, M., Richter, J., Schratz, P., Pfisterer, F., Coors, S., Au, Q., Casalicchio, G., Kotthoff, L., Bischl, B. (2019), mlr3: A modern object-oriented machine learing framework in R. Journal of Open Source Software, <a class="reference external" href="(doi:10.21105/joss.01903)[10.21105/joss.01903]">doi:10.21105/joss.01903</a>.</p></li>
<li><p>Becker, M., Binder, M., Bischl, B., Lang, M., Pfisterer, F., Reich, N.G., Richter, J., Schratz, P., Sonabend, R. (2020), mlr3 book, available at <a class="reference external" href="https://mlr3book.mlr-org.com">https://mlr3book.mlr-org.com</a>.</p></li>
</ul>
</div>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="algorithms.html" title="previous page"><span class="section-number">5. </span>Double machine learning algorithms</a>
    <a class='right-next' id="next-link" href="se_confint.html" title="next page"><span class="section-number">7. </span>Variance estimation, confidence intervals and multiplier bootstrap</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d8bbf5861d671d414e1a.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>