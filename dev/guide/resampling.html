
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>9. Sample-splitting, cross-fitting and repeated cross-fitting &#8212; DoubleML  documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DoubleML Workflow" href="../workflow/workflow.html" />
    <link rel="prev" title="8. Confidence bands and multiplier bootstrap for valid simultaneous inference" href="sim_inf.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
<a class="navbar-brand" href="../index.html">
<p class="title">DoubleML</p>
</a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  DoubleML
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/install.html">
  Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/intro.html">
  Getting started
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="guide.html">
  User guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../workflow/workflow.html">
  Workflow
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api.html">
  Python API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference external nav-link" href="https://docs.doubleml.org/r/stable/">
  R API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../examples/index.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../release/release.html">
  Release notes
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><p class="logo" style="text-align:center;"><a href="../index.html">
    <img class="logo" src="../logo.png" alt="Logo" width="65%" height="65%">
</a></p><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="basics.html">
   1.  The basics of double/debiased machine learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="data_backend.html">
   2.  The data-backend DoubleMLData
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="models.html">
   3.  Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="scores.html">
   4.  Score functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="algorithms.html">
   5.  Double machine learning algorithms
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="learners.html">
   6.  Learners, hyperparameters and hyperparameter tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="se_confint.html">
   7.  Variance estimation and confidence intervals for a causal parameter of interest
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="sim_inf.html">
   8.  Confidence bands and multiplier bootstrap for valid simultaneous inference
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   9.  Sample-splitting, cross-fitting and repeated cross-fitting
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cross-fitting-with-k-folds">
   9.1. Cross-fitting with
   <span class="math notranslate nohighlight">
    \(K\)
   </span>
   folds
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#repeated-cross-fitting-with-k-folds-and-m-repetition">
   9.2. Repeated cross-fitting with
   <span class="math notranslate nohighlight">
    \(K\)
   </span>
   folds and
   <span class="math notranslate nohighlight">
    \(M\)
   </span>
   repetition
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#externally-provide-a-sample-splitting-partition">
   9.3. Externally provide a sample splitting / partition
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sample-splitting-without-cross-fitting">
   9.4. Sample-splitting without cross-fitting
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#estimate-dml-models-without-sample-splitting">
   9.5. Estimate DML models without sample-splitting
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="sample-splitting-cross-fitting-and-repeated-cross-fitting">
<span id="resampling"></span><h1><span class="section-number">9. </span>Sample-splitting, cross-fitting and repeated cross-fitting<a class="headerlink" href="#sample-splitting-cross-fitting-and-repeated-cross-fitting" title="Permalink to this headline">¶</a></h1>
<p>Sample-splitting and the application of cross-fitting is a central part of double/debiased machine learning (DML).
For all DML models
<code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code>,
<code class="docutils literal notranslate"><span class="pre">DoubleMLPLIV</span></code>,
<code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code>,
and <code class="docutils literal notranslate"><span class="pre">DoubleMLIIVM</span></code>,
the specification is done via the parameters <code class="docutils literal notranslate"><span class="pre">n_folds</span></code> and <code class="docutils literal notranslate"><span class="pre">n_rep</span></code>.
Advanced resampling techniques can be obtained via the boolean parameters
<code class="docutils literal notranslate"><span class="pre">draw_sample_splitting</span></code> and <code class="docutils literal notranslate"><span class="pre">apply_cross_fitting</span></code> as well as the methods
<code class="docutils literal notranslate"><span class="pre">draw_sample_splitting()</span></code> and <code class="docutils literal notranslate"><span class="pre">set_sample_splitting()</span></code>.</p>
<p>As an example we consider a partially linear regression model (PLR)
implemented in <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code>.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="524efdc3-7e63-4cd2-a60b-a17a773eb021" name="2490085b-d1bf-4c25-a7a9-d7200cbaae3e" type="radio">
</input><label class="tabbed-label" for="524efdc3-7e63-4cd2-a60b-a17a773eb021">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [2]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="gp">In [3]: </span><span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_plr_CCDDHNR2018</span>

<span class="gp">In [4]: </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="gp">In [5]: </span><span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">clone</span>

<span class="gp">In [6]: </span><span class="n">learner</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [7]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">learner</span><span class="p">)</span>

<span class="gp">In [8]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">learner</span><span class="p">)</span>

<span class="gp">In [9]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="gp">In [10]: </span><span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_plr_CCDDHNR2018</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input id="40282014-5c6a-4a0c-8f28-1a0ef8445712" name="2490085b-d1bf-4c25-a7a9-d7200cbaae3e" type="radio">
</input><label class="tabbed-label" for="40282014-5c6a-4a0c-8f28-1a0ef8445712">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>library(DoubleML)
library(mlr3)
lgr::get_logger(&quot;mlr3&quot;)$set_threshold(&quot;warn&quot;)
library(mlr3learners)
library(data.table)

learner = lrn(&quot;regr.ranger&quot;, num.trees = 100, mtry = 20, min.node.size = 2, max.depth = 5)
ml_g = learner
ml_m = learner
data = make_plr_CCDDHNR2018(alpha=0.5, n_obs=100, return_type = &quot;data.table&quot;)
obj_dml_data = DoubleMLData$new(data,
                                y_col = &quot;y&quot;,
                                d_cols = &quot;d&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
</div>
</div>
<div class="section" id="cross-fitting-with-k-folds">
<span id="k-fold-cross-fitting"></span><h2><span class="section-number">9.1. </span>Cross-fitting with <span class="math notranslate nohighlight">\(K\)</span> folds<a class="headerlink" href="#cross-fitting-with-k-folds" title="Permalink to this headline">¶</a></h2>
<p>The default setting is <code class="docutils literal notranslate"><span class="pre">n_folds</span> <span class="pre">=</span> <span class="pre">5</span></code> and <code class="docutils literal notranslate"><span class="pre">n_rep</span> <span class="pre">=</span> <span class="pre">1</span></code>, i.e.,
<span class="math notranslate nohighlight">\(K=5\)</span> folds and no repeated cross-fitting.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="aa9c0de7-2bdb-4c95-884b-e6770351b984" name="3d1d6b68-7c51-4c29-a487-72cb38e0e63b" type="radio">
</input><label class="tabbed-label" for="aa9c0de7-2bdb-4c95-884b-e6770351b984">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [11]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span> <span class="n">n_folds</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_rep</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="gp">In [12]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">n_folds</span><span class="p">)</span>
<span class="go">5</span>

<span class="gp">In [13]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">n_rep</span><span class="p">)</span>
<span class="go">1</span>
</pre></div>
</div>
</div>
<input id="a40404da-2825-480a-b4ac-376a54ade1e6" name="3d1d6b68-7c51-4c29-a487-72cb38e0e63b" type="radio">
</input><label class="tabbed-label" for="a40404da-2825-480a-b4ac-376a54ade1e6">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m, n_folds = 5, n_rep = 1)
print(dml_plr_obj$n_folds)
print(dml_plr_obj$n_rep)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] 5
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] 1
</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>During the initialization of a DML model like <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code> a <span class="math notranslate nohighlight">\(K\)</span>-fold random
partition <span class="math notranslate nohighlight">\((I_k)_{k=1}^{K}\)</span> of observation indices is generated.
The <span class="math notranslate nohighlight">\(K\)</span>-fold random partition is stored in the <code class="docutils literal notranslate"><span class="pre">smpls</span></code> attribute of the DML model object.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="d35d2b98-81f8-4b3c-8595-f2e340c92055" name="e2524276-4315-4e2e-ad35-22a315700f2d" type="radio">
</input><label class="tabbed-label" for="d35d2b98-81f8-4b3c-8595-f2e340c92055">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [14]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">smpls</span><span class="p">)</span>
<span class="go">[[(array([ 0,  2,  3,  4,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 19,</span>
<span class="go">       21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38, 40, 44,</span>
<span class="go">       46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64,</span>
<span class="go">       65, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 80, 81, 82, 84, 85,</span>
<span class="go">       86, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99]), array([ 1,  5, 18, 20, 26, 30, 33, 39, 41, 42, 43, 45, 56, 57, 66, 73, 78,</span>
<span class="go">       83, 87, 96])), (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 14, 15, 16, 17,</span>
<span class="go">       18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40,</span>
<span class="go">       41, 42, 43, 44, 45, 46, 48, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63,</span>
<span class="go">       65, 66, 69, 70, 71, 72, 73, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87,</span>
<span class="go">       88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), array([ 9, 23, 24, 25, 27, 28, 35, 47, 49, 50, 51, 52, 59, 64, 67, 68, 74,</span>
<span class="go">       75, 76, 86])), (array([ 0,  1,  2,  3,  5,  6,  7,  9, 10, 11, 12, 14, 16, 17, 18, 20, 21,</span>
<span class="go">       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 38, 39, 40, 41, 42,</span>
<span class="go">       43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62,</span>
<span class="go">       63, 64, 65, 66, 67, 68, 69, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81,</span>
<span class="go">       83, 84, 86, 87, 88, 89, 90, 91, 92, 96, 98, 99]), array([ 4,  8, 13, 15, 19, 32, 34, 36, 37, 46, 54, 55, 70, 72, 82, 85, 93,</span>
<span class="go">       94, 95, 97])), (array([ 0,  1,  3,  4,  5,  6,  8,  9, 13, 14, 15, 17, 18, 19, 20, 21, 22,</span>
<span class="go">       23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41,</span>
<span class="go">       42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 64,</span>
<span class="go">       65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82,</span>
<span class="go">       83, 85, 86, 87, 88, 89, 93, 94, 95, 96, 97, 98]), array([ 2,  7, 10, 11, 12, 16, 38, 40, 48, 58, 60, 61, 62, 63, 81, 84, 90,</span>
<span class="go">       91, 92, 99])), (array([ 1,  2,  4,  5,  7,  8,  9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 23,</span>
<span class="go">       24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,</span>
<span class="go">       43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61,</span>
<span class="go">       62, 63, 64, 66, 67, 68, 70, 72, 73, 74, 75, 76, 78, 81, 82, 83, 84,</span>
<span class="go">       85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 99]), array([ 0,  3,  6, 14, 17, 21, 22, 29, 31, 44, 53, 65, 69, 71, 77, 79, 80,</span>
<span class="go">       88, 89, 98]))]]</span>
</pre></div>
</div>
</div>
<input id="f7c88862-3363-439c-8a3f-8f3f80859fc6" name="e2524276-4315-4e2e-ad35-22a315700f2d" type="radio">
</input><label class="tabbed-label" for="f7c88862-3363-439c-8a3f-8f3f80859fc6">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>dml_plr_obj$smpls
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><ol>
	<li><dl>
	<dt>$train_ids</dt>
		<dd><ol>
	<li><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>3</li><li>6</li><li>11</li><li>15</li><li>17</li><li>18</li><li>20</li><li>22</li><li>32</li><li>37</li><li>41</li><li>43</li><li>51</li><li>56</li><li>58</li><li>59</li><li>65</li><li>83</li><li>84</li><li>87</li><li>4</li><li>9</li><li>16</li><li>25</li><li>28</li><li>29</li><li>34</li><li>38</li><li>40</li><li>46</li><li>57</li><li>63</li><li>64</li><li>67</li><li>69</li><li>72</li><li>81</li><li>82</li><li>89</li><li>95</li><li>1</li><li>2</li><li>7</li><li>13</li><li>21</li><li>24</li><li>26</li><li>35</li><li>44</li><li>45</li><li>47</li><li>52</li><li>54</li><li>60</li><li>61</li><li>68</li><li>85</li><li>86</li><li>91</li><li>98</li><li>10</li><li>14</li><li>23</li><li>30</li><li>31</li><li>33</li><li>49</li><li>50</li><li>55</li><li>62</li><li>66</li><li>70</li><li>73</li><li>74</li><li>75</li><li>79</li><li>88</li><li>90</li><li>94</li><li>100</li></ol>
</li>
	<li><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>5</li><li>8</li><li>12</li><li>19</li><li>27</li><li>36</li><li>39</li><li>42</li><li>48</li><li>53</li><li>71</li><li>76</li><li>77</li><li>78</li><li>80</li><li>92</li><li>93</li><li>96</li><li>97</li><li>99</li><li>4</li><li>9</li><li>16</li><li>25</li><li>28</li><li>29</li><li>34</li><li>38</li><li>40</li><li>46</li><li>57</li><li>63</li><li>64</li><li>67</li><li>69</li><li>72</li><li>81</li><li>82</li><li>89</li><li>95</li><li>1</li><li>2</li><li>7</li><li>13</li><li>21</li><li>24</li><li>26</li><li>35</li><li>44</li><li>45</li><li>47</li><li>52</li><li>54</li><li>60</li><li>61</li><li>68</li><li>85</li><li>86</li><li>91</li><li>98</li><li>10</li><li>14</li><li>23</li><li>30</li><li>31</li><li>33</li><li>49</li><li>50</li><li>55</li><li>62</li><li>66</li><li>70</li><li>73</li><li>74</li><li>75</li><li>79</li><li>88</li><li>90</li><li>94</li><li>100</li></ol>
</li>
	<li><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>5</li><li>8</li><li>12</li><li>19</li><li>27</li><li>36</li><li>39</li><li>42</li><li>48</li><li>53</li><li>71</li><li>76</li><li>77</li><li>78</li><li>80</li><li>92</li><li>93</li><li>96</li><li>97</li><li>99</li><li>3</li><li>6</li><li>11</li><li>15</li><li>17</li><li>18</li><li>20</li><li>22</li><li>32</li><li>37</li><li>41</li><li>43</li><li>51</li><li>56</li><li>58</li><li>59</li><li>65</li><li>83</li><li>84</li><li>87</li><li>1</li><li>2</li><li>7</li><li>13</li><li>21</li><li>24</li><li>26</li><li>35</li><li>44</li><li>45</li><li>47</li><li>52</li><li>54</li><li>60</li><li>61</li><li>68</li><li>85</li><li>86</li><li>91</li><li>98</li><li>10</li><li>14</li><li>23</li><li>30</li><li>31</li><li>33</li><li>49</li><li>50</li><li>55</li><li>62</li><li>66</li><li>70</li><li>73</li><li>74</li><li>75</li><li>79</li><li>88</li><li>90</li><li>94</li><li>100</li></ol>
</li>
	<li><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>5</li><li>8</li><li>12</li><li>19</li><li>27</li><li>36</li><li>39</li><li>42</li><li>48</li><li>53</li><li>71</li><li>76</li><li>77</li><li>78</li><li>80</li><li>92</li><li>93</li><li>96</li><li>97</li><li>99</li><li>3</li><li>6</li><li>11</li><li>15</li><li>17</li><li>18</li><li>20</li><li>22</li><li>32</li><li>37</li><li>41</li><li>43</li><li>51</li><li>56</li><li>58</li><li>59</li><li>65</li><li>83</li><li>84</li><li>87</li><li>4</li><li>9</li><li>16</li><li>25</li><li>28</li><li>29</li><li>34</li><li>38</li><li>40</li><li>46</li><li>57</li><li>63</li><li>64</li><li>67</li><li>69</li><li>72</li><li>81</li><li>82</li><li>89</li><li>95</li><li>10</li><li>14</li><li>23</li><li>30</li><li>31</li><li>33</li><li>49</li><li>50</li><li>55</li><li>62</li><li>66</li><li>70</li><li>73</li><li>74</li><li>75</li><li>79</li><li>88</li><li>90</li><li>94</li><li>100</li></ol>
</li>
	<li><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>5</li><li>8</li><li>12</li><li>19</li><li>27</li><li>36</li><li>39</li><li>42</li><li>48</li><li>53</li><li>71</li><li>76</li><li>77</li><li>78</li><li>80</li><li>92</li><li>93</li><li>96</li><li>97</li><li>99</li><li>3</li><li>6</li><li>11</li><li>15</li><li>17</li><li>18</li><li>20</li><li>22</li><li>32</li><li>37</li><li>41</li><li>43</li><li>51</li><li>56</li><li>58</li><li>59</li><li>65</li><li>83</li><li>84</li><li>87</li><li>4</li><li>9</li><li>16</li><li>25</li><li>28</li><li>29</li><li>34</li><li>38</li><li>40</li><li>46</li><li>57</li><li>63</li><li>64</li><li>67</li><li>69</li><li>72</li><li>81</li><li>82</li><li>89</li><li>95</li><li>1</li><li>2</li><li>7</li><li>13</li><li>21</li><li>24</li><li>26</li><li>35</li><li>44</li><li>45</li><li>47</li><li>52</li><li>54</li><li>60</li><li>61</li><li>68</li><li>85</li><li>86</li><li>91</li><li>98</li></ol>
</li>
</ol>
</dd>
	<dt>$test_ids</dt>
		<dd><ol>
	<li><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>5</li><li>8</li><li>12</li><li>19</li><li>27</li><li>36</li><li>39</li><li>42</li><li>48</li><li>53</li><li>71</li><li>76</li><li>77</li><li>78</li><li>80</li><li>92</li><li>93</li><li>96</li><li>97</li><li>99</li></ol>
</li>
	<li><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>3</li><li>6</li><li>11</li><li>15</li><li>17</li><li>18</li><li>20</li><li>22</li><li>32</li><li>37</li><li>41</li><li>43</li><li>51</li><li>56</li><li>58</li><li>59</li><li>65</li><li>83</li><li>84</li><li>87</li></ol>
</li>
	<li><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>4</li><li>9</li><li>16</li><li>25</li><li>28</li><li>29</li><li>34</li><li>38</li><li>40</li><li>46</li><li>57</li><li>63</li><li>64</li><li>67</li><li>69</li><li>72</li><li>81</li><li>82</li><li>89</li><li>95</li></ol>
</li>
	<li><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>1</li><li>2</li><li>7</li><li>13</li><li>21</li><li>24</li><li>26</li><li>35</li><li>44</li><li>45</li><li>47</li><li>52</li><li>54</li><li>60</li><li>61</li><li>68</li><li>85</li><li>86</li><li>91</li><li>98</li></ol>
</li>
	<li><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>10</li><li>14</li><li>23</li><li>30</li><li>31</li><li>33</li><li>49</li><li>50</li><li>55</li><li>62</li><li>66</li><li>70</li><li>73</li><li>74</li><li>75</li><li>79</li><li>88</li><li>90</li><li>94</li><li>100</li></ol>
</li>
</ol>
</dd>
</dl>
</li>
</ol>
</div></div>
</div>
</div>
</div>
<p>For each <span class="math notranslate nohighlight">\(k \in [K] = \lbrace 1, \ldots, K]\)</span> the nuisance ML estimator</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\hat{\eta}_{0,k} = \hat{\eta}_{0,k}\big((W_i)_{i\not\in I_k}\big)\]</div>
</div></blockquote>
<p>is based on the observations of all other <span class="math notranslate nohighlight">\(k-1\)</span> folds.
The values of the two score function components
<span class="math notranslate nohighlight">\(\psi_a(W_i; \hat{\eta}_0)\)</span> and <span class="math notranslate nohighlight">\(\psi_b(W_i; \hat{\eta}_0))\)</span>
for each observation index <span class="math notranslate nohighlight">\(i \in I_k\)</span> are computed and
stored in the attributes <code class="docutils literal notranslate"><span class="pre">psi_a</span></code> and <code class="docutils literal notranslate"><span class="pre">psi_b</span></code>.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="82558300-069b-427f-acf5-625a02fcbdcc" name="b28f4c11-ddc8-426d-a4a7-0e008708e7a7" type="radio">
</input><label class="tabbed-label" for="82558300-069b-427f-acf5-625a02fcbdcc">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [15]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">();</span>

<span class="gp">In [16]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">psi_a</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="go">[[[-2.88531   ]]</span>

<span class="go"> [[-2.90210293]]</span>

<span class="go"> [[-0.07859105]]</span>

<span class="go"> [[-0.32047806]]</span>

<span class="go"> [[-2.63196468]]]</span>

<span class="gp">In [17]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">psi_b</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="go">[[[ 0.14584976]]</span>

<span class="go"> [[-1.07752306]]</span>

<span class="go"> [[-0.11679041]]</span>

<span class="go"> [[ 0.39065473]]</span>

<span class="go"> [[ 1.14544635]]]</span>
</pre></div>
</div>
</div>
<input id="95d24850-ec0c-427b-88d1-26b20fbf7d67" name="b28f4c11-ddc8-426d-a4a7-0e008708e7a7" type="radio">
</input><label class="tabbed-label" for="95d24850-ec0c-427b-88d1-26b20fbf7d67">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>dml_plr_obj$fit()
print(dml_plr_obj$psi_a[1:5, ,1])
print(dml_plr_obj$psi_b[1:5, ,1])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] -5.04328550 -3.34457842 -0.00169177 -0.15758133 -1.58724094
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1]  0.13942453 -0.33361428  0.06837869 -0.54696003 -0.62099668
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="repeated-cross-fitting-with-k-folds-and-m-repetition">
<span id="repeated-cross-fitting"></span><h2><span class="section-number">9.2. </span>Repeated cross-fitting with <span class="math notranslate nohighlight">\(K\)</span> folds and <span class="math notranslate nohighlight">\(M\)</span> repetition<a class="headerlink" href="#repeated-cross-fitting-with-k-folds-and-m-repetition" title="Permalink to this headline">¶</a></h2>
<p>Repeated cross-fitting is obtained by choosing a value <span class="math notranslate nohighlight">\(M&gt;1\)</span> for the number of repetition <code class="docutils literal notranslate"><span class="pre">n_rep</span></code>.
It results in <span class="math notranslate nohighlight">\(M\)</span> random <span class="math notranslate nohighlight">\(K\)</span>-fold partitions being drawn.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="6e49125a-8c6b-4c51-a8e0-873342df6e92" name="fa1199c1-f45f-4c6f-8998-e56f9a8cfa1f" type="radio">
</input><label class="tabbed-label" for="6e49125a-8c6b-4c51-a8e0-873342df6e92">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [18]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span> <span class="n">n_folds</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_rep</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>

<span class="gp">In [19]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">n_folds</span><span class="p">)</span>
<span class="go">5</span>

<span class="gp">In [20]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">n_rep</span><span class="p">)</span>
<span class="go">10</span>
</pre></div>
</div>
</div>
<input id="b0b96dfd-c686-4707-8b64-694a8f6da215" name="fa1199c1-f45f-4c6f-8998-e56f9a8cfa1f" type="radio">
</input><label class="tabbed-label" for="b0b96dfd-c686-4707-8b64-694a8f6da215">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m, n_folds = 5, n_rep = 10)
print(dml_plr_obj$n_folds)
print(dml_plr_obj$n_rep)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] 5
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] 10
</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>For each of the <span class="math notranslate nohighlight">\(M\)</span> partitions, the nuisance ML models are estimated and score functions computed as described
in <a class="reference internal" href="#k-fold-cross-fitting"><span class="std std-ref">Cross-fitting with K folds</span></a>.
The resulting values of the score functions are stored in 3-dimensional arrays <code class="docutils literal notranslate"><span class="pre">psi_a</span></code> and <code class="docutils literal notranslate"><span class="pre">psi_b</span></code>, where the
row index corresponds the observation index <span class="math notranslate nohighlight">\(i \in [N] = \lbrace 1, \ldots, N\rbrace\)</span>
and the column index to the partition <span class="math notranslate nohighlight">\(m \in [M] = \lbrace 1, \ldots, M\rbrace\)</span>.
The third dimension refers to the treatment variable and becomes non-singleton in case of multiple treatment variables.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="e5f87a88-9f19-4f7c-91cc-9b262bdd5c2c" name="01021e15-8843-48e1-aad1-b78eaea192d6" type="radio">
</input><label class="tabbed-label" for="e5f87a88-9f19-4f7c-91cc-9b262bdd5c2c">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [21]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">();</span>

<span class="gp">In [22]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">psi_a</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">])</span>
<span class="go">[[-2.68599367 -3.23380465 -3.87925464 -2.89041468 -3.08674439 -3.17372511</span>
<span class="go">  -4.06162781 -2.71757056 -3.93769627 -4.80729735]</span>
<span class="go"> [-2.88112325 -2.42456107 -2.02910892 -2.04403523 -3.37767737 -2.35320534</span>
<span class="go">  -2.45193279 -2.22980749 -1.9562462  -2.09392654]</span>
<span class="go"> [-0.181359   -0.16799817 -0.07332458 -0.21872073 -0.06599282 -0.11102169</span>
<span class="go">  -0.16396342 -0.50714384 -0.29398956 -0.56135776]</span>
<span class="go"> [-0.04570088 -0.12277897 -0.10397745 -0.13543039 -0.36304868 -0.11301572</span>
<span class="go">  -0.19153314 -0.62534417 -0.02197674 -0.01718614]</span>
<span class="go"> [-2.99590389 -4.12622929 -1.77374567 -2.84585724 -1.47892889 -2.80198843</span>
<span class="go">  -4.7074332  -1.77410084 -3.5422875  -3.20771252]]</span>

<span class="gp">In [23]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">psi_b</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">])</span>
<span class="go">[[ 0.04605718  0.40626329  0.74793091  0.18205525 -0.13083083  0.24800699</span>
<span class="go">  -0.15153994  0.02067865  0.17040069  0.40464152]</span>
<span class="go"> [-0.44276955 -1.3415938  -0.50685506 -0.8130893  -0.40504965 -0.5433195</span>
<span class="go">  -0.77235098 -0.97564857 -0.68378606 -0.8890806 ]</span>
<span class="go"> [-0.2085827  -0.15144663 -0.10209256 -0.24270094 -0.20685474 -0.15512408</span>
<span class="go">  -0.11551561 -0.35281149 -0.07560974 -0.20729528]</span>
<span class="go"> [ 0.15462366  0.17402885  0.22050906  0.33823906  0.43836142  0.16201454</span>
<span class="go">   0.20697463  0.53725044  0.08476671  0.10902499]</span>
<span class="go"> [ 0.64042081  1.36752436  0.21184894  0.45545298  0.39017148  0.71515068</span>
<span class="go">   1.00864349  0.91863437  0.93603507  0.55055093]]</span>
</pre></div>
</div>
</div>
<input id="64d0b6f4-0fcc-4d4e-9f2a-e9bd4b7e5ff1" name="01021e15-8843-48e1-aad1-b78eaea192d6" type="radio">
</input><label class="tabbed-label" for="64d0b6f4-0fcc-4d4e-9f2a-e9bd4b7e5ff1">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>dml_plr_obj$fit()
print(dml_plr_obj$psi_a[1:5, ,1])
print(dml_plr_obj$psi_b[1:5, ,1])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>           [,1]        [,2]         [,3]          [,4]         [,5]
[1,] -7.0197456 -6.73917511 -6.793235980 -6.771992e+00 -5.365484954
[2,] -2.9610326 -2.87590251 -2.779803105 -3.379351e+00 -3.584349035
[3,] -0.1701172 -0.08074214 -0.004632868 -2.586886e-05 -0.006511975
[4,] -0.4575783 -0.08954329 -0.040258854 -1.298007e-02 -0.213147207
[5,] -1.5960983 -1.07984288 -1.389794267 -6.262164e-01 -1.348202058
             [,6]        [,7]          [,8]          [,9]       [,10]
[1,] -4.059327441 -4.89194037 -6.9464951281 -6.5358474474 -4.96446761
[2,] -4.267640064 -3.12329557 -3.5255755300 -3.3762500631 -2.14803855
[3,] -0.007394946 -0.02355336 -0.1544177919 -0.0002823763 -0.01132117
[4,] -0.083591711 -0.40505922 -0.0004867152 -0.0003564807 -0.01309433
[5,] -1.173782830 -1.22197517 -1.3011014234 -2.3091936603 -1.58977799
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>           [,1]       [,2]       [,3]         [,4]       [,5]       [,6]
[1,]  0.7293140  0.7151069  1.2679128  0.587555697 -0.1779704 -0.5746633
[2,] -0.7144908 -1.0110014 -0.7655938 -0.928463257  0.4089461  0.6906554
[3,] -0.6062212  0.4018902 -0.1089949 -0.009430181 -0.1376258 -0.1151909
[4,] -0.8817557 -0.2647558  0.4053105 -0.120032426 -0.6117385 -0.4001574
[5,] -0.3501772 -0.0162179 -0.2726885 -0.198454230 -0.2257089 -0.4022101
           [,7]        [,8]        [,9]      [,10]
[1,]  0.1338775  1.07469429  1.42147629 -0.1745989
[2,] -0.6162437 -0.90530097 -0.55511092 -0.2702633
[3,] -0.1850525 -0.55665375 -0.02289377  0.1601106
[4,] -1.0124681 -0.02499624  0.02669853  0.1122322
[5,] -0.3302765  0.21225735 -0.33461521 -0.5209101
</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>We estimate the causal parameter <span class="math notranslate nohighlight">\(\tilde{\theta}_{0,m}\)</span> for each of the <span class="math notranslate nohighlight">\(M\)</span> partitions with a DML
algorithm as described in <a class="reference internal" href="algorithms.html#algorithms"><span class="std std-ref">Double machine learning algorithms</span></a>.
Standard errors are obtained as described in <a class="reference internal" href="se_confint.html#se-confint"><span class="std std-ref">Variance estimation and confidence intervals for a causal parameter of interest</span></a>.
The aggregation of the estimates of the causal parameter and its standard errors is done using the median</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\tilde{\theta}_{0} &amp;= \text{Median}\big((\tilde{\theta}_{0,m})_{m \in [M]}\big),\\\hat{\sigma} &amp;= \sqrt{\text{Median}\big((\hat{\sigma}_m^2 + (\tilde{\theta}_{0,m} - \tilde{\theta}_{0})^2)_{m \in [M]}\big)}.\end{aligned}\end{align} \]</div>
</div></blockquote>
<p>The estimate of the causal parameter <span class="math notranslate nohighlight">\(\tilde{\theta}_{0}\)</span> is stored in the <code class="docutils literal notranslate"><span class="pre">coef</span></code> attribute
and the asymptotic standard error <span class="math notranslate nohighlight">\(\hat{\sigma}/\sqrt{N}\)</span> in <code class="docutils literal notranslate"><span class="pre">se</span></code>.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="5b80295d-0c79-4065-a8b6-356eb3d9e6be" name="b6dd001f-9c33-44b4-819c-a3dd0a90a543" type="radio">
</input><label class="tabbed-label" for="5b80295d-0c79-4065-a8b6-356eb3d9e6be">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [24]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">coef</span><span class="p">)</span>
<span class="go">[0.49855526]</span>

<span class="gp">In [25]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">se</span><span class="p">)</span>
<span class="go">[0.07599746]</span>
</pre></div>
</div>
</div>
<input id="8c6d8824-406e-461e-8c32-d8bff94ac14c" name="b6dd001f-9c33-44b4-819c-a3dd0a90a543" type="radio">
</input><label class="tabbed-label" for="8c6d8824-406e-461e-8c32-d8bff94ac14c">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>print(dml_plr_obj$coef)
print(dml_plr_obj$se)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>        d 
0.4566335 
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>         d 
0.08215616 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>The parameter estimates <span class="math notranslate nohighlight">\((\tilde{\theta}_{0,m})_{m \in [M]}\)</span> and asymptotic standard errors
<span class="math notranslate nohighlight">\((\hat{\sigma}_m/\sqrt{N})_{m \in [M]}\)</span> for each of the <span class="math notranslate nohighlight">\(M\)</span> partitions are stored in the attributes
<code class="docutils literal notranslate"><span class="pre">_all_coef</span></code> and <code class="docutils literal notranslate"><span class="pre">_all_se</span></code>, respectively.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="0f6ab52b-3247-4d38-8ac4-b35cff6f833e" name="afc85a44-4da0-4353-a39d-e1a41d8478b2" type="radio">
</input><label class="tabbed-label" for="0f6ab52b-3247-4d38-8ac4-b35cff6f833e">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [26]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">_all_coef</span><span class="p">)</span>
<span class="go">[[0.4912799  0.47383624 0.47971449 0.51116967 0.50583062 0.54217549</span>
<span class="go">  0.52744838 0.47070297 0.52106584 0.4732103 ]]</span>

<span class="gp">In [27]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">_all_se</span><span class="p">)</span>
<span class="go">[[0.07574142 0.0764744  0.07045978 0.08555445 0.08032833 0.0760157</span>
<span class="go">  0.07579885 0.0761749  0.07356857 0.07122361]]</span>
</pre></div>
</div>
</div>
<input id="0ae82430-0e0c-4c66-bb06-b72e6e0c0126" name="afc85a44-4da0-4353-a39d-e1a41d8478b2" type="radio">
</input><label class="tabbed-label" for="0ae82430-0e0c-4c66-bb06-b72e6e0c0126">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>print(dml_plr_obj$all_coef)
print(dml_plr_obj$all_se)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>          [,1]      [,2]     [,3]      [,4]      [,5]      [,6]      [,7]
[1,] 0.4301688 0.4660924 0.459442 0.4232786 0.4858854 0.4348586 0.4928431
          [,8]      [,9]     [,10]
[1,] 0.4784604 0.4371613 0.4538251
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>           [,1]       [,2]       [,3]      [,4]       [,5]      [,6]       [,7]
[1,] 0.08552354 0.08395575 0.08283511 0.0759131 0.08349116 0.0875911 0.08139057
           [,8]       [,9]      [,10]
[1,] 0.07458783 0.07502135 0.08063287
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="externally-provide-a-sample-splitting-partition">
<h2><span class="section-number">9.3. </span>Externally provide a sample splitting / partition<a class="headerlink" href="#externally-provide-a-sample-splitting-partition" title="Permalink to this headline">¶</a></h2>
<p>All DML models allow a partition to be provided externally via the method <code class="docutils literal notranslate"><span class="pre">set_sample_splitting()</span></code>.
In Python we can for example use the K-Folds cross-validator of sklearn <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> in
order to generate a sample splitting and provide it to the DML model object.
Note that by setting <code class="docutils literal notranslate"><span class="pre">draw_sample_splitting</span> <span class="pre">=</span> <span class="pre">False</span></code> one can prevent that a partition is drawn during initialization
of the DML model object.
The following calls are equivalent.
In the first sample code, we use the standard interface and draw the sample-splitting with <span class="math notranslate nohighlight">\(K=4\)</span> folds during
initialization of the <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code> object.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="f08a8059-227f-40c4-b778-c95495c715ea" name="b1ca5335-a1b1-4e18-80a0-eaea8df5e7ad" type="radio">
</input><label class="tabbed-label" for="f08a8059-227f-40c4-b778-c95495c715ea">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [28]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">314</span><span class="p">)</span>

<span class="gp">In [29]: </span><span class="n">dml_plr_obj_internal</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span> <span class="n">n_folds</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>

<span class="gp">In [30]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj_internal</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">     coef   std err         t         P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.5005  0.086388  5.793628  6.888187e-09  0.331182  0.669817</span>
</pre></div>
</div>
</div>
<input id="4486acad-1265-4069-88a6-fec0d482f17b" name="b1ca5335-a1b1-4e18-80a0-eaea8df5e7ad" type="radio">
</input><label class="tabbed-label" for="4486acad-1265-4069-88a6-fec0d482f17b">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>set.seed(314)
dml_plr_obj_internal = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m, n_folds = 4)
dml_plr_obj_internal$fit()
dml_plr_obj_internal$summary()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Estimates and significance testing of the effect of target variables
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.47109    0.08819   5.342  9.2e-08 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>In the second sample code, we use the K-Folds cross-validator of sklearn <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a>
and set the partition via the <code class="docutils literal notranslate"><span class="pre">set_sample_splitting()</span></code> method.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="4b6f4641-ca8c-4fcd-ade4-b617ee710a88" name="91f14a83-8baf-43a7-abae-8c81d78dc0fc" type="radio">
</input><label class="tabbed-label" for="4b6f4641-ca8c-4fcd-ade4-b617ee710a88">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [31]: </span><span class="n">dml_plr_obj_external</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span> <span class="n">draw_sample_splitting</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>

<span class="gp">In [32]: </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>

<span class="gp">In [33]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">314</span><span class="p">)</span>

<span class="gp">In [34]: </span><span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">In [35]: </span><span class="n">smpls</span> <span class="o">=</span> <span class="p">[(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span> <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="o">.</span><span class="n">x</span><span class="p">)]</span>

<span class="gp">In [36]: </span><span class="n">dml_plr_obj_external</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">(</span><span class="n">smpls</span><span class="p">);</span>

<span class="gp">In [37]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj_external</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">     coef   std err         t         P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.5005  0.086388  5.793628  6.888187e-09  0.331182  0.669817</span>
</pre></div>
</div>
</div>
<input id="58e65056-04ca-4c6d-8458-34bda0fe9e71" name="91f14a83-8baf-43a7-abae-8c81d78dc0fc" type="radio">
</input><label class="tabbed-label" for="58e65056-04ca-4c6d-8458-34bda0fe9e71">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>dml_plr_obj_external = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m, draw_sample_splitting = FALSE)

set.seed(314)
# set up a task and cross-validation resampling scheme in mlr3
my_task = Task$new(&quot;help task&quot;, &quot;regr&quot;, data)
my_sampling = rsmp(&quot;cv&quot;, folds = 4)$instantiate(my_task)

train_ids = lapply(1:4, function(x) my_sampling$train_set(x))
test_ids = lapply(1:4, function(x) my_sampling$test_set(x))
smpls = list(list(train_ids = train_ids, test_ids = test_ids))

dml_plr_obj_external$set_sample_splitting(smpls)
dml_plr_obj_external$fit()
dml_plr_obj_external$summary()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Estimates and significance testing of the effect of target variables
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.47109    0.08819   5.342  9.2e-08 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="sample-splitting-without-cross-fitting">
<h2><span class="section-number">9.4. </span>Sample-splitting without cross-fitting<a class="headerlink" href="#sample-splitting-without-cross-fitting" title="Permalink to this headline">¶</a></h2>
<p>The boolean flag <code class="docutils literal notranslate"><span class="pre">apply_cross_fitting</span></code> allows to estimate DML models without applying cross-fitting.
It results in randomly splitting the sample into two parts.
The first half of the data is used for the estimation of the nuisance ML models and the second half for estimating the
causal parameter.
Note that cross-fitting performs well empirically and is recommended to remove bias induced by overfitting, see also
<a class="reference internal" href="basics.html#bias-overfitting"><span class="std std-ref">Sample splitting to remove bias induced by overfitting</span></a>.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="32719097-319d-4613-9e3f-0449b2841575" name="d65bfa1d-34a9-4700-817d-2a48706aba6b" type="radio">
</input><label class="tabbed-label" for="32719097-319d-4613-9e3f-0449b2841575">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [38]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">314</span><span class="p">)</span>

<span class="gp">In [39]: </span><span class="n">dml_plr_obj_external</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span>
<span class="gp">   ....: </span>                                       <span class="n">n_folds</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">apply_cross_fitting</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="gp">   ....: </span>

<span class="gp">In [40]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj_external</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err         t     P&gt;|t|     2.5 %   97.5 %</span>
<span class="go">d  0.559242  0.118328  4.726196  0.000002  0.327323  0.79116</span>
</pre></div>
</div>
</div>
<input id="bf0ab1e4-66e2-4d5c-9e3b-4c06222ee7e3" name="d65bfa1d-34a9-4700-817d-2a48706aba6b" type="radio">
</input><label class="tabbed-label" for="bf0ab1e4-66e2-4d5c-9e3b-4c06222ee7e3">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>dml_plr_obj_external = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m,
                                       n_folds = 2, apply_cross_fitting = FALSE)
dml_plr_obj_external$fit()
dml_plr_obj_external$summary()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Estimates and significance testing of the effect of target variables
  Estimate. Std. Error t value Pr(&gt;|t|)    
d    0.5123     0.1010   5.072 3.94e-07 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>Note, that in order to split data unevenly into train and test sets the interface to externally set the sample splitting
via <code class="docutils literal notranslate"><span class="pre">set_sample_splitting()</span></code> needs to be applied, like for example:</p>
<div class="tabbed-set docutils">
<input checked="checked" id="38bc0b2f-d63c-47a7-ac72-3d57a85847dc" name="ec388aee-9d3b-452f-96d7-c94703682cd1" type="radio">
</input><label class="tabbed-label" for="38bc0b2f-d63c-47a7-ac72-3d57a85847dc">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [41]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">314</span><span class="p">)</span>

<span class="gp">In [42]: </span><span class="n">dml_plr_obj_external</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span>
<span class="gp">   ....: </span>                                       <span class="n">n_folds</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">apply_cross_fitting</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">draw_sample_splitting</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="gp">   ....: </span>

<span class="gp">In [43]: </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="gp">In [44]: </span><span class="n">smpls</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="o">.</span><span class="n">n_obs</span><span class="p">),</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>

<span class="gp">In [45]: </span><span class="n">dml_plr_obj_external</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">smpls</span><span class="p">));</span>

<span class="gp">In [46]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj_external</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">      coef   std err         t     P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.47396  0.134194  3.531894  0.000413  0.210944  0.736976</span>
</pre></div>
</div>
</div>
<input id="eff65b80-5bac-4abd-b281-bc2ebb78858f" name="ec388aee-9d3b-452f-96d7-c94703682cd1" type="radio">
</input><label class="tabbed-label" for="eff65b80-5bac-4abd-b281-bc2ebb78858f">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>dml_plr_obj_external = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m,
                                        n_folds = 2, apply_cross_fitting = FALSE,
                                        draw_sample_splitting = FALSE)

set.seed(314)
# set up a task and cross-validation resampling scheme in mlr3
my_task = Task$new(&quot;help task&quot;, &quot;regr&quot;, data)
my_sampling = rsmp(&quot;holdout&quot;, ratio = 0.8)$instantiate(my_task)

train_ids = list(my_sampling$train_set(1))
test_ids = list(my_sampling$test_set(1))
smpls = list(list(train_ids = train_ids, test_ids = test_ids))

dml_plr_obj_external$set_sample_splitting(smpls)
dml_plr_obj_external$fit()
dml_plr_obj_external$summary()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Estimates and significance testing of the effect of target variables
  Estimate. Std. Error t value Pr(&gt;|t|)  
d    0.2907     0.1512   1.923   0.0545 .
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="estimate-dml-models-without-sample-splitting">
<h2><span class="section-number">9.5. </span>Estimate DML models without sample-splitting<a class="headerlink" href="#estimate-dml-models-without-sample-splitting" title="Permalink to this headline">¶</a></h2>
<p>The implementation of the DML models allows the estimation without sample splitting, i.e., all observations are used
for learning the nuisance models as well as for the estimation of the causal parameter.
Note that this approach usually results in a bias and is therefore not recommended without appropriate theoretical
justification, see also <a class="reference internal" href="basics.html#bias-overfitting"><span class="std std-ref">Sample splitting to remove bias induced by overfitting</span></a>.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="f787fc06-fb52-4477-85af-792ccd2f0d32" name="74182477-786c-42f6-8839-42654bb4508d" type="radio">
</input><label class="tabbed-label" for="f787fc06-fb52-4477-85af-792ccd2f0d32">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [47]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">314</span><span class="p">)</span>

<span class="gp">In [48]: </span><span class="n">dml_plr_no_split</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span>
<span class="gp">   ....: </span>                                   <span class="n">n_folds</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">apply_cross_fitting</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="gp">   ....: </span>

<span class="gp">In [49]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj_external</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err        t    P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.508076  0.125342  4.05353  0.00005  0.262411  0.753741</span>
</pre></div>
</div>
</div>
<input id="4286b5ba-fc3f-4b83-9a72-ce2e6273885a" name="74182477-786c-42f6-8839-42654bb4508d" type="radio">
</input><label class="tabbed-label" for="4286b5ba-fc3f-4b83-9a72-ce2e6273885a">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>dml_plr_no_split = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m,
                                   n_folds = 1, apply_cross_fitting = FALSE)

set.seed(314)
dml_plr_no_split$fit()
dml_plr_no_split$summary()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Estimates and significance testing of the effect of target variables
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.48698    0.09354   5.206 1.93e-07 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="sim_inf.html" title="previous page"><span class="section-number">8. </span>Confidence bands and multiplier bootstrap for valid simultaneous inference</a>
    <a class='right-next' id="next-link" href="../workflow/workflow.html" title="next page">DoubleML Workflow</a>

              </div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.1.2.<br/>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>