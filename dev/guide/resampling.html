
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>8. Sample-splitting, cross-fitting and repeated cross-fitting &#8212; DoubleML 0.2.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Examples" href="../auto_examples/index.html" />
    <link rel="prev" title="7. Variance estimation, confidence intervals and multiplier bootstrap" href="se_confint.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <p class="title">DoubleML</p>
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../index.html">DoubleML</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/install.html"> Install</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../intro/intro.html"> Getting started</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="guide.html"> User guide</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../auto_examples/index.html"> Examples</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../api/api.html"> Python API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="https://docs.doubleml.org/r/stable/"> R API</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../release/release.html"> Release notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
          
            
                <li class="">
                    <a href="basics.html"> The basics of double/debiased machine learning</a>
                </li>
            
          
            
                <li class="">
                    <a href="data_backend.html"> The data-backend DoubleMLData</a>
                </li>
            
          
            
                <li class="">
                    <a href="models.html"> Models</a>
                </li>
            
          
            
                <li class="">
                    <a href="scores.html"> Score functions</a>
                </li>
            
          
            
                <li class="">
                    <a href="algorithms.html"> Double machine learning algorithms</a>
                </li>
            
          
            
                <li class="">
                    <a href="learners.html"> Machine learners, hyperparameters and hyperparameter tuning</a>
                </li>
            
          
            
                <li class="">
                    <a href="se_confint.html"> Variance estimation, confidence intervals and boostrap standard errors</a>
                </li>
            
          
            
                <li class="active">
                    <a href=""> Sample-splitting, cross-fitting and repeated cross-fitting</a>
                </li>
            
          
        
        
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#cross-fitting-with-k-folds" class="nav-link">Cross-fitting with K folds</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#repeated-cross-fitting-with-k-folds-and-m-repetition" class="nav-link">Repeated cross-fitting with K folds and M repetition</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#externally-provide-a-sample-splitting-partition" class="nav-link">Externally provide a sample splitting / partition</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#sample-splitting-without-cross-fitting" class="nav-link">Sample-splitting without cross-fitting</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#estimate-dml-models-without-sample-splitting" class="nav-link">Estimate DML models without sample-splitting</a>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="sample-splitting-cross-fitting-and-repeated-cross-fitting">
<span id="resampling"></span><h1><span class="section-number">8. </span>Sample-splitting, cross-fitting and repeated cross-fitting<a class="headerlink" href="#sample-splitting-cross-fitting-and-repeated-cross-fitting" title="Permalink to this headline">Â¶</a></h1>
<p>Sample-splitting and the application of cross-fitting is a central part of double/debiased machine learning (DML).
For all DML models
<code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code>,
<code class="docutils literal notranslate"><span class="pre">DoubleMLPLIV</span></code>,
<code class="docutils literal notranslate"><span class="pre">DoubleMLIRM</span></code>,
and <code class="docutils literal notranslate"><span class="pre">DoubleMLIIVM</span></code>,
the specification is done via the parameters <code class="docutils literal notranslate"><span class="pre">n_folds</span></code> and <code class="docutils literal notranslate"><span class="pre">n_rep</span></code>.
Advanced resampling techniques can be obtained via the boolean parameters
<code class="docutils literal notranslate"><span class="pre">draw_sample_splitting</span></code> and <code class="docutils literal notranslate"><span class="pre">apply_cross_fitting</span></code> as well as the methods
<code class="docutils literal notranslate"><span class="pre">draw_sample_splitting()</span></code> and <code class="docutils literal notranslate"><span class="pre">set_sample_splitting()</span></code>.</p>
<p>As an example we consider a partially linear regression model (PLR)
implemented in <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code>.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="b01423c4-4149-4911-a9ed-e87765b8aede" name="d7697fe9-0649-4860-9189-762ff4ef733c" type="radio">
</input><label class="tabbed-label" for="b01423c4-4149-4911-a9ed-e87765b8aede">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [2]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="gp">In [3]: </span><span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_plr_CCDDHNR2018</span>

<span class="gp">In [4]: </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="gp">In [5]: </span><span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">clone</span>

<span class="gp">In [6]: </span><span class="n">learner</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [7]: </span><span class="n">ml_g</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">learner</span><span class="p">)</span>

<span class="gp">In [8]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">learner</span><span class="p">)</span>

<span class="gp">In [9]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="gp">In [10]: </span><span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">make_plr_CCDDHNR2018</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input id="980aad75-8371-41ee-8b63-c42c1fe2717d" name="d7697fe9-0649-4860-9189-762ff4ef733c" type="radio">
</input><label class="tabbed-label" for="980aad75-8371-41ee-8b63-c42c1fe2717d">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13</pre></div></td><td class="code"><div class="highlight"><pre><span></span>library(DoubleML)
library(mlr3)
lgr::get_logger(&quot;mlr3&quot;)$set_threshold(&quot;warn&quot;)
library(mlr3learners)
library(data.table)

learner = lrn(&quot;regr.ranger&quot;, num.trees = 100, mtry = 20, min.node.size = 2, max.depth = 5)
ml_g = learner
ml_m = learner
data = make_plr_CCDDHNR2018(alpha=0.5, n_obs=100, return_type = &quot;data.table&quot;)
obj_dml_data = DoubleMLData$new(data,
                                y_col = &quot;y&quot;,
                                d_cols = &quot;d&quot;)
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
</div>
</div>
</div>
</div>
<div class="section" id="cross-fitting-with-k-folds">
<span id="k-fold-cross-fitting"></span><h2><span class="section-number">8.1. </span>Cross-fitting with <span class="math notranslate nohighlight">\(K\)</span> folds<a class="headerlink" href="#cross-fitting-with-k-folds" title="Permalink to this headline">Â¶</a></h2>
<p>The default setting is <code class="docutils literal notranslate"><span class="pre">n_folds</span> <span class="pre">=</span> <span class="pre">5</span></code> and <code class="docutils literal notranslate"><span class="pre">n_rep</span> <span class="pre">=</span> <span class="pre">1</span></code>, i.e.,
<span class="math notranslate nohighlight">\(K=5\)</span> folds and no repeated cross-fitting.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="1e75acb1-219d-4654-9f4d-a61ef0a5cd1e" name="2a60bd4b-132e-4fa5-80e8-90930f93d23f" type="radio">
</input><label class="tabbed-label" for="1e75acb1-219d-4654-9f4d-a61ef0a5cd1e">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [11]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span> <span class="n">n_folds</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_rep</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="gp">In [12]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">n_folds</span><span class="p">)</span>
<span class="go">5</span>

<span class="gp">In [13]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">n_rep</span><span class="p">)</span>
<span class="go">1</span>
</pre></div>
</div>
</div>
<input id="664d7083-6d19-43dd-aa56-6001e8cfdc42" name="2a60bd4b-132e-4fa5-80e8-90930f93d23f" type="radio">
</input><label class="tabbed-label" for="664d7083-6d19-43dd-aa56-6001e8cfdc42">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="highlight"><pre><span></span>dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m, n_folds = 5, n_rep = 1)
print(dml_plr_obj$n_folds)
print(dml_plr_obj$n_rep)
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] 5
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] 1
</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>During the initialization of a DML model like <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code> a <span class="math notranslate nohighlight">\(K\)</span>-fold random
partition <span class="math notranslate nohighlight">\((I_k)_{k=1}^{K}\)</span> of observation indices is generated.
The <span class="math notranslate nohighlight">\(K\)</span>-fold random partition is stored in the <code class="docutils literal notranslate"><span class="pre">smpls</span></code> attribute of the DML model object.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="e767a059-c813-4989-a3a5-2c075e0fc0b5" name="c7137f10-dec1-468d-aa24-7c74a3fd8de2" type="radio">
</input><label class="tabbed-label" for="e767a059-c813-4989-a3a5-2c075e0fc0b5">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [14]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">smpls</span><span class="p">)</span>
<span class="go">[[(array([ 0,  2,  3,  4,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 19,</span>
<span class="go">       21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38, 40, 44,</span>
<span class="go">       46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64,</span>
<span class="go">       65, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 80, 81, 82, 84, 85,</span>
<span class="go">       86, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99]), array([ 1,  5, 18, 20, 26, 30, 33, 39, 41, 42, 43, 45, 56, 57, 66, 73, 78,</span>
<span class="go">       83, 87, 96])), (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 14, 15, 16, 17,</span>
<span class="go">       18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40,</span>
<span class="go">       41, 42, 43, 44, 45, 46, 48, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63,</span>
<span class="go">       65, 66, 69, 70, 71, 72, 73, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87,</span>
<span class="go">       88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), array([ 9, 23, 24, 25, 27, 28, 35, 47, 49, 50, 51, 52, 59, 64, 67, 68, 74,</span>
<span class="go">       75, 76, 86])), (array([ 0,  1,  2,  3,  5,  6,  7,  9, 10, 11, 12, 14, 16, 17, 18, 20, 21,</span>
<span class="go">       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 38, 39, 40, 41, 42,</span>
<span class="go">       43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62,</span>
<span class="go">       63, 64, 65, 66, 67, 68, 69, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81,</span>
<span class="go">       83, 84, 86, 87, 88, 89, 90, 91, 92, 96, 98, 99]), array([ 4,  8, 13, 15, 19, 32, 34, 36, 37, 46, 54, 55, 70, 72, 82, 85, 93,</span>
<span class="go">       94, 95, 97])), (array([ 0,  1,  3,  4,  5,  6,  8,  9, 13, 14, 15, 17, 18, 19, 20, 21, 22,</span>
<span class="go">       23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41,</span>
<span class="go">       42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 64,</span>
<span class="go">       65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82,</span>
<span class="go">       83, 85, 86, 87, 88, 89, 93, 94, 95, 96, 97, 98]), array([ 2,  7, 10, 11, 12, 16, 38, 40, 48, 58, 60, 61, 62, 63, 81, 84, 90,</span>
<span class="go">       91, 92, 99])), (array([ 1,  2,  4,  5,  7,  8,  9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 23,</span>
<span class="go">       24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,</span>
<span class="go">       43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61,</span>
<span class="go">       62, 63, 64, 66, 67, 68, 70, 72, 73, 74, 75, 76, 78, 81, 82, 83, 84,</span>
<span class="go">       85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 99]), array([ 0,  3,  6, 14, 17, 21, 22, 29, 31, 44, 53, 65, 69, 71, 77, 79, 80,</span>
<span class="go">       88, 89, 98]))]]</span>
</pre></div>
</div>
</div>
<input id="7e11d104-48d2-49fd-bd95-7e9677ce813d" name="c7137f10-dec1-468d-aa24-7c74a3fd8de2" type="radio">
</input><label class="tabbed-label" for="7e11d104-48d2-49fd-bd95-7e9677ce813d">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="highlight"><pre><span></span>dml_plr_obj$smpls
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><ol>
	<li><dl>
	<dt>$train_ids</dt>
		<dd><ol>
	<li><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>3</li><li>4</li><li>7</li><li>9</li><li>12</li><li>14</li><li>21</li><li>24</li><li>34</li><li>37</li><li>39</li><li>52</li><li>60</li><li>68</li><li>75</li><li>81</li><li>82</li><li>86</li><li>90</li><li>95</li><li>5</li><li>6</li><li>8</li><li>11</li><li>16</li><li>19</li><li>22</li><li>26</li><li>38</li><li>42</li><li>44</li><li>49</li><li>50</li><li>55</li><li>57</li><li>61</li><li>76</li><li>85</li><li>96</li><li>100</li><li>23</li><li>25</li><li>27</li><li>29</li><li>32</li><li>33</li><li>40</li><li>41</li><li>51</li><li>54</li><li>63</li><li>66</li><li>67</li><li>69</li><li>70</li><li>84</li><li>91</li><li>92</li><li>97</li><li>98</li><li>2</li><li>13</li><li>15</li><li>20</li><li>36</li><li>43</li><li>53</li><li>58</li><li>64</li><li>65</li><li>71</li><li>72</li><li>73</li><li>74</li><li>77</li><li>78</li><li>79</li><li>80</li><li>87</li><li>88</li></ol>
</li>
	<li><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>1</li><li>10</li><li>17</li><li>18</li><li>28</li><li>30</li><li>31</li><li>35</li><li>45</li><li>46</li><li>47</li><li>48</li><li>56</li><li>59</li><li>62</li><li>83</li><li>89</li><li>93</li><li>94</li><li>99</li><li>5</li><li>6</li><li>8</li><li>11</li><li>16</li><li>19</li><li>22</li><li>26</li><li>38</li><li>42</li><li>44</li><li>49</li><li>50</li><li>55</li><li>57</li><li>61</li><li>76</li><li>85</li><li>96</li><li>100</li><li>23</li><li>25</li><li>27</li><li>29</li><li>32</li><li>33</li><li>40</li><li>41</li><li>51</li><li>54</li><li>63</li><li>66</li><li>67</li><li>69</li><li>70</li><li>84</li><li>91</li><li>92</li><li>97</li><li>98</li><li>2</li><li>13</li><li>15</li><li>20</li><li>36</li><li>43</li><li>53</li><li>58</li><li>64</li><li>65</li><li>71</li><li>72</li><li>73</li><li>74</li><li>77</li><li>78</li><li>79</li><li>80</li><li>87</li><li>88</li></ol>
</li>
	<li><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>1</li><li>10</li><li>17</li><li>18</li><li>28</li><li>30</li><li>31</li><li>35</li><li>45</li><li>46</li><li>47</li><li>48</li><li>56</li><li>59</li><li>62</li><li>83</li><li>89</li><li>93</li><li>94</li><li>99</li><li>3</li><li>4</li><li>7</li><li>9</li><li>12</li><li>14</li><li>21</li><li>24</li><li>34</li><li>37</li><li>39</li><li>52</li><li>60</li><li>68</li><li>75</li><li>81</li><li>82</li><li>86</li><li>90</li><li>95</li><li>23</li><li>25</li><li>27</li><li>29</li><li>32</li><li>33</li><li>40</li><li>41</li><li>51</li><li>54</li><li>63</li><li>66</li><li>67</li><li>69</li><li>70</li><li>84</li><li>91</li><li>92</li><li>97</li><li>98</li><li>2</li><li>13</li><li>15</li><li>20</li><li>36</li><li>43</li><li>53</li><li>58</li><li>64</li><li>65</li><li>71</li><li>72</li><li>73</li><li>74</li><li>77</li><li>78</li><li>79</li><li>80</li><li>87</li><li>88</li></ol>
</li>
	<li><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>1</li><li>10</li><li>17</li><li>18</li><li>28</li><li>30</li><li>31</li><li>35</li><li>45</li><li>46</li><li>47</li><li>48</li><li>56</li><li>59</li><li>62</li><li>83</li><li>89</li><li>93</li><li>94</li><li>99</li><li>3</li><li>4</li><li>7</li><li>9</li><li>12</li><li>14</li><li>21</li><li>24</li><li>34</li><li>37</li><li>39</li><li>52</li><li>60</li><li>68</li><li>75</li><li>81</li><li>82</li><li>86</li><li>90</li><li>95</li><li>5</li><li>6</li><li>8</li><li>11</li><li>16</li><li>19</li><li>22</li><li>26</li><li>38</li><li>42</li><li>44</li><li>49</li><li>50</li><li>55</li><li>57</li><li>61</li><li>76</li><li>85</li><li>96</li><li>100</li><li>2</li><li>13</li><li>15</li><li>20</li><li>36</li><li>43</li><li>53</li><li>58</li><li>64</li><li>65</li><li>71</li><li>72</li><li>73</li><li>74</li><li>77</li><li>78</li><li>79</li><li>80</li><li>87</li><li>88</li></ol>
</li>
	<li><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>1</li><li>10</li><li>17</li><li>18</li><li>28</li><li>30</li><li>31</li><li>35</li><li>45</li><li>46</li><li>47</li><li>48</li><li>56</li><li>59</li><li>62</li><li>83</li><li>89</li><li>93</li><li>94</li><li>99</li><li>3</li><li>4</li><li>7</li><li>9</li><li>12</li><li>14</li><li>21</li><li>24</li><li>34</li><li>37</li><li>39</li><li>52</li><li>60</li><li>68</li><li>75</li><li>81</li><li>82</li><li>86</li><li>90</li><li>95</li><li>5</li><li>6</li><li>8</li><li>11</li><li>16</li><li>19</li><li>22</li><li>26</li><li>38</li><li>42</li><li>44</li><li>49</li><li>50</li><li>55</li><li>57</li><li>61</li><li>76</li><li>85</li><li>96</li><li>100</li><li>23</li><li>25</li><li>27</li><li>29</li><li>32</li><li>33</li><li>40</li><li>41</li><li>51</li><li>54</li><li>63</li><li>66</li><li>67</li><li>69</li><li>70</li><li>84</li><li>91</li><li>92</li><li>97</li><li>98</li></ol>
</li>
</ol>
</dd>
	<dt>$test_ids</dt>
		<dd><ol>
	<li><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>1</li><li>10</li><li>17</li><li>18</li><li>28</li><li>30</li><li>31</li><li>35</li><li>45</li><li>46</li><li>47</li><li>48</li><li>56</li><li>59</li><li>62</li><li>83</li><li>89</li><li>93</li><li>94</li><li>99</li></ol>
</li>
	<li><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>3</li><li>4</li><li>7</li><li>9</li><li>12</li><li>14</li><li>21</li><li>24</li><li>34</li><li>37</li><li>39</li><li>52</li><li>60</li><li>68</li><li>75</li><li>81</li><li>82</li><li>86</li><li>90</li><li>95</li></ol>
</li>
	<li><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>5</li><li>6</li><li>8</li><li>11</li><li>16</li><li>19</li><li>22</li><li>26</li><li>38</li><li>42</li><li>44</li><li>49</li><li>50</li><li>55</li><li>57</li><li>61</li><li>76</li><li>85</li><li>96</li><li>100</li></ol>
</li>
	<li><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>23</li><li>25</li><li>27</li><li>29</li><li>32</li><li>33</li><li>40</li><li>41</li><li>51</li><li>54</li><li>63</li><li>66</li><li>67</li><li>69</li><li>70</li><li>84</li><li>91</li><li>92</li><li>97</li><li>98</li></ol>
</li>
	<li><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>2</li><li>13</li><li>15</li><li>20</li><li>36</li><li>43</li><li>53</li><li>58</li><li>64</li><li>65</li><li>71</li><li>72</li><li>73</li><li>74</li><li>77</li><li>78</li><li>79</li><li>80</li><li>87</li><li>88</li></ol>
</li>
</ol>
</dd>
</dl>
</li>
</ol>
</div></div>
</div>
</div>
</div>
<p>For each <span class="math notranslate nohighlight">\(k \in [K] = \lbrace 1, \ldots, K]\)</span> the nuisance ML estimator</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\hat{\eta}_{0,k} = \hat{\eta}_{0,k}\big((W_i)_{i\not\in I_k}\big)\]</div>
</div></blockquote>
<p>is based on the observations of all other <span class="math notranslate nohighlight">\(k-1\)</span> folds.
The values of the two score function components
<span class="math notranslate nohighlight">\(\psi_a(W_i; \hat{\eta}_0)\)</span> and <span class="math notranslate nohighlight">\(\psi_b(W_i; \hat{\eta}_0))\)</span>
for each observation index <span class="math notranslate nohighlight">\(i \in I_k\)</span> are computed and
stored in the attributes <code class="docutils literal notranslate"><span class="pre">psi_a</span></code> and <code class="docutils literal notranslate"><span class="pre">psi_b</span></code>.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="2385c9f1-27aa-44b2-b6ca-e626346814a6" name="ed1a83cd-dedb-409f-a3cd-d25865fc4ac9" type="radio">
</input><label class="tabbed-label" for="2385c9f1-27aa-44b2-b6ca-e626346814a6">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [15]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">();</span>

<span class="gp">In [16]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">psi_a</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="go">[[[-2.77031254]]</span>

<span class="go"> [[-2.87771887]]</span>

<span class="go"> [[-0.08013837]]</span>

<span class="go"> [[-0.36003344]]</span>

<span class="go"> [[-2.62438715]]]</span>

<span class="gp">In [17]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">psi_b</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="go">[[[ 0.08694518]]</span>

<span class="go"> [[-1.06665591]]</span>

<span class="go"> [[-0.1202984 ]]</span>

<span class="go"> [[ 0.4134775 ]]</span>

<span class="go"> [[ 1.11809605]]]</span>
</pre></div>
</div>
</div>
<input id="9195fddd-9106-4f42-a72b-d46e0ba985df" name="ed1a83cd-dedb-409f-a3cd-d25865fc4ac9" type="radio">
</input><label class="tabbed-label" for="9195fddd-9106-4f42-a72b-d46e0ba985df">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="highlight"><pre><span></span>dml_plr_obj$fit()
print(dml_plr_obj$psi_a[1:5, ,1])
print(dml_plr_obj$psi_b[1:5, ,1])
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] -7.1933002 -1.7764012 -4.0778379 -0.0595795 -4.5255830
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1]  5.4721191  1.3236719  1.9578583 -0.4693057  1.9354612
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="repeated-cross-fitting-with-k-folds-and-m-repetition">
<h2><span class="section-number">8.2. </span>Repeated cross-fitting with <span class="math notranslate nohighlight">\(K\)</span> folds and <span class="math notranslate nohighlight">\(M\)</span> repetition<a class="headerlink" href="#repeated-cross-fitting-with-k-folds-and-m-repetition" title="Permalink to this headline">Â¶</a></h2>
<p>Repeated cross-fitting is obtained by choosing a value <span class="math notranslate nohighlight">\(M&gt;1\)</span> for the number of repetition <code class="docutils literal notranslate"><span class="pre">n_rep</span></code>.
It results in <span class="math notranslate nohighlight">\(M\)</span> random <span class="math notranslate nohighlight">\(K\)</span>-fold partitions being drawn.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="c6d65483-460e-4c78-b3dd-363740ed88a0" name="7a1db5e2-8fe7-4a0b-be37-68e754315783" type="radio">
</input><label class="tabbed-label" for="c6d65483-460e-4c78-b3dd-363740ed88a0">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [18]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span> <span class="n">n_folds</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_rep</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>

<span class="gp">In [19]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">n_folds</span><span class="p">)</span>
<span class="go">5</span>

<span class="gp">In [20]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">n_rep</span><span class="p">)</span>
<span class="go">10</span>
</pre></div>
</div>
</div>
<input id="5850ac94-d969-4bc8-a86d-932d245a76bf" name="7a1db5e2-8fe7-4a0b-be37-68e754315783" type="radio">
</input><label class="tabbed-label" for="5850ac94-d969-4bc8-a86d-932d245a76bf">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="highlight"><pre><span></span>dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m, n_folds = 5, n_rep = 10)
print(dml_plr_obj$n_folds)
print(dml_plr_obj$n_rep)
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] 5
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] 10
</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>For each of the <span class="math notranslate nohighlight">\(M\)</span> partitions, the nuisance ML models are estimated and score functions computed as described
in <a class="reference internal" href="#k-fold-cross-fitting"><span class="std std-ref">Cross-fitting with K folds</span></a>.
The resulting values of the score functions are stored in 3-dimensional arrays <code class="docutils literal notranslate"><span class="pre">psi_a</span></code> and <code class="docutils literal notranslate"><span class="pre">psi_b</span></code>, where the
row index corresponds the observation index <span class="math notranslate nohighlight">\(i \in [N] = \lbrace 1, \ldots, N]\)</span>
and the column index to the partition <span class="math notranslate nohighlight">\(m \in [M] = \lbrace 1, \ldots, M]\)</span>.
The third dimension refers to the treatment variable and becomes non-singleton in case of multiple treatment variables.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="68f25492-2677-438b-b1d6-99aac503ebf3" name="6f43f9c8-72d2-46fe-a40d-061df072bf9d" type="radio">
</input><label class="tabbed-label" for="68f25492-2677-438b-b1d6-99aac503ebf3">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [21]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">();</span>

<span class="gp">In [22]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">psi_a</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">])</span>
<span class="go">[[-2.98432359 -3.06480151 -3.85921198 -2.96874769 -3.05657146 -3.2140234</span>
<span class="go">  -3.93301812 -2.72412326 -3.92721123 -4.88704139]</span>
<span class="go"> [-2.83359228 -2.53108066 -2.03009132 -2.07915489 -3.3994495  -2.36751096</span>
<span class="go">  -2.49584278 -2.14283539 -1.98361135 -2.07559537]</span>
<span class="go"> [-0.23465747 -0.19072988 -0.09287264 -0.18618573 -0.04664579 -0.10008165</span>
<span class="go">  -0.17123038 -0.4765105  -0.29798259 -0.57459766]</span>
<span class="go"> [-0.04854801 -0.12693729 -0.11709589 -0.13362169 -0.34118416 -0.1356885</span>
<span class="go">  -0.21936282 -0.61791403 -0.01701573 -0.00959174]</span>
<span class="go"> [-2.94228402 -4.09970808 -1.74962533 -2.91622689 -1.46372629 -2.85263354</span>
<span class="go">  -4.71027078 -1.79069144 -3.53482783 -2.95084544]]</span>

<span class="gp">In [23]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">psi_b</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">])</span>
<span class="go">[[ 0.05194436  0.36904565  0.7322728   0.18000647 -0.08155766  0.25451579</span>
<span class="go">  -0.15635892 -0.00700313  0.10084129  0.35967313]</span>
<span class="go"> [-0.37844833 -1.3861506  -0.51353049 -0.80280278 -0.35055124 -0.52875372</span>
<span class="go">  -0.72369879 -0.94641422 -0.7244148  -0.87413061]</span>
<span class="go"> [-0.23876905 -0.17447994 -0.11406848 -0.21012099 -0.17211746 -0.14038296</span>
<span class="go">  -0.12573943 -0.31596746 -0.09332741 -0.22672197]</span>
<span class="go"> [ 0.15449116  0.19571928  0.23704881  0.3477631   0.41909963  0.19310959</span>
<span class="go">   0.22392664  0.52443597  0.07921596  0.08061351]</span>
<span class="go"> [ 0.61359257  1.3563012   0.18112505  0.45243241  0.38899264  0.77911744</span>
<span class="go">   1.01224811  0.87656413  0.92262984  0.50719376]]</span>
</pre></div>
</div>
</div>
<input id="bc9bc58d-2526-4f09-b245-2512ff70456f" name="6f43f9c8-72d2-46fe-a40d-061df072bf9d" type="radio">
</input><label class="tabbed-label" for="bc9bc58d-2526-4f09-b245-2512ff70456f">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="highlight"><pre><span></span>dml_plr_obj$fit()
print(dml_plr_obj$psi_a[1:5, ,1])
print(dml_plr_obj$psi_b[1:5, ,1])
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>            [,1]       [,2]         [,3]        [,4]       [,5]       [,6]
[1,] -5.14057375 -5.7323437 -9.967099489 -6.40114466 -6.5157388 -6.6994843
[2,] -1.13463121 -1.3296819 -1.699927183 -1.48382752 -0.8042610 -1.1451811
[3,] -3.27503942 -3.4016176 -4.380515575 -3.53657188 -4.6001998 -2.7926985
[4,] -0.05637162 -0.9897354 -0.001659113 -0.02828584 -0.4230385 -0.1248583
[5,] -3.93967728 -3.4275796 -3.885096195 -4.66162487 -4.1873131 -4.4561796
           [,7]       [,8]       [,9]       [,10]
[1,] -6.2387421 -5.0404595 -7.1072031 -7.01402314
[2,] -2.0790534 -1.8125825 -1.4267215 -1.62687497
[3,] -2.6998322 -3.5653061 -3.9843145 -3.16554733
[4,] -0.1959463 -0.1754679 -0.1637765 -0.01090388
[5,] -3.4549881 -4.8644968 -2.9904646 -3.95156166
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>           [,1]      [,2]        [,3]       [,4]      [,5]       [,6]
[1,]  4.0386407  5.106418  6.76236982  5.4951888  5.476137  4.5551003
[2,]  1.0886059  1.006386  1.45221841  1.2521688  1.280144  1.1234440
[3,]  1.7991789  1.249419  4.09910193  1.4873185  1.362751  2.7689416
[4,] -0.4958399 -2.403604 -0.09503799 -0.3582995 -1.681796 -0.6280586
[5,]  1.0549015  1.241128  1.12915347  1.8133643  1.607291  1.3367732
           [,7]       [,8]       [,9]      [,10]
[1,]  5.2651616  4.4671559  5.2117796  5.8161549
[2,]  1.4070503  1.7900291  1.4094570  1.1555700
[3,]  3.0803552  2.3609928  1.7364562  1.8491756
[4,] -0.9688589 -0.9293682 -0.8706996 -0.2011085
[5,]  1.2880614  2.3322998  1.3922114  1.8114160
</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>We estimate the causal parameter <span class="math notranslate nohighlight">\(\tilde{\theta}_{0,m}\)</span> for each of the <span class="math notranslate nohighlight">\(M\)</span> partitions with a DML
algorithm as described in <a class="reference internal" href="algorithms.html#algorithms"><span class="std std-ref">Double machine learning algorithms</span></a>.
Standard errors are obtained as described in <a class="reference internal" href="se_confint.html#se-confint"><span class="std std-ref">Variance estimation, confidence intervals and multiplier bootstrap</span></a>.
The aggregation of the estimates of the causal parameter and its standard errors is done using the median</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\tilde{\theta}_{0} &amp;= \text{Median}\big((\tilde{\theta}_{0,m})_{m \in [M]}\big),\\\hat{\sigma} &amp;= \sqrt{\text{Median}\big(\hat{\sigma}_m^2 + (\tilde{\theta}_{0,m} - \tilde{\theta}_{0})^2\big)}.\end{aligned}\end{align} \]</div>
</div></blockquote>
<p>The estimate of the causal parameter <span class="math notranslate nohighlight">\(\tilde{\theta}_{0}\)</span> is stored in the <code class="docutils literal notranslate"><span class="pre">coef</span></code> attribute
and the asymptotic standard error <span class="math notranslate nohighlight">\(\hat{\sigma}/\sqrt{N}\)</span> in <code class="docutils literal notranslate"><span class="pre">se</span></code>.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="06fe76c8-7675-4d73-abec-30a04c445809" name="3cbd9b5f-2533-4327-b4cb-047a96f5510b" type="radio">
</input><label class="tabbed-label" for="06fe76c8-7675-4d73-abec-30a04c445809">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [24]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">coef</span><span class="p">)</span>
<span class="go">[0.50003654]</span>

<span class="gp">In [25]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">se</span><span class="p">)</span>
<span class="go">[0.0759755]</span>
</pre></div>
</div>
</div>
<input id="0676afba-9218-4a0a-a2b5-3294467d4a2f" name="3cbd9b5f-2533-4327-b4cb-047a96f5510b" type="radio">
</input><label class="tabbed-label" for="0676afba-9218-4a0a-a2b5-3294467d4a2f">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="highlight"><pre><span></span>print(dml_plr_obj$coef)
print(dml_plr_obj$se)
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>        d 
0.3294643 
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>         d 
0.09078717 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>The parameter estimates <span class="math notranslate nohighlight">\((\tilde{\theta}_{0,m})_{m \in [M]}\)</span> and asymptotic standard errors
<span class="math notranslate nohighlight">\((\hat{\sigma}_m)_{m \in [M]}\)</span> for each of the <span class="math notranslate nohighlight">\(M\)</span> partitions are stored in the attributes
<code class="docutils literal notranslate"><span class="pre">_all_coef</span></code> and <code class="docutils literal notranslate"><span class="pre">_all_se</span></code>, respectively.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="225589eb-87c6-49d7-b8d8-27cc20d87636" name="36d23159-dc7e-451d-9e06-51eba5aae3ff" type="radio">
</input><label class="tabbed-label" for="225589eb-87c6-49d7-b8d8-27cc20d87636">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [26]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">_all_coef</span><span class="p">)</span>
<span class="go">[[0.49050748 0.47162414 0.47976884 0.50956561 0.51360033 0.54163618</span>
<span class="go">  0.5278666  0.46204646 0.51533086 0.47119733]]</span>

<span class="gp">In [27]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">_all_se</span><span class="p">)</span>
<span class="go">[[0.075171   0.07658685 0.07032188 0.08584866 0.07904228 0.07626231</span>
<span class="go">  0.07552195 0.07687109 0.07377529 0.07145054]]</span>
</pre></div>
</div>
</div>
<input id="7e8aa3c2-bd07-4f82-aa59-a077a15043cf" name="36d23159-dc7e-451d-9e06-51eba5aae3ff" type="radio">
</input><label class="tabbed-label" for="7e8aa3c2-bd07-4f82-aa59-a077a15043cf">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="highlight"><pre><span></span>print(dml_plr_obj$all_coef)
print(dml_plr_obj$all_se)
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>          [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
[1,] 0.3493994 0.2610144 0.3597111 0.3266575 0.2124206 0.3267843 0.3321444
          [,8]      [,9]     [,10]
[1,] 0.3366511 0.3149603 0.3930323
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>           [,1]       [,2]       [,3]     [,4]       [,5]       [,6]       [,7]
[1,] 0.08131353 0.08730869 0.08492418 0.087199 0.08144714 0.09138081 0.09203365
           [,8]      [,9]      [,10]
[1,] 0.08347496 0.0856891 0.08220552
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="externally-provide-a-sample-splitting-partition">
<h2><span class="section-number">8.3. </span>Externally provide a sample splitting / partition<a class="headerlink" href="#externally-provide-a-sample-splitting-partition" title="Permalink to this headline">Â¶</a></h2>
<p>All DML models allow a partition to be provided externally via the method <code class="docutils literal notranslate"><span class="pre">set_sample_splitting()</span></code>.
In Python we can for example use the K-Folds cross-validator of sklearn <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> in
order to generate a sample splitting and provide it to the DML model object.
Note that by setting <code class="docutils literal notranslate"><span class="pre">draw_sample_splitting</span> <span class="pre">=</span> <span class="pre">False</span></code> one can prevent that a partition is drawn during initialization
of the DML model object.
The following calls are equivalent.
In the first sample code, we use the standard interface and draw the sample-splitting with <span class="math notranslate nohighlight">\(K=4\)</span> folds during
initialization of the <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code> object.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="fed5289f-04db-4ac4-8434-d80d50f98889" name="72d3da13-f3cb-450e-9ede-2a7542ea965b" type="radio">
</input><label class="tabbed-label" for="fed5289f-04db-4ac4-8434-d80d50f98889">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [28]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">314</span><span class="p">)</span>

<span class="gp">In [29]: </span><span class="n">dml_plr_obj_internal</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span> <span class="n">n_folds</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>

<span class="gp">In [30]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj_internal</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err         t         P&gt;|t|     2.5 %   97.5 %</span>
<span class="go">d  0.502792  0.086164  5.835291  5.369687e-09  0.333913  0.67167</span>
</pre></div>
</div>
</div>
<input id="7e24084c-af52-4782-b2b6-5b2ebf297295" name="72d3da13-f3cb-450e-9ede-2a7542ea965b" type="radio">
</input><label class="tabbed-label" for="7e24084c-af52-4782-b2b6-5b2ebf297295">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="highlight"><pre><span></span>set.seed(314)
dml_plr_obj_internal = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m, n_folds = 4)
dml_plr_obj_internal$fit()
dml_plr_obj_internal$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.29909    0.09014   3.318 0.000906 ***
---
Signif. codes:  0 â***â 0.001 â**â 0.01 â*â 0.05 â.â 0.1 â â 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>In the second sample code, we use the K-Folds cross-validator of sklearn <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a>
and set the partition via the <code class="docutils literal notranslate"><span class="pre">set_sample_splitting()</span></code> method.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="f989e18c-180d-4bf0-9ae5-46cc0a4943dd" name="3008c8a5-7b9e-4ba8-8f95-66c7937e949f" type="radio">
</input><label class="tabbed-label" for="f989e18c-180d-4bf0-9ae5-46cc0a4943dd">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [31]: </span><span class="n">dml_plr_obj_external</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span> <span class="n">draw_sample_splitting</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>

<span class="gp">In [32]: </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>

<span class="gp">In [33]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">314</span><span class="p">)</span>

<span class="gp">In [34]: </span><span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">In [35]: </span><span class="n">smpls</span> <span class="o">=</span> <span class="p">[(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span> <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="o">.</span><span class="n">x</span><span class="p">)]</span>

<span class="gp">In [36]: </span><span class="n">dml_plr_obj_external</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">(</span><span class="n">smpls</span><span class="p">);</span>

<span class="gp">In [37]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj_external</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err         t         P&gt;|t|     2.5 %   97.5 %</span>
<span class="go">d  0.502792  0.086164  5.835291  5.369687e-09  0.333913  0.67167</span>
</pre></div>
</div>
</div>
<input id="ab8c3306-17aa-4432-ade7-9ca3d87740c3" name="3008c8a5-7b9e-4ba8-8f95-66c7937e949f" type="radio">
</input><label class="tabbed-label" for="ab8c3306-17aa-4432-ade7-9ca3d87740c3">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14</pre></div></td><td class="code"><div class="highlight"><pre><span></span>dml_plr_obj_external = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m, draw_sample_splitting = FALSE)

set.seed(314)
# set up a task and cross-validation resampling scheme in mlr3
my_task = Task$new(&quot;help task&quot;, &quot;regr&quot;, data)
my_sampling = rsmp(&quot;cv&quot;, folds = 4)$instantiate(my_task)

train_ids = lapply(1:4, function(x) my_sampling$train_set(x))
test_ids = lapply(1:4, function(x) my_sampling$test_set(x))
smpls = list(list(train_ids = train_ids, test_ids = test_ids))

dml_plr_obj_external$set_sample_splitting(smpls)
dml_plr_obj_external$fit()
dml_plr_obj_external$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.29909    0.09014   3.318 0.000906 ***
---
Signif. codes:  0 â***â 0.001 â**â 0.01 â*â 0.05 â.â 0.1 â â 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="sample-splitting-without-cross-fitting">
<h2><span class="section-number">8.4. </span>Sample-splitting without cross-fitting<a class="headerlink" href="#sample-splitting-without-cross-fitting" title="Permalink to this headline">Â¶</a></h2>
<p>The boolean flag <code class="docutils literal notranslate"><span class="pre">apply_cross_fitting</span></code> allows to estimate DML models without applying cross-fitting.
It results in randomly splitting the sample into two parts.
The first half of the data is used for the estimation of the nuisance ML models and the second half for estimating the
causal parameter.
Note that cross-fitting performs well empirically and is recommended to remove bias induced by overfitting, see also
<a class="reference internal" href="basics.html#bias-overfitting"><span class="std std-ref">Sample splitting to remove bias induced by overfitting</span></a>.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="7ef2595f-9c5c-4ade-8de2-684e6e101948" name="8950a410-1a82-452f-849b-a7b31cab4ca8" type="radio">
</input><label class="tabbed-label" for="7ef2595f-9c5c-4ade-8de2-684e6e101948">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [38]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">314</span><span class="p">)</span>

<span class="gp">In [39]: </span><span class="n">dml_plr_obj_external</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span>
<span class="gp">   ....: </span>                                       <span class="n">n_folds</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">apply_cross_fitting</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="gp">   ....: </span>

<span class="gp">In [40]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj_external</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err         t     P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.553448  0.121353  4.560651  0.000005  0.315601  0.791296</span>
</pre></div>
</div>
</div>
<input id="9ddeb702-6fc3-4c79-84d2-2be3d4343e04" name="8950a410-1a82-452f-849b-a7b31cab4ca8" type="radio">
</input><label class="tabbed-label" for="9ddeb702-6fc3-4c79-84d2-2be3d4343e04">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="highlight"><pre><span></span>dml_plr_obj_external = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m,
                                       n_folds = 2, apply_cross_fitting = FALSE)
dml_plr_obj_external$fit()
dml_plr_obj_external$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)   
d    0.3640     0.1229   2.961  0.00306 **
---
Signif. codes:  0 â***â 0.001 â**â 0.01 â*â 0.05 â.â 0.1 â â 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>Note, that in order to split data unevenly into train and test sets the interface to externally set the sample splitting
via <code class="docutils literal notranslate"><span class="pre">set_sample_splitting()</span></code> needs to be applied, like for example:</p>
<div class="tabbed-set docutils">
<input checked="checked" id="e1699e06-ac70-4fe0-8ca5-082bfc0e24e7" name="9378a3a7-2d56-4d6d-9ab7-312ee9049a1f" type="radio">
</input><label class="tabbed-label" for="e1699e06-ac70-4fe0-8ca5-082bfc0e24e7">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [41]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">314</span><span class="p">)</span>

<span class="gp">In [42]: </span><span class="n">dml_plr_obj_external</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span>
<span class="gp">   ....: </span>                                       <span class="n">n_folds</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">apply_cross_fitting</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">draw_sample_splitting</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="gp">   ....: </span>

<span class="gp">In [43]: </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="gp">In [44]: </span><span class="n">smpls</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="o">.</span><span class="n">n_obs</span><span class="p">),</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>

<span class="gp">In [45]: </span><span class="n">dml_plr_obj_external</span><span class="o">.</span><span class="n">set_sample_splitting</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">smpls</span><span class="p">));</span>

<span class="gp">In [46]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj_external</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err         t     P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.473033  0.134977  3.504531  0.000457  0.208482  0.737584</span>
</pre></div>
</div>
</div>
<input id="7da9fcd1-5179-4e8b-8979-b2806925003f" name="9378a3a7-2d56-4d6d-9ab7-312ee9049a1f" type="radio">
</input><label class="tabbed-label" for="7da9fcd1-5179-4e8b-8979-b2806925003f">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16</pre></div></td><td class="code"><div class="highlight"><pre><span></span>dml_plr_obj_external = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m,
                                        n_folds = 2, apply_cross_fitting = FALSE,
                                        draw_sample_splitting = FALSE)

set.seed(314)
# set up a task and cross-validation resampling scheme in mlr3
my_task = Task$new(&quot;help task&quot;, &quot;regr&quot;, data)
my_sampling = rsmp(&quot;holdout&quot;, ratio = 0.8)$instantiate(my_task)

train_ids = list(my_sampling$train_set(1))
test_ids = list(my_sampling$test_set(1))
smpls = list(list(train_ids = train_ids, test_ids = test_ids))

dml_plr_obj_external$set_sample_splitting(smpls)
dml_plr_obj_external$fit()
dml_plr_obj_external$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)
d   0.07056    0.31954   0.221    0.825


</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="estimate-dml-models-without-sample-splitting">
<h2><span class="section-number">8.5. </span>Estimate DML models without sample-splitting<a class="headerlink" href="#estimate-dml-models-without-sample-splitting" title="Permalink to this headline">Â¶</a></h2>
<p>The implementation of the DML models allows the estimation without sample splitting, i.e., all observations are used
for learning the nuisance models as well as for the estimation of the causal parameter.
Note that this approach usually results in a bias and is therefore not recommended without appropriate theoretical
justification, see also <a class="reference internal" href="basics.html#bias-overfitting"><span class="std std-ref">Sample splitting to remove bias induced by overfitting</span></a>.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="442430fb-7bbe-4464-bdc8-cf32d8660eb7" name="e98f7165-40f9-45f4-bd36-583d3d63d824" type="radio">
</input><label class="tabbed-label" for="442430fb-7bbe-4464-bdc8-cf32d8660eb7">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [47]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">314</span><span class="p">)</span>

<span class="gp">In [48]: </span><span class="n">dml_plr_no_split</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span>
<span class="gp">   ....: </span>                                   <span class="n">n_folds</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">apply_cross_fitting</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="gp">   ....: </span>

<span class="gp">In [49]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj_external</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err         t     P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.514558  0.123173  4.177519  0.000029  0.273143  0.755973</span>
</pre></div>
</div>
</div>
<input id="67d56e65-f8b4-4db4-a73d-d3bd2b1c2ead" name="e98f7165-40f9-45f4-bd36-583d3d63d824" type="radio">
</input><label class="tabbed-label" for="67d56e65-f8b4-4db4-a73d-d3bd2b1c2ead">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="highlight"><pre><span></span>dml_plr_no_split = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m,
                                   n_folds = 1, apply_cross_fitting = FALSE)

set.seed(314)
dml_plr_no_split$fit()
dml_plr_no_split$summary()
</pre></div>
</td></tr></table></div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[1] &quot;Estimates and significance testing of the effect of target variables&quot;
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.31817    0.07899   4.028 5.63e-05 ***
---
Signif. codes:  0 â***â 0.001 â**â 0.01 â*â 0.05 â.â 0.1 â â 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="se_confint.html" title="previous page"><span class="section-number">7. </span>Variance estimation, confidence intervals and multiplier bootstrap</a>
    <a class='right-next' id="next-link" href="../auto_examples/index.html" title="next page">Examples</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, Bach, P., Chernozhukov, V., Kurz, M. S., and Spindler, M..<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.4.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>