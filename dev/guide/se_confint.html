
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>8. Variance estimation and confidence intervals &#8212; DoubleML  documentation</title>
<script>
  document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
  document.documentElement.dataset.theme = localStorage.getItem("theme") || "light"
</script>

  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=92025949c220c2e29695" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=92025949c220c2e29695" rel="stylesheet">


  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />

  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="9. Sample-splitting, cross-fitting and repeated cross-fitting" href="resampling.html" />
    <link rel="prev" title="7. Learners, hyperparameters and hyperparameter tuning" href="learners.html" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="docsearch:language" content="None">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">
    <div class="bd-header-announcement container-fluid" id="banner">
      

    </div>

    
    <nav class="bd-header navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="bd-header__inner container-xl">

  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    <p class="title logo__title">DoubleML  documentation</p>
  
</a>
    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="fas fa-bars"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  DoubleML
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/install.html">
  Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro/intro.html">
  Getting started
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="guide.html">
  User guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../workflow/workflow.html">
  Workflow
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api.html">
  Python API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference external nav-link" href="https://docs.doubleml.org/r/stable/">
  R API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../examples/index.html">
  Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../literature/literature.html">
  Literature
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../release/release.html">
  Release notes
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <span id="theme-switch" class="btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/DoubleML/doubleml-for-py" rel="noopener" target="_blank" title="GitHub"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="bd-container container-xl">
      <div class="bd-container__inner row">
          

<!-- Only show if we have sidebars configured, else just a small margin  -->
<div class="bd-sidebar-primary col-12 col-md-3 bd-sidebar">
  <div class="sidebar-start-items"><p class="logo" style="text-align:center;"><a href="../index.html">
    <img class="logo" src="../logo.png" alt="Logo" width="65%" height="65%">
</a></p><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="basics.html">
   1.  The basics of double/debiased machine learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="data_backend.html">
   2.  The data-backend DoubleMLData
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="models.html">
   3.  Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="heterogeneity.html">
   4.  Heterogeneous Treatment Effects
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="scores.html">
   5.  Score functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="algorithms.html">
   6.  Double machine learning algorithms
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="learners.html">
   7.  Learners, hyperparameters and hyperparameter tuning
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   8.  Variance estimation and confidence intervals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="resampling.html">
   9.  Sample-splitting, cross-fitting and repeated cross-fitting
  </a>
 </li>
</ul>

  </div>
</nav>
  </div>
  <div class="sidebar-end-items">
  </div>
</div>


          


<div class="bd-sidebar-secondary d-none d-xl-block col-xl-2 bd-toc">
  
    
    <div class="toc-item">
      
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#variance-estimation">
   8.1. Variance estimation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference">
   8.2. Confidence bands and multiplier bootstrap for valid simultaneous inference
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   8.3. References
  </a>
 </li>
</ul>

</nav>
    </div>
    
    <div class="toc-item">
      
    </div>
    
  
</div>


          
          
          <div class="bd-content col-12 col-md-9 col-xl-7">
              
              <article class="bd-article" role="main">
                
  <section id="variance-estimation-and-confidence-intervals">
<span id="se-confint"></span><h1><span class="section-number">8. </span>Variance estimation and confidence intervals<a class="headerlink" href="#variance-estimation-and-confidence-intervals" title="Permalink to this headline">#</a></h1>
<section id="variance-estimation">
<h2><span class="section-number">8.1. </span>Variance estimation<a class="headerlink" href="#variance-estimation" title="Permalink to this headline">#</a></h2>
<p>Under regularity conditions the estimator <span class="math notranslate nohighlight">\(\tilde{\theta}_0\)</span> concentrates in a <span class="math notranslate nohighlight">\(1/\sqrt{N}\)</span>-neighborhood
of <span class="math notranslate nohighlight">\(\theta_0\)</span> and the sampling error <span class="math notranslate nohighlight">\(\sqrt{N}(\tilde{\theta}_0 - \theta_0)\)</span> is approximately normal</p>
<div class="math notranslate nohighlight">
\[\sqrt{N}(\tilde{\theta}_0 - \theta_0) \leadsto N(o, \sigma^2),\]</div>
<p>with mean zero and variance given by</p>
<div class="math notranslate nohighlight">
\[\sigma^2 := J_0^{-2} \mathbb{E}(\psi^2(W; \theta_0, \eta_0)),\]</div>
<p>where <span class="math notranslate nohighlight">\(J_0 = \mathbb{E}(\psi_a(W; \eta_0))\)</span>, if the score function is linear in the parameter <span class="math notranslate nohighlight">\(\theta\)</span>.
If the score is not linear in the parameter <span class="math notranslate nohighlight">\(\theta\)</span>, then
<span class="math notranslate nohighlight">\(J_0 = \partial_\theta\mathbb{E}(\psi(W; \theta, \eta_0)) \big|_{\theta=\theta_0}\)</span>.</p>
<p>Estimates of the variance are obtained by</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\hat{\sigma}^2 &amp;= \hat{J}_0^{-2} \frac{1}{N} \sum_{k=1}^{K} \sum_{i \in I_k} \big[\psi(W_i; \tilde{\theta}_0, \hat{\eta}_{0,k})\big]^2,\\\hat{J}_0 &amp;= \frac{1}{N} \sum_{k=1}^{K} \sum_{i \in I_k} \psi_a(W_i; \hat{\eta}_{0,k}),\end{aligned}\end{align} \]</div>
<p>for score functions being linear in the parameter <span class="math notranslate nohighlight">\(\theta\)</span>.
For non-linear score functions, the implementation assumes that derivatives and expectations are interchangeable, so
that</p>
<div class="math notranslate nohighlight">
\[\hat{J}_0 = \frac{1}{N} \sum_{k=1}^{K} \sum_{i \in I_k} \partial_\theta \psi(W_i; \tilde{\theta}_0, \hat{\eta}_{0,k}).\]</div>
<p>An approximate confidence interval is given by</p>
<div class="math notranslate nohighlight">
\[\big[\tilde{\theta}_0 \pm \Phi^{-1}(1 - \alpha/2) \hat{\sigma} / \sqrt{N}].\]</div>
<p>As an example we consider a partially linear regression model (PLR)
implemented in <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code>.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="abe5655b-633d-44da-af2f-c269c384d854" name="23202e31-4ebb-479e-b97c-33cf2b6f9ef5" type="radio">
</input><label class="tabbed-label" for="abe5655b-633d-44da-af2f-c269c384d854">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [2]: </span><span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_plr_CCDDHNR2018</span>

<span class="gp">In [3]: </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="gp">In [4]: </span><span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">clone</span>

<span class="gp">In [5]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3141</span><span class="p">)</span>

<span class="gp">In [6]: </span><span class="n">learner</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">In [7]: </span><span class="n">ml_l</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">learner</span><span class="p">)</span>

<span class="gp">In [8]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">learner</span><span class="p">)</span>

<span class="gp">In [9]: </span><span class="n">data</span> <span class="o">=</span> <span class="n">make_plr_CCDDHNR2018</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;DataFrame&#39;</span><span class="p">)</span>

<span class="gp">In [10]: </span><span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">)</span>

<span class="gp">In [11]: </span><span class="n">dml_plr_obj</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span> <span class="n">ml_l</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">)</span>

<span class="gp">In [12]: </span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">();</span>
</pre></div>
</div>
</div>
<input id="fde432f0-82a4-4277-bc66-7a0762046819" name="23202e31-4ebb-479e-b97c-33cf2b6f9ef5" type="radio">
</input><label class="tabbed-label" for="fde432f0-82a4-4277-bc66-7a0762046819">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">DoubleML</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">mlr3</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">mlr3learners</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">data.table</span><span class="p">)</span>
<span class="n">lgr</span><span class="o">::</span><span class="nf">get_logger</span><span class="p">(</span><span class="s">&quot;mlr3&quot;</span><span class="p">)</span><span class="o">$</span><span class="nf">set_threshold</span><span class="p">(</span><span class="s">&quot;warn&quot;</span><span class="p">)</span>

<span class="n">learner</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">lrn</span><span class="p">(</span><span class="s">&quot;regr.ranger&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">num.trees</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">mtry</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">min.node.size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">max.depth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">)</span>
<span class="n">ml_l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">learner</span><span class="o">$</span><span class="nf">clone</span><span class="p">()</span>
<span class="n">ml_m</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">learner</span><span class="o">$</span><span class="nf">clone</span><span class="p">()</span>

<span class="nf">set.seed</span><span class="p">(</span><span class="m">3141</span><span class="p">)</span>
<span class="n">obj_dml_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">make_plr_CCDDHNR2018</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="m">0.5</span><span class="p">)</span>
<span class="n">dml_plr_obj</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">DoubleMLPLR</span><span class="o">$</span><span class="nf">new</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span><span class="w"> </span><span class="n">ml_l</span><span class="p">,</span><span class="w"> </span><span class="n">ml_m</span><span class="p">)</span>
<span class="n">dml_plr_obj</span><span class="o">$</span><span class="nf">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">fit()</span></code> method of <code class="docutils literal notranslate"><span class="pre">DoubleMLPLR</span></code>
stores the estimate <span class="math notranslate nohighlight">\(\tilde{\theta}_0\)</span> in its <code class="docutils literal notranslate"><span class="pre">coef</span></code> attribute.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="6f0fda1c-ae56-4a0f-865c-b534ea184ec4" name="b7530562-daff-4069-8238-53f68b566a9b" type="radio">
</input><label class="tabbed-label" for="6f0fda1c-ae56-4a0f-865c-b534ea184ec4">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [13]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">coef</span><span class="p">)</span>
<span class="go">[0.48011605]</span>
</pre></div>
</div>
</div>
<input id="7f6a21e3-6b79-4ed6-ba9e-4e9d1ef024e6" name="b7530562-daff-4069-8238-53f68b566a9b" type="radio">
</input><label class="tabbed-label" for="7f6a21e3-6b79-4ed6-ba9e-4e9d1ef024e6">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">$</span><span class="n">coef</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>        d 
0.5443965 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>The asymptotic standard error <span class="math notranslate nohighlight">\(\hat{\sigma}/\sqrt{N}\)</span> is stored in its <code class="docutils literal notranslate"><span class="pre">se</span></code> attribute.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="df135bdd-6690-4cb2-88f5-f744d5b6106c" name="3da49d6f-3419-45eb-82d8-a7c5b96df82c" type="radio">
</input><label class="tabbed-label" for="df135bdd-6690-4cb2-88f5-f744d5b6106c">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [14]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">se</span><span class="p">)</span>
<span class="go">[0.04051489]</span>
</pre></div>
</div>
</div>
<input id="2b436d0a-b5f2-480b-9ceb-e88940909f6f" name="3da49d6f-3419-45eb-82d8-a7c5b96df82c" type="radio">
</input><label class="tabbed-label" for="2b436d0a-b5f2-480b-9ceb-e88940909f6f">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">$</span><span class="n">se</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>         d 
0.04512331 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<p>Additionally, the value of the <span class="math notranslate nohighlight">\(t\)</span>-statistic and the corresponding p-value are provided in the attributes
<code class="docutils literal notranslate"><span class="pre">t_stat</span></code> and <code class="docutils literal notranslate"><span class="pre">pval</span></code>.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="7bfa09de-3f98-4a46-b455-b8f24fddb673" name="8099b873-86f7-464d-88ce-2e51f4b1b60e" type="radio">
</input><label class="tabbed-label" for="7bfa09de-3f98-4a46-b455-b8f24fddb673">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [15]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">t_stat</span><span class="p">)</span>
<span class="go">[11.85036084]</span>

<span class="gp">In [16]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">pval</span><span class="p">)</span>
<span class="go">[2.14266176e-32]</span>
</pre></div>
</div>
</div>
<input id="5cf31863-0f69-40e7-ba1e-7db7aca555f9" name="8099b873-86f7-464d-88ce-2e51f4b1b60e" type="radio">
</input><label class="tabbed-label" for="5cf31863-0f69-40e7-ba1e-7db7aca555f9">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">$</span><span class="n">t_stat</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">$</span><span class="n">pval</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>       d 
12.06464 
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>           d 
1.623681e-33 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>In Python, an overview of all these estimates, together with a 95 % confidence interval is stored in the
attribute <code class="docutils literal notranslate"><span class="pre">summary</span></code>.</p></li>
<li><p>In R, a summary can be obtained by using the method <code class="docutils literal notranslate"><span class="pre">summary()</span></code>. The <code class="docutils literal notranslate"><span class="pre">confint()</span></code> method performs estimation of
confidence intervals.</p></li>
</ul>
</div>
<div class="tabbed-set docutils">
<input checked="checked" id="7891722e-1efe-4db4-9c7f-dbd8450588a1" name="fa28a923-fa61-40f6-8046-de7b9bc07921" type="radio">
</input><label class="tabbed-label" for="7891722e-1efe-4db4-9c7f-dbd8450588a1">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [17]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="o">.</span><span class="n">summary</span><span class="p">)</span>
<span class="go">       coef   std err          t         P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.480116  0.040515  11.850361  2.142662e-32  0.400708  0.559524</span>
</pre></div>
</div>
</div>
<input id="9e246dd4-c662-413f-88e9-d0a13bb9b04b" name="fa28a923-fa61-40f6-8046-de7b9bc07921" type="radio">
</input><label class="tabbed-label" for="9e246dd4-c662-413f-88e9-d0a13bb9b04b">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">dml_plr_obj</span><span class="o">$</span><span class="nf">summary</span><span class="p">()</span>
<span class="n">dml_plr_obj</span><span class="o">$</span><span class="nf">confint</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Estimates and significance testing of the effect of target variables
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.54440    0.04512   12.06   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
<div class="output text_html"><table class="dataframe">
<caption>A matrix: 1 × 2 of type dbl</caption>
<thead>
	<tr><th></th><th scope=col>2.5 %</th><th scope=col>97.5 %</th></tr>
</thead>
<tbody>
	<tr><th scope=row>d</th><td>0.4559565</td><td>0.6328366</td></tr>
</tbody>
</table>
</div></div>
</div>
</div>
</div>
<p>A more detailed overview of the fitted model, its specifications and the summary can be obtained via the
string-representation of the object.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="275c20be-f785-4cbe-99f9-268afe5e0367" name="37a6f6fa-3ea4-4987-838f-3b693200f99f" type="radio">
</input><label class="tabbed-label" for="275c20be-f785-4cbe-99f9-268afe5e0367">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [18]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="p">)</span>
<span class="go">================== DoubleMLPLR Object ==================</span>

<span class="go">------------------ Data summary      ------------------</span>
<span class="go">Outcome variable: y</span>
<span class="go">Treatment variable(s): [&#39;d&#39;]</span>
<span class="go">Covariates: [&#39;X1&#39;, &#39;X2&#39;, &#39;X3&#39;, &#39;X4&#39;, &#39;X5&#39;, &#39;X6&#39;, &#39;X7&#39;, &#39;X8&#39;, &#39;X9&#39;, &#39;X10&#39;, &#39;X11&#39;, &#39;X12&#39;, &#39;X13&#39;, &#39;X14&#39;, &#39;X15&#39;, &#39;X16&#39;, &#39;X17&#39;, &#39;X18&#39;, &#39;X19&#39;, &#39;X20&#39;]</span>
<span class="go">Instrument variable(s): None</span>
<span class="go">No. Observations: 500</span>

<span class="go">------------------ Score &amp; algorithm ------------------</span>
<span class="go">Score function: partialling out</span>
<span class="go">DML algorithm: dml2</span>

<span class="go">------------------ Machine learner   ------------------</span>
<span class="go">Learner ml_l: RandomForestRegressor(max_depth=5, max_features=20, min_samples_leaf=2)</span>
<span class="go">Learner ml_m: RandomForestRegressor(max_depth=5, max_features=20, min_samples_leaf=2)</span>
<span class="go">Out-of-sample Performance:</span>
<span class="go">Learner ml_l RMSE: [[1.12659372]]</span>
<span class="go">Learner ml_m RMSE: [[1.04007791]]</span>

<span class="go">------------------ Resampling        ------------------</span>
<span class="go">No. folds: 5</span>
<span class="go">No. repeated sample splits: 1</span>
<span class="go">Apply cross-fitting: True</span>

<span class="go">------------------ Fit summary       ------------------</span>
<span class="go">       coef   std err          t         P&gt;|t|     2.5 %    97.5 %</span>
<span class="go">d  0.480116  0.040515  11.850361  2.142662e-32  0.400708  0.559524</span>
</pre></div>
</div>
</div>
<input id="3edc69bd-007e-484b-bc08-2f20a79cb0f2" name="37a6f6fa-3ea4-4987-838f-3b693200f99f" type="radio">
</input><label class="tabbed-label" for="3edc69bd-007e-484b-bc08-2f20a79cb0f2">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="n">dml_plr_obj</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>================= DoubleMLPLR Object ==================


------------------ Data summary      ------------------
Outcome variable: y
Treatment variable(s): d
Covariates: X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15, X16, X17, X18, X19, X20
Instrument(s): 
No. Observations: 500

------------------ Score &amp; algorithm ------------------
Score function: partialling out
DML algorithm: dml2

------------------ Machine learner   ------------------
ml_l: regr.ranger
ml_m: regr.ranger

------------------ Resampling        ------------------
No. folds: 5
No. repeated sample splits: 1
Apply cross-fitting: TRUE

------------------ Fit summary       ------------------
 Estimates and significance testing of the effect of target variables
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.54440    0.04512   12.06   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


</pre></div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference">
<span id="sim-inf"></span><h2><span class="section-number">8.2. </span>Confidence bands and multiplier bootstrap for valid simultaneous inference<a class="headerlink" href="#confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference" title="Permalink to this headline">#</a></h2>
<p><a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a> provides methods to perform valid simultaneous inference for multiple treatment variables.
As an example, consider a PLR with <span class="math notranslate nohighlight">\(p_1\)</span> causal parameters of interest <span class="math notranslate nohighlight">\(\theta_{0,1}, \ldots, \theta_{0,p_1}\)</span> associated with
treatment variables <span class="math notranslate nohighlight">\(D_1, \ldots, D_{p_1}\)</span>. Inference on multiple target coefficients can be performed by iteratively applying the DML inference procedure over the target variables of
interests: Each of the coefficients of interest, <span class="math notranslate nohighlight">\(\theta_{0,j}\)</span>, with <span class="math notranslate nohighlight">\(j \in \lbrace 1, \ldots, p_1 \rbrace\)</span>, solves a corresponding moment condition</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}[ \psi_j(W; \theta_{0,j}, \eta_{0,j})] = 0.\]</div>
<p>Analogously to the case with a single parameter of interest, the PLR model with multiple treatment variables includes two regression steps to achieve orthogonality.
First, the main regression is given by</p>
<div class="math notranslate nohighlight">
\[Y = D_j \theta_{0,j} + g_{0,j}([D_k, X]) + \zeta_j, \quad \mathbb{E}(\zeta_j | D, X) = 0,\]</div>
<p>with <span class="math notranslate nohighlight">\([D_k, X]\)</span> being a matrix comprising the confounders, <span class="math notranslate nohighlight">\(X\)</span>, and all remaining treatment variables
<span class="math notranslate nohighlight">\(D_k\)</span> with  <span class="math notranslate nohighlight">\(k \in \lbrace 1, \ldots, p_1\rbrace \setminus j\)</span>, by default.
Second, the relationship between the treatment variable <span class="math notranslate nohighlight">\(D_j\)</span> and the remaining explanatory variables is determined by the equation</p>
<div class="math notranslate nohighlight">
\[D_j = m_{0,j}([D_k, X]) + V_j, \quad \mathbb{E}(V_j | D_k, X) = 0,\]</div>
<p>For further details, we refer to Belloni et al. (2018). Simultaneous inference can be based on a multiplier bootstrap procedure introduced in Chernozhukov et al. (2013, 2014).
Alternatively, traditional correction approaches, for example the Bonferroni correction, can be used to adjust p-values.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">bootstrap()</span></code> method provides an implementation of a multiplier bootstrap for double machine learning models.
For <span class="math notranslate nohighlight">\(b=1, \ldots, B\)</span> weights <span class="math notranslate nohighlight">\(\xi_{i, b}\)</span> are generated according to a normal (Gaussian) bootstrap, wild
bootstrap or exponential bootstrap.
The number of bootstrap samples is provided as input <code class="docutils literal notranslate"><span class="pre">n_rep_boot</span></code> and for <code class="docutils literal notranslate"><span class="pre">method</span></code> one can choose <code class="docutils literal notranslate"><span class="pre">'Bayes'</span></code>,
<code class="docutils literal notranslate"><span class="pre">'normal'</span></code> or <code class="docutils literal notranslate"><span class="pre">'wild'</span></code>.
Based on the estimates of the standard errors <span class="math notranslate nohighlight">\(\hat{\sigma}_j\)</span>
and <span class="math notranslate nohighlight">\(\hat{J}_{0,j} = \mathbb{E}_N(\psi_{a,j}(W; \eta_{0,j}))\)</span>
that are obtained from DML, we construct bootstrap coefficients
<span class="math notranslate nohighlight">\(\theta^{*,b}_j\)</span> and bootstrap t-statistics <span class="math notranslate nohighlight">\(t^{*,b}_j\)</span>
for <span class="math notranslate nohighlight">\(j=1, \ldots, p_1\)</span></p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\theta^{*,b}_{j} &amp;= \frac{1}{\sqrt{N} \hat{J}_{0,j}}\sum_{k=1}^{K} \sum_{i \in I_k} \xi_{i}^b \cdot \psi_j(W_i; \tilde{\theta}_{0,j}, \hat{\eta}_{0,j;k}),\\t^{*,b}_{j} &amp;= \frac{1}{\sqrt{N} \hat{J}_{0,j} \hat{\sigma}_{j}} \sum_{k=1}^{K} \sum_{i \in I_k} \xi_{i}^b  \cdot \psi_j(W_i; \tilde{\theta}_{0,j}, \hat{\eta}_{0,j;k}).\end{aligned}\end{align} \]</div>
<p>The output of the multiplier bootstrap can be used to determine the constant, <span class="math notranslate nohighlight">\(c_{1-\alpha}\)</span> that is required for the construction of a
simultaneous <span class="math notranslate nohighlight">\((1-\alpha)\)</span> confidence band</p>
<div class="math notranslate nohighlight">
\[\left[\tilde\theta_{0,j} \pm c_{1-\alpha} \cdot \hat\sigma_j/\sqrt{N} \right].\]</div>
<p>To demonstrate the bootstrap, we simulate data from a sparse partially linear regression model.
Then we estimate the PLR model and perform the multiplier bootstrap.
Joint confidence intervals based on the multiplier bootstrap are then obtained by setting the option <code class="docutils literal notranslate"><span class="pre">joint</span></code>
when calling the method <code class="docutils literal notranslate"><span class="pre">confint</span></code>.</p>
<p>Moreover, a multiple hypotheses testing adjustment of p-values from a high-dimensional model can be obtained with
the method <code class="docutils literal notranslate"><span class="pre">p_adjust</span></code>. <a class="reference internal" href="../index.html#doubleml-package"><span class="std std-ref">DoubleML</span></a>  performs a version of the Romano-Wolf stepdown adjustment,
which is based on the multiplier bootstrap, by default. Alternatively, <code class="docutils literal notranslate"><span class="pre">p_adjust</span></code> allows users to apply traditional corrections
via the option <code class="docutils literal notranslate"><span class="pre">method</span></code>.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="eb5167d1-0378-4413-9d01-2f203c6451a9" name="556de1d9-c4c7-4584-baaf-c194f76c932b" type="radio">
</input><label class="tabbed-label" for="eb5167d1-0378-4413-9d01-2f203c6451a9">
Python</label><div class="tabbed-content docutils">
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="gp">In [19]: </span><span class="kn">import</span> <span class="nn">doubleml</span> <span class="k">as</span> <span class="nn">dml</span>

<span class="gp">In [20]: </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="gp">In [21]: </span><span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">clone</span>

<span class="gp">In [22]: </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LassoCV</span>

<span class="go"># Simulate data</span>
<span class="gp">In [23]: </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="gp">In [24]: </span><span class="n">n_obs</span> <span class="o">=</span> <span class="mi">500</span>

<span class="gp">In [25]: </span><span class="n">n_vars</span> <span class="o">=</span> <span class="mi">100</span>

<span class="gp">In [26]: </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_obs</span><span class="p">,</span> <span class="n">n_vars</span><span class="p">))</span>

<span class="gp">In [27]: </span><span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>

<span class="gp">In [28]: </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="n">theta</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_obs</span><span class="p">,))</span>

<span class="gp">In [29]: </span><span class="n">dml_data</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLData</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">10</span><span class="p">:],</span> <span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">10</span><span class="p">])</span>

<span class="gp">In [30]: </span><span class="n">learner</span> <span class="o">=</span> <span class="n">LassoCV</span><span class="p">()</span>

<span class="gp">In [31]: </span><span class="n">ml_l</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">learner</span><span class="p">)</span>

<span class="gp">In [32]: </span><span class="n">ml_m</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">learner</span><span class="p">)</span>

<span class="gp">In [33]: </span><span class="n">dml_plr</span> <span class="o">=</span> <span class="n">dml</span><span class="o">.</span><span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">dml_data</span><span class="p">,</span> <span class="n">ml_l</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">)</span>

<span class="gp">In [34]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">bootstrap</span><span class="p">()</span><span class="o">.</span><span class="n">confint</span><span class="p">(</span><span class="n">joint</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="go">        2.5 %    97.5 %</span>
<span class="go">d1   2.813342  3.055680</span>
<span class="go">d2   2.815224  3.083258</span>
<span class="go">d3   2.860663  3.109069</span>
<span class="go">d4  -0.141546  0.091391</span>
<span class="go">d5  -0.060845  0.176929</span>
<span class="go">d6  -0.158697  0.078474</span>
<span class="go">d7  -0.172022  0.062964</span>
<span class="go">d8  -0.067721  0.174499</span>
<span class="go">d9  -0.092365  0.139491</span>
<span class="go">d10 -0.110717  0.138698</span>

<span class="gp">In [35]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr</span><span class="o">.</span><span class="n">p_adjust</span><span class="p">())</span>
<span class="go">         coef   pval</span>
<span class="go">d1   2.934511  0.000</span>
<span class="go">d2   2.949241  0.000</span>
<span class="go">d3   2.984866  0.000</span>
<span class="go">d4  -0.025077  0.850</span>
<span class="go">d5   0.058042  0.492</span>
<span class="go">d6  -0.040112  0.850</span>
<span class="go">d7  -0.054529  0.850</span>
<span class="go">d8   0.053389  0.514</span>
<span class="go">d9   0.023563  0.802</span>
<span class="go">d10  0.013990  0.850</span>

<span class="gp">In [36]: </span><span class="nb">print</span><span class="p">(</span><span class="n">dml_plr</span><span class="o">.</span><span class="n">p_adjust</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;bonferroni&#39;</span><span class="p">))</span>
<span class="go">         coef  pval</span>
<span class="go">d1   2.934511   0.0</span>
<span class="go">d2   2.949241   0.0</span>
<span class="go">d3   2.984866   0.0</span>
<span class="go">d4  -0.025077   1.0</span>
<span class="go">d5   0.058042   1.0</span>
<span class="go">d6  -0.040112   1.0</span>
<span class="go">d7  -0.054529   1.0</span>
<span class="go">d8   0.053389   1.0</span>
<span class="go">d9   0.023563   1.0</span>
<span class="go">d10  0.013990   1.0</span>
</pre></div>
</div>
</div>
<input id="161d3027-c6d8-4b0d-a75f-500eb00cac15" name="556de1d9-c4c7-4584-baaf-c194f76c932b" type="radio">
</input><label class="tabbed-label" for="161d3027-c6d8-4b0d-a75f-500eb00cac15">
R</label><div class="tabbed-content docutils">
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">DoubleML</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">mlr3</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">mlr3learners</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">data.table</span><span class="p">)</span>
<span class="n">lgr</span><span class="o">::</span><span class="nf">get_logger</span><span class="p">(</span><span class="s">&quot;mlr3&quot;</span><span class="p">)</span><span class="o">$</span><span class="nf">set_threshold</span><span class="p">(</span><span class="s">&quot;warn&quot;</span><span class="p">)</span>

<span class="nf">set.seed</span><span class="p">(</span><span class="m">3141</span><span class="p">)</span>
<span class="n">n_obs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span>
<span class="n">n_vars</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span>
<span class="n">theta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">)</span>
<span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="n">stats</span><span class="o">::</span><span class="nf">rnorm</span><span class="p">(</span><span class="n">n_obs</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">n_vars</span><span class="p">),</span><span class="w"> </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n_obs</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n_vars</span><span class="p">)</span>
<span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">X</span><span class="p">[,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">drop</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">]</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">theta</span><span class="w">  </span><span class="o">+</span><span class="w"> </span><span class="n">stats</span><span class="o">::</span><span class="nf">rnorm</span><span class="p">(</span><span class="n">n_obs</span><span class="p">)</span>
<span class="n">dml_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">double_ml_data_from_matrix</span><span class="p">(</span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">X</span><span class="p">[,</span><span class="w"> </span><span class="m">11</span><span class="o">:</span><span class="n">n_vars</span><span class="p">],</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">X</span><span class="p">[,</span><span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">])</span>

<span class="n">learner</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">lrn</span><span class="p">(</span><span class="s">&quot;regr.cv_glmnet&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">s</span><span class="o">=</span><span class="s">&quot;lambda.min&quot;</span><span class="p">)</span>
<span class="n">ml_l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">learner</span><span class="o">$</span><span class="nf">clone</span><span class="p">()</span>
<span class="n">ml_m</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">learner</span><span class="o">$</span><span class="nf">clone</span><span class="p">()</span>
<span class="n">dml_plr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">DoubleMLPLR</span><span class="o">$</span><span class="nf">new</span><span class="p">(</span><span class="n">dml_data</span><span class="p">,</span><span class="w"> </span><span class="n">ml_l</span><span class="p">,</span><span class="w"> </span><span class="n">ml_m</span><span class="p">)</span>

<span class="n">dml_plr</span><span class="o">$</span><span class="nf">fit</span><span class="p">()</span>
<span class="n">dml_plr</span><span class="o">$</span><span class="nf">bootstrap</span><span class="p">()</span>
<span class="n">dml_plr</span><span class="o">$</span><span class="nf">confint</span><span class="p">(</span><span class="n">joint</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>
<span class="n">dml_plr</span><span class="o">$</span><span class="nf">p_adjust</span><span class="p">()</span>
<span class="n">dml_plr</span><span class="o">$</span><span class="nf">p_adjust</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s">&quot;bonferroni&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A matrix: 10 × 2 of type dbl</caption>
<thead>
	<tr><th></th><th scope=col>2.5 %</th><th scope=col>97.5 %</th></tr>
</thead>
<tbody>
	<tr><th scope=row>d1</th><td> 2.89027368</td><td>3.14532650</td></tr>
	<tr><th scope=row>d2</th><td> 2.90794478</td><td>3.14368145</td></tr>
	<tr><th scope=row>d3</th><td> 2.87430335</td><td>3.12752825</td></tr>
	<tr><th scope=row>d4</th><td>-0.14790924</td><td>0.07828372</td></tr>
	<tr><th scope=row>d5</th><td>-0.09779675</td><td>0.16803512</td></tr>
	<tr><th scope=row>d6</th><td>-0.12105472</td><td>0.12539340</td></tr>
	<tr><th scope=row>d7</th><td>-0.16536299</td><td>0.09310496</td></tr>
	<tr><th scope=row>d8</th><td>-0.10127930</td><td>0.14200098</td></tr>
	<tr><th scope=row>d9</th><td>-0.13868238</td><td>0.09980311</td></tr>
	<tr><th scope=row>d10</th><td>-0.04444978</td><td>0.19680840</td></tr>
</tbody>
</table>
</div><div class="output text_html"><table class="dataframe">
<caption>A matrix: 10 × 2 of type dbl</caption>
<thead>
	<tr><th></th><th scope=col>Estimate.</th><th scope=col>pval</th></tr>
</thead>
<tbody>
	<tr><th scope=row>d1</th><td> 3.017800092</td><td>0.000</td></tr>
	<tr><th scope=row>d2</th><td> 3.025813114</td><td>0.000</td></tr>
	<tr><th scope=row>d3</th><td> 3.000915799</td><td>0.000</td></tr>
	<tr><th scope=row>d4</th><td>-0.034812763</td><td>0.938</td></tr>
	<tr><th scope=row>d5</th><td> 0.035119185</td><td>0.938</td></tr>
	<tr><th scope=row>d6</th><td> 0.002169338</td><td>0.958</td></tr>
	<tr><th scope=row>d7</th><td>-0.036129015</td><td>0.938</td></tr>
	<tr><th scope=row>d8</th><td> 0.020360838</td><td>0.954</td></tr>
	<tr><th scope=row>d9</th><td>-0.019439633</td><td>0.954</td></tr>
	<tr><th scope=row>d10</th><td> 0.076179312</td><td>0.428</td></tr>
</tbody>
</table>
</div><div class="output text_html"><table class="dataframe">
<caption>A matrix: 10 × 2 of type dbl</caption>
<thead>
	<tr><th></th><th scope=col>Estimate.</th><th scope=col>pval</th></tr>
</thead>
<tbody>
	<tr><th scope=row>d1</th><td> 3.017800092</td><td>0.0000000</td></tr>
	<tr><th scope=row>d2</th><td> 3.025813114</td><td>0.0000000</td></tr>
	<tr><th scope=row>d3</th><td> 3.000915799</td><td>0.0000000</td></tr>
	<tr><th scope=row>d4</th><td>-0.034812763</td><td>1.0000000</td></tr>
	<tr><th scope=row>d5</th><td> 0.035119185</td><td>1.0000000</td></tr>
	<tr><th scope=row>d6</th><td> 0.002169338</td><td>1.0000000</td></tr>
	<tr><th scope=row>d7</th><td>-0.036129015</td><td>1.0000000</td></tr>
	<tr><th scope=row>d8</th><td> 0.020360838</td><td>1.0000000</td></tr>
	<tr><th scope=row>d9</th><td>-0.019439633</td><td>1.0000000</td></tr>
	<tr><th scope=row>d10</th><td> 0.076179312</td><td>0.8116912</td></tr>
</tbody>
</table>
</div></div>
</div>
</div>
</div>
</section>
<section id="references">
<h2><span class="section-number">8.3. </span>References<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Belloni, A., Chernozhukov, V., Chetverikov, D., Wei, Y. (2018), Uniformly valid post-regularization confidence regions for many functional parameters in z-estimation framework. The Annals of Statistics, 46 (6B): 3643-75,  <a class="reference external" href="https://dx.doi.org/10.1214%2F17-AOS1671">doi: 10.1214/17-AOS1671</a>.</p></li>
<li><p>Chernozhukov, V., Chetverikov, D., Kato, K. (2013). Gaussian approximations and multiplier bootstrap for maxima of sums of high-dimensional random vectors. The Annals of Statistics 41 (6): 2786-2819, <a class="reference external" href="https://dx.doi.org/10.1214/13-AOS1161">doi: 10.1214/13-AOS1161</a>.</p></li>
<li><p>Chernozhukov, V., Chetverikov, D., Kato, K. (2014), Gaussian approximation of suprema of empirical processes. The Annals of Statistics 42 (4): 1564-97, <a class="reference external" href="https://dx.doi.org/10.1214/14-AOS1230">doi: 10.1214/14-AOS1230</a>.</p></li>
</ul>
</section>
</section>


              </article>
              

              
              <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="learners.html" title="previous page">
      <i class="fas fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title"><span class="section-number">7. </span>Learners, hyperparameters and hyperparameter tuning</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="resampling.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title"><span class="section-number">9. </span>Sample-splitting, cross-fitting and repeated cross-fitting</p>
  </div>
  <i class="fas fa-angle-right"></i>
  </a>
</div>
              </footer>
              
          </div>
          
      </div>
    </div>

  
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695"></script>

<footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    <p class="copyright">
    &copy; Copyright 2023, Bach, P., Chernozhukov, V., Klaassen, S., Kurz, M. S., and Spindler, M..<br>
</p>
  </div>
  
  <div class="footer-item">
    <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
  </div>
  
</div>
</footer>
  </body>
</html>