Search.setIndex({"alltitles": {"(One-Way) Cluster Robust Double Machine Learing": [[50, "(One-Way)-Cluster-Robust-Double-Machine-Learing"], [70, "(One-Way)-Cluster-Robust-Double-Machine-Learing"]], "0. Problem Formulation": [[116, "problem-formulation"]], "1. Data-Backend": [[116, "data-backend"]], "1. Formulation of Causal Model & Identification Assumptions": [[78, "1.-Formulation-of-Causal-Model-&-Identification-Assumptions"]], "2. Causal Model": [[116, "causal-model"]], "2. Estimation of Causal Effect": [[78, "2.-Estimation-of-Causal-Effect"]], "3. ML Methods": [[116, "ml-methods"]], "3. Sensitivity Analysis": [[78, "3.-Sensitivity-Analysis"]], "4. Benchmarking Analysis": [[78, "4.-Benchmarking-Analysis"]], "4. DML Specifications": [[116, "dml-specifications"]], "5. Conclusion": [[78, "5.-Conclusion"]], "5. Estimation": [[116, "estimation"]], "6. Inference": [[116, "inference"]], "7. Sensitivity Analysis": [[116, "sensitivity-analysis"]], "A Motivating Example: Two-Way Cluster Robust DML": [[50, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"], [70, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"]], "API Reference": [[0, null]], "ATE Estimation and Sensitivity": [[66, "ATE-Estimation-and-Sensitivity"]], "ATE estimates distribution": [[79, "ATE-estimates-distribution"], [79, "id3"]], "ATTE Estimation": [[61, "ATTE-Estimation"], [61, "id2"]], "Acknowledgements": [[111, "acknowledgements"]], "Acknowledgements and Final Remarks": [[49, "Acknowledgements-and-Final-Remarks"]], "Additional Results: CATE estimates": [[73, "Additional-Results:-CATE-estimates"]], "Advanced: External Predictions": [[85, "advanced-external-predictions"]], "Advanced: Global and Local Learners, Stacked Ensembles": [[76, "Advanced:-Global-and-Local-Learners,-Stacked-Ensembles"]], "Algorithm DML1": [[80, "algorithm-dml1"]], "Algorithm DML2": [[80, "algorithm-dml2"]], "Application Results": [[50, "Application-Results"], [70, "Application-Results"]], "Application: 401(k)": [[77, "Application:-401(k)"]], "AutoML with less Computation time": [[69, "AutoML-with-less-Computation-time"]], "Average Potential Outcome (APOs)": [[55, "Average-Potential-Outcome-(APOs)"]], "Average Potential Outcomes (APOs)": [[86, "average-potential-outcomes-apos"], [88, "average-potential-outcomes-apos"], [102, "average-potential-outcomes-apos"]], "Average Potential Outcomes (APOs) for Multiple Treatment Levels": [[86, "average-potential-outcomes-apos-for-multiple-treatment-levels"]], "Average Treatment Effect": [[67, "Average-Treatment-Effect"]], "Average Treatment Effect on the Treated": [[67, "Average-Treatment-Effect-on-the-Treated"]], "Benchmarking": [[102, "benchmarking"]], "Benchmarking Analysis": [[77, "Benchmarking-Analysis"]], "Binary Interactive Regression Model (IRM)": [[86, "binary-interactive-regression-model-irm"], [88, "binary-interactive-regression-model-irm"]], "CATEs for IRM models": [[84, "cates-for-irm-models"]], "CATEs for PLR models": [[84, "cates-for-plr-models"]], "CVaR Treatment Effects": [[60, "CVaR-Treatment-Effects"]], "CVaR of potential outcomes": [[84, "cvar-of-potential-outcomes"]], "CVaR treatment effects": [[84, "cvar-treatment-effects"]], "Causal Analysis with DoubleML": [[78, "Causal-Analysis-with-DoubleML"]], "Causal Contrasts": [[55, "Causal-Contrasts"]], "Causal estimation vs. lasso penalty \\lambda": [[63, "Causal-estimation-vs.-lasso-penalty-\\lambda"]], "Chernozhukov et al. (2023): Benchmarking": [[78, "Chernozhukov-et-al.-(2023):-Benchmarking"]], "Citation": [[111, "citation"]], "Cluster Robust Cross Fitting": [[50, "Cluster-Robust-Cross-Fitting"], [70, "Cluster-Robust-Cross-Fitting"]], "Cluster Robust Standard Errors": [[50, "Cluster-Robust-Standard-Errors"], [70, "Cluster-Robust-Standard-Errors"]], "Clustering and double machine learning": [[50, "Clustering-and-double-machine-learning"], [70, "Clustering-and-double-machine-learning"]], "Combined loss vs. lasso penalty \\lambda": [[63, "Combined-loss-vs.-lasso-penalty-\\lambda"]], "Compare Metrics for Nuisance Estimation": [[69, "Compare-Metrics-for-Nuisance-Estimation"]], "Comparing different learners": [[68, "Comparing-different-learners"]], "Comparison and summary": [[69, "Comparison-and-summary"]], "Comparison to AutoML with less Computation time and Untuned XGBoost Learners": [[69, "Comparison-to-AutoML-with-less-Computation-time-and-Untuned-XGBoost-Learners"]], "Comparison to did package": [[49, "Comparison-to-did-package"]], "Computation time": [[68, "Computation-time"]], "Conclusion": [[69, "Conclusion"]], "Conditional Value at Risk (CVaR)": [[60, "Conditional-Value-at-Risk-(CVaR)"]], "Conditional average treatment effects (CATEs)": [[84, "conditional-average-treatment-effects-cates"]], "Conditional value at risk (CVaR)": [[84, "conditional-value-at-risk-cvar"], [88, "conditional-value-at-risk-cvar"]], "Confidence bands and multiplier bootstrap for valid simultaneous inference": [[101, "confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference"]], "Coverage Simulation": [[61, "Coverage-Simulation"], [61, "id3"]], "Cross-fitting with K folds": [[87, "cross-fitting-with-k-folds"]], "Cross-fitting, DML algorithms and Neyman-orthogonal score functions": [[113, "cross-fitting-dml-algorithms-and-neyman-orthogonal-score-functions"]], "Custom evaluation metrics": [[68, "Custom-evaluation-metrics"]], "DML: Bonus Data": [[53, null]], "Data": [[51, "Data"], [58, "Data"], [59, "Data"], [60, "Data"], [61, "Data"], [61, "id1"], [64, "Data"], [65, "Data"], [66, "Data"], [67, "Data"], [71, "Data"], [72, "Data"], [74, "Data"], [75, "Data"], [75, "id1"], [77, "Data"], [79, "Data"], [79, "id1"], [113, "data"]], "Data Generating Process (DGP)": [[48, "Data-Generating-Process-(DGP)"], [55, "Data-Generating-Process-(DGP)"], [57, "Data-Generating-Process-(DGP)"]], "Data Generation": [[69, "Data-Generation"]], "Data Simulation": [[47, "Data-Simulation"], [56, "Data-Simulation"]], "Data and Effect Estimation": [[77, "Data-and-Effect-Estimation"]], "Data generating process": [[81, "data-generating-process"]], "Data preprocessing": [[52, "Data-preprocessing"]], "Data-Backend for Cluster Data": [[50, "Data-Backend-for-Cluster-Data"], [70, "Data-Backend-for-Cluster-Data"]], "Dataset Generators": [[2, "dataset-generators"]], "Dataset Loaders": [[2, "dataset-loaders"]], "Datasets": [[2, null]], "Define Helper Functions for Plotting": [[50, "Define-Helper-Functions-for-Plotting"], [70, "Define-Helper-Functions-for-Plotting"]], "Demo Example from did": [[49, "Demo-Example-from-did"]], "Details on Predictive Performance": [[49, "Details-on-Predictive-Performance"]], "Difference-in-Differences Models": [[88, "difference-in-differences-models"]], "Difference-in-Differences Models (DID)": [[86, "difference-in-differences-models-did"]], "Difference-in-Differences for Panel Data": [[102, "difference-in-differences-for-panel-data"]], "Difference-in-Differences for repeated cross-sections": [[102, "difference-in-differences-for-repeated-cross-sections"]], "Disclaimer": [[78, "Disclaimer"]], "Double Machine Learning Algorithm": [[111, "double-machine-learning-algorithm"]], "Double Machine Learning Literature": [[114, null]], "Double machine learning algorithms": [[80, null]], "Double/debiased machine learning": [[48, "Double/debiased-machine-learning"], [57, "Double/debiased-machine-learning"], [81, "double-debiased-machine-learning"]], "DoubleML": [[111, null]], "DoubleML Data Class": [[1, null]], "DoubleML Models": [[3, null]], "DoubleML Object": [[77, "DoubleML-Object"]], "DoubleML Workflow": [[116, null]], "DoubleML meets FLAML - How to tune learners automatically within DoubleML": [[69, null]], "DoubleMLData from arrays and matrices": [[82, "doublemldata-from-arrays-and-matrices"]], "DoubleMLData from dataframes": [[82, "doublemldata-from-dataframes"]], "Effect Heterogeneity": [[54, "effect-heterogeneity"], [67, "Effect-Heterogeneity"]], "Empirical coverage vs. lasso penalty \\lambda": [[63, "Empirical-coverage-vs.-lasso-penalty-\\lambda"]], "Estimate DML models without sample-splitting": [[87, "estimate-dml-models-without-sample-splitting"]], "Estimate double/debiased machine learning models": [[113, "estimate-double-debiased-machine-learning-models"]], "Estimating Potential Quantiles and Quantile Treatment Effects": [[72, "Estimating-Potential-Quantiles-and-Quantile-Treatment-Effects"]], "Estimating local quantile treatment effects (LQTEs)": [[72, "Estimating-local-quantile-treatment-effects-(LQTEs)"]], "Estimating the Average Treatment Effect of 401(k) Eligibility on Net Financial Assets": [[51, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"], [71, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"]], "Estimating the treatment effect on the Conditional Value a Risk (CVaR)": [[72, "Estimating-the-treatment-effect-on-the-Conditional-Value-a-Risk-(CVaR)"]], "Estimation": [[79, "Estimation"], [79, "id2"]], "Estimation quality vs. \\lambda": [[63, "Estimation-quality-vs.-\\lambda"]], "Evaluate learners": [[85, "evaluate-learners"]], "Example: Sensitivity Analysis for Causal ML": [[78, null]], "Examples": [[54, null]], "Exploiting the Functionalities of did": [[49, "Exploiting-the-Functionalities-of-did"]], "Externally provide a sample splitting / partition": [[87, "externally-provide-a-sample-splitting-partition"]], "Flexible Covariate Adjustment in Regression Discontinuity Designs (RDD)": [[76, null]], "Fuzzy RDD": [[76, "Fuzzy-RDD"]], "Fuzzy RDD Without Adjustment": [[76, "Fuzzy-RDD-Without-Adjustment"]], "Fuzzy RDD with Flexible Adjustment": [[76, "Fuzzy-RDD-with-Flexible-Adjustment"]], "Fuzzy RDD with Linear Adjustment": [[76, "Fuzzy-RDD-with-Linear-Adjustment"]], "Fuzzy Regression Discontinuity Design": [[86, "fuzzy-regression-discontinuity-design"]], "GATE Estimation and Sensitivity": [[66, "GATE-Estimation-and-Sensitivity"]], "GATET Estimation and Sensitivity": [[66, "GATET-Estimation-and-Sensitivity"]], "GATEs for IRM models": [[84, "gates-for-irm-models"]], "GATEs for PLR models": [[84, "gates-for-plr-models"]], "General Examples": [[54, "general-examples"]], "General algorithm": [[102, "general-algorithm"]], "Generate Fuzzy Data": [[76, "Generate-Fuzzy-Data"]], "Generate Sharp Data": [[76, "Generate-Sharp-Data"]], "Getting Started": [[113, null]], "Group Average Treatment Effects (GATEs)": [[64, "Group-Average-Treatment-Effects-(GATEs)"], [65, "Group-Average-Treatment-Effects-(GATEs)"]], "Group average treatment effects (GATEs)": [[84, "group-average-treatment-effects-gates"]], "Heterogeneous treatment effects": [[84, null]], "How to exploit more features of mlr3pipelines in DoubleML": [[52, "How-to-exploit-more-features-of-mlr3pipelines-in-DoubleML"]], "Hyperparameter tuning": [[85, "hyperparameter-tuning"], [85, "id16"]], "Hyperparameter tuning with pipelines": [[85, "hyperparameter-tuning-with-pipelines"]], "Implementation": [[102, "implementation"]], "Implementation Details": [[86, "implementation-details"]], "Implementation of the double machine learning algorithms": [[80, "implementation-of-the-double-machine-learning-algorithms"]], "Implementation of the score function and the estimate of the causal parameter": [[88, "implementation-of-the-score-function-and-the-estimate-of-the-causal-parameter"]], "Implemented Neyman orthogonal score functions": [[88, "implemented-neyman-orthogonal-score-functions"]], "Initialize DoubleMLClusterData object": [[50, "Initialize-DoubleMLClusterData-object"], [70, "Initialize-DoubleMLClusterData-object"]], "Initialize the objects of class DoubleMLPLIV": [[50, "Initialize-the-objects-of-class-DoubleMLPLIV"], [70, "Initialize-the-objects-of-class-DoubleMLPLIV"]], "Installing DoubleML": [[112, null]], "Instrumental Variables Directed Acyclic Graph (IV - DAG)": [[47, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"], [56, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"]], "Interactive IV Model (IIVM)": [[51, "Interactive-IV-Model-(IIVM)"], [71, "Interactive-IV-Model-(IIVM)"]], "Interactive IV model (IIVM)": [[86, "interactive-iv-model-iivm"], [88, "interactive-iv-model-iivm"]], "Interactive Regression Model (IRM)": [[51, "Interactive-Regression-Model-(IRM)"], [64, "Interactive-Regression-Model-(IRM)"], [71, "Interactive-Regression-Model-(IRM)"], [74, "Interactive-Regression-Model-(IRM)"]], "Interactive regression model (IRM)": [[102, "interactive-regression-model-irm"]], "Interactive regression models (IRM)": [[86, "interactive-regression-models-irm"], [88, "interactive-regression-models-irm"]], "Learners and Hyperparameters": [[67, "Learners-and-Hyperparameters"]], "Learners to estimate the nuisance models": [[113, "learners-to-estimate-the-nuisance-models"]], "Learners, hyperparameters and hyperparameter tuning": [[85, null]], "Load Data": [[78, "Load-Data"]], "Load and Process Data": [[50, "Load-and-Process-Data"], [70, "Load-and-Process-Data"]], "Load bonus data using the dml datasets module": [[53, "Load-bonus-data-using-the-dml-datasets-module"]], "Local Average Treatment Effects of 401(k) Participation on Net Financial Assets": [[51, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"], [71, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"]], "Local Potential Quantile Estimation": [[75, "Local-Potential-Quantile-Estimation"]], "Local Potential Quantiles (LPQs)": [[75, "Local-Potential-Quantiles-(LPQs)"]], "Local Quantile Treatment Effects (LQTEs)": [[75, "Local-Quantile-Treatment-Effects-(LQTEs)"]], "Local potential quantiles (LPQs)": [[88, "local-potential-quantiles-lpqs"]], "Main Features": [[111, "main-features"]], "Minimum requirements for learners": [[85, "minimum-requirements-for-learners"], [85, "id2"]], "Missingness at Random": [[86, "missingness-at-random"], [88, "missingness-at-random"]], "Model-specific implementations": [[102, "model-specific-implementations"]], "Models": [[86, null]], "Motivation": [[50, "Motivation"], [70, "Motivation"]], "Multiple Average Potential Outcome Models (APOS)": [[55, "Multiple-Average-Potential-Outcome-Models-(APOS)"]], "Naive estimation": [[47, "Naive-estimation"], [56, "Naive-estimation"]], "No Clustering / Zero-Way Clustering": [[50, "No-Clustering-/-Zero-Way-Clustering"], [70, "No-Clustering-/-Zero-Way-Clustering"]], "Nonignorable Nonresponse": [[86, "nonignorable-nonresponse"], [88, "nonignorable-nonresponse"]], "One-Way Clustering with Respect to the Market": [[50, "One-Way-Clustering-with-Respect-to-the-Market"], [70, "One-Way-Clustering-with-Respect-to-the-Market"]], "One-Way Clustering with Respect to the Product": [[50, "One-Way-Clustering-with-Respect-to-the-Product"], [70, "One-Way-Clustering-with-Respect-to-the-Product"]], "One-dimensional Example": [[58, "One-dimensional-Example"], [59, "One-dimensional-Example"]], "Other models": [[45, null]], "Outcome missing at random (MAR)": [[79, "Outcome-missing-at-random-(MAR)"]], "Outcome missing under nonignorable nonresponse": [[79, "Outcome-missing-under-nonignorable-nonresponse"]], "Overcoming regularization bias by orthogonalization": [[48, "Overcoming-regularization-bias-by-orthogonalization"], [57, "Overcoming-regularization-bias-by-orthogonalization"], [81, "overcoming-regularization-bias-by-orthogonalization"]], "Panel Data": [[88, "panel-data"]], "Panel Data (Repeated Outcomes)": [[61, "Panel-Data-(Repeated-Outcomes)"]], "Panel data": [[86, "panel-data"]], "Parameter tuning": [[52, "Parameter-tuning"]], "Partialling out score": [[48, "Partialling-out-score"], [57, "Partialling-out-score"], [81, "partialling-out-score"]], "Partially Linear Regression Model (PLR)": [[51, "Partially-Linear-Regression-Model-(PLR)"], [65, "Partially-Linear-Regression-Model-(PLR)"], [71, "Partially-Linear-Regression-Model-(PLR)"]], "Partially linear IV regression model (PLIV)": [[86, "partially-linear-iv-regression-model-pliv"], [88, "partially-linear-iv-regression-model-pliv"]], "Partially linear models (PLM)": [[86, "partially-linear-models-plm"], [88, "partially-linear-models-plm"]], "Partially linear regression model (PLR)": [[86, "partially-linear-regression-model-plr"], [88, "partially-linear-regression-model-plr"], [102, "partially-linear-regression-model-plr"]], "Plot Coefficients and 95% Confidence Intervals": [[69, "Plot-Coefficients-and-95%-Confidence-Intervals"]], "Policy Learning with Trees": [[74, "Policy-Learning-with-Trees"], [84, "policy-learning-with-trees"]], "Potential Quantile Estimation": [[75, "Potential-Quantile-Estimation"]], "Potential Quantiles (PQs)": [[75, "Potential-Quantiles-(PQs)"]], "Potential quantiles (PQs)": [[84, "potential-quantiles-pqs"], [88, "potential-quantiles-pqs"]], "Python: Average Potential Outcome (APO) Models": [[55, null]], "Python: Basic Instrumental Variables calculation": [[56, null]], "Python: Basics of Double Machine Learning": [[57, null]], "Python: Building the package from source": [[112, "python-building-the-package-from-source"]], "Python: Case studies": [[54, "python-case-studies"]], "Python: Choice of learners": [[68, null]], "Python: Cluster Robust Double Machine Learning": [[70, null]], "Python: Conditional Average Treatment Effects (CATEs) for IRM models": [[58, null]], "Python: Conditional Average Treatment Effects (CATEs) for PLR models": [[59, null]], "Python: Conditional Value at Risk of potential outcomes": [[60, null]], "Python: Difference-in-Differences": [[61, null]], "Python: Difference-in-Differences Pre-Testing": [[62, null]], "Python: First Stage and Causal Estimation": [[63, null]], "Python: GATE Sensitivity Analysis": [[66, null]], "Python: Group Average Treatment Effects (GATEs) for IRM models": [[64, null]], "Python: Group Average Treatment Effects (GATEs) for PLR models": [[65, null]], "Python: IRM and APO Model Comparison": [[67, null]], "Python: Impact of 401(k) on Financial Wealth": [[71, null]], "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)": [[72, null]], "Python: Installing DoubleML": [[112, "python-installing-doubleml"]], "Python: Installing a released version from a .whl file": [[112, "python-installing-a-released-version-from-a-whl-file"]], "Python: Installing the latest release from pip or conda": [[112, "python-installing-the-latest-release-from-pip-or-conda"]], "Python: Learners and hyperparameters": [[85, "python-learners-and-hyperparameters"]], "Python: Optional Dependencies": [[112, "python-optional-dependencies"]], "Python: PLM and IRM for Multiple Treatments": [[73, null]], "Python: Policy Learning with Trees": [[74, null]], "Python: Potential Quantiles and Quantile Treatment Effects": [[75, null]], "Python: Sample Selection Models": [[79, null]], "Python: Sensitivity Analysis": [[77, null]], "Quantile Treatment Effects (QTEs)": [[75, "Quantile-Treatment-Effects-(QTEs)"]], "Quantile treatment effects (QTEs)": [[84, "quantile-treatment-effects-qtes"]], "Quantiles": [[84, "quantiles"]], "R: Basic Instrumental Variables Calculation": [[47, null]], "R: Basics of Double Machine Learning": [[48, null]], "R: Case studies": [[54, "r-case-studies"]], "R: Cluster Robust Double Machine Learning": [[50, null]], "R: DoubleML for Difference-in-Differences": [[49, null]], "R: Ensemble Learners and More with mlr3pipelines": [[52, null]], "R: Impact of 401(k) on Financial Wealth": [[51, null]], "R: Installing DoubleML": [[112, "r-installing-doubleml"]], "R: Installing the development version from GitHub": [[112, "r-installing-the-development-version-from-github"]], "R: Installing the latest release from CRAN": [[112, "r-installing-the-latest-release-from-cran"]], "R: Learners and hyperparameters": [[85, "r-learners-and-hyperparameters"]], "Ranking Treatment Effects under Treatment Propensity and Treatment Effect Heterogeneity": [[73, "Ranking-Treatment-Effects-under-Treatment-Propensity-and-Treatment-Effect-Heterogeneity"]], "Real-Data Application": [[50, "Real-Data-Application"], [70, "Real-Data-Application"]], "References": [[47, "References"], [49, "References"], [50, "References"], [52, "References"], [56, "References"], [63, "References"], [68, "References"], [69, "References"], [70, "References"], [73, "References"], [78, "References"], [81, "references"], [85, "references"], [87, "references"], [101, "references"], [111, "references"], [113, "references"]], "Regression Discontinuity Designs (RDD)": [[86, "regression-discontinuity-designs-rdd"]], "Regularization Bias in Simple ML-Approaches": [[48, "Regularization-Bias-in-Simple-ML-Approaches"], [57, "Regularization-Bias-in-Simple-ML-Approaches"]], "Regularization bias in simple ML-approaches": [[81, "regularization-bias-in-simple-ml-approaches"]], "Release Notes": [[115, null]], "Repeated Cross-Sectional Data": [[61, "Repeated-Cross-Sectional-Data"], [88, "repeated-cross-sectional-data"]], "Repeated cross-fitting with K folds and M repetitions": [[87, "repeated-cross-fitting-with-k-folds-and-m-repetitions"]], "Repeated cross-sections": [[86, "repeated-cross-sections"]], "Sample Selection Models": [[88, "sample-selection-models"]], "Sample Selection Models (SSM)": [[86, "sample-selection-models-ssm"]], "Sample splitting to remove bias induced by overfitting": [[48, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [57, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [81, "sample-splitting-to-remove-bias-induced-by-overfitting"]], "Sample-splitting without cross-fitting": [[87, "sample-splitting-without-cross-fitting"]], "Sample-splitting, cross-fitting and repeated cross-fitting": [[87, null]], "Sandbox": [[54, "sandbox"]], "Score Mixin Classes for DoubleML Models": [[44, null]], "Score functions": [[88, null]], "Sensitivity Analysis": [[55, "Sensitivity-Analysis"], [67, "Sensitivity-Analysis"], [77, "Sensitivity-Analysis"], [77, "id1"]], "Sensitivity Analysis with IRM": [[77, "Sensitivity-Analysis-with-IRM"]], "Sensitivity analysis": [[102, null]], "Set up learners based on mlr3pipelines": [[52, "Set-up-learners-based-on-mlr3pipelines"]], "Sharp RDD": [[76, "Sharp-RDD"]], "Sharp RDD Without Adjustment": [[76, "Sharp-RDD-Without-Adjustment"]], "Sharp RDD with Flexible Adjustment": [[76, "Sharp-RDD-with-Flexible-Adjustment"]], "Sharp RDD with Linear Adjustment": [[76, "Sharp-RDD-with-Linear-Adjustment"]], "Sharp Regression Discontinuity Design": [[86, "sharp-regression-discontinuity-design"]], "Simulate two-way cluster data": [[50, "Simulate-two-way-cluster-data"], [70, "Simulate-two-way-cluster-data"]], "Simulation Example": [[77, "Simulation-Example"]], "Simultaneous inference over different DoubleML models (advanced)": [[101, "simultaneous-inference-over-different-doubleml-models-advanced"]], "Single Average Potential Outcome Models (APO)": [[55, "Single-Average-Potential-Outcome-Models-(APO)"]], "Source code and maintenance": [[111, "source-code-and-maintenance"]], "Specify learner and estimate causal parameter: IRM model with Lasso as learner": [[53, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: IRM model with random forest as learner": [[53, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-random-forest-as-learner"]], "Specify learner and estimate causal parameter: PLR model with Lasso as learner": [[53, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: PLR model with random forest as learner": [[53, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-random-forest-as-learner"]], "Specifying alternative score functions via callables": [[88, "specifying-alternative-score-functions-via-callables"]], "Specifying learners and set hyperparameters": [[85, "specifying-learners-and-set-hyperparameters"], [85, "id9"]], "Standard approach": [[68, "Standard-approach"]], "Step 1: Custom API for FLAML Models within DoubleML": [[69, "Step-1:-Custom-API-for-FLAML-Models-within-DoubleML"]], "Step 1: Initialize and Train the AutoML Models:": [[69, "Step-1:-Initialize-and-Train-the-AutoML-Models:"]], "Step 2: Evaluate the Tuned Models": [[69, "Step-2:-Evaluate-the-Tuned-Models"]], "Step 2: Using the API when calling DoubleML\u2019s .fit() Method": [[69, "Step-2:-Using-the-API-when-calling-DoubleML's-.fit()-Method"]], "Step 3: Create and Fit DoubleML Model": [[69, "Step-3:-Create-and-Fit-DoubleML-Model"]], "Summary Figure": [[73, "Summary-Figure"]], "Summary of Results": [[51, "Summary-of-Results"], [71, "Summary-of-Results"]], "The Augmented Inverse Propensity Weighting Model estimates the ATE under arbitrary effect and propensity score heterogeneity": [[73, "The-Augmented-Inverse-Propensity-Weighting-Model-estimates-the-ATE-under-arbitrary-effect-and-propensity-score-heterogeneity"]], "The Data Backend: DoubleMLData": [[51, "The-Data-Backend:-DoubleMLData"], [71, "The-Data-Backend:-DoubleMLData"]], "The DoubleML package": [[51, "The-DoubleML-package"], [71, "The-DoubleML-package"]], "The Partially Linear Model performs overlap weighting": [[73, "The-Partially-Linear-Model-performs-overlap-weighting"]], "The basics of double/debiased machine learning": [[81, null]], "The causal model": [[113, "the-causal-model"]], "The data-backend DoubleMLData": [[82, null], [113, "the-data-backend-doublemldata"]], "Theory": [[102, "theory"]], "Tuning on the Folds": [[69, "Tuning-on-the-Folds"]], "Tuning on the full Sample": [[69, "Tuning-on-the-full-Sample"]], "Two-Dimensional Example": [[58, "Two-Dimensional-Example"], [59, "Two-Dimensional-Example"]], "Two-Way Clustering with Respect to Product and Market": [[50, "Two-Way-Clustering-with-Respect-to-Product-and-Market"], [70, "Two-Way-Clustering-with-Respect-to-Product-and-Market"]], "Untuned (default parameter) XGBoost": [[69, "Untuned-(default-parameter)-XGBoost"]], "Use ensemble learners based on mlr3pipelines": [[52, "Use-ensemble-learners-based-on-mlr3pipelines"]], "User Guide": [[83, null]], "Using DoubleML": [[47, "Using-DoubleML"], [56, "Using-DoubleML"]], "Using ML for DiD: Integrating DoubleML in did": [[49, "Using-ML-for-DiD:-Integrating-DoubleML-in-did"]], "Using learners from mlr3, mlr3learners and mlr3extralearners": [[52, "Using-learners-from-mlr3,-mlr3learners-and-mlr3extralearners"]], "Using pipelines to construct learners": [[85, "using-pipelines-to-construct-learners"]], "Utility Classes": [[46, "utility-classes"]], "Utility Classes and Functions": [[46, null]], "Utility Functions": [[46, "utility-functions"]], "VanderWeele and Arah (2011): Benchmarking": [[78, "VanderWeele-and-Arah-(2011):-Benchmarking"]], "Variance estimation": [[101, "variance-estimation"]], "Variance estimation and confidence intervals": [[101, null]], "Weighted Average Treatment Effects": [[84, "weighted-average-treatment-effects"]], "doubleml.DoubleMLAPO": [[4, null]], "doubleml.DoubleMLAPOS": [[5, null]], "doubleml.DoubleMLCVAR": [[6, null]], "doubleml.DoubleMLClusterData": [[7, null]], "doubleml.DoubleMLDID": [[8, null]], "doubleml.DoubleMLDIDCS": [[9, null]], "doubleml.DoubleMLData": [[10, null]], "doubleml.DoubleMLIIVM": [[11, null]], "doubleml.DoubleMLIRM": [[12, null]], "doubleml.DoubleMLLPQ": [[13, null]], "doubleml.DoubleMLPLIV": [[14, null]], "doubleml.DoubleMLPLR": [[15, null]], "doubleml.DoubleMLPQ": [[16, null]], "doubleml.DoubleMLQTE": [[17, null]], "doubleml.DoubleMLSSM": [[18, null]], "doubleml.datasets.fetch_401K": [[19, null]], "doubleml.datasets.fetch_bonus": [[20, null]], "doubleml.datasets.make_confounded_irm_data": [[21, null]], "doubleml.datasets.make_confounded_plr_data": [[22, null]], "doubleml.datasets.make_did_SZ2020": [[23, null]], "doubleml.datasets.make_heterogeneous_data": [[24, null]], "doubleml.datasets.make_iivm_data": [[25, null]], "doubleml.datasets.make_irm_data": [[26, null]], "doubleml.datasets.make_irm_data_discrete_treatments": [[27, null]], "doubleml.datasets.make_pliv_CHS2015": [[28, null]], "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021": [[29, null]], "doubleml.datasets.make_plr_CCDDHNR2018": [[30, null]], "doubleml.datasets.make_plr_turrell2018": [[31, null]], "doubleml.datasets.make_ssm_data": [[32, null]], "doubleml.double_ml_score_mixins.LinearScoreMixin": [[33, null]], "doubleml.double_ml_score_mixins.NonLinearScoreMixin": [[34, null]], "doubleml.rdd.RDFlex": [[35, null]], "doubleml.rdd.datasets.make_simple_rdd_data": [[36, null]], "doubleml.utils.DMLDummyClassifier": [[37, null]], "doubleml.utils.DMLDummyRegressor": [[38, null]], "doubleml.utils.DoubleMLBLP": [[39, null]], "doubleml.utils.DoubleMLPolicyTree": [[40, null]], "doubleml.utils.GlobalClassifier": [[41, null]], "doubleml.utils.GlobalRegressor": [[42, null]], "doubleml.utils.gain_statistics": [[43, null]]}, "docnames": ["api/api", "api/data_class", "api/datasets", "api/dml_models", "api/generated/doubleml.DoubleMLAPO", "api/generated/doubleml.DoubleMLAPOS", "api/generated/doubleml.DoubleMLCVAR", "api/generated/doubleml.DoubleMLClusterData", "api/generated/doubleml.DoubleMLDID", "api/generated/doubleml.DoubleMLDIDCS", "api/generated/doubleml.DoubleMLData", "api/generated/doubleml.DoubleMLIIVM", "api/generated/doubleml.DoubleMLIRM", "api/generated/doubleml.DoubleMLLPQ", "api/generated/doubleml.DoubleMLPLIV", "api/generated/doubleml.DoubleMLPLR", "api/generated/doubleml.DoubleMLPQ", "api/generated/doubleml.DoubleMLQTE", "api/generated/doubleml.DoubleMLSSM", "api/generated/doubleml.datasets.fetch_401K", "api/generated/doubleml.datasets.fetch_bonus", "api/generated/doubleml.datasets.make_confounded_irm_data", "api/generated/doubleml.datasets.make_confounded_plr_data", "api/generated/doubleml.datasets.make_did_SZ2020", "api/generated/doubleml.datasets.make_heterogeneous_data", "api/generated/doubleml.datasets.make_iivm_data", "api/generated/doubleml.datasets.make_irm_data", "api/generated/doubleml.datasets.make_irm_data_discrete_treatments", "api/generated/doubleml.datasets.make_pliv_CHS2015", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018", "api/generated/doubleml.datasets.make_plr_turrell2018", "api/generated/doubleml.datasets.make_ssm_data", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin", "api/generated/doubleml.rdd.RDFlex", "api/generated/doubleml.rdd.datasets.make_simple_rdd_data", "api/generated/doubleml.utils.DMLDummyClassifier", "api/generated/doubleml.utils.DMLDummyRegressor", "api/generated/doubleml.utils.DoubleMLBLP", "api/generated/doubleml.utils.DoubleMLPolicyTree", "api/generated/doubleml.utils.GlobalClassifier", "api/generated/doubleml.utils.GlobalRegressor", "api/generated/doubleml.utils.gain_statistics", "api/mixins", "api/other_models", "api/utility", "examples/R_double_ml_basic_iv", "examples/R_double_ml_basics", "examples/R_double_ml_did", "examples/R_double_ml_multiway_cluster", "examples/R_double_ml_pension", "examples/R_double_ml_pipeline", "examples/double_ml_bonus_data", "examples/index", "examples/py_double_ml_apo", "examples/py_double_ml_basic_iv", "examples/py_double_ml_basics", "examples/py_double_ml_cate", "examples/py_double_ml_cate_plr", "examples/py_double_ml_cvar", "examples/py_double_ml_did", "examples/py_double_ml_did_pretest", "examples/py_double_ml_firststage", "examples/py_double_ml_gate", "examples/py_double_ml_gate_plr", "examples/py_double_ml_gate_sensitivity", "examples/py_double_ml_irm_vs_apo", "examples/py_double_ml_learner", "examples/py_double_ml_meets_flaml", "examples/py_double_ml_multiway_cluster", "examples/py_double_ml_pension", "examples/py_double_ml_pension_qte", "examples/py_double_ml_plm_irm_hetfx", "examples/py_double_ml_policy_tree", "examples/py_double_ml_pq", "examples/py_double_ml_rdflex", "examples/py_double_ml_sensitivity", "examples/py_double_ml_sensitivity_booking", "examples/py_double_ml_ssm", "guide/algorithms", "guide/basics", "guide/data_backend", "guide/guide", "guide/heterogeneity", "guide/learners", "guide/models", "guide/resampling", "guide/scores", "guide/scores/apo_score", "guide/scores/cvar_score", "guide/scores/did_score", "guide/scores/didcs_score", "guide/scores/iivm_score", "guide/scores/irm_score", "guide/scores/lpq_score", "guide/scores/mar_score", "guide/scores/nr_score", "guide/scores/pliv_score", "guide/scores/plr_score", "guide/scores/pq_score", "guide/se_confint", "guide/sensitivity", "guide/sensitivity/apo_sensitivity", "guide/sensitivity/benchmarking", "guide/sensitivity/did_cs_sensitivity", "guide/sensitivity/did_sensitivity", "guide/sensitivity/implementation", "guide/sensitivity/irm_sensitivity", "guide/sensitivity/plr_sensitivity", "guide/sensitivity/theory", "index", "intro/install", "intro/intro", "literature/literature", "release/release", "workflow/workflow"], "envversion": {"nbsphinx": 4, "sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["api/api.rst", "api/data_class.rst", "api/datasets.rst", "api/dml_models.rst", "api/generated/doubleml.DoubleMLAPO.rst", "api/generated/doubleml.DoubleMLAPOS.rst", "api/generated/doubleml.DoubleMLCVAR.rst", "api/generated/doubleml.DoubleMLClusterData.rst", "api/generated/doubleml.DoubleMLDID.rst", "api/generated/doubleml.DoubleMLDIDCS.rst", "api/generated/doubleml.DoubleMLData.rst", "api/generated/doubleml.DoubleMLIIVM.rst", "api/generated/doubleml.DoubleMLIRM.rst", "api/generated/doubleml.DoubleMLLPQ.rst", "api/generated/doubleml.DoubleMLPLIV.rst", "api/generated/doubleml.DoubleMLPLR.rst", "api/generated/doubleml.DoubleMLPQ.rst", "api/generated/doubleml.DoubleMLQTE.rst", "api/generated/doubleml.DoubleMLSSM.rst", "api/generated/doubleml.datasets.fetch_401K.rst", "api/generated/doubleml.datasets.fetch_bonus.rst", "api/generated/doubleml.datasets.make_confounded_irm_data.rst", "api/generated/doubleml.datasets.make_confounded_plr_data.rst", "api/generated/doubleml.datasets.make_did_SZ2020.rst", "api/generated/doubleml.datasets.make_heterogeneous_data.rst", "api/generated/doubleml.datasets.make_iivm_data.rst", "api/generated/doubleml.datasets.make_irm_data.rst", "api/generated/doubleml.datasets.make_irm_data_discrete_treatments.rst", "api/generated/doubleml.datasets.make_pliv_CHS2015.rst", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021.rst", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018.rst", "api/generated/doubleml.datasets.make_plr_turrell2018.rst", "api/generated/doubleml.datasets.make_ssm_data.rst", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin.rst", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin.rst", "api/generated/doubleml.rdd.RDFlex.rst", "api/generated/doubleml.rdd.datasets.make_simple_rdd_data.rst", "api/generated/doubleml.utils.DMLDummyClassifier.rst", "api/generated/doubleml.utils.DMLDummyRegressor.rst", "api/generated/doubleml.utils.DoubleMLBLP.rst", "api/generated/doubleml.utils.DoubleMLPolicyTree.rst", "api/generated/doubleml.utils.GlobalClassifier.rst", "api/generated/doubleml.utils.GlobalRegressor.rst", "api/generated/doubleml.utils.gain_statistics.rst", "api/mixins.rst", "api/other_models.rst", "api/utility.rst", "examples/R_double_ml_basic_iv.ipynb", "examples/R_double_ml_basics.ipynb", "examples/R_double_ml_did.ipynb", "examples/R_double_ml_multiway_cluster.ipynb", "examples/R_double_ml_pension.ipynb", "examples/R_double_ml_pipeline.ipynb", "examples/double_ml_bonus_data.ipynb", "examples/index.rst", "examples/py_double_ml_apo.ipynb", "examples/py_double_ml_basic_iv.ipynb", "examples/py_double_ml_basics.ipynb", "examples/py_double_ml_cate.ipynb", "examples/py_double_ml_cate_plr.ipynb", "examples/py_double_ml_cvar.ipynb", "examples/py_double_ml_did.ipynb", "examples/py_double_ml_did_pretest.ipynb", "examples/py_double_ml_firststage.ipynb", "examples/py_double_ml_gate.ipynb", "examples/py_double_ml_gate_plr.ipynb", "examples/py_double_ml_gate_sensitivity.ipynb", "examples/py_double_ml_irm_vs_apo.ipynb", "examples/py_double_ml_learner.ipynb", "examples/py_double_ml_meets_flaml.ipynb", "examples/py_double_ml_multiway_cluster.ipynb", "examples/py_double_ml_pension.ipynb", "examples/py_double_ml_pension_qte.ipynb", "examples/py_double_ml_plm_irm_hetfx.ipynb", "examples/py_double_ml_policy_tree.ipynb", "examples/py_double_ml_pq.ipynb", "examples/py_double_ml_rdflex.ipynb", "examples/py_double_ml_sensitivity.ipynb", "examples/py_double_ml_sensitivity_booking.ipynb", "examples/py_double_ml_ssm.ipynb", "guide/algorithms.rst", "guide/basics.rst", "guide/data_backend.rst", "guide/guide.rst", "guide/heterogeneity.rst", "guide/learners.rst", "guide/models.rst", "guide/resampling.rst", "guide/scores.rst", "guide/scores/apo_score.rst", "guide/scores/cvar_score.rst", "guide/scores/did_score.rst", "guide/scores/didcs_score.rst", "guide/scores/iivm_score.rst", "guide/scores/irm_score.rst", "guide/scores/lpq_score.rst", "guide/scores/mar_score.rst", "guide/scores/nr_score.rst", "guide/scores/pliv_score.rst", "guide/scores/plr_score.rst", "guide/scores/pq_score.rst", "guide/se_confint.rst", "guide/sensitivity.rst", "guide/sensitivity/apo_sensitivity.rst", "guide/sensitivity/benchmarking.rst", "guide/sensitivity/did_cs_sensitivity.rst", "guide/sensitivity/did_sensitivity.rst", "guide/sensitivity/implementation.rst", "guide/sensitivity/irm_sensitivity.rst", "guide/sensitivity/plr_sensitivity.rst", "guide/sensitivity/theory.rst", "index.rst", "intro/install.rst", "intro/intro.rst", "literature/literature.rst", "release/release.rst", "workflow/workflow.rst"], "indexentries": {"aggregate_over_splits() (doubleml.rdd.rdflex method)": [[35, "doubleml.rdd.RDFlex.aggregate_over_splits", false]], "bootstrap() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.bootstrap", false]], "bootstrap() (doubleml.doublemlapos method)": [[5, "doubleml.DoubleMLAPOS.bootstrap", false]], "bootstrap() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.bootstrap", false]], "bootstrap() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.bootstrap", false]], "bootstrap() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.bootstrap", false]], "bootstrap() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.bootstrap", false]], "bootstrap() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.bootstrap", false]], "bootstrap() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.bootstrap", false]], "bootstrap() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.bootstrap", false]], "bootstrap() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.bootstrap", false]], "bootstrap() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.bootstrap", false]], "bootstrap() (doubleml.doublemlqte method)": [[17, "doubleml.DoubleMLQTE.bootstrap", false]], "bootstrap() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.bootstrap", false]], "capo() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.capo", false]], "cate() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.cate", false]], "cate() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.cate", false]], "causal_contrast() (doubleml.doublemlapos method)": [[5, "doubleml.DoubleMLAPOS.causal_contrast", false]], "confint() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.confint", false]], "confint() (doubleml.doublemlapos method)": [[5, "doubleml.DoubleMLAPOS.confint", false]], "confint() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.confint", false]], "confint() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.confint", false]], "confint() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.confint", false]], "confint() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.confint", false]], "confint() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.confint", false]], "confint() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.confint", false]], "confint() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.confint", false]], "confint() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.confint", false]], "confint() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.confint", false]], "confint() (doubleml.doublemlqte method)": [[17, "doubleml.DoubleMLQTE.confint", false]], "confint() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.confint", false]], "confint() (doubleml.rdd.rdflex method)": [[35, "doubleml.rdd.RDFlex.confint", false]], "confint() (doubleml.utils.doublemlblp method)": [[39, "doubleml.utils.DoubleMLBLP.confint", false]], "construct_framework() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.construct_framework", false]], "construct_framework() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.construct_framework", false]], "construct_framework() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.construct_framework", false]], "construct_framework() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.construct_framework", false]], "construct_framework() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.construct_framework", false]], "construct_framework() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.construct_framework", false]], "construct_framework() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.construct_framework", false]], "construct_framework() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.construct_framework", false]], "construct_framework() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.construct_framework", false]], "construct_framework() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.construct_framework", false]], "construct_framework() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.construct_framework", false]], "dmldummyclassifier (class in doubleml.utils)": [[37, "doubleml.utils.DMLDummyClassifier", false]], "dmldummyregressor (class in doubleml.utils)": [[38, "doubleml.utils.DMLDummyRegressor", false]], "doublemlapo (class in doubleml)": [[4, "doubleml.DoubleMLAPO", false]], "doublemlapos (class in doubleml)": [[5, "doubleml.DoubleMLAPOS", false]], "doublemlblp (class in doubleml.utils)": [[39, "doubleml.utils.DoubleMLBLP", false]], "doublemlclusterdata (class in doubleml)": [[7, "doubleml.DoubleMLClusterData", false]], "doublemlcvar (class in doubleml)": [[6, "doubleml.DoubleMLCVAR", false]], "doublemldata (class in doubleml)": [[10, "doubleml.DoubleMLData", false]], "doublemldid (class in doubleml)": [[8, "doubleml.DoubleMLDID", false]], "doublemldidcs (class in doubleml)": [[9, "doubleml.DoubleMLDIDCS", false]], "doublemliivm (class in doubleml)": [[11, "doubleml.DoubleMLIIVM", false]], "doublemlirm (class in doubleml)": [[12, "doubleml.DoubleMLIRM", false]], "doublemllpq (class in doubleml)": [[13, "doubleml.DoubleMLLPQ", false]], "doublemlpliv (class in doubleml)": [[14, "doubleml.DoubleMLPLIV", false]], "doublemlplr (class in doubleml)": [[15, "doubleml.DoubleMLPLR", false]], "doublemlpolicytree (class in doubleml.utils)": [[40, "doubleml.utils.DoubleMLPolicyTree", false]], "doublemlpq (class in doubleml)": [[16, "doubleml.DoubleMLPQ", false]], "doublemlqte (class in doubleml)": [[17, "doubleml.DoubleMLQTE", false]], "doublemlssm (class in doubleml)": [[18, "doubleml.DoubleMLSSM", false]], "draw_sample_splitting() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlapos method)": [[5, "doubleml.DoubleMLAPOS.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlqte method)": [[17, "doubleml.DoubleMLQTE.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.draw_sample_splitting", false]], "evaluate_learners() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.evaluate_learners", false]], "fetch_401k() (in module doubleml.datasets)": [[19, "doubleml.datasets.fetch_401K", false]], "fetch_bonus() (in module doubleml.datasets)": [[20, "doubleml.datasets.fetch_bonus", false]], "fit() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.fit", false]], "fit() (doubleml.doublemlapos method)": [[5, "doubleml.DoubleMLAPOS.fit", false]], "fit() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.fit", false]], "fit() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.fit", false]], "fit() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.fit", false]], "fit() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.fit", false]], "fit() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.fit", false]], "fit() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.fit", false]], "fit() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.fit", false]], "fit() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.fit", false]], "fit() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.fit", false]], "fit() (doubleml.doublemlqte method)": [[17, "doubleml.DoubleMLQTE.fit", false]], "fit() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.fit", false]], "fit() (doubleml.rdd.rdflex method)": [[35, "doubleml.rdd.RDFlex.fit", false]], "fit() (doubleml.utils.dmldummyclassifier method)": [[37, "doubleml.utils.DMLDummyClassifier.fit", false]], "fit() (doubleml.utils.dmldummyregressor method)": [[38, "doubleml.utils.DMLDummyRegressor.fit", false]], "fit() (doubleml.utils.doublemlblp method)": [[39, "doubleml.utils.DoubleMLBLP.fit", false]], "fit() (doubleml.utils.doublemlpolicytree method)": [[40, "doubleml.utils.DoubleMLPolicyTree.fit", false]], "fit() (doubleml.utils.globalclassifier method)": [[41, "doubleml.utils.GlobalClassifier.fit", false]], "fit() (doubleml.utils.globalregressor method)": [[42, "doubleml.utils.GlobalRegressor.fit", false]], "from_arrays() (doubleml.doublemlclusterdata class method)": [[7, "doubleml.DoubleMLClusterData.from_arrays", false]], "from_arrays() (doubleml.doublemldata class method)": [[10, "doubleml.DoubleMLData.from_arrays", false]], "gain_statistics() (in module doubleml.utils)": [[43, "doubleml.utils.gain_statistics", false]], "gapo() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.gapo", false]], "gate() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.gate", false]], "gate() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.gate", false]], "get_metadata_routing() (doubleml.utils.dmldummyclassifier method)": [[37, "doubleml.utils.DMLDummyClassifier.get_metadata_routing", false]], "get_metadata_routing() (doubleml.utils.dmldummyregressor method)": [[38, "doubleml.utils.DMLDummyRegressor.get_metadata_routing", false]], "get_metadata_routing() (doubleml.utils.globalclassifier method)": [[41, "doubleml.utils.GlobalClassifier.get_metadata_routing", false]], "get_metadata_routing() (doubleml.utils.globalregressor method)": [[42, "doubleml.utils.GlobalRegressor.get_metadata_routing", false]], "get_params() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.get_params", false]], "get_params() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.get_params", false]], "get_params() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.get_params", false]], "get_params() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.get_params", false]], "get_params() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.get_params", false]], "get_params() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.get_params", false]], "get_params() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.get_params", false]], "get_params() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.get_params", false]], "get_params() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.get_params", false]], "get_params() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.get_params", false]], "get_params() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.get_params", false]], "get_params() (doubleml.utils.dmldummyclassifier method)": [[37, "doubleml.utils.DMLDummyClassifier.get_params", false]], "get_params() (doubleml.utils.dmldummyregressor method)": [[38, "doubleml.utils.DMLDummyRegressor.get_params", false]], "get_params() (doubleml.utils.globalclassifier method)": [[41, "doubleml.utils.GlobalClassifier.get_params", false]], "get_params() (doubleml.utils.globalregressor method)": [[42, "doubleml.utils.GlobalRegressor.get_params", false]], "globalclassifier (class in doubleml.utils)": [[41, "doubleml.utils.GlobalClassifier", false]], "globalregressor (class in doubleml.utils)": [[42, "doubleml.utils.GlobalRegressor", false]], "linearscoremixin (class in doubleml.double_ml_score_mixins)": [[33, "doubleml.double_ml_score_mixins.LinearScoreMixin", false]], "make_confounded_irm_data() (in module doubleml.datasets)": [[21, "doubleml.datasets.make_confounded_irm_data", false]], "make_confounded_plr_data() (in module doubleml.datasets)": [[22, "doubleml.datasets.make_confounded_plr_data", false]], "make_did_sz2020() (in module doubleml.datasets)": [[23, "doubleml.datasets.make_did_SZ2020", false]], "make_heterogeneous_data() (in module doubleml.datasets)": [[24, "doubleml.datasets.make_heterogeneous_data", false]], "make_iivm_data() (in module doubleml.datasets)": [[25, "doubleml.datasets.make_iivm_data", false]], "make_irm_data() (in module doubleml.datasets)": [[26, "doubleml.datasets.make_irm_data", false]], "make_irm_data_discrete_treatments() (in module doubleml.datasets)": [[27, "doubleml.datasets.make_irm_data_discrete_treatments", false]], "make_pliv_chs2015() (in module doubleml.datasets)": [[28, "doubleml.datasets.make_pliv_CHS2015", false]], "make_pliv_multiway_cluster_ckms2021() (in module doubleml.datasets)": [[29, "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", false]], "make_plr_ccddhnr2018() (in module doubleml.datasets)": [[30, "doubleml.datasets.make_plr_CCDDHNR2018", false]], "make_plr_turrell2018() (in module doubleml.datasets)": [[31, "doubleml.datasets.make_plr_turrell2018", false]], "make_simple_rdd_data() (in module doubleml.rdd.datasets)": [[36, "doubleml.rdd.datasets.make_simple_rdd_data", false]], "make_ssm_data() (in module doubleml.datasets)": [[32, "doubleml.datasets.make_ssm_data", false]], "nonlinearscoremixin (class in doubleml.double_ml_score_mixins)": [[34, "doubleml.double_ml_score_mixins.NonLinearScoreMixin", false]], "p_adjust() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.p_adjust", false]], "p_adjust() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.p_adjust", false]], "p_adjust() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.p_adjust", false]], "p_adjust() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.p_adjust", false]], "p_adjust() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.p_adjust", false]], "p_adjust() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.p_adjust", false]], "p_adjust() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.p_adjust", false]], "p_adjust() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.p_adjust", false]], "p_adjust() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.p_adjust", false]], "p_adjust() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.p_adjust", false]], "p_adjust() (doubleml.doublemlqte method)": [[17, "doubleml.DoubleMLQTE.p_adjust", false]], "p_adjust() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.p_adjust", false]], "plot_tree() (doubleml.utils.doublemlpolicytree method)": [[40, "doubleml.utils.DoubleMLPolicyTree.plot_tree", false]], "policy_tree() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.policy_tree", false]], "predict() (doubleml.utils.dmldummyclassifier method)": [[37, "doubleml.utils.DMLDummyClassifier.predict", false]], "predict() (doubleml.utils.dmldummyregressor method)": [[38, "doubleml.utils.DMLDummyRegressor.predict", false]], "predict() (doubleml.utils.doublemlpolicytree method)": [[40, "doubleml.utils.DoubleMLPolicyTree.predict", false]], "predict() (doubleml.utils.globalclassifier method)": [[41, "doubleml.utils.GlobalClassifier.predict", false]], "predict() (doubleml.utils.globalregressor method)": [[42, "doubleml.utils.GlobalRegressor.predict", false]], "predict_proba() (doubleml.utils.dmldummyclassifier method)": [[37, "doubleml.utils.DMLDummyClassifier.predict_proba", false]], "predict_proba() (doubleml.utils.globalclassifier method)": [[41, "doubleml.utils.GlobalClassifier.predict_proba", false]], "rdflex (class in doubleml.rdd)": [[35, "doubleml.rdd.RDFlex", false]], "score() (doubleml.utils.dmldummyclassifier method)": [[37, "doubleml.utils.DMLDummyClassifier.score", false]], "score() (doubleml.utils.dmldummyregressor method)": [[38, "doubleml.utils.DMLDummyRegressor.score", false]], "score() (doubleml.utils.globalclassifier method)": [[41, "doubleml.utils.GlobalClassifier.score", false]], "score() (doubleml.utils.globalregressor method)": [[42, "doubleml.utils.GlobalRegressor.score", false]], "sensitivity_analysis() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlapos method)": [[5, "doubleml.DoubleMLAPOS.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.sensitivity_analysis", false]], "sensitivity_benchmark() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlapos method)": [[5, "doubleml.DoubleMLAPOS.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.sensitivity_benchmark", false]], "sensitivity_plot() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlapos method)": [[5, "doubleml.DoubleMLAPOS.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.sensitivity_plot", false]], "set_fit_request() (doubleml.utils.globalclassifier method)": [[41, "doubleml.utils.GlobalClassifier.set_fit_request", false]], "set_fit_request() (doubleml.utils.globalregressor method)": [[42, "doubleml.utils.GlobalRegressor.set_fit_request", false]], "set_ml_nuisance_params() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.set_ml_nuisance_params", false]], "set_params() (doubleml.utils.dmldummyclassifier method)": [[37, "doubleml.utils.DMLDummyClassifier.set_params", false]], "set_params() (doubleml.utils.dmldummyregressor method)": [[38, "doubleml.utils.DMLDummyRegressor.set_params", false]], "set_params() (doubleml.utils.globalclassifier method)": [[41, "doubleml.utils.GlobalClassifier.set_params", false]], "set_params() (doubleml.utils.globalregressor method)": [[42, "doubleml.utils.GlobalRegressor.set_params", false]], "set_sample_splitting() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlapos method)": [[5, "doubleml.DoubleMLAPOS.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlqte method)": [[17, "doubleml.DoubleMLQTE.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.set_sample_splitting", false]], "set_score_request() (doubleml.utils.dmldummyclassifier method)": [[37, "doubleml.utils.DMLDummyClassifier.set_score_request", false]], "set_score_request() (doubleml.utils.dmldummyregressor method)": [[38, "doubleml.utils.DMLDummyRegressor.set_score_request", false]], "set_score_request() (doubleml.utils.globalclassifier method)": [[41, "doubleml.utils.GlobalClassifier.set_score_request", false]], "set_score_request() (doubleml.utils.globalregressor method)": [[42, "doubleml.utils.GlobalRegressor.set_score_request", false]], "set_x_d() (doubleml.doublemlclusterdata method)": [[7, "doubleml.DoubleMLClusterData.set_x_d", false]], "set_x_d() (doubleml.doublemldata method)": [[10, "doubleml.DoubleMLData.set_x_d", false]], "tune() (doubleml.doublemlapo method)": [[4, "doubleml.DoubleMLAPO.tune", false]], "tune() (doubleml.doublemlcvar method)": [[6, "doubleml.DoubleMLCVAR.tune", false]], "tune() (doubleml.doublemldid method)": [[8, "doubleml.DoubleMLDID.tune", false]], "tune() (doubleml.doublemldidcs method)": [[9, "doubleml.DoubleMLDIDCS.tune", false]], "tune() (doubleml.doublemliivm method)": [[11, "doubleml.DoubleMLIIVM.tune", false]], "tune() (doubleml.doublemlirm method)": [[12, "doubleml.DoubleMLIRM.tune", false]], "tune() (doubleml.doublemllpq method)": [[13, "doubleml.DoubleMLLPQ.tune", false]], "tune() (doubleml.doublemlpliv method)": [[14, "doubleml.DoubleMLPLIV.tune", false]], "tune() (doubleml.doublemlplr method)": [[15, "doubleml.DoubleMLPLR.tune", false]], "tune() (doubleml.doublemlpq method)": [[16, "doubleml.DoubleMLPQ.tune", false]], "tune() (doubleml.doublemlssm method)": [[18, "doubleml.DoubleMLSSM.tune", false]]}, "objects": {"doubleml": [[4, 0, 1, "", "DoubleMLAPO"], [5, 0, 1, "", "DoubleMLAPOS"], [6, 0, 1, "", "DoubleMLCVAR"], [7, 0, 1, "", "DoubleMLClusterData"], [8, 0, 1, "", "DoubleMLDID"], [9, 0, 1, "", "DoubleMLDIDCS"], [10, 0, 1, "", "DoubleMLData"], [11, 0, 1, "", "DoubleMLIIVM"], [12, 0, 1, "", "DoubleMLIRM"], [13, 0, 1, "", "DoubleMLLPQ"], [14, 0, 1, "", "DoubleMLPLIV"], [15, 0, 1, "", "DoubleMLPLR"], [16, 0, 1, "", "DoubleMLPQ"], [17, 0, 1, "", "DoubleMLQTE"], [18, 0, 1, "", "DoubleMLSSM"]], "doubleml.DoubleMLAPO": [[4, 1, 1, "", "bootstrap"], [4, 1, 1, "", "capo"], [4, 1, 1, "", "confint"], [4, 1, 1, "", "construct_framework"], [4, 1, 1, "", "draw_sample_splitting"], [4, 1, 1, "", "evaluate_learners"], [4, 1, 1, "", "fit"], [4, 1, 1, "", "gapo"], [4, 1, 1, "", "get_params"], [4, 1, 1, "", "p_adjust"], [4, 1, 1, "", "sensitivity_analysis"], [4, 1, 1, "", "sensitivity_benchmark"], [4, 1, 1, "", "sensitivity_plot"], [4, 1, 1, "", "set_ml_nuisance_params"], [4, 1, 1, "", "set_sample_splitting"], [4, 1, 1, "", "tune"]], "doubleml.DoubleMLAPOS": [[5, 1, 1, "", "bootstrap"], [5, 1, 1, "", "causal_contrast"], [5, 1, 1, "", "confint"], [5, 1, 1, "", "draw_sample_splitting"], [5, 1, 1, "", "fit"], [5, 1, 1, "", "sensitivity_analysis"], [5, 1, 1, "", "sensitivity_benchmark"], [5, 1, 1, "", "sensitivity_plot"], [5, 1, 1, "", "set_sample_splitting"]], "doubleml.DoubleMLCVAR": [[6, 1, 1, "", "bootstrap"], [6, 1, 1, "", "confint"], [6, 1, 1, "", "construct_framework"], [6, 1, 1, "", "draw_sample_splitting"], [6, 1, 1, "", "evaluate_learners"], [6, 1, 1, "", "fit"], [6, 1, 1, "", "get_params"], [6, 1, 1, "", "p_adjust"], [6, 1, 1, "", "sensitivity_analysis"], [6, 1, 1, "", "sensitivity_benchmark"], [6, 1, 1, "", "sensitivity_plot"], [6, 1, 1, "", "set_ml_nuisance_params"], [6, 1, 1, "", "set_sample_splitting"], [6, 1, 1, "", "tune"]], "doubleml.DoubleMLClusterData": [[7, 1, 1, "", "from_arrays"], [7, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLDID": [[8, 1, 1, "", "bootstrap"], [8, 1, 1, "", "confint"], [8, 1, 1, "", "construct_framework"], [8, 1, 1, "", "draw_sample_splitting"], [8, 1, 1, "", "evaluate_learners"], [8, 1, 1, "", "fit"], [8, 1, 1, "", "get_params"], [8, 1, 1, "", "p_adjust"], [8, 1, 1, "", "sensitivity_analysis"], [8, 1, 1, "", "sensitivity_benchmark"], [8, 1, 1, "", "sensitivity_plot"], [8, 1, 1, "", "set_ml_nuisance_params"], [8, 1, 1, "", "set_sample_splitting"], [8, 1, 1, "", "tune"]], "doubleml.DoubleMLDIDCS": [[9, 1, 1, "", "bootstrap"], [9, 1, 1, "", "confint"], [9, 1, 1, "", "construct_framework"], [9, 1, 1, "", "draw_sample_splitting"], [9, 1, 1, "", "evaluate_learners"], [9, 1, 1, "", "fit"], [9, 1, 1, "", "get_params"], [9, 1, 1, "", "p_adjust"], [9, 1, 1, "", "sensitivity_analysis"], [9, 1, 1, "", "sensitivity_benchmark"], [9, 1, 1, "", "sensitivity_plot"], [9, 1, 1, "", "set_ml_nuisance_params"], [9, 1, 1, "", "set_sample_splitting"], [9, 1, 1, "", "tune"]], "doubleml.DoubleMLData": [[10, 1, 1, "", "from_arrays"], [10, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLIIVM": [[11, 1, 1, "", "bootstrap"], [11, 1, 1, "", "confint"], [11, 1, 1, "", "construct_framework"], [11, 1, 1, "", "draw_sample_splitting"], [11, 1, 1, "", "evaluate_learners"], [11, 1, 1, "", "fit"], [11, 1, 1, "", "get_params"], [11, 1, 1, "", "p_adjust"], [11, 1, 1, "", "sensitivity_analysis"], [11, 1, 1, "", "sensitivity_benchmark"], [11, 1, 1, "", "sensitivity_plot"], [11, 1, 1, "", "set_ml_nuisance_params"], [11, 1, 1, "", "set_sample_splitting"], [11, 1, 1, "", "tune"]], "doubleml.DoubleMLIRM": [[12, 1, 1, "", "bootstrap"], [12, 1, 1, "", "cate"], [12, 1, 1, "", "confint"], [12, 1, 1, "", "construct_framework"], [12, 1, 1, "", "draw_sample_splitting"], [12, 1, 1, "", "evaluate_learners"], [12, 1, 1, "", "fit"], [12, 1, 1, "", "gate"], [12, 1, 1, "", "get_params"], [12, 1, 1, "", "p_adjust"], [12, 1, 1, "", "policy_tree"], [12, 1, 1, "", "sensitivity_analysis"], [12, 1, 1, "", "sensitivity_benchmark"], [12, 1, 1, "", "sensitivity_plot"], [12, 1, 1, "", "set_ml_nuisance_params"], [12, 1, 1, "", "set_sample_splitting"], [12, 1, 1, "", "tune"]], "doubleml.DoubleMLLPQ": [[13, 1, 1, "", "bootstrap"], [13, 1, 1, "", "confint"], [13, 1, 1, "", "construct_framework"], [13, 1, 1, "", "draw_sample_splitting"], [13, 1, 1, "", "evaluate_learners"], [13, 1, 1, "", "fit"], [13, 1, 1, "", "get_params"], [13, 1, 1, "", "p_adjust"], [13, 1, 1, "", "sensitivity_analysis"], [13, 1, 1, "", "sensitivity_benchmark"], [13, 1, 1, "", "sensitivity_plot"], [13, 1, 1, "", "set_ml_nuisance_params"], [13, 1, 1, "", "set_sample_splitting"], [13, 1, 1, "", "tune"]], "doubleml.DoubleMLPLIV": [[14, 1, 1, "", "bootstrap"], [14, 1, 1, "", "confint"], [14, 1, 1, "", "construct_framework"], [14, 1, 1, "", "draw_sample_splitting"], [14, 1, 1, "", "evaluate_learners"], [14, 1, 1, "", "fit"], [14, 1, 1, "", "get_params"], [14, 1, 1, "", "p_adjust"], [14, 1, 1, "", "sensitivity_analysis"], [14, 1, 1, "", "sensitivity_benchmark"], [14, 1, 1, "", "sensitivity_plot"], [14, 1, 1, "", "set_ml_nuisance_params"], [14, 1, 1, "", "set_sample_splitting"], [14, 1, 1, "", "tune"]], "doubleml.DoubleMLPLR": [[15, 1, 1, "", "bootstrap"], [15, 1, 1, "", "cate"], [15, 1, 1, "", "confint"], [15, 1, 1, "", "construct_framework"], [15, 1, 1, "", "draw_sample_splitting"], [15, 1, 1, "", "evaluate_learners"], [15, 1, 1, "", "fit"], [15, 1, 1, "", "gate"], [15, 1, 1, "", "get_params"], [15, 1, 1, "", "p_adjust"], [15, 1, 1, "", "sensitivity_analysis"], [15, 1, 1, "", "sensitivity_benchmark"], [15, 1, 1, "", "sensitivity_plot"], [15, 1, 1, "", "set_ml_nuisance_params"], [15, 1, 1, "", "set_sample_splitting"], [15, 1, 1, "", "tune"]], "doubleml.DoubleMLPQ": [[16, 1, 1, "", "bootstrap"], [16, 1, 1, "", "confint"], [16, 1, 1, "", "construct_framework"], [16, 1, 1, "", "draw_sample_splitting"], [16, 1, 1, "", "evaluate_learners"], [16, 1, 1, "", "fit"], [16, 1, 1, "", "get_params"], [16, 1, 1, "", "p_adjust"], [16, 1, 1, "", "sensitivity_analysis"], [16, 1, 1, "", "sensitivity_benchmark"], [16, 1, 1, "", "sensitivity_plot"], [16, 1, 1, "", "set_ml_nuisance_params"], [16, 1, 1, "", "set_sample_splitting"], [16, 1, 1, "", "tune"]], "doubleml.DoubleMLQTE": [[17, 1, 1, "", "bootstrap"], [17, 1, 1, "", "confint"], [17, 1, 1, "", "draw_sample_splitting"], [17, 1, 1, "", "fit"], [17, 1, 1, "", "p_adjust"], [17, 1, 1, "", "set_sample_splitting"]], "doubleml.DoubleMLSSM": [[18, 1, 1, "", "bootstrap"], [18, 1, 1, "", "confint"], [18, 1, 1, "", "construct_framework"], [18, 1, 1, "", "draw_sample_splitting"], [18, 1, 1, "", "evaluate_learners"], [18, 1, 1, "", "fit"], [18, 1, 1, "", "get_params"], [18, 1, 1, "", "p_adjust"], [18, 1, 1, "", "sensitivity_analysis"], [18, 1, 1, "", "sensitivity_benchmark"], [18, 1, 1, "", "sensitivity_plot"], [18, 1, 1, "", "set_ml_nuisance_params"], [18, 1, 1, "", "set_sample_splitting"], [18, 1, 1, "", "tune"]], "doubleml.datasets": [[19, 2, 1, "", "fetch_401K"], [20, 2, 1, "", "fetch_bonus"], [21, 2, 1, "", "make_confounded_irm_data"], [22, 2, 1, "", "make_confounded_plr_data"], [23, 2, 1, "", "make_did_SZ2020"], [24, 2, 1, "", "make_heterogeneous_data"], [25, 2, 1, "", "make_iivm_data"], [26, 2, 1, "", "make_irm_data"], [27, 2, 1, "", "make_irm_data_discrete_treatments"], [28, 2, 1, "", "make_pliv_CHS2015"], [29, 2, 1, "", "make_pliv_multiway_cluster_CKMS2021"], [30, 2, 1, "", "make_plr_CCDDHNR2018"], [31, 2, 1, "", "make_plr_turrell2018"], [32, 2, 1, "", "make_ssm_data"]], "doubleml.double_ml_score_mixins": [[33, 0, 1, "", "LinearScoreMixin"], [34, 0, 1, "", "NonLinearScoreMixin"]], "doubleml.rdd": [[35, 0, 1, "", "RDFlex"]], "doubleml.rdd.RDFlex": [[35, 1, 1, "", "aggregate_over_splits"], [35, 1, 1, "", "confint"], [35, 1, 1, "", "fit"]], "doubleml.rdd.datasets": [[36, 2, 1, "", "make_simple_rdd_data"]], "doubleml.utils": [[37, 0, 1, "", "DMLDummyClassifier"], [38, 0, 1, "", "DMLDummyRegressor"], [39, 0, 1, "", "DoubleMLBLP"], [40, 0, 1, "", "DoubleMLPolicyTree"], [41, 0, 1, "", "GlobalClassifier"], [42, 0, 1, "", "GlobalRegressor"], [43, 2, 1, "", "gain_statistics"]], "doubleml.utils.DMLDummyClassifier": [[37, 1, 1, "", "fit"], [37, 1, 1, "", "get_metadata_routing"], [37, 1, 1, "", "get_params"], [37, 1, 1, "", "predict"], [37, 1, 1, "", "predict_proba"], [37, 1, 1, "", "score"], [37, 1, 1, "", "set_params"], [37, 1, 1, "", "set_score_request"]], "doubleml.utils.DMLDummyRegressor": [[38, 1, 1, "", "fit"], [38, 1, 1, "", "get_metadata_routing"], [38, 1, 1, "", "get_params"], [38, 1, 1, "", "predict"], [38, 1, 1, "", "score"], [38, 1, 1, "", "set_params"], [38, 1, 1, "", "set_score_request"]], "doubleml.utils.DoubleMLBLP": [[39, 1, 1, "", "confint"], [39, 1, 1, "", "fit"]], "doubleml.utils.DoubleMLPolicyTree": [[40, 1, 1, "", "fit"], [40, 1, 1, "", "plot_tree"], [40, 1, 1, "", "predict"]], "doubleml.utils.GlobalClassifier": [[41, 1, 1, "", "fit"], [41, 1, 1, "", "get_metadata_routing"], [41, 1, 1, "", "get_params"], [41, 1, 1, "", "predict"], [41, 1, 1, "", "predict_proba"], [41, 1, 1, "", "score"], [41, 1, 1, "", "set_fit_request"], [41, 1, 1, "", "set_params"], [41, 1, 1, "", "set_score_request"]], "doubleml.utils.GlobalRegressor": [[42, 1, 1, "", "fit"], [42, 1, 1, "", "get_metadata_routing"], [42, 1, 1, "", "get_params"], [42, 1, 1, "", "predict"], [42, 1, 1, "", "score"], [42, 1, 1, "", "set_fit_request"], [42, 1, 1, "", "set_params"], [42, 1, 1, "", "set_score_request"]]}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function"}, "terms": {"": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 25, 26, 28, 29, 30, 31, 32, 35, 39, 41, 42, 47, 49, 50, 51, 52, 53, 55, 61, 63, 64, 65, 66, 68, 70, 71, 72, 76, 77, 78, 79, 80, 82, 85, 86, 88, 96, 97, 101, 102, 104, 111, 113, 114, 115, 116], "0": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 101, 102, 104, 105, 106, 107, 108, 112, 113, 115], "00": [65, 67, 71, 72, 87], "000": [101, 116], "00000": 67, "000000": [53, 55, 67, 71, 72, 82, 84, 113], "0000000": 101, "0000000000000010000100": [52, 82, 113], "000000e": [65, 67, 71, 72], "00000591": 75, "000006": [55, 75], "000017": 75, "000025": 70, "000034": 71, "000039": 70, "000064": 56, "000067": 70, "000076": 86, "000091": 70, "0001": [53, 71], "000219": [16, 84], "000242": [17, 84], "000341": 70, "000442": 70, "00047580260495": 47, "000488": 70, "000494": 66, "0005": 53, "000522": 70, "0005a80b528f": 52, "000670": 70, "000743": 77, "000915799": 101, "0009157990": 101, "000943": [58, 59], "001": [47, 49, 50, 51, 52, 57, 85, 86, 87, 88, 101, 113, 116], "0010163": 87, "001051": 70, "001234": 72, "00133": 52, "00138944": [80, 88], "001403": 76, "001471": 67, "001494": [84, 85, 86], "0016": [51, 71], "001698": 67, "001714": 84, "00173": 87, "0018": [51, 71], "0019": 53, "001907": 67, "002": 73, "002169338": 101, "0021693380": 101, "0021693381": 101, "002277": 58, "002290": 62, "0023": 49, "00236": 87, "002388": 69, "002436": 66, "0026": 53, "002779": 77, "0028": [49, 51, 71], "002821": 78, "0028213335041910427": 78, "002983": 70, "003": [21, 22, 23, 73], "003045": 67, "003074": 86, "003134": 75, "003187": 58, "003220": 55, "003328": 75, "0034": 63, "003404": 55, "003415": 55, "003427": 70, "003607": 59, "003779": 66, "003836": 75, "003924": 66, "003944": 58, "003975": 58, "00409412": [80, 88], "0042": [51, 71], "004253": 55, "004392": 66, "004526": 55, "004542": 67, "004688": 11, "0047": [51, 71], "004846": 78, "005339": [58, 59], "005857": 70, "005e": 86, "006055": 55, "006267": 59, "006425": 72, "0068101213851626": 69, "006922": 53, "006958": [58, 59], "007210e": 72, "00728": 113, "0073": 53, "007332": 60, "007332393760465": 60, "007421": 84, "00778625": 87, "0078540263583833": 69, "008": 78, "008023": 72, "008223": [58, 59], "008266e": 72, "008487": 53, "0084871742256079": 69, "008642": 84, "008883698": 88, "00888458890362062": 80, "008884589": 80, "008dbd": 73, "008e80": 73, "009": [73, 78], "009122": 75, "009255": 58, "009317": 73, "009329847": 88, "00941": 87, "009428": 60, "00944171905420782": 78, "00950122695463054": 80, "009501226954630540": 80, "009501227": 80, "009645422": 50, "009656": 75, "00972": 53, "009790": 72, "009986": 75, "01": [4, 5, 6, 8, 9, 11, 12, 13, 16, 17, 18, 40, 47, 50, 51, 52, 58, 59, 67, 71, 72, 73, 74, 75, 76, 85, 86, 87, 88, 101, 113, 116], "010213": 77, "010269": 70, "010343": 73, "010450": 50, "010940": 70, "011": 73, "011131": 75, "0112": 49, "011204": 67, "01128": 53, "011598": 75, "0118095": 50, "011823": 77, "011988e": 75, "012006": 73, "01219": 52, "01274": 78, "012780": 72, "012831": 78, "013": 73, "013034": 78, "013128": 58, "013313": 69, "013327": 73, "013450": 67, "01351638": 50, "013593": 77, "013617": 72, "013677": 76, "013712": 58, "013904": 73, "01398951": 50, "013990": 101, "014": 76, "01403089": 50, "014080": [58, 59], "014432": 62, "014637": 70, "014681": 77, "014873e": 58, "015": 52, "015038": 60, "015552": 58, "015565": 75, "0156853566737638": 69, "015698": 75, "01574297": 75, "015743": 75, "015831": 58, "016011": 59, "016154": 70, "016200": [58, 59], "016315": 64, "01643": 114, "017": 52, "017140": 58, "017393e": 101, "017660": 67, "01772": 104, "017777e": 59, "017800092": 101, "0178000920": 101, "018": 52, "018023": 74, "018092": 84, "018148": 75, "018508": 58, "019": [47, 73], "01903": [52, 85, 111, 113], "01916030e": 87, "01925597": 50, "019439633": 101, "0194396330": 101, "0194396331": 101, "019596": 60, "019660": [17, 84], "01990373": 79, "019974": 72, "02": [58, 59, 71, 72, 75, 84, 86, 87], "02016117": 113, "020166": 75, "020271": 70, "020272": 67, "020360838": 101, "0203608380": 101, "0203608381": 101, "02052929": [80, 88], "0207805": 87, "02079162e": 87, "020819": 84, "02092": 113, "021": 73, "021269": [64, 65], "02163217": 50, "021690": 65, "021823": 69, "021866": 74, "021926": 60, "022181": 58, "022258": 67, "022295e": 58, "02247976": 50, "022768": 53, "022783": 77, "022915": 70, "022969": 72, "023020e": [71, 72], "023052": 59, "023256": 75, "023537": 69, "023563": 101, "023955": 72, "0240432": 87, "02424779": 87, "024266": 67, "024346": 58, "024355": 62, "024364": 102, "024401": [64, 65], "024604": 70, "024782": 75, "024926": 62, "025": [58, 59, 64, 65, 67, 73], "025077": [59, 101], "02528067": 68, "0253": 52, "025300e": 59, "025443": 53, "025496": 58, "0255741": 87, "0257": 49, "025813114": 101, "0258131140": 101, "02584": 52, "025841": 67, "025964": 67, "026669": 72, "026723": 60, "026822": 69, "026966": 67, "02791": 53, "028": 73, "0281": 52, "028520": [58, 59], "028731": 84, "02897287": 61, "02900983": 75, "029010": 75, "029022": 59, "029209": 116, "029364": [102, 107], "029831": 75, "029910e": [71, 72], "02e": 51, "03": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 55, 58, 59, 60, 66, 67, 71, 72, 75, 76, 77, 78, 87, 102, 107, 116], "030059": 84, "0301": 52, "03018": 13, "030346": 113, "0307": 52, "030934": 75, "0309525": 87, "030962": 75, "031007": 69, "03113": 79, "031134": 85, "031156": 59, "031269": 53, "031639": 75, "031820": 59, "03191": 114, "032": 73, "03220": 115, "0323": 49, "03244552": 85, "0325": 113, "03258": 69, "032580": 69, "032738": 69, "032941": 58, "032953": 77, "033265": 69, "033756": 60, "033764": 73, "033946": [64, 65], "034065": 59, "03411": 113, "034226": 72, "034690": 60, "034812763": 101, "0348127630": 101, "0348127631": 101, "034846": 71, "03489": [29, 50, 70], "035119185": 101, "0351191850": 101, "0351191851": 101, "035264": 59, "03536": 113, "03538": 52, "03539": 52, "035391": 53, "0354": 52, "035411": 113, "035441": 59, "03545": 52, "035545": 53, "035572": 53, "035730": 75, "03574": 53, "035762": 75, "035785": 59, "0359": 52, "036129015": 101, "0361290150": 101, "0361290151": 101, "036143": 75, "036147": 75, "036240": 55, "036729": 70, "0368": 49, "036945": 72, "03698487": 75, "036985": 75, "037008": [64, 65], "037114": 67, "0374": 52, "037504": 59, "037509": 79, "037529": 67, "037747": [58, 59], "038": 47, "038103": 67, "038845": 58, "039036": 58, "039141": 55, "03917696": [88, 101], "03920960e": 87, "039310e": 60, "039661": 67, "039895": 67, "039991e": 58, "04": [22, 35, 51, 55, 58, 59, 71, 72, 75, 76, 77, 87, 116], "040010": 67, "040079": 59, "040112": 101, "040139": [58, 59], "040533": [88, 101], "04053339": 101, "040562": 58, "040629": 15, "040688": 58, "040784": 55, "0408": 58, "040912": 59, "040919": 59, "041": 87, "041147": 60, "041284": 60, "041387": 60, "041459": 72, "041491e": 60, "04165": 86, "0418": 49, "041831": 60, "041925": 58, "042034": 78, "042249": 59, "042265": 60, "042442": 73, "0425": 85, "0428": 79, "042804": 67, "042822e": 72, "042844e": 75, "043": 73, "043108": 72, "0433": 49, "0434e374": 52, "04387": 85, "043998": 59, "044113": 60, "04415": 52, "044176": 67, "044239": 67, "04424": 52, "04444978": 101, "044449780": 101, "0445": 85, "04465": 50, "044704": 59, "04486": 113, "04487585": [102, 107], "04491": 86, "044929": 67, "04497975": [102, 107], "04501612": 101, "04502": [85, 88, 101], "045144": 70, "045172": 67, "045313": 58, "045379": 113, "04552": 70, "045553": 60, "045624": 62, "04563": 85, "045638": 58, "045754": 75, "04586": 85, "045932": 75, "045984": 67, "045993": 85, "04625": 85, "046451": 67, "046525": 84, "046527": 60, "04653976": 75, "046540": 75, "046587": 59, "0466028": 50, "046728": 77, "04682310e": 87, "046922": 85, "047": 73, "047194": 11, "047239": 67, "047288": 84, "047652e": 59, "047724": 58, "047873": 67, "047954": 70, "048220": 69, "048308": 65, "048476": 67, "048699": 79, "048723": 85, "048853": 59, "049264": 55, "04973": 59, "05": [35, 47, 49, 50, 51, 52, 58, 59, 60, 63, 68, 70, 71, 72, 73, 75, 76, 78, 85, 86, 87, 88, 101, 113, 116], "05039": 77, "050494e": 59, "050538": 59, "051": 52, "051651": 76, "051867e": 60, "052": 76, "052000e": 72, "052023": 67, "052272": 73, "052298": 75, "052380": 58, "052488": 65, "052502": 75, "052745": 60, "053": [52, 86], "053049": 59, "0533": 49, "053331": 60, "053342": 72, "053389": 101, "053436": 12, "053541": 75, "053558": 60, "053849e": 58, "054": [52, 73, 76], "054068": 70, "054162": 70, "054348": 101, "054370": 60, "054529": 101, "054771e": 75, "0550029": 87, "055165": 77, "055171": 59, "055439": [69, 72], "055493": 78, "055680": 101, "056": 76, "056499": 65, "056745": 58, "056764": 58, "056915": 67, "057095": 75, "0576": [51, 71], "057762": 75, "057792": 58, "057962": 60, "058042": 101, "058276": 72, "058375": 55, "058463": 75, "058508": 79, "058595": 58, "0590": 49, "059128": 58, "059384": 75, "059627": 72, "059630": 62, "059685": 75, "06": [21, 22, 23, 55, 58, 59, 60, 71, 72, 75, 84, 85], "060": 47, "060016": 55, "06008533": 86, "060201": 75, "060212": [71, 72], "060417": 58, "060581": 68, "060845": 101, "060933": 58, "0611": 49, "06111111": 52, "0615": 49, "062": [76, 86], "062414": 72, "06248233": 87, "062507": 75, "0628": 49, "062964": 101, "062988": 58, "063017": 55, "0632": 49, "063234e": 59, "063327": 67, "0635": 49, "063593": 59, "0636": 49, "063700": 58, "0638": 49, "063881": 86, "064": 73, "0640": 49, "064161": 72, "064213": 59, "06428": 71, "064280": 71, "0645": 49, "0646222": 51, "0647": 49, "0649": 49, "065": 78, "0653": 49, "065356": [64, 65], "065368": 69, "0654": 49, "065451": 72, "0655": 49, "065725": 60, "0659": 49, "065969": 86, "065976": 67, "0662": 49, "066295": 67, "066464": 77, "066889": 75, "0669": 49, "06692492": 87, "067046e": 58, "0671": 49, "067212": 67, "067240": 75, "06724028": 75, "0673": 49, "0675": 49, "067528": 78, "067721": 101, "068073": 59, "06827": 77, "06834315": 61, "068377": 72, "068514": 58, "068700": 84, "068934": 55, "06895837": 50, "0693639": 87, "069443": 55, "0695854": 50, "069589": 67, "069600": 72, "069882e": 58, "07": [58, 59, 72, 75, 76, 78, 87], "070": 73, "070020": 75, "070196": 60, "0701961897676835": 60, "0702127": 50, "0704": 49, "070433": 67, "070497": 78, "070534": 18, "070552": 58, "070574e": 72, "0707": 49, "070751": 58, "07085301": 86, "070884": 75, "0711": 49, "071285": 101, "07136": [50, 70], "071362": 58, "071488e": 60, "0716": 49, "07168291": 50, "071777": 85, "071782": [17, 84], "0719": 49, "07202564": [64, 65], "07222222": 52, "072293": 74, "072516": 67, "072605": 55, "0727": 86, "073": 76, "073013": 75, "073207": 70, "073275": 58, "073384": 67, "07347676": 50, "07350015": [29, 32, 50, 70], "073520": 60, "0736": 49, "07366": [52, 85], "073694": 59, "0739130271918385": 69, "073929": 69, "0743": 49, "074304": 101, "07436521": 87, "074426": 75, "07456127": 50, "074617": 59, "07479278": 77, "074927": 55, "075261": 62, "075384": 75, "07538443": 75, "07544271e": 87, "07561": 113, "07564554e": 87, "0758": 78, "075809": 55, "075869": 85, "075942": 69, "076019": 71, "076156": 101, "076179312": 101, "0761793120": 101, "076322": 75, "076347": 60, "07643374": 87, "0765": 52, "076596": 58, "076684": 113, "07685043": 87, "07689": 52, "07691847": 87, "076953": [64, 65], "076971": 53, "077144e": 59, "077161": 72, "07727773e": 87, "077319": 75, "077502": [102, 107], "077555": 58, "077592": 67, "077702": 55, "0777777777777778": 85, "07777778": [52, 85], "077840": 72, "077883": 75, "077923e": 58, "07796": 86, "078017": 58, "078096": 101, "078207": 53, "07828372": 101, "078426": 84, "078474": 101, "078709": 59, "078810": 75, "079": [47, 73], "079085": 53, "07913001": 87, "07915": 52, "07919896": 87, "07942v3": 114, "079458e": 71, "079500e": 58, "07961": 77, "07978296": 87, "08": [60, 72, 75, 78, 86], "08005229": 87, "080079": 73, "08031571": 87, "080854": 72, "08091581": 87, "080947": 53, "081": 52, "081100": 75, "081230": [58, 59], "081396": 65, "081488": 70, "08154161": 87, "08181827e": 87, "0820": 49, "082197": 67, "082263": 14, "082297": 87, "082400e": 58, "082574": 12, "082804": 62, "082858": 59, "082934": 72, "082973": 70, "083": 73, "083258": 101, "083318": 101, "08333333": 52, "08333617": 87, "0835771416": 50, "0836": 67, "08364": 67, "083706": 78, "083750": 72, "083949": 78, "084": 50, "084156": 59, "084184": 60, "0841842065698133": 60, "084212": 66, "084269": 72, "084323": 58, "084337": 86, "084633": 64, "0853505": 50, "085395": 58, "085566": 60, "085592": 67, "085671": 58, "085965": 72, "086004": 67, "08602774e": 87, "0862": 111, "086264": 60, "08664208": 87, "086679": 85, "086889": 64, "0872": 49, "087222": 59, "087561": 58, "087634": 58, "087745": 59, "087947": 75, "088048": 75, "088282": 65, "088357": 75, "08848": 85, "088482": [17, 84], "088504e": 14, "08888889": 52, "0894": 49, "08968939": 50, "089964": 69, "08e": 51, "09": [58, 59, 60, 71, 72, 75, 84], "09000000000000001": 85, "090025": 72, "09015": 49, "090255": 75, "090436": 59, "091179e": 58, "091263": 69, "091391": 101, "091406": 102, "091535": 58, "0916": 49, "091824": 59, "091992": 74, "092229": 78, "092247": 75, "092263": 86, "092365": 101, "092919": 104, "092935": 58, "093043": 75, "09310496": 101, "093153": 75, "093474": 75, "09347419": 75, "09351167": 86, "093746": 101, "093950": 70, "094026": 70, "094118": 75, "094378e": 58, "094381": 70, "09444444": 52, "094581e": 59, "094829": 86, "094999": 75, "095": 73, "095104": 55, "095654": 58, "095781": 6, "095785": 55, "09603": 111, "096337": 70, "096418": 55, "096550": 64, "096616": 84, "096688": 59, "096741": 61, "09682314": 86, "096915": 78, "097": 76, "097009": 67, "097157": 78, "097468": 60, "09779675": 101, "097796750": 101, "09786305": 87, "098": 51, "098256": 75, "09830758": 77, "098308": 77, "098317": 72, "098319": 75, "0986": 49, "098712": 75, "09879814e": 87, "098901": 67, "099": 76, "099001": 59, "099307": 59, "099647": 74, "099670": 72, "099731": [58, 59], "09980311": 101, "09988": 114, "0_": 28, "0ff823b17d45": 52, "0x1747bdd4520": 53, "0x1747bdd6b90": 53, "0x2920d7b7150": 74, "0x7f454e212090": 107, "0x7f454e659c70": 102, "0x7f454e7dc500": 101, "0x7f454e7dfef0": 101, "0x7f454e85fcb0": 101, "0x7f454e85fe90": 101, "0x7f454ee552e0": 85, "0x7f454ee57230": 86, "0x7f454f121010": 86, "0x7f454f3083e0": 85, "0x7f454f30a810": 85, "0x7f454f45ffe0": 116, "0x7f454fd63950": 86, "0x7f45552452b0": 86, "0x7f7f5538ad20": 78, "1": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 41, 42, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], "10": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 29, 30, 32, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 101, 102, 107, 111, 113, 114, 116], "100": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 29, 31, 32, 50, 52, 58, 59, 61, 63, 66, 67, 68, 70, 73, 78, 79, 80, 82, 84, 85, 86, 87, 88, 101, 102, 107, 113, 115], "1000": [11, 13, 48, 56, 57, 61, 62, 64, 65, 66, 68, 69, 71, 72, 76, 77, 78, 81, 86], "10000": [47, 58, 59, 62, 71, 72, 75], "100000e": 72, "100044": 65, "100154": 69, "100208": 84, "100356": 60, "10038": 77, "100385": 69, "10039862": [79, 86], "100517": 101, "100715": 58, "10079785": 86, "100807": [58, 59], "100858": 77, "10089588": 75, "100896": 75, "10092": 72, "100923": 75, "100_000": 73, "101": [21, 22, 23, 49, 76, 84, 86, 114, 115], "10126": 72, "10127930": 101, "101279300": 101, "1015": [51, 71], "1016": [21, 22, 23, 49], "1016010": 51, "1018": 72, "101998": 55, "102": [82, 84, 86, 113, 115], "10235": 72, "1024748": 87, "10258": 72, "102616": 60, "102775": 60, "10299": 71, "103": [58, 70, 76, 79, 84, 86, 115], "10307": 101, "1031": 72, "103189": 72, "1034779": 87, "10348": 71, "103497": 75, "1038": 72, "103806": 60, "103951906910721": 60, "103952": 60, "10396": 71, "104": [51, 71, 79, 84, 86, 115], "10406": 72, "104087": 58, "1041": 49, "10414": 72, "104492": 67, "1045303": 50, "104787": 70, "104849": 58, "105": [28, 50, 67, 70, 84, 86, 115], "105318": 75, "1054": 52, "105461": 84, "1055": 49, "1057703": 87, "106": [52, 84, 86, 115], "10607": [53, 82, 113], "10618": 72, "10637173e": 87, "106391": 101, "1065": [63, 68, 69], "106595": 86, "106746": 75, "106952": 66, "107": [52, 78, 84, 86, 115], "107073": 60, "107156": 67, "107295": 101, "1073": 72, "107413": 58, "10747": [53, 82, 113], "1078571": 87, "10799": 72, "108": [84, 86, 111, 114, 115], "1080": [29, 32, 49, 50, 70], "10824": [53, 82, 113], "108257e": 72, "108259": 55, "10831": [53, 82, 113], "10878571": 75, "108786": 75, "1089245": 87, "109": [58, 84, 86], "109005": 75, "10903": 71, "109069": 101, "109079e": 75, "109273": 70, "109277": 67, "10928": 72, "1093": 63, "109454": 72, "109470": 59, "1095": 87, "1096": 49, "10967": 71, "109861": 113, "1099434": 87, "1099472942084532": 56, "10e": [60, 75], "11": [15, 47, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 75, 76, 77, 78, 80, 82, 84, 85, 86, 87, 88, 101, 102, 107, 113, 116], "110": [84, 86, 115], "110081": 67, "1101": 72, "11019365749799062": 78, "110194": 78, "110359": 70, "110365": 78, "1104": 87, "110681": 77, "1107": 72, "11071087": [79, 86], "110717": 101, "1109": 72, "110902": 60, "110902411746278": 60, "111": [59, 84, 86, 115], "1111": [19, 20, 30, 48, 50, 57, 63, 70, 78, 81, 86, 102, 107, 111], "111164": 74, "11120": 72, "1116867": 87, "1117": [63, 68, 69], "1118": 51, "11199615e": 87, "112": [52, 84, 86, 115], "1120": 71, "112078": 84, "11208236": [80, 88], "1122": 72, "112216": 60, "1126214": 87, "1129": 72, "113": [19, 84, 86, 115], "113022": 67, "11311": 71, "113149": 67, "113207": 75, "113270": 60, "113415": 72, "11375": 72, "113780": 70, "113952": 67, "11399": 71, "114": [84, 86, 115], "1144500": 50, "11447": 77, "114530": 64, "1145370": 50, "114570": 59, "11458": 72, "114647": 60, "1147": 49, "1148": 72, "114834": 72, "11488": 72, "11495": 72, "114989": 55, "115": [84, 86, 115], "11500": [71, 116], "115060e": 75, "1151610541568202": 69, "115296e": 72, "115297e": 71, "1155142425200442": 69, "11552911": 77, "11559": 72, "115636": 59, "1157": 87, "11570": 71, "115792e": 72, "115901": 55, "115972": 58, "116": [84, 86, 115], "116027": 60, "11617": 72, "116274": 60, "116569": 72, "1166": [71, 114], "1167": 71, "11673": 72, "1167419": 87, "11675": 72, "1169868": 87, "117": [58, 84, 86], "1170": 77, "11700": 116, "117072": 64, "117112": 59, "117242": 75, "11724226": 75, "117366": 75, "11743": 116, "11750": 72, "1176": 49, "1177": 49, "117710": 60, "11792": 51, "11796": 72, "118": [84, 86], "11802": 72, "1182": 51, "11823404": 78, "118255": 75, "1186": 51, "118601": 70, "11861": 51, "1187339840850312": 70, "11879": 72, "118799": 72, "118938e": 86, "118952": 70, "119": [78, 84, 86, 115], "11932": 72, "11935": 77, "119766": 75, "1198": [50, 70], "12": [18, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 64, 65, 66, 67, 69, 70, 71, 72, 73, 75, 76, 77, 78, 80, 82, 84, 85, 86, 87, 88, 101, 102, 107, 111, 113, 114, 115, 116], "120": [61, 69, 79, 84, 86, 115], "12002": 71, "1202": 114, "1204498": 87, "120468": 75, "12046836": 75, "120567": [64, 65], "120721": 70, "1208": 78, "12097": [19, 20, 30, 50, 63, 70, 81, 111], "121": [72, 84, 86, 115], "1210": 72, "12101": 72, "12105472": 101, "121054720": 101, "1211": 72, "1213405": 50, "121399": 72, "1214": 101, "121584e": 75, "121711": 72, "121774": 66, "121824": 59, "12196389e": 87, "122": [21, 22, 23, 49, 76, 82, 84, 86, 114, 115], "12214": 51, "12223182e": 87, "122408": 60, "122421": 67, "122777": 101, "123": [35, 51, 52, 71, 78, 84, 86, 115, 116], "1230": 72, "123192": 78, "12323": 72, "1234": [47, 48, 49, 53, 56, 57, 76, 81, 85, 87, 101], "12348": 78, "1238": 72, "123917": 72, "124": [73, 84, 86], "12410": 72, "124306": 69, "124480": 69, "124805": 71, "124825": 59, "125": [84, 115], "12500": 71, "125065": 101, "12539340": 101, "1255": 72, "12579": 72, "1258": 50, "126": [84, 115], "12606": 72, "1261133363739424547485663648182848999": 87, "12612": 72, "126777": 101, "126802": 72, "12689": 72, "127": [21, 84, 115], "127006": 72, "12705095": [88, 101], "12707800": 50, "1272404618426184": 69, "127337": 67, "12752825": 101, "127563": 77, "1277": 73, "127778": 72, "127889": 84, "128": [51, 84, 115], "12802": 51, "12814": 72, "128229": 67, "128300e": 59, "128312": 75, "128408": 70, "12846564": 87, "1285": 49, "12861": 72, "128651": 59, "1288985": 87, "129": [70, 84, 115], "1291": 87, "12945": 114, "1295": [49, 72], "129514": 72, "12955": 71, "129606": 58, "129798": 58, "1298": 72, "12980769e": 87, "12983057": 86, "13": [22, 23, 25, 27, 48, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 75, 76, 77, 78, 80, 82, 84, 85, 86, 87, 88, 101, 102, 107, 113, 116], "130": [52, 64, 70, 84, 115], "130122": 77, "13034980e": 87, "130370": 60, "1306": 77, "130829": 75, "13084": 86, "13091": 72, "1309844442144665": 69, "131": [84, 115], "13102231": 86, "131024": 69, "13119": 77, "1312": 116, "131211": 72, "1313": [51, 116], "13137893e": 87, "131483": 67, "1318": 49, "131842": 67, "132": [52, 58, 70, 84, 115], "13208": 116, "1321": [71, 116], "132248": 84, "1324": [51, 71], "132454": 62, "132481": 84, "1325": 51, "13257": 71, "132671": 60, "132903": 72, "132982": 58, "133": [52, 82, 84, 114, 115], "13300": 72, "133202": 72, "133421": 72, "13356": 72, "133596": 75, "133839": 67, "13398": 78, "133f5a": 73, "134": [70, 79, 84, 87, 115], "1340371": 49, "1341": 51, "134146": 72, "1342": 72, "134211": 75, "1343": 71, "134542": 58, "134567": 72, "1346035": 51, "134687": 72, "13474": 72, "134765": 72, "134784": 86, "134784e": 58, "1348": 71, "1349": 77, "13490": 72, "135": [52, 84, 86, 115], "13505272": 50, "135142": 59, "135344": 55, "135352": 8, "135379": 101, "135665": 59, "135707": 85, "135856": 75, "13585644": 75, "135871": 70, "136": [53, 70, 78, 84, 115], "1360": 51, "13602": 78, "136089": 70, "1361": 72, "136102": 58, "1362430723104844": 69, "13642": 72, "136442": 70, "1366": 73, "136836": 70, "137": [21, 52, 53, 84, 115], "1371": 72, "137165": 86, "137213": 59, "137396": 75, "1378": 72, "137999": 86, "138": [84, 115], "1380": 71, "138068": 64, "13809": 72, "138264": 78, "138378": 60, "1384": 71, "1386": 49, "13868238": 101, "138682380": 101, "138698": 101, "1387": 49, "138851": 64, "13893": 72, "13894828": 87, "139": [73, 78, 84, 113], "139117e": 58, "139491": 101, "139508": 67, "13956": 77, "1398": 72, "1399": 49, "14": [48, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 64, 65, 66, 67, 69, 70, 71, 72, 75, 76, 77, 78, 80, 82, 84, 85, 86, 87, 88, 101, 102, 107, 113, 114, 116], "140": [61, 67, 72, 79, 84, 115], "1400": 72, "14000073": 87, "140073": 58, "140081": 69, "1401": 49, "14018": 86, "140770": [58, 59], "140833": 60, "140861": 50, "140926": 75, "141": [72, 84, 115], "141002": 59, "141098e": 72, "14114": 77, "14141": 72, "141460": 55, "141546": 101, "141820": 60, "142": [84, 115], "14200098": 101, "142119": 58, "142270": 62, "142382": 58, "1424": 85, "14268": 86, "14281403493938022": 85, "14289": 72, "143": [82, 84, 115], "143342": 59, "143495": 84, "1435": 72, "143534": 58, "14368145": 101, "144": [84, 115], "14400": 71, "14405": 72, "14406": 72, "144084": 60, "1441": 49, "144137": 61, "144241": 64, "1443": 72, "144500e": 72, "144669": 75, "1447": 72, "144800": 60, "144908": 74, "144971": 71, "145": [84, 115], "145027": 55, "145245": 75, "14532650": 101, "145625": 75, "145748": 101, "14587": 72, "146": [73, 84, 115], "146037": 75, "146087": 113, "146142808990006": 60, "146143": 60, "14625": 72, "146435": 59, "1465": 51, "146641": 101, "14667": 72, "1468115": 50, "146973": 60, "1469734445741286": 60, "147": [84, 115], "147015e": 72, "14702": 53, "147121": 75, "14744": 72, "14772": 72, "1479": 72, "14790924": 101, "147909240": 101, "147927": 53, "14798": 72, "148": [84, 115], "148005": 55, "14803": 72, "148134": [58, 59], "148161": 75, "14845": 53, "1485": 72, "148750e": [71, 72], "148790": 72, "148802": 72, "149": [84, 115], "1492": 47, "149215e": 59, "149228": 78, "149285": 75, "149472": 78, "149714": 70, "14984": 72, "149858": [16, 84], "149898": 75, "15": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 20, 48, 50, 51, 52, 55, 57, 58, 59, 60, 61, 64, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 78, 82, 84, 85, 86, 87, 88, 101, 102, 107, 113, 116], "150": [28, 52, 73, 78, 84, 115], "15000": [51, 71], "150000": 51, "15000000000000002": [60, 72, 75, 85], "150000e": 72, "1502": 50, "150200": 70, "150334": 72, "150408": 50, "150614": 53, "150719e": 71, "151": [84, 115], "151047e": 64, "151063": 58, "15113": 72, "1511614": 87, "1516023": 87, "151636": 60, "151819": 75, "15194": 71, "152": [84, 115], "152034": 72, "152148": [58, 59], "152353": 59, "152706": 86, "15285": 72, "152896": 69, "152926": 62, "153": [78, 84, 115], "1530959776797396": 60, "153096": 60, "153119": 60, "153314": 59, "15347": 72, "15354": 77, "153587": 70, "153633": 53, "153639": 87, "153935": 59, "154": 84, "1540055": 87, "15430": 116, "154421": 101, "1545": 72, "154557": 75, "154758": 101, "154828": 60, "154890": 69, "155": [84, 115], "155000": 71, "155025": 75, "155120": 75, "155160": 55, "155174": 55, "155423": 55, "155516": 74, "15556": 72, "1555617": 87, "1557093": 50, "156": [84, 115], "1560": 72, "156021": 75, "156169": 59, "156202": [58, 59], "156317": [58, 59], "1564": 101, "156545": 101, "156684": 59, "1569": 72, "156969": 60, "157": [47, 59, 84, 115], "157091": 101, "1571232": 87, "157154": 58, "1576": 72, "157733": 69, "1577657": 50, "157e": 86, "158": [84, 115], "158007": 75, "15815035": 51, "158178": 60, "1582": 72, "1586": 72, "158697": 101, "158726": 84, "1589": 72, "15891559": 75, "158916": 75, "159": 115, "15916": 49, "159386": 77, "1596": 52, "159633e": 59, "159841": 58, "159959": 72, "16": [6, 47, 48, 50, 51, 52, 55, 58, 59, 60, 65, 66, 67, 70, 71, 72, 75, 76, 77, 78, 82, 84, 85, 86, 87, 88, 101, 102, 107, 113, 116], "160": [61, 79, 115], "1604": 51, "160836": 67, "160932": 60, "161": [52, 114, 115], "161049": 59, "161141": 70, "161198": 74, "161236": 75, "161243": 75, "161269": 58, "161288": [59, 69], "161543": 72, "1619": 51, "162": 115, "16201": 72, "16211": 71, "162153": 75, "1622": 72, "1623242527324046525455576066737683919294": 87, "16241": 72, "162436": 78, "162593": 69, "1626685": 50, "162683": 78, "162710": 60, "1628": 71, "162930": 72, "163": [72, 115], "163194": 75, "163566": 72, "163895": 60, "164": [55, 76, 115], "164034": 101, "164467": 71, "164608": 75, "164698": 66, "1648": 49, "164801": 75, "164805": 60, "164864": 70, "165": 115, "16500": 71, "165178": 75, "16536299": 101, "165362990": 101, "16539906e": 87, "1654": 72, "165419": 75, "16553": 71, "165549": 113, "165707": 55, "16590": 72, "16597": 72, "166": 115, "1661": 71, "166238": 69, "166375": 84, "166517": 67, "167": [51, 71, 115], "16725": 72, "167547": 75, "167581e": 58, "1676": 72, "167765": 72, "167993": 101, "168": 115, "16803512": 101, "168089": 69, "168092": 101, "1681": [49, 71], "168195": 77, "168614": 75, "168931": 75, "169": [52, 115], "1691": [49, 72], "16910": 72, "169117": 78, "169196": 75, "169230e": 60, "16951": 72, "16984": 72, "17": [48, 50, 51, 52, 55, 58, 59, 66, 67, 70, 71, 72, 75, 76, 77, 78, 82, 84, 85, 86, 87, 88, 101, 102, 107, 113, 116], "170": 115, "1704": 72, "170705": 84, "170709e": 59, "17083": 72, "171": 115, "1712": 114, "1714": 51, "171575": 75, "171696": 84, "171815": 85, "171833": 59, "171848e": 58, "171942": 72, "172": [76, 115], "172022": 101, "172083": 59, "1722080": 87, "172628": 69, "172793": 75, "173": 115, "173504": 65, "17372": 72, "1738": 72, "17385178": 85, "173969": 101, "173e": 76, "174": 115, "174106": 77, "174185": 75, "174499": 101, "174516e": 75, "17453": 72, "1746": 72, "174835": 59, "174968": 71, "17499": 72, "175": 115, "1750146": 87, "1751": 71, "175176": 75, "17522": 72, "175254": 71, "175284": 60, "175369": 59, "175635027": 50, "17576": 72, "175894": 78, "175931": [84, 85, 86], "176495": 75, "17655394": 75, "176554": 75, "176929": 101, "177": [114, 115], "177007": 75, "17700723": 75, "177043": [58, 59], "1773": 72, "1774": 49, "177463": 74, "177496": 75, "177611": 75, "177740": 58, "177751": 75, "17778": 72, "177830": 59, "17799": 72, "177995": 75, "178": 115, "178169": 64, "178218": 59, "17823": 52, "178704": 101, "178763": 75, "178934": 101, "179": [64, 115], "179026": 59, "179101": 84, "1795850": 50, "179588e": 75, "179777": 59, "1797971": 87, "1798913180930109556": 73, "18": [48, 50, 51, 52, 53, 58, 59, 66, 67, 68, 70, 71, 72, 75, 76, 77, 78, 82, 84, 85, 86, 87, 101, 113, 116], "180": [61, 79, 115], "180143": 55, "18015": 72, "180176e": 72, "180262": 59, "180271": 67, "1803": 49, "18030": 72, "180575": [64, 65], "1807": [49, 72], "1809": 114, "180951": 75, "181": 115, "1812": 72, "1814": 49, "18141": 72, "181446": 101, "182": 115, "1820": 49, "182427": 59, "182633": 75, "182849": 75, "183": [52, 71, 86, 115], "183339": 58, "183373": 86, "183526": 60, "183553": 76, "18356413": 86, "18368": 72, "183855": 85, "183888": 70, "184": [52, 114, 115], "184224": 55, "184247": 58, "184347": 59, "1844721": 87, "185": [51, 52], "18500": 72, "185130": 76, "1855": 72, "185984": 58, "186": [47, 72, 115], "18604": 72, "1862": 49, "186237": 59, "18631": 72, "18637": 111, "186589": 55, "18666": 72, "186689": 86, "186735": 75, "18678094e": 87, "186836": 75, "187": 115, "187153": 101, "187664": 58, "187690": 75, "18789": 72, "188": 115, "188175": 75, "1881752": 75, "188223": 75, "188400": 59, "1887": [84, 85, 86], "188760": 67, "18888149e": 87, "188882": 59, "188991": 101, "189": [52, 76, 115], "189195": 72, "189248": 58, "189293": 72, "1895815": [29, 50, 70], "189737": 75, "189739": 55, "189927": 72, "189998": 75, "19": [48, 50, 51, 52, 58, 59, 67, 69, 70, 71, 72, 75, 76, 77, 78, 84, 85, 86, 87, 101, 113, 116], "190": [52, 115], "19000": 72, "190096": 101, "19031969": 75, "190320": 75, "19033538": 50, "190648": 11, "19073905e": 87, "190809": 75, "190892": 78, "1909": [29, 50, 70], "190915": 60, "190921": 65, "190976": 76, "190982": 75, "191": [52, 114, 115], "191192": 58, "1912": 114, "191223": 59, "1912705": 81, "191294": 59, "191534": 71, "191716": 72, "1918": 49, "192": 115, "1922": 72, "192240": 101, "192505": 74, "192526": 77, "19252647": 77, "192539": [17, 84], "192587": 75, "192952": 55, "193": 115, "193060": 75, "193253": 58, "193285": 58, "193308": [17, 84], "193341": 59, "193375": 67, "19374710e": 87, "19382": 72, "193849": 76, "19385": 72, "193f0d909729": 52, "194": [68, 72, 115], "194092": 58, "1941": 51, "19413": [71, 72], "194303": 59, "194601": 61, "195": 115, "19508": 78, "19508031003642462": 78, "19509680e": 87, "195377": 75, "195396": 75, "195547": 72, "195564": 70, "19559": [51, 71], "195761": 75, "195781": 58, "1959": 114, "1959385": 87, "195963": 67, "196": 115, "196189": 75, "196437": 72, "196478e": 59, "196655": 67, "19680840": 101, "196e": 35, "197": 115, "1970": 72, "197000e": 72, "19705": 72, "197225": [53, 82, 113], "1972250000001000100001": [52, 82, 113], "1974": 72, "197424": 85, "197484": 101, "19756": 72, "19758": 72, "197600": 62, "197711": 72, "197920": 58, "19793": 72, "19794": 72, "198": [73, 115], "198218": 70, "19824": 72, "198346e": 73, "198351": 75, "198493": 67, "198503": 76, "198549": 53, "198687": 51, "1988": [48, 57, 81, 86], "199": 115, "1990": [51, 71, 72], "1991": [51, 71, 72, 116], "199281e": 75, "199282e": 72, "199412": 59, "199458": 101, "1995": [50, 70], "1995266": 87, "1998": 73, "19983954": 79, "199893": 64, "1999": [73, 79], "1_": [60, 75], "1e": [4, 6, 8, 9, 11, 12, 13, 16, 17, 18, 67, 72], "1f77b4": 62, "1x_4x_3": 62, "2": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 35, 36, 38, 40, 42, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 84, 85, 86, 87, 88, 101, 102, 103, 104, 107, 108, 109, 110, 112, 113, 114, 115], "20": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 29, 30, 31, 48, 50, 51, 52, 58, 59, 60, 61, 64, 66, 67, 68, 70, 71, 72, 75, 77, 78, 79, 80, 81, 84, 85, 86, 87, 88, 101, 102, 107, 113, 116], "200": [24, 27, 28, 49, 60, 61, 63, 68, 74, 75, 79, 81, 85, 115], "2000": [18, 20, 51, 55, 58, 59, 60, 67, 71, 72, 75, 79, 84, 86], "20000": [51, 71], "20000000000000004": [60, 72, 75], "200000e": 72, "200049": 58, "20010": 72, "200110": 72, "2003": [19, 114], "200303": 113, "2005": 61, "20055": 72, "2006": 72, "20073763": 68, "20074": 72, "201": [52, 72, 115], "2010": [50, 70], "2011": [50, 70, 111, 113], "2013": [63, 101, 114], "2014": [101, 114], "2015": [28, 114], "201528": [58, 59], "20158": 72, "2016": 73, "2017": [26, 114], "201768": 70, "201788e": 72, "2018": [19, 20, 30, 31, 48, 50, 51, 57, 61, 63, 68, 70, 71, 72, 77, 81, 87, 88, 94, 101, 111, 114, 115], "2019": [24, 52, 58, 59, 60, 64, 65, 72, 75, 77, 85, 88, 90, 95, 100, 111, 113, 114], "201e": 76, "202": 115, "2020": [8, 9, 21, 22, 23, 25, 27, 49, 52, 61, 78, 85, 86, 102, 104, 114], "2020435": 50, "2021": [29, 49, 50, 52, 58, 59, 70, 114, 115], "20219609": 50, "2022": [77, 78, 86, 102, 104, 110, 111, 114], "2023": [32, 79, 86, 88, 96, 97, 114], "2024": [47, 56, 63, 68, 69, 73, 76, 78, 86, 111, 114], "202603": 59, "202650e": 60, "20269": 72, "20274": 72, "202846": 59, "203": [51, 58, 71, 115], "203284": 60, "20329": 72, "2036": 72, "203828": 72, "204": 115, "204007": 75, "20400735": 75, "204362": 78, "204455": 59, "204482": 75, "204794": 75, "204893": 55, "205": [76, 77, 115], "205187": 60, "205224": 77, "205333e": 71, "205938": 70, "206": 115, "2061": 72, "206253": [71, 72], "206256": 67, "2064": 72, "206614": 75, "207": [73, 76, 86, 115], "2075": 49, "207834": 59, "20783816": 50, "207840": 65, "207885": 71, "207912": 101, "208": [55, 115], "208034e": 72, "2080787": 50, "20823898": 50, "2086": 72, "209": 55, "209014": 75, "209219e": 77, "209257": 8, "209546e": 72, "209894": 75, "21": [19, 20, 30, 48, 50, 51, 52, 58, 59, 63, 70, 71, 72, 75, 77, 78, 81, 84, 85, 86, 87, 101, 111, 113, 114, 116], "210": [22, 23, 27, 55], "2103": [72, 111], "2103034": 50, "210319": [58, 59], "210323": 75, "2104": 115, "2107": 114, "21078": 72, "211": [55, 76, 115], "21105": [52, 85, 111, 113], "2112": 78, "21142": 72, "211534": 60, "21155656": 75, "211557": 75, "212": [55, 115], "2122": 72, "2124070": 87, "21257396e": 87, "212811": 55, "212844": 70, "212863": 58, "213": [55, 76, 114, 115], "213026": 72, "213070": 59, "213135": 59, "213199": 86, "21361": 72, "213743e": 59, "2139": 25, "214458": 69, "214764": 77, "214769": 67, "215": 55, "215069": 75, "215342": 75, "2155": 72, "21550": 72, "21562": 72, "21573": 72, "215967": 101, "216": [55, 73], "216207": 85, "21624417": 50, "2163": 72, "216344": 75, "21669513e": 87, "216761": 74, "216943": 84, "217": [55, 76, 114], "21716": 72, "2171802": [50, 70], "217244": 13, "217684": 67, "218": 55, "21804": [51, 71], "218383": 55, "218767": 72, "2189": 72, "218938": 72, "219": [21, 22, 23, 47, 49, 55, 114], "2191274": 50, "219585": 55, "2197237644227434": 69, "2198": 87, "22": [48, 50, 51, 52, 58, 59, 69, 70, 71, 75, 76, 77, 78, 84, 85, 86, 87, 101, 113, 116], "220": [35, 55, 115], "220088": 72, "220398": 58, "220407": 69, "220772": 75, "221": [55, 115], "2213": 70, "2214": 70, "221419": 72, "2215": 70, "2216": 70, "2217": [50, 70], "22172924": 87, "222": 115, "2222": [48, 50, 57, 86], "22222": 72, "222261": 84, "22272803e": 87, "222843": 75, "222882": [59, 69], "223": [76, 115], "223158": 69, "22336235": 50, "223485956098176": [64, 65], "223617": 69, "22375856": 50, "22390": 71, "223928": 69, "224": [73, 76, 115], "2241716": 87, "224897": [58, 59], "225": [49, 79, 115], "225034": 61, "22505965": 50, "22507006e": 87, "225175": 75, "225222": 75, "22522221": 75, "22528": 72, "225350": 59, "225427": 55, "225459760731946": 60, "225460": 60, "225574": 70, "2256": 72, "22562": 72, "225670": 69, "225776": 78, "226": 115, "2264": 49, "226479": 67, "226524": 75, "226598": 70, "226938": 65, "226969": 55, "227": [72, 115], "2271071": 32, "2276": 49, "2279": 72, "227932e": 71, "228035": 72, "2281": 72, "228404": 69, "228597e": 59, "228630": 59, "228648": 51, "229": [51, 115], "22925": 72, "22937": 72, "229443": 75, "229452": [84, 85, 86], "229472": 71, "2295": 72, "229759": 85, "2298": 49, "229961": [58, 59], "229994": [58, 59], "23": [9, 38, 42, 50, 51, 52, 58, 59, 61, 68, 70, 71, 72, 75, 77, 78, 82, 84, 85, 86, 87, 101, 111, 113, 114, 116], "230": 49, "230009": [64, 65], "2307": [50, 70, 81], "2308": 77, "230842": 58, "230956": 62, "231": [19, 115], "23113": 86, "231153": 59, "231310": 75, "231430": 101, "231467": 86, "231734": 86, "231798": 86, "231986": 75, "231e": 76, "232134": [58, 59], "232157": 59, "2328": 72, "232868e": 59, "232959": [64, 65], "232e": 86, "233": 26, "233029": 58, "233154": 116, "2335": 49, "233705": 59, "234": 114, "234137": 78, "234153": 78, "234205": 72, "2343175": 87, "234431": 69, "234534": 60, "234605": 53, "234798": 72, "2348756": 87, "234910": 70, "235": 115, "235291": 58, "2359": 116, "23590": 72, "236008": 60, "236015e": 58, "236309": 72, "236884": 69, "23690345e": 87, "237": 52, "237115": 59, "237200e": 58, "237252": 72, "237341": 58, "237461": 77, "23748": 72, "2374976": 87, "23751359e": 87, "237896": 75, "23789633": 75, "238": [50, 70, 115], "238101": 75, "238225": 101, "238251": 60, "238529": 12, "23856": 72, "238619": 55, "238794": 75, "239": 115, "239019": 67, "239243": 58, "239267": 69, "239313": 59, "23965": 72, "23e": 51, "24": [50, 51, 52, 58, 59, 68, 69, 70, 71, 72, 75, 77, 78, 79, 84, 85, 86, 87, 101, 113, 114, 115, 116], "240127": [58, 59], "240146": 59, "240295": 77, "240532": [58, 59], "2407": 49, "24080030a4d": 52, "240813": 66, "241049": 75, "241064": 59, "241503": 84, "2416": 49, "241609": 72, "241645": 59, "241678": 58, "241827": 59, "241962": 78, "24199": 72, "241e": 76, "242": [73, 114], "242000": 72, "242124": [71, 72], "242139": 101, "242158": [71, 72], "2424": 67, "242427": 67, "2424596822": 65, "242815": 101, "242902": 75, "2430561": 49, "243246": 75, "2438": 72, "2439": 72, "243e": 76, "244": [35, 72], "244090": 72, "244455": 75, "244622": 101, "24469564": 113, "245": [114, 115], "245062": 75, "2451": 49, "24510393": 51, "245370": 70, "245512": 75, "245531": 58, "245720": 62, "246": [47, 115], "246624": 84, "2467506": 50, "246753": 75, "246879": 75, "247": [76, 115], "247020": 60, "247057e": 75, "2471": 72, "2472": 72, "247617": 84, "247717": 72, "24774": [71, 72], "247826": 70, "247977": 58, "248171": 75, "248441": 84, "248638": 60, "249": [50, 70, 73, 115], "2491": 72, "24917": 72, "249986": 69, "25": [17, 18, 21, 22, 23, 27, 28, 29, 30, 50, 51, 52, 58, 59, 60, 62, 63, 68, 69, 70, 71, 72, 75, 78, 79, 84, 85, 86, 87, 101, 113, 116], "250": [73, 115], "2500": 72, "25000000000000006": [60, 72, 75], "250073": 72, "250210": 60, "2503": 72, "250354": 75, "250425": 60, "251": [71, 72, 77], "251412": 59, "251480": 59, "251953": 72, "252133": 72, "252253": 77, "25240463": 86, "252524": 75, "252601": 101, "253026": [58, 59], "2532": 72, "253437": 74, "253675": 71, "253724": 75, "25374": 72, "254": [72, 115], "25401679": 50, "254035": 69, "254038": 65, "254083": 59, "2543": 72, "254324": 60, "254400": 101, "255": [72, 115], "255034e": 59, "255995": 58, "256": [72, 85], "256082": 84, "256416": 75, "256567": 70, "25672": 72, "256944": 75, "256992": 72, "257019": 59, "257207": 50, "257377": 62, "257523": 58, "258083": 59, "258158": [58, 59], "2583": 72, "2584277": 87, "258522": 58, "258541e": 18, "258951": 75, "259164": 59, "259367": 84, "259395": 66, "2594": [51, 71], "259828": [58, 59], "259875": 59, "2599370": 87, "25x_3": 62, "26": [50, 51, 52, 53, 58, 59, 61, 68, 70, 71, 72, 79, 82, 84, 85, 86, 87, 101, 113], "26016": 72, "260161": [16, 84], "260211": [58, 59], "260356": 71, "260360": 75, "260762": 55, "261": 76, "2610": 72, "2613": 72, "261624": [71, 72], "261685": 72, "26175": 72, "261777": 72, "261903": 70, "2619317": 50, "262423e": 72, "262621": 70, "262829": 87, "263": [19, 72, 115], "2633": 72, "263942e": 59, "263974e": 75, "264": [114, 115], "264086": 62, "264274e": 72, "264884": 72, "265": 115, "2651": 86, "265119": 74, "2652": [52, 71, 72], "265547": 72, "265744": 69, "2658": 65, "265929": 76, "266": 115, "266147": 76, "266686": 58, "266922": 101, "267": 73, "2670691": 50, "267500": 70, "267581": 72, "267950": 75, "268": 115, "268055": 72, "268343": 69, "268628e": 59, "268942": 75, "268943": 58, "268998": 51, "269043": 75, "269112": 86, "269977": 72, "26bd56a6": 52, "26e": 51, "27": [22, 23, 27, 47, 48, 50, 51, 52, 53, 58, 59, 61, 68, 70, 71, 72, 79, 82, 84, 85, 86, 87, 101, 113, 114], "270": 115, "2700": 52, "270644": [58, 59], "271": 115, "271004": [71, 72], "271083": 72, "271183": 71, "2721118": 87, "272296": 72, "272332e": 58, "272408": 59, "272662": 72, "273": 52, "273299": 59, "273356": 60, "27371": [51, 71], "27372": [51, 71], "274": [52, 72], "2740991": 49, "274251e": 71, "274267": 70, "27429763": 86, "274793": 75, "274825": [17, 84], "27487": 72, "2754": 49, "275596": 101, "276": [52, 115], "276148": 75, "276189e": 70, "2764": 72, "276554": 73, "2766091": 51, "27713": 72, "277299": 53, "27751": 72, "277512": 59, "277561e": 70, "277968": 75, "278": [77, 115], "2780": 50, "278000": 70, "278035": 55, "278391": 72, "278434": 64, "278454": 67, "2786": 101, "278804": 59, "279": 115, "27951256e": 87, "279595": 55, "27986": 72, "279933e": 59, "28": [47, 50, 51, 52, 58, 59, 63, 68, 70, 71, 79, 84, 85, 86, 87, 101, 113, 115], "280196": 65, "280454dd": 52, "280514": 101, "280963": 74, "281": [76, 115], "281024": 75, "28111364": 51, "2815": 72, "2818": 49, "2819": 101, "282": [76, 114, 115], "282200": 65, "2825": [111, 113], "28251": 72, "282870": 72, "2830": [111, 113], "283041": 58, "283207": 58, "28326": 72, "283386": 58, "2836": 49, "2836059": 50, "28382": 72, "283974": 75, "283992": 58, "283994": 75, "283e": 76, "284": 115, "28425026": 77, "284271": 66, "284397": 116, "28452": [51, 71], "2849": 72, "284987": 72, "285": [76, 86, 115], "285001": 55, "285483": 67, "285e": 76, "286": [47, 115], "286203": 58, "286371": 58, "2865": [49, 72], "286507": 60, "286563e": 72, "286593": 72, "287041": 75, "287123": 84, "287196": 58, "287815": 77, "287926": 75, "288": 73, "28803313": 87, "288976": 72, "289": 114, "289062": 71, "289357": 59, "289440": [58, 59], "289555": 67, "29": [50, 51, 52, 58, 59, 68, 70, 71, 77, 79, 84, 85, 86, 87, 101, 113], "290": 86, "290565": 59, "290736e": 59, "290901": 55, "290987": 71, "291": [72, 76], "2910": 72, "291008": 58, "291011": 86, "291071": 75, "29107127": 75, "291405": 75, "291406": 75, "291434": 59, "291500e": [71, 72], "291517": [58, 59], "2915845": 87, "291963": 75, "292": 74, "292028": 60, "292047": 101, "292105": 75, "292302995303554": 60, "292303": 60, "2925": 52, "2927": 72, "292997": 75, "29299726": 75, "293218": 75, "293617e": 72, "294067": [58, 59], "294123": 84, "294449": 58, "2948667": 87, "295": 114, "295307": 58, "295481": 75, "29548121": 75, "295837": [53, 82, 113], "2958370000000100000100": [52, 82, 113], "2958370001000010011100": [52, 82, 113], "2958371000000010010100": [52, 82, 113], "2959553": 87, "296099": 55, "296228": 72, "2966006": 87, "296729": 70, "29678199": [80, 88], "296901": 58, "297287": [58, 59], "2973": 72, "297349": [64, 65], "297682": 75, "297687": 72, "297749": 72, "29784405": 77, "298": [26, 52], "298076": 58, "298120": 60, "298228e": 72, "299": [52, 76], "2991222": 87, "299537": 65, "299712": 64, "2999": 55, "2_": [32, 79, 102, 104, 110], "2_x": [32, 79], "2d": [88, 95], "2dx_5": [60, 75], "2e": [47, 49, 50, 51, 52, 85, 86, 88, 101, 113], "2f": 66, "2m": [102, 107, 110], "2n_t": 62, "2x": 75, "2x_0": [24, 58, 59, 64, 65], "2x_4": 62, "3": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 30, 35, 36, 37, 38, 41, 42, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 84, 85, 86, 87, 88, 101, 102, 107, 111, 112, 113, 114, 115], "30": [24, 47, 48, 50, 52, 55, 56, 57, 58, 59, 60, 61, 68, 70, 71, 72, 75, 76, 79, 84, 85, 86, 87, 101, 113], "300": [48, 57, 60, 72, 75, 81, 114], "3000": 55, "30000000000000004": [60, 72, 75], "300031": 58, "30031116e": 87, "300892e": 59, "30093956": 77, "301": 52, "301366": 101, "301371": 75, "3016": 71, "301737": 58, "30189": 72, "302149": 58, "302357": 75, "302382": 69, "302648": 70, "303007": 58, "303324": 70, "303489": 75, "303613": 75, "30361321": 75, "30383": 72, "303835": 70, "303f00f0bd62": 52, "304130": 75, "304159": 75, "304201": 62, "30527": 72, "305341": 75, "305612": 70, "305775": 75, "305b": 52, "306297": 58, "30645": 72, "30672815": 50, "306915": 70, "306963": 75, "307407": 75, "308": 72, "308568": 59, "308774": 58, "30917769": [64, 65], "309539": 69, "309772": 70, "309823e": 72, "30982972": 75, "309830": 75, "31": [50, 51, 52, 58, 59, 68, 70, 71, 72, 79, 84, 85, 86, 87, 101, 113, 116], "310000e": 72, "310145": 69, "310761": 74, "311": 76, "311253": 72, "311321": 59, "311667": 59, "311712": 64, "311869": 84, "3120": 72, "312652": 76, "313": 86, "313056": 101, "313209": 60, "313324": 72, "31337878": 72, "313535": 75, "31378": 52, "313870": 67, "314": 87, "3141": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 50, 52, 53, 70, 80, 82, 84, 85, 88, 101, 113], "314247": 78, "314341": 58, "3146": 18, "314625": 59, "314651": 64, "31476": [71, 72], "315031": 78, "315036": 58, "3151": 72, "315155": 59, "315290": [64, 65], "315310": 58, "315769e": 58, "316": 52, "316193": 75, "31632": 72, "316407": 86, "316540": 70, "316717": [58, 59], "316826": 58, "316863": 59, "317394": 62, "317487": 75, "317607": 75, "318": 52, "318000e": 72, "318438": 72, "318552": 72, "318584": 101, "318753": [64, 65], "319": 52, "319100": [64, 65], "319420": 67, "319759": 75, "319850": 75, "32": [15, 50, 51, 52, 58, 59, 68, 69, 70, 71, 72, 79, 84, 85, 86, 87, 88, 101, 113], "320": 72, "320314": 71, "320633": 60, "321": 73, "3212797": 87, "321686": 101, "322186e": 58, "32236455588136": 61, "322404": 77, "322751": 59, "3234": 72, "323636": 71, "323679": 70, "324": [51, 72], "324518": 74, "32458367": 50, "3245837": 75, "325": 73, "325056": 75, "325090": 72, "325486": 58, "325599": 58, "326": 76, "326148": 59, "326721": 59, "326740": 75, "326871": 78, "3268714482135234": 78, "327257": 58, "327803": 84, "327958": 55, "328471": 58, "329339": 61, "32950022e": 87, "33": [50, 51, 52, 58, 59, 64, 68, 69, 70, 71, 72, 79, 84, 85, 86, 87, 101, 113, 114, 116], "3300": [51, 71], "330068": 58, "330100": 58, "330143": 75, "33014346": 75, "330163": 59, "330285": [58, 59], "3304269": 50, "330615": 75, "330731": [17, 84], "331365": 64, "331521": 75, "331602": 72, "33175566": 75, "331756": 75, "3318138": 87, "332502": 59, "332782": [17, 84], "3329": 72, "332996": 70, "3333": [48, 50, 57, 84, 85, 86], "3333333": 52, "33335939e": 87, "3335": 72, "333581": 71, "333655": 58, "333704": 59, "3337697": 87, "333955": 59, "334": 51, "334750": 60, "33500": 72, "335176": 72, "3352": 87, "335446": 55, "335609e": 75, "3358": 87, "335846": 75, "335853": 72, "336": 73, "336382": 59, "336461": 72, "336612": 62, "33716612": 87, "337380": 75, "3376": 49, "337619": 61, "338": 77, "33849": 72, "3385752": 87, "3386": 87, "338603": 58, "338775": 60, "338908": 60, "339269": 77, "33928": 72, "339443": 59, "339570": 75, "339855": 87, "339875": [64, 65], "34": [48, 49, 50, 51, 52, 58, 59, 65, 68, 70, 71, 72, 77, 79, 84, 85, 86, 87, 101, 116], "340": [51, 72], "340029": 59, "340142": 86, "340235": 67, "340274": 77, "341336": 13, "341472": 69, "341755e": 58, "3420": 72, "342117": 67, "342362": 55, "342632": 69, "342675": 50, "34287815": 77, "342989": 72, "342992": 70, "343": [72, 76], "3431": 87, "343639": 84, "343685": 58, "34375": 71, "343828": 58, "344212": 116, "344440": 84, "344505": [71, 72], "344640": 75, "344787": [58, 59], "344834": 62, "3449337": 87, "345065e": 72, "345381": 60, "3453813031813522": 60, "3454": 72, "345852": 59, "345903": 75, "345989": 58, "346107": 71, "346206": 75, "346238": 77, "346269": 59, "346678": 74, "346964": 58, "347310": [17, 84], "347696": 60, "34769649731686": 60, "347929": 72, "348": 76, "348319": 59, "348351": 87, "34858240261807": 61, "348617": 75, "348622": 76, "348700": 59, "3488357": 87, "348980e": 59, "3492131": 49, "349383": 70, "34943627": 68, "349638": 59, "34967621": 50, "349772": 65, "35": [51, 52, 58, 59, 60, 70, 71, 72, 73, 75, 84, 85, 86, 87, 101, 102, 107, 116], "3500000000000001": [60, 72, 75], "350165": 85, "350208": 58, "350518": 75, "350712": [64, 65], "35077502": [102, 107], "351220": 59, "351629": 72, "351766": 74, "352": [51, 70], "352250e": 71, "352259e": 72, "3522697": 50, "3526772": 87, "35292": 72, "352990": 72, "352998": 72, "353105": 18, "353412": 75, "35341202": 75, "35365143": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "353748e": 75, "3538": 49, "354": 72, "354188": 62, "354371": 75, "354688": 14, "355065": 55, "355209": 75, "355627": 84, "355651": 59, "356136e": 72, "356167": 65, "356183": 72, "35620768e": 87, "3564": 72, "3565": 72, "3568": 86, "357": 72, "357170": 58, "35731523": 86, "358158": [71, 116], "358289": 70, "358395": 77, "358799": 101, "359": [76, 116], "359100": 72, "359161e": 58, "359229": 55, "3593": 77, "359307": 59, "35th": 114, "36": [51, 52, 58, 59, 70, 71, 84, 85, 86, 87, 101, 116], "360004": 75, "360065": 101, "360249": 66, "360475": [58, 59], "360572": 59, "360655": 72, "360683": 60, "360801": 60, "361": 76, "361518": 60, "361518457569366": 60, "361521": 14, "361623": 67, "3619201": 25, "362157": 58, "36231307e": 87, "3631679": 87, "363276": 50, "364221": 58, "3643": 101, "364595": 50, "3647": 52, "364800": 75, "36501": 72, "365551": 59, "36557195e": 87, "36566025e": 87, "366": 72, "36616": 72, "366310": 58, "366529": 74, "366718627": 50, "366950": 58, "367": [35, 76], "367181": 58, "367323": 75, "367366": 67, "367398": 69, "367571": 60, "367625": 75, "368152": 70, "3682": [51, 71, 72], "368324": 70, "368499": 60, "3684990272106954": 60, "368577": 84, "369556": 60, "3696": 77, "369796": 75, "369869": 71, "369981": 70, "37": [51, 58, 59, 67, 70, 71, 72, 73, 84, 85, 86, 87, 101, 116], "3701026": 87, "370254e": 71, "3702770": 50, "370736": 70, "3707775": 50, "370908": 58, "3710": 72, "371357": [71, 72], "371429": 60, "371850e": 59, "372": 114, "37200": [71, 72], "372097": 60, "3722": 72, "37231324": 79, "3724": 72, "372427": 59, "3727679": 50, "373218e": 69, "3732418": 87, "373451": 84, "3738573": 50, "374": 47, "374364": 75, "37436439": 75, "3745": 72, "374821e": 72, "374862": 58, "374917e": 58, "375081": 72, "375274": 58, "375465": 75, "375621": 69, "375844": 69, "3766": 67, "376617": 67, "376760": 59, "376806": 59, "3770548": 87, "377060": 72, "377147": 84, "377311": 75, "377669": 59, "378351": 11, "378588": 58, "378596": 70, "378688": 75, "378727": 58, "378834": 75, "3788859": 50, "379": 114, "379038": 75, "37939": 72, "379614": 75, "379626": 58, "379981e": 59, "38": [52, 58, 59, 71, 84, 85, 86, 87, 101], "380": 116, "3800694": 50, "380837": [71, 72], "3808679": 87, "381": 76, "381072": 75, "381603": 58, "381685e": [71, 72], "381689": 75, "3817": 72, "382286": 72, "382582e": 6, "382872": 60, "383297": 75, "383531": 69, "384": 72, "384443": 59, "384677": 55, "384777": 72, "384865": 59, "384928": 58, "3851": 72, "385160": 59, "385240": 101, "385917": 70, "386": [52, 72], "386102": 60, "386502": 72, "386831": 55, "386988": 61, "387": 52, "3871": 49, "387426": 75, "387780": 75, "388026": 58, "388071": 75, "388185": 55, "38818693": 87, "388216e": 85, "388668": 75, "38866808": 75, "388871": 72, "389": 52, "389126": 86, "389164": 69, "389566": 74, "38973512e": 87, "389755": 58, "38990574": 87, "39": [47, 49, 50, 51, 52, 53, 55, 58, 59, 61, 65, 66, 68, 70, 71, 72, 77, 78, 79, 84, 85, 86, 87, 101], "39010121e": 87, "390379": 75, "391014151719202931345058617879809096100": 87, "391377": 78, "392128": 59, "392242": 66, "39236801": 68, "392400": 72, "392623": 59, "392752": 61, "392833": 77, "392864e": [71, 72], "392917": 58, "393604": 60, "393654": 55, "394226": 59, "39425708": 50, "3946044": 87, "395076e": 72, "395136": 70, "395268": 84, "395569": 58, "395603": 58, "3958": 86, "395889": 72, "396": [35, 86], "39611477": 51, "396173": 64, "39621961e": 87, "396300": 64, "3964": 72, "396531": 72, "396985": 70, "396992": [58, 59], "397140": 60, "397155": 59, "39727": 72, "397313": 49, "397536": 69, "397578": 66, "397811": 77, "398": [82, 113], "398166": 55, "3985": 72, "398770": 75, "398999": 84, "399": 51, "399056": 75, "399223": 62, "399343e": 58, "399355": 62, "399679": 86, "399692": 75, "399858": 78, "3cd0": 52, "3dx_1": [60, 75], "3e1c": 52, "3ec2": 52, "3f5d93": 73, "3x_": 75, "3x_4": [60, 75], "4": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 22, 23, 27, 32, 35, 36, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 84, 85, 86, 87, 88, 101, 102, 107, 113, 115], "40": [50, 58, 59, 60, 61, 69, 71, 72, 75, 79, 82, 84, 85, 86, 87, 101, 102, 107], "400": 70, "4000000000000001": 85, "40000000000000013": [60, 72, 75], "400113": 67, "40029364": [102, 107], "4007611": 87, "400823": 75, "400855956463958": 60, "400856": 60, "400905": 55, "401": [19, 116], "401247": [88, 101], "40127723e": 87, "401690e": 59, "401931": [64, 65], "402077": 72, "402113": 101, "402301e": 85, "402619": 15, "402902": 72, "403": 76, "403425": 75, "403626490670169": 80, "4036264906701690": 80, "403626491": 80, "403715": 6, "403771948": 88, "4039": 49, "404267": 58, "404300": 55, "404318": 49, "404411": 58, "40452": 72, "404550": 74, "405050": 59, "405203": 62, "405374": 72, "40583": 49, "405890": [17, 84], "406": 47, "406285": 75, "406446": 60, "4065173": 87, "40676": 49, "407": 76, "40732": 67, "407558": 58, "407565": 58, "408476": [102, 107], "40847623": [102, 107], "408479": 70, "408509": 59, "408539": 75, "408565": 75, "409154": 49, "4093": 77, "409328": 72, "409395": 75, "409746": 60, "409848": [58, 59], "41": [58, 59, 71, 72, 84, 85, 86, 87, 101], "410100": 58, "410393": 60, "410667": 84, "410681": 62, "410682": 58, "410795": 70, "41093655": 87, "411146e": 59, "411190": [58, 59], "411291": 74, "411295": 75, "411304": [58, 59], "411447": 72, "411582": 75, "411768": 59, "411793": 73, "412004": 64, "412127": 75, "412304": 78, "412477": 62, "412653": 70, "412714": 60, "412726": 59, "412941e": 59, "413247e": 58, "41336": 85, "413376": 86, "41341040": 50, "413608": 75, "414": 76, "414073": 12, "414533": 59, "41525168e": 87, "415375": 58, "415556": 84, "41566": 86, "415812": 116, "4159296": 87, "415988": 72, "416052": 55, "416132": 59, "4166": 72, "4166667": 52, "416757": 75, "416899": 58, "416919": 59, "416e": 76, "417640": 58, "417727": 71, "417736": 69, "417767": [64, 65], "417834": 55, "41798768e": 87, "418": 35, "418056": 75, "41805621": 75, "4183649": 87, "418400": 67, "418741": 55, "418806e": 60, "418969": 84, "41918406e": 87, "419371": 75, "419871": 55, "41989983e": 87, "4199952": 50, "41e5": 52, "42": [8, 9, 27, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 72, 74, 75, 77, 78, 79, 84, 85, 86, 87, 101, 114], "4200": 72, "420316e": 72, "420608e": 77, "42073312": 50, "420967": 60, "421083": 49, "4211349413": 50, "421163": 58, "421200": 78, "421297e": 59, "421357": [64, 65], "421576e": 72, "421793": 77, "421919": 72, "422007": 77, "422266": 72, "422293e": 84, "422325": 60, "422591": 59, "42338": 72, "4235164": 87, "4235839": [64, 65], "42388745": 79, "423921e": 84, "423951": 49, "424108": 60, "424127": 87, "42412729": 50, "424292": 58, "424328": 75, "424651": 86, "424717": 60, "424748": 78, "425": 70, "425103": 49, "425208": 72, "425325": 67, "425493": 49, "42550": 72, "425636": 67, "426055": 49, "426540": 70, "426540301": 50, "426736": 72, "427": 72, "427486": [58, 59], "42755087": 77, "427551": 77, "427573": 70, "427654": 67, "427725": 75, "428": [101, 116], "428046": 74, "42811700": 116, "428255": 75, "428411": [71, 72], "428467": 75, "4284675": 75, "428771": [17, 84], "4289717": 87, "4290": 49, "429057": 59, "429230": 58, "429705": 58, "42ba": 52, "43": [51, 55, 58, 59, 84, 85, 86, 87, 101, 116], "430298e": [71, 72], "430595": 59, "430608": 58, "431061e": 58, "4311947070055128": 85, "431253": 69, "431306": 75, "431701914": 111, "431998": 55, "432130e": 71, "432300e": 75, "43231359e": 87, "432707": 76, "43294": 52, "432f": 52, "433": [47, 52, 76], "433221": 60, "4336": 72, "4337041": 87, "43374433": 79, "433750": 58, "433753": 69, "4339": 49, "434054e": 67, "434121": 69, "434535": 75, "43453524": 75, "435": 52, "43503345": 86, "43511": 72, "435401": 70, "4357": 72, "435927": 72, "435967": 70, "43597565": 75, "435976": 75, "436": [52, 72], "436016": 69, "43627032": 61, "436327": 72, "436394": 69, "436693": 73, "436764": 76, "436806": 72, "436817": 69, "437667": 71, "437924": 72, "438": 70, "438219": 75, "438289": 72, "438569": 72, "438578e": 72, "43883": 65, "438834": 59, "4389": 72, "438960": 70, "4390992": 87, "439401e": 59, "439541": [71, 72], "439675": 76, "439699": 55, "43989": 84, "439958": 69, "43f0": 52, "44": [55, 58, 59, 61, 84, 85, 86, 87, 101], "440320": 72, "440605": 85, "440747": 58, "440a": 52, "441153": 75, "441209": 75, "441219": 64, "44124313": 86, "441282": 58, "4416552": 50, "441849": 58, "442": 47, "443016": 60, "443032": 71, "44312177": 51, "443686": 75, "4437": 72, "443e": 76, "444046": 72, "4444": [48, 50, 57, 86], "444500": [71, 72], "444850": 72, "4449272": 72, "445": [76, 116], "445476": 58, "44563945e": 87, "445736": 73, "4461928741399595": 60, "446193": 60, "4462": 52, "44647451": 77, "44713577e": 87, "447492": 72, "447624": [58, 59], "447706": 60, "447849": 61, "448": 72, "448252": 59, "448456e": 59, "448569": 58, "448587": 60, "448745": 75, "448842": 59, "4489": 72, "44890536": 87, "448923": 66, "449107": 9, "449150": [17, 84], "44950": 72, "449677": 67, "44fa97767be8": 52, "45": [58, 59, 60, 64, 66, 69, 72, 75, 84, 85, 86, 87, 101], "4500": 71, "45000000000000007": [60, 72, 75, 85], "450031": 69, "450152": 70, "450812e": 59, "450870601": 50, "451312e": 58, "452": 52, "452091": 72, "452114": 84, "452488701": 50, "452489": 70, "452623": 59, "453": 52, "453279": 58, "4535": 72, "4539": 52, "454081": 72, "454397": 75, "454406": 55, "45467447": 87, "455": 52, "45500": 72, "455078": 60, "455091": 59, "455107": 60, "455120": 75, "4552": 52, "455293": 60, "4552b8af": 52, "455448": 77, "455672": 72, "455981": 102, "456370": 70, "456458e": 58, "4566031": 101, "45660310": 101, "4567": 77, "4568530": 87, "456892": 60, "457088": 75, "457667": 72, "458114": 72, "4581821262830384349596265717577858893": 87, "458182126283038434959626571757785889339101415171920293134505861787980909610016232425273240465254555760667376839192941261133363739424547485663648182848999": 87, "458182126283038434959626571757785889371213223541445153676869707274868795979816232425273240465254555760667376839192941261133363739424547485663648182848999": 87, "45818212628303843495962657175778588937121322354144515367686970727486879597983910141517192029313450586178798090961001261133363739424547485663648182848999": 87, "45818212628303843495962657175778588937121322354144515367686970727486879597983910141517192029313450586178798090961001623242527324046525455576066737683919294": 87, "458307": 104, "458420": 72, "4584447": 50, "458784": 58, "458814": 67, "458855": 51, "4592": 50, "459200": 70, "459383": 60, "459418": 59, "459436": 69, "4595072": 87, "45957837": 87, "459760": 72, "459812": 60, "46": [58, 59, 66, 68, 84, 85, 86, 87, 101], "460": [47, 72], "4601": 72, "460207": [58, 59], "460218": 60, "460289": 75, "460744": 71, "4610": 116, "461227e": 58, "461412": 84, "461629": 78, "462319": 73, "462451": 60, "462567": 59, "462979": 58, "463325": 75, "4634": 72, "463418": 78, "463668": 72, "463766": 65, "463857": 72, "463903": 59, "463b": 52, "464": 86, "464076": 60, "464284": 70, "46448227": 87, "464668": 13, "465": 55, "46507214": 77, "465424": 69, "465649": 78, "465730": 78, "4659651": 80, "465965114589023": 80, "4659651145890230": 80, "466047": 75, "46618738": 87, "466440": 60, "466756": 75, "467": 72, "46709481": 87, "46722576e": 87, "467613": 70, "467613401": 50, "467681": [58, 59], "467770": 60, "468072": 59, "468075": 75, "46807543": 75, "46811985": 75, "468120": 75, "468406": 72, "468907": 55, "468919": 72, "468d": 52, "469": 52, "469474": 78, "469676": 55, "469825": 60, "469895": 59, "469905": 59, "47": [51, 55, 58, 59, 61, 71, 73, 77, 84, 85, 86, 87, 101, 115], "470055": 59, "470904": 58, "471": 55, "471435": 76, "471622": 58, "472": 72, "47222159": 79, "472255": 72, "472699": 59, "472891": 75, "472e": 52, "473099": 60, "47319": 86, "47419634": 113, "474214": [64, 65], "474731": 84, "475304": 72, "475517": 69, "475569": 58, "475e": 76, "4765649": 87, "476856": 60, "477130": [58, 59], "477150": 75, "477247": 59, "477357": 76, "477474": 70, "47759584": 87, "47761563": 61, "478032": 72, "478059": 59, "478064": 59, "4781": 72, "47857478": 87, "479655": 69, "47966100e": 87, "479722": 59, "479860": 72, "479876": [64, 65], "479882": 59, "479928": 75, "47be": 52, "48": [52, 55, 58, 59, 65, 71, 72, 84, 85, 86, 87, 101], "480": 55, "480133e": 75, "480199": 67, "48029755": 77, "480579": 59, "48069071": [80, 88, 101], "480691": [88, 101], "480800e": 75, "481172": 75, "481218": 72, "481399": [71, 72], "481705": 86, "481713": 67, "481761e": 72, "482": [52, 55], "482012": 64, "4820241": 87, "482038": 60, "48208358": 75, "482084": 75, "482179": 58, "482251": 15, "482461": [102, 107], "48246134": [102, 107], "482483": 75, "482616": 69, "482790": 62, "482898e": 59, "48296": 77, "483": [76, 86], "48315": 77, "483186": 62, "483192": [71, 72], "48331": 77, "4835": 72, "483711": 75, "483717": 60, "48390784": 86, "48404": 50, "484303": 59, "4845": 72, "484640": 75, "4849": 52, "485": [52, 72], "485197": 58, "48550": 78, "485617": [71, 72], "485812e": 72, "48583": [71, 72], "485871": 65, "486": [28, 72], "486178e": 58, "486202": 60, "486532": 75, "48661": 72, "487": [55, 72], "487467": 72, "487524": 67, "487641e": 75, "487793": 59, "487872": 56, "488394": 58, "488460": 72, "488485": 72, "48873663": 61, "488811": 75, "488909": [71, 72], "488982e": 60, "4895498": 75, "489550": 75, "489699": 60, "489951": 59, "49": [52, 55, 58, 59, 84, 85, 86, 87, 101], "490000e": 72, "490070931": 50, "490488e": 71, "490504e": 72, "490700": 75, "490896": 55, "490941": 72, "491": 47, "491034": 58, "491245": 70, "49135": 18, "4915707": 86, "492": 72, "4923156": 80, "49231564722955": 80, "492315647229550": 80, "492417e": 86, "492637": 66, "492656": 59, "49270769e": 87, "493": [76, 86, 114], "493102e": 69, "493144": 78, "493195": 67, "493219": 75, "493313": 72, "493325": 8, "493426": 76, "494": 76, "494089": 59, "494129": 75, "494324": 70, "494324401": 50, "495": 74, "495108": 69, "49530782": 50, "495657": 60, "495752": 75, "49594264": 87, "49596416e": 87, "496": 74, "49650883": 77, "496551": 75, "496714": 78, "496777": 116, "49693": 85, "497": 74, "497168": 69, "497422": 59, "497539": 73, "497655": 9, "497674": 61, "497964": 84, "498": 74, "498122": 67, "498141": 73, "4981507": 87, "498286": 69, "498921": 75, "498979": 72, "498992": 58, "498f": 52, "499": [72, 74, 82, 113], "499000e": [71, 72], "499776": 72, "49d4": 52, "4a53": 52, "4b8f": 52, "4dba": 52, "4dd2": 52, "4e": [50, 51], "4ecd": 52, "4fee": 52, "4x": 75, "4x_0": [24, 58, 59, 64, 65], "4x_1": [24, 58, 59], "5": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 84, 85, 86, 87, 88, 94, 101, 102, 107, 112, 113, 115], "50": [17, 50, 52, 55, 60, 62, 65, 68, 69, 71, 72, 73, 75, 84, 85, 86, 87, 101], "500": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 25, 26, 30, 39, 48, 52, 53, 57, 58, 59, 64, 65, 68, 71, 74, 76, 77, 81, 82, 84, 85, 86, 88, 101, 102, 107, 113, 116], "5000": [36, 58, 59, 60, 75], "50000": 70, "500000": [71, 72], "5000000000000001": [60, 72, 75], "500084": 75, "500267": 66, "5003517412": 50, "500517": 75, "50093148e": 87, "501021": 72, "501047e": 58, "501859": 73, "501983": 75, "502005": 84, "502016": 69, "502084": 86, "502205": 58, "502461": 73, "502494": 60, "5025850": 50, "502595": 59, "502612": 75, "502901": 59, "502995": 75, "503": 35, "503374": 69, "503504": 85, "503511": 72, "503700": 55, "50398782e": 87, "504286": 70, "5042861": 50, "5043049": 87, "504548e": 59, "5050973": 50, "505264": 58, "505353": 59, "506050": 58, "506591": 73, "506644": 58, "506659": 72, "506687": 72, "50672034": 50, "506900e": 75, "506903": 60, "507": 76, "507285": 67, "50768b": 73, "508153": 74, "508433": 58, "508459": 70, "5085": 72, "508947": 86, "509059": 72, "509196": 75, "509461": 75, "50967": 78, "5097": 78, "5098": [53, 82, 113], "509853": 75, "5099": [52, 53, 82, 113], "509951": 60, "509958": 70, "51": [49, 51, 52, 55, 64, 69, 84, 85, 86, 87, 101, 115], "510000e": [71, 72], "510121": 58, "510385": 70, "510555": 55, "51079110": 50, "511257": 69, "511515": 72, "511540": 72, "5115547": 80, "5115547181877": 80, "51155471818770": 80, "511665": 58, "511668": 78, "5116683753999614": 78, "511862": 75, "512": 70, "512108": 75, "512149": 75, "51214922": 75, "51243406e": 87, "512519": 70, "512572": 75, "512672": [86, 102, 107], "5131": 71, "513222": 67, "513624": 84, "513992": 75, "514": 52, "514173": 59, "514545": 72, "515031": 58, "515338e": 58, "515358": 60, "5154": 72, "5154789948092002": 70, "5155": 52, "515672": 59, "516": 52, "516125": 60, "516222": 75, "516242": 59, "516255": 75, "516256": 75, "516528": 75, "516797": 59, "517": [52, 70], "517279": 59, "5175": 72, "517753": 58, "517798": 55, "518175": 70, "518375": 59, "518446": 72, "518478": 55, "518610": 86, "518782": 72, "518846": 70, "518854": 55, "51966955": 50, "519710": 75, "52": [49, 52, 66, 69, 71, 76, 84, 85, 86, 87, 101], "520": 72, "520415": 58, "520641": 77, "520930": 60, "521002": 60, "521233": 55, "521611": 59, "521632": 58, "521788": 58, "522753": 14, "522835": 62, "523030": 78, "523163": 60, "5232": 68, "52343523e": 87, "523794e": 75, "523807": 74, "523977545": 50, "52424539": 50, "524657": 75, "524934": [58, 59], "5250": 72, "525064": 55, "52510803": 51, "5251546891842586": 78, "5255": 52, "525722": 58, "52590": [51, 71], "526": [70, 87], "526532": 72, "526582": 67, "526769": [58, 59], "526984": 59, "527226": 58, "52732": 85, "527452": 59, "527540": 58, "528381e": 79, "528580": 75, "528763": 59, "52892": 73, "528937": [64, 65], "528996901": 50, "528997": 70, "529": 70, "529405": 49, "529468": 84, "529782": 49, "53": [49, 52, 55, 66, 82, 84, 85, 86, 87, 101, 111, 114], "530659": 66, "530793": 58, "530940": 75, "53094017": 75, "531": 52, "531223": 60, "531594": 72, "53209683": 86, "532266": 60, "53257": 85, "532738": 75, "53273833": 75, "532751": 64, "5329": 72, "533": 76, "533283": 86, "533489": 62, "533900": 75, "534139": 55, "5346": 52, "535179": 75, "535318": 75, "535609": 72, "535718e": 72, "53606675": 75, "536067": 75, "536143": 72, "536746": 75, "536778e": 59, "536798e": [71, 72], "537240": 75, "53724023": 75, "53791422": 86, "538": 52, "538013": 72, "538105": 59, "5382": 77, "5389208": 87, "538937": [71, 72], "539455": 75, "539475": 75, "53947541": 75, "539491": [64, 65], "539767": 60, "54": [49, 51, 52, 61, 76, 81, 84, 85, 86, 87, 101, 115], "540240": 72, "540375": 67, "5405": 67, "540549": 67, "5408": 49, "541": 76, "541060": 67, "541159": 75, "54163": 77, "5416844": 80, "541684435562712": 80, "541821": 72, "541990": 72, "542": 76, "542136": 58, "542159": 59, "542170": 59, "542333": 72, "542446": 65, "542451": 75, "542560": 78, "542584": 60, "5425843074324594": 60, "542647": 75, "542648": 84, "542671": 70, "542883": [102, 107], "5428834": [102, 107], "542919": 84, "542989": 75, "543": [70, 72], "543052": 55, "543075": 60, "5431279": 87, "543136": 60, "543380": 70, "5434231": 80, "543423145188043": 80, "5436005": 50, "543691": 59, "543764": 65, "54378": 77, "543832": 75, "544097": 75, "544383": 78, "544555": 70, "544669": 64, "54483": [88, 101], "5448331": [88, 101], "54517706e": 87, "545492": 55, "54550506": 76, "545605e": 75, "545919": 72, "545930": 84, "546294": 72, "5467606094959261": 60, "546761": 60, "546953": 59, "547039": 58, "54716": 77, "547324": 59, "547431": 74, "5476": 72, "5479": 72, "547909": 72, "548": 73, "549109e": 72, "55": [51, 52, 60, 71, 72, 75, 84, 85, 86, 87, 101], "5500000000000002": [60, 72, 75], "550242": 69, "551317": 59, "551586928482123": 60, "551587": 60, "551686": 60, "55176": 85, "5518": 72, "552": 72, "552058": 77, "552508": 72, "552694e": 58, "552727": 70, "552776": 75, "553004": 55, "55307": 85, "553522": 59, "553754": 84, "553878": [16, 84], "553916": 72, "554076": 60, "554793e": 87, "555": 70, "555137": 59, "555150": 72, "555445": 74, "555498": 75, "5555": [48, 57], "555536": 58, "555949e": 72, "555954": 72, "556191": [58, 59], "556792": 75, "55729546": 87, "5574dcd4": 52, "557595": 70, "557731": 74, "557999": 70, "558134": [58, 59], "5584": 70, "5585": 70, "55863386": 86, "558655": 60, "5589": 70, "559": 116, "5590": 70, "559144": 60, "559186": 60, "5592": 70, "559394": 75, "559522": 75, "559592e": 58, "559680": 72, "55dc37e31fb1": 52, "55e": 51, "56": [52, 81, 84, 85, 86, 87, 101, 111, 114], "560135": [88, 101], "56018481": 75, "560185": 75, "5602727": 61, "560530": 59, "560689": 49, "560723": 66, "561348": 59, "5616": 71, "561711": 72, "561785": 86, "561883": 15, "562013": 75, "56223": 77, "562288": 78, "562390": 84, "562452": 69, "562518": 72, "5625561": 49, "562712": [58, 59], "563067": 76, "563374e": 60, "563503": 75, "563528": 72, "563563": 67, "563673": 72, "56387280e": 87, "56390147e": 87, "564045": 75, "564073": 72, "5641": 72, "564142": 60, "564232": [58, 59], "564451": 59, "564577": 72, "565": 86, "565066": 60, "565373": 58, "566": 78, "566024": 75, "566091": 72, "566388": 58, "567004": 77, "567215": 69, "567343": 72, "567364": 59, "567529": 75, "567695": 58, "567945": [64, 65], "568287": 67, "569315e": 59, "569449": 84, "569540": 59, "569590": 69, "56965663": 75, "569657": 75, "569911": 50, "5699994715": 50, "57": [52, 76, 84, 85, 86, 87, 101, 116], "570038": 60, "5700384030890744": 60, "570111": 74, "5702": 72, "570486": 49, "570562": 49, "570722": 113, "570936": 58, "571778": 49, "5718": 72, "5722": 71, "572408e": 59, "57245066": 75, "572451": 75, "572991": 59, "573700": 62, "574": 52, "574160": 67, "5745748": 87, "5748": 85, "5748071": 87, "57496671": 50, "575": 20, "575381": 71, "57572422": 77, "575810": 58, "57585824": 77, "57592948e": 87, "57599221": 77, "575e": 76, "576": 52, "5763996": 50, "57643609": 77, "577": 52, "5770": 71, "57715074": 50, "577271": 70, "577273": 58, "5776971": 77, "57775704": 77, "577807": [58, 59], "577813": 58, "577e": 76, "578081": 72, "578307": 75, "578523": 70, "578557": 59, "578846e": 60, "579125": 71, "57914935": 51, "579197": 67, "579213": 78, "579238": 60, "579322e": 71, "579875e": 58, "57e": 51, "58": [21, 51, 71, 78, 84, 85, 86, 87, 101, 115], "5800": 72, "58000": 71, "5804": 52, "580414": 78, "580751": 71, "580853": 58, "580922": 64, "5811823": 87, "581655": 72, "581827": 69, "581849": 59, "582031": 71, "582146": 59, "58241568": 87, "582761": 60, "582991": 71, "583034": 64, "583195": [58, 59], "583201": 59, "5833333": 52, "583534": 75, "583692": 69, "584012": 72, "584057e": 58, "584742": 65, "584849": 60, "584928": 58, "584942e": 70, "5852": 72, "585426": 87, "585479": 67, "585793": 60, "586362": 75, "5864": 49, "5866": 72, "586719": 60, "586719493648897": 60, "586794": 58, "5868472": 50, "586921": 69, "587135": 59, "587292": 72, "588": 72, "58812": 85, "5882": 71, "588233": 58, "588364": 84, "588854": 58, "589147e": 69, "589248": 77, "589440": 60, "589958": 59, "59": [59, 84, 85, 86, 87, 101], "590320": 62, "5905": 71, "590736": 75, "590813": 75, "590904": 59, "590911": 60, "590991": 60, "591080": 62, "591411": 64, "591441": 6, "591652": 71, "591678": 71, "591782": 75, "59199423e": 87, "592186": 59, "5922610": 87, "592681e": 60, "59307502e": 87, "593648": 85, "593981": 84, "594": 20, "594316e": 75, "595353": 60, "596": 72, "596069e": 72, "596270": [64, 65], "5964": 68, "596460": 59, "596758": 58, "597": [51, 87], "597098": 72, "597923": 72, "598178": 72, "59854797": 86, "5985730": 51, "59861": 72, "598761e": 59, "599": 87, "599297": [84, 85, 86], "5cb31a99b9cc": 52, "5d": [60, 75], "5x_2": 62, "5x_3": 62, "5z_i": 75, "6": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 27, 28, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 84, 85, 86, 87, 88, 101, 102, 107, 111, 113, 114, 115], "60": [50, 60, 61, 72, 73, 75, 79, 84, 85, 86, 87, 101, 114], "600": [70, 73], "6000": 72, "6000000000000002": [60, 72, 75], "600000e": 72, "600195": 58, "600254": 74, "600694": 86, "600776": 55, "601": 51, "601061": 60, "601598": 70, "601783e": 59, "601984": 59, "602079": 65, "602168": 60, "602322": 84, "602386e": 58, "602492": 58, "602587": 75, "602628": 60, "6026665": 87, "6029": 72, "603": 116, "604016": 72, "604111": 72, "6044970": 87, "604603": 9, "604825": 72, "604841": [71, 72], "605": 72, "605195": 65, "606034": 75, "606129": 75, "606342": 60, "606759": 72, "6068": 50, "606800": 70, "606954": 60, "607": 47, "607264": 58, "6075": 116, "607600": 72, "607900e": 59, "608": [63, 76], "608392": 75, "60857": 49, "608818": 77, "609": 76, "609522": 69, "609575": 86, "61": [55, 84, 85, 86, 87, 101, 115], "610318": 55, "611": 116, "6110": 72, "611269": 70, "61170069": 76, "611859": 65, "612": 76, "612104": 73, "612246": 67, "612792": 72, "61290312": 87, "613244": 59, "6133": 51, "613314": 60, "613408": 75, "613498": 72, "613574": 66, "613622": 59, "613691": 86, "614": 76, "61404894": 86, "614188": 70, "614678": 72, "615": 55, "615498": 6, "615863": [64, 65], "616372": 71, "616617": 59, "61669761": [102, 107], "616698": [102, 107], "616828": 72, "617": 70, "61728": 84, "617283": 72, "6173": 52, "61771229": 76, "617877": 75, "618069": 71, "61810738": 51, "618574": 59, "618776": 61, "618881": 59, "619": 76, "619128": 59, "619294": 55, "619351": [58, 59], "619390": [58, 59], "619454": 62, "619613": 71, "619903": 59, "61e": [51, 116], "62": [6, 55, 65, 66, 84, 85, 86, 87, 101], "620156": 75, "620874e": 86, "620995": 79, "621094": [71, 72], "621318": 75, "62131806": 75, "621359": 84, "621490": 75, "6215": 71, "622": [72, 76], "622153": 72, "622272": 55, "6224": 50, "623024": 60, "623173": 58, "624": 70, "6240": 77, "62403053": 61, "6243811": 50, "624535": 85, "624764": 59, "624798": 71, "624818": 59, "624919": 72, "624988": 72, "625": [50, 70], "625159": 66, "625477": 75, "625766": 64, "625767": 58, "625891": [64, 65], "626433": 75, "6266": 72, "626633": 59, "627505": [64, 65], "627560": 75, "627564": 60, "627588e": 72, "628": 76, "628069": 70, "62929779": 87, "629346": 72, "6294388": 87, "629549": 59, "629595": 18, "629740": 58, "629e": 76, "63": [50, 55, 70, 73, 84, 85, 86, 87, 101, 114, 115], "630150e": 75, "630880": 76, "630914": 66, "631083": 59, "63117637": 86, "631333": 75, "6318": [71, 116], "632058": 70, "63245862e": 87, "632747e": 75, "632958": 74, "6330631": 101, "633433": 70, "634": 76, "63407762": 116, "634078": [71, 116], "634577": 101, "63499": 72, "635": 35, "635000e": [71, 72], "635199": [71, 72], "635768": 58, "63593298": 86, "636048": 86, "636453": 13, "636575": 60, "637326": 75, "6379": 71, "638264": 75, "638461": 69, "638488": 66, "639": 71, "639135": 70, "63916605": 51, "639345": 72, "639580": 59, "639603": 59, "64": [55, 65, 71, 72, 76, 84, 85, 86, 87, 101, 113], "640": 72, "640900": 72, "641528": 75, "641547": 75, "64154727": 75, "64197957": 75, "641980": 75, "642": 76, "6420": 72, "642016": 75, "642329": 55, "64269": 77, "643133": 72, "64340": 77, "643512": 60, "643752": 75, "643939": 55, "644113": 84, "644371": 59, "644665": 60, "64476745e": 87, "644799": 62, "644985": 58, "645": 72, "645583": 55, "64579": 49, "6458": 50, "645800": 70, "646117": 59, "646937": 62, "647002": 72, "647004": 86, "647010": 72, "647196": 62, "64723": 77, "647254e": 58, "647689": 78, "647864": 84, "647873": 75, "64797": 77, "648": 71, "648355": 58, "648690": 59, "648769": 59, "649": 114, "649158": 75, "649514": 58, "649738": 58, "65": [55, 60, 66, 72, 75, 76, 84, 85, 86, 87, 101], "650": [63, 86], "6500000000000001": [60, 72, 75], "650000e": 72, "650234": 55, "650810": 72, "650867": 60, "651127": 59, "6511506": 87, "6517642": 87, "652071": 72, "6522": 114, "652312": 64, "652324": 55, "652349": 75, "652350": 70, "652450e": [71, 72], "6527": 63, "652778": 70, "6528": 72, "653": 47, "6530": 72, "653008e": 71, "653829": 67, "653846": 60, "653901": [58, 59], "654070e": 86, "654755": 62, "655284": 75, "6553": 116, "6554": 114, "655422": 72, "655547": 58, "65557405e": 87, "655959": 67, "657": 52, "658": 70, "658267": 75, "658592": 59, "6586": 49, "658702": 59, "659": 52, "659245": [58, 59], "659339": 59, "6593871": 49, "659423": [58, 59], "659473": 78, "659636": 60, "659735": 58, "659755": 76, "6598": 68, "659835": 59, "66": [55, 67, 68, 73, 84, 85, 86, 87, 101, 113, 115], "660": [52, 86], "660073": 59, "660320": 65, "660479": 86, "6607402": 76, "660776": 75, "66133": 86, "661369": 74, "661388": 58, "6625": 72, "662975": 69, "663081975281988": 60, "663082": 60, "663177": 55, "663182": 60, "6634357241067617": 78, "663529": 75, "663533": 72, "663672": 67, "663765": 59, "664103e": 72, "664147": 72, "664409": 59, "664797": 58, "664824": 72, "664850": 70, "665264": 75, "66601815": 86, "666104": 75, "666307": 62, "6666667": 52, "666742": 84, "666959e": 67, "667": 70, "667274": 66, "667492e": 72, "667536": 75, "667598": 73, "667614": 60, "667614205604159": 60, "667981": 58, "667985": 66, "668337": 72, "668452": 66, "668584": 62, "668981": 64, "669579": 59, "66989604": 61, "67": [47, 52, 71, 78, 84, 85, 86, 87, 101, 113], "670867": [17, 84], "671224": 59, "671271": [58, 59], "67136": 72, "6716717587835648": 60, "671672": 60, "671690": 58, "6722": 52, "672234": [58, 59], "672368": 60, "6723684718264447": 60, "672384": [58, 59], "67245350": 50, "672511": 58, "673092": [58, 59], "673302": 70, "673330": 59, "67410934": 50, "6745349414": 50, "674552": 72, "67456": 78, "674609": 60, "674747": 69, "674949e": 77, "675233": 59, "675293": 74, "675625": 84, "675775": 69, "676405": 60, "6765": [51, 71], "676534": 101, "676641": 58, "676756": 75, "676807": 71, "677123": 58, "677614": 75, "677980": 60, "678": 76, "678117": 72, "678826": 60, "67936506": 86, "679539": 70, "679789e": 58, "67ad635a": 52, "68": [52, 55, 77, 84, 85, 86, 87, 101], "680": 72, "680491": 73, "6810775": 77, "681176": 70, "681246": 59, "681448": 72, "681521": 58, "681562": 72, "681817dcfcda": 52, "682": [73, 86], "682122": 69, "682269": 72, "6826": 71, "682875": 60, "683487": 59, "683581": 86, "683637e": 67, "683687": 59, "683942": 75, "683984": 14, "684": 116, "68410364": 51, "68411700": [51, 116], "684128": 59, "684142": 58, "684502": 75, "685104": 8, "685107": 75, "68554404e": 87, "68562150e": 87, "685807": 75, "6858483": 87, "685989": 86, "686270": 59, "686627": 58, "687345": 75, "6873628": 87, "687612": 59, "687647": 75, "687854": 62, "687871": 70, "6878711": 50, "688": 114, "688540": 84, "688641": 69, "688747": 72, "688886": 84, "688918": 72, "688956": 58, "689088": [58, 59], "689188": 62, "689392": 75, "6895168": 87, "689600": 69, "689932": 58, "69": [66, 84, 85, 86, 87, 101, 115], "690334": 60, "6903344145051182": 60, "691097": 58, "691157": 61, "69140475e": 87, "691423": 58, "691511": 71, "691848e": 59, "691911": 84, "692297": 59, "692460": 69, "692579": 59, "692725": 75, "692907": 72, "692959": 58, "693316": 72, "693497e": 72, "693690": 72, "693796": 70, "694154": 60, "694561": 76, "694845e": 72, "694919": 70, "695": 47, "6950": 72, "695045": 58, "69508862": 86, "695123": 73, "695581": 66, "69562150e": 87, "695711": 69, "695928": 58, "696011": [16, 84], "696224": 84, "696289": [64, 65], "69684828": 86, "696966": 59, "697": 70, "697000": 60, "697420": [64, 65], "697545": 75, "697616": 59, "697693": 58, "698223": 62, "698244": 62, "69840389e": 87, "698509": 58, "698694": 70, "698751": 69, "699035": 75, "699082": 60, "69921": 52, "699259e": 75, "6992887": 87, "699333": 60, "699616": 69, "699697": 59, "6_design_1a": 63, "6_r2d_0": 63, "6_r2y_0": 63, "6b": 101, "6cea": 52, "7": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 22, 23, 27, 30, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 101, 102, 107, 113, 114, 115], "70": [51, 60, 64, 71, 72, 73, 75, 84, 85, 86, 87, 101, 115], "700": [58, 59, 63, 70], "7000000000000002": [60, 72, 75], "700015": 75, "700102": 75, "700314": 55, "700458": 58, "701078": 75, "701088": 71, "701106": 66, "701265": 64, "701413": 72, "701672e": 60, "701841e": 65, "701866": 75, "7018663": 75, "701966": 72, "702489": 72, "703049": 58, "703108e": 15, "7031513": 87, "703325": 67, "703772": 72, "7040": 72, "704482": 67, "7045": 67, "704558": 67, "704814": 58, "704896": 67, "705090": 59, "705354": 58, "705581": 72, "7055958": 80, "705595810371231": 80, "7055958103712310": 80, "705794": 59, "70583": 77, "706056": 72, "706077": 59, "706122": 59, "706430": 58, "706645": 60, "706657": 60, "706862": 9, "707125": 59, "707441": 59, "707738": 59, "707868": 75, "707963e": 71, "708190": 70, "708235": 58, "708459": 75, "708472": 59, "708821": 55, "708837": 55, "709026": 62, "709596": 58, "709606": [17, 84], "71": [84, 85, 86, 87, 101, 115], "710059": 55, "710319": 59, "710515": 58, "710586e": 70, "711024": 72, "711328": 72, "711383e": 58, "711518": 72, "711638": 86, "712064": 58, "712082": 72, "712095": 55, "712132235414451536768697072748687959798": 87, "71213223541445153676869707274868795979839101415171920293134505861787980909610016232425273240465254555760667376839192941261133363739424547485663648182848999": 87, "712157": 74, "712268": 58, "712372e": 59, "712503": 77, "712592": 71, "712774": 64, "712846": 84, "712960": 60, "713": 72, "713407": 72, "713457": 58, "713986": 72, "713993": 59, "714240": 70, "714250": 59, "714321": 71, "714534e": 59, "714651": 75, "71465114": 75, "715013": 72, "715180e": 72, "7154": 72, "715407": 60, "7155": 72, "7158581": 50, "7160126": 87, "716013e": 58, "716098": 55, "7161": 72, "716387": 58, "716427e": 59, "716456": 75, "716595e": 72, "716615": 55, "716762": 60, "716793": 60, "716799": 70, "7167991": 50, "716801": 69, "717": 72, "717130": 72, "717185": 75, "718686": 78, "719552": 59, "72": [67, 84, 85, 86, 87, 101, 115], "720559": 58, "720571": 75, "720573": 58, "720589": 76, "720664": 70, "721018": 58, "721071": 75, "721245": 59, "7215093d9089": 52, "72155839e": 87, "721609": 72, "722316": 75, "722634": 75, "722848": 60, "722881": 75, "7229": 72, "723": 52, "723314": 75, "723342": 84, "723345e": 75, "723657": 58, "723846": 55, "7239": 72, "7241399": 50, "724338": 75, "724767": [64, 65], "724918": 78, "725": 52, "725010": 55, "725061": 58, "725087": 72, "725166": 75, "725565": 58, "725802": 9, "725820": 69, "725919": 58, "726": [52, 76], "726658": 69, "7268131": 50, "727159e": 59, "727543": 62, "727693": 72, "727704": 72, "727976": 60, "7282094": 86, "728294": 74, "728710": 75, "72875815e": 87, "728852": 72, "728e": 76, "729668": 84, "729867": 58, "73": [51, 55, 84, 85, 86, 87, 101], "730023": 72, "7308": 49, "730809": 58, "731174": 58, "731317": 60, "732": 76, "732067": 58, "732137": 58, "732150": 59, "7326": 72, "732638": 75, "73285": 13, "732918": 64, "733": 72, "733047": 59, "733644": 58, "7337268": 87, "7338552": 87, "734635": 58, "734770": 59, "734948": 75, "735369e": 84, "7357": 72, "735848": 84, "735941": 12, "735964": 62, "736082": [58, 59], "736084": 75, "73608412": 75, "736823": 59, "737": 47, "737052": 72, "7375615": 51, "73764317e": 87, "737951": [58, 59], "738": 71, "738065": 59, "7381122": 87, "738223": 72, "738315": 72, "738659e": 72, "738876": 59, "739": 72, "739063": 58, "7395359436844482": 60, "739536": 60, "739595": 76, "739720": 72, "739817": 66, "74": [21, 51, 59, 71, 84, 85, 86, 87, 101, 115], "740": 70, "740180e": 75, "740367": 58, "740417": 71, "740505": 55, "7405544": 87, "740785": 58, "740869": 60, "741104": 60, "741380": 76, "741523": 55, "741702": 75, "7418": 49, "74189": 52, "741894": 73, "742128": 75, "742375": 58, "742407": 74, "742411": 58, "742907": 75, "7432": 49, "743247": 72, "743341": 59, "743609": 58, "7437": 72, "74402577": 75, "744026": 75, "744236": 77, "74461783e": 87, "745": 72, "745022": 55, "745444": 58, "745638": 71, "745881": 58, "746361": 75, "746843": 65, "7470": 72, "747646": 72, "747945": 50, "747961": 72, "748084": 59, "748377": 71, "748513": 72, "748880": 72, "74938952": 86, "749443": 72, "749854893": 88, "75": [17, 21, 23, 52, 55, 60, 62, 67, 71, 72, 75, 84, 85, 86, 87, 101, 115], "75000": 78, "7500000000000002": [60, 72, 75], "750000e": 72, "750597": 59, "750701": 55, "751013": 72, "751261": 72, "751633": 72, "75171": 71, "751710": [60, 71], "751712655588833": 80, "7517126555888330": 80, "751712656": 80, "752015": 11, "752283": 72, "752696": 55, "752909": 67, "7533": 71, "753323": 58, "753393": 58, "753523": 75, "753866": 59, "754469": 58, "754499": 59, "754678": 69, "754692": 84, "7548": 78, "754870": 70, "755688": 58, "755701e": 58, "755885": 84, "755910": 72, "7559417564883749": 60, "755942": 60, "7560824": 50, "756200": 55, "756805": 70, "756867e": 72, "756905": 9, "756969": 60, "757": [76, 114], "757151": [58, 59], "757183": 60, "757411": 75, "757438": 73, "757559": 67, "757819": 70, "757917e": 75, "758391": 72, "758831": 59, "75887": 52, "759006": 61, "759054": 59, "759833": 59, "76": [84, 85, 86, 87, 101, 114, 115], "760104": 75, "7603": 49, "760386": 86, "760778": 70, "760915": 62, "761": [50, 70], "761224": 55, "761429": 59, "761714": 60, "762284": 75, "76228406": 75, "762748": 72, "7633872": 87, "763691": 72, "764093": [58, 59], "76419024e": 87, "764315": 75, "76444177e": 87, "764478": 74, "7646": 72, "764798": 75, "764953": 71, "765202": 72, "765363": [58, 59], "765500e": [71, 72], "765710e": 79, "765792": 75, "765864": 77, "76591188": 50, "765960": 58, "7660": 49, "7663": 72, "766499": 75, "766940": 55, "76702611e": 87, "767188": [64, 65], "767435": 78, "767549": 59, "768015": 73, "768071": 75, "768273": [64, 65], "768763": 59, "768798": 55, "769361": 75, "769805": 75, "77": [76, 84, 85, 86, 87, 101], "770556": 72, "770944": [64, 65], "7710": 77, "771157": 101, "771390e": 72, "7714": 73, "7716982": 51, "771741": 72, "771965": 72, "772104": 58, "772157": 67, "77227783e": 87, "772396": 59, "772444": 84, "772791": 72, "77289874e": 87, "773": 52, "773177": 60, "773339": 67, "773488": 75, "77348822": 75, "773769": 69, "77401500e": 87, "774271e": 72, "775": [52, 72], "7750468": 87, "775191": [58, 59], "775285": 58, "775969": 77, "776254e": 58, "7763": 71, "776728e": 70, "776887": 71, "7776071": 50, "777718": 69, "777728": 84, "777867": 67, "777e": 76, "778400": 58, "7786": 49, "779": 76, "779068": 67, "779108": 58, "779167": 6, "779517": [58, 59], "779682": 60, "7799": 68, "779912": 72, "78": [76, 84, 85, 86, 87, 101, 115], "780": 52, "780068": 69, "780338": 58, "780458": 75, "780700": 73, "780856": 71, "781": 72, "781233": 72, "781530": 75, "781681": 75, "782": 52, "782050": 75, "782555": 72, "783": 52, "783276": 86, "7833": 49, "7838": 49, "784": 101, "784238": 70, "784405": 77, "784483": 70, "784624": 60, "784792": 69, "784872": 55, "785": 52, "785038": 59, "785153": 59, "785815": 55, "785911": 75, "785e": 35, "786": 52, "786090": 69, "7861864": 87, "786237": 58, "786563": 69, "786744": 60, "786986": 55, "78711285e": 87, "78777": 77, "788": 114, "78818": 52, "788868": 59, "789032": 58, "789039": 59, "789330": 59, "789671": 60, "789671060840732": 60, "79": [55, 84, 85, 86, 87, 115], "790039e": 58, "790115": 72, "790261": 84, "790723": [64, 65], "791097": 71, "791241": 75, "791297": [17, 84], "792396": 55, "792939": 60, "792972": 84, "793315": 84, "79338596e": 87, "793570": 75, "793598": 59, "793735": 75, "793818": [58, 59], "794": 86, "794136": 73, "794366": 72, "79458848e": 87, "794805": 64, "795": 76, "795647": 75, "7957": 72, "795932": 85, "796014": 59, "796384": 59, "796444": 72, "796596e": 58, "796e": 76, "797086": 58, "797280": 75, "797454": 86, "797737": 101, "797868": 59, "79792890e": 87, "797965": 101, "798071": 8, "798308": 71, "798783": [64, 65], "799403": 75, "7999": 79, "7b428990": 52, "7x": 75, "8": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 40, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 84, 85, 86, 87, 88, 101, 102, 107, 113, 115, 116], "80": [60, 61, 72, 75, 79, 84, 85, 86, 87, 115], "800": 70, "8000": [32, 79], "8000000000000002": [60, 72, 75], "800143": 58, "800326e": 58, "800351": 58, "801623": 72, "802": 76, "802289": 72, "802738": 84, "803112": 69, "803300": 58, "803492e": 75, "8035566": 87, "803563": 72, "803902e": 72, "804": 72, "804219": 75, "804231": 73, "804284": 77, "804316": 75, "804484": 75, "8048": 51, "804828": 75, "804889": 72, "805007": 70, "805153e": [71, 72], "805293": 59, "8055563": 50, "805774": 58, "8059": 71, "806218e": 72, "806531": 72, "806554": 58, "806732": 66, "80696592e": 87, "80714504e": 87, "807879": 75, "808": [51, 101], "808246": 71, "808284": 72, "808640": 72, "809125": 58, "8095": 73, "809913": [58, 59], "80a8": 52, "81": [50, 58, 63, 66, 68, 84, 85, 86, 87, 115], "810044": 71, "81009724": 87, "810134": 75, "8102": [49, 71], "810306": 55, "810322": 58, "810363": 72, "810382": [71, 72], "810419": 59, "810707": 72, "810895": 59, "811011": 59, "811155": 66, "811458": 71, "811513": 59, "8116912": 101, "811696": 58, "811825": 70, "811901": 75, "81190107": 75, "812": 76, "8132463": 50, "813293": 75, "813342": 101, "8136659": 87, "813682": 72, "814136": 60, "814246e": 59, "814351": 60, "814913": 70, "8152": 72, "815213e": 59, "815224": 101, "815226": 86, "8152772": 87, "81568484": 75, "815685": 75, "815993": 75, "816176": 78, "816318": 70, "816373": 58, "816752": 72, "816982": 58, "817119": 58, "817291": 72, "8173602": 68, "817967": 86, "8180042": 87, "81827267": 75, "818273": 75, "818289": 75, "81828926": 75, "818380": [58, 59], "81856": 52, "819223": 84, "819507": 69, "82": [78, 84, 85, 86, 87, 115], "8202": 51, "820366": 70, "8209": 51, "820963": 55, "821": 114, "8210": 51, "821021": 60, "821457": 72, "821566": 75, "821855": 84, "821970": 69, "821995": 59, "8221": 49, "822289": [71, 116], "82228913": 116, "822482": 60, "8227": 72, "822822": 60, "823247": 75, "823273": [58, 59], "8235760": 87, "824350": [58, 59], "824657": 69, "824701": 60, "824750": 60, "824889": 60, "824961e": 72, "8250": 49, "825587": 59, "825617": 70, "825862": 75, "825980": 60, "8259803249536914": 60, "8260": 71, "826065": [58, 59], "826426": 86, "826467e": 58, "826492": 75, "826519": [17, 84], "82666866e": 87, "82684324": 77, "827375": 61, "827381": 75, "827735": 75, "827763": 73, "827938162750831": [64, 65], "8280386": 87, "828058": 72, "828157": 55, "8284138": 87, "828618": 67, "828778e": 58, "828912": 58, "828915": [64, 65], "829543": 60, "829730e": 59, "829764": 84, "82985": 66, "83": [84, 85, 86, 87, 115], "830263": 69, "830273": 55, "830301": 74, "830442": 58, "830467": 58, "831": 76, "831019": 60, "831190": 59, "831278": 58, "831741": 58, "832086": 75, "8326928": 77, "832693": 77, "832875": 75, "83287529": 75, "833024": 70, "833065": 55, "833227e": 85, "833464": 72, "833907": 70, "8340041": 87, "834133": 67, "835": 76, "8350": 72, "835035": 69, "835344": 55, "835596": 72, "835750": 67, "835935": 59, "836234": 86, "838114": 75, "838235": 73, "838457": 72, "83905": 8, "84": [52, 66, 76, 84, 85, 86, 87, 115], "840041": 72, "840303": 75, "84030318": 75, "840673": 58, "840718": 86, "840836": 75, "840995e": 71, "841": [50, 70], "841132": 71, "8415": 51, "841847": 72, "842132": 86, "842405": 60, "842625": 70, "842746": 75, "8428": 71, "842853": 75, "843": 47, "843018": 84, "843730": 70, "843796": 58, "8440": 72, "844107e": 59, "8441527": 87, "844308": 75, "844549": [64, 65], "844663": 55, "844667": 101, "844707": 75, "844889": 70, "845241": 76, "845534": 69, "846388": 60, "847029": 59, "847555": 58, "847595": [16, 84], "847948": 60, "847962": 58, "847966": 72, "848688e": 69, "848757e": 71, "848868": 60, "84930915e": 87, "849427": 84, "849747": 77, "8497f641": 52, "8499": 72, "85": [26, 60, 66, 72, 75, 79, 84, 85, 86, 87], "8500000000000002": [60, 72, 75], "850038": 55, "850321": 70, "850439": 59, "850575": [58, 59], "850656": 67, "850794": 75, "851": 114, "851198": 72, "8513": 52, "851366": 70, "852": 72, "85265193": 68, "85280376": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "85397773": 86, "855035": 58, "855780": 75, "855862": 59, "856404": 65, "856758": 84, "8571": 49, "857161": 75, "857515": 84, "857544": 70, "857765": 72, "858212e": 59, "858952": 55, "859": 72, "85911521e": 87, "85912862": 101, "859129": [88, 101], "8597": 71, "85974356": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "85c5": 52, "85e": 51, "86": [84, 85, 86, 87, 115], "860663": 101, "860804": 75, "860992": 72, "861019": 55, "861519": 58, "862043": [64, 65], "862359": 60, "863": 47, "863772": 71, "863982270": 88, "864": 76, "86415573": 51, "86424193e": 87, "8644": 52, "864664": 55, "864741e": 72, "865313": 72, "865562": [58, 59], "865854": 72, "865860": [71, 72], "865914": 59, "866102": [58, 59], "866179899731091": 80, "866179900": 80, "866579": 72, "866798": 72, "867201": 69, "867565": 75, "8679": 72, "868": 52, "8685788": 75, "868579": 75, "869": [52, 76], "869020": 60, "869195": 59, "869398": 59, "869477": 58, "869585": 15, "869586": 66, "87": [51, 58, 66, 70, 84, 85, 86, 87, 115], "8700": 51, "870099": [64, 65], "870260": 75, "870332": 75, "870444": 71, "870857": 75, "871": 52, "871545e": 58, "871923": 59, "871972": 67, "872": 76, "872132": 59, "872222": 72, "8723743": 87, "872727": 58, "872768": 75, "872852": 75, "87290240e": 87, "872994": 72, "873198": 72, "873677": [64, 65], "87384812361": 49, "87384812362": 49, "8740611": 87, "87430335": 101, "874303353": 101, "874702": [64, 65], "8750": 72, "8753903": 87, "8759": 72, "876": 76, "876083": 72, "87623301": 49, "876431e": 60, "876549": 72, "87674597e": 87, "8768": 49, "8771": 72, "877153": 72, "877455": 74, "877833": [58, 59], "877903": 55, "878281": 75, "878289": 72, "878402": 58, "878746": 55, "878847e": 72, "878895": 55, "878968e": 58, "879": 86, "879049": 72, "879058": 69, "879103": 60, "879509": 58, "87e": 51, "88": [51, 66, 76, 84, 86, 87], "880106": 70, "880579": 75, "880591": 74, "880808e": 72, "880880e": 72, "880886": 71, "8810": 71, "881201": 72, "88125046e": 87, "881465": 62, "881581": 12, "88173062": 50, "881937": 55, "882": 47, "882475": 60, "882641": 71, "882928": 55, "883485": 59, "883622": 75, "883914": 60, "883953": 69, "884132": 75, "8843": 77, "8845": 49, "884821": 84, "884996": 60, "8850": 51, "885065": 75, "885832": 76, "885956": 58, "885978": [64, 65], "886": 73, "886041": 59, "886086": [58, 59], "886266": 72, "88629": 49, "886314": 59, "88664": 52, "887345": 72, "887556": 60, "887648": 59, "887680": 58, "888146": 70, "8881461": 50, "888352": 55, "888445": 59, "888775": 65, "888804": 72, "889293": 75, "889326": 59, "889638": 55, "889733": 75, "889792": 59, "88988263e": 87, "889913": [58, 59], "889963": 75, "88ad": 52, "89": [51, 59, 84, 86, 87, 114, 115], "890": [50, 70], "89027368": 101, "890273683": 101, "890318": 58, "89035917": 66, "890372": [53, 82, 113], "8903720000100010000010": [52, 82, 113], "8904": 47, "890454": 85, "890665": 67, "890855": 55, "8909": [50, 71, 116], "89135253": 87, "891606": 71, "891752": 59, "891997": 58, "892": 52, "892648": 75, "892796": [58, 59], "892828": 67, "893": 52, "8932105": 50, "893461": 55, "893649": [58, 59], "893851": 75, "894": 52, "894307e": 72, "894448": 59, "895106": [58, 59], "895308": 72, "895333": 75, "895442": 71, "895690": [58, 59], "895768e": 60, "896": 73, "896023": 75, "896182e": 67, "896263": 67, "897220": 75, "897240": 72, "8974": 71, "897451": 58, "897495e": 59, "898": 73, "898183": 55, "898722": 75, "899021": 84, "899250": 55, "899460": 75, "899654": 55, "899662e": 58, "899716": 59, "8bdee1a1d83d": 52, "8da924c": 52, "8e3aa840": 52, "9": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 82, 84, 85, 86, 87, 88, 101, 102, 107, 112, 113, 115, 116], "90": [28, 51, 60, 61, 72, 75, 79, 84, 86, 87, 115], "9000000000000002": [60, 72, 75], "900000e": 72, "900021": 85, "900829": 67, "901": 47, "901013": 59, "901148": 75, "90136": 71, "901360": 71, "901526": 66, "901683": 72, "901705": 58, "902": 101, "902573": 60, "902920": 84, "903056e": 75, "903339": 60, "903351e": 60, "903418": 70, "903674": 58, "903681": 75, "903767": [58, 59], "904156": 60, "9041560442482157": 60, "904315": 58, "904396": 58, "905042": 59, "905494": 60, "905858": 78, "905951": 77, "906072": 84, "9061": 72, "906716732639898": [64, 65], "906757": 56, "907115": 75, "907176": 75, "9073": 72, "907491": 60, "907801": 70, "907879": 55, "90794478": 101, "907944783": 101, "907961": 72, "908024": 78, "908663": 59, "908767": 69, "909304": [58, 59], "909571": 55, "90963122e": 87, "909942e": 84, "909975": 72, "909997": [71, 116], "91": [84, 86, 87, 115], "910000e": 72, "910895": 59, "9109": 52, "91102953": 75, "911030": 75, "9112": 71, "911277": 59, "911662": 64, "912230": [58, 59], "9126": [51, 116], "9127": [51, 116], "912903": 58, "913": 52, "91315015": 50, "913280": 78, "913371": 59, "913415e": 58, "913485": 72, "913585": 67, "913774": 60, "9142": 72, "91438767e": 87, "9145": 49, "914598": 55, "915": [51, 52, 71, 72], "915000e": [71, 72], "915260e": 58, "915488": [64, 65], "9158080176561963": 69, "916236": 49, "916359": 55, "916528": 64, "9166667": 52, "916914": 75, "916930": 58, "917": [52, 73], "917000": 59, "9170550": 87, "917066": 72, "917248": 75, "91724807": 75, "917436": 75, "918": 76, "918227": 60, "919432": 75, "9197": 72, "919969": 58, "91e": 51, "92": [84, 85, 86, 87, 115], "920052": 59, "920335": 72, "920337": 65, "920645": 72, "9209": 49, "9210": 72, "921061": 78, "921198": 67, "921256e": 59, "921372": 60, "921778": 67, "921913": 70, "921956": [58, 59], "921e4f0d": 52, "922160": 72, "922251": 58, "9223": 72, "922668": 67, "922996": 70, "923074e": 60, "923517": 79, "923607": 75, "92369755": 50, "9237108": 87, "923804": 60, "923943": 116, "923977": 72, "924002": 75, "9243": 72, "924396": [64, 65], "924443": 55, "924634": 62, "9248": 52, "924821": 60, "924843": 70, "924921": 84, "925": 61, "925248": [64, 65], "925660": 58, "925736": 60, "925957": 64, "925994": 71, "925995": 59, "926": [47, 116], "926227": 59, "926621": 60, "926901": 69, "927": 48, "927074": 75, "927232": 72, "9274": 72, "927950": 72, "92827999": 86, "92881435e": 87, "928947": 70, "92905": 50, "929643": 58, "92972925e": 101, "929729e": [88, 101], "93": [51, 67, 84, 85, 86, 87, 115], "9304028": 50, "931": 81, "931479": 75, "931978": 113, "932027": 60, "932404e": 72, "9325": 49, "9327": 49, "932973": 75, "933322": 59, "933671": 59, "933857": 59, "933996": 60, "934058": 58, "934243": 59, "934433": [58, 59], "9345": 52, "934500": 59, "934511": 101, "934549": 72, "93458": 77, "934963": 59, "934992": 60, "935": [35, 68, 86], "935591": 75, "935730": 75, "935764": 59, "935989": 70, "9359891": 50, "93648": 79, "936494": 58, "936739": 75, "937116": 70, "9371462": 87, "937586": 72, "938": 101, "939068": [64, 65], "9392": 72, "939250": 58, "939458": 58, "9395": 72, "93958082416": 116, "94": [61, 68, 84, 86, 87, 115, 116], "940354721701296": 60, "940355": 60, "940373": 72, "941440": 58, "941724": 72, "941788": 64, "942139": 65, "942312": 75, "942460e": 75, "942489": 72, "9425": 49, "942550": 72, "942661": 70, "942823": 72, "94309994e": 87, "9434457": 87, "943548": 67, "943938": 75, "943949e": 75, "944253e": 75, "944266": [64, 65], "944280": 72, "94441007e": 87, "945881": 58, "946180": 67, "94629": 79, "946297": 60, "946406": 65, "946433": 75, "946533": 58, "946658": 72, "946968": 60, "947440": 74, "947466": 85, "947613": 59, "947855": 55, "9480": 72, "948112": 76, "948154e": 64, "948785e": 58, "948868": 72, "948975": 66, "94906344": 50, "949241": 101, "949456": 75, "949866": 59, "95": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 39, 49, 51, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 75, 76, 77, 78, 79, 84, 86, 87, 101, 102, 107, 115, 116], "9500": 72, "950158": 58, "950545": 56, "95062986e": 87, "951502": 75, "951532": 70, "951920": 74, "952": [51, 76, 116], "9523": 49, "952839": 75, "9534": 72, "953683": 70, "953704": 58, "95372559e": 87, "953884": 86, "954": 101, "95401167e": 87, "955005e": 72, "9551": 72, "9552": 49, "955541": [17, 84], "95559917": 85, "955701": 58, "955e": 86, "956047": 50, "9561": 49, "956574": 72, "956588": 86, "956724": 60, "9567242535070148": 60, "956877": 59, "956892": 72, "957229": 65, "957375": 70, "957745": 60, "9579": 51, "957996": 60, "958": [101, 116], "9580": 51, "958105": 84, "958541": 72, "959132": 59, "959384": 59, "959613": 84, "95e": 51, "96": [51, 58, 59, 73, 84, 86, 87, 115], "960236": 86, "9605": 72, "960808": 60, "960834": 59, "9609": 49, "961539": 72, "961962": 60, "962364": 55, "962373": 59, "962954": 59, "963055": 72, "963427e": 59, "964025e": 75, "964065e": 59, "9640690": 87, "964261e": 70, "964318": 72, "9647": 49, "965341": 59, "965531": 86, "965696": 58, "965774": 72, "96582": 85, "966015": 75, "966097": 18, "966659": 60, "9666592590622916": 60, "967092": 59, "967467": 77, "968127": 55, "968134e": 75, "968258e": 58, "968577": 61, "969141": [84, 85, 86], "9699": 71, "969925e": 59, "97": [6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 53, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 84, 85, 86, 87, 88, 101, 113, 115, 116], "970": 73, "970065": 75, "970150": 59, "971": 116, "971058": [64, 65], "972509": 59, "972745": 58, "972748": 60, "97276281": 75, "972763": 75, "9728341": 87, "97314470": 50, "973156": 84, "973229": 59, "973241": 75, "973331": 72, "973741": 59, "973890": 59, "974202": 60, "974213": 59, "97441062": [64, 65], "974414": 60, "974487": 58, "97470872": 77, "9748910611": 50, "975": [58, 59, 64, 65, 67, 68, 73], "975289": 55, "9753": 52, "975447": 61, "975450": 59, "975461": 70, "975592": 55, "976088": 75, "976548e": 59, "976562": 75, "977202": 59, "977280": [58, 59], "977295": 72, "977507": 59, "977820": 58, "978": 73, "978303": 69, "9787": 72, "978977": 75, "979": 76, "979384": 67, "979475": 58, "979702": 58, "979857": 58, "979966": 67, "979971e": 58, "98": [58, 59, 72, 84, 86, 87, 115], "980026": 72, "9802393": 50, "980440": 59, "980643e": 60, "981104": 74, "981403": 59, "981438": 58, "981648": 73, "981672": 60, "981715": 58, "982019e": 59, "982353e": 72, "982417": 60, "982720": 58, "982797": 74, "983192": 75, "983253": 58, "983759": 116, "98393441": 77, "984": 73, "984024": 74, "984083": [64, 65], "984551": 11, "984562": 75, "984866": 101, "984872": [58, 59], "984937": 60, "985": 73, "98505871e": 87, "9850893": 87, "985207": [58, 59], "9854102": 87, "985654": 59, "986249": 71, "986383": 72, "986417": 58, "98673": 66, "9870004": 52, "987220": 72, "987307": 69, "9875": 49, "987726": 59, "9880384": 52, "988421": [58, 59], "988463": 75, "988541": 58, "988709": 72, "988780": 72, "989657": 73, "99": [51, 55, 58, 59, 73, 84, 86, 87, 115], "990210": 72, "990683": 73, "990903": 58, "991": 52, "9914": [71, 72, 77], "991444e": 64, "9915": [51, 71, 72, 77], "991512": 51, "991963": [58, 59], "991977": 72, "991988": 58, "992": 76, "99232145": 77, "992582": [58, 59], "993": 73, "993201": 59, "993416": 67, "993575": 72, "994": 76, "994168239": 50, "994208": 55, "994214": 72, "994332": 56, "994377": 58, "9944": [68, 86], "994851": 72, "9948816": 87, "994937": 65, "995": 73, "995015": 72, "9951": 49, "995248": 75, "99549118e": 87, "99571372e": 87, "9961": 71, "9961392": 50, "996313": 58, "996892": 69, "996934": 70, "9970": 72, "997034": 79, "997494": 79, "997571": 70, "997621": 60, "997934": [64, 65], "998063": 56, "99864670889": 116, "998766": 72, "999": [61, 62, 66, 77, 116], "999207": 75, "9995": [58, 59, 62], "9996": [58, 59, 62], "9996553": 51, "9997": [58, 59, 62], "9998": [58, 59, 62], "9999": [58, 59, 62], "99c8": 52, "A": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 26, 27, 31, 35, 37, 38, 39, 41, 42, 47, 48, 49, 51, 52, 56, 57, 63, 65, 68, 69, 73, 74, 76, 77, 78, 81, 82, 84, 85, 86, 101, 102, 103, 104, 108, 109, 110, 111, 113, 114, 116], "ATE": [12, 18, 21, 51, 53, 55, 67, 71, 77, 78, 84, 86, 88, 94, 102, 108], "ATEs": [55, 73], "And": [73, 79, 102, 105], "As": [48, 49, 50, 51, 52, 55, 57, 58, 59, 60, 61, 63, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 79, 80, 85, 86, 87, 88, 90, 101, 102, 104, 110, 116], "At": [21, 22, 23, 50, 55, 61, 62, 66, 68, 70, 72, 75, 116], "Being": 116, "But": [67, 68], "By": [49, 50, 70, 76, 78, 85, 86, 102, 107], "For": [4, 8, 9, 11, 12, 15, 23, 33, 34, 38, 42, 47, 49, 50, 52, 55, 56, 61, 66, 67, 68, 69, 70, 72, 74, 76, 77, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 108, 110, 112, 113, 116], "ITE": [27, 55], "ITEs": 55, "If": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 41, 42, 48, 50, 57, 58, 59, 61, 67, 68, 70, 72, 76, 81, 82, 84, 85, 86, 88, 89, 91, 92, 94, 101, 102, 104, 105, 106, 107, 109, 110, 111, 116], "In": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 37, 41, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116], "It": [49, 50, 51, 58, 59, 63, 64, 65, 70, 71, 72, 76, 78, 85, 87, 111, 115], "No": [25, 47, 49, 51, 52, 53, 55, 61, 66, 71, 72, 76, 77, 79, 82, 85, 86, 88, 101, 113, 114], "Of": [68, 101, 116], "On": [48, 57, 69, 73, 81, 114], "One": [51, 71, 72, 78, 84, 101], "Or": 35, "Such": [78, 85], "That": [35, 116], "The": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 47, 48, 49, 50, 52, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 87, 88, 89, 94, 97, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 114, 115, 116], "Then": [23, 60, 75, 86, 101, 102, 110, 111, 112], "There": [51, 71, 78, 86, 112, 116], "These": [51, 52, 54, 69, 71, 74, 76, 77, 84, 86, 116], "To": [34, 47, 48, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 64, 65, 67, 68, 70, 71, 72, 74, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 101, 102, 104, 107, 110, 112, 113, 116], "With": [26, 58, 59, 85, 114], "_": [48, 50, 57, 58, 59, 60, 62, 63, 64, 65, 70, 71, 72, 74, 75, 76, 80, 81, 84, 86, 87, 88, 101, 102, 104, 107], "_0": [48, 50, 57, 63, 70, 80, 81, 87, 88, 96, 97, 101, 102, 110], "_1": [21, 22, 23, 27, 73, 79, 88, 96, 97], "_2": [21, 22, 23, 27, 73], "_3": [21, 22, 23, 27], "_4": [21, 22, 23, 27], "_5": [21, 27], "__": [41, 42], "__init__": 69, "__version__": 112, "_all_coef": 87, "_all_s": 87, "_compute_scor": 34, "_compute_score_deriv": 34, "_coordinate_desc": 70, "_d": [76, 86], "_est_causal_pars_and_s": 115, "_estimator_typ": 69, "_h": [76, 86], "_i": [48, 57, 75, 79, 81], "_id": 87, "_j": [21, 22, 23, 27, 29, 50, 70, 101], "_l": 85, "_m": [85, 87], "_n": [88, 91, 92, 94, 101, 102, 107, 109], "_n_folds_per_clust": 70, "_offset": 85, "_pred": 85, "_rmse": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "_x": 36, "_y": [76, 86], "a0": 69, "a09a": 52, "a09b": 52, "a1": 69, "a3d9": 52, "a4a147": 73, "a5e6": 52, "a5e7": 52, "a6ba": 52, "a79359d2da46": 52, "a840": 52, "a_": 79, "a_0": 30, "a_1": 30, "a_j": 86, "ab": [49, 111], "ab71": 52, "abadi": [19, 61], "abb0fd28": 52, "abdt": [53, 82, 113], "abl": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 48, 57, 68, 72, 73, 85, 102, 104, 110], "about": [51, 68, 71, 86, 111, 113, 116], "abov": [48, 51, 55, 57, 58, 59, 64, 65, 68, 69, 71, 73, 74, 75, 76, 78, 81, 84, 85, 86, 112], "absolut": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 68, 85], "abstract": [34, 49, 50, 70, 88, 111, 115], "acc": [5, 49], "accept": [84, 85], "access": [37, 38, 49, 51, 64, 65, 66, 68, 77, 85, 102, 107, 116], "accord": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 48, 51, 55, 57, 60, 61, 71, 75, 76, 78, 79, 85, 86, 101, 102, 103, 105, 106, 108, 116], "accordingli": [61, 68, 69, 71, 76, 79], "account": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 50, 51, 70, 71, 72, 77, 78, 102, 107, 110, 116], "accumul": [51, 71, 72, 77], "accuraci": [37, 41, 49, 86], "acemoglu": 114, "achiev": [50, 67, 70, 74, 78, 86, 101], "acic_2024_post": 73, "acknowledg": [51, 52, 71], "acm": 114, "acov": 114, "across": [51, 71, 73, 116], "action": 115, "activ": [7, 10, 112, 115], "actual": [35, 66, 78], "acycl": [79, 116], "ad": [7, 10, 19, 20, 34, 37, 38, 41, 42, 66, 82, 85, 86, 101, 102, 104, 115], "adapt": [11, 71, 115], "add": [49, 50, 53, 55, 61, 62, 64, 65, 66, 73, 75, 76, 77, 78, 79, 85, 86, 114, 115], "add_trac": 78, "addit": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 23, 27, 29, 30, 31, 36, 39, 63, 78, 85, 86, 88, 95, 102, 103, 108, 110, 114, 115], "addition": [21, 22, 55, 60, 72, 77, 85, 86, 87, 101, 102, 107, 113], "address": 78, "adel": 114, "adj": [76, 78], "adj_coef_bench": 78, "adj_est": 78, "adj_vanderweelearah": 78, "adjust": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 40, 50, 62, 67, 70, 72, 77, 78, 84, 86, 101, 102, 107, 114, 115, 116], "adopt": [61, 86], "advanc": [69, 83, 87, 114], "advantag": [48, 49, 51, 55, 57, 71, 72, 81, 112], "advers": [102, 104], "adversari": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 77, 102, 107, 110], "ae": [48, 50, 51], "ae56": 52, "ae89": 52, "aesthet": 48, "aeturrel": 31, "afd9e4": 73, "affect": [55, 63, 86, 115, 116], "after": [49, 51, 52, 61, 63, 71, 72, 78, 79, 84, 85, 102, 105, 107, 112, 116], "after_stat": 48, "ag": [51, 71, 72, 74, 77, 116], "again": [48, 49, 50, 51, 55, 57, 61, 66, 69, 70, 71, 76, 77, 78, 79, 81, 102, 105], "against": [61, 66, 68, 74, 85], "agebra": 84, "agegt54": [52, 53, 82, 113], "agelt35": [52, 53, 82, 113], "agg": 49, "aggreg": [49, 80, 87, 115], "aggregate_over_split": 35, "aggt": 49, "aim": 76, "aipw": 73, "aipw_est_1": 73, "aipw_est_2": 73, "aipw_obj_1": 73, "aipw_obj_2": 73, "air": [50, 70], "al": [19, 20, 24, 26, 29, 30, 48, 50, 51, 52, 57, 58, 59, 60, 61, 63, 64, 65, 68, 70, 71, 72, 75, 77, 81, 86, 87, 88, 90, 94, 95, 100, 101, 102, 104, 110, 111, 113, 115], "alexandr": [63, 114], "algebra": 86, "algorithm": [47, 49, 50, 52, 55, 57, 60, 61, 67, 68, 70, 72, 75, 77, 79, 83, 85, 86, 87, 88, 101, 115, 116], "alia": [37, 38, 41, 42], "align": [48, 50, 57, 60, 62, 68, 70, 71, 73, 74, 75, 79, 115], "all": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 38, 41, 42, 43, 48, 49, 50, 51, 55, 57, 61, 66, 67, 68, 69, 70, 71, 72, 74, 76, 78, 79, 81, 82, 84, 85, 86, 87, 101, 102, 110, 111, 112, 115], "all_coef": 87, "all_dml1_coef": 80, "all_s": 87, "all_smpl": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 67], "all_smpls_clust": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "all_z_col": [50, 70], "allow": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 34, 37, 38, 41, 42, 51, 55, 71, 72, 76, 84, 85, 86, 87, 88, 101, 111, 115, 116], "almqvist": 114, "along": 85, "alpha": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 28, 30, 48, 50, 51, 53, 55, 57, 58, 59, 60, 63, 67, 68, 69, 70, 71, 72, 75, 80, 81, 84, 85, 86, 87, 88, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110], "alpha_": [29, 50, 70, 85], "alpha_0": [102, 110], "alpha_ml_l": 63, "alpha_ml_m": 63, "alpha_x": [11, 25, 86], "alreadi": [23, 61, 79, 85, 86], "also": [4, 8, 9, 11, 12, 15, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 61, 64, 65, 66, 68, 69, 70, 71, 72, 74, 76, 77, 78, 81, 84, 85, 86, 87, 88, 101, 102, 104, 112, 113, 115, 116], "alter": [50, 70], "altern": [49, 51, 52, 71, 74, 83, 85, 101, 111, 113], "although": 78, "alwai": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 38, 42, 49, 76, 115], "always_tak": [11, 51, 71], "amamb": 70, "american": [28, 73], "amgrem": 70, "amhorn": 70, "amit": [78, 114], "amjavl": 70, "ammata": 70, "among": [51, 63, 71, 72, 77, 78], "amount": [51, 69, 71, 72, 116], "amp": [47, 50, 52, 61, 70, 72, 77, 79], "an": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 27, 37, 38, 41, 42, 48, 49, 50, 51, 52, 55, 57, 58, 59, 63, 66, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 101, 102, 104, 107, 111, 113, 114, 115, 116], "analog": [33, 34, 50, 70, 72, 77, 84, 86, 88, 91, 92, 101, 102, 107], "analys": 116, "analysi": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 36, 48, 50, 51, 57, 70, 71, 72, 81, 83, 84, 104, 107, 110, 111, 115], "analyt": [73, 75], "analyz": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 51, 71, 72, 77, 116], "ancillari": 78, "andrea": 114, "angl": 51, "angrist": 73, "ani": [47, 48, 49, 52, 56, 57, 61, 78, 79, 81, 86, 112, 116], "anna": [8, 9, 21, 22, 23, 27, 49, 61, 86, 114], "annal": [101, 114], "anneal": 85, "annot": 48, "annual": 114, "anoth": [48, 49, 50, 51, 57, 68, 69, 70, 81, 85, 86], "anticip": 49, "anymor": [50, 70], "aos1161": 101, "aos1230": 101, "aos1671": 101, "ap": [51, 71], "ape_e401_uncond": 51, "ape_p401_uncond": 51, "api": [82, 111, 115], "apo": [4, 5, 89, 103], "apoorva": 115, "apoorva__l": 73, "apoorval": 73, "app": 115, "appeal": 78, "append": [57, 68, 81], "appendix": [26, 32, 77, 79, 102, 104], "appli": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 47, 48, 50, 51, 52, 57, 61, 62, 67, 68, 70, 71, 72, 76, 78, 79, 81, 86, 87, 88, 101, 111, 113, 115, 116], "applic": [48, 57, 61, 73, 78, 81, 84, 87, 114, 116], "apply_along_axi": 74, "apply_cross_fit": [48, 87], "apply_crossfit": 115, "appreci": 111, "approach": [4, 6, 8, 9, 11, 12, 13, 16, 17, 18, 49, 50, 55, 70, 76, 77, 78, 83, 85, 87, 101, 102, 104, 112, 114, 116], "appropri": [51, 63, 71, 86, 87, 116], "approx": 84, "approxim": [48, 57, 58, 59, 60, 68, 75, 78, 81, 84, 86, 101, 115, 116], "apt": 112, "ar": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 48, 49, 50, 51, 52, 54, 55, 57, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 116], "arang": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 57, 60, 62, 72, 74, 75, 77, 78, 85], "arbitrarili": [38, 42], "architectur": [88, 114], "arellano": 114, "arg": [69, 76, 84, 86], "argmin": 68, "argu": [48, 51, 57, 71, 72, 77, 81, 116], "argument": [4, 12, 15, 23, 29, 30, 31, 35, 36, 39, 51, 58, 59, 61, 66, 68, 71, 72, 80, 84, 85, 86, 115, 116], "aris": [48, 49, 50, 57, 70, 78, 81, 116], "aronow": 73, "around": [49, 51, 71, 72, 76, 86, 88], "arr": 74, "arrai": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 25, 26, 28, 29, 30, 31, 32, 37, 38, 39, 40, 41, 42, 55, 57, 58, 59, 60, 61, 68, 70, 73, 74, 77, 78, 79, 80, 81, 83, 84, 85, 87, 101, 102, 107, 113, 115, 116], "arrang": 50, "array_lik": 17, "articl": [31, 111], "arxiv": [29, 49, 50, 70, 78, 111, 114, 115], "as_learn": [52, 85], "asarrai": [58, 59], "aspect": [51, 71, 72], "assert": 85, "assess": 49, "asset": [72, 77, 116], "assign": [7, 10, 51, 65, 71, 76, 84, 85, 86, 116], "assmput": 86, "associ": [51, 63, 71, 86, 101, 114], "assum": [47, 50, 56, 61, 70, 73, 74, 78, 86, 88, 91, 92, 101, 102, 110, 116], "assumpt": [49, 50, 51, 61, 62, 68, 70, 71, 73, 76, 79, 86, 101, 116], "assur": 115, "astyp": [56, 76, 78], "asymptot": [33, 34, 48, 50, 57, 70, 81, 87, 101, 114], "ate": 55, "ate_estim": 79, "ates": 55, "athei": 114, "att": [12, 21, 49, 62, 66, 67, 74, 78, 84, 86, 88, 94, 102, 108, 115], "att_gt": 49, "attach": 49, "atte_estim": 61, "attempt": [37, 38], "attenu": [51, 71], "attr": 51, "attribut": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 35, 39, 40, 41, 42, 68, 69, 80, 85, 87, 88, 101], "attributeerror": [37, 38], "attrict": 86, "attrit": [18, 79, 86], "au": [52, 85, 111, 113], "auc": 49, "author": [49, 78, 111], "auto_ml": 69, "autodoubleml": 69, "autom": 69, "automat": [48, 57, 66, 81, 84, 102, 107], "automl": 115, "automl_l": 69, "automl_l_lesstim": 69, "automl_m": 69, "automl_m_lesstim": 69, "automobil": [50, 70], "autos": 63, "autosklearn": 69, "auxiliari": [48, 57, 81], "avail": [25, 49, 51, 52, 55, 61, 63, 68, 71, 72, 73, 74, 76, 78, 81, 84, 85, 86, 102, 110, 111, 112, 115, 116], "avaiv": 40, "aver": 55, "averag": [4, 5, 11, 12, 15, 21, 22, 23, 47, 49, 52, 56, 61, 62, 66, 72, 73, 74, 76, 77, 78, 79, 83, 89, 94, 101, 103, 108, 114, 115, 116], "average_it": 55, "avoid": [48, 49, 57, 76, 86, 87, 112, 115], "awai": 77, "ax": [55, 57, 58, 59, 60, 62, 64, 65, 68, 69, 70, 71, 72, 73, 75, 76], "ax1": [55, 60, 67, 72, 75], "ax2": [55, 60, 67, 72, 75], "axhlin": [62, 69, 76], "axi": [50, 51, 55, 63, 67, 68, 70, 71, 73, 74, 76], "axvlin": [55, 57], "b": [8, 9, 31, 48, 50, 52, 57, 58, 59, 70, 73, 75, 76, 78, 81, 84, 85, 101, 102, 110, 111, 113, 114], "b208": 52, "b371": 52, "b5d34a6f42b": 52, "b5d7": 52, "b_": 86, "b_0": 30, "b_1": 30, "b_j": 31, "bach": [63, 68, 69, 78, 111, 114, 115], "backbon": 68, "backend": [7, 10, 49, 72, 77, 78, 83, 115], "backward": 115, "bad": 73, "balanc": [51, 71, 72], "band": [49, 83, 116], "bandwidth": [13, 16, 17, 35, 76, 86], "bar": [66, 69, 71, 84, 86, 88, 89, 94, 102, 103], "base": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 24, 27, 36, 40, 48, 49, 50, 51, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 101, 102, 104, 107, 111, 113, 114, 115, 116], "base_estim": [41, 42, 76], "baselin": [27, 51, 69, 71], "basi": [4, 12, 15, 39, 58, 59, 67, 84], "basic": [49, 50, 51, 61, 70, 71, 72, 73, 76, 77, 78, 83, 85], "basis_df": 67, "basis_matrix": 67, "batch": 52, "battocchi": 114, "bay": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 101], "bb2913dc": 52, "bbotk": [52, 85, 115], "bbox_inch": 57, "bbox_to_anchor": 57, "bcallaway11": 49, "bd929a9e": 52, "bde4": 52, "becam": [51, 71, 72], "becaus": [38, 42, 47, 48, 49, 50, 56, 57, 65, 66, 70, 73, 78, 81, 116], "becker": [52, 85], "becom": [50, 65, 69, 70, 84, 87], "bee": 62, "been": [50, 51, 69, 70, 71, 72, 77, 78, 84, 85, 115], "befor": [49, 51, 55, 62, 66, 71, 75, 78, 86, 116], "begin": [25, 28, 29, 48, 50, 51, 52, 57, 60, 62, 68, 70, 71, 73, 74, 75, 79, 80, 82, 85, 87, 101, 113, 116], "behav": 65, "behavior": [51, 73, 85], "behaviour": 65, "behind": 86, "being": [27, 32, 33, 34, 36, 41, 42, 50, 70, 76, 78, 86, 87, 88, 90, 101, 102, 107, 111], "belloni": [26, 63, 101, 114], "below": [47, 51, 56, 71, 73, 86, 112, 113], "bench_x1": 78, "bench_x2": 78, "benchmark": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 43, 55, 66, 104, 115], "benchmark_dict": [43, 77], "benchmark_inc": 77, "benchmark_pira": 77, "benchmark_result": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "benchmark_twoearn": 77, "benchmarking_set": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 55, 66, 77, 78, 102, 104], "benchmarking_vari": 66, "benefit": [48, 51, 57, 71, 81], "bernoulli": 25, "berri": [50, 70], "besid": 113, "best": [4, 12, 15, 38, 39, 42, 58, 59, 64, 65, 69, 112], "best_loss": 69, "beta": [18, 25, 26, 28, 32, 51, 71, 74, 76, 79, 86], "beta_": 79, "beta_0": [24, 74, 79, 84], "beta_a": [21, 22, 78], "beta_j": [25, 26, 28, 32], "better": [49, 55, 68, 78], "between": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 47, 55, 56, 60, 62, 63, 69, 73, 75, 77, 78, 79, 86, 88, 91, 92, 94, 98, 99, 101, 102, 110, 113, 115], "betwen": [47, 56], "beyond": 114, "bia": [32, 47, 56, 63, 76, 78, 79, 83, 86, 87, 88, 96, 97, 102, 110, 114, 115], "bias": [47, 51, 56, 71, 72, 77, 116], "bias_bench": 78, "bibtex": 111, "big": [63, 80, 87, 88, 92, 95, 101, 102, 105, 106, 108, 109, 110], "bigg": [50, 70, 88, 93, 94, 102, 108], "bilia": 20, "bin": [48, 55, 57, 112], "binari": [4, 6, 8, 9, 11, 12, 13, 15, 16, 18, 24, 36, 47, 49, 51, 52, 56, 61, 66, 67, 68, 71, 73, 74, 78, 84, 85, 102, 103, 108, 115, 116], "binary_outcom": 36, "binary_treat": [24, 58, 64, 66], "bind": 115, "binder": [52, 85, 111, 113, 115], "binomi": [56, 73, 74, 75], "bischl": [52, 85, 111, 113], "black": [48, 52, 53, 82, 113], "blob": 49, "blog": 31, "blondel": [111, 113], "blp": [39, 50, 70], "blp_data": [50, 70], "blp_model": [64, 65], "blue": [48, 50, 70], "bodori": 114, "bond": [51, 71, 72], "bonferroni": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 101], "bonu": [20, 52, 82, 113], "book": [52, 78, 85], "bool": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 24, 27, 35, 36, 37, 38, 39, 41, 42, 66, 76], "boolean": [32, 64, 65, 82, 87], "boost": [47, 51, 56, 61, 68, 71], "boost_class": [51, 71], "boost_summari": 71, "boostrap": [60, 115], "bootstrap": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 39, 55, 58, 59, 60, 64, 65, 72, 75, 83, 84, 87, 88, 111, 113, 115, 116], "both": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 22, 24, 49, 51, 52, 61, 62, 67, 68, 69, 71, 72, 74, 76, 77, 78, 82, 85, 86, 101, 102, 104, 107, 109, 110, 115, 116], "bottom": [50, 51, 68, 70, 71, 72], "bound": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 27, 51, 55, 66, 67, 71, 77, 78, 102, 104, 107, 110, 116], "branch": 52, "brantli": 49, "break": [48, 115], "breviti": 116, "brew": 112, "brewer": 50, "bridg": 78, "brief": 81, "bring": [47, 56], "brucher": [111, 113], "bsd": 115, "bst": 71, "budget": [69, 85], "bug": [111, 115], "build": [50, 68, 70, 74], "build_design_matric": [58, 59], "build_sim_dataset": 49, "built": [40, 69, 85, 111], "bureau": [78, 87, 114], "busi": [29, 32, 50, 70, 78, 114], "b\u00fchlmann": 114, "c": [19, 20, 22, 23, 26, 28, 30, 47, 48, 49, 50, 51, 52, 53, 56, 57, 62, 63, 64, 65, 70, 71, 73, 76, 81, 82, 85, 86, 111, 112, 113, 114, 116], "c1": [19, 20, 30, 50, 63, 70, 81, 111, 114], "c68": [19, 20, 30, 50, 63, 70, 81, 111, 114], "c895": 52, "c_": 101, "c_d": [26, 102, 108, 109, 110], "c_y": [26, 102, 110], "ca1af7be64b2": 52, "caac5a95": 52, "calcualt": 74, "calcul": [4, 12, 15, 49, 51, 55, 58, 59, 60, 64, 65, 68, 69, 71, 75, 77, 102, 107, 110], "calibr": [68, 69, 78], "call": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 38, 41, 42, 47, 49, 50, 51, 52, 56, 58, 59, 60, 61, 64, 65, 70, 71, 72, 74, 75, 76, 77, 78, 79, 82, 85, 87, 88, 101, 102, 107, 110, 113, 115, 116], "callabl": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 48, 57, 58, 59, 68, 83, 85, 111], "callawai": 49, "camera": 63, "cameron": [50, 70], "can": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 24, 35, 38, 40, 42, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 91, 92, 94, 98, 99, 101, 102, 103, 104, 107, 108, 109, 110, 111, 112, 113, 115, 116], "candid": 78, "cannot": [68, 76, 78, 86, 116], "capabl": [7, 10, 47, 56], "capo": [4, 67], "capo0": 67, "capo1": 67, "capsiz": [55, 69, 73, 76], "capthick": [55, 76], "cardin": [50, 70], "care": 85, "carlo": [21, 22, 24, 27, 58, 59, 64, 65, 78, 114], "casalicchio": [52, 85, 111, 113], "case": [4, 7, 10, 11, 12, 20, 24, 35, 47, 50, 51, 56, 58, 59, 60, 63, 65, 66, 67, 69, 70, 74, 75, 76, 77, 78, 82, 84, 85, 86, 87, 88, 101, 102, 107, 113, 115, 116], "cat": [48, 115], "catboost": 68, "cate": [12, 15, 39, 67, 83, 115], "cate_obj": 84, "cattaneo": [86, 114], "caus": [48, 57, 76, 81], "causal": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 25, 26, 28, 29, 30, 31, 32, 35, 47, 48, 50, 51, 52, 56, 57, 67, 68, 69, 70, 71, 73, 77, 79, 80, 81, 82, 83, 86, 87, 101, 102, 107, 114], "causal_contrast": [5, 55, 67, 86], "causal_contrast_att": 67, "causal_contrast_c": 67, "causal_contrast_model": [55, 86], "causaldml": 114, "causalweight": 114, "caution": 101, "caveat": [65, 78], "cbind": 50, "cc": 71, "ccp_alpha": [12, 40, 71], "cd": 112, "cd_fast": 70, "cda85647": 52, "cdf": 84, "cdid": [50, 70], "cdot": [21, 22, 23, 27, 36, 50, 60, 62, 66, 70, 73, 75, 76, 78, 84, 86, 88, 89, 94, 95, 96, 97, 101, 102, 103], "cdot1": 66, "cell": 69, "center": 63, "central": [87, 115], "certain": [65, 86], "cexcol": 50, "cexrow": 50, "cf_d": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 43, 55, 66, 67, 77, 78, 102, 103, 104, 107, 108, 109, 110, 116], "cf_y": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 43, 55, 66, 67, 77, 78, 102, 103, 104, 107, 108, 109, 110, 116], "chad": 78, "chain": 65, "chainedassignmenterror": 65, "challeng": [50, 70, 102, 104], "chang": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 37, 38, 41, 42, 51, 61, 65, 72, 77, 78, 79, 86, 88, 94, 101, 102, 103, 104, 105, 106, 107, 108, 112, 114, 115], "channel": 116, "chapter": [33, 34, 52, 85, 102, 110], "charact": [51, 52, 85, 115], "characterist": [77, 116], "chart": 69, "check": [37, 38, 41, 42, 48, 51, 57, 68, 69, 71, 72, 80, 81, 111, 112, 115], "check_data": 115, "check_scor": 115, "checkmat": 115, "chernozhukov": [19, 20, 26, 28, 30, 48, 50, 51, 57, 63, 68, 69, 70, 71, 72, 77, 81, 87, 88, 94, 101, 102, 104, 110, 111, 114, 115], "chetverikov": [19, 20, 30, 50, 63, 70, 81, 101, 111, 114], "chiang": [29, 50, 70, 114], "chieh": 114, "choic": [4, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 51, 63, 71, 74, 84, 85, 102, 104, 107, 110, 115], "choos": [47, 51, 56, 57, 63, 68, 71, 72, 80, 87, 88, 91, 92, 94, 98, 99, 101, 113, 116], "chosen": [4, 22, 27, 68, 85, 86], "chou": 73, "chr": 51, "christian": [63, 114], "christoph": 114, "chunk": 85, "ci": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 35, 55, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 71, 72, 75, 76, 77, 78, 84, 86, 102, 107, 115, 116], "ci_at": 55, "ci_cvar": [60, 72], "ci_cvar_0": 60, "ci_cvar_1": 60, "ci_joint": 55, "ci_joint_cvar": 60, "ci_joint_lqt": 75, "ci_joint_qt": 75, "ci_length": 61, "ci_low": 55, "ci_lpq_0": 75, "ci_lpq_1": 75, "ci_lqt": [72, 75], "ci_pointwis": 55, "ci_pq_0": [72, 75], "ci_pq_1": [72, 75], "ci_qt": [72, 75], "ci_upp": 55, "cinelli": [78, 102, 104, 114], "circumv": 116, "citat": 115, "claim": 52, "clash": 49, "class": [0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 33, 34, 35, 37, 38, 39, 40, 41, 42, 51, 52, 53, 55, 61, 66, 67, 69, 71, 72, 77, 79, 80, 82, 84, 85, 87, 88, 101, 111, 113, 115], "class_estim": 76, "class_learn": 72, "class_learner_1": 68, "class_learner_2": 68, "classes_": 69, "classic": [49, 50, 70, 116], "classif": [12, 37, 41, 47, 49, 51, 52, 68, 69, 74, 77, 84, 85, 86, 116], "classifavg": 52, "classifi": [4, 6, 8, 9, 11, 12, 13, 15, 16, 17, 18, 35, 37, 41, 52, 55, 69, 76, 85, 115], "classmethod": [7, 10], "claudia": [114, 115], "claus": 115, "clean": 115, "cleaner": 68, "cleanup": 115, "clear": [50, 70], "clearli": 76, "clever": 68, "clone": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 47, 48, 52, 57, 68, 70, 72, 80, 85, 86, 87, 88, 101, 102, 107, 112, 113], "close": [49, 51, 71, 78, 102, 104], "cluster": [4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 29, 114, 115], "cluster_col": [7, 50, 70], "cluster_var": [7, 29], "cluster_var_i": [7, 50, 70], "cluster_var_j": [7, 50, 70], "cmap": 70, "cmd": 115, "co": [31, 62], "codaci": 115, "code": [4, 12, 15, 31, 47, 49, 50, 51, 52, 56, 63, 71, 81, 84, 85, 86, 87, 88, 101, 112, 113, 115, 116], "codecov": 115, "coef": [6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 84, 85, 86, 87, 88, 101, 113, 116], "coef_": 78, "coef_df": 50, "coef_valu": 69, "coeffici": [21, 22, 24, 38, 39, 42, 51, 64, 65, 68, 71, 73, 74, 76, 78, 79, 84, 101, 102, 107, 116], "coefs_t": 74, "coefs_w": 74, "coffici": [102, 107], "cofid": 39, "coincid": [62, 67, 72], "col": [48, 50, 65, 71], "collect": [52, 61, 70, 79], "colnam": [50, 68], "color": [51, 55, 57, 58, 59, 60, 62, 69, 70, 71, 72, 73, 75, 76, 78], "color_palett": [55, 57, 70, 71, 72], "colorbar": 70, "colorblind": 55, "colorramppalett": 50, "colorscal": [58, 59], "colour": [48, 50], "column": [7, 10, 53, 55, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 82, 84, 85, 86, 87, 113, 115, 116], "column_stack": [55, 62, 64, 65, 76, 77, 78, 86], "colv": 50, "com": [31, 49, 51, 52, 63, 73, 78, 85, 112], "comb": 63, "combin": [49, 50, 52, 55, 61, 67, 68, 69, 70, 78, 85, 87, 102, 107, 115], "combind": 72, "combined_loss": 63, "come": [80, 85, 88, 102, 104, 111, 116], "command": [112, 115], "comment": 82, "common": [68, 77, 78, 84, 86, 114], "companion": 114, "compar": [48, 50, 57, 58, 59, 60, 62, 64, 65, 67, 70, 73, 75, 76, 78, 81, 85, 86, 102, 104], "comparevers": 51, "comparison": [55, 68, 73], "compat": [47, 49, 56, 115], "complement": 78, "complet": [69, 81, 102, 107, 112], "complex": [12, 49, 69], "compli": [76, 86], "complianc": [75, 76, 86, 88, 95], "complic": [52, 116], "complier": [51, 71, 72, 75, 76, 84, 86], "compon": [41, 42, 49, 51, 63, 68, 69, 71, 74, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 98, 99, 115], "compont": 49, "composit": 114, "compris": 101, "comput": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 39, 43, 48, 49, 51, 52, 57, 71, 72, 77, 78, 87, 88, 102, 103, 104, 105, 106, 107, 108, 111, 114, 115, 116], "computation": [102, 104], "concat": [69, 70, 71, 74, 101], "concaten": [62, 71, 101], "concentr": 101, "concern": 78, "conclud": [76, 78, 116], "cond": 86, "conda": [70, 114, 115], "condit": [4, 6, 12, 15, 21, 22, 24, 33, 34, 48, 50, 51, 55, 57, 61, 62, 66, 67, 70, 71, 74, 76, 78, 79, 81, 83, 86, 101, 102, 103, 108, 110, 113, 114, 115, 116], "conduct": [84, 86, 116], "conf": [49, 75], "confer": 114, "confid": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 39, 49, 50, 51, 55, 58, 59, 60, 61, 64, 65, 67, 70, 72, 75, 76, 77, 79, 83, 84, 87, 88, 102, 107, 113, 114, 116], "confidenceband": 60, "confidenti": 78, "config": 73, "configur": [52, 69], "confint": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 39, 51, 55, 58, 59, 60, 61, 62, 64, 65, 67, 68, 72, 74, 75, 76, 77, 79, 84, 87, 101, 111, 113, 116], "conflict": 112, "confound": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 24, 43, 47, 51, 56, 66, 71, 75, 77, 78, 82, 86, 101, 102, 104, 107, 109, 110, 113, 114, 115, 116], "congress": 114, "connect": [51, 71, 72], "consequ": [21, 22, 50, 66, 70, 77, 84, 86, 102, 103, 104, 108, 110], "conserv": [77, 78, 102, 110], "consid": [6, 11, 12, 13, 16, 36, 48, 50, 51, 57, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 84, 85, 86, 87, 88, 101, 102, 104, 111, 116], "consider": [78, 86], "consist": [14, 15, 38, 42, 51, 61, 69, 71, 72, 73, 78, 81, 82, 86, 113, 115], "consol": [48, 115], "constant": [26, 38, 42, 63, 74, 84, 86, 101], "constrained_layout": 57, "construct": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 39, 52, 58, 59, 60, 62, 67, 72, 77, 80, 84, 88, 90, 97, 101, 115, 116], "construct_framework": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "construct_iv": 70, "constructiv": 50, "constructor": 52, "consum": [50, 70], "cont": 27, "cont_d": 55, "contain": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 27, 36, 37, 38, 41, 42, 48, 50, 51, 55, 57, 58, 59, 64, 65, 68, 70, 71, 81, 84, 85, 101, 102, 104, 107, 115], "context": [78, 86, 116], "contin": [27, 69], "continu": [27, 47, 52, 55, 56, 63, 73, 76, 86, 102, 110, 115, 116], "contour": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 63, 66, 77, 78, 102, 107], "contour_plot": 78, "contours_z": [58, 59], "contrast": [5, 60, 61, 67, 86], "contribut": [112, 115], "contributor": 115, "control": [28, 36, 49, 63, 67, 72, 74, 76, 78, 116], "convent": [35, 51, 71, 72, 76, 86], "converg": [48, 57, 68, 70, 81], "convergencewarn": 70, "convers": 70, "convert": [60, 70, 75], "convex": 73, "cooper": 115, "coor": [52, 85, 111, 113], "coordin": 78, "copi": [65, 69, 71, 74, 78], "cor": [102, 110], "core": [53, 55, 60, 61, 66, 70, 71, 72, 75, 77, 79, 82, 85, 113, 115], "cores_us": [60, 72, 75], "correct": [66, 67, 78, 84, 101, 115], "correctli": [37, 41, 61, 73, 77, 102, 110], "correl": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 50, 63, 70, 77, 79, 86, 102, 104, 110], "correpond": 86, "correspond": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 27, 33, 34, 48, 50, 51, 52, 55, 57, 58, 59, 61, 62, 63, 67, 68, 70, 71, 72, 74, 75, 77, 78, 81, 84, 85, 86, 87, 101, 102, 104, 107, 108, 110, 115, 116], "cosh": 31, "coul": 50, "could": [47, 52, 56, 58, 59, 69, 78, 115, 116], "counfound": [21, 22, 75, 77, 84, 102, 110], "count": [55, 71, 72], "countour": [102, 107], "coupl": [51, 71, 72], "cournapeau": [111, 113], "cours": [51, 68, 71, 78, 101, 116], "cov": [18, 21, 36, 76], "cov_nam": [76, 86], "cov_typ": [4, 12, 15, 39, 115], "covari": [7, 8, 9, 10, 12, 14, 15, 21, 22, 24, 25, 26, 28, 29, 30, 31, 32, 35, 36, 39, 40, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 73, 74, 77, 78, 79, 81, 82, 84, 85, 86, 88, 91, 92, 101, 102, 104, 113, 114, 115], "cover": [49, 63, 77], "coverag": [68, 76, 84, 115], "cp": [51, 52, 85], "cpu": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "cpu_count": [60, 72, 75], "cran": [52, 114, 115], "creat": [24, 47, 50, 52, 55, 56, 57, 58, 59, 60, 64, 65, 70, 72, 74, 75, 78, 85, 102, 104, 107, 110, 112, 115], "create_synthetic_group_data": 74, "critic": [78, 116], "cross": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 23, 47, 48, 49, 51, 52, 57, 68, 69, 71, 72, 76, 78, 81, 83, 85, 91, 92, 97, 101, 105, 107, 115, 116], "cross_sectional_data": [9, 23, 61, 86], "crossfit": [68, 86], "crosstab": 73, "crucial": [63, 86, 116], "csail": [111, 113], "csv": 63, "cumul": 86, "current": [40, 49, 65, 67, 88, 102, 110, 111, 112, 116], "custom": [48, 49, 57, 78, 85], "custom_measur": 49, "cut": 74, "cutoff": [35, 36, 76, 86], "cv": [52, 71, 85, 87], "cv_glmnet": [50, 51, 52, 85, 101, 113], "cvar": [6, 17, 83, 90, 115], "cvar_0": 60, "cvar_1": 60, "d": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 39, 40, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 116], "d0": [60, 75, 101], "d0_true": 75, "d0cdb0ea4795": 52, "d1": [60, 73, 75, 101], "d10": 101, "d1_true": 75, "d2": [73, 101], "d21ee5775b5f": 52, "d3": 101, "d4": 101, "d5": 101, "d5a0c70f1d98": 52, "d6": 101, "d7": 101, "d8": 101, "d9": 101, "d_": [27, 29, 50, 55, 62, 70, 86, 101], "d_0": 86, "d_1": [73, 101], "d_2": 73, "d_col": [7, 10, 47, 48, 50, 51, 52, 56, 58, 59, 64, 65, 67, 70, 71, 72, 74, 76, 77, 80, 81, 82, 85, 86, 87, 88, 113, 115, 116], "d_i": [24, 25, 26, 28, 30, 31, 32, 48, 55, 57, 60, 61, 73, 75, 76, 79, 81, 86], "d_j": [55, 86, 101], "d_k": [86, 101], "d_l": 86, "d_w": 74, "da1440": 73, "dag": [78, 79, 116], "dark": [48, 57], "darkblu": 50, "darkr": 50, "dash": 55, "dat": 82, "data": [0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 39, 41, 42, 49, 62, 63, 68, 73, 80, 83, 84, 85, 87, 101, 106, 107, 114, 115], "data_apo": 55, "data_cvar": 72, "data_dict": [35, 58, 59, 64, 65, 66, 76, 86], "data_dml": 77, "data_dml_bas": [51, 58, 59, 64, 65, 71, 72, 74], "data_dml_base_iv": [51, 71, 72], "data_dml_flex": [51, 71], "data_dml_flex_iv": 51, "data_dml_iv_flex": 71, "data_dml_new": 74, "data_fram": 116, "data_lqt": 72, "data_pq": 72, "data_qt": 72, "data_transf": [50, 70, 71], "datafram": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 25, 26, 28, 29, 30, 31, 32, 35, 39, 40, 50, 53, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 88, 101, 102, 104, 107, 113, 116], "dataset": [0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 35, 48, 49, 55, 57, 58, 59, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 101, 102, 107, 113, 116], "datatyp": 115, "date": 85, "db": [51, 71, 72, 77, 116], "dbl": [49, 50, 51, 52, 82, 101, 113, 116], "dc13a11076b3": 52, "ddc9": 52, "de": [47, 56, 114], "deal": [47, 56], "debias": [19, 20, 29, 30, 50, 63, 70, 83, 85, 87, 111, 114, 115], "debt": [51, 71, 72], "decai": 79, "decid": [51, 71], "decis": [12, 47, 51, 56, 71, 72, 84, 86, 114, 116], "decision_effect": 47, "decision_impact": [47, 56], "decisiontreeclassifi": [12, 40, 71], "decisiontreeregressor": 71, "declar": 116, "decreas": 76, "deep": [37, 38, 41, 42, 69], "deeper": 12, "def": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 57, 60, 68, 69, 70, 73, 74, 75, 78, 85, 88], "default": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 27, 29, 30, 31, 35, 36, 37, 38, 39, 40, 41, 42, 49, 50, 61, 64, 65, 68, 70, 74, 76, 77, 78, 79, 80, 84, 85, 86, 87, 101, 102, 103, 107, 113, 116], "default_convert": 70, "defier": [76, 86], "defin": [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 38, 42, 48, 51, 52, 55, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 71, 72, 74, 75, 76, 77, 78, 84, 85, 86, 88, 91, 92, 102, 104, 107, 110], "definit": [31, 64, 65, 67, 102, 103, 108], "defint": 102, "degre": [36, 51, 58, 59, 67, 70, 71, 76, 84, 102, 104], "dekel": 114, "delete_origin": 52, "deliber": 73, "delta": [28, 49, 61, 78, 86], "delta_bench": 78, "delta_i": 49, "delta_j": 28, "delta_theta": [43, 55, 66, 77, 78, 102, 104], "delta_v": 78, "demand": [50, 70, 102, 104], "demir": [19, 20, 30, 50, 63, 70, 81, 87, 111, 114], "demo": 78, "demonstr": [48, 49, 50, 57, 70, 76, 78, 82, 86, 101, 111, 113], "deni": 114, "denomin": [102, 103, 104, 108], "denot": [14, 50, 51, 61, 62, 70, 71, 76, 78, 79, 84, 86, 88, 102, 104, 107, 108, 110], "dens_net_tfa": 51, "densiti": [13, 16, 17, 48, 55, 57], "dep": 53, "dep1": [52, 53, 82, 113], "dep2": [52, 53, 82, 113], "depend": [4, 6, 12, 13, 17, 24, 52, 58, 59, 61, 64, 65, 66, 68, 69, 74, 76, 80, 84, 85, 86, 88, 95, 100, 102, 103, 104, 110, 113, 114], "deprec": [80, 87], "depreci": 115, "depth": [12, 40, 51, 52, 74, 80, 84, 85, 86, 87, 88, 101, 113, 116], "deriv": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 34, 86, 101], "describ": [49, 50, 70, 71, 72, 78, 85, 87, 112, 115], "descript": [51, 53, 77, 85, 87, 102, 104], "deserv": 86, "design": [35, 36, 55, 69, 83, 114, 115], "design_info": [58, 59], "design_matrix": [58, 59, 84], "desir": [22, 52, 74, 86, 112], "detail": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 33, 34, 48, 51, 52, 55, 57, 61, 62, 63, 69, 72, 76, 77, 78, 81, 82, 84, 85, 88, 90, 94, 95, 96, 97, 100, 101, 102, 104, 110, 111, 112, 113, 115, 116], "determin": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 38, 42, 51, 60, 71, 72, 75, 76, 77, 86, 101, 102, 110], "determinist": [74, 76, 84, 86], "deutsch": 111, "dev": [112, 115], "develop": [49, 50, 52, 70, 78, 86, 115], "deviat": [68, 86, 102, 110], "dezeur": 114, "df": [7, 10, 47, 48, 50, 55, 56, 58, 59, 60, 62, 65, 67, 70, 73, 75, 76, 77, 78, 79, 81, 84, 86], "df_agg": 63, "df_apo": 55, "df_apo_ci": 55, "df_apos_ci": 55, "df_ate": 55, "df_bench": 78, "df_binari": 78, "df_bonu": [52, 82, 113], "df_capo0": 67, "df_capo1": 67, "df_cate": [58, 59, 67], "df_causal_contrast_c": 67, "df_ci": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 39], "df_coef": 68, "df_cvar": 72, "df_fuzzi": 76, "df_lqte": 72, "df_ml_g0": 68, "df_ml_g1": 68, "df_ml_m": 68, "df_pa": [61, 79], "df_plot": 50, "df_pq": 72, "df_qte": 72, "df_result": 63, "df_sharp": 76, "df_sort": 55, "df_summari": 71, "df_wide": 70, "dfg": 111, "dgp": [23, 50, 60, 62, 63, 70, 73, 74, 75, 78, 79], "dgp1": 23, "dgp2": 23, "dgp3": 23, "dgp4": 23, "dgp5": 23, "dgp6": 23, "dgp_dict": 78, "dgp_tpye": 61, "dgp_type": [23, 61], "diagon": 78, "diagram": [47, 56, 86], "dichotom": [47, 56], "dict": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 37, 38, 39, 40, 41, 42, 43, 58, 59, 63, 69, 78, 85], "dict_kei": [102, 107], "dictionari": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 24, 27, 36, 43, 58, 59, 64, 65, 77, 84, 85, 102, 107], "dictonari": [51, 71], "did": [7, 10, 48, 61, 62, 70, 83, 115, 116], "diff": 71, "differ": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 24, 47, 48, 50, 51, 52, 55, 56, 57, 60, 64, 65, 66, 67, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 83, 84, 85, 87, 91, 92, 112, 113, 114, 115, 116], "differenti": 86, "difficult": 78, "dillon": 114, "dim": [36, 51], "dim_x": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 25, 26, 28, 29, 30, 31, 32, 36, 48, 50, 52, 57, 67, 68, 69, 70, 81, 84, 85, 86, 102, 107], "dim_z": [14, 28, 86], "dimens": [24, 29, 50, 70, 74, 87], "dimension": [14, 15, 24, 26, 63, 84, 86, 87, 101, 102, 107, 113, 114], "direct": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 48, 57, 62, 67, 79, 81, 86, 116], "directli": [35, 48, 49, 51, 55, 57, 68, 77, 81, 102, 107, 113, 116], "discontinu": [35, 36, 83, 114, 115], "discret": [5, 27, 55, 70, 86, 115], "discretis": 72, "discuss": [25, 50, 51, 70, 71, 114, 115, 116], "disjoint": [50, 64, 65, 70], "displai": [50, 55, 70, 78, 84, 85, 102, 107], "displot": 71, "disproportion": [51, 71], "disregard": [38, 42], "dist": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "distr": 85, "distribut": [36, 48, 55, 57, 61, 68, 78, 81, 86, 102, 108, 112, 114, 115], "diverg": [35, 48, 57, 81], "divid": 86, "dmatrix": [58, 59, 84], "dml": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 33, 34, 35, 47, 48, 52, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 88, 101, 102, 107, 112], "dml1": [83, 113, 115, 116], "dml2": [47, 50, 52, 53, 61, 70, 72, 83, 86, 88, 101, 113, 115, 116], "dml_apo": 67, "dml_apo_obj": 86, "dml_apos_att": 67, "dml_apos_obj": 86, "dml_base": 70, "dml_combin": 101, "dml_cv_predict": 115, "dml_cvar": [60, 72], "dml_cvar_0": 60, "dml_cvar_1": 60, "dml_cvar_obj": [6, 84], "dml_data": [49, 50, 53, 55, 61, 62, 66, 67, 68, 70, 73, 77, 78, 79, 84, 85, 86, 101, 116], "dml_data_bench": 78, "dml_data_bonu": [52, 113], "dml_data_df": 116, "dml_data_fuzzi": 76, "dml_data_lasso": 53, "dml_data_sharp": 76, "dml_data_sim": [52, 113], "dml_df": [50, 70], "dml_did": [61, 62], "dml_did_obj": [8, 9, 86], "dml_iivm_boost": [51, 71], "dml_iivm_forest": [51, 71], "dml_iivm_lasso": [51, 71], "dml_iivm_obj": [11, 56, 86], "dml_iivm_tre": [51, 71], "dml_irm": [58, 64, 67, 68, 74], "dml_irm_at": 66, "dml_irm_att": 67, "dml_irm_boost": [51, 71], "dml_irm_forest": [51, 71], "dml_irm_gat": 66, "dml_irm_gatet": 66, "dml_irm_lasso": [51, 53, 71], "dml_irm_new": 74, "dml_irm_obj": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 77, 84, 85, 86], "dml_irm_obj_ext": 85, "dml_irm_rf": 53, "dml_irm_tre": [51, 71], "dml_irm_weighted_att": 67, "dml_kwarg": 67, "dml_long": 43, "dml_lpq_0": 75, "dml_lpq_1": 75, "dml_lpq_obj": [13, 84], "dml_lqte": [72, 75], "dml_obj": [49, 55, 77, 78], "dml_obj_bench": 78, "dml_pliv": [50, 70], "dml_pliv_obj": [14, 50, 70, 86], "dml_plr": [59, 65, 101], "dml_plr_1": 101, "dml_plr_2": 101, "dml_plr_boost": [51, 71], "dml_plr_forest": [51, 71, 116], "dml_plr_lasso": [51, 53, 71], "dml_plr_no_split": 87, "dml_plr_obj": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 77, 80, 84, 85, 86, 87, 88, 101, 102, 104, 107], "dml_plr_obj_extern": 87, "dml_plr_obj_intern": 87, "dml_plr_obj_onfold": 69, "dml_plr_obj_untun": 69, "dml_plr_rf": 53, "dml_plr_tree": [51, 71, 116], "dml_pq_0": [72, 75], "dml_pq_1": [72, 75], "dml_pq_obj": [16, 84], "dml_procedur": [53, 80, 113, 115, 116], "dml_qte": [72, 75], "dml_qte_obj": [17, 84], "dml_short": 43, "dml_ssm": [79, 86], "dml_tune": 115, "dmldummyclassifi": 85, "dmldummyregressor": 85, "dmlmt": 114, "dnorm": 48, "do": [49, 50, 51, 52, 67, 68, 70, 71, 72, 73, 78, 84, 85, 102, 110, 113, 116], "doabl": 88, "doc": [47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 111, 115], "doccument": 115, "docu": 115, "document": [54, 58, 59, 62, 64, 65, 67, 69, 78, 111, 115], "doe": [5, 17, 49, 50, 51, 55, 67, 70, 71, 73, 77, 78, 102, 110, 116], "doesn": [47, 56], "doi": [19, 20, 21, 22, 23, 25, 29, 30, 32, 49, 50, 52, 63, 70, 78, 81, 85, 87, 101, 111, 113, 115], "domain": 74, "don": [49, 69], "done": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 69, 72, 85, 87, 102, 104], "dosag": 55, "dot": [18, 62, 74, 82, 84, 85, 86, 101, 113], "doubl": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 29, 30, 31, 32, 35, 51, 63, 68, 69, 71, 73, 83, 85, 87, 88, 101, 102, 104, 115], "double_ml_bonus_data": 53, "double_ml_data_from_data_fram": [48, 81, 82, 116], "double_ml_data_from_matrix": [49, 52, 82, 85, 101, 113], "double_ml_irm": [53, 74], "double_ml_score_mixin": 0, "doubleiivm": 111, "doubleml": [0, 48, 50, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 107, 113, 114, 115], "doubleml2022python": 111, "doubleml2024r": 111, "doubleml_did_eval_linear": 49, "doubleml_did_eval_rf": 49, "doubleml_did_linear": 49, "doubleml_did_rf": 49, "doubleml_framework": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "doublemlapo": [0, 55, 67, 86, 88, 89, 115], "doublemlblp": [4, 12, 15, 58, 59, 67, 84, 115], "doublemlclusterdata": [0, 29], "doublemlcvar": [0, 60, 84, 88, 90, 115], "doublemldata": [0, 4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 25, 26, 28, 30, 31, 32, 35, 47, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 101, 102, 107, 115, 116], "doublemldid": [0, 61, 62, 86, 88, 91, 115], "doublemldidc": [0, 61, 86, 88, 92, 115], "doublemlframework": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 87, 101, 115], "doublemlframwork": 5, "doublemlidid": 86, "doublemlididc": 86, "doublemliivm": [0, 47, 51, 56, 71, 85, 86, 87, 88, 93, 115], "doublemlirm": [0, 4, 6, 8, 9, 11, 13, 14, 15, 16, 18, 49, 51, 53, 55, 58, 64, 66, 67, 68, 71, 73, 74, 77, 78, 84, 85, 86, 87, 88, 94, 111, 115], "doublemllpq": [0, 75, 84, 88, 95, 115], "doublemlpliv": [0, 85, 86, 87, 88, 98, 111, 115], "doublemlplr": [0, 4, 5, 6, 8, 9, 11, 12, 13, 14, 16, 17, 18, 48, 51, 52, 53, 57, 59, 65, 69, 71, 73, 77, 80, 81, 84, 85, 86, 87, 88, 99, 101, 102, 107, 111, 113, 115, 116], "doublemlpolicytre": [12, 84], "doublemlpq": [0, 72, 75, 84, 88, 100, 115], "doublemlqt": [0, 60, 72, 75, 84, 101, 115], "doublemlresampl": [67, 68], "doublemlsmm": 115, "doublemlssm": [0, 79, 86, 88, 96, 97], "doubli": [21, 22, 23, 49, 114], "down": 78, "download": [47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 112, 113], "downward": 78, "dpg_dict": 77, "dpi": [48, 57, 73], "dramat": 49, "draw": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 78, 87, 115], "draw_sample_split": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 67, 68, 87], "drawn": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 24, 36, 51, 71, 72, 74, 87], "drive": [48, 57, 81], "driven": [78, 116], "drop": [49, 69, 70, 73, 82, 85, 88, 91, 92, 101], "dt": [88, 92, 102, 105], "dt_bonu": 82, "dta": 49, "dtrain": 71, "dtype": [53, 55, 61, 64, 65, 66, 68, 70, 71, 72, 77, 79, 82, 84, 113], "dualiti": 70, "dubourg": [111, 113], "duchesnai": [111, 113], "due": [48, 49, 57, 58, 59, 66, 77, 78, 81, 86, 102, 104, 115, 116], "duflo": [19, 20, 30, 50, 63, 70, 81, 87, 111, 114], "dummi": [4, 12, 15, 37, 38, 39, 69, 78, 84, 85, 86, 115], "dummyclassifi": 37, "dummyregressor": 38, "duplic": 115, "durabl": [52, 53, 82, 113], "durat": 20, "dure": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 49, 50, 51, 52, 69, 70, 71, 85, 87, 113, 115, 116], "dx": 25, "dynam": [49, 114], "e": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 27, 30, 32, 33, 34, 35, 37, 38, 41, 42, 48, 49, 50, 51, 55, 57, 58, 59, 61, 63, 66, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116], "e20ea26": 52, "e401": [51, 71, 72, 77, 116], "e4016553": 116, "e45228": 73, "e57c": 52, "each": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 27, 37, 38, 41, 42, 50, 52, 55, 62, 64, 65, 68, 69, 70, 72, 73, 74, 77, 78, 80, 82, 85, 86, 87, 101, 102, 107, 116], "earlier": 116, "earn": [51, 71, 72], "earner": [51, 71, 77], "easi": [52, 88], "easier": 69, "easili": [52, 68, 69, 72, 115], "ec973f": 73, "ecolor": [55, 62, 71, 73], "econ": 114, "econml": 114, "econom": [28, 29, 31, 32, 50, 63, 70, 73, 78, 87, 114], "econometr": [19, 20, 21, 22, 23, 30, 31, 49, 50, 63, 70, 81, 111, 114], "econometrica": [26, 50, 70, 73, 81, 114], "ecosystem": [111, 116], "ectj": [19, 20, 30, 50, 63, 70, 81, 111], "ed": 114, "edge_color": 57, "edgecolor": 57, "edit": [112, 114], "edu": [111, 113], "educ": [51, 71, 72, 77, 116], "ee97bda7": 52, "effect": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 27, 36, 37, 38, 41, 42, 47, 48, 49, 50, 52, 55, 56, 57, 61, 62, 63, 66, 70, 74, 76, 79, 81, 83, 85, 86, 87, 88, 94, 101, 102, 104, 113, 114, 115, 116], "effici": [86, 114], "effort": 88, "eight": [50, 70], "either": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 24, 52, 62, 63, 74, 76, 84, 85, 86, 116], "eleanor": 114, "element": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 50, 58, 59, 60, 61, 68, 70, 72, 75, 77, 79, 88, 89, 91, 92, 102, 107, 109, 110, 115], "element_text": [50, 51], "elementari": 114, "elif": [64, 65, 74], "elig": [72, 77, 116], "eligibl": [51, 71, 77], "ell": [48, 50, 57, 63, 70, 81, 88, 98, 99, 113], "ell_0": [11, 14, 15, 48, 57, 63, 69, 81, 86], "ell_2": 68, "els": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 39, 49, 50, 51, 62, 64, 65, 70, 74, 78], "em": 114, "emphas": [50, 70], "empir": [33, 34, 48, 50, 57, 70, 73, 78, 81, 86, 87, 88, 101], "emploi": [50, 63, 70, 78, 88, 93], "employ": [51, 71, 72], "employe": 116, "empti": 70, "emul": [102, 104], "enabl": [55, 74, 77, 84, 102, 104, 115], "enable_metadata_rout": [37, 38, 41, 42], "encapsul": [37, 38, 41, 42], "encod": 73, "end": [25, 28, 29, 48, 49, 50, 51, 57, 60, 62, 63, 68, 70, 71, 73, 74, 75, 79, 80, 82, 85, 87, 101, 113, 116], "endogen": [51, 71, 72, 116], "enet_coordinate_descent_gram": 70, "engin": [52, 114], "enrol": [51, 71, 72], "ensembl": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 53, 55, 57, 58, 59, 64, 65, 66, 68, 71, 74, 77, 78, 80, 84, 85, 86, 87, 88, 101, 102, 107, 113, 116], "ensemble_learner_pipelin": 85, "ensemble_pipe_classif": 52, "ensemble_pipe_regr": 52, "ensur": [41, 42, 50, 65, 67, 69, 70, 74], "entir": [48, 51, 57, 71, 81, 102, 104], "entri": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 48, 50, 53, 55, 57, 61, 66, 70, 71, 72, 77, 79, 81, 82, 85, 111, 113, 115], "enumer": [55, 60, 62, 64, 65, 68, 70, 71, 72, 75, 80, 85, 87], "env": [70, 112], "environ": 112, "ep": 73, "epanechnikov": 35, "epsilon": [51, 60, 61, 62, 71, 75, 84, 86], "epsilon_": [50, 62, 70], "epsilon_0": 36, "epsilon_1": 36, "epsilon_i": [24, 60, 73, 74, 75], "epsilon_sampl": 74, "epsilon_tru": [60, 75], "eqnarrai": 51, "equal": [4, 12, 50, 70, 73, 79, 84, 85, 86, 102, 108], "equat": [36, 50, 51, 70, 71, 78, 80, 101, 116], "equilibrium": [50, 70], "equival": [63, 67, 87], "err": [6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 53, 55, 56, 58, 59, 60, 61, 64, 65, 66, 67, 69, 70, 71, 72, 73, 75, 77, 78, 79, 84, 85, 86, 87, 88, 101, 113, 116], "error": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 37, 38, 41, 42, 47, 48, 49, 51, 52, 57, 62, 63, 64, 65, 68, 69, 71, 76, 78, 81, 85, 86, 87, 88, 101, 102, 107, 113, 115, 116], "errorbar": [55, 62, 64, 65, 69, 71, 73, 76], "erstellt": [50, 51, 52], "esim": 76, "especi": [68, 69], "essenti": 78, "est": 76, "est_method": 49, "esther": [87, 114], "estim": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 33, 34, 35, 37, 38, 39, 40, 41, 42, 48, 49, 50, 52, 55, 57, 58, 59, 60, 62, 64, 65, 67, 68, 70, 74, 76, 80, 81, 83, 84, 85, 86, 90, 91, 92, 95, 97, 100, 102, 104, 107, 111, 114, 115], "estimatior": [7, 10], "estimator_list": 69, "et": [19, 20, 24, 26, 29, 30, 48, 50, 51, 52, 57, 58, 59, 60, 61, 63, 64, 65, 68, 70, 71, 72, 75, 77, 81, 86, 87, 88, 90, 94, 95, 100, 101, 102, 104, 110, 111, 113, 115], "eta": [33, 34, 48, 50, 51, 62, 69, 70, 71, 75, 76, 80, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 110, 113, 116], "eta1": 73, "eta2": 73, "eta_": [101, 102, 110], "eta_0": [35, 80, 86, 88, 101], "eta_d": [76, 86], "eta_i": [24, 62, 74, 75, 76, 86], "eta_sampl": 74, "eta_tru": 75, "etc": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 50, 68, 69, 70, 115], "ev": [48, 57, 81], "eval": [52, 85], "eval_metr": [51, 71, 116], "eval_pr": 49, "eval_predict": 49, "evalu": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 26, 34, 49, 52, 58, 59, 60, 62, 66, 67, 72, 75, 77, 80, 114, 115], "evaluate_learn": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 68, 69, 85, 115], "evalut": 85, "even": [51, 52, 71, 73, 76, 85, 86, 116], "eventu": [50, 70], "everi": [50, 70], "everyth": 111, "evid": [66, 69], "exact": [67, 78], "exactli": [76, 78, 86], "exampl": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 24, 35, 47, 48, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 79, 80, 81, 84, 85, 86, 87, 88, 101, 102, 107, 111, 113, 115, 116], "example_attgt": 49, "example_attgt_dml_eval_linear": 49, "example_attgt_dml_eval_rf": 49, "example_attgt_dml_linear": 49, "example_attgt_dml_rf": 49, "except": [38, 42, 63, 78, 115], "excess": 68, "exclud": 43, "exclus": [4, 12, 15, 64, 65, 84], "execut": [52, 116], "exemplarili": 113, "exemplatori": 74, "exhaust": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 85], "exhibit": [50, 70], "exist": [37, 38, 41, 42, 67, 86, 102, 110], "exogen": [51, 71, 72, 86, 116], "exp": [21, 22, 23, 24, 26, 27, 30, 48, 57, 58, 59, 62, 64, 65, 73, 74, 81], "expect": [21, 22, 38, 42, 49, 55, 61, 66, 68, 69, 76, 78, 79, 84, 86, 87, 101, 102, 103, 113], "experi": [20, 25, 26, 48, 51, 57, 71, 78, 81, 82, 87, 113, 114], "experiment": [8, 9, 23, 88, 91, 92, 102, 105, 106], "expertis": 78, "explain": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 22, 77, 102, 104, 109, 110], "explan": [50, 61, 70, 77, 102, 109, 111, 116], "explanatori": [78, 101], "explicit": 78, "explicitli": [66, 116], "exploit": [48, 57, 81, 86, 116], "explor": 69, "exponenti": 101, "export": [69, 115], "exposur": 62, "express": [50, 63, 76, 102, 110], "extend": [78, 85, 111, 115], "extendend": [102, 110], "extens": [85, 88, 111, 114, 115], "extent": 63, "extern": [48, 57, 67, 69, 83, 102, 104, 115], "external_predict": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 57, 85], "externalptr": 51, "extra": 52, "extract": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 69], "extralearn": 52, "extrem": [51, 71], "ey": 63, "f": [51, 52, 55, 57, 60, 61, 62, 63, 68, 70, 71, 72, 74, 75, 77, 78, 79, 85, 102, 110, 111, 113], "f00584a57972": 52, "f1718fdeb9b0": 52, "f2e7": 52, "f3d24993": 52, "f6ebc": 73, "f_": [21, 23, 62, 84], "f_loc": [60, 75], "f_p": 62, "f_scale": [60, 75], "f_x": 86, "face_color": 57, "facet_wrap": 51, "facilit": 69, "fact": [51, 71, 72], "factor": [36, 48, 49, 50, 51, 52, 57, 68, 81, 85, 116], "faculti": 114, "fail": 115, "fair": 68, "fake": [47, 56], "fals": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 35, 36, 37, 38, 39, 41, 42, 48, 51, 52, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 78, 79, 82, 85, 86, 87, 88, 91, 92, 101, 102, 105, 106, 116], "famili": [51, 71, 85], "fanci": 49, "far": [51, 71], "farbmach": 25, "fast": [68, 74, 85], "faster": 63, "fb5c25fa": 52, "fc9e": 52, "fd8a": 52, "featur": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 38, 40, 42, 49, 53, 66, 67, 68, 71, 74, 84, 85, 86], "featureless": [52, 85], "features_bas": [51, 71, 72, 77], "features_flex": 51, "featureunion": 52, "februari": 78, "femal": [52, 53, 82, 113], "fern\u00e1ndez": [26, 87, 114], "fetch": [51, 70, 71, 72, 82], "fetch_401k": [51, 71, 72, 77, 116], "fetch_bonu": [52, 53, 82, 113], "few": [51, 71, 72], "ff7f0e": 62, "field": [50, 70, 85, 116], "fifteenth": 114, "fifth": 50, "fig": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 55, 58, 59, 60, 62, 63, 67, 68, 69, 72, 73, 75, 76, 78], "fig_al": 57, "fig_dml": 57, "fig_non_orth": 57, "fig_orth_nosplit": 57, "fig_po_al": 57, "fig_po_dml": 57, "fig_po_nosplit": 57, "figsiz": [53, 55, 58, 59, 60, 62, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 76], "figur": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 30, 48, 50, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 67, 69, 70, 71, 72, 75, 78, 81], "figure_format": 73, "file": [19, 20, 63, 73, 114, 115], "filenam": 48, "fill": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 48, 50, 51, 61, 68, 71, 79], "fill_between": [58, 59, 60, 67, 72, 75], "fill_valu": 68, "filter": 52, "filterwarn": 57, "final": [48, 52, 55, 57, 58, 59, 60, 62, 64, 65, 66, 72, 75, 76, 79, 81, 86, 116], "final_estim": 76, "financi": [19, 77, 116], "find": [51, 62, 71, 78, 84, 85, 116], "finish": 52, "finit": [48, 51], "firm": [50, 70, 77], "firmid": 70, "first": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 29, 35, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 74, 75, 76, 78, 79, 81, 84, 86, 87, 101, 102, 107, 112, 113, 115, 116], "fit": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 37, 38, 39, 40, 41, 42, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 88, 91, 92, 97, 101, 102, 104, 107, 111, 115, 116], "fit_arg": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "fit_transform": [67, 70, 71], "five": 70, "fix": [62, 68, 115], "flag": [23, 87, 112], "flake8": 115, "flamlclassifierdoubleml": 69, "flamlregressordoubleml": 69, "flatten": [69, 73], "flexibl": [35, 47, 49, 51, 52, 56, 61, 71, 86, 111, 114, 115, 116], "flexibli": [51, 71, 77], "float": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 35, 36, 37, 38, 39, 41, 42], "float32": [71, 72, 77], "float64": [53, 55, 61, 65, 66, 70, 71, 77, 79, 82, 85, 113], "floor": 52, "floor_divid": 70, "flt": 52, "flush": 48, "fmt": [55, 62, 64, 65, 69, 71, 73, 76], "fobj": 71, "focu": [50, 51, 67, 70, 71, 72, 78, 84, 86, 116], "focus": [72, 77, 78, 116], "fold": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 47, 50, 51, 52, 61, 68, 70, 71, 72, 77, 79, 80, 83, 85, 86, 88, 91, 92, 101, 113, 116], "follow": [21, 22, 23, 24, 27, 48, 50, 51, 57, 58, 59, 60, 61, 62, 64, 65, 69, 70, 71, 72, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 116], "font_scal": [70, 71, 72], "fontsiz": [60, 72, 75], "force_all_x_finit": [7, 10], "forest": [25, 47, 48, 49, 51, 52, 56, 57, 61, 66, 68, 71, 77, 81, 85, 113, 116], "forest_summari": 71, "forg": [112, 114, 115], "form": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 24, 39, 41, 42, 51, 58, 59, 60, 61, 62, 64, 65, 66, 68, 71, 75, 76, 77, 79, 84, 86, 88, 89, 94, 102, 103, 104, 107, 108, 109, 110, 112, 113], "format": [57, 66, 102, 107], "formula": [50, 51, 70, 71, 76, 78, 115], "formula_flex": 51, "forschungsgemeinschaft": 111, "forthcom": [78, 114], "forum": 115, "forward": [12, 40], "found": [58, 59, 63, 64, 65, 69, 81, 82, 85, 86, 113], "foundat": [111, 114], "four": [51, 68, 71, 115], "fourth": [50, 70], "frac": [11, 21, 22, 23, 25, 26, 28, 30, 31, 32, 34, 38, 42, 48, 50, 52, 57, 62, 63, 66, 70, 73, 76, 80, 81, 84, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110], "fraction": 52, "frame": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 39, 47, 48, 50, 51, 53, 55, 58, 59, 61, 64, 65, 66, 70, 71, 72, 73, 74, 77, 79, 81, 82, 113, 116], "framework": [34, 48, 50, 52, 57, 68, 69, 70, 73, 78, 81, 85, 101, 111, 113, 115, 116], "freez": 112, "fribourg": 114, "friendli": 55, "from": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 38, 39, 42, 47, 48, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 101, 102, 107, 113, 115, 116], "from_arrai": [7, 10, 18, 35, 57, 60, 61, 62, 75, 81, 82, 85, 101, 113], "from_product": 70, "front": 55, "fr\u00e9chet": [102, 110], "fs_kernel": [35, 86], "fs_specif": [35, 86], "fsize": [51, 71, 72, 77, 116], "full": [55, 57, 60, 61, 62, 64, 65, 68, 71, 72, 75, 76, 79, 81, 86], "fulli": [12, 51, 54, 69, 71, 86], "fun": 48, "func": 49, "function": [0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 30, 31, 33, 34, 35, 47, 48, 51, 52, 56, 57, 58, 59, 60, 61, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 110, 111, 114, 115, 116], "fund": [51, 71, 72, 111], "further": [21, 22, 23, 24, 27, 29, 50, 52, 55, 58, 59, 60, 61, 62, 66, 67, 68, 70, 72, 74, 75, 76, 77, 78, 79, 85, 86, 88, 90, 95, 96, 97, 100, 101, 102, 104, 107, 109, 110, 111, 113, 115, 116], "furthermor": [57, 88, 89, 94], "futurewarn": 65, "fuzzi": [35, 36], "g": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 35, 37, 38, 41, 42, 48, 49, 52, 53, 57, 58, 59, 61, 62, 63, 66, 68, 72, 73, 74, 77, 79, 81, 84, 85, 86, 88, 89, 91, 92, 93, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 116], "g_": [36, 55, 88, 90, 91, 92, 95, 100, 101], "g_0": [4, 8, 9, 11, 12, 14, 15, 16, 30, 31, 35, 36, 48, 50, 51, 57, 68, 70, 71, 81, 84, 85, 86, 88, 89, 96, 97, 102, 103, 108, 110, 113, 116], "g_1": [36, 68], "g_all": [48, 51], "g_all_po": 48, "g_ci": 51, "g_d": [88, 90, 100], "g_dml": 48, "g_dml_po": 48, "g_hat": [14, 15, 48, 57, 88], "g_hat0": [11, 12], "g_hat1": [11, 12], "g_k": 84, "g_nonorth": 48, "g_nosplit": 48, "g_nosplit_po": 48, "g_x": 62, "gain": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 22, 43, 68, 102, 104, 108, 115], "gain_statist": 115, "galleri": [81, 84, 85, 86, 111, 115], "gama": 69, "gamma": [28, 31, 32, 50, 70, 73, 74, 76, 78, 86, 88, 90, 95], "gamma_0": [24, 74, 79, 88, 90, 95], "gamma_a": [21, 22, 78], "gamma_bench": 78, "gamma_v": 78, "gap": [70, 78], "gapo": 4, "gate": [4, 12, 15, 39, 73, 74, 83, 115], "gate_obj": 84, "gatet": 84, "gaussian": [13, 16, 17, 48, 57, 81, 84, 85, 101, 114], "ge": [21, 23, 24, 66, 74, 84], "geer": 114, "gelbach": [50, 70], "gener": [0, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 42, 47, 49, 50, 51, 52, 53, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 94, 101, 103, 104, 105, 106, 108, 110, 114, 115, 116], "generate_treat": 75, "geom_bar": 51, "geom_dens": 51, "geom_errorbar": 51, "geom_funct": 48, "geom_histogram": 48, "geom_hlin": 51, "geom_point": 51, "geom_til": 50, "geom_vlin": 48, "geq": [76, 86], "german": 111, "get": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 37, 38, 41, 42, 52, 55, 68, 73, 77, 78, 102, 104, 111, 112], "get_dummi": 73, "get_feature_names_out": [67, 70, 71], "get_legend_handles_label": 55, "get_level_valu": 69, "get_logg": [48, 49, 50, 51, 52, 80, 85, 86, 87, 88, 101, 113], "get_metadata_rout": [37, 38, 41, 42], "get_param": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 37, 38, 41, 42, 69, 85], "get_ylim": 67, "ggdid": 49, "ggplot": [48, 50, 51], "ggplot2": [48, 50, 51], "ggsave": 48, "ggtitl": 51, "gh": 115, "git": 112, "github": [49, 51, 63, 69, 73, 111, 114, 115], "githubusercont": 63, "give": [51, 67, 71], "given": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 26, 30, 31, 34, 35, 36, 37, 38, 41, 42, 48, 50, 55, 57, 62, 64, 65, 70, 72, 73, 76, 78, 79, 81, 84, 88, 89, 101, 102, 103, 107, 108, 109, 110, 113, 115], "glmnet": [51, 52, 85, 115], "global": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 41, 42, 85, 86], "globalclassifi": 76, "globallearn": 76, "globalregressor": 76, "glrn": 52, "glrn_lasso": 52, "gname": 49, "go": [58, 59, 63, 67, 69, 76, 78], "goal": [55, 64, 65, 86], "goe": 86, "goldman": 114, "good": [63, 102, 104, 116], "gradient": [51, 71], "gradientboostingclassifi": 68, "gradientboostingregressor": 68, "gradual": 78, "gramfort": [111, 113], "graph": [52, 79, 116], "graph_ensemble_classif": 52, "graph_ensemble_regr": 52, "graph_obj": 76, "graph_object": [58, 59, 63, 78], "graphlearn": [52, 85], "grasp": [55, 102, 104], "great": [62, 116], "greater": 116, "green": [48, 58, 59, 60, 75], "greg": 114, "grei": [51, 55], "grenand": 114, "grey50": 50, "grid": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 50, 52, 55, 58, 59, 60, 63, 67, 72, 73, 75, 78, 85, 102, 107], "grid_arrai": [58, 59], "grid_basi": 67, "grid_bound": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 78], "grid_search": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 52, 85], "grid_siz": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 58, 59], "gridextra": 50, "gridsearchcv": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 85], "grisel": [111, 113], "grob": 50, "group": [4, 12, 15, 47, 49, 55, 56, 66, 67, 72, 73, 74, 78, 83], "group_0": 84, "group_1": [64, 65, 84], "group_2": [64, 65, 84], "group_3": [64, 65], "group_effect": 74, "group_ind": 66, "group_treat": 66, "groupbi": [63, 71], "gruber": 25, "gt": [47, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 113], "guarante": [50, 70], "guber": 25, "guess": [77, 102, 104], "guid": [33, 34, 37, 38, 41, 42, 48, 49, 50, 52, 55, 57, 62, 66, 67, 70, 76, 77, 85, 111, 113, 115], "guidelin": 115, "gunion": [52, 85], "gxidclusterperiodytreat": 49, "h": [21, 22, 23, 25, 29, 49, 50, 70, 76, 86, 114], "h20": 69, "h_0": [55, 66, 67, 77, 78, 102, 107, 116], "h_f": [35, 86], "ha": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 23, 37, 38, 39, 40, 41, 42, 48, 49, 50, 51, 57, 63, 68, 69, 70, 71, 72, 73, 76, 77, 78, 84, 85, 86, 102, 103, 104, 107, 108, 109, 110, 116], "half": [48, 57, 73, 81, 87], "hand": [35, 68, 69, 73, 116], "handbook": 73, "handl": [49, 55, 68, 85, 115], "hansen": [19, 20, 26, 28, 30, 50, 63, 70, 81, 111, 114], "happend": 68, "hard": [77, 102, 104], "harold": 114, "harsh": [37, 41], "hat": [48, 50, 57, 63, 66, 70, 73, 76, 80, 81, 84, 86, 87, 88, 101, 102, 104, 107, 109], "have": [4, 5, 12, 15, 17, 24, 27, 39, 40, 41, 42, 47, 48, 49, 50, 51, 52, 55, 56, 58, 59, 61, 62, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 82, 84, 85, 86, 101, 102, 103, 104, 110, 112, 113, 115, 116], "hazlett": [78, 102, 104], "hc": [49, 114], "hc0": [39, 115], "hdm": [50, 70], "he": 79, "head": [49, 50, 52, 53, 58, 59, 64, 65, 67, 69, 70, 71, 73, 76, 78, 82, 84, 113], "heat": [50, 70], "heatmap": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 50, 70, 78], "heavili": 68, "hei": 114, "height": [48, 50, 63, 69], "help": [49, 51, 60, 68, 72, 74, 78, 87, 116], "helper": 115, "henc": [49, 51, 52, 71, 78, 85, 88, 116], "here": [13, 16, 17, 49, 50, 51, 52, 58, 59, 60, 61, 62, 64, 65, 66, 68, 70, 71, 72, 74, 75, 76, 78, 79, 82, 85, 86, 112], "heterogen": [12, 24, 51, 66, 71, 72, 74, 83, 86, 87, 114, 115, 116], "heteroskedast": [64, 65], "heurist": [48, 57, 81], "high": [14, 15, 26, 51, 62, 63, 71, 72, 80, 86, 101, 111, 113, 114], "higher": [49, 51, 63, 71, 72, 73, 76, 115, 116], "highli": [51, 71, 111], "highlight": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 61, 67, 69, 78, 115], "highlightcolor": [58, 59], "hint": 69, "hispan": 53, "hist": 55, "hist_e401": 51, "hist_p401": 51, "histogram": 55, "histplot": 57, "hjust": 51, "hline": [82, 101, 113, 116], "hold": [32, 50, 51, 69, 70, 71, 79, 84, 85, 86], "holdout": [85, 87], "holm": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "home": [51, 71, 78], "homogen": 86, "hopefulli": 72, "horizont": [50, 62, 70], "hostedtoolcach": 71, "hot": 73, "hotstart_backward": [52, 85], "hotstart_forward": [52, 85], "household": [51, 71, 72, 77], "how": [37, 38, 41, 42, 47, 49, 50, 51, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 75, 76, 77, 78, 79, 81, 85, 86, 111, 112], "howev": [48, 51, 57, 69, 71, 76, 78, 79, 81, 86, 116], "hown": [51, 71, 72, 77, 116], "hpwt": [50, 70], "hpwt0": 50, "hpwtairmpdspac": 50, "href": 111, "hspace": 68, "hstack": [18, 62], "html": [52, 65, 111, 113, 115], "http": [25, 31, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 85, 111, 112, 113, 115], "huber": [32, 79, 86, 88, 96, 97, 114], "hue": 71, "huge": 68, "hugo": 114, "husd": [52, 53, 82, 113], "hyperparamet": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 51, 52, 53, 63, 68, 69, 71, 83, 113], "hypothes": [101, 114], "hypothesi": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 51, 71, 77, 102, 107, 114], "hypothet": 78, "i": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 97, 100, 101, 102, 103, 104, 107, 108, 110, 111, 112, 113, 115, 116], "i0": [61, 62, 86], "i03": 111, "i1": [61, 86], "i_": [28, 70, 74], "i_1": [50, 70], "i_2": [50, 70], "i_3": [50, 70], "i_4": 62, "i_est": 57, "i_fold": 50, "i_k": [50, 70, 80, 87, 101], "i_learn": 68, "i_level": 55, "i_rep": [48, 57, 61, 68, 79, 81], "i_split": 70, "i_train": 57, "icp": 114, "id": [49, 50, 52, 70], "id_var": 70, "idea": [51, 52, 71, 72, 78, 85, 86, 102, 104, 116], "ident": [21, 22, 23, 24, 27, 28, 40, 52, 55, 67, 69, 76, 85, 86, 88, 94, 102, 107], "identfi": 78, "identif": [76, 86, 116], "identifi": [50, 51, 61, 66, 70, 71, 72, 76, 78, 84, 86, 102, 110, 115], "identifii": 84, "idnam": 49, "idx_tau": [60, 72, 75], "idx_treat": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 55, 102, 107], "ieee": 114, "ifels": 49, "ignor": [37, 38, 41, 42, 57, 76], "ii": [50, 70], "iid": 86, "iivm": [11, 25, 33, 34, 72, 80, 84, 93, 111, 115], "iivm_summari": 71, "iivmglmnet": 51, "iivmrang": 51, "iivmrpart": 51, "iivmxgboost11861": 51, "ij": [29, 50, 55, 70, 79], "ilia": 114, "illustr": [48, 50, 51, 52, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 74, 75, 77, 78, 79, 81, 85, 116], "iloc": [55, 61, 62, 68, 70, 73], "immedi": 112, "immun": [87, 114], "impact": [47, 56, 68, 73, 77], "implement": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 33, 34, 35, 41, 42, 48, 49, 50, 51, 52, 57, 61, 63, 67, 68, 70, 71, 73, 76, 77, 78, 79, 81, 83, 84, 85, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 111, 113, 114, 115, 116], "impli": [21, 22, 50, 51, 70, 71, 72, 76, 84, 86, 102, 103, 105, 106, 108], "implment": 62, "import": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 35, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 101, 102, 107, 112, 113, 115, 116], "importlib": 63, "impos": 78, "improv": [61, 68, 74, 86, 115], "in_sample_norm": [8, 9, 61, 88, 91, 92, 102, 105, 106], "inbuild": 68, "inbuilt": 68, "inc": [51, 71, 72, 77, 116], "includ": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 43, 49, 51, 55, 62, 64, 65, 67, 71, 76, 77, 78, 84, 86, 101, 102, 103, 107, 108, 110, 112, 115, 116], "include_bia": [67, 70, 71], "include_scenario": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 78], "incom": [51, 71, 72, 74, 77, 116], "incorpor": [52, 77, 102, 107], "increas": [66, 68, 70, 78, 116], "increment": 115, "ind": 71, "independ": [8, 9, 21, 22, 23, 24, 36, 50, 52, 62, 66, 70, 74, 86, 88, 91, 92, 115], "index": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 48, 50, 53, 57, 62, 63, 64, 65, 69, 70, 71, 73, 74, 81, 82, 87, 88, 91, 92, 113], "index_col": 63, "india": [87, 114], "indic": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 27, 32, 35, 39, 50, 51, 62, 66, 70, 71, 72, 76, 78, 79, 80, 82, 84, 86, 87], "individu": [4, 12, 41, 42, 49, 51, 55, 62, 64, 65, 66, 69, 71, 72, 76, 77, 84, 86, 116], "individual_df": 62, "induc": [83, 87], "industri": [50, 70], "inf": [7, 10, 49], "inf_model": 88, "infer": [26, 28, 47, 48, 50, 56, 57, 63, 68, 69, 70, 81, 83, 86, 87, 111, 113, 114, 115], "inferenti": 116, "infinit": [7, 10, 115], "influenc": [38, 42, 86], "info": [47, 52, 53, 55, 61, 66, 69, 70, 71, 72, 77, 79, 82, 113, 115, 116], "inform": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 37, 38, 39, 41, 42, 47, 52, 56, 58, 59, 68, 76, 77, 78, 86, 102, 104, 114], "infti": [48, 57, 81], "inher": 78, "inherit": [73, 115], "initi": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 35, 51, 52, 60, 61, 71, 72, 75, 76, 77, 78, 79, 82, 84, 85, 86, 87, 113, 115, 116], "inlin": [53, 73], "inlinebackend": 73, "inner": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 85], "innermost": 85, "input": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 38, 42, 52, 77, 80, 101, 102, 104, 107], "insensit": 86, "insid": [37, 38, 41, 42], "insight": [63, 78], "insignific": 77, "inspect": 113, "inspir": [21, 25, 26, 32, 78], "instal": [51, 69, 76, 86, 115], "install_github": 112, "instanc": [41, 42, 51, 52, 71, 85], "instanti": [50, 51, 70, 71, 85, 87], "instead": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 37, 38, 41, 42, 47, 49, 51, 55, 56, 65, 66, 69, 71, 72, 84, 85, 86, 102, 105, 106, 108, 109, 115], "instruct": [112, 115], "instrument": [7, 10, 11, 14, 19, 25, 28, 50, 51, 52, 53, 55, 61, 66, 70, 71, 72, 75, 77, 79, 82, 85, 86, 88, 95, 101, 113, 116], "instrument_effect": 47, "instrument_impact": 56, "insuffienct": 69, "int": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 24, 27, 35, 36, 39, 40, 49, 50, 51, 56, 60, 61, 74, 75, 78, 79], "int64": [53, 68, 70, 82, 113], "int8": [71, 72, 77], "integ": [23, 52, 85], "integr": [69, 78, 102, 110, 115], "intend": [35, 52, 78, 116], "intent": [86, 116], "inter": 85, "interact": [4, 5, 11, 12, 21, 25, 26, 27, 35, 36, 55, 78, 83, 85, 103, 108, 111, 115, 116], "interchang": 101, "interest": [11, 12, 14, 15, 21, 22, 48, 51, 57, 61, 63, 71, 72, 76, 79, 81, 84, 86, 88, 101, 113, 116], "interfac": [49, 51, 52, 82, 85, 87, 113], "intermedi": [65, 78], "intern": [49, 51, 52, 55, 69, 72, 85, 114], "internet": [51, 71, 72], "interpret": [64, 65, 78, 84, 102, 103, 104, 108, 109, 110, 112, 116], "intersect": [78, 102, 107, 115], "interv": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 39, 49, 50, 51, 55, 58, 59, 60, 61, 64, 65, 67, 70, 72, 75, 76, 77, 79, 83, 84, 87, 88, 102, 107, 113, 114, 116], "intial": 76, "introduc": [48, 57, 81, 82, 101, 115, 116], "introduct": [48, 50, 52, 57, 70, 72, 77, 85, 86, 102, 104], "introductori": [49, 78], "intrument": 79, "intspecifi": 35, "intuit": 78, "inuidur1": [52, 53, 82, 113], "inuidur1femaleblackothracedep1dep2q2q3q4q5q6agelt35agegt54durablelusdhusdtg": [52, 82, 113], "inuidur2": [53, 82, 113], "inv_sigmoid": 73, "invalid": [48, 57, 81], "invari": 86, "invers": [4, 6, 11, 12, 13, 16, 17, 18, 79, 102, 103, 108], "invert_yaxi": 70, "investig": [63, 69, 78], "involv": [84, 85, 88, 116], "io": [73, 115], "ipw_norm": 115, "ipykernel_45884": 65, "ipynb": [47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79], "ira": [51, 71, 72], "irm": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 26, 27, 33, 34, 39, 40, 68, 78, 80, 83, 85, 94, 103, 108, 111, 115, 116], "irm_summari": 71, "irmglmnet": 51, "irmrang": 51, "irmrpart": 51, "irmxgboost8047": 51, "irrespect": 78, "is_classifi": [4, 8, 9, 11, 12, 15], "is_gat": [4, 12, 15, 39], "isnan": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 68, 85], "isoton": 78, "isotonicregress": 78, "issn": 63, "issu": [78, 111, 114, 115], "ite": [55, 64, 65, 66], "item": [11, 71, 80, 85, 87], "iter": [35, 47, 61, 70, 71, 76, 79, 85, 101, 116], "itertool": 63, "its": [37, 38, 78, 80, 84, 85, 86, 87, 88, 101], "iv": [11, 14, 15, 25, 28, 29, 48, 50, 57, 70, 81, 82, 98, 99, 102, 109, 111, 115, 116], "iv_2": 47, "iv_var": [50, 70], "iv\u00e1n": [87, 114], "j": [19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 48, 49, 50, 52, 55, 57, 63, 70, 73, 79, 81, 85, 86, 101, 111, 113], "j_": [50, 70], "j_0": 101, "j_1": [50, 70], "j_2": [50, 70], "j_3": [50, 70], "j_k": [50, 70], "jame": 114, "janni": [51, 71], "jasenakova": 115, "javanmard": 114, "jbe": [50, 70], "jeconom": [21, 22, 23, 49], "jerzi": 114, "jia": 78, "jk": 86, "jmlr": [52, 111, 113, 115], "job": [51, 71, 72], "joint": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 39, 55, 58, 59, 60, 64, 65, 67, 72, 75, 86, 101, 115, 116], "jointli": [75, 84], "joss": [52, 85, 111, 113], "journal": [19, 20, 21, 22, 23, 29, 30, 32, 49, 50, 52, 63, 70, 73, 78, 81, 85, 111, 113, 114, 115], "jss": 111, "jump": [74, 76, 86], "jun": [49, 114], "jupyt": [47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79], "juraj": 114, "just": [49, 52, 55, 60, 61, 62, 64, 65, 66, 67, 74, 75, 86, 88, 91, 92, 102, 104], "justif": [87, 102, 104], "k": [19, 22, 23, 25, 26, 28, 29, 30, 32, 48, 50, 52, 57, 68, 69, 70, 76, 80, 81, 83, 84, 86, 101, 116], "k_h": [76, 86], "kaggl": [51, 71], "kallu": [60, 72, 75, 77, 88, 90, 95, 100, 114], "kappa": 86, "kato": [29, 50, 70, 101, 114], "kb": [55, 61, 66, 70, 71, 72, 77, 82, 113], "kde": [13, 16, 17, 71], "kdeplot": [61, 68, 79], "kdeunivari": [13, 16, 17], "kecsk\u00e9sov\u00e1": 115, "keep": [38, 42, 49, 65, 67, 78, 116], "kei": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 35, 40, 50, 51, 58, 59, 64, 65, 69, 70, 71, 72, 76, 78, 85, 86, 88, 102, 107, 115], "keith": 114, "kengo": 114, "kernel": [13, 16, 17, 35, 38, 42, 76, 86], "kernel_regress": 76, "kernelreg": 76, "keyword": [4, 12, 15, 23, 29, 30, 31, 36, 39], "kf": 87, "kfold": [70, 87], "kind": [47, 56, 71], "kj": [22, 23, 25, 26, 28, 29, 30, 32, 48, 50, 57, 70, 81], "klaassen": [25, 63, 68, 69, 78, 111, 114], "klaa\u00dfen": 25, "knau": 114, "know": [61, 74], "knowledg": [47, 56, 68, 73, 74], "known": [66, 68, 76, 78, 85, 86], "kohei": 114, "kotthof": 52, "kotthoff": [52, 85, 111, 113], "krueger": 73, "kueck": [51, 71], "kurz": [111, 114, 115], "kwarg": [4, 12, 15, 21, 22, 23, 27, 29, 30, 31, 35, 36, 37, 39, 69, 86], "l": [50, 52, 53, 58, 59, 70, 78, 79, 85, 102, 109, 111, 113], "l1": [71, 79, 86], "l_hat": [14, 15, 48, 57, 88], "label": [37, 41, 55, 57, 58, 59, 60, 62, 64, 65, 67, 69, 72, 73, 75, 76], "labor": 73, "laffer": 114, "laff\u00e9r": [32, 79, 86, 88, 96, 97], "lal": [73, 115], "lambda": [50, 51, 52, 71, 73, 74, 85, 88, 92, 101, 113], "lambda_": 63, "lambda_0": [88, 92], "lambda_t": 23, "land": 74, "lang": [52, 85, 111, 113], "langl": [24, 74], "lappli": 87, "larg": [48, 57, 66, 68, 69, 73, 78, 86], "larger": [12, 49, 76, 78, 102, 107], "largest": 68, "largli": 68, "lasso": [50, 51, 52, 71, 79, 85, 113, 114], "lasso_class": [51, 71], "lasso_pip": [52, 85], "lasso_summari": 71, "lassocv": [18, 63, 70, 71, 79, 85, 86, 101, 113], "last": [23, 52, 112], "late": [11, 47, 51, 71, 86, 88, 93], "latent": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 22, 77, 102, 109, 110], "later": [51, 52, 76, 78, 85, 116], "latter": [41, 42, 86], "layout": 63, "lbrace": [11, 12, 25, 26, 32, 50, 70, 80, 86, 87, 88, 89, 101, 102, 103], "ldot": [14, 15, 50, 70, 79, 80, 86, 87, 101, 113], "le": [23, 61, 74, 84, 86, 88, 95, 100], "lead": [49, 78, 86], "leadsto": 101, "lear": [52, 85, 111, 113], "learn": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 29, 30, 31, 32, 35, 47, 51, 52, 53, 55, 56, 60, 63, 67, 68, 69, 71, 72, 73, 75, 76, 78, 82, 83, 85, 87, 88, 101, 102, 104, 115, 116], "learner": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 47, 48, 49, 50, 51, 57, 58, 59, 61, 63, 70, 71, 72, 77, 78, 79, 80, 81, 83, 86, 87, 88, 101, 102, 107, 115, 116], "learner_class": [18, 115], "learner_cv": 52, "learner_forest_classif": 52, "learner_forest_regr": 52, "learner_l": 77, "learner_lasso": 52, "learner_list": 68, "learner_m": 77, "learner_nam": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 85], "learner_param_v": 52, "learner_rf": 101, "learnerclassif": 52, "learnerregr": 52, "learnerregrcvglmnet": 52, "learnerregrrang": [52, 85], "learning_r": [57, 60, 72, 75, 76, 78, 81], "least": [47, 51, 56, 71, 72, 77, 86, 87], "leav": [78, 79], "left": [25, 26, 28, 29, 32, 48, 50, 55, 57, 68, 70, 71, 72, 73, 75, 76, 81, 86, 88, 91, 92, 101, 102, 103, 105, 106, 108], "legend": [51, 55, 57, 58, 59, 60, 62, 64, 65, 67, 68, 72, 73, 75], "len": [55, 60, 68, 69, 70, 72, 75], "length": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 48, 52, 61, 85], "leq": [50, 70], "less": [49, 51, 71, 72, 76, 78], "lester": 114, "let": [21, 22, 23, 27, 48, 49, 51, 52, 55, 57, 60, 61, 64, 65, 67, 68, 71, 72, 75, 78, 79, 80, 81, 85, 86, 102, 104, 110, 116], "level": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 27, 35, 39, 50, 51, 55, 58, 59, 60, 61, 62, 64, 65, 66, 67, 70, 71, 72, 75, 77, 78, 79, 85, 88, 89, 102, 103, 107, 116], "level_0": [52, 70], "level_1": 70, "level_bound": 55, "levinsohn": [50, 70], "lewi": 114, "lgbmclassifi": [60, 61, 62, 68, 72, 75, 76, 78], "lgbmregressor": [57, 60, 61, 62, 68, 72, 76, 78, 81], "lgr": [48, 49, 50, 51, 52, 80, 85, 86, 87, 88, 101, 113], "lib": [70, 71], "liblinear": [71, 79, 86], "librari": [47, 48, 49, 50, 51, 52, 80, 81, 82, 85, 86, 87, 88, 101, 112, 113, 116], "licens": 115, "lie": 114, "lightgbm": [57, 60, 61, 62, 68, 72, 75, 76, 78], "like": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 37, 38, 41, 42, 49, 51, 52, 63, 65, 71, 72, 78, 85, 87, 113, 116], "lim": 73, "lim_": [76, 86], "limegreen": [58, 59], "limit": [73, 86, 114], "limits_": 84, "lin": [76, 78, 86], "line": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 55, 62, 78], "linear": [4, 12, 14, 15, 21, 22, 27, 28, 29, 30, 31, 33, 34, 39, 47, 48, 49, 50, 52, 55, 56, 57, 58, 59, 61, 62, 63, 64, 67, 68, 69, 70, 77, 78, 80, 81, 83, 84, 85, 87, 89, 91, 92, 93, 94, 98, 99, 101, 107, 108, 109, 110, 111, 113, 114, 115, 116], "linear_model": [4, 12, 15, 18, 39, 53, 55, 56, 63, 67, 68, 70, 71, 76, 78, 79, 85, 86, 101, 113], "linearli": [76, 86], "linearregress": [47, 55, 56, 67, 68, 76, 78], "linearscoremixin": [0, 88], "lineplot": 55, "linestyl": [55, 62, 69, 76], "linewidth": 62, "link": [78, 115], "linspac": [58, 59, 67, 78], "lint": 115, "linux": 112, "list": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 38, 42, 48, 49, 50, 51, 52, 57, 58, 59, 70, 72, 74, 81, 85, 87, 88, 112, 115], "listedcolormap": 70, "literatur": [78, 86], "littl": 66, "ll": [52, 101, 116], "lllllllllllllllll": [82, 113], "lm": [47, 49, 78], "ln_alpha_ml_l": 63, "ln_alpha_ml_m": 63, "load": [47, 49, 51, 52, 63, 71, 72, 82, 112, 113], "loader": 0, "loc": [55, 57, 60, 62, 63, 65, 70, 73, 75, 77, 78], "local": [11, 13, 84, 86, 114, 115], "localconvert": 70, "locat": [60, 75, 86], "log": [50, 63, 68, 70, 73, 77, 85, 86], "log_odd": 74, "log_p": [50, 70], "log_reg": [47, 49], "logarithm": 63, "logic": [11, 52, 85], "logical_not": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 68, 85], "logist": [21, 36, 47, 49, 51, 55, 56, 71, 78, 79, 116], "logisticregress": [47, 53, 55, 56, 67, 76, 78], "logisticregressioncv": [18, 68, 71, 79, 86], "logit": [68, 73], "loglik": 52, "logloss": [51, 71, 116], "logo": 115, "logspac": 71, "long": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 48, 57, 68, 77, 78, 102, 104, 110, 114], "look": [49, 51, 52, 60, 61, 62, 68, 71, 72, 75, 76, 77], "loop": 55, "loss": [68, 69, 76, 77, 85, 86], "loss_ml_g0": 68, "loss_ml_g1": 68, "loss_ml_m": 68, "low": [62, 66, 84, 114], "lower": [51, 52, 55, 60, 62, 63, 66, 67, 72, 73, 75, 76, 77, 78, 85, 102, 107, 110, 116], "lower_bound": [58, 59], "lpq": [13, 17, 72, 84, 95, 115], "lpq_0": 75, "lpq_1": 75, "lqte": 84, "lr": 76, "lrn": [47, 48, 49, 50, 51, 52, 80, 85, 86, 87, 88, 101, 113, 116], "lrn_0": 52, "lt": [47, 49, 50, 51, 52, 53, 55, 61, 66, 70, 71, 72, 74, 77, 78, 79, 82, 113], "lucien": 115, "luka": 114, "luk\u00e1\u0161": 32, "lusd": [52, 53, 82, 113], "lvert": 63, "m": [18, 19, 20, 21, 28, 29, 30, 48, 50, 52, 53, 57, 63, 66, 68, 69, 70, 73, 81, 83, 84, 85, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115], "m_": [55, 86, 88, 89, 95, 101], "m_0": [4, 6, 8, 9, 11, 12, 14, 15, 16, 30, 31, 35, 48, 50, 51, 57, 63, 66, 69, 70, 71, 81, 84, 85, 86, 88, 90, 91, 92, 95, 96, 97, 100, 113, 116], "m_hat": [11, 12, 14, 15, 48, 57, 67, 88], "m_i": [76, 86], "ma": [29, 50, 70, 114], "mac": 112, "machin": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 29, 30, 31, 32, 35, 47, 51, 52, 53, 55, 56, 60, 61, 63, 67, 68, 69, 71, 72, 73, 75, 76, 77, 78, 79, 83, 85, 86, 87, 88, 101, 102, 104, 115, 116], "machineri": [63, 114], "mackei": 114, "maco": 112, "made": [86, 116], "mae": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 68, 85], "maggi": 114, "magnitud": [102, 104], "mai": [38, 42, 61, 79], "main": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 63, 72, 78, 86, 101, 102, 104, 114, 116], "mainli": 78, "maintain": [49, 111, 115], "mainten": 115, "major": [52, 78, 115], "make": [47, 55, 56, 68, 69, 78, 84, 85, 115, 116], "make_confounded_irm_data": [78, 115], "make_confounded_plr_data": 77, "make_did_sz2020": [8, 9, 61, 86], "make_heterogeneous_data": [58, 59, 64, 65, 66], "make_iivm_data": [11, 13, 84, 86], "make_irm_data": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 67, 68, 84, 85, 86], "make_irm_data_discrete_treat": 55, "make_pipelin": 71, "make_pliv_chs2015": [14, 86], "make_pliv_multiway_cluster_ckms2021": [7, 50, 70], "make_plr_ccddhnr2018": [4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 48, 57, 69, 80, 81, 84, 85, 86, 87, 88, 101, 102, 107], "make_simple_rdd_data": [35, 76, 86], "make_spd_matrix": 31, "make_ssm_data": [79, 86], "malt": [111, 114], "maltekurz": 111, "man": [47, 56], "manag": [85, 112], "mani": [28, 33, 34, 48, 49, 50, 52, 57, 61, 69, 70, 81, 88, 101, 116], "manili": 39, "manipul": [51, 52, 76, 86], "manual": [51, 67, 69, 77, 116], "mao": 114, "map": [11, 37, 38, 41, 42, 49, 50, 70, 84, 86], "mapsto": [80, 84], "mar": [32, 86], "march": [63, 68, 69], "margin": [58, 59, 78], "marit": [51, 71], "marker": [55, 78], "markers": 73, "market": 73, "markettwo": 50, "markov": [31, 114], "marr": [51, 71, 72, 77, 116], "marshal": 85, "martin": [32, 78, 111, 114, 115], "masatoshi": 114, "master": 49, "mat": 50, "match": [85, 102, 109], "math": 18, "mathbb": [11, 12, 14, 15, 21, 22, 23, 27, 33, 34, 50, 55, 61, 62, 66, 68, 69, 70, 73, 76, 79, 84, 86, 88, 89, 90, 91, 92, 94, 95, 96, 97, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 113, 116], "mathcal": [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 48, 50, 57, 60, 62, 70, 74, 75, 79, 81], "mathop": 84, "mathrm": [21, 22, 76, 86], "matia": 114, "matplotlib": [53, 55, 57, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 76, 78, 79], "matric": [74, 83, 115], "matrix": [21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 38, 42, 48, 50, 51, 52, 57, 70, 79, 81, 82, 85, 101, 113, 115, 116], "matt": 114, "matter": [68, 73], "max": [51, 52, 67, 71, 72, 80, 84, 85, 86, 87, 88, 90, 101, 113, 116], "max_depth": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 53, 71, 77, 80, 84, 85, 86, 87, 88, 101, 102, 107, 113, 116], "max_featur": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 53, 71, 77, 80, 84, 85, 86, 87, 88, 101, 102, 107, 113, 116], "max_it": [70, 71, 78], "maxim": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 74, 84, 86], "maxima": 101, "maximum": [84, 85], "mb": [53, 79, 82, 113], "mb706": 115, "mea": 25, "mean": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 37, 38, 41, 42, 47, 48, 50, 51, 55, 56, 57, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 77, 78, 81, 85, 86, 101, 116], "mean_absolute_error": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 68, 85], "meant": [84, 115], "measir": 77, "measur": [49, 52, 63, 69, 77, 78, 85, 86, 102, 103, 104, 108, 109, 110], "measure_col": 63, "measure_func": 49, "measure_pr": 49, "measures_r": 49, "mechan": [37, 38, 41, 42, 78], "median": [78, 87], "melt": 50, "membership": 78, "memori": [53, 55, 61, 66, 70, 71, 72, 77, 79, 82, 113], "mention": [66, 84], "merg": [51, 71], "mert": [87, 114], "meshgrid": [58, 59, 78], "messag": [48, 49, 50, 51, 52, 113, 115], "meta": [37, 38, 41, 42, 85, 113], "metadata": [37, 38, 41, 42], "metadata_rout": [37, 38, 41, 42], "metadatarequest": [37, 38, 41, 42], "method": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 33, 34, 35, 37, 38, 39, 40, 41, 42, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 64, 65, 67, 68, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 84, 85, 86, 87, 88, 101, 102, 104, 107, 111, 113, 115], "methodolog": 114, "methodologi": 78, "metric": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 37, 41, 85], "michael": 114, "michaela": 115, "michel": [111, 113], "michela": [32, 114], "mid": [51, 71, 73, 76, 86], "mid_point": 55, "might": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 50, 60, 67, 68, 70, 74, 76, 77, 78, 85, 86], "mild": [48, 57, 81], "militari": 73, "miller": [50, 70], "mimic": 78, "min": [50, 51, 52, 60, 67, 70, 71, 72, 75, 76, 80, 85, 86, 87, 88, 101, 113, 116], "min_": 84, "min_samples_leaf": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 40, 66, 71, 77, 80, 84, 85, 86, 87, 88, 101, 102, 107, 116], "min_samples_split": 71, "minim": [12, 40, 51, 68, 71, 76, 86], "minor": [48, 57, 81, 88, 115], "minsplit": 51, "minut": 69, "miruna": 114, "mislead": 115, "miss": [7, 10, 18, 52, 85, 86, 88, 96, 115], "missing": [32, 79], "misspecif": 61, "misspecifi": 61, "mit": [111, 113], "mixin": [0, 33, 34, 88], "ml": [31, 50, 51, 52, 63, 69, 70, 71, 76, 80, 83, 85, 86, 87, 111, 114, 115], "ml_g": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 47, 48, 49, 51, 53, 55, 56, 57, 58, 60, 61, 62, 64, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 85, 86, 115], "ml_g0": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 49, 51, 53, 61, 68, 71, 77, 85, 86], "ml_g1": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 49, 51, 53, 61, 68, 71, 77, 85, 86], "ml_g_d0": [79, 86], "ml_g_d0_t0": [61, 86], "ml_g_d0_t1": [61, 86], "ml_g_d1": [79, 86], "ml_g_d1_t0": [61, 86], "ml_g_d1_t1": [61, 86], "ml_g_d_lvl0": 86, "ml_g_d_lvl1": 86, "ml_g_sim": 18, "ml_l": [14, 15, 48, 50, 51, 52, 53, 57, 59, 65, 69, 70, 71, 73, 77, 80, 81, 85, 86, 87, 88, 101, 102, 107, 113, 115, 116], "ml_l_bonu": 113, "ml_l_forest": 52, "ml_l_forest_pip": 52, "ml_l_lasso": 52, "ml_l_lasso_pip": 52, "ml_l_rf": 116, "ml_l_sim": 113, "ml_l_tune": 85, "ml_l_xgb": 116, "ml_m": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 84, 85, 86, 87, 88, 101, 102, 107, 113, 115, 116], "ml_m_bench_control": 78, "ml_m_bench_treat": 78, "ml_m_bonu": 113, "ml_m_forest": 52, "ml_m_forest_pip": 52, "ml_m_lasso": 52, "ml_m_lasso_pip": 52, "ml_m_rf": 116, "ml_m_sim": [18, 113], "ml_m_tune": 85, "ml_m_xgb": 116, "ml_pi": [18, 79, 86], "ml_pi_sim": 18, "ml_r": [11, 14, 47, 50, 51, 56, 70, 71, 86, 115], "ml_r0": 86, "ml_r1": [51, 71, 86], "mlr": [52, 85], "mlr3": [47, 48, 49, 50, 51, 80, 85, 86, 87, 88, 101, 111, 113, 115, 116], "mlr3book": [52, 85], "mlr3extralearn": [51, 85], "mlr3filter": 52, "mlr3learner": [47, 48, 49, 50, 51, 80, 85, 86, 87, 88, 101, 113, 116], "mlr3measur": 49, "mlr3pipelin": [85, 115], "mlr3tune": [52, 85, 115], "mlr3vers": 51, "mlrmeasur": 49, "mode": [78, 112], "model": [0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 42, 43, 47, 48, 49, 50, 52, 56, 57, 60, 61, 62, 63, 66, 68, 70, 72, 75, 77, 80, 81, 82, 83, 85, 89, 91, 92, 93, 94, 98, 99, 103, 104, 107, 108, 109, 110, 111, 114, 115], "model_data": [51, 71], "model_label": 69, "model_select": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 57, 70, 85, 87], "modellist": 67, "modelmlestimatelowerupp": 51, "modern": [52, 85, 111, 113], "modul": [76, 86, 112], "moment": [33, 34, 50, 70, 88, 101, 102, 104, 110, 113], "monoton": 86, "mont": [21, 22, 24, 27, 58, 59, 64, 65], "montanari": 114, "more": [12, 39, 47, 49, 51, 55, 56, 58, 59, 63, 67, 68, 69, 71, 72, 76, 77, 78, 80, 84, 85, 86, 88, 94, 101, 102, 104, 107, 110, 113, 116], "moreov": [51, 52, 63, 85, 101, 116], "mortgag": [51, 71, 72], "most": [51, 60, 68, 71, 72, 75, 78, 84, 85, 86, 102, 107, 112], "motiv": [78, 81], "motivation_example_bch": 63, "mp": 49, "mpd": [50, 70], "mpg": 70, "mse": [52, 63, 85], "mserd": 76, "msr": [52, 85], "mtry": [51, 52, 80, 85, 86, 87, 88, 101, 116], "mu": 62, "mu_": 62, "mu_0": 86, "mu_mean": 62, "much": [51, 52, 71, 76, 78, 116], "muld": [53, 82, 113], "multi": [37, 41, 49, 50, 58, 59, 70], "multiclass": [52, 69], "multiindex": 70, "multioutput": [38, 42], "multioutputregressor": [38, 42], "multipl": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 27, 49, 50, 51, 61, 67, 70, 71, 77, 78, 79, 82, 85, 87, 101, 102, 104, 115, 116], "multipletest": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "multipli": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 57, 83, 84, 88, 116], "multiprocess": [60, 72, 75], "multitest": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "multivariate_norm": 18, "multiwai": [29, 50, 70, 114], "music": 114, "must": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 85, 86], "mutat": 52, "mutual": [4, 12, 15, 51, 64, 65, 71, 72, 84], "my_sampl": 87, "my_task": 87, "n": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 36, 47, 48, 50, 52, 55, 56, 57, 60, 62, 63, 66, 70, 73, 74, 75, 76, 79, 80, 81, 84, 85, 86, 87, 101, 111, 112], "n_": [27, 62], "n_coef": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 102, 107], "n_complier": 75, "n_core": [60, 72, 75], "n_estim": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 53, 57, 58, 59, 60, 61, 62, 64, 65, 66, 71, 72, 74, 75, 76, 77, 78, 80, 81, 84, 85, 86, 87, 88, 101, 102, 107, 113, 116], "n_eval": [52, 85], "n_featur": [37, 38, 41, 42], "n_fold": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 48, 49, 50, 51, 53, 57, 58, 59, 60, 61, 64, 65, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 85, 87, 113, 116], "n_folds_per_clust": [50, 70], "n_folds_tun": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "n_iter": [35, 76, 86], "n_iter_randomized_search": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 85], "n_job": 71, "n_jobs_cv": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 68], "n_jobs_model": [5, 17, 60, 72, 75], "n_level": [27, 55], "n_ob": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 36, 39, 40, 48, 52, 55, 57, 58, 59, 61, 62, 64, 65, 66, 67, 68, 69, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 101, 102, 107, 113], "n_output": [37, 38, 41, 42], "n_rep": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 48, 49, 50, 53, 55, 57, 61, 66, 67, 68, 70, 76, 77, 78, 79, 81, 85, 87, 102, 107, 113, 116], "n_rep_boot": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 39, 55, 58, 59, 60, 64, 65, 67, 72, 75, 101], "n_sampl": [37, 38, 41, 42, 74], "n_samples_fit": [38, 42], "n_split": 87, "n_t": 62, "n_target": [41, 42], "n_time_period": 62, "n_true": [60, 75], "n_var": [48, 52, 57, 81, 82, 85, 101, 113], "n_w": 74, "n_x": [24, 58, 59, 64, 65, 66], "na": [7, 10, 48, 50, 81, 115], "na_real_": [50, 115], "naiv": [48, 57, 81], "name": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 37, 38, 41, 42, 48, 49, 50, 64, 65, 66, 69, 70, 76, 77, 78, 85, 112, 115], "namespac": 49, "nan": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 55, 57, 60, 61, 62, 64, 65, 68, 69, 71, 72, 75, 79, 81, 85], "nanmean": 57, "narita": 114, "nathan": 114, "nation": [78, 87, 114], "nativ": 49, "natt": 74, "natur": 78, "ncol": [50, 51, 52, 76, 82, 85, 101, 113], "ncoverag": 68, "ndarrai": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 23, 25, 26, 28, 29, 30, 31, 32, 82], "nearli": 68, "necess": [50, 70], "necessari": [49, 50, 69, 70, 76, 86, 112], "need": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 34, 47, 48, 49, 51, 56, 57, 69, 72, 79, 85, 87, 102, 110, 115, 116], "neg": [38, 42], "neighborhood": [76, 101], "neither": [7, 10, 50, 70, 82], "neng": 114, "neq": [76, 86], "nest": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 41, 42, 85, 88, 97, 102, 107], "net": [72, 77, 116], "net_tfa": [51, 71, 72, 77, 116], "never": [11, 49, 50, 65, 70, 115], "never_tak": [11, 51, 71], "nevertheless": 67, "new": [47, 48, 49, 50, 51, 52, 58, 59, 69, 71, 74, 80, 81, 82, 84, 85, 86, 87, 88, 101, 111, 113, 114, 115, 116], "new_data": [58, 59, 74], "newei": [19, 20, 30, 50, 63, 70, 78, 81, 111, 114], "newest": 115, "next": [49, 51, 52, 58, 59, 60, 66, 68, 71, 72, 74, 75, 78, 115], "neyman": [50, 70, 80, 83, 102, 110, 111, 114], "nfold": [50, 51], "nh": 86, "nice": 49, "nifa": [71, 72, 77], "nil": 78, "nine": [50, 70], "nn": 76, "noack": [76, 86, 114, 115], "node": [51, 52, 80, 86, 87, 88, 101, 113, 116], "nois": [36, 73, 74], "non": [23, 29, 30, 31, 35, 47, 48, 51, 56, 57, 62, 71, 72, 74, 76, 85, 87, 88, 101], "non_orth_scor": [48, 57, 88], "nondur": 53, "none": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 27, 35, 37, 38, 39, 41, 42, 50, 51, 53, 55, 56, 61, 66, 71, 72, 77, 78, 79, 82, 85, 86, 88, 101, 112, 113], "nonignor": [18, 97], "nonlinear": [34, 51, 71, 76, 86, 88, 95, 100, 115], "nonlinearscoremixin": [0, 88], "nonparametr": [13, 16, 17, 76, 78, 102, 103, 104, 108, 109, 110, 114], "nop": 52, "nor": [7, 10, 50, 70, 82], "norm": 57, "normal": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 23, 48, 56, 57, 60, 61, 62, 66, 72, 73, 74, 75, 76, 79, 81, 82, 85, 86, 88, 91, 92, 101, 113], "normalize_ipw": [4, 5, 6, 11, 12, 13, 16, 17, 18, 67, 72, 79], "notat": [50, 61, 70, 79, 86], "note": [7, 10, 11, 12, 14, 15, 18, 33, 34, 37, 38, 40, 41, 42, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 87, 88, 111, 113], "notebook": [47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 85, 86, 116], "notic": [47, 56], "now": [49, 50, 51, 58, 59, 68, 70, 71, 74, 78, 79, 113, 115], "np": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 25, 26, 28, 29, 30, 31, 32, 35, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 101, 102, 107, 113, 116], "nround": [48, 51, 116], "nrow": [49, 50, 52, 76, 82, 85, 101, 113], "nu": [11, 23, 31, 79, 86, 102, 104, 107, 109, 110], "nu2": [102, 107], "nu_0": [102, 110], "nu_i": 79, "nuis_g0": 47, "nuis_g1": 47, "nuis_l": 116, "nuis_m": [47, 116], "nuis_r0": 47, "nuis_r1": 47, "nuis_rmse_ml_l": 63, "nuis_rmse_ml_m": 63, "nuisanc": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 30, 31, 35, 48, 49, 50, 51, 52, 57, 58, 59, 60, 61, 63, 66, 68, 70, 71, 72, 75, 77, 78, 79, 80, 81, 85, 86, 87, 88, 89, 91, 92, 95, 101, 102, 110, 111, 115, 116], "nuisance_el": [102, 103, 105, 106, 108, 109], "nuisance_loss": [68, 85, 115], "nuisance_target": 68, "null": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 49, 77, 85, 102, 107, 115], "null_hypothesi": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 77, 102, 107], "num": [51, 52, 80, 85, 86, 87, 88, 101, 113], "num_leav": [60, 62, 72, 75], "number": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 38, 39, 40, 42, 48, 50, 57, 58, 59, 60, 62, 63, 64, 65, 68, 70, 72, 74, 75, 76, 78, 87, 101, 111, 113, 116], "numer": [34, 47, 52, 67, 73, 85, 88, 102, 103, 108, 115], "numeric_onli": 63, "numpi": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 35, 39, 40, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 101, 102, 107, 113], "ny": 114, "o": [55, 62, 63, 64, 65, 68, 69, 71, 73, 76, 101, 111, 113], "ob": [49, 51, 62, 76], "obei": 88, "obj": 71, "obj_dml_data": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 47, 48, 50, 56, 57, 60, 67, 69, 70, 75, 80, 81, 84, 85, 86, 87, 88, 101, 102, 107, 115], "obj_dml_data_bonu": 82, "obj_dml_data_bonus_df": 82, "obj_dml_data_from_arrai": [7, 10], "obj_dml_data_from_df": [7, 10], "obj_dml_data_sim": 82, "obj_dml_plr": [48, 57, 81], "obj_dml_plr_bonu": [52, 113], "obj_dml_plr_bonus_pip": 52, "obj_dml_plr_bonus_pipe2": 52, "obj_dml_plr_bonus_pipe3": 52, "obj_dml_plr_bonus_pipe_ensembl": 52, "obj_dml_plr_fullsampl": 69, "obj_dml_plr_lesstim": 69, "obj_dml_plr_nonorth": [48, 57], "obj_dml_plr_orth_nosplit": [48, 57], "obj_dml_plr_sim": [52, 113], "obj_dml_plr_sim_pip": 52, "obj_dml_plr_sim_pipe_ensembl": 52, "obj_dml_plr_sim_pipe_tun": 52, "obj_dml_sim": 18, "object": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 25, 26, 28, 29, 30, 31, 32, 35, 37, 38, 39, 40, 41, 42, 47, 51, 52, 53, 55, 58, 59, 60, 61, 65, 66, 67, 69, 71, 72, 75, 76, 79, 82, 84, 85, 86, 87, 88, 101, 111, 113, 114, 115, 116], "obs_confound": [47, 56], "observ": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 39, 40, 43, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 63, 66, 68, 69, 70, 71, 72, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 91, 92, 101, 102, 104, 105, 106, 113, 114, 116], "obtain": [22, 47, 48, 49, 50, 56, 57, 58, 59, 60, 61, 63, 68, 70, 75, 78, 79, 80, 81, 84, 85, 87, 88, 101, 102, 104, 107, 112, 113], "occur": [69, 115], "off": [74, 114], "offer": [49, 51, 71, 72, 78, 116], "offici": 112, "offset": 85, "often": 75, "oka": 114, "ol": [4, 12, 15, 39], "olma": [76, 86, 114, 115], "omega": [66, 84, 88, 89, 94, 102, 103, 108], "omega_": [29, 50, 70], "omega_1": [29, 50, 70], "omega_2": [29, 50, 70], "omega_epsilon": [50, 70], "omega_v": [29, 50, 70], "omega_x": [29, 50, 70], "omit": [77, 78, 102, 104, 110, 114, 115, 116], "ommit": 78, "onc": [49, 69, 78, 86, 116], "one": [14, 43, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 68, 70, 72, 73, 76, 77, 78, 81, 84, 85, 86, 87, 88, 91, 92, 94, 98, 99, 101, 102, 103, 104, 107, 108, 109, 113, 115], "ones": [52, 60, 62, 69, 75, 77, 84], "ones_lik": [55, 75], "onli": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 37, 38, 39, 41, 42, 49, 50, 51, 58, 59, 64, 65, 66, 68, 69, 70, 71, 72, 76, 80, 84, 85, 86, 88, 90, 95, 100, 101, 102, 103, 104, 108, 110, 115], "onlin": 116, "onto": 68, "oo": 69, "oob_error": [52, 85], "oop": 115, "opac": [58, 59], "open": [52, 85, 111, 113], "oper": 52, "opposit": [74, 76, 86], "oprescu": [24, 58, 59, 64, 65, 114], "opt": 71, "optim": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 35, 52, 58, 59, 69, 74, 84, 85, 114], "option": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 37, 38, 41, 42, 47, 48, 50, 51, 55, 58, 59, 64, 65, 66, 68, 70, 71, 72, 79, 85, 86, 87, 88, 90, 95, 100, 101, 115], "oracl": [27, 36, 55], "oracle_valu": [21, 22, 27, 36, 55], "orang": 48, "orcal": [21, 22], "order": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 41, 49, 50, 51, 52, 67, 70, 71, 76, 85, 86, 87, 88], "org": [25, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 85, 111, 112, 115], "orient": [52, 85, 88, 111, 113, 114, 115], "origin": [37, 38, 40, 41, 42, 49, 52, 65, 74, 77, 78, 84, 88, 94], "orign": [51, 71], "orth_sign": [39, 40, 67], "orthogon": [39, 40, 50, 51, 70, 71, 80, 83, 86, 101, 102, 110, 111, 114], "orthongon": [102, 110], "osx": 112, "other": [0, 7, 10, 14, 15, 37, 38, 41, 42, 48, 50, 51, 52, 55, 57, 61, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 94, 101, 102, 110, 111, 112, 113, 114, 115, 116], "other_ind": 70, "otherwis": [4, 8, 9, 11, 12, 15, 37, 38, 41, 42, 51, 71, 72, 74, 86], "othrac": [52, 53, 82, 113], "our": [48, 49, 51, 52, 57, 58, 59, 60, 61, 68, 69, 71, 72, 75, 76, 77, 78, 81, 86, 111, 113, 115, 116], "ourselv": 68, "out": [14, 15, 50, 52, 53, 61, 63, 68, 69, 70, 72, 77, 78, 79, 80, 82, 83, 84, 85, 86, 88, 98, 99, 101, 102, 104, 107, 109, 111, 113, 115, 116], "outcom": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 27, 36, 47, 49, 50, 51, 52, 53, 56, 62, 63, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 82, 85, 89, 101, 103, 104, 107, 109, 110, 113, 115, 116], "outcome_0": 56, "outcome_1": 56, "outer": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 85], "output": [49, 68, 80, 101, 116], "outshr": 70, "outsid": 48, "over": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 48, 55, 57, 63, 68, 81, 83, 85, 102, 107], "overal": [74, 78], "overcom": [83, 88], "overfit": [69, 83, 87], "overlap": [61, 78, 86], "overrid": [85, 115], "overridden": 86, "overst": [51, 71, 72], "overview": [68, 101, 102, 107, 114], "overwrit": 115, "ownership": [51, 71], "p": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 35, 36, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 95, 96, 97, 100, 101, 102, 103, 108, 111, 112, 113, 115], "p401": [51, 71, 72], "p_0": [88, 91, 92], "p_1": 101, "p_adjust": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 87, 101, 111, 113], "p_dbl": [52, 85], "p_hat": 67, "p_int": 85, "p_n": 28, "p_val": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "p_x": [29, 50, 70], "p_x0": 73, "p_x1": 73, "packag": [47, 48, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 69, 70, 72, 74, 75, 76, 77, 78, 79, 80, 81, 84, 85, 86, 87, 88, 101, 102, 104, 111, 113, 114, 115, 116], "packagedata": 70, "packagevers": 51, "page": [78, 111, 114], "pair": [47, 56], "pake": [50, 70], "paket": [50, 51, 52], "pal": 50, "palett": 55, "panda": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 39, 40, 53, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 84, 86, 102, 104, 113], "pandas2ri": 70, "panel": [8, 23, 106, 114, 115], "paper": [25, 28, 52, 69, 73, 76, 77, 78, 102, 110, 111, 113, 114, 115], "par": 53, "par_grid": [52, 85], "paradox": [52, 85, 115], "parallel": [49, 55, 60, 61, 62, 68, 75, 86], "param": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 37, 38, 41, 42, 69, 85], "param_grid": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 85], "param_nam": 49, "param_set": [52, 85], "param_v": 52, "paramet": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 48, 49, 50, 51, 55, 57, 58, 59, 60, 61, 63, 66, 67, 68, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 95, 100, 101, 102, 104, 107, 108, 110, 111, 113, 114, 115, 116], "parametr": [49, 78, 81, 85, 116], "params_exact": 85, "params_nam": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 49], "parenttoc": 111, "part": [31, 48, 50, 51, 52, 57, 68, 69, 70, 71, 81, 85, 87, 102, 110, 115, 116], "parti": 31, "partial": [14, 15, 22, 28, 29, 30, 31, 34, 50, 52, 53, 63, 69, 70, 77, 80, 83, 85, 87, 98, 99, 101, 103, 107, 108, 109, 110, 111, 113, 115, 116], "partial_": [88, 101], "partiallli": 77, "particip": [19, 72, 77, 116], "particular": [86, 111], "particularli": 69, "partion": [50, 70], "partit": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 50, 70, 80, 83], "partli": 116, "pass": [4, 12, 15, 37, 38, 39, 41, 42, 49, 52, 69, 85, 116], "passo": [111, 113], "past": 50, "paste0": 50, "pastel": 57, "path": [85, 86], "path_to_r": 63, "patsi": [58, 59, 84], "pattern": 78, "paul": 114, "pd": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 25, 26, 28, 29, 30, 31, 32, 35, 39, 55, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 84, 86], "pdf": [57, 73], "pedregosa": [111, 113], "pedregosa11a": [111, 113], "pedro": [49, 114], "penal": 79, "penalti": [51, 52, 56, 71, 78, 79, 85, 86], "pennsylvania": [20, 82, 113], "pension": [51, 71, 72, 116], "peopl": [51, 71, 72], "pep8": 115, "per": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 50, 70], "percent": 85, "percentag": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 22], "perf_count": 68, "perfectli": [76, 86], "perform": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 40, 48, 50, 52, 57, 61, 63, 65, 66, 68, 69, 70, 72, 77, 78, 79, 81, 85, 86, 87, 88, 101, 111, 113, 114, 116], "perfrom": 66, "perhap": 116, "period": [8, 49, 61, 62, 86], "perp": 86, "perrot": [111, 113], "person": 116, "pessimist": 78, "peter": 114, "petra": 115, "petronelaj": 115, "pfister": [52, 85, 111, 113], "phi": [50, 70, 84, 101], "philipp": [78, 111, 114], "philippbach": [111, 115], "pi": [18, 26, 28, 31, 84, 86, 88, 96, 97], "pi_": [29, 50, 70], "pi_0": [88, 96, 97], "pi_i": [79, 86], "pick": [76, 116], "pip": [76, 86], "pip3": 112, "pipe": 52, "pipe_forest_classif": 52, "pipe_forest_regr": 52, "pipe_lasso": 52, "pipelin": [37, 38, 41, 42, 52, 71, 115], "pipeop": 52, "pira": [51, 71, 72, 77, 116], "pivot": [63, 70, 114], "plai": [69, 116], "plan": [19, 51, 71, 72, 116], "plausibl": 78, "pleas": [37, 38, 41, 42, 49, 55, 69, 78, 87, 112], "plim": 73, "pliv": [14, 33, 34, 50, 70, 80, 84, 98, 111, 115], "plm": [83, 85, 101, 102, 107, 116], "plot": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 40, 48, 49, 51, 52, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 71, 72, 73, 75, 76, 77, 78, 79, 84, 102, 107], "plot_tre": [40, 74, 84], "plotli": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 58, 59, 63, 76, 78], "plr": [15, 33, 34, 52, 69, 73, 77, 80, 85, 87, 99, 101, 107, 108, 109, 110, 111, 113, 115, 116], "plr_est": 73, "plr_est1": 73, "plr_est2": 73, "plr_obj": 73, "plr_obj_1": 73, "plr_obj_2": 73, "plr_summari": 71, "plrglmnet": 51, "plrranger": 51, "plrrpart": 51, "plrxgboost8700": 51, "plt": [53, 55, 57, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 76, 78, 79], "plt_smpl": [50, 70], "plt_smpls_cluster": [50, 70], "plug": [66, 102, 103, 105, 106, 107, 108], "pm": [35, 50, 70, 101, 102, 107, 110], "pmatrix": 79, "pmlr": [63, 68, 69], "po": [52, 85], "point": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 49, 50, 64, 65, 70, 78, 84, 86, 116], "pointwis": [39, 60, 64, 65, 75], "poli": [51, 67, 70, 71], "polici": [12, 14, 15, 40, 83, 86, 113, 114, 115], "policy_tre": [12, 74, 84], "policy_tree_2": 74, "policy_tree_obj": 84, "policytre": 74, "polit": 73, "poly_dict": 71, "polynomi": [19, 20, 36, 51, 53, 67, 71, 76], "polynomial_featur": [19, 20, 51, 53], "polynomialfeatur": [67, 70, 71], "popul": [78, 88], "popular": [68, 86, 102, 104], "porport": 77, "posit": [31, 51, 73, 78, 116], "posixct": [52, 85], "possibl": [7, 10, 38, 41, 42, 49, 52, 58, 59, 64, 65, 66, 67, 68, 69, 74, 76, 77, 78, 85, 86, 101, 102, 104, 115, 116], "possibli": [102, 104], "post": [28, 31, 86, 101, 114], "postdoubl": 114, "poster": 73, "potenti": [4, 5, 6, 13, 16, 18, 21, 27, 36, 61, 67, 73, 76, 79, 89, 90, 101, 103, 112, 115, 116], "potential_level": 55, "power": [52, 69, 78, 85, 114], "pp": [49, 63, 68, 69], "pq": [13, 16, 17, 72, 100, 115], "pq_0": [72, 75], "pq_1": [72, 75], "pr": [18, 47, 50, 51, 52, 85, 86, 87, 88, 101, 113, 116], "practic": [68, 78, 114], "pre": [49, 61, 79, 85, 86], "precis": [49, 86, 102, 108, 116], "precomput": [38, 42], "pred": [49, 69], "pred_df": 74, "pred_dict": 85, "pred_treat": 74, "predict": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 35, 37, 38, 39, 40, 41, 42, 48, 50, 51, 52, 57, 60, 63, 67, 68, 69, 70, 71, 74, 78, 81, 84, 87, 102, 104, 107, 108, 115, 116], "predict_proba": [4, 6, 8, 9, 11, 12, 13, 15, 16, 17, 18, 35, 37, 41, 69, 85], "predictor": [4, 12, 15, 39, 40, 58, 59, 64, 65, 78, 80], "prefer": [51, 71, 72, 116], "preliminari": [6, 48, 57, 76, 88, 90, 95, 97, 100], "prepar": [49, 50, 70, 115], "preprint": 114, "preprocess": [51, 67, 70, 71, 72, 85], "presenc": [51, 71, 72], "present": [49, 78, 85, 88, 94, 116], "prespecifi": 77, "pretest": 49, "pretreat": [8, 9, 49, 61], "prettenhof": [111, 113], "preval": 78, "prevent": [87, 115], "previou": [62, 66, 67, 73, 112, 116], "previous": [85, 116], "price": [50, 70], "priliminari": [13, 17], "primari": 55, "principl": [102, 104], "print": [35, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 84, 85, 86, 87, 88, 101, 102, 107, 112, 113, 115, 116], "print_detail": 49, "prior": [68, 86], "privat": 115, "prob": 52, "probabilit": 66, "probabl": [4, 6, 11, 12, 13, 16, 17, 18, 23, 27, 41, 48, 49, 55, 57, 61, 66, 73, 75, 76, 78, 79, 81, 86, 88, 91, 92, 95, 114], "problem": [51, 71, 72, 84, 85], "procedur": [48, 50, 51, 57, 68, 70, 71, 77, 78, 85, 101, 112, 115], "proceed": [28, 114], "process": [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 49, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 74, 75, 78, 79, 83, 101, 102, 104, 114, 115], "produc": 73, "product": [58, 59, 63, 68, 78, 102, 110], "producton": 50, "program": [26, 51, 71, 72, 114, 116], "progress": 54, "project": [52, 58, 59, 84, 111, 115], "project_z": [58, 59], "prone": 88, "pronounc": 76, "propens": [13, 17, 21, 22, 51, 61, 66, 67, 68, 71, 72, 78, 79, 84, 86, 102, 103], "properli": [69, 116], "properti": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 51, 52, 68, 71, 72, 73, 77, 85, 86, 102, 107, 113, 115], "proport": [77, 102, 104, 109, 110], "propos": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 50, 52, 70, 76, 102, 104, 114, 115], "provid": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 35, 37, 38, 41, 42, 49, 50, 51, 52, 58, 59, 64, 65, 67, 69, 70, 71, 76, 78, 80, 81, 82, 83, 85, 101, 111, 113, 115, 116], "prune": [12, 40], "ps911c": 70, "ps944": 70, "pscore1": 73, "pscore2": 73, "psi": [33, 34, 48, 49, 50, 70, 80, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 110, 113], "psi_": [101, 102, 107, 109, 110], "psi_a": [11, 12, 14, 15, 33, 48, 50, 57, 70, 87, 88, 89, 91, 92, 93, 94, 98, 99, 101], "psi_b": [11, 12, 14, 15, 33, 48, 57, 84, 87, 88, 89, 91, 92, 93, 94, 98, 99], "psi_el": [87, 88], "psi_j": 101, "psi_nu2": [102, 107], "psi_sigma2": [102, 107], "public": [47, 56, 115], "publish": [78, 115], "pull": [51, 115], "purchas": 78, "pure": 78, "purp": [58, 59], "purpos": [48, 57, 66, 77, 78, 102, 104, 113], "pval": 101, "px": [63, 76], "py": [65, 70, 71, 78, 111, 112, 115], "py3": 112, "py_al": 57, "py_dml": 57, "py_dml_nosplit": 57, "py_dml_po": 57, "py_dml_po_nosplit": 57, "py_double_ml_apo": 55, "py_double_ml_bas": 57, "py_double_ml_basic_iv": 56, "py_double_ml_c": 58, "py_double_ml_cate_plr": 59, "py_double_ml_cvar": 60, "py_double_ml_did": 61, "py_double_ml_did_pretest": 62, "py_double_ml_firststag": 63, "py_double_ml_g": 64, "py_double_ml_gate_plr": 65, "py_double_ml_gate_sensit": 66, "py_double_ml_irm_vs_apo": 67, "py_double_ml_learn": 68, "py_double_ml_meets_flaml": 69, "py_double_ml_multiway_clust": 70, "py_double_ml_pens": 71, "py_double_ml_pension_qt": 72, "py_double_ml_plm_irm_hetfx": 73, "py_double_ml_policy_tre": 74, "py_double_ml_pq": 75, "py_double_ml_rdflex": 76, "py_double_ml_sensit": 77, "py_double_ml_sensitivity_book": 78, "py_double_ml_ssm": 79, "py_non_orthogon": 57, "py_po_al": 57, "pydata": 65, "pypi": [114, 115], "pyplot": [53, 55, 57, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 76, 78, 79], "pyproject": 115, "python": [31, 49, 69, 78, 80, 81, 82, 83, 84, 86, 87, 88, 101, 102, 104, 107, 111, 113, 114, 115, 116], "python3": [71, 112], "q": [52, 60, 75, 76, 85, 111, 113], "q2": [52, 53, 82, 113], "q3": [52, 53, 82, 113], "q4": [52, 53, 82, 113], "q5": [52, 53, 82, 113], "q6": [52, 53, 82, 113], "q_i": [76, 86], "qquad": 26, "qte": [60, 72, 115], "quad": [23, 51, 61, 71, 74, 76, 79, 84, 86, 88, 95, 101, 102, 105], "quadrat": 79, "qualiti": [77, 80, 115], "quanitl": 72, "quant": 60, "quantifi": 78, "quantil": [5, 6, 13, 16, 17, 27, 55, 60, 67, 77, 83, 85, 90, 95, 100, 114, 115], "quantiti": [47, 56, 78], "queri": 71, "question": [78, 116], "quick": 72, "quit": [68, 74, 77, 102, 104], "r": [11, 25, 37, 38, 41, 42, 57, 58, 59, 62, 63, 70, 73, 76, 78, 80, 81, 82, 83, 86, 87, 88, 93, 98, 101, 102, 103, 104, 108, 109, 110, 111, 113, 114, 115, 116], "r2_d": [26, 68], "r2_score": [38, 42], "r2_y": [26, 68], "r6": [52, 115], "r_0": [11, 14, 51, 71, 86], "r_all": 48, "r_d": 26, "r_df": 70, "r_dml": 48, "r_dml_nosplit": 48, "r_dml_po": 48, "r_dml_po_nosplit": 48, "r_double_ml_bas": 48, "r_double_ml_basic_iv": 47, "r_double_ml_did": 49, "r_double_ml_multiway_clust": 50, "r_double_ml_pens": 51, "r_double_ml_pipelin": 52, "r_hat": 14, "r_hat0": 11, "r_hat1": 11, "r_non_orthogon": 48, "r_po_al": 48, "r_y": 26, "rais": [7, 10, 37, 38, 41, 42, 85], "randint": 73, "randn": 18, "random": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 27, 31, 32, 35, 36, 47, 48, 49, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 84, 85, 87, 96, 101, 102, 107, 110, 113, 114, 116], "random_search": 85, "random_st": [27, 57, 66, 67, 74], "randomforest": [51, 68, 71], "randomforest_class": [51, 58, 71, 74], "randomforest_reg": [58, 74], "randomforestclassifi": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 53, 55, 58, 59, 64, 65, 66, 68, 71, 74, 76, 77, 78, 84, 85, 86, 116], "randomforestregressor": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 53, 55, 57, 58, 59, 64, 65, 66, 68, 71, 74, 76, 77, 78, 80, 84, 85, 86, 87, 88, 101, 102, 107, 113, 116], "randomized_search": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 85], "randomizedsearchcv": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 85], "randomli": [48, 50, 57, 70, 81, 87, 116], "rang": [48, 55, 57, 60, 61, 62, 64, 65, 68, 69, 70, 72, 74, 75, 76, 78, 79, 81, 85, 86], "rangeindex": [53, 55, 61, 66, 70, 71, 72, 77, 79, 82, 113], "ranger": [49, 51, 52, 80, 85, 86, 87, 88, 101, 113, 116], "rangl": [24, 74], "rank": 115, "rate": [63, 68, 86], "rather": [76, 78, 86], "ratio": [85, 87, 102, 104], "ravel": [58, 59], "raw": [51, 63, 71], "raw_res_manual_lasso_r_100_n_100_p_200_rho_0": 63, "rbind": 51, "rbindlist": 51, "rbinom": 47, "rbrace": [11, 12, 25, 26, 32, 50, 70, 80, 86, 87, 88, 89, 101, 102, 103], "rcolorbrew": 50, "rcparam": [53, 58, 59, 60, 62, 64, 65, 67, 70, 71, 72, 75], "rd": [86, 115], "rdbu": 50, "rdbu_r": 70, "rdbwselect": 86, "rdd": [0, 7, 10, 83, 112], "rdflex": [0, 76, 86, 115], "rdflex_fuzzi": 76, "rdflex_fuzzy_stack": 76, "rdflex_obj": [35, 86], "rdflex_sharp": 76, "rdflex_sharp_stack": 76, "rdrobust": [35, 76, 86, 112, 115], "rdrobust_fuzzi": 76, "rdrobust_fuzzy_noadj": 76, "rdrobust_sharp": 76, "rdrobust_sharp_noadj": 76, "rdt044": 63, "re": [70, 78, 112], "read": 112, "read_csv": 63, "readabl": 115, "readili": 111, "real": [51, 71, 72, 77, 102, 104], "realat": 86, "realiz": [76, 86], "reason": [7, 10, 47, 56, 63, 68, 69, 77, 78, 102, 104, 116], "recal": [53, 102, 110], "receiv": [55, 76, 86], "recent": [69, 86], "recogn": [51, 71, 72], "recommend": [52, 68, 76, 78, 80, 87, 112, 114, 115], "recov": [47, 49, 56, 73], "recsi": 114, "red": [50, 64, 65, 69, 70], "reduc": [51, 66, 69, 71, 76, 77, 78, 86, 115], "redund": 115, "reemploy": [20, 82, 113], "refactor": 115, "refer": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 51, 55, 62, 66, 71, 72, 76, 77, 82, 83, 84, 86, 102, 104, 107, 114, 115], "reference_level": [5, 55, 67, 86], "refin": 115, "refit": [102, 104], "reflect": [74, 78, 84], "reg": [23, 51, 71, 116], "reg_estim": 76, "reg_learn": 72, "reg_learner_1": 68, "reg_learner_2": 68, "regard": [78, 111], "regener": 115, "region": [50, 60, 70, 101, 114], "regr": [47, 48, 49, 50, 51, 52, 80, 85, 86, 87, 88, 101, 113, 116], "regravg": [52, 85], "regress": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 25, 26, 27, 28, 29, 30, 31, 35, 36, 39, 47, 49, 50, 52, 55, 56, 63, 69, 70, 73, 77, 78, 79, 80, 81, 83, 84, 85, 87, 101, 103, 104, 107, 108, 109, 110, 111, 113, 114, 115, 116], "regressor": [38, 42, 48, 51, 55, 57, 60, 68, 69, 71, 81], "regular": [28, 83, 85, 88, 101, 114], "reich": [52, 85], "reinforc": 114, "reject": [51, 71], "rel": [51, 71, 102, 103, 104, 108], "relat": [67, 78, 116], "relationship": [47, 56, 63, 78, 101], "relev": [7, 8, 9, 10, 24, 37, 38, 39, 41, 42, 60, 74, 75, 86, 102, 116], "reli": [58, 59, 61, 62, 66, 67, 84, 85, 86, 102, 104, 116], "reload": 51, "remain": [49, 101, 116], "remark": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 48, 55, 57, 58, 59, 60, 62, 64, 65, 66, 67, 68, 72, 77, 84, 85, 86, 88, 91, 92, 95, 100, 101, 102, 108], "remot": 112, "remov": [51, 67, 78, 83, 87, 115], "renam": [71, 115], "render": [77, 78], "reorgan": 115, "rep": [48, 81, 85, 101], "repeat": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 47, 48, 50, 51, 52, 57, 66, 70, 71, 72, 73, 76, 77, 79, 81, 83, 85, 101, 105, 113, 115, 116], "repeatedkfold": 70, "repet": 77, "repetit": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 39, 58, 59, 63, 64, 65, 66, 68, 83, 85, 101, 113, 116], "repetiton": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35], "replac": [74, 78, 115], "replic": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 48, 51, 57, 63, 78], "repo": 115, "report": [51, 69, 71, 111, 115], "repositori": [63, 76, 115], "repr": [48, 50], "repres": [73, 78, 86], "represent": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 22, 77, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 113, 115], "reproduc": 27, "request": [37, 38, 41, 42, 115], "requir": [14, 15, 37, 41, 47, 51, 52, 55, 66, 71, 72, 77, 86, 101, 102, 104, 107, 112, 115, 116], "requirenamespac": 49, "res_df": 70, "res_dict": [21, 22, 24, 27, 36], "resampl": [47, 50, 52, 61, 70, 72, 77, 79, 85, 86, 87, 88, 101, 111, 113, 116], "research": [50, 52, 70, 73, 78, 87, 111, 113, 114, 116], "resembl": 79, "reset": 49, "reset_index": [63, 70, 71], "reshap": [57, 58, 59, 62, 67], "reshape2": 50, "residu": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 22, 38, 42, 77, 102, 104, 109, 110], "resolut": [52, 85], "resourc": 68, "resourcewis": 68, "respect": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 51, 55, 71, 72, 76, 84, 86, 87, 102, 110, 116], "respons": [19, 52, 85], "rest": 86, "restart": 112, "restrict": 68, "restructur": 115, "restud": 63, "result": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 47, 48, 49, 52, 55, 57, 58, 59, 61, 62, 63, 66, 67, 68, 74, 76, 77, 78, 79, 81, 85, 87, 88, 91, 92, 102, 104, 107, 113, 115], "result_iivm": 51, "result_irm": 51, "result_plr": 51, "retain": [37, 38, 41, 42], "retina": 73, "retir": [51, 71, 72, 77], "return": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 48, 49, 50, 52, 57, 60, 65, 68, 69, 70, 73, 74, 75, 77, 78, 79, 80, 85, 88, 102, 104, 115], "return_count": [55, 68], "return_tune_r": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "return_typ": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 25, 26, 28, 29, 30, 31, 32, 48, 51, 52, 57, 61, 67, 68, 69, 71, 72, 77, 79, 80, 81, 82, 84, 85, 86, 87, 88, 101, 102, 107, 113, 116], "rev": 50, "reveal": 66, "review": [28, 63, 114], "revist": [50, 70], "rf": 76, "rho": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 43, 55, 66, 67, 76, 77, 78, 102, 104, 107, 110, 116], "rho_val": 78, "richter": [52, 85, 111, 113], "riesz": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 22, 77, 102, 104, 105, 106, 107, 109, 110], "riesz_rep": [102, 107], "right": [25, 26, 28, 29, 32, 48, 50, 57, 68, 70, 71, 72, 73, 75, 76, 78, 81, 86, 88, 91, 92, 101, 102, 103, 105, 106, 108], "rightarrow_": [48, 57, 81], "risk": [6, 83, 115], "ritov": 114, "rival": 70, "rival_ind": 70, "rmd": 49, "rmse": [49, 61, 68, 69, 72, 77, 79, 85, 86, 88, 101, 113, 115], "rmse_dml_ml_l_fullsampl": 69, "rmse_dml_ml_l_lesstim": 69, "rmse_dml_ml_l_onfold": 69, "rmse_dml_ml_l_untun": 69, "rmse_dml_ml_m_fullsampl": 69, "rmse_dml_ml_m_lesstim": 69, "rmse_dml_ml_m_onfold": 69, "rmse_dml_ml_m_untun": 69, "rmse_oos_ml_l": 69, "rmse_oos_ml_m": 69, "rmse_oos_onfolds_ml_l": 69, "rmse_oos_onfolds_ml_m": 69, "rnorm": [47, 52, 82, 85, 101, 113], "robin": [19, 20, 30, 50, 63, 70, 81, 111, 114], "robinson": [48, 57, 81], "robject": 70, "robu": [64, 65], "robust": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 29, 35, 49, 55, 66, 67, 76, 77, 78, 86, 102, 107, 114, 116], "roc\u00edo": 114, "role": [7, 10, 48, 57, 69, 81, 116], "romano": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 101], "root": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 34, 63, 81, 85, 88, 114], "rotat": [69, 76], "roth": [76, 86, 114], "rough": [78, 116], "roughli": 78, "round": [51, 55, 67, 68, 73, 78], "rout": [37, 38, 41, 42], "row": [48, 51, 53, 58, 59, 62, 69, 70, 74, 82, 87, 113, 116], "row_index": 65, "rownam": 50, "rowv": 50, "roxygen2": 115, "royal": [78, 114], "rpart": [51, 52, 85], "rpart_cv": 52, "rprocess": 68, "rpy2": 70, "rpy2pi": 70, "rskf": 67, "rsmp": [52, 85, 87], "rsmp_tune": [52, 85], "rssb": 78, "rtype": 5, "ruben": 114, "ruiz": [47, 56], "rule": [49, 84], "run": [49, 76, 86, 112, 115], "runif": 47, "runner": 78, "runtime_learn": 52, "rv": [55, 66, 67, 77, 78, 102, 107, 116], "rva": [55, 66, 67, 77, 78, 102, 107, 116], "rvert": 63, "rvert_": 63, "s1": 69, "s2": 69, "s_": [29, 50, 70, 86], "s_1": 30, "s_2": 30, "s_col": [7, 10, 76, 79, 86], "s_i": [32, 76, 79, 86], "s_x": [29, 50, 70], "safeguard": [61, 85], "sake": [51, 71, 78, 116], "same": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 27, 39, 48, 50, 57, 58, 59, 66, 67, 68, 70, 72, 74, 76, 77, 78, 79, 85, 88, 91, 92, 101, 102, 108, 115], "samii": 73, "sampl": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 29, 32, 35, 37, 38, 41, 42, 47, 49, 50, 52, 56, 61, 64, 65, 67, 68, 70, 72, 74, 77, 83, 85, 101, 113, 114, 115], "sample_weight": [35, 37, 38, 41, 42, 76], "sant": [8, 9, 21, 22, 23, 27, 49, 61, 86, 114], "sara": 114, "sasaki": [29, 50, 70, 114], "satisfi": [79, 85, 88, 101], "save": [48, 51, 57, 64, 65, 68, 69, 71, 72, 85, 102, 107, 116], "savefig": 57, "saveguard": 68, "saver": [51, 71, 72], "scalar": 86, "scale": [48, 50, 60, 62, 67, 73, 75, 78, 101, 102, 110], "scale_color_manu": 48, "scale_fill_manu": [48, 50], "scaled_psi": 67, "scatter": [55, 62, 64, 65, 73, 76, 78], "scatterplot": 55, "scenario": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 55, 66, 67, 77, 78, 86, 102, 107, 116], "scene": [58, 59, 63], "scene_camera": 63, "schacht": [63, 68, 69], "schaefer": 73, "schedul": 115, "scheme": [50, 70, 85, 87, 111], "schneider": 52, "schratz": [52, 85, 111, 113], "scienc": [31, 47, 56, 73, 114], "scikit": [68, 71, 85, 111, 113, 115, 116], "scipi": 57, "score": [0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 33, 34, 35, 36, 37, 38, 41, 42, 47, 49, 50, 51, 52, 53, 58, 59, 60, 61, 63, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 110, 111, 115, 116], "scoring_method": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "script": 112, "sd": 47, "se": [48, 50, 57, 77, 81, 85, 87, 101, 102, 107, 114, 116], "se_df": 50, "se_dml": [48, 57, 81], "se_dml_po": [48, 57, 81], "se_nonorth": [48, 57], "se_orth_nosplit": [48, 57], "se_orth_po_nosplit": [48, 57], "seaborn": [53, 55, 57, 61, 68, 70, 71, 72, 78, 79], "search": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 34, 85, 88], "search_mod": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 85], "searchabl": 51, "second": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 29, 48, 50, 52, 57, 68, 69, 70, 80, 81, 87, 101, 102, 104, 110, 113], "secondari": 55, "section": [9, 23, 49, 50, 51, 52, 66, 69, 70, 72, 78, 94, 105, 115], "secur": 73, "see": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 26, 32, 33, 34, 37, 38, 39, 41, 42, 47, 49, 50, 51, 52, 55, 56, 58, 59, 61, 65, 67, 69, 70, 72, 73, 74, 76, 77, 78, 85, 86, 87, 88, 90, 94, 95, 96, 97, 100, 102, 104, 107, 110, 112, 113, 115], "seed": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 27, 35, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 101, 102, 107, 113, 116], "seek": 73, "seem": [49, 51, 66, 71, 72, 116], "seen": [64, 65, 67], "sel_cols_chiang": 70, "select": [7, 10, 18, 27, 28, 32, 47, 63, 68, 76, 78, 80, 82, 83, 85, 101, 113, 114, 115, 116], "selected_coef": 68, "selected_featur": [52, 85], "selected_learn": 68, "self": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 37, 38, 39, 40, 41, 42, 68, 69, 116], "selfref": 51, "semenova": [58, 59, 114], "semi": 81, "semiparametr": 19, "sens": [77, 78], "sensemakr": [102, 104], "sensit": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 43, 83, 84, 104, 107, 110, 115], "sensitivity_analysi": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 55, 66, 67, 77, 78, 102, 107, 116], "sensitivity_benchmark": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 55, 66, 77, 78, 102, 104], "sensitivity_el": [102, 107], "sensitivity_param": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 77, 78, 102, 104, 107], "sensitivity_plot": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 55, 66, 77, 78, 102, 107], "sensitivity_summari": [55, 66, 67, 77, 78, 102, 107, 116], "sensitv": 67, "sensitvity_benchmark": 55, "sensiv": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "senstiv": [102, 109], "sep": 48, "separ": [73, 77, 85, 86, 115], "seper": [69, 76, 77, 87, 101, 102, 104], "seq_len": [48, 81], "sequenti": 20, "seri": [65, 78, 114], "serv": [82, 113, 115], "serverless": [114, 115], "servic": 73, "set": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 29, 30, 31, 37, 40, 41, 42, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 84, 86, 87, 88, 89, 91, 92, 94, 101, 102, 103, 104, 108, 109, 112, 113, 115, 116], "set_as_param": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "set_config": [37, 38, 41, 42], "set_fit_request": [41, 42], "set_fold_specif": 85, "set_index": 71, "set_ml_nuisance_param": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 51, 53, 71, 85, 115], "set_param": [37, 38, 41, 42, 69, 85], "set_sample_split": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 67, 68, 87, 115], "set_score_request": [37, 38, 41, 42], "set_styl": [71, 72], "set_text": 68, "set_threshold": [48, 49, 50, 51, 52, 80, 85, 86, 87, 88, 101, 113], "set_tick": 70, "set_ticklabel": 70, "set_titl": [55, 67, 69, 70, 76], "set_x_d": [7, 10], "set_xlabel": [55, 57, 67, 69, 70, 76], "set_xlim": 57, "set_xtick": 73, "set_xticklabel": 73, "set_ylabel": [55, 67, 69, 70, 73, 76], "set_ylim": [60, 67, 69, 70, 75], "setdiff": 115, "setdiff1d": 70, "setminu": [50, 70, 101], "settings_l": 69, "settings_m": 69, "setup": [112, 115], "seven": [50, 70], "sever": [43, 51, 52, 68, 69, 71, 72, 77, 78, 81, 85, 116], "shape": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 37, 38, 39, 40, 41, 42, 55, 58, 59, 62, 64, 65, 68, 70, 71, 74, 76, 77, 78, 85, 86], "share": [50, 51, 70, 71], "sharma": [78, 114], "sharp": 35, "shock": [50, 70], "short": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 77, 78, 102, 104, 114, 115, 116], "shortcut": 51, "shortli": [50, 52, 70, 85], "shota": 114, "should": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 34, 37, 38, 41, 42, 51, 55, 64, 65, 68, 71, 76, 77, 79, 82, 84, 85, 86, 101, 102, 104, 111], "show": [47, 48, 50, 53, 55, 56, 57, 58, 59, 61, 63, 66, 67, 68, 69, 70, 73, 76, 78, 79, 81, 102, 109, 112], "showcas": 74, "showlabel": 78, "showlegend": 78, "shown": [47, 56, 73, 113], "showscal": [58, 59, 63], "shrink": 76, "shuffl": 87, "side": [76, 86, 102, 107], "sigma": [18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 48, 50, 57, 70, 79, 81, 84, 87, 101, 102, 104, 107, 109, 110], "sigma2": [102, 107], "sigma_": [22, 23, 25, 26, 28, 29, 30, 32, 48, 50, 57, 70, 81], "sigma_0": [102, 110], "sigma_j": 101, "sigmoid": 73, "sign": 78, "signal": [39, 40], "signatur": [11, 12, 13, 14, 15, 16, 17, 88], "signif": [47, 49, 50, 51, 52, 85, 86, 87, 88, 101, 113, 116], "signific": [47, 50, 51, 52, 55, 66, 67, 71, 74, 76, 77, 78, 85, 86, 87, 88, 101, 102, 107, 113, 116], "silverman": [13, 16, 17], "sim": [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 48, 49, 50, 57, 60, 62, 70, 74, 75, 79, 81, 86], "similar": [22, 27, 49, 52, 58, 59, 66, 69, 72, 76, 77, 78, 86], "similarli": 69, "simpl": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 24, 41, 42, 49, 52, 58, 59, 64, 65, 66, 67, 74, 78, 83, 86, 102, 104], "simplest": 84, "simpli": [52, 61, 116], "simplic": [51, 68, 71, 74, 78], "simplif": [102, 105], "simplifi": [67, 73, 78, 84, 102, 109], "simul": [21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 48, 52, 57, 58, 59, 60, 63, 64, 65, 68, 69, 75, 76, 78, 79, 81, 85, 101, 113], "simul_data": 18, "simulaten": 86, "simulation_run": 63, "simult": 49, "simultan": [83, 116], "sin": [24, 27, 31, 58, 59, 62, 64, 65], "sinc": [21, 22, 37, 41, 51, 55, 61, 62, 64, 65, 66, 68, 69, 71, 73, 79, 85, 86, 102, 107, 108, 112, 115], "singl": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 61, 64, 65, 72, 73, 85, 101], "single_learner_pipelin": 85, "singleton": 87, "sinh": 31, "sipp": [51, 71, 72], "site": [70, 71], "situat": [50, 70], "six": 50, "sixth": 70, "size": [18, 48, 50, 51, 52, 57, 60, 62, 63, 66, 68, 69, 71, 73, 74, 75, 78, 80, 82, 85, 86, 87, 88, 101, 113, 116], "sizeabl": 78, "skill": 114, "sklearn": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 31, 35, 37, 38, 40, 41, 42, 53, 55, 56, 57, 58, 59, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 84, 85, 86, 87, 88, 101, 102, 107, 113, 116], "skotara": 78, "slide": 73, "slightli": [62, 64, 65, 66, 68, 84, 88, 91, 92, 102, 104], "sligthli": [8, 9], "slow": [48, 57, 81], "slower": [48, 57, 81], "small": [24, 61, 62, 67, 74, 79, 86, 102, 104, 108], "smaller": [51, 61, 64, 65, 66, 69, 71, 76, 78, 86, 116], "smallest": 68, "smpl": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 48, 50, 57, 68, 70, 87, 88], "smpls_cluster": [50, 70], "sn": [53, 55, 57, 61, 68, 70, 71, 72, 78, 79], "so": [41, 42, 47, 51, 52, 56, 61, 69, 71, 73, 78, 79, 85, 101, 116], "social": [73, 114], "societi": [50, 70, 78, 114], "softwar": [52, 85, 111, 113, 114, 115], "solari": 115, "sole": 78, "solut": [80, 84, 88], "solv": [33, 50, 70, 84, 85, 101], "solver": [71, 79, 86], "some": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 37, 38, 41, 42, 51, 52, 53, 61, 62, 68, 69, 71, 72, 76, 77, 79, 84, 85, 86, 112, 115], "sometim": 68, "sonabend": [52, 85], "sophist": 85, "sort": [71, 86], "sort_valu": 55, "sourc": [52, 85, 113, 115], "sourcefileload": 63, "sp": 49, "space": [50, 70, 85], "spars": [63, 85, 101, 113, 114], "sparsiti": 114, "spec": 114, "special": [50, 70, 86], "specif": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 34, 35, 50, 51, 55, 67, 68, 70, 71, 78, 82, 83, 84, 85, 86, 87, 88, 94, 101, 107, 110, 111, 113], "specifi": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 35, 47, 50, 51, 52, 55, 56, 58, 59, 60, 61, 64, 65, 67, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 86, 89, 94, 112, 113, 115, 116], "specifii": 72, "speed": [5, 17, 68], "speedup": 68, "spefici": 11, "spindler": [28, 63, 68, 69, 78, 111, 114, 115], "spine": [71, 72], "spline": [58, 59, 84], "spline_basi": [58, 59, 84], "spline_grid": [58, 59], "split": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 47, 50, 52, 61, 67, 68, 70, 72, 74, 77, 79, 83, 84, 85, 86, 88, 101, 113, 115], "split_sampl": [67, 68], "sponsor": [51, 71, 72], "sprintf": 48, "sq_error": 63, "sqrt": [21, 22, 23, 26, 27, 48, 50, 52, 53, 57, 60, 70, 75, 81, 87, 101, 102, 104, 113], "squar": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 38, 42, 51, 63, 71, 85, 86, 102, 110, 114], "squarederror": [51, 71, 116], "squeez": [60, 61, 75, 79], "src": 71, "ssm": [7, 10, 32, 83], "ssrn": 25, "stabil": 66, "stabl": [47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 111], "stack": [52, 85], "stackingclassifi": 76, "stackingregressor": 76, "stacklrn": 52, "stackrel": 86, "stage": [35, 58, 59, 64, 65, 74, 76, 85, 86, 115, 116], "standard": [23, 49, 52, 60, 64, 65, 76, 86, 87, 88, 101, 102, 107, 110, 115, 116], "standard_norm": [82, 85, 101, 113], "standardscal": 71, "star": 86, "start": [49, 51, 52, 58, 59, 63, 66, 68, 69, 70, 71, 75, 78, 86, 111, 116], "stat": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 35, 57, 76, 82, 85, 86, 101, 111, 114], "stat_bin": 48, "stat_dens": 51, "state": 116, "stationar": 61, "stationari": 86, "statist": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 29, 32, 43, 50, 70, 77, 78, 101, 102, 107, 111, 113, 114, 115, 116], "statsmodel": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 39, 76], "statu": [49, 51, 61, 71, 73, 76, 79], "std": [6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 47, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 64, 65, 66, 67, 69, 70, 71, 72, 73, 75, 77, 78, 79, 84, 85, 86, 87, 88, 101, 113, 116], "stefan": 114, "step": [48, 51, 52, 57, 64, 65, 66, 71, 74, 81, 85, 86, 101, 111, 116], "stepdown": 101, "stick": [51, 71], "still": [58, 59, 61, 64, 65, 66, 72, 76, 77, 79, 85], "stochast": [14, 15, 86, 113], "stock": [51, 71, 72], "store": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 80, 85, 87, 88, 101, 102, 107, 115], "store_model": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 69], "store_predict": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 49, 71, 74], "stori": [78, 114], "str": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 35, 37, 38, 39, 41, 42, 51, 55, 64, 65, 75, 76, 84, 86, 115], "straightforward": [64, 65, 68, 84], "strategi": [73, 78, 86, 116], "stratifi": [67, 68], "stratum": 73, "strength": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 77, 78, 102, 104, 107, 109], "strictli": 86, "string": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 84, 101, 102, 107, 113, 115], "string_label": 73, "strong": [79, 102, 104], "stronger": [101, 116], "structur": [19, 20, 30, 50, 51, 63, 70, 71, 79, 81, 85, 111, 114, 116], "student": 114, "studi": [32, 50, 51, 63, 68, 69, 70, 71, 72, 77, 113, 116], "style": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 69, 115], "styler": 115, "styliz": 78, "sub": [37, 38, 41, 42, 50, 70], "subclass": 115, "subfold": 85, "subgroup": [11, 51, 71, 115], "subject": [50, 70], "submiss": 115, "subobject": [37, 38, 41, 42], "subplot": [50, 55, 57, 58, 59, 60, 62, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 76], "subplots_adjust": 68, "subpopul": 86, "subsampl": [52, 68], "subscript": [102, 104], "subsequ": [50, 70], "subset": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 37, 41, 50, 68, 70, 74, 80, 84, 85, 102, 104], "subseteq": 84, "substanti": [51, 71, 73], "substract": 101, "subtract": 101, "sudo": 112, "suffic": 78, "suffici": [68, 69, 78], "suggest": [50, 51, 70, 71, 78, 115], "suitabl": [58, 59, 79], "sum": [38, 42, 50, 51, 70, 71, 72, 75, 76, 84, 101], "sum_": [36, 48, 50, 57, 70, 76, 80, 81, 84, 86, 101], "sum_i": 73, "sum_oth": 70, "sum_riv": 70, "summar": [49, 55, 73, 78, 80, 102, 107], "summari": [6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 47, 49, 50, 52, 53, 55, 56, 58, 59, 60, 61, 64, 65, 66, 67, 70, 72, 75, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 101, 102, 113, 115, 116], "summary_result": 51, "suppli": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 58, 59, 64, 65, 66, 74, 84, 102, 103, 104, 107], "support": [11, 24, 35, 49, 50, 68, 70, 74, 76, 85, 86, 116], "support_s": [24, 58, 59, 64, 65, 74], "support_t": 74, "support_w": 74, "suppos": 78, "suppress": [49, 51, 52], "suppresswarn": 48, "suprema": 101, "suptitl": [60, 68, 69, 72, 75], "supxlabel": [60, 72, 75], "supylabel": [60, 72, 75], "sure": [55, 85, 115], "surfac": [58, 59, 63], "surpress": [50, 113], "survei": [51, 71, 72, 116], "susan": 114, "sven": [78, 111, 114], "svenk": 70, "svenklaassen": [111, 115], "svg": [48, 57], "switch": [48, 57, 78, 81], "symbol": 78, "symmetr": 31, "syntax": [76, 86], "synthet": [24, 36, 47, 56, 58, 59, 60, 64, 65, 69, 74, 75], "syrgkani": [78, 114], "system": 114, "szita": 114, "t": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 27, 35, 37, 38, 41, 42, 47, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 84, 85, 86, 87, 88, 92, 101, 102, 105, 113, 116], "t_1_start": 68, "t_1_stop": 68, "t_2_start": 68, "t_2_stop": 68, "t_3_start": 68, "t_3_stop": 68, "t_col": [7, 9, 10, 86], "t_df": 74, "t_diff": 62, "t_dml": 48, "t_i": [61, 74, 76, 86], "t_idx": 62, "t_nonorth": 48, "t_orth_nosplit": 48, "t_sigmoid": 74, "t_stat": 101, "tabl": [48, 50, 51, 52, 55, 80, 82, 85, 86, 87, 88, 101, 113, 116], "tabular": [68, 82, 101, 113, 116], "taddi": 114, "take": [11, 12, 14, 15, 21, 22, 24, 58, 59, 60, 61, 62, 63, 64, 65, 68, 72, 75, 76, 77, 79, 80, 84, 85, 86, 88, 89, 94, 102, 103, 108, 109, 113], "taken": [51, 71, 72, 116], "taker": [11, 115], "talk": 116, "target": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 33, 34, 41, 42, 47, 50, 51, 52, 58, 59, 68, 70, 84, 85, 86, 87, 88, 95, 100, 101, 102, 108, 110, 111, 113, 115, 116], "task": [47, 69, 82, 87, 116], "task_typ": 115, "tau": [36, 60, 62, 72, 73, 75, 76, 84, 86, 88, 90, 95, 100], "tau_": [73, 76, 86], "tau_0": [76, 86], "tau_1": 73, "tau_2": 73, "tau_vec": [60, 72, 75], "tax": [51, 71, 72], "te": [49, 58, 59, 74], "techniqu": [48, 57, 81, 87, 116], "templat": 115, "ten": 69, "tend": [51, 71, 72, 86], "tensor": [58, 59], "tenth": 114, "term": [48, 50, 51, 52, 57, 62, 63, 70, 71, 73, 78, 81, 86, 111, 116], "termin": [52, 85], "terminatorev": 52, "test": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 25, 37, 38, 41, 42, 47, 48, 49, 50, 51, 52, 57, 66, 70, 78, 81, 85, 86, 87, 88, 101, 113, 114, 115, 116], "test_id": [50, 87], "test_ind": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "test_set": 87, "test_siz": 57, "text": [21, 22, 23, 25, 27, 35, 36, 50, 51, 60, 63, 73, 74, 75, 76, 78, 84, 86, 87], "textbf": [80, 85, 116], "textposit": 78, "textrm": [102, 103, 104, 108, 109, 110], "tg": [52, 53, 82, 113], "th": [50, 70], "than": [12, 48, 49, 51, 57, 63, 67, 68, 71, 72, 73, 76, 77, 78, 81, 86, 102, 107, 116], "thank": [49, 51, 52, 71, 115], "thatw": 62, "thei": [49, 51, 62, 64, 65, 71, 73, 86, 102, 110], "them": [51, 52, 58, 59, 60, 66, 69, 71, 75, 86], "theme": [50, 51], "theme_minim": [48, 51], "theorem": [102, 110], "theoret": [68, 78, 87, 114], "theori": [84, 114], "therebi": [50, 52, 70, 116], "therefor": [55, 73, 76, 77, 87, 88, 102, 109], "theta": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 25, 26, 27, 29, 31, 32, 33, 34, 48, 50, 52, 55, 57, 61, 62, 63, 66, 67, 68, 70, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 107, 109, 110, 113, 116], "theta_": [55, 76, 78, 84, 86, 101, 102, 110], "theta_0": [11, 12, 14, 15, 24, 48, 50, 51, 55, 57, 58, 59, 63, 64, 65, 70, 71, 78, 79, 81, 84, 86, 88, 95, 100, 101, 102, 103, 108, 110, 113], "theta_dml": [48, 57, 81], "theta_dml_po": [48, 57, 81], "theta_initi": 57, "theta_nonorth": [48, 57], "theta_orth_nosplit": [48, 57], "theta_orth_po_nosplit": [48, 57], "theta_resc": 48, "theta_t": 62, "thi": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 34, 37, 38, 40, 41, 42, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 85, 86, 87, 88, 90, 91, 92, 94, 95, 100, 101, 102, 103, 104, 107, 108, 111, 112, 113, 114, 115, 116], "think": 52, "third": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 48, 57, 70, 81, 87], "thirion": [111, 113], "this_df": [63, 71], "this_split_ind": 70, "those": [49, 51, 71, 72], "though": [47, 56, 73], "thread": [73, 85], "three": [50, 52, 64, 65, 112, 115], "threshold": [4, 6, 8, 9, 11, 12, 13, 16, 17, 18, 76, 78, 86], "through": [49, 60, 64, 65, 75, 76, 85, 86], "throughout": 66, "thu": [69, 76, 84, 86], "tibbl": 49, "tick_param": 76, "tight": 57, "tight_layout": [69, 70, 76], "tighter": 76, "tild": [21, 22, 23, 27, 50, 70, 73, 80, 84, 87, 88, 95, 96, 97, 100, 101, 102, 109, 110], "time": [7, 8, 10, 28, 29, 48, 49, 50, 51, 57, 61, 62, 63, 64, 65, 70, 71, 72, 76, 77, 78, 79, 86, 115, 116], "time_budget": 69, "time_df": 62, "time_period": 62, "titiunik": [86, 114], "titl": [50, 51, 55, 58, 59, 60, 63, 64, 65, 68, 69, 70, 71, 72, 73, 75, 76, 78, 111], "tmp": 65, "tname": 49, "tnr": [52, 85], "to_fram": 74, "to_numpi": [60, 66, 72, 75], "todo": [50, 53], "toeplitz": 63, "togeth": [64, 65, 101], "toler": 70, "tomasz": [114, 115], "toml": 115, "too": 68, "tool": [49, 52, 77, 116], "top": [50, 68, 70, 71, 72, 76, 78, 86, 111], "total": [38, 42, 51, 69, 71], "tpot": 69, "tracker": 111, "tradit": 101, "train": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 41, 42, 48, 50, 52, 57, 58, 59, 60, 64, 65, 67, 68, 70, 71, 74, 75, 80, 81, 87], "train_id": [50, 87], "train_ind": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "train_set": 87, "train_test_split": 57, "transact": 114, "transform": [21, 22, 36, 67, 73, 78, 116], "translat": 63, "transpos": 62, "treament": 74, "treat": [12, 23, 49, 55, 61, 62, 66, 74, 76, 78, 84, 86, 101, 116], "treat1_param": 73, "treat2_param": 73, "treat_var": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 85], "treatment": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 30, 35, 47, 49, 50, 52, 53, 55, 56, 61, 62, 63, 66, 68, 69, 70, 74, 76, 77, 78, 79, 81, 82, 83, 85, 87, 88, 89, 90, 91, 92, 94, 95, 100, 101, 102, 103, 107, 109, 111, 113, 114, 115, 116], "treatment_df": 62, "treatment_effect": [24, 58, 59], "treatment_level": [4, 5, 55, 67, 86], "treatment_var": [7, 10], "tree": [12, 40, 51, 52, 61, 62, 68, 71, 80, 83, 85, 86, 87, 88, 101, 113, 115], "tree_param": [12, 40], "tree_summari": 71, "trees_class": [51, 71], "trend": [49, 61, 62, 70, 86, 114], "tri": [63, 102, 104], "triangular": [35, 76, 86], "trim": [4, 6, 8, 9, 11, 12, 13, 16, 17, 18, 51, 71, 72, 78], "trimming_rul": [4, 5, 6, 8, 9, 11, 12, 13, 16, 17, 18, 72], "trimming_threshold": [4, 5, 6, 8, 9, 11, 12, 13, 16, 17, 18, 51, 58, 67, 71, 72, 74, 75, 78], "trm": [52, 85], "true": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 27, 32, 35, 36, 37, 38, 41, 42, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 85, 86, 87, 88, 89, 90, 95, 96, 97, 100, 101, 102, 105, 106, 110, 113, 116], "true_effect": [58, 59, 62, 64, 65], "true_gatet_effect": 66, "true_group_effect": 66, "true_tau": 76, "truncat": [4, 5, 6, 8, 9, 11, 12, 13, 16, 17, 18, 72], "try": [68, 77], "tune": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 63, 68, 76, 83, 86, 111, 113, 115], "tune_on_fold": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 85], "tune_r": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18], "tune_set": [52, 85], "tuned_model": 69, "tuner": 85, "tunergridsearch": 52, "tupl": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "turn": 78, "turrel": 31, "tutori": 51, "tw": [71, 72], "twice": 86, "twinx": 55, "two": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 47, 48, 51, 52, 56, 57, 60, 61, 67, 68, 69, 71, 72, 73, 74, 75, 77, 78, 80, 81, 84, 85, 86, 87, 88, 95, 101, 116], "twoclass": 52, "twoearn": [51, 71, 72, 77, 116], "type": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 24, 27, 35, 36, 37, 38, 39, 40, 41, 42, 43, 48, 49, 50, 51, 52, 57, 68, 69, 70, 76, 78, 81, 85, 86, 88, 98, 99, 101, 102, 109, 115, 116], "typic": [65, 86, 111], "u": [11, 12, 13, 16, 17, 21, 22, 23, 24, 26, 32, 38, 42, 48, 49, 50, 51, 55, 57, 60, 61, 62, 64, 65, 67, 68, 70, 71, 72, 74, 75, 77, 78, 81, 86, 102, 104, 112, 116], "u_hat": [48, 57, 88], "u_i": [25, 28, 31, 32], "u_t": 23, "uehara": 114, "uhash": 52, "ulf": 114, "unambigu": 78, "uncertainti": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 64, 65, 67, 76, 77, 102, 107, 116], "unchang": [37, 38, 41, 42], "uncondit": [51, 71, 116], "unconfounded": [78, 114], "under": [18, 48, 51, 57, 61, 71, 74, 76, 78, 81, 86, 101, 114], "underbrac": [48, 57, 62, 81, 84], "underfit": 69, "underli": [21, 27, 51, 52, 55, 64, 65, 73, 74, 86, 102, 104, 116], "underlin": [50, 70], "underset": [76, 86], "understand": 78, "undesir": 85, "unevenli": 87, "uniform": [23, 35, 36, 56, 58, 59, 60, 62, 74, 75, 101], "uniform_averag": [38, 42], "uniformli": [60, 72, 101], "uniqu": [47, 55, 56, 68, 76, 88, 102, 110], "unique_label": 69, "unit": [48, 49, 61, 62, 66, 76, 79, 86, 88, 91, 92, 115], "univari": [24, 58, 59], "univers": 114, "unknown": 86, "unlik": [51, 71, 72, 78], "unobserv": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 47, 51, 56, 71, 72, 77, 78, 86, 102, 104, 110, 116], "unpen": 49, "unstabl": [102, 104], "unter": [50, 51, 52], "untest": 78, "until": [86, 115], "untreat": [78, 86], "up": [5, 17, 51, 63, 68, 69, 71, 72, 77, 78, 85, 86, 87, 102, 104, 112, 115, 116], "upcom": 115, "updat": [37, 38, 41, 42, 50, 65, 70, 71, 114, 115], "update_layout": [58, 59, 63, 76, 78], "update_trac": [58, 59], "upload": 115, "upon": [88, 115], "upper": [51, 52, 55, 57, 60, 62, 66, 67, 72, 75, 76, 77, 78, 85, 102, 107, 110, 116], "upper_bound": [58, 59], "upsilon": 79, "upsilon_i": 79, "upward": [51, 71, 72, 78], "upweight": 73, "url": [63, 111, 114], "us": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39, 41, 42, 48, 50, 51, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 84, 86, 87, 88, 91, 92, 101, 102, 104, 107, 108, 109, 110, 111, 112, 113, 115, 116], "usa": 114, "usabl": 68, "usag": [49, 53, 55, 61, 66, 70, 71, 72, 77, 79, 82, 113, 115], "use_label_encod": [71, 116], "use_other_treat_as_covari": [7, 10, 82], "use_pred_offset": 85, "usecolormap": [58, 59], "user": [33, 34, 37, 38, 41, 42, 48, 49, 50, 51, 52, 55, 57, 66, 67, 68, 70, 71, 76, 77, 84, 85, 86, 88, 101, 111, 112, 113, 115, 116], "user_guid": 65, "userwarn": [71, 78], "usual": [50, 58, 59, 61, 68, 70, 76, 77, 78, 84, 85, 87, 102, 110], "util": [0, 34, 67, 68, 69, 73, 76, 85, 86, 115], "v": [11, 12, 14, 15, 19, 20, 26, 28, 29, 30, 32, 38, 42, 48, 50, 51, 55, 57, 66, 67, 68, 69, 70, 71, 73, 76, 80, 81, 84, 86, 101, 111, 113, 114, 115, 116], "v108": 111, "v12": [111, 113], "v22": 52, "v23": 111, "v_": [29, 50, 70, 86], "v_i": [25, 26, 30, 31, 32, 48, 57, 81, 86], "v_j": 101, "val": [26, 87, 114], "val_list": 63, "valid": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 25, 48, 49, 50, 51, 57, 60, 61, 68, 69, 70, 71, 72, 75, 81, 83, 84, 85, 87, 88, 90, 95, 100, 102, 104, 114, 116], "valu": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 41, 42, 43, 47, 48, 49, 50, 51, 52, 55, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76, 77, 78, 80, 83, 85, 86, 87, 90, 95, 96, 97, 100, 101, 102, 104, 107, 110, 113, 115, 116], "value_count": 71, "van": 114, "vanderpla": [111, 113], "vanish": [48, 57, 81], "var": [21, 22, 23, 27, 50, 70, 73, 76, 102, 103, 104, 108, 109, 110], "var_ep": 78, "varepsilon": [11, 21, 22, 29, 50, 70, 79, 84, 86], "varepsilon_": [29, 50, 70], "varepsilon_0": 23, "varepsilon_1": 23, "varepsilon_d": [22, 27], "varepsilon_i": [27, 28, 60, 75, 79], "vari": [51, 62, 68, 71, 73, 78], "variabl": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 35, 50, 51, 52, 53, 55, 61, 63, 66, 69, 70, 71, 72, 76, 77, 78, 79, 82, 84, 85, 86, 87, 88, 101, 102, 104, 107, 110, 113, 114, 115, 116], "varianc": [33, 34, 50, 52, 70, 76, 77, 78, 83, 86, 87, 102, 104, 107, 108, 109, 110, 113], "variant": [49, 67], "variat": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 22, 67, 77, 102, 104, 110], "variou": [49, 69, 78, 85, 116], "varoquaux": [111, 113], "vasili": [78, 114], "vector": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 24, 25, 26, 28, 29, 31, 32, 47, 50, 51, 56, 61, 64, 65, 66, 70, 71, 74, 79, 86, 101, 113, 115], "venv": 112, "verbos": [51, 57, 62, 68, 69, 76, 78], "veri": [49, 50, 52, 66, 68, 70, 78, 88, 111], "verifi": 73, "versa": [68, 73, 102, 107], "version": [21, 37, 38, 41, 42, 50, 51, 52, 78, 80, 84, 101, 102, 103, 105, 106, 108, 115], "versoin": 78, "versu": 65, "vertic": [50, 55, 70], "via": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 34, 49, 60, 61, 62, 63, 64, 65, 66, 67, 68, 76, 77, 79, 80, 82, 83, 84, 85, 86, 87, 90, 97, 101, 102, 104, 107, 110, 111, 112, 113, 114, 115, 116], "viabl": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18], "vice": [68, 73, 102, 107], "victor": [63, 78, 87, 111, 114], "view": 65, "vignett": [49, 115], "villa": [47, 56], "violet": [60, 72, 75], "vira": 114, "virtual": 112, "virtualenv": 112, "visibl": [72, 76, 78], "visit": [111, 116], "visual": [50, 66, 67, 69, 70, 76], "vol": 49, "volum": [78, 111], "voluntari": 73, "vv740": 70, "vv760g": 70, "w": [19, 20, 21, 22, 23, 30, 33, 34, 37, 38, 41, 42, 50, 63, 70, 73, 74, 80, 81, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 113], "w24678": 87, "w30302": 114, "w_": [23, 50, 70, 74, 86], "w_1": [23, 74], "w_2": [23, 74], "w_3": 23, "w_4": 23, "w_df": 74, "w_i": [32, 61, 74, 76, 80, 84, 86, 87, 88, 101], "wa": [50, 62, 69, 70, 78, 115], "wager": 114, "wai": [51, 68, 69, 71, 78, 85, 88, 112], "wander": 31, "wang": 114, "want": [47, 50, 51, 52, 56, 60, 61, 68, 70, 75, 76, 85, 86, 111, 112, 114], "warn": [47, 48, 49, 50, 51, 52, 57, 71, 78, 80, 85, 86, 87, 88, 101, 113, 115], "wayon": 50, "we": [12, 40, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 93, 101, 102, 104, 110, 112, 113, 115, 116], "weak": [102, 104, 114], "wealth": [19, 77], "websit": [51, 52, 85, 111], "wedg": [50, 70], "week": 115, "wei": 101, "weight": [4, 5, 6, 11, 12, 13, 16, 17, 18, 37, 38, 41, 42, 50, 51, 52, 55, 66, 67, 70, 71, 76, 79, 83, 85, 86, 88, 89, 94, 101, 102, 103, 108, 115], "weights_bar": [4, 12, 67], "weights_dict": 67, "weiss": [111, 113], "well": [7, 10, 41, 42, 48, 50, 57, 63, 68, 69, 70, 80, 81, 82, 87, 112, 113], "were": [51, 71, 72, 79, 116], "what": [49, 63, 68], "when": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 37, 38, 41, 42, 51, 61, 65, 67, 71, 73, 86, 88, 101, 111, 112, 113, 115], "whenev": [51, 71], "whera": [102, 108], "where": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 38, 39, 40, 42, 47, 48, 50, 51, 55, 56, 57, 60, 61, 62, 66, 70, 71, 73, 74, 75, 76, 78, 79, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 107, 108, 110, 112, 113, 115, 116], "wherea": [24, 55, 61, 78, 79, 88, 94, 102, 103, 116], "whether": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 27, 32, 35, 39, 51, 62, 68, 71, 72, 76, 78, 82, 85, 86, 102, 104, 115], "which": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 24, 34, 37, 41, 47, 48, 49, 51, 52, 54, 55, 56, 57, 61, 63, 65, 66, 68, 69, 71, 72, 74, 76, 77, 78, 79, 81, 82, 84, 85, 86, 88, 101, 102, 103, 104, 107, 108, 110, 112, 115, 116], "while": [47, 56, 86], "white": [50, 64, 65, 70, 78], "whitegrid": [71, 72], "whitnei": [78, 114], "who": [49, 51, 71, 78], "whole": [48, 57, 61, 76, 81, 85, 102, 104], "whom": 86, "widehat": 86, "width": [48, 50, 58, 59, 63], "wiki": 115, "wiksel": 114, "wild": [4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 101], "window": 112, "wise": [64, 65], "wish": 112, "within": [35, 50, 64, 65, 70, 74, 76], "without": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 27, 35, 47, 48, 56, 57, 68, 69, 78, 81, 83, 85, 86, 102, 104, 112, 115], "wolf": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 101], "won": 78, "word": [35, 76, 86, 115, 116], "work": [37, 38, 41, 42, 54, 55, 65, 66, 68, 73, 77, 78, 85, 86, 101, 112, 114], "workflow": [111, 115], "workspac": 71, "world": 114, "worri": 78, "wors": [38, 42], "would": [38, 42, 49, 51, 52, 58, 59, 63, 68, 71, 72, 76, 77, 78, 84, 85, 102, 110, 116], "wrapper": [49, 76, 85], "write": [48, 49, 57, 61, 65, 79, 81, 102, 110], "written": [86, 88, 102, 103, 108], "wrong": [68, 73], "wspace": 68, "wurd": [50, 51, 52], "www": [111, 112], "x": [4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 41, 42, 48, 49, 50, 51, 52, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 108, 109, 110, 113, 116], "x0": [55, 73, 76], "x1": [50, 52, 55, 61, 67, 69, 70, 73, 76, 77, 78, 79, 82, 84, 85, 86, 88, 101, 102, 104, 113], "x10": [50, 52, 67, 69, 70, 79, 82, 85, 86, 88, 101, 113], "x100": [50, 52, 70, 79, 82, 86, 113], "x11": [50, 52, 70, 79, 82, 85, 86, 88, 101, 113], "x12": [50, 52, 70, 79, 82, 85, 86, 88, 101, 113], "x13": [50, 52, 70, 79, 82, 85, 86, 88, 101, 113], "x14": [50, 52, 70, 79, 82, 85, 86, 88, 101, 113], "x15": [50, 52, 70, 79, 82, 85, 86, 88, 101, 113], "x16": [50, 52, 70, 79, 82, 85, 86, 88, 101, 113], "x17": [50, 52, 70, 79, 82, 85, 86, 88, 101, 113], "x18": [50, 52, 70, 79, 82, 85, 86, 88, 101, 113], "x19": [50, 52, 70, 79, 82, 85, 86, 88, 101, 113], "x1x2x3x4x5x6x7x8x9x10": 50, "x2": [50, 52, 55, 61, 67, 69, 70, 76, 77, 78, 79, 82, 84, 85, 86, 88, 101, 113], "x20": [50, 52, 70, 79, 82, 85, 86, 88, 101, 113], "x21": [50, 52, 70, 79, 82, 86, 113], "x22": [50, 52, 70, 79, 82, 86, 113], "x23": [50, 52, 70, 79, 82, 86, 113], "x24": [50, 52, 70, 79, 82, 86, 113], "x25": [50, 52, 70, 79, 82, 86, 113], "x26": [50, 52, 70, 79, 82, 86, 113], "x27": [50, 52, 70, 79, 82, 86, 113], "x28": [50, 52, 70, 79, 82, 86, 113], "x29": [50, 52, 70, 79, 82, 86, 113], "x2_dummi": 78, "x2_preds_control": 78, "x2_preds_treat": 78, "x3": [50, 52, 55, 61, 67, 69, 70, 77, 78, 79, 82, 84, 85, 86, 88, 101, 113], "x30": [50, 52, 70, 79, 82, 86, 113], "x31": [50, 52, 70, 79, 82, 86, 113], "x32": [50, 52, 70, 79, 82, 86, 113], "x33": [50, 52, 70, 79, 82, 86, 113], "x34": [50, 52, 70, 79, 82, 86, 113], "x35": [50, 52, 70, 79, 82, 86, 113], "x36": [50, 52, 70, 79, 82, 86, 113], "x37": [50, 52, 70, 79, 82, 86, 113], "x38": [50, 52, 70, 79, 82, 86, 113], "x39": [50, 52, 70, 79, 82, 86, 113], "x4": [50, 52, 55, 61, 67, 69, 70, 77, 78, 79, 82, 85, 86, 88, 101, 113], "x40": [50, 52, 70, 79, 82, 86, 113], "x41": [50, 52, 70, 79, 82, 86, 113], "x42": [50, 52, 70, 79, 82, 86, 113], "x43": [50, 52, 69, 70, 79, 82, 86, 113], "x44": [50, 52, 69, 70, 79, 82, 86, 113], "x45": [50, 52, 69, 70, 79, 82, 86, 113], "x46": [50, 52, 69, 70, 79, 82, 86, 113], "x47": [50, 52, 69, 70, 79, 82, 86, 113], "x48": [50, 52, 69, 70, 79, 82, 86, 113], "x49": [50, 52, 69, 70, 79, 82, 86, 113], "x5": [50, 52, 67, 69, 70, 78, 79, 82, 85, 86, 88, 101, 113], "x50": [50, 52, 69, 70, 79, 82, 86, 113], "x51": [50, 52, 70, 79, 82, 86, 113], "x52": [50, 52, 70, 79, 82, 86, 113], "x53": [50, 52, 70, 79, 82, 86, 113], "x54": [50, 52, 70, 79, 82, 86, 113], "x55": [50, 52, 70, 79, 82, 86, 113], "x56": [50, 52, 70, 79, 82, 86, 113], "x57": [50, 52, 70, 79, 82, 86, 113], "x58": [50, 52, 70, 79, 82, 86, 113], "x59": [50, 52, 70, 79, 82, 86, 113], "x6": [50, 52, 67, 69, 70, 79, 82, 85, 86, 88, 101, 113], "x60": [50, 52, 70, 79, 82, 86, 113], "x61": [50, 52, 70, 79, 82, 86, 113], "x62": [50, 52, 70, 79, 82, 86, 113], "x63": [50, 52, 70, 79, 82, 86, 113], "x64": [50, 52, 70, 71, 79, 82, 86, 113], "x65": [50, 52, 70, 79, 82, 86, 113], "x66": [50, 52, 70, 79, 82, 86, 113], "x67": [50, 52, 70, 79, 82, 86, 113], "x68": [50, 52, 70, 79, 82, 86, 113], "x69": [50, 52, 70, 79, 82, 86, 113], "x7": [50, 52, 67, 69, 70, 79, 82, 85, 86, 88, 101, 113], "x70": [50, 52, 70, 79, 82, 86, 113], "x71": [50, 52, 70, 79, 82, 86, 113], "x72": [50, 52, 70, 79, 82, 86, 113], "x73": [50, 52, 70, 79, 82, 86, 113], "x74": [50, 52, 70, 79, 82, 86, 113], "x75": [50, 52, 70, 79, 82, 86, 113], "x76": [50, 52, 70, 79, 82, 86, 113], "x77": [50, 52, 70, 79, 82, 86, 113], "x78": [50, 52, 70, 79, 82, 86, 113], "x79": [50, 52, 70, 79, 82, 86, 113], "x8": [50, 52, 67, 69, 70, 79, 82, 85, 86, 88, 101, 113], "x80": [50, 52, 70, 79, 82, 86, 113], "x81": [50, 52, 70, 79, 82, 86, 113], "x82": [50, 52, 70, 79, 82, 86, 113], "x83": [50, 52, 70, 79, 82, 86, 113], "x84": [50, 52, 70, 79, 82, 86, 113], "x85": [50, 52, 70, 79, 82, 86, 113], "x86": [50, 52, 70, 79, 82, 86, 113], "x87": [50, 52, 70, 79, 82, 86, 113], "x88": [50, 52, 70, 79, 82, 86, 113], "x89": [50, 52, 70, 79, 82, 86, 113], "x9": [50, 52, 67, 69, 70, 79, 82, 85, 86, 88, 101, 113], "x90": [50, 52, 70, 79, 82, 86, 113], "x91": [50, 52, 70, 79, 82, 86, 113], "x92": [50, 52, 70, 79, 82, 86, 113], "x93": [50, 52, 70, 79, 82, 86, 113], "x94": [50, 52, 70, 79, 82, 86, 113], "x95": [50, 52, 70, 79, 82, 86, 113], "x96": [50, 52, 70, 79, 82, 86, 113], "x96x97x98x99x100ydcluster_var_icluster_var_jz": 50, "x97": [50, 52, 70, 79, 82, 86, 113], "x98": [50, 52, 70, 79, 82, 86, 113], "x99": [50, 52, 70, 79, 82, 86, 113], "x_": [29, 30, 48, 50, 57, 62, 70, 78, 81], "x_0": [58, 59, 62, 64, 65, 66], "x_1": [14, 15, 21, 22, 23, 27, 58, 59, 60, 62, 64, 65, 66, 75, 78, 86, 102, 104, 113], "x_1x_3": [60, 75], "x_2": [21, 22, 23, 27, 58, 59, 60, 62, 64, 65, 66, 75, 78, 102, 104], "x_3": [21, 22, 23, 27, 58, 59, 62, 64, 65, 66, 102, 104], "x_4": [21, 22, 23, 27, 58, 59, 60, 64, 65, 66, 75], "x_5": [21, 22, 27, 58, 59, 64, 65], "x_6": [58, 59, 64, 65], "x_7": [58, 59, 64, 65], "x_8": [58, 59, 64, 65], "x_9": [58, 59, 64, 65], "x_binary_control": 78, "x_binary_tr": 78, "x_col": [7, 10, 47, 50, 51, 52, 56, 63, 70, 71, 72, 74, 76, 77, 78, 82, 85, 86, 113, 115, 116], "x_cols_bench": 78, "x_cols_binari": 78, "x_cols_poli": 70, "x_conf": 75, "x_conf_tru": 75, "x_df": 62, "x_domain": 52, "x_i": [24, 25, 26, 28, 30, 31, 32, 36, 48, 57, 60, 61, 64, 65, 73, 75, 76, 79, 81, 84, 86], "x_p": [14, 15, 86, 113], "x_train": 69, "x_true": [60, 75], "x_var": 52, "xaxis_titl": [58, 59, 63, 76, 78], "xformla": 49, "xgb": 69, "xgb_untuned_l": 69, "xgb_untuned_m": 69, "xgbclassifi": [68, 71, 73, 116], "xgboost": [48, 51, 68, 71, 73, 116], "xgbregressor": [68, 69, 71, 73, 116], "xi": [23, 27, 86], "xi_": 101, "xi_0": [29, 50, 70], "xi_i": 79, "xiaoji": 114, "xintercept": 48, "xlab": [48, 50, 51], "xlabel": [55, 58, 59, 60, 62, 64, 65, 69, 71, 72, 75], "xlim": [48, 51], "xtick": [55, 69], "xval": [52, 85], "xx": 57, "y": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 41, 42, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 107, 108, 109, 110, 113, 116], "y0": [49, 55, 60, 75], "y0_cvar": 60, "y0_quant": [60, 75], "y1": [49, 60, 75], "y1_cvar": 60, "y1_quant": [60, 75], "y_": [29, 50, 61, 62, 70, 79, 86], "y_0": [8, 23, 36, 88, 91], "y_1": [8, 23, 36, 88, 91], "y_col": [7, 10, 47, 48, 50, 51, 52, 56, 58, 59, 63, 64, 65, 67, 70, 71, 72, 74, 76, 77, 80, 81, 82, 85, 86, 87, 88, 113, 115, 116], "y_df": [62, 74], "y_diff": 62, "y_i": [24, 25, 26, 28, 30, 31, 32, 48, 57, 60, 61, 73, 74, 75, 76, 79, 81, 86], "y_pred": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 38, 42, 68, 85], "y_train": 69, "y_true": [4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 18, 38, 42, 68, 85], "ya": 114, "yasui": 114, "yata": 114, "yaxis_titl": [58, 59, 63, 76, 78], "year": 111, "yerr": [55, 62, 64, 65, 69, 71, 73, 76], "yet": [50, 54], "yggvpl": 70, "yield": 86, "yintercept": 51, "ylab": [48, 50, 51], "ylabel": [55, 58, 59, 60, 62, 64, 65, 69, 71, 72, 75], "ylim": 71, "ymax": 51, "ymin": 51, "yname": 49, "york": 114, "you": [37, 38, 41, 42, 47, 48, 56, 62, 65, 70, 77, 86, 111, 112, 116], "your": [68, 112], "ython": 111, "yukun": 114, "yusuk": 114, "yuya": 114, "yy": 57, "z": [7, 10, 11, 13, 14, 18, 21, 22, 23, 25, 27, 28, 29, 32, 47, 50, 51, 56, 58, 59, 63, 70, 71, 75, 78, 79, 84, 86, 88, 93, 95, 97, 98, 101, 115], "z1": [14, 86], "z2": 86, "z3": 86, "z4": 86, "z_": [29, 50, 70], "z_1": [21, 22, 27], "z_2": [21, 22, 27], "z_3": [21, 22, 27], "z_4": [21, 22, 27], "z_5": 21, "z_col": [7, 10, 11, 13, 14, 47, 50, 51, 56, 70, 71, 72, 79, 82, 84, 86, 115], "z_i": [28, 32, 75, 79, 86], "z_j": [21, 22, 23, 27], "z_true": 75, "zadik": 114, "zaxis_titl": [58, 59, 63], "zero": [23, 36, 60, 61, 62, 67, 68, 74, 75, 77, 78, 86, 101], "zeros_lik": 75, "zeta": [11, 14, 15, 51, 71, 84, 86, 113], "zeta_": [29, 50, 70], "zeta_0": [29, 50, 70], "zeta_i": [26, 28, 30, 48, 57, 81], "zeta_j": 101, "zhang": 114, "zhao": [8, 9, 21, 22, 23, 27, 49, 61, 86, 114], "zimmert": [61, 114], "zip": [58, 59], "zorder": 55, "\u03c4_x0": 73, "\u03c4_x1": 73, "\u2139": 48}, "titles": ["API Reference", "<span class=\"section-number\">1. </span>DoubleML Data Class", "<span class=\"section-number\">4. </span>Datasets", "<span class=\"section-number\">2. </span>DoubleML Models", "<span class=\"section-number\">2.4. </span>doubleml.DoubleMLAPO", "<span class=\"section-number\">2.5. </span>doubleml.DoubleMLAPOS", "<span class=\"section-number\">2.12. </span>doubleml.DoubleMLCVAR", "<span class=\"section-number\">1.2. </span>doubleml.DoubleMLClusterData", "<span class=\"section-number\">2.7. </span>doubleml.DoubleMLDID", "<span class=\"section-number\">2.8. </span>doubleml.DoubleMLDIDCS", "<span class=\"section-number\">1.1. </span>doubleml.DoubleMLData", "<span class=\"section-number\">2.6. </span>doubleml.DoubleMLIIVM", "<span class=\"section-number\">2.3. </span>doubleml.DoubleMLIRM", "<span class=\"section-number\">2.11. </span>doubleml.DoubleMLLPQ", "<span class=\"section-number\">2.2. </span>doubleml.DoubleMLPLIV", "<span class=\"section-number\">2.1. </span>doubleml.DoubleMLPLR", "<span class=\"section-number\">2.10. </span>doubleml.DoubleMLPQ", "<span class=\"section-number\">2.13. </span>doubleml.DoubleMLQTE", "<span class=\"section-number\">2.9. </span>doubleml.DoubleMLSSM", "<span class=\"section-number\">4.1.1. </span>doubleml.datasets.fetch_401K", "<span class=\"section-number\">4.1.2. </span>doubleml.datasets.fetch_bonus", "<span class=\"section-number\">4.2.10. </span>doubleml.datasets.make_confounded_irm_data", "<span class=\"section-number\">4.2.9. </span>doubleml.datasets.make_confounded_plr_data", "<span class=\"section-number\">4.2.7. </span>doubleml.datasets.make_did_SZ2020", "<span class=\"section-number\">4.2.11. </span>doubleml.datasets.make_heterogeneous_data", "<span class=\"section-number\">4.2.4. </span>doubleml.datasets.make_iivm_data", "<span class=\"section-number\">4.2.3. </span>doubleml.datasets.make_irm_data", "<span class=\"section-number\">4.2.12. </span>doubleml.datasets.make_irm_data_discrete_treatments", "<span class=\"section-number\">4.2.2. </span>doubleml.datasets.make_pliv_CHS2015", "<span class=\"section-number\">4.2.6. </span>doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "<span class=\"section-number\">4.2.1. </span>doubleml.datasets.make_plr_CCDDHNR2018", "<span class=\"section-number\">4.2.5. </span>doubleml.datasets.make_plr_turrell2018", "<span class=\"section-number\">4.2.8. </span>doubleml.datasets.make_ssm_data", "<span class=\"section-number\">6.1. </span>doubleml.double_ml_score_mixins.LinearScoreMixin", "<span class=\"section-number\">6.2. </span>doubleml.double_ml_score_mixins.NonLinearScoreMixin", "<span class=\"section-number\">3.1. </span>doubleml.rdd.RDFlex", "<span class=\"section-number\">4.2.13. </span>doubleml.rdd.datasets.make_simple_rdd_data", "<span class=\"section-number\">5.1.2. </span>doubleml.utils.DMLDummyClassifier", "<span class=\"section-number\">5.1.1. </span>doubleml.utils.DMLDummyRegressor", "<span class=\"section-number\">5.1.3. </span>doubleml.utils.DoubleMLBLP", "<span class=\"section-number\">5.1.4. </span>doubleml.utils.DoubleMLPolicyTree", "<span class=\"section-number\">5.1.6. </span>doubleml.utils.GlobalClassifier", "<span class=\"section-number\">5.1.5. </span>doubleml.utils.GlobalRegressor", "<span class=\"section-number\">5.2.1. </span>doubleml.utils.gain_statistics", "<span class=\"section-number\">6. </span>Score Mixin Classes for DoubleML Models", "<span class=\"section-number\">3. </span>Other models", "<span class=\"section-number\">5. </span>Utility Classes and Functions", "R: Basic Instrumental Variables Calculation", "R: Basics of Double Machine Learning", "R: DoubleML for Difference-in-Differences", "R: Cluster Robust Double Machine Learning", "R: Impact of 401(k) on Financial Wealth", "R: Ensemble Learners and More with <code class=\"docutils literal notranslate\"><span class=\"pre\">mlr3pipelines</span></code>", "DML: Bonus Data", "Examples", "Python: Average Potential Outcome (APO) Models", "Python: Basic Instrumental Variables calculation", "Python: Basics of Double Machine Learning", "Python: Conditional Average Treatment Effects (CATEs) for IRM models", "Python: Conditional Average Treatment Effects (CATEs) for PLR models", "Python: Conditional Value at Risk of potential outcomes", "Python: Difference-in-Differences", "Python: Difference-in-Differences Pre-Testing", "Python: First Stage and Causal Estimation", "Python: Group Average Treatment Effects (GATEs) for IRM models", "Python: Group Average Treatment Effects (GATEs) for PLR models", "Python: GATE Sensitivity Analysis", "Python: IRM and APO Model Comparison", "Python: Choice of learners", "DoubleML meets FLAML - How to tune learners automatically within <code class=\"docutils literal notranslate\"><span class=\"pre\">DoubleML</span></code>", "Python: Cluster Robust Double Machine Learning", "Python: Impact of 401(k) on Financial Wealth", "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)", "Python: PLM and IRM for Multiple Treatments", "Python: Policy Learning with Trees", "Python: Potential Quantiles and Quantile Treatment Effects", "Flexible Covariate Adjustment in Regression Discontinuity Designs (RDD)", "Python: Sensitivity Analysis", "Example: Sensitivity Analysis for Causal ML", "Python: Sample Selection Models", "<span class=\"section-number\">6. </span>Double machine learning algorithms", "<span class=\"section-number\">1. </span>The basics of double/debiased machine learning", "<span class=\"section-number\">2. </span>The data-backend DoubleMLData", "User Guide", "<span class=\"section-number\">4. </span>Heterogeneous treatment effects", "<span class=\"section-number\">7. </span>Learners, hyperparameters and hyperparameter tuning", "<span class=\"section-number\">3. </span>Models", "<span class=\"section-number\">9. </span>Sample-splitting, cross-fitting and repeated cross-fitting", "<span class=\"section-number\">5. </span>Score functions", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "<span class=\"section-number\">8. </span>Variance estimation and confidence intervals", "<span class=\"section-number\">10. </span>Sensitivity analysis", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "DoubleML", "Installing DoubleML", "Getting Started", "Double Machine Learning Literature", "Release Notes", "DoubleML Workflow"], "titleterms": {"": 69, "0": 116, "1": [69, 78, 116], "2": [69, 78, 116], "2011": 78, "2023": 78, "3": [69, 78, 116], "4": [78, 116], "401": [51, 71, 72, 77], "5": [78, 116], "6": 116, "7": 116, "95": 69, "A": [50, 70], "ATE": [66, 73, 79], "No": [50, 70], "One": [50, 58, 59, 70], "The": [51, 71, 73, 81, 82, 113], "acknowledg": [49, 111], "acycl": [47, 56], "addit": 73, "adjust": 76, "advanc": [76, 85, 101], "al": 78, "algorithm": [80, 102, 111, 113], "altern": 88, "analysi": [55, 66, 67, 77, 78, 102, 116], "api": [0, 69], "apo": [55, 67, 86, 88, 102], "applic": [50, 70, 77], "approach": [48, 57, 68, 81], "arah": 78, "arbitrari": 73, "arrai": 82, "asset": [51, 71], "assumpt": 78, "att": 61, "augment": 73, "automat": 69, "automl": 69, "averag": [51, 55, 58, 59, 64, 65, 67, 71, 84, 86, 88, 102], "backend": [50, 51, 70, 71, 82, 113, 116], "band": 101, "base": 52, "basic": [47, 48, 56, 57, 81], "benchmark": [77, 78, 102], "bia": [48, 57, 81], "binari": [86, 88], "bonu": 53, "bootstrap": 101, "build": 112, "calcul": [47, 56], "call": 69, "callabl": 88, "case": 54, "cate": [58, 59, 73, 84], "causal": [53, 55, 63, 78, 88, 113, 116], "chernozhukov": 78, "choic": 68, "citat": 111, "class": [1, 44, 46, 50, 70], "cluster": [50, 70], "code": 111, "coeffici": 69, "combin": 63, "compar": [68, 69], "comparison": [49, 67, 69], "comput": [68, 69], "conclus": [69, 78], "conda": 112, "condit": [58, 59, 60, 72, 84, 88], "confid": [69, 101], "construct": 85, "contrast": 55, "covari": 76, "coverag": [61, 63], "cran": 112, "creat": 69, "cross": [50, 61, 70, 86, 87, 88, 102, 113], "custom": [68, 69], "cvar": [60, 72, 84, 88], "dag": [47, 56], "data": [1, 47, 48, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 81, 82, 86, 88, 102, 113, 116], "datafram": 82, "dataset": [2, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 53], "debias": [48, 57, 81, 113], "default": 69, "defin": [50, 70], "demo": 49, "depend": 112, "design": [76, 86], "detail": [49, 86], "develop": 112, "dgp": [48, 55, 57], "did": [49, 86], "differ": [49, 61, 62, 68, 86, 88, 101, 102], "dimension": [58, 59], "direct": [47, 56], "disclaim": 78, "discontinu": [76, 86], "distribut": 79, "dml": [50, 53, 70, 87, 113, 116], "dml1": 80, "dml2": 80, "dmldummyclassifi": 37, "dmldummyregressor": 38, "doubl": [48, 50, 57, 70, 80, 81, 111, 113, 114], "double_ml_score_mixin": [33, 34], "doubleml": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 49, 51, 52, 56, 69, 71, 77, 78, 101, 111, 112, 116], "doublemlapo": [4, 5], "doublemlblp": 39, "doublemlclusterdata": [7, 50, 70], "doublemlcvar": 6, "doublemldata": [10, 51, 71, 82, 113], "doublemldid": 8, "doublemldidc": 9, "doublemliivm": 11, "doublemlirm": 12, "doublemllpq": 13, "doublemlpliv": [14, 50, 70], "doublemlplr": 15, "doublemlpolicytre": 40, "doublemlpq": 16, "doublemlqt": 17, "doublemlssm": 18, "effect": [51, 54, 58, 59, 60, 64, 65, 67, 71, 72, 73, 75, 77, 78, 84], "elig": [51, 71], "empir": 63, "ensembl": [52, 76], "error": [50, 70], "estim": [47, 51, 53, 56, 61, 63, 66, 69, 71, 72, 73, 75, 77, 78, 79, 87, 88, 101, 113, 116], "et": 78, "evalu": [68, 69, 85], "exampl": [49, 50, 54, 58, 59, 70, 77, 78], "exploit": [49, 52], "extern": [85, 87], "featur": [52, 111], "fetch_401k": 19, "fetch_bonu": 20, "figur": 73, "file": 112, "final": 49, "financi": [51, 71, 72], "first": 63, "fit": [50, 69, 70, 87, 113], "flaml": 69, "flexibl": 76, "fold": [69, 87], "forest": 53, "formul": [78, 116], "from": [49, 52, 82, 112], "full": 69, "function": [46, 49, 50, 70, 88, 113], "fuzzi": [76, 86], "gain_statist": 43, "gate": [64, 65, 66, 84], "gatet": 66, "gener": [2, 48, 54, 55, 57, 69, 76, 81, 102], "get": 113, "github": 112, "global": 76, "globalclassifi": 41, "globalregressor": 42, "graph": [47, 56], "group": [64, 65, 84], "guid": 83, "helper": [50, 70], "heterogen": [54, 67, 73, 84], "how": [52, 69], "hyperparamet": [67, 85], "identif": 78, "iivm": [51, 71, 86, 88], "impact": [51, 71, 72], "implement": [80, 86, 88, 102], "induc": [48, 57, 81], "infer": [101, 116], "initi": [50, 69, 70], "instal": 112, "instrument": [47, 56], "integr": 49, "interact": [51, 64, 71, 74, 86, 88, 102], "interv": [69, 101], "invers": 73, "irm": [51, 53, 58, 64, 67, 71, 73, 74, 77, 84, 86, 88, 102], "iv": [47, 51, 56, 71, 86, 88], "k": [51, 71, 72, 77, 87], "lambda": 63, "lasso": [53, 63], "latest": 112, "lear": [50, 70], "learn": [48, 50, 57, 70, 74, 80, 81, 84, 111, 113, 114], "learner": [52, 53, 67, 68, 69, 76, 85, 113], "less": 69, "level": 86, "linear": [51, 65, 71, 73, 76, 86, 88, 102], "linearscoremixin": 33, "literatur": 114, "load": [50, 53, 70, 78], "loader": 2, "local": [51, 71, 72, 75, 76, 88], "loss": 63, "lpq": [75, 88], "lqte": [72, 75], "m": 87, "machin": [48, 50, 57, 70, 80, 81, 111, 113, 114], "main": 111, "mainten": 111, "make_confounded_irm_data": 21, "make_confounded_plr_data": 22, "make_did_sz2020": 23, "make_heterogeneous_data": 24, "make_iivm_data": 25, "make_irm_data": 26, "make_irm_data_discrete_treat": 27, "make_pliv_chs2015": 28, "make_pliv_multiway_cluster_ckms2021": 29, "make_plr_ccddhnr2018": 30, "make_plr_turrell2018": 31, "make_simple_rdd_data": 36, "make_ssm_data": 32, "mar": 79, "market": [50, 70], "matric": 82, "meet": 69, "method": [69, 116], "metric": [68, 69], "minimum": 85, "miss": 79, "missing": [86, 88], "mixin": 44, "ml": [48, 49, 57, 78, 81, 116], "mlr3": 52, "mlr3extralearn": 52, "mlr3learner": 52, "mlr3pipelin": 52, "model": [3, 44, 45, 51, 53, 55, 58, 59, 64, 65, 67, 69, 71, 73, 74, 78, 79, 84, 86, 87, 88, 101, 102, 113, 116], "modul": 53, "more": 52, "motiv": [50, 70], "multipl": [55, 73, 86], "multipli": 101, "naiv": [47, 56], "net": [51, 71], "neyman": [88, 113], "nonignor": [79, 86, 88], "nonlinearscoremixin": 34, "nonrespons": [79, 86, 88], "note": 115, "nuisanc": [69, 113], "object": [50, 70, 77], "option": 112, "orthogon": [48, 57, 81, 88, 113], "other": 45, "out": [48, 57, 81], "outcom": [55, 60, 61, 79, 84, 86, 88, 102], "over": 101, "overcom": [48, 57, 81], "overfit": [48, 57, 81], "overlap": 73, "packag": [49, 51, 71, 112], "panel": [61, 86, 88, 102], "paramet": [52, 53, 69, 88], "partial": [48, 51, 57, 65, 71, 73, 81, 86, 88, 102], "particip": [51, 71], "partit": 87, "penalti": 63, "perform": [49, 73], "pip": 112, "pipelin": 85, "pliv": [86, 88], "plm": [73, 86, 88], "plot": [50, 69, 70], "plr": [51, 53, 59, 65, 71, 84, 86, 88, 102], "polici": [74, 84], "potenti": [55, 60, 72, 75, 84, 86, 88, 102], "pq": [75, 84, 88], "pre": 62, "predict": [49, 85], "preprocess": 52, "problem": 116, "process": [48, 50, 55, 57, 70, 81], "product": [50, 70], "propens": 73, "provid": 87, "python": [54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 79, 85, 112], "qte": [75, 84], "qualiti": 63, "quantil": [72, 75, 84, 88], "r": [47, 48, 49, 50, 51, 52, 54, 85, 112], "random": [53, 79, 86, 88], "rank": 73, "rdd": [35, 36, 76, 86], "rdflex": 35, "real": [50, 70], "refer": [0, 47, 49, 50, 52, 56, 63, 68, 69, 70, 73, 78, 81, 85, 87, 101, 111, 113], "regress": [51, 64, 65, 71, 74, 76, 86, 88, 102], "regular": [48, 57, 81], "releas": [112, 115], "remark": 49, "remov": [48, 57, 81], "repeat": [61, 86, 87, 88, 102], "repetit": 87, "requir": 85, "respect": [50, 70], "result": [50, 51, 70, 71, 73], "risk": [60, 72, 84, 88], "robust": [50, 70], "sampl": [48, 57, 69, 79, 81, 86, 87, 88], "sandbox": 54, "score": [44, 48, 57, 73, 81, 88, 113], "section": [61, 86, 88, 102], "select": [79, 86, 88], "sensit": [55, 66, 67, 77, 78, 102, 116], "set": [52, 85], "sharp": [76, 86], "simpl": [48, 57, 81], "simul": [47, 50, 56, 61, 70, 77], "simultan": 101, "singl": 55, "sourc": [111, 112], "specif": [102, 116], "specifi": [53, 85, 88], "split": [48, 57, 81, 87], "ssm": 86, "stack": 76, "stage": 63, "standard": [50, 68, 70], "start": 113, "step": 69, "studi": 54, "summari": [51, 69, 71, 73], "test": 62, "theori": 102, "time": [68, 69], "train": 69, "treat": 67, "treatment": [51, 58, 59, 60, 64, 65, 67, 71, 72, 73, 75, 84, 86], "tree": [74, 84], "tune": [52, 69, 85], "two": [50, 58, 59, 70], "under": [73, 79], "untun": 69, "up": 52, "us": [47, 49, 52, 53, 56, 69, 85], "user": 83, "util": [37, 38, 39, 40, 41, 42, 43, 46], "v": 63, "valid": 101, "valu": [60, 72, 84, 88], "vanderweel": 78, "variabl": [47, 56], "varianc": 101, "version": 112, "via": 88, "wai": [50, 70], "wealth": [51, 71, 72], "weight": [73, 84], "when": 69, "whl": 112, "within": 69, "without": [76, 87], "workflow": 116, "xgboost": 69, "zero": [50, 70]}})