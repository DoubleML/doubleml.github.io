Search.setIndex({"alltitles": {"(One-Way) Cluster Robust Double Machine Learing": [[35, "(One-Way)-Cluster-Robust-Double-Machine-Learing"], [52, "(One-Way)-Cluster-Robust-Double-Machine-Learing"]], "0. Problem Formulation": [[77, "problem-formulation"]], "1. Data-Backend": [[77, "data-backend"]], "2. Causal Model": [[77, "causal-model"]], "3. ML Methods": [[77, "ml-methods"]], "4. DML Specifications": [[77, "dml-specifications"]], "5. Estimation": [[77, "estimation"]], "6. Inference": [[77, "inference"]], "7. Sensitivity Analysis": [[77, "sensitivity-analysis"]], "A Motivating Example: Two-Way Cluster Robust DML": [[35, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"], [52, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"]], "API reference": [[0, "api-reference"]], "ATE Estimation and Sensitivity": [[50, "ATE-Estimation-and-Sensitivity"]], "ATE estimates distribution": [[59, "ATE-estimates-distribution"], [59, "id3"]], "ATTE Estimation": [[45, "ATTE-Estimation"], [45, "id2"]], "Acknowledgements": [[72, "acknowledgements"]], "Additional Results: CATE estimates": [[55, "Additional-Results:-CATE-estimates"]], "Advanced: External Predictions": [[65, "advanced-external-predictions"]], "Algorithm DML1": [[60, "algorithm-dml1"]], "Algorithm DML2": [[60, "algorithm-dml2"]], "Application Results": [[35, "Application-Results"], [52, "Application-Results"]], "Application: 401(k)": [[58, "Application:-401(k)"]], "Benchmarking": [[70, "benchmarking"]], "Benchmarking Analysis": [[58, "Benchmarking-Analysis"]], "CATEs for IRM models": [[64, "cates-for-irm-models"]], "CATEs for PLR models": [[64, "cates-for-plr-models"]], "CVaR Treatment Effects": [[44, "CVaR-Treatment-Effects"]], "CVaR of potential outcomes": [[64, "cvar-of-potential-outcomes"]], "CVaR treatment effects": [[64, "cvar-treatment-effects"]], "Causal estimation vs. lasso penalty \\lambda": [[47, "Causal-estimation-vs.-lasso-penalty-\\lambda"]], "Citation": [[72, "citation"]], "Cluster Robust Cross Fitting": [[35, "Cluster-Robust-Cross-Fitting"], [52, "Cluster-Robust-Cross-Fitting"]], "Cluster Robust Standard Errors": [[35, "Cluster-Robust-Standard-Errors"], [52, "Cluster-Robust-Standard-Errors"]], "Clustering and double machine learning": [[35, "Clustering-and-double-machine-learning"], [52, "Clustering-and-double-machine-learning"]], "Combined loss vs. lasso penalty \\lambda": [[47, "Combined-loss-vs.-lasso-penalty-\\lambda"]], "Comparing different learners": [[51, "Comparing-different-learners"]], "Comparison to did package": [[34, "Comparison-to-did-package"]], "Computation time": [[51, "Computation-time"]], "Conditional Value at Risk (CVaR)": [[44, "Conditional-Value-at-Risk-(CVaR)"]], "Conditional average treatment effects (CATEs)": [[64, "conditional-average-treatment-effects-cates"]], "Conditional value at risk (CVaR)": [[64, "conditional-value-at-risk-cvar"], [68, "conditional-value-at-risk-cvar"]], "Confidence bands and multiplier bootstrap for valid simultaneous inference": [[69, "confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference"], [71, "confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference"]], "Coverage Simulation": [[45, "Coverage-Simulation"], [45, "id3"]], "Cross-fitting with K folds": [[67, "cross-fitting-with-k-folds"]], "Cross-fitting, DML algorithms and Neyman-orthogonal score functions": [[74, "cross-fitting-dml-algorithms-and-neyman-orthogonal-score-functions"]], "Custom evaluation metrics": [[51, "Custom-evaluation-metrics"]], "DML: Bonus Data": [[38, "DML:-Bonus-Data"]], "Data": [[36, "Data"], [42, "Data"], [43, "Data"], [44, "Data"], [45, "Data"], [45, "id1"], [48, "Data"], [49, "Data"], [50, "Data"], [53, "Data"], [54, "Data"], [56, "Data"], [57, "Data"], [57, "id1"], [58, "Data"], [59, "Data"], [59, "id1"], [74, "data"]], "Data Generating Process (DGP)": [[33, "Data-Generating-Process-(DGP)"], [41, "Data-Generating-Process-(DGP)"]], "Data Simulation": [[32, "Data-Simulation"], [40, "Data-Simulation"]], "Data and Effect Estimation": [[58, "Data-and-Effect-Estimation"]], "Data generating process": [[61, "data-generating-process"]], "Data preprocessing": [[37, "Data-preprocessing"]], "Data-Backend for Cluster Data": [[35, "Data-Backend-for-Cluster-Data"], [52, "Data-Backend-for-Cluster-Data"]], "Dataset generators": [[0, "dataset-generators"]], "Dataset loaders": [[0, "dataset-loaders"]], "Datasets module": [[0, "datasets-module"]], "Define Helper Functions for Plotting": [[35, "Define-Helper-Functions-for-Plotting"], [52, "Define-Helper-Functions-for-Plotting"]], "Demo example from did": [[34, "Demo-example-from-did"]], "Details on Predictive Performance": [[34, "Details-on-Predictive-Performance"]], "Difference-in-Differences Models (DID)": [[66, "difference-in-differences-models-did"]], "Difference-in-Differences for Panel Data": [[68, "difference-in-differences-for-panel-data"], [70, "difference-in-differences-for-panel-data"]], "Difference-in-Differences for repeated cross-sections": [[68, "difference-in-differences-for-repeated-cross-sections"], [70, "difference-in-differences-for-repeated-cross-sections"]], "Double Machine Learning Algorithm": [[72, "double-machine-learning-algorithm"]], "Double machine learning algorithms": [[60, "double-machine-learning-algorithms"]], "Double machine learning data class": [[0, "double-machine-learning-data-class"]], "Double machine learning literature": [[75, "double-machine-learning-literature"]], "Double machine learning models": [[0, "double-machine-learning-models"]], "Double/debiased machine learning": [[33, "Double/debiased-machine-learning"], [41, "Double/debiased-machine-learning"], [61, "double-debiased-machine-learning"]], "DoubleML": [[72, "doubleml"]], "DoubleML Object": [[58, "DoubleML-Object"]], "DoubleML Workflow": [[77, "doubleml-workflow"]], "DoubleMLData from arrays and matrices": [[62, "doublemldata-from-arrays-and-matrices"]], "DoubleMLData from dataframes": [[62, "doublemldata-from-dataframes"]], "Effect Heterogeneity": [[39, "effect-heterogeneity"]], "Empirical coverage vs. lasso penalty \\lambda": [[47, "Empirical-coverage-vs.-lasso-penalty-\\lambda"]], "Estimate DML models without sample-splitting": [[67, "estimate-dml-models-without-sample-splitting"]], "Estimate double/debiased machine learning models": [[74, "estimate-double-debiased-machine-learning-models"]], "Estimating Potential Quantiles and Quantile Treatment Effects": [[54, "Estimating-Potential-Quantiles-and-Quantile-Treatment-Effects"]], "Estimating local quantile treatment effects (LQTEs)": [[54, "Estimating-local-quantile-treatment-effects-(LQTEs)"]], "Estimating the Average Treatment Effect of 401(k) Eligibility on Net Financial Assets": [[36, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"], [53, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"]], "Estimating the treatment effect on the Conditional Value a Risk (CVaR)": [[54, "Estimating-the-treatment-effect-on-the-Conditional-Value-a-Risk-(CVaR)"]], "Estimation": [[59, "Estimation"], [59, "id2"]], "Estimation quality vs. \\lambda": [[47, "Estimation-quality-vs.-\\lambda"]], "Evaluate learners": [[65, "evaluate-learners"]], "Examples": [[39, "examples"]], "Exploiting the Functionalities of did": [[34, "Exploiting-the-Functionalities-of-did"]], "Externally provide a sample splitting / partition": [[67, "externally-provide-a-sample-splitting-partition"]], "GATE Estimation and Sensitivity": [[50, "GATE-Estimation-and-Sensitivity"]], "GATET Estimation and Sensitivity": [[50, "GATET-Estimation-and-Sensitivity"]], "GATEs for IRM models": [[64, "gates-for-irm-models"]], "GATEs for PLR models": [[64, "gates-for-plr-models"]], "General Examples": [[39, "general-examples"]], "General algorithm": [[70, "general-algorithm"]], "Getting started": [[74, "getting-started"]], "Group Average Treatment Effects (GATEs)": [[48, "Group-Average-Treatment-Effects-(GATEs)"], [49, "Group-Average-Treatment-Effects-(GATEs)"]], "Group average treatment effects (GATEs)": [[64, "group-average-treatment-effects-gates"]], "Heterogeneous treatment effects": [[64, "heterogeneous-treatment-effects"]], "How to exploit more features of mlr3pipelines in DoubleML": [[37, "How-to-exploit-more-features-of-mlr3pipelines-in-DoubleML"]], "Hyperparameter tuning": [[65, "hyperparameter-tuning"], [65, "id16"]], "Hyperparameter tuning with pipelines": [[65, "hyperparameter-tuning-with-pipelines"]], "Implementation": [[70, "implementation"]], "Implementation of the double machine learning algorithms": [[60, "implementation-of-the-double-machine-learning-algorithms"]], "Implementation of the score function and the estimate of the causal parameter": [[68, "implementation-of-the-score-function-and-the-estimate-of-the-causal-parameter"]], "Implemented Neyman orthogonal score functions": [[68, "implemented-neyman-orthogonal-score-functions"]], "Initialize DoubleMLClusterData object": [[35, "Initialize-DoubleMLClusterData-object"], [52, "Initialize-DoubleMLClusterData-object"]], "Initialize the objects of class DoubleMLPLIV": [[35, "Initialize-the-objects-of-class-DoubleMLPLIV"], [52, "Initialize-the-objects-of-class-DoubleMLPLIV"]], "Installing DoubleML": [[73, "installing-doubleml"]], "Instrumental Variables Directed Acyclic Graph (IV - DAG)": [[32, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"], [40, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"]], "Interactive IV Model (IIVM)": [[36, "Interactive-IV-Model-(IIVM)"], [53, "Interactive-IV-Model-(IIVM)"]], "Interactive IV model (IIVM)": [[66, "interactive-iv-model-iivm"], [68, "interactive-iv-model-iivm"]], "Interactive Regression Model (IRM)": [[36, "Interactive-Regression-Model-(IRM)"], [48, "Interactive-Regression-Model-(IRM)"], [53, "Interactive-Regression-Model-(IRM)"], [56, "Interactive-Regression-Model-(IRM)"]], "Interactive regression model (IRM)": [[66, "interactive-regression-model-irm"], [68, "interactive-regression-model-irm"], [70, "interactive-regression-model-irm"]], "Learners to estimate the nuisance models": [[74, "learners-to-estimate-the-nuisance-models"]], "Learners, hyperparameters and hyperparameter tuning": [[65, "learners-hyperparameters-and-hyperparameter-tuning"]], "Load and Process Data": [[35, "Load-and-Process-Data"], [52, "Load-and-Process-Data"]], "Load bonus data using the dml datasets module": [[38, "Load-bonus-data-using-the-dml-datasets-module"]], "Local Average Treatment Effects of 401(k) Participation on Net Financial Assets": [[36, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"], [53, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"]], "Local Potential Quantile Estimation": [[57, "Local-Potential-Quantile-Estimation"]], "Local Potential Quantiles (LPQs)": [[57, "Local-Potential-Quantiles-(LPQs)"]], "Local Quantile Treatment Effects (LQTEs)": [[57, "Local-Quantile-Treatment-Effects-(LQTEs)"]], "Local potential quantiles (LPQs)": [[68, "local-potential-quantiles-lpqs"]], "Main Features": [[72, "main-features"]], "Minimum requirements for learners": [[65, "minimum-requirements-for-learners"], [65, "id2"]], "Missingness at Random": [[66, "missingness-at-random"], [68, "missingness-at-random"]], "Model-specific implementations": [[70, "model-specific-implementations"]], "Models": [[66, "models"]], "Motivation": [[35, "Motivation"], [52, "Motivation"]], "Multiplier bootstrap and joint confidence intervals": [[71, "multiplier-bootstrap-and-joint-confidence-intervals"]], "Naive estimation": [[32, "Naive-estimation"], [40, "Naive-estimation"]], "No Clustering / Zero-Way Clustering": [[35, "No-Clustering-/-Zero-Way-Clustering"], [52, "No-Clustering-/-Zero-Way-Clustering"]], "Nonignorable Nonresponse": [[66, "nonignorable-nonresponse"], [68, "nonignorable-nonresponse"]], "One-Way Clustering with Respect to the Market": [[35, "One-Way-Clustering-with-Respect-to-the-Market"], [52, "One-Way-Clustering-with-Respect-to-the-Market"]], "One-Way Clustering with Respect to the Product": [[35, "One-Way-Clustering-with-Respect-to-the-Product"], [52, "One-Way-Clustering-with-Respect-to-the-Product"]], "One-dimensional Example": [[42, "One-dimensional-Example"], [43, "One-dimensional-Example"]], "Outcome missing at random (MAR)": [[59, "Outcome-missing-at-random-(MAR)"]], "Outcome missing under nonignorable nonresponse": [[59, "Outcome-missing-under-nonignorable-nonresponse"]], "Overcoming regularization bias by orthogonalization": [[33, "Overcoming-regularization-bias-by-orthogonalization"], [41, "Overcoming-regularization-bias-by-orthogonalization"], [61, "overcoming-regularization-bias-by-orthogonalization"]], "Panel Data (Repeated Outcomes)": [[45, "Panel-Data-(Repeated-Outcomes)"]], "Panel data": [[66, "panel-data"]], "Parameter tuning": [[37, "Parameter-tuning"]], "Partialling out score": [[33, "Partialling-out-score"], [41, "Partialling-out-score"], [61, "partialling-out-score"]], "Partially Linear Regression Model (PLR)": [[36, "Partially-Linear-Regression-Model-(PLR)"], [49, "Partially-Linear-Regression-Model-(PLR)"], [53, "Partially-Linear-Regression-Model-(PLR)"]], "Partially linear IV regression model (PLIV)": [[66, "partially-linear-iv-regression-model-pliv"], [68, "partially-linear-iv-regression-model-pliv"]], "Partially linear regression model (PLR)": [[66, "partially-linear-regression-model-plr"], [68, "partially-linear-regression-model-plr"], [70, "partially-linear-regression-model-plr"]], "Policy Learning with Trees": [[56, "Policy-Learning-with-Trees"], [64, "policy-learning-with-trees"]], "Potential Quantile Estimation": [[57, "Potential-Quantile-Estimation"]], "Potential Quantiles (PQs)": [[57, "Potential-Quantiles-(PQs)"]], "Potential quantiles (PQs)": [[64, "potential-quantiles-pqs"], [68, "potential-quantiles-pqs"]], "Python: Basic Instrumental Variables calculation": [[40, "Python:-Basic-Instrumental-Variables-calculation"]], "Python: Basics of Double Machine Learning": [[41, "Python:-Basics-of-Double-Machine-Learning"]], "Python: Building the package from source": [[73, "python-building-the-package-from-source"]], "Python: Case studies": [[39, "python-case-studies"]], "Python: Choice of learners": [[51, "Python:-Choice-of-learners"]], "Python: Cluster Robust Double Machine Learning": [[52, "Python:-Cluster-Robust-Double-Machine-Learning"]], "Python: Conditional Average Treatment Effects (CATEs) for IRM models": [[42, "Python:-Conditional-Average-Treatment-Effects-(CATEs)-for-IRM-models"]], "Python: Conditional Average Treatment Effects (CATEs) for PLR models": [[43, "Python:-Conditional-Average-Treatment-Effects-(CATEs)-for-PLR-models"]], "Python: Conditional Value at Risk of potential outcomes": [[44, "Python:-Conditional-Value-at-Risk-of-potential-outcomes"]], "Python: Difference-in-Differences": [[45, "Python:-Difference-in-Differences"]], "Python: Difference-in-Differences Pre-Testing": [[46, "Python:-Difference-in-Differences-Pre-Testing"]], "Python: First Stage and Causal Estimation": [[47, "Python:-First-Stage-and-Causal-Estimation"]], "Python: GATE Sensitivity Analysis": [[50, "Python:-GATE-Sensitivity-Analysis"]], "Python: Group Average Treatment Effects (GATEs) for IRM models": [[48, "Python:-Group-Average-Treatment-Effects-(GATEs)-for-IRM-models"]], "Python: Group Average Treatment Effects (GATEs) for PLR models": [[49, "Python:-Group-Average-Treatment-Effects-(GATEs)-for-PLR-models"]], "Python: Impact of 401(k) on Financial Wealth": [[53, "Python:-Impact-of-401(k)-on-Financial-Wealth"]], "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)": [[54, "Python:-Impact-of-401(k)-on-Financial-Wealth-(Quantile-Effects)"]], "Python: Installing DoubleML": [[73, "python-installing-doubleml"]], "Python: Installing a released version from a .whl file": [[73, "python-installing-a-released-version-from-a-whl-file"]], "Python: Installing the latest release from pip or conda": [[73, "python-installing-the-latest-release-from-pip-or-conda"]], "Python: Learners and hyperparameters": [[65, "python-learners-and-hyperparameters"]], "Python: PLM and IRM for Multiple Treatments": [[55, "Python:-PLM-and-IRM-for-Multiple-Treatments"]], "Python: Policy Learning with Trees": [[56, "Python:-Policy-Learning-with-Trees"]], "Python: Potential Quantiles and Quantile Treatment Effects": [[57, "Python:-Potential-Quantiles-and-Quantile-Treatment-Effects"]], "Python: Sample Selection Models": [[59, "Python:-Sample-Selection-Models"]], "Python: Sensitivity Analysis": [[58, "Python:-Sensitivity-Analysis"]], "Quantile Treatment Effects (QTEs)": [[57, "Quantile-Treatment-Effects-(QTEs)"]], "Quantile treatment effects (QTEs)": [[64, "quantile-treatment-effects-qtes"]], "Quantiles": [[64, "quantiles"]], "R: Basic Instrumental Variables Calculation": [[32, "R:-Basic-Instrumental-Variables-Calculation"]], "R: Basics of Double Machine Learning": [[33, "R:-Basics-of-Double-Machine-Learning"]], "R: Case studies": [[39, "r-case-studies"]], "R: Cluster Robust Double Machine Learning": [[35, "R:-Cluster-Robust-Double-Machine-Learning"]], "R: DoubleML for Difference-in-Differences": [[34, "R:-DoubleML-for-Difference-in-Differences"]], "R: Ensemble Learners and More with mlr3pipelines": [[37, "R:-Ensemble-Learners-and-More-with-mlr3pipelines"]], "R: Impact of 401(k) on Financial Wealth": [[36, "R:-Impact-of-401(k)-on-Financial-Wealth"]], "R: Installing DoubleML": [[73, "r-installing-doubleml"]], "R: Installing the development version from GitHub": [[73, "r-installing-the-development-version-from-github"]], "R: Installing the latest release from CRAN": [[73, "r-installing-the-latest-release-from-cran"]], "R: Learners and hyperparameters": [[65, "r-learners-and-hyperparameters"]], "Ranking Treatment Effects under Treatment Propensity and Treatment Effect Heterogeneity": [[55, "Ranking-Treatment-Effects-under-Treatment-Propensity-and-Treatment-Effect-Heterogeneity"]], "Real-Data Application": [[35, "Real-Data-Application"], [52, "Real-Data-Application"]], "References": [[32, "References"], [35, "References"], [37, "References"], [40, "References"], [47, "References"], [52, "References"], [55, "References"], [61, "references"], [65, "references"], [67, "references"], [69, "references"], [71, "references"], [72, "references"], [74, "references"]], "Regularization Bias in Simple ML-Approaches": [[33, "Regularization-Bias-in-Simple-ML-Approaches"], [41, "Regularization-Bias-in-Simple-ML-Approaches"]], "Regularization bias in simple ML-approaches": [[61, "regularization-bias-in-simple-ml-approaches"]], "Release notes": [[76, "release-notes"]], "Repeated Cross-Sectional Data": [[45, "Repeated-Cross-Sectional-Data"]], "Repeated cross-fitting with K folds and M repetitions": [[67, "repeated-cross-fitting-with-k-folds-and-m-repetitions"]], "Repeated cross-sections": [[66, "repeated-cross-sections"]], "Sample Selection Models (SSM)": [[66, "sample-selection-models-ssm"]], "Sample splitting to remove bias induced by overfitting": [[33, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [41, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [61, "sample-splitting-to-remove-bias-induced-by-overfitting"]], "Sample-splitting without cross-fitting": [[67, "sample-splitting-without-cross-fitting"]], "Sample-splitting, cross-fitting and repeated cross-fitting": [[67, "sample-splitting-cross-fitting-and-repeated-cross-fitting"]], "Sandbox": [[39, "sandbox"]], "Score functions": [[68, "score-functions"]], "Score mixin classes for double machine learning models": [[0, "score-mixin-classes-for-double-machine-learning-models"]], "Sensitivity Analysis": [[58, "Sensitivity-Analysis"], [58, "id1"]], "Sensitivity Analysis with IRM": [[58, "Sensitivity-Analysis-with-IRM"]], "Sensitivity analysis": [[70, "sensitivity-analysis"]], "Set up learners based on mlr3pipelines": [[37, "Set-up-learners-based-on-mlr3pipelines"]], "Simulate two-way cluster data": [[35, "Simulate-two-way-cluster-data"], [52, "Simulate-two-way-cluster-data"]], "Simulation Example": [[58, "Simulation-Example"]], "Simultaneous inference over different DoubleML models (advanced)": [[69, "simultaneous-inference-over-different-doubleml-models-advanced"]], "Source code and maintenance": [[72, "source-code-and-maintenance"]], "Specify learner and estimate causal parameter: IRM model with Lasso as learner": [[38, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: IRM model with random forest as learner": [[38, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-random-forest-as-learner"]], "Specify learner and estimate causal parameter: PLR model with Lasso as learner": [[38, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: PLR model with random forest as learner": [[38, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-random-forest-as-learner"]], "Specifying alternative score functions via callables": [[68, "specifying-alternative-score-functions-via-callables"]], "Specifying learners and set hyperparameters": [[65, "specifying-learners-and-set-hyperparameters"], [65, "id9"]], "Standard approach": [[51, "Standard-approach"]], "Summary Figure": [[55, "Summary-Figure"]], "Summary of Results": [[36, "Summary-of-Results"], [53, "Summary-of-Results"]], "The Augmented Inverse Propensity Weighting Model estimates the ATE under arbitrary effect and propensity score heterogeneity": [[55, "The-Augmented-Inverse-Propensity-Weighting-Model-estimates-the-ATE-under-arbitrary-effect-and-propensity-score-heterogeneity"]], "The Data Backend: DoubleMLData": [[36, "The-Data-Backend:-DoubleMLData"], [53, "The-Data-Backend:-DoubleMLData"]], "The DoubleML package": [[36, "The-DoubleML-package"], [53, "The-DoubleML-package"]], "The Partially Linear Model performs overlap weighting": [[55, "The-Partially-Linear-Model-performs-overlap-weighting"]], "The basics of double/debiased machine learning": [[61, "the-basics-of-double-debiased-machine-learning"]], "The causal model": [[74, "the-causal-model"]], "The data-backend DoubleMLData": [[62, "the-data-backend-doublemldata"], [74, "the-data-backend-doublemldata"]], "Theory": [[70, "theory"]], "Two-Dimensional Example": [[42, "Two-Dimensional-Example"], [43, "Two-Dimensional-Example"]], "Two-Way Clustering with Respect to Product and Market": [[35, "Two-Way-Clustering-with-Respect-to-Product-and-Market"], [52, "Two-Way-Clustering-with-Respect-to-Product-and-Market"]], "Use ensemble learners based on mlr3pipelines": [[37, "Use-ensemble-learners-based-on-mlr3pipelines"]], "User guide": [[63, "user-guide"]], "Using DoubleML": [[32, "Using-DoubleML"], [40, "Using-DoubleML"]], "Using ML for DiD: Integrating DoubleML in did": [[34, "Using-ML-for-DiD:-Integrating-DoubleML-in-did"]], "Using learners from mlr3, mlr3learners and mlr3extralearners": [[37, "Using-learners-from-mlr3,-mlr3learners-and-mlr3extralearners"]], "Using pipelines to construct learners": [[65, "using-pipelines-to-construct-learners"]], "Utility classes": [[0, "utility-classes"]], "Utility classes and functions": [[0, "utility-classes-and-functions"]], "Utility functions": [[0, "utility-functions"]], "Variance estimation": [[69, "variance-estimation"]], "Variance estimation and confidence intervals": [[69, "variance-estimation-and-confidence-intervals"]], "Weighted Average Treatment Effects": [[64, "weighted-average-treatment-effects"]], "doubleml.DoubleMLBLP": [[1, "doubleml-doublemlblp"]], "doubleml.DoubleMLCVAR": [[2, "doubleml-doublemlcvar"]], "doubleml.DoubleMLClusterData": [[3, "doubleml-doublemlclusterdata"]], "doubleml.DoubleMLDID": [[4, "doubleml-doublemldid"]], "doubleml.DoubleMLDIDCS": [[5, "doubleml-doublemldidcs"]], "doubleml.DoubleMLData": [[6, "doubleml-doublemldata"]], "doubleml.DoubleMLIIVM": [[7, "doubleml-doublemliivm"]], "doubleml.DoubleMLIRM": [[8, "doubleml-doublemlirm"]], "doubleml.DoubleMLLPQ": [[9, "doubleml-doublemllpq"]], "doubleml.DoubleMLPLIV": [[10, "doubleml-doublemlpliv"]], "doubleml.DoubleMLPLR": [[11, "doubleml-doublemlplr"]], "doubleml.DoubleMLPQ": [[12, "doubleml-doublemlpq"]], "doubleml.DoubleMLQTE": [[13, "doubleml-doublemlqte"]], "doubleml.datasets.fetch_401K": [[14, "doubleml-datasets-fetch-401k"]], "doubleml.datasets.fetch_bonus": [[15, "doubleml-datasets-fetch-bonus"]], "doubleml.datasets.make_confounded_irm_data": [[16, "doubleml-datasets-make-confounded-irm-data"]], "doubleml.datasets.make_confounded_plr_data": [[17, "doubleml-datasets-make-confounded-plr-data"]], "doubleml.datasets.make_did_SZ2020": [[18, "doubleml-datasets-make-did-sz2020"]], "doubleml.datasets.make_heterogeneous_data": [[19, "doubleml-datasets-make-heterogeneous-data"]], "doubleml.datasets.make_iivm_data": [[20, "doubleml-datasets-make-iivm-data"]], "doubleml.datasets.make_irm_data": [[21, "doubleml-datasets-make-irm-data"]], "doubleml.datasets.make_pliv_CHS2015": [[22, "doubleml-datasets-make-pliv-chs2015"]], "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021": [[23, "doubleml-datasets-make-pliv-multiway-cluster-ckms2021"]], "doubleml.datasets.make_plr_CCDDHNR2018": [[24, "doubleml-datasets-make-plr-ccddhnr2018"]], "doubleml.datasets.make_plr_turrell2018": [[25, "doubleml-datasets-make-plr-turrell2018"]], "doubleml.datasets.make_ssm_data": [[26, "doubleml-datasets-make-ssm-data"]], "doubleml.double_ml_score_mixins.LinearScoreMixin": [[27, "doubleml-double-ml-score-mixins-linearscoremixin"]], "doubleml.double_ml_score_mixins.NonLinearScoreMixin": [[28, "doubleml-double-ml-score-mixins-nonlinearscoremixin"]], "doubleml.utils.DMLDummyClassifier": [[29, "doubleml-utils-dmldummyclassifier"]], "doubleml.utils.DMLDummyRegressor": [[30, "doubleml-utils-dmldummyregressor"]], "doubleml.utils.gain_statistics": [[31, "doubleml-utils-gain-statistics"]]}, "docnames": ["api/api", "api/generated/doubleml.DoubleMLBLP", "api/generated/doubleml.DoubleMLCVAR", "api/generated/doubleml.DoubleMLClusterData", "api/generated/doubleml.DoubleMLDID", "api/generated/doubleml.DoubleMLDIDCS", "api/generated/doubleml.DoubleMLData", "api/generated/doubleml.DoubleMLIIVM", "api/generated/doubleml.DoubleMLIRM", "api/generated/doubleml.DoubleMLLPQ", "api/generated/doubleml.DoubleMLPLIV", "api/generated/doubleml.DoubleMLPLR", "api/generated/doubleml.DoubleMLPQ", "api/generated/doubleml.DoubleMLQTE", "api/generated/doubleml.datasets.fetch_401K", "api/generated/doubleml.datasets.fetch_bonus", "api/generated/doubleml.datasets.make_confounded_irm_data", "api/generated/doubleml.datasets.make_confounded_plr_data", "api/generated/doubleml.datasets.make_did_SZ2020", "api/generated/doubleml.datasets.make_heterogeneous_data", "api/generated/doubleml.datasets.make_iivm_data", "api/generated/doubleml.datasets.make_irm_data", "api/generated/doubleml.datasets.make_pliv_CHS2015", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018", "api/generated/doubleml.datasets.make_plr_turrell2018", "api/generated/doubleml.datasets.make_ssm_data", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin", "api/generated/doubleml.utils.DMLDummyClassifier", "api/generated/doubleml.utils.DMLDummyRegressor", "api/generated/doubleml.utils.gain_statistics", "examples/R_double_ml_basic_iv", "examples/R_double_ml_basics", "examples/R_double_ml_did", "examples/R_double_ml_multiway_cluster", "examples/R_double_ml_pension", "examples/R_double_ml_pipeline", "examples/double_ml_bonus_data", "examples/index", "examples/py_double_ml_basic_iv", "examples/py_double_ml_basics", "examples/py_double_ml_cate", "examples/py_double_ml_cate_plr", "examples/py_double_ml_cvar", "examples/py_double_ml_did", "examples/py_double_ml_did_pretest", "examples/py_double_ml_firststage", "examples/py_double_ml_gate", "examples/py_double_ml_gate_plr", "examples/py_double_ml_gate_sensitivity", "examples/py_double_ml_learner", "examples/py_double_ml_multiway_cluster", "examples/py_double_ml_pension", "examples/py_double_ml_pension_qte", "examples/py_double_ml_plm_irm_hetfx", "examples/py_double_ml_policy_tree", "examples/py_double_ml_pq", "examples/py_double_ml_sensitivity", "examples/py_double_ml_ssm", "guide/algorithms", "guide/basics", "guide/data_backend", "guide/guide", "guide/heterogeneity", "guide/learners", "guide/models", "guide/resampling", "guide/scores", "guide/se_confint", "guide/sensitivity", "guide/sim_inf", "index", "intro/install", "intro/intro", "literature/literature", "release/release", "workflow/workflow"], "envversion": {"nbsphinx": 4, "sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["api/api.rst", "api/generated/doubleml.DoubleMLBLP.rst", "api/generated/doubleml.DoubleMLCVAR.rst", "api/generated/doubleml.DoubleMLClusterData.rst", "api/generated/doubleml.DoubleMLDID.rst", "api/generated/doubleml.DoubleMLDIDCS.rst", "api/generated/doubleml.DoubleMLData.rst", "api/generated/doubleml.DoubleMLIIVM.rst", "api/generated/doubleml.DoubleMLIRM.rst", "api/generated/doubleml.DoubleMLLPQ.rst", "api/generated/doubleml.DoubleMLPLIV.rst", "api/generated/doubleml.DoubleMLPLR.rst", "api/generated/doubleml.DoubleMLPQ.rst", "api/generated/doubleml.DoubleMLQTE.rst", "api/generated/doubleml.datasets.fetch_401K.rst", "api/generated/doubleml.datasets.fetch_bonus.rst", "api/generated/doubleml.datasets.make_confounded_irm_data.rst", "api/generated/doubleml.datasets.make_confounded_plr_data.rst", "api/generated/doubleml.datasets.make_did_SZ2020.rst", "api/generated/doubleml.datasets.make_heterogeneous_data.rst", "api/generated/doubleml.datasets.make_iivm_data.rst", "api/generated/doubleml.datasets.make_irm_data.rst", "api/generated/doubleml.datasets.make_pliv_CHS2015.rst", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021.rst", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018.rst", "api/generated/doubleml.datasets.make_plr_turrell2018.rst", "api/generated/doubleml.datasets.make_ssm_data.rst", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin.rst", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin.rst", "api/generated/doubleml.utils.DMLDummyClassifier.rst", "api/generated/doubleml.utils.DMLDummyRegressor.rst", "api/generated/doubleml.utils.gain_statistics.rst", "examples/R_double_ml_basic_iv.ipynb", "examples/R_double_ml_basics.ipynb", "examples/R_double_ml_did.ipynb", "examples/R_double_ml_multiway_cluster.ipynb", "examples/R_double_ml_pension.ipynb", "examples/R_double_ml_pipeline.ipynb", "examples/double_ml_bonus_data.ipynb", "examples/index.rst", "examples/py_double_ml_basic_iv.ipynb", "examples/py_double_ml_basics.ipynb", "examples/py_double_ml_cate.ipynb", "examples/py_double_ml_cate_plr.ipynb", "examples/py_double_ml_cvar.ipynb", "examples/py_double_ml_did.ipynb", "examples/py_double_ml_did_pretest.ipynb", "examples/py_double_ml_firststage.ipynb", "examples/py_double_ml_gate.ipynb", "examples/py_double_ml_gate_plr.ipynb", "examples/py_double_ml_gate_sensitivity.ipynb", "examples/py_double_ml_learner.ipynb", "examples/py_double_ml_multiway_cluster.ipynb", "examples/py_double_ml_pension.ipynb", "examples/py_double_ml_pension_qte.ipynb", "examples/py_double_ml_plm_irm_hetfx.ipynb", "examples/py_double_ml_policy_tree.ipynb", "examples/py_double_ml_pq.ipynb", "examples/py_double_ml_sensitivity.ipynb", "examples/py_double_ml_ssm.ipynb", "guide/algorithms.rst", "guide/basics.rst", "guide/data_backend.rst", "guide/guide.rst", "guide/heterogeneity.rst", "guide/learners.rst", "guide/models.rst", "guide/resampling.rst", "guide/scores.rst", "guide/se_confint.rst", "guide/sensitivity.rst", "guide/sim_inf.rst", "index.rst", "intro/install.rst", "intro/intro.rst", "literature/literature.rst", "release/release.rst", "workflow/workflow.rst"], "indexentries": {"bootstrap() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.bootstrap", false]], "bootstrap() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.bootstrap", false]], "bootstrap() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.bootstrap", false]], "bootstrap() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.bootstrap", false]], "bootstrap() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.bootstrap", false]], "bootstrap() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.bootstrap", false]], "bootstrap() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.bootstrap", false]], "bootstrap() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.bootstrap", false]], "bootstrap() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.bootstrap", false]], "bootstrap() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.bootstrap", false]], "cate() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.cate", false]], "cate() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.cate", false]], "confint() (doubleml.doublemlblp method)": [[1, "doubleml.DoubleMLBLP.confint", false]], "confint() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.confint", false]], "confint() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.confint", false]], "confint() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.confint", false]], "confint() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.confint", false]], "confint() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.confint", false]], "confint() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.confint", false]], "confint() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.confint", false]], "confint() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.confint", false]], "confint() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.confint", false]], "confint() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.confint", false]], "construct_framework() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.construct_framework", false]], "construct_framework() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.construct_framework", false]], "construct_framework() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.construct_framework", false]], "construct_framework() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.construct_framework", false]], "construct_framework() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.construct_framework", false]], "construct_framework() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.construct_framework", false]], "construct_framework() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.construct_framework", false]], "construct_framework() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.construct_framework", false]], "construct_framework() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.construct_framework", false]], "dmldummyclassifier (class in doubleml.utils)": [[29, "doubleml.utils.DMLDummyClassifier", false]], "dmldummyregressor (class in doubleml.utils)": [[30, "doubleml.utils.DMLDummyRegressor", false]], "doublemlblp (class in doubleml)": [[1, "doubleml.DoubleMLBLP", false]], "doublemlclusterdata (class in doubleml)": [[3, "doubleml.DoubleMLClusterData", false]], "doublemlcvar (class in doubleml)": [[2, "doubleml.DoubleMLCVAR", false]], "doublemldata (class in doubleml)": [[6, "doubleml.DoubleMLData", false]], "doublemldid (class in doubleml)": [[4, "doubleml.DoubleMLDID", false]], "doublemldidcs (class in doubleml)": [[5, "doubleml.DoubleMLDIDCS", false]], "doublemliivm (class in doubleml)": [[7, "doubleml.DoubleMLIIVM", false]], "doublemlirm (class in doubleml)": [[8, "doubleml.DoubleMLIRM", false]], "doublemllpq (class in doubleml)": [[9, "doubleml.DoubleMLLPQ", false]], "doublemlpliv (class in doubleml)": [[10, "doubleml.DoubleMLPLIV", false]], "doublemlplr (class in doubleml)": [[11, "doubleml.DoubleMLPLR", false]], "doublemlpq (class in doubleml)": [[12, "doubleml.DoubleMLPQ", false]], "doublemlqte (class in doubleml)": [[13, "doubleml.DoubleMLQTE", false]], "draw_sample_splitting() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.draw_sample_splitting", false]], "evaluate_learners() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.evaluate_learners", false]], "fetch_401k() (in module doubleml.datasets)": [[14, "doubleml.datasets.fetch_401K", false]], "fetch_bonus() (in module doubleml.datasets)": [[15, "doubleml.datasets.fetch_bonus", false]], "fit() (doubleml.doublemlblp method)": [[1, "doubleml.DoubleMLBLP.fit", false]], "fit() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.fit", false]], "fit() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.fit", false]], "fit() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.fit", false]], "fit() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.fit", false]], "fit() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.fit", false]], "fit() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.fit", false]], "fit() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.fit", false]], "fit() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.fit", false]], "fit() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.fit", false]], "fit() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.fit", false]], "fit() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.fit", false]], "fit() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.fit", false]], "from_arrays() (doubleml.doublemlclusterdata class method)": [[3, "doubleml.DoubleMLClusterData.from_arrays", false]], "from_arrays() (doubleml.doublemldata class method)": [[6, "doubleml.DoubleMLData.from_arrays", false]], "gain_statistics() (in module doubleml.utils)": [[31, "doubleml.utils.gain_statistics", false]], "gate() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.gate", false]], "gate() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.gate", false]], "get_metadata_routing() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.get_metadata_routing", false]], "get_metadata_routing() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.get_metadata_routing", false]], "get_params() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.get_params", false]], "get_params() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.get_params", false]], "get_params() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.get_params", false]], "get_params() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.get_params", false]], "get_params() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.get_params", false]], "get_params() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.get_params", false]], "get_params() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.get_params", false]], "get_params() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.get_params", false]], "get_params() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.get_params", false]], "get_params() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.get_params", false]], "get_params() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.get_params", false]], "linearscoremixin (class in doubleml.double_ml_score_mixins)": [[27, "doubleml.double_ml_score_mixins.LinearScoreMixin", false]], "make_confounded_irm_data() (in module doubleml.datasets)": [[16, "doubleml.datasets.make_confounded_irm_data", false]], "make_confounded_plr_data() (in module doubleml.datasets)": [[17, "doubleml.datasets.make_confounded_plr_data", false]], "make_did_sz2020() (in module doubleml.datasets)": [[18, "doubleml.datasets.make_did_SZ2020", false]], "make_heterogeneous_data() (in module doubleml.datasets)": [[19, "doubleml.datasets.make_heterogeneous_data", false]], "make_iivm_data() (in module doubleml.datasets)": [[20, "doubleml.datasets.make_iivm_data", false]], "make_irm_data() (in module doubleml.datasets)": [[21, "doubleml.datasets.make_irm_data", false]], "make_pliv_chs2015() (in module doubleml.datasets)": [[22, "doubleml.datasets.make_pliv_CHS2015", false]], "make_pliv_multiway_cluster_ckms2021() (in module doubleml.datasets)": [[23, "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", false]], "make_plr_ccddhnr2018() (in module doubleml.datasets)": [[24, "doubleml.datasets.make_plr_CCDDHNR2018", false]], "make_plr_turrell2018() (in module doubleml.datasets)": [[25, "doubleml.datasets.make_plr_turrell2018", false]], "make_ssm_data() (in module doubleml.datasets)": [[26, "doubleml.datasets.make_ssm_data", false]], "nonlinearscoremixin (class in doubleml.double_ml_score_mixins)": [[28, "doubleml.double_ml_score_mixins.NonLinearScoreMixin", false]], "p_adjust() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.p_adjust", false]], "p_adjust() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.p_adjust", false]], "p_adjust() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.p_adjust", false]], "p_adjust() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.p_adjust", false]], "p_adjust() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.p_adjust", false]], "p_adjust() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.p_adjust", false]], "p_adjust() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.p_adjust", false]], "p_adjust() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.p_adjust", false]], "p_adjust() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.p_adjust", false]], "p_adjust() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.p_adjust", false]], "policy_tree() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.policy_tree", false]], "predict() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.predict", false]], "predict() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.predict", false]], "predict_proba() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.predict_proba", false]], "sensitivity_analysis() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.sensitivity_analysis", false]], "sensitivity_benchmark() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.sensitivity_benchmark", false]], "sensitivity_plot() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.sensitivity_plot", false]], "set_ml_nuisance_params() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.set_ml_nuisance_params", false]], "set_params() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.set_params", false]], "set_params() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.set_params", false]], "set_sample_splitting() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.set_sample_splitting", false]], "set_x_d() (doubleml.doublemlclusterdata method)": [[3, "doubleml.DoubleMLClusterData.set_x_d", false]], "set_x_d() (doubleml.doublemldata method)": [[6, "doubleml.DoubleMLData.set_x_d", false]], "tune() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.tune", false]], "tune() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.tune", false]], "tune() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.tune", false]], "tune() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.tune", false]], "tune() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.tune", false]], "tune() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.tune", false]], "tune() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.tune", false]], "tune() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.tune", false]], "tune() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.tune", false]]}, "objects": {"doubleml": [[1, 0, 1, "", "DoubleMLBLP"], [2, 0, 1, "", "DoubleMLCVAR"], [3, 0, 1, "", "DoubleMLClusterData"], [4, 0, 1, "", "DoubleMLDID"], [5, 0, 1, "", "DoubleMLDIDCS"], [6, 0, 1, "", "DoubleMLData"], [7, 0, 1, "", "DoubleMLIIVM"], [8, 0, 1, "", "DoubleMLIRM"], [9, 0, 1, "", "DoubleMLLPQ"], [10, 0, 1, "", "DoubleMLPLIV"], [11, 0, 1, "", "DoubleMLPLR"], [12, 0, 1, "", "DoubleMLPQ"], [13, 0, 1, "", "DoubleMLQTE"]], "doubleml.DoubleMLBLP": [[1, 1, 1, "", "confint"], [1, 1, 1, "", "fit"]], "doubleml.DoubleMLCVAR": [[2, 1, 1, "", "bootstrap"], [2, 1, 1, "", "confint"], [2, 1, 1, "", "construct_framework"], [2, 1, 1, "", "draw_sample_splitting"], [2, 1, 1, "", "evaluate_learners"], [2, 1, 1, "", "fit"], [2, 1, 1, "", "get_params"], [2, 1, 1, "", "p_adjust"], [2, 1, 1, "", "sensitivity_analysis"], [2, 1, 1, "", "sensitivity_benchmark"], [2, 1, 1, "", "sensitivity_plot"], [2, 1, 1, "", "set_ml_nuisance_params"], [2, 1, 1, "", "set_sample_splitting"], [2, 1, 1, "", "tune"]], "doubleml.DoubleMLClusterData": [[3, 1, 1, "", "from_arrays"], [3, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLDID": [[4, 1, 1, "", "bootstrap"], [4, 1, 1, "", "confint"], [4, 1, 1, "", "construct_framework"], [4, 1, 1, "", "draw_sample_splitting"], [4, 1, 1, "", "evaluate_learners"], [4, 1, 1, "", "fit"], [4, 1, 1, "", "get_params"], [4, 1, 1, "", "p_adjust"], [4, 1, 1, "", "sensitivity_analysis"], [4, 1, 1, "", "sensitivity_benchmark"], [4, 1, 1, "", "sensitivity_plot"], [4, 1, 1, "", "set_ml_nuisance_params"], [4, 1, 1, "", "set_sample_splitting"], [4, 1, 1, "", "tune"]], "doubleml.DoubleMLDIDCS": [[5, 1, 1, "", "bootstrap"], [5, 1, 1, "", "confint"], [5, 1, 1, "", "construct_framework"], [5, 1, 1, "", "draw_sample_splitting"], [5, 1, 1, "", "evaluate_learners"], [5, 1, 1, "", "fit"], [5, 1, 1, "", "get_params"], [5, 1, 1, "", "p_adjust"], [5, 1, 1, "", "sensitivity_analysis"], [5, 1, 1, "", "sensitivity_benchmark"], [5, 1, 1, "", "sensitivity_plot"], [5, 1, 1, "", "set_ml_nuisance_params"], [5, 1, 1, "", "set_sample_splitting"], [5, 1, 1, "", "tune"]], "doubleml.DoubleMLData": [[6, 1, 1, "", "from_arrays"], [6, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLIIVM": [[7, 1, 1, "", "bootstrap"], [7, 1, 1, "", "confint"], [7, 1, 1, "", "construct_framework"], [7, 1, 1, "", "draw_sample_splitting"], [7, 1, 1, "", "evaluate_learners"], [7, 1, 1, "", "fit"], [7, 1, 1, "", "get_params"], [7, 1, 1, "", "p_adjust"], [7, 1, 1, "", "sensitivity_analysis"], [7, 1, 1, "", "sensitivity_benchmark"], [7, 1, 1, "", "sensitivity_plot"], [7, 1, 1, "", "set_ml_nuisance_params"], [7, 1, 1, "", "set_sample_splitting"], [7, 1, 1, "", "tune"]], "doubleml.DoubleMLIRM": [[8, 1, 1, "", "bootstrap"], [8, 1, 1, "", "cate"], [8, 1, 1, "", "confint"], [8, 1, 1, "", "construct_framework"], [8, 1, 1, "", "draw_sample_splitting"], [8, 1, 1, "", "evaluate_learners"], [8, 1, 1, "", "fit"], [8, 1, 1, "", "gate"], [8, 1, 1, "", "get_params"], [8, 1, 1, "", "p_adjust"], [8, 1, 1, "", "policy_tree"], [8, 1, 1, "", "sensitivity_analysis"], [8, 1, 1, "", "sensitivity_benchmark"], [8, 1, 1, "", "sensitivity_plot"], [8, 1, 1, "", "set_ml_nuisance_params"], [8, 1, 1, "", "set_sample_splitting"], [8, 1, 1, "", "tune"]], "doubleml.DoubleMLLPQ": [[9, 1, 1, "", "bootstrap"], [9, 1, 1, "", "confint"], [9, 1, 1, "", "construct_framework"], [9, 1, 1, "", "draw_sample_splitting"], [9, 1, 1, "", "evaluate_learners"], [9, 1, 1, "", "fit"], [9, 1, 1, "", "get_params"], [9, 1, 1, "", "p_adjust"], [9, 1, 1, "", "sensitivity_analysis"], [9, 1, 1, "", "sensitivity_benchmark"], [9, 1, 1, "", "sensitivity_plot"], [9, 1, 1, "", "set_ml_nuisance_params"], [9, 1, 1, "", "set_sample_splitting"], [9, 1, 1, "", "tune"]], "doubleml.DoubleMLPLIV": [[10, 1, 1, "", "bootstrap"], [10, 1, 1, "", "confint"], [10, 1, 1, "", "construct_framework"], [10, 1, 1, "", "draw_sample_splitting"], [10, 1, 1, "", "evaluate_learners"], [10, 1, 1, "", "fit"], [10, 1, 1, "", "get_params"], [10, 1, 1, "", "p_adjust"], [10, 1, 1, "", "sensitivity_analysis"], [10, 1, 1, "", "sensitivity_benchmark"], [10, 1, 1, "", "sensitivity_plot"], [10, 1, 1, "", "set_ml_nuisance_params"], [10, 1, 1, "", "set_sample_splitting"], [10, 1, 1, "", "tune"]], "doubleml.DoubleMLPLR": [[11, 1, 1, "", "bootstrap"], [11, 1, 1, "", "cate"], [11, 1, 1, "", "confint"], [11, 1, 1, "", "construct_framework"], [11, 1, 1, "", "draw_sample_splitting"], [11, 1, 1, "", "evaluate_learners"], [11, 1, 1, "", "fit"], [11, 1, 1, "", "gate"], [11, 1, 1, "", "get_params"], [11, 1, 1, "", "p_adjust"], [11, 1, 1, "", "sensitivity_analysis"], [11, 1, 1, "", "sensitivity_benchmark"], [11, 1, 1, "", "sensitivity_plot"], [11, 1, 1, "", "set_ml_nuisance_params"], [11, 1, 1, "", "set_sample_splitting"], [11, 1, 1, "", "tune"]], "doubleml.DoubleMLPQ": [[12, 1, 1, "", "bootstrap"], [12, 1, 1, "", "confint"], [12, 1, 1, "", "construct_framework"], [12, 1, 1, "", "draw_sample_splitting"], [12, 1, 1, "", "evaluate_learners"], [12, 1, 1, "", "fit"], [12, 1, 1, "", "get_params"], [12, 1, 1, "", "p_adjust"], [12, 1, 1, "", "sensitivity_analysis"], [12, 1, 1, "", "sensitivity_benchmark"], [12, 1, 1, "", "sensitivity_plot"], [12, 1, 1, "", "set_ml_nuisance_params"], [12, 1, 1, "", "set_sample_splitting"], [12, 1, 1, "", "tune"]], "doubleml.DoubleMLQTE": [[13, 1, 1, "", "bootstrap"], [13, 1, 1, "", "confint"], [13, 1, 1, "", "draw_sample_splitting"], [13, 1, 1, "", "fit"], [13, 1, 1, "", "p_adjust"]], "doubleml.datasets": [[14, 2, 1, "", "fetch_401K"], [15, 2, 1, "", "fetch_bonus"], [16, 2, 1, "", "make_confounded_irm_data"], [17, 2, 1, "", "make_confounded_plr_data"], [18, 2, 1, "", "make_did_SZ2020"], [19, 2, 1, "", "make_heterogeneous_data"], [20, 2, 1, "", "make_iivm_data"], [21, 2, 1, "", "make_irm_data"], [22, 2, 1, "", "make_pliv_CHS2015"], [23, 2, 1, "", "make_pliv_multiway_cluster_CKMS2021"], [24, 2, 1, "", "make_plr_CCDDHNR2018"], [25, 2, 1, "", "make_plr_turrell2018"], [26, 2, 1, "", "make_ssm_data"]], "doubleml.double_ml_score_mixins": [[27, 0, 1, "", "LinearScoreMixin"], [28, 0, 1, "", "NonLinearScoreMixin"]], "doubleml.utils": [[29, 0, 1, "", "DMLDummyClassifier"], [30, 0, 1, "", "DMLDummyRegressor"], [31, 2, 1, "", "gain_statistics"]], "doubleml.utils.DMLDummyClassifier": [[29, 1, 1, "", "fit"], [29, 1, 1, "", "get_metadata_routing"], [29, 1, 1, "", "get_params"], [29, 1, 1, "", "predict"], [29, 1, 1, "", "predict_proba"], [29, 1, 1, "", "set_params"]], "doubleml.utils.DMLDummyRegressor": [[30, 1, 1, "", "fit"], [30, 1, 1, "", "get_metadata_routing"], [30, 1, 1, "", "get_params"], [30, 1, 1, "", "predict"], [30, 1, 1, "", "set_params"]]}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function"}, "terms": {"": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 20, 21, 22, 23, 24, 25, 26, 32, 34, 35, 36, 37, 38, 45, 48, 49, 50, 52, 53, 54, 58, 59, 60, 62, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77], "0": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76], "00": [53, 54, 55, 67], "000": [69, 71, 77], "000000": [38, 53, 54, 62, 64, 74], "0000000": [69, 71], "0000000000000010000100": [37, 62, 74], "000000e": [53, 54], "00000591": 57, "000006": 57, "000017": 57, "000025": 52, "000034": 53, "000039": 52, "000064": 40, "000067": 52, "000091": [52, 64], "0001": [38, 53], "000219": [12, 64], "000242": [13, 64], "000341": 52, "000442": 52, "00047580260495": 32, "000488": 52, "000494": 50, "0005": 38, "000522": 52, "0005a80b528f": 37, "0006060991": 67, "000670": 52, "000743": 58, "000784623154372457": 60, "0007846231543724570": 60, "0007846232": 60, "000915799": [69, 71], "0009157990": [69, 71], "000943": [42, 43], "0009695237": 68, "001": [32, 34, 35, 36, 37, 41, 65, 66, 67, 68, 69, 74, 77], "001051": 52, "001234": 54, "00133": 37, "00138944": [60, 68], "00141": 66, "0016": [36, 53], "001714": 64, "0018": [36, 53], "0019": 38, "002110": 43, "002169338": [69, 71], "0021693380": [69, 71], "0021693381": [69, 71], "002290": 46, "0023": 34, "002436": 50, "0026": 38, "002779": 58, "0028": [34, 36, 53], "002983": 52, "003": [16, 17, 18, 55], "003134": 57, "003328": 57, "0034": 47, "003427": 52, "003779": 50, "003836": 57, "003965": 42, "00409412": [60, 68], "0042": [36, 53], "004392": 50, "004645": 43, "004688": 7, "0047": [36, 53], "005339": [42, 43], "005857": 52, "006066": 42, "006338": 55, "006425": 54, "006922": 38, "006958": [42, 43], "007210e": 54, "00728": 74, "0073": 38, "007332": 44, "007332393760465": 44, "007659": 64, "00778625": 67, "007909": 42, "008023": 54, "008223": [42, 43], "008266e": 54, "008487": 38, "008642": 64, "008855679": 67, "008dbd": 55, "008e80": 55, "009": 55, "0090193584": 68, "00902031947837708": 60, "0090203195": 60, "009122": 57, "009428": 44, "009645422": 35, "009656": 57, "00972": 38, "009790": 54, "009904": 64, "009986": 57, "01": [2, 4, 5, 7, 8, 9, 12, 13, 32, 35, 36, 37, 42, 43, 53, 54, 55, 56, 57, 65, 66, 67, 68, 69, 74, 77], "010092": 55, "010128": 55, "010213": 58, "010269": 52, "010450": 35, "010940": 52, "011131": 57, "0112": 34, "01128": 38, "011511": 43, "011598": 57, "0118095": 35, "011823": 58, "011862": 55, "011988e": 57, "01219": 37, "012390518": 67, "012780": 54, "013": 67, "013469": 42, "013515": 55, "01351638": 35, "013593": 58, "013617": 54, "01398951": 35, "013990": [69, 71], "01403089": 35, "014080": [42, 43], "014432": 46, "014637": 52, "014681": 58, "015": [37, 55], "015035": 42, "015038": 44, "015548": 43, "015565": 57, "015698": 57, "01574297": 57, "015743": 57, "015831": 42, "016011": 43, "016154": 52, "016200": [42, 43], "016315": 48, "016429": 64, "01643": 75, "01667882": 67, "017": [37, 55], "017800092": [69, 71], "0178000920": [69, 71], "017805": 42, "018": 37, "018023": 56, "018099": 42, "018148": 57, "018508": 42, "019008": 43, "01903": [37, 65, 72, 74], "01916030e": 67, "01925597": 35, "019439633": [69, 71], "0194396330": [69, 71], "0194396331": [69, 71], "019596": 44, "019660": [13, 64], "01990373": 59, "019953": 42, "019974": 54, "02": [42, 43, 51, 53, 54, 57, 64, 67], "020": [55, 77], "02016117": 74, "020166": 57, "020271": 52, "020360838": [69, 71], "0203608380": [69, 71], "0203608381": [69, 71], "020387": 43, "0204887": 67, "02052929": [60, 68], "02079162e": 67, "020819": 64, "02092": 74, "021013": 42, "021269": [48, 49], "02163217": 35, "021866": 56, "021926": 44, "02247976": 35, "022768": 38, "022783": 58, "022915": 52, "022954": 64, "022969": 54, "022991": 43, "023020e": [53, 54], "023160": 42, "02322693": 67, "023256": 57, "023505": 42, "023563": [69, 71], "023955": 54, "024355": 46, "024364": 70, "024401": [48, 49], "024604": 52, "024782": 57, "024926": 46, "025": [42, 43, 48, 49, 55], "025077": [69, 71], "0253": 37, "025443": 38, "0257": 34, "025708e": 43, "025783e": 43, "025813114": [69, 71], "0258131140": [69, 71], "02584": 37, "025958": 64, "02649578": 51, "026518e": 42, "02661753": 67, "026669": 54, "026723": 44, "027": 55, "027329": 42, "0274093": 67, "02756055": 67, "02791": 38, "028001": 43, "0281": 37, "028520": [42, 43], "02897287": 45, "02900983": 57, "029010": 57, "029022": 43, "029209": 77, "029364": 70, "029831": 57, "029910e": [53, 54], "02e": 36, "03": [2, 4, 5, 7, 8, 9, 10, 11, 12, 42, 43, 44, 50, 53, 54, 57, 58, 67, 70, 77], "030087": 64, "0301": 37, "03018": [9, 64], "030346": 74, "0307": 37, "030934": 57, "030962": 57, "031": 55, "03113": 59, "031134": 65, "031156": 43, "031269": 38, "03155725": 67, "031639": 57, "031820": 43, "03191": 75, "03220": 76, "0323": 34, "03244552": 65, "0325": 74, "032525": 55, "032953": 58, "033224": 42, "03347253": 67, "033737": 43, "033756": 44, "033946": [48, 49], "034097": 42, "03411": 74, "03414913": 67, "034226": 54, "034485891": 67, "034690": 44, "034812763": [69, 71], "0348127630": [69, 71], "0348127631": [69, 71], "034836": 53, "03489": [23, 35, 52], "035088": 43, "035119185": [69, 71], "0351191850": [69, 71], "0351191851": [69, 71], "035264": 43, "03536": 74, "03538": 37, "03539": 37, "035391": 38, "0354": 37, "035411": 74, "035441": 43, "03545": 37, "035545": 38, "035572": 38, "035730": 57, "03574": 38, "035762": 57, "0359": 37, "036": 67, "036129015": [69, 71], "0361290150": [69, 71], "0361290151": [69, 71], "036143": 57, "036147": 57, "036729": 52, "0368": 34, "036874e": 43, "036945": 54, "03698487": 57, "036985": 57, "037": 55, "037008": [48, 49], "0374": 37, "037509": 59, "037747": [42, 43], "038845": 42, "039036": 42, "03917696": [68, 69], "03920960e": 67, "039310e": 44, "039660": 42, "039897": 43, "04": [16, 17, 36, 42, 43, 53, 54, 57, 58, 67, 77], "040112": [69, 71], "040139": [42, 43], "040141": 43, "040445": 42, "040533": [68, 69], "04053339": 69, "040688": 42, "0408": 42, "040912": 43, "040919": 43, "04107": 11, "041112": 43, "041147": 44, "041151": 55, "041284": 44, "041387": 44, "041459": 54, "041491e": 44, "04166": 66, "0418": 34, "041831": 44, "041925": 42, "042249": 43, "042265": 44, "042266": 42, "0425": 65, "0428": 59, "042822e": 54, "042844e": 57, "043108": 54, "0433": 34, "0434e374": 37, "043998": 43, "044": 55, "044062": 43, "044113": 44, "04415": [37, 65], "04424": 37, "044334": 42, "04444978": [69, 71], "044449780": [69, 71], "04458": 65, "04465": 35, "044704": 43, "04486": 74, "04487585": 70, "04491": 66, "04497975": 70, "04512": [68, 69], "04512331": 69, "045144": 52, "04532": 65, "045379": 74, "04552": 52, "045553": 44, "04559": 65, "045624": 46, "045754": 57, "0459": 65, "045932": 57, "045993": 65, "046": 55, "04623464": 67, "04631": 65, "046405": 64, "04648933": 67, "046527": 44, "04653976": 57, "046540": 57, "0466028": 35, "046728": 58, "046757": 43, "04682310e": 67, "046922": 65, "047156": 42, "047194": 7, "047215": 43, "047375e": 42, "047954": 52, "048308": 49, "048326": 43, "048699": 59, "048723": 65, "049": 55, "04973": 43, "049959": 42, "05": [32, 34, 35, 36, 37, 42, 43, 44, 47, 52, 53, 54, 55, 57, 65, 66, 67, 68, 69, 74, 77], "05039": 58, "050399": 43, "050538": 43, "050843": 43, "050856": [64, 65, 66], "051": 37, "051578e": 43, "051867e": 44, "052000e": 54, "052298": 57, "052380": 42, "052488": 49, "052502": 57, "052745": 44, "053": 37, "0533": 34, "053331": 44, "053342": 54, "053389": [69, 71], "053436": 8, "053541": 57, "053558": 44, "054": 37, "054068": 52, "054162": 52, "054348": 69, "054370": 44, "054529": [69, 71], "054771e": 57, "055078": 42, "055165": 58, "055171": 43, "055338e": 53, "055439": 54, "055680": [69, 71], "056052": 42, "056389": 43, "056499": 49, "05671447": 67, "056745": 42, "056953": 42, "057": 55, "057095": 57, "05716383": 67, "05741": 55, "0576": [36, 53], "057762": 57, "057962": 44, "058042": [69, 71], "058276": 54, "058463": 57, "058508": 59, "0590": 34, "059187": 43, "059384": 57, "059627": 54, "059630": 46, "059685": 57, "06": [16, 17, 18, 42, 43, 44, 53, 54, 57, 64, 68, 69], "06008533": 66, "060201": 57, "060212": [53, 54], "060417": 42, "06046108": 51, "060845": [69, 71], "0611": 34, "06111111": 37, "0615": 34, "0617": 34, "061832508": 67, "0620": 34, "062414": 54, "06245673": 67, "062507": 57, "062964": [69, 71], "063": 32, "0635": 34, "063618": 43, "063700": 42, "063881": 66, "064161": 54, "06428": 53, "064280": 53, "0643": 34, "064400": 42, "0646222": 36, "06464": 69, "0646580": 67, "0649": 34, "065128": 42, "0652": 34, "0653": 34, "065356": [48, 49], "0654": 34, "065451": 54, "0655": 34, "065725": 44, "065969": 66, "066": 55, "0660": 34, "0662": 34, "0664": 34, "066464": 58, "06650103": 67, "066689e": 43, "066889": 57, "0669": 34, "06692492": 67, "067240": 57, "06724028": 57, "0673": 34, "0674": 34, "0675": 34, "067721": [69, 71], "06778448": 67, "068073": 43, "06827": 58, "06834315": 45, "068377": 54, "068514": 42, "06895837": 35, "0692": 34, "0695854": 35, "069600": 54, "07": [42, 43, 54, 57, 67], "070020": 57, "070086": 55, "070196": 44, "0701961897676835": 44, "0702127": 35, "0704": 34, "070552": 42, "070574e": 54, "0707": 34, "070751": 42, "070884": 57, "0711": 34, "071285": 69, "07136": [35, 52], "071488e": 44, "0716": 34, "07168291": 35, "071777": 65, "071782": [13, 64], "0719": 34, "07202564": [48, 49], "072058": 42, "07222222": 37, "072293": 56, "072852": 42, "073": 66, "073013": 57, "073207": 52, "073352": 42, "07347676": 35, "07350015": [23, 26, 35, 52], "073520": 44, "0736": 34, "07366": [37, 65], "073694": 43, "07387444": 67, "0743": 34, "074304": 69, "07436521": 67, "074426": 57, "07456127": 35, "074617": 43, "07479278": 58, "074961": 55, "075261": 46, "075384": 57, "07538443": 57, "07544271e": 67, "07561": 74, "07564554e": 67, "075869": 65, "076019": 53, "07614845": 67, "076156": 69, "076179312": [69, 71], "0761793120": [69, 71], "076322": 57, "076347": 44, "0765": 37, "076559": [64, 65, 66], "076596": 42, "07667224": 67, "076684": 74, "07685043": 67, "07688959": 67, "07689": 37, "07691847": 67, "076953": [48, 49], "076971": 38, "077161": 54, "07727773e": 67, "077319": 57, "077502": 70, "0777777777777778": 65, "07777778": [37, 65], "077840": 54, "07786": 66, "077883": 57, "078096": 69, "078207": 38, "07828372": [69, 71], "07829462": 67, "078474": [69, 71], "078810": 57, "07888": 67, "079085": 38, "07915": 37, "07919896": 67, "079458e": 53, "07961": 58, "07978296": 67, "07993031": 67, "08": [42, 43, 44, 54, 57, 66], "08001427": 67, "08005229": 67, "08007853": 67, "08031571": 67, "080351": 43, "08041529": 67, "08057641": 67, "080854": 54, "080900": 42, "08091581": 67, "080947": 38, "081": 37, "081100": 57, "081230": [42, 43], "081488": 52, "08154161": 67, "08154418": 67, "08177739": 67, "08181827e": 67, "0820": 34, "082263": 10, "082297": 67, "082574": 8, "082804": 46, "082858": 43, "082934": 54, "082973": 52, "083258": [69, 71], "083318": 69, "08333333": 37, "08333617": 67, "0835373": 67, "0835771416": 35, "083750": 54, "084": 35, "084156": 43, "084184": 44, "0841842065698133": 44, "084212": 50, "084269": 54, "084337": 66, "084633": 48, "084771": 42, "084891": 67, "0853505": 35, "085395": 42, "085566": 44, "08567": 67, "085671": 42, "085965": 54, "086": 55, "08602774e": 67, "086109": 43, "0862": 72, "086264": 44, "086464": 42, "08664208": 67, "086679": 65, "086889": 48, "0872": 34, "087491e": 43, "087561": 42, "087634": 42, "087947": 57, "088048": 57, "088282": 49, "088357": 57, "08848": 65, "088482": [13, 64], "088504e": 10, "088696e": 43, "08888889": 37, "089064e": 42, "08914387": 67, "0894": 34, "089661": 49, "08968939": 35, "089825": 43, "08e": 36, "09": [42, 44, 53, 54, 57, 64, 67], "09000000000000001": 65, "090025": 54, "09015": 34, "090255": 57, "091": 32, "091046": 49, "091391": [69, 71], "091406": 70, "091535": 42, "0916": 34, "091611": 43, "091992": 56, "092247": 57, "092263": 66, "092365": [69, 71], "093043": 57, "09310496": [69, 71], "093153": 57, "093474": 57, "09347419": 57, "093746": 69, "09392932": 66, "093950": 52, "094026": 52, "094118": 57, "094381": 52, "09444444": 37, "094829": 66, "094999": 57, "095475": 64, "095781": 2, "095835": 43, "09603": 72, "096245": 64, "096337": 52, "096550": 48, "096616": 64, "096741": 45, "096934": 43, "09741": 67, "097468": 44, "09779675": [69, 71], "097796750": [69, 71], "0979": 34, "098": 36, "098256": 57, "09830758": 58, "098308": 58, "098317": 54, "098319": 57, "098712": 57, "09879814e": 67, "09900798": 67, "099647": 56, "099670": 54, "099731": [42, 43], "09980311": [69, 71], "09988": 75, "0_": 22, "0ff823b17d45": 37, "0x1747bdd4520": 38, "0x1747bdd6b90": 38, "0x2920d7b7150": 56, "0x7efc8e68e220": 66, "0x7efc8e8c7e80": 69, "0x7efc8e8eb130": 65, "0x7efc9cb9f910": 77, "0x7efca6931970": 70, "0x7efca6b57eb0": 69, "0x7efca6c62430": 69, "0x7efca6c62670": 69, "0x7efca701e820": 65, "0x7efcaf1e9400": 65, "0x7efcaf8426d0": 66, "1": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "10": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 23, 24, 26, 32, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77], "100": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 23, 25, 26, 35, 37, 41, 42, 43, 45, 47, 50, 51, 52, 55, 59, 60, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 76], "1000": [7, 9, 33, 40, 41, 45, 46, 48, 49, 50, 51, 53, 54, 58, 61, 64, 66], "10000": [32, 34, 42, 43, 46, 53, 54, 57], "100000e": 54, "100356": 44, "10038": 58, "10039862": [59, 66], "100517": 69, "100614": 50, "10079785": 66, "100807": [42, 43], "100858": 58, "10089588": 57, "100896": 57, "10092": 54, "100923": 57, "100_000": 55, "101": [16, 17, 18, 64, 75, 76], "101076": 43, "10116083": 67, "10126": 54, "10127930": [69, 71], "101279300": [69, 71], "1015": [36, 53], "1016": [16, 17, 18, 34], "1016010": 36, "1018": 54, "102": [62, 64, 74, 76], "10235": 54, "102553e": 42, "10258": 54, "102616": 44, "102775": 44, "10299": 53, "103": [52, 59, 64, 76], "1031": 54, "103186": 43, "103189": 54, "10348": 53, "103497": 57, "1038": 54, "103806": 44, "103951906910721": 44, "103952": 44, "10396": 53, "104": [36, 53, 59, 64, 76], "10406": 54, "1041": 34, "10414": 54, "1045303": 35, "104787": 52, "1049483": 67, "105": [22, 35, 42, 52, 64, 76], "105318": 57, "1054": 37, "1055": 34, "105722": 43, "105751e": 42, "105942": 42, "106": [37, 64, 76], "10607": [38, 62, 74], "10618": 54, "10637173e": 67, "106391": 69, "106401e": 42, "106595": 66, "1066604": 67, "106691": 64, "106743": 43, "106746": 57, "107": [37, 64, 76], "107073": 44, "107295": 69, "1073": 54, "10747": [38, 62, 74], "107872": 64, "10799": 54, "108": [64, 72, 75, 76], "1080": [23, 26, 34, 35, 52], "10824": [38, 62, 74], "108257e": 54, "10831": [38, 62, 74], "10878571": 57, "108786": 57, "109": [42, 64], "109005": 57, "10903": 53, "109069": [69, 71], "109079e": 57, "1092232": 67, "109273": 52, "10928": 54, "1093": 47, "109454": 54, "1096": 34, "10967": 53, "109861": 74, "1099028": 67, "1099472942084532": 40, "10e": [44, 57], "11": [11, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 60, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 77], "110": [64, 76], "1101": 54, "110359": 52, "110681": 58, "1107": 54, "11071087": [59, 66], "110717": [69, 71], "1109": 54, "110902": 44, "110902411746278": 44, "111": [64, 76], "1111": [14, 15, 24, 33, 35, 41, 47, 52, 61, 66, 70, 72], "111164": 56, "11120": 54, "1118": 36, "11199615e": 67, "112": [37, 64, 76], "1120": [53, 67], "11208236": [60, 68], "1122": 54, "112216": 44, "11285869": 67, "1129": 54, "113": [14, 64, 76], "113207": 57, "113270": 44, "113415": 54, "1134993": 67, "11375": 54, "113780": 52, "114": [64, 76], "11409": 53, "11414": 53, "1144500": 35, "11447": 58, "114530": 48, "1145370": 35, "114570": 43, "11458": 54, "114591": 43, "114647": 44, "1146803": 67, "1147": 34, "1148": 54, "114834": 54, "11488": 54, "11495": 54, "115": [64, 76], "11500": [53, 77], "115060e": 57, "1151629323744485357596466697275828487100": 67, "115296e": 54, "115297e": 53, "11552911": 58, "11559": 54, "115636": 43, "11570": 53, "115792e": 54, "115972": 42, "116": [55, 64, 76], "116027": 44, "11617": 54, "116274": 44, "116483": 43, "116569": 54, "1166": 75, "1167": 53, "11673": 54, "11675": 54, "117": [42, 55, 64], "1170": 58, "11700": 77, "117072": 48, "117242": 57, "11724226": 57, "117366": 57, "11743": 77, "11750": 54, "1177": [34, 53], "117710": 44, "11792": 36, "11796": 54, "118": 64, "11802": 54, "1182": 36, "118255": 57, "1186": 36, "118601": 52, "11861": 36, "118721": [43, 49], "1187339840850312": 52, "11879": 54, "118799": 54, "118938e": 66, "118952": 52, "119": [64, 76], "11932": 54, "119348e": 43, "11935": 58, "11960772": 67, "119766": 57, "1198": [35, 52], "12": [32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 60, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77], "120": [45, 59, 64, 76], "12002": 53, "1202": 75, "120456": 49, "120468": 57, "12046836": 57, "120567": [48, 49], "120636": 42, "120721": 52, "12097": [14, 15, 24, 35, 47, 52, 61, 72], "121": [54, 64, 76, 77], "1210": 54, "12101": 54, "12105472": [69, 71], "121054720": [69, 71], "1211": 54, "1213405": 35, "121399": 54, "1214": [69, 71], "121584e": 57, "121711": 54, "121774": 50, "12196389e": 67, "122": [16, 17, 18, 62, 64, 75, 76], "12214": 36, "12223182e": 67, "122408": 44, "122777": 69, "123": [36, 37, 53, 64, 76, 77], "1230": 54, "12323": 54, "1234": [32, 33, 34, 38, 40, 41, 61, 65, 67, 69, 71], "1238": 54, "123806e": 43, "123917": 54, "124": [32, 64], "1240": 34, "12410": 54, "12411908": 66, "124465": 42, "12457757": 67, "124805": 53, "125": [64, 76], "12500": 53, "125065": 69, "12539340": [69, 71], "1255": 54, "12579": 54, "1258": 35, "126": [64, 76], "12606": 54, "12612": 54, "12660894": 67, "126777": 69, "126802": 54, "126875": 42, "12689": 54, "127": [64, 76], "127006": 54, "12705095": [68, 69], "12707800": 35, "12752825": [69, 71], "127563": 58, "1277": 55, "127778": 54, "127831": 43, "128": [36, 64, 76], "12802": 36, "12814": 54, "128273e": 42, "128312": 57, "128408": 52, "1285": 34, "12861": 54, "128651": 43, "129": [52, 55, 64, 76], "129152": 42, "12945": 75, "1295": [34, 54], "129514": 54, "12955": 53, "1298": 54, "12980769e": 67, "12983057": 66, "13": [16, 17, 18, 20, 33, 35, 36, 37, 38, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 57, 58, 60, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 77], "130": [37, 48, 52, 64, 76], "130122": 58, "13034980e": 67, "130370": 44, "130526": 64, "1306": 58, "130829": 57, "13091": 54, "131": [64, 76], "13102231": 66, "13119": 58, "1312": 77, "131211": 54, "1313": [36, 77], "13137893e": 67, "131544": 42, "131771": 43, "132": [37, 52, 64, 76], "13208": 77, "1321": [53, 77], "1324": [36, 53], "132454": 46, "1325": 36, "132671": 44, "13288": 53, "132903": 54, "133": [37, 62, 64, 75, 76], "13300": 54, "133202": 54, "133204": 42, "133343": 43, "133421": 54, "13356": 54, "133596": 57, "1339": 34, "133f5a": 55, "134": [52, 59, 64, 76], "1340371": 34, "1341": 36, "134146": 54, "1342": 54, "134211": 57, "1343": 53, "134542": 42, "134567": 54, "1346035": 36, "134687": 54, "13474": 54, "134765": 54, "1348": 53, "1349": 58, "13490": 54, "135": [37, 64, 76], "13505272": 35, "1352": 34, "135329": 50, "135352": 4, "135379": 69, "135396": 42, "135707": 65, "135755": 64, "135856": 57, "13585644": 57, "135871": 52, "136": [38, 52, 64, 76], "1360": 36, "136089": 52, "1361": [34, 54], "13642": 54, "136442": 52, "1366": 55, "136836": 52, "137": [37, 38, 64, 76], "1371": 54, "137213": 43, "137396": 57, "1378": 54, "138": [64, 76], "1380": 53, "138068": 48, "13809": 54, "138378": 44, "1386": 34, "13868238": [69, 71], "138682380": [69, 71], "138698": [69, 71], "138851": 48, "13893": 54, "139": [55, 64, 74], "1390": 53, "139491": [69, 71], "13956": 58, "139582e": 11, "1398": 54, "139921": 64, "14": [33, 35, 36, 37, 38, 42, 43, 44, 45, 48, 49, 50, 52, 53, 54, 57, 58, 60, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 77], "140": [45, 54, 59, 64, 76], "1400": 54, "14000073": 67, "1401": 34, "140770": [42, 43], "140833": 44, "140861": 35, "140926": 57, "141": [54, 64, 76], "141098e": 54, "14114": 58, "141347": 42, "141384": 50, "14141": 54, "141546": [69, 71], "141729": 43, "141820": 44, "1418370": 67, "142": [64, 76], "14200098": [69, 71], "142270": 46, "142382": 42, "1424": 65, "142624": 43, "14268": 66, "14281403493938022": 65, "14289": 54, "143": [62, 64, 76], "143380": 55, "143495": 64, "1435": 54, "14368145": [69, 71], "144": [42, 43, 64, 76], "14400": 53, "14405": 54, "14406": 54, "144084": 44, "1441": 34, "144137": 45, "144241": 48, "1443": 54, "144500e": 54, "144669": 57, "1447": 54, "144800": 44, "144861": 53, "144908": 56, "145": [64, 76], "145245": 57, "14532650": [69, 71], "145513": 42, "145625": 57, "145748": 69, "14587": 54, "146": [64, 76], "146037": 57, "146046": 43, "146087": 74, "146142808990006": 44, "146143": 44, "14625": 54, "1465": 36, "146641": 69, "14667": 54, "1468115": 35, "146973": 44, "1469734445741286": 44, "147": [64, 76], "147015e": 54, "14702": 38, "147121": 57, "14744": 54, "14772": 54, "1479": 54, "14790924": [69, 71], "147909240": [69, 71], "147927": 38, "14798": 54, "148": [64, 76], "14803": 54, "148134": [42, 43], "148161": 57, "148443": 64, "14845": 38, "1485": 54, "148750e": [53, 54], "148790": 54, "148802": 54, "148950": 42, "149": [64, 76], "1492": [32, 51], "149285": 57, "149671e": 43, "149714": 52, "14984": 54, "149858": [12, 64], "149898": 57, "149973e": 43, "15": [2, 4, 5, 7, 8, 9, 10, 11, 12, 15, 33, 35, 36, 37, 42, 43, 44, 45, 48, 50, 51, 52, 53, 54, 57, 58, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 77], "150": [22, 37, 42, 43, 64, 76], "15000": [36, 53], "150000": 36, "15000000000000002": [44, 54, 57, 65], "150000e": 54, "150136": 43, "1502": 35, "150200": 52, "150334": 54, "150408": 35, "150614": 38, "150719e": 53, "151": [32, 64, 76], "151047e": 48, "151063": 42, "151087e": 42, "15113": 54, "151636": 44, "151819": 57, "15194": 53, "152": [64, 76], "152034": 54, "152148": [42, 43], "152772": 43, "15285": 54, "152926": 46, "153": [55, 64, 76], "1530959776797396": 44, "153096": 44, "153119": 44, "15347": 54, "153587": 52, "153633": 38, "153639": 67, "15375": 58, "154": 64, "15430": 77, "154421": 69, "1545": 54, "154557": 57, "154758": 69, "154811": 43, "154828": 44, "155": [64, 76], "155000": 53, "155025": 57, "155120": 57, "155516": 56, "15556": 54, "155610": 42, "155676": 42, "1557093": 35, "156": [64, 76], "1560": 54, "156021": 57, "156202": [42, 43], "156317": [42, 43], "1564": [69, 71], "156545": 69, "156567": 42, "1569": 54, "156969": 44, "157": [64, 76], "157091": 69, "1576": 54, "157613": 42, "1577657": 35, "158": [53, 64, 76], "158007": 57, "158087": 42, "15815035": 36, "158178": 44, "1582": 54, "1586": 54, "158697": [69, 71], "1589": 54, "15891559": 57, "158916": 57, "159": 76, "159011": 42, "15916": 34, "159202e": 43, "159386": 58, "1596": 37, "159959": 54, "16": [2, 32, 33, 35, 36, 37, 42, 43, 44, 50, 52, 53, 54, 57, 58, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 77], "160": [45, 59, 76], "1600403": 67, "1604": 36, "160438": 42, "160932": 44, "161": [37, 49, 75, 76], "161049": 43, "161088": 43, "161141": 52, "161198": 56, "161236": 57, "161243": 57, "161288": 43, "161543": 54, "1619": 36, "162": 76, "16201": 54, "16211": 53, "162153": 57, "1622": 54, "16241": 54, "162587": 58, "1626685": 35, "162710": 44, "1628": 53, "162930": 54, "163": [54, 76], "163194": 57, "163393e": 43, "163566": 54, "163895": 44, "164": 76, "164034": 69, "16403663": 67, "164608": 57, "164617": 53, "164698": 50, "164801": 57, "164805": 44, "164864": 52, "165": 76, "16500": 53, "165178": 57, "16536299": [69, 71], "165362990": [69, 71], "16539906e": 67, "1654": 54, "165419": 57, "165549": 74, "165569": 42, "16587": 53, "16590": 54, "16597": 54, "166": 76, "166079": 42, "1661": 53, "166375": 64, "167": [36, 53, 76], "16725": 54, "167547": 57, "1676": 54, "167765": 54, "167993": 69, "168": 76, "16803512": [69, 71], "168092": 69, "1681": 34, "168195": 58, "1683": 53, "168614": 57, "168931": 57, "169": [37, 76], "1691": [34, 54], "16910": 54, "169196": 57, "169230e": 44, "16951": 54, "16984": 54, "17": [33, 35, 36, 37, 42, 43, 50, 52, 53, 54, 57, 58, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 77], "170": 76, "1703": 34, "1704": 54, "17083": 54, "171": 76, "1712": 75, "1713394": 67, "1714": 36, "171575": 57, "171709": 42, "171815": 65, "171868e": 42, "171942": 54, "172": 76, "172022": [69, 71], "172083": 43, "17265861": 67, "172793": 57, "173": 76, "17372": 54, "1738": 54, "17385178": 65, "173969": 69, "174": 76, "174106": 58, "174185": 57, "174499": [69, 71], "174516e": 57, "17453": 54, "1746": 54, "174743": 64, "174884": 43, "174901": 43, "174940": 64, "17499": 54, "175": 76, "1751": 53, "175176": 57, "17522": 54, "175284": 44, "175342": 42, "175635027": 35, "17576": 54, "176495": 57, "17655394": 57, "176554": 57, "176929": [69, 71], "177": [75, 76], "177007": 57, "17700723": 57, "177043": [42, 43], "1773": 54, "177304": 43, "177463": 56, "177496": 57, "177611": 57, "17762282": 67, "177751": 57, "17778": 54, "177933e": 42, "17799": 54, "177995": 57, "178": [50, 76], "178169": 48, "178218": 43, "17823": 37, "178704": 69, "178763": 57, "178805": 49, "178934": 69, "178980": 43, "179": [48, 76], "1795850": 35, "179588e": 57, "1798913180930109556": 55, "18": [33, 35, 36, 37, 38, 42, 43, 50, 52, 53, 54, 57, 58, 62, 64, 65, 66, 67, 69, 70, 71, 74, 77], "180": [45, 59], "18015": 54, "180176e": 54, "1803": 34, "18030": 54, "180348": 43, "180575": [48, 49], "1807": [34, 54], "1809": 75, "180951": 57, "181": 76, "1812": 54, "1814": 34, "18141": 54, "181446": 69, "1819243224": 67, "182": 76, "182208e": 42, "182393": 42, "182633": 57, "182692": 43, "182849": 57, "183": [37, 76], "183373": 66, "183526": 44, "18356413": 66, "18368": 54, "183855": 65, "183888": 52, "184": [37, 75], "185": [36, 37], "18500": 54, "1855": 54, "185585": 64, "185984": 42, "186": [54, 76], "186027": 42, "18604": 54, "18617350": 67, "1862": 34, "186237": 43, "18631": 54, "18637": 72, "18666": 54, "186735": 57, "18678094e": 67, "186795": 43, "186836": 57, "187153": 69, "187664": 42, "187690": 57, "18789": 54, "188": 76, "1881": 34, "188175": 57, "1881752": 57, "188223": 57, "18888149e": 67, "188991": 69, "189": [32, 37], "189195": 54, "189248": 42, "189293": 54, "189302": 42, "189493": 43, "1895815": [23, 35, 52], "189737": 57, "189927": 54, "189998": 57, "19": [33, 35, 36, 37, 42, 43, 51, 52, 53, 54, 57, 58, 64, 65, 66, 67, 69, 74, 77], "190": [37, 76], "19000": 54, "190096": 69, "190140": 42, "19031969": 57, "190320": 57, "19033538": 35, "190648": 7, "19073905e": 67, "190809": 57, "190869": 64, "1909": [23, 35, 52], "190915": 44, "190921": 49, "190982": 57, "191": [37, 51, 75, 76], "1912": 75, "1912705": 61, "191320e": 53, "191397": 64, "191606": 53, "191716": 54, "1918": 34, "192": [66, 76], "1922": 54, "192240": 69, "192505": 56, "192526": 58, "19252647": 58, "192539": [13, 64], "192587": 57, "192739": 43, "1928": 34, "193060": 57, "193069e": 42, "1932181": 67, "193300": 42, "193308": [13, 64], "19374710e": 67, "19382": 54, "19385": 54, "193f0d909729": 37, "194": [54, 76], "1941": 36, "19413": [53, 54], "194232": 43, "194601": 45, "194861": 55, "19499843": 67, "195": 76, "19509680e": 67, "195377": 57, "195396": 57, "195547": 54, "195564": 52, "19559": [36, 53], "195761": 57, "1959": 75, "196": 76, "196189": 57, "196437": 54, "19680840": [69, 71], "1970": 54, "197000e": 54, "19705": 54, "197225": [38, 62, 74], "1972250000001000100001": [37, 62, 74], "1974": 54, "197424": 65, "197484": 69, "19756": 54, "19758": 54, "197600": 46, "197711": 54, "197920": 42, "19793": 54, "19794": 54, "198": 76, "198218": 52, "19824": 54, "198351": 57, "198549": 38, "198687": 36, "1988": [33, 41, 61], "198953": 64, "199": 76, "1990": [36, 53, 54, 66], "1991": [36, 53, 54, 77], "199206e": 42, "199281e": 57, "199282e": 54, "199412": 43, "199458": 69, "1995": [35, 52], "1998": 55, "19983954": 59, "199893": 48, "1999": [55, 59], "199959": 42, "1_": [44, 57], "1e": [2, 4, 5, 7, 8, 9, 12, 13, 54], "1f77b4": 46, "1x_4x_3": 46, "2": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 26, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 75, 76], "20": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, 21, 23, 24, 25, 33, 35, 36, 37, 42, 43, 44, 45, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 74, 77], "200": [19, 22, 34, 41, 44, 45, 47, 51, 56, 57, 59, 61, 65, 76], "2000": [15, 36, 42, 43, 44, 53, 54, 57, 59, 66], "20000": [36, 53], "20000000000000004": [44, 54, 57], "200000e": 54, "20010": 54, "200110": 54, "2003": [14, 75], "200303": 74, "2005": 45, "20055": 54, "2006": 54, "20074": 54, "200863": 42, "201": [37, 54, 76], "2010": [35, 52], "2011": [35, 52, 72, 74], "2013": [47, 69, 71, 75], "2014": [69, 71, 75], "20148598": 51, "2015": [22, 75], "201528": [42, 43], "20158": 54, "2016": 55, "2017": [21, 75], "201768": 52, "201788e": 54, "201796": 50, "2018": [14, 15, 24, 25, 33, 35, 36, 41, 45, 47, 51, 52, 53, 54, 58, 61, 67, 69, 71, 72, 75, 76], "2019": [19, 37, 42, 43, 44, 48, 49, 54, 57, 58, 65, 68, 72, 74, 75], "202": 76, "2020": [4, 5, 16, 17, 18, 20, 34, 37, 45, 65, 66, 70, 75], "2020435": 35, "2020983": 67, "2021": [23, 34, 35, 37, 42, 43, 52, 75, 76], "20219609": 35, "2022": [58, 66, 70, 72, 75], "2023": [26, 59, 66, 68, 75], "2024": [32, 40, 55, 72, 75], "202650e": 44, "20269": 54, "20274": 54, "202846": 43, "20294426": 67, "203": [36, 53, 55], "203284": 44, "20329": 54, "2036": 54, "203828": 54, "203893": 64, "204007": 57, "20400735": 57, "204482": 57, "204653": 64, "204794": 57, "205": 58, "205187": 44, "205656": 42, "205938": 52, "206": 76, "2061": 54, "206253": [53, 54], "2064": 54, "206614": 57, "206748": 43, "207222": 53, "2075": 34, "20783816": 35, "207840": 49, "207912": 69, "208": 76, "208034e": 54, "2080787": 35, "208147": 55, "20823898": 35, "2086": 54, "208922": 42, "209014": 57, "209219e": 58, "209257": 4, "209546e": 54, "2097": 66, "209894": 57, "21": [14, 15, 24, 33, 35, 36, 37, 42, 43, 47, 51, 52, 53, 54, 57, 58, 61, 64, 65, 66, 67, 69, 72, 74, 75, 77], "210": [16, 17, 18, 55], "2103": [54, 72], "2103034": 35, "210319": [42, 43], "210323": 57, "2104": 76, "21078": 54, "211": 76, "21105": [37, 65, 72, 74], "21142": 54, "211534": 44, "21155656": 57, "211557": 57, "212": 76, "2122": 54, "21257396e": 67, "212844": 52, "213": [75, 76], "213026": 54, "213070": 43, "213135": 43, "21361": 54, "213635": 42, "2139": 20, "214764": 58, "215": 49, "215069": 57, "215342": 57, "215389": 42, "2155": 54, "21550": 54, "21562": 54, "21573": 54, "215967": 69, "216130e": 42, "216207": 65, "21624417": 35, "2163": 54, "216344": 57, "21669513e": 67, "216761": 56, "217": [67, 75], "21716": 54, "2171802": [35, 52], "217244": [9, 64], "21804": [36, 53], "218767": 54, "2189": 54, "218938": 54, "219": [16, 17, 18, 75], "2191274": 35, "219196e": 43, "21997": 53, "22": [33, 35, 36, 37, 42, 43, 52, 53, 57, 58, 64, 65, 66, 67, 69, 74, 77], "220": 76, "220088": 54, "220772": 57, "220773": 42, "221": 76, "221245": 43, "2213": 52, "2214": 52, "221419": 54, "2215": 52, "2216": 52, "2217": [35, 52], "222": 76, "22200024": 67, "2222": [33, 35, 41, 66], "22222": 54, "2227": 34, "22272803e": 67, "222843": 57, "223": 76, "22336235": 35, "223485956098176": [48, 49], "22375856": 35, "22390": 53, "224": [76, 77], "224539e": 42, "224546": 42, "224897": [42, 43], "225": [34, 59, 76], "225034": 45, "22505965": 35, "22507006e": 67, "225175": 57, "225222": 57, "22522221": 57, "22528": 54, "225459760731946": 44, "225460": 44, "225574": 52, "2256": 54, "22562": 54, "2258": 58, "226": [55, 76], "226524": 57, "226598": 52, "22677110": 67, "226776": 43, "226938": 49, "227": [54, 76], "2271071": 26, "227190": 49, "2276": 34, "2279": 54, "227931e": 53, "228035": 54, "2281": 54, "228621": 42, "228630": 43, "228648": 36, "2288": 34, "229": [36, 76], "22925": 54, "22937": 54, "229443": 57, "229472": 53, "2295": 54, "229759": 65, "2298": 34, "229897": 42, "229961": [42, 43], "229994": [42, 43], "23": [5, 35, 36, 37, 42, 43, 45, 52, 53, 54, 57, 58, 62, 64, 65, 66, 67, 69, 72, 74, 75, 77], "230": 34, "230009": [48, 49], "2307": [35, 52, 61], "230956": 46, "231": [14, 76], "23113": 66, "231153": 43, "231310": 57, "231330e": 43, "231430": 69, "231467": 66, "231986": 57, "232134": [42, 43], "2328": 54, "232959": [48, 49], "233": 21, "233029": 42, "233154": 77, "234": 75, "234205": 54, "234534": 44, "234605": 38, "234798": 54, "234812e": 43, "234910": 52, "235": 76, "235501e": 42, "235873": 42, "2359": 77, "23590": 54, "236008": 44, "236309": 54, "23690345e": 67, "237": 37, "237252": 54, "237292": 43, "237341": 42, "237430": 43, "237461": 58, "23748": 54, "23751359e": 67, "237896": 57, "23789633": 57, "238": [35, 52, 76], "238101": 57, "238225": 69, "238251": 44, "238529": 8, "23856": 54, "238794": 57, "239": 76, "239313": 43, "239317": 43, "23965": 54, "239799": 42, "23e": 36, "24": [35, 36, 37, 42, 43, 49, 52, 53, 54, 57, 58, 59, 64, 65, 66, 67, 69, 74, 75, 76, 77], "240127": [42, 43], "240295": 58, "240532": [42, 43], "24080030a4d": 37, "240813": 50, "241049": 57, "241063": 42, "241064": 43, "2416": 34, "241609": 54, "241678": 42, "24199": 54, "242": 75, "242000": 54, "242124": [53, 54], "242139": 69, "242158": [53, 54], "2424596822": 49, "242815": 69, "242902": 57, "2430561": 34, "243246": 57, "2438": 54, "2439": 54, "244": 54, "244090": 54, "244455": 57, "244622": 69, "24469564": 74, "245": 75, "245062": 57, "2451": 34, "24510393": 36, "245370": 52, "245416": 43, "245512": 57, "245720": 46, "246": 76, "246624": 64, "246731": 53, "2467506": 35, "246753": 57, "246879": 57, "247": 76, "247020": 44, "247057e": 57, "2471": [34, 54], "2472": 54, "247207": 43, "247617": 64, "247717": 54, "24774": [53, 54], "247826": 52, "248171": 57, "248638": 44, "249": [35, 52, 55], "2491": 54, "249109e": 43, "24917": 54, "25": [13, 16, 17, 18, 22, 23, 24, 35, 36, 37, 42, 43, 44, 46, 47, 52, 53, 54, 57, 59, 64, 65, 66, 67, 69, 74, 77], "250": [55, 77], "2500": 54, "25000000000000006": [44, 54, 57], "250073": 54, "250210": 44, "2503": 54, "250354": 57, "250425": 44, "251": [54, 58], "251101": [64, 65, 66], "251412": 43, "251480": 43, "251953": 54, "252133": 54, "252253": 58, "25240463": 66, "252524": 57, "252601": 69, "252644": 42, "253026": [42, 43], "2532": 54, "253437": 56, "253724": 57, "25374": 54, "254": 54, "25401679": 35, "254038": 49, "2543": 54, "254324": 44, "254400": 69, "254551": 43, "255": 54, "255598": 43, "256": [54, 65], "2562627": 67, "256416": 57, "256567": 52, "25672": 54, "256944": 57, "256983": 11, "256992": 54, "257207": 35, "257377": 46, "258158": [42, 43], "2583": 54, "258951": 57, "259118": 50, "2594": [36, 53], "259828": [42, 43], "25x_3": 46, "26": [35, 36, 37, 38, 42, 43, 45, 52, 53, 54, 59, 62, 64, 65, 66, 67, 69, 74], "26016": 54, "260161": [12, 64], "260211": [42, 43], "260356": 53, "260360": 57, "260687": 43, "2610": 54, "2613": 54, "261624": [53, 54], "261685": 54, "26175": 54, "261777": 54, "261903": 52, "2619317": 35, "262000e": 42, "262357": 43, "262423e": 54, "262621": 52, "262829": 67, "263": [14, 54], "2633": 54, "263672": 42, "263974e": 57, "264": 75, "264086": 46, "264274e": 54, "2643300": 67, "264884": 54, "265119": 56, "2652": [37, 53, 54], "265547": 54, "2658": 49, "266922": 69, "267": 55, "2670691": 35, "267099": 42, "267500": 52, "267581": 54, "267767": 43, "267950": 57, "268055": 54, "268942": 57, "268998": 36, "269043": 57, "269977": 54, "26bd56a6": 37, "26e": 36, "27": [16, 17, 18, 33, 35, 36, 37, 38, 42, 43, 45, 52, 53, 54, 59, 62, 64, 65, 66, 67, 69, 74, 75], "270": 32, "2700": 37, "270644": [42, 43], "270694e": 42, "271004": [53, 54], "271083": 54, "2713538": 67, "272296": 54, "272408": 43, "272662": 54, "273": 37, "2731989": 67, "273356": 44, "27371": [36, 53], "27372": [36, 53], "274": [37, 54], "2740991": 34, "274247e": 53, "274267": 52, "27429763": 66, "274430": 43, "274793": 57, "274825": [13, 64], "27487": 54, "2754": 34, "275535": 42, "275596": 69, "276": 37, "276148": 57, "276189e": 52, "27620395": 67, "2764": 54, "2766091": 36, "27713": 54, "277299": 38, "27751": 54, "277561e": 52, "277968": 57, "278": 58, "2780": 35, "278000": 52, "278303e": 42, "278391": 54, "278434": 48, "2786": [69, 71], "278683": 42, "2787": 34, "27951256e": 67, "27986": 54, "28": [35, 36, 37, 42, 43, 47, 50, 52, 53, 59, 64, 65, 66, 67, 69, 74, 76], "280196": 49, "280454dd": 37, "280514": 69, "280963": 56, "281024": 57, "28111364": 36, "2815": 54, "2818": 34, "2819": [69, 71], "282": 75, "282200": 49, "2825": [72, 74], "28251": 54, "282870": 54, "2830": [72, 74], "28326": 54, "2836059": 35, "28382": 54, "283974": 57, "283994": 57, "28425026": 58, "284271": 50, "284397": 77, "28452": [36, 53], "2849": 54, "284949": 43, "284987": 54, "286027": 64, "286203": 42, "2865": [34, 54], "286507": 44, "286563e": 54, "286593": 54, "287011": 43, "287041": 57, "287384": 58, "287815": 58, "287926": 57, "288": 55, "288006": 53, "288850e": 42, "288976": 54, "289": 75, "289357": 43, "289440": [42, 43], "289718": 42, "29": [11, 35, 36, 37, 42, 43, 52, 53, 58, 59, 64, 65, 66, 67, 69, 74], "290987": 53, "291": [54, 77], "2910": 54, "291008": 42, "291011": 66, "291071": 57, "29107127": 57, "29121314182628363840425268707376778389": 67, "291213141826283638404252687073767783891151629323744485357596466697275828487100463335474950555658627988909192939596995781019212330313446515460677174788697": 67, "291405": 57, "291406": 57, "291434": 43, "291500e": [53, 54], "291517": [42, 43], "291963": 57, "292": 56, "292028": 44, "292047": 69, "292105": 57, "29210861": 67, "292178": 53, "292302995303554": 44, "292303": 44, "2925": 37, "2927": 54, "292997": 57, "29299726": 57, "293218": 57, "293617e": 54, "293960": 42, "294067": [42, 43], "295": 75, "295481": 57, "29548121": 57, "295642": 42, "295837": [38, 62, 74], "2958370000000100000100": [37, 62, 74], "2958370001000010011100": [37, 62, 74], "2958371000000010010100": [37, 62, 74], "296228": 54, "296585": 43, "296729": 52, "29678199": [60, 68], "296901": 42, "297287": [42, 43], "2973": 54, "297349": [48, 49], "297682": 57, "297687": 54, "297749": 54, "297779e": 43, "29784405": 58, "298": [21, 37], "298076": 42, "298120": 44, "298228e": 54, "299": 37, "299537": 49, "299712": 48, "2_": [26, 59, 70], "2_x": [26, 59], "2d": 68, "2dx_5": [44, 57], "2e": [32, 34, 35, 36, 37, 65, 66, 68, 69, 74], "2f": 50, "2m": 70, "2n_t": 46, "2x": 57, "2x_0": [19, 42, 43, 48, 49], "2x_4": 46, "3": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 24, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "30": [19, 32, 33, 34, 35, 37, 40, 41, 42, 43, 44, 45, 52, 53, 54, 57, 59, 64, 65, 66, 67, 69, 74], "300": [33, 41, 44, 54, 57, 61, 75], "30000000000000004": [44, 54, 57], "30031116e": 67, "30093956": 58, "301": [32, 37], "301366": 69, "301371": 57, "3016": 53, "301737": 42, "30189": 54, "302357": 57, "302571": 64, "302648": 52, "303007": 42, "303324": 52, "303489": 57, "303613": 57, "30361321": 57, "30383": 54, "303835": 52, "303f00f0bd62": 37, "304130": 57, "304159": 57, "304201": 46, "304217": 42, "305133": 64, "305255": 43, "30527": 54, "305341": 57, "305612": 52, "305775": 57, "305b": 37, "30645": 54, "30672815": 35, "306915": 52, "306963": 57, "307176": 42, "307407": 57, "308": 54, "308568": 43, "308774": 42, "30917769": [48, 49], "309605": 42, "309772": 52, "309823e": 54, "30982972": 57, "309830": 57, "31": [35, 36, 37, 42, 43, 52, 53, 54, 59, 64, 65, 66, 67, 69, 74, 77], "310000e": 54, "310761": 56, "311172022242527394143456163658081859498": 67, "3111720222425273941434561636580818594981151629323744485357596466697275828487100463335474950555658627988909192939596995781019212330313446515460677174788697": 67, "31117202224252739414345616365808185949829121314182628363840425268707376778389115162932374448535759646669727582848710046333547495055565862798890919293959699": 67, "3111720222425273941434561636580818594982912131418262836384042526870737677838911516293237444853575964666972758284871005781019212330313446515460677174788697": 67, "31117202224252739414345616365808185949829121314182628363840425268707376778389463335474950555658627988909192939596995781019212330313446515460677174788697": 67, "311253": 54, "311712": 48, "3120": 54, "312008": 43, "312882": 43, "313056": 69, "313209": 44, "313324": 54, "31337878": 54, "313535": 57, "31378": 37, "314": 67, "314071e": 42, "3141": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 37, 38, 52, 60, 62, 64, 65, 68, 69, 71, 74], "314341": 42, "314625": 43, "314651": 48, "31476": [53, 54], "3151": 54, "315155": 43, "315290": [48, 49], "315310": 42, "316": 37, "316193": 57, "31632": 54, "316407": 66, "316540": 52, "316717": [42, 43], "316863": 43, "317064": 42, "317394": 46, "317487": 57, "317607": 57, "318": 37, "318000e": 54, "318438": 54, "318552": 54, "318584": 69, "318753": [48, 49], "319": 37, "319100": [48, 49], "319759": 57, "319850": 57, "31e": 67, "32": [35, 36, 37, 42, 43, 52, 53, 54, 59, 64, 65, 66, 67, 68, 69, 74], "320": 54, "320314": 53, "320633": 44, "321520": 43, "321686": 69, "322": 77, "32236455588136": 45, "322404": 58, "3234": 54, "323622": 53, "323679": 52, "324": [36, 54], "324518": 56, "32458367": 35, "3245837": 57, "325056": 57, "325090": 54, "326148": 43, "326740": 57, "327265": 43, "327803": 64, "329": 32, "329181": 43, "329339": 45, "32950022e": 67, "329679": 43, "33": [35, 36, 37, 42, 43, 48, 52, 53, 54, 59, 64, 65, 66, 67, 69, 74, 75], "3300": [36, 53], "330143": 57, "33014346": 57, "330285": [42, 43], "3304269": 35, "330615": 57, "330731": [13, 64], "331365": 48, "331521": 57, "331602": 54, "331640": 43, "33175566": 57, "331756": 57, "3317974": 67, "332502": 43, "332782": [13, 64], "3329": 54, "332996": 52, "3333": [33, 35, 41, 64, 65, 66], "3333333": 37, "33335939e": 67, "3335": 54, "333575": 53, "333655": 42, "333704": 43, "334": 36, "334425": 42, "334750": 44, "334785": 50, "335": 55, "33500": 54, "335121": 43, "335176": 54, "33527": 58, "335609e": 57, "335846": 57, "335853": 54, "336153": 42, "336461": 54, "336510": 43, "336612": 46, "337380": 57, "3376": 34, "337619": 45, "338": 58, "33849": 54, "3386": 67, "338603": 42, "338775": 44, "338900": 43, "338908": 44, "339273": 58, "33928": 54, "339570": 57, "339875": [48, 49], "33e": 67, "34": [33, 34, 35, 36, 37, 42, 43, 49, 52, 53, 54, 55, 58, 59, 64, 65, 66, 67, 69, 77], "340": [36, 54], "340485e": 42, "341": 32, "341336": [9, 64], "3420": 54, "342467": 64, "342675": 35, "34287815": 58, "342989": 54, "342992": 52, "343": 54, "3435498": 67, "344": 55, "344212": 77, "344305": 50, "344505": [53, 54], "344640": 57, "34475": 53, "344787": [42, 43], "344834": 46, "345065e": 54, "345381": 44, "3453813031813522": 44, "3454": 54, "345852": 43, "345903": 57, "345989": 42, "3461187": 67, "346206": 57, "346238": 58, "346269": 43, "346678": 56, "347310": [13, 64], "347696": 44, "34769649731686": 44, "34786480": 67, "347929": 54, "34858240261807": 45, "348617": 57, "348700": 43, "3492131": 34, "349383": 52, "34943161": 51, "3495005": 67, "349638": 43, "34967621": 35, "349772": 49, "35": [36, 37, 42, 43, 44, 52, 53, 54, 55, 57, 64, 65, 66, 67, 69, 70, 77], "3500000000000001": [44, 54, 57], "350165": 65, "350208": 42, "350518": 57, "350712": [48, 49], "35077502": 70, "351629": 54, "351766": 56, "352": [36, 52], "352250e": 53, "352259e": 54, "3522697": 35, "352365": 42, "352813": [64, 65, 66], "35292": 54, "352990": 54, "352998": 54, "353412": 57, "35341202": 57, "35365143": [2, 4, 5, 7, 8, 9, 10, 11, 12], "353748e": 57, "3538": 34, "354": 54, "354188": 46, "354371": 57, "354688": 10, "355209": 57, "355699e": 42, "356136e": 54, "356167": 49, "356183": 54, "35620768e": 67, "3564": 54, "3565": 54, "356886e": 43, "3569": 66, "357": 54, "357170": 42, "35731523": 66, "358158": [53, 77], "358289": 52, "358395": 58, "358653": 43, "358799": 69, "358977": 53, "359": 77, "359100": 54, "3592069": 67, "3593": 58, "359307": 43, "35th": 75, "36": [36, 37, 42, 43, 52, 53, 64, 65, 66, 67, 69], "360004": 57, "360065": 69, "360122": 42, "360475": [42, 43], "360655": 54, "360683": 44, "360801": 44, "3608694": 67, "361518": 44, "361518457569366": 44, "361521": 10, "3619201": 20, "362155e": 43, "3622318": 66, "36231307e": 67, "363": 32, "363276": 35, "3643": [69, 71], "364595": 35, "3647": 37, "364800": 57, "36501": 54, "36557195e": 67, "36566025e": 67, "366": 54, "36616": 54, "366529": 56, "366541e": 42, "366718627": 35, "366950": 42, "367056": 43, "367181": 42, "367323": 57, "367571": 44, "367625": 57, "368092": 43, "368152": 52, "3682": [36, 53, 54], "368324": 52, "368499": 44, "3684990272106954": 44, "369556": 44, "3696": 58, "369796": 57, "369869": 53, "369981": 52, "37": [32, 36, 42, 43, 52, 53, 54, 64, 65, 66, 67, 69], "3702770": 35, "370736": 52, "3707775": 35, "3710": 54, "371357": [53, 54], "371429": 44, "371535": 42, "372": 75, "37200": [53, 54], "372097": 44, "3722": 54, "37231324": 59, "3724": 54, "372427": 43, "372628": 42, "3727679": 35, "372989": 42, "373802": 43, "3738573": 35, "374364": 57, "37436439": 57, "3745": 54, "374821e": 54, "374862": 42, "375077e": 42, "375081": 54, "375465": 57, "376760": 43, "376780": 42, "376806": 43, "377060": 54, "377311": 57, "37743524": 66, "377669": 43, "378351": 7, "378588": 42, "378596": 52, "378688": 57, "378828e": 42, "378834": 57, "3788859": 35, "379": 75, "379038": 57, "379117": 42, "37939": 54, "379614": 57, "379626": 42, "38": [37, 42, 43, 53, 64, 65, 66, 67, 69], "3800694": 35, "380170e": 42, "380432e": 43, "380837": [53, 54], "381072": 57, "381603": 42, "381623e": 49, "381685e": [53, 54], "381689": 57, "3817": 54, "381826": 11, "382188e": 43, "382286": 54, "382582e": 2, "382684": 64, "382872": 44, "38295998": 67, "383297": 57, "384": 54, "384443": 43, "384777": 54, "384928": 42, "3851": 54, "385240": 69, "385877e": 43, "385917": 52, "386": [37, 54], "386102": 44, "386502": 54, "386834": 43, "386894": 43, "386988": 45, "387": 37, "3871": 34, "387426": 57, "387780": 57, "388071": 57, "38818693": 67, "388216e": 65, "388298e": 42, "388593e": 43, "388668": 57, "38866808": 57, "388871": 54, "389": 37, "389126": 66, "389566": 56, "38973512e": 67, "38990574": 67, "39": [32, 34, 35, 36, 37, 38, 42, 43, 45, 49, 50, 51, 52, 53, 54, 58, 59, 64, 65, 66, 67, 69], "39010121e": 67, "390379": 57, "390599": 43, "392242": 50, "392400": 54, "392623": 43, "392752": 45, "3927872": 67, "392833": 58, "392864e": [53, 54], "393": 32, "393060": 64, "39323452": 67, "393604": 44, "39425708": 35, "395076e": 54, "395136": 52, "395268": 64, "395603": 42, "395889": 54, "39611477": 36, "396173": 48, "39621961e": 67, "3962918": 67, "396300": 48, "3964": 54, "396531": 54, "396985": 52, "396992": [42, 43], "397140": 44, "397155": 43, "39727": 54, "397313": 34, "397578": 50, "397811": 58, "398": [62, 74], "3985": 54, "398770": 57, "398999": 64, "399": 36, "399056": 57, "399207": 43, "399223": 46, "399355": 46, "399692": 57, "39986167": 67, "3cd0": 37, "3dx_1": [44, 57], "3e1c": 37, "3ec2": 37, "3f5d93": 55, "3x_": 57, "3x_4": [44, 57], "4": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 26, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 76], "40": [35, 42, 43, 44, 45, 49, 53, 54, 57, 59, 62, 64, 65, 66, 67, 69, 70], "400": 52, "4000000000000001": 65, "40000000000000013": [44, 54, 57], "400164": 50, "40029364": 70, "400823": 57, "400855956463958": 44, "400856": 44, "400910": 42, "401": [14, 77], "401247": [68, 69], "40127723e": 67, "401861": 42, "401931": [48, 49], "402077": 54, "402113": 69, "402301e": 65, "402902": 54, "403425": 57, "4035699755": 60, "403569975514042": 60, "4035699755140420": 60, "403715": 2, "4037269089": 68, "4039": 34, "404318": 34, "404411": 42, "40452": 54, "404550": 56, "40485166": 67, "405203": 46, "405374": 54, "405400e": 42, "40583": 34, "405890": [13, 64], "406": 53, "406285": 57, "406446": 44, "4065173": 67, "40676": 34, "407558": 42, "408014": 50, "408476": 70, "40847623": 70, "408479": 52, "408539": 57, "408565": 57, "409154": 34, "4093": 58, "409328": 54, "409395": 57, "409746": 44, "409848": [42, 43], "41": [42, 43, 53, 54, 64, 65, 66, 67, 69, 71], "410124": 43, "410393": 44, "410667": 64, "410681": 46, "41072003": 67, "410795": 52, "41093655": 67, "411190": [42, 43], "411291": 56, "411295": 57, "411304": [42, 43], "411447": 54, "411582": 57, "411869": 43, "412004": 48, "412127": 57, "412477": 46, "412653": 52, "412714": 44, "412726": 43, "412838": 43, "41336": 65, "41341040": 35, "413608": 57, "413933e": 43, "414073": 8, "414533": 43, "41525168e": 67, "415465": 43, "41566": 66, "415812": 77, "415988": 54, "416132": 43, "4166": 54, "4166667": 37, "416757": 57, "416899": 42, "41702876": 66, "417640": 42, "417767": [48, 49], "417822": 53, "41798768e": 67, "418056": 57, "41805621": 57, "41836": 53, "418360": 53, "418806e": 44, "41918406e": 67, "419371": 57, "41989983e": 67, "4199952": 35, "41e5": 37, "42": [4, 5, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 54, 56, 57, 58, 59, 64, 65, 66, 67, 69, 71, 75, 77], "4200": 54, "420316e": 54, "420608e": 58, "42073312": 35, "420967": 44, "421083": 34, "4211349413": 35, "421234": 64, "421357": [48, 49], "421576e": 54, "421721": 55, "421793": 58, "421919": 54, "422007": 58, "422266": 54, "422293e": 64, "422325": 44, "42338": 54, "4235839": [48, 49], "42388745": [59, 66], "423921e": 64, "423951": 34, "424108": 44, "424127": 67, "42412729": 35, "424292": 42, "424328": 57, "424651": 66, "424700": 43, "424717": 44, "425": 52, "425072": 49, "425103": 34, "425208": 54, "425493": 34, "42550": 54, "426055": 34, "426283": 42, "426540": 52, "426540301": 35, "426736": 54, "427": 54, "427101": 42, "427486": [42, 43], "42755087": 58, "427551": 58, "427573": 52, "427725": 57, "428": [69, 71, 77], "428046": 56, "42811700": 77, "428255": 57, "428411": [53, 54], "428467": 57, "4284675": 57, "428588": 42, "428771": [13, 64], "4290": 34, "429057": 43, "429705": 42, "429986": 43, "42ba": 37, "43": [36, 42, 43, 64, 65, 66, 67, 69], "430298e": [53, 54], "430595": 43, "4311947070055128": 65, "431306": 57, "431701914": 72, "431848": 42, "431852": 43, "432125e": 53, "432300e": 57, "43231359e": 67, "432484": 42, "43294": 37, "432f": 37, "433": 37, "433221": 44, "4336": 54, "43374433": 59, "433750": 42, "4339": 34, "434519": 64, "434535": 57, "43453524": 57, "434677": 43, "435": 37, "43511": 54, "435401": 52, "4357": 54, "435927": 54, "435967": 52, "43597565": 57, "435976": 57, "436": [37, 54], "436194": 42, "43627032": 45, "436327": 54, "436806": 54, "437594": 42, "437767": 53, "437924": 54, "438": 52, "438219": 57, "438289": 54, "438569": 54, "438578e": 54, "438709": 53, "43883": 49, "4389": 54, "438960": 52, "439541": [53, 54], "43989": 64, "43e": 67, "43f0": 37, "44": [42, 43, 45, 64, 65, 66, 67, 69, 77], "440320": 54, "440364": 64, "440605": 65, "440747": 42, "440a": 37, "441153": 57, "441209": 57, "441219": 48, "4416552": 35, "441893": 42, "442202": 43, "442462": 43, "443016": 44, "443032": 53, "44312177": 36, "443686": 57, "4437": 54, "443701": 50, "444046": 54, "44408333": 58, "44414044": 58, "44427868": 58, "44435333": 58, "4444": [33, 35, 41, 66], "444500": [53, 54], "4448089": 58, "44482929": 58, "444850": 54, "4449272": 54, "445473": 42, "445476": 42, "44563945e": 67, "445642": 42, "4461928741399595": 44, "446193": 44, "4462": 37, "44647451": 58, "44713577e": 67, "447492": 54, "447624": [42, 43], "447706": 44, "447849": 45, "447999": 49, "448": 54, "448587": 44, "448745": 57, "448842": 43, "4489": 54, "44890536": 67, "448923": 50, "448973": 43, "449107": 5, "449150": [13, 64], "449406e": 42, "44950": 54, "44fa97767be8": 37, "45": [42, 43, 44, 48, 50, 53, 54, 57, 64, 65, 66, 67, 69, 77], "4500": 53, "45000000000000007": [44, 54, 57, 65], "450152": 52, "450870601": 35, "450926e": 42, "45143571": 66, "4519": 67, "452": 37, "452091": 54, "452114": 64, "452484e": 43, "452488701": 35, "452489": 52, "453": 37, "45303567": 67, "453279": 42, "4535": 54, "4539": 37, "454081": 54, "454185": 43, "454397": 57, "45467447": 67, "455": 37, "45500": 54, "455078": 44, "455091": 43, "455107": 44, "455120": 57, "4552": 37, "455293": 44, "4552b8af": 37, "45537040": 67, "455448": 58, "455672": 54, "4559565": 69, "45595650": 69, "455981": 70, "456370": [43, 52], "456432": 42, "456552": 64, "4567": 58, "456892": 44, "457088": 57, "457252": 43, "457667": 54, "458114": 54, "458420": 54, "4584447": 35, "458784": 42, "458855": 36, "458976": 43, "4592": 35, "459200": 52, "459383": 44, "45957837": 67, "459584e": 43, "459760": 54, "459812": 44, "459913": 42, "46": [42, 43, 50, 53, 64, 65, 66, 67, 69, 71, 77], "460": 54, "4601": 54, "460207": [42, 43], "460218": 44, "460289": 57, "460535": 64, "4610": 77, "461458": 43, "462321": 11, "462451": 44, "462567": 43, "462979": 42, "463325": 57, "46333547495055565862798890919293959699": 67, "4634": 54, "463668": 54, "463766": 49, "463857": 54, "463903": 43, "463b": 37, "464076": 44, "464284": 52, "46448227": 67, "464668": [9, 64], "46507214": 58, "465212699957609": 60, "4652126999576090": 60, "4652127": 60, "465832": 43, "466047": 57, "46618738": 67, "466440": 44, "466756": 57, "467": 54, "46709481": 67, "46722576e": 67, "46734623": 67, "467613": 52, "467613401": 35, "467681": [42, 43], "467770": 44, "468051e": 43, "468072": 43, "468075": 57, "46807543": 57, "46811985": 57, "468120": 57, "468406": 54, "468919": 54, "468d": 37, "469": 37, "469825": 44, "469895": 43, "47": [36, 42, 43, 45, 53, 58, 64, 65, 66, 67, 69, 76, 77], "470458": 42, "470904": 42, "47192288": 67, "472": 54, "47222159": [59, 66], "472255": 54, "4726291608": 67, "472657": 43, "472891": 57, "472e": 37, "473099": 44, "47419634": 74, "474214": [48, 49], "474731": 64, "474846": 53, "475304": 54, "475569": 42, "47659": 66, "476856": 44, "477130": [42, 43], "477150": 57, "477247": 43, "477443": 42, "477474": 52, "47759584": 67, "47761563": 45, "478032": 54, "4781": 54, "47857478": 67, "47966100e": 67, "479722": 43, "479860": 54, "479876": [48, 49], "479882": 43, "479928": 57, "47be": 37, "48": [37, 42, 43, 53, 54, 64, 65, 66, 67, 69, 77], "480133e": 57, "48029755": 58, "480579": 43, "48069071": [60, 68, 69], "480691": [68, 69], "480800e": 57, "481172": 57, "481218": 54, "481399": [53, 54], "481705": 66, "481761e": 54, "482": 37, "482012": 48, "482038": 44, "48208358": 57, "482084": 57, "482461": 70, "48246134": 70, "482483": 57, "482790": 46, "48296": 58, "48315": 58, "483186": 46, "483192": [53, 54], "48331": 58, "4835": 54, "483711": 57, "483717": 44, "48390784": 66, "483944": 42, "48404": 35, "4845": 54, "484640": 57, "4849": 37, "485": [37, 54], "485377": 42, "485617": [53, 54], "485812e": 54, "48583": [53, 54], "48584006": 66, "485871": 49, "486": [22, 54], "486202": 44, "486532": 57, "48661": 54, "487": 54, "487467": 54, "487641e": 57, "487872": 40, "488460": 54, "488485": 54, "48873663": 45, "488811": 57, "488909": [53, 54], "488982e": 44, "4895498": 57, "489550": 57, "489699": 44, "49": [37, 42, 43, 64, 65, 66, 67, 69], "490000e": 54, "490070931": 35, "490488e": 53, "490504e": 54, "490700": 57, "490941": 54, "49098": 65, "491034": 42, "491245": 52, "4915707": 66, "492": 54, "49203859": 66, "492417e": 66, "492454": 43, "492656": 43, "49270769e": 67, "493": 75, "493219": 57, "493313": 54, "493325": 4, "4934180": 67, "49361160": 67, "494089": 43, "494129": 57, "494324": 52, "494324401": 35, "495": 56, "4951206": 67, "495271": 55, "49530782": 35, "495657": 44, "495752": 57, "4958502": 60, "495850216426873": 60, "4958502164268730": 60, "49596416e": 67, "496": 56, "496248": 55, "49650883": 58, "496551": 57, "496777": 77, "497": 56, "497298": 64, "497422": 43, "497655": 5, "497674": 45, "497964": 64, "498": 56, "4985501785": 67, "498921": 57, "498979": 54, "498f": 37, "499": [54, 56, 62, 74], "499000e": [53, 54], "499083": 55, "499776": 54, "49d4": 37, "4a53": 37, "4b8f": 37, "4dba": 37, "4dd2": 37, "4e": [35, 36], "4ecd": 37, "4fee": 37, "4x": 57, "4x_0": [19, 42, 43, 48, 49], "4x_1": [19, 42, 43], "5": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76], "50": [13, 35, 37, 44, 46, 49, 51, 53, 54, 55, 57, 64, 65, 66, 67, 69], "500": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, 21, 24, 33, 37, 38, 41, 42, 43, 48, 49, 51, 53, 56, 58, 61, 62, 64, 65, 66, 68, 69, 70, 71, 74, 77], "5000": [42, 43, 44, 57], "50000": 52, "500000": [53, 54], "5000000000000001": [44, 54, 57], "50003363": 66, "500084": 57, "500267": 50, "5003517412": 35, "500517": 57, "500917": 55, "50093148e": 67, "501021": 54, "50173922": 66, "501954": 43, "501983": 57, "502054": 43, "502084": 66, "502375": 55, "502494": 44, "5025850": 35, "502595": 43, "502612": 57, "502843e": 43, "502901": 43, "502995": 57, "503504": 65, "503511": 54, "503752": 55, "50398782e": 67, "504286": 52, "5042861": 35, "504569": 42, "5050973": 35, "505913": 42, "506050": 42, "506159e": 42, "506644": 42, "506659": 54, "506687": 54, "50672034": 35, "506900e": 57, "506903": 44, "50768b": 55, "508153": 56, "508433": 42, "508459": 52, "5085": 54, "508630": 43, "508947": 66, "509059": 54, "509196": 57, "509339693389362": 60, "5093396933893620": 60, "5093397": 60, "509461": 57, "509782": 43, "5098": [38, 62, 74], "509853": 57, "5099": [37, 38, 62, 74], "509951": 44, "509958": 52, "51": [34, 36, 37, 48, 64, 65, 66, 67, 69, 76], "510000e": [53, 54], "510385": 52, "51079110": 35, "510982": 53, "511022": 64, "5112418": 67, "511293": 53, "511515": 54, "511540": 54, "511862": 57, "512": 52, "512081e": 42, "512108": 57, "512149": 57, "51214922": 57, "51243406e": 67, "512519": 52, "512572": 57, "512672": [66, 70], "51273915": 67, "512832": 42, "513052": 42, "5131": 53, "513992": 57, "514": 37, "514160": 42, "514173": 43, "514545": 54, "515031": 42, "515358": 44, "5154": 54, "5154789948092002": 52, "5155": 37, "516": 37, "516125": 44, "516222": 57, "516255": 57, "516256": 57, "516528": 57, "516888": 42, "517": [37, 52], "517266": 43, "51734627": 67, "5175": 54, "517785": 42, "518175": 52, "518446": 54, "518682": 43, "518767": 42, "518782": 54, "518846": 52, "519622": 42, "51966955": 35, "519710": 57, "519888e": 43, "52": [32, 34, 37, 50, 55, 64, 65, 66, 67, 69], "520": 54, "520641": 58, "52068983": 67, "520930": 44, "521002": 44, "521085": 64, "521611": 43, "522753": 10, "522835": 46, "523163": 44, "52343523e": 67, "523794e": 57, "523807": 56, "523977545": 35, "524088": 42, "52424539": 35, "524657": 57, "5249": 65, "524934": [42, 43], "5250": 54, "52510803": 36, "525135": 43, "525138": 42, "5255": 37, "52590": [36, 53], "526": 52, "526532": 54, "526769": [42, 43], "5273918": 67, "527452": 43, "527728": 43, "528381e": 59, "528580": 57, "528937": [48, 49], "528996901": 35, "528997": 52, "529": 52, "529405": 34, "529782": 34, "529969": 43, "53": [32, 34, 37, 62, 64, 65, 66, 67, 69, 72, 75], "530940": 57, "53094017": 57, "531": 37, "531223": 44, "531594": 54, "53209683": 66, "532266": 44, "53257": 65, "532738": 57, "53273833": 57, "532751": 48, "5329": 54, "533489": 46, "533900": 57, "5346": 37, "53512586": 67, "535179": 57, "535278991538703": 60, "535279": 60, "535318": 57, "535609": 54, "535718e": 54, "53606675": 57, "536067": 57, "536143": 54, "536746": 57, "536798e": [53, 54], "537240": 57, "53724023": 57, "538": 37, "538013": 54, "5382": 58, "538937": [53, 54], "5391581": 67, "539455": 57, "539475": 57, "53947541": 57, "539491": [48, 49], "539767": 44, "54": [34, 36, 37, 45, 61, 64, 65, 66, 67, 69, 76], "540240": 54, "540270": 43, "540542": 53, "540789": 42, "5408": 34, "541159": 57, "54163": 58, "541821": 54, "541990": 54, "542159": 43, "542333": 54, "542451": 57, "542584": 44, "5425843074324594": 44, "542647": 57, "542671": 52, "542816": 11, "5428753": 60, "54287532563466": 60, "542883": 70, "5428834": 70, "542919": 64, "542989": 57, "543": [52, 54], "543075": 44, "543136": 44, "543358": 64, "543380": 52, "5435779": 67, "5436005": 35, "543691": 43, "543764": 49, "54378": 58, "543832": 57, "544097": 57, "5443965": [68, 69], "54440": [68, 69], "544555": 52, "544669": 48, "54517706e": 67, "545602": 43, "545605e": 57, "545919": 54, "546294": 54, "5467606094959261": 44, "546761": 44, "547039": 42, "54716": 58, "547324": 43, "547431": 56, "5476": 54, "5479": 54, "547909": 54, "549109e": 54, "549645": 64, "55": [36, 37, 44, 49, 53, 54, 57, 64, 65, 66, 67, 69], "5500000000000002": [44, 54, 57], "5503807": 67, "551317": 43, "551355": 43, "551586928482123": 44, "551587": 44, "551686": 44, "55173": 65, "5518": 54, "552": 54, "552058": 58, "552508": 54, "552727": 52, "552776": 57, "55321": 67, "55348": 65, "553878": [12, 64], "553916": 54, "553965": 42, "554076": 44, "554203": 43, "554793e": 67, "555": 52, "555137": 43, "555150": 54, "555445": 56, "555498": 57, "5555": [33, 41], "555536": 42, "555949e": 54, "555954": 54, "556191": [42, 43], "556792": 57, "557267": 42, "5574dcd4": 37, "557595": 52, "557731": 56, "557999": 52, "558134": [42, 43], "5584": 52, "5585": 52, "558655": 44, "5589": 52, "559": 77, "5590": 52, "559144": 44, "559186": 44, "5592": 52, "559394": 57, "559522": 57, "559680": 54, "55dc37e31fb1": 37, "55e": 36, "56": [37, 61, 64, 65, 66, 67, 69, 72, 75], "560135": [68, 69], "56018481": 57, "560185": 57, "5602727": 45, "560545e": 42, "560689": 34, "561183e": 43, "5616": 53, "561711": 54, "561785": 66, "561819": 42, "562001": 43, "562013": 57, "562153": 42, "56223": 58, "562518": 54, "5625561": 34, "562557": 42, "562712": [42, 43], "563374e": 44, "563503": 57, "563528": 54, "563673": 54, "563851e": 42, "56387280e": 67, "56390147e": 67, "564": 32, "564045": 57, "564073": 54, "5641": 54, "564142": 44, "564232": [42, 43], "564451": 43, "564537": 43, "564577": 54, "565066": 44, "566024": 57, "566091": 54, "567004": 58, "567343": 54, "567364": 43, "567529": 57, "567531": 42, "567568": 42, "567695": 42, "567945": [48, 49], "568111": 64, "569135": 43, "569540": 43, "56965663": 57, "569657": 57, "569684": 43, "569911": 35, "5699994715": 35, "57": [37, 64, 65, 66, 67, 69, 77], "570038": 44, "5700384030890744": 44, "570111": 56, "5702": 54, "570486": 34, "570562": 34, "570722": 74, "570936": 42, "571707": 64, "571778": 34, "5718": 54, "572153": 64, "5722": 53, "57245066": 57, "572451": 57, "572991": 43, "573700": 46, "574": 37, "57474": 67, "574904": 43, "57496671": 35, "575": 15, "57505": 65, "575810": 42, "57592948e": 67, "576": [37, 55], "5763623": 67, "5763996": 35, "576631e": 67, "577": 37, "5770": 53, "57715074": 35, "577271": 52, "577422": 42, "577807": [42, 43], "577813": 42, "578081": 54, "5781019212330313446515460677174788697": 67, "578307": 57, "578523": 52, "578557": 43, "578846e": 44, "57914935": 36, "579238": 44, "579322e": 53, "579605e": 43, "57e": 36, "58": [36, 53, 64, 65, 66, 67, 69, 76], "5800": 54, "58000": 53, "580231e": 43, "580368": 42, "5804": 37, "580477e": 43, "580922": 48, "581655": 54, "581849": 43, "581868": 42, "582146": 43, "58241568": 67, "582747": 43, "582761": 44, "58303": 55, "583034": 48, "583195": [42, 43], "5832693": 67, "5833333": 37, "583404": 53, "583508": 42, "583534": 57, "584012": 54, "584742": 49, "584849": 44, "584877": 43, "584928": 42, "584942e": 52, "5852": 54, "585426": 67, "585793": 44, "586362": 57, "5864": 34, "5866": 54, "586719": 44, "586719493648897": 44, "5868472": 35, "587135": 43, "587292": 54, "58765": 65, "588": 54, "588000": 64, "588364": 64, "588992e": 43, "589248": 58, "589440": 44, "59": [64, 65, 66, 67, 69], "590320": 46, "5905": 53, "590736": 57, "590813": 57, "590911": 44, "590991": 44, "591080": 46, "591411": 48, "591441": 2, "591741": 53, "591782": 57, "591788": 53, "59199423e": 67, "592186": 43, "5925244": 67, "592681e": 44, "59307502e": 67, "593648": 65, "593754e": 49, "5937716": 67, "593981": 64, "594": 15, "5940229": 67, "594241": 64, "5942743": 67, "594316e": 57, "595353": 44, "596": 54, "596069e": 54, "5962": 53, "596270": [48, 49], "596758": 42, "597": 36, "597098": 54, "597923": 54, "598080": 42, "598178": 54, "598539": 43, "5985730": 36, "5985872": 67, "59861": 54, "5987": 51, "5cb31a99b9cc": 37, "5d": [44, 57], "5x_2": 46, "5x_3": 46, "5z_i": 57, "6": [2, 4, 5, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 22, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76], "60": [35, 44, 45, 54, 55, 57, 59, 64, 65, 66, 67, 69, 75], "600": 52, "6000": 54, "6000000000000002": [44, 54, 57], "600000e": 54, "600254": 56, "600438": 50, "600694": 66, "600934": 64, "601": 36, "601061": 44, "601149": 42, "601314": 42, "601598": 52, "601645": 43, "602079": 49, "602168": 44, "602587": 57, "602628": 44, "6029": 54, "603273": 42, "6035213": 67, "604": 32, "604016": 54, "604111": 54, "604227": 53, "604603": 5, "604825": 54, "604841": [53, 54], "605": 54, "605195": 49, "606034": 57, "606129": 57, "606342": 44, "606759": 54, "6068": 35, "606800": 52, "606954": 44, "607080": 43, "607264": 42, "6075": 77, "607600": 54, "608": 47, "608003e": 43, "608392": 57, "60857": 34, "608818": 58, "609205": 42, "609575": 66, "6099365": 67, "61": [64, 65, 66, 67, 69, 76], "610195e": 42, "610559": 43, "611": 77, "6110": 54, "611269": 52, "611859": 49, "612151": 43, "612792": 54, "6133": 36, "613314": 44, "613408": 57, "613498": 54, "613574": 50, "613622": 43, "613691": 66, "614185e": 43, "614188": 52, "614678": 54, "615498": 2, "615573e": 43, "615574": 43, "615863": [48, 49], "61669761": 70, "616698": 70, "616797": 43, "616828": 54, "617": 52, "617283": 54, "6173": 37, "617800": 43, "617877": 57, "618069": 53, "61810738": 36, "618256": 43, "61827": 67, "618776": 45, "618922e": 42, "619128": 43, "619177": 53, "619351": [42, 43], "619390": [42, 43], "619454": 46, "619613": 53, "61e": [36, 77], "62": [2, 50, 64, 65, 66, 67, 69], "620156": 57, "620407": 42, "620874e": 66, "620995": 59, "621094": 54, "621318": 57, "62131806": 57, "621490": 57, "6215": 53, "622": 54, "622153": 54, "622301": 42, "6224": 35, "622949": 42, "623024": 44, "623147": 49, "623173": 42, "623197": 53, "623681e": 69, "623726": 67, "624": 52, "6240": 58, "62403053": 45, "624224e": 42, "6243811": 35, "624482e": 42, "624535": 65, "624798": 53, "624919": 54, "624988": 54, "625": [35, 52], "625477": 57, "625766": 48, "625891": [48, 49], "626433": 57, "6264607": 67, "6266": 54, "626633": 43, "627505": [48, 49], "627560": 57, "627564": 44, "627588e": 54, "628069": 52, "629306": 43, "629346": 54, "629549": 43, "629771": 43, "63": [35, 52, 64, 65, 66, 67, 69, 75, 76], "630150e": 57, "630914": 50, "631333": 57, "6318": [53, 77], "631821": 43, "632058": 52, "63245862e": 67, "632747e": 57, "6328366": 69, "632958": 56, "633350": 43, "633433": 52, "634055": 42, "63407762": 77, "634078": [53, 77], "634577": 69, "63499": 54, "635000e": [53, 54], "635199": [53, 54], "635296": 50, "636048": 66, "636453": [9, 64], "636575": 44, "637326": 57, "6379": 53, "638264": 57, "638742": 43, "638888": 50, "639135": 52, "63916605": 36, "639345": 54, "639580": 43, "63e": 67, "64": [43, 51, 53, 54, 55, 64, 65, 66, 67, 69, 74], "640": 54, "640900": 54, "641": 32, "641528": 57, "641547": 57, "64154727": 57, "64197957": 57, "641980": 57, "6420": 54, "642016": 57, "64269": 58, "642735": 53, "643133": 54, "64340": 58, "643512": 44, "643752": 57, "644113": 64, "644182": 64, "644665": 44, "64476745e": 67, "644799": 46, "644985": 42, "645": 54, "64579": 34, "6458": 35, "645800": 52, "646937": 46, "646997": 42, "647002": 54, "647004": 66, "647010": 54, "647196": 46, "64723": 58, "647873": 57, "64797": 58, "649": 75, "649158": 57, "649891": 43, "65": [44, 50, 51, 54, 57, 64, 65, 66, 67, 69], "650": 47, "6500000000000001": [44, 54, 57], "650000e": 54, "650802": 43, "650810": 54, "650867": 44, "651127": 43, "652071": 54, "6522": 75, "652312": 48, "652349": 57, "652350": 52, "652450e": [53, 54], "6527": 47, "652778": 52, "6528": 54, "6530": 54, "653820": 64, "653846": 44, "653901": [42, 43], "653991": 64, "654070e": 66, "654755": 46, "655284": 57, "6553": 77, "6554": 75, "655422": 54, "655547": 42, "65557405e": 67, "656526": 43, "657": 37, "657024": 42, "657470": 43, "658": 52, "658267": 57, "6586": 34, "658702": 43, "659": 37, "659245": [42, 43], "659339": 43, "6593871": 34, "659423": [42, 43], "659605e": 42, "659636": 44, "66": [55, 64, 65, 66, 67, 69, 74, 76], "660": 37, "660320": 49, "660479": 66, "660776": 57, "661369": 56, "661388": 42, "661391": 50, "66184": 66, "6625": 54, "663081975281988": 44, "663082": 44, "663182": 44, "663529": 57, "663533": 54, "664103e": 54, "664147": 54, "66425477": 67, "664276": [64, 65, 66], "664824": 54, "664850": 52, "665264": 57, "665554": 42, "665585": 43, "666104": 57, "666259": 43, "666307": 46, "6666667": 37, "666865": 42, "666912": 43, "667": 52, "667492e": 54, "667536": 57, "667614": 44, "667614205604159": 44, "668337": 54, "668452": 50, "668584": 46, "668981": 48, "6695": 66, "66989604": 45, "67": [32, 37, 42, 53, 55, 64, 65, 66, 67, 69, 74], "670867": [13, 64], "671271": [42, 43], "67136": 54, "6716717587835648": 44, "671672": 44, "671690": 42, "6722": 37, "672234": [42, 43], "672368": 44, "6723684718264447": 44, "672384": [42, 43], "67245350": 35, "673092": [42, 43], "673302": 52, "673586": 42, "67410934": 35, "6745349414": 35, "674552": 54, "674609": 44, "674936": 43, "674949e": 58, "675293": 56, "675625": 64, "675733e": 43, "676405": 44, "6765": [36, 53], "676534": 69, "676756": 57, "676807": 53, "677614": 57, "677980": 44, "678": 32, "678117": 54, "678369": 43, "678826": 44, "6795": 53, "679539": 52, "67ad635a": 37, "68": [37, 55, 58, 64, 65, 66, 67, 69], "680": 54, "680620": 43, "6810775": 58, "681176": 52, "681246": 43, "681448": 54, "681521": 42, "681562": 54, "681817dcfcda": 37, "682269": 54, "682353": 43, "682631": 43, "682875": 44, "683487": 43, "683581": 66, "683942": 57, "683984": 10, "684": 77, "68410364": 36, "68411700": [36, 77], "684142": 42, "684502": 57, "685104": 4, "685107": 57, "68554404e": 67, "68562150e": 67, "685807": 57, "686627": 42, "687345": 57, "687619": 43, "687647": 57, "687854": 46, "687871": 52, "6878711": 35, "688": 75, "688747": 54, "688918": 54, "689088": [42, 43], "689188": 46, "689392": 57, "6899154": 67, "69": [50, 55, 64, 65, 66, 67, 69, 76], "690334": 44, "6903344145051182": 44, "690668": 43, "690796e": 43, "691136": 64, "691157": 45, "69140475e": 67, "691423": 42, "691511": 53, "691814": 42, "691911": 64, "692199": 43, "692297": 43, "692465": 43, "692725": 57, "692907": 54, "693316": 54, "693497e": 54, "693513": 43, "693632": 42, "693690": 54, "693796": 52, "694154": 44, "694839": 43, "694845e": 54, "694919": 52, "6950": 54, "695045": 42, "695581": 50, "69562150e": 67, "696011": [12, 64], "696289": [48, 49], "696770": 64, "697": 52, "697000": 44, "697089": 42, "697420": [48, 49], "697545": 57, "697616": 43, "698223": 46, "698244": 46, "69840389e": 67, "698509": 42, "698694": 52, "699035": 57, "699082": 44, "69921": 37, "699259e": 57, "699333": 44, "6_design_1a": 47, "6_r2d_0": 47, "6_r2y_0": 47, "6b": [69, 71], "6cea": 37, "7": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 24, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 75, 76], "70": [36, 44, 48, 53, 54, 57, 64, 65, 66, 67, 69, 76], "700": [42, 43, 47, 52], "7000000000000002": [44, 54, 57], "700015": 57, "700102": 57, "701078": 57, "701088": 53, "701265": 48, "701413": 54, "701672e": 44, "701866": 57, "7018663": 57, "701966": 54, "702489": 54, "703049": 42, "703772": 54, "703942": 64, "7040": 54, "704814": 42, "705090": 43, "705354": 42, "705419e": 67, "705456": 42, "705474": 49, "705581": 54, "70583": 58, "706056": 54, "706231": 64, "706645": 44, "706657": 44, "706862": 5, "707125": 43, "707197": 64, "707738": 43, "707868": 57, "707963e": 53, "708190": 52, "708235": 42, "708459": 57, "708465": 43, "708695": 60, "708695026860755": 60, "7086950268607550": 60, "709026": 46, "709596": 42, "709606": [13, 64], "71": [64, 65, 66, 67, 69, 76], "710586e": 52, "711024": 54, "711328": 54, "711518": 54, "711638": 66, "711834": 43, "712082": 54, "712157": 56, "712503": 58, "712592": 53, "712774": 48, "712960": 44, "713": 54, "713407": 54, "713457": 42, "713959": 43, "713986": 54, "714240": 52, "714557": 43, "714651": 57, "71465114": 57, "715013": 54, "715075e": 42, "715180e": 54, "7154": 54, "715407": 44, "7155": 54, "715515": 43, "7158581": 35, "7161": 54, "716316": 42, "716387": 42, "716456": 57, "716595e": 54, "716762": 44, "716793": 44, "716799": 52, "7167991": 35, "717": 54, "717130": 54, "717185": 57, "717860": 64, "719645545": 67, "72": [64, 65, 66, 67, 69, 76], "720559": 42, "720571": 57, "720573": 42, "720664": 52, "721018": 42, "721071": 57, "721245": 43, "7215093d9089": 37, "72155839e": 67, "721609": 54, "722316": 57, "722634": 57, "722848": 44, "722881": 57, "7229": 54, "723": 37, "723314": 57, "723345e": 57, "7239": 54, "7241399": 35, "724338": 57, "724603": 42, "724767": [48, 49], "725": 37, "725087": 54, "725166": 57, "725802": 5, "725820": 43, "726": 37, "7268131": 35, "727543": 46, "727693": 54, "727704": 54, "727976": 44, "7282094": 66, "728294": 56, "728438": 55, "728710": 57, "72875815e": 67, "728852": 54, "73": [36, 64, 65, 66, 67, 69], "730023": 54, "7308": 34, "730884e": 43, "731317": 44, "732067": 42, "732405": 53, "732586": 53, "7326": 54, "732638": 57, "73285": [9, 64], "732918": 48, "733": 54, "733047": 43, "733644": 42, "734635": 42, "734689": 42, "734770": 43, "734948": 57, "735048": 43, "735054": 43, "735369e": 64, "735656": 42, "7357": 54, "735848": 64, "735941": 8, "735964": 46, "736001": 42, "736082": [42, 43], "736084": 57, "73608412": 57, "736823": 43, "737052": 54, "7375615": 36, "73764317e": 67, "737694e": 42, "737951": [42, 43], "738065": 43, "738223": 54, "738315": 54, "738659e": 54, "7387266": 67, "738793": 64, "739": 54, "7395359436844482": 44, "739536": 44, "739720": 54, "739817": 50, "74": [36, 53, 64, 65, 66, 67, 69, 76], "740": [52, 53], "740180e": 57, "740417": 53, "740869": 44, "741104": 44, "741702": 57, "7418": 34, "74189": 37, "742128": 57, "742375": 42, "742407": 56, "742758e": 43, "742907": 57, "743247": 54, "743341": 43, "7437": 54, "7440": 34, "74402577": 57, "744026": 57, "744228": 43, "744236": 58, "74461783e": 67, "745": 54, "745444": 42, "745714": 53, "745881": 42, "746361": 57, "746843": 49, "747": 55, "7470": 54, "747646": 54, "747945": 35, "747961": 54, "748377": 53, "748513": 54, "748880": 54, "74938952": 66, "749443": 54, "749540": 42, "75": [13, 18, 37, 42, 44, 46, 53, 54, 57, 64, 65, 66, 67, 69, 71, 76], "7500000000000002": [44, 54, 57], "750000e": 54, "750571e": 43, "750597": 43, "751013": 54, "751261": 54, "751482e": 49, "751633": 54, "75171": 53, "751710": [44, 53], "752015": 7, "752283": 54, "7533": 53, "753393": 42, "753523": 57, "753866": 43, "754448": 42, "754710": 42, "754870": 52, "754927": 55, "755": 53, "755688": 42, "755717": 42, "755910": 54, "7559417564883749": 44, "755942": 44, "7560824": 35, "756647": 42, "756775": 55, "756805": 52, "756867e": 54, "756905": 5, "756969": 44, "757": 75, "757151": [42, 43], "757183": 44, "757411": 57, "7578": 51, "757819": 52, "757917e": 57, "758391": 54, "75887": 37, "759006": 45, "759833": 43, "76": [64, 65, 66, 67, 69, 75, 76], "760104": 57, "7603": 34, "760386": 66, "760494e": 43, "760778": 52, "760915": 46, "761": [35, 52], "761429": 43, "761714": 44, "762237": 42, "762284": 57, "76228406": 57, "762748": 54, "763219": 42, "763691": 54, "764": 55, "764093": [42, 43], "76419024e": 67, "764315": 57, "76444177e": 67, "764478": 56, "7646": 54, "764798": 57, "764953": 53, "765": 53, "765202": 54, "765363": [42, 43], "765500e": [53, 54], "765710e": 59, "765792": 57, "765864": 58, "76591188": 35, "7663": 54, "766499": 57, "766850e": 43, "76702611e": 67, "767188": [48, 49], "767247": 64, "767349": 64, "768071": 57, "768273": [48, 49], "7683": 51, "768331": 43, "769290": 42, "769361": 57, "769805": 57, "77": [64, 65, 66, 67, 69], "770556": 54, "7707": 34, "770944": [48, 49], "7710": 58, "771157": 69, "771390e": 54, "7714": 55, "7716982": 36, "771741": 54, "771965": 54, "772": 55, "772253": 43, "77227783e": 67, "772291": 42, "7725630": 67, "772791": 54, "77289874e": 67, "773": 37, "7731": 51, "773177": 44, "773488": 57, "77348822": 57, "77401500e": 67, "774253": 42, "774271e": 54, "775": [37, 54], "775191": [42, 43], "7752": 34, "775969": 58, "7763": 53, "776728e": 52, "776887": 53, "7776071": 35, "777728": 64, "777994": 55, "778": 32, "778852": 64, "779167": 2, "779185": 42, "779350": 42, "779517": [42, 43], "779682": 44, "779912": 54, "78": [43, 64, 65, 66, 67, 69, 76], "780": 37, "780120": 43, "780458": 57, "780857": 53, "780887e": 42, "781": 54, "7811465543": 68, "781233": 54, "781415": 55, "781530": 57, "781681": 57, "782": 37, "782050": 57, "782555": 54, "782646": 64, "782913e": 67, "783": 37, "7831243849": 60, "783124384910379": 60, "7831243849103790": 60, "783276": 66, "7833": 34, "7838": 34, "784": [69, 71], "784066": 43, "784238": 52, "784341": 42, "784405": 58, "784483": 52, "784624": 44, "785": 37, "785038": 43, "785911": 57, "786": 37, "786744": 44, "78711285e": 67, "78729182": 67, "787396": 42, "787716": 42, "78777": 58, "788": 75, "78818": 37, "788400": 43, "789671": 44, "789671060840732": 44, "79": [64, 65, 66, 67, 76], "790115": 54, "790261": 64, "790314": 42, "790723": [48, 49], "79122": 53, "791220": 53, "791241": 57, "791297": [13, 64], "791529": 42, "792534": 55, "792939": 44, "793": 66, "793316": 64, "79338596e": 67, "793570": 57, "793735": 57, "793818": [42, 43], "794366": 54, "794526": 42, "79458848e": 67, "794805": 48, "795558": 43, "795647": 57, "7957": 54, "795932": 65, "796": 32, "796014": 43, "796220": 43, "796384": 43, "796444": 54, "797280": 57, "797737": 69, "79792890e": 67, "797965": 69, "798071": 4, "798309": 53, "798783": [48, 49], "799403": 57, "799422e": 67, "7999": 59, "7b428990": 37, "7x": 57, "8": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 76, 77], "80": [44, 45, 54, 57, 59, 64, 65, 66, 67, 76], "800": 52, "8000": [26, 59], "8000000000000002": [44, 54, 57], "800272": 64, "800351": 42, "800854": 42, "801623": 54, "802289": 54, "8027842": 67, "803300": 42, "803492e": 57, "803563": 54, "803902e": 54, "804": 54, "804081e": 43, "804219": 57, "804284": 58, "804316": 57, "804484": 57, "8047": 34, "8048": 36, "804828": 57, "804889": 54, "805007": 52, "805153e": [53, 54], "8055563": 35, "805774": 42, "8059": 53, "805962": 42, "806218e": 54, "806531": 54, "806554": 42, "806964": 43, "80696592e": 67, "80714504e": 67, "807879": 57, "808": [36, 69, 71], "808246": 53, "808284": 54, "808640": 54, "8095": 55, "809913": [42, 43], "80a8": 37, "81": [35, 47, 50, 64, 65, 66, 67, 76], "810044": 53, "810134": 57, "8102": 53, "810363": 54, "810382": [53, 54], "810707": 54, "811155": 50, "811398": 64, "8116912": [69, 71], "811696": 42, "811825": 52, "811901": 57, "81190107": 57, "812": 32, "812201e": 55, "812311": 42, "812484e": 42, "8132463": 35, "813293": 57, "813342": [69, 71], "813682": 54, "814136": 44, "814351": 44, "814410": 42, "814913": 52, "8152": 54, "815224": [69, 71], "815226": 66, "815574": 43, "81568484": 57, "815685": 57, "815783": 55, "815993": 57, "816318": 52, "816752": 54, "817291": 54, "81827267": 57, "818273": 57, "818289": 57, "81828926": 57, "818380": [42, 43], "81856": 37, "818590": 42, "82": [64, 65, 66, 67, 76], "8202": 36, "820366": 52, "8209": 36, "8210": 36, "821021": 44, "821457": 54, "821566": 57, "821855": 64, "821870": 43, "8221": 34, "822289": [53, 77], "82228913": 77, "822482": 44, "82261299": 51, "8227": 54, "822822": 44, "823247": 57, "823273": [42, 43], "823769e": 42, "824350": [42, 43], "824701": 44, "824750": 44, "824889": 44, "824961e": 54, "8250": 34, "825140": 42, "825617": 52, "825824": 43, "825862": 57, "825980": 44, "8259803249536914": 44, "8260": 53, "826065": [42, 43], "826215": 43, "826391": 43, "826426": 66, "826492": 57, "826519": [13, 64], "82666866e": 67, "826829": 42, "82684324": 58, "827192": 42, "827234": 42, "827375": 45, "827381": 57, "827438": 42, "827735": 57, "827938162750831": [48, 49], "828": 32, "828058": 54, "828915": [48, 49], "829162": 64, "829543": 44, "829619": 43, "82985": 50, "83": [64, 65, 66, 67, 76], "830301": 56, "830755e": 50, "831019": 44, "831741": 42, "832086": 57, "8326928": 58, "832693": 58, "832844": 43, "832875": 57, "83287529": 57, "833024": 52, "833117": 42, "833227e": 65, "833464": 54, "833781": 42, "833907": 52, "834092e": 67, "8350": 54, "835125": 43, "835596": 54, "836234": 66, "836515": 43, "837680": 42, "838006e": 43, "838114": 57, "838235": 55, "838457": 54, "839032": 55, "83905": 4, "84": [37, 64, 65, 66, 67, 76], "840041": 54, "840303": 57, "84030318": 57, "840630": 42, "840673": 42, "840718": 66, "840836": 57, "840995e": 53, "841": [35, 52], "841132": 53, "8415": 36, "841847": 54, "842132": 66, "842405": 44, "842444": 42, "842625": 52, "842746": 57, "842770e": 43, "8428": 53, "842853": 57, "842859": 43, "842901": 43, "843730": 52, "843796": 42, "8440": 54, "844122": 55, "844308": 57, "844549": [48, 49], "844667": 69, "844707": 57, "844889": 52, "845059": 43, "845502": 55, "846388": 44, "847555": 42, "847595": [12, 64], "847948": 44, "847966": 54, "848757e": 53, "848868": 44, "84930915e": 67, "849747": 58, "8497f641": 37, "8499": 54, "85": [21, 44, 50, 54, 57, 59, 64, 65, 66, 67], "8500000000000002": [44, 54, 57], "850321": 52, "850439": 43, "850575": [42, 43], "850794": 57, "851198": 54, "8513": 37, "851366": 52, "852": [32, 54], "85280376": [2, 4, 5, 7, 8, 9, 10, 11, 12], "853177": 51, "85397773": 66, "855199e": 42, "855780": 57, "856117": 42, "856404": 49, "8571": 34, "857161": 57, "857544": 52, "857765": 54, "858579": 43, "859": 54, "85901669": 67, "85911521e": 67, "85912862": 69, "859129": [68, 69], "85974356": [2, 4, 5, 7, 8, 9, 10, 11, 12], "85c5": 37, "85e": 36, "86": [64, 65, 66, 67, 76], "860261": 43, "860663": [69, 71], "860804": 57, "860992": 54, "861755": 50, "862043": [48, 49], "862359": 44, "863687": 42, "863772": 53, "86415573": 36, "86424193e": 67, "8644": 37, "8646627426": 68, "864741e": 54, "865284": 42, "865313": 54, "865540": 43, "865562": [42, 43], "865854": 54, "865860": [53, 54], "866102": [42, 43], "866579": 54, "866798": 54, "8670337521": 60, "867033752141195": 60, "867565": 57, "8679": 54, "868": 37, "8685788": 57, "868579": 57, "8688": 53, "869": 37, "869020": 44, "869136": 43, "869425": 49, "869477": 42, "869586": 50, "869651": 43, "87": [36, 49, 50, 52, 64, 65, 66, 67, 76], "870": 55, "8700": 36, "870099": [48, 49], "870185": 43, "870260": 57, "870332": 57, "870857": 57, "871": 37, "871887e": 43, "871923": 43, "872222": 54, "872768": 57, "872852": 57, "87290240e": 67, "872994": 54, "873048": 43, "873198": 54, "873677": [48, 49], "87384812361": 34, "87384812362": 34, "873972": 42, "87430335": [69, 71], "874303353": [69, 71], "874702": [48, 49], "8750": 54, "8759": 54, "876080": 42, "876083": 54, "87623301": 34, "876431e": 44, "876549": 54, "8766091": 67, "87674597e": 67, "8768": 34, "8771": 54, "877153": 54, "877455": 56, "877833": [42, 43], "878281": 57, "878289": 54, "878402": 42, "878847e": 54, "879049": 54, "879103": 44, "87e": 36, "88": [36, 50, 64, 66, 67], "880106": 52, "880202e": 43, "880579": 57, "880591": 56, "880808e": 54, "880880e": 54, "880886": 53, "8810": 53, "881201": 54, "88125046e": 67, "881465": 46, "881581": 8, "88173062": 35, "882475": 44, "883485": 43, "883622": 57, "883778": 43, "883914": 44, "884132": 57, "8843": 58, "884996": 44, "8850": 36, "885065": 57, "885978": [48, 49], "886041": 43, "886086": [42, 43], "886266": 54, "88629": 34, "886577": 43, "88664": 37, "886771e": 42, "886777e": 43, "886989": 43, "887345": 54, "887556": 44, "888146": 52, "8881461": 35, "888775": 49, "888804": 54, "888863e": 42, "889293": 57, "8893": [34, 53], "889300": 53, "889326": 43, "889733": 57, "88988263e": 67, "889913": [42, 43], "889963": 57, "88ad": 37, "89": [36, 43, 64, 66, 67, 75, 76], "890": [35, 52], "89027368": [69, 71], "890273683": [69, 71], "89035917": 50, "890372": [38, 62, 74], "8903720000100010000010": [37, 62, 74], "8904": 32, "890454": 65, "8909": [35, 53, 77], "891697": 53, "892": 37, "892331": 43, "892648": 57, "892796": [42, 43], "893": 37, "8932105": 35, "893649": [42, 43], "893851": 57, "894": [37, 55], "894307e": 54, "89449": 53, "894490": 53, "894609e": 42, "895106": [42, 43], "895308": 54, "895333": 57, "895690": [42, 43], "895768e": 44, "896023": 57, "896681e": 43, "896758": 42, "897220": 57, "897240": 54, "8974": 53, "898722": 57, "899460": 57, "899716": 43, "8bdee1a1d83d": 37, "8da924c": 37, "8e3aa840": 37, "9": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 76, 77], "90": [22, 36, 44, 45, 54, 57, 59, 64, 66, 67, 76], "9000000000000002": [44, 54, 57], "900000e": 54, "900021": 65, "901013": 43, "901148": 57, "90136": 53, "901360": 53, "901683": 54, "902": [69, 71], "902573": 44, "903056e": 57, "903135": 64, "903339": 44, "903351e": 44, "903418": 52, "903681": 57, "903767": [42, 43], "904156": 44, "9041560442482157": 44, "904315": 42, "905": 55, "905042": 43, "905494": 44, "905951": 58, "905998": 49, "906073": 43, "9061": 54, "906716732639898": [48, 49], "906757": 40, "906864": 42, "907115": 57, "907130": 42, "907176": 57, "907198": 43, "9073": 54, "907491": 44, "907702": 42, "907801": 52, "90794478": [69, 71], "907944783": [69, 71], "907961": 54, "908620": 42, "909141": 43, "909304": [42, 43], "90963122e": 67, "909752": 43, "909942e": 64, "909975": 54, "909997": [53, 77], "91": [64, 65, 66, 67, 76], "910000e": 54, "9102": 53, "910895": 43, "9109": 37, "910991": 42, "91102953": 57, "911030": 57, "911662": 48, "912230": [42, 43], "9126": [36, 77], "9127": [36, 77], "913": [37, 55], "91315015": 35, "913285": 42, "913485": 54, "913774": 44, "9140792": 67, "9142": 54, "91438767e": 67, "9145": 34, "915": [36, 37, 53, 54], "915000e": [53, 54], "915057e": 53, "915488": [48, 49], "916": 55, "916236": 34, "916528": 48, "9166667": 37, "916806": 43, "916914": 57, "917": 37, "917066": 54, "917248": 57, "91724807": 57, "917436": 57, "918104": 42, "918227": 44, "918747": 43, "919432": 57, "9197": 54, "919814": 42, "91e": 36, "92": [64, 66, 67, 76], "920335": 54, "920337": 49, "920439": 42, "920645": 54, "9209": 34, "921": 32, "9210": 54, "921372": 44, "921913": 52, "921956": [42, 43], "921e4f0d": 37, "922160": 54, "922201e": 42, "9223": 54, "922996": 52, "923074e": 44, "923517": 59, "923607": 57, "92369755": 35, "923804": 44, "923943": 77, "923977": 54, "924002": 57, "9243": 54, "924396": [48, 49], "92463": 53, "924630": 53, "924634": 46, "9248": 37, "924821": 44, "924843": 52, "924921": 64, "925": 45, "925248": [48, 49], "925660": 42, "925736": 44, "925957": 48, "926493": 53, "926621": 44, "927": 33, "927074": 57, "927232": 54, "9274": 54, "927950": 54, "92827999": 66, "92881435e": 67, "928947": 52, "92905": 35, "929363": 42, "929552": 42, "929598": 43, "92972925e": 69, "929729e": [68, 69], "93": [36, 64, 65, 66, 67, 76], "9304028": 35, "930417": 42, "931": 61, "931479": 57, "931507": 42, "931978": 74, "932027": 44, "932404e": 54, "9327": 34, "932973": 57, "933322": 43, "933996": 44, "934433": [42, 43], "9345": 37, "934511": [69, 71], "934549": 54, "934992": 44, "935": 51, "935591": 57, "935730": 57, "935989": 52, "9359891": 35, "93648": 59, "936739": 57, "937116": 52, "9374": 34, "937586": 54, "937857": 42, "938": [32, 69, 71], "938975": [64, 65, 66], "939068": [48, 49], "9392": 54, "939250": 42, "9395": 54, "93958082416": 77, "94": [45, 51, 64, 66, 67, 76, 77], "940354721701296": 44, "940355": 44, "940373": 54, "941440": 42, "941724": 54, "941788": 48, "942139": 49, "942312": 57, "942460e": 57, "942489": 54, "9425": 34, "942550": 54, "942661": 52, "942823": 54, "94309994e": 67, "943200": 42, "943270": 42, "943465e": 42, "943938": 57, "943949e": 57, "944149": 64, "944253e": 57, "944266": [48, 49], "944280": 54, "94441007e": 67, "945": 55, "945402e": 42, "945417": 42, "945881": 42, "94629": 59, "946297": 44, "946406": 49, "946433": 57, "946533": 42, "946658": 54, "946968": 44, "947440": 56, "947466": 65, "947613": 43, "9480": 54, "948154e": 48, "948344e": 43, "948868": 54, "94906344": 35, "949241": [69, 71], "949456": 57, "949866": 43, "95": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 36, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 57, 58, 59, 64, 66, 67, 69, 70, 76, 77], "9500": 54, "950131e": 43, "950545": 40, "95062986e": 67, "951115": 43, "951415": 42, "951502": 57, "951532": 52, "951550": 43, "951920": 56, "952": [36, 77], "9523": 34, "952839": 57, "9534": 54, "953683": 52, "95372559e": 67, "954": [69, 71], "95401167e": 67, "954536": 64, "955": 32, "955005e": 54, "9551": 54, "9552": 34, "955541": [13, 64], "95559917": 65, "955701": 42, "955926": 43, "956047": 35, "9561": 34, "956110": 43, "956217": 42, "956574": 54, "956724": 44, "9567242535070148": 44, "95676375": 67, "956892": 54, "957375": 52, "957437": 42, "957745": 44, "9579": 36, "957996": 44, "958": [69, 71], "9580": 36, "958105": 64, "958541": 54, "959": 55, "959132": 43, "95e": 36, "96": [36, 42, 43, 50, 55, 64, 66, 67, 76], "960074": 42, "9605": 54, "960808": 44, "960875e": 43, "9609": 34, "961360": 43, "961539": 54, "961962": 44, "963051": 43, "963055": 54, "963389": 42, "964025e": 57, "964261e": 52, "964318": 54, "9647": 34, "965341": 43, "965531": 66, "965696": 42, "965774": 54, "96582": 65, "966015": 57, "966659": 44, "9666592590622916": 44, "967467": 58, "968134e": 57, "968577": 45, "968800": 42, "9699": 53, "97": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77], "970065": 57, "9702712": 67, "971": 32, "971058": [48, 49], "971724": 42, "972088e": 42, "972509": 43, "972732": 43, "972748": 44, "97276281": 57, "972763": 57, "97314470": 35, "973156": 64, "973229": 43, "973241": 57, "973262": 42, "973331": 54, "973392e": 42, "973741": 43, "974202": 44, "974213": 43, "97441062": [48, 49], "974414": 44, "97470872": 58, "9748910611": 35, "974898": 55, "975": [42, 43, 48, 49, 51, 55], "975232": 43, "9753": 37, "975447": 45, "975450": 43, "975461": 52, "975957e": 43, "976088": 57, "976562": 57, "977280": [42, 43], "977295": 54, "977507": 43, "978554": 42, "9787": 54, "978977": 57, "979857": 42, "979896": 43, "98": [42, 43, 54, 55, 64, 66, 67, 76], "980": 55, "980026": 54, "9802393": 35, "980256e": 42, "980643e": 44, "981104": 56, "981438": 42, "981672": 44, "982353e": 54, "982417": 44, "982720": 42, "982797": 56, "982986e": 42, "983192": 57, "983253": 42, "983759": 77, "983896": 42, "98393441": 58, "984024": 56, "984083": [48, 49], "984551": 7, "984562": 57, "984821": 42, "984866": [69, 71], "984872": [42, 43], "984937": 44, "98505871e": 67, "985207": [42, 43], "986383": 54, "986417": 42, "9870004": 37, "987220": 54, "987329": 43, "9875": 34, "9880384": 37, "988421": [42, 43], "988463": 57, "988690": 43, "988709": 54, "988780": 54, "989291": 42, "989372": 50, "989872": 55, "989908": 55, "98998404": 67, "99": [36, 42, 43, 55, 64, 66, 67, 76], "990210": 54, "990377": 43, "991": [32, 37], "9914": [53, 54, 58], "991444e": 48, "9915": [36, 53, 54, 58], "991512": 36, "991539": 43, "991963": [42, 43], "991977": 54, "991988": 42, "9920040357": 67, "99232145": 58, "992582": [42, 43], "993201": 43, "993575": 54, "99363245": 67, "994168239": 35, "994214": 54, "994332": 40, "994377": 42, "9944": 66, "994851": 54, "994937": 49, "995": 55, "995015": 54, "9951": 34, "995248": 57, "99549118e": 67, "99571372e": 67, "9961392": 35, "996454": 43, "996934": 52, "996946": 43, "997": 55, "9970": 54, "997034": 59, "997494": 59, "997571": 52, "997621": 44, "997934": [48, 49], "998063": 40, "99864670889": 77, "998766": 54, "9989": 53, "999": [45, 46, 50, 58, 77], "999207": 57, "9995": [42, 43, 46], "9996": [42, 43, 46], "9996553": 36, "9997": [42, 43, 46], "9998": [42, 43, 46], "9999": [42, 43, 46], "99c8": 37, "A": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 21, 25, 29, 30, 32, 33, 34, 36, 37, 40, 41, 47, 49, 55, 56, 58, 61, 62, 64, 65, 66, 69, 70, 71, 72, 74, 75, 77], "ATE": [8, 36, 38, 53, 58, 64, 66, 68, 70], "ATEs": 55, "And": [55, 59, 70], "As": [33, 34, 35, 36, 37, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 54, 55, 57, 59, 60, 65, 67, 68, 69, 70, 71, 77], "At": [16, 17, 18, 35, 45, 46, 50, 51, 52, 54, 57, 77], "Being": 77, "But": 51, "By": [34, 35, 52, 65, 70], "For": [4, 5, 7, 8, 11, 18, 27, 28, 32, 34, 35, 37, 40, 45, 50, 51, 52, 54, 56, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 77], "If": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 33, 35, 41, 42, 43, 45, 51, 52, 54, 61, 62, 64, 65, 66, 68, 69, 70, 72, 77], "In": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77], "It": [34, 35, 36, 42, 43, 47, 48, 49, 52, 53, 54, 65, 67, 72, 76], "No": [20, 32, 34, 36, 37, 38, 45, 50, 53, 54, 58, 59, 62, 65, 66, 68, 69, 74, 75], "Of": [51, 69, 77], "On": [33, 41, 55, 61, 75], "One": [36, 53, 54, 64, 69], "Such": 65, "That": 77, "The": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 34, 35, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77], "Then": [18, 44, 57, 69, 70, 71, 72, 73], "There": [36, 53, 73, 77], "These": [36, 37, 39, 53, 56, 58, 64, 77], "To": [28, 32, 33, 35, 36, 37, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 64, 65, 67, 69, 70, 71, 73, 74, 77], "With": [21, 42, 43, 65, 75], "_": [33, 35, 41, 42, 43, 44, 46, 47, 48, 49, 52, 53, 54, 56, 57, 60, 61, 64, 67, 68, 69, 70, 71], "_0": [33, 35, 41, 47, 52, 60, 61, 67, 68, 69, 70], "_1": [16, 17, 18, 55, 59, 68], "_2": [16, 17, 18, 55], "_3": [16, 17, 18], "_4": [16, 17, 18], "_5": 16, "__version__": 73, "_all_coef": 67, "_all_s": 67, "_compute_scor": 28, "_compute_score_deriv": 28, "_coordinate_desc": 52, "_est_causal_pars_and_s": 76, "_i": [33, 41, 57, 59, 61], "_id": 67, "_j": [16, 17, 18, 23, 35, 52, 69, 71], "_l": 65, "_m": [65, 67], "_n": [68, 69, 70, 71], "_n_folds_per_clust": 52, "_rmse": [2, 4, 5, 7, 8, 9, 10, 11, 12], "_utils_resampl": 51, "a09a": 37, "a09b": 37, "a3d9": 37, "a4a147": 55, "a5e6": 37, "a5e7": 37, "a6ba": 37, "a79359d2da46": 37, "a840": 37, "a_": 59, "a_0": 24, "a_1": 24, "ab": [34, 72], "ab71": 37, "abadi": [14, 45], "abb0fd28": 37, "abdt": [38, 62, 74], "abl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 41, 51, 54, 55, 65, 70], "about": [36, 51, 53, 72, 74, 77], "abov": [33, 36, 41, 42, 43, 48, 49, 51, 53, 55, 56, 57, 61, 64, 65, 66, 73], "absolut": [2, 4, 5, 7, 8, 9, 10, 11, 12, 51, 65], "abstract": [28, 34, 35, 52, 68, 72, 76], "acc": 34, "accept": [64, 65], "access": [29, 30, 34, 36, 48, 49, 50, 51, 58, 65, 70, 77], "accord": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 36, 41, 44, 45, 53, 57, 59, 65, 69, 70, 71, 77], "accordingli": [45, 51, 53, 59], "account": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 36, 52, 53, 54, 58, 70, 77], "accumul": [36, 53, 54, 58], "accuraci": 34, "acemoglu": 75, "achiev": [35, 52, 56, 69, 71], "acic_2024_post": 55, "acknowledg": [36, 37, 53], "acm": 75, "acov": 75, "across": [36, 53, 55, 77], "action": 76, "activ": [3, 6, 73, 76], "actual": 50, "acycl": [59, 77], "ad": [3, 6, 14, 15, 28, 50, 62, 65, 69, 70, 76], "adapt": [7, 53, 76], "add": [34, 35, 38, 45, 46, 48, 49, 50, 55, 57, 58, 59, 65, 75, 76], "addit": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 23, 24, 25, 47, 65, 66, 68, 70, 75, 76], "addition": [16, 17, 44, 54, 58, 65, 66, 67, 69, 70, 74], "adel": 75, "adjust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 46, 52, 54, 58, 64, 69, 70, 71, 77], "adopt": [45, 66], "advanc": [63, 67, 75], "advantag": [33, 34, 36, 41, 53, 54, 61, 73], "advers": 70, "adversari": [2, 4, 5, 7, 8, 9, 10, 11, 12, 58, 70], "ae": [33, 35, 36], "ae56": 37, "ae89": 37, "aesthet": 33, "aeturrel": 25, "afd9e4": 55, "affect": [47, 66, 76, 77], "after": [34, 36, 37, 45, 47, 53, 54, 59, 64, 65, 70, 73, 77], "after_stat": 33, "ag": [36, 53, 54, 56, 58, 77], "again": [33, 34, 35, 36, 41, 45, 50, 52, 53, 58, 59, 61, 70], "against": [45, 50, 51, 56, 65], "agebra": 64, "agegt54": [37, 38, 62, 74], "agelt35": [37, 38, 62, 74], "agg": 34, "aggreg": [34, 60, 67, 76], "aggt": 34, "aipw": 55, "aipw_est_1": 55, "aipw_est_2": 55, "aipw_obj_1": 55, "aipw_obj_2": 55, "air": [35, 52], "al": [14, 15, 19, 21, 23, 24, 33, 35, 36, 37, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54, 57, 58, 61, 66, 67, 68, 69, 70, 71, 72, 74, 76], "alexandr": [47, 75], "algorithm": [32, 34, 35, 37, 41, 44, 45, 51, 52, 54, 57, 58, 59, 63, 65, 66, 67, 68, 69, 76, 77], "align": [33, 35, 41, 44, 46, 51, 52, 53, 55, 56, 57, 59, 76], "all": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 31, 33, 34, 35, 36, 41, 45, 50, 51, 52, 53, 54, 56, 59, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 76], "all_coef": 67, "all_dml1_coef": 60, "all_s": 67, "all_smpl": [2, 4, 5, 7, 8, 9, 10, 11, 12], "all_z_col": [35, 52], "allow": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 28, 36, 53, 54, 64, 65, 67, 68, 69, 71, 72, 76, 77], "almqvist": 75, "along": 65, "alpha": [2, 4, 5, 7, 8, 9, 10, 11, 12, 22, 24, 33, 35, 36, 38, 41, 42, 43, 44, 47, 51, 52, 53, 54, 57, 60, 61, 64, 65, 66, 67, 68, 69, 70, 71], "alpha_": [23, 35, 52, 65], "alpha_0": 70, "alpha_ml_l": 47, "alpha_ml_m": 47, "alpha_x": [7, 20, 66], "alreadi": [18, 45, 59, 65, 66], "also": [4, 5, 7, 8, 11, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 48, 49, 50, 52, 53, 54, 56, 58, 61, 64, 65, 67, 68, 69, 70, 73, 74, 76, 77], "alter": [35, 52], "altern": [34, 36, 37, 53, 56, 63, 65, 69, 71, 72, 73, 74], "alwai": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 76], "always_tak": [7, 36, 53], "amamb": 52, "american": [22, 55], "amgrem": 52, "amhorn": 52, "amit": 75, "amjavl": 52, "ammata": 52, "among": [36, 47, 53, 54, 58], "amount": [36, 53, 54, 77], "amp": [32, 35, 37, 45, 52, 54, 58, 59], "an": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 18, 29, 30, 33, 34, 35, 36, 37, 41, 42, 43, 47, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "analog": [27, 28, 35, 52, 54, 58, 64, 66, 68, 69, 70, 71], "analys": 77, "analysi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 35, 36, 41, 52, 53, 54, 61, 63, 64, 72, 76], "analyt": [55, 57], "analyz": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 36, 53, 54, 58, 77], "andrea": 75, "angl": 36, "angrist": 55, "ani": [32, 33, 34, 37, 40, 41, 45, 59, 61, 73, 77], "anna": [4, 5, 16, 17, 18, 34, 45, 66, 75], "annal": [69, 71, 75], "anneal": 65, "annot": 33, "annual": 75, "anoth": [33, 34, 35, 36, 41, 51, 52, 61, 65], "anticip": 34, "anymor": [35, 52], "aos1161": [69, 71], "aos1230": [69, 71], "aos1671": [69, 71], "ap": [36, 53], "ape_e401_uncond": 36, "ape_p401_uncond": 36, "api": [62, 72, 76], "apoorva": 76, "apoorva__l": 55, "apoorval": 55, "app": 76, "append": [41, 51, 61], "appendix": [21, 26, 58, 59, 70], "appli": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 32, 33, 35, 36, 37, 41, 45, 46, 51, 52, 53, 54, 59, 61, 66, 67, 68, 69, 71, 72, 74, 76, 77], "applic": [33, 41, 45, 55, 61, 64, 67, 75, 77], "apply_along_axi": 56, "apply_cross_fit": [33, 51, 67], "apply_crossfit": 76, "appreci": 72, "approach": [2, 4, 5, 7, 8, 9, 12, 13, 34, 35, 52, 58, 63, 65, 67, 69, 70, 71, 73, 75, 77], "appropri": [36, 47, 53, 67, 77], "approx": 64, "approxim": [33, 41, 42, 43, 44, 51, 57, 61, 64, 69, 71, 76, 77], "apt": 73, "ar": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 24, 25, 27, 28, 29, 30, 33, 34, 35, 36, 37, 39, 41, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77], "arang": [2, 4, 5, 7, 8, 9, 10, 11, 12, 41, 44, 46, 54, 56, 57, 58, 65], "architectur": [68, 75], "arellano": 75, "arg": 64, "argmin": 51, "argu": [33, 36, 41, 53, 54, 58, 61, 77], "argument": [18, 23, 24, 25, 36, 42, 43, 45, 50, 51, 53, 54, 60, 64, 65, 66, 77], "aris": [33, 34, 35, 41, 52, 61, 77], "aronow": 55, "around": [34, 36, 53, 54, 68], "arr": 56, "arrai": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 20, 21, 22, 23, 24, 25, 26, 41, 42, 43, 44, 45, 51, 52, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 69, 70, 71, 74, 76, 77], "arrang": 35, "array_lik": 13, "articl": [25, 72], "arxiv": [23, 34, 35, 52, 72, 75, 76], "as_learn": [37, 65], "asarrai": [42, 43], "aspect": [36, 53, 54], "assert": 65, "assess": 34, "asset": [54, 58, 77], "assign": [3, 6, 36, 49, 53, 64, 65, 66, 77], "assmput": 66, "associ": [36, 47, 53, 66, 69, 71, 75], "assum": [32, 35, 40, 45, 52, 55, 56, 66, 68, 69, 70, 77], "assumpt": [34, 35, 36, 45, 46, 51, 52, 53, 55, 59, 66, 69, 77], "assur": 76, "astyp": [40, 53], "asymptot": [27, 28, 33, 35, 41, 52, 61, 67, 69, 75], "ate_estim": 59, "athei": 75, "att": [8, 34, 46, 50, 56, 64, 66, 68, 70, 76], "att_gt": 34, "attach": 34, "atte_estim": 45, "attempt": [29, 30], "attenu": [36, 53], "attr": 36, "attribut": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 51, 60, 65, 67, 68, 69], "attributeerror": [29, 30], "attrict": 66, "attrit": [59, 66], "au": [37, 65, 72, 74], "auc": 34, "author": 72, "automat": [33, 41, 50, 61, 64, 70], "automobil": [35, 52], "autos": 47, "auxiliari": [33, 41, 61], "avail": [20, 34, 36, 37, 45, 47, 51, 53, 54, 55, 56, 61, 64, 65, 66, 70, 72, 73, 76, 77], "averag": [7, 8, 11, 16, 17, 18, 32, 34, 37, 40, 45, 46, 50, 54, 55, 56, 58, 59, 63, 66, 69, 70, 75, 77], "avoid": [33, 34, 41, 67, 73, 76], "awai": 58, "ax": [41, 42, 43, 44, 46, 48, 49, 51, 52, 53, 54, 55, 57], "ax1": [44, 54, 57], "ax2": [44, 54, 57], "axhlin": 46, "axi": [35, 36, 47, 51, 52, 53, 55, 56], "axvlin": 41, "b": [4, 5, 25, 33, 35, 37, 41, 42, 43, 52, 55, 57, 61, 64, 65, 69, 70, 71, 72, 74, 75], "b208": 37, "b371": 37, "b5d34a6f42b": 37, "b5d7": 37, "b_0": 24, "b_1": 24, "b_j": 25, "bach": [72, 75, 76], "backbon": 51, "backend": [3, 6, 34, 54, 58, 63, 76], "backward": 76, "bad": 55, "balanc": [36, 53, 54], "band": [34, 63, 77], "bandwidth": [9, 12, 13], "bar": [50, 53, 64], "base": [2, 4, 5, 7, 8, 9, 10, 11, 12, 19, 33, 34, 35, 36, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77], "baselin": [36, 53], "basi": [1, 8, 11, 42, 43, 64], "basic": [34, 35, 36, 45, 52, 53, 54, 55, 58, 63, 65], "batch": 37, "battocchi": 75, "bay": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 69, 71], "bb2913dc": 37, "bbotk": [37, 65, 76], "bbox_inch": 41, "bbox_to_anchor": 41, "bcallaway11": 34, "bd929a9e": 37, "bde4": 37, "becam": [36, 53, 54], "becaus": [32, 33, 34, 35, 40, 41, 49, 50, 52, 55, 61, 77], "becker": [37, 65], "becom": [35, 49, 52, 64, 67], "bee": 46, "been": [35, 36, 52, 53, 54, 58, 64, 65, 76], "befor": [34, 36, 46, 50, 53, 57, 66, 77], "begin": [20, 22, 23, 33, 35, 36, 37, 41, 44, 46, 51, 52, 53, 55, 56, 57, 59, 60, 62, 65, 67, 69, 71, 74, 77], "behav": 49, "behavior": [36, 55, 65], "behaviour": 49, "being": [26, 27, 28, 35, 52, 67, 68, 69, 70, 71, 72], "belloni": [21, 47, 69, 71, 75], "below": [32, 36, 40, 53, 55, 73, 74], "benchmark": [2, 4, 5, 7, 8, 9, 10, 11, 12, 31, 50, 76], "benchmark_dict": [31, 58], "benchmark_inc": 58, "benchmark_pira": 58, "benchmark_result": [2, 4, 5, 7, 8, 9, 10, 11, 12], "benchmark_twoearn": 58, "benchmarking_set": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 58, 70], "benchmarking_vari": 50, "benefit": [33, 36, 41, 53, 61], "bernoulli": 20, "berri": [35, 52], "besid": 74, "best": [1, 8, 11, 42, 43, 48, 49, 73], "beta": [20, 21, 22, 26, 36, 53, 56, 59], "beta_": 59, "beta_0": [19, 56, 59, 64], "beta_a": [16, 17], "beta_j": [20, 21, 22, 26], "better": [34, 51], "between": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 40, 44, 46, 47, 55, 57, 58, 59, 68, 69, 70, 71, 74, 76], "betwen": [32, 40], "beyond": 75, "bia": [26, 32, 40, 47, 59, 63, 66, 67, 68, 70, 75, 76], "bias": [32, 36, 40, 53, 54, 58, 77], "bibtex": 72, "big": [47, 60, 67, 68, 69, 70], "bigg": [35, 52, 68, 70], "bilia": 15, "bin": [33, 41, 73], "binari": [2, 4, 5, 7, 8, 9, 11, 12, 19, 32, 34, 36, 37, 40, 45, 50, 53, 55, 56, 64, 65, 66, 76, 77], "binary_treat": [19, 42, 48, 50], "bind": 76, "binder": [37, 65, 72, 74, 76], "binomi": [40, 55, 56, 57], "bischl": [37, 65, 72, 74], "black": [33, 37, 38, 62, 74], "blob": 34, "blog": 25, "blondel": [72, 74], "blp": [1, 35, 52], "blp_data": [35, 52], "blp_model": [48, 49], "blue": [33, 35, 52], "bodori": 75, "bond": [36, 53, 54], "bonferroni": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 69, 71], "bonu": [15, 37, 62, 74], "book": [37, 65], "bool": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 29, 30, 50], "boolean": [26, 48, 49, 62, 67], "boost": [32, 36, 40, 45, 51, 53], "boost_class": [36, 53], "boost_summari": 53, "boostrap": [44, 76], "bootstrap": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 42, 43, 44, 48, 49, 54, 57, 63, 64, 67, 68, 72, 74, 76, 77], "both": [16, 17, 19, 34, 36, 37, 45, 46, 51, 53, 54, 56, 58, 62, 65, 69, 70, 76, 77], "bottom": [35, 36, 51, 52, 53, 54], "bound": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 50, 53, 58, 70, 77], "branch": 37, "brantli": 34, "break": [33, 76], "breviti": 77, "brew": 73, "brewer": 35, "brief": 61, "bring": [32, 40], "brucher": [72, 74], "bsd": 76, "budget": 65, "bug": [72, 76], "build": [35, 51, 52, 56], "build_design_matric": [42, 43], "build_sim_dataset": 34, "built": [65, 72], "bureau": [67, 75], "busi": [23, 26, 35, 52, 75], "b\u00fchlmann": 75, "c": [14, 15, 17, 18, 21, 22, 24, 32, 33, 34, 35, 36, 37, 38, 40, 41, 46, 47, 48, 49, 52, 53, 55, 61, 62, 65, 72, 73, 74, 75, 77], "c1": [14, 15, 24, 35, 47, 52, 61, 72, 75], "c68": [14, 15, 24, 35, 47, 52, 61, 72, 75], "c895": 37, "c_": [69, 71], "c_d": [21, 70], "c_y": [21, 70], "ca1af7be64b2": 37, "caac5a95": 37, "calcualt": 56, "calcul": [8, 11, 34, 36, 42, 43, 44, 48, 49, 51, 53, 57, 58, 70], "call": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 34, 35, 36, 37, 40, 42, 43, 44, 45, 48, 49, 52, 53, 54, 56, 57, 58, 59, 62, 65, 67, 68, 69, 70, 71, 73, 74, 76, 77], "callabl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 41, 42, 43, 51, 63, 65, 72], "callawai": 34, "camera": 47, "cameron": [35, 52], "can": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77], "cannot": [51, 77], "capabl": [3, 6, 32, 40], "capsiz": 55, "cardin": [35, 52], "care": 65, "carlo": [16, 17, 19, 42, 43, 48, 49, 75], "casalicchio": [37, 65, 72, 74], "case": [3, 6, 7, 8, 15, 19, 32, 35, 36, 40, 42, 43, 44, 47, 49, 50, 52, 56, 57, 58, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 76, 77], "cat": [33, 76], "catboost": 51, "cate": [1, 8, 11, 63, 76], "cate_obj": 64, "caus": [33, 41, 61], "causal": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 20, 21, 22, 23, 24, 25, 26, 32, 33, 35, 36, 37, 40, 41, 52, 53, 55, 58, 59, 60, 61, 62, 63, 66, 67, 69, 70, 71, 75], "causaldml": 75, "causalweight": 75, "caution": 69, "caveat": 49, "cbind": 35, "cc": 53, "ccp_alpha": [8, 53], "cd": 73, "cd_fast": 52, "cda85647": 37, "cdf": 64, "cdid": [35, 52], "cdot": [16, 17, 18, 35, 44, 46, 50, 52, 55, 57, 64, 66, 68, 69, 71], "cdot1": 50, "center": 47, "central": [67, 76], "certain": 49, "cexcol": 35, "cexrow": 35, "cf_d": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 31, 50, 58, 70, 77], "cf_y": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 31, 50, 58, 70, 77], "chain": 49, "chainedassignmenterror": 49, "challeng": [35, 52, 70], "chang": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 45, 49, 54, 58, 59, 69, 70, 73, 75, 76], "channel": 77, "chapter": [27, 28, 37, 65, 70], "charact": [36, 37, 65, 76], "characterist": [58, 77], "check": [29, 30, 33, 36, 41, 51, 53, 54, 60, 61, 72, 73, 76], "check_data": 76, "check_scor": 76, "checkmat": 76, "chernozhukov": [14, 15, 21, 22, 24, 33, 35, 36, 41, 47, 51, 52, 53, 54, 58, 61, 67, 69, 70, 71, 72, 75, 76], "chetverikov": [14, 15, 24, 35, 47, 52, 61, 69, 71, 72, 75], "chiang": [23, 35, 52, 75], "chieh": 75, "choic": [2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 36, 47, 53, 56, 64, 65, 70, 76], "choos": [32, 36, 40, 41, 47, 51, 53, 54, 60, 67, 68, 69, 71, 74, 77], "chosen": [16, 17, 51, 65], "chou": 55, "chr": 36, "christian": [47, 75], "chunk": 65, "ci": [2, 4, 5, 7, 8, 9, 10, 11, 12, 42, 43, 44, 45, 46, 48, 49, 50, 53, 54, 57, 58, 64, 70, 76, 77], "ci_cvar": [44, 54], "ci_cvar_0": 44, "ci_cvar_1": 44, "ci_joint_cvar": 44, "ci_joint_lqt": 57, "ci_joint_qt": 57, "ci_length": 45, "ci_lpq_0": 57, "ci_lpq_1": 57, "ci_lqt": [54, 57], "ci_pq_0": [54, 57], "ci_pq_1": [54, 57], "ci_qt": [54, 57], "cinelli": [70, 75], "circumv": 77, "citat": 76, "claim": 37, "clash": 34, "class": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 27, 28, 29, 30, 36, 37, 38, 45, 50, 53, 54, 58, 59, 60, 62, 64, 65, 67, 68, 69, 72, 74, 76], "class_learn": 54, "class_learner_1": 51, "class_learner_2": 51, "classic": [34, 35, 52, 77], "classif": [8, 32, 34, 36, 37, 51, 56, 64, 65, 66, 77], "classifavg": 37, "classifi": [2, 4, 5, 7, 8, 9, 11, 12, 13, 29, 37, 65, 76], "classmethod": [3, 6], "claus": 76, "clean": 76, "cleaner": 51, "cleanup": 76, "clear": [35, 52], "clever": 51, "clone": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 33, 37, 41, 51, 52, 54, 60, 65, 66, 67, 68, 69, 70, 71, 73, 74], "close": [34, 36, 53, 70], "cluster": [3, 23, 75, 76], "cluster_col": [3, 35, 52], "cluster_var": [3, 23], "cluster_var_i": [3, 35, 52], "cluster_var_j": [3, 35, 52], "cmap": 52, "cmd": 76, "co": [25, 46], "codaci": 76, "code": [8, 11, 25, 32, 34, 35, 36, 37, 40, 47, 53, 61, 64, 65, 66, 67, 68, 69, 73, 74, 76, 77], "codecov": 76, "coef": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 74, 77], "coef_df": 35, "coeffici": [1, 16, 17, 19, 36, 48, 49, 51, 53, 55, 56, 59, 64, 69, 70, 71, 77], "coefs_t": 56, "coefs_w": 56, "coffici": 70, "cofid": 1, "coincid": [46, 54], "col": [33, 35, 49, 53], "collect": [37, 45, 52, 59], "colnam": [35, 51], "color": [36, 41, 42, 43, 44, 46, 52, 53, 54, 55, 57], "color_palett": [41, 52, 53, 54], "colorbar": 52, "colorramppalett": 35, "colorscal": [42, 43], "colour": [33, 35], "column": [3, 6, 38, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58, 59, 62, 64, 65, 67, 74, 76, 77], "column_stack": [46, 48, 49, 58], "colv": 35, "com": [25, 34, 36, 37, 47, 53, 55, 65, 73], "comb": 47, "combin": [34, 35, 37, 45, 51, 52, 65, 67, 70, 76], "combind": 54, "combined_loss": 47, "come": [60, 65, 68, 70, 72, 77], "command": [73, 76], "comment": 62, "common": [58, 64, 66, 75], "companion": 75, "compar": [33, 35, 41, 42, 43, 44, 46, 48, 49, 52, 55, 57, 61, 65, 70], "comparevers": 36, "comparison": [51, 55], "compat": [32, 34, 40, 76], "complet": [61, 70, 73], "complex": [8, 34], "complianc": [57, 68], "complic": [37, 77], "complier": [36, 53, 54, 57, 64], "compon": [34, 36, 47, 51, 53, 56, 64, 65, 67, 68, 76], "compont": 34, "composit": 75, "compris": [69, 71], "comput": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 31, 33, 34, 36, 37, 41, 53, 54, 58, 67, 68, 70, 72, 75, 76, 77], "computation": 70, "concat": [52, 53, 56, 69], "concaten": [46, 53, 69], "concentr": 69, "conclud": 77, "cond": 66, "conda": [52, 75, 76], "condit": [2, 8, 11, 16, 17, 19, 27, 28, 33, 35, 36, 41, 45, 46, 50, 52, 53, 56, 59, 61, 63, 66, 69, 70, 71, 74, 75, 76, 77], "conduct": [64, 66, 77], "conf": [34, 57], "confer": 75, "confid": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 42, 43, 44, 45, 48, 49, 52, 54, 57, 58, 59, 63, 64, 67, 68, 70, 74, 75, 77], "confidenceband": 44, "config": 55, "configur": 37, "confint": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 36, 42, 43, 44, 45, 46, 48, 49, 51, 54, 56, 57, 58, 59, 64, 67, 69, 71, 72, 74, 77], "conflict": 73, "confound": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 19, 31, 32, 34, 36, 40, 50, 53, 57, 58, 62, 66, 69, 70, 71, 74, 75, 76, 77], "congress": 75, "connect": [36, 53, 54], "consequ": [16, 17, 35, 50, 52, 58, 64, 66, 70], "conserv": [58, 70], "consid": [2, 7, 8, 9, 12, 33, 35, 36, 41, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 77], "consist": [10, 11, 36, 45, 53, 54, 55, 61, 62, 66, 74, 76], "consol": [33, 76], "constant": [21, 47, 56, 64, 69, 71], "constrained_layout": 41, "construct": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 37, 42, 43, 44, 46, 54, 58, 60, 64, 68, 69, 71, 76, 77], "construct_framework": [2, 4, 5, 7, 8, 9, 10, 11, 12], "construct_iv": 52, "constructiv": 35, "constructor": 37, "consum": [35, 52], "contain": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 33, 35, 36, 41, 42, 43, 48, 49, 51, 52, 53, 61, 64, 65, 69, 70, 76], "context": [66, 77], "continu": [32, 37, 40, 47, 55, 70, 76, 77], "contour": [2, 4, 5, 7, 8, 9, 10, 11, 12, 47, 50, 58, 70], "contours_z": [42, 43], "contrast": [44, 45], "contribut": [73, 76], "contributor": 76, "control": [22, 34, 47, 54, 56, 77], "convent": [36, 53, 54], "converg": [33, 41, 51, 52, 61], "convergencewarn": 52, "convers": 52, "convert": [44, 52, 57], "convex": 55, "coor": [37, 65, 72, 74], "copi": [49, 53, 56], "cor": 70, "core": [38, 44, 45, 50, 52, 53, 54, 57, 58, 59, 62, 65, 74, 76], "cores_us": [44, 54, 57], "correct": [50, 64, 69, 71, 76], "correctli": [45, 55, 58, 70], "correl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 47, 52, 58, 59, 66, 70], "correpond": 66, "correspond": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 27, 28, 33, 35, 36, 37, 41, 42, 43, 45, 46, 47, 51, 52, 53, 54, 56, 57, 58, 61, 64, 65, 66, 67, 69, 70, 71, 76, 77], "cosh": 25, "coul": 35, "could": [32, 37, 40, 42, 43, 76, 77], "counfound": [16, 17, 57, 58, 64, 70], "count": [53, 54], "countour": 70, "coupl": [36, 53, 54], "cournapeau": [72, 74], "cours": [36, 51, 53, 69, 77], "cov": 16, "covari": [3, 4, 5, 6, 8, 10, 11, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 61, 62, 64, 65, 66, 68, 69, 70, 74, 76], "cover": [34, 47, 58], "coverag": [51, 64, 76], "cp": [36, 37, 65], "cpu": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "cpu_count": [44, 54, 57], "cran": [37, 75, 76], "creat": [19, 32, 35, 37, 40, 41, 42, 43, 44, 48, 49, 52, 54, 56, 57, 65, 70, 73], "create_synthetic_group_data": 56, "critic": 77, "cross": [2, 4, 5, 7, 8, 9, 10, 11, 12, 18, 32, 33, 34, 36, 37, 41, 51, 53, 54, 61, 63, 65, 69, 76, 77], "cross_sectional_data": [5, 18, 45, 66], "crossfit": 51, "crosstab": 55, "crucial": [47, 77], "csail": [72, 74], "csv": 47, "cumul": 66, "current": [34, 49, 68, 70, 72, 77], "custom": [33, 34, 41, 65], "custom_measur": 34, "cut": 56, "cv": [37, 53, 65, 67], "cv_glmnet": [35, 36, 37, 65, 69, 71, 74], "cvar": [2, 13, 63, 76], "cvar_0": 44, "cvar_1": 44, "d": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77], "d0": [44, 57, 69], "d0_true": 57, "d0cdb0ea4795": 37, "d1": [44, 55, 57, 69, 71], "d10": [69, 71], "d1_true": 57, "d2": [55, 69, 71], "d21ee5775b5f": 37, "d3": [69, 71], "d4": [69, 71], "d5": [69, 71], "d5a0c70f1d98": 37, "d6": [69, 71], "d7": [69, 71], "d8": [69, 71], "d9": [69, 71], "d_": [23, 35, 46, 52, 66, 69, 71], "d_1": [55, 69, 71], "d_2": 55, "d_col": [3, 6, 32, 33, 35, 36, 37, 40, 42, 43, 48, 49, 52, 53, 54, 56, 58, 60, 61, 62, 65, 66, 67, 68, 74, 76, 77], "d_i": [19, 20, 21, 22, 24, 25, 26, 33, 41, 44, 45, 55, 57, 59, 61, 66], "d_j": [69, 71], "d_k": [69, 71], "d_w": 56, "da1440": 55, "dag": [59, 77], "dark": [33, 41], "darkblu": 35, "darkr": 35, "dat": 62, "data": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 34, 46, 47, 51, 55, 60, 63, 64, 65, 67, 69, 71, 75, 76], "data_cvar": 54, "data_dict": [42, 43, 48, 49, 50], "data_dml": 58, "data_dml_bas": [36, 42, 43, 48, 49, 53, 54, 56], "data_dml_base_iv": [36, 53, 54], "data_dml_flex": [36, 53], "data_dml_flex_iv": 36, "data_dml_iv_flex": 53, "data_dml_new": 56, "data_fram": 77, "data_lqt": 54, "data_pq": 54, "data_qt": 54, "data_transf": [35, 52, 53], "datafram": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 35, 38, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 68, 69, 70, 74, 77], "dataset": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 33, 34, 41, 42, 43, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 74, 77], "datatyp": 76, "db": [36, 53, 54, 58, 77], "dbl": [34, 35, 36, 37, 62, 69, 71, 74, 77], "dc13a11076b3": 37, "ddc9": 37, "de": [32, 40, 75], "deal": [32, 40], "debias": [14, 15, 23, 24, 35, 47, 52, 63, 65, 67, 72, 75, 76], "debt": [36, 53, 54], "decai": 59, "decid": [36, 53], "decis": [8, 32, 34, 36, 40, 53, 54, 64, 75, 77], "decision_effect": [32, 34], "decision_impact": [32, 40], "decisiontreeclassifi": [8, 53], "decisiontreeregressor": 53, "declar": 77, "deep": [29, 30], "deeper": 8, "def": [2, 4, 5, 7, 8, 9, 10, 11, 12, 41, 44, 51, 52, 55, 56, 57, 65, 68], "default": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 23, 24, 25, 29, 30, 34, 35, 45, 48, 49, 51, 52, 56, 58, 59, 60, 64, 65, 67, 69, 70, 71, 74, 77], "default_convert": 52, "defin": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 36, 37, 41, 42, 43, 44, 45, 47, 48, 49, 51, 53, 54, 56, 57, 58, 64, 65, 66, 68, 70], "definit": [25, 48, 49, 70], "defint": 70, "degre": [36, 42, 43, 52, 53, 64, 70], "dekel": 75, "delete_origin": 37, "deliber": 55, "delta": [22, 34, 45, 66], "delta_i": 34, "delta_j": 22, "delta_theta": [31, 50, 58, 70], "demand": [35, 52, 70], "demir": [14, 15, 24, 35, 47, 52, 61, 67, 72, 75], "demonstr": [33, 34, 35, 41, 52, 62, 69, 71, 72, 74], "deni": 75, "denomin": 70, "denot": [10, 35, 36, 45, 46, 52, 53, 59, 64, 66, 68, 70], "dens_net_tfa": 36, "densiti": [9, 12, 13, 33, 41], "dep": 38, "dep1": [37, 38, 62, 74], "dep2": [37, 38, 62, 74], "depend": [2, 8, 9, 13, 19, 37, 42, 43, 45, 48, 49, 50, 51, 56, 60, 64, 65, 68, 70, 74, 75], "deprec": [60, 67], "depreci": 76, "depth": [8, 36, 37, 56, 60, 64, 65, 66, 67, 68, 69, 74, 77], "deriv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 28, 69], "describ": [34, 35, 52, 53, 54, 65, 67, 73, 76], "descript": [36, 38, 58, 65, 67, 70], "design": 75, "design_info": [42, 43], "design_matrix": [42, 43, 64], "desir": [16, 17, 37, 56], "detail": [2, 4, 5, 7, 8, 9, 10, 11, 12, 27, 28, 33, 36, 37, 41, 45, 46, 47, 54, 58, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 74, 76, 77], "determin": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 36, 44, 53, 54, 57, 58, 66, 69, 70, 71], "determinist": [56, 64], "deutsch": 72, "dev": 76, "develop": [34, 35, 37, 52, 66, 76], "deviat": [51, 70], "dezeur": 75, "df": [3, 6, 32, 33, 34, 35, 40, 42, 43, 44, 46, 49, 52, 55, 57, 58, 59, 61, 64, 66], "df_agg": 47, "df_bonu": [37, 62, 74], "df_cate": [42, 43], "df_ci": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "df_coef": 51, "df_cvar": 54, "df_lqte": 54, "df_ml_g0": 51, "df_ml_g1": 51, "df_ml_m": 51, "df_pa": [45, 59], "df_plot": 35, "df_pq": 54, "df_qte": 54, "df_result": 47, "df_summari": 53, "df_wide": 52, "dfg": 72, "dgp": [18, 35, 44, 46, 47, 52, 55, 56, 57, 59], "dgp1": 18, "dgp2": 18, "dgp3": 18, "dgp4": 18, "dgp5": 18, "dgp6": 18, "dgp_tpye": 45, "dgp_type": [18, 45], "diagram": [32, 40, 66], "dichotom": [32, 40], "dict": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 31, 42, 43, 47, 65], "dict_kei": 70, "dictionari": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 19, 31, 42, 43, 48, 49, 58, 64, 65, 70], "dictonari": [36, 53], "did": [3, 6, 33, 45, 46, 52, 63, 76, 77], "diff": 53, "differ": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 32, 33, 35, 36, 37, 40, 41, 44, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 63, 64, 65, 67, 73, 74, 75, 76, 77], "dillon": 75, "dim": 36, "dim_x": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 20, 21, 22, 23, 24, 25, 26, 33, 35, 37, 41, 51, 52, 61, 64, 65, 66, 70], "dim_z": [10, 22, 66], "dimens": [19, 23, 35, 52, 56, 67], "dimension": [10, 11, 19, 21, 47, 64, 66, 67, 69, 70, 71, 74, 75], "direct": [33, 41, 46, 59, 61, 77], "directli": [33, 34, 36, 41, 51, 58, 61, 70, 74, 77], "discret": 52, "discretis": 54, "discuss": [20, 35, 36, 52, 53, 75, 76, 77], "disjoint": [35, 48, 49, 52], "displai": [35, 52, 64, 70], "displot": 53, "disproportion": [36, 53], "dist": [2, 4, 5, 7, 8, 9, 10, 11, 12], "distr": 65, "distribut": [33, 41, 45, 51, 61, 66, 70, 73, 75, 76], "diverg": [33, 41, 61], "dmatrix": [42, 43, 64], "dml": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 27, 28, 32, 33, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 53, 54, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 73], "dml1": [63, 74, 76, 77], "dml2": [32, 35, 37, 38, 45, 52, 54, 63, 66, 68, 69, 74, 76, 77], "dml_base": 52, "dml_combin": 69, "dml_cv_predict": 76, "dml_cvar": [44, 54], "dml_cvar_0": 44, "dml_cvar_1": 44, "dml_cvar_obj": [2, 64], "dml_data": [34, 35, 38, 45, 46, 50, 51, 52, 55, 58, 59, 64, 65, 66, 69, 71, 77], "dml_data_bonu": [37, 74], "dml_data_df": 77, "dml_data_lasso": 38, "dml_data_sim": [37, 74], "dml_df": [35, 52], "dml_did": [45, 46], "dml_did_obj": [4, 5, 66], "dml_iivm_boost": [36, 53], "dml_iivm_forest": [36, 53], "dml_iivm_lasso": [36, 53], "dml_iivm_obj": [7, 40, 66], "dml_iivm_tre": [36, 53], "dml_irm": [42, 48, 51, 56], "dml_irm_at": 50, "dml_irm_boost": [36, 53], "dml_irm_forest": [36, 53], "dml_irm_gat": 50, "dml_irm_gatet": 50, "dml_irm_lasso": [36, 38, 53], "dml_irm_new": 56, "dml_irm_obj": [2, 4, 5, 7, 8, 9, 10, 11, 12, 58, 64, 65, 66], "dml_irm_obj_ext": 65, "dml_irm_rf": 38, "dml_irm_tre": [36, 53], "dml_long": 31, "dml_lpq_0": 57, "dml_lpq_1": 57, "dml_lpq_obj": [9, 64], "dml_lqte": [54, 57], "dml_obj": [34, 58], "dml_pliv": [35, 52], "dml_pliv_obj": [10, 35, 52, 66], "dml_plr": [43, 49, 69, 71], "dml_plr_1": 69, "dml_plr_2": 69, "dml_plr_boost": [36, 53], "dml_plr_forest": [36, 53, 77], "dml_plr_lasso": [36, 38, 53], "dml_plr_no_split": 67, "dml_plr_obj": [2, 4, 5, 7, 8, 9, 10, 11, 12, 58, 60, 64, 65, 66, 67, 68, 69, 70], "dml_plr_obj_extern": 67, "dml_plr_obj_intern": 67, "dml_plr_rf": 38, "dml_plr_tree": [36, 53, 77], "dml_pq_0": [54, 57], "dml_pq_1": [54, 57], "dml_pq_obj": [12, 64], "dml_procedur": [38, 60, 74, 76, 77], "dml_qte": [54, 57], "dml_qte_obj": [13, 64], "dml_short": 31, "dml_ssm": [59, 66], "dml_tune": 76, "dmldummyclassifi": 65, "dmldummyregressor": 65, "dmlmt": 75, "dnorm": 33, "do": [34, 35, 36, 37, 51, 52, 53, 54, 55, 64, 65, 70, 74, 77], "doabl": 68, "doc": [32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 72, 76], "docu": 76, "document": [39, 42, 43, 46, 48, 49, 72, 76], "doe": [13, 34, 35, 36, 52, 53, 55, 58, 70, 77], "doesn": [32, 40], "doi": [14, 15, 16, 17, 18, 20, 23, 24, 26, 34, 35, 37, 47, 52, 61, 65, 67, 69, 71, 72, 74, 76], "domain": 56, "don": 34, "done": [2, 4, 5, 7, 8, 9, 10, 11, 12, 54, 65, 67, 70], "dot": [46, 56, 62, 64, 65, 69, 71, 74], "doubl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 23, 24, 25, 26, 36, 47, 53, 55, 63, 65, 67, 68, 69, 70, 71, 76], "double_ml_bonus_data": 38, "double_ml_data_from_data_fram": [33, 61, 62, 77], "double_ml_data_from_matrix": [34, 37, 62, 65, 69, 71, 74], "double_ml_irm": [38, 56], "doubleiivm": 72, "doubleml": [33, 35, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 74, 75, 76], "doubleml2022python": 72, "doubleml2024r": 72, "doubleml_did_eval_linear": 34, "doubleml_did_eval_rf": 34, "doubleml_did_linear": 34, "doubleml_did_rf": 34, "doubleml_framework": [2, 4, 5, 7, 8, 9, 10, 11, 12], "doublemlblp": [8, 11, 42, 43, 64, 76], "doublemlclusterdata": 23, "doublemlcvar": [44, 64, 68, 76], "doublemldata": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 24, 25, 26, 32, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 76, 77], "doublemldid": [45, 46, 66, 68, 76], "doublemldidc": [45, 66, 68, 76], "doublemlframework": [2, 4, 5, 7, 8, 9, 10, 11, 12, 67, 69, 76], "doublemlidid": 66, "doublemlididc": 66, "doublemliivm": [32, 36, 40, 53, 65, 66, 67, 68, 76], "doublemlirm": [2, 4, 5, 7, 9, 10, 11, 12, 34, 36, 38, 42, 48, 50, 51, 53, 55, 56, 58, 64, 65, 66, 67, 68, 72, 76], "doublemllpq": [57, 64, 68, 76], "doublemlpliv": [65, 66, 67, 68, 72, 76], "doublemlplr": [2, 4, 5, 7, 8, 9, 10, 12, 33, 36, 37, 38, 41, 43, 49, 53, 55, 58, 60, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77], "doublemlpolicytre": [8, 64], "doublemlpq": [54, 57, 64, 68, 76], "doublemlqt": [44, 54, 57, 64, 69, 76], "doublemlresampl": 51, "doublemlsmm": 76, "doublemlssm": [59, 66, 68], "doubli": [16, 17, 18, 34, 75], "download": [32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 73, 74], "dpg_dict": 58, "dpi": [33, 41, 55], "dramat": 34, "draw": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 67, 76], "draw_sample_split": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 51, 67], "drawn": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 19, 36, 53, 54, 56, 67], "drive": [33, 41, 61], "driven": 77, "drop": [34, 52, 55, 62, 65, 68, 69, 71], "dt": [68, 70], "dt_bonu": 62, "dta": 34, "dtype": [38, 45, 48, 49, 50, 51, 52, 53, 54, 58, 59, 62, 64, 74], "dualiti": 52, "dubourg": [72, 74], "duchesnai": [72, 74], "due": [33, 34, 41, 42, 43, 50, 58, 61, 66, 70, 76, 77], "duflo": [14, 15, 24, 35, 47, 52, 61, 67, 72, 75], "dummi": [1, 8, 11, 29, 30, 64, 65, 66, 76], "dummyclassifi": 29, "dummyregressor": 30, "duplic": 76, "durabl": [37, 38, 62, 74], "durat": 15, "dure": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 37, 52, 53, 65, 67, 74, 76, 77], "dx": 20, "dynam": [34, 75], "e": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 24, 26, 27, 28, 33, 34, 35, 36, 41, 42, 43, 45, 47, 50, 51, 52, 53, 54, 55, 58, 59, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77], "e20ea26": 37, "e401": [36, 53, 54, 58, 77], "e4016553": 77, "e45228": 55, "e57c": 37, "each": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 37, 46, 48, 49, 51, 52, 54, 55, 56, 58, 60, 62, 65, 67, 69, 70, 71, 77], "earlier": 77, "earn": [36, 53, 54], "earner": [36, 53, 58], "easi": [37, 68], "easili": [37, 51, 54, 76], "ec973f": 55, "ecolor": [46, 53, 55], "econ": 75, "econml": 75, "econom": [22, 23, 25, 26, 35, 47, 52, 55, 67, 75], "econometr": [14, 15, 16, 17, 18, 24, 25, 34, 35, 47, 52, 61, 72, 75], "econometrica": [21, 35, 52, 55, 61, 75], "ecosystem": [72, 77], "ectj": [14, 15, 24, 35, 47, 52, 61, 72], "ed": 75, "edge_color": 41, "edgecolor": 41, "edit": [73, 75], "edu": [72, 74], "educ": [36, 53, 54, 58, 77], "ee97bda7": 37, "effect": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 32, 33, 34, 35, 37, 40, 41, 45, 46, 47, 50, 52, 56, 59, 61, 63, 65, 66, 67, 68, 69, 70, 74, 75, 76, 77], "effici": 75, "effort": 68, "eight": [35, 52], "either": [2, 4, 5, 7, 8, 9, 10, 11, 12, 19, 37, 46, 47, 56, 64, 65, 77], "eleanor": 75, "element": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 42, 43, 44, 45, 51, 52, 54, 57, 58, 59, 68, 70, 76], "element_text": [35, 36], "elementari": 75, "elif": [48, 49, 56], "elig": [54, 58, 77], "eligibl": [36, 53, 58], "ell": [33, 35, 41, 47, 52, 61, 68, 74], "ell_0": [7, 10, 11, 33, 41, 47, 61, 66], "ell_2": 51, "els": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 36, 46, 48, 49, 52, 56], "em": 75, "emphas": [35, 52], "empir": [27, 28, 33, 35, 41, 52, 55, 61, 67, 68, 69, 71], "emploi": [35, 47, 52, 68], "employ": [36, 53, 54], "employe": 77, "empti": 52, "emul": 70, "enabl": [56, 58, 64, 70, 76], "encapsul": [29, 30], "encod": 55, "end": [20, 22, 23, 33, 34, 35, 36, 41, 44, 46, 47, 51, 52, 53, 55, 56, 57, 59, 60, 62, 65, 67, 69, 71, 74, 77], "endogen": [36, 53, 54, 77], "enet_coordinate_descent_gram": 52, "engin": [37, 75], "enrol": [36, 53, 54], "ensembl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 41, 42, 43, 48, 49, 50, 51, 53, 56, 58, 60, 64, 65, 66, 67, 68, 69, 70, 74, 77], "ensemble_learner_pipelin": 65, "ensemble_pipe_classif": 37, "ensemble_pipe_regr": 37, "ensur": [35, 49, 52, 56], "entir": [33, 36, 41, 53, 61, 70], "entri": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 35, 38, 41, 45, 50, 52, 53, 54, 58, 59, 61, 62, 65, 72, 74, 76], "enumer": [44, 46, 48, 49, 51, 52, 53, 54, 57, 60, 65, 67], "env": [52, 73], "environ": 73, "ep": 55, "epsilon": [36, 44, 45, 46, 53, 57, 64, 66], "epsilon_": [35, 46, 52], "epsilon_i": [19, 44, 55, 56, 57], "epsilon_sampl": 56, "epsilon_tru": [44, 57], "eqnarrai": 36, "equal": [8, 35, 52, 55, 59, 64, 65, 70], "equat": [35, 36, 52, 53, 60, 69, 71, 77], "equilibrium": [35, 52], "equival": [47, 67], "err": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 40, 42, 43, 44, 45, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 64, 65, 66, 67, 68, 69, 74, 77], "error": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 32, 33, 34, 36, 37, 41, 46, 47, 48, 49, 51, 53, 61, 65, 66, 67, 68, 69, 70, 71, 74, 76, 77], "errorbar": [46, 48, 49, 53, 55], "erstellt": [35, 36, 37], "especi": 51, "est_method": 34, "esther": [67, 75], "estim": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 27, 28, 29, 30, 33, 34, 35, 37, 41, 42, 43, 44, 46, 48, 49, 51, 52, 56, 60, 61, 63, 64, 65, 66, 70, 71, 72, 75, 76], "estimatior": [3, 6], "et": [14, 15, 19, 21, 23, 24, 33, 35, 36, 37, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54, 57, 58, 61, 66, 67, 68, 69, 70, 71, 72, 74, 76], "eta": [27, 28, 33, 35, 36, 46, 52, 53, 57, 60, 64, 67, 68, 69, 70, 71, 74, 77], "eta1": 55, "eta2": 55, "eta_": [69, 70, 71], "eta_0": [60, 68, 69], "eta_i": [19, 46, 56, 57], "eta_sampl": 56, "eta_tru": 57, "etc": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 51, 52, 76], "ev": [33, 41, 61], "eval": [37, 65], "eval_metr": [36, 53, 77], "eval_pr": 34, "eval_predict": 34, "evalu": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 21, 28, 34, 37, 42, 43, 44, 46, 50, 54, 57, 58, 60, 75, 76], "evaluate_learn": [2, 4, 5, 7, 8, 9, 10, 11, 12, 51, 65, 76], "evalut": 65, "even": [36, 37, 53, 55, 65, 77], "eventu": [35, 52], "everi": [35, 52], "everyth": 72, "evid": 50, "exampl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 32, 33, 36, 37, 38, 40, 41, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77], "example_attgt": 34, "example_attgt_dml_eval_linear": 34, "example_attgt_dml_eval_rf": 34, "example_attgt_dml_linear": 34, "example_attgt_dml_rf": 34, "except": [47, 76], "excess": 51, "exclud": 31, "exclus": [8, 11, 48, 49, 64], "execut": [37, 77], "exemplarili": 74, "exemplatori": 56, "exhaust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 65], "exhibit": [35, 52], "exist": [66, 70], "exogen": [36, 53, 54, 77], "exp": [16, 17, 18, 19, 21, 24, 33, 41, 42, 43, 46, 48, 49, 55, 56, 61], "expect": [16, 17, 34, 45, 50, 51, 59, 64, 67, 69, 74], "experi": [15, 20, 21, 33, 36, 41, 53, 61, 62, 67, 74, 75], "experiment": [4, 5, 18, 68, 70], "explain": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 58, 70], "explan": [35, 45, 52, 58, 70, 72, 77], "explanatori": [69, 71], "explicitli": [50, 77], "exploit": [33, 41, 61, 77], "exponenti": [69, 71], "export": 76, "exposur": 46, "express": [35, 47, 70], "extend": [65, 72, 76], "extendend": 70, "extens": [65, 68, 72, 75, 76], "extent": 47, "extern": [33, 41, 63, 70, 76], "external_predict": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 41, 65], "externalptr": 36, "extra": 37, "extract": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "extralearn": 37, "extrem": [36, 53], "ey": 47, "f": [36, 37, 41, 44, 45, 46, 47, 51, 52, 53, 54, 56, 57, 58, 59, 65, 70, 72, 74], "f00584a57972": 37, "f1718fdeb9b0": 37, "f2e7": 37, "f3d24993": 37, "f6ebc": 55, "f_": [18, 46, 64], "f_loc": [44, 57], "f_p": 46, "f_scale": [44, 57], "face_color": 41, "facet_wrap": 36, "fact": [36, 53, 54], "factor": [33, 34, 35, 36, 37, 41, 51, 61, 65, 77], "faculti": 75, "fail": 76, "fair": 51, "fake": [32, 40], "fals": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 33, 36, 37, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 59, 62, 65, 66, 67, 68, 69, 70, 71, 77], "famili": [36, 53, 65], "fanci": 34, "far": [36, 53], "farbmach": 20, "fast": [51, 56, 65], "faster": 47, "fb5c25fa": 37, "fc9e": 37, "fd8a": 37, "featur": [2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 34, 38, 50, 51, 53, 56, 64, 65], "featureless": [37, 65], "features_bas": [36, 53, 54, 58], "features_flex": 36, "featureunion": 37, "femal": [37, 38, 62, 74], "fern\u00e1ndez": [21, 67, 75], "fetch": [36, 52, 53, 54, 62], "fetch_401k": [36, 53, 54, 58, 77], "fetch_bonu": [37, 38, 62, 74], "few": [36, 53, 54], "ff7f0e": 46, "field": [35, 52, 65, 77], "fifteenth": 75, "fifth": 35, "fig": [2, 4, 5, 7, 8, 9, 10, 11, 12, 42, 43, 44, 46, 47, 51, 54, 55, 57], "fig_al": 41, "fig_dml": 41, "fig_non_orth": 41, "fig_orth_nosplit": 41, "fig_po_al": 41, "fig_po_dml": 41, "fig_po_nosplit": 41, "figsiz": [38, 42, 43, 44, 46, 48, 49, 51, 52, 53, 54, 55, 57], "figur": [2, 4, 5, 7, 8, 9, 10, 11, 12, 24, 33, 35, 38, 41, 42, 43, 44, 46, 47, 48, 49, 52, 53, 54, 57, 61], "figure_format": 55, "file": [14, 15, 47, 55, 75, 76], "filenam": 33, "fill": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 35, 36, 45, 51, 53, 59], "fill_between": [42, 43, 44, 54, 57], "fill_valu": 51, "filter": 37, "filterwarn": 41, "final": [33, 37, 41, 42, 43, 44, 46, 48, 49, 50, 54, 57, 59, 61, 66, 77], "financi": [14, 58, 77], "find": [36, 46, 53, 64, 65, 77], "finish": 37, "finit": [33, 36], "firm": [35, 52, 58], "firmid": 52, "first": [16, 17, 18, 23, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 46, 48, 49, 50, 51, 52, 53, 54, 56, 57, 59, 61, 64, 67, 69, 70, 71, 73, 74, 76, 77], "fit": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 29, 30, 32, 33, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 76, 77], "fit_arg": [2, 4, 5, 7, 8, 9, 10, 11, 12], "fit_transform": [52, 53], "five": 52, "fix": [46, 51, 53, 76], "flag": [18, 67, 73], "flake8": 76, "flatten": 55, "flexibl": [32, 36, 37, 40, 45, 53, 72, 77], "flexibli": [36, 53, 58], "float": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17], "float32": [54, 58], "float64": [38, 45, 49, 50, 52, 53, 58, 59, 62, 65, 74], "floor": 37, "floor_divid": 52, "flt": 37, "flush": 33, "fmt": [46, 48, 49, 53, 55], "focu": [35, 36, 52, 53, 54, 64, 66, 77], "focus": [54, 58, 77], "fold": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 35, 36, 37, 45, 51, 52, 53, 54, 58, 59, 60, 63, 65, 66, 68, 69, 74, 77], "follow": [16, 17, 18, 19, 33, 35, 36, 41, 42, 43, 44, 45, 46, 48, 49, 52, 53, 54, 57, 58, 59, 61, 62, 64, 65, 66, 67, 70, 73, 74, 77], "font_scal": [52, 53, 54], "fontsiz": [44, 54, 57], "force_all_x_finit": [3, 6], "forest": [20, 32, 33, 34, 36, 37, 40, 41, 45, 50, 51, 53, 58, 61, 65, 74, 77], "forest_summari": 53, "forg": [73, 75, 76], "form": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 19, 36, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 57, 58, 59, 64, 66, 70, 73, 74], "format": [41, 50, 70], "formula": [35, 36, 52, 53, 76], "formula_flex": 36, "forschungsgemeinschaft": 72, "forthcom": 75, "forum": 76, "forward": 8, "found": [42, 43, 47, 48, 49, 61, 62, 65, 66, 74], "foundat": [72, 75], "four": [36, 51, 53, 76], "fourth": [35, 52], "frac": [7, 16, 17, 18, 20, 21, 22, 24, 25, 26, 28, 33, 35, 37, 41, 46, 47, 50, 52, 55, 60, 61, 64, 66, 68, 69, 70, 71], "fraction": 37, "frame": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 36, 38, 42, 43, 45, 48, 49, 50, 52, 53, 54, 55, 56, 58, 59, 61, 62, 74, 77], "framework": [28, 33, 35, 37, 41, 51, 52, 55, 61, 65, 69, 71, 72, 74, 76, 77], "freez": 73, "fribourg": 75, "from": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 76, 77], "from_arrai": [3, 6, 41, 44, 45, 46, 57, 61, 62, 65, 69, 71, 74], "from_product": 52, "fr\u00e9chet": 70, "fsize": [36, 53, 54, 58, 77], "full": [41, 44, 45, 46, 48, 49, 51, 53, 54, 57, 59, 61], "fulli": [8, 36, 39, 53, 66], "fun": 33, "func": 34, "function": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 24, 25, 27, 28, 32, 33, 36, 37, 40, 41, 42, 43, 44, 45, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 69, 70, 71, 72, 75, 76, 77], "fund": [36, 53, 54, 72], "further": [16, 17, 18, 19, 23, 35, 37, 42, 43, 44, 45, 46, 50, 51, 52, 54, 56, 57, 58, 59, 65, 66, 68, 69, 70, 71, 72, 74, 76, 77], "furthermor": 41, "futurewarn": 49, "g": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 33, 34, 37, 38, 41, 42, 43, 45, 46, 47, 50, 51, 54, 55, 56, 58, 59, 61, 64, 65, 66, 68, 69, 70, 72, 73, 74, 77], "g_": [68, 69, 71], "g_0": [4, 5, 7, 8, 10, 11, 12, 24, 25, 33, 35, 36, 41, 51, 52, 53, 61, 64, 65, 66, 68, 70, 74, 77], "g_1": 51, "g_all": [33, 36], "g_all_po": 33, "g_ci": 36, "g_d": 68, "g_dml": 33, "g_dml_po": 33, "g_hat": [10, 11, 33, 41, 68], "g_hat0": [7, 8], "g_hat1": [7, 8], "g_k": 64, "g_nonorth": 33, "g_nosplit": 33, "g_nosplit_po": 33, "g_x": 46, "gain": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 31, 51, 70, 76], "gain_statist": 76, "galleri": [61, 64, 65, 66, 72, 76], "gamma": [22, 25, 26, 35, 52, 55, 56, 68], "gamma_0": [19, 56, 59, 68], "gamma_a": [16, 17], "gap": 52, "gate": [1, 8, 11, 55, 56, 63, 76], "gate_obj": 64, "gatet": 64, "gaussian": [9, 12, 13, 33, 41, 61, 64, 65, 69, 71, 75], "ge": [16, 18, 19, 50, 56, 64], "geer": 75, "gelbach": [35, 52], "gener": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 75, 76, 77], "generate_treat": 57, "geom_bar": 36, "geom_dens": 36, "geom_errorbar": 36, "geom_funct": 33, "geom_histogram": 33, "geom_hlin": 36, "geom_point": 36, "geom_til": 35, "geom_vlin": 33, "german": 72, "get": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 37, 51, 55, 58, 70, 72, 73], "get_dummi": 55, "get_feature_names_out": [52, 53], "get_logg": [33, 34, 35, 36, 37, 60, 65, 66, 67, 68, 69, 71, 74], "get_metadata_rout": [29, 30], "get_param": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 65], "ggdid": 34, "ggplot": [33, 35, 36], "ggplot2": [33, 35, 36], "ggsave": 33, "ggtitl": 36, "gh": 76, "git": 73, "github": [34, 36, 47, 53, 55, 72, 75, 76], "githubusercont": 47, "give": [36, 53], "given": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 21, 24, 25, 28, 33, 35, 41, 46, 48, 49, 52, 54, 55, 59, 61, 64, 69, 70, 71, 74, 76], "glmnet": [36, 37, 65, 76], "global": [2, 4, 5, 7, 8, 9, 10, 11, 12, 65], "glrn": 37, "glrn_lasso": 37, "gname": 34, "go": [42, 43, 47], "goal": [48, 49], "goldman": 75, "good": [47, 70, 77], "gradient": [36, 53], "gradientboostingclassifi": 51, "gradientboostingregressor": 51, "gramfort": [72, 74], "graph": [37, 59, 77], "graph_ensemble_classif": 37, "graph_ensemble_regr": 37, "graph_object": [42, 43, 47], "graphlearn": [37, 65], "grasp": 70, "great": [46, 77], "greater": 77, "green": [33, 42, 43, 44, 57], "greg": 75, "grei": 36, "grenand": 75, "grey50": 35, "grid": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 37, 42, 43, 44, 47, 54, 55, 57, 65, 70], "grid_arrai": [42, 43], "grid_bound": [2, 4, 5, 7, 8, 9, 10, 11, 12], "grid_search": [2, 4, 5, 7, 8, 9, 10, 11, 12, 37, 65], "grid_siz": [2, 4, 5, 7, 8, 9, 10, 11, 12, 42, 43], "gridextra": 35, "gridsearchcv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 65], "grisel": [72, 74], "grob": 35, "group": [8, 11, 32, 34, 40, 50, 54, 55, 56, 63], "group_0": 64, "group_1": [48, 49, 64], "group_2": [48, 49, 64], "group_3": [48, 49], "group_effect": 56, "group_ind": 50, "group_treat": 50, "groupbi": [47, 53], "gruber": 20, "gt": [32, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 62, 74], "guarante": [35, 52], "guber": 20, "guess": [58, 70], "guid": [27, 28, 29, 30, 33, 34, 35, 37, 41, 46, 50, 52, 58, 65, 72, 74, 76], "guidelin": 76, "gunion": [37, 65], "gxidclusterperiodytreat": 34, "h": [16, 17, 18, 20, 23, 34, 35, 52, 75], "h_0": [50, 58, 70, 77], "ha": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 18, 33, 34, 35, 36, 41, 47, 51, 52, 53, 54, 55, 58, 64, 65, 66, 70, 77], "half": [33, 41, 55, 61, 67], "hand": [51, 55, 77], "handbook": 55, "handl": [34, 51, 65, 76], "hansen": [14, 15, 21, 22, 24, 35, 47, 52, 61, 72, 75], "happend": 51, "hard": [58, 70], "harold": 75, "hat": [33, 35, 41, 47, 50, 52, 55, 60, 61, 64, 67, 68, 69, 70, 71], "have": [1, 8, 11, 13, 19, 32, 33, 34, 35, 36, 37, 40, 42, 43, 45, 46, 50, 51, 52, 53, 54, 55, 56, 58, 59, 62, 64, 65, 69, 70, 73, 74, 76, 77], "hazlett": 70, "hc": 75, "hdm": [35, 52], "he": 59, "head": [34, 35, 37, 38, 42, 43, 48, 49, 52, 53, 55, 62, 64, 74], "heat": [35, 52], "heatmap": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 52], "heavili": 51, "hei": 75, "height": [33, 35, 47], "help": [34, 36, 44, 51, 54, 56, 67, 77], "helper": 76, "henc": [34, 36, 37, 53, 65, 68, 77], "here": [9, 12, 13, 34, 35, 36, 37, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 56, 57, 59, 62, 65, 73], "heterogen": [8, 19, 36, 50, 53, 54, 56, 63, 66, 67, 75, 76, 77], "heteroskedast": [48, 49], "heurist": [33, 41, 61], "high": [10, 11, 21, 36, 46, 47, 53, 54, 60, 66, 69, 71, 72, 74, 75], "higher": [34, 36, 47, 53, 54, 55, 76, 77], "highli": [36, 53, 72], "highlight": [2, 4, 5, 7, 8, 9, 10, 11, 12, 45, 76], "highlightcolor": [42, 43], "hispan": 38, "hist_e401": 36, "hist_p401": 36, "histplot": 41, "hjust": 36, "hline": [62, 69, 71, 74, 77], "hold": [26, 35, 36, 52, 53, 59, 64, 65], "holdout": [65, 67], "holm": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "home": [36, 53], "homogen": 66, "hopefulli": 54, "horizont": [35, 46, 52], "hostedtoolcach": 53, "hot": 55, "hotstart_backward": [37, 65], "hotstart_forward": [37, 65], "household": [36, 53, 54, 58], "how": [29, 30, 32, 34, 35, 36, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 61, 65, 72, 73], "howev": [33, 36, 41, 53, 59, 61, 77], "hown": [36, 53, 54, 58, 77], "hpwt": [35, 52], "hpwt0": 35, "hpwtairmpdspac": 35, "href": 72, "hspace": 51, "hstack": 46, "html": [37, 49, 72, 74, 76], "http": [20, 25, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 65, 72, 73, 74, 76], "huber": [26, 59, 66, 68, 75], "hue": 53, "huge": 51, "hugo": 75, "husd": [37, 38, 62, 74], "hyperparamet": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 37, 38, 47, 51, 53, 63, 74], "hypothes": [69, 71, 75], "hypothesi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 53, 58, 70, 75], "i": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77], "i0": [45, 46, 66], "i03": 72, "i1": [45, 66], "i_": [22, 52, 56], "i_1": [35, 52], "i_2": [35, 52], "i_3": [35, 52], "i_4": 46, "i_est": 41, "i_fold": 35, "i_k": [35, 52, 60, 67, 69, 71], "i_learn": 51, "i_rep": [33, 41, 45, 51, 59, 61], "i_split": 52, "i_train": 41, "icp": 75, "id": [34, 35, 37, 52], "id_var": 52, "idea": [36, 37, 53, 54, 65, 70, 77], "ident": [16, 17, 18, 19, 22, 37, 65, 70], "identif": [66, 77], "identifi": [35, 36, 45, 50, 52, 53, 54, 64, 66, 70, 76], "identifii": 64, "idnam": 34, "idx_tau": [44, 54, 57], "idx_treat": [2, 4, 5, 7, 8, 9, 10, 11, 12, 70], "ieee": 75, "ifels": 34, "ignor": 41, "ii": [35, 52], "iid": 66, "iivm": [7, 20, 27, 28, 54, 60, 63, 64, 72, 76], "iivm_summari": 53, "iivmglmnet": 36, "iivmrang": 36, "iivmrpart": 36, "iivmxgboost11861": 36, "ij": [23, 35, 52, 59], "ilia": 75, "illustr": [33, 35, 36, 37, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 56, 57, 58, 59, 61, 65, 77], "iloc": [45, 46, 51, 52, 55], "immedi": 73, "immun": [67, 75], "impact": [32, 40, 51, 55, 58], "implement": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 27, 28, 33, 34, 35, 36, 37, 41, 45, 47, 51, 52, 53, 55, 58, 59, 61, 63, 64, 65, 66, 67, 69, 71, 72, 74, 75, 76, 77], "impli": [16, 17, 35, 36, 52, 53, 54, 64, 70], "implment": 46, "import": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76, 77], "importlib": 47, "improv": [45, 51, 56, 76], "in_sample_norm": [4, 5, 45, 68, 70], "inbuild": 51, "inbuilt": 51, "inc": [36, 53, 54, 58, 77], "includ": [2, 4, 5, 7, 8, 9, 10, 11, 12, 31, 34, 36, 46, 48, 49, 53, 58, 64, 66, 69, 70, 71, 76, 77], "include_bia": [52, 53], "include_scenario": [2, 4, 5, 7, 8, 9, 10, 11, 12], "incom": [36, 53, 54, 56, 58, 77], "incorpor": [37, 58, 70], "increas": [50, 51, 52, 77], "increment": 76, "ind": 53, "independ": [4, 5, 16, 17, 18, 19, 35, 37, 46, 50, 52, 56, 66, 68, 76], "index": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 35, 38, 41, 46, 47, 48, 49, 52, 53, 55, 56, 61, 62, 67, 68, 74], "index_col": 47, "india": [67, 75], "indic": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 19, 26, 35, 36, 46, 50, 52, 53, 54, 59, 60, 62, 64, 66, 67], "individu": [8, 34, 36, 46, 48, 49, 50, 53, 54, 58, 64, 77], "individual_df": 46, "induc": [63, 67], "industri": [35, 52], "inf": [3, 6, 34], "inf_model": 68, "infer": [21, 22, 32, 33, 35, 40, 41, 47, 52, 61, 63, 67, 72, 74, 75, 76], "inferenti": 77, "infinit": [3, 6, 76], "info": [32, 37, 38, 45, 50, 52, 53, 54, 58, 59, 62, 74, 76, 77], "inform": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 29, 30, 32, 37, 40, 42, 43, 51, 58, 70, 75], "infti": [33, 41, 61], "inherit": [55, 76], "initi": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 36, 37, 44, 45, 53, 54, 57, 58, 59, 62, 64, 65, 67, 74, 76, 77], "inlin": [38, 55], "inlinebackend": 55, "inner": [2, 4, 5, 7, 8, 9, 10, 11, 12, 65], "innermost": 65, "input": [2, 4, 5, 7, 8, 9, 10, 11, 12, 37, 58, 60, 69, 70, 71], "insight": 47, "insignific": 58, "inspect": 74, "inspir": [20, 21, 26], "instal": [36, 76], "install_github": 73, "instanc": [36, 37, 53, 65], "instanti": [35, 36, 52, 53, 65, 67], "instead": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 34, 36, 40, 49, 50, 53, 54, 64, 65, 70, 76], "instruct": 76, "instrument": [3, 6, 7, 10, 14, 20, 22, 34, 35, 36, 37, 38, 45, 50, 52, 53, 54, 57, 58, 59, 62, 65, 66, 68, 69, 74, 77], "instrument_effect": [32, 34], "instrument_impact": 40, "int": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 34, 35, 36, 40, 44, 45, 56, 57, 59], "int64": [38, 51, 52, 62, 74], "int8": [53, 54, 58], "integ": [18, 37, 65], "integr": [70, 76], "intend": [37, 77], "intent": 77, "inter": 65, "interact": [7, 8, 16, 20, 21, 63, 65, 72, 76, 77], "interchang": 69, "interest": [7, 8, 10, 11, 16, 17, 33, 36, 41, 45, 47, 53, 54, 59, 61, 64, 66, 68, 69, 71, 74, 77], "interfac": [36, 37, 62, 65, 67, 74], "intermedi": 49, "intern": [34, 36, 37, 54, 65, 75], "internet": [36, 53, 54], "interpret": [48, 49, 64, 70, 73, 77], "intersect": [70, 76], "interv": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 42, 43, 44, 45, 48, 49, 52, 54, 57, 58, 59, 63, 64, 67, 68, 70, 74, 75, 77], "introduc": [33, 41, 61, 62, 69, 71, 76, 77], "introduct": [33, 35, 37, 41, 52, 54, 58, 65, 66, 70], "introductori": 34, "intrument": 59, "inuidur1": [37, 38, 62, 74], "inuidur1femaleblackothracedep1dep2q2q3q4q5q6agelt35agegt54durablelusdhusdtg": [37, 62, 74], "inuidur2": [38, 62, 74], "inv_sigmoid": 55, "invalid": [33, 41, 61], "invari": 66, "invers": [2, 7, 8, 9, 12, 13, 59, 70], "invert_yaxi": 52, "investig": 47, "involv": [64, 65, 68, 77], "io": [55, 76], "ipw_norm": 76, "ipykernel_43323": 49, "ipynb": [32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "ira": [36, 53, 54], "irm": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 21, 27, 28, 51, 60, 63, 65, 72, 76, 77], "irm_summari": 53, "irmglmnet": 36, "irmrang": 36, "irmrpart": 36, "irmxgboost8047": 36, "is_classifi": [4, 5, 7, 8, 11], "is_gat": [1, 8, 11], "isnan": [2, 4, 5, 7, 8, 9, 10, 11, 12, 51, 65], "issn": 47, "issu": [53, 72, 75, 76], "ite": [48, 49, 50], "item": [7, 53, 60, 65, 67], "iter": [32, 45, 52, 59, 65, 69, 71, 77], "itertool": 47, "its": [29, 30, 60, 64, 65, 66, 67, 68, 69], "iv": [7, 10, 11, 20, 22, 23, 33, 35, 41, 52, 61, 62, 63, 70, 72, 76, 77], "iv_2": 32, "iv_var": [35, 52], "iv\u00e1n": [67, 75], "j": [14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 33, 34, 35, 37, 41, 47, 52, 55, 59, 61, 65, 69, 71, 72, 74], "j_": [35, 52], "j_0": 69, "j_1": [35, 52], "j_2": [35, 52], "j_3": [35, 52], "j_k": [35, 52], "jame": 75, "janni": [36, 53], "javanmard": 75, "jbe": [35, 52], "jeconom": [16, 17, 18, 34], "jerzi": 75, "jmlr": [37, 72, 74, 76], "job": [36, 53, 54], "joint": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 42, 43, 44, 48, 49, 54, 57, 66, 69, 76, 77], "jointli": [57, 64], "joss": [37, 65, 72, 74], "journal": [14, 15, 16, 17, 18, 23, 24, 26, 34, 35, 37, 47, 52, 55, 61, 65, 72, 74, 75, 76], "jss": 72, "jump": 56, "jun": 75, "jupyt": [32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "juraj": 75, "just": [34, 37, 44, 45, 46, 48, 49, 50, 56, 57, 68, 70], "justif": [67, 70], "k": [14, 17, 18, 20, 21, 22, 23, 24, 26, 33, 35, 37, 41, 51, 52, 60, 61, 63, 64, 69, 71, 77], "kaggl": [36, 53], "kallu": [44, 54, 57, 58, 68, 75], "kato": [23, 35, 52, 69, 71, 75], "kb": [45, 50, 52, 53, 54, 58, 62, 74], "kde": [9, 12, 13, 53], "kdeplot": [45, 51, 59], "kdeunivari": [9, 12, 13], "kecsk\u00e9sov\u00e1": 76, "keep": [34, 49, 77], "kei": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 36, 42, 43, 48, 49, 52, 53, 54, 65, 68, 70, 76], "keith": 75, "kengo": 75, "kernel": [9, 12, 13], "keyword": [18, 23, 24, 25], "kf": 67, "kfold": [52, 67], "kind": [32, 40, 53], "kj": [17, 18, 20, 21, 22, 23, 24, 26, 33, 35, 41, 52, 61], "klaassen": [20, 72, 75], "klaa\u00dfen": 20, "knau": 75, "know": [45, 56], "knowledg": [32, 40, 51, 55, 56], "known": [50, 51, 65], "kohei": 75, "kotthof": 37, "kotthoff": [37, 65, 72, 74], "krueger": 55, "kueck": [36, 53], "kurz": [72, 75, 76], "kwarg": [17, 18, 23, 24, 25, 29], "l": [35, 37, 38, 42, 43, 52, 59, 65, 70, 72, 74], "l1": [53, 59, 66], "l_hat": [10, 11, 33, 41, 68], "label": [41, 42, 43, 44, 46, 48, 49, 54, 55, 57], "labor": 55, "laffer": 75, "laff\u00e9r": [26, 59, 66, 68], "lal": [55, 76], "lambda": [35, 36, 37, 53, 55, 56, 65, 68, 69, 71, 74], "lambda_": 47, "lambda_0": 68, "lambda_t": 18, "land": 56, "lang": [37, 65, 72, 74], "langl": [19, 56], "lappli": 67, "larg": [33, 41, 50, 51, 55], "larger": [8, 34, 70], "largest": 51, "largli": 51, "lasso": [35, 36, 37, 53, 59, 65, 74, 75], "lasso_class": [36, 53], "lasso_pip": [37, 65], "lasso_summari": 53, "lassocv": [47, 52, 53, 59, 65, 66, 69, 71, 74], "last": [18, 37, 73], "late": [7, 32, 36, 53, 66, 68], "latent": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 58, 70], "later": [36, 37, 65, 77], "layout": 47, "lbrace": [7, 8, 20, 21, 26, 35, 52, 60, 66, 67, 69, 71], "ldot": [10, 11, 35, 52, 59, 60, 66, 67, 69, 71, 74], "le": [18, 45, 56, 64, 66, 68], "lead": 34, "leadsto": 69, "lear": [37, 65, 72, 74], "learn": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 23, 24, 25, 26, 32, 36, 37, 38, 40, 44, 47, 51, 53, 54, 55, 57, 62, 63, 65, 67, 68, 69, 70, 71, 76, 77], "learner": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 36, 41, 42, 43, 45, 47, 52, 53, 54, 58, 59, 60, 61, 63, 66, 67, 68, 69, 70, 71, 76, 77], "learner_class": 76, "learner_cv": 37, "learner_forest_classif": 37, "learner_forest_regr": 37, "learner_l": 58, "learner_lasso": 37, "learner_list": 51, "learner_m": 58, "learner_nam": [2, 4, 5, 7, 8, 9, 10, 11, 12, 65], "learner_param_v": 37, "learner_rf": 69, "learnerclassif": 37, "learnerregr": 37, "learnerregrcvglmnet": 37, "learnerregrrang": [37, 65], "learning_r": [41, 44, 54, 57, 61], "least": [32, 36, 40, 53, 54, 58, 67], "leav": 59, "left": [20, 21, 22, 23, 26, 33, 35, 41, 51, 52, 53, 54, 55, 57, 61, 68, 69, 70, 71], "legend": [36, 41, 42, 43, 44, 46, 48, 49, 51, 54, 55, 57], "len": [44, 51, 52, 54, 57], "length": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 37, 45, 65], "leq": [35, 52], "less": [34, 36, 53, 54], "lester": 75, "let": [16, 17, 18, 33, 34, 36, 37, 41, 44, 45, 48, 49, 51, 53, 54, 57, 59, 60, 61, 65, 66, 70, 77], "level": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 36, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 57, 58, 59, 65, 70, 77], "level_0": [37, 52], "level_1": 52, "levinsohn": [35, 52], "lewi": 75, "lgbmclassifi": [44, 45, 46, 51, 54, 57], "lgbmregressor": [41, 44, 45, 46, 51, 54, 61], "lgr": [33, 34, 35, 36, 37, 60, 65, 66, 67, 68, 69, 71, 74], "lib": [52, 53], "liblinear": [53, 59, 66], "librari": [32, 33, 34, 35, 36, 37, 60, 61, 62, 65, 66, 67, 68, 69, 71, 73, 74, 77], "licens": 76, "lie": 75, "lightgbm": [41, 44, 45, 46, 51, 54, 57], "like": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 36, 37, 47, 49, 53, 54, 65, 67, 74, 77], "lim": 55, "limegreen": [42, 43], "limit": [55, 75], "limits_": 64, "line": [2, 4, 5, 7, 8, 9, 10, 11, 12, 46], "linear": [1, 8, 10, 11, 17, 22, 23, 24, 25, 27, 28, 32, 33, 34, 35, 37, 40, 41, 42, 43, 45, 46, 47, 48, 51, 52, 58, 60, 61, 63, 64, 65, 67, 69, 71, 72, 74, 75, 76, 77], "linear_model": [38, 40, 47, 51, 52, 53, 59, 65, 66, 69, 71, 74], "linearregress": [32, 40, 51], "linearscoremixin": 68, "linestyl": 46, "linewidth": 46, "link": 76, "linspac": [42, 43], "lint": 76, "linux": 73, "list": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 33, 34, 35, 36, 37, 41, 42, 43, 52, 54, 56, 61, 65, 67, 68, 73, 76], "listedcolormap": 52, "literatur": 66, "littl": 50, "ll": [37, 69, 71, 77], "lllllllllllllllll": [62, 74], "lm": [32, 34], "ln_alpha_ml_l": 47, "ln_alpha_ml_m": 47, "load": [32, 34, 36, 37, 47, 53, 54, 62, 73, 74], "loc": [41, 44, 46, 47, 49, 52, 55, 57, 58], "local": [7, 9, 64, 66, 75, 76], "localconvert": 52, "locat": [44, 57], "log": [35, 47, 52, 55], "log_odd": 56, "log_p": [35, 52], "log_reg": [32, 34], "logarithm": 47, "logic": [7, 37, 65], "logical_not": [2, 4, 5, 7, 8, 9, 10, 11, 12, 51, 65], "logist": [32, 34, 36, 40, 53, 59, 77], "logisticregress": [32, 38, 40], "logisticregressioncv": [51, 53, 59, 66], "logit": [51, 55], "loglik": [37, 65], "logloss": [36, 53, 77], "logo": 76, "logspac": 53, "long": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 33, 41, 51, 58, 70, 75], "look": [34, 36, 37, 44, 45, 46, 51, 53, 54, 57, 58], "loss": 51, "low": [46, 50, 64, 75], "lower": [36, 37, 44, 46, 47, 50, 54, 55, 57, 58, 65, 70, 77], "lower_bound": [42, 43], "lpq": [9, 13, 54, 64, 76], "lpq_0": 57, "lpq_1": 57, "lqte": 64, "lrn": [32, 33, 34, 35, 36, 37, 60, 65, 66, 67, 68, 69, 71, 74, 77], "lrn_0": 37, "lt": [32, 34, 35, 36, 37, 38, 45, 50, 52, 53, 54, 56, 58, 59, 62, 74], "lucien": 76, "luka": 75, "luk\u00e1\u0161": 26, "lusd": [37, 38, 62, 74], "lvert": 47, "m": [14, 15, 16, 22, 23, 24, 33, 35, 37, 38, 41, 47, 50, 52, 55, 61, 63, 64, 65, 68, 70, 72, 73, 74, 75, 76], "m_": [68, 69, 71], "m_0": [2, 4, 5, 7, 8, 10, 11, 12, 24, 25, 33, 35, 36, 41, 47, 50, 52, 53, 61, 64, 65, 66, 68, 74, 77], "m_hat": [7, 8, 10, 11, 33, 41, 68], "ma": [23, 35, 52, 75], "mac": 73, "machin": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 23, 24, 25, 26, 32, 36, 37, 38, 40, 44, 45, 47, 53, 54, 55, 57, 58, 59, 63, 65, 66, 67, 68, 69, 70, 71, 76, 77], "machineri": [47, 75], "mackei": 75, "maco": 73, "made": [66, 77], "mae": [2, 4, 5, 7, 8, 9, 10, 11, 12, 51, 65], "maggi": 75, "magnitud": 70, "mai": [45, 59], "main": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 47, 54, 69, 70, 71, 75, 77], "maintain": [72, 76], "mainten": 76, "major": [37, 76], "make": [32, 40, 51, 64, 65, 76, 77], "make_confounded_plr_data": 58, "make_did_sz2020": [4, 5, 45, 66], "make_heterogeneous_data": [42, 43, 48, 49, 50], "make_iivm_data": [7, 9, 64, 66], "make_irm_data": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 51, 64, 65, 66], "make_pipelin": 53, "make_pliv_chs2015": [10, 66], "make_pliv_multiway_cluster_ckms2021": [3, 35, 52], "make_plr_ccddhnr2018": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 33, 41, 60, 61, 64, 65, 66, 67, 68, 69, 70], "make_spd_matrix": 25, "make_ssm_data": [59, 66], "malt": [72, 75], "maltekurz": 72, "man": [32, 40], "manag": [65, 73], "mani": [22, 27, 28, 33, 34, 35, 37, 41, 45, 52, 61, 68, 69, 71, 77], "manili": 1, "manipul": [36, 37], "manual": [36, 58, 77], "mao": 75, "map": [7, 29, 30, 34, 35, 52, 64, 66], "mapsto": [60, 64], "mar": [26, 66], "margin": [42, 43], "marit": [36, 53], "markers": 55, "market": 55, "markettwo": 35, "markov": [25, 75], "marr": [36, 53, 54, 58, 77], "marshal": 65, "martin": [26, 72, 75, 76], "masatoshi": 75, "master": 34, "mat": 35, "match": [65, 70], "math": 50, "mathbb": [7, 8, 10, 11, 16, 17, 18, 27, 28, 35, 45, 46, 50, 51, 52, 55, 59, 64, 66, 68, 69, 70, 71, 74, 77], "mathcal": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 35, 41, 44, 46, 52, 56, 57, 59, 61], "mathop": 64, "mathrm": [16, 17], "matplotlib": [38, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 57, 59], "matric": [56, 63, 76], "matrix": [16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 33, 35, 36, 37, 41, 52, 59, 61, 62, 65, 69, 71, 74, 76, 77], "matt": 75, "matter": [51, 55], "max": [36, 37, 53, 54, 60, 64, 65, 66, 67, 68, 69, 74, 77], "max_depth": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 41, 53, 58, 60, 64, 65, 66, 67, 68, 69, 70, 74, 77], "max_featur": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 41, 53, 58, 60, 64, 65, 66, 67, 68, 69, 70, 74, 77], "max_it": [52, 53], "maxim": [2, 4, 5, 7, 8, 9, 10, 11, 12, 56, 64], "maxima": [69, 71], "maximum": [64, 65], "mb": [38, 59, 62, 74], "mb706": 76, "mea": 20, "mean": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 35, 36, 40, 41, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 61, 65, 69, 77], "mean_absolute_error": [2, 4, 5, 7, 8, 9, 10, 11, 12, 51, 65], "meant": [64, 76], "measir": 58, "measur": [34, 37, 47, 58, 65, 66, 70], "measure_col": 47, "measure_func": 34, "measure_pr": 34, "measures_r": 34, "mechan": [29, 30], "median": 67, "melt": 35, "memori": [38, 45, 50, 52, 53, 54, 58, 59, 62, 74], "mention": [50, 64], "merg": [36, 53], "mert": [67, 75], "meshgrid": [42, 43], "messag": [33, 34, 35, 36, 37, 74, 76], "meta": [65, 74], "metadata": [29, 30], "metadatarequest": [29, 30], "method": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76], "methodolog": 75, "metric": [2, 4, 5, 7, 8, 9, 10, 11, 12, 65], "michael": 75, "michaela": 76, "michel": [72, 74], "michela": [26, 75], "mid": [36, 53, 55], "might": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 44, 51, 52, 56, 58, 65], "mild": [33, 41, 61], "militari": 55, "miller": [35, 52], "min": [35, 36, 37, 44, 52, 53, 54, 57, 60, 65, 66, 67, 68, 69, 71, 74, 77], "min_": 64, "min_samples_leaf": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 41, 50, 53, 58, 60, 64, 65, 66, 67, 68, 69, 70, 77], "min_samples_split": 53, "minim": [8, 36, 51, 53], "minor": [33, 41, 61, 68, 76], "minsplit": 36, "miruna": 75, "mislead": 76, "miss": [3, 6, 37, 65, 66, 68, 76], "missing": [26, 59], "misspecif": 45, "misspecifi": 45, "mit": [72, 74], "mixin": [27, 28, 68], "ml": [25, 35, 36, 37, 47, 52, 53, 60, 63, 65, 67, 72, 75, 76], "ml_g": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 36, 38, 40, 41, 42, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 76], "ml_g0": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 36, 38, 45, 51, 53, 58, 65, 66], "ml_g1": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 36, 38, 45, 51, 53, 58, 65, 66], "ml_g_d0": [59, 66], "ml_g_d0_t0": [45, 66], "ml_g_d0_t1": [45, 66], "ml_g_d1": [59, 66], "ml_g_d1_t0": [45, 66], "ml_g_d1_t1": [45, 66], "ml_l": [10, 11, 33, 35, 36, 37, 38, 41, 43, 49, 52, 53, 55, 58, 60, 61, 65, 66, 67, 68, 69, 70, 71, 74, 76, 77], "ml_l_bonu": 74, "ml_l_forest": 37, "ml_l_forest_pip": 37, "ml_l_lasso": 37, "ml_l_lasso_pip": 37, "ml_l_rf": 77, "ml_l_sim": 74, "ml_l_tune": 65, "ml_l_xgb": 77, "ml_m": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 71, 74, 76, 77], "ml_m_bonu": 74, "ml_m_forest": 37, "ml_m_forest_pip": 37, "ml_m_lasso": 37, "ml_m_lasso_pip": 37, "ml_m_rf": 77, "ml_m_sim": 74, "ml_m_tune": 65, "ml_m_xgb": 77, "ml_pi": [59, 66], "ml_r": [7, 10, 32, 35, 36, 40, 52, 53, 66, 76], "ml_r0": 66, "ml_r1": [36, 53, 66], "mlr": [37, 65], "mlr3": [32, 33, 34, 35, 36, 60, 65, 66, 67, 68, 69, 71, 72, 74, 76, 77], "mlr3book": [37, 65], "mlr3extralearn": [36, 65], "mlr3filter": 37, "mlr3learner": [32, 33, 34, 35, 36, 60, 65, 66, 67, 68, 69, 71, 74, 77], "mlr3measur": 34, "mlr3pipelin": [65, 76], "mlr3tune": [37, 65, 76], "mlr3vers": 36, "mlrmeasur": 34, "mode": 73, "model": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 37, 40, 41, 44, 45, 46, 47, 50, 51, 52, 54, 57, 58, 60, 61, 62, 63, 65, 71, 72, 75, 76], "model_data": [36, 53], "model_select": [2, 4, 5, 7, 8, 9, 10, 11, 12, 41, 52, 65, 67], "modelmlestimatelowerupp": 36, "modern": [37, 65, 72, 74], "moment": [27, 28, 35, 52, 68, 69, 70, 71, 74], "monoton": 66, "mont": [16, 17, 19, 42, 43, 48, 49], "montanari": 75, "more": [8, 32, 34, 36, 40, 42, 43, 47, 51, 53, 54, 58, 60, 64, 65, 66, 68, 69, 70, 74, 77], "moreov": [36, 37, 47, 65, 69, 71, 77], "mortgag": [36, 53, 54], "most": [36, 44, 51, 53, 54, 57, 64, 65, 70, 73], "motiv": 61, "motivation_example_bch": 47, "mp": 34, "mpd": [35, 52], "mpg": 52, "mse": [37, 47, 65], "msr": [37, 65], "mtry": [36, 37, 60, 65, 66, 67, 68, 69, 77], "mu": 46, "mu_": 46, "mu_mean": 46, "much": [36, 37, 53, 77], "muld": [38, 62, 74], "multi": [34, 35, 42, 43, 52], "multiclass": 37, "multiindex": 52, "multipl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 45, 52, 53, 58, 59, 62, 65, 66, 67, 69, 70, 71, 76, 77], "multipletest": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "multipli": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 41, 63, 64, 68, 77], "multiprocess": [44, 54, 57], "multitest": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "multiwai": [23, 35, 52, 75], "music": 75, "must": [2, 4, 5, 7, 8, 9, 10, 11, 12, 65, 66], "mutat": 37, "mutual": [8, 11, 36, 48, 49, 53, 54, 64], "my_sampl": 67, "my_task": 67, "n": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 37, 40, 41, 44, 46, 47, 50, 52, 55, 56, 57, 59, 60, 61, 64, 65, 67, 69, 71, 72, 73], "n_": 46, "n_coef": [2, 4, 5, 7, 8, 9, 10, 11, 12, 70], "n_complier": 57, "n_core": [44, 54, 57], "n_estim": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 41, 42, 43, 44, 45, 46, 48, 49, 50, 53, 54, 56, 57, 58, 60, 61, 64, 65, 66, 67, 68, 69, 70, 74, 77], "n_eval": [37, 65], "n_fold": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 34, 35, 36, 38, 41, 42, 43, 44, 45, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 61, 65, 67, 74, 77], "n_folds_per_clust": [35, 52], "n_folds_tun": [2, 4, 5, 7, 8, 9, 10, 11, 12], "n_iter_randomized_search": [2, 4, 5, 7, 8, 9, 10, 11, 12, 65], "n_job": 53, "n_jobs_cv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 51], "n_jobs_model": [13, 44, 54, 57], "n_ob": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 33, 37, 41, 42, 43, 45, 46, 48, 49, 50, 51, 58, 59, 61, 62, 64, 65, 66, 67, 69, 70, 71, 74], "n_rep": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 34, 35, 38, 41, 45, 50, 51, 52, 58, 59, 61, 65, 67, 70, 74, 77], "n_rep_boot": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 42, 43, 44, 48, 49, 54, 57, 69, 71], "n_sampl": 56, "n_split": 67, "n_t": 46, "n_time_period": 46, "n_true": [44, 57], "n_var": [33, 37, 41, 61, 62, 65, 69, 71, 74], "n_w": 56, "n_x": [19, 42, 43, 48, 49, 50], "na": [3, 6, 33, 35, 61, 76], "na_real_": [35, 76], "naiv": [33, 41, 61], "name": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 33, 34, 35, 48, 49, 50, 52, 58, 65, 73, 76], "namespac": 34, "nan": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 41, 44, 45, 46, 48, 49, 51, 53, 54, 57, 59, 61, 65], "nanmean": 41, "narita": 75, "nathan": 75, "nation": [67, 75], "nativ": 34, "natt": 56, "nbsphinx": 50, "ncol": [35, 36, 37, 62, 65, 69, 71, 74], "ncoverag": 51, "ndarrai": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 20, 21, 22, 23, 24, 25, 26, 62], "nearli": 51, "necess": [35, 52], "necessari": [34, 35, 52], "need": [2, 4, 5, 7, 8, 9, 10, 11, 12, 28, 32, 33, 34, 36, 40, 41, 54, 59, 65, 67, 70, 76, 77], "neighborhood": 69, "neither": [3, 6, 35, 52, 62], "neng": 75, "neq": 66, "nest": [2, 4, 5, 7, 8, 9, 10, 11, 12, 65, 68, 70], "net": [54, 58, 77], "net_tfa": [36, 53, 54, 58, 77], "never": [7, 34, 35, 49, 52, 76], "never_tak": [7, 36, 53], "new": [32, 33, 34, 35, 36, 37, 42, 43, 53, 56, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 76, 77], "new_data": [42, 43, 56], "newei": [14, 15, 24, 35, 47, 52, 61, 72, 75], "newest": 76, "next": [34, 36, 37, 42, 43, 44, 50, 51, 53, 54, 56, 57, 76], "neyman": [35, 52, 60, 63, 70, 72, 75], "nfold": [35, 36], "nice": 34, "nifa": [53, 54, 58], "nine": [35, 52], "node": [36, 37, 60, 66, 67, 68, 69, 74, 77], "nois": [55, 56], "non": [18, 23, 24, 25, 32, 33, 36, 40, 41, 46, 53, 54, 56, 65, 67, 68, 69], "non_orth_scor": [33, 41, 68], "nondur": 38, "none": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 35, 36, 38, 40, 45, 50, 53, 54, 58, 59, 62, 65, 66, 68, 69, 73, 74], "nonlinear": [28, 36, 53, 68, 76], "nonlinearscoremixin": 68, "nonparametr": [9, 12, 13, 70, 75], "nop": 37, "nor": [3, 6, 35, 52, 62], "norm": 41, "normal": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 33, 40, 41, 44, 45, 46, 50, 54, 55, 56, 57, 59, 61, 62, 65, 68, 69, 71, 74], "normalize_ipw": [2, 7, 8, 9, 12, 13, 54, 59], "notat": [35, 45, 52, 59, 66], "note": [3, 6, 7, 8, 10, 11, 27, 28, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 67, 68, 72, 74], "notebook": [32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 77], "notic": [32, 40], "now": [34, 35, 36, 42, 43, 51, 52, 53, 56, 59, 74, 76], "np": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 20, 21, 22, 23, 24, 25, 26, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 77], "nround": [33, 36, 77], "nrow": [34, 35, 37, 62, 65, 69, 71, 74], "nu": [7, 18, 25, 59, 66, 70], "nu2": 70, "nu_0": 70, "nu_i": 59, "nuis_g0": 32, "nuis_g1": 32, "nuis_l": 77, "nuis_m": [32, 77], "nuis_r0": 32, "nuis_r1": 32, "nuis_rmse_ml_l": 47, "nuis_rmse_ml_m": 47, "nuisanc": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 24, 25, 33, 34, 35, 36, 37, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 65, 67, 68, 69, 70, 72, 76, 77], "nuisance_el": 70, "nuisance_target": 51, "null": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 58, 65, 70, 76], "null_hypothesi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 58, 70], "num": [36, 37, 60, 65, 66, 67, 68, 69, 74], "num_leav": [44, 46, 54, 57], "number": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 35, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 54, 56, 57, 67, 69, 71, 72, 74, 77], "numer": [28, 32, 34, 37, 55, 65, 68, 70, 76], "numeric_onli": 47, "numpi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74], "ny": 75, "o": [46, 48, 49, 53, 55, 69, 72, 74], "ob": [34, 36, 46], "obei": 68, "obj_dml_data": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 35, 40, 41, 44, 52, 57, 60, 61, 64, 65, 66, 67, 68, 69, 70, 76], "obj_dml_data_bonu": 62, "obj_dml_data_bonus_df": 62, "obj_dml_data_from_arrai": [3, 6], "obj_dml_data_from_df": [3, 6], "obj_dml_data_sim": 62, "obj_dml_plr": [33, 41, 61], "obj_dml_plr_bonu": [37, 74], "obj_dml_plr_bonus_pip": 37, "obj_dml_plr_bonus_pipe2": 37, "obj_dml_plr_bonus_pipe3": 37, "obj_dml_plr_bonus_pipe_ensembl": 37, "obj_dml_plr_nonorth": [33, 41], "obj_dml_plr_orth_nosplit": [33, 41], "obj_dml_plr_sim": [37, 74], "obj_dml_plr_sim_pip": 37, "obj_dml_plr_sim_pipe_ensembl": 37, "obj_dml_plr_sim_pipe_tun": 37, "object": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30, 32, 36, 37, 38, 42, 43, 44, 45, 49, 50, 53, 54, 57, 59, 62, 64, 65, 66, 67, 68, 69, 72, 74, 75, 76, 77], "obs_confound": [32, 40], "observ": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 74, 75, 77], "obtain": [16, 17, 32, 33, 34, 35, 40, 41, 42, 43, 44, 45, 47, 51, 52, 57, 59, 60, 61, 64, 65, 67, 68, 69, 70, 71, 73, 74], "occur": 76, "off": [56, 75], "offer": [34, 36, 53, 54, 77], "offici": 73, "often": 57, "oka": 75, "omega": [50, 64, 70], "omega_": [23, 35, 52], "omega_1": [23, 35, 52], "omega_2": [23, 35, 52], "omega_epsilon": [35, 52], "omega_v": [23, 35, 52], "omega_x": [23, 35, 52], "omit": [58, 70, 75, 76, 77], "onc": [34, 77], "one": [10, 31, 32, 33, 35, 36, 37, 40, 41, 42, 43, 51, 52, 54, 55, 58, 61, 64, 65, 66, 67, 68, 69, 70, 71, 74, 76], "ones": [37, 44, 46, 57, 58, 64], "ones_lik": 57, "onli": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 42, 43, 48, 49, 50, 51, 52, 53, 54, 60, 64, 65, 66, 68, 69, 70, 76], "onlin": 77, "onto": 51, "oob_error": [37, 65], "oop": 76, "opac": [42, 43], "open": [37, 65, 72, 74], "oper": 37, "opposit": 56, "oprescu": [19, 42, 43, 48, 49, 75], "opt": 53, "optim": [2, 4, 5, 7, 8, 9, 10, 11, 12, 37, 42, 43, 56, 64, 65, 75], "option": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 33, 35, 36, 42, 43, 48, 49, 50, 51, 52, 53, 54, 59, 65, 67, 68, 69, 71, 76], "oracle_valu": [16, 17], "orang": 33, "orcal": [16, 17], "order": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 36, 37, 52, 53, 65, 67, 68], "org": [20, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 65, 72, 73, 76], "orient": [37, 65, 68, 72, 74, 75, 76], "origin": [34, 37, 49, 56, 58, 64], "orign": [36, 53], "orth_sign": 1, "orthogon": [1, 35, 36, 52, 53, 60, 63, 69, 70, 71, 72, 75], "orthongon": 70, "osx": 73, "other": [3, 6, 10, 11, 33, 35, 36, 37, 41, 45, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 65, 66, 67, 69, 70, 72, 73, 74, 75, 76, 77], "other_ind": 52, "otherwis": [4, 5, 7, 8, 11, 36, 53, 54, 56, 66], "othrac": [37, 38, 62, 74], "our": [33, 34, 36, 37, 41, 42, 43, 44, 45, 51, 53, 54, 57, 58, 61, 72, 74, 76, 77], "ourselv": 51, "out": [10, 11, 35, 37, 38, 45, 47, 51, 52, 54, 58, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 76, 77], "outcom": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 18, 32, 34, 35, 36, 37, 38, 40, 46, 47, 50, 52, 53, 54, 55, 56, 57, 58, 62, 65, 66, 68, 69, 70, 74, 76, 77], "outcome_0": 40, "outcome_1": 40, "outer": [2, 4, 5, 7, 8, 9, 10, 11, 12, 65], "output": [34, 51, 60, 69, 71, 77], "outshr": 52, "outsid": 33, "over": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 41, 47, 51, 61, 63, 65, 70, 71], "overal": 56, "overcom": [63, 68], "overfit": [63, 67], "overlap": [45, 66], "overrid": [65, 76], "overst": [36, 53, 54], "overview": [51, 69, 70, 75], "overwrit": 76, "ownership": [36, 53], "p": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 21, 33, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76], "p401": [36, 53, 54], "p_0": 68, "p_1": [69, 71], "p_adjust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 67, 69, 71, 72, 74], "p_dbl": [37, 65], "p_int": 65, "p_n": 22, "p_val": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "p_x": [23, 35, 52], "p_x0": 55, "p_x1": 55, "packag": [32, 33, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 54, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 77], "packagedata": 52, "packagevers": 36, "page": [72, 75], "pair": [32, 40], "pake": [35, 52], "paket": [35, 36, 37], "pal": 35, "panda": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 38, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 64, 70, 74], "pandas2ri": 52, "panel": [4, 18, 75, 76], "paper": [20, 22, 37, 55, 58, 70, 72, 74, 75, 76], "par": 38, "par_grid": [37, 65], "paradox": [37, 65, 76], "parallel": [34, 44, 45, 46, 51, 57, 66], "param": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 65], "param_grid": [2, 4, 5, 7, 8, 9, 10, 11, 12, 65], "param_nam": 34, "param_set": [37, 65], "param_v": 37, "paramet": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 76, 77], "parametr": [34, 61, 65, 77], "params_exact": 65, "params_nam": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34], "parenttoc": 72, "part": [25, 33, 35, 36, 37, 41, 51, 52, 53, 61, 65, 67, 70, 76, 77], "parti": 25, "partial": [10, 11, 17, 22, 23, 24, 25, 28, 35, 37, 38, 47, 52, 58, 60, 63, 65, 67, 69, 71, 72, 74, 76, 77], "partial_": [68, 69], "partiallli": 58, "particip": [14, 54, 58, 77], "particular": 72, "partion": [35, 52], "partit": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 52, 60, 63], "partli": 77, "pass": [1, 34, 37, 65, 77], "passo": [72, 74], "past": 35, "paste0": 35, "pastel": 41, "path": [65, 66], "path_to_r": 47, "patsi": [42, 43, 64], "paul": 75, "pd": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 64], "pdf": [41, 55], "pedregosa": [72, 74], "pedregosa11a": [72, 74], "pedro": [34, 75], "penal": 59, "penalti": [36, 37, 40, 53, 59, 65, 66], "pennsylvania": [15, 62, 74], "pension": [36, 53, 54, 77], "peopl": [36, 53, 54], "pep8": 76, "per": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 52], "percent": 65, "percentag": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17], "perf_count": 51, "perform": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 35, 37, 41, 45, 47, 49, 50, 51, 52, 54, 58, 59, 61, 65, 66, 67, 68, 69, 71, 72, 74, 75, 77], "perfrom": 50, "perhap": 77, "period": [4, 34, 45, 46, 66], "perp": 66, "perrot": [72, 74], "person": 77, "peter": 75, "pfister": [37, 65, 72, 74], "phi": [35, 52, 64, 69], "philipp": [72, 75], "philippbach": [72, 76], "pi": [21, 22, 25, 64, 66, 68], "pi_": [23, 35, 52], "pi_0": 68, "pi_i": [59, 66], "pick": 77, "pip3": 73, "pipe": 37, "pipe_forest_classif": 37, "pipe_forest_regr": 37, "pipe_lasso": 37, "pipelin": [37, 53, 76], "pipeop": 37, "pira": [36, 53, 54, 58, 77], "pivot": [47, 52, 75], "plai": 77, "plan": [14, 36, 53, 54, 77], "pleas": [29, 30, 34, 67], "plim": 55, "pliv": [10, 27, 28, 35, 52, 60, 63, 64, 72, 76], "plm": [65, 69, 70, 77], "plot": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 34, 36, 37, 41, 42, 43, 44, 46, 47, 48, 49, 50, 53, 54, 55, 57, 58, 59, 64, 70], "plot_tre": [56, 64], "plotli": [2, 4, 5, 7, 8, 9, 10, 11, 12, 42, 43, 47], "plr": [11, 27, 28, 37, 55, 58, 60, 63, 65, 67, 69, 71, 72, 74, 76, 77], "plr_est": 55, "plr_est1": 55, "plr_est2": 55, "plr_obj": 55, "plr_obj_1": 55, "plr_obj_2": 55, "plr_summari": 53, "plrglmnet": 36, "plrranger": 36, "plrrpart": 36, "plrxgboost8700": 36, "plt": [38, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 57, 59], "plt_smpl": [35, 52], "plt_smpls_cluster": [35, 52], "plug": [50, 70], "pm": [35, 52, 69, 70, 71], "pmatrix": 59, "po": [37, 65], "point": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 48, 49, 52, 64, 77], "pointwis": [1, 44, 48, 49, 57], "poli": [36, 52, 53], "polici": [8, 10, 11, 63, 66, 74, 75, 76], "policy_tre": [8, 56, 64], "policy_tree_2": 56, "policy_tree_obj": 64, "policytre": 56, "polit": 55, "poly_dict": 53, "polynomi": [14, 15, 36, 38, 53], "polynomial_featur": [14, 15, 36, 38], "polynomialfeatur": [52, 53], "popul": 68, "popular": [51, 70], "porport": 58, "posit": [25, 36, 55, 77], "posixct": [37, 65], "possibl": [3, 6, 34, 37, 42, 43, 48, 49, 50, 51, 56, 58, 65, 69, 70, 76, 77], "possibli": 70, "post": [22, 25, 66, 69, 71, 75], "postdoubl": 75, "poster": 55, "potenti": [2, 9, 12, 16, 45, 55, 59, 66, 69, 73, 76, 77], "power": [37, 65, 75], "pp": 34, "pq": [9, 12, 13, 54, 76], "pq_0": [54, 57], "pq_1": [54, 57], "pr": [32, 35, 36, 37, 65, 66, 67, 68, 69, 74, 77], "practic": [51, 75], "pre": [34, 45, 59, 65, 66], "precis": [34, 70, 77], "pred": 34, "pred_df": 56, "pred_dict": 65, "pred_treat": 56, "predict": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 29, 30, 33, 35, 36, 37, 41, 44, 47, 51, 52, 53, 56, 61, 64, 67, 70, 76, 77], "predict_proba": [2, 4, 5, 7, 8, 9, 11, 12, 13, 29, 65], "predictor": [1, 8, 11, 42, 43, 48, 49, 60], "prefer": [36, 53, 54, 77], "preliminari": [2, 33, 41, 68], "prepar": [34, 35, 52, 76], "preprint": 75, "preprocess": [36, 52, 53, 54, 65], "presenc": [36, 53, 54], "present": [65, 77], "prespecifi": 58, "pretreat": [4, 5, 34, 45], "prettenhof": [72, 74], "prevent": [67, 76], "previou": [46, 50, 55, 73, 77], "previous": [65, 77], "price": [35, 52], "priliminari": [9, 13], "principl": 70, "print": [33, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76, 77], "print_detail": 34, "prior": [51, 66], "privat": 76, "prob": 37, "probabilit": 50, "probabl": [2, 7, 8, 9, 12, 13, 18, 33, 34, 41, 45, 50, 55, 57, 59, 61, 66, 68, 75], "problem": [36, 53, 54, 64, 65], "procedur": [33, 35, 36, 41, 51, 52, 53, 58, 65, 69, 71, 76], "proceed": [22, 75], "process": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 34, 42, 43, 44, 45, 46, 47, 48, 49, 51, 56, 57, 59, 63, 69, 70, 71, 75], "produc": 55, "product": [42, 43, 47, 51, 70], "producton": 35, "program": [21, 36, 53, 54, 75, 77], "progress": 39, "project": [37, 42, 43, 64, 72, 76], "project_z": [42, 43], "prone": 68, "propens": [9, 13, 16, 17, 36, 45, 50, 51, 53, 54, 59, 64], "properli": 77, "properti": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 37, 51, 53, 54, 55, 58, 65, 70, 74], "proport": [58, 70], "propos": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 37, 52, 70, 75], "provid": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 37, 42, 43, 48, 49, 52, 53, 60, 61, 62, 63, 65, 69, 71, 72, 74, 76, 77], "prune": 8, "ps911c": 52, "ps944": 52, "pscore1": 55, "pscore2": 55, "psi": [27, 28, 33, 34, 35, 52, 60, 68, 69, 70, 74], "psi_": [69, 70, 71], "psi_a": [7, 8, 10, 11, 27, 33, 35, 41, 52, 67, 68, 69], "psi_b": [7, 8, 10, 11, 27, 33, 41, 64, 67, 68], "psi_el": [67, 68], "psi_j": [69, 71], "psi_nu2": 70, "psi_sigma2": 70, "public": [32, 40, 76], "publish": 76, "pull": [36, 76], "purp": [42, 43], "purpos": [33, 41, 50, 58, 70, 74], "pval": [69, 71], "px": 47, "py": [49, 52, 53, 72, 73, 76], "py3": 73, "py_al": 41, "py_dml": 41, "py_dml_nosplit": 41, "py_dml_po": 41, "py_dml_po_nosplit": 41, "py_double_ml_bas": 41, "py_double_ml_basic_iv": 40, "py_double_ml_c": 42, "py_double_ml_cate_plr": 43, "py_double_ml_cvar": 44, "py_double_ml_did": 45, "py_double_ml_did_pretest": 46, "py_double_ml_firststag": 47, "py_double_ml_g": 48, "py_double_ml_gate_plr": 49, "py_double_ml_gate_sensit": 50, "py_double_ml_learn": 51, "py_double_ml_multiway_clust": 52, "py_double_ml_pens": 53, "py_double_ml_pension_qt": 54, "py_double_ml_plm_irm_hetfx": 55, "py_double_ml_policy_tre": 56, "py_double_ml_pq": 57, "py_double_ml_sensit": 58, "py_double_ml_ssm": 59, "py_non_orthogon": 41, "py_po_al": 41, "pydata": 49, "pypi": [75, 76], "pyplot": [38, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 57, 59], "python": [25, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77], "python3": [53, 73], "q": [37, 44, 57, 65, 72, 74], "q2": [37, 38, 62, 74], "q3": [37, 38, 62, 74], "q4": [37, 38, 62, 74], "q5": [37, 38, 62, 74], "q6": [37, 38, 62, 74], "qquad": 21, "qte": [44, 54, 76], "quad": [18, 36, 45, 53, 56, 59, 64, 66, 68, 69, 70, 71], "quadrat": 59, "qualiti": [58, 60, 76], "quanitl": 54, "quant": 44, "quantil": [2, 9, 12, 13, 44, 58, 63, 75, 76], "quantiti": [32, 40], "queri": 53, "question": 77, "quick": 54, "quit": [51, 56, 58, 70], "r": [7, 20, 41, 42, 43, 46, 47, 52, 55, 60, 61, 62, 63, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77], "r2_d": [21, 51], "r2_y": [21, 51], "r6": [37, 76], "r_0": [7, 10, 36, 53, 66], "r_all": 33, "r_d": 21, "r_df": 52, "r_dml": 33, "r_dml_nosplit": 33, "r_dml_po": 33, "r_dml_po_nosplit": 33, "r_double_ml_bas": 33, "r_double_ml_basic_iv": 32, "r_double_ml_did": 34, "r_double_ml_multiway_clust": 35, "r_double_ml_pens": 36, "r_double_ml_pipelin": 37, "r_hat": 10, "r_hat0": 7, "r_hat1": 7, "r_non_orthogon": 33, "r_po_al": 33, "r_y": 21, "rais": [3, 6, 29, 30, 65], "randint": 55, "random": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 19, 25, 26, 32, 33, 34, 36, 37, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 64, 65, 67, 69, 70, 71, 74, 75, 77], "random_search": 65, "random_st": [41, 50, 56], "randomforest": [36, 51, 53], "randomforest_class": [36, 42, 53, 56], "randomforest_reg": [42, 56], "randomforestclassifi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 42, 43, 48, 49, 50, 51, 53, 56, 58, 64, 65, 66, 77], "randomforestregressor": [2, 4, 5, 7, 8, 9, 10, 11, 12, 38, 41, 42, 43, 48, 49, 50, 51, 53, 56, 58, 60, 64, 65, 66, 67, 68, 69, 70, 74, 77], "randomized_search": [2, 4, 5, 7, 8, 9, 10, 11, 12, 65], "randomizedsearchcv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 65], "randomli": [33, 35, 41, 52, 61, 67, 77], "rang": [33, 41, 44, 45, 46, 48, 49, 51, 52, 54, 56, 57, 59, 61, 65], "rangeindex": [38, 45, 50, 52, 53, 54, 58, 59, 62, 74], "ranger": [34, 36, 37, 60, 65, 66, 67, 68, 69, 74, 77], "rangl": [19, 56], "rank": 76, "rate": [47, 51], "ratio": [65, 67, 70], "ravel": [42, 43], "raw": [36, 47, 53], "raw_res_manual_lasso_r_100_n_100_p_200_rho_0": 47, "rbind": 36, "rbindlist": 36, "rbinom": [32, 34], "rbrace": [7, 8, 20, 21, 26, 35, 52, 60, 66, 67, 69, 71], "rcolorbrew": 35, "rcparam": [38, 42, 43, 44, 46, 48, 49, 52, 53, 54, 57], "rd": 76, "rdbu": 35, "rdbu_r": 52, "rdt044": 47, "re": [52, 73], "read_csv": 47, "readabl": 76, "readili": 72, "real": [36, 53, 54, 58, 70], "realat": 66, "realiz": 66, "reason": [3, 6, 32, 40, 58, 70, 77], "recal": [38, 70], "receiv": 66, "recent": 66, "recogn": [36, 53, 54], "recommend": [37, 51, 60, 67, 73, 75, 76], "recov": [32, 34, 40, 55], "recsi": 75, "red": [35, 48, 49, 52], "reduc": [36, 50, 53, 58, 76], "redund": 76, "reemploy": [15, 62, 74], "refactor": 76, "refer": [2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 34, 36, 46, 50, 53, 54, 58, 62, 63, 64, 66, 70, 75, 76], "refin": 76, "refit": 70, "reflect": [56, 64], "reg": [18, 36, 53, 77], "reg_learn": 54, "reg_learner_1": 51, "reg_learner_2": 51, "regard": 72, "regener": 76, "region": [35, 44, 52, 69, 71, 75], "regr": [32, 33, 34, 35, 36, 37, 60, 65, 66, 67, 68, 69, 71, 74, 77], "regravg": [37, 65], "regress": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 20, 21, 22, 23, 24, 25, 32, 34, 35, 37, 40, 47, 52, 55, 58, 59, 60, 61, 63, 64, 65, 67, 69, 71, 72, 74, 75, 76, 77], "regressor": [30, 33, 36, 41, 44, 53, 61], "regular": [22, 63, 65, 68, 69, 71, 75], "reich": [37, 65], "reinforc": 75, "reject": [36, 53], "rel": [36, 53, 70], "relat": 77, "relationship": [32, 40, 47, 69, 71], "releas": 53, "relev": [1, 3, 4, 5, 6, 19, 44, 56, 57, 70, 77], "reli": [42, 43, 45, 46, 50, 64, 65, 66, 70, 77], "reload": 36, "remain": [34, 69, 71, 77], "remark": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 41, 42, 43, 44, 46, 48, 49, 50, 51, 54, 58, 64, 65, 66, 68, 69, 70], "remot": 73, "remov": [36, 53, 63, 67, 76], "renam": [53, 76], "render": 58, "reorgan": 76, "rep": [33, 61, 65, 69, 71], "repeat": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 33, 35, 36, 37, 41, 50, 52, 53, 54, 55, 58, 59, 61, 63, 65, 69, 74, 76, 77], "repeatedkfold": 52, "repet": 58, "repetit": [1, 42, 43, 47, 48, 49, 50, 51, 63, 65, 69, 74, 77], "repetiton": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "replac": [56, 76], "replic": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 33, 36, 41, 47], "repo": 76, "report": [36, 53, 72, 76], "repositori": [47, 76], "repr": [33, 35], "repres": 55, "represent": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 58, 69, 70, 74, 76], "request": 76, "requir": [10, 11, 32, 36, 37, 50, 53, 54, 58, 66, 69, 70, 71, 73, 76, 77], "requirenamespac": 34, "res_df": 52, "res_dict": [16, 17, 19], "resampl": [32, 35, 37, 45, 52, 54, 58, 59, 65, 66, 67, 68, 69, 72, 74, 77], "research": [35, 37, 52, 55, 67, 72, 74, 75, 77], "resembl": 59, "reset": 34, "reset_index": [47, 52, 53], "reshap": [41, 42, 43, 46], "reshape2": 35, "residu": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 58, 70], "resolut": [37, 65], "resourc": 51, "resourcewis": 51, "respect": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 53, 54, 64, 66, 67, 70, 77], "respons": [14, 37, 65], "restart": 73, "restrict": 51, "restructur": 76, "restud": 47, "result": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 33, 34, 37, 41, 42, 43, 45, 46, 47, 50, 51, 56, 58, 59, 61, 65, 67, 68, 70, 74, 76], "result_iivm": 36, "result_irm": 36, "result_plr": 36, "retina": 55, "retir": [36, 53, 54, 58], "return": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 33, 34, 35, 37, 41, 44, 49, 51, 52, 55, 56, 57, 58, 59, 60, 65, 68, 70, 76], "return_count": 51, "return_tune_r": [2, 4, 5, 7, 8, 9, 10, 11, 12], "return_typ": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 33, 36, 37, 41, 45, 51, 53, 54, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 74, 77], "rev": 35, "reveal": 50, "review": [22, 47, 75], "revist": [35, 52], "rho": [2, 4, 5, 7, 8, 9, 10, 11, 12, 31, 50, 58, 70, 77], "richter": [37, 65, 72, 74], "riesz": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 58, 70], "right": [20, 21, 22, 23, 26, 33, 35, 41, 51, 52, 53, 54, 55, 57, 61, 68, 69, 70, 71], "rightarrow_": [33, 41, 61], "risk": [2, 63, 76], "ritov": 75, "rival": 52, "rival_ind": 52, "rmd": 34, "rmse": [34, 45, 51, 54, 58, 59, 65, 66, 68, 69, 74, 76], "rmses_ml_g0": 51, "rmses_ml_g1": 51, "rmses_ml_m": 51, "rnorm": [32, 34, 37, 62, 65, 69, 71, 74], "robin": [14, 15, 24, 35, 47, 52, 61, 72, 75], "robinson": [33, 41, 61], "robject": 52, "robu": [48, 49], "robust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 23, 34, 50, 58, 70, 75, 77], "role": [3, 6, 33, 41, 61, 77], "romano": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 69, 71], "root": [2, 4, 5, 7, 8, 9, 10, 11, 12, 28, 47, 61, 65, 68, 75], "roth": 66, "rough": 77, "round": [36, 51, 55], "rout": [29, 30], "row": [33, 36, 38, 42, 43, 46, 52, 56, 62, 67, 74, 77], "row_index": 49, "rownam": 35, "rowv": 35, "roxygen2": 76, "royal": 75, "rpart": [36, 37, 65], "rpart_cv": 37, "rprocess": 51, "rpy2": 52, "rpy2pi": 52, "rsmp": [37, 65, 67], "rsmp_tune": [37, 65], "rtype": [2, 4, 5, 7, 8, 9, 10, 11, 12], "ruben": 75, "ruiz": [32, 40], "rule": [34, 64], "run": [34, 73, 76], "runif": [32, 34], "runtime_learn": 37, "rv": [50, 58, 70, 77], "rva": [50, 58, 70, 77], "rvert": 47, "rvert_": 47, "s_": [23, 35, 52, 66], "s_1": 24, "s_2": 24, "s_col": [3, 6, 59, 66], "s_i": [26, 59, 66], "s_x": [23, 35, 52], "safeguard": [45, 65], "sake": [36, 53, 77], "same": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 35, 41, 42, 43, 50, 51, 52, 54, 56, 58, 59, 65, 68, 69, 70, 76], "samii": 55, "sampl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 23, 26, 32, 34, 35, 37, 40, 45, 48, 49, 51, 52, 54, 56, 58, 63, 65, 68, 69, 71, 74, 75, 76], "sant": [4, 5, 16, 17, 18, 34, 45, 66, 75], "sara": 75, "sasaki": [23, 35, 52, 75], "satisfi": [59, 65, 68, 69], "save": [33, 36, 41, 48, 49, 51, 53, 54, 65, 70, 77], "savefig": 41, "saveguard": 51, "saver": [36, 53, 54], "scalar": 66, "scale": [33, 35, 44, 46, 55, 57, 69, 70], "scale_color_manu": 33, "scale_fill_manu": [33, 35], "scatter": [46, 48, 49, 55], "scenario": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 58, 70, 77], "scene": [42, 43, 47], "scene_camera": 47, "schaefer": 55, "schedul": 76, "scheme": [35, 52, 65, 67, 72], "schneider": 37, "schratz": [37, 65, 72, 74], "scienc": [25, 32, 40, 55, 75], "scikit": [51, 53, 65, 72, 74, 76, 77], "scipi": 41, "score": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 27, 28, 32, 34, 35, 36, 37, 38, 42, 43, 44, 45, 47, 50, 51, 52, 53, 54, 57, 58, 59, 60, 63, 64, 65, 66, 67, 69, 70, 72, 76, 77], "scoring_method": [2, 4, 5, 7, 8, 9, 10, 11, 12], "script": 73, "sd": [32, 34], "se": [33, 35, 41, 58, 61, 65, 67, 69, 70, 75, 77], "se_df": 35, "se_dml": [33, 41, 61], "se_dml_po": [33, 41, 61], "se_nonorth": [33, 41], "se_orth_nosplit": [33, 41], "se_orth_po_nosplit": [33, 41], "seaborn": [38, 41, 45, 51, 52, 53, 54, 59], "search": [2, 4, 5, 7, 8, 9, 10, 11, 12, 28, 65, 68], "search_mod": [2, 4, 5, 7, 8, 9, 10, 11, 12, 65], "searchabl": 36, "second": [23, 33, 35, 37, 41, 51, 52, 60, 61, 67, 69, 70, 71, 74], "section": [5, 18, 34, 35, 36, 37, 50, 52, 54, 76], "secur": 55, "see": [2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 21, 26, 27, 28, 32, 34, 35, 36, 37, 40, 42, 43, 45, 49, 52, 54, 55, 56, 58, 65, 66, 67, 68, 70, 73, 74, 76], "seed": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 77], "seek": 55, "seem": [34, 36, 50, 53, 54, 77], "seen": [48, 49], "sel_cols_chiang": 52, "select": [3, 6, 22, 26, 47, 51, 60, 63, 65, 75, 76, 77], "selected_coef": 51, "selected_featur": [37, 65], "selected_learn": 51, "self": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 51, 77], "selfref": 36, "semenova": [42, 43, 75], "semi": 61, "semiparametr": 14, "sens": 58, "sensemakr": 70, "sensit": [2, 4, 5, 7, 8, 9, 10, 11, 12, 31, 63, 64, 76], "sensitivity_analysi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 58, 70, 77], "sensitivity_benchmark": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 58, 70], "sensitivity_el": 70, "sensitivity_param": [2, 4, 5, 7, 8, 9, 10, 11, 12, 58, 70], "sensitivity_plot": [2, 4, 5, 7, 8, 9, 10, 11, 12, 50, 58, 70], "sensitivity_summari": [50, 58, 70, 77], "sensiv": [2, 4, 5, 7, 8, 9, 10, 11, 12], "senstiv": 70, "sep": 33, "separ": [55, 58, 65, 76], "seper": [58, 67, 69, 70], "seq_len": [33, 61], "sequenti": 15, "seri": [49, 75], "serv": [62, 74, 76], "serverless": [75, 76], "servic": 55, "set": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 18, 19, 23, 24, 25, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 45, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 64, 66, 67, 68, 69, 70, 71, 73, 74, 76, 77], "set_as_param": [2, 4, 5, 7, 8, 9, 10, 11, 12], "set_fold_specif": 65, "set_index": 53, "set_ml_nuisance_param": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 38, 53, 65, 76], "set_param": [29, 30, 65], "set_sample_split": [2, 4, 5, 7, 8, 9, 10, 11, 12, 51, 67], "set_styl": [53, 54], "set_text": 51, "set_threshold": [33, 34, 35, 36, 37, 60, 65, 66, 67, 68, 69, 71, 74], "set_tick": 52, "set_ticklabel": 52, "set_titl": 52, "set_x_d": [3, 6], "set_xlabel": [41, 52], "set_xlim": 41, "set_xtick": 55, "set_xticklabel": 55, "set_ylabel": [52, 55], "set_ylim": [44, 52, 57], "setdiff": 76, "setdiff1d": 52, "setminu": [35, 52, 69, 71], "setup": 73, "setuptool": 73, "seven": [35, 52], "sever": [31, 36, 37, 51, 53, 54, 58, 61, 65, 77], "shape": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 42, 43, 46, 48, 49, 51, 52, 53, 56, 58, 65], "share": [35, 36, 52, 53], "sharma": 75, "shock": [35, 52], "short": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 58, 70, 75, 76, 77], "shortcut": 36, "shortli": [35, 37, 52, 65], "shota": 75, "should": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 28, 36, 48, 49, 51, 53, 58, 59, 62, 64, 65, 69, 70, 72], "show": [32, 33, 35, 38, 40, 41, 42, 43, 45, 47, 50, 51, 52, 55, 59, 61, 65, 70, 73], "showcas": 56, "shown": [32, 40, 55, 74], "showscal": [42, 43, 47], "shuffl": 67, "side": 70, "sigma": [16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 33, 35, 41, 52, 59, 61, 64, 67, 69, 70, 71], "sigma2": 70, "sigma_": [17, 18, 20, 21, 22, 23, 24, 26, 33, 35, 41, 52, 61], "sigma_0": 70, "sigma_j": [69, 71], "sigmoid": 55, "signal": 1, "signatur": [7, 8, 9, 10, 11, 12, 13, 68], "signif": [32, 34, 35, 36, 37, 65, 66, 67, 68, 69, 74, 77], "signific": [32, 35, 36, 37, 50, 53, 56, 58, 65, 66, 67, 68, 69, 70, 74, 77], "silverman": [9, 12, 13], "sim": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 35, 41, 44, 46, 52, 56, 57, 59, 61], "similar": [16, 17, 37, 42, 43, 50, 54, 58], "simpl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 19, 34, 37, 42, 43, 48, 49, 50, 56, 63, 70], "simplest": 64, "simpli": [37, 45, 77], "simplic": [36, 51, 53, 56], "simplif": 70, "simplifi": [55, 64, 70], "simul": [16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 33, 37, 41, 42, 43, 44, 47, 48, 49, 57, 59, 61, 65, 69, 71, 74], "simulation_run": 47, "simult": 34, "simultan": [63, 77], "sin": [19, 25, 42, 43, 46, 48, 49], "sinc": [16, 17, 36, 45, 46, 48, 49, 50, 51, 53, 55, 59, 65, 66, 70, 76], "singl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 45, 48, 49, 54, 55, 65, 69, 71], "single_learner_pipelin": 65, "singleton": 67, "sinh": 25, "sipp": [36, 53, 54], "site": [52, 53], "situat": [35, 52], "six": 35, "sixth": 52, "size": [33, 35, 36, 37, 41, 44, 46, 47, 50, 51, 53, 55, 56, 57, 60, 62, 65, 66, 67, 68, 69, 71, 74, 77], "skill": 75, "sklearn": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 25, 38, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58, 59, 60, 64, 65, 66, 67, 68, 69, 70, 71, 74, 77], "slide": 55, "slightli": [46, 48, 49, 50, 51, 64, 68, 70], "sligthli": [4, 5], "slow": [33, 41, 61], "slower": [33, 41, 61], "small": [19, 45, 46, 56, 59, 70], "smaller": [36, 45, 48, 49, 50, 53, 77], "smallest": 51, "smpl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 35, 41, 51, 52, 67, 68], "smpls_cluster": [35, 52], "smsg": 53, "sn": [38, 41, 45, 51, 52, 53, 54, 59], "so": [32, 36, 37, 40, 45, 53, 55, 59, 65, 69, 77], "social": [55, 75], "societi": [35, 52, 75], "softwar": [37, 65, 72, 74, 75, 76], "solari": 76, "solut": [60, 64, 68], "solv": [27, 35, 52, 64, 65, 69, 71], "solver": [53, 59, 66], "some": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 37, 38, 45, 46, 51, 53, 54, 58, 59, 64, 65, 66, 76], "sometim": 51, "sonabend": [37, 65], "sophist": 65, "sort": 53, "sourc": [37, 65, 74, 76], "sourcefileload": 47, "sp": 34, "space": [35, 52, 65], "spars": [47, 65, 69, 71, 74, 75], "sparsiti": 75, "spec": 75, "special": [35, 52], "specif": [2, 4, 5, 7, 8, 9, 10, 11, 12, 28, 35, 36, 52, 53, 62, 63, 64, 65, 67, 68, 69, 72, 74], "specifi": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 32, 35, 36, 37, 40, 42, 43, 44, 45, 48, 49, 52, 53, 54, 56, 57, 58, 59, 60, 62, 63, 64, 74, 76, 77], "specifii": 54, "speed": [13, 51], "speedup": 51, "spefici": 7, "spindler": [22, 72, 75, 76], "spine": [53, 54], "spline": [42, 43, 64], "spline_basi": [42, 43, 64], "spline_grid": [42, 43], "split": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 35, 37, 45, 51, 52, 54, 56, 58, 59, 63, 64, 65, 66, 68, 69, 74, 76], "split_sampl": 51, "sponsor": [36, 53, 54], "sprintf": 33, "sq_error": 47, "sqrt": [16, 17, 18, 21, 33, 35, 37, 38, 41, 44, 52, 57, 61, 67, 69, 70, 71, 74], "squar": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 47, 53, 65, 70, 75], "squarederror": [36, 53, 77], "squeez": [44, 45, 57, 59], "src": 53, "ssm": [3, 6, 26, 63], "ssrn": 20, "stabil": 50, "stabl": [32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 72], "stack": [37, 65], "stacklrn": 37, "stage": [42, 43, 48, 49, 56, 65, 76, 77], "standard": [18, 34, 37, 44, 48, 49, 67, 68, 69, 70, 71, 76, 77], "standard_norm": [62, 65, 69, 71, 74], "standardscal": 53, "start": [34, 36, 37, 42, 43, 47, 50, 51, 52, 53, 57, 66, 72, 77], "stat": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 41, 62, 65, 69, 71, 72, 75], "stat_bin": 33, "stat_dens": 36, "state": 77, "stationar": 45, "stationari": 66, "statist": [2, 4, 5, 7, 8, 9, 10, 11, 12, 23, 26, 31, 35, 52, 58, 69, 70, 71, 72, 74, 75, 76, 77], "statsmodel": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "statu": [34, 36, 45, 53, 55, 59], "std": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 64, 65, 66, 67, 68, 69, 74, 77], "stefan": 75, "step": [33, 36, 37, 41, 48, 49, 50, 53, 56, 61, 65, 69, 71, 72, 77], "stepdown": [69, 71], "stick": [36, 53], "still": [42, 43, 45, 48, 49, 50, 54, 58, 59, 65], "stochast": [10, 11, 66, 74], "stock": [36, 53, 54], "store": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 60, 65, 67, 68, 69, 70, 76], "store_model": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "store_predict": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 53, 56], "stori": 75, "str": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 36, 48, 49, 57, 64, 76], "straightforward": [48, 49, 51, 64], "strategi": [55, 77], "stratifi": 51, "stratum": 55, "strength": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 58, 70], "strictli": 66, "string": [2, 4, 5, 7, 8, 9, 10, 11, 12, 64, 69, 70, 74, 76], "string_label": 55, "strong": [59, 70], "stronger": [69, 77], "structur": [14, 15, 24, 35, 36, 47, 52, 53, 59, 61, 65, 72, 75, 77], "student": 75, "studi": [26, 35, 36, 47, 52, 53, 54, 58, 74, 77], "style": [2, 4, 5, 7, 8, 9, 10, 11, 12, 76], "styler": 76, "sub": [35, 52], "subclass": 76, "subfold": 65, "subgroup": [7, 36, 53, 76], "subject": [35, 52], "submiss": 76, "subobject": [29, 30], "subplot": [35, 41, 42, 43, 44, 46, 48, 49, 51, 52, 53, 54, 55, 57], "subplots_adjust": 51, "subpopul": 66, "subsampl": [37, 51], "subscript": 70, "subsequ": [35, 52], "subset": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 51, 52, 56, 60, 64, 65, 70], "subseteq": 64, "substanti": [36, 53, 55], "substract": 69, "subtract": 69, "sudo": 73, "suffici": 51, "suggest": [35, 36, 52, 53, 76], "suitabl": [42, 43, 59], "sum": [35, 36, 52, 53, 54, 57, 64, 69, 71], "sum_": [33, 35, 41, 52, 60, 61, 64, 69, 71], "sum_i": 55, "sum_oth": 52, "sum_riv": 52, "summar": [34, 55, 60, 70], "summari": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 34, 35, 37, 38, 40, 42, 43, 44, 45, 48, 49, 50, 52, 54, 57, 58, 59, 61, 62, 64, 65, 66, 67, 68, 69, 70, 74, 76, 77], "summary_result": 36, "suppli": [2, 4, 5, 7, 8, 9, 10, 11, 12, 42, 43, 48, 49, 50, 56, 64, 70], "support": [7, 19, 34, 35, 51, 52, 56, 65, 66, 77], "support_s": [19, 42, 43, 48, 49, 56], "support_t": 56, "support_w": 56, "suppress": [34, 36, 37], "suppresswarn": 33, "suprema": [69, 71], "suptitl": [44, 51, 54, 57], "supxlabel": [44, 54, 57], "supylabel": [44, 54, 57], "sure": [65, 76], "surfac": [42, 43, 47], "surpress": [35, 74], "survei": [36, 53, 54, 77], "susan": 75, "sven": [72, 75], "svenk": 52, "svenklaassen": 72, "svg": [33, 41], "switch": [33, 41, 61], "symmetr": 25, "synthet": [19, 32, 40, 42, 43, 44, 48, 49, 56, 57], "syrgkani": 75, "system": 75, "szita": 75, "t": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 32, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 64, 65, 66, 67, 68, 69, 70, 71, 74, 77], "t_1_start": 51, "t_1_stop": 51, "t_2_start": 51, "t_2_stop": 51, "t_3_start": 51, "t_3_stop": 51, "t_col": [3, 5, 6, 66], "t_df": 56, "t_diff": 46, "t_dml": 33, "t_i": [45, 56, 66], "t_idx": 46, "t_nonorth": 33, "t_orth_nosplit": 33, "t_sigmoid": 56, "t_stat": 69, "tabl": [33, 35, 36, 37, 60, 62, 65, 66, 67, 68, 69, 71, 74, 77], "tabular": [51, 62, 69, 71, 74, 77], "taddi": 75, "take": [7, 8, 10, 11, 16, 17, 19, 42, 43, 44, 45, 46, 47, 48, 49, 51, 54, 57, 58, 59, 60, 64, 65, 66, 70, 74], "taken": [36, 53, 54, 77], "taker": [7, 76], "talk": 77, "target": [2, 4, 5, 7, 8, 9, 10, 11, 12, 27, 28, 32, 35, 36, 37, 42, 43, 51, 52, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77], "task": [32, 62, 67, 77], "task_typ": 76, "tau": [44, 46, 54, 55, 57, 64, 68], "tau_": 55, "tau_1": 55, "tau_2": 55, "tau_vec": [44, 54, 57], "tax": [36, 53, 54], "te": [34, 42, 43, 56], "techniqu": [33, 41, 61, 67, 77], "templat": 76, "temporari": 53, "tend": [36, 53, 54], "tensor": [42, 43], "tenth": 75, "term": [33, 35, 36, 37, 41, 46, 47, 52, 53, 55, 61, 72, 77], "termin": [37, 65], "terminatorev": 37, "test": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 20, 32, 33, 34, 35, 36, 37, 41, 50, 52, 61, 65, 66, 67, 68, 69, 71, 74, 75, 76, 77], "test_id": [35, 67], "test_ind": [2, 4, 5, 7, 8, 9, 10, 11, 12], "test_set": 67, "test_siz": 41, "text": [16, 17, 18, 20, 35, 36, 44, 47, 55, 56, 57, 64, 67], "textbf": [60, 65, 77], "textrm": 70, "tg": [37, 38, 62, 74], "th": [35, 52], "than": [8, 33, 34, 36, 41, 47, 51, 53, 54, 55, 58, 61, 70, 77], "thank": [36, 37, 53, 76], "thatw": 46, "thei": [34, 36, 46, 48, 49, 53, 55, 70], "them": [36, 37, 42, 43, 44, 50, 53, 57], "theme": [35, 36], "theme_minim": [33, 36], "theorem": 70, "theoret": [51, 67, 75], "theori": [64, 75], "therebi": [35, 37, 52, 77], "therefor": [55, 58, 67, 68, 70], "theta": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 23, 25, 26, 27, 28, 33, 35, 37, 41, 45, 46, 47, 50, 51, 52, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 77], "theta_": [64, 69, 70, 71], "theta_0": [7, 8, 10, 11, 19, 33, 35, 36, 41, 42, 43, 47, 48, 49, 52, 53, 59, 61, 64, 66, 68, 69, 70, 74], "theta_dml": [33, 41, 61], "theta_dml_po": [33, 41, 61], "theta_initi": 41, "theta_nonorth": [33, 41], "theta_orth_nosplit": [33, 41], "theta_orth_po_nosplit": [33, 41], "theta_resc": 33, "theta_t": 46, "thi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77], "think": 37, "third": [33, 41, 52, 61, 67], "thirion": [72, 74], "this_df": [47, 53], "this_split_ind": 52, "those": [34, 36, 53, 54], "though": [32, 40, 55], "thread": [55, 65], "three": [35, 37, 48, 49, 73, 76], "threshold": [2, 4, 5, 7, 8, 9, 12, 13, 66], "through": [34, 44, 48, 49, 57, 65], "throughout": 50, "thu": 64, "tibbl": 34, "tight": 41, "tight_layout": 52, "tild": [16, 17, 18, 35, 52, 55, 60, 64, 67, 68, 69, 70, 71], "time": [3, 4, 6, 22, 23, 33, 34, 35, 36, 41, 45, 46, 47, 48, 49, 52, 53, 54, 58, 59, 66, 76, 77], "time_df": 46, "time_period": 46, "titl": [35, 36, 42, 43, 44, 47, 48, 49, 51, 52, 53, 54, 55, 57, 72], "tmp": 49, "tname": 34, "tnr": [37, 65], "to_fram": 56, "to_numpi": [44, 50, 54, 57], "todo": [35, 38], "toeplitz": 47, "togeth": [48, 49, 69], "toler": 52, "too": 51, "tool": [34, 37, 58, 77], "top": [35, 51, 52, 53, 54, 72], "total": [36, 53], "tracker": 72, "tradit": [69, 71], "train": [33, 35, 37, 41, 42, 43, 44, 48, 49, 51, 52, 56, 57, 60, 61, 67], "train_id": [35, 67], "train_ind": [2, 4, 5, 7, 8, 9, 10, 11, 12], "train_set": 67, "train_test_split": 41, "transact": 75, "transform": [16, 17, 55, 77], "translat": 47, "transpos": 46, "treament": 56, "treat": [8, 18, 34, 45, 46, 50, 56, 64, 66, 69, 77], "treat1_param": 55, "treat2_param": 55, "treat_var": [2, 4, 5, 7, 8, 9, 10, 11, 12, 65], "treatment": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 32, 34, 35, 37, 38, 40, 45, 46, 47, 50, 51, 52, 56, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77], "treatment_df": 46, "treatment_effect": [19, 42, 43], "treatment_var": [3, 6], "tree": [8, 36, 37, 45, 46, 51, 53, 60, 63, 65, 66, 67, 68, 69, 74, 76], "tree_param": 8, "tree_summari": 53, "trees_class": [36, 53], "trend": [34, 45, 46, 52, 66, 75], "tri": [47, 70], "trim": [2, 4, 5, 7, 8, 9, 12, 13, 36, 53, 54], "trimming_rul": [2, 4, 5, 7, 8, 9, 12, 13, 54], "trimming_threshold": [2, 4, 5, 7, 8, 9, 12, 13, 36, 42, 53, 54, 56, 57], "trm": [37, 65], "true": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 26, 29, 30, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 65, 66, 67, 68, 69, 70, 71, 74, 77], "true_effect": [42, 43, 46, 48, 49], "true_gatet_effect": 50, "true_group_effect": 50, "truncat": [2, 4, 5, 7, 8, 9, 12, 13, 54], "try": [51, 58], "tune": [2, 4, 5, 7, 8, 9, 10, 11, 12, 47, 63, 72, 74, 76], "tune_on_fold": [2, 4, 5, 7, 8, 9, 10, 11, 12, 65], "tune_r": [2, 4, 5, 7, 8, 9, 10, 11, 12], "tune_set": [37, 65], "tuner": 65, "tunergridsearch": 37, "tupl": [2, 4, 5, 7, 8, 9, 10, 11, 12], "turrel": 25, "tutori": 36, "tw": [53, 54], "two": [2, 4, 5, 7, 8, 9, 10, 11, 12, 18, 19, 32, 33, 36, 37, 40, 41, 44, 45, 51, 53, 54, 55, 56, 57, 58, 60, 61, 64, 65, 66, 67, 68, 69, 71, 77], "twoclass": 37, "twoearn": [36, 53, 54, 58, 77], "type": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 29, 30, 31, 33, 34, 35, 36, 37, 41, 51, 52, 61, 65, 68, 69, 70, 71, 76, 77], "typic": [49, 72], "u": [7, 8, 9, 12, 13, 16, 17, 18, 19, 21, 26, 33, 34, 35, 36, 41, 44, 45, 46, 48, 49, 51, 52, 53, 54, 56, 57, 58, 61, 66, 70, 73, 77], "u_hat": [33, 41, 68], "u_i": [20, 22, 25, 26], "u_t": 18, "uehara": 75, "uhash": 37, "ulf": 75, "uncertainti": [2, 4, 5, 7, 8, 9, 10, 11, 12, 48, 49, 58, 70, 77], "uncondit": [36, 53, 77], "unconfounded": 75, "under": [33, 36, 41, 45, 53, 56, 61, 66, 69, 75], "underbrac": [33, 41, 46, 61, 64], "underli": [36, 37, 48, 49, 55, 56, 70, 77], "underlin": [35, 52], "undesir": 65, "unevenli": 67, "uniform": [18, 40, 42, 43, 44, 46, 56, 57, 69], "uniformli": [44, 54, 69, 71], "uniqu": [32, 40, 51, 68, 70], "unit": [33, 34, 45, 46, 50, 59, 66, 68, 76], "univari": [19, 42, 43], "univers": 75, "unknown": 66, "unlik": [36, 53, 54], "unobserv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 36, 40, 53, 54, 58, 66, 70, 77], "unpen": 34, "unstabl": 70, "unter": [35, 36, 37], "until": [66, 76], "untreat": 66, "up": [13, 36, 47, 51, 53, 54, 58, 65, 66, 67, 70, 73, 76, 77], "upcom": 76, "updat": [35, 49, 52, 75, 76], "update_layout": [42, 43, 47], "update_trac": [42, 43], "upload": 76, "upon": [68, 76], "upper": [36, 37, 41, 44, 46, 50, 54, 57, 58, 65, 70, 77], "upper_bound": [42, 43], "upsilon": 59, "upsilon_i": 59, "upward": [36, 53, 54], "upweight": 55, "url": [47, 72, 75], "us": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 33, 35, 36, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 64, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77], "usa": 75, "usabl": 51, "usag": [34, 38, 45, 50, 52, 53, 54, 58, 59, 62, 74, 76], "use_label_encod": [53, 77], "use_other_treat_as_covari": [3, 6, 62], "usecolormap": [42, 43], "user": [27, 28, 29, 30, 33, 34, 35, 36, 37, 41, 50, 51, 52, 53, 58, 64, 65, 68, 69, 71, 72, 73, 74, 76, 77], "user_guid": 49, "userwarn": 53, "usual": [35, 42, 43, 45, 51, 52, 58, 64, 65, 67, 70], "util": [28, 55, 65, 76], "v": [7, 8, 10, 11, 14, 15, 21, 22, 23, 24, 26, 33, 35, 36, 41, 50, 52, 53, 55, 60, 61, 64, 66, 69, 71, 72, 74, 75, 76, 77], "v108": 72, "v12": [72, 74], "v22": 37, "v23": 72, "v_": [23, 35, 52], "v_i": [20, 21, 24, 25, 26, 33, 41, 61, 66], "v_j": [69, 71], "val": [21, 67, 75], "val_list": 47, "valid": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 20, 33, 34, 35, 36, 41, 44, 45, 51, 52, 53, 54, 57, 61, 63, 64, 65, 67, 68, 70, 75, 77], "valu": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 58, 60, 63, 65, 66, 67, 69, 70, 71, 74, 76, 77], "value_count": 53, "van": 75, "vanderpla": [72, 74], "vanish": [33, 41, 61], "var": [16, 17, 18, 35, 52, 55, 70], "varepsilon": [7, 16, 17, 23, 35, 52, 59, 64, 66], "varepsilon_": [23, 35, 52], "varepsilon_0": 18, "varepsilon_1": 18, "varepsilon_d": 17, "varepsilon_i": [22, 44, 57, 59], "vari": [36, 46, 51, 53, 55], "variabl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 35, 36, 37, 38, 45, 47, 50, 52, 53, 54, 58, 59, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 75, 76, 77], "varianc": [27, 28, 35, 37, 52, 58, 63, 67, 70, 74], "variant": 34, "variat": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 58, 70], "variou": [34, 65, 77], "varoquaux": [72, 74], "vasili": 75, "vector": [2, 4, 5, 7, 8, 9, 10, 11, 12, 19, 20, 21, 22, 23, 25, 26, 32, 35, 36, 40, 45, 48, 49, 50, 52, 53, 56, 59, 66, 69, 71, 74, 76], "venv": 73, "verbos": [36, 46], "veri": [34, 35, 37, 50, 51, 52, 68, 72], "verifi": 55, "versa": [51, 55, 70], "version": [35, 36, 37, 53, 60, 64, 69, 70, 71, 76], "versu": 49, "vertic": [35, 52], "via": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 28, 34, 44, 45, 46, 47, 48, 49, 50, 51, 58, 59, 60, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77], "viabl": [2, 4, 5, 7, 8, 9, 10, 11, 12], "vice": [51, 55, 70], "victor": [47, 67, 72, 75], "view": 49, "vignett": [34, 76], "villa": [32, 40], "violet": [44, 54, 57], "vira": 75, "virtual": 73, "virtualenv": 73, "visibl": 54, "visit": [72, 77], "visual": [35, 50, 52], "vol": 34, "volum": 72, "voluntari": 55, "vv740": 52, "vv760g": 52, "w": [14, 15, 16, 17, 18, 24, 27, 28, 35, 47, 52, 55, 56, 60, 61, 68, 69, 70, 71, 72, 74], "w24678": 67, "w30302": 75, "w_": [18, 35, 52, 56], "w_1": [18, 56], "w_2": [18, 56], "w_3": 18, "w_4": 18, "w_df": 56, "w_i": [26, 45, 56, 60, 64, 67, 68, 69, 71], "wa": [35, 46, 52, 76], "wager": 75, "wai": [36, 51, 53, 65, 68, 73], "wander": 25, "wang": 75, "want": [32, 35, 36, 37, 40, 44, 45, 51, 52, 57, 65, 72, 73, 75], "warn": [32, 33, 34, 35, 36, 37, 41, 53, 60, 65, 66, 67, 68, 69, 71, 74, 76], "wayon": 35, "we": [8, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76, 77], "weak": [70, 75], "wealth": [14, 58], "websit": [36, 37, 65, 72], "wedg": [35, 52], "week": 76, "wei": [69, 71], "weight": [2, 7, 8, 9, 12, 13, 35, 36, 37, 50, 52, 53, 59, 63, 65, 69, 70, 71, 76], "weights_bar": 8, "weiss": [72, 74], "well": [3, 6, 33, 35, 41, 47, 51, 52, 60, 61, 62, 67, 74], "were": [36, 53, 54, 59, 77], "what": [34, 47, 51], "when": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 36, 45, 49, 53, 55, 66, 68, 69, 71, 72, 73, 74, 76], "whenev": [36, 53], "whera": 70, "where": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 32, 33, 35, 36, 40, 41, 44, 45, 46, 50, 52, 53, 55, 56, 57, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 73, 74, 76, 77], "wherea": [19, 45, 59, 70, 77], "whether": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 19, 26, 36, 46, 51, 53, 54, 62, 65, 70, 76], "which": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 28, 32, 33, 34, 36, 37, 39, 40, 41, 45, 47, 49, 50, 51, 53, 54, 56, 58, 59, 61, 62, 64, 65, 66, 68, 69, 70, 71, 73, 76, 77], "while": [32, 40], "white": [35, 48, 49, 52], "whitegrid": [53, 54], "whitnei": 75, "who": [34, 36, 53], "whole": [33, 41, 45, 61, 65, 70], "width": [33, 35, 42, 43, 47], "wiki": 76, "wiksel": 75, "wild": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 69, 71], "window": 73, "wise": [48, 49], "wish": 73, "within": [35, 48, 49, 52, 56], "without": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 33, 40, 41, 51, 61, 63, 65, 70, 73, 76], "wolf": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 69, 71], "word": 77, "work": [29, 30, 39, 49, 50, 51, 55, 58, 65, 69, 73, 75], "workflow": [72, 76], "workspac": 53, "world": 75, "would": [36, 37, 42, 43, 47, 51, 53, 54, 58, 64, 65, 70, 77], "wrapper": [34, 65], "write": [33, 34, 41, 45, 49, 59, 61, 70], "written": [68, 70], "wrong": [51, 55], "wspace": 51, "wurd": [35, 36, 37], "www": [72, 73], "x": [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 35, 36, 37, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 77], "x0": 55, "x1": [35, 37, 45, 52, 55, 58, 59, 62, 64, 65, 66, 68, 69, 70, 74], "x10": [35, 37, 52, 59, 62, 65, 66, 68, 69, 74], "x100": [35, 37, 52, 59, 62, 66, 74], "x11": [35, 37, 52, 59, 62, 65, 66, 68, 69, 74], "x12": [35, 37, 52, 59, 62, 65, 66, 68, 69, 74], "x13": [35, 37, 52, 59, 62, 65, 66, 68, 69, 74], "x14": [35, 37, 52, 59, 62, 65, 66, 68, 69, 74], "x15": [35, 37, 52, 59, 62, 65, 66, 68, 69, 74], "x16": [35, 37, 52, 59, 62, 65, 66, 68, 69, 74], "x17": [35, 37, 52, 59, 62, 65, 66, 68, 69, 74], "x18": [35, 37, 52, 59, 62, 65, 66, 68, 69, 74], "x19": [35, 37, 52, 59, 62, 65, 66, 68, 69, 74], "x1x2x3x4x5x6x7x8x9x10": 35, "x2": [35, 37, 45, 52, 58, 59, 62, 64, 65, 66, 68, 69, 74], "x20": [35, 37, 52, 59, 62, 65, 66, 68, 69, 74], "x21": [35, 37, 52, 59, 62, 66, 74], "x22": [35, 37, 52, 59, 62, 66, 74], "x23": [35, 37, 52, 59, 62, 66, 74], "x24": [35, 37, 52, 59, 62, 66, 74], "x25": [35, 37, 52, 59, 62, 66, 74], "x26": [35, 37, 52, 59, 62, 66, 74], "x27": [35, 37, 52, 59, 62, 66, 74], "x28": [35, 37, 52, 59, 62, 66, 74], "x29": [35, 37, 52, 59, 62, 66, 74], "x3": [35, 37, 45, 52, 58, 59, 62, 64, 65, 66, 68, 69, 74], "x30": [35, 37, 52, 59, 62, 66, 74], "x31": [35, 37, 52, 59, 62, 66, 74], "x32": [35, 37, 52, 59, 62, 66, 74], "x33": [35, 37, 52, 59, 62, 66, 74], "x34": [35, 37, 52, 59, 62, 66, 74], "x35": [35, 37, 52, 59, 62, 66, 74], "x36": [35, 37, 52, 59, 62, 66, 74], "x37": [35, 37, 52, 59, 62, 66, 74], "x38": [35, 37, 52, 59, 62, 66, 74], "x39": [35, 37, 52, 59, 62, 66, 74], "x4": [35, 37, 45, 52, 58, 59, 62, 65, 66, 68, 69, 74], "x40": [35, 37, 52, 59, 62, 66, 74], "x41": [35, 37, 52, 59, 62, 66, 74], "x42": [35, 37, 52, 59, 62, 66, 74], "x43": [35, 37, 52, 59, 62, 66, 74], "x44": [35, 37, 52, 59, 62, 66, 74], "x45": [35, 37, 52, 59, 62, 66, 74], "x46": [35, 37, 52, 59, 62, 66, 74], "x47": [35, 37, 52, 59, 62, 66, 74], "x48": [35, 37, 52, 59, 62, 66, 74], "x49": [35, 37, 52, 59, 62, 66, 74], "x5": [35, 37, 52, 59, 62, 65, 66, 68, 69, 74], "x50": [35, 37, 52, 59, 62, 66, 74], "x51": [35, 37, 52, 59, 62, 66, 74], "x52": [35, 37, 52, 59, 62, 66, 74], "x53": [35, 37, 52, 59, 62, 66, 74], "x54": [35, 37, 52, 59, 62, 66, 74], "x55": [35, 37, 52, 59, 62, 66, 74], "x56": [35, 37, 52, 59, 62, 66, 74], "x57": [35, 37, 52, 59, 62, 66, 74], "x58": [35, 37, 52, 59, 62, 66, 74], "x59": [35, 37, 52, 59, 62, 66, 74], "x6": [35, 37, 52, 59, 62, 65, 66, 68, 69, 74], "x60": [35, 37, 52, 59, 62, 66, 74], "x61": [35, 37, 52, 59, 62, 66, 74], "x62": [35, 37, 52, 59, 62, 66, 74], "x63": [35, 37, 52, 59, 62, 66, 74], "x64": [35, 37, 52, 53, 59, 62, 66, 74], "x65": [35, 37, 52, 59, 62, 66, 74], "x66": [35, 37, 52, 59, 62, 66, 74], "x67": [35, 37, 52, 59, 62, 66, 74], "x68": [35, 37, 52, 59, 62, 66, 74], "x69": [35, 37, 52, 59, 62, 66, 74], "x7": [35, 37, 52, 59, 62, 65, 66, 68, 69, 74], "x70": [35, 37, 52, 59, 62, 66, 74], "x71": [35, 37, 52, 59, 62, 66, 74], "x72": [35, 37, 52, 59, 62, 66, 74], "x73": [35, 37, 52, 59, 62, 66, 74], "x74": [35, 37, 52, 59, 62, 66, 74], "x75": [35, 37, 52, 59, 62, 66, 74], "x76": [35, 37, 52, 59, 62, 66, 74], "x77": [35, 37, 52, 59, 62, 66, 74], "x78": [35, 37, 52, 59, 62, 66, 74], "x79": [35, 37, 52, 59, 62, 66, 74], "x8": [35, 37, 52, 59, 62, 65, 66, 68, 69, 74], "x80": [35, 37, 52, 59, 62, 66, 74], "x81": [35, 37, 52, 59, 62, 66, 74], "x82": [35, 37, 52, 59, 62, 66, 74], "x83": [35, 37, 52, 59, 62, 66, 74], "x84": [35, 37, 52, 59, 62, 66, 74], "x85": [35, 37, 52, 59, 62, 66, 74], "x86": [35, 37, 52, 59, 62, 66, 74], "x87": [35, 37, 52, 59, 62, 66, 74], "x88": [35, 37, 52, 59, 62, 66, 74], "x89": [35, 37, 52, 59, 62, 66, 74], "x9": [35, 37, 52, 59, 62, 65, 66, 68, 69, 74], "x90": [35, 37, 52, 59, 62, 66, 74], "x91": [35, 37, 52, 59, 62, 66, 74], "x92": [35, 37, 52, 59, 62, 66, 74], "x93": [35, 37, 52, 59, 62, 66, 74], "x94": [35, 37, 52, 59, 62, 66, 74], "x95": [35, 37, 52, 59, 62, 66, 74], "x96": [35, 37, 52, 59, 62, 66, 74], "x96x97x98x99x100ydcluster_var_icluster_var_jz": 35, "x97": [35, 37, 52, 59, 62, 66, 74], "x98": [35, 37, 52, 59, 62, 66, 74], "x99": [35, 37, 52, 59, 62, 66, 74], "x_": [23, 24, 33, 35, 41, 46, 52, 61], "x_0": [42, 43, 46, 48, 49, 50], "x_1": [10, 11, 16, 17, 18, 42, 43, 44, 46, 48, 49, 50, 57, 66, 70, 74], "x_1x_3": [44, 57], "x_2": [16, 17, 18, 42, 43, 44, 46, 48, 49, 50, 57, 70], "x_3": [16, 17, 18, 42, 43, 46, 48, 49, 50, 70], "x_4": [16, 17, 18, 42, 43, 44, 48, 49, 50, 57], "x_5": [16, 17, 42, 43, 48, 49], "x_6": [42, 43, 48, 49], "x_7": [42, 43, 48, 49], "x_8": [42, 43, 48, 49], "x_9": [42, 43, 48, 49], "x_col": [3, 6, 32, 35, 36, 37, 40, 47, 52, 53, 54, 56, 58, 62, 65, 74, 76, 77], "x_cols_poli": 52, "x_conf": 57, "x_conf_tru": 57, "x_df": 46, "x_domain": 37, "x_i": [19, 20, 21, 22, 24, 25, 26, 33, 41, 44, 45, 48, 49, 55, 57, 59, 61, 64, 66], "x_p": [10, 11, 66, 74], "x_true": [44, 57], "x_var": 37, "xaxis_titl": [42, 43, 47], "xformla": 34, "xgbclassifi": [51, 53, 55, 77], "xgboost": [33, 36, 51, 53, 55, 77], "xgbregressor": [51, 53, 55, 77], "xi": [18, 66], "xi_": [69, 71], "xi_0": [23, 35, 52], "xi_i": 59, "xiaoji": 75, "xintercept": 33, "xlab": [33, 35, 36], "xlabel": [42, 43, 44, 46, 48, 49, 53, 54, 57], "xlim": [33, 36], "xval": [37, 65], "xx": 41, "y": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74, 77], "y0": [34, 44, 57], "y0_cvar": 44, "y0_quant": [44, 57], "y1": [34, 44, 57], "y1_cvar": 44, "y1_quant": [44, 57], "y_": [23, 35, 45, 46, 52, 59, 66], "y_0": [4, 18, 68], "y_1": [4, 18, 68], "y_col": [3, 6, 32, 33, 35, 36, 37, 40, 42, 43, 47, 48, 49, 52, 53, 54, 56, 58, 60, 61, 62, 65, 66, 67, 68, 74, 76, 77], "y_df": [46, 56], "y_diff": 46, "y_i": [19, 20, 21, 22, 24, 25, 26, 33, 41, 44, 45, 55, 56, 57, 59, 61, 66], "y_pred": [2, 4, 5, 7, 8, 9, 10, 11, 12, 51, 65], "y_true": [2, 4, 5, 7, 8, 9, 10, 11, 12, 51, 65], "ya": 75, "yasui": 75, "yata": 75, "yaxis_titl": [42, 43, 47], "year": 72, "yerr": [46, 48, 49, 53, 55], "yet": [35, 39], "yggvpl": 52, "yintercept": 36, "ylab": [33, 35, 36], "ylabel": [42, 43, 44, 46, 48, 49, 53, 54, 57], "ylim": 53, "ymax": 36, "ymin": 36, "yname": 34, "york": 75, "you": [32, 33, 40, 46, 49, 52, 58, 72, 73, 77], "your": [51, 73], "ython": 72, "yukun": 75, "yusuk": 75, "yuya": 75, "yy": 41, "z": [3, 6, 7, 9, 10, 16, 17, 18, 20, 22, 23, 26, 32, 35, 36, 40, 42, 43, 47, 52, 53, 57, 59, 64, 66, 68, 69, 71, 76], "z1": [10, 66], "z2": 66, "z3": 66, "z4": 66, "z_": [23, 35, 52], "z_1": [16, 17], "z_2": [16, 17], "z_3": [16, 17], "z_4": [16, 17], "z_5": 16, "z_col": [3, 6, 7, 9, 10, 32, 35, 36, 40, 52, 53, 54, 59, 62, 64, 66, 76], "z_i": [22, 26, 57, 59, 66], "z_j": [16, 17, 18], "z_true": 57, "zadik": 75, "zaxis_titl": [42, 43, 47], "zero": [18, 44, 45, 46, 51, 56, 57, 58, 69], "zeros_lik": 57, "zeta": [7, 10, 11, 36, 53, 64, 66, 74], "zeta_": [23, 35, 52], "zeta_0": [23, 35, 52], "zeta_i": [21, 22, 24, 33, 41, 61], "zeta_j": [69, 71], "zhang": 75, "zhao": [4, 5, 16, 17, 18, 34, 45, 66, 75], "zimmert": [45, 75], "zip": [42, 43], "\u03c4_x0": 55, "\u03c4_x1": 55, "\u2139": 33}, "titles": ["API reference", "doubleml.DoubleMLBLP", "doubleml.DoubleMLCVAR", "doubleml.DoubleMLClusterData", "doubleml.DoubleMLDID", "doubleml.DoubleMLDIDCS", "doubleml.DoubleMLData", "doubleml.DoubleMLIIVM", "doubleml.DoubleMLIRM", "doubleml.DoubleMLLPQ", "doubleml.DoubleMLPLIV", "doubleml.DoubleMLPLR", "doubleml.DoubleMLPQ", "doubleml.DoubleMLQTE", "doubleml.datasets.fetch_401K", "doubleml.datasets.fetch_bonus", "doubleml.datasets.make_confounded_irm_data", "doubleml.datasets.make_confounded_plr_data", "doubleml.datasets.make_did_SZ2020", "doubleml.datasets.make_heterogeneous_data", "doubleml.datasets.make_iivm_data", "doubleml.datasets.make_irm_data", "doubleml.datasets.make_pliv_CHS2015", "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "doubleml.datasets.make_plr_CCDDHNR2018", "doubleml.datasets.make_plr_turrell2018", "doubleml.datasets.make_ssm_data", "doubleml.double_ml_score_mixins.LinearScoreMixin", "doubleml.double_ml_score_mixins.NonLinearScoreMixin", "doubleml.utils.DMLDummyClassifier", "doubleml.utils.DMLDummyRegressor", "doubleml.utils.gain_statistics", "R: Basic Instrumental Variables Calculation", "R: Basics of Double Machine Learning", "R: DoubleML for Difference-in-Differences", "R: Cluster Robust Double Machine Learning", "R: Impact of 401(k) on Financial Wealth", "R: Ensemble Learners and More with <code class=\"docutils literal notranslate\"><span class=\"pre\">mlr3pipelines</span></code>", "DML: Bonus Data", "Examples", "Python: Basic Instrumental Variables calculation", "Python: Basics of Double Machine Learning", "Python: Conditional Average Treatment Effects (CATEs) for IRM models", "Python: Conditional Average Treatment Effects (CATEs) for PLR models", "Python: Conditional Value at Risk of potential outcomes", "Python: Difference-in-Differences", "Python: Difference-in-Differences Pre-Testing", "Python: First Stage and Causal Estimation", "Python: Group Average Treatment Effects (GATEs) for IRM models", "Python: Group Average Treatment Effects (GATEs) for PLR models", "Python: GATE Sensitivity Analysis", "Python: Choice of learners", "Python: Cluster Robust Double Machine Learning", "Python: Impact of 401(k) on Financial Wealth", "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)", "Python: PLM and IRM for Multiple Treatments", "Python: Policy Learning with Trees", "Python: Potential Quantiles and Quantile Treatment Effects", "Python: Sensitivity Analysis", "Python: Sample Selection Models", "<span class=\"section-number\">6. </span>Double machine learning algorithms", "<span class=\"section-number\">1. </span>The basics of double/debiased machine learning", "<span class=\"section-number\">2. </span>The data-backend DoubleMLData", "User guide", "<span class=\"section-number\">4. </span>Heterogeneous treatment effects", "<span class=\"section-number\">7. </span>Learners, hyperparameters and hyperparameter tuning", "<span class=\"section-number\">3. </span>Models", "<span class=\"section-number\">9. </span>Sample-splitting, cross-fitting and repeated cross-fitting", "<span class=\"section-number\">5. </span>Score functions", "<span class=\"section-number\">8. </span>Variance estimation and confidence intervals", "<span class=\"section-number\">10. </span>Sensitivity analysis", "Confidence bands and multiplier bootstrap for valid simultaneous inference", "DoubleML", "Installing DoubleML", "Getting started", "Double machine learning literature", "Release notes", "DoubleML Workflow"], "titleterms": {"0": 77, "1": 77, "2": 77, "3": 77, "4": 77, "401": [36, 53, 54, 58], "5": 77, "6": 77, "7": 77, "A": [35, 52], "ATE": [50, 55, 59], "No": [35, 52], "One": [35, 42, 43, 52], "The": [36, 53, 55, 61, 62, 74], "acknowledg": 72, "acycl": [32, 40], "addit": 55, "advanc": [65, 69], "algorithm": [60, 70, 72, 74], "altern": 68, "analysi": [50, 58, 70, 77], "api": 0, "applic": [35, 52, 58], "approach": [33, 41, 51, 61], "arbitrari": 55, "arrai": 62, "asset": [36, 53], "att": 45, "augment": 55, "averag": [36, 42, 43, 48, 49, 53, 64], "backend": [35, 36, 52, 53, 62, 74, 77], "band": [69, 71], "base": 37, "basic": [32, 33, 40, 41, 61], "benchmark": [58, 70], "bia": [33, 41, 61], "bonu": 38, "bootstrap": [69, 71], "build": 73, "calcul": [32, 40], "callabl": 68, "case": 39, "cate": [42, 43, 55, 64], "causal": [38, 47, 68, 74, 77], "choic": 51, "citat": 72, "class": [0, 35, 52], "cluster": [35, 52], "code": 72, "combin": 47, "compar": 51, "comparison": 34, "comput": 51, "conda": 73, "condit": [42, 43, 44, 54, 64, 68], "confid": [69, 71], "construct": 65, "coverag": [45, 47], "cran": 73, "cross": [35, 45, 52, 66, 67, 68, 70, 74], "custom": 51, "cvar": [44, 54, 64, 68], "dag": [32, 40], "data": [0, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 48, 49, 50, 52, 53, 54, 56, 57, 58, 59, 61, 62, 66, 68, 70, 74, 77], "datafram": 62, "dataset": [0, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 38], "debias": [33, 41, 61, 74], "defin": [35, 52], "demo": 34, "detail": 34, "develop": 73, "dgp": [33, 41], "did": [34, 66], "differ": [34, 45, 46, 51, 66, 68, 69, 70], "dimension": [42, 43], "direct": [32, 40], "distribut": 59, "dml": [35, 38, 52, 67, 74, 77], "dml1": 60, "dml2": 60, "dmldummyclassifi": 29, "dmldummyregressor": 30, "doubl": [0, 33, 35, 41, 52, 60, 61, 72, 74, 75], "double_ml_score_mixin": [27, 28], "doubleml": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 40, 53, 58, 69, 72, 73, 77], "doublemlblp": 1, "doublemlclusterdata": [3, 35, 52], "doublemlcvar": 2, "doublemldata": [6, 36, 53, 62, 74], "doublemldid": 4, "doublemldidc": 5, "doublemliivm": 7, "doublemlirm": 8, "doublemllpq": 9, "doublemlpliv": [10, 35, 52], "doublemlplr": 11, "doublemlpq": 12, "doublemlqt": 13, "effect": [36, 39, 42, 43, 44, 48, 49, 53, 54, 55, 57, 58, 64], "elig": [36, 53], "empir": 47, "ensembl": 37, "error": [35, 52], "estim": [32, 36, 38, 40, 45, 47, 50, 53, 54, 55, 57, 58, 59, 67, 68, 69, 74, 77], "evalu": [51, 65], "exampl": [34, 35, 39, 42, 43, 52, 58], "exploit": [34, 37], "extern": [65, 67], "featur": [37, 72], "fetch_401k": 14, "fetch_bonu": 15, "figur": 55, "file": 73, "financi": [36, 53, 54], "first": 47, "fit": [35, 52, 67, 74], "fold": 67, "forest": 38, "formul": 77, "from": [34, 37, 62, 73], "function": [0, 34, 35, 52, 68, 74], "gain_statist": 31, "gate": [48, 49, 50, 64], "gatet": 50, "gener": [0, 33, 39, 41, 61, 70], "get": 74, "github": 73, "graph": [32, 40], "group": [48, 49, 64], "guid": 63, "helper": [35, 52], "heterogen": [39, 55, 64], "how": 37, "hyperparamet": 65, "iivm": [36, 53, 66, 68], "impact": [36, 53, 54], "implement": [60, 68, 70], "induc": [33, 41, 61], "infer": [69, 71, 77], "initi": [35, 52], "instal": 73, "instrument": [32, 40], "integr": 34, "interact": [36, 48, 53, 56, 66, 68, 70], "interv": [69, 71], "invers": 55, "irm": [36, 38, 42, 48, 53, 55, 56, 58, 64, 66, 68, 70], "iv": [32, 36, 40, 53, 66, 68], "joint": 71, "k": [36, 53, 54, 58, 67], "lambda": 47, "lasso": [38, 47], "latest": 73, "lear": [35, 52], "learn": [0, 33, 35, 41, 52, 56, 60, 61, 64, 72, 74, 75], "learner": [37, 38, 51, 65, 74], "linear": [36, 49, 53, 55, 66, 68, 70], "linearscoremixin": 27, "literatur": 75, "load": [35, 38, 52], "loader": 0, "local": [36, 53, 54, 57, 68], "loss": 47, "lpq": [57, 68], "lqte": [54, 57], "m": 67, "machin": [0, 33, 35, 41, 52, 60, 61, 72, 74, 75], "main": 72, "mainten": 72, "make_confounded_irm_data": 16, "make_confounded_plr_data": 17, "make_did_sz2020": 18, "make_heterogeneous_data": 19, "make_iivm_data": 20, "make_irm_data": 21, "make_pliv_chs2015": 22, "make_pliv_multiway_cluster_ckms2021": 23, "make_plr_ccddhnr2018": 24, "make_plr_turrell2018": 25, "make_ssm_data": 26, "mar": 59, "market": [35, 52], "matric": 62, "method": 77, "metric": 51, "minimum": 65, "miss": 59, "missing": [66, 68], "mixin": 0, "ml": [33, 34, 41, 61, 77], "mlr3": 37, "mlr3extralearn": 37, "mlr3learner": 37, "mlr3pipelin": 37, "model": [0, 36, 38, 42, 43, 48, 49, 53, 55, 56, 59, 64, 66, 67, 68, 69, 70, 74, 77], "modul": [0, 38], "more": 37, "motiv": [35, 52], "multipl": 55, "multipli": [69, 71], "naiv": [32, 40], "net": [36, 53], "neyman": [68, 74], "nonignor": [59, 66, 68], "nonlinearscoremixin": 28, "nonrespons": [59, 66, 68], "note": 76, "nuisanc": 74, "object": [35, 52, 58], "orthogon": [33, 41, 61, 68, 74], "out": [33, 41, 61], "outcom": [44, 45, 59, 64], "over": 69, "overcom": [33, 41, 61], "overfit": [33, 41, 61], "overlap": 55, "packag": [34, 36, 53, 73], "panel": [45, 66, 68, 70], "paramet": [37, 38, 68], "partial": [33, 36, 41, 49, 53, 55, 61, 66, 68, 70], "particip": [36, 53], "partit": 67, "penalti": 47, "perform": [34, 55], "pip": 73, "pipelin": 65, "pliv": [66, 68], "plm": 55, "plot": [35, 52], "plr": [36, 38, 43, 49, 53, 64, 66, 68, 70], "polici": [56, 64], "potenti": [44, 54, 57, 64, 68], "pq": [57, 64, 68], "pre": 46, "predict": [34, 65], "preprocess": 37, "problem": 77, "process": [33, 35, 41, 52, 61], "product": [35, 52], "propens": 55, "provid": 67, "python": [39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 65, 73], "qte": [57, 64], "qualiti": 47, "quantil": [54, 57, 64, 68], "r": [32, 33, 34, 35, 36, 37, 39, 65, 73], "random": [38, 59, 66, 68], "rank": 55, "real": [35, 52], "refer": [0, 32, 35, 37, 40, 47, 52, 55, 61, 65, 67, 69, 71, 72, 74], "regress": [36, 48, 49, 53, 56, 66, 68, 70], "regular": [33, 41, 61], "releas": [73, 76], "remov": [33, 41, 61], "repeat": [45, 66, 67, 68, 70], "repetit": 67, "requir": 65, "respect": [35, 52], "result": [35, 36, 52, 53, 55], "risk": [44, 54, 64, 68], "robust": [35, 52], "sampl": [33, 41, 59, 61, 66, 67], "sandbox": 39, "score": [0, 33, 41, 55, 61, 68, 74], "section": [45, 66, 68, 70], "select": [59, 66], "sensit": [50, 58, 70, 77], "set": [37, 65], "simpl": [33, 41, 61], "simul": [32, 35, 40, 45, 52, 58], "simultan": [69, 71], "sourc": [72, 73], "specif": [70, 77], "specifi": [38, 65, 68], "split": [33, 41, 61, 67], "ssm": 66, "stage": 47, "standard": [35, 51, 52], "start": 74, "studi": 39, "summari": [36, 53, 55], "test": 46, "theori": 70, "time": 51, "treatment": [36, 42, 43, 44, 48, 49, 53, 54, 55, 57, 64], "tree": [56, 64], "tune": [37, 65], "two": [35, 42, 43, 52], "under": [55, 59], "up": 37, "us": [32, 34, 37, 38, 40, 65], "user": 63, "util": [0, 29, 30, 31], "v": 47, "valid": [69, 71], "valu": [44, 54, 64, 68], "variabl": [32, 40], "varianc": 69, "version": 73, "via": 68, "wai": [35, 52], "wealth": [36, 53, 54], "weight": [55, 64], "whl": 73, "without": 67, "workflow": 77, "zero": [35, 52]}})