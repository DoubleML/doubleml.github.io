Search.setIndex({"alltitles": {"(One-Way) Cluster Robust Double Machine Learing": [[40, "(One-Way)-Cluster-Robust-Double-Machine-Learing"], [59, "(One-Way)-Cluster-Robust-Double-Machine-Learing"]], "0. Problem Formulation": [[105, "problem-formulation"]], "1. Data-Backend": [[105, "data-backend"]], "1. Formulation of Causal Model & Identification Assumptions": [[66, "1.-Formulation-of-Causal-Model-&-Identification-Assumptions"]], "2. Causal Model": [[105, "causal-model"]], "2. Estimation of Causal Effect": [[66, "2.-Estimation-of-Causal-Effect"]], "3. ML Methods": [[105, "ml-methods"]], "3. Sensitivity Analysis": [[66, "3.-Sensitivity-Analysis"]], "4. Benchmarking Analysis": [[66, "4.-Benchmarking-Analysis"]], "4. DML Specifications": [[105, "dml-specifications"]], "5. Conclusion": [[66, "5.-Conclusion"]], "5. Estimation": [[105, "estimation"]], "6. Inference": [[105, "inference"]], "7. Sensitivity Analysis": [[105, "sensitivity-analysis"]], "A Motivating Example: Two-Way Cluster Robust DML": [[40, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"], [59, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"]], "API reference": [[0, "api-reference"]], "ATE Estimation and Sensitivity": [[56, "ATE-Estimation-and-Sensitivity"]], "ATE estimates distribution": [[67, "ATE-estimates-distribution"], [67, "id3"]], "ATTE Estimation": [[51, "ATTE-Estimation"], [51, "id2"]], "Acknowledgements": [[100, "acknowledgements"]], "Acknowledgements and Final Remarks": [[39, "Acknowledgements-and-Final-Remarks"]], "Additional Results: CATE estimates": [[62, "Additional-Results:-CATE-estimates"]], "Advanced: External Predictions": [[73, "advanced-external-predictions"]], "Algorithm DML1": [[68, "algorithm-dml1"]], "Algorithm DML2": [[68, "algorithm-dml2"]], "Application Results": [[40, "Application-Results"], [59, "Application-Results"]], "Application: 401(k)": [[65, "Application:-401(k)"]], "AutoML with less Computation time": [[58, "AutoML-with-less-Computation-time"]], "Average Potential Outcome (APOs)": [[45, "Average-Potential-Outcome-(APOs)"]], "Average Potential Outcomes (APOs)": [[74, "average-potential-outcomes-apos"], [76, "average-potential-outcomes-apos"], [90, "average-potential-outcomes-apos"]], "Average Potential Outcomes (APOs) for Multiple Treatment Levels": [[74, "average-potential-outcomes-apos-for-multiple-treatment-levels"]], "Benchmarking": [[90, "benchmarking"]], "Benchmarking Analysis": [[65, "Benchmarking-Analysis"]], "Binary Interactive Regression Model (IRM)": [[74, "binary-interactive-regression-model-irm"], [76, "binary-interactive-regression-model-irm"]], "CATEs for IRM models": [[72, "cates-for-irm-models"]], "CATEs for PLR models": [[72, "cates-for-plr-models"]], "CVaR Treatment Effects": [[50, "CVaR-Treatment-Effects"]], "CVaR of potential outcomes": [[72, "cvar-of-potential-outcomes"]], "CVaR treatment effects": [[72, "cvar-treatment-effects"]], "Causal Analysis with DoubleML": [[66, "Causal-Analysis-with-DoubleML"]], "Causal Contrasts": [[45, "Causal-Contrasts"]], "Causal estimation vs. lasso penalty \\lambda": [[53, "Causal-estimation-vs.-lasso-penalty-\\lambda"]], "Chernozhukov et al. (2023): Benchmarking": [[66, "Chernozhukov-et-al.-(2023):-Benchmarking"]], "Citation": [[100, "citation"]], "Cluster Robust Cross Fitting": [[40, "Cluster-Robust-Cross-Fitting"], [59, "Cluster-Robust-Cross-Fitting"]], "Cluster Robust Standard Errors": [[40, "Cluster-Robust-Standard-Errors"], [59, "Cluster-Robust-Standard-Errors"]], "Clustering and double machine learning": [[40, "Clustering-and-double-machine-learning"], [59, "Clustering-and-double-machine-learning"]], "Combined loss vs. lasso penalty \\lambda": [[53, "Combined-loss-vs.-lasso-penalty-\\lambda"]], "Compare Metrics for Nuisance Estimation": [[58, "Compare-Metrics-for-Nuisance-Estimation"]], "Comparing different learners": [[57, "Comparing-different-learners"]], "Comparison and summary": [[58, "Comparison-and-summary"]], "Comparison to AutoML with less Computation time and Untuned XGBoost Learners": [[58, "Comparison-to-AutoML-with-less-Computation-time-and-Untuned-XGBoost-Learners"]], "Comparison to did package": [[39, "Comparison-to-did-package"]], "Computation time": [[57, "Computation-time"]], "Conclusion": [[58, "Conclusion"]], "Conditional Value at Risk (CVaR)": [[50, "Conditional-Value-at-Risk-(CVaR)"]], "Conditional average treatment effects (CATEs)": [[72, "conditional-average-treatment-effects-cates"]], "Conditional value at risk (CVaR)": [[72, "conditional-value-at-risk-cvar"], [76, "conditional-value-at-risk-cvar"]], "Confidence bands and multiplier bootstrap for valid simultaneous inference": [[89, "confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference"], [99, "confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference"]], "Coverage Simulation": [[51, "Coverage-Simulation"], [51, "id3"]], "Cross-fitting with K folds": [[75, "cross-fitting-with-k-folds"]], "Cross-fitting, DML algorithms and Neyman-orthogonal score functions": [[102, "cross-fitting-dml-algorithms-and-neyman-orthogonal-score-functions"]], "Custom evaluation metrics": [[57, "Custom-evaluation-metrics"]], "DML: Bonus Data": [[43, "DML:-Bonus-Data"]], "Data": [[41, "Data"], [48, "Data"], [49, "Data"], [50, "Data"], [51, "Data"], [51, "id1"], [54, "Data"], [55, "Data"], [56, "Data"], [60, "Data"], [61, "Data"], [63, "Data"], [64, "Data"], [64, "id1"], [65, "Data"], [67, "Data"], [67, "id1"], [102, "data"]], "Data Generating Process (DGP)": [[38, "Data-Generating-Process-(DGP)"], [45, "Data-Generating-Process-(DGP)"], [47, "Data-Generating-Process-(DGP)"]], "Data Generation": [[58, "Data-Generation"]], "Data Simulation": [[37, "Data-Simulation"], [46, "Data-Simulation"]], "Data and Effect Estimation": [[65, "Data-and-Effect-Estimation"]], "Data generating process": [[69, "data-generating-process"]], "Data preprocessing": [[42, "Data-preprocessing"]], "Data-Backend for Cluster Data": [[40, "Data-Backend-for-Cluster-Data"], [59, "Data-Backend-for-Cluster-Data"]], "Dataset generators": [[0, "dataset-generators"]], "Dataset loaders": [[0, "dataset-loaders"]], "Datasets module": [[0, "datasets-module"]], "Define Helper Functions for Plotting": [[40, "Define-Helper-Functions-for-Plotting"], [59, "Define-Helper-Functions-for-Plotting"]], "Demo Example from did": [[39, "Demo-Example-from-did"]], "Details on Predictive Performance": [[39, "Details-on-Predictive-Performance"]], "Difference-in-Differences Models": [[76, "difference-in-differences-models"]], "Difference-in-Differences Models (DID)": [[74, "difference-in-differences-models-did"]], "Difference-in-Differences for Panel Data": [[90, "difference-in-differences-for-panel-data"]], "Difference-in-Differences for repeated cross-sections": [[90, "difference-in-differences-for-repeated-cross-sections"]], "Disclaimer": [[66, "Disclaimer"]], "Double Machine Learning Algorithm": [[100, "double-machine-learning-algorithm"]], "Double machine learning algorithms": [[68, "double-machine-learning-algorithms"]], "Double machine learning data class": [[0, "double-machine-learning-data-class"]], "Double machine learning literature": [[103, "double-machine-learning-literature"]], "Double machine learning models": [[0, "double-machine-learning-models"]], "Double/debiased machine learning": [[38, "Double/debiased-machine-learning"], [47, "Double/debiased-machine-learning"], [69, "double-debiased-machine-learning"]], "DoubleML": [[100, "doubleml"]], "DoubleML Object": [[65, "DoubleML-Object"]], "DoubleML Workflow": [[105, "doubleml-workflow"]], "DoubleML meets FLAML - How to tune learners automatically within DoubleML": [[58, "DoubleML-meets-FLAML---How-to-tune-learners-automatically-within-DoubleML"]], "DoubleMLData from arrays and matrices": [[70, "doublemldata-from-arrays-and-matrices"]], "DoubleMLData from dataframes": [[70, "doublemldata-from-dataframes"]], "Effect Heterogeneity": [[44, "effect-heterogeneity"]], "Empirical coverage vs. lasso penalty \\lambda": [[53, "Empirical-coverage-vs.-lasso-penalty-\\lambda"]], "Estimate DML models without sample-splitting": [[75, "estimate-dml-models-without-sample-splitting"]], "Estimate double/debiased machine learning models": [[102, "estimate-double-debiased-machine-learning-models"]], "Estimating Potential Quantiles and Quantile Treatment Effects": [[61, "Estimating-Potential-Quantiles-and-Quantile-Treatment-Effects"]], "Estimating local quantile treatment effects (LQTEs)": [[61, "Estimating-local-quantile-treatment-effects-(LQTEs)"]], "Estimating the Average Treatment Effect of 401(k) Eligibility on Net Financial Assets": [[41, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"], [60, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"]], "Estimating the treatment effect on the Conditional Value a Risk (CVaR)": [[61, "Estimating-the-treatment-effect-on-the-Conditional-Value-a-Risk-(CVaR)"]], "Estimation": [[67, "Estimation"], [67, "id2"]], "Estimation quality vs. \\lambda": [[53, "Estimation-quality-vs.-\\lambda"]], "Evaluate learners": [[73, "evaluate-learners"]], "Example: Sensitivity Analysis for Causal ML": [[66, "Example:-Sensitivity-Analysis-for-Causal-ML"]], "Examples": [[44, "examples"]], "Exploiting the Functionalities of did": [[39, "Exploiting-the-Functionalities-of-did"]], "Externally provide a sample splitting / partition": [[75, "externally-provide-a-sample-splitting-partition"]], "GATE Estimation and Sensitivity": [[56, "GATE-Estimation-and-Sensitivity"]], "GATET Estimation and Sensitivity": [[56, "GATET-Estimation-and-Sensitivity"]], "GATEs for IRM models": [[72, "gates-for-irm-models"]], "GATEs for PLR models": [[72, "gates-for-plr-models"]], "General Examples": [[44, "general-examples"]], "General algorithm": [[90, "general-algorithm"]], "Getting started": [[102, "getting-started"]], "Group Average Treatment Effects (GATEs)": [[54, "Group-Average-Treatment-Effects-(GATEs)"], [55, "Group-Average-Treatment-Effects-(GATEs)"]], "Group average treatment effects (GATEs)": [[72, "group-average-treatment-effects-gates"]], "Heterogeneous treatment effects": [[72, "heterogeneous-treatment-effects"]], "How to exploit more features of mlr3pipelines in DoubleML": [[42, "How-to-exploit-more-features-of-mlr3pipelines-in-DoubleML"]], "Hyperparameter tuning": [[73, "hyperparameter-tuning"], [73, "id16"]], "Hyperparameter tuning with pipelines": [[73, "hyperparameter-tuning-with-pipelines"]], "Implementation": [[90, "implementation"]], "Implementation of the double machine learning algorithms": [[68, "implementation-of-the-double-machine-learning-algorithms"]], "Implementation of the score function and the estimate of the causal parameter": [[76, "implementation-of-the-score-function-and-the-estimate-of-the-causal-parameter"]], "Implemented Neyman orthogonal score functions": [[76, "implemented-neyman-orthogonal-score-functions"]], "Initialize DoubleMLClusterData object": [[40, "Initialize-DoubleMLClusterData-object"], [59, "Initialize-DoubleMLClusterData-object"]], "Initialize the objects of class DoubleMLPLIV": [[40, "Initialize-the-objects-of-class-DoubleMLPLIV"], [59, "Initialize-the-objects-of-class-DoubleMLPLIV"]], "Installing DoubleML": [[101, "installing-doubleml"]], "Instrumental Variables Directed Acyclic Graph (IV - DAG)": [[37, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"], [46, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"]], "Interactive IV Model (IIVM)": [[41, "Interactive-IV-Model-(IIVM)"], [60, "Interactive-IV-Model-(IIVM)"]], "Interactive IV model (IIVM)": [[74, "interactive-iv-model-iivm"], [76, "interactive-iv-model-iivm"]], "Interactive Regression Model (IRM)": [[41, "Interactive-Regression-Model-(IRM)"], [54, "Interactive-Regression-Model-(IRM)"], [60, "Interactive-Regression-Model-(IRM)"], [63, "Interactive-Regression-Model-(IRM)"]], "Interactive regression model (IRM)": [[90, "interactive-regression-model-irm"]], "Interactive regression models (IRM)": [[74, "interactive-regression-models-irm"], [76, "interactive-regression-models-irm"]], "Learners to estimate the nuisance models": [[102, "learners-to-estimate-the-nuisance-models"]], "Learners, hyperparameters and hyperparameter tuning": [[73, "learners-hyperparameters-and-hyperparameter-tuning"]], "Load Data": [[66, "Load-Data"]], "Load and Process Data": [[40, "Load-and-Process-Data"], [59, "Load-and-Process-Data"]], "Load bonus data using the dml datasets module": [[43, "Load-bonus-data-using-the-dml-datasets-module"]], "Local Average Treatment Effects of 401(k) Participation on Net Financial Assets": [[41, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"], [60, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"]], "Local Potential Quantile Estimation": [[64, "Local-Potential-Quantile-Estimation"]], "Local Potential Quantiles (LPQs)": [[64, "Local-Potential-Quantiles-(LPQs)"]], "Local Quantile Treatment Effects (LQTEs)": [[64, "Local-Quantile-Treatment-Effects-(LQTEs)"]], "Local potential quantiles (LPQs)": [[76, "local-potential-quantiles-lpqs"]], "Main Features": [[100, "main-features"]], "Minimum requirements for learners": [[73, "minimum-requirements-for-learners"], [73, "id2"]], "Missingness at Random": [[74, "missingness-at-random"], [76, "missingness-at-random"]], "Model-specific implementations": [[90, "model-specific-implementations"]], "Models": [[74, "models"]], "Motivation": [[40, "Motivation"], [59, "Motivation"]], "Multiple Average Potential Outcome Models (APOS)": [[45, "Multiple-Average-Potential-Outcome-Models-(APOS)"]], "Multiplier bootstrap and joint confidence intervals": [[99, "multiplier-bootstrap-and-joint-confidence-intervals"]], "Naive estimation": [[37, "Naive-estimation"], [46, "Naive-estimation"]], "No Clustering / Zero-Way Clustering": [[40, "No-Clustering-/-Zero-Way-Clustering"], [59, "No-Clustering-/-Zero-Way-Clustering"]], "Nonignorable Nonresponse": [[74, "nonignorable-nonresponse"], [76, "nonignorable-nonresponse"]], "One-Way Clustering with Respect to the Market": [[40, "One-Way-Clustering-with-Respect-to-the-Market"], [59, "One-Way-Clustering-with-Respect-to-the-Market"]], "One-Way Clustering with Respect to the Product": [[40, "One-Way-Clustering-with-Respect-to-the-Product"], [59, "One-Way-Clustering-with-Respect-to-the-Product"]], "One-dimensional Example": [[48, "One-dimensional-Example"], [49, "One-dimensional-Example"]], "Outcome missing at random (MAR)": [[67, "Outcome-missing-at-random-(MAR)"]], "Outcome missing under nonignorable nonresponse": [[67, "Outcome-missing-under-nonignorable-nonresponse"]], "Overcoming regularization bias by orthogonalization": [[38, "Overcoming-regularization-bias-by-orthogonalization"], [47, "Overcoming-regularization-bias-by-orthogonalization"], [69, "overcoming-regularization-bias-by-orthogonalization"]], "Panel Data": [[76, "panel-data"]], "Panel Data (Repeated Outcomes)": [[51, "Panel-Data-(Repeated-Outcomes)"]], "Panel data": [[74, "panel-data"]], "Parameter tuning": [[42, "Parameter-tuning"]], "Partialling out score": [[38, "Partialling-out-score"], [47, "Partialling-out-score"], [69, "partialling-out-score"]], "Partially Linear Regression Model (PLR)": [[41, "Partially-Linear-Regression-Model-(PLR)"], [55, "Partially-Linear-Regression-Model-(PLR)"], [60, "Partially-Linear-Regression-Model-(PLR)"]], "Partially linear IV regression model (PLIV)": [[74, "partially-linear-iv-regression-model-pliv"], [76, "partially-linear-iv-regression-model-pliv"]], "Partially linear models (PLM)": [[74, "partially-linear-models-plm"], [76, "partially-linear-models-plm"]], "Partially linear regression model (PLR)": [[74, "partially-linear-regression-model-plr"], [76, "partially-linear-regression-model-plr"], [90, "partially-linear-regression-model-plr"]], "Plot Coefficients and 95% Confidence Intervals": [[58, "Plot-Coefficients-and-95%-Confidence-Intervals"]], "Policy Learning with Trees": [[63, "Policy-Learning-with-Trees"], [72, "policy-learning-with-trees"]], "Potential Quantile Estimation": [[64, "Potential-Quantile-Estimation"]], "Potential Quantiles (PQs)": [[64, "Potential-Quantiles-(PQs)"]], "Potential quantiles (PQs)": [[72, "potential-quantiles-pqs"], [76, "potential-quantiles-pqs"]], "Python: Average Potential Outcome (APO) Models": [[45, "Python:-Average-Potential-Outcome-(APO)-Models"]], "Python: Basic Instrumental Variables calculation": [[46, "Python:-Basic-Instrumental-Variables-calculation"]], "Python: Basics of Double Machine Learning": [[47, "Python:-Basics-of-Double-Machine-Learning"]], "Python: Building the package from source": [[101, "python-building-the-package-from-source"]], "Python: Case studies": [[44, "python-case-studies"]], "Python: Choice of learners": [[57, "Python:-Choice-of-learners"]], "Python: Cluster Robust Double Machine Learning": [[59, "Python:-Cluster-Robust-Double-Machine-Learning"]], "Python: Conditional Average Treatment Effects (CATEs) for IRM models": [[48, "Python:-Conditional-Average-Treatment-Effects-(CATEs)-for-IRM-models"]], "Python: Conditional Average Treatment Effects (CATEs) for PLR models": [[49, "Python:-Conditional-Average-Treatment-Effects-(CATEs)-for-PLR-models"]], "Python: Conditional Value at Risk of potential outcomes": [[50, "Python:-Conditional-Value-at-Risk-of-potential-outcomes"]], "Python: Difference-in-Differences": [[51, "Python:-Difference-in-Differences"]], "Python: Difference-in-Differences Pre-Testing": [[52, "Python:-Difference-in-Differences-Pre-Testing"]], "Python: First Stage and Causal Estimation": [[53, "Python:-First-Stage-and-Causal-Estimation"]], "Python: GATE Sensitivity Analysis": [[56, "Python:-GATE-Sensitivity-Analysis"]], "Python: Group Average Treatment Effects (GATEs) for IRM models": [[54, "Python:-Group-Average-Treatment-Effects-(GATEs)-for-IRM-models"]], "Python: Group Average Treatment Effects (GATEs) for PLR models": [[55, "Python:-Group-Average-Treatment-Effects-(GATEs)-for-PLR-models"]], "Python: Impact of 401(k) on Financial Wealth": [[60, "Python:-Impact-of-401(k)-on-Financial-Wealth"]], "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)": [[61, "Python:-Impact-of-401(k)-on-Financial-Wealth-(Quantile-Effects)"]], "Python: Installing DoubleML": [[101, "python-installing-doubleml"]], "Python: Installing a released version from a .whl file": [[101, "python-installing-a-released-version-from-a-whl-file"]], "Python: Installing the latest release from pip or conda": [[101, "python-installing-the-latest-release-from-pip-or-conda"]], "Python: Learners and hyperparameters": [[73, "python-learners-and-hyperparameters"]], "Python: PLM and IRM for Multiple Treatments": [[62, "Python:-PLM-and-IRM-for-Multiple-Treatments"]], "Python: Policy Learning with Trees": [[63, "Python:-Policy-Learning-with-Trees"]], "Python: Potential Quantiles and Quantile Treatment Effects": [[64, "Python:-Potential-Quantiles-and-Quantile-Treatment-Effects"]], "Python: Sample Selection Models": [[67, "Python:-Sample-Selection-Models"]], "Python: Sensitivity Analysis": [[65, "Python:-Sensitivity-Analysis"]], "Quantile Treatment Effects (QTEs)": [[64, "Quantile-Treatment-Effects-(QTEs)"]], "Quantile treatment effects (QTEs)": [[72, "quantile-treatment-effects-qtes"]], "Quantiles": [[72, "quantiles"]], "R: Basic Instrumental Variables Calculation": [[37, "R:-Basic-Instrumental-Variables-Calculation"]], "R: Basics of Double Machine Learning": [[38, "R:-Basics-of-Double-Machine-Learning"]], "R: Case studies": [[44, "r-case-studies"]], "R: Cluster Robust Double Machine Learning": [[40, "R:-Cluster-Robust-Double-Machine-Learning"]], "R: DoubleML for Difference-in-Differences": [[39, "R:-DoubleML-for-Difference-in-Differences"]], "R: Ensemble Learners and More with mlr3pipelines": [[42, "R:-Ensemble-Learners-and-More-with-mlr3pipelines"]], "R: Impact of 401(k) on Financial Wealth": [[41, "R:-Impact-of-401(k)-on-Financial-Wealth"]], "R: Installing DoubleML": [[101, "r-installing-doubleml"]], "R: Installing the development version from GitHub": [[101, "r-installing-the-development-version-from-github"]], "R: Installing the latest release from CRAN": [[101, "r-installing-the-latest-release-from-cran"]], "R: Learners and hyperparameters": [[73, "r-learners-and-hyperparameters"]], "Ranking Treatment Effects under Treatment Propensity and Treatment Effect Heterogeneity": [[62, "Ranking-Treatment-Effects-under-Treatment-Propensity-and-Treatment-Effect-Heterogeneity"]], "Real-Data Application": [[40, "Real-Data-Application"], [59, "Real-Data-Application"]], "References": [[37, "References"], [39, "References"], [40, "References"], [42, "References"], [46, "References"], [53, "References"], [59, "References"], [62, "References"], [66, "References"], [69, "references"], [73, "references"], [75, "references"], [89, "references"], [99, "references"], [100, "references"], [102, "references"]], "Regularization Bias in Simple ML-Approaches": [[38, "Regularization-Bias-in-Simple-ML-Approaches"], [47, "Regularization-Bias-in-Simple-ML-Approaches"]], "Regularization bias in simple ML-approaches": [[69, "regularization-bias-in-simple-ml-approaches"]], "Release notes": [[104, "release-notes"]], "Repeated Cross-Sectional Data": [[51, "Repeated-Cross-Sectional-Data"], [76, "repeated-cross-sectional-data"]], "Repeated cross-fitting with K folds and M repetitions": [[75, "repeated-cross-fitting-with-k-folds-and-m-repetitions"]], "Repeated cross-sections": [[74, "repeated-cross-sections"]], "Sample Selection Models": [[76, "sample-selection-models"]], "Sample Selection Models (SSM)": [[74, "sample-selection-models-ssm"]], "Sample splitting to remove bias induced by overfitting": [[38, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [47, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [69, "sample-splitting-to-remove-bias-induced-by-overfitting"]], "Sample-splitting without cross-fitting": [[75, "sample-splitting-without-cross-fitting"]], "Sample-splitting, cross-fitting and repeated cross-fitting": [[75, "sample-splitting-cross-fitting-and-repeated-cross-fitting"]], "Sandbox": [[44, "sandbox"]], "Score functions": [[76, "score-functions"]], "Score mixin classes for double machine learning models": [[0, "score-mixin-classes-for-double-machine-learning-models"]], "Sensitivity Analysis": [[45, "Sensitivity-Analysis"], [65, "Sensitivity-Analysis"], [65, "id1"]], "Sensitivity Analysis with IRM": [[65, "Sensitivity-Analysis-with-IRM"]], "Sensitivity analysis": [[90, "sensitivity-analysis"]], "Set up learners based on mlr3pipelines": [[42, "Set-up-learners-based-on-mlr3pipelines"]], "Simulate two-way cluster data": [[40, "Simulate-two-way-cluster-data"], [59, "Simulate-two-way-cluster-data"]], "Simulation Example": [[65, "Simulation-Example"]], "Simultaneous inference over different DoubleML models (advanced)": [[89, "simultaneous-inference-over-different-doubleml-models-advanced"]], "Single Average Potential Outcome Models (APO)": [[45, "Single-Average-Potential-Outcome-Models-(APO)"]], "Source code and maintenance": [[100, "source-code-and-maintenance"]], "Specify learner and estimate causal parameter: IRM model with Lasso as learner": [[43, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: IRM model with random forest as learner": [[43, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-random-forest-as-learner"]], "Specify learner and estimate causal parameter: PLR model with Lasso as learner": [[43, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: PLR model with random forest as learner": [[43, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-random-forest-as-learner"]], "Specifying alternative score functions via callables": [[76, "specifying-alternative-score-functions-via-callables"]], "Specifying learners and set hyperparameters": [[73, "specifying-learners-and-set-hyperparameters"], [73, "id9"]], "Standard approach": [[57, "Standard-approach"]], "Step 1: Custom API for FLAML Models within DoubleML": [[58, "Step-1:-Custom-API-for-FLAML-Models-within-DoubleML"]], "Step 1: Initialize and Train the AutoML Models:": [[58, "Step-1:-Initialize-and-Train-the-AutoML-Models:"]], "Step 2: Evaluate the Tuned Models": [[58, "Step-2:-Evaluate-the-Tuned-Models"]], "Step 2: Using the API when calling DoubleML\u2019s .fit() Method": [[58, "Step-2:-Using-the-API-when-calling-DoubleML's-.fit()-Method"]], "Step 3: Create and Fit DoubleML Model": [[58, "Step-3:-Create-and-Fit-DoubleML-Model"]], "Summary Figure": [[62, "Summary-Figure"]], "Summary of Results": [[41, "Summary-of-Results"], [60, "Summary-of-Results"]], "The Augmented Inverse Propensity Weighting Model estimates the ATE under arbitrary effect and propensity score heterogeneity": [[62, "The-Augmented-Inverse-Propensity-Weighting-Model-estimates-the-ATE-under-arbitrary-effect-and-propensity-score-heterogeneity"]], "The Data Backend: DoubleMLData": [[41, "The-Data-Backend:-DoubleMLData"], [60, "The-Data-Backend:-DoubleMLData"]], "The DoubleML package": [[41, "The-DoubleML-package"], [60, "The-DoubleML-package"]], "The Partially Linear Model performs overlap weighting": [[62, "The-Partially-Linear-Model-performs-overlap-weighting"]], "The basics of double/debiased machine learning": [[69, "the-basics-of-double-debiased-machine-learning"]], "The causal model": [[102, "the-causal-model"]], "The data-backend DoubleMLData": [[70, "the-data-backend-doublemldata"], [102, "the-data-backend-doublemldata"]], "Theory": [[90, "theory"]], "Tuning on the Folds": [[58, "Tuning-on-the-Folds"]], "Tuning on the full Sample": [[58, "Tuning-on-the-full-Sample"]], "Two-Dimensional Example": [[48, "Two-Dimensional-Example"], [49, "Two-Dimensional-Example"]], "Two-Way Clustering with Respect to Product and Market": [[40, "Two-Way-Clustering-with-Respect-to-Product-and-Market"], [59, "Two-Way-Clustering-with-Respect-to-Product-and-Market"]], "Untuned (default parameter) XGBoost": [[58, "Untuned-(default-parameter)-XGBoost"]], "Use ensemble learners based on mlr3pipelines": [[42, "Use-ensemble-learners-based-on-mlr3pipelines"]], "User guide": [[71, "user-guide"]], "Using DoubleML": [[37, "Using-DoubleML"], [46, "Using-DoubleML"]], "Using ML for DiD: Integrating DoubleML in did": [[39, "Using-ML-for-DiD:-Integrating-DoubleML-in-did"]], "Using learners from mlr3, mlr3learners and mlr3extralearners": [[42, "Using-learners-from-mlr3,-mlr3learners-and-mlr3extralearners"]], "Using pipelines to construct learners": [[73, "using-pipelines-to-construct-learners"]], "Utility classes": [[0, "utility-classes"]], "Utility classes and functions": [[0, "utility-classes-and-functions"]], "Utility functions": [[0, "utility-functions"]], "VanderWeele and Arah (2011): Benchmarking": [[66, "VanderWeele-and-Arah-(2011):-Benchmarking"]], "Variance estimation": [[89, "variance-estimation"]], "Variance estimation and confidence intervals": [[89, "variance-estimation-and-confidence-intervals"]], "Weighted Average Treatment Effects": [[72, "weighted-average-treatment-effects"]], "doubleml.DoubleMLAPO": [[1, "doubleml-doublemlapo"]], "doubleml.DoubleMLAPOS": [[2, "doubleml-doublemlapos"]], "doubleml.DoubleMLCVAR": [[3, "doubleml-doublemlcvar"]], "doubleml.DoubleMLClusterData": [[4, "doubleml-doublemlclusterdata"]], "doubleml.DoubleMLDID": [[5, "doubleml-doublemldid"]], "doubleml.DoubleMLDIDCS": [[6, "doubleml-doublemldidcs"]], "doubleml.DoubleMLData": [[7, "doubleml-doublemldata"]], "doubleml.DoubleMLIIVM": [[8, "doubleml-doublemliivm"]], "doubleml.DoubleMLIRM": [[9, "doubleml-doublemlirm"]], "doubleml.DoubleMLLPQ": [[10, "doubleml-doublemllpq"]], "doubleml.DoubleMLPLIV": [[11, "doubleml-doublemlpliv"]], "doubleml.DoubleMLPLR": [[12, "doubleml-doublemlplr"]], "doubleml.DoubleMLPQ": [[13, "doubleml-doublemlpq"]], "doubleml.DoubleMLQTE": [[14, "doubleml-doublemlqte"]], "doubleml.DoubleMLSSM": [[15, "doubleml-doublemlssm"]], "doubleml.datasets.fetch_401K": [[16, "doubleml-datasets-fetch-401k"]], "doubleml.datasets.fetch_bonus": [[17, "doubleml-datasets-fetch-bonus"]], "doubleml.datasets.make_confounded_irm_data": [[18, "doubleml-datasets-make-confounded-irm-data"]], "doubleml.datasets.make_confounded_plr_data": [[19, "doubleml-datasets-make-confounded-plr-data"]], "doubleml.datasets.make_did_SZ2020": [[20, "doubleml-datasets-make-did-sz2020"]], "doubleml.datasets.make_heterogeneous_data": [[21, "doubleml-datasets-make-heterogeneous-data"]], "doubleml.datasets.make_iivm_data": [[22, "doubleml-datasets-make-iivm-data"]], "doubleml.datasets.make_irm_data": [[23, "doubleml-datasets-make-irm-data"]], "doubleml.datasets.make_irm_data_discrete_treatments": [[24, "doubleml-datasets-make-irm-data-discrete-treatments"]], "doubleml.datasets.make_pliv_CHS2015": [[25, "doubleml-datasets-make-pliv-chs2015"]], "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021": [[26, "doubleml-datasets-make-pliv-multiway-cluster-ckms2021"]], "doubleml.datasets.make_plr_CCDDHNR2018": [[27, "doubleml-datasets-make-plr-ccddhnr2018"]], "doubleml.datasets.make_plr_turrell2018": [[28, "doubleml-datasets-make-plr-turrell2018"]], "doubleml.datasets.make_ssm_data": [[29, "doubleml-datasets-make-ssm-data"]], "doubleml.double_ml_score_mixins.LinearScoreMixin": [[30, "doubleml-double-ml-score-mixins-linearscoremixin"]], "doubleml.double_ml_score_mixins.NonLinearScoreMixin": [[31, "doubleml-double-ml-score-mixins-nonlinearscoremixin"]], "doubleml.utils.DMLDummyClassifier": [[32, "doubleml-utils-dmldummyclassifier"]], "doubleml.utils.DMLDummyRegressor": [[33, "doubleml-utils-dmldummyregressor"]], "doubleml.utils.DoubleMLBLP": [[34, "doubleml-utils-doublemlblp"]], "doubleml.utils.DoubleMLPolicyTree": [[35, "doubleml-utils-doublemlpolicytree"]], "doubleml.utils.gain_statistics": [[36, "doubleml-utils-gain-statistics"]]}, "docnames": ["api/api", "api/generated/doubleml.DoubleMLAPO", "api/generated/doubleml.DoubleMLAPOS", "api/generated/doubleml.DoubleMLCVAR", "api/generated/doubleml.DoubleMLClusterData", "api/generated/doubleml.DoubleMLDID", "api/generated/doubleml.DoubleMLDIDCS", "api/generated/doubleml.DoubleMLData", "api/generated/doubleml.DoubleMLIIVM", "api/generated/doubleml.DoubleMLIRM", "api/generated/doubleml.DoubleMLLPQ", "api/generated/doubleml.DoubleMLPLIV", "api/generated/doubleml.DoubleMLPLR", "api/generated/doubleml.DoubleMLPQ", "api/generated/doubleml.DoubleMLQTE", "api/generated/doubleml.DoubleMLSSM", "api/generated/doubleml.datasets.fetch_401K", "api/generated/doubleml.datasets.fetch_bonus", "api/generated/doubleml.datasets.make_confounded_irm_data", "api/generated/doubleml.datasets.make_confounded_plr_data", "api/generated/doubleml.datasets.make_did_SZ2020", "api/generated/doubleml.datasets.make_heterogeneous_data", "api/generated/doubleml.datasets.make_iivm_data", "api/generated/doubleml.datasets.make_irm_data", "api/generated/doubleml.datasets.make_irm_data_discrete_treatments", "api/generated/doubleml.datasets.make_pliv_CHS2015", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018", "api/generated/doubleml.datasets.make_plr_turrell2018", "api/generated/doubleml.datasets.make_ssm_data", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin", "api/generated/doubleml.utils.DMLDummyClassifier", "api/generated/doubleml.utils.DMLDummyRegressor", "api/generated/doubleml.utils.DoubleMLBLP", "api/generated/doubleml.utils.DoubleMLPolicyTree", "api/generated/doubleml.utils.gain_statistics", "examples/R_double_ml_basic_iv", "examples/R_double_ml_basics", "examples/R_double_ml_did", "examples/R_double_ml_multiway_cluster", "examples/R_double_ml_pension", "examples/R_double_ml_pipeline", "examples/double_ml_bonus_data", "examples/index", "examples/py_double_ml_apo", "examples/py_double_ml_basic_iv", "examples/py_double_ml_basics", "examples/py_double_ml_cate", "examples/py_double_ml_cate_plr", "examples/py_double_ml_cvar", "examples/py_double_ml_did", "examples/py_double_ml_did_pretest", "examples/py_double_ml_firststage", "examples/py_double_ml_gate", "examples/py_double_ml_gate_plr", "examples/py_double_ml_gate_sensitivity", "examples/py_double_ml_learner", "examples/py_double_ml_meets_flaml", "examples/py_double_ml_multiway_cluster", "examples/py_double_ml_pension", "examples/py_double_ml_pension_qte", "examples/py_double_ml_plm_irm_hetfx", "examples/py_double_ml_policy_tree", "examples/py_double_ml_pq", "examples/py_double_ml_sensitivity", "examples/py_double_ml_sensitivity_booking", "examples/py_double_ml_ssm", "guide/algorithms", "guide/basics", "guide/data_backend", "guide/guide", "guide/heterogeneity", "guide/learners", "guide/models", "guide/resampling", "guide/scores", "guide/scores/apo_score", "guide/scores/cvar_score", "guide/scores/did_score", "guide/scores/didcs_score", "guide/scores/iivm_score", "guide/scores/irm_score", "guide/scores/lpq_score", "guide/scores/mar_score", "guide/scores/nr_score", "guide/scores/pliv_score", "guide/scores/plr_score", "guide/scores/pq_score", "guide/se_confint", "guide/sensitivity", "guide/sensitivity/apo_sensitivity", "guide/sensitivity/benchmarking", "guide/sensitivity/did_cs_sensitivity", "guide/sensitivity/did_sensitivity", "guide/sensitivity/implementation", "guide/sensitivity/irm_sensitivity", "guide/sensitivity/plr_sensitivity", "guide/sensitivity/theory", "guide/sim_inf", "index", "intro/install", "intro/intro", "literature/literature", "release/release", "workflow/workflow"], "envversion": {"nbsphinx": 4, "sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["api/api.rst", "api/generated/doubleml.DoubleMLAPO.rst", "api/generated/doubleml.DoubleMLAPOS.rst", "api/generated/doubleml.DoubleMLCVAR.rst", "api/generated/doubleml.DoubleMLClusterData.rst", "api/generated/doubleml.DoubleMLDID.rst", "api/generated/doubleml.DoubleMLDIDCS.rst", "api/generated/doubleml.DoubleMLData.rst", "api/generated/doubleml.DoubleMLIIVM.rst", "api/generated/doubleml.DoubleMLIRM.rst", "api/generated/doubleml.DoubleMLLPQ.rst", "api/generated/doubleml.DoubleMLPLIV.rst", "api/generated/doubleml.DoubleMLPLR.rst", "api/generated/doubleml.DoubleMLPQ.rst", "api/generated/doubleml.DoubleMLQTE.rst", "api/generated/doubleml.DoubleMLSSM.rst", "api/generated/doubleml.datasets.fetch_401K.rst", "api/generated/doubleml.datasets.fetch_bonus.rst", "api/generated/doubleml.datasets.make_confounded_irm_data.rst", "api/generated/doubleml.datasets.make_confounded_plr_data.rst", "api/generated/doubleml.datasets.make_did_SZ2020.rst", "api/generated/doubleml.datasets.make_heterogeneous_data.rst", "api/generated/doubleml.datasets.make_iivm_data.rst", "api/generated/doubleml.datasets.make_irm_data.rst", "api/generated/doubleml.datasets.make_irm_data_discrete_treatments.rst", "api/generated/doubleml.datasets.make_pliv_CHS2015.rst", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021.rst", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018.rst", "api/generated/doubleml.datasets.make_plr_turrell2018.rst", "api/generated/doubleml.datasets.make_ssm_data.rst", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin.rst", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin.rst", "api/generated/doubleml.utils.DMLDummyClassifier.rst", "api/generated/doubleml.utils.DMLDummyRegressor.rst", "api/generated/doubleml.utils.DoubleMLBLP.rst", "api/generated/doubleml.utils.DoubleMLPolicyTree.rst", "api/generated/doubleml.utils.gain_statistics.rst", "examples/R_double_ml_basic_iv.ipynb", "examples/R_double_ml_basics.ipynb", "examples/R_double_ml_did.ipynb", "examples/R_double_ml_multiway_cluster.ipynb", "examples/R_double_ml_pension.ipynb", "examples/R_double_ml_pipeline.ipynb", "examples/double_ml_bonus_data.ipynb", "examples/index.rst", "examples/py_double_ml_apo.ipynb", "examples/py_double_ml_basic_iv.ipynb", "examples/py_double_ml_basics.ipynb", "examples/py_double_ml_cate.ipynb", "examples/py_double_ml_cate_plr.ipynb", "examples/py_double_ml_cvar.ipynb", "examples/py_double_ml_did.ipynb", "examples/py_double_ml_did_pretest.ipynb", "examples/py_double_ml_firststage.ipynb", "examples/py_double_ml_gate.ipynb", "examples/py_double_ml_gate_plr.ipynb", "examples/py_double_ml_gate_sensitivity.ipynb", "examples/py_double_ml_learner.ipynb", "examples/py_double_ml_meets_flaml.ipynb", "examples/py_double_ml_multiway_cluster.ipynb", "examples/py_double_ml_pension.ipynb", "examples/py_double_ml_pension_qte.ipynb", "examples/py_double_ml_plm_irm_hetfx.ipynb", "examples/py_double_ml_policy_tree.ipynb", "examples/py_double_ml_pq.ipynb", "examples/py_double_ml_sensitivity.ipynb", "examples/py_double_ml_sensitivity_booking.ipynb", "examples/py_double_ml_ssm.ipynb", "guide/algorithms.rst", "guide/basics.rst", "guide/data_backend.rst", "guide/guide.rst", "guide/heterogeneity.rst", "guide/learners.rst", "guide/models.rst", "guide/resampling.rst", "guide/scores.rst", "guide/scores/apo_score.rst", "guide/scores/cvar_score.rst", "guide/scores/did_score.rst", "guide/scores/didcs_score.rst", "guide/scores/iivm_score.rst", "guide/scores/irm_score.rst", "guide/scores/lpq_score.rst", "guide/scores/mar_score.rst", "guide/scores/nr_score.rst", "guide/scores/pliv_score.rst", "guide/scores/plr_score.rst", "guide/scores/pq_score.rst", "guide/se_confint.rst", "guide/sensitivity.rst", "guide/sensitivity/apo_sensitivity.rst", "guide/sensitivity/benchmarking.rst", "guide/sensitivity/did_cs_sensitivity.rst", "guide/sensitivity/did_sensitivity.rst", "guide/sensitivity/implementation.rst", "guide/sensitivity/irm_sensitivity.rst", "guide/sensitivity/plr_sensitivity.rst", "guide/sensitivity/theory.rst", "guide/sim_inf.rst", "index.rst", "intro/install.rst", "intro/intro.rst", "literature/literature.rst", "release/release.rst", "workflow/workflow.rst"], "indexentries": {"bootstrap() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.bootstrap", false]], "bootstrap() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.bootstrap", false]], "bootstrap() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.bootstrap", false]], "bootstrap() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.bootstrap", false]], "bootstrap() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.bootstrap", false]], "bootstrap() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.bootstrap", false]], "bootstrap() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.bootstrap", false]], "bootstrap() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.bootstrap", false]], "bootstrap() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.bootstrap", false]], "bootstrap() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.bootstrap", false]], "bootstrap() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.bootstrap", false]], "bootstrap() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.bootstrap", false]], "bootstrap() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.bootstrap", false]], "capo() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.capo", false]], "cate() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.cate", false]], "cate() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.cate", false]], "causal_contrast() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.causal_contrast", false]], "confint() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.confint", false]], "confint() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.confint", false]], "confint() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.confint", false]], "confint() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.confint", false]], "confint() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.confint", false]], "confint() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.confint", false]], "confint() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.confint", false]], "confint() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.confint", false]], "confint() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.confint", false]], "confint() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.confint", false]], "confint() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.confint", false]], "confint() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.confint", false]], "confint() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.confint", false]], "confint() (doubleml.utils.doublemlblp method)": [[34, "doubleml.utils.DoubleMLBLP.confint", false]], "construct_framework() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.construct_framework", false]], "construct_framework() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.construct_framework", false]], "construct_framework() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.construct_framework", false]], "construct_framework() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.construct_framework", false]], "construct_framework() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.construct_framework", false]], "construct_framework() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.construct_framework", false]], "construct_framework() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.construct_framework", false]], "construct_framework() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.construct_framework", false]], "construct_framework() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.construct_framework", false]], "construct_framework() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.construct_framework", false]], "construct_framework() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.construct_framework", false]], "dmldummyclassifier (class in doubleml.utils)": [[32, "doubleml.utils.DMLDummyClassifier", false]], "dmldummyregressor (class in doubleml.utils)": [[33, "doubleml.utils.DMLDummyRegressor", false]], "doublemlapo (class in doubleml)": [[1, "doubleml.DoubleMLAPO", false]], "doublemlapos (class in doubleml)": [[2, "doubleml.DoubleMLAPOS", false]], "doublemlblp (class in doubleml.utils)": [[34, "doubleml.utils.DoubleMLBLP", false]], "doublemlclusterdata (class in doubleml)": [[4, "doubleml.DoubleMLClusterData", false]], "doublemlcvar (class in doubleml)": [[3, "doubleml.DoubleMLCVAR", false]], "doublemldata (class in doubleml)": [[7, "doubleml.DoubleMLData", false]], "doublemldid (class in doubleml)": [[5, "doubleml.DoubleMLDID", false]], "doublemldidcs (class in doubleml)": [[6, "doubleml.DoubleMLDIDCS", false]], "doublemliivm (class in doubleml)": [[8, "doubleml.DoubleMLIIVM", false]], "doublemlirm (class in doubleml)": [[9, "doubleml.DoubleMLIRM", false]], "doublemllpq (class in doubleml)": [[10, "doubleml.DoubleMLLPQ", false]], "doublemlpliv (class in doubleml)": [[11, "doubleml.DoubleMLPLIV", false]], "doublemlplr (class in doubleml)": [[12, "doubleml.DoubleMLPLR", false]], "doublemlpolicytree (class in doubleml.utils)": [[35, "doubleml.utils.DoubleMLPolicyTree", false]], "doublemlpq (class in doubleml)": [[13, "doubleml.DoubleMLPQ", false]], "doublemlqte (class in doubleml)": [[14, "doubleml.DoubleMLQTE", false]], "doublemlssm (class in doubleml)": [[15, "doubleml.DoubleMLSSM", false]], "draw_sample_splitting() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.draw_sample_splitting", false]], "evaluate_learners() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.evaluate_learners", false]], "fetch_401k() (in module doubleml.datasets)": [[16, "doubleml.datasets.fetch_401K", false]], "fetch_bonus() (in module doubleml.datasets)": [[17, "doubleml.datasets.fetch_bonus", false]], "fit() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.fit", false]], "fit() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.fit", false]], "fit() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.fit", false]], "fit() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.fit", false]], "fit() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.fit", false]], "fit() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.fit", false]], "fit() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.fit", false]], "fit() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.fit", false]], "fit() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.fit", false]], "fit() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.fit", false]], "fit() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.fit", false]], "fit() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.fit", false]], "fit() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.fit", false]], "fit() (doubleml.utils.dmldummyclassifier method)": [[32, "doubleml.utils.DMLDummyClassifier.fit", false]], "fit() (doubleml.utils.dmldummyregressor method)": [[33, "doubleml.utils.DMLDummyRegressor.fit", false]], "fit() (doubleml.utils.doublemlblp method)": [[34, "doubleml.utils.DoubleMLBLP.fit", false]], "fit() (doubleml.utils.doublemlpolicytree method)": [[35, "doubleml.utils.DoubleMLPolicyTree.fit", false]], "from_arrays() (doubleml.doublemlclusterdata class method)": [[4, "doubleml.DoubleMLClusterData.from_arrays", false]], "from_arrays() (doubleml.doublemldata class method)": [[7, "doubleml.DoubleMLData.from_arrays", false]], "gain_statistics() (in module doubleml.utils)": [[36, "doubleml.utils.gain_statistics", false]], "gapo() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.gapo", false]], "gate() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.gate", false]], "gate() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.gate", false]], "get_metadata_routing() (doubleml.utils.dmldummyclassifier method)": [[32, "doubleml.utils.DMLDummyClassifier.get_metadata_routing", false]], "get_metadata_routing() (doubleml.utils.dmldummyregressor method)": [[33, "doubleml.utils.DMLDummyRegressor.get_metadata_routing", false]], "get_params() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.get_params", false]], "get_params() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.get_params", false]], "get_params() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.get_params", false]], "get_params() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.get_params", false]], "get_params() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.get_params", false]], "get_params() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.get_params", false]], "get_params() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.get_params", false]], "get_params() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.get_params", false]], "get_params() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.get_params", false]], "get_params() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.get_params", false]], "get_params() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.get_params", false]], "get_params() (doubleml.utils.dmldummyclassifier method)": [[32, "doubleml.utils.DMLDummyClassifier.get_params", false]], "get_params() (doubleml.utils.dmldummyregressor method)": [[33, "doubleml.utils.DMLDummyRegressor.get_params", false]], "linearscoremixin (class in doubleml.double_ml_score_mixins)": [[30, "doubleml.double_ml_score_mixins.LinearScoreMixin", false]], "make_confounded_irm_data() (in module doubleml.datasets)": [[18, "doubleml.datasets.make_confounded_irm_data", false]], "make_confounded_plr_data() (in module doubleml.datasets)": [[19, "doubleml.datasets.make_confounded_plr_data", false]], "make_did_sz2020() (in module doubleml.datasets)": [[20, "doubleml.datasets.make_did_SZ2020", false]], "make_heterogeneous_data() (in module doubleml.datasets)": [[21, "doubleml.datasets.make_heterogeneous_data", false]], "make_iivm_data() (in module doubleml.datasets)": [[22, "doubleml.datasets.make_iivm_data", false]], "make_irm_data() (in module doubleml.datasets)": [[23, "doubleml.datasets.make_irm_data", false]], "make_irm_data_discrete_treatments() (in module doubleml.datasets)": [[24, "doubleml.datasets.make_irm_data_discrete_treatments", false]], "make_pliv_chs2015() (in module doubleml.datasets)": [[25, "doubleml.datasets.make_pliv_CHS2015", false]], "make_pliv_multiway_cluster_ckms2021() (in module doubleml.datasets)": [[26, "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", false]], "make_plr_ccddhnr2018() (in module doubleml.datasets)": [[27, "doubleml.datasets.make_plr_CCDDHNR2018", false]], "make_plr_turrell2018() (in module doubleml.datasets)": [[28, "doubleml.datasets.make_plr_turrell2018", false]], "make_ssm_data() (in module doubleml.datasets)": [[29, "doubleml.datasets.make_ssm_data", false]], "nonlinearscoremixin (class in doubleml.double_ml_score_mixins)": [[31, "doubleml.double_ml_score_mixins.NonLinearScoreMixin", false]], "p_adjust() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.p_adjust", false]], "p_adjust() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.p_adjust", false]], "p_adjust() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.p_adjust", false]], "p_adjust() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.p_adjust", false]], "p_adjust() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.p_adjust", false]], "p_adjust() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.p_adjust", false]], "p_adjust() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.p_adjust", false]], "p_adjust() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.p_adjust", false]], "p_adjust() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.p_adjust", false]], "p_adjust() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.p_adjust", false]], "p_adjust() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.p_adjust", false]], "p_adjust() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.p_adjust", false]], "plot_tree() (doubleml.utils.doublemlpolicytree method)": [[35, "doubleml.utils.DoubleMLPolicyTree.plot_tree", false]], "policy_tree() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.policy_tree", false]], "predict() (doubleml.utils.dmldummyclassifier method)": [[32, "doubleml.utils.DMLDummyClassifier.predict", false]], "predict() (doubleml.utils.dmldummyregressor method)": [[33, "doubleml.utils.DMLDummyRegressor.predict", false]], "predict() (doubleml.utils.doublemlpolicytree method)": [[35, "doubleml.utils.DoubleMLPolicyTree.predict", false]], "predict_proba() (doubleml.utils.dmldummyclassifier method)": [[32, "doubleml.utils.DMLDummyClassifier.predict_proba", false]], "sensitivity_analysis() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.sensitivity_analysis", false]], "sensitivity_benchmark() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.sensitivity_benchmark", false]], "sensitivity_plot() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.sensitivity_plot", false]], "set_ml_nuisance_params() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.set_ml_nuisance_params", false]], "set_params() (doubleml.utils.dmldummyclassifier method)": [[32, "doubleml.utils.DMLDummyClassifier.set_params", false]], "set_params() (doubleml.utils.dmldummyregressor method)": [[33, "doubleml.utils.DMLDummyRegressor.set_params", false]], "set_sample_splitting() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.set_sample_splitting", false]], "set_x_d() (doubleml.doublemlclusterdata method)": [[4, "doubleml.DoubleMLClusterData.set_x_d", false]], "set_x_d() (doubleml.doublemldata method)": [[7, "doubleml.DoubleMLData.set_x_d", false]], "tune() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.tune", false]], "tune() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.tune", false]], "tune() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.tune", false]], "tune() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.tune", false]], "tune() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.tune", false]], "tune() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.tune", false]], "tune() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.tune", false]], "tune() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.tune", false]], "tune() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.tune", false]], "tune() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.tune", false]], "tune() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.tune", false]]}, "objects": {"doubleml": [[1, 0, 1, "", "DoubleMLAPO"], [2, 0, 1, "", "DoubleMLAPOS"], [3, 0, 1, "", "DoubleMLCVAR"], [4, 0, 1, "", "DoubleMLClusterData"], [5, 0, 1, "", "DoubleMLDID"], [6, 0, 1, "", "DoubleMLDIDCS"], [7, 0, 1, "", "DoubleMLData"], [8, 0, 1, "", "DoubleMLIIVM"], [9, 0, 1, "", "DoubleMLIRM"], [10, 0, 1, "", "DoubleMLLPQ"], [11, 0, 1, "", "DoubleMLPLIV"], [12, 0, 1, "", "DoubleMLPLR"], [13, 0, 1, "", "DoubleMLPQ"], [14, 0, 1, "", "DoubleMLQTE"], [15, 0, 1, "", "DoubleMLSSM"]], "doubleml.DoubleMLAPO": [[1, 1, 1, "", "bootstrap"], [1, 1, 1, "", "capo"], [1, 1, 1, "", "confint"], [1, 1, 1, "", "construct_framework"], [1, 1, 1, "", "draw_sample_splitting"], [1, 1, 1, "", "evaluate_learners"], [1, 1, 1, "", "fit"], [1, 1, 1, "", "gapo"], [1, 1, 1, "", "get_params"], [1, 1, 1, "", "p_adjust"], [1, 1, 1, "", "sensitivity_analysis"], [1, 1, 1, "", "sensitivity_benchmark"], [1, 1, 1, "", "sensitivity_plot"], [1, 1, 1, "", "set_ml_nuisance_params"], [1, 1, 1, "", "set_sample_splitting"], [1, 1, 1, "", "tune"]], "doubleml.DoubleMLAPOS": [[2, 1, 1, "", "bootstrap"], [2, 1, 1, "", "causal_contrast"], [2, 1, 1, "", "confint"], [2, 1, 1, "", "draw_sample_splitting"], [2, 1, 1, "", "fit"], [2, 1, 1, "", "sensitivity_analysis"], [2, 1, 1, "", "sensitivity_benchmark"], [2, 1, 1, "", "sensitivity_plot"], [2, 1, 1, "", "set_sample_splitting"]], "doubleml.DoubleMLCVAR": [[3, 1, 1, "", "bootstrap"], [3, 1, 1, "", "confint"], [3, 1, 1, "", "construct_framework"], [3, 1, 1, "", "draw_sample_splitting"], [3, 1, 1, "", "evaluate_learners"], [3, 1, 1, "", "fit"], [3, 1, 1, "", "get_params"], [3, 1, 1, "", "p_adjust"], [3, 1, 1, "", "sensitivity_analysis"], [3, 1, 1, "", "sensitivity_benchmark"], [3, 1, 1, "", "sensitivity_plot"], [3, 1, 1, "", "set_ml_nuisance_params"], [3, 1, 1, "", "set_sample_splitting"], [3, 1, 1, "", "tune"]], "doubleml.DoubleMLClusterData": [[4, 1, 1, "", "from_arrays"], [4, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLDID": [[5, 1, 1, "", "bootstrap"], [5, 1, 1, "", "confint"], [5, 1, 1, "", "construct_framework"], [5, 1, 1, "", "draw_sample_splitting"], [5, 1, 1, "", "evaluate_learners"], [5, 1, 1, "", "fit"], [5, 1, 1, "", "get_params"], [5, 1, 1, "", "p_adjust"], [5, 1, 1, "", "sensitivity_analysis"], [5, 1, 1, "", "sensitivity_benchmark"], [5, 1, 1, "", "sensitivity_plot"], [5, 1, 1, "", "set_ml_nuisance_params"], [5, 1, 1, "", "set_sample_splitting"], [5, 1, 1, "", "tune"]], "doubleml.DoubleMLDIDCS": [[6, 1, 1, "", "bootstrap"], [6, 1, 1, "", "confint"], [6, 1, 1, "", "construct_framework"], [6, 1, 1, "", "draw_sample_splitting"], [6, 1, 1, "", "evaluate_learners"], [6, 1, 1, "", "fit"], [6, 1, 1, "", "get_params"], [6, 1, 1, "", "p_adjust"], [6, 1, 1, "", "sensitivity_analysis"], [6, 1, 1, "", "sensitivity_benchmark"], [6, 1, 1, "", "sensitivity_plot"], [6, 1, 1, "", "set_ml_nuisance_params"], [6, 1, 1, "", "set_sample_splitting"], [6, 1, 1, "", "tune"]], "doubleml.DoubleMLData": [[7, 1, 1, "", "from_arrays"], [7, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLIIVM": [[8, 1, 1, "", "bootstrap"], [8, 1, 1, "", "confint"], [8, 1, 1, "", "construct_framework"], [8, 1, 1, "", "draw_sample_splitting"], [8, 1, 1, "", "evaluate_learners"], [8, 1, 1, "", "fit"], [8, 1, 1, "", "get_params"], [8, 1, 1, "", "p_adjust"], [8, 1, 1, "", "sensitivity_analysis"], [8, 1, 1, "", "sensitivity_benchmark"], [8, 1, 1, "", "sensitivity_plot"], [8, 1, 1, "", "set_ml_nuisance_params"], [8, 1, 1, "", "set_sample_splitting"], [8, 1, 1, "", "tune"]], "doubleml.DoubleMLIRM": [[9, 1, 1, "", "bootstrap"], [9, 1, 1, "", "cate"], [9, 1, 1, "", "confint"], [9, 1, 1, "", "construct_framework"], [9, 1, 1, "", "draw_sample_splitting"], [9, 1, 1, "", "evaluate_learners"], [9, 1, 1, "", "fit"], [9, 1, 1, "", "gate"], [9, 1, 1, "", "get_params"], [9, 1, 1, "", "p_adjust"], [9, 1, 1, "", "policy_tree"], [9, 1, 1, "", "sensitivity_analysis"], [9, 1, 1, "", "sensitivity_benchmark"], [9, 1, 1, "", "sensitivity_plot"], [9, 1, 1, "", "set_ml_nuisance_params"], [9, 1, 1, "", "set_sample_splitting"], [9, 1, 1, "", "tune"]], "doubleml.DoubleMLLPQ": [[10, 1, 1, "", "bootstrap"], [10, 1, 1, "", "confint"], [10, 1, 1, "", "construct_framework"], [10, 1, 1, "", "draw_sample_splitting"], [10, 1, 1, "", "evaluate_learners"], [10, 1, 1, "", "fit"], [10, 1, 1, "", "get_params"], [10, 1, 1, "", "p_adjust"], [10, 1, 1, "", "sensitivity_analysis"], [10, 1, 1, "", "sensitivity_benchmark"], [10, 1, 1, "", "sensitivity_plot"], [10, 1, 1, "", "set_ml_nuisance_params"], [10, 1, 1, "", "set_sample_splitting"], [10, 1, 1, "", "tune"]], "doubleml.DoubleMLPLIV": [[11, 1, 1, "", "bootstrap"], [11, 1, 1, "", "confint"], [11, 1, 1, "", "construct_framework"], [11, 1, 1, "", "draw_sample_splitting"], [11, 1, 1, "", "evaluate_learners"], [11, 1, 1, "", "fit"], [11, 1, 1, "", "get_params"], [11, 1, 1, "", "p_adjust"], [11, 1, 1, "", "sensitivity_analysis"], [11, 1, 1, "", "sensitivity_benchmark"], [11, 1, 1, "", "sensitivity_plot"], [11, 1, 1, "", "set_ml_nuisance_params"], [11, 1, 1, "", "set_sample_splitting"], [11, 1, 1, "", "tune"]], "doubleml.DoubleMLPLR": [[12, 1, 1, "", "bootstrap"], [12, 1, 1, "", "cate"], [12, 1, 1, "", "confint"], [12, 1, 1, "", "construct_framework"], [12, 1, 1, "", "draw_sample_splitting"], [12, 1, 1, "", "evaluate_learners"], [12, 1, 1, "", "fit"], [12, 1, 1, "", "gate"], [12, 1, 1, "", "get_params"], [12, 1, 1, "", "p_adjust"], [12, 1, 1, "", "sensitivity_analysis"], [12, 1, 1, "", "sensitivity_benchmark"], [12, 1, 1, "", "sensitivity_plot"], [12, 1, 1, "", "set_ml_nuisance_params"], [12, 1, 1, "", "set_sample_splitting"], [12, 1, 1, "", "tune"]], "doubleml.DoubleMLPQ": [[13, 1, 1, "", "bootstrap"], [13, 1, 1, "", "confint"], [13, 1, 1, "", "construct_framework"], [13, 1, 1, "", "draw_sample_splitting"], [13, 1, 1, "", "evaluate_learners"], [13, 1, 1, "", "fit"], [13, 1, 1, "", "get_params"], [13, 1, 1, "", "p_adjust"], [13, 1, 1, "", "sensitivity_analysis"], [13, 1, 1, "", "sensitivity_benchmark"], [13, 1, 1, "", "sensitivity_plot"], [13, 1, 1, "", "set_ml_nuisance_params"], [13, 1, 1, "", "set_sample_splitting"], [13, 1, 1, "", "tune"]], "doubleml.DoubleMLQTE": [[14, 1, 1, "", "bootstrap"], [14, 1, 1, "", "confint"], [14, 1, 1, "", "draw_sample_splitting"], [14, 1, 1, "", "fit"], [14, 1, 1, "", "p_adjust"], [14, 1, 1, "", "set_sample_splitting"]], "doubleml.DoubleMLSSM": [[15, 1, 1, "", "bootstrap"], [15, 1, 1, "", "confint"], [15, 1, 1, "", "construct_framework"], [15, 1, 1, "", "draw_sample_splitting"], [15, 1, 1, "", "evaluate_learners"], [15, 1, 1, "", "fit"], [15, 1, 1, "", "get_params"], [15, 1, 1, "", "p_adjust"], [15, 1, 1, "", "sensitivity_analysis"], [15, 1, 1, "", "sensitivity_benchmark"], [15, 1, 1, "", "sensitivity_plot"], [15, 1, 1, "", "set_ml_nuisance_params"], [15, 1, 1, "", "set_sample_splitting"], [15, 1, 1, "", "tune"]], "doubleml.datasets": [[16, 2, 1, "", "fetch_401K"], [17, 2, 1, "", "fetch_bonus"], [18, 2, 1, "", "make_confounded_irm_data"], [19, 2, 1, "", "make_confounded_plr_data"], [20, 2, 1, "", "make_did_SZ2020"], [21, 2, 1, "", "make_heterogeneous_data"], [22, 2, 1, "", "make_iivm_data"], [23, 2, 1, "", "make_irm_data"], [24, 2, 1, "", "make_irm_data_discrete_treatments"], [25, 2, 1, "", "make_pliv_CHS2015"], [26, 2, 1, "", "make_pliv_multiway_cluster_CKMS2021"], [27, 2, 1, "", "make_plr_CCDDHNR2018"], [28, 2, 1, "", "make_plr_turrell2018"], [29, 2, 1, "", "make_ssm_data"]], "doubleml.double_ml_score_mixins": [[30, 0, 1, "", "LinearScoreMixin"], [31, 0, 1, "", "NonLinearScoreMixin"]], "doubleml.utils": [[32, 0, 1, "", "DMLDummyClassifier"], [33, 0, 1, "", "DMLDummyRegressor"], [34, 0, 1, "", "DoubleMLBLP"], [35, 0, 1, "", "DoubleMLPolicyTree"], [36, 2, 1, "", "gain_statistics"]], "doubleml.utils.DMLDummyClassifier": [[32, 1, 1, "", "fit"], [32, 1, 1, "", "get_metadata_routing"], [32, 1, 1, "", "get_params"], [32, 1, 1, "", "predict"], [32, 1, 1, "", "predict_proba"], [32, 1, 1, "", "set_params"]], "doubleml.utils.DMLDummyRegressor": [[33, 1, 1, "", "fit"], [33, 1, 1, "", "get_metadata_routing"], [33, 1, 1, "", "get_params"], [33, 1, 1, "", "predict"], [33, 1, 1, "", "set_params"]], "doubleml.utils.DoubleMLBLP": [[34, 1, 1, "", "confint"], [34, 1, 1, "", "fit"]], "doubleml.utils.DoubleMLPolicyTree": [[35, 1, 1, "", "fit"], [35, 1, 1, "", "plot_tree"], [35, 1, 1, "", "predict"]]}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function"}, "terms": {"": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 22, 23, 25, 26, 27, 28, 29, 34, 37, 39, 40, 41, 42, 43, 45, 51, 54, 55, 56, 59, 60, 61, 65, 66, 67, 68, 70, 73, 74, 76, 84, 85, 89, 90, 92, 99, 100, 102, 103, 104, 105], "0": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 90, 92, 93, 94, 95, 96, 99, 101, 102, 104], "00": [55, 60, 61, 75], "000": [89, 99, 105], "000000": [43, 45, 60, 61, 70, 72, 102], "0000000": [89, 99], "0000000000000010000100": [42, 70, 102], "000000e": [55, 60, 61], "00000591": 64, "000006": [45, 64], "000017": 64, "000025": 59, "000034": 60, "000039": 59, "000064": 46, "000067": 59, "000091": [59, 72], "0001": [43, 60], "000135": 74, "000219": [13, 72], "000242": [14, 72], "000259": 75, "000341": 59, "000442": 59, "00047580260495": 37, "000488": 59, "000494": 56, "0005": 43, "000522": 59, "0005a80b528f": 42, "0006321326": 75, "000670": 59, "000743": 65, "000915799": [89, 99], "0009157990": [89, 99], "000943": [48, 49], "0009478777": 75, "001": [37, 39, 40, 41, 42, 47, 73, 74, 75, 76, 89, 102, 105], "001051": 59, "001234": 61, "00133": 42, "00138944": [68, 76], "001494": 74, "0016": [41, 60], "001714": 72, "0018": [41, 60], "0019": 43, "002169338": [89, 99], "0021693380": [89, 99], "0021693381": [89, 99], "002277": 48, "002290": 52, "0023": 39, "002388": 58, "002436": 56, "002539": 74, "0026": 43, "002779": 65, "0028": [39, 41, 60], "002821": 66, "0028213335041910427": 66, "002983": 59, "003": [18, 19, 20], "003111": 45, "003134": 64, "003187": 48, "003220": 45, "003328": 64, "0034": 53, "003404": 45, "003415": 45, "003427": 59, "003536905": 75, "003607": 49, "003779": 56, "0037998": 75, "003836": 64, "003924": 56, "003944": 48, "003975": 48, "004": 62, "00409412": [68, 76], "0042": [41, 60], "004253": 45, "004392": 56, "004526": 45, "004688": 8, "0047": [41, 60], "004747573": 75, "004846": 66, "005213774": 75, "005339": [48, 49], "005857": 59, "006": 62, "006055": 45, "006267": 49, "0064036": 75, "006425": 61, "0068101213851626": 58, "006922": 43, "006958": [48, 49], "007210e": 61, "00728": 102, "0073": 43, "007332": 50, "007332393760465": 50, "007659": 72, "007741706": 75, "00778625": 75, "0078540263583833": 58, "008": 66, "008023": 61, "008223": [48, 49], "008266e": 61, "008487": 43, "0084871742256079": 58, "008642": 72, "008883698": 76, "00888458890362062": 68, "008884589": 68, "008dbd": 62, "008e80": 62, "009": [62, 66], "009122": 64, "009255": 48, "009329847": 76, "009341": 62, "009428": 50, "00944171905420782": 66, "00950122695463054": 68, "009501226954630540": 68, "009501227": 68, "009645422": 40, "009656": 64, "009678": 62, "00972": 43, "009790": 61, "009904": 72, "009986": 64, "01": [1, 2, 3, 5, 6, 8, 9, 10, 13, 14, 15, 35, 37, 40, 41, 42, 48, 49, 60, 61, 62, 63, 64, 73, 74, 75, 76, 89, 102, 105], "010213": 65, "010224": 62, "010269": 59, "010450": 40, "010940": 59, "011": 62, "011131": 64, "0112": 39, "01128": 43, "011310": 62, "011431": 62, "011598": 64, "0118095": 40, "011823": 65, "011988e": 64, "012012": 62, "01219": 42, "0124599701": 75, "01274": 66, "012780": 61, "012831": 66, "013034": 66, "013089": 62, "013128": 48, "013313": 58, "01351638": 40, "013593": 65, "013617": 61, "013712": 48, "01398951": 40, "013990": [89, 99], "014": 75, "01403089": 40, "014080": [48, 49], "014432": 52, "014637": 59, "014681": 65, "014873e": 48, "015": [42, 62], "015038": 50, "015552": 48, "015565": 64, "0156853566737638": 58, "015698": 64, "01574297": 64, "015743": 64, "015831": 48, "016011": 49, "016154": 59, "016200": [48, 49], "016315": 54, "016429": 72, "01643": 103, "017": 42, "017140": 48, "017393e": 89, "01772": 92, "017777e": 49, "017800092": [89, 99], "0178000920": [89, 99], "018": 42, "018023": 63, "018148": 64, "018508": 48, "018602": 74, "01903": [42, 73, 100, 102], "01916030e": 75, "01925597": 40, "019439633": [89, 99], "0194396330": [89, 99], "0194396331": [89, 99], "019596": 50, "019660": [14, 72], "01990373": 67, "019974": 61, "02": [48, 49, 60, 61, 64, 72, 75], "02016117": 102, "020166": 64, "020271": 59, "020360838": [89, 99], "0203608380": [89, 99], "0203608381": [89, 99], "02052929": [68, 76], "02079162e": 75, "020819": 72, "02092": 102, "021269": [54, 55], "02163217": 40, "021690": 55, "021823": 58, "021866": 63, "021926": 50, "022": 37, "022181": 48, "022295e": 48, "02247976": 40, "022768": 43, "022783": 65, "022915": 59, "022954": 72, "022969": 61, "023020e": [60, 61], "023052": 49, "023256": 64, "023537": 58, "023563": [89, 99], "023955": 61, "024346": 48, "024355": 52, "024364": 90, "024401": [54, 55], "024604": 59, "024742574": 75, "024782": 64, "024926": 52, "025": [48, 49, 54, 55, 62], "025077": [49, 89, 99], "02528067": 57, "0253": 42, "025300e": 49, "025443": 43, "025496": 48, "0257": 39, "025813114": [89, 99], "0258131140": [89, 99], "02584": 42, "025958": 72, "026669": 61, "026723": 50, "026822": 58, "027": 37, "02791": 43, "0281": 42, "02831464": 75, "028520": [48, 49], "02897287": 51, "02900983": 64, "029010": 64, "029022": 49, "029209": 105, "029364": [90, 95], "029831": 64, "029910e": [60, 61], "02e": 41, "03": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 48, 49, 50, 56, 60, 61, 64, 65, 66, 75, 90, 95, 105], "030087": 72, "0301": 42, "03018": [10, 72], "03028439": 75, "030346": 102, "0307": 42, "030934": 64, "030962": 64, "031007": 58, "03113": 67, "031134": 73, "031156": 49, "031269": 43, "031639": 64, "031820": 49, "03191": 103, "03220": 104, "0323": 39, "032401": 62, "03244552": 73, "0325": 102, "03258": 58, "032580": 58, "032738": 58, "032941": 48, "032953": 65, "033265": 58, "03330886": 75, "033756": 50, "033946": [54, 55], "034065": 49, "03411": 102, "034226": 61, "034690": 50, "034812763": [89, 99], "0348127630": [89, 99], "0348127631": [89, 99], "034836": 60, "03489": [26, 40, 59], "035119185": [89, 99], "0351191850": [89, 99], "0351191851": [89, 99], "035264": 49, "03536": 102, "03538": 42, "03539": 42, "035391": 43, "0354": 42, "035411": 102, "035441": 49, "03545": 42, "035545": 43, "035572": 43, "035730": 64, "03574": 43, "035762": 64, "035785": 49, "0359": 42, "036129015": [89, 99], "0361290150": [89, 99], "0361290151": [89, 99], "036143": 64, "036147": 64, "036240": 45, "036729": 59, "0368": 39, "036945": 61, "03698487": 64, "036985": 64, "037008": [54, 55], "0374": 42, "037504": 49, "037509": 67, "037747": [48, 49], "03809844": 75, "038845": 48, "039036": 48, "0391009": 75, "039141": 45, "03917696": [76, 89], "03920960e": 75, "039310e": 50, "039991e": 48, "04": [19, 41, 45, 48, 49, 60, 61, 64, 65, 75, 105], "040079": 49, "040112": [89, 99], "040139": [48, 49], "040533": [76, 89], "04053339": 89, "040562": 48, "040688": 48, "0408": 48, "040881": 62, "040912": 49, "040919": 49, "04107": 12, "041147": 50, "041284": 50, "041387": 50, "041459": 61, "041491e": 50, "04165": 74, "0418": 39, "041831": 50, "041925": 48, "042034": 66, "042249": 49, "042265": 50, "0425": 73, "0428": 67, "042822e": 61, "042844e": 64, "04292482": 75, "043108": 61, "0433": 39, "0434e374": 42, "04387": 73, "043998": 49, "044": 62, "044113": 50, "04415": 42, "04424": 42, "0443862": 75, "04444978": [89, 99], "044449780": [89, 99], "0445": 73, "04465": 40, "044704": 49, "04486": 102, "04487585": [90, 95], "04491": 74, "04497975": [90, 95], "04501612": 89, "04502": [73, 76, 89], "045144": 59, "045313": 48, "045379": 102, "04552": 59, "045553": 50, "045624": 52, "04563": 73, "045638": 48, "045754": 64, "04586": 73, "045932": 64, "045993": 73, "046": 62, "04625": 73, "046405": 72, "046527": 50, "04653976": 64, "046540": 64, "046587": 49, "0466028": 40, "046728": 65, "04682310e": 75, "046922": 73, "047194": 8, "047652e": 49, "047724": 48, "047954": 59, "048220": 58, "048308": 55, "048699": 67, "048723": 73, "048853": 49, "049264": 45, "04973": 49, "05": [37, 39, 40, 41, 42, 48, 49, 50, 53, 57, 59, 60, 61, 62, 64, 66, 73, 74, 75, 76, 89, 102, 105], "05039": 65, "050494e": 49, "050538": 49, "05073729": 75, "050856": [72, 73], "051": 42, "051867e": 50, "052": 37, "052000e": 61, "052073": 62, "052135608": 75, "052298": 64, "052380": 48, "052488": 55, "052502": 64, "052745": 50, "053": 42, "053049": 49, "0533": 39, "053331": 50, "053342": 61, "053389": [89, 99], "053436": 9, "053541": 64, "053558": 50, "053849e": 48, "054": 42, "054068": 59, "054162": 59, "054348": 89, "054370": 50, "054529": [89, 99], "054771e": 64, "055165": 65, "055171": 49, "055338e": 60, "055439": [58, 61], "055493": 66, "055680": [89, 99], "05607009": 75, "056499": 55, "056745": 48, "056764": 48, "057095": 64, "057274": 45, "0576": [41, 60], "057762": 64, "057792": 48, "057962": 50, "058": 62, "058042": [89, 99], "058276": 61, "058375": 45, "058463": 64, "058508": 67, "058595": 48, "0590": 39, "059128": 48, "059384": 64, "059627": 61, "059630": 52, "059685": 64, "06": [18, 19, 20, 45, 48, 49, 50, 60, 61, 64, 72, 73, 75], "06008533": 74, "060201": 64, "060212": [60, 61], "060417": 48, "060581": 57, "060845": [89, 99], "060933": 48, "061": 62, "0611": 39, "06111111": 42, "06149508": 75, "0615": 39, "062414": 61, "062507": 64, "0628": 39, "062964": [89, 99], "062988": 48, "063017": 45, "0632": 39, "063234e": 49, "0635": 39, "063593": 49, "0636": 39, "063685": 45, "063700": 48, "0638": 39, "063881": 74, "0640": 39, "064161": 61, "064175": 45, "064213": 49, "06428": 60, "064280": 60, "0645": 39, "0646222": 41, "0647": 39, "0649": 39, "065": 66, "0653": 39, "065356": [54, 55], "065368": 58, "0654": 39, "065451": 61, "0655": 39, "065725": 50, "0659": 39, "065969": 74, "0662": 39, "066464": 65, "066889": 64, "0669": 39, "06692492": 75, "06694255": 74, "067046e": 48, "0671": 39, "067240": 64, "06724028": 64, "0673": 39, "0675": 39, "067528": 66, "067721": [89, 99], "068073": 49, "06827": 65, "06834315": 51, "068377": 61, "068514": 48, "068934": 45, "06895837": 40, "069443": 45, "0695854": 40, "069600": 61, "069882e": 48, "07": [48, 49, 61, 64, 66, 75], "070020": 64, "070196": 50, "0701961897676835": 50, "0702127": 40, "0704": 39, "070497": 66, "070534": 15, "070552": 48, "070574e": 61, "0707": 39, "070751": 48, "07085301": 74, "070884": 64, "0711": 39, "071285": 89, "07136": [40, 59], "071362": 48, "071488e": 50, "0716": 39, "07168291": 40, "071777": 73, "071782": [14, 72], "0719": 39, "072": 62, "07202564": [54, 55], "07222222": 42, "072293": 63, "0727": 74, "073013": 64, "073207": 59, "073275": 48, "07333105": 75, "07347676": 40, "07350015": [26, 29, 40, 59], "073520": 50, "0736": 39, "07366": [42, 73], "073694": 49, "0739130271918385": 58, "073929": 58, "0743": 39, "074304": 89, "07436521": 75, "074426": 64, "07456127": 40, "074617": 49, "07479278": 65, "074927": 45, "074935": 62, "075261": 52, "075384": 64, "07538443": 64, "07544271e": 75, "07561": 102, "07564554e": 75, "0758": 66, "075809": 45, "075869": 73, "075942": 58, "076": 37, "076019": 60, "076156": 89, "076179312": [89, 99], "0761793120": [89, 99], "076322": 64, "076347": 50, "0765": 42, "076559": [72, 73], "076596": 48, "076684": 102, "07685043": 75, "07689": 42, "07691847": 75, "076953": [54, 55], "076971": 43, "077144e": 49, "077161": 61, "07727773e": 75, "077319": 64, "077502": [90, 95], "077555": 48, "077702": 45, "0777777777777778": 73, "07777778": [42, 73], "077840": 61, "077883": 64, "077923e": 48, "07796": 74, "078017": 48, "078096": 89, "078207": 43, "07828372": [89, 99], "078474": [89, 99], "078709": 49, "078810": 64, "079085": 43, "07915": 42, "07919896": 75, "079458e": 60, "07949822": 75, "079500e": 48, "07961": 65, "07978296": 75, "08": [50, 61, 64, 66, 74], "080": 62, "08005229": 75, "08031571": 75, "080854": 61, "08091581": 75, "080947": 43, "081": 42, "081100": 64, "081230": [48, 49], "081396": 55, "081488": 59, "08154161": 75, "08181827e": 75, "08191204": 74, "0820": 39, "082263": 11, "082297": 75, "082400e": 48, "082574": 9, "082804": 52, "082858": 49, "082934": 61, "082973": 59, "083258": [89, 99], "083318": 89, "08333333": 42, "08333617": 75, "0835771416": 40, "083706": 66, "083750": 61, "083949": 66, "084": 40, "08410373": 75, "084156": 49, "084184": 50, "0841842065698133": 50, "084212": 56, "08424614": 75, "084269": 61, "084323": 48, "084337": 74, "084633": 54, "08473315": 75, "0853505": 40, "08537576": 75, "085395": 48, "085566": 50, "085671": 48, "085965": 61, "08602774e": 75, "0862": 100, "086264": 50, "08635891": 75, "08664208": 75, "086679": 73, "086889": 54, "08713079": 75, "0872": 39, "0872162": 75, "087222": 49, "087561": 48, "087634": 48, "087745": 49, "087947": 64, "088048": 64, "0881676": 75, "088282": 55, "088357": 64, "08848": 73, "088482": [14, 72], "08848262": 75, "088504e": 11, "08855": 75, "08857": 75, "08888889": 42, "0894": 39, "08968939": 40, "089964": 58, "08e": 41, "09": [48, 49, 50, 60, 61, 64, 72], "09000000000000001": 73, "090025": 61, "09015": 39, "090255": 64, "090436": 49, "091179e": 48, "091263": 58, "09131798": 75, "091391": [89, 99], "091406": 90, "091535": 48, "0916": 39, "091824": 49, "091992": 63, "092229": 66, "092247": 64, "092263": 74, "092365": [89, 99], "092919": 92, "092935": 48, "093043": 64, "09310496": [89, 99], "093153": 64, "093474": 64, "09347419": 64, "093746": 89, "093950": 59, "094026": 59, "094118": 64, "094378e": 48, "094381": 59, "09444444": 42, "094581e": 49, "094829": 74, "094999": 64, "095104": 45, "095475": 72, "095654": 48, "095781": 3, "095785": 45, "09603": 100, "096245": 72, "096337": 59, "096418": 45, "096550": 54, "096616": 72, "096688": 49, "096741": 51, "09682314": 74, "096915": 66, "097157": 66, "097468": 50, "09779675": [89, 99], "097796750": [89, 99], "098": 41, "098256": 64, "09830758": 65, "098308": 65, "098317": 61, "098319": 64, "09847374": 75, "0986": 39, "09869747": 75, "098712": 64, "09879814e": 75, "099001": 49, "099307": 49, "099647": 63, "099670": 61, "099731": [48, 49], "09980311": [89, 99], "09988": 103, "0_": 25, "0ff823b17d45": 42, "0x1747bdd4520": 43, "0x1747bdd6b90": 43, "0x2920d7b7150": 63, "0x7f20cb8c9640": 105, "0x7f20cbb76c30": 89, "0x7f20cbc037d0": 89, "0x7f20cbc2f020": 90, "0x7f20cbce5a30": 89, "0x7f20cbce5c40": 89, "0x7f20cbe8f950": 74, "0x7f20cbff07a0": 73, "0x7f20cbff3d70": 73, "0x7f20d91e5670": 95, "0x7f20d999dfd0": 74, "0x7f20d9c81730": 73, "0x7f7f992bd970": 66, "1": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104], "10": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 26, 27, 29, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 100, 102, 103, 105], "100": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 26, 28, 29, 40, 42, 48, 49, 51, 53, 56, 57, 59, 62, 66, 67, 68, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 102, 104], "1000": [8, 10, 38, 46, 47, 51, 52, 54, 55, 56, 57, 58, 60, 61, 65, 66, 69, 72, 74], "10000": [37, 48, 49, 52, 60, 61, 64], "100000e": 61, "100044": 55, "100154": 58, "100356": 50, "10038": 65, "100385": 58, "10039862": [67, 74], "100517": 89, "100715": 48, "10079785": 74, "100807": [48, 49], "100858": 65, "10089588": 64, "100896": 64, "10092": 61, "100923": 64, "100_000": 62, "101": [18, 19, 20, 39, 72, 74, 103, 104], "10126": 61, "10127930": [89, 99], "101279300": [89, 99], "1015": [41, 60], "1016": [18, 19, 20, 39], "1016010": 41, "1018": 61, "102": [70, 72, 74, 102, 104], "10235": 61, "10258": 61, "102616": 50, "102775": 50, "10299": 60, "103": [48, 59, 67, 72, 74, 104], "10307": 89, "1031": 61, "103189": 61, "10348": 60, "103497": 64, "1038": 61, "103806": 50, "103951906910721": 50, "103952": 50, "10396": 60, "104": [41, 60, 67, 72, 74, 104], "10406": 61, "104087": 48, "1041": 39, "10414": 61, "1045303": 40, "104787": 59, "104849": 48, "105": [25, 40, 59, 72, 74, 104], "1050": 66, "105318": 64, "1054": 42, "1055": 39, "106": [42, 72, 74, 104], "10607": [43, 70, 102], "10618": 61, "10637173e": 75, "106391": 89, "106595": 74, "106691": 72, "106746": 64, "107": [42, 62, 66, 72, 74, 104], "107073": 50, "10713484": 75, "107295": 89, "1073": 61, "107413": 48, "10747": [43, 70, 102], "107872": 72, "10799": 61, "108": [72, 74, 100, 103, 104], "1080": [26, 29, 39, 40, 59], "10824": [43, 70, 102], "108257e": 61, "108259": 45, "10831": [43, 70, 102], "10878571": 64, "108786": 64, "109": [48, 72, 74, 75], "109005": 64, "10903": 60, "109069": [89, 99], "109079e": 64, "109273": 59, "10928": 61, "1093": 53, "109454": 61, "109470": 49, "1096": 39, "10967": 60, "109811": 56, "109861": 102, "1099472942084532": 46, "10e": [50, 64], "11": [12, 37, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 68, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 102, 105], "110": [72, 74, 104], "1101": 61, "11019365749799062": 66, "110194": 66, "110359": 59, "110365": 66, "110681": 65, "1107": 61, "11071087": [67, 74], "110717": [89, 99], "1109": 61, "110902": 50, "110902411746278": 50, "111": [49, 72, 74, 104], "1111": [16, 17, 27, 38, 40, 47, 53, 59, 66, 69, 74, 90, 95, 100], "111164": 63, "11120": 61, "1118": 41, "11199615e": 75, "112": [42, 72, 74, 104], "1120": 60, "11208236": [68, 76], "1122": 61, "112216": 50, "1129": 61, "113": [16, 72, 74, 104], "113207": 64, "113270": 50, "113415": 61, "11375": 61, "113780": 59, "114": [72, 74, 104], "11409": 60, "11414": 60, "1144500": 40, "11447": 65, "114530": 54, "1145370": 40, "114570": 49, "11458": 61, "114647": 50, "1147": 39, "1148": 61, "114834": 61, "11488": 61, "11495": 61, "115": [72, 74, 104], "11500": [60, 105], "115060e": 64, "1151610541568202": 58, "115296e": 61, "115297e": 60, "1155142425200442": 58, "11552911": 65, "11559": 61, "115636": 49, "11570": 60, "115792e": 61, "115972": 48, "116": [72, 74, 104], "116027": 50, "11617": 61, "11617290": 75, "116274": 50, "116569": 61, "1166": 103, "1167": 60, "11673": 61, "11675": 61, "117": [48, 72, 74], "1170": 65, "11700": 105, "117072": 54, "117112": 49, "117242": 64, "11724226": 64, "117366": 64, "11743": 105, "11750": 61, "1176": 39, "1177": [39, 60], "11770674": 75, "117710": 50, "11792": 41, "11796": 61, "118": [72, 74], "11802": 61, "1182": 41, "11823404": 66, "118255": 64, "1186": 41, "118601": 59, "11861": 41, "1187339840850312": 59, "11879": 61, "118799": 61, "118938e": 74, "118952": 59, "119": [66, 72, 74, 104], "11932": 61, "11935": 65, "119669": 74, "119766": 64, "1198": [40, 59], "12": [15, 37, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 68, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 100, 102, 103, 104, 105], "120": [51, 58, 67, 72, 74, 104], "12002": 60, "1202": 103, "12023345": 75, "120468": 64, "12046836": 64, "120567": [54, 55], "120721": 59, "12097": [16, 17, 27, 40, 53, 59, 69, 100], "121": [61, 72, 74, 104], "1210": 61, "12101": 61, "12105472": [89, 99], "121054720": [89, 99], "1211": 61, "1213405": 40, "121399": 61, "1214": [89, 99], "121584e": 64, "121711": 61, "121774": 56, "121824": 49, "12196389e": 75, "122": [18, 19, 20, 39, 70, 72, 74, 103, 104], "12214": 41, "12223182e": 75, "1222954": 75, "122408": 50, "122777": 89, "1228390": 75, "123": [41, 42, 60, 66, 72, 74, 104, 105], "1230": 61, "123192": 66, "12323": 61, "1234": [37, 38, 39, 43, 46, 47, 69, 73, 75, 89, 99], "12348": 66, "1238": 61, "123917": 61, "124": [72, 74], "12410": 61, "124306": 58, "124480": 58, "124805": 60, "124825": 49, "125": [72, 104], "12500": 60, "125065": 89, "12539340": [89, 99], "1255": 61, "12579": 61, "1258": 40, "126": [72, 104], "12606": 61, "12612": 61, "126777": 89, "126802": 61, "12689": 61, "127": [18, 72, 104], "127006": 61, "12705095": [76, 89], "12707800": 40, "1272404618426184": 58, "12752825": [89, 99], "127563": 65, "1277": 62, "127778": 61, "127922e": 62, "128": [41, 72, 104], "12802": 41, "12814": 61, "128300e": 49, "128312": 64, "128408": 59, "1285": 39, "12861": 61, "128651": 49, "129": [59, 72, 75, 104], "12945": 103, "1295": [39, 61], "129514": 61, "12955": 60, "129606": 48, "129798": 48, "1298": 61, "12980769e": 75, "12983057": 74, "13": [19, 20, 22, 24, 38, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 64, 65, 66, 68, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 102, 105], "130": [42, 54, 59, 72, 104], "130122": 65, "13034980e": 75, "130370": 50, "130526": 72, "1306": 65, "130829": 64, "13091": 61, "1309844442144665": 58, "131": [72, 104], "13102231": 74, "131024": 58, "13119": 65, "1312": 105, "131211": 61, "1313": [41, 105], "13137893e": 75, "1318": 39, "132": [42, 48, 59, 72, 104], "13208": 105, "1321": [60, 105], "1324": [41, 60], "132454": 52, "1325": 41, "132671": 50, "13288": 60, "132903": 61, "132982": 48, "133": [42, 70, 72, 103, 104], "13300": 61, "133202": 61, "133421": 61, "13356": 61, "133596": 64, "13398": 66, "133f5a": 62, "134": [59, 67, 72, 104], "134036304": 75, "1340371": 39, "1341": 41, "134146": 61, "1342": 61, "134211": 64, "1343": 60, "134542": 48, "134567": 61, "1346035": 41, "134687": 61, "13474": 61, "134765": 61, "134784e": 48, "1348": 60, "1349": 65, "13490": 61, "135": [42, 62, 72, 74, 104], "13505272": 40, "135142": 49, "135329": 56, "135344": 45, "135352": 5, "135379": 89, "135665": 49, "135707": 73, "135755": 72, "135856": 64, "13585644": 64, "135871": 59, "136": [43, 59, 66, 72, 104], "1360": 41, "13602": 66, "136089": 59, "1361": 61, "136102": 48, "136178": 74, "1362430723104844": 58, "13642": 61, "136442": 59, "1366": 62, "136836": 59, "137": [18, 42, 43, 72, 104], "1371": 61, "137213": 49, "137396": 64, "137529": 74, "1378": 61, "137809": 74, "138": [72, 104], "1380": 60, "138068": 54, "13809": 61, "138264": 66, "138378": 50, "1386": 39, "13868238": [89, 99], "138682380": [89, 99], "138698": [89, 99], "1387": 39, "138851": 54, "13893": 61, "138953": 45, "139": [66, 72, 102], "1390": 60, "139117e": 48, "139491": [89, 99], "13956": 65, "139582e": 12, "1398": 61, "1399": 39, "139921": 72, "14": [38, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 68, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 102, 105], "140": [51, 61, 67, 72, 104], "1400": 61, "14000073": 75, "140073": 48, "140081": 58, "1401": 39, "140770": [48, 49], "140833": 50, "140861": 40, "140926": 64, "141": [61, 72, 104], "141002": 49, "141098e": 61, "14114": 65, "141384": 56, "14141": 61, "141460": 45, "141546": [89, 99], "141820": 50, "14199633": 75, "142": [72, 104], "14200098": [89, 99], "142119": 48, "142270": 52, "142382": 48, "1424": 73, "14268": 74, "14281403493938022": 73, "14289": 61, "143": [70, 72, 104], "143342": 49, "143495": 72, "1435": 61, "143534": 48, "14368145": [89, 99], "144": [72, 104], "14400": 60, "14405": 61, "14406": 61, "144084": 50, "1441": 39, "144137": 51, "144241": 54, "144263002": 75, "1443": 61, "144500e": 61, "144669": 64, "1447": 61, "144800": 50, "144861": 60, "144908": 63, "145": [72, 104], "145027": 45, "145245": 64, "14532650": [89, 99], "145625": 64, "145748": 89, "14587": 61, "146": [72, 104], "146037": 64, "146087": 102, "146142808990006": 50, "146143": 50, "14625": 61, "146435": 49, "1465": 41, "146641": 89, "14667": 61, "1468115": 40, "146973": 50, "1469734445741286": 50, "147": [72, 104], "147015e": 61, "14702": 43, "147121": 64, "14744": 61, "14772": 61, "1479": 61, "14790924": [89, 99], "147909240": [89, 99], "147927": 43, "14798": 61, "148": [62, 72, 104], "14803": 61, "148134": [48, 49], "148161": 64, "148443": 72, "14845": 43, "1485": 61, "148750e": [60, 61], "148790": 61, "148802": 61, "149": [72, 104], "1492": 37, "149215e": 49, "149228": 66, "149285": 64, "149472": 66, "149714": 59, "14984": 61, "149858": [13, 72], "149882": 74, "149898": 64, "15": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 17, 38, 40, 41, 42, 45, 47, 48, 49, 50, 51, 54, 56, 57, 58, 59, 60, 61, 64, 65, 66, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 102, 105], "150": [25, 42, 62, 66, 72, 104], "15000": [41, 60], "150000": 41, "15000000000000002": [50, 61, 64, 73], "150000e": 61, "1502": 40, "150200": 59, "150334": 61, "150408": 40, "150614": 43, "150719e": 60, "151": [72, 104], "151047e": 54, "151063": 48, "15113": 61, "151636": 50, "151819": 64, "15194": 60, "152": [72, 104], "152034": 61, "1520867": 75, "152148": [48, 49], "152353": 49, "15285": 61, "152896": 58, "152926": 52, "153": [66, 72, 104], "1530959776797396": 50, "153096": 50, "153119": 50, "153314": 49, "15347": 61, "15354": 65, "153587": 59, "153633": 43, "153639": 75, "153935": 49, "154": 72, "15430": 105, "154421": 89, "1545": 61, "154557": 64, "154758": 89, "154774": 62, "154828": 50, "154890": 58, "155": [72, 104], "155000": 60, "155025": 64, "155120": 64, "155160": 45, "155174": 45, "155516": 63, "15556": 61, "1557093": 40, "156": [72, 104], "1560": 61, "156021": 64, "156169": 49, "156202": [48, 49], "156317": [48, 49], "1564": [89, 99], "156545": 89, "156684": 49, "1569": 61, "156969": 50, "157": [49, 62, 72, 104], "157091": 89, "157154": 48, "1576": 61, "157733": 58, "1577657": 40, "158": [60, 72, 104], "158007": 64, "15815035": 41, "158178": 50, "1582": 61, "1586": 61, "158697": [89, 99], "1589": 61, "15891559": 64, "158916": 64, "159": 104, "15916": 39, "159386": 65, "1596": 42, "159633e": 49, "159841": 48, "159959": 61, "16": [3, 37, 38, 40, 41, 42, 45, 48, 49, 50, 55, 56, 59, 60, 61, 64, 65, 66, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 102, 105], "160": [51, 67, 104], "1604": 41, "160932": 50, "161": [42, 103, 104], "161049": 49, "161141": 59, "161198": 63, "161236": 64, "161243": 64, "161269": 48, "161288": [49, 58], "161543": 61, "1619": 41, "162": [62, 104], "16201": 61, "16211": 60, "162153": 64, "1622": 61, "16241": 61, "162436": 66, "162593": 58, "1626685": 40, "162683": 66, "162710": 50, "162784": 74, "1628": 60, "162930": 61, "163": [61, 104], "163194": 64, "163566": 61, "163577": 45, "163816": 45, "163895": 50, "164": [45, 104], "164034": 89, "164608": 64, "164617": 60, "164698": 56, "1648": 39, "164801": 64, "164805": 50, "164864": 59, "165": 104, "16500": 60, "165178": 64, "16536299": [89, 99], "165362990": [89, 99], "16539906e": 75, "1654": 61, "165419": 64, "165549": 102, "165707": 45, "16587": 60, "16590": 61, "16597": 61, "166": 104, "1661": 60, "166238": 58, "166375": 72, "167": [41, 60, 104], "16725": 61, "167547": 64, "167581e": 48, "1676": 61, "167765": 61, "167993": 89, "168": 104, "16803512": [89, 99], "168089": 58, "168092": 89, "1681": 39, "168195": 65, "1683": 60, "168614": 64, "168931": 64, "169": [42, 104], "1691": [39, 61], "16910": 61, "169117": 66, "169196": 64, "169230e": 50, "16951": 61, "16984": 61, "16988856": 75, "17": [38, 40, 41, 42, 48, 49, 56, 59, 60, 61, 64, 65, 66, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 102, 105], "170": 104, "1704": 61, "170709e": 49, "17083": 61, "171": 104, "1712": 103, "1714": 41, "171575": 64, "171815": 73, "171833": 49, "171848e": 48, "171942": 61, "172": 104, "172022": [89, 99], "172083": 49, "172628": 58, "172793": 64, "173": 104, "173504": 55, "17372": 61, "1738": 61, "17385178": 73, "173969": 89, "174": 104, "174106": 65, "174185": 64, "174499": [89, 99], "174516e": 64, "17453": 61, "1746": 61, "174743": 72, "174835": 49, "174940": 72, "17499": 61, "175": 104, "1751": 60, "175176": 64, "17522": 61, "175284": 50, "175369": 49, "175635027": 40, "17576": 61, "175894": 66, "175931": 74, "176235088": 75, "176495": 64, "1764962": 75, "17655394": 64, "176554": 64, "176929": [89, 99], "177": [103, 104], "177007": 64, "17700723": 64, "177043": [48, 49], "1773": 61, "1774": 39, "177463": 63, "177496": 64, "177611": 64, "177740": 48, "177751": 64, "17778": 61, "177830": 49, "17799": 61, "177995": 64, "178": [56, 104], "178169": 54, "178218": 49, "17823": 42, "178704": 89, "178763": 64, "178934": 89, "179": [54, 104], "179026": 49, "1795850": 40, "179588e": 64, "179777": 49, "1798913180930109556": 62, "18": [37, 38, 40, 41, 42, 43, 48, 49, 56, 57, 59, 60, 61, 64, 65, 66, 70, 72, 73, 74, 75, 89, 99, 102, 105], "180": [51, 67, 104], "180143": 45, "18015": 61, "180176e": 61, "180190": 74, "180262": 49, "1803": 39, "18030": 61, "180575": [54, 55], "1807": [39, 61], "1809": 103, "180951": 64, "181": 104, "1812": 61, "1814": 39, "18141": 61, "181446": 89, "182": 104, "1820": 39, "1822914": 75, "182427": 49, "182633": 64, "182849": 64, "183": [42, 104], "183339": 48, "183373": 74, "183526": 50, "18356413": 74, "18368": 61, "183855": 73, "183888": 59, "184": [42, 103, 104], "184247": 48, "184347": 49, "185": [41, 42], "18500": 61, "1855": 61, "185585": 72, "185984": 48, "186": [61, 104], "18604": 61, "1862": 39, "186237": 49, "18631": 61, "18637": 100, "186589": 45, "18666": 61, "186735": 64, "18678094e": 75, "186836": 64, "187": 104, "187153": 89, "187664": 48, "187690": 64, "18789": 61, "188": 104, "1880867": 75, "188175": 64, "1881752": 64, "188223": 64, "188400": 49, "1887": 74, "18888149e": 75, "188882": 49, "188991": 89, "189": [42, 104], "1890037": 75, "189195": 61, "189248": 48, "189293": 61, "1895815": [26, 40, 59], "189737": 64, "189927": 61, "189998": 64, "19": [38, 40, 41, 42, 48, 49, 58, 59, 60, 61, 64, 65, 66, 72, 73, 74, 75, 89, 102, 105], "190": [42, 104], "19000": 61, "190096": 89, "19031969": 64, "190320": 64, "19033538": 40, "190381": 74, "190648": 8, "19073905e": 75, "190809": 64, "190869": 72, "190892": 66, "1909": [26, 40, 59], "190915": 50, "190921": 55, "190982": 64, "191": [42, 103, 104], "19101117182329353645464861626975768287": 75, "1910111718232935364546486162697576828748162028314142495863647273798084859499213192225303752535657606570778990959710035141524273438404447515568747881869398": 75, "1910111718232935364546486162697576828767122126323339435054596667718388919296213192225303752535657606570778990959710035141524273438404447515568747881869398": 75, "1910111718232935364546486162697576828767122126323339435054596667718388919296481620283141424958636472737980848594992131922253037525356576065707789909597100": 75, "19101117182329353645464861626975768287671221263233394350545966677183889192964816202831414249586364727379808485949935141524273438404447515568747881869398": 75, "191192": 48, "1912": 103, "191223": 49, "1912705": 69, "191294": 49, "191320e": 60, "191397": 72, "191606": 60, "191716": 61, "1918": 39, "192": 104, "1922": 61, "192240": 89, "192505": 63, "192526": 65, "19252647": 65, "192539": [14, 72], "192587": 64, "192952": 45, "193": 104, "193060": 64, "193253": 48, "193285": 48, "193308": [14, 72], "193341": 49, "19374710e": 75, "19382": 61, "19385": 61, "193f0d909729": 42, "194": [57, 61, 104], "194092": 48, "1941": 41, "19413": [60, 61], "194303": 49, "194601": 51, "195": 104, "19508": 66, "19508031003642462": 66, "19509680e": 75, "195377": 64, "195396": 64, "195547": 61, "195564": 59, "19559": [41, 60], "195761": 64, "195781": 48, "1959": 103, "196": 104, "196189": 64, "196437": 61, "196478e": 49, "19680840": [89, 99], "197": 104, "1970": 61, "197000e": 61, "19705": 61, "197225": [43, 70, 102], "1972250000001000100001": [42, 70, 102], "1974": 61, "197424": 73, "197484": 89, "19756": 61, "19758": 61, "197600": 52, "197711": 61, "197920": 48, "19793": 61, "19794": 61, "198": 104, "198218": 59, "19824": 61, "198351": 64, "198549": 43, "198687": 41, "1988": [38, 47, 69, 74], "198953": 72, "199": 104, "1990": [41, 60, 61], "1991": [41, 60, 61, 105], "199281e": 64, "199282e": 61, "199412": 49, "199458": 89, "1995": [40, 59], "1998": 62, "19983954": 67, "199893": 54, "1999": [62, 67], "1_": [50, 64], "1e": [1, 3, 5, 6, 8, 9, 10, 13, 14, 15, 61], "1f77b4": 52, "1x_4x_3": 52, "2": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 89, 90, 91, 92, 95, 96, 97, 98, 99, 102, 103, 104], "20": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 22, 23, 24, 26, 27, 28, 38, 40, 41, 42, 48, 49, 50, 51, 54, 56, 57, 59, 60, 61, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 89, 90, 95, 102, 105], "200": [21, 24, 25, 39, 50, 51, 53, 57, 63, 64, 67, 69, 73, 104], "2000": [15, 17, 41, 45, 48, 49, 50, 60, 61, 64, 67, 74], "20000": [41, 60], "20000000000000004": [50, 61, 64], "200000e": 61, "200049": 48, "200065": 45, "20010": 61, "2001010851": 75, "200110": 61, "2003": [16, 103], "200303": 102, "2005": 51, "20055": 61, "2006": 61, "20073763": 57, "20074": 61, "201": [42, 61, 104], "2010": [40, 59], "2011": [40, 59, 100, 102], "2013": [53, 89, 99, 103], "2014": [89, 99, 103], "2015": [25, 75, 103], "201528": [48, 49], "20158": 61, "2016": 62, "2017": [23, 103], "201768": 59, "201788e": 61, "201796": 56, "2018": [16, 17, 27, 28, 38, 40, 41, 47, 51, 53, 57, 59, 60, 61, 65, 69, 75, 89, 99, 100, 103, 104], "2019": [21, 42, 48, 49, 50, 54, 55, 61, 64, 65, 73, 76, 78, 83, 88, 100, 102, 103], "202": 104, "2020": [5, 6, 18, 19, 20, 22, 24, 39, 42, 51, 66, 73, 74, 90, 92, 103], "2020435": 40, "2021": [26, 39, 40, 42, 48, 49, 59, 103, 104], "20219609": 40, "2022": [65, 66, 74, 90, 92, 98, 100, 103], "2023": [29, 67, 74, 76, 84, 85, 103], "2024": [37, 46, 62, 66, 100, 103], "202603": 49, "202650e": 50, "20269": 61, "20274": 61, "2027650": 75, "202846": 49, "203": [41, 48, 60], "203284": 50, "20329": 61, "2036": 61, "203828": 61, "203893": 72, "204007": 64, "20400735": 64, "2040638": 75, "204362": 66, "204455": 49, "204482": 64, "204626": 45, "204653": 72, "204794": 64, "205": 65, "205187": 50, "205224": 65, "205938": 59, "206": 104, "2061": 61, "206253": [60, 61], "2064": 61, "206614": 64, "207222": 60, "2075": 39, "207834": 49, "20783816": 40, "207840": 55, "207912": 89, "208": [45, 104], "208034e": 61, "2080787": 40, "20823898": 40, "208417": 62, "2086": 61, "209": 45, "209014": 64, "209219e": 65, "209257": 5, "20929659": 75, "209546e": 61, "209894": 64, "21": [16, 17, 27, 38, 40, 41, 42, 48, 49, 53, 59, 60, 61, 64, 65, 66, 69, 72, 73, 74, 75, 89, 100, 102, 103, 105], "210": [19, 20, 24, 45], "2103": [61, 100], "2103034": 40, "210319": [48, 49], "210323": 64, "2104": 104, "21078": 61, "211": [45, 104], "21105": [42, 73, 100, 102], "2112": 66, "21142": 61, "211534": 50, "21155656": 64, "211557": 64, "212": [45, 62, 104], "2122": 61, "21257396e": 75, "212844": 59, "212863": 48, "213": [45, 103, 104], "213026": 61, "213070": 49, "213135": 49, "2131922253037525356576065707789909597100": 75, "21361": 61, "213743e": 49, "2139": 22, "214458": 58, "214491989": 75, "214764": 65, "215": 45, "215069": 64, "215342": 64, "2155": 61, "21550": 61, "21562": 61, "21573": 61, "215967": 89, "216": 45, "216207": 73, "21624417": 40, "2163": 61, "216344": 64, "21669513e": 75, "216761": 63, "217": [45, 103], "2170862": 75, "21716": 61, "2171802": [40, 59], "217244": [10, 72], "218": 45, "21804": [41, 60], "218176": 45, "218383": 45, "2186451": 75, "218767": 61, "2189": 61, "218938": 61, "219": [18, 19, 20, 39, 45, 103], "2191274": 40, "2197237644227434": 58, "21997": 60, "22": [38, 40, 41, 42, 48, 49, 58, 59, 60, 64, 65, 66, 72, 73, 74, 75, 89, 102, 105], "220": [45, 104], "220088": 61, "220398": 48, "220407": 58, "220772": 64, "221": [45, 104], "22104337": 75, "2213": 59, "2214": 59, "221419": 61, "2215": 59, "2216": 59, "2217": [40, 59], "222": [62, 104], "2222": [38, 40, 47, 74], "2222122": 75, "22222": 61, "22272803e": 75, "222843": 64, "222882": [49, 58], "223": [62, 104], "223158": 58, "22336235": 40, "223485956098176": [54, 55], "223617": 58, "22375856": 40, "22390": 60, "223928": 58, "224": 104, "224897": [48, 49], "225": [39, 67, 104], "225034": 51, "22505965": 40, "22507006e": 75, "225175": 64, "225222": 64, "22522221": 64, "22528": 61, "225350": 49, "225427": 45, "225459760731946": 50, "225460": 50, "2254787": 75, "225574": 59, "2256": 61, "22562": 61, "225670": 58, "225776": 66, "226": 104, "2264": 39, "226524": 64, "226598": 59, "226938": 55, "226969": 45, "227": [61, 104], "2271071": 29, "2276": 39, "2279": 61, "227931e": 60, "228035": 61, "2281": 61, "228214": 74, "228404": 58, "228597e": 49, "228630": 49, "228648": 41, "229": [41, 104], "22925": 61, "22937": 61, "229443": 64, "229452": 74, "229472": 60, "2295": 61, "229759": 73, "2298": 39, "229961": [48, 49], "229994": [48, 49], "23": [6, 40, 41, 42, 48, 49, 51, 57, 59, 60, 61, 64, 65, 66, 70, 72, 73, 74, 75, 89, 100, 102, 103, 105], "230": 39, "230009": [54, 55], "2300136": 75, "2307": [40, 59, 69], "2308": 65, "230842": 48, "230956": 52, "231": [16, 104], "23113": 74, "231153": 49, "231310": 64, "231430": 89, "231467": 74, "231986": 64, "232134": [48, 49], "232157": 49, "2328": 61, "232868e": 49, "232959": [54, 55], "233": 23, "233029": 48, "233154": 105, "2335": 39, "233705": 49, "234": 103, "234137": 66, "234153": 66, "234205": 61, "234431": 58, "234534": 50, "234605": 43, "234798": 61, "234910": 59, "235": 104, "235291": 48, "2359": 105, "23590": 61, "236008": 50, "236015e": 48, "236309": 61, "236884": 58, "23690345e": 75, "237": 42, "237115": 49, "237200e": 48, "237252": 61, "237341": 48, "237461": 65, "23748": 61, "23751359e": 75, "237896": 64, "23789633": 64, "238": [40, 59, 104], "238101": 64, "238225": 89, "238251": 50, "238529": 9, "23856": 61, "238794": 64, "239": 104, "239243": 48, "239267": 58, "239313": 49, "23965": 61, "23e": 41, "24": [40, 41, 42, 48, 49, 57, 58, 59, 60, 61, 64, 65, 66, 67, 72, 73, 74, 75, 89, 102, 103, 104, 105], "240127": [48, 49], "240146": 49, "240295": 65, "240532": [48, 49], "2407": 39, "24080030a4d": 42, "240813": 56, "241049": 64, "241064": 49, "241596": 74, "2416": 39, "241609": 61, "241645": 49, "241678": 48, "241827": 49, "241962": 66, "24199": 61, "242": 103, "242000": 61, "242124": [60, 61], "242139": 89, "242158": [60, 61], "2424596822": 55, "242815": 89, "242902": 64, "2430561": 39, "243246": 64, "2438": 61, "2439": 61, "244": 61, "244090": 61, "244455": 64, "244622": 89, "24469564": 102, "245": [103, 104], "245062": 64, "2451": 39, "24510393": 41, "245370": 59, "245512": 64, "245531": 48, "245720": 52, "246": 104, "246624": 72, "246731": 60, "2467506": 40, "246753": 64, "246879": 64, "247": 104, "247020": 50, "247057e": 64, "2471": 61, "2472": 61, "247617": 72, "247717": 61, "24774": [60, 61], "247826": 59, "247977": 48, "248171": 64, "248638": 50, "249": [40, 59, 62, 104], "2491": 61, "24917": 61, "249986": 58, "25": [14, 15, 18, 19, 20, 24, 25, 26, 27, 40, 41, 42, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 64, 66, 67, 72, 73, 74, 75, 89, 102, 105], "250": [62, 104], "2500": 61, "25000000000000006": [50, 61, 64], "250073": 61, "250210": 50, "2503": 61, "250354": 64, "250425": 50, "251": [61, 65], "251101": [72, 73], "251412": 49, "2514122": 75, "251480": 49, "251953": 61, "252133": 61, "252253": 65, "25240463": 74, "252524": 64, "252601": 89, "252747025": 75, "253026": [48, 49], "2532": 61, "253437": 63, "253724": 64, "25374": 61, "254": [61, 104], "25401679": 40, "254035": 58, "254038": 55, "254083": 49, "2543": 61, "254324": 50, "254400": 89, "255": [61, 104], "255034e": 49, "25575125": 75, "255995": 48, "256": [61, 73], "256002": 74, "256416": 64, "256567": 59, "25672": 61, "256944": 64, "256983": 12, "256992": 61, "257019": 49, "257207": 40, "257377": 52, "257523": 48, "258083": 49, "258158": [48, 49], "2583": 61, "258522": 48, "258541e": 15, "258951": 64, "259164": 49, "259395": 56, "2594": [41, 60], "259828": [48, 49], "259875": 49, "25x_3": 52, "26": [40, 41, 42, 43, 48, 49, 51, 57, 59, 60, 61, 67, 70, 72, 73, 74, 75, 89, 102], "26016": 61, "260161": [13, 72], "260211": [48, 49], "260356": 60, "260360": 64, "2610": 61, "2613": 61, "261520": 45, "26161837": 75, "261624": [60, 61], "261685": 61, "26175": 61, "261777": 61, "261903": 59, "2619317": 40, "262423e": 61, "262621": 59, "262829": 75, "263": [16, 61, 104], "2633": 61, "263942e": 49, "263974e": 64, "264": [103, 104], "264086": 52, "264274e": 61, "264884": 61, "2649074535": 75, "265": 104, "2651": 74, "265119": 63, "2652": [42, 60, 61], "265547": 61, "265744": 58, "2658": 55, "266": 104, "266686": 48, "266922": 89, "267": 62, "2670691": 40, "2673046": 75, "267500": 59, "267581": 61, "267950": 64, "268": 37, "268055": 61, "268343": 58, "268628e": 49, "268942": 64, "268943": 48, "268998": 41, "269043": 64, "269977": 61, "26bd56a6": 42, "26e": 41, "27": [19, 20, 24, 38, 40, 41, 42, 43, 48, 49, 51, 57, 59, 60, 61, 67, 70, 72, 73, 74, 75, 89, 102, 103], "2700": 42, "270644": [48, 49], "271004": [60, 61], "271083": 61, "2711369": 75, "272296": 61, "272332e": 48, "272408": 49, "272662": 61, "273": 42, "273299": 49, "273356": 50, "27371": [41, 60], "27372": [41, 60], "274": [42, 61], "2740991": 39, "274247e": 60, "274267": 59, "27429763": 74, "274793": 64, "274825": [14, 72], "27487": 61, "2754": 39, "275596": 89, "276": 42, "276148": 64, "276189e": 59, "2764": 61, "2765185": 75, "2766091": 41, "276716": 62, "27713": 61, "277299": 43, "27751": 61, "277512": 49, "277561e": 59, "277968": 64, "278": 65, "2780": 40, "278000": 59, "278035": 45, "278391": 61, "278434": 54, "278522": 45, "2786": [89, 99], "278804": 49, "27951256e": 75, "27986": 61, "279933e": 49, "28": [40, 41, 42, 48, 49, 53, 56, 57, 59, 60, 67, 72, 73, 74, 75, 89, 102, 104], "280196": 55, "280454dd": 42, "280514": 89, "280963": 63, "281024": 64, "28111364": 41, "2815": 61, "2818": 39, "2819": [89, 99], "282": 103, "282200": 55, "2825": [100, 102], "28251": 61, "2828579342": 75, "282870": 61, "2830": [100, 102], "283041": 48, "283207": 48, "28326": 61, "283386": 48, "2836": 39, "2836059": 40, "28382": 61, "283974": 64, "283992": 48, "283994": 64, "28425026": 65, "284271": 56, "284397": 105, "28452": [41, 60], "2849": 61, "284987": 61, "286027": 72, "286203": 48, "286371": 48, "2865": [39, 61], "286507": 50, "286563e": 61, "286593": 61, "2870376": 75, "287041": 64, "287196": 48, "287815": 65, "287926": 64, "288": 62, "288006": 60, "288607069": 75, "288976": 61, "289": 103, "289357": 49, "289440": [48, 49], "29": [12, 40, 41, 42, 48, 49, 57, 59, 60, 65, 67, 72, 73, 74, 75, 89, 102], "290565": 49, "290736e": 49, "290987": 60, "291": 61, "2910": 61, "291008": 48, "291011": 74, "291071": 64, "29107127": 64, "291405": 64, "291406": 64, "291434": 49, "291500e": [60, 61], "291517": [48, 49], "291963": 64, "292": 63, "292028": 50, "292047": 89, "292105": 64, "292178": 60, "292302995303554": 50, "292303": 50, "2925": 42, "2927": 61, "292997": 64, "29299726": 64, "293218": 64, "293617e": 61, "294067": [48, 49], "294449": 48, "295": 103, "295307": 48, "295481": 64, "29548121": 64, "295837": [43, 70, 102], "2958370000000100000100": [42, 70, 102], "2958370001000010011100": [42, 70, 102], "2958371000000010010100": [42, 70, 102], "296228": 61, "296729": 59, "29678199": [68, 76], "296901": 48, "297287": [48, 49], "2973": 61, "297349": [54, 55], "297682": 64, "297687": 61, "297749": 61, "29784405": 65, "298": [23, 42], "298076": 48, "298120": 50, "298228e": 61, "299": 42, "299537": 55, "299712": 54, "2999": 45, "2_": [29, 67, 90, 92, 98], "2_x": [29, 67], "2d": [76, 83], "2dx_5": [50, 64], "2e": [37, 39, 40, 41, 42, 73, 74, 76, 89, 102], "2f": 56, "2m": [90, 95, 98], "2n_t": 52, "2x": 64, "2x_0": [21, 48, 49, 54, 55], "2x_4": 52, "3": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 27, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 100, 101, 102, 103, 104], "30": [21, 37, 38, 40, 42, 45, 46, 47, 48, 49, 50, 51, 57, 59, 60, 61, 64, 67, 72, 73, 74, 75, 89, 102], "300": [38, 47, 50, 61, 64, 69, 103], "3000": 45, "30000000000000004": [50, 61, 64], "300031": 48, "30031116e": 75, "300624406": 75, "300892e": 49, "30093956": 65, "301": 42, "301366": 89, "301371": 64, "3016": 60, "301737": 48, "30189": 61, "302149": 48, "302357": 64, "302382": 58, "302571": 72, "302648": 59, "303007": 48, "303324": 59, "303489": 64, "303613": 64, "30361321": 64, "30383": 61, "303835": 59, "303f00f0bd62": 42, "304130": 64, "304159": 64, "304201": 52, "3047724": 75, "305133": 72, "30527": 61, "305341": 64, "305612": 59, "305775": 64, "305b": 42, "306297": 48, "30645": 61, "30672815": 40, "306915": 59, "306963": 64, "307407": 64, "308": 61, "308568": 49, "308774": 48, "30917769": [54, 55], "309539": 58, "309772": 59, "309823e": 61, "30982972": 64, "309830": 64, "31": [40, 41, 42, 45, 48, 49, 57, 59, 60, 61, 67, 72, 73, 74, 75, 89, 102, 105], "310000e": 61, "310145": 58, "310761": 63, "311253": 61, "311321": 49, "311667": 49, "311712": 54, "3119552": 75, "3120": 61, "313056": 89, "313209": 50, "313324": 61, "31337878": 61, "313535": 64, "31378": 42, "314": 75, "3141": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 40, 42, 43, 59, 68, 70, 72, 73, 76, 89, 99, 102], "314247": 66, "314341": 48, "3146": 15, "314625": 49, "314651": 54, "31476": [60, 61], "315031": 66, "315036": 48, "3151": 61, "315155": 49, "315223": 45, "315290": [54, 55], "315310": 48, "315769e": 48, "316": 42, "316193": 64, "31632": 61, "316407": 74, "316540": 59, "316717": [48, 49], "316826": 48, "316863": 49, "317": 37, "317394": 52, "317487": 64, "317607": 64, "318": [42, 62], "318000e": 61, "318438": 61, "318552": 61, "318584": 89, "3187510850": 75, "318753": [54, 55], "319": 42, "319100": [54, 55], "319759": 64, "319850": 64, "32": [40, 41, 42, 48, 49, 57, 58, 59, 60, 61, 67, 72, 73, 74, 75, 76, 89, 102], "320": 61, "320314": 60, "320633": 50, "321686": 89, "322186e": 48, "32236455588136": 51, "322404": 65, "322751": 49, "3234": 61, "323622": 60, "323679": 59, "324": [41, 61], "324476": 45, "324518": 63, "32458367": 40, "3245837": 64, "325056": 64, "325080132": 75, "325090": 61, "325486": 48, "325599": 48, "326148": 49, "326721": 49, "326740": 64, "326871": 66, "3268714482135234": 66, "327257": 48, "32729955": 75, "327803": 72, "328471": 48, "329339": 51, "3294386": 75, "32950022e": 75, "33": [40, 41, 42, 48, 49, 54, 57, 58, 59, 60, 61, 67, 72, 73, 74, 75, 89, 102, 103], "3300": [41, 60], "330068": 48, "330100": 48, "330143": 64, "33014346": 64, "330163": 49, "330285": [48, 49], "3304269": 40, "330615": 64, "330731": [14, 72], "3310278": 75, "3312258": 75, "331365": 54, "331521": 64, "331602": 61, "33175566": 64, "331756": 64, "332502": 49, "332782": [14, 72], "3329": 61, "332996": 59, "333": 62, "3333": [38, 40, 47, 72, 73, 74], "3333333": 42, "33335939e": 75, "3335": 61, "333575": 60, "333655": 48, "333704": 49, "333955": 49, "334": 41, "334649": 56, "334750": 50, "33500": 61, "335176": 61, "335446": 45, "335609e": 64, "335846": 64, "335853": 61, "336382": 49, "336461": 61, "336612": 52, "3370459": 75, "337380": 64, "3376": 39, "337619": 51, "3378421": 75, "338": 65, "33849": 61, "3386": 75, "338603": 48, "3386382": 75, "338775": 50, "3387784": 75, "338908": 50, "338952372": 75, "339269": 65, "33928": 61, "339443": 49, "339570": 64, "339875": [54, 55], "34": [38, 39, 40, 41, 42, 48, 49, 55, 57, 59, 60, 61, 65, 67, 72, 73, 74, 75, 89, 105], "340": [41, 61], "340029": 49, "340274": 65, "341336": [10, 72], "341472": 58, "341755e": 48, "3420": 61, "342362": 45, "342467": 72, "342632": 58, "342675": 40, "34287815": 65, "342989": 61, "342992": 59, "343": 61, "343685": 48, "343828": 48, "344212": 105, "344305": 56, "3444328": 75, "344505": [60, 61], "344640": 64, "34475": 60, "344753": 45, "344787": [48, 49], "344834": 52, "344913": 62, "345065e": 61, "345381": 50, "3453813031813522": 50, "3454": 61, "345852": 49, "345903": 64, "345989": 48, "346043": 62, "346206": 64, "346238": 65, "346269": 49, "346678": 63, "346964": 48, "347310": [14, 72], "347696": 50, "34769649731686": 50, "347929": 61, "348319": 49, "34858240261807": 51, "348617": 64, "348700": 49, "348980e": 49, "3492131": 39, "349383": 59, "34943627": 57, "349638": 49, "34967621": 40, "349772": 55, "35": [41, 42, 48, 49, 50, 59, 60, 61, 64, 72, 73, 74, 75, 89, 90, 95, 105], "3500000000000001": [50, 61, 64], "350165": 73, "350208": 48, "350518": 64, "350712": [54, 55], "35077502": [90, 95], "351220": 49, "35141524273438404447515568747881869398": 75, "351629": 61, "351766": 63, "352": [41, 59], "352250e": 60, "352259e": 61, "3522697": 40, "352805": 62, "352813": [72, 73], "35292": 61, "352990": 61, "352998": 61, "353105": 15, "353412": 64, "35341202": 64, "35365143": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "353748e": 64, "3538": 39, "354": 61, "354188": 52, "354371": 64, "354688": 11, "355065": 45, "355209": 64, "35555": 75, "355651": 49, "356136e": 61, "356167": 55, "356183": 61, "35620768e": 75, "3564": 61, "3565": 61, "3568": 74, "357": 61, "357170": 48, "35731523": 74, "357899": 75, "358158": [60, 105], "358289": 59, "358395": 65, "358799": 89, "358977": 60, "359": 105, "359100": 61, "359161e": 48, "3593": 65, "359307": 49, "35th": 103, "36": [41, 42, 48, 49, 59, 60, 72, 73, 74, 75, 89], "360004": 64, "360065": 89, "360249": 56, "360475": [48, 49], "360572": 49, "360655": 61, "360683": 50, "360801": 50, "361518": 50, "361518457569366": 50, "361521": 11, "3619201": 22, "362157": 48, "36231307e": 75, "363276": 40, "364221": 48, "3643": [89, 99], "364595": 40, "3647": 42, "364800": 64, "36501": 61, "365551": 49, "36557": 75, "36557195e": 75, "36566025e": 75, "366": 61, "36616": 61, "366310": [48, 74], "366529": 63, "366718627": 40, "366950": 48, "367": 37, "367181": 48, "367323": 64, "367398": 58, "367571": 50, "367625": 64, "368152": 59, "3682": [41, 60, 61], "368324": 59, "368499": 50, "3684990272106954": 50, "369556": 50, "3696": 65, "369796": 64, "369869": 60, "369981": 59, "37": [41, 48, 49, 59, 60, 61, 72, 73, 74, 75, 89], "3702770": 40, "370736": 59, "3707775": 40, "370908": 48, "3710": 61, "371357": [60, 61], "371429": 50, "371850e": 49, "372": 103, "37200": [60, 61], "372097": 50, "3722": 61, "37231324": 67, "3724": 61, "372427": 49, "3727679": 40, "373218e": 58, "3738573": 40, "374364": 64, "37436439": 64, "3744560": 75, "3745": 61, "374821e": 61, "374862": 48, "374917e": 48, "375081": 61, "3751204477": 75, "375274": 48, "375465": 64, "375621": 58, "375844": 58, "376760": 49, "376806": 49, "377060": 61, "377195": 45, "377311": 64, "3774518": 75, "377669": 49, "378351": 8, "378588": 48, "378596": 59, "378688": 64, "378727": 48, "378834": 64, "3788859": 40, "379": 103, "379038": 64, "37939": 61, "379614": 64, "379626": 48, "379981e": 49, "38": [42, 48, 49, 60, 72, 73, 74, 75, 89], "3800694": 40, "380837": [60, 61], "381072": 64, "381603": 48, "381685e": [60, 61], "381689": 64, "3817": 61, "381826": 12, "382286": 61, "382582e": 3, "382684": 72, "382872": 50, "383": 105, "383297": 64, "383531": 58, "384": 61, "384223": 74, "384443": 49, "384677": 45, "384777": 61, "384865": 49, "384928": 48, "385013": 45, "3851": 61, "385160": 49, "385240": 89, "385615": 45, "385917": 59, "386": [42, 61], "386102": 50, "386502": 61, "386831": 45, "386988": 51, "387": 42, "3871": 39, "387426": 64, "387780": 64, "388026": 48, "388071": 64, "388185": 45, "38818693": 75, "388216e": 73, "388668": 64, "38866808": 64, "388871": 61, "389": 42, "389126": 74, "389164": 58, "38922": 74, "389566": 63, "38973512e": 75, "389755": 48, "38990574": 75, "39": [37, 39, 40, 41, 42, 43, 45, 48, 49, 51, 55, 56, 57, 59, 60, 61, 62, 65, 66, 67, 72, 73, 74, 75, 89], "39010121e": 75, "390379": 64, "391377": 66, "392128": 49, "392242": 56, "39236801": 57, "392400": 61, "392623": 49, "392752": 51, "392833": 65, "392864e": [60, 61], "392917": 48, "393060": 72, "393604": 50, "393654": 45, "394226": 49, "39425708": 40, "395076e": 61, "395136": 59, "395268": 72, "395569": 48, "395603": 48, "3958": 74, "395889": 61, "39611477": 41, "396173": 54, "39621961e": 75, "396300": 54, "3964": 61, "396531": 61, "3969374": 75, "396985": 59, "396992": [48, 49], "397140": 50, "397155": 49, "397179": 45, "39727": 61, "397313": 39, "397473": 75, "397536": 58, "397578": 56, "397811": 65, "398": [70, 102], "3985": 61, "398770": 64, "398999": 72, "399": 41, "399056": 64, "399223": 52, "399343e": 48, "399355": 52, "399692": 64, "399858": 66, "3cd0": 42, "3dx_1": [50, 64], "3e1c": 42, "3ec2": 42, "3f5d93": 62, "3x_": 64, "3x_4": [50, 64], "4": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 19, 20, 24, 29, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 102, 104], "40": [40, 48, 49, 50, 51, 58, 60, 61, 64, 67, 70, 72, 73, 74, 75, 89, 90, 95], "400": 59, "4000000000000001": 73, "40000000000000013": [50, 61, 64], "40029364": [90, 95], "400823": 64, "400855956463958": 50, "400856": 50, "401": [16, 105], "401247": [76, 89], "40127723e": 75, "401690e": 49, "401931": [54, 55], "402077": 61, "402113": 89, "402301e": 73, "402902": 61, "403425": 64, "403626490670169": 68, "4036264906701690": 68, "403626491": 68, "403715": 3, "403771948": 76, "4039": 39, "404267": 48, "404300": 45, "404318": 39, "404411": 48, "40452": 61, "404550": 63, "405050": 49, "405203": 52, "405374": 61, "40583": 39, "405890": [14, 72], "406": [37, 60], "406285": 64, "406446": 50, "4065173": 75, "40676": 39, "407558": 48, "407565": 48, "4078915": 75, "408476": [90, 95], "40847623": [90, 95], "408479": 59, "408509": 49, "408539": 64, "408565": 64, "409154": 39, "4093": 65, "409328": 61, "409395": 64, "4094012": 75, "409746": 50, "409848": [48, 49], "41": [45, 48, 49, 60, 61, 72, 73, 74, 75, 89, 99], "410100": 48, "410393": 50, "410667": 72, "410681": 52, "410682": 48, "410795": 59, "41093655": 75, "411146e": 49, "411190": [48, 49], "411291": 63, "411295": 64, "411304": [48, 49], "411447": 61, "411582": 64, "411768": 49, "412004": 54, "412127": 64, "412304": 66, "412477": 52, "412653": 59, "412714": 50, "412726": 49, "412941e": 49, "413247e": 48, "41336": 73, "41341040": 40, "413608": 64, "414073": 9, "414533": 49, "41525168e": 75, "415375": 48, "41566": 74, "415812": 105, "415988": 61, "416052": 45, "416132": 49, "4166": 61, "4166667": 42, "416757": 64, "416899": 48, "416919": 49, "417640": 48, "417736": 58, "417767": [54, 55], "417822": 60, "417834": 45, "41798768e": 75, "4180466440": 75, "418056": 64, "41805621": 64, "41836": 60, "418360": 60, "418741": 45, "418806e": 50, "41918406e": 75, "419371": 64, "419871": 45, "41989983e": 75, "4199952": 40, "41e5": 42, "42": [5, 6, 24, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 61, 63, 64, 65, 66, 67, 72, 73, 74, 75, 89, 99, 103], "4200": 61, "4200897": 75, "420316e": 61, "420608e": 65, "42073312": 40, "420967": 50, "421083": 39, "4211349413": 40, "421163": 48, "421200": 66, "421234": 72, "421297e": 49, "421357": [54, 55], "421576e": 61, "421793": 65, "421919": 61, "422007": 65, "422266": 61, "422293e": 72, "422325": 50, "422561": 45, "422591": 49, "42338": 61, "4235839": [54, 55], "42388745": 67, "423921e": 72, "423951": 39, "424108": 50, "424127": 75, "42412729": 40, "424292": 48, "424328": 64, "424651": 74, "424717": 50, "424748": 66, "425": 59, "425103": 39, "425208": 61, "425493": 39, "42550": 61, "426055": 39, "426540": 59, "426540301": 40, "426736": 61, "427": 61, "427486": [48, 49], "42755087": 65, "427551": 65, "427573": 59, "427725": 64, "428": [89, 99, 105], "428046": 63, "42811700": 105, "428255": 64, "428411": [60, 61], "428467": 64, "4284675": 64, "428771": [14, 72], "4290": 39, "429057": 49, "429230": 48, "429705": 48, "42ba": 42, "43": [41, 45, 48, 49, 72, 73, 74, 75, 89, 105], "430298e": [60, 61], "430595": 49, "430608": 48, "431061e": 48, "4311947070055128": 73, "431253": 58, "431306": 64, "431701914": 100, "431998": 45, "432125e": 60, "432300e": 64, "43231359e": 75, "43294": 42, "432f": 42, "433": 42, "433221": 50, "4335858": 75, "4336": 61, "43374433": 67, "433750": 48, "433753": 58, "4339": 39, "434121": 58, "434519": 72, "434535": 64, "43453524": 64, "435": 42, "43503345": 74, "43511": 61, "435401": 59, "4357": 61, "435927": 61, "435967": 59, "43597565": 64, "435976": 64, "436": [42, 61], "436016": 58, "43627032": 51, "436327": 61, "436394": 58, "436806": 61, "436817": 58, "437767": 60, "437924": 61, "438": 59, "438219": 64, "438289": 61, "438569": 61, "438578e": 61, "438709": 60, "43883": 55, "438834": 49, "4389": 61, "438960": 59, "439401e": 49, "439541": [60, 61], "439699": 45, "43989": 72, "439958": 58, "43f0": 42, "44": [45, 48, 49, 51, 72, 73, 74, 75, 89], "440320": 61, "440364": 72, "440605": 73, "440747": 48, "440a": 42, "441153": 64, "441209": 64, "441219": 54, "44124313": 74, "441282": 48, "4416552": 40, "441676": 45, "441849": 48, "443016": 50, "443032": 60, "44312177": 41, "443686": 64, "4437": 61, "443701": 56, "444046": 61, "4444": [38, 40, 47, 74], "444500": [60, 61], "444850": 61, "4449272": 61, "445476": 48, "44563945e": 75, "4461928741399595": 50, "446193": 50, "4462": 42, "44647451": 65, "44713577e": 75, "447492": 61, "447624": [48, 49], "447706": 50, "447849": 51, "448": 61, "448252": 49, "448456e": 49, "448569": 48, "448587": 50, "448745": 64, "448842": 49, "4489": 61, "44890536": 75, "448923": 56, "449107": 6, "449150": [14, 72], "44950": 61, "44fa97767be8": 42, "45": [45, 48, 49, 50, 54, 56, 58, 60, 61, 64, 72, 73, 74, 75, 89, 105], "4500": 60, "45000000000000007": [50, 61, 64, 73], "450031": 58, "450152": 59, "450812e": 49, "450870601": 40, "451312e": 48, "452": 42, "452091": 61, "452114": 72, "45244377": 75, "452488701": 40, "452489": 59, "452623": 49, "453": 42, "453279": 48, "4535": 61, "4539": 42, "454081": 61, "454397": 64, "454406": 45, "45467447": 75, "455": 42, "45500": 61, "455078": 50, "455091": 49, "455107": 50, "455120": 64, "4552": 42, "455293": 50, "4552b8af": 42, "455448": 65, "455672": 61, "455981": 90, "4563111": 75, "456370": 59, "456458e": 48, "456552": 72, "4566031": 89, "45660310": 89, "4567": 65, "456892": 50, "457088": 64, "457667": 61, "458114": 61, "458307": 92, "458420": 61, "4584447": 40, "458784": 48, "458855": 41, "4592": 40, "459200": 59, "459383": 50, "459418": 49, "459436": 58, "45957837": 75, "459760": 61, "459812": 50, "46": [45, 48, 49, 56, 57, 62, 72, 73, 74, 75, 89, 99, 105], "460": 61, "4601": 61, "460207": [48, 49], "460218": 50, "460289": 64, "460535": 72, "4610": 105, "461227e": 48, "461629": 66, "461646": 45, "462321": 12, "462451": 50, "462567": 49, "462979": 48, "463325": 64, "4634": 61, "463418": 66, "463668": 61, "463766": 55, "463857": 61, "463903": 49, "463b": 42, "464076": 50, "464284": 59, "46448227": 75, "464668": [10, 72], "465": 45, "46507214": 65, "465424": 58, "465649": 66, "465730": 66, "4659651": 68, "465965114589023": 68, "4659651145890230": 68, "466047": 64, "46618738": 75, "466440": 50, "466756": 64, "467": 61, "46709481": 75, "46722576e": 75, "467613": 59, "467613401": 40, "467681": [48, 49], "467770": 50, "468072": 49, "468075": 64, "46807543": 64, "46811985": 64, "468120": 64, "468406": 61, "468907": 45, "468919": 61, "468d": 42, "469": 42, "469474": 66, "46961915": 75, "469825": 50, "469895": 49, "469905": 49, "47": [41, 45, 48, 49, 51, 60, 65, 72, 73, 74, 75, 89, 104, 105], "470055": 49, "470904": 48, "471": 45, "471622": 48, "471911748": 75, "472": 61, "47222159": 67, "472255": 61, "472699": 49, "472891": 64, "472e": 42, "473099": 50, "47319": 74, "47419634": 102, "474214": [54, 55], "474731": 72, "474846": 60, "475304": 61, "475517": 58, "475569": 48, "476856": 50, "477130": [48, 49], "477150": 64, "477247": 49, "477474": 59, "47759584": 75, "47761563": 51, "478032": 61, "478059": 49, "478064": 49, "4781": 61, "478427517": 75, "47857478": 75, "479655": 58, "47966100e": 75, "479722": 49, "479860": 61, "479876": [54, 55], "479882": 49, "479928": 64, "47be": 42, "48": [42, 45, 48, 49, 55, 60, 61, 72, 73, 74, 75, 89, 105], "480": 45, "480133e": 64, "48029755": 65, "480579": 49, "48069071": [68, 76, 89], "480691": [76, 89], "480800e": 64, "481172": 64, "481218": 61, "481399": [60, 61], "48162028314142495863647273798084859499": 75, "481705": 74, "481761e": 61, "482": [42, 45], "482012": 54, "482038": 50, "48208358": 64, "482084": 64, "482179": 48, "482461": [90, 95], "48246134": [90, 95], "482483": 64, "482616": 58, "482790": 52, "482898e": 49, "48296": 65, "483": 74, "48315": 65, "483186": 52, "483192": [60, 61], "48331": 65, "4835": 61, "483711": 64, "483717": 50, "48390784": 74, "48404": 40, "484303": 49, "4845": 61, "484640": 64, "4849": 42, "485": [42, 61], "485197": 48, "48550": 66, "485617": [60, 61], "485812e": 61, "48583": [60, 61], "485871": 55, "486": [25, 61], "486178e": 48, "486202": 50, "486532": 64, "48661": 61, "487": [45, 61], "487467": 61, "487641e": 64, "487793": 49, "487872": 46, "488": 105, "488394": 48, "488460": 61, "488485": 61, "48873663": 51, "488811": 64, "488909": [60, 61], "488982e": 50, "4895498": 64, "489550": 64, "489699": 50, "489951": 49, "49": [42, 45, 48, 49, 60, 62, 72, 73, 74, 75, 89, 105], "490000e": 61, "490070931": 40, "490488e": 60, "490504e": 61, "490700": 64, "490941": 61, "491034": 48, "491245": 59, "49135": 15, "4915707": 74, "492": 61, "4923156": 68, "49231564722955": 68, "492315647229550": 68, "492417e": 74, "492656": 49, "49270769e": 75, "493": [74, 103], "493102e": 58, "493144": 66, "493219": 64, "493313": 61, "493325": 5, "494089": 49, "494129": 64, "494324": 59, "494324401": 40, "495": 63, "495108": 58, "49530782": 40, "495657": 50, "495752": 64, "49596416e": 75, "496": 63, "49650883": 65, "496551": 64, "496714": 66, "496777": 105, "49693": 73, "497": 63, "497100": 62, "497168": 58, "497298": 72, "497422": 49, "497655": 6, "497674": 51, "497840": 62, "497964": 72, "498": 63, "498286": 58, "498921": 64, "498979": 61, "498992": 48, "498f": 42, "499": [61, 63, 70, 102], "499000e": [60, 61], "499776": 61, "49d4": 42, "4a53": 42, "4b8f": 42, "4dba": 42, "4dd2": 42, "4e": [40, 41], "4ecd": 42, "4fee": 42, "4x": 64, "4x_0": [21, 48, 49, 54, 55], "4x_1": [21, 48, 49], "5": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 101, 102, 104], "50": [14, 40, 42, 50, 52, 55, 57, 58, 60, 61, 62, 64, 72, 73, 74, 75, 89], "500": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 22, 23, 27, 34, 38, 42, 43, 47, 48, 49, 54, 55, 57, 60, 63, 65, 69, 70, 72, 73, 74, 76, 89, 90, 95, 99, 102, 105], "5000": [48, 49, 50, 64], "50000": 59, "500000": [60, 61], "5000000000000001": [50, 61, 64], "500084": 64, "500267": 56, "5003517412": 40, "500517": 64, "50093148e": 75, "501021": 61, "501047e": 48, "501983": 64, "502016": 58, "502084": 74, "502160": 62, "502205": 48, "502494": 50, "5025850": 40, "502595": 49, "502612": 64, "502900": 62, "502901": 49, "502995": 64, "503374": 58, "503504": 73, "503511": 61, "503700": 45, "50398782e": 75, "504286": 59, "5042861": 40, "504548e": 49, "505": 37, "5050973": 40, "505264": 48, "505353": 49, "505729": 62, "506050": 48, "50635": 62, "506644": 48, "506659": 61, "506687": 61, "50672034": 40, "506900e": 64, "506903": 50, "50768b": 62, "508153": 63, "5082378": 75, "508433": 48, "508459": 59, "5085": 61, "508947": 74, "509059": 61, "509196": 64, "509461": 64, "50967": 66, "5097": 66, "5098": [43, 70, 102], "509853": 64, "5099": [42, 43, 70, 102], "509951": 50, "509958": 59, "51": [39, 41, 42, 54, 58, 72, 73, 74, 75, 89, 104], "510": 75, "510000e": [60, 61], "510121": 48, "510385": 59, "510555": 45, "51079110": 40, "510982": 60, "511022": 72, "511257": 58, "511293": 60, "51143117": 75, "511515": 61, "511540": 61, "5115547": 68, "5115547181877": 68, "51155471818770": 68, "511665": 48, "511668": 66, "5116683753999614": 66, "511862": 64, "512": 59, "512108": 64, "512149": 64, "51214922": 64, "51243406e": 75, "512519": 59, "512572": 64, "512672": [74, 90, 95], "5131": 60, "513992": 64, "514": 42, "514173": 49, "514545": 61, "515031": 48, "515338e": 48, "515358": 50, "5154": 61, "5154789948092002": 59, "5155": 42, "515672": 49, "515950": 74, "516": 42, "516125": 50, "516222": 64, "516242": 49, "516255": 64, "516256": 64, "516528": 64, "516797": 49, "516945": 45, "517": [42, 59], "517279": 49, "5175": 61, "517753": 48, "518175": 59, "518375": 49, "518446": 61, "518478": 45, "518782": 61, "518846": 59, "51966955": 40, "519710": 64, "52": [39, 42, 56, 58, 72, 73, 74, 75, 89], "520": 61, "520415": 48, "520641": 65, "520930": 50, "521002": 50, "521085": 72, "521233": 45, "521611": 49, "521632": 48, "521788": 48, "522": 37, "522753": 11, "522835": 52, "523030": 66, "523163": 50, "5232": 57, "52343523e": 75, "523794e": 64, "523807": 63, "523977545": 40, "52424539": 40, "524657": 64, "524934": [48, 49], "5250": 61, "525064": 45, "52510803": 41, "5251546891842586": 66, "5255": 42, "525722": 48, "52590": [41, 60], "526": 59, "526102": 74, "526532": 61, "526769": [48, 49], "526984": 49, "527226": 48, "52732": 73, "527452": 49, "52747392": 75, "527540": 48, "528381e": 67, "528580": 64, "528763": 49, "528937": [54, 55], "528996901": 40, "528997": 59, "529": 59, "529405": 39, "529782": 39, "53": [39, 42, 45, 70, 72, 73, 74, 75, 89, 100, 103, 105], "530793": 48, "530940": 64, "53094017": 64, "530981129": 75, "531": 42, "531223": 50, "531594": 61, "53209683": 74, "532266": 50, "53257": 73, "532738": 64, "53273833": 64, "532751": 54, "5329": 61, "533489": 52, "533900": 64, "5346": 42, "535179": 64, "535318": 64, "535609": 61, "535718e": 61, "53606675": 64, "536067": 64, "536082": 45, "536143": 61, "536219": 45, "536746": 64, "536778e": 49, "536798e": [60, 61], "537240": 64, "53724023": 64, "5374188": 75, "53791422": 74, "538": [37, 42], "538013": 61, "538105": 49, "5382": 65, "538937": [60, 61], "539455": 64, "539475": 64, "53947541": 64, "539491": [54, 55], "539767": 50, "54": [39, 41, 42, 51, 69, 72, 73, 74, 75, 89, 104], "540": 62, "540240": 61, "540542": 60, "5408": 39, "541159": 64, "54163": 65, "5416844": 68, "541684435562712": 68, "541821": 61, "541990": 61, "542136": 48, "542159": 49, "542170": 49, "542333": 61, "54242696": 75, "542446": 55, "542451": 64, "542560": 66, "542584": 50, "5425843074324594": 50, "542647": 64, "542671": 59, "542816": 12, "542883": [90, 95], "5428834": [90, 95], "542919": 72, "542989": 64, "543": [59, 61], "543075": 50, "543136": 50, "543358": 72, "543380": 59, "5434231": 68, "543423145188043": 68, "5436005": 40, "543691": 49, "543764": 55, "54378": 65, "543832": 64, "544097": 64, "5441532": 75, "544383": 66, "544555": 59, "5445840": 75, "544669": 54, "54483": [76, 89], "5448331": [76, 89], "54517706e": 75, "545492": 45, "545605e": 64, "545919": 61, "546266": 45, "546294": 61, "5467606094959261": 50, "546761": 50, "546953": 49, "547039": 48, "54716": 65, "547324": 49, "547431": 63, "5476": 61, "5479": 61, "547909": 61, "549109e": 61, "549645": 72, "55": [37, 41, 42, 50, 60, 61, 64, 72, 73, 74, 75, 89], "5500000000000002": [50, 61, 64], "550242": 58, "551317": 49, "551586928482123": 50, "551587": 50, "5516139": 75, "551686": 50, "55176": 73, "5518": 61, "552": 61, "552058": 65, "552508": 61, "552694e": 48, "552727": 59, "552776": 64, "553004": 45, "55307": 73, "553522": 49, "553878": [13, 72], "553916": 61, "554": 37, "554076": 50, "554793e": 75, "555": 59, "555137": 49, "555150": 61, "555445": 63, "555498": 64, "5555": [38, 47], "555536": 48, "555949e": 61, "555954": 61, "556191": [48, 49], "556792": 64, "5574dcd4": 42, "557595": 59, "557731": 63, "557999": 59, "558134": [48, 49], "5584": 59, "5585": 59, "55863386": 74, "558655": 50, "5589": 59, "559": 105, "5590": 59, "559144": 50, "559186": 50, "5592": 59, "559394": 64, "559522": 64, "559592e": 48, "559680": 61, "55980336": 75, "55dc37e31fb1": 42, "55e": 41, "56": [37, 42, 69, 72, 73, 74, 75, 89, 100, 103], "560135": [76, 89], "56018481": 64, "560185": 64, "5602727": 51, "560530": 49, "560689": 39, "560723": 56, "561348": 49, "5616": 60, "561711": 61, "561785": 74, "562013": 64, "56223": 65, "562288": 66, "562452": 58, "562518": 61, "5625561": 39, "562712": [48, 49], "563374e": 50, "563503": 64, "563528": 61, "563673": 61, "56387280e": 75, "56390147e": 75, "564045": 64, "564073": 61, "5641": 61, "564142": 50, "564232": [48, 49], "564451": 49, "564577": 61, "565066": 50, "565373": 48, "566": 66, "566024": 64, "566091": 61, "566388": 48, "567004": 65, "567215": 58, "567343": 61, "567364": 49, "567529": 64, "567695": 48, "567945": [54, 55], "568111": 72, "569315e": 49, "569444": 45, "569540": 49, "569590": 58, "56965663": 64, "569657": 64, "569911": 40, "5699994715": 40, "57": [42, 72, 73, 74, 75, 89, 105], "570038": 50, "5700384030890744": 50, "570111": 63, "5702": 61, "570486": 39, "570562": 39, "570722": 102, "570936": 48, "571707": 72, "571778": 39, "5718": 61, "572153": 72, "5722": 60, "572408e": 49, "57245066": 64, "572451": 64, "572991": 49, "573700": 52, "574": 42, "5748": 73, "57496671": 40, "575": 17, "57572422": 65, "575810": 48, "57585824": 65, "57592948e": 75, "57599221": 65, "576": 42, "5763996": 40, "57643609": 65, "577": 42, "5770": 60, "57715074": 40, "577271": 59, "577273": 48, "577647": 45, "5776971": 65, "57775704": 65, "577807": [48, 49], "577813": 48, "578081": 61, "578307": 64, "578523": 59, "578557": 49, "578846e": 50, "57914935": 41, "579213": 66, "579238": 50, "579322e": 60, "579875e": 48, "57e": 41, "58": [18, 41, 60, 66, 72, 73, 74, 75, 89, 104], "580": 37, "5800": 61, "58000": 60, "5804": 42, "580414": 66, "580853": 48, "580922": 54, "581655": 61, "581827": 58, "581849": 49, "581896": 45, "582146": 49, "58241568": 75, "582761": 50, "583034": 54, "583195": [48, 49], "583201": 49, "5833333": 42, "583404": 60, "583534": 64, "583692": 58, "584012": 61, "584057e": 48, "584742": 55, "584849": 50, "584928": 48, "584942e": 59, "5852": 61, "585426": 75, "585793": 50, "5862232": 75, "586362": 64, "5864": 39, "586475": 62, "5866": 61, "586719": 50, "586719493648897": 50, "586794": 48, "5868472": 40, "586921": 58, "587": 105, "587135": 49, "587292": 61, "58729768": 75, "588": 61, "588000": 72, "58812": 73, "588233": 48, "588364": 72, "588854": 48, "589147e": 58, "589248": 65, "589440": 50, "589958": 49, "59": [49, 72, 73, 74, 75, 89], "590320": 52, "5905": 60, "590736": 64, "590813": 64, "590904": 49, "590911": 50, "590991": 50, "591080": 52, "591411": 54, "591441": 3, "591741": 60, "591782": 64, "591788": 60, "59199423e": 75, "592186": 49, "592681e": 50, "59307502e": 75, "593648": 73, "593981": 72, "594": 17, "594241": 72, "594316e": 64, "595353": 50, "596": 61, "596069e": 61, "5962": 60, "596270": [54, 55], "5964": 57, "596460": 49, "596758": 48, "597": 41, "597098": 61, "597923": 61, "598178": 61, "59854797": 74, "5985730": 41, "59861": 61, "598761e": 49, "599208": 45, "599297": 74, "5cb31a99b9cc": 42, "5d": [50, 64], "5x_2": 52, "5x_3": 52, "5z_i": 64, "6": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 24, 25, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 100, 102, 103, 104], "60": [40, 50, 51, 61, 62, 64, 67, 72, 73, 74, 75, 89, 103], "600": 59, "6000": 61, "6000000000000002": [50, 61, 64], "600000e": 61, "600195": 48, "600254": 63, "600694": 74, "600776": 45, "600934": 72, "601": 41, "601061": 50, "601598": 59, "601783e": 49, "601984": 49, "602079": 55, "602168": 50, "602386e": 48, "602492": 48, "602587": 64, "602628": 50, "6029": 61, "604016": 61, "604111": 61, "604227": 60, "604603": 6, "604825": 61, "604841": [60, 61], "605": 61, "605195": 55, "606034": 64, "606129": 64, "606342": 50, "606759": 61, "6068": 40, "606800": 59, "606954": 50, "607264": 48, "6075": 105, "607600": 61, "607900e": 49, "608": 53, "608392": 64, "60857": 39, "608818": 65, "609522": 58, "609575": 74, "61": [72, 73, 74, 75, 89, 104], "611": 105, "6110": 61, "611269": 59, "611859": 55, "612792": 61, "613244": 49, "6133": 41, "613314": 50, "613408": 64, "613498": 61, "613574": 56, "613622": 49, "613691": 74, "614188": 59, "614201": 45, "614678": 61, "615": 45, "615498": 3, "615863": [54, 55], "616617": 49, "61669761": [90, 95], "616698": [90, 95], "616828": 61, "617": 59, "617283": 61, "6173": 42, "617877": 64, "618069": 60, "61810738": 41, "618574": 49, "618776": 51, "618881": 49, "619128": 49, "619177": 60, "619351": [48, 49], "619390": [48, 49], "619454": 52, "619613": 60, "619903": 49, "61e": [41, 105], "62": [3, 55, 56, 72, 73, 74, 75, 89], "620156": 64, "620874e": 74, "620995": 67, "621094": 61, "621318": 64, "62131806": 64, "621490": 64, "6215": 60, "621902": 45, "622": 61, "622153": 61, "622272": 45, "6224": 40, "622750": 45, "623024": 50, "623173": 48, "623197": 60, "624": 59, "6240": 65, "62403053": 51, "6243811": 40, "624535": 73, "624764": 49, "624798": 60, "624818": 49, "624919": 61, "624988": 61, "625": [40, 59], "625159": 56, "625183": 45, "625477": 64, "625766": 54, "625767": 48, "625891": [54, 55], "626433": 64, "6266": 61, "626633": 49, "627505": [54, 55], "627560": 64, "627564": 50, "627588e": 61, "628069": 59, "629346": 61, "629549": 49, "629595": 15, "629740": 48, "63": [40, 59, 72, 73, 74, 75, 89, 103, 104], "630150e": 64, "630914": 56, "631083": 49, "631333": 64, "6318": [60, 105], "632058": 59, "63245862e": 75, "632747e": 64, "632958": 63, "6330631": 89, "633433": 59, "63407762": 105, "634078": [60, 105], "634577": 89, "63499": 61, "635000e": [60, 61], "635199": [60, 61], "635768": 48, "63593298": 74, "636048": 74, "636453": [10, 72], "636575": 50, "637326": 64, "6379": 60, "638264": 64, "638461": 58, "638488": 56, "639135": 59, "63916605": 41, "639345": 61, "639580": 49, "639603": 49, "64": [55, 60, 61, 72, 73, 74, 75, 89, 102], "640": 61, "640334": 45, "640900": 61, "641528": 64, "641547": 64, "64154727": 64, "64197957": 64, "641980": 64, "6420": 61, "642016": 64, "642329": 45, "64269": 65, "642735": 60, "643133": 61, "64340": 65, "643512": 50, "643752": 64, "644113": 72, "644182": 72, "644371": 49, "644665": 50, "64476745e": 75, "644799": 52, "644985": 48, "645": [37, 61], "645583": 45, "64579": 39, "6458": 40, "645800": 59, "646117": 49, "646937": 52, "647002": 61, "647004": 74, "647010": 61, "647196": 52, "64723": 65, "647254e": 48, "647689": 66, "647873": 64, "64797": 65, "648355": 48, "648690": 49, "648769": 49, "649": 103, "649158": 64, "649514": 48, "649738": 48, "65": [50, 56, 61, 64, 72, 73, 74, 75, 89], "650": 53, "6500000000000001": [50, 61, 64], "650000e": 61, "650234": 45, "650810": 61, "650867": 50, "651127": 49, "652071": 61, "6522": 103, "652312": 54, "652349": 64, "652350": 59, "652450e": [60, 61], "6527": 53, "652778": 59, "6528": 61, "653": 75, "6530": 61, "653820": 72, "653846": 50, "653901": [48, 49], "653991": 72, "654070e": 74, "654755": 52, "65488831": 75, "655284": 64, "6553": 105, "6554": 103, "655422": 61, "655547": 48, "65557405e": 75, "657": 42, "658": 59, "658267": 64, "658592": 49, "6586": 39, "658702": 49, "659": 42, "659245": [48, 49], "659339": 49, "659361": 45, "6593871": 39, "659423": [48, 49], "659473": 66, "659636": 50, "659735": 48, "6598": 57, "659835": 49, "65e": 75, "66": [45, 57, 62, 72, 73, 74, 75, 89, 102, 104], "660": 42, "660073": 49, "660320": 55, "660479": 74, "660776": 64, "661": 37, "66133": 74, "661369": 63, "661388": 48, "6625": 61, "662975": 58, "663081975281988": 50, "663082": 50, "663182": 50, "6634357241067617": 66, "663529": 64, "663533": 61, "663765": 49, "664103e": 61, "664147": 61, "664276": [72, 73], "664409": 49, "664797": 48, "664824": 61, "664850": 59, "665264": 64, "6658149": 75, "66601815": 74, "666104": 64, "666307": 52, "666599": 62, "6666667": 42, "667": 59, "667492e": 61, "667536": 64, "667614": 50, "667614205604159": 50, "667981": 48, "667985": 56, "668337": 61, "668452": 56, "668584": 52, "668981": 54, "669579": 49, "66989604": 51, "67": [37, 42, 60, 66, 72, 73, 74, 75, 89, 102], "670785": 45, "670867": [14, 72], "67122126323339435054596667718388919296": 75, "6712212632333943505459666771838891929648162028314142495863647273798084859499213192225303752535657606570778990959710035141524273438404447515568747881869398": 75, "671224": 49, "671271": [48, 49], "67136": 61, "6716717587835648": 50, "671672": 50, "67168779": 75, "671690": 48, "6722": 42, "672234": [48, 49], "672368": 50, "6723684718264447": 50, "672384": [48, 49], "67245350": 40, "672511": 48, "673092": [48, 49], "673302": 59, "673330": 49, "67410934": 40, "6745349414": 40, "674552": 61, "67456": 66, "674609": 50, "674747": 58, "674949e": 65, "675233": 49, "675293": 63, "675625": 72, "675775": 58, "676": 37, "676405": 50, "6765": [41, 60], "676534": 89, "676641": 48, "676756": 64, "676807": 60, "677123": 48, "677614": 64, "677980": 50, "678117": 61, "678826": 50, "67936506": 74, "6795": 60, "679539": 59, "679789e": 48, "67ad635a": 42, "68": [42, 45, 65, 72, 73, 74, 75, 89], "680": 61, "6810775": 65, "681176": 59, "681246": 49, "681448": 61, "681521": 48, "681562": 61, "681817dcfcda": 42, "682122": 58, "682269": 61, "6825281": 75, "682875": 50, "683487": 49, "683581": 74, "683687": 49, "683942": 64, "683984": 11, "684": 105, "68410364": 41, "68411700": [41, 105], "684128": 49, "684142": 48, "684502": 64, "685104": 5, "685107": 64, "68554404e": 75, "68562150e": 75, "685807": 64, "686270": 49, "686627": 48, "687345": 64, "687612": 49, "687647": 64, "687697": 45, "687854": 52, "687871": 59, "6878711": 40, "688": 103, "688641": 58, "688747": 61, "688887": 74, "688918": 61, "688956": 48, "689088": [48, 49], "689188": 52, "689392": 64, "689600": 58, "689932": 48, "69": [56, 72, 73, 74, 75, 89, 104], "690334": 50, "6903344145051182": 50, "691": 37, "691097": 48, "691136": 72, "691157": 51, "69140475e": 75, "691423": 48, "691511": 60, "691848e": 49, "691911": 72, "692297": 49, "692460": 58, "692579": 49, "692725": 64, "692907": 61, "692959": 48, "693316": 61, "693497e": 61, "693690": 61, "693796": 59, "694154": 50, "694845e": 61, "694919": 59, "6950": 61, "695045": 48, "69508862": 74, "695581": 56, "69562150e": 75, "695711": 58, "695928": 48, "696011": [13, 72], "696289": [54, 55], "696770": 72, "69684828": 74, "696966": 49, "697": 59, "697000": 50, "697420": [54, 55], "697545": 64, "697616": 49, "697693": 48, "698223": 52, "698244": 52, "69840389e": 75, "698509": 48, "698651": 45, "698694": 59, "698751": 58, "6988656": 75, "699035": 64, "699082": 50, "69921": 42, "699259e": 64, "699333": 50, "699543": 45, "699616": 58, "699697": 49, "6_design_1a": 53, "6_r2d_0": 53, "6_r2y_0": 53, "6b": [89, 99], "6cea": 42, "7": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 19, 20, 24, 27, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 102, 103, 104], "70": [41, 50, 54, 60, 61, 62, 64, 72, 73, 74, 75, 89, 104], "700": [48, 49, 53, 59], "7000000000000002": [50, 61, 64], "700015": 64, "700102": 64, "700458": 48, "70055207": 75, "701078": 64, "701088": 60, "701106": 56, "701265": 54, "701413": 61, "701672e": 50, "701841e": 55, "701866": 64, "7018663": 64, "701966": 61, "702489": 61, "703049": 48, "703772": 61, "703942": 72, "7040": 61, "704814": 48, "705090": 49, "705354": 48, "705581": 61, "7055958": 68, "705595810371231": 68, "7055958103712310": 68, "705794": 49, "70583": 65, "706056": 61, "706077": 49, "706122": 49, "706231": 72, "706430": 48, "706645": 50, "706657": 50, "706862": 6, "707125": 49, "707197": 72, "707441": 49, "707738": 49, "707868": 64, "707963e": 60, "708190": 59, "708235": 48, "708459": 64, "708472": 49, "708821": 45, "708837": 45, "709026": 52, "709596": 48, "709606": [14, 72], "71": [72, 73, 74, 75, 89, 104], "710": 37, "710059": 45, "710319": 49, "710515": 48, "710586e": 59, "711024": 61, "711328": 61, "711383e": 48, "711518": 61, "711638": 74, "712064": 48, "712082": 61, "712095": 45, "712157": 63, "712268": 48, "712372e": 49, "712503": 65, "712592": 60, "712774": 54, "712960": 50, "713": 61, "713407": 61, "713457": 48, "713986": 61, "713993": 49, "714240": 59, "714250": 49, "714534e": 49, "714651": 64, "71465114": 64, "715013": 61, "715180e": 61, "7154": 61, "715407": 50, "7155": 61, "7158581": 40, "716013e": 48, "7161": 61, "716387": 48, "716427e": 49, "716456": 64, "716595e": 61, "716762": 50, "716793": 50, "716799": 59, "7167991": 40, "716801": 58, "717": 61, "717130": 61, "717185": 64, "717860": 72, "718686": 66, "7193116": 75, "719552": 49, "72": [72, 73, 74, 75, 89, 104], "720559": 48, "720571": 64, "720573": 48, "720664": 59, "721018": 48, "721071": 64, "721245": 49, "7215093d9089": 42, "72155839e": 75, "721609": 61, "722316": 64, "722634": 64, "722848": 50, "722881": 64, "7229": 61, "723": 42, "723314": 64, "723345e": 64, "723657": 48, "723846": 45, "7239": 61, "7241399": 40, "724235": 62, "724338": 64, "724767": [54, 55], "724918": 66, "725": 42, "725061": 48, "725080": 45, "725087": 61, "725166": 64, "725565": 48, "725802": 6, "725820": 58, "725919": 48, "726": 42, "726658": 58, "7268131": 40, "727159e": 49, "727543": 52, "727693": 61, "727704": 61, "727976": 50, "7282094": 74, "728294": 63, "728710": 64, "728734": 45, "72875815e": 75, "728852": 61, "729867": 48, "73": [41, 45, 72, 73, 74, 75, 89], "730023": 61, "7308": 39, "730809": 48, "731174": 48, "731317": 50, "732067": 48, "732137": 48, "732150": 49, "732405": 60, "732586": 60, "7326": 61, "732638": 64, "73285": [10, 72], "732918": 54, "733": 61, "733047": 49, "733644": 48, "734278": 45, "734635": 48, "734770": 49, "734948": 64, "735369e": 72, "7357": 61, "735848": 72, "735941": 9, "735964": 52, "7360": 75, "736082": [48, 49], "736084": 64, "73608412": 64, "736823": 49, "737052": 61, "7375615": 41, "73764317e": 75, "737951": [48, 49], "738065": 49, "738223": 61, "738315": 61, "738659e": 61, "738793": 72, "738876": 49, "739": 61, "739063": 48, "7395359436844482": 50, "739536": 50, "739720": 61, "739817": 56, "74": [18, 41, 49, 60, 72, 73, 74, 75, 89, 104], "740": [59, 60], "740180e": 64, "740367": 48, "740417": 60, "740505": 45, "740785": 48, "740869": 50, "741104": 50, "741523": 45, "741702": 64, "7418": 39, "74189": 42, "742128": 64, "742375": 48, "742407": 63, "742411": 48, "742907": 64, "7432": 39, "743247": 61, "743341": 49, "743609": 48, "7437": 61, "74402577": 64, "744026": 64, "744236": 65, "74461783e": 75, "745": 61, "745022": 45, "745444": 48, "745714": 60, "745881": 48, "746": 62, "746361": 64, "746843": 55, "7470": 61, "747646": 61, "747945": 40, "747961": 61, "748084": 49, "748377": 60, "748513": 61, "748880": 61, "74938952": 74, "749443": 61, "749854893": 76, "75": [14, 18, 20, 42, 45, 50, 52, 60, 61, 64, 72, 73, 74, 75, 89, 99, 104], "75000": 66, "7500000000000002": [50, 61, 64], "750000e": 61, "750597": 49, "750701": 45, "751013": 61, "751261": 61, "751633": 61, "75171": 60, "751710": [50, 60], "751712655588833": 68, "7517126555888330": 68, "751712656": 68, "752015": 8, "752283": 61, "752831": 62, "7533": 60, "753323": 48, "753393": 48, "753523": 64, "753866": 49, "754469": 48, "754499": 49, "754678": 58, "7548": 66, "754870": 59, "755": 60, "755688": 48, "755701e": 48, "755910": 61, "7559417564883749": 50, "755942": 50, "7560824": 40, "756200": 45, "756805": 59, "756867e": 61, "756905": 6, "756969": 50, "757": 103, "757151": [48, 49], "757183": 50, "757411": 64, "757819": 59, "757917e": 64, "758391": 61, "758831": 49, "75887": 42, "759006": 51, "759054": 49, "759833": 49, "76": [72, 73, 74, 75, 89, 103, 104], "760104": 64, "7603": 39, "760386": 74, "760778": 59, "760915": 52, "761": [40, 59], "761429": 49, "761714": 50, "762284": 64, "76228406": 64, "762748": 61, "763691": 61, "764093": [48, 49], "76419024e": 75, "764315": 64, "76444177e": 75, "764478": 63, "7646": 61, "764798": 64, "764953": 60, "765": 60, "765202": 61, "765363": [48, 49], "765478310": 75, "765500e": [60, 61], "765710e": 67, "765792": 64, "765864": 65, "76591188": 40, "765960": 48, "7660": 39, "7663": 61, "766499": 64, "766940": 45, "76702611e": 75, "767188": [54, 55], "767247": 72, "767349": 72, "767435": 66, "767549": 49, "767616": 45, "768071": 64, "768273": [54, 55], "768763": 49, "768798": 45, "769361": 64, "769805": 64, "77": [72, 73, 74, 75, 89], "770556": 61, "770944": [54, 55], "7710": 65, "771157": 89, "771390e": 61, "7714": 62, "7716982": 41, "771741": 61, "771965": 61, "772104": 48, "77227783e": 75, "772396": 49, "772791": 61, "77289874e": 75, "773": 42, "773177": 50, "773488": 64, "77348822": 64, "773769": 58, "77401500e": 75, "774271e": 61, "775": [42, 61], "775191": [48, 49], "775285": 48, "775969": 65, "776254e": 48, "7763": 60, "776728e": 59, "776887": 60, "7776071": 40, "777718": 58, "777728": 72, "778": 37, "778400": 48, "778485": 62, "7786": 39, "778852": 72, "779108": 48, "779167": 3, "779517": [48, 49], "779682": 50, "7799": 57, "779912": 61, "78": [72, 73, 74, 75, 89, 104], "780": 42, "780068": 58, "780338": 48, "780458": 64, "780857": 60, "781": 61, "781233": 61, "781530": 64, "781681": 64, "782": 42, "782050": 64, "782117": 45, "782555": 61, "782646": 72, "783": [42, 105], "783276": 74, "7833": 39, "783749701": 75, "7838": 39, "784": [89, 99], "784238": 59, "784310": 62, "784405": 65, "784483": 59, "784624": 50, "784792": 58, "785": 42, "785038": 49, "785153": 49, "785815": 45, "785911": 64, "786": 42, "786090": 58, "786237": 48, "786563": 58, "786744": 50, "78711285e": 75, "78777": 65, "788": 103, "78818": 42, "788868": 49, "789032": 48, "789039": 49, "789330": 49, "789671": 50, "789671060840732": 50, "79": [45, 72, 73, 74, 75, 104], "790039e": 48, "790115": 61, "790261": 72, "790723": [54, 55], "79122": 60, "791220": 60, "791241": 64, "791297": [14, 72], "792939": 50, "793316": 72, "79338596e": 75, "793570": 64, "793598": 49, "793735": 64, "793818": [48, 49], "794": 74, "794366": 61, "79458848e": 75, "794805": 54, "795647": 64, "7957": 61, "795932": 73, "796014": 49, "796203": 74, "796384": 49, "796444": 61, "796596e": 48, "797086": 48, "797157": 45, "797280": 64, "797737": 89, "797868": 49, "79792890e": 75, "797965": 89, "798071": 5, "798309": 60, "798783": [54, 55], "799403": 64, "7999": 67, "7b428990": 42, "7x": 64, "8": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 35, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 102, 104, 105], "80": [50, 51, 61, 64, 67, 72, 73, 74, 75, 104], "800": 59, "8000": [29, 67], "8000000000000002": [50, 61, 64], "800143": 48, "800272": 72, "800326e": 48, "800351": 48, "801623": 61, "802289": 61, "803112": 58, "803300": 48, "803492e": 64, "803563": 61, "80383217": 75, "803902e": 61, "804": 61, "804139": 62, "804219": 64, "804284": 65, "804316": 64, "804484": 64, "8048": 41, "804828": 64, "804889": 61, "805": 37, "805007": 59, "805153e": [60, 61], "805293": 49, "8055563": 40, "805774": 48, "8059": 60, "806218e": 61, "806531": 61, "806554": 48, "80696592e": 75, "80714504e": 75, "807853": 62, "807879": 64, "808": [41, 89, 99], "808246": 60, "808284": 61, "808640": 61, "809125": 48, "8095": 62, "809913": [48, 49], "80a8": 42, "81": [40, 48, 53, 56, 57, 72, 73, 74, 75, 104], "810044": 60, "810134": 64, "8102": [39, 60], "810306": 45, "810322": 48, "810363": 61, "810382": [60, 61], "810419": 49, "810707": 61, "810895": 49, "811011": 49, "811155": 56, "811398": 72, "811513": 49, "8116912": [89, 99], "811696": 48, "811825": 59, "811901": 64, "81190107": 64, "8132463": 40, "813293": 64, "813342": [89, 99], "813682": 61, "814136": 50, "814246e": 49, "814351": 50, "814913": 59, "8152": 61, "815213e": 49, "815224": [89, 99], "815226": 74, "81568484": 64, "815685": 64, "815993": 64, "816176": 66, "816318": 59, "816373": 48, "816645": 45, "816752": 61, "816982": 48, "817119": 48, "817291": 61, "8173602": 57, "817628": 74, "81827267": 64, "818273": 64, "818289": 64, "81828926": 64, "818313": 45, "818380": [48, 49], "81856": 42, "819507": 58, "82": [66, 72, 73, 74, 75, 104], "8202": 41, "820366": 59, "8209": 41, "820963": 45, "8210": 41, "821021": 50, "821457": 61, "821566": 64, "821855": 72, "821970": 58, "821995": 49, "822": 105, "8221": 39, "822289": [60, 105], "82228913": 105, "822482": 50, "8227": 61, "822822": 50, "823247": 64, "823273": [48, 49], "824350": [48, 49], "824657": 58, "824701": 50, "824750": 50, "824889": 50, "824961e": 61, "8250": 39, "825587": 49, "825617": 59, "825801": 45, "825862": 64, "825980": 50, "8259803249536914": 50, "8260": 60, "826065": [48, 49], "826426": 74, "826467e": 48, "826492": 64, "826519": [14, 72], "82666866e": 75, "82684324": 65, "827375": 51, "827381": 64, "827445": 45, "827735": 64, "827938162750831": [54, 55], "828058": 61, "828157": 45, "828778e": 48, "828912": 48, "828915": [54, 55], "829162": 72, "829543": 50, "829730e": 49, "82985": 56, "83": [72, 73, 74, 75, 104], "830263": 58, "830301": 63, "830442": 48, "830467": 48, "830755e": 56, "831019": 50, "831190": 49, "831278": 48, "831396": 62, "831741": 48, "832078": 45, "832086": 64, "8326928": 65, "832693": 65, "832875": 64, "83287529": 64, "833": 62, "833024": 59, "833227e": 73, "833464": 61, "833907": 59, "8350": 61, "835035": 58, "835596": 61, "835822": 45, "835935": 49, "836234": 74, "838114": 64, "838235": 62, "838457": 61, "83905": 5, "84": [42, 56, 72, 73, 74, 75, 104], "840041": 61, "840303": 64, "84030318": 64, "840673": 48, "840718": 74, "8407599": 75, "840836": 64, "840995e": 60, "841": [40, 59], "841132": 60, "8415": 41, "841847": 61, "842": 37, "842132": 74, "842405": 50, "842589": 45, "842625": 59, "842746": 64, "8428": 60, "842853": 64, "843730": 59, "843796": 48, "8440": 61, "844107e": 49, "844308": 64, "844549": [54, 55], "844667": 89, "844707": 64, "844889": 59, "845534": 58, "846388": 50, "847029": 49, "847555": 48, "847595": [13, 72], "847948": 50, "847962": 48, "847966": 61, "848688e": 58, "848757e": 60, "848868": 50, "849245": 45, "84930915e": 75, "849747": 65, "8497f641": 42, "8499": 61, "85": [23, 50, 56, 61, 64, 67, 72, 73, 74, 75], "8500000000000002": [50, 61, 64], "850038": 45, "850321": 59, "850439": 49, "850575": [48, 49], "850794": 64, "851198": 61, "8513": 42, "851366": 59, "852": 61, "85265193": 57, "85280376": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "85397773": 74, "855035": 48, "855780": 64, "855862": 49, "856404": 55, "8571": 39, "857161": 64, "857294": 45, "857544": 59, "857765": 61, "858212e": 49, "859": 61, "85911521e": 75, "85912862": 89, "859129": [76, 89], "85974356": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "85c5": 42, "85e": 41, "86": [72, 73, 74, 75, 104], "860663": [89, 99], "860804": 64, "860992": 61, "861519": 48, "86174649": 75, "862043": [54, 55], "862359": 50, "863772": 60, "863982270": 76, "86415573": 41, "86424193e": 75, "8644": 42, "864741e": 61, "865074": 45, "865313": 61, "865562": [48, 49], "865854": 61, "865860": [60, 61], "865914": 49, "866102": [48, 49], "866179899731091": 68, "866179900": 68, "866579": 61, "866798": 61, "867": 37, "867201": 58, "867565": 64, "8679": 61, "868": 42, "8685788": 64, "868579": 64, "8688": 60, "869": 42, "869020": 50, "869195": 49, "869398": 49, "869477": 48, "869586": 56, "87": [41, 48, 56, 59, 72, 73, 74, 75, 104], "8700": 41, "870099": [54, 55], "870142": 74, "870260": 64, "870332": 64, "870857": 64, "871": 42, "871545e": 48, "871923": 49, "872132": 49, "872222": 61, "872727": 48, "872768": 64, "872852": 64, "87290240e": 75, "872994": 61, "873198": 61, "873677": [54, 55], "87384812361": 39, "87384812362": 39, "87430335": [89, 99], "874303353": [89, 99], "874702": [54, 55], "8750": 61, "8759": 61, "876083": 61, "87623301": 39, "876431e": 50, "876549": 61, "87674597e": 75, "8768": 39, "8771": 61, "877153": 61, "877455": 63, "877833": [48, 49], "878281": 64, "878289": 61, "878402": 48, "878746": 45, "878847e": 61, "878968e": 48, "879049": 61, "879058": 58, "879103": 50, "879509": 48, "87e": [41, 75], "88": [41, 56, 72, 74, 75], "880": 105, "880106": 59, "880579": 64, "880591": 63, "880808e": 61, "880880e": 61, "880886": 60, "8810": 60, "881201": 61, "88125046e": 75, "881465": 52, "881581": 9, "88173062": 40, "881937": 45, "882475": 50, "883485": 49, "883622": 64, "883914": 50, "883953": 58, "884132": 64, "8843": 65, "8845": 39, "884996": 50, "8850": 41, "885065": 64, "885956": 48, "885978": [54, 55], "886041": 49, "886086": [48, 49], "886266": 61, "88629": 39, "886314": 49, "88664": 42, "887197": 45, "887345": 61, "887556": 50, "887648": 49, "887680": 48, "888146": 59, "8881461": 40, "888445": 49, "888775": 55, "888804": 61, "889293": 64, "8893": 60, "889300": 60, "889326": 49, "889638": 45, "889733": 64, "889792": 49, "88988263e": 75, "889913": [48, 49], "889963": 64, "88ad": 42, "89": [41, 49, 72, 74, 75, 103, 104], "890": [40, 59], "890229": 45, "89027368": [89, 99], "890273683": [89, 99], "890318": 48, "89035917": 56, "890372": [43, 70, 102], "8903720000100010000010": [42, 70, 102], "8904": 37, "890454": 73, "8909": [40, 60, 105], "891": 37, "891697": 60, "891752": 49, "891997": 48, "892": 42, "89257838": 75, "892648": 64, "892796": [48, 49], "893": 42, "8932105": 40, "893649": [48, 49], "893851": 64, "894": 42, "894307e": 61, "894448": 49, "89449": 60, "894490": 60, "895": 62, "895106": [48, 49], "895308": 61, "895333": 64, "895690": [48, 49], "895768e": 50, "896023": 64, "897220": 64, "897240": 61, "8974": 60, "897451": 48, "897495e": 49, "898722": 64, "899460": 64, "899662e": 48, "899716": 49, "8bdee1a1d83d": 42, "8da924c": 42, "8e3aa840": 42, "9": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 102, 104, 105], "90": [25, 41, 50, 51, 61, 64, 67, 72, 74, 75, 104], "9000000000000002": [50, 61, 64], "900000e": 61, "900021": 73, "901013": 49, "901148": 64, "90136": 60, "901360": 60, "901526": 56, "901683": 61, "901705": 48, "902": [89, 99], "902573": 50, "903056e": 64, "903135": 72, "903339": 50, "903351e": 50, "903406": 74, "903418": 59, "903674": 48, "903681": 64, "903767": [48, 49], "904156": 50, "9041560442482157": 50, "904315": 48, "904396": 48, "905042": 49, "905494": 50, "905858": 66, "905951": 65, "9061": 61, "906716732639898": [54, 55], "906757": 46, "907115": 64, "907176": 64, "9073": 61, "907491": 50, "907801": 59, "90794478": [89, 99], "907944783": [89, 99], "907961": 61, "908024": 66, "908663": 49, "908767": 58, "909304": [48, 49], "90963122e": 75, "909942e": 72, "909975": 61, "909997": [60, 105], "91": [72, 74, 75, 104], "910000e": 61, "9102": 60, "910895": 49, "9109": 42, "91102953": 64, "911030": 64, "911277": 49, "911662": 54, "912230": [48, 49], "9126": [41, 105], "9127": [41, 105], "912903": 48, "913": 42, "91315015": 40, "913280": 66, "913371": 49, "913415e": 48, "913485": 61, "9135337": 75, "913774": 50, "9142": 61, "91438767e": 75, "9145": 39, "915": [41, 42, 60, 61], "915000e": [60, 61], "915057e": 60, "915260e": 48, "915488": [54, 55], "9158080176561963": 58, "916236": 39, "916528": 54, "9166667": 42, "916914": 64, "916930": 48, "917": 42, "917000": 49, "917066": 61, "917248": 64, "91724807": 64, "917436": 64, "918227": 50, "919432": 64, "9197": 61, "919969": 48, "91e": 41, "92": [72, 73, 74, 75, 104], "920052": 49, "920335": 61, "920337": 55, "920645": 61, "9209": 39, "9210": 61, "921061": 66, "921256e": 49, "921372": 50, "921913": 59, "921956": [48, 49], "921e4f0d": 42, "922160": 61, "922251": 48, "9223": 61, "922996": 59, "923074e": 50, "923517": 67, "923607": 64, "92369755": 40, "923804": 50, "923943": 105, "923977": 61, "924002": 64, "9243": 61, "924396": [54, 55], "92463": 60, "924630": 60, "924634": 52, "9248": 42, "924821": 50, "924843": 59, "924921": 72, "925": 51, "925248": [54, 55], "925660": 48, "925736": 50, "925957": 54, "925995": 49, "926227": 49, "926493": 60, "926621": 50, "926901": 58, "927": 38, "927074": 64, "927232": 61, "9274": 61, "927950": 61, "92827999": 74, "92881435e": 75, "928947": 59, "92905": 40, "929643": 48, "92972925e": 89, "929729e": [76, 89], "93": [41, 72, 73, 74, 75, 104], "9304028": 40, "931": 69, "931479": 64, "931978": 102, "932027": 50, "932404e": 61, "9325": 39, "9327": 39, "932973": 64, "933": 62, "933259": 45, "933322": 49, "933671": 49, "933857": 49, "933996": 50, "934058": 48, "934068": 45, "934243": 49, "934433": [48, 49], "9345": 42, "934500": 49, "934511": [89, 99], "934549": 61, "93458": 65, "934963": 49, "934992": 50, "935": 57, "935591": 64, "935730": 64, "935764": 49, "935989": 59, "9359891": 40, "93648": 67, "936494": 48, "936739": 64, "937": 62, "937116": 59, "937586": 61, "938": [89, 99], "938975": [72, 73], "939068": [54, 55], "9392": 61, "939250": 48, "939458": 48, "9395": 61, "93958082416": 105, "94": [51, 57, 72, 74, 75, 104, 105], "940354721701296": 50, "940355": 50, "940373": 61, "940450": 45, "941440": 48, "941724": 61, "941788": 54, "942139": 55, "942312": 64, "942460e": 64, "942489": 61, "9425": 39, "942550": 61, "942661": 59, "942823": 61, "94309994e": 75, "943938": 64, "943949e": 64, "944149": 72, "944253e": 64, "944266": [54, 55], "944280": 61, "94441007e": 75, "944839": 45, "945881": 48, "94629": 67, "946297": 50, "946406": 55, "946433": 64, "946533": 48, "946658": 61, "946968": 50, "947440": 63, "947466": 73, "947613": 49, "9480": 61, "948154e": 54, "948785e": 48, "948868": 61, "94906344": 40, "949241": [89, 99], "949456": 64, "949866": 49, "95": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 39, 41, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 64, 65, 66, 67, 72, 74, 75, 89, 90, 95, 104, 105], "9500": 61, "950158": 48, "9504277795": 75, "950545": 46, "95062986e": 75, "951502": 64, "951532": 59, "951920": 63, "952": [41, 105], "9523": 39, "952839": 64, "9534": 61, "953683": 59, "953704": 48, "95372559e": 75, "954": [62, 89, 99], "95401167e": 75, "954536": 72, "955005e": 61, "9551": 61, "9552": 39, "955541": [14, 72], "95559917": 73, "955701": 48, "956047": 40, "9561": 39, "956574": 61, "956724": 50, "9567242535070148": 50, "956877": 49, "956892": 61, "957229": 55, "957375": 59, "957745": 50, "9579": 41, "957996": 50, "958": [89, 99], "9580": 41, "958105": 72, "958541": 61, "959132": 49, "959384": 49, "95e": 41, "96": [41, 48, 49, 62, 72, 74, 75, 104], "9605": 61, "960808": 50, "960834": 49, "9609": 39, "961539": 61, "961962": 50, "962364": 45, "962373": 49, "962523": 45, "962954": 49, "963055": 61, "963427e": 49, "964025e": 64, "964065e": 49, "964261e": 59, "964318": 61, "9647": 39, "965341": 49, "965531": 74, "965696": 48, "965774": 61, "96582": 73, "966015": 64, "966097": 15, "966320": 45, "966659": 50, "9666592590622916": 50, "967092": 49, "967467": 65, "968127": 45, "968134e": 64, "968258e": 48, "968577": 51, "969": [37, 62], "969141": 74, "9699": 60, "969925e": 49, "96e": 75, "97": [3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 43, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 72, 73, 74, 75, 76, 89, 99, 102, 104, 105], "970065": 64, "970150": 49, "971058": [54, 55], "972": 62, "972509": 49, "972745": 48, "972748": 50, "97276281": 64, "972763": 64, "97279930": 75, "97314470": 40, "973156": 72, "973229": 49, "973241": 64, "973331": 61, "973741": 49, "973890": 49, "974202": 50, "974213": 49, "97441062": [54, 55], "974414": 50, "974487": 48, "97470872": 65, "9748910611": 40, "975": [48, 49, 54, 55, 57, 62], "975289": 45, "9753": 42, "975447": 51, "975450": 49, "975461": 59, "975592": 45, "976": 62, "976088": 64, "976548e": 49, "976562": 64, "977202": 49, "977280": [48, 49], "977295": 61, "977507": 49, "977820": 48, "978303": 58, "9787": 61, "978977": 64, "978997": 45, "979475": 48, "979702": 48, "979857": 48, "979971e": 48, "98": [48, 49, 61, 72, 74, 75, 104], "980026": 61, "9802393": 40, "980440": 49, "980643e": 50, "981104": 63, "981403": 49, "981438": 48, "981672": 50, "981715": 48, "982019e": 49, "982353e": 61, "982417": 50, "982720": 48, "982797": 63, "983192": 64, "983253": 48, "983759": 105, "98393441": 65, "984024": 63, "984083": [54, 55], "984551": 8, "984562": 64, "984866": [89, 99], "984872": [48, 49], "984937": 50, "98505871e": 75, "985207": [48, 49], "985654": 49, "986": 62, "986383": 61, "986417": 48, "987": 62, "9870004": 42, "987220": 61, "987307": 58, "9875": 39, "987726": 49, "9880384": 42, "988421": [48, 49], "988463": 64, "988541": 48, "988709": 61, "988780": 61, "99": [41, 45, 48, 49, 62, 72, 74, 75, 104], "990": 62, "990210": 61, "990322": 62, "990659": 62, "990903": 48, "991": [42, 62], "9914": [60, 61, 65], "991444e": 54, "9915": [41, 60, 61, 65], "991512": 41, "991963": [48, 49], "991977": 61, "991988": 48, "99232145": 65, "992582": [48, 49], "993": 37, "993201": 49, "993575": 61, "994": 62, "994168239": 40, "994208": 45, "994214": 61, "994332": 46, "994377": 48, "9944": [57, 74], "994851": 61, "994937": 55, "995015": 61, "9951": 39, "995248": 64, "99549118e": 75, "99571372e": 75, "9961392": 40, "996313": 48, "996892": 58, "996934": 59, "9970": 61, "997034": 67, "997494": 67, "997571": 59, "997621": 50, "997934": [54, 55], "998063": 46, "99864670889": 105, "998766": 61, "9989": 60, "999": [51, 52, 56, 65, 105], "999207": 64, "9995": [48, 49, 52], "9996": [48, 49, 52], "9996553": 41, "9997": [48, 49, 52], "9998": [48, 49, 52], "9999": [48, 49, 52], "99c8": 42, "A": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 23, 24, 28, 32, 33, 34, 37, 38, 39, 41, 42, 46, 47, 53, 55, 62, 63, 65, 66, 69, 70, 72, 73, 74, 89, 90, 91, 92, 96, 97, 98, 99, 100, 102, 103, 105], "ATE": [9, 15, 18, 41, 43, 45, 60, 65, 66, 72, 74, 76, 82, 90, 96], "ATEs": [45, 62], "And": [62, 67, 90, 93], "As": [38, 39, 40, 41, 42, 45, 47, 48, 49, 50, 51, 53, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 68, 73, 75, 76, 78, 89, 90, 92, 98, 99, 105], "At": [18, 19, 20, 40, 45, 51, 52, 56, 57, 59, 61, 64, 105], "Being": 105, "But": 57, "By": [39, 40, 59, 66, 73, 90, 95], "For": [1, 5, 6, 8, 9, 12, 20, 30, 31, 37, 39, 40, 42, 45, 46, 51, 56, 57, 58, 59, 61, 63, 65, 66, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 96, 98, 99, 101, 102, 105], "ITE": [24, 45], "ITEs": 45, "If": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 32, 33, 34, 38, 40, 47, 48, 49, 51, 57, 59, 61, 69, 70, 72, 73, 74, 76, 77, 79, 80, 82, 89, 90, 92, 93, 94, 95, 97, 98, 100, 105], "In": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105], "It": [39, 40, 41, 48, 49, 53, 54, 55, 59, 60, 61, 66, 73, 75, 100, 104], "No": [22, 37, 39, 41, 42, 43, 45, 51, 56, 60, 61, 65, 67, 70, 73, 74, 76, 89, 102, 103], "Of": [57, 89, 105], "On": [38, 47, 58, 62, 69, 103], "One": [41, 60, 61, 66, 72, 89], "Such": [66, 73], "That": 105, "The": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 37, 38, 39, 40, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 82, 85, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105], "Then": [20, 50, 64, 89, 90, 98, 99, 100, 101], "There": [41, 60, 66, 101, 105], "These": [41, 42, 44, 58, 60, 63, 65, 72, 105], "To": [31, 37, 38, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 54, 55, 57, 59, 60, 61, 63, 64, 65, 66, 67, 69, 70, 72, 73, 75, 89, 90, 92, 95, 98, 99, 101, 102, 105], "With": [23, 48, 49, 73, 103], "_": [38, 40, 47, 48, 49, 50, 52, 53, 54, 55, 59, 60, 61, 63, 64, 68, 69, 72, 75, 76, 89, 90, 92, 95, 99], "_0": [38, 40, 47, 53, 59, 68, 69, 75, 76, 84, 85, 89, 90, 98], "_1": [18, 19, 20, 24, 62, 67, 76, 84, 85], "_2": [18, 19, 20, 24, 62], "_3": [18, 19, 20, 24], "_4": [18, 19, 20, 24], "_5": [18, 24], "__init__": 58, "__version__": 101, "_all_coef": 75, "_all_s": 75, "_compute_scor": 31, "_compute_score_deriv": 31, "_coordinate_desc": 59, "_est_causal_pars_and_s": 104, "_estimator_typ": 58, "_i": [38, 47, 64, 67, 69], "_id": 75, "_j": [18, 19, 20, 24, 26, 40, 59, 89, 99], "_l": 73, "_m": [73, 75], "_n": [76, 79, 80, 82, 89, 90, 95, 97, 99], "_n_folds_per_clust": 59, "_rmse": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "a0": 58, "a09a": 42, "a09b": 42, "a1": 58, "a3d9": 42, "a4a147": 62, "a5e6": 42, "a5e7": 42, "a6ba": 42, "a79359d2da46": 42, "a840": 42, "a_": 67, "a_0": 27, "a_1": 27, "a_j": 74, "ab": [39, 100], "ab71": 42, "abadi": [16, 51], "abb0fd28": 42, "abdt": [43, 70, 102], "abl": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 47, 57, 61, 62, 73, 90, 92, 98], "about": [41, 57, 60, 100, 102, 105], "abov": [38, 41, 45, 47, 48, 49, 54, 55, 57, 58, 60, 62, 63, 64, 66, 69, 72, 73, 74, 101], "absolut": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 57, 73], "abstract": [31, 39, 40, 59, 76, 100, 104], "acc": [2, 39], "accept": [72, 73], "access": [32, 33, 39, 41, 54, 55, 56, 57, 65, 73, 90, 95, 105], "accord": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 41, 45, 47, 50, 51, 60, 64, 66, 67, 73, 89, 90, 91, 93, 94, 96, 99, 105], "accordingli": [51, 57, 58, 60, 67], "account": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 41, 59, 60, 61, 65, 66, 90, 95, 98, 105], "accumul": [41, 60, 61, 65], "accuraci": 39, "acemoglu": 103, "achiev": [40, 59, 63, 66, 89, 99], "acic_2024_post": 62, "acknowledg": [41, 42, 60], "acm": 103, "acov": 103, "across": [41, 60, 62, 105], "action": 104, "activ": [4, 7, 101, 104], "actual": [56, 66], "acycl": [67, 105], "ad": [4, 7, 16, 17, 31, 56, 70, 73, 89, 90, 92, 104], "adapt": [8, 60, 104], "add": [39, 40, 43, 45, 51, 52, 54, 55, 56, 62, 64, 65, 66, 67, 73, 103, 104], "add_trac": 66, "addit": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 20, 24, 26, 27, 28, 34, 53, 66, 73, 74, 76, 83, 90, 91, 96, 98, 103, 104], "addition": [18, 19, 45, 50, 61, 65, 73, 74, 75, 89, 90, 95, 102], "address": 66, "adel": 103, "adj": 66, "adj_coef_bench": 66, "adj_est": 66, "adj_vanderweelearah": 66, "adjust": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 35, 40, 52, 59, 61, 65, 66, 72, 89, 90, 95, 99, 105], "adopt": [51, 74], "advanc": [58, 71, 75, 103], "advantag": [38, 39, 41, 45, 47, 60, 61, 69, 101], "advers": [90, 92], "adversari": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 65, 90, 95, 98], "ae": [38, 40, 41], "ae56": 42, "ae89": 42, "aesthet": 38, "aeturrel": 28, "afd9e4": 62, "affect": [45, 53, 74, 104, 105], "after": [39, 41, 42, 51, 53, 60, 61, 66, 67, 72, 73, 90, 93, 95, 101, 105], "after_stat": 38, "ag": [41, 60, 61, 63, 65, 105], "again": [38, 39, 40, 41, 45, 47, 51, 56, 58, 59, 60, 65, 66, 67, 69, 90, 93], "against": [51, 56, 57, 63, 73], "agebra": 72, "agegt54": [42, 43, 70, 102], "agelt35": [42, 43, 70, 102], "agg": 39, "aggreg": [39, 68, 75, 104], "aggt": 39, "aipw": 62, "aipw_est_1": 62, "aipw_est_2": 62, "aipw_obj_1": 62, "aipw_obj_2": 62, "air": [40, 59], "al": [16, 17, 21, 23, 26, 27, 38, 40, 41, 42, 47, 48, 49, 50, 51, 53, 54, 55, 57, 59, 60, 61, 64, 65, 69, 74, 75, 76, 78, 83, 88, 89, 90, 92, 98, 99, 100, 102, 104], "alexandr": [53, 103], "algorithm": [37, 39, 40, 42, 45, 47, 50, 51, 57, 59, 61, 64, 65, 67, 71, 73, 74, 75, 76, 89, 104, 105], "align": [38, 40, 47, 50, 52, 57, 59, 60, 62, 63, 64, 67, 104], "all": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 36, 38, 39, 40, 41, 45, 47, 51, 56, 57, 58, 59, 60, 61, 63, 66, 67, 69, 70, 72, 73, 74, 75, 89, 90, 98, 99, 100, 101, 104], "all_coef": 75, "all_dml1_coef": 68, "all_s": 75, "all_smpl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "all_smpls_clust": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "all_z_col": [40, 59], "allow": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 31, 41, 45, 60, 61, 72, 73, 74, 75, 76, 89, 99, 100, 104, 105], "almqvist": 103, "along": 73, "alpha": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 25, 27, 38, 40, 41, 43, 45, 47, 48, 49, 50, 53, 57, 58, 59, 60, 61, 64, 68, 69, 72, 73, 74, 75, 76, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], "alpha_": [26, 40, 59, 73], "alpha_0": [90, 98], "alpha_ml_l": 53, "alpha_ml_m": 53, "alpha_x": [8, 22, 74], "alreadi": [20, 51, 67, 73, 74], "also": [1, 5, 6, 8, 9, 12, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 51, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 69, 72, 73, 75, 76, 89, 90, 92, 101, 102, 104, 105], "alter": [40, 59], "altern": [39, 41, 42, 60, 63, 71, 73, 89, 99, 100, 101, 102], "although": 66, "alwai": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 39, 104], "always_tak": [8, 41, 60], "amamb": 59, "american": [25, 62], "amgrem": 59, "amhorn": 59, "amit": [66, 103], "amjavl": 59, "ammata": 59, "among": [41, 53, 60, 61, 65, 66], "amount": [41, 58, 60, 61, 105], "amp": [37, 40, 42, 51, 59, 61, 65, 67], "an": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 24, 32, 33, 38, 39, 40, 41, 42, 45, 47, 48, 49, 53, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 89, 90, 92, 95, 99, 100, 101, 102, 103, 104, 105], "analog": [30, 31, 40, 59, 61, 65, 72, 74, 76, 79, 80, 89, 90, 95, 99], "analys": 105, "analysi": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 40, 41, 47, 59, 60, 61, 69, 71, 72, 92, 95, 98, 100, 104], "analyt": [62, 64], "analyz": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 41, 60, 61, 65, 105], "ancillari": 66, "andrea": 103, "angl": 41, "angrist": 62, "ani": [37, 38, 39, 42, 46, 47, 51, 66, 67, 69, 101, 105], "anna": [5, 6, 18, 19, 20, 24, 39, 51, 74, 103], "annal": [89, 99, 103], "anneal": 73, "annot": 38, "annual": 103, "anoth": [38, 39, 40, 41, 47, 57, 58, 59, 69, 73, 74], "anticip": 39, "anymor": [40, 59], "aos1161": [89, 99], "aos1230": [89, 99], "aos1671": [89, 99], "ap": [41, 60], "ape_e401_uncond": 41, "ape_p401_uncond": 41, "api": [70, 100, 104], "apo": [1, 2, 77, 91], "apoorva": 104, "apoorva__l": 62, "apoorval": 62, "app": 104, "appeal": 66, "append": [47, 57, 69], "appendix": [23, 29, 65, 67, 90, 92], "appli": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 37, 38, 40, 41, 42, 47, 51, 52, 57, 59, 60, 61, 66, 67, 69, 74, 75, 76, 89, 99, 100, 102, 104, 105], "applic": [38, 47, 51, 62, 66, 69, 72, 75, 103, 105], "apply_along_axi": 63, "apply_cross_fit": [38, 75], "apply_crossfit": 104, "appreci": 100, "approach": [1, 3, 5, 6, 8, 9, 10, 13, 14, 15, 39, 40, 45, 59, 65, 66, 71, 73, 75, 89, 90, 92, 99, 101, 103, 105], "appropri": [41, 53, 60, 75, 105], "approx": 72, "approxim": [38, 47, 48, 49, 50, 57, 64, 66, 69, 72, 89, 99, 104, 105], "apt": 101, "ar": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 44, 45, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105], "arang": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 47, 50, 52, 61, 63, 64, 65, 66, 73], "architectur": [76, 103], "arellano": 103, "arg": [58, 72], "argmin": 57, "argu": [38, 41, 47, 60, 61, 65, 69, 105], "argument": [1, 9, 12, 20, 26, 27, 28, 34, 41, 48, 49, 51, 56, 57, 60, 61, 68, 72, 73, 74, 105], "aris": [38, 39, 40, 47, 59, 66, 69, 105], "aronow": 62, "around": [39, 41, 60, 61, 76], "arr": 63, "arrai": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 22, 23, 25, 26, 27, 28, 29, 34, 35, 45, 47, 48, 49, 50, 51, 57, 59, 62, 63, 65, 66, 67, 68, 69, 71, 72, 73, 75, 89, 90, 95, 99, 102, 104, 105], "arrang": 40, "array_lik": 14, "articl": [28, 100], "arxiv": [26, 39, 40, 59, 66, 100, 103, 104], "as_learn": [42, 73], "asarrai": [48, 49], "aspect": [41, 60, 61], "assert": 73, "assess": 39, "asset": [61, 65, 105], "assign": [4, 7, 41, 55, 60, 72, 73, 74, 105], "assmput": 74, "associ": [41, 53, 60, 74, 89, 99, 103], "assum": [37, 40, 46, 51, 59, 62, 63, 66, 74, 76, 79, 80, 89, 90, 98, 105], "assumpt": [39, 40, 41, 51, 52, 57, 59, 60, 62, 67, 74, 89, 105], "assur": 104, "astyp": [46, 60, 66], "asymptot": [30, 31, 38, 40, 47, 59, 69, 75, 89, 103], "ate": 45, "ate_estim": 67, "ates": 45, "athei": 103, "att": [9, 18, 39, 52, 56, 63, 66, 72, 74, 76, 82, 90, 96, 104], "att_gt": 39, "attach": 39, "atte_estim": 51, "attempt": [32, 33], "attenu": [41, 60], "attr": 41, "attribut": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 34, 35, 57, 58, 68, 73, 75, 76, 89], "attributeerror": [32, 33], "attrict": 74, "attrit": [15, 67, 74], "au": [42, 73, 100, 102], "auc": 39, "author": [39, 66, 100], "auto_ml": 58, "autodoubleml": 58, "autom": 58, "automat": [38, 47, 56, 69, 72, 90, 95], "automl_l": 58, "automl_l_lesstim": 58, "automl_m": 58, "automl_m_lesstim": 58, "automobil": [40, 59], "autos": 53, "autosklearn": 58, "auxiliari": [38, 47, 69], "avail": [22, 39, 41, 42, 45, 51, 53, 57, 60, 61, 62, 63, 66, 69, 72, 73, 74, 90, 98, 100, 101, 104, 105], "avaiv": 35, "aver": 45, "averag": [1, 2, 8, 9, 12, 18, 19, 20, 37, 39, 42, 46, 51, 52, 56, 61, 62, 63, 65, 66, 67, 71, 77, 82, 89, 91, 96, 103, 104, 105], "average_it": 45, "avoid": [38, 39, 47, 75, 101, 104], "awai": 65, "ax": [45, 47, 48, 49, 50, 52, 54, 55, 57, 58, 59, 60, 61, 62, 64], "ax1": [45, 50, 61, 64], "ax2": [45, 50, 61, 64], "axhlin": [52, 58], "axi": [40, 41, 45, 53, 57, 59, 60, 62, 63], "axvlin": [45, 47], "b": [5, 6, 28, 38, 40, 42, 47, 48, 49, 59, 62, 64, 66, 69, 72, 73, 89, 90, 98, 99, 100, 102, 103], "b208": 42, "b371": 42, "b5d34a6f42b": 42, "b5d7": 42, "b_0": 27, "b_1": 27, "b_j": 28, "bach": [66, 100, 103, 104], "backbon": 57, "backend": [4, 7, 39, 61, 65, 66, 71, 104], "backward": 104, "bad": 62, "balanc": [41, 60, 61], "band": [39, 71, 105], "bandwidth": [10, 13, 14], "bar": [56, 58, 60, 72, 76, 77, 82, 90, 91], "base": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 21, 24, 35, 38, 39, 40, 41, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 89, 90, 92, 95, 99, 100, 102, 103, 104, 105], "baselin": [24, 41, 58, 60], "basi": [1, 9, 12, 34, 48, 49, 72], "basic": [39, 40, 41, 51, 59, 60, 61, 62, 65, 66, 71, 73], "batch": 42, "battocchi": 103, "bay": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 89, 99], "bb2913dc": 42, "bbotk": [42, 73, 104], "bbox_inch": 47, "bbox_to_anchor": 47, "bcallaway11": 39, "bd929a9e": 42, "bde4": 42, "becam": [41, 60, 61], "becaus": [37, 38, 39, 40, 46, 47, 55, 56, 59, 62, 66, 69, 105], "becker": [42, 73], "becom": [40, 55, 58, 59, 72, 75], "bee": 52, "been": [40, 41, 58, 59, 60, 61, 65, 66, 72, 73, 104], "befor": [39, 41, 45, 52, 56, 60, 64, 66, 74, 105], "begin": [22, 25, 26, 38, 40, 41, 42, 47, 50, 52, 57, 59, 60, 62, 63, 64, 67, 68, 70, 73, 75, 89, 99, 102, 105], "behav": 55, "behavior": [41, 62, 73], "behaviour": 55, "being": [24, 29, 30, 31, 40, 59, 66, 75, 76, 78, 89, 90, 95, 99, 100], "belloni": [23, 53, 89, 99, 103], "below": [37, 41, 46, 60, 62, 101, 102], "bench_x1": 66, "bench_x2": 66, "benchmark": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 36, 45, 56, 92, 104], "benchmark_dict": [36, 65], "benchmark_inc": 65, "benchmark_pira": 65, "benchmark_result": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "benchmark_twoearn": 65, "benchmarking_set": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 56, 65, 66, 90, 92], "benchmarking_vari": 56, "benefit": [38, 41, 47, 60, 69], "bernoulli": 22, "berri": [40, 59], "besid": 102, "best": [1, 9, 12, 34, 48, 49, 54, 55, 58, 101], "best_loss": 58, "beta": [15, 22, 23, 25, 29, 41, 60, 63, 67], "beta_": 67, "beta_0": [21, 63, 67, 72], "beta_a": [18, 19, 66], "beta_j": [22, 23, 25, 29], "better": [39, 45, 57, 66], "between": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 45, 46, 50, 52, 53, 58, 62, 64, 65, 66, 67, 74, 76, 79, 80, 82, 86, 87, 89, 90, 98, 99, 102, 104], "betwen": [37, 46], "beyond": 103, "bia": [29, 37, 46, 53, 66, 67, 71, 74, 75, 76, 84, 85, 90, 98, 103, 104], "bias": [37, 41, 46, 60, 61, 65, 105], "bias_bench": 66, "bibtex": 100, "big": [53, 68, 75, 76, 80, 83, 89, 90, 93, 94, 96, 97, 98], "bigg": [40, 59, 76, 81, 82, 90, 96], "bilia": 17, "bin": [38, 45, 47, 101], "binari": [1, 3, 5, 6, 8, 9, 10, 12, 13, 15, 21, 37, 39, 41, 42, 46, 51, 56, 57, 60, 62, 63, 66, 72, 73, 90, 91, 96, 104, 105], "binary_treat": [21, 48, 54, 56], "bind": 104, "binder": [42, 73, 100, 102, 104], "binomi": [46, 62, 63, 64], "bischl": [42, 73, 100, 102], "black": [38, 42, 43, 70, 102], "blob": 39, "blog": 28, "blondel": [100, 102], "blp": [34, 40, 59], "blp_data": [40, 59], "blp_model": [54, 55], "blue": [38, 40, 59], "bodori": 103, "bond": [41, 60, 61], "bonferroni": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 89, 99], "bonu": [17, 42, 70, 102], "book": [42, 66, 73], "bool": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 21, 24, 32, 33, 34, 56], "boolean": [29, 54, 55, 70, 75], "boost": [37, 41, 46, 51, 57, 60], "boost_class": [41, 60], "boost_summari": 60, "boostrap": [50, 104], "bootstrap": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 45, 48, 49, 50, 54, 55, 61, 64, 71, 72, 75, 76, 100, 102, 104, 105], "both": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 19, 21, 39, 41, 42, 51, 52, 57, 58, 60, 61, 63, 65, 66, 70, 73, 89, 90, 92, 95, 97, 98, 104, 105], "bottom": [40, 41, 57, 59, 60, 61], "bound": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 24, 41, 45, 56, 60, 65, 66, 90, 92, 95, 98, 105], "branch": 42, "brantli": 39, "break": [38, 104], "breviti": 105, "brew": 101, "brewer": 40, "bridg": 66, "brief": 69, "bring": [37, 46], "brucher": [100, 102], "bsd": 104, "budget": [58, 73], "bug": [100, 104], "build": [40, 57, 59, 63], "build_design_matric": [48, 49], "build_sim_dataset": 39, "built": [35, 58, 73, 100], "bureau": [66, 75, 103], "busi": [26, 29, 40, 59, 66, 103], "b\u00fchlmann": 103, "c": [16, 17, 19, 20, 23, 25, 27, 37, 38, 39, 40, 41, 42, 43, 46, 47, 52, 53, 54, 55, 59, 60, 62, 69, 70, 73, 100, 101, 102, 103, 105], "c1": [16, 17, 27, 40, 53, 59, 69, 100, 103], "c68": [16, 17, 27, 40, 53, 59, 69, 100, 103], "c895": 42, "c_": [89, 99], "c_d": [23, 90, 96, 97, 98], "c_y": [23, 90, 98], "ca1af7be64b2": 42, "caac5a95": 42, "calcualt": 63, "calcul": [1, 9, 12, 39, 41, 45, 48, 49, 50, 54, 55, 57, 58, 60, 64, 65, 90, 95, 98], "calibr": [57, 58, 66], "call": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 37, 39, 40, 41, 42, 46, 48, 49, 50, 51, 54, 55, 59, 60, 61, 63, 64, 65, 66, 67, 70, 73, 75, 76, 89, 90, 95, 98, 99, 101, 102, 104, 105], "callabl": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 47, 48, 49, 57, 71, 73, 100], "callawai": 39, "camera": 53, "cameron": [40, 59], "can": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 21, 35, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 79, 80, 82, 86, 87, 89, 90, 91, 92, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105], "candid": 66, "cannot": [57, 66, 105], "capabl": [4, 7, 37, 46], "capo": 1, "capsiz": [45, 58, 62], "capthick": 45, "cardin": [40, 59], "care": 73, "carlo": [18, 19, 21, 24, 48, 49, 54, 55, 66, 103], "casalicchio": [42, 73, 100, 102], "case": [1, 4, 7, 8, 9, 17, 21, 37, 40, 41, 46, 48, 49, 50, 53, 55, 56, 58, 59, 63, 64, 65, 66, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 102, 104, 105], "cat": [38, 104], "catboost": 57, "cate": [9, 12, 34, 71, 104], "cate_obj": 72, "caus": [38, 47, 69], "causal": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 22, 23, 25, 26, 27, 28, 29, 37, 38, 40, 41, 42, 46, 47, 59, 60, 62, 65, 67, 68, 69, 70, 71, 74, 75, 89, 90, 95, 99, 103], "causal_contrast": [2, 45, 74], "causal_contrast_model": [45, 74], "causaldml": 103, "causalweight": 103, "caution": 89, "caveat": [55, 66], "cbind": 40, "cc": 60, "ccp_alpha": [9, 35, 60], "cd": 101, "cd_fast": 59, "cda85647": 42, "cdf": 72, "cdid": [40, 59], "cdot": [18, 19, 20, 24, 40, 50, 52, 56, 59, 62, 64, 66, 72, 74, 76, 77, 82, 83, 84, 85, 89, 90, 91, 99], "cdot1": 56, "cell": 58, "center": 53, "central": [75, 104], "certain": 55, "cexcol": 40, "cexrow": 40, "cf_d": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 36, 45, 56, 65, 66, 90, 91, 92, 95, 96, 97, 98, 105], "cf_y": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 36, 45, 56, 65, 66, 90, 91, 92, 95, 96, 97, 98, 105], "chad": 66, "chain": 55, "chainedassignmenterror": 55, "challeng": [40, 59, 90, 92], "chang": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 51, 55, 61, 65, 66, 67, 76, 82, 89, 90, 91, 92, 93, 94, 95, 96, 101, 103, 104], "channel": 105, "chapter": [30, 31, 42, 73, 90, 98], "charact": [41, 42, 73, 104], "characterist": [65, 105], "chart": 58, "check": [32, 33, 38, 41, 47, 57, 58, 60, 61, 68, 69, 100, 101, 104], "check_data": 104, "check_scor": 104, "checkmat": 104, "chernozhukov": [16, 17, 23, 25, 27, 38, 40, 41, 47, 53, 57, 59, 60, 61, 65, 69, 75, 89, 90, 92, 98, 99, 100, 103, 104], "chetverikov": [16, 17, 27, 40, 53, 59, 69, 89, 99, 100, 103], "chiang": [26, 40, 59, 103], "chieh": 103, "choic": [1, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 41, 53, 60, 63, 72, 73, 90, 92, 95, 98, 104], "choos": [37, 41, 46, 47, 53, 57, 60, 61, 68, 75, 76, 79, 80, 82, 86, 87, 89, 99, 102, 105], "chosen": [1, 19, 24, 57, 73], "chou": 62, "chr": 41, "christian": [53, 103], "chunk": 73, "ci": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 48, 49, 50, 51, 52, 54, 55, 56, 58, 60, 61, 64, 65, 66, 72, 90, 95, 104, 105], "ci_at": 45, "ci_cvar": [50, 61], "ci_cvar_0": 50, "ci_cvar_1": 50, "ci_joint": 45, "ci_joint_cvar": 50, "ci_joint_lqt": 64, "ci_joint_qt": 64, "ci_length": 51, "ci_low": 45, "ci_lpq_0": 64, "ci_lpq_1": 64, "ci_lqt": [61, 64], "ci_pointwis": 45, "ci_pq_0": [61, 64], "ci_pq_1": [61, 64], "ci_qt": [61, 64], "ci_upp": 45, "cinelli": [66, 90, 92, 103], "circumv": 105, "citat": 104, "claim": 42, "clash": 39, "class": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 30, 31, 32, 33, 34, 35, 41, 42, 43, 45, 51, 56, 58, 60, 61, 65, 67, 68, 70, 72, 73, 75, 76, 89, 100, 102, 104], "class_learn": 61, "class_learner_1": 57, "class_learner_2": 57, "classes_": 58, "classic": [39, 40, 59, 105], "classif": [9, 37, 39, 41, 42, 57, 58, 63, 65, 72, 73, 74, 105], "classifavg": 42, "classifi": [1, 3, 5, 6, 8, 9, 10, 12, 13, 14, 15, 32, 42, 45, 58, 73, 104], "classmethod": [4, 7], "claus": 104, "clean": 104, "cleaner": 57, "cleanup": 104, "clear": [40, 59], "clever": 57, "clone": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 38, 42, 47, 57, 59, 61, 68, 73, 74, 75, 76, 89, 90, 95, 99, 101, 102], "close": [39, 41, 60, 66, 90, 92], "cluster": [1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 26, 103, 104], "cluster_col": [4, 40, 59], "cluster_var": [4, 26], "cluster_var_i": [4, 40, 59], "cluster_var_j": [4, 40, 59], "cmap": 59, "cmd": 104, "co": [28, 52], "codaci": 104, "code": [1, 9, 12, 28, 37, 39, 40, 41, 42, 46, 53, 60, 69, 72, 73, 74, 75, 76, 89, 101, 102, 104, 105], "codecov": 104, "coef": [3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 89, 102, 105], "coef_": 66, "coef_df": 40, "coef_valu": 58, "coeffici": [18, 19, 21, 34, 41, 54, 55, 57, 60, 62, 63, 66, 67, 72, 89, 90, 95, 99, 105], "coefs_t": 63, "coefs_w": 63, "coffici": [90, 95], "cofid": 34, "coincid": [52, 61], "col": [38, 40, 55, 60], "collect": [42, 51, 59, 67], "colnam": [40, 57], "color": [41, 45, 47, 48, 49, 50, 52, 58, 59, 60, 61, 62, 64, 66], "color_palett": [45, 47, 59, 60, 61], "colorbar": 59, "colorblind": 45, "colorramppalett": 40, "colorscal": [48, 49], "colour": [38, 40], "column": [4, 7, 43, 45, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 70, 72, 73, 75, 102, 104, 105], "column_stack": [45, 52, 54, 55, 65, 66], "colv": 40, "com": [28, 39, 41, 42, 53, 60, 62, 66, 73, 101], "comb": 53, "combin": [39, 40, 42, 45, 51, 57, 58, 59, 66, 73, 75, 90, 95, 104], "combind": 61, "combined_loss": 53, "come": [68, 73, 76, 90, 92, 100, 105], "command": [101, 104], "comment": 70, "common": [57, 65, 66, 72, 74, 103], "companion": 103, "compar": [38, 40, 47, 48, 49, 50, 52, 54, 55, 59, 62, 64, 66, 69, 73, 90, 92], "comparevers": 41, "comparison": [45, 57, 62], "compat": [37, 39, 46, 104], "complement": 66, "complet": [58, 69, 90, 95, 101], "complex": [9, 39, 58], "complianc": [64, 76, 83], "complic": [42, 105], "complier": [41, 60, 61, 64, 72], "compon": [39, 41, 53, 57, 58, 60, 63, 72, 73, 75, 76, 77, 79, 80, 81, 82, 83, 86, 87, 104], "compont": 39, "composit": 103, "compris": [89, 99], "comput": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 36, 38, 39, 41, 42, 47, 60, 61, 65, 66, 75, 76, 90, 91, 92, 93, 94, 95, 96, 100, 103, 104, 105], "computation": [90, 92], "concat": [58, 59, 60, 63, 89], "concaten": [52, 60, 89], "concentr": 89, "concern": 66, "conclud": [66, 105], "cond": 74, "conda": [59, 103, 104], "condit": [1, 3, 9, 12, 18, 19, 21, 30, 31, 38, 40, 41, 45, 47, 51, 52, 56, 59, 60, 63, 66, 67, 69, 71, 74, 89, 90, 91, 96, 98, 99, 102, 103, 104, 105], "conduct": [72, 74, 105], "conf": [39, 64], "confer": 103, "confid": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 39, 40, 41, 45, 48, 49, 50, 51, 54, 55, 59, 61, 64, 65, 67, 71, 72, 75, 76, 90, 95, 102, 103, 105], "confidenceband": 50, "confidenti": 66, "config": 62, "configur": [42, 58], "confint": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 41, 45, 48, 49, 50, 51, 52, 54, 55, 57, 61, 63, 64, 65, 67, 72, 75, 89, 99, 100, 102, 105], "conflict": 101, "confound": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 21, 36, 37, 41, 46, 56, 60, 64, 65, 66, 70, 74, 89, 90, 92, 95, 97, 98, 99, 102, 103, 104, 105], "congress": 103, "connect": [41, 60, 61], "consequ": [18, 19, 40, 56, 59, 65, 72, 74, 90, 91, 92, 96, 98], "conserv": [65, 66, 90, 98], "consid": [3, 8, 9, 10, 13, 38, 40, 41, 47, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 89, 90, 92, 99, 100, 105], "consider": 66, "consist": [11, 12, 41, 51, 58, 60, 61, 62, 66, 69, 70, 74, 102, 104], "consol": [38, 104], "constant": [23, 53, 63, 72, 89, 99], "constrained_layout": 47, "construct": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 34, 42, 48, 49, 50, 52, 61, 65, 68, 72, 76, 78, 85, 89, 99, 104, 105], "construct_framework": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "construct_iv": 59, "constructiv": 40, "constructor": 42, "consum": [40, 59], "cont": 24, "cont_d": 45, "contain": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 24, 32, 33, 38, 40, 41, 45, 47, 48, 49, 54, 55, 57, 59, 60, 69, 72, 73, 89, 90, 92, 95, 104], "context": [66, 74, 105], "contin": [24, 58], "continu": [24, 37, 42, 45, 46, 53, 62, 90, 98, 104, 105], "contour": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 53, 56, 65, 66, 90, 95], "contour_plot": 66, "contours_z": [48, 49], "contrast": [2, 50, 51, 74], "contribut": [101, 104], "contributor": 104, "control": [25, 39, 53, 61, 63, 66, 105], "convent": [41, 60, 61], "converg": [38, 47, 57, 59, 69], "convergencewarn": 59, "convers": 59, "convert": [50, 59, 64], "convex": 62, "coor": [42, 73, 100, 102], "coordin": 66, "copi": [55, 58, 60, 63, 66], "cor": [90, 98], "core": [43, 45, 50, 51, 56, 59, 60, 61, 64, 65, 67, 70, 73, 102, 104], "cores_us": [50, 61, 64], "correct": [56, 66, 72, 89, 99, 104], "correctli": [51, 62, 65, 90, 98], "correl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 53, 59, 65, 67, 74, 90, 92, 98], "correpond": 74, "correspond": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 24, 30, 31, 38, 40, 41, 42, 45, 47, 48, 49, 51, 52, 53, 57, 59, 60, 61, 63, 64, 65, 66, 69, 72, 73, 74, 75, 89, 90, 92, 95, 96, 98, 99, 104, 105], "cosh": 28, "coul": 40, "could": [37, 42, 46, 48, 49, 58, 66, 104, 105], "counfound": [18, 19, 64, 65, 72, 90, 98], "count": [45, 60, 61], "countour": [90, 95], "coupl": [41, 60, 61], "cournapeau": [100, 102], "cours": [41, 57, 60, 66, 89, 105], "cov": [15, 18], "cov_typ": [1, 9, 12, 34], "covari": [4, 5, 6, 7, 9, 11, 12, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 70, 72, 73, 74, 76, 79, 80, 89, 90, 92, 102, 104], "cover": [39, 53, 65], "coverag": [57, 72, 104], "cp": [41, 42, 73], "cpu": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "cpu_count": [50, 61, 64], "cran": [42, 103, 104], "creat": [21, 37, 40, 42, 45, 46, 47, 48, 49, 50, 54, 55, 59, 61, 63, 64, 66, 73, 90, 92, 95, 98, 101], "create_synthetic_group_data": 63, "critic": [66, 105], "cross": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 20, 37, 38, 39, 41, 42, 47, 57, 58, 60, 61, 66, 69, 71, 73, 79, 80, 85, 89, 93, 95, 104, 105], "cross_sectional_data": [6, 20, 51, 74], "crossfit": 57, "crosstab": 62, "crucial": [53, 105], "csail": [100, 102], "csv": 53, "cumul": 74, "current": [35, 39, 55, 76, 90, 98, 100, 105], "custom": [38, 39, 47, 66, 73], "custom_measur": 39, "cut": 63, "cv": [42, 60, 73, 75], "cv_glmnet": [40, 41, 42, 73, 89, 99, 102], "cvar": [3, 14, 71, 78, 104], "cvar_0": 50, "cvar_1": 50, "d": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 34, 35, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 105], "d0": [50, 64, 89], "d0_true": 64, "d0cdb0ea4795": 42, "d1": [50, 62, 64, 89, 99], "d10": [89, 99], "d1_true": 64, "d2": [62, 89, 99], "d21ee5775b5f": 42, "d3": [89, 99], "d4": [89, 99], "d5": [89, 99], "d5a0c70f1d98": 42, "d6": [89, 99], "d7": [89, 99], "d8": [89, 99], "d9": [89, 99], "d_": [24, 26, 40, 45, 52, 59, 74, 89, 99], "d_0": 74, "d_1": [62, 89, 99], "d_2": 62, "d_col": [4, 7, 37, 38, 40, 41, 42, 46, 48, 49, 54, 55, 59, 60, 61, 63, 65, 68, 69, 70, 73, 74, 75, 76, 102, 104, 105], "d_i": [21, 22, 23, 25, 27, 28, 29, 38, 45, 47, 50, 51, 62, 64, 67, 69, 74], "d_j": [45, 74, 89, 99], "d_k": [74, 89, 99], "d_l": 74, "d_w": 63, "da1440": 62, "dag": [66, 67, 105], "dark": [38, 47], "darkblu": 40, "darkr": 40, "dash": 45, "dat": 70, "data": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 34, 39, 52, 53, 57, 62, 68, 71, 72, 73, 75, 89, 94, 95, 99, 103, 104], "data_apo": 45, "data_cvar": 61, "data_dict": [48, 49, 54, 55, 56], "data_dml": 65, "data_dml_bas": [41, 48, 49, 54, 55, 60, 61, 63], "data_dml_base_iv": [41, 60, 61], "data_dml_flex": [41, 60], "data_dml_flex_iv": 41, "data_dml_iv_flex": 60, "data_dml_new": 63, "data_fram": 105, "data_lqt": 61, "data_pq": 61, "data_qt": 61, "data_transf": [40, 59, 60], "datafram": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 34, 35, 40, 43, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 76, 89, 90, 92, 95, 102, 105], "dataset": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 38, 39, 45, 47, 48, 49, 51, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 89, 90, 95, 102, 105], "datatyp": 104, "db": [41, 60, 61, 65, 105], "dbl": [39, 40, 41, 42, 70, 89, 99, 102, 105], "dc13a11076b3": 42, "ddc9": 42, "de": [37, 46, 103], "deal": [37, 46], "debias": [16, 17, 26, 27, 40, 53, 59, 71, 73, 75, 100, 103, 104], "debt": [41, 60, 61], "decai": 67, "decid": [41, 60], "decis": [9, 37, 41, 46, 60, 61, 72, 103, 105], "decision_effect": 37, "decision_impact": [37, 46], "decisiontreeclassifi": [9, 35, 60], "decisiontreeregressor": 60, "declar": 105, "deep": [32, 33, 58], "deeper": 9, "def": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 47, 50, 57, 58, 59, 62, 63, 64, 66, 73, 76], "default": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 24, 26, 27, 28, 32, 33, 34, 35, 39, 40, 51, 54, 55, 57, 59, 63, 65, 66, 67, 68, 72, 73, 75, 89, 90, 91, 95, 99, 102, 105], "default_convert": 59, "defin": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 38, 41, 42, 45, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 60, 61, 63, 64, 65, 66, 72, 73, 74, 76, 79, 80, 90, 92, 95, 98], "definit": [28, 54, 55, 90, 91, 96], "defint": 90, "degre": [41, 48, 49, 59, 60, 72, 90, 92], "dekel": 103, "delete_origin": 42, "deliber": 62, "delta": [25, 39, 51, 66, 74], "delta_bench": 66, "delta_i": 39, "delta_j": 25, "delta_theta": [36, 45, 56, 65, 66, 90, 92], "delta_v": 66, "demand": [40, 59, 90, 92], "demir": [16, 17, 27, 40, 53, 59, 69, 75, 100, 103], "demo": 66, "demonstr": [38, 39, 40, 47, 59, 66, 70, 89, 99, 100, 102], "deni": 103, "denomin": [90, 91, 92, 96], "denot": [11, 40, 41, 51, 52, 59, 60, 66, 67, 72, 74, 76, 90, 92, 95, 96, 98], "dens_net_tfa": 41, "densiti": [10, 13, 14, 38, 45, 47], "dep": 43, "dep1": [42, 43, 70, 102], "dep2": [42, 43, 70, 102], "depend": [1, 3, 9, 10, 14, 21, 42, 48, 49, 51, 54, 55, 56, 57, 58, 63, 68, 72, 73, 76, 83, 88, 90, 91, 92, 98, 102, 103], "deprec": [68, 75], "depreci": 104, "depth": [9, 35, 41, 42, 63, 68, 72, 73, 74, 75, 76, 89, 102, 105], "deriv": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 31, 89], "describ": [39, 40, 59, 60, 61, 66, 73, 75, 101, 104], "descript": [41, 43, 65, 73, 75, 90, 92], "design": [45, 58, 103], "design_info": [48, 49], "design_matrix": [48, 49, 72], "desir": [19, 42, 63], "detail": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 30, 31, 38, 41, 42, 45, 47, 51, 52, 53, 58, 61, 65, 66, 69, 70, 72, 73, 74, 76, 78, 82, 83, 84, 85, 88, 89, 90, 92, 98, 99, 100, 102, 104, 105], "determin": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 41, 50, 60, 61, 64, 65, 74, 89, 90, 98, 99], "determinist": [63, 72], "deutsch": 100, "dev": 104, "develop": [39, 40, 42, 59, 66, 74, 104], "deviat": [57, 90, 98], "dezeur": 103, "df": [4, 7, 37, 38, 40, 45, 46, 48, 49, 50, 52, 55, 59, 62, 64, 65, 66, 67, 69, 72, 74], "df_agg": 53, "df_apo": 45, "df_apo_ci": 45, "df_apos_ci": 45, "df_ate": 45, "df_bench": 66, "df_binari": 66, "df_bonu": [42, 70, 102], "df_cate": [48, 49], "df_ci": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34], "df_coef": 57, "df_cvar": 61, "df_lqte": 61, "df_ml_g0": 57, "df_ml_g1": 57, "df_ml_m": 57, "df_pa": [51, 67], "df_plot": 40, "df_pq": 61, "df_qte": 61, "df_result": 53, "df_sort": 45, "df_summari": 60, "df_wide": 59, "dfg": 100, "dgp": [20, 40, 50, 52, 53, 59, 62, 63, 64, 66, 67], "dgp1": 20, "dgp2": 20, "dgp3": 20, "dgp4": 20, "dgp5": 20, "dgp6": 20, "dgp_dict": 66, "dgp_tpye": 51, "dgp_type": [20, 51], "diagon": 66, "diagram": [37, 46, 74], "dichotom": [37, 46], "dict": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 32, 33, 34, 35, 36, 48, 49, 53, 58, 66, 73], "dict_kei": [90, 95], "dictionari": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 21, 24, 36, 48, 49, 54, 55, 65, 72, 73, 90, 95], "dictonari": [41, 60], "did": [4, 7, 38, 51, 52, 59, 71, 104, 105], "diff": 60, "differ": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 21, 37, 38, 40, 41, 42, 45, 46, 47, 50, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 71, 72, 73, 75, 79, 80, 101, 102, 103, 104, 105], "difficult": 66, "dillon": 103, "dim": 41, "dim_x": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 22, 23, 25, 26, 27, 28, 29, 38, 40, 42, 47, 57, 58, 59, 69, 72, 73, 74, 90, 95], "dim_z": [11, 25, 74], "dimens": [21, 26, 40, 59, 63, 75], "dimension": [11, 12, 21, 23, 53, 72, 74, 75, 89, 90, 95, 99, 102, 103], "direct": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 47, 52, 67, 69, 105], "directli": [38, 39, 41, 45, 47, 57, 65, 69, 90, 95, 102, 105], "discret": [2, 24, 45, 59, 74, 104], "discretis": 61, "discuss": [22, 40, 41, 59, 60, 103, 104, 105], "disjoint": [40, 54, 55, 59], "displai": [40, 45, 59, 66, 72, 73, 90, 95], "displot": 60, "disproportion": [41, 60], "dist": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "distr": 73, "distribut": [38, 45, 47, 51, 57, 66, 69, 74, 90, 96, 101, 103, 104], "diverg": [38, 47, 69], "dmatrix": [48, 49, 72], "dml": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 30, 31, 37, 38, 42, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 76, 89, 90, 95, 99, 101], "dml1": [71, 102, 104, 105], "dml2": [37, 40, 42, 43, 51, 59, 61, 71, 74, 76, 89, 102, 104, 105], "dml_apo_obj": 74, "dml_apos_obj": 74, "dml_base": 59, "dml_combin": 89, "dml_cv_predict": 104, "dml_cvar": [50, 61], "dml_cvar_0": 50, "dml_cvar_1": 50, "dml_cvar_obj": [3, 72], "dml_data": [39, 40, 43, 45, 51, 52, 56, 57, 59, 62, 65, 66, 67, 72, 73, 74, 89, 99, 105], "dml_data_bench": 66, "dml_data_bonu": [42, 102], "dml_data_df": 105, "dml_data_lasso": 43, "dml_data_sim": [42, 102], "dml_df": [40, 59], "dml_did": [51, 52], "dml_did_obj": [5, 6, 74], "dml_iivm_boost": [41, 60], "dml_iivm_forest": [41, 60], "dml_iivm_lasso": [41, 60], "dml_iivm_obj": [8, 46, 74], "dml_iivm_tre": [41, 60], "dml_irm": [48, 54, 57, 63], "dml_irm_at": 56, "dml_irm_boost": [41, 60], "dml_irm_forest": [41, 60], "dml_irm_gat": 56, "dml_irm_gatet": 56, "dml_irm_lasso": [41, 43, 60], "dml_irm_new": 63, "dml_irm_obj": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 65, 72, 73, 74], "dml_irm_obj_ext": 73, "dml_irm_rf": 43, "dml_irm_tre": [41, 60], "dml_long": 36, "dml_lpq_0": 64, "dml_lpq_1": 64, "dml_lpq_obj": [10, 72], "dml_lqte": [61, 64], "dml_obj": [39, 45, 65, 66], "dml_obj_bench": 66, "dml_pliv": [40, 59], "dml_pliv_obj": [11, 40, 59, 74], "dml_plr": [49, 55, 89, 99], "dml_plr_1": 89, "dml_plr_2": 89, "dml_plr_boost": [41, 60], "dml_plr_forest": [41, 60, 105], "dml_plr_lasso": [41, 43, 60], "dml_plr_no_split": 75, "dml_plr_obj": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 65, 68, 72, 73, 74, 75, 76, 89, 90, 92, 95], "dml_plr_obj_extern": 75, "dml_plr_obj_intern": 75, "dml_plr_obj_onfold": 58, "dml_plr_obj_untun": 58, "dml_plr_rf": 43, "dml_plr_tree": [41, 60, 105], "dml_pq_0": [61, 64], "dml_pq_1": [61, 64], "dml_pq_obj": [13, 72], "dml_procedur": [43, 68, 102, 104, 105], "dml_qte": [61, 64], "dml_qte_obj": [14, 72], "dml_short": 36, "dml_ssm": [67, 74], "dml_tune": 104, "dmldummyclassifi": 73, "dmldummyregressor": 73, "dmlmt": 103, "dnorm": 38, "do": [39, 40, 41, 42, 57, 59, 60, 61, 62, 66, 72, 73, 90, 98, 102, 105], "doabl": 76, "doc": [37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 100, 104], "docu": 104, "document": [44, 48, 49, 52, 54, 55, 58, 66, 100, 104], "doe": [2, 14, 39, 40, 41, 45, 59, 60, 62, 65, 66, 90, 98, 105], "doesn": [37, 46], "doi": [16, 17, 18, 19, 20, 22, 26, 27, 29, 39, 40, 42, 53, 59, 66, 69, 73, 75, 89, 99, 100, 102, 104], "domain": 63, "don": [39, 58], "done": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 58, 61, 73, 75, 90, 92], "dosag": 45, "dot": [15, 52, 63, 70, 72, 73, 74, 89, 99, 102], "doubl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 26, 27, 28, 29, 41, 53, 60, 62, 71, 73, 75, 76, 89, 90, 92, 99, 104], "double_ml_bonus_data": 43, "double_ml_data_from_data_fram": [38, 69, 70, 105], "double_ml_data_from_matrix": [39, 42, 70, 73, 89, 99, 102], "double_ml_irm": [43, 63], "doubleiivm": 100, "doubleml": [38, 40, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 90, 95, 99, 102, 103, 104], "doubleml2022python": 100, "doubleml2024r": 100, "doubleml_did_eval_linear": 39, "doubleml_did_eval_rf": 39, "doubleml_did_linear": 39, "doubleml_did_rf": 39, "doubleml_framework": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "doublemlapo": [45, 74, 76, 77, 104], "doublemlblp": [1, 9, 12, 48, 49, 72, 104], "doublemlclusterdata": 26, "doublemlcvar": [50, 72, 76, 78, 104], "doublemldata": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 25, 27, 28, 29, 37, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 89, 90, 95, 99, 104, 105], "doublemldid": [51, 52, 74, 76, 79, 104], "doublemldidc": [51, 74, 76, 80, 104], "doublemlframework": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 75, 89, 104], "doublemlframwork": 2, "doublemlidid": 74, "doublemlididc": 74, "doublemliivm": [37, 41, 46, 60, 73, 74, 75, 76, 81, 104], "doublemlirm": [1, 3, 5, 6, 8, 10, 11, 12, 13, 15, 39, 41, 43, 45, 48, 54, 56, 57, 60, 62, 63, 65, 66, 72, 73, 74, 75, 76, 82, 100, 104], "doublemllpq": [64, 72, 76, 83, 104], "doublemlpliv": [73, 74, 75, 76, 86, 100, 104], "doublemlplr": [1, 2, 3, 5, 6, 8, 9, 10, 11, 13, 14, 15, 38, 41, 42, 43, 47, 49, 55, 58, 60, 62, 65, 68, 69, 72, 73, 74, 75, 76, 87, 89, 90, 95, 99, 100, 102, 104, 105], "doublemlpolicytre": [9, 72], "doublemlpq": [61, 64, 72, 76, 88, 104], "doublemlqt": [50, 61, 64, 72, 89, 104], "doublemlresampl": 57, "doublemlsmm": 104, "doublemlssm": [67, 74, 76, 84, 85], "doubli": [18, 19, 20, 39, 103], "down": 66, "download": [37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 70, 101, 102], "downward": 66, "dpg_dict": 65, "dpi": [38, 47, 62], "dramat": 39, "draw": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 66, 75, 104], "draw_sample_split": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 57, 75], "drawn": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 21, 41, 60, 61, 63, 75], "drive": [38, 47, 69], "driven": [66, 105], "drop": [39, 58, 59, 62, 70, 73, 76, 79, 80, 89, 99], "dt": [76, 80, 90, 93], "dt_bonu": 70, "dta": 39, "dtype": [43, 45, 51, 54, 55, 56, 57, 59, 60, 61, 65, 67, 70, 72, 102], "dualiti": 59, "dubourg": [100, 102], "duchesnai": [100, 102], "due": [38, 39, 47, 48, 49, 56, 65, 66, 69, 74, 90, 92, 104, 105], "duflo": [16, 17, 27, 40, 53, 59, 69, 75, 100, 103], "dummi": [1, 9, 12, 32, 33, 34, 58, 66, 72, 73, 74, 104], "dummyclassifi": 32, "dummyregressor": 33, "duplic": 104, "durabl": [42, 43, 70, 102], "durat": 17, "dure": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 39, 40, 41, 42, 58, 59, 60, 73, 75, 102, 104, 105], "dx": 22, "dynam": [39, 103], "e": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 24, 27, 29, 30, 31, 38, 39, 40, 41, 45, 47, 48, 49, 51, 53, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 69, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105], "e20ea26": 42, "e401": [41, 60, 61, 65, 105], "e4016553": 105, "e45228": 62, "e57c": 42, "each": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 24, 40, 42, 45, 52, 54, 55, 57, 58, 59, 61, 62, 63, 65, 66, 68, 70, 73, 75, 89, 90, 95, 99, 105], "earlier": 105, "earn": [41, 60, 61], "earner": [41, 60, 65], "easi": [42, 76], "easier": 58, "easili": [42, 57, 58, 61, 104], "ec973f": 62, "ecolor": [45, 52, 60, 62], "econ": 103, "econml": 103, "econom": [25, 26, 28, 29, 40, 53, 59, 62, 66, 75, 103], "econometr": [16, 17, 18, 19, 20, 27, 28, 39, 40, 53, 59, 69, 100, 103], "econometrica": [23, 40, 59, 62, 69, 103], "ecosystem": [100, 105], "ectj": [16, 17, 27, 40, 53, 59, 69, 100], "ed": 103, "edge_color": 47, "edgecolor": 47, "edit": [101, 103], "edu": [100, 102], "educ": [41, 60, 61, 65, 105], "ee97bda7": 42, "effect": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 24, 37, 38, 39, 40, 42, 45, 46, 47, 51, 52, 53, 56, 59, 63, 67, 69, 71, 73, 74, 75, 76, 82, 89, 90, 92, 102, 103, 104, 105], "effici": 103, "effort": 76, "eight": [40, 59], "either": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 21, 42, 52, 53, 63, 72, 73, 105], "eleanor": 103, "element": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 40, 48, 49, 50, 51, 57, 59, 61, 64, 65, 67, 76, 77, 79, 80, 90, 95, 97, 98, 104], "element_text": [40, 41], "elementari": 103, "elif": [54, 55, 63], "elig": [61, 65, 105], "eligibl": [41, 60, 65], "ell": [38, 40, 47, 53, 59, 69, 76, 86, 87, 102], "ell_0": [8, 11, 12, 38, 47, 53, 58, 69, 74], "ell_2": 57, "els": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 34, 39, 40, 41, 52, 54, 55, 59, 63, 66], "em": 103, "emphas": [40, 59], "empir": [30, 31, 38, 40, 47, 59, 62, 66, 69, 75, 76, 89, 99], "emploi": [40, 53, 59, 66, 76, 81], "employ": [41, 60, 61], "employe": 105, "empti": 59, "emul": [90, 92], "enabl": [45, 63, 65, 72, 90, 92, 104], "encapsul": [32, 33], "encod": 62, "end": [22, 25, 26, 38, 39, 40, 41, 47, 50, 52, 53, 57, 59, 60, 62, 63, 64, 67, 68, 70, 73, 75, 89, 99, 102, 105], "endogen": [41, 60, 61, 105], "enet_coordinate_descent_gram": 59, "engin": [42, 103], "enrol": [41, 60, 61], "ensembl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 43, 45, 47, 48, 49, 54, 55, 56, 57, 60, 63, 65, 66, 68, 72, 73, 74, 75, 76, 89, 90, 95, 102, 105], "ensemble_learner_pipelin": 73, "ensemble_pipe_classif": 42, "ensemble_pipe_regr": 42, "ensur": [40, 55, 58, 59, 63], "entir": [38, 41, 47, 60, 69, 90, 92], "entri": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 38, 40, 43, 45, 47, 51, 56, 59, 60, 61, 65, 67, 69, 70, 73, 100, 102, 104], "enumer": [45, 50, 52, 54, 55, 57, 59, 60, 61, 64, 68, 73, 75], "env": [59, 101], "environ": 101, "ep": 62, "epsilon": [41, 50, 51, 52, 60, 64, 72, 74], "epsilon_": [40, 52, 59], "epsilon_i": [21, 50, 62, 63, 64], "epsilon_sampl": 63, "epsilon_tru": [50, 64], "eqnarrai": 41, "equal": [1, 9, 40, 59, 62, 67, 72, 73, 90, 96], "equat": [40, 41, 59, 60, 66, 68, 89, 99, 105], "equilibrium": [40, 59], "equival": [53, 75], "err": [3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 43, 45, 46, 48, 49, 50, 51, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 72, 73, 74, 75, 76, 89, 102, 105], "error": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 37, 38, 39, 41, 42, 47, 52, 53, 54, 55, 57, 58, 60, 66, 69, 73, 74, 75, 76, 89, 90, 95, 99, 102, 104, 105], "errorbar": [45, 52, 54, 55, 58, 60, 62], "erstellt": [40, 41, 42], "especi": [57, 58], "essenti": 66, "est_method": 39, "esther": [75, 103], "estim": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 30, 31, 32, 33, 34, 35, 38, 39, 40, 42, 45, 47, 48, 49, 50, 52, 54, 55, 57, 59, 63, 68, 69, 71, 72, 73, 74, 78, 79, 80, 83, 85, 88, 90, 92, 95, 99, 100, 103, 104], "estimatior": [4, 7], "estimator_list": 58, "et": [16, 17, 21, 23, 26, 27, 38, 40, 41, 42, 47, 48, 49, 50, 51, 53, 54, 55, 57, 59, 60, 61, 64, 65, 69, 74, 75, 76, 78, 83, 88, 89, 90, 92, 98, 99, 100, 102, 104], "eta": [30, 31, 38, 40, 41, 52, 58, 59, 60, 64, 68, 72, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 98, 99, 102, 105], "eta1": 62, "eta2": 62, "eta_": [89, 90, 98, 99], "eta_0": [68, 76, 89], "eta_i": [21, 52, 63, 64], "eta_sampl": 63, "eta_tru": 64, "etc": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 40, 57, 58, 59, 104], "ev": [38, 47, 69], "eval": [42, 73], "eval_metr": [41, 60, 105], "eval_pr": 39, "eval_predict": 39, "evalu": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 42, 48, 49, 50, 52, 56, 61, 64, 65, 68, 103, 104], "evaluate_learn": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 57, 58, 73, 104], "evalut": 73, "even": [41, 42, 60, 62, 73, 105], "eventu": [40, 59], "everi": [40, 59], "everyth": 100, "evid": [56, 58], "exact": 66, "exactli": 66, "exampl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 21, 37, 38, 41, 42, 43, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 67, 68, 69, 72, 73, 74, 75, 76, 89, 90, 95, 99, 100, 102, 104, 105], "example_attgt": 39, "example_attgt_dml_eval_linear": 39, "example_attgt_dml_eval_rf": 39, "example_attgt_dml_linear": 39, "example_attgt_dml_rf": 39, "except": [53, 66, 104], "excess": 57, "exclud": 36, "exclus": [1, 9, 12, 54, 55, 72], "execut": [42, 105], "exemplarili": 102, "exemplatori": 63, "exhaust": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 73], "exhibit": [40, 59], "exist": [74, 90, 98], "exogen": [41, 60, 61, 105], "exp": [18, 19, 20, 21, 23, 24, 27, 38, 47, 48, 49, 52, 54, 55, 62, 63, 69], "expect": [18, 19, 39, 45, 51, 56, 57, 58, 66, 67, 72, 75, 89, 90, 91, 102], "experi": [17, 22, 23, 38, 41, 47, 60, 66, 69, 70, 75, 102, 103], "experiment": [5, 6, 20, 76, 79, 80, 90, 93, 94], "expertis": 66, "explain": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 65, 90, 92, 97, 98], "explan": [40, 51, 59, 65, 90, 97, 100, 105], "explanatori": [66, 89, 99], "explicit": 66, "explicitli": [56, 105], "exploit": [38, 47, 69, 105], "explor": 58, "exponenti": [89, 99], "export": [58, 104], "exposur": 52, "express": [40, 53, 90, 98], "extend": [66, 73, 100, 104], "extendend": [90, 98], "extens": [73, 76, 100, 103, 104], "extent": 53, "extern": [38, 47, 58, 71, 90, 92, 104], "external_predict": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 47, 73], "externalptr": 41, "extra": 42, "extract": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 58], "extralearn": 42, "extrem": [41, 60], "ey": 53, "f": [41, 42, 45, 47, 50, 51, 52, 53, 57, 59, 60, 61, 63, 64, 65, 66, 67, 73, 90, 98, 100, 102], "f00584a57972": 42, "f1718fdeb9b0": 42, "f2e7": 42, "f3d24993": 42, "f6ebc": 62, "f_": [18, 20, 52, 72], "f_loc": [50, 64], "f_p": 52, "f_scale": [50, 64], "face_color": 47, "facet_wrap": 41, "facilit": 58, "fact": [41, 60, 61], "factor": [38, 39, 40, 41, 42, 47, 57, 69, 73, 105], "faculti": 103, "fail": 104, "fair": 57, "fake": [37, 46], "fals": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 24, 34, 38, 41, 42, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 66, 67, 70, 73, 74, 75, 76, 79, 80, 89, 90, 93, 94, 99, 105], "famili": [41, 60, 73], "fanci": 39, "far": [41, 60], "farbmach": 22, "fast": [57, 63, 73], "faster": 53, "fb5c25fa": 42, "fc9e": 42, "fd8a": 42, "featur": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 35, 39, 43, 56, 57, 60, 63, 72, 73], "featureless": [42, 73], "features_bas": [41, 60, 61, 65], "features_flex": 41, "featureunion": 42, "februari": 66, "femal": [42, 43, 70, 102], "fern\u00e1ndez": [23, 75, 103], "fetch": [41, 59, 60, 61, 70], "fetch_401k": [41, 60, 61, 65, 105], "fetch_bonu": [42, 43, 70, 102], "few": [41, 60, 61], "ff7f0e": 52, "field": [40, 59, 73, 105], "fifteenth": 103, "fifth": 40, "fig": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 48, 49, 50, 52, 53, 57, 58, 61, 62, 64, 66], "fig_al": 47, "fig_dml": 47, "fig_non_orth": 47, "fig_orth_nosplit": 47, "fig_po_al": 47, "fig_po_dml": 47, "fig_po_nosplit": 47, "figsiz": [43, 45, 48, 49, 50, 52, 54, 55, 57, 58, 59, 60, 61, 62, 64], "figur": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 27, 38, 40, 43, 45, 47, 48, 49, 50, 52, 53, 54, 55, 58, 59, 60, 61, 64, 66, 69], "figure_format": 62, "file": [16, 17, 53, 62, 103, 104], "filenam": 38, "fill": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 40, 41, 51, 57, 60, 67], "fill_between": [48, 49, 50, 61, 64], "fill_valu": 57, "filter": 42, "filterwarn": 47, "final": [38, 42, 45, 47, 48, 49, 50, 52, 54, 55, 56, 61, 64, 67, 69, 74, 105], "financi": [16, 65, 105], "find": [41, 52, 60, 66, 72, 73, 105], "finish": 42, "finit": [38, 41], "firm": [40, 59, 65], "firmid": 59, "first": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 26, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 66, 67, 69, 72, 75, 89, 90, 95, 99, 101, 102, 104, 105], "fit": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 76, 79, 80, 85, 89, 90, 92, 95, 99, 100, 104, 105], "fit_arg": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "fit_transform": [59, 60], "five": 59, "fix": [52, 57, 60, 104], "flag": [20, 75, 101], "flake8": 104, "flamlclassifierdoubleml": 58, "flamlregressordoubleml": 58, "flatten": [58, 62], "flexibl": [37, 39, 41, 42, 46, 51, 60, 100, 105], "flexibli": [41, 60, 65], "float": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 34], "float32": [61, 65], "float64": [43, 45, 51, 55, 56, 59, 60, 65, 67, 70, 73, 102], "floor": 42, "floor_divid": 59, "flt": 42, "flush": 38, "fmt": [45, 52, 54, 55, 58, 60, 62], "focu": [40, 41, 59, 60, 61, 66, 72, 74, 105], "focus": [61, 65, 66, 105], "fold": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 40, 41, 42, 51, 57, 59, 60, 61, 65, 67, 68, 71, 73, 74, 76, 79, 80, 89, 102, 105], "follow": [18, 19, 20, 21, 24, 38, 40, 41, 47, 48, 49, 50, 51, 52, 54, 55, 58, 59, 60, 61, 64, 65, 66, 67, 69, 70, 72, 73, 74, 75, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 105], "font_scal": [59, 60, 61], "fontsiz": [50, 61, 64], "force_all_x_finit": [4, 7], "forest": [22, 37, 38, 39, 41, 42, 46, 47, 51, 56, 57, 60, 65, 69, 73, 102, 105], "forest_summari": 60, "forg": [101, 103, 104], "form": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 21, 34, 41, 48, 49, 50, 51, 52, 54, 55, 56, 57, 60, 64, 65, 67, 72, 74, 76, 77, 82, 90, 91, 92, 95, 96, 97, 98, 101, 102], "format": [47, 56, 90, 95], "formula": [40, 41, 59, 60, 66, 104], "formula_flex": 41, "forschungsgemeinschaft": 100, "forthcom": [66, 103], "forum": 104, "forward": [9, 35], "found": [48, 49, 53, 54, 55, 58, 69, 70, 73, 74, 102], "foundat": [100, 103], "four": [41, 57, 60, 104], "fourth": [40, 59], "frac": [8, 18, 19, 20, 22, 23, 25, 27, 28, 29, 31, 38, 40, 42, 47, 52, 53, 56, 59, 62, 68, 69, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99], "fraction": 42, "frame": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 37, 38, 40, 41, 43, 45, 48, 49, 51, 54, 55, 56, 59, 60, 61, 62, 63, 65, 67, 69, 70, 102, 105], "framework": [31, 38, 40, 42, 47, 57, 58, 59, 62, 66, 69, 73, 89, 99, 100, 102, 104, 105], "freez": 101, "fribourg": 103, "friendli": 45, "from": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 34, 37, 38, 40, 41, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 89, 90, 95, 99, 102, 104, 105], "from_arrai": [4, 7, 15, 47, 50, 51, 52, 64, 69, 70, 73, 89, 99, 102], "from_product": 59, "front": 45, "fr\u00e9chet": [90, 98], "fsize": [41, 60, 61, 65, 105], "full": [45, 47, 50, 51, 52, 54, 55, 57, 60, 61, 64, 67, 69], "fulli": [9, 41, 44, 58, 60, 74], "fun": 38, "func": 39, "function": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 27, 28, 30, 31, 37, 38, 41, 42, 46, 47, 48, 49, 50, 51, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 94, 98, 99, 100, 103, 104, 105], "fund": [41, 60, 61, 100], "further": [18, 19, 20, 21, 24, 26, 40, 42, 45, 48, 49, 50, 51, 52, 56, 57, 59, 61, 63, 64, 65, 66, 67, 73, 74, 76, 78, 83, 84, 85, 88, 89, 90, 92, 95, 97, 98, 99, 100, 102, 104, 105], "furthermor": [47, 76, 77, 82], "futurewarn": 55, "g": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 38, 39, 42, 43, 47, 48, 49, 51, 52, 53, 56, 57, 61, 62, 63, 65, 67, 69, 72, 73, 74, 76, 77, 79, 80, 81, 82, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 105], "g_": [45, 76, 78, 79, 80, 83, 88, 89, 99], "g_0": [1, 5, 6, 8, 9, 11, 12, 13, 27, 28, 38, 40, 41, 47, 57, 59, 60, 69, 72, 73, 74, 76, 77, 84, 85, 90, 91, 96, 98, 102, 105], "g_1": 57, "g_all": [38, 41], "g_all_po": 38, "g_ci": 41, "g_d": [76, 78, 88], "g_dml": 38, "g_dml_po": 38, "g_hat": [11, 12, 38, 47, 76], "g_hat0": [8, 9], "g_hat1": [8, 9], "g_k": 72, "g_nonorth": 38, "g_nosplit": 38, "g_nosplit_po": 38, "g_x": 52, "gain": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 36, 57, 90, 92, 96, 104], "gain_statist": 104, "galleri": [69, 72, 73, 74, 100, 104], "gama": 58, "gamma": [25, 28, 29, 40, 59, 62, 63, 66, 76, 78, 83], "gamma_0": [21, 63, 67, 76, 78, 83], "gamma_a": [18, 19, 66], "gamma_bench": 66, "gamma_v": 66, "gap": [59, 66], "gapo": 1, "gate": [1, 9, 12, 34, 62, 63, 71, 104], "gate_obj": 72, "gatet": 72, "gaussian": [10, 13, 14, 38, 47, 69, 72, 73, 89, 99, 103], "ge": [18, 20, 21, 56, 63, 72], "geer": 103, "gelbach": [40, 59], "gener": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 37, 39, 40, 41, 42, 43, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 82, 89, 91, 92, 93, 94, 96, 98, 99, 103, 104, 105], "generate_treat": 64, "geom_bar": 41, "geom_dens": 41, "geom_errorbar": 41, "geom_funct": 38, "geom_histogram": 38, "geom_hlin": 41, "geom_point": 41, "geom_til": 40, "geom_vlin": 38, "german": 100, "get": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 32, 33, 42, 45, 57, 62, 65, 66, 90, 92, 100, 101], "get_dummi": 62, "get_feature_names_out": [59, 60], "get_legend_handles_label": 45, "get_level_valu": 58, "get_logg": [38, 39, 40, 41, 42, 68, 73, 74, 75, 76, 89, 99, 102], "get_metadata_rout": [32, 33], "get_param": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 32, 33, 58, 73], "ggdid": 39, "ggplot": [38, 40, 41], "ggplot2": [38, 40, 41], "ggsave": 38, "ggtitl": 41, "gh": 104, "git": 101, "github": [39, 41, 53, 58, 60, 62, 100, 103, 104], "githubusercont": 53, "give": [41, 60], "given": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 23, 27, 28, 31, 38, 40, 45, 47, 52, 54, 55, 59, 61, 62, 66, 67, 69, 72, 76, 77, 89, 90, 91, 95, 96, 97, 98, 99, 102, 104], "glmnet": [41, 42, 73, 104], "global": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 73], "glrn": 42, "glrn_lasso": 42, "gname": 39, "go": [48, 49, 53, 58, 66], "goal": [45, 54, 55], "goldman": 103, "good": [53, 90, 92, 105], "gradient": [41, 60], "gradientboostingclassifi": 57, "gradientboostingregressor": 57, "gradual": 66, "gramfort": [100, 102], "graph": [42, 67, 105], "graph_ensemble_classif": 42, "graph_ensemble_regr": 42, "graph_object": [48, 49, 53, 66], "graphlearn": [42, 73], "grasp": [45, 90, 92], "great": [52, 105], "greater": 105, "green": [38, 48, 49, 50, 64], "greg": 103, "grei": [41, 45], "grenand": 103, "grey50": 40, "grid": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 42, 45, 48, 49, 50, 53, 61, 62, 64, 66, 73, 90, 95], "grid_arrai": [48, 49], "grid_bound": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 66], "grid_search": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 42, 73], "grid_siz": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 48, 49], "gridextra": 40, "gridsearchcv": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 73], "grisel": [100, 102], "grob": 40, "group": [1, 9, 12, 37, 39, 45, 46, 56, 61, 62, 63, 66, 71], "group_0": 72, "group_1": [54, 55, 72], "group_2": [54, 55, 72], "group_3": [54, 55], "group_effect": 63, "group_ind": 56, "group_treat": 56, "groupbi": [53, 60], "gruber": 22, "gt": [37, 39, 40, 41, 42, 43, 45, 46, 48, 49, 50, 51, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 70, 102], "guarante": [40, 59], "guber": 22, "guess": [65, 90, 92], "guid": [30, 31, 32, 33, 38, 39, 40, 42, 45, 47, 52, 56, 59, 65, 73, 100, 102, 104], "guidelin": 104, "gunion": [42, 73], "gxidclusterperiodytreat": 39, "h": [18, 19, 20, 22, 26, 39, 40, 59, 103], "h20": 58, "h_0": [45, 56, 65, 66, 90, 95, 105], "ha": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 20, 34, 35, 38, 39, 40, 41, 47, 53, 57, 58, 59, 60, 61, 62, 65, 66, 72, 73, 74, 90, 91, 92, 95, 96, 97, 98, 105], "half": [38, 47, 62, 69, 75], "hand": [57, 58, 62, 105], "handbook": 62, "handl": [39, 45, 57, 73, 104], "hansen": [16, 17, 23, 25, 27, 40, 53, 59, 69, 100, 103], "happend": 57, "hard": [65, 90, 92], "harold": 103, "hat": [38, 40, 47, 53, 56, 59, 62, 68, 69, 72, 75, 76, 89, 90, 92, 95, 97, 99], "have": [1, 2, 9, 12, 14, 21, 24, 34, 35, 37, 38, 39, 40, 41, 42, 45, 46, 48, 49, 51, 52, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 70, 72, 73, 89, 90, 91, 92, 98, 101, 102, 104, 105], "hazlett": [66, 90, 92], "hc": [39, 103], "hc0": 34, "hdm": [40, 59], "he": 67, "head": [39, 40, 42, 43, 48, 49, 54, 55, 58, 59, 60, 62, 66, 70, 72, 102], "heat": [40, 59], "heatmap": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 59, 66], "heavili": 57, "hei": 103, "height": [38, 40, 53, 58], "help": [39, 41, 50, 57, 61, 63, 66, 75, 105], "helper": 104, "henc": [39, 41, 42, 60, 66, 73, 76, 105], "here": [10, 13, 14, 39, 40, 41, 42, 48, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 66, 67, 70, 73, 101], "heterogen": [9, 21, 41, 56, 60, 61, 63, 71, 74, 75, 103, 104, 105], "heteroskedast": [54, 55], "heurist": [38, 47, 69], "high": [11, 12, 23, 41, 52, 53, 60, 61, 68, 74, 89, 99, 100, 102, 103], "higher": [39, 41, 53, 60, 61, 62, 104, 105], "highli": [41, 60, 100], "highlight": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 51, 58, 66, 104], "highlightcolor": [48, 49], "hint": 58, "hispan": 43, "hist": 45, "hist_e401": 41, "hist_p401": 41, "histogram": 45, "histplot": 47, "hjust": 41, "hline": [70, 89, 99, 102, 105], "hold": [29, 40, 41, 58, 59, 60, 67, 72, 73], "holdout": [73, 75], "holm": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "home": [41, 60, 66], "homogen": 74, "hopefulli": 61, "horizont": [40, 52, 59], "hostedtoolcach": 60, "hot": 62, "hotstart_backward": [42, 73], "hotstart_forward": [42, 73], "household": [41, 60, 61, 65], "how": [32, 33, 37, 39, 40, 41, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 69, 73, 100, 101], "howev": [38, 41, 47, 58, 60, 66, 67, 69, 105], "hown": [41, 60, 61, 65, 105], "hpwt": [40, 59], "hpwt0": 40, "hpwtairmpdspac": 40, "href": 100, "hspace": 57, "hstack": [15, 52], "html": [42, 55, 100, 102, 104], "http": [22, 28, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 73, 100, 101, 102, 104], "huber": [29, 67, 74, 76, 84, 85, 103], "hue": 60, "huge": 57, "hugo": 103, "husd": [42, 43, 70, 102], "hyperparamet": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 42, 43, 53, 57, 58, 60, 71, 102], "hypothes": [89, 99, 103], "hypothesi": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 60, 65, 90, 95, 103], "hypothet": 66, "i": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 85, 88, 89, 90, 91, 92, 95, 96, 98, 99, 100, 101, 102, 104, 105], "i0": [51, 52, 74], "i03": 100, "i1": [51, 74], "i_": [25, 59, 63], "i_1": [40, 59], "i_2": [40, 59], "i_3": [40, 59], "i_4": 52, "i_est": 47, "i_fold": 40, "i_k": [40, 59, 68, 75, 89, 99], "i_learn": 57, "i_level": 45, "i_rep": [38, 47, 51, 57, 67, 69], "i_split": 59, "i_train": 47, "icp": 103, "id": [39, 40, 42, 59], "id_var": 59, "idea": [41, 42, 60, 61, 66, 73, 90, 92, 105], "ident": [18, 19, 20, 21, 24, 25, 35, 42, 45, 58, 73, 90, 95], "identfi": 66, "identif": [74, 105], "identifi": [40, 41, 51, 56, 59, 60, 61, 66, 72, 74, 90, 98, 104], "identifii": 72, "idnam": 39, "idx_tau": [50, 61, 64], "idx_treat": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 90, 95], "ieee": 103, "ifels": 39, "ignor": 47, "ii": [40, 59], "iid": 74, "iivm": [8, 22, 30, 31, 61, 68, 72, 81, 100, 104], "iivm_summari": 60, "iivmglmnet": 41, "iivmrang": 41, "iivmrpart": 41, "iivmxgboost11861": 41, "ij": [26, 40, 45, 59, 67], "ilia": 103, "illustr": [38, 40, 41, 42, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 63, 64, 65, 66, 67, 69, 73, 105], "iloc": [45, 51, 52, 57, 59, 62], "immedi": 101, "immun": [75, 103], "impact": [37, 46, 57, 62, 65], "implement": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 30, 31, 38, 39, 40, 41, 42, 47, 51, 53, 57, 59, 60, 62, 65, 66, 67, 69, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 99, 100, 102, 103, 104, 105], "impli": [18, 19, 40, 41, 59, 60, 61, 72, 90, 91, 93, 94, 96], "implment": 52, "import": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 101, 102, 104, 105], "importlib": 53, "impos": 66, "improv": [51, 57, 63, 104], "in_sample_norm": [5, 6, 51, 76, 79, 80, 90, 93, 94], "inbuild": 57, "inbuilt": 57, "inc": [41, 60, 61, 65, 105], "includ": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 36, 39, 41, 45, 52, 54, 55, 60, 65, 66, 72, 74, 89, 90, 91, 95, 96, 98, 99, 104, 105], "include_bia": [59, 60], "include_scenario": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 66], "incom": [41, 60, 61, 63, 65, 105], "incorpor": [42, 65, 90, 95], "increas": [56, 57, 59, 66, 105], "increment": 104, "ind": 60, "independ": [5, 6, 18, 19, 20, 21, 40, 42, 52, 56, 59, 63, 74, 76, 79, 80, 104], "index": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 40, 43, 47, 52, 53, 54, 55, 58, 59, 60, 62, 63, 69, 70, 75, 76, 79, 80, 102], "index_col": 53, "india": [75, 103], "indic": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 24, 29, 34, 40, 41, 52, 56, 59, 60, 61, 66, 67, 68, 70, 72, 74, 75], "individu": [1, 9, 39, 41, 45, 52, 54, 55, 56, 58, 60, 61, 65, 72, 105], "individual_df": 52, "induc": [71, 75], "industri": [40, 59], "inf": [4, 7, 39], "inf_model": 76, "infer": [23, 25, 37, 38, 40, 46, 47, 53, 59, 69, 71, 75, 100, 102, 103, 104], "inferenti": 105, "infinit": [4, 7, 104], "info": [37, 42, 43, 45, 51, 56, 58, 59, 60, 61, 65, 67, 70, 102, 104, 105], "inform": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 33, 34, 37, 42, 46, 48, 49, 57, 65, 66, 90, 92, 103], "infti": [38, 47, 69], "inher": 66, "inherit": [62, 104], "initi": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 41, 42, 50, 51, 60, 61, 64, 65, 66, 67, 70, 72, 73, 75, 102, 104, 105], "inlin": [43, 62], "inlinebackend": 62, "inner": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 73], "innermost": 73, "input": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 42, 65, 68, 89, 90, 92, 95, 99], "insight": [53, 66], "insignific": 65, "inspect": 102, "inspir": [18, 22, 23, 29, 66], "instal": [41, 58, 104], "install_github": 101, "instanc": [41, 42, 60, 73], "instanti": [40, 41, 59, 60, 73, 75], "instead": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 37, 39, 41, 45, 46, 55, 56, 58, 60, 61, 72, 73, 90, 93, 94, 96, 97, 104], "instruct": 104, "instrument": [4, 7, 8, 11, 16, 22, 25, 40, 41, 42, 43, 45, 51, 56, 59, 60, 61, 64, 65, 67, 70, 73, 74, 76, 83, 89, 102, 105], "instrument_effect": 37, "instrument_impact": 46, "insuffienct": 58, "int": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 21, 24, 34, 35, 39, 40, 41, 46, 50, 51, 63, 64, 66, 67], "int64": [43, 57, 59, 70, 102], "int8": [60, 61, 65], "integ": [20, 42, 73], "integr": [58, 66, 90, 98, 104], "intend": [42, 66, 105], "intent": 105, "inter": 73, "interact": [1, 2, 8, 9, 18, 22, 23, 24, 45, 66, 71, 73, 91, 96, 100, 104, 105], "interchang": 89, "interest": [8, 9, 11, 12, 18, 19, 38, 41, 47, 51, 53, 60, 61, 67, 69, 72, 74, 76, 89, 99, 102, 105], "interfac": [39, 41, 42, 70, 73, 75, 102], "intermedi": [55, 66], "intern": [39, 41, 42, 45, 58, 61, 73, 103], "internet": [41, 60, 61], "interpret": [54, 55, 66, 72, 90, 91, 92, 96, 97, 98, 101, 105], "intersect": [66, 90, 95, 104], "interv": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 39, 40, 41, 45, 48, 49, 50, 51, 54, 55, 59, 61, 64, 65, 67, 71, 72, 75, 76, 90, 95, 102, 103, 105], "introduc": [38, 47, 69, 70, 89, 99, 104, 105], "introduct": [38, 40, 42, 47, 59, 61, 65, 73, 74, 90, 92], "introductori": [39, 66], "intrument": 67, "intuit": 66, "inuidur1": [42, 43, 70, 102], "inuidur1femaleblackothracedep1dep2q2q3q4q5q6agelt35agegt54durablelusdhusdtg": [42, 70, 102], "inuidur2": [43, 70, 102], "inv_sigmoid": 62, "invalid": [38, 47, 69], "invari": 74, "invers": [1, 3, 8, 9, 10, 13, 14, 15, 67, 90, 91, 96], "invert_yaxi": 59, "investig": [53, 58, 66], "involv": [72, 73, 76, 105], "io": [62, 104], "ipw_norm": 104, "ipykernel_43024": 55, "ipynb": [37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67], "ira": [41, 60, 61], "irm": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 23, 24, 30, 31, 34, 35, 57, 66, 68, 71, 73, 82, 91, 96, 100, 104, 105], "irm_summari": 60, "irmglmnet": 41, "irmrang": 41, "irmrpart": 41, "irmxgboost8047": 41, "irrespect": 66, "is_classifi": [1, 5, 6, 8, 9, 12], "is_gat": [1, 9, 12, 34], "isnan": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 57, 73], "isoton": 66, "isotonicregress": 66, "issn": 53, "issu": [60, 66, 100, 103, 104], "ite": [45, 54, 55, 56], "item": [8, 60, 68, 73, 75], "iter": [37, 51, 59, 67, 73, 89, 99, 105], "itertool": 53, "its": [32, 33, 66, 68, 72, 73, 74, 75, 76, 89], "iv": [8, 11, 12, 22, 25, 26, 38, 40, 47, 59, 69, 70, 86, 87, 90, 97, 100, 104, 105], "iv_2": 37, "iv_var": [40, 59], "iv\u00e1n": [75, 103], "j": [16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 38, 39, 40, 42, 45, 47, 53, 59, 62, 67, 69, 73, 74, 89, 99, 100, 102], "j_": [40, 59], "j_0": 89, "j_1": [40, 59], "j_2": [40, 59], "j_3": [40, 59], "j_k": [40, 59], "jame": 103, "janni": [41, 60], "javanmard": 103, "jbe": [40, 59], "jeconom": [18, 19, 20, 39], "jerzi": 103, "jia": 66, "jk": 74, "jmlr": [42, 100, 102, 104], "job": [41, 60, 61], "joint": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 45, 48, 49, 50, 54, 55, 61, 64, 74, 89, 104, 105], "jointli": [64, 72], "joss": [42, 73, 100, 102], "journal": [16, 17, 18, 19, 20, 26, 27, 29, 39, 40, 42, 53, 59, 62, 66, 69, 73, 100, 102, 103, 104], "jss": 100, "jump": 63, "jun": [39, 103], "jupyt": [37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67], "juraj": 103, "just": [39, 42, 45, 50, 51, 52, 54, 55, 56, 63, 64, 76, 79, 80, 90, 92], "justif": [75, 90, 92], "k": [16, 19, 20, 22, 23, 25, 26, 27, 29, 38, 40, 42, 47, 57, 58, 59, 68, 69, 71, 72, 89, 99, 105], "kaggl": [41, 60], "kallu": [50, 61, 64, 65, 76, 78, 83, 88, 103], "kato": [26, 40, 59, 89, 99, 103], "kb": [45, 51, 56, 59, 60, 61, 65, 70, 102], "kde": [10, 13, 14, 60], "kdeplot": [51, 57, 67], "kdeunivari": [10, 13, 14], "kecsk\u00e9sov\u00e1": 104, "keep": [39, 55, 66, 105], "kei": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 35, 40, 41, 48, 49, 54, 55, 58, 59, 60, 61, 66, 73, 76, 90, 95, 104], "keith": 103, "kengo": 103, "kernel": [10, 13, 14], "keyword": [1, 9, 12, 20, 26, 27, 28, 34], "kf": 75, "kfold": [59, 75], "kind": [37, 46, 60], "kj": [19, 20, 22, 23, 25, 26, 27, 29, 38, 40, 47, 59, 69], "klaassen": [22, 66, 100, 103], "klaa\u00dfen": 22, "knau": 103, "know": [51, 63], "knowledg": [37, 46, 57, 62, 63], "known": [56, 57, 66, 73], "kohei": 103, "kotthof": 42, "kotthoff": [42, 73, 100, 102], "krueger": 62, "kueck": [41, 60], "kurz": [100, 103, 104], "kwarg": [1, 9, 12, 18, 19, 20, 24, 26, 27, 28, 32, 34, 58], "l": [40, 42, 43, 48, 49, 59, 66, 67, 73, 90, 97, 100, 102], "l1": [60, 67, 74], "l_hat": [11, 12, 38, 47, 76], "label": [45, 47, 48, 49, 50, 52, 54, 55, 58, 61, 62, 64], "labor": 62, "laffer": 103, "laff\u00e9r": [29, 67, 74, 76, 84, 85], "lal": [62, 104], "lambda": [40, 41, 42, 60, 62, 63, 73, 76, 80, 89, 99, 102], "lambda_": 53, "lambda_0": [76, 80], "lambda_t": 20, "land": 63, "lang": [42, 73, 100, 102], "langl": [21, 63], "lappli": 75, "larg": [38, 47, 56, 57, 58, 62, 66], "larger": [9, 39, 66, 90, 95], "largest": 57, "largli": 57, "lasso": [40, 41, 42, 60, 67, 73, 102, 103], "lasso_class": [41, 60], "lasso_pip": [42, 73], "lasso_summari": 60, "lassocv": [15, 53, 59, 60, 67, 73, 74, 89, 99, 102], "last": [20, 42, 101], "late": [8, 37, 41, 60, 74, 76, 81], "latent": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 65, 90, 97, 98], "later": [41, 42, 66, 73, 105], "layout": 53, "lbrace": [8, 9, 22, 23, 29, 40, 59, 68, 74, 75, 76, 77, 89, 90, 91, 99], "ldot": [11, 12, 40, 59, 67, 68, 74, 75, 89, 99, 102], "le": [20, 51, 63, 72, 74, 76, 83, 88], "lead": [39, 66], "leadsto": 89, "lear": [42, 73, 100, 102], "learn": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 26, 27, 28, 29, 37, 41, 42, 43, 45, 46, 50, 53, 57, 58, 60, 61, 62, 64, 66, 70, 71, 73, 75, 76, 89, 90, 92, 99, 104, 105], "learner": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 38, 39, 40, 41, 47, 48, 49, 51, 53, 59, 60, 61, 65, 66, 67, 68, 69, 71, 74, 75, 76, 89, 90, 95, 99, 104, 105], "learner_class": [15, 104], "learner_cv": 42, "learner_forest_classif": 42, "learner_forest_regr": 42, "learner_l": 65, "learner_lasso": 42, "learner_list": 57, "learner_m": 65, "learner_nam": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 73], "learner_param_v": 42, "learner_rf": 89, "learnerclassif": 42, "learnerregr": 42, "learnerregrcvglmnet": 42, "learnerregrrang": [42, 73], "learning_r": [47, 50, 61, 64, 66, 69], "least": [37, 41, 46, 60, 61, 65, 75], "leav": [66, 67], "left": [22, 23, 25, 26, 29, 38, 40, 45, 47, 57, 59, 60, 61, 62, 64, 69, 76, 79, 80, 89, 90, 91, 93, 94, 96, 99], "legend": [41, 45, 47, 48, 49, 50, 52, 54, 55, 57, 61, 62, 64], "len": [45, 50, 57, 58, 59, 61, 64], "length": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 42, 51, 73], "leq": [40, 59], "less": [39, 41, 60, 61, 66], "lester": 103, "let": [18, 19, 20, 24, 38, 39, 41, 42, 45, 47, 50, 51, 54, 55, 57, 60, 61, 64, 66, 67, 68, 69, 73, 74, 90, 92, 98, 105], "level": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 24, 34, 40, 41, 45, 48, 49, 50, 51, 52, 54, 55, 56, 59, 60, 61, 64, 65, 66, 67, 73, 76, 77, 90, 91, 95, 105], "level_0": [42, 59], "level_1": 59, "level_bound": 45, "levinsohn": [40, 59], "lewi": 103, "lgbmclassifi": [50, 51, 52, 57, 61, 64, 66], "lgbmregressor": [47, 50, 51, 52, 57, 61, 66, 69], "lgr": [38, 39, 40, 41, 42, 68, 73, 74, 75, 76, 89, 99, 102], "lib": [59, 60], "liblinear": [60, 67, 74], "librari": [37, 38, 39, 40, 41, 42, 68, 69, 70, 73, 74, 75, 76, 89, 99, 101, 102, 105], "licens": 104, "lie": 103, "lightgbm": [47, 50, 51, 52, 57, 61, 64, 66], "like": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 39, 41, 42, 53, 55, 60, 61, 66, 73, 75, 102, 105], "lim": 62, "limegreen": [48, 49], "limit": [62, 103], "limits_": 72, "lin": 66, "line": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 52, 66], "linear": [1, 9, 11, 12, 18, 19, 24, 25, 26, 27, 28, 30, 31, 34, 37, 38, 39, 40, 42, 45, 46, 47, 48, 49, 51, 52, 53, 54, 57, 58, 59, 65, 66, 68, 69, 71, 72, 73, 75, 77, 79, 80, 81, 82, 86, 87, 89, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105], "linear_model": [1, 9, 12, 15, 34, 43, 45, 46, 53, 57, 59, 60, 66, 67, 73, 74, 89, 99, 102], "linearregress": [37, 45, 46, 57, 66], "linearscoremixin": 76, "lineplot": 45, "linestyl": [45, 52, 58], "linewidth": 52, "link": [66, 104], "linspac": [48, 49, 66], "lint": 104, "linux": 101, "list": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 38, 39, 40, 41, 42, 47, 48, 49, 59, 61, 63, 69, 73, 75, 76, 101, 104], "listedcolormap": 59, "literatur": [66, 74], "littl": 56, "ll": [42, 89, 99, 105], "lllllllllllllllll": [70, 102], "lm": [37, 39, 66], "ln_alpha_ml_l": 53, "ln_alpha_ml_m": 53, "load": [37, 39, 41, 42, 53, 60, 61, 70, 101, 102], "loc": [45, 47, 50, 52, 53, 55, 59, 62, 64, 65, 66], "local": [8, 10, 72, 74, 103, 104], "localconvert": 59, "locat": [50, 64], "log": [40, 53, 57, 59, 62, 65, 73, 74], "log_odd": 63, "log_p": [40, 59], "log_reg": [37, 39], "logarithm": 53, "logic": [8, 42, 73], "logical_not": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 57, 73], "logist": [18, 37, 39, 41, 45, 46, 60, 66, 67, 105], "logisticregress": [37, 43, 45, 46, 66], "logisticregressioncv": [15, 57, 60, 67, 74], "logit": [57, 62], "loglik": 42, "logloss": [41, 60, 105], "logo": 104, "logspac": 60, "long": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 38, 47, 57, 65, 66, 90, 92, 98, 103], "look": [39, 41, 42, 50, 51, 52, 57, 60, 61, 64, 65], "loop": 45, "loss": [57, 58, 65, 73, 74], "loss_ml_g0": 57, "loss_ml_g1": 57, "loss_ml_m": 57, "low": [52, 56, 72, 103], "lower": [41, 42, 45, 50, 52, 53, 56, 61, 62, 64, 65, 66, 73, 90, 95, 98, 105], "lower_bound": [48, 49], "lpq": [10, 14, 61, 72, 83, 104], "lpq_0": 64, "lpq_1": 64, "lqte": 72, "lrn": [37, 38, 39, 40, 41, 42, 68, 73, 74, 75, 76, 89, 99, 102, 105], "lrn_0": 42, "lt": [37, 39, 40, 41, 42, 43, 45, 51, 56, 59, 60, 61, 63, 65, 66, 67, 70, 102], "lucien": 104, "luka": 103, "luk\u00e1\u0161": 29, "lusd": [42, 43, 70, 102], "lvert": 53, "m": [15, 16, 17, 18, 25, 26, 27, 38, 40, 42, 43, 47, 53, 56, 59, 62, 69, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 94, 96, 97, 98, 100, 101, 102, 103, 104], "m_": [45, 74, 76, 77, 83, 89, 99], "m_0": [1, 3, 5, 6, 8, 9, 11, 12, 13, 27, 28, 38, 40, 41, 47, 53, 56, 58, 59, 60, 69, 72, 73, 74, 76, 78, 79, 80, 83, 84, 85, 88, 102, 105], "m_hat": [8, 9, 11, 12, 38, 47, 76], "ma": [26, 40, 59, 103], "mac": 101, "machin": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 26, 27, 28, 29, 37, 41, 42, 43, 45, 46, 50, 51, 53, 58, 60, 61, 62, 64, 65, 66, 67, 71, 73, 74, 75, 76, 89, 90, 92, 99, 104, 105], "machineri": [53, 103], "mackei": 103, "maco": 101, "made": [74, 105], "mae": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 57, 73], "maggi": 103, "magnitud": [90, 92], "mai": [51, 67], "main": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 53, 61, 66, 89, 90, 92, 99, 103, 105], "mainli": 66, "maintain": [39, 100, 104], "mainten": 104, "major": [42, 66, 104], "make": [37, 45, 46, 57, 58, 66, 72, 73, 104, 105], "make_confounded_irm_data": [66, 104], "make_confounded_plr_data": 65, "make_did_sz2020": [5, 6, 51, 74], "make_heterogeneous_data": [48, 49, 54, 55, 56], "make_iivm_data": [8, 10, 72, 74], "make_irm_data": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 57, 72, 73, 74], "make_irm_data_discrete_treat": 45, "make_pipelin": 60, "make_pliv_chs2015": [11, 74], "make_pliv_multiway_cluster_ckms2021": [4, 40, 59], "make_plr_ccddhnr2018": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 38, 47, 58, 68, 69, 72, 73, 74, 75, 76, 89, 90, 95], "make_spd_matrix": 28, "make_ssm_data": [67, 74], "malt": [100, 103], "maltekurz": 100, "man": [37, 46], "manag": [73, 101], "mani": [25, 30, 31, 38, 39, 40, 42, 47, 51, 58, 59, 69, 76, 89, 99, 105], "manili": 34, "manipul": [41, 42], "manual": [41, 58, 65, 105], "mao": 103, "map": [8, 32, 33, 39, 40, 59, 72, 74], "mapsto": [68, 72], "mar": [29, 74], "margin": [48, 49, 66], "marit": [41, 60], "marker": [45, 66], "markers": 62, "market": 62, "markettwo": 40, "markov": [28, 103], "marr": [41, 60, 61, 65, 105], "marshal": 73, "martin": [29, 66, 100, 103, 104], "masatoshi": 103, "master": 39, "mat": 40, "match": [73, 90, 97], "math": 15, "mathbb": [8, 9, 11, 12, 18, 19, 20, 24, 30, 31, 40, 45, 51, 52, 56, 57, 58, 59, 62, 67, 72, 74, 76, 77, 78, 79, 80, 82, 83, 84, 85, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 102, 105], "mathcal": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 38, 40, 47, 50, 52, 59, 63, 64, 67, 69], "mathop": 72, "mathrm": [18, 19], "matplotlib": [43, 45, 47, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 64, 66, 67], "matric": [63, 71, 104], "matrix": [18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 38, 40, 41, 42, 47, 59, 67, 69, 70, 73, 89, 99, 102, 104, 105], "matt": 103, "matter": [57, 62], "max": [41, 42, 60, 61, 68, 72, 73, 74, 75, 76, 78, 89, 102, 105], "max_depth": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 43, 60, 65, 68, 72, 73, 74, 75, 76, 89, 90, 95, 102, 105], "max_featur": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 43, 60, 65, 68, 72, 73, 74, 75, 76, 89, 90, 95, 102, 105], "max_it": [59, 60, 66], "maxim": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 63, 72], "maxima": [89, 99], "maximum": [72, 73], "mb": [43, 67, 70, 102], "mb706": 104, "mea": 22, "mean": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 38, 40, 41, 45, 46, 47, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 69, 73, 89, 105], "mean_absolute_error": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 57, 73], "meant": [72, 104], "measir": 65, "measur": [39, 42, 53, 58, 65, 66, 73, 74, 90, 91, 92, 96, 97, 98], "measure_col": 53, "measure_func": 39, "measure_pr": 39, "measures_r": 39, "mechan": [32, 33, 66], "median": [66, 75], "melt": 40, "membership": 66, "memori": [43, 45, 51, 56, 59, 60, 61, 65, 67, 70, 102], "mention": [56, 72], "merg": [41, 60], "mert": [75, 103], "meshgrid": [48, 49, 66], "messag": [38, 39, 40, 41, 42, 102, 104], "meta": [73, 102], "metadata": [32, 33], "metadatarequest": [32, 33], "method": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 54, 55, 57, 59, 60, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 89, 90, 92, 95, 99, 100, 102, 104], "methodolog": 103, "methodologi": 66, "metric": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 73], "michael": 103, "michaela": 104, "michel": [100, 102], "michela": [29, 103], "mid": [41, 60, 62], "mid_point": 45, "might": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 50, 57, 59, 63, 65, 66, 73], "mild": [38, 47, 69], "militari": 62, "miller": [40, 59], "mimic": 66, "min": [40, 41, 42, 50, 59, 60, 61, 64, 68, 73, 74, 75, 76, 89, 99, 102, 105], "min_": 72, "min_samples_leaf": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 35, 56, 60, 65, 68, 72, 73, 74, 75, 76, 89, 90, 95, 105], "min_samples_split": 60, "minim": [9, 35, 41, 57, 60], "minor": [38, 47, 69, 76, 104], "minsplit": 41, "minut": 58, "miruna": 103, "mislead": 104, "miss": [4, 7, 15, 42, 73, 74, 76, 84, 104], "missing": [29, 67], "misspecif": 51, "misspecifi": 51, "mit": [100, 102], "mixin": [30, 31, 76], "ml": [28, 40, 41, 42, 53, 58, 59, 60, 68, 71, 73, 75, 100, 103, 104], "ml_g": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 38, 39, 41, 43, 45, 46, 47, 48, 50, 51, 52, 54, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 69, 72, 73, 74, 104], "ml_g0": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 39, 41, 43, 51, 57, 60, 65, 73, 74], "ml_g1": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 39, 41, 43, 51, 57, 60, 65, 73, 74], "ml_g_d0": [67, 74], "ml_g_d0_t0": [51, 74], "ml_g_d0_t1": [51, 74], "ml_g_d1": [67, 74], "ml_g_d1_t0": [51, 74], "ml_g_d1_t1": [51, 74], "ml_g_sim": 15, "ml_l": [11, 12, 38, 40, 41, 42, 43, 47, 49, 55, 58, 59, 60, 62, 65, 68, 69, 73, 74, 75, 76, 89, 90, 95, 99, 102, 104, 105], "ml_l_bonu": 102, "ml_l_forest": 42, "ml_l_forest_pip": 42, "ml_l_lasso": 42, "ml_l_lasso_pip": 42, "ml_l_rf": 105, "ml_l_sim": 102, "ml_l_tune": 73, "ml_l_xgb": 105, "ml_m": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 89, 90, 95, 99, 102, 104, 105], "ml_m_bench_control": 66, "ml_m_bench_treat": 66, "ml_m_bonu": 102, "ml_m_forest": 42, "ml_m_forest_pip": 42, "ml_m_lasso": 42, "ml_m_lasso_pip": 42, "ml_m_rf": 105, "ml_m_sim": [15, 102], "ml_m_tune": 73, "ml_m_xgb": 105, "ml_pi": [15, 67, 74], "ml_pi_sim": 15, "ml_r": [8, 11, 37, 40, 41, 46, 59, 60, 74, 104], "ml_r0": 74, "ml_r1": [41, 60, 74], "mlr": [42, 73], "mlr3": [37, 38, 39, 40, 41, 68, 73, 74, 75, 76, 89, 99, 100, 102, 104, 105], "mlr3book": [42, 73], "mlr3extralearn": [41, 73], "mlr3filter": 42, "mlr3learner": [37, 38, 39, 40, 41, 68, 73, 74, 75, 76, 89, 99, 102, 105], "mlr3measur": 39, "mlr3pipelin": [73, 104], "mlr3tune": [42, 73, 104], "mlr3vers": 41, "mlrmeasur": 39, "mode": [66, 101], "model": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 36, 37, 38, 39, 40, 42, 46, 47, 50, 51, 52, 53, 56, 57, 59, 61, 64, 65, 68, 69, 70, 71, 73, 77, 79, 80, 81, 82, 86, 87, 91, 92, 95, 96, 97, 98, 99, 100, 103, 104], "model_data": [41, 60], "model_label": 58, "model_select": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 47, 59, 73, 75], "modelmlestimatelowerupp": 41, "modern": [42, 73, 100, 102], "moment": [30, 31, 40, 59, 76, 89, 90, 92, 98, 99, 102], "monoton": 74, "mont": [18, 19, 21, 24, 48, 49, 54, 55], "montanari": 103, "more": [9, 34, 37, 39, 41, 45, 46, 48, 49, 53, 57, 58, 60, 61, 65, 66, 68, 72, 73, 74, 76, 82, 89, 90, 92, 95, 98, 102, 105], "moreov": [41, 42, 53, 73, 89, 99, 105], "mortgag": [41, 60, 61], "most": [41, 50, 57, 60, 61, 64, 66, 72, 73, 90, 95, 101], "motiv": [66, 69], "motivation_example_bch": 53, "mp": 39, "mpd": [40, 59], "mpg": 59, "mse": [42, 53, 73], "msr": [42, 73], "mtry": [41, 42, 68, 73, 74, 75, 76, 89, 105], "mu": 52, "mu_": 52, "mu_mean": 52, "much": [41, 42, 60, 66, 105], "muld": [43, 70, 102], "multi": [39, 40, 48, 49, 59], "multiclass": [42, 58], "multiindex": 59, "multipl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 24, 39, 40, 41, 51, 59, 60, 65, 66, 67, 70, 73, 75, 89, 90, 92, 99, 104, 105], "multipletest": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "multipli": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 47, 71, 72, 76, 105], "multiprocess": [50, 61, 64], "multitest": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "multivariate_norm": 15, "multiwai": [26, 40, 59, 103], "music": 103, "must": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 73, 74], "mutat": 42, "mutual": [1, 9, 12, 41, 54, 55, 60, 61, 72], "my_sampl": 75, "my_task": 75, "n": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 37, 38, 40, 42, 45, 46, 47, 50, 52, 53, 56, 59, 62, 63, 64, 67, 68, 69, 72, 73, 75, 89, 99, 100, 101], "n_": [24, 52], "n_coef": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 90, 95], "n_complier": 64, "n_core": [50, 61, 64], "n_estim": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 43, 47, 48, 49, 50, 51, 52, 54, 55, 56, 60, 61, 63, 64, 65, 66, 68, 69, 72, 73, 74, 75, 76, 89, 90, 95, 102, 105], "n_eval": [42, 73], "n_fold": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 39, 40, 41, 43, 47, 48, 49, 50, 51, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 69, 73, 75, 102, 105], "n_folds_per_clust": [40, 59], "n_folds_tun": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "n_iter_randomized_search": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 73], "n_job": 60, "n_jobs_cv": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 57], "n_jobs_model": [2, 14, 50, 61, 64], "n_level": [24, 45], "n_ob": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 34, 35, 38, 42, 45, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 65, 66, 67, 69, 70, 72, 73, 74, 75, 89, 90, 95, 99, 102], "n_rep": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 39, 40, 43, 45, 47, 51, 56, 57, 59, 65, 66, 67, 69, 73, 75, 90, 95, 102, 105], "n_rep_boot": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 45, 48, 49, 50, 54, 55, 61, 64, 89, 99], "n_sampl": 63, "n_split": 75, "n_t": 52, "n_time_period": 52, "n_true": [50, 64], "n_var": [38, 42, 47, 69, 70, 73, 89, 99, 102], "n_w": 63, "n_x": [21, 48, 49, 54, 55, 56], "na": [4, 7, 38, 40, 69, 104], "na_real_": [40, 104], "naiv": [38, 47, 69], "name": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 32, 33, 38, 39, 40, 54, 55, 56, 58, 59, 65, 66, 73, 101, 104], "namespac": 39, "nan": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 45, 47, 50, 51, 52, 54, 55, 57, 58, 60, 61, 64, 67, 69, 73], "nanmean": 47, "narita": 103, "nathan": 103, "nation": [66, 75, 103], "nativ": 39, "natt": 63, "natur": 66, "ncol": [40, 41, 42, 70, 73, 89, 99, 102], "ncoverag": 57, "ndarrai": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 20, 22, 23, 25, 26, 27, 28, 29, 70], "nearli": 57, "necess": [40, 59], "necessari": [39, 40, 58, 59], "need": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 31, 37, 38, 39, 41, 46, 47, 58, 61, 67, 73, 75, 90, 98, 104, 105], "neighborhood": 89, "neither": [4, 7, 40, 59, 70], "neng": 103, "neq": 74, "nest": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 73, 76, 85, 90, 95], "net": [61, 65, 105], "net_tfa": [41, 60, 61, 65, 105], "never": [8, 39, 40, 55, 59, 104], "never_tak": [8, 41, 60], "new": [37, 38, 39, 40, 41, 42, 48, 49, 58, 60, 63, 68, 69, 70, 72, 73, 74, 75, 76, 89, 99, 100, 102, 103, 104, 105], "new_data": [48, 49, 63], "newei": [16, 17, 27, 40, 53, 59, 66, 69, 100, 103], "newest": 104, "next": [39, 41, 42, 48, 49, 50, 56, 57, 60, 61, 63, 64, 66, 104], "neyman": [40, 59, 68, 71, 90, 98, 100, 103], "nfold": [40, 41], "nice": 39, "nifa": [60, 61, 65], "nil": 66, "nine": [40, 59], "node": [41, 42, 68, 74, 75, 76, 89, 102, 105], "nois": [62, 63], "non": [20, 26, 27, 28, 37, 38, 41, 46, 47, 52, 60, 61, 63, 73, 75, 76, 89], "non_orth_scor": [38, 47, 76], "nondur": 43, "none": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 24, 34, 40, 41, 43, 45, 46, 51, 56, 60, 61, 65, 66, 67, 70, 73, 74, 76, 89, 101, 102], "nonignor": [15, 85], "nonlinear": [31, 41, 60, 76, 83, 88, 104], "nonlinearscoremixin": 76, "nonparametr": [10, 13, 14, 66, 90, 91, 92, 96, 97, 98, 103], "nop": 42, "nor": [4, 7, 40, 59, 70], "norm": 47, "normal": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 20, 38, 46, 47, 50, 51, 52, 56, 61, 62, 63, 64, 67, 69, 70, 73, 76, 79, 80, 89, 99, 102], "normalize_ipw": [1, 2, 3, 8, 9, 10, 13, 14, 15, 61, 67], "notat": [40, 51, 59, 67, 74], "note": [4, 7, 8, 9, 11, 12, 15, 30, 31, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 75, 76, 100, 102], "notebook": [37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 72, 73, 105], "notic": [37, 46], "now": [39, 40, 41, 48, 49, 57, 59, 60, 63, 66, 67, 102, 104], "np": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 22, 23, 25, 26, 27, 28, 29, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 102, 105], "nround": [38, 41, 105], "nrow": [39, 40, 42, 70, 73, 89, 99, 102], "nu": [8, 20, 28, 67, 74, 90, 92, 95, 97, 98], "nu2": [90, 95], "nu_0": [90, 98], "nu_i": 67, "nuis_g0": 37, "nuis_g1": 37, "nuis_l": 105, "nuis_m": [37, 105], "nuis_r0": 37, "nuis_r1": 37, "nuis_rmse_ml_l": 53, "nuis_rmse_ml_m": 53, "nuisanc": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 27, 28, 38, 39, 40, 41, 42, 47, 48, 49, 50, 51, 53, 56, 57, 59, 60, 61, 64, 65, 66, 67, 68, 69, 73, 75, 76, 77, 79, 80, 83, 89, 90, 98, 100, 104, 105], "nuisance_el": [90, 91, 93, 94, 96, 97], "nuisance_loss": [57, 73, 104], "nuisance_target": 57, "null": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 39, 65, 73, 90, 95, 104], "null_hypothesi": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 65, 90, 95], "num": [41, 42, 68, 73, 74, 75, 76, 89, 102], "num_leav": [50, 52, 61, 64], "number": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 34, 35, 38, 40, 47, 48, 49, 50, 52, 53, 54, 55, 57, 59, 61, 63, 64, 66, 75, 89, 99, 100, 102, 105], "numer": [31, 37, 42, 62, 73, 76, 90, 91, 96, 104], "numeric_onli": 53, "numpi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 34, 35, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 102], "ny": 103, "o": [45, 52, 54, 55, 58, 60, 62, 89, 100, 102], "ob": [39, 41, 52], "obei": 76, "obj_dml_data": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 38, 40, 46, 47, 50, 58, 59, 64, 68, 69, 72, 73, 74, 75, 76, 89, 90, 95, 104], "obj_dml_data_bonu": 70, "obj_dml_data_bonus_df": 70, "obj_dml_data_from_arrai": [4, 7], "obj_dml_data_from_df": [4, 7], "obj_dml_data_sim": 70, "obj_dml_plr": [38, 47, 69], "obj_dml_plr_bonu": [42, 102], "obj_dml_plr_bonus_pip": 42, "obj_dml_plr_bonus_pipe2": 42, "obj_dml_plr_bonus_pipe3": 42, "obj_dml_plr_bonus_pipe_ensembl": 42, "obj_dml_plr_fullsampl": 58, "obj_dml_plr_lesstim": 58, "obj_dml_plr_nonorth": [38, 47], "obj_dml_plr_orth_nosplit": [38, 47], "obj_dml_plr_sim": [42, 102], "obj_dml_plr_sim_pip": 42, "obj_dml_plr_sim_pipe_ensembl": 42, "obj_dml_plr_sim_pipe_tun": 42, "obj_dml_sim": 15, "object": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 32, 33, 34, 35, 37, 41, 42, 43, 45, 48, 49, 50, 51, 55, 56, 58, 60, 61, 64, 67, 70, 72, 73, 74, 75, 76, 89, 100, 102, 103, 104, 105], "obs_confound": [37, 46], "observ": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 53, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 79, 80, 89, 90, 92, 93, 94, 102, 103, 105], "obtain": [19, 37, 38, 39, 40, 46, 47, 48, 49, 50, 51, 53, 57, 59, 64, 66, 67, 68, 69, 72, 73, 75, 76, 89, 90, 92, 95, 99, 101, 102], "occur": [58, 104], "off": [63, 103], "offer": [39, 41, 60, 61, 66, 105], "offici": 101, "often": 64, "oka": 103, "ol": [1, 9, 12, 34], "omega": [56, 72, 76, 77, 82, 90, 91, 96], "omega_": [26, 40, 59], "omega_1": [26, 40, 59], "omega_2": [26, 40, 59], "omega_epsilon": [40, 59], "omega_v": [26, 40, 59], "omega_x": [26, 40, 59], "omit": [65, 66, 90, 92, 98, 103, 104, 105], "ommit": 66, "onc": [39, 58, 66, 105], "one": [11, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 57, 59, 61, 62, 65, 66, 69, 72, 73, 74, 75, 76, 79, 80, 82, 86, 87, 89, 90, 91, 92, 95, 96, 97, 99, 102, 104], "ones": [42, 50, 52, 58, 64, 65, 72], "ones_lik": [45, 64], "onli": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 34, 39, 40, 41, 48, 49, 54, 55, 56, 57, 58, 59, 60, 61, 68, 72, 73, 74, 76, 78, 83, 88, 89, 90, 91, 92, 96, 98, 104], "onlin": 105, "onto": 57, "oo": 58, "oob_error": [42, 73], "oop": 104, "opac": [48, 49], "open": [42, 73, 100, 102], "oper": 42, "opposit": 63, "oprescu": [21, 48, 49, 54, 55, 103], "opt": 60, "optim": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 42, 48, 49, 58, 63, 72, 73, 103], "option": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 38, 40, 41, 45, 48, 49, 54, 55, 56, 57, 59, 60, 61, 67, 73, 75, 76, 78, 83, 88, 89, 99, 104], "oracl": [24, 45], "oracle_valu": [18, 19, 24, 45], "orang": 38, "orcal": [18, 19], "order": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 39, 40, 41, 42, 59, 60, 73, 75, 76], "org": [22, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 73, 100, 101, 104], "orient": [42, 73, 76, 100, 102, 103, 104], "origin": [35, 39, 42, 55, 63, 65, 66, 72], "orign": [41, 60], "orth_sign": [34, 35], "orthogon": [34, 35, 40, 41, 59, 60, 68, 71, 89, 90, 98, 99, 100, 103], "orthongon": [90, 98], "osx": 101, "other": [4, 7, 11, 12, 38, 40, 41, 42, 45, 47, 51, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 72, 73, 74, 75, 76, 82, 89, 90, 98, 100, 101, 102, 103, 104, 105], "other_ind": 59, "otherwis": [1, 5, 6, 8, 9, 12, 41, 60, 61, 63, 74], "othrac": [42, 43, 70, 102], "our": [38, 39, 41, 42, 47, 48, 49, 50, 51, 57, 58, 60, 61, 64, 65, 66, 69, 100, 102, 104, 105], "ourselv": 57, "out": [11, 12, 40, 42, 43, 51, 53, 57, 58, 59, 61, 65, 66, 67, 68, 70, 71, 72, 73, 74, 76, 86, 87, 89, 90, 92, 95, 97, 100, 102, 104, 105], "outcom": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 24, 37, 39, 40, 41, 42, 43, 46, 52, 53, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 70, 73, 77, 89, 91, 92, 95, 97, 98, 102, 104, 105], "outcome_0": 46, "outcome_1": 46, "outer": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 73], "output": [39, 57, 68, 89, 99, 105], "outshr": 59, "outsid": 38, "over": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 45, 47, 53, 57, 69, 71, 73, 90, 95, 99], "overal": [63, 66], "overcom": [71, 76], "overfit": [58, 71, 75], "overlap": [51, 66, 74], "overrid": [73, 104], "overst": [41, 60, 61], "overview": [57, 89, 90, 95, 103], "overwrit": 104, "ownership": [41, 60], "p": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 38, 39, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 88, 89, 90, 91, 96, 99, 100, 101, 102, 104], "p401": [41, 60, 61], "p_0": [76, 79, 80], "p_1": [89, 99], "p_adjust": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 75, 89, 99, 100, 102], "p_dbl": [42, 73], "p_int": 73, "p_n": 25, "p_val": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "p_x": [26, 40, 59], "p_x0": 62, "p_x1": 62, "packag": [37, 38, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 89, 90, 92, 100, 102, 103, 104, 105], "packagedata": 59, "packagevers": 41, "page": [66, 100, 103], "pair": [37, 46], "pake": [40, 59], "paket": [40, 41, 42], "pal": 40, "palett": 45, "panda": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 34, 35, 43, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 70, 72, 90, 92, 102], "pandas2ri": 59, "panel": [5, 20, 94, 103, 104], "paper": [22, 25, 42, 58, 62, 65, 66, 90, 98, 100, 102, 103, 104], "par": 43, "par_grid": [42, 73], "paradox": [42, 73, 104], "parallel": [39, 45, 50, 51, 52, 57, 64, 74], "param": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 32, 33, 58, 73], "param_grid": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 73], "param_nam": 39, "param_set": [42, 73], "param_v": 42, "paramet": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 45, 47, 48, 49, 50, 51, 53, 56, 57, 59, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 83, 88, 89, 90, 92, 95, 96, 98, 99, 100, 102, 103, 104, 105], "parametr": [39, 66, 69, 73, 105], "params_exact": 73, "params_nam": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 39], "parenttoc": 100, "part": [28, 38, 40, 41, 42, 47, 57, 58, 59, 60, 69, 73, 75, 90, 98, 104, 105], "parti": 28, "partial": [11, 12, 19, 25, 26, 27, 28, 31, 40, 42, 43, 53, 58, 59, 65, 68, 71, 73, 75, 86, 87, 89, 91, 95, 96, 97, 98, 99, 100, 102, 104, 105], "partial_": [76, 89], "partiallli": 65, "particip": [16, 61, 65, 105], "particular": 100, "particularli": 58, "partion": [40, 59], "partit": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 40, 59, 68, 71], "partli": 105, "pass": [1, 9, 12, 34, 39, 42, 58, 73, 105], "passo": [100, 102], "past": 40, "paste0": 40, "pastel": 47, "path": [73, 74], "path_to_r": 53, "patsi": [48, 49, 72], "pattern": 66, "paul": 103, "pd": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 34, 45, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 72], "pdf": [47, 62], "pedregosa": [100, 102], "pedregosa11a": [100, 102], "pedro": [39, 103], "penal": 67, "penalti": [41, 42, 46, 60, 66, 67, 73, 74], "pennsylvania": [17, 70, 102], "pension": [41, 60, 61, 105], "peopl": [41, 60, 61], "pep8": 104, "per": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 40, 59], "percent": 73, "percentag": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19], "perf_count": 57, "perform": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 35, 38, 40, 42, 47, 51, 53, 55, 56, 57, 58, 59, 61, 65, 66, 67, 69, 73, 74, 75, 76, 89, 99, 100, 102, 103, 105], "perfrom": 56, "perhap": 105, "period": [5, 39, 51, 52, 74], "perp": 74, "perrot": [100, 102], "person": 105, "pessimist": 66, "peter": 103, "pfister": [42, 73, 100, 102], "phi": [40, 59, 72, 89], "philipp": [66, 100, 103], "philippbach": [100, 104], "pi": [15, 23, 25, 28, 72, 74, 76, 84, 85], "pi_": [26, 40, 59], "pi_0": [76, 84, 85], "pi_i": [67, 74], "pick": 105, "pip3": 101, "pipe": 42, "pipe_forest_classif": 42, "pipe_forest_regr": 42, "pipe_lasso": 42, "pipelin": [42, 60, 104], "pipeop": 42, "pira": [41, 60, 61, 65, 105], "pivot": [53, 59, 103], "plai": [58, 105], "plan": [16, 41, 60, 61, 105], "plausibl": 66, "pleas": [32, 33, 39, 45, 58, 66, 75], "plim": 62, "pliv": [11, 30, 31, 40, 59, 68, 72, 86, 100, 104], "plm": [71, 73, 89, 90, 95, 105], "plot": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 35, 38, 39, 41, 42, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 60, 61, 62, 64, 65, 66, 67, 72, 90, 95], "plot_tre": [35, 63, 72], "plotli": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 48, 49, 53, 66], "plr": [12, 30, 31, 42, 58, 62, 65, 68, 73, 75, 87, 89, 95, 96, 97, 98, 99, 100, 102, 104, 105], "plr_est": 62, "plr_est1": 62, "plr_est2": 62, "plr_obj": 62, "plr_obj_1": 62, "plr_obj_2": 62, "plr_summari": 60, "plrglmnet": 41, "plrranger": 41, "plrrpart": 41, "plrxgboost8700": 41, "plt": [43, 45, 47, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 64, 66, 67], "plt_smpl": [40, 59], "plt_smpls_cluster": [40, 59], "plug": [56, 90, 91, 93, 94, 95, 96], "pm": [40, 59, 89, 90, 95, 98, 99], "pmatrix": 67, "po": [42, 73], "point": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 39, 40, 54, 55, 59, 66, 72, 105], "pointwis": [34, 50, 54, 55, 64], "poli": [41, 59, 60], "polici": [9, 11, 12, 35, 71, 74, 102, 103, 104], "policy_tre": [9, 63, 72], "policy_tree_2": 63, "policy_tree_obj": 72, "policytre": 63, "polit": 62, "poly_dict": 60, "polynomi": [16, 17, 41, 43, 60], "polynomial_featur": [16, 17, 41, 43], "polynomialfeatur": [59, 60], "popul": [66, 76], "popular": [57, 90, 92], "porport": 65, "posit": [28, 41, 62, 66, 105], "posixct": [42, 73], "possibl": [4, 7, 39, 42, 48, 49, 54, 55, 56, 57, 58, 63, 65, 66, 73, 74, 89, 90, 92, 104, 105], "possibli": [90, 92], "post": [25, 28, 74, 89, 99, 103], "postdoubl": 103, "poster": 62, "potenti": [1, 2, 3, 10, 13, 15, 18, 24, 51, 62, 67, 77, 78, 89, 91, 101, 104, 105], "potential_level": 45, "power": [42, 58, 66, 73, 103], "pp": 39, "pq": [10, 13, 14, 61, 88, 104], "pq_0": [61, 64], "pq_1": [61, 64], "pr": [15, 37, 40, 41, 42, 73, 74, 75, 76, 89, 102, 105], "practic": [57, 66, 103], "pre": [39, 51, 67, 73, 74], "precis": [39, 90, 96, 105], "pred": [39, 58], "pred_df": 63, "pred_dict": 73, "pred_treat": 63, "predict": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 32, 33, 34, 35, 38, 40, 41, 42, 47, 50, 53, 57, 58, 59, 60, 63, 66, 69, 72, 75, 90, 92, 95, 96, 104, 105], "predict_proba": [1, 3, 5, 6, 8, 9, 10, 12, 13, 14, 15, 32, 58, 73], "predictor": [1, 9, 12, 34, 35, 48, 49, 54, 55, 66, 68], "prefer": [41, 60, 61, 105], "preliminari": [3, 38, 47, 76, 78, 83, 85, 88], "prepar": [39, 40, 59, 104], "preprint": 103, "preprocess": [41, 59, 60, 61, 73], "presenc": [41, 60, 61], "present": [39, 66, 73, 105], "prespecifi": 65, "pretest": 39, "pretreat": [5, 6, 39, 51], "prettenhof": [100, 102], "preval": 66, "prevent": [75, 104], "previou": [52, 56, 62, 101, 105], "previous": [73, 105], "price": [40, 59], "priliminari": [10, 14], "primari": 45, "principl": [90, 92], "print": [38, 39, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 101, 102, 104, 105], "print_detail": 39, "prior": [57, 74], "privat": 104, "prob": 42, "probabilit": 56, "probabl": [1, 3, 8, 9, 10, 13, 14, 15, 20, 24, 38, 39, 45, 47, 51, 56, 62, 64, 66, 67, 69, 74, 76, 79, 80, 83, 103], "problem": [41, 60, 61, 72, 73], "procedur": [38, 40, 41, 47, 57, 59, 60, 65, 66, 73, 89, 99, 104], "proceed": [25, 103], "process": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 39, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 63, 64, 66, 67, 71, 89, 90, 92, 99, 103, 104], "produc": 62, "product": [48, 49, 53, 57, 66, 90, 98], "producton": 40, "program": [23, 41, 60, 61, 103, 105], "progress": 44, "project": [42, 48, 49, 72, 100, 104], "project_z": [48, 49], "prone": 76, "propens": [10, 14, 18, 19, 41, 51, 56, 57, 60, 61, 66, 67, 72, 74, 90, 91], "properli": [58, 105], "properti": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 42, 57, 60, 61, 62, 65, 73, 90, 95, 102, 104], "proport": [65, 90, 92, 97, 98], "propos": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 42, 59, 90, 92, 103, 104], "provid": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 39, 40, 41, 42, 48, 49, 54, 55, 58, 59, 60, 66, 68, 69, 70, 71, 73, 89, 99, 100, 102, 104, 105], "prune": [9, 35], "ps911c": 59, "ps944": 59, "pscore1": 62, "pscore2": 62, "psi": [30, 31, 38, 39, 40, 59, 68, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 98, 102], "psi_": [89, 90, 95, 97, 98, 99], "psi_a": [8, 9, 11, 12, 30, 38, 40, 47, 59, 75, 76, 77, 79, 80, 81, 82, 86, 87, 89], "psi_b": [8, 9, 11, 12, 30, 38, 47, 72, 75, 76, 77, 79, 80, 81, 82, 86, 87], "psi_el": [75, 76], "psi_j": [89, 99], "psi_nu2": [90, 95], "psi_sigma2": [90, 95], "public": [37, 46, 104], "publish": [66, 104], "pull": [41, 104], "purchas": 66, "pure": 66, "purp": [48, 49], "purpos": [38, 47, 56, 65, 66, 90, 92, 102], "pval": [89, 99], "px": 53, "py": [55, 59, 60, 66, 100, 101, 104], "py3": 101, "py_al": 47, "py_dml": 47, "py_dml_nosplit": 47, "py_dml_po": 47, "py_dml_po_nosplit": 47, "py_double_ml_apo": 45, "py_double_ml_bas": 47, "py_double_ml_basic_iv": 46, "py_double_ml_c": 48, "py_double_ml_cate_plr": 49, "py_double_ml_cvar": 50, "py_double_ml_did": 51, "py_double_ml_did_pretest": 52, "py_double_ml_firststag": 53, "py_double_ml_g": 54, "py_double_ml_gate_plr": 55, "py_double_ml_gate_sensit": 56, "py_double_ml_learn": 57, "py_double_ml_meets_flaml": 58, "py_double_ml_multiway_clust": 59, "py_double_ml_pens": 60, "py_double_ml_pension_qt": 61, "py_double_ml_plm_irm_hetfx": 62, "py_double_ml_policy_tre": 63, "py_double_ml_pq": 64, "py_double_ml_sensit": 65, "py_double_ml_sensitivity_book": 66, "py_double_ml_ssm": 67, "py_non_orthogon": 47, "py_po_al": 47, "pydata": 55, "pypi": [103, 104], "pyplot": [43, 45, 47, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 64, 66, 67], "python": [28, 39, 58, 66, 68, 69, 70, 71, 72, 74, 75, 76, 89, 90, 92, 95, 99, 100, 102, 103, 104, 105], "python3": [60, 101], "q": [42, 50, 64, 73, 100, 102], "q2": [42, 43, 70, 102], "q3": [42, 43, 70, 102], "q4": [42, 43, 70, 102], "q5": [42, 43, 70, 102], "q6": [42, 43, 70, 102], "qquad": 23, "qte": [50, 61, 104], "quad": [20, 41, 51, 60, 63, 67, 72, 74, 76, 83, 89, 90, 93, 99], "quadrat": 67, "qualiti": [65, 68, 104], "quanitl": 61, "quant": 50, "quantifi": 66, "quantil": [2, 3, 10, 13, 14, 24, 45, 50, 65, 71, 73, 78, 83, 88, 103, 104], "quantiti": [37, 46, 66], "queri": 60, "question": [66, 105], "quick": 61, "quit": [57, 63, 65, 90, 92], "r": [8, 22, 47, 48, 49, 52, 53, 59, 62, 66, 68, 69, 70, 71, 74, 75, 76, 81, 86, 89, 90, 91, 92, 96, 97, 98, 99, 100, 102, 103, 104, 105], "r2_d": [23, 57], "r2_y": [23, 57], "r6": [42, 104], "r_0": [8, 11, 41, 60, 74], "r_all": 38, "r_d": 23, "r_df": 59, "r_dml": 38, "r_dml_nosplit": 38, "r_dml_po": 38, "r_dml_po_nosplit": 38, "r_double_ml_bas": 38, "r_double_ml_basic_iv": 37, "r_double_ml_did": 39, "r_double_ml_multiway_clust": 40, "r_double_ml_pens": 41, "r_double_ml_pipelin": 42, "r_hat": 11, "r_hat0": 8, "r_hat1": 8, "r_non_orthogon": 38, "r_po_al": 38, "r_y": 23, "rais": [4, 7, 32, 33, 73], "randint": 62, "randn": 15, "random": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 24, 28, 29, 37, 38, 39, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 73, 75, 84, 89, 90, 95, 98, 99, 102, 103, 105], "random_search": 73, "random_st": [24, 47, 56, 63], "randomforest": [41, 57, 60], "randomforest_class": [41, 48, 60, 63], "randomforest_reg": [48, 63], "randomforestclassifi": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 43, 45, 48, 49, 54, 55, 56, 57, 60, 63, 65, 66, 72, 73, 74, 105], "randomforestregressor": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 43, 45, 47, 48, 49, 54, 55, 56, 57, 60, 63, 65, 66, 68, 72, 73, 74, 75, 76, 89, 90, 95, 102, 105], "randomized_search": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 73], "randomizedsearchcv": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 73], "randomli": [38, 40, 47, 59, 69, 75, 105], "rang": [38, 45, 47, 50, 51, 52, 54, 55, 57, 58, 59, 61, 63, 64, 66, 67, 69, 73], "rangeindex": [43, 45, 51, 56, 59, 60, 61, 65, 67, 70, 102], "ranger": [39, 41, 42, 68, 73, 74, 75, 76, 89, 102, 105], "rangl": [21, 63], "rank": 104, "rate": [53, 57], "rather": 66, "ratio": [73, 75, 90, 92], "ravel": [48, 49], "raw": [41, 53, 60], "raw_res_manual_lasso_r_100_n_100_p_200_rho_0": 53, "rbind": 41, "rbindlist": 41, "rbinom": 37, "rbrace": [8, 9, 22, 23, 29, 40, 59, 68, 74, 75, 76, 77, 89, 90, 91, 99], "rcolorbrew": 40, "rcparam": [43, 48, 49, 50, 52, 54, 55, 59, 60, 61, 64], "rd": 104, "rdbu": 40, "rdbu_r": 59, "rdt044": 53, "re": [59, 66, 101], "read_csv": 53, "readabl": 104, "readili": 100, "real": [41, 60, 61, 65, 90, 92], "realat": 74, "realiz": 74, "reason": [4, 7, 37, 46, 65, 66, 90, 92, 105], "recal": [43, 90, 98], "receiv": [45, 74], "recent": [58, 74], "recogn": [41, 60, 61], "recommend": [42, 57, 66, 68, 75, 101, 103, 104], "recov": [37, 39, 46, 62], "recsi": 103, "red": [40, 54, 55, 58, 59], "reduc": [41, 56, 58, 60, 65, 66, 104], "redund": 104, "reemploy": [17, 70, 102], "refactor": 104, "refer": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 41, 45, 52, 56, 58, 60, 61, 65, 70, 71, 72, 74, 90, 92, 95, 103, 104], "reference_level": [2, 45, 74], "refin": 104, "refit": [90, 92], "reflect": [63, 66, 72], "reg": [20, 41, 60, 105], "reg_learn": 61, "reg_learner_1": 57, "reg_learner_2": 57, "regard": [66, 100], "regener": 104, "region": [40, 50, 59, 89, 99, 103], "regr": [37, 38, 39, 40, 41, 42, 68, 73, 74, 75, 76, 89, 99, 102, 105], "regravg": [42, 73], "regress": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 40, 42, 45, 46, 53, 58, 59, 62, 65, 66, 67, 68, 69, 71, 72, 73, 75, 89, 91, 92, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105], "regressor": [33, 38, 41, 45, 47, 50, 57, 58, 60, 69], "regular": [25, 71, 73, 76, 89, 99, 103], "reich": [42, 73], "reinforc": 103, "reject": [41, 60], "rel": [41, 60, 90, 91, 92, 96], "relat": [66, 105], "relationship": [37, 46, 53, 66, 89, 99], "releas": 60, "relev": [4, 5, 6, 7, 21, 34, 50, 63, 64, 90, 105], "reli": [48, 49, 51, 52, 56, 72, 73, 74, 90, 92, 105], "reload": 41, "remain": [39, 89, 99, 105], "remark": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 45, 47, 48, 49, 50, 52, 54, 55, 56, 57, 61, 65, 72, 73, 74, 76, 79, 80, 83, 88, 89, 90, 96], "remot": 101, "remov": [41, 60, 66, 71, 75, 104], "renam": [60, 104], "render": [65, 66], "reorgan": 104, "rep": [38, 69, 73, 89, 99], "repeat": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 38, 40, 41, 42, 47, 56, 59, 60, 61, 62, 65, 67, 69, 71, 73, 89, 93, 102, 104, 105], "repeatedkfold": 59, "repet": 65, "repetit": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 48, 49, 53, 54, 55, 56, 57, 71, 73, 89, 102, 105], "repetiton": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "replac": [63, 66, 104], "replic": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 38, 41, 47, 53, 66], "repo": 104, "report": [41, 58, 60, 100, 104], "repositori": [53, 104], "repr": [38, 40], "repres": [62, 66], "represent": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 65, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 102, 104], "reproduc": 24, "request": 104, "requir": [11, 12, 37, 41, 42, 45, 56, 60, 61, 65, 74, 89, 90, 92, 95, 99, 101, 104, 105], "requirenamespac": 39, "res_df": 59, "res_dict": [18, 19, 21, 24], "resampl": [37, 40, 42, 51, 59, 61, 65, 67, 73, 74, 75, 76, 89, 100, 102, 105], "research": [40, 42, 59, 62, 66, 75, 100, 102, 103, 105], "resembl": 67, "reset": 39, "reset_index": [53, 59, 60], "reshap": [47, 48, 49, 52], "reshape2": 40, "residu": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 65, 90, 92, 97, 98], "resolut": [42, 73], "resourc": 57, "resourcewis": 57, "respect": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 45, 60, 61, 72, 74, 75, 90, 98, 105], "respons": [16, 42, 73], "restart": 101, "restrict": 57, "restructur": 104, "restud": 53, "result": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 37, 38, 39, 42, 45, 47, 48, 49, 51, 52, 53, 56, 57, 63, 65, 66, 67, 69, 73, 75, 76, 79, 80, 90, 92, 95, 102, 104], "result_iivm": 41, "result_irm": 41, "result_plr": 41, "retina": 62, "retir": [41, 60, 61, 65], "return": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 38, 39, 40, 42, 47, 50, 55, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 73, 76, 90, 92, 104], "return_count": [45, 57], "return_tune_r": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "return_typ": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 38, 41, 42, 47, 51, 57, 58, 60, 61, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 89, 90, 95, 102, 105], "rev": 40, "reveal": 56, "review": [25, 53, 103], "revist": [40, 59], "rho": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 36, 45, 56, 65, 66, 90, 92, 95, 98, 105], "rho_val": 66, "richter": [42, 73, 100, 102], "riesz": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 65, 90, 92, 93, 94, 95, 97, 98], "riesz_rep": [90, 95], "right": [22, 23, 25, 26, 29, 38, 40, 47, 57, 59, 60, 61, 62, 64, 66, 69, 76, 79, 80, 89, 90, 91, 93, 94, 96, 99], "rightarrow_": [38, 47, 69], "risk": [3, 71, 104], "ritov": 103, "rival": 59, "rival_ind": 59, "rmd": 39, "rmse": [39, 51, 57, 58, 61, 65, 67, 73, 74, 76, 89, 102, 104], "rmse_dml_ml_l_fullsampl": 58, "rmse_dml_ml_l_lesstim": 58, "rmse_dml_ml_l_onfold": 58, "rmse_dml_ml_l_untun": 58, "rmse_dml_ml_m_fullsampl": 58, "rmse_dml_ml_m_lesstim": 58, "rmse_dml_ml_m_onfold": 58, "rmse_dml_ml_m_untun": 58, "rmse_oos_ml_l": 58, "rmse_oos_ml_m": 58, "rmse_oos_onfolds_ml_l": 58, "rmse_oos_onfolds_ml_m": 58, "rnorm": [37, 42, 70, 73, 89, 99, 102], "robin": [16, 17, 27, 40, 53, 59, 69, 100, 103], "robinson": [38, 47, 69], "robject": 59, "robu": [54, 55], "robust": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 26, 39, 45, 56, 65, 66, 90, 95, 103, 105], "role": [4, 7, 38, 47, 58, 69, 105], "romano": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 89, 99], "root": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 31, 53, 69, 73, 76, 103], "rotat": 58, "roth": 74, "rough": [66, 105], "roughli": 66, "round": [41, 45, 57, 62, 66], "rout": [32, 33], "row": [38, 41, 43, 48, 49, 52, 58, 59, 63, 70, 75, 102, 105], "row_index": 55, "rownam": 40, "rowv": 40, "roxygen2": 104, "royal": [66, 103], "rpart": [41, 42, 73], "rpart_cv": 42, "rprocess": 57, "rpy2": 59, "rpy2pi": 59, "rsmp": [42, 73, 75], "rsmp_tune": [42, 73], "rssb": 66, "rtype": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "ruben": 103, "ruiz": [37, 46], "rule": [39, 72], "run": [39, 101, 104], "runif": 37, "runner": 66, "runtime_learn": 42, "rv": [45, 56, 65, 66, 90, 95, 105], "rva": [45, 56, 65, 66, 90, 95, 105], "rvert": 53, "rvert_": 53, "s1": 58, "s2": 58, "s_": [26, 40, 59, 74], "s_1": 27, "s_2": 27, "s_col": [4, 7, 67, 74], "s_i": [29, 67, 74], "s_x": [26, 40, 59], "safeguard": [51, 73], "sake": [41, 60, 66, 105], "same": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 24, 34, 38, 40, 47, 48, 49, 56, 57, 59, 61, 63, 65, 66, 67, 73, 76, 79, 80, 89, 90, 96, 104], "samii": 62, "sampl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 26, 29, 37, 39, 40, 42, 46, 51, 54, 55, 57, 59, 61, 63, 65, 71, 73, 89, 99, 102, 103, 104], "sant": [5, 6, 18, 19, 20, 24, 39, 51, 74, 103], "sara": 103, "sasaki": [26, 40, 59, 103], "satisfi": [67, 73, 76, 89], "save": [38, 41, 47, 54, 55, 57, 58, 60, 61, 73, 90, 95, 105], "savefig": 47, "saveguard": 57, "saver": [41, 60, 61], "scalar": 74, "scale": [38, 40, 50, 52, 62, 64, 66, 89, 90, 98], "scale_color_manu": 38, "scale_fill_manu": [38, 40], "scatter": [45, 52, 54, 55, 62, 66], "scatterplot": 45, "scenario": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 56, 65, 66, 90, 95, 105], "scene": [48, 49, 53], "scene_camera": 53, "schaefer": 62, "schedul": 104, "scheme": [40, 59, 73, 75, 100], "schneider": 42, "schratz": [42, 73, 100, 102], "scienc": [28, 37, 46, 62, 103], "scikit": [57, 60, 73, 100, 102, 104, 105], "scipi": 47, "score": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 30, 31, 37, 39, 40, 41, 42, 43, 48, 49, 50, 51, 53, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 100, 104, 105], "scoring_method": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "script": 101, "sd": 37, "se": [38, 40, 47, 65, 69, 73, 75, 89, 90, 95, 103, 105], "se_df": 40, "se_dml": [38, 47, 69], "se_dml_po": [38, 47, 69], "se_nonorth": [38, 47], "se_orth_nosplit": [38, 47], "se_orth_po_nosplit": [38, 47], "seaborn": [43, 45, 47, 51, 57, 59, 60, 61, 66, 67], "search": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 31, 73, 76], "search_mod": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 73], "searchabl": 41, "second": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 26, 38, 40, 42, 47, 57, 58, 59, 68, 69, 75, 89, 90, 92, 98, 99, 102], "secondari": 45, "section": [6, 20, 39, 40, 41, 42, 56, 58, 59, 61, 66, 93, 104], "secur": 62, "see": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 23, 29, 30, 31, 34, 37, 39, 40, 41, 42, 45, 46, 48, 49, 51, 55, 58, 59, 61, 62, 63, 65, 66, 73, 74, 75, 76, 78, 82, 83, 84, 85, 88, 90, 92, 95, 98, 101, 102, 104], "seed": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 24, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 89, 90, 95, 99, 102, 105], "seek": 62, "seem": [39, 41, 56, 60, 61, 105], "seen": [54, 55], "sel_cols_chiang": 59, "select": [4, 7, 15, 24, 25, 29, 53, 57, 66, 68, 71, 73, 103, 104, 105], "selected_coef": 57, "selected_featur": [42, 73], "selected_learn": 57, "self": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 35, 57, 58, 105], "selfref": 41, "semenova": [48, 49, 103], "semi": 69, "semiparametr": 16, "sens": [65, 66], "sensemakr": [90, 92], "sensit": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 36, 71, 72, 92, 95, 98, 104], "sensitivity_analysi": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 56, 65, 66, 90, 95, 105], "sensitivity_benchmark": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 56, 65, 66, 90, 92], "sensitivity_el": [90, 95], "sensitivity_param": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 65, 66, 90, 92, 95], "sensitivity_plot": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 56, 65, 66, 90, 95], "sensitivity_summari": [45, 56, 65, 66, 90, 95, 105], "sensitvity_benchmark": 45, "sensiv": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "senstiv": [90, 97], "sep": 38, "separ": [62, 65, 73, 104], "seper": [58, 65, 75, 89, 90, 92], "seq_len": [38, 69], "sequenti": 17, "seri": [55, 66, 103], "serv": [70, 102, 104], "serverless": [103, 104], "servic": 62, "set": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 26, 27, 28, 35, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 51, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 77, 79, 80, 82, 89, 90, 91, 92, 96, 97, 99, 101, 102, 104, 105], "set_as_param": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "set_fold_specif": 73, "set_index": 60, "set_ml_nuisance_param": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 43, 60, 73, 104], "set_param": [32, 33, 58, 73], "set_sample_split": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 57, 75, 104], "set_styl": [60, 61], "set_text": 57, "set_threshold": [38, 39, 40, 41, 42, 68, 73, 74, 75, 76, 89, 99, 102], "set_tick": 59, "set_ticklabel": 59, "set_titl": [45, 58, 59], "set_x_d": [4, 7], "set_xlabel": [45, 47, 58, 59], "set_xlim": 47, "set_xtick": 62, "set_xticklabel": 62, "set_ylabel": [45, 58, 59, 62], "set_ylim": [50, 58, 59, 64], "setdiff": 104, "setdiff1d": 59, "setminu": [40, 59, 89, 99], "settings_l": 58, "settings_m": 58, "setup": 101, "setuptool": 101, "seven": [40, 59], "sever": [36, 41, 42, 57, 58, 60, 61, 65, 66, 69, 73, 105], "shape": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 34, 35, 45, 48, 49, 52, 54, 55, 57, 59, 60, 63, 65, 66, 73], "share": [40, 41, 59, 60], "sharma": [66, 103], "shock": [40, 59], "short": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 65, 66, 90, 92, 103, 104, 105], "shortcut": 41, "shortli": [40, 42, 59, 73], "shota": 103, "should": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 31, 41, 45, 54, 55, 57, 60, 65, 67, 70, 72, 73, 74, 89, 90, 92, 100], "show": [37, 38, 40, 43, 45, 46, 47, 48, 49, 51, 53, 56, 57, 58, 59, 62, 66, 67, 69, 90, 97, 101], "showcas": 63, "showlabel": 66, "showlegend": 66, "shown": [37, 46, 62, 102], "showscal": [48, 49, 53], "shuffl": 75, "side": [90, 95], "sigma": [15, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 38, 40, 47, 59, 67, 69, 72, 75, 89, 90, 92, 95, 97, 98, 99], "sigma2": [90, 95], "sigma_": [19, 20, 22, 23, 25, 26, 27, 29, 38, 40, 47, 59, 69], "sigma_0": [90, 98], "sigma_j": [89, 99], "sigmoid": 62, "sign": 66, "signal": [34, 35], "signatur": [8, 9, 10, 11, 12, 13, 14, 76], "signif": [37, 39, 40, 41, 42, 73, 74, 75, 76, 89, 102, 105], "signific": [37, 40, 41, 42, 45, 56, 60, 63, 65, 66, 73, 74, 75, 76, 89, 90, 95, 102, 105], "silverman": [10, 13, 14], "sim": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 38, 39, 40, 47, 50, 52, 59, 63, 64, 67, 69], "similar": [19, 24, 39, 42, 48, 49, 56, 58, 61, 65, 66], "similarli": 58, "simpl": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 21, 39, 42, 48, 49, 54, 55, 56, 63, 66, 71, 90, 92], "simplest": 72, "simpli": [42, 51, 105], "simplic": [41, 57, 60, 63, 66], "simplif": [90, 93], "simplifi": [62, 66, 72, 90, 97], "simul": [18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 38, 42, 47, 48, 49, 50, 53, 54, 55, 64, 66, 67, 69, 73, 89, 99, 102], "simul_data": 15, "simulaten": 74, "simulation_run": 53, "simult": 39, "simultan": [71, 105], "sin": [21, 24, 28, 48, 49, 52, 54, 55], "sinc": [18, 19, 41, 45, 51, 52, 54, 55, 56, 57, 58, 60, 62, 67, 73, 74, 90, 95, 96, 104], "singl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 51, 54, 55, 61, 62, 73, 89, 99], "single_learner_pipelin": 73, "singleton": 75, "sinh": 28, "sipp": [41, 60, 61], "site": [59, 60], "situat": [40, 59], "six": 40, "sixth": 59, "size": [15, 38, 40, 41, 42, 47, 50, 52, 53, 56, 57, 58, 60, 62, 63, 64, 66, 68, 70, 73, 74, 75, 76, 89, 99, 102, 105], "sizeabl": 66, "skill": 103, "sklearn": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 28, 35, 43, 45, 46, 47, 48, 49, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 72, 73, 74, 75, 76, 89, 90, 95, 99, 102, 105], "skotara": 66, "slide": 62, "slightli": [52, 54, 55, 56, 57, 72, 76, 79, 80, 90, 92], "sligthli": [5, 6], "slow": [38, 47, 69], "slower": [38, 47, 69], "small": [21, 51, 52, 63, 67, 90, 92, 96], "smaller": [41, 51, 54, 55, 56, 58, 60, 66, 105], "smallest": 57, "smpl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 40, 47, 57, 59, 75, 76], "smpls_cluster": [40, 59], "smsg": 60, "sn": [43, 45, 47, 51, 57, 59, 60, 61, 66, 67], "so": [37, 41, 42, 46, 51, 58, 60, 62, 66, 67, 73, 89, 105], "social": [62, 103], "societi": [40, 59, 66, 103], "softwar": [42, 73, 100, 102, 103, 104], "solari": 104, "sole": 66, "solut": [68, 72, 76], "solv": [30, 40, 59, 72, 73, 89, 99], "solver": [60, 67, 74], "some": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 42, 43, 51, 52, 57, 58, 60, 61, 65, 67, 72, 73, 74, 104], "sometim": 57, "sonabend": [42, 73], "sophist": 73, "sort": [60, 74], "sort_valu": 45, "sourc": [42, 73, 102, 104], "sourcefileload": 53, "sp": 39, "space": [40, 59, 73], "spars": [53, 73, 89, 99, 102, 103], "sparsiti": 103, "spec": 103, "special": [40, 59], "specif": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 31, 40, 41, 45, 57, 59, 60, 66, 70, 71, 72, 73, 75, 76, 82, 89, 95, 98, 100, 102], "specifi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 37, 40, 41, 42, 45, 46, 48, 49, 50, 51, 54, 55, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 77, 82, 102, 104, 105], "specifii": 61, "speed": [2, 14, 57], "speedup": 57, "spefici": 8, "spindler": [25, 66, 100, 103, 104], "spine": [60, 61], "spline": [48, 49, 72], "spline_basi": [48, 49, 72], "spline_grid": [48, 49], "split": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 40, 42, 51, 57, 59, 61, 63, 65, 67, 71, 72, 73, 74, 76, 89, 102, 104], "split_sampl": 57, "sponsor": [41, 60, 61], "sprintf": 38, "sq_error": 53, "sqrt": [18, 19, 20, 23, 24, 38, 40, 42, 43, 47, 50, 59, 64, 69, 75, 89, 90, 92, 99, 102], "squar": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 53, 60, 73, 90, 98, 103], "squarederror": [41, 60, 105], "squeez": [50, 51, 64, 67], "src": 60, "ssm": [4, 7, 29, 71], "ssrn": 22, "stabil": 56, "stabl": [37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 100], "stack": [42, 73], "stacklrn": 42, "stage": [48, 49, 54, 55, 63, 73, 104, 105], "standard": [20, 39, 42, 50, 54, 55, 75, 76, 89, 90, 95, 98, 99, 104, 105], "standard_norm": [70, 73, 89, 99, 102], "standardscal": 60, "start": [39, 41, 42, 48, 49, 53, 56, 57, 58, 59, 60, 64, 66, 74, 100, 105], "stat": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 47, 70, 73, 89, 99, 100, 103], "stat_bin": 38, "stat_dens": 41, "state": 105, "stationar": 51, "stationari": 74, "statist": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 26, 29, 36, 40, 59, 65, 66, 89, 90, 95, 99, 100, 102, 103, 104, 105], "statsmodel": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34], "statu": [39, 41, 51, 60, 62, 67], "std": [3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 39, 40, 41, 42, 43, 45, 46, 48, 49, 50, 51, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 72, 73, 74, 75, 76, 89, 102, 105], "stefan": 103, "step": [38, 41, 42, 47, 54, 55, 56, 60, 63, 69, 73, 89, 99, 100, 105], "stepdown": [89, 99], "stick": [41, 60], "still": [48, 49, 51, 54, 55, 56, 61, 65, 67, 73], "stochast": [11, 12, 74, 102], "stock": [41, 60, 61], "store": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 68, 73, 75, 76, 89, 90, 95, 104], "store_model": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 58], "store_predict": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 39, 60, 63], "stori": [66, 103], "str": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 34, 41, 45, 54, 55, 64, 72, 104], "straightforward": [54, 55, 57, 72], "strategi": [62, 66, 105], "stratifi": 57, "stratum": 62, "strength": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 65, 66, 90, 92, 95, 97], "strictli": 74, "string": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 72, 89, 90, 95, 102, 104], "string_label": 62, "strong": [67, 90, 92], "stronger": [89, 105], "structur": [16, 17, 27, 40, 41, 53, 59, 60, 67, 69, 73, 100, 103, 105], "student": 103, "studi": [29, 40, 41, 53, 58, 59, 60, 61, 65, 102, 105], "style": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 58, 104], "styler": 104, "styliz": 66, "sub": [40, 59], "subclass": 104, "subfold": 73, "subgroup": [8, 41, 60, 104], "subject": [40, 59], "submiss": 104, "subobject": [32, 33], "subplot": [40, 45, 47, 48, 49, 50, 52, 54, 55, 57, 58, 59, 60, 61, 62, 64], "subplots_adjust": 57, "subpopul": 74, "subsampl": [42, 57], "subscript": [90, 92], "subsequ": [40, 59], "subset": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 57, 59, 63, 68, 72, 73, 90, 92], "subseteq": 72, "substanti": [41, 60, 62], "substract": 89, "subtract": 89, "sudo": 101, "suffic": 66, "suffici": [57, 58, 66], "suggest": [40, 41, 59, 60, 66, 104], "suitabl": [48, 49, 67], "sum": [40, 41, 59, 60, 61, 64, 72, 89, 99], "sum_": [38, 40, 47, 59, 68, 69, 72, 89, 99], "sum_i": 62, "sum_oth": 59, "sum_riv": 59, "summar": [39, 45, 62, 66, 68, 90, 95], "summari": [3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 39, 40, 42, 43, 45, 46, 48, 49, 50, 51, 54, 55, 56, 59, 61, 64, 65, 66, 67, 69, 70, 72, 73, 74, 75, 76, 89, 90, 102, 104, 105], "summary_result": 41, "suppli": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 48, 49, 54, 55, 56, 63, 72, 90, 91, 92, 95], "support": [8, 21, 39, 40, 57, 59, 63, 73, 74, 105], "support_s": [21, 48, 49, 54, 55, 63], "support_t": 63, "support_w": 63, "suppos": 66, "suppress": [39, 41, 42], "suppresswarn": 38, "suprema": [89, 99], "suptitl": [50, 57, 58, 61, 64], "supxlabel": [50, 61, 64], "supylabel": [50, 61, 64], "sure": [45, 73, 104], "surfac": [48, 49, 53], "surpress": [40, 102], "survei": [41, 60, 61, 105], "susan": 103, "sven": [66, 100, 103], "svenk": 59, "svenklaassen": 100, "svg": [38, 47], "switch": [38, 47, 66, 69], "symbol": 66, "symmetr": 28, "synthet": [21, 37, 46, 48, 49, 50, 54, 55, 58, 63, 64], "syrgkani": [66, 103], "system": 103, "szita": 103, "t": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 24, 37, 39, 40, 41, 42, 43, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 72, 73, 74, 75, 76, 80, 89, 90, 93, 99, 102, 105], "t_1_start": 57, "t_1_stop": 57, "t_2_start": 57, "t_2_stop": 57, "t_3_start": 57, "t_3_stop": 57, "t_col": [4, 6, 7, 74], "t_df": 63, "t_diff": 52, "t_dml": 38, "t_i": [51, 63, 74], "t_idx": 52, "t_nonorth": 38, "t_orth_nosplit": 38, "t_sigmoid": 63, "t_stat": 89, "tabl": [38, 40, 41, 42, 45, 68, 70, 73, 74, 75, 76, 89, 99, 102, 105], "tabular": [57, 70, 89, 99, 102, 105], "taddi": 103, "take": [8, 9, 11, 12, 18, 19, 21, 48, 49, 50, 51, 52, 53, 54, 55, 57, 61, 64, 65, 67, 68, 72, 73, 74, 76, 77, 82, 90, 91, 96, 97, 102], "taken": [41, 60, 61, 105], "taker": [8, 104], "talk": 105, "target": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 30, 31, 37, 40, 41, 42, 48, 49, 57, 59, 72, 73, 74, 75, 76, 83, 88, 89, 90, 96, 98, 99, 100, 102, 104, 105], "task": [37, 58, 70, 75, 105], "task_typ": 104, "tau": [50, 52, 61, 62, 64, 72, 76, 78, 83, 88], "tau_": 62, "tau_1": 62, "tau_2": 62, "tau_vec": [50, 61, 64], "tax": [41, 60, 61], "te": [39, 48, 49, 63], "techniqu": [38, 47, 69, 75, 105], "templat": 104, "temporari": 60, "ten": 58, "tend": [41, 60, 61], "tensor": [48, 49], "tenth": 103, "term": [38, 40, 41, 42, 47, 52, 53, 59, 60, 62, 66, 69, 100, 105], "termin": [42, 73], "terminatorev": 42, "test": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 22, 37, 38, 39, 40, 41, 42, 47, 56, 59, 66, 69, 73, 74, 75, 76, 89, 99, 102, 103, 104, 105], "test_id": [40, 75], "test_ind": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "test_set": 75, "test_siz": 47, "text": [18, 19, 20, 22, 24, 40, 41, 50, 53, 62, 63, 64, 66, 72, 75], "textbf": [68, 73, 105], "textposit": 66, "textrm": [90, 91, 92, 96, 97, 98], "tg": [42, 43, 70, 102], "th": [40, 59], "than": [9, 38, 39, 41, 47, 53, 57, 60, 61, 62, 65, 66, 69, 90, 95, 105], "thank": [39, 41, 42, 60, 104], "thatw": 52, "thei": [39, 41, 52, 54, 55, 60, 62, 90, 98], "them": [41, 42, 48, 49, 50, 56, 58, 60, 64], "theme": [40, 41], "theme_minim": [38, 41], "theorem": [90, 98], "theoret": [57, 66, 75, 103], "theori": [72, 103], "therebi": [40, 42, 59, 105], "therefor": [45, 62, 65, 75, 76, 90, 97], "theta": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 22, 23, 24, 26, 28, 29, 30, 31, 38, 40, 42, 45, 47, 51, 52, 53, 56, 57, 59, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 95, 97, 98, 99, 102, 105], "theta_": [45, 66, 72, 74, 89, 90, 98, 99], "theta_0": [8, 9, 11, 12, 21, 38, 40, 41, 45, 47, 48, 49, 53, 54, 55, 59, 60, 66, 67, 69, 72, 74, 76, 83, 88, 89, 90, 91, 96, 98, 102], "theta_dml": [38, 47, 69], "theta_dml_po": [38, 47, 69], "theta_initi": 47, "theta_nonorth": [38, 47], "theta_orth_nosplit": [38, 47], "theta_orth_po_nosplit": [38, 47], "theta_resc": 38, "theta_t": 52, "thi": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 72, 73, 74, 75, 76, 78, 79, 80, 83, 88, 89, 90, 91, 92, 95, 96, 100, 101, 102, 103, 104, 105], "think": 42, "third": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 47, 59, 69, 75], "thirion": [100, 102], "this_df": [53, 60], "this_split_ind": 59, "those": [39, 41, 60, 61], "though": [37, 46, 62], "thread": [62, 73], "three": [40, 42, 54, 55, 101, 104], "threshold": [1, 3, 5, 6, 8, 9, 10, 13, 14, 15, 66, 74], "through": [39, 50, 54, 55, 64, 73], "throughout": 56, "thu": [58, 72], "tibbl": 39, "tight": 47, "tight_layout": [58, 59], "tild": [18, 19, 20, 24, 40, 59, 62, 68, 72, 75, 76, 83, 84, 85, 88, 89, 90, 97, 98, 99], "time": [4, 5, 7, 25, 26, 38, 39, 40, 41, 47, 51, 52, 53, 54, 55, 59, 60, 61, 65, 66, 67, 74, 104, 105], "time_budget": 58, "time_df": 52, "time_period": 52, "titl": [40, 41, 45, 48, 49, 50, 53, 54, 55, 57, 58, 59, 60, 61, 62, 64, 66, 100], "tmp": 55, "tname": 39, "tnr": [42, 73], "to_fram": 63, "to_numpi": [50, 56, 61, 64], "todo": [40, 43], "toeplitz": 53, "togeth": [54, 55, 89], "toler": 59, "too": 57, "tool": [39, 42, 65, 105], "top": [40, 57, 59, 60, 61, 66, 100], "total": [41, 58, 60], "tpot": 58, "tracker": 100, "tradit": [89, 99], "train": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 40, 42, 47, 48, 49, 50, 54, 55, 57, 59, 63, 64, 68, 69, 75], "train_id": [40, 75], "train_ind": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "train_set": 75, "train_test_split": 47, "transact": 103, "transform": [18, 19, 62, 66, 105], "translat": 53, "transpos": 52, "treament": 63, "treat": [9, 20, 39, 45, 51, 52, 56, 63, 66, 72, 74, 89, 105], "treat1_param": 62, "treat2_param": 62, "treat_var": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 73], "treatment": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 27, 37, 39, 40, 42, 43, 45, 46, 51, 52, 53, 56, 57, 58, 59, 63, 65, 66, 67, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 82, 83, 88, 89, 90, 91, 95, 97, 99, 100, 102, 103, 104, 105], "treatment_df": 52, "treatment_effect": [21, 48, 49], "treatment_level": [1, 2, 45, 74], "treatment_var": [4, 7], "tree": [9, 35, 41, 42, 51, 52, 57, 60, 68, 71, 73, 74, 75, 76, 89, 102, 104], "tree_param": [9, 35], "tree_summari": 60, "trees_class": [41, 60], "trend": [39, 51, 52, 59, 74, 103], "tri": [53, 90, 92], "trim": [1, 3, 5, 6, 8, 9, 10, 13, 14, 15, 41, 60, 61, 66], "trimming_rul": [1, 2, 3, 5, 6, 8, 9, 10, 13, 14, 15, 61], "trimming_threshold": [1, 2, 3, 5, 6, 8, 9, 10, 13, 14, 15, 41, 48, 60, 61, 63, 64, 66], "trm": [42, 73], "true": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 24, 29, 32, 33, 37, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 73, 74, 75, 76, 77, 78, 83, 84, 85, 88, 89, 90, 93, 94, 98, 99, 102, 105], "true_effect": [48, 49, 52, 54, 55], "true_gatet_effect": 56, "true_group_effect": 56, "truncat": [1, 2, 3, 5, 6, 8, 9, 10, 13, 14, 15, 61], "try": [57, 65], "tune": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 53, 71, 100, 102, 104], "tune_on_fold": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 73], "tune_r": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "tune_set": [42, 73], "tuned_model": 58, "tuner": 73, "tunergridsearch": 42, "tupl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "turn": 66, "turrel": 28, "tutori": 41, "tw": [60, 61], "twinx": 45, "two": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 37, 38, 41, 42, 46, 47, 50, 51, 57, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 72, 73, 74, 75, 76, 83, 89, 99, 105], "twoclass": 42, "twoearn": [41, 60, 61, 65, 105], "type": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 21, 24, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 47, 57, 58, 59, 66, 69, 73, 76, 86, 87, 89, 90, 97, 99, 104, 105], "typic": [55, 100], "u": [8, 9, 10, 13, 14, 18, 19, 20, 21, 23, 29, 38, 39, 40, 41, 45, 47, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 64, 65, 66, 69, 74, 90, 92, 101, 105], "u_hat": [38, 47, 76], "u_i": [22, 25, 28, 29], "u_t": 20, "uehara": 103, "uhash": 42, "ulf": 103, "unambigu": 66, "uncertainti": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 54, 55, 65, 90, 95, 105], "uncondit": [41, 60, 105], "unconfounded": [66, 103], "under": [15, 38, 41, 47, 51, 60, 63, 66, 69, 74, 89, 103], "underbrac": [38, 47, 52, 69, 72], "underfit": 58, "underli": [18, 24, 41, 42, 45, 54, 55, 62, 63, 90, 92, 105], "underlin": [40, 59], "understand": 66, "undesir": 73, "unevenli": 75, "uniform": [20, 46, 48, 49, 50, 52, 63, 64, 89], "uniformli": [50, 61, 89, 99], "uniqu": [37, 45, 46, 57, 76, 90, 98], "unique_label": 58, "unit": [38, 39, 51, 52, 56, 67, 74, 76, 79, 80, 104], "univari": [21, 48, 49], "univers": 103, "unknown": 74, "unlik": [41, 60, 61, 66], "unobserv": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 37, 41, 46, 60, 61, 65, 66, 74, 90, 92, 98, 105], "unpen": 39, "unstabl": [90, 92], "unter": [40, 41, 42], "untest": 66, "until": [74, 104], "untreat": [66, 74], "up": [2, 14, 41, 53, 57, 58, 60, 61, 65, 66, 73, 74, 75, 90, 92, 101, 104, 105], "upcom": 104, "updat": [40, 55, 59, 103, 104], "update_layout": [48, 49, 53, 66], "update_trac": [48, 49], "upload": 104, "upon": [76, 104], "upper": [41, 42, 45, 47, 50, 52, 56, 61, 64, 65, 66, 73, 90, 95, 98, 105], "upper_bound": [48, 49], "upsilon": 67, "upsilon_i": 67, "upward": [41, 60, 61, 66], "upweight": 62, "url": [53, 100, 103], "us": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 34, 38, 40, 41, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 72, 75, 76, 79, 80, 89, 90, 92, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105], "usa": 103, "usabl": 57, "usag": [39, 43, 45, 51, 56, 59, 60, 61, 65, 67, 70, 102, 104], "use_label_encod": [60, 105], "use_other_treat_as_covari": [4, 7, 70], "usecolormap": [48, 49], "user": [30, 31, 32, 33, 38, 39, 40, 41, 42, 45, 47, 56, 57, 59, 60, 65, 72, 73, 76, 89, 99, 100, 101, 102, 104, 105], "user_guid": 55, "userwarn": [60, 66], "usual": [40, 48, 49, 51, 57, 59, 65, 66, 72, 73, 75, 90, 98], "util": [31, 57, 58, 62, 73, 104], "v": [8, 9, 11, 12, 16, 17, 23, 25, 26, 27, 29, 38, 40, 41, 45, 47, 56, 59, 60, 62, 68, 69, 72, 74, 89, 99, 100, 102, 103, 104, 105], "v108": 100, "v12": [100, 102], "v22": 42, "v23": 100, "v_": [26, 40, 59], "v_i": [22, 23, 27, 28, 29, 38, 47, 69, 74], "v_j": [89, 99], "val": [23, 75, 103], "val_list": 53, "valid": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 22, 38, 39, 40, 41, 47, 50, 51, 57, 58, 59, 60, 61, 64, 69, 71, 72, 73, 75, 76, 78, 83, 88, 90, 92, 103, 105], "valu": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 36, 37, 38, 39, 40, 41, 42, 45, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 65, 66, 68, 71, 73, 74, 75, 78, 83, 84, 85, 88, 89, 90, 92, 95, 98, 99, 102, 104, 105], "value_count": 60, "van": 103, "vanderpla": [100, 102], "vanish": [38, 47, 69], "var": [18, 19, 20, 24, 40, 59, 62, 90, 91, 92, 96, 97, 98], "var_ep": 66, "varepsilon": [8, 18, 19, 26, 40, 59, 67, 72, 74], "varepsilon_": [26, 40, 59], "varepsilon_0": 20, "varepsilon_1": 20, "varepsilon_d": [19, 24], "varepsilon_i": [24, 25, 50, 64, 67], "vari": [41, 52, 57, 60, 62, 66], "variabl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 40, 41, 42, 43, 45, 51, 53, 56, 58, 59, 60, 61, 65, 66, 67, 70, 72, 73, 74, 75, 76, 89, 90, 92, 95, 98, 99, 102, 103, 104, 105], "varianc": [30, 31, 40, 42, 59, 65, 66, 71, 75, 90, 92, 95, 96, 97, 98, 102], "variant": 39, "variat": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 65, 90, 92, 98], "variou": [39, 58, 66, 73, 105], "varoquaux": [100, 102], "vasili": [66, 103], "vector": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 21, 22, 23, 25, 26, 28, 29, 37, 40, 41, 46, 51, 54, 55, 56, 59, 60, 63, 67, 74, 89, 99, 102, 104], "venv": 101, "verbos": [41, 47, 52, 57, 58, 66], "veri": [39, 40, 42, 56, 57, 59, 66, 76, 100], "verifi": 62, "versa": [57, 62, 90, 95], "version": [18, 40, 41, 42, 60, 66, 68, 72, 89, 90, 91, 93, 94, 96, 99, 104], "versoin": 66, "versu": 55, "vertic": [40, 45, 59], "via": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 31, 39, 50, 51, 52, 53, 54, 55, 56, 57, 65, 67, 68, 70, 71, 72, 73, 74, 75, 78, 85, 89, 90, 92, 95, 98, 99, 100, 101, 102, 103, 104, 105], "viabl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "vice": [57, 62, 90, 95], "victor": [53, 66, 75, 100, 103], "view": 55, "vignett": [39, 104], "villa": [37, 46], "violet": [50, 61, 64], "vira": 103, "virtual": 101, "virtualenv": 101, "visibl": [61, 66], "visit": [100, 105], "visual": [40, 56, 58, 59], "vol": 39, "volum": [66, 100], "voluntari": 62, "vv740": 59, "vv760g": 59, "w": [16, 17, 18, 19, 20, 27, 30, 31, 40, 53, 59, 62, 63, 68, 69, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 102], "w24678": 75, "w30302": 103, "w_": [20, 40, 59, 63], "w_1": [20, 63], "w_2": [20, 63], "w_3": 20, "w_4": 20, "w_df": 63, "w_i": [29, 51, 63, 68, 72, 75, 76, 89, 99], "wa": [40, 52, 58, 59, 66, 104], "wager": 103, "wai": [41, 57, 58, 60, 66, 73, 76, 101], "wander": 28, "wang": 103, "want": [37, 40, 41, 42, 46, 50, 51, 57, 59, 64, 73, 100, 101, 103], "warn": [37, 38, 39, 40, 41, 42, 47, 60, 66, 68, 73, 74, 75, 76, 89, 99, 102, 104], "wayon": 40, "we": [9, 35, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 81, 89, 90, 92, 98, 99, 101, 102, 104, 105], "weak": [90, 92, 103], "wealth": [16, 65], "websit": [41, 42, 73, 100], "wedg": [40, 59], "week": 104, "wei": [89, 99], "weight": [1, 2, 3, 8, 9, 10, 13, 14, 15, 40, 41, 42, 45, 56, 59, 60, 67, 71, 73, 76, 77, 82, 89, 90, 91, 96, 99, 104], "weights_bar": [1, 9], "weiss": [100, 102], "well": [4, 7, 38, 40, 47, 53, 57, 58, 59, 68, 69, 70, 75, 102], "were": [41, 60, 61, 67, 105], "what": [39, 53, 57], "when": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 32, 33, 41, 51, 55, 60, 62, 74, 76, 89, 99, 100, 101, 102, 104], "whenev": [41, 60], "whera": [90, 96], "where": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 34, 35, 37, 38, 40, 41, 45, 46, 47, 50, 51, 52, 56, 59, 60, 62, 63, 64, 66, 67, 68, 69, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 95, 96, 98, 101, 102, 104, 105], "wherea": [21, 45, 51, 66, 67, 76, 82, 90, 91, 105], "whether": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 24, 29, 34, 41, 52, 57, 60, 61, 66, 70, 73, 90, 92, 104], "which": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 21, 31, 37, 38, 39, 41, 42, 44, 45, 46, 47, 51, 53, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 70, 72, 73, 74, 76, 89, 90, 91, 92, 95, 96, 98, 99, 101, 104, 105], "while": [37, 46], "white": [40, 54, 55, 59, 66], "whitegrid": [60, 61], "whitnei": [66, 103], "who": [39, 41, 60, 66], "whole": [38, 47, 51, 69, 73, 90, 92], "width": [38, 40, 48, 49, 53], "wiki": 104, "wiksel": 103, "wild": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 89, 99], "window": 101, "wise": [54, 55], "wish": 101, "within": [40, 54, 55, 59, 63], "without": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 24, 37, 38, 46, 47, 57, 58, 66, 69, 71, 73, 90, 92, 101, 104], "wolf": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 89, 99], "won": 66, "word": 105, "work": [32, 33, 44, 45, 55, 56, 57, 62, 65, 66, 73, 89, 101, 103], "workflow": [100, 104], "workspac": 60, "world": 103, "worri": 66, "would": [39, 41, 42, 48, 49, 53, 57, 60, 61, 65, 66, 72, 73, 90, 98, 105], "wrapper": [39, 73], "write": [38, 39, 47, 51, 55, 67, 69, 90, 98], "written": [76, 90, 91, 96], "wrong": [57, 62], "wspace": 57, "wurd": [40, 41, 42], "www": [100, 101], "x": [1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 38, 39, 40, 41, 42, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99, 102, 105], "x0": [45, 62], "x1": [40, 42, 45, 51, 58, 59, 62, 65, 66, 67, 70, 72, 73, 74, 76, 89, 90, 92, 102], "x10": [40, 42, 58, 59, 67, 70, 73, 74, 76, 89, 102], "x100": [40, 42, 59, 67, 70, 74, 102], "x11": [40, 42, 59, 67, 70, 73, 74, 76, 89, 102], "x12": [40, 42, 59, 67, 70, 73, 74, 76, 89, 102], "x13": [40, 42, 59, 67, 70, 73, 74, 76, 89, 102], "x14": [40, 42, 59, 67, 70, 73, 74, 76, 89, 102], "x15": [40, 42, 59, 67, 70, 73, 74, 76, 89, 102], "x16": [40, 42, 59, 67, 70, 73, 74, 76, 89, 102], "x17": [40, 42, 59, 67, 70, 73, 74, 76, 89, 102], "x18": [40, 42, 59, 67, 70, 73, 74, 76, 89, 102], "x19": [40, 42, 59, 67, 70, 73, 74, 76, 89, 102], "x1x2x3x4x5x6x7x8x9x10": 40, "x2": [40, 42, 45, 51, 58, 59, 65, 66, 67, 70, 72, 73, 74, 76, 89, 102], "x20": [40, 42, 59, 67, 70, 73, 74, 76, 89, 102], "x21": [40, 42, 59, 67, 70, 74, 102], "x22": [40, 42, 59, 67, 70, 74, 102], "x23": [40, 42, 59, 67, 70, 74, 102], "x24": [40, 42, 59, 67, 70, 74, 102], "x25": [40, 42, 59, 67, 70, 74, 102], "x26": [40, 42, 59, 67, 70, 74, 102], "x27": [40, 42, 59, 67, 70, 74, 102], "x28": [40, 42, 59, 67, 70, 74, 102], "x29": [40, 42, 59, 67, 70, 74, 102], "x2_dummi": 66, "x2_preds_control": 66, "x2_preds_treat": 66, "x3": [40, 42, 45, 51, 58, 59, 65, 66, 67, 70, 72, 73, 74, 76, 89, 102], "x30": [40, 42, 59, 67, 70, 74, 102], "x31": [40, 42, 59, 67, 70, 74, 102], "x32": [40, 42, 59, 67, 70, 74, 102], "x33": [40, 42, 59, 67, 70, 74, 102], "x34": [40, 42, 59, 67, 70, 74, 102], "x35": [40, 42, 59, 67, 70, 74, 102], "x36": [40, 42, 59, 67, 70, 74, 102], "x37": [40, 42, 59, 67, 70, 74, 102], "x38": [40, 42, 59, 67, 70, 74, 102], "x39": [40, 42, 59, 67, 70, 74, 102], "x4": [40, 42, 45, 51, 58, 59, 65, 66, 67, 70, 73, 74, 76, 89, 102], "x40": [40, 42, 59, 67, 70, 74, 102], "x41": [40, 42, 59, 67, 70, 74, 102], "x42": [40, 42, 59, 67, 70, 74, 102], "x43": [40, 42, 58, 59, 67, 70, 74, 102], "x44": [40, 42, 58, 59, 67, 70, 74, 102], "x45": [40, 42, 58, 59, 67, 70, 74, 102], "x46": [40, 42, 58, 59, 67, 70, 74, 102], "x47": [40, 42, 58, 59, 67, 70, 74, 102], "x48": [40, 42, 58, 59, 67, 70, 74, 102], "x49": [40, 42, 58, 59, 67, 70, 74, 102], "x5": [40, 42, 58, 59, 66, 67, 70, 73, 74, 76, 89, 102], "x50": [40, 42, 58, 59, 67, 70, 74, 102], "x51": [40, 42, 59, 67, 70, 74, 102], "x52": [40, 42, 59, 67, 70, 74, 102], "x53": [40, 42, 59, 67, 70, 74, 102], "x54": [40, 42, 59, 67, 70, 74, 102], "x55": [40, 42, 59, 67, 70, 74, 102], "x56": [40, 42, 59, 67, 70, 74, 102], "x57": [40, 42, 59, 67, 70, 74, 102], "x58": [40, 42, 59, 67, 70, 74, 102], "x59": [40, 42, 59, 67, 70, 74, 102], "x6": [40, 42, 58, 59, 67, 70, 73, 74, 76, 89, 102], "x60": [40, 42, 59, 67, 70, 74, 102], "x61": [40, 42, 59, 67, 70, 74, 102], "x62": [40, 42, 59, 67, 70, 74, 102], "x63": [40, 42, 59, 67, 70, 74, 102], "x64": [40, 42, 59, 60, 67, 70, 74, 102], "x65": [40, 42, 59, 67, 70, 74, 102], "x66": [40, 42, 59, 67, 70, 74, 102], "x67": [40, 42, 59, 67, 70, 74, 102], "x68": [40, 42, 59, 67, 70, 74, 102], "x69": [40, 42, 59, 67, 70, 74, 102], "x7": [40, 42, 58, 59, 67, 70, 73, 74, 76, 89, 102], "x70": [40, 42, 59, 67, 70, 74, 102], "x71": [40, 42, 59, 67, 70, 74, 102], "x72": [40, 42, 59, 67, 70, 74, 102], "x73": [40, 42, 59, 67, 70, 74, 102], "x74": [40, 42, 59, 67, 70, 74, 102], "x75": [40, 42, 59, 67, 70, 74, 102], "x76": [40, 42, 59, 67, 70, 74, 102], "x77": [40, 42, 59, 67, 70, 74, 102], "x78": [40, 42, 59, 67, 70, 74, 102], "x79": [40, 42, 59, 67, 70, 74, 102], "x8": [40, 42, 58, 59, 67, 70, 73, 74, 76, 89, 102], "x80": [40, 42, 59, 67, 70, 74, 102], "x81": [40, 42, 59, 67, 70, 74, 102], "x82": [40, 42, 59, 67, 70, 74, 102], "x83": [40, 42, 59, 67, 70, 74, 102], "x84": [40, 42, 59, 67, 70, 74, 102], "x85": [40, 42, 59, 67, 70, 74, 102], "x86": [40, 42, 59, 67, 70, 74, 102], "x87": [40, 42, 59, 67, 70, 74, 102], "x88": [40, 42, 59, 67, 70, 74, 102], "x89": [40, 42, 59, 67, 70, 74, 102], "x9": [40, 42, 58, 59, 67, 70, 73, 74, 76, 89, 102], "x90": [40, 42, 59, 67, 70, 74, 102], "x91": [40, 42, 59, 67, 70, 74, 102], "x92": [40, 42, 59, 67, 70, 74, 102], "x93": [40, 42, 59, 67, 70, 74, 102], "x94": [40, 42, 59, 67, 70, 74, 102], "x95": [40, 42, 59, 67, 70, 74, 102], "x96": [40, 42, 59, 67, 70, 74, 102], "x96x97x98x99x100ydcluster_var_icluster_var_jz": 40, "x97": [40, 42, 59, 67, 70, 74, 102], "x98": [40, 42, 59, 67, 70, 74, 102], "x99": [40, 42, 59, 67, 70, 74, 102], "x_": [26, 27, 38, 40, 47, 52, 59, 66, 69], "x_0": [48, 49, 52, 54, 55, 56], "x_1": [11, 12, 18, 19, 20, 24, 48, 49, 50, 52, 54, 55, 56, 64, 66, 74, 90, 92, 102], "x_1x_3": [50, 64], "x_2": [18, 19, 20, 24, 48, 49, 50, 52, 54, 55, 56, 64, 66, 90, 92], "x_3": [18, 19, 20, 24, 48, 49, 52, 54, 55, 56, 90, 92], "x_4": [18, 19, 20, 24, 48, 49, 50, 54, 55, 56, 64], "x_5": [18, 19, 24, 48, 49, 54, 55], "x_6": [48, 49, 54, 55], "x_7": [48, 49, 54, 55], "x_8": [48, 49, 54, 55], "x_9": [48, 49, 54, 55], "x_binary_control": 66, "x_binary_tr": 66, "x_col": [4, 7, 37, 40, 41, 42, 46, 53, 59, 60, 61, 63, 65, 66, 70, 73, 102, 104, 105], "x_cols_bench": 66, "x_cols_binari": 66, "x_cols_poli": 59, "x_conf": 64, "x_conf_tru": 64, "x_df": 52, "x_domain": 42, "x_i": [21, 22, 23, 25, 27, 28, 29, 38, 47, 50, 51, 54, 55, 62, 64, 67, 69, 72, 74], "x_p": [11, 12, 74, 102], "x_train": 58, "x_true": [50, 64], "x_var": 42, "xaxis_titl": [48, 49, 53, 66], "xformla": 39, "xgb": 58, "xgb_untuned_l": 58, "xgb_untuned_m": 58, "xgbclassifi": [57, 60, 62, 105], "xgboost": [38, 41, 57, 60, 62, 105], "xgbregressor": [57, 58, 60, 62, 105], "xi": [20, 24, 74], "xi_": [89, 99], "xi_0": [26, 40, 59], "xi_i": 67, "xiaoji": 103, "xintercept": 38, "xlab": [38, 40, 41], "xlabel": [45, 48, 49, 50, 52, 54, 55, 58, 60, 61, 64], "xlim": [38, 41], "xtick": [45, 58], "xval": [42, 73], "xx": 47, "y": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 95, 96, 97, 98, 99, 102, 105], "y0": [39, 45, 50, 64], "y0_cvar": 50, "y0_quant": [50, 64], "y1": [39, 50, 64], "y1_cvar": 50, "y1_quant": [50, 64], "y_": [26, 40, 51, 52, 59, 67, 74], "y_0": [5, 20, 76, 79], "y_1": [5, 20, 76, 79], "y_col": [4, 7, 37, 38, 40, 41, 42, 46, 48, 49, 53, 54, 55, 59, 60, 61, 63, 65, 68, 69, 70, 73, 74, 75, 76, 102, 104, 105], "y_df": [52, 63], "y_diff": 52, "y_i": [21, 22, 23, 25, 27, 28, 29, 38, 47, 50, 51, 62, 63, 64, 67, 69, 74], "y_pred": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 57, 73], "y_train": 58, "y_true": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 57, 73], "ya": 103, "yasui": 103, "yata": 103, "yaxis_titl": [48, 49, 53, 66], "year": 100, "yerr": [45, 52, 54, 55, 58, 60, 62], "yet": [40, 44], "yggvpl": 59, "yintercept": 41, "ylab": [38, 40, 41], "ylabel": [45, 48, 49, 50, 52, 54, 55, 58, 60, 61, 64], "ylim": 60, "ymax": 41, "ymin": 41, "yname": 39, "york": 103, "you": [37, 38, 46, 52, 55, 59, 65, 100, 101, 105], "your": [57, 101], "ython": 100, "yukun": 103, "yusuk": 103, "yuya": 103, "yy": 47, "z": [4, 7, 8, 10, 11, 15, 18, 19, 20, 22, 24, 25, 26, 29, 37, 40, 41, 46, 48, 49, 53, 59, 60, 64, 66, 67, 72, 74, 76, 81, 83, 85, 86, 89, 99, 104], "z1": [11, 74], "z2": 74, "z3": 74, "z4": 74, "z_": [26, 40, 59], "z_1": [18, 19, 24], "z_2": [18, 19, 24], "z_3": [18, 19, 24], "z_4": [18, 19, 24], "z_5": 18, "z_col": [4, 7, 8, 10, 11, 37, 40, 41, 46, 59, 60, 61, 67, 70, 72, 74, 104], "z_i": [25, 29, 64, 67, 74], "z_j": [18, 19, 20, 24], "z_true": 64, "zadik": 103, "zaxis_titl": [48, 49, 53], "zero": [20, 50, 51, 52, 57, 63, 64, 65, 66, 89], "zeros_lik": 64, "zeta": [8, 11, 12, 41, 60, 72, 74, 102], "zeta_": [26, 40, 59], "zeta_0": [26, 40, 59], "zeta_i": [23, 25, 27, 38, 47, 69], "zeta_j": [89, 99], "zhang": 103, "zhao": [5, 6, 18, 19, 20, 24, 39, 51, 74, 103], "zimmert": [51, 103], "zip": [48, 49], "zorder": 45, "\u03c4_x0": 62, "\u03c4_x1": 62, "\u2139": 38}, "titles": ["API reference", "doubleml.DoubleMLAPO", "doubleml.DoubleMLAPOS", "doubleml.DoubleMLCVAR", "doubleml.DoubleMLClusterData", "doubleml.DoubleMLDID", "doubleml.DoubleMLDIDCS", "doubleml.DoubleMLData", "doubleml.DoubleMLIIVM", "doubleml.DoubleMLIRM", "doubleml.DoubleMLLPQ", "doubleml.DoubleMLPLIV", "doubleml.DoubleMLPLR", "doubleml.DoubleMLPQ", "doubleml.DoubleMLQTE", "doubleml.DoubleMLSSM", "doubleml.datasets.fetch_401K", "doubleml.datasets.fetch_bonus", "doubleml.datasets.make_confounded_irm_data", "doubleml.datasets.make_confounded_plr_data", "doubleml.datasets.make_did_SZ2020", "doubleml.datasets.make_heterogeneous_data", "doubleml.datasets.make_iivm_data", "doubleml.datasets.make_irm_data", "doubleml.datasets.make_irm_data_discrete_treatments", "doubleml.datasets.make_pliv_CHS2015", "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "doubleml.datasets.make_plr_CCDDHNR2018", "doubleml.datasets.make_plr_turrell2018", "doubleml.datasets.make_ssm_data", "doubleml.double_ml_score_mixins.LinearScoreMixin", "doubleml.double_ml_score_mixins.NonLinearScoreMixin", "doubleml.utils.DMLDummyClassifier", "doubleml.utils.DMLDummyRegressor", "doubleml.utils.DoubleMLBLP", "doubleml.utils.DoubleMLPolicyTree", "doubleml.utils.gain_statistics", "R: Basic Instrumental Variables Calculation", "R: Basics of Double Machine Learning", "R: DoubleML for Difference-in-Differences", "R: Cluster Robust Double Machine Learning", "R: Impact of 401(k) on Financial Wealth", "R: Ensemble Learners and More with <code class=\"docutils literal notranslate\"><span class=\"pre\">mlr3pipelines</span></code>", "DML: Bonus Data", "Examples", "Python: Average Potential Outcome (APO) Models", "Python: Basic Instrumental Variables calculation", "Python: Basics of Double Machine Learning", "Python: Conditional Average Treatment Effects (CATEs) for IRM models", "Python: Conditional Average Treatment Effects (CATEs) for PLR models", "Python: Conditional Value at Risk of potential outcomes", "Python: Difference-in-Differences", "Python: Difference-in-Differences Pre-Testing", "Python: First Stage and Causal Estimation", "Python: Group Average Treatment Effects (GATEs) for IRM models", "Python: Group Average Treatment Effects (GATEs) for PLR models", "Python: GATE Sensitivity Analysis", "Python: Choice of learners", "DoubleML meets FLAML - How to tune learners automatically within <code class=\"docutils literal notranslate\"><span class=\"pre\">DoubleML</span></code>", "Python: Cluster Robust Double Machine Learning", "Python: Impact of 401(k) on Financial Wealth", "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)", "Python: PLM and IRM for Multiple Treatments", "Python: Policy Learning with Trees", "Python: Potential Quantiles and Quantile Treatment Effects", "Python: Sensitivity Analysis", "Example: Sensitivity Analysis for Causal ML", "Python: Sample Selection Models", "<span class=\"section-number\">6. </span>Double machine learning algorithms", "<span class=\"section-number\">1. </span>The basics of double/debiased machine learning", "<span class=\"section-number\">2. </span>The data-backend DoubleMLData", "User guide", "<span class=\"section-number\">4. </span>Heterogeneous treatment effects", "<span class=\"section-number\">7. </span>Learners, hyperparameters and hyperparameter tuning", "<span class=\"section-number\">3. </span>Models", "<span class=\"section-number\">9. </span>Sample-splitting, cross-fitting and repeated cross-fitting", "<span class=\"section-number\">5. </span>Score functions", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "<span class=\"section-number\">8. </span>Variance estimation and confidence intervals", "<span class=\"section-number\">10. </span>Sensitivity analysis", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "Confidence bands and multiplier bootstrap for valid simultaneous inference", "DoubleML", "Installing DoubleML", "Getting started", "Double machine learning literature", "Release notes", "DoubleML Workflow"], "titleterms": {"": 58, "0": 105, "1": [58, 66, 105], "2": [58, 66, 105], "2011": 66, "2023": 66, "3": [58, 66, 105], "4": [66, 105], "401": [41, 60, 61, 65], "5": [66, 105], "6": 105, "7": 105, "95": 58, "A": [40, 59], "ATE": [56, 62, 67], "No": [40, 59], "One": [40, 48, 49, 59], "The": [41, 60, 62, 69, 70, 102], "acknowledg": [39, 100], "acycl": [37, 46], "addit": 62, "advanc": [73, 89], "al": 66, "algorithm": [68, 90, 100, 102], "altern": 76, "analysi": [45, 56, 65, 66, 90, 105], "api": [0, 58], "apo": [45, 74, 76, 90], "applic": [40, 59, 65], "approach": [38, 47, 57, 69], "arah": 66, "arbitrari": 62, "arrai": 70, "asset": [41, 60], "assumpt": 66, "att": 51, "augment": 62, "automat": 58, "automl": 58, "averag": [41, 45, 48, 49, 54, 55, 60, 72, 74, 76, 90], "backend": [40, 41, 59, 60, 70, 102, 105], "band": [89, 99], "base": 42, "basic": [37, 38, 46, 47, 69], "benchmark": [65, 66, 90], "bia": [38, 47, 69], "binari": [74, 76], "bonu": 43, "bootstrap": [89, 99], "build": 101, "calcul": [37, 46], "call": 58, "callabl": 76, "case": 44, "cate": [48, 49, 62, 72], "causal": [43, 45, 53, 66, 76, 102, 105], "chernozhukov": 66, "choic": 57, "citat": 100, "class": [0, 40, 59], "cluster": [40, 59], "code": 100, "coeffici": 58, "combin": 53, "compar": [57, 58], "comparison": [39, 58], "comput": [57, 58], "conclus": [58, 66], "conda": 101, "condit": [48, 49, 50, 61, 72, 76], "confid": [58, 89, 99], "construct": 73, "contrast": 45, "coverag": [51, 53], "cran": 101, "creat": 58, "cross": [40, 51, 59, 74, 75, 76, 90, 102], "custom": [57, 58], "cvar": [50, 61, 72, 76], "dag": [37, 46], "data": [0, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 69, 70, 74, 76, 90, 102, 105], "datafram": 70, "dataset": [0, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 43], "debias": [38, 47, 69, 102], "default": 58, "defin": [40, 59], "demo": 39, "detail": 39, "develop": 101, "dgp": [38, 45, 47], "did": [39, 74], "differ": [39, 51, 52, 57, 74, 76, 89, 90], "dimension": [48, 49], "direct": [37, 46], "disclaim": 66, "distribut": 67, "dml": [40, 43, 59, 75, 102, 105], "dml1": 68, "dml2": 68, "dmldummyclassifi": 32, "dmldummyregressor": 33, "doubl": [0, 38, 40, 47, 59, 68, 69, 100, 102, 103], "double_ml_score_mixin": [30, 31], "doubleml": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 46, 58, 60, 65, 66, 89, 100, 101, 105], "doublemlapo": [1, 2], "doublemlblp": 34, "doublemlclusterdata": [4, 40, 59], "doublemlcvar": 3, "doublemldata": [7, 41, 60, 70, 102], "doublemldid": 5, "doublemldidc": 6, "doublemliivm": 8, "doublemlirm": 9, "doublemllpq": 10, "doublemlpliv": [11, 40, 59], "doublemlplr": 12, "doublemlpolicytre": 35, "doublemlpq": 13, "doublemlqt": 14, "doublemlssm": 15, "effect": [41, 44, 48, 49, 50, 54, 55, 60, 61, 62, 64, 65, 66, 72], "elig": [41, 60], "empir": 53, "ensembl": 42, "error": [40, 59], "estim": [37, 41, 43, 46, 51, 53, 56, 58, 60, 61, 62, 64, 65, 66, 67, 75, 76, 89, 102, 105], "et": 66, "evalu": [57, 58, 73], "exampl": [39, 40, 44, 48, 49, 59, 65, 66], "exploit": [39, 42], "extern": [73, 75], "featur": [42, 100], "fetch_401k": 16, "fetch_bonu": 17, "figur": 62, "file": 101, "final": 39, "financi": [41, 60, 61], "first": 53, "fit": [40, 58, 59, 75, 102], "flaml": 58, "fold": [58, 75], "forest": 43, "formul": [66, 105], "from": [39, 42, 70, 101], "full": 58, "function": [0, 39, 40, 59, 76, 102], "gain_statist": 36, "gate": [54, 55, 56, 72], "gatet": 56, "gener": [0, 38, 44, 45, 47, 58, 69, 90], "get": 102, "github": 101, "graph": [37, 46], "group": [54, 55, 72], "guid": 71, "helper": [40, 59], "heterogen": [44, 62, 72], "how": [42, 58], "hyperparamet": 73, "identif": 66, "iivm": [41, 60, 74, 76], "impact": [41, 60, 61], "implement": [68, 76, 90], "induc": [38, 47, 69], "infer": [89, 99, 105], "initi": [40, 58, 59], "instal": 101, "instrument": [37, 46], "integr": 39, "interact": [41, 54, 60, 63, 74, 76, 90], "interv": [58, 89, 99], "invers": 62, "irm": [41, 43, 48, 54, 60, 62, 63, 65, 72, 74, 76, 90], "iv": [37, 41, 46, 60, 74, 76], "joint": 99, "k": [41, 60, 61, 65, 75], "lambda": 53, "lasso": [43, 53], "latest": 101, "lear": [40, 59], "learn": [0, 38, 40, 47, 59, 63, 68, 69, 72, 100, 102, 103], "learner": [42, 43, 57, 58, 73, 102], "less": 58, "level": 74, "linear": [41, 55, 60, 62, 74, 76, 90], "linearscoremixin": 30, "literatur": 103, "load": [40, 43, 59, 66], "loader": 0, "local": [41, 60, 61, 64, 76], "loss": 53, "lpq": [64, 76], "lqte": [61, 64], "m": 75, "machin": [0, 38, 40, 47, 59, 68, 69, 100, 102, 103], "main": 100, "mainten": 100, "make_confounded_irm_data": 18, "make_confounded_plr_data": 19, "make_did_sz2020": 20, "make_heterogeneous_data": 21, "make_iivm_data": 22, "make_irm_data": 23, "make_irm_data_discrete_treat": 24, "make_pliv_chs2015": 25, "make_pliv_multiway_cluster_ckms2021": 26, "make_plr_ccddhnr2018": 27, "make_plr_turrell2018": 28, "make_ssm_data": 29, "mar": 67, "market": [40, 59], "matric": 70, "meet": 58, "method": [58, 105], "metric": [57, 58], "minimum": 73, "miss": 67, "missing": [74, 76], "mixin": 0, "ml": [38, 39, 47, 66, 69, 105], "mlr3": 42, "mlr3extralearn": 42, "mlr3learner": 42, "mlr3pipelin": 42, "model": [0, 41, 43, 45, 48, 49, 54, 55, 58, 60, 62, 63, 66, 67, 72, 74, 75, 76, 89, 90, 102, 105], "modul": [0, 43], "more": 42, "motiv": [40, 59], "multipl": [45, 62, 74], "multipli": [89, 99], "naiv": [37, 46], "net": [41, 60], "neyman": [76, 102], "nonignor": [67, 74, 76], "nonlinearscoremixin": 31, "nonrespons": [67, 74, 76], "note": 104, "nuisanc": [58, 102], "object": [40, 59, 65], "orthogon": [38, 47, 69, 76, 102], "out": [38, 47, 69], "outcom": [45, 50, 51, 67, 72, 74, 76, 90], "over": 89, "overcom": [38, 47, 69], "overfit": [38, 47, 69], "overlap": 62, "packag": [39, 41, 60, 101], "panel": [51, 74, 76, 90], "paramet": [42, 43, 58, 76], "partial": [38, 41, 47, 55, 60, 62, 69, 74, 76, 90], "particip": [41, 60], "partit": 75, "penalti": 53, "perform": [39, 62], "pip": 101, "pipelin": 73, "pliv": [74, 76], "plm": [62, 74, 76], "plot": [40, 58, 59], "plr": [41, 43, 49, 55, 60, 72, 74, 76, 90], "polici": [63, 72], "potenti": [45, 50, 61, 64, 72, 74, 76, 90], "pq": [64, 72, 76], "pre": 52, "predict": [39, 73], "preprocess": 42, "problem": 105, "process": [38, 40, 45, 47, 59, 69], "product": [40, 59], "propens": 62, "provid": 75, "python": [44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 67, 73, 101], "qte": [64, 72], "qualiti": 53, "quantil": [61, 64, 72, 76], "r": [37, 38, 39, 40, 41, 42, 44, 73, 101], "random": [43, 67, 74, 76], "rank": 62, "real": [40, 59], "refer": [0, 37, 39, 40, 42, 46, 53, 59, 62, 66, 69, 73, 75, 89, 99, 100, 102], "regress": [41, 54, 55, 60, 63, 74, 76, 90], "regular": [38, 47, 69], "releas": [101, 104], "remark": 39, "remov": [38, 47, 69], "repeat": [51, 74, 75, 76, 90], "repetit": 75, "requir": 73, "respect": [40, 59], "result": [40, 41, 59, 60, 62], "risk": [50, 61, 72, 76], "robust": [40, 59], "sampl": [38, 47, 58, 67, 69, 74, 75, 76], "sandbox": 44, "score": [0, 38, 47, 62, 69, 76, 102], "section": [51, 74, 76, 90], "select": [67, 74, 76], "sensit": [45, 56, 65, 66, 90, 105], "set": [42, 73], "simpl": [38, 47, 69], "simul": [37, 40, 46, 51, 59, 65], "simultan": [89, 99], "singl": 45, "sourc": [100, 101], "specif": [90, 105], "specifi": [43, 73, 76], "split": [38, 47, 69, 75], "ssm": 74, "stage": 53, "standard": [40, 57, 59], "start": 102, "step": 58, "studi": 44, "summari": [41, 58, 60, 62], "test": 52, "theori": 90, "time": [57, 58], "train": 58, "treatment": [41, 48, 49, 50, 54, 55, 60, 61, 62, 64, 72, 74], "tree": [63, 72], "tune": [42, 58, 73], "two": [40, 48, 49, 59], "under": [62, 67], "untun": 58, "up": 42, "us": [37, 39, 42, 43, 46, 58, 73], "user": 71, "util": [0, 32, 33, 34, 35, 36], "v": 53, "valid": [89, 99], "valu": [50, 61, 72, 76], "vanderweel": 66, "variabl": [37, 46], "varianc": 89, "version": 101, "via": 76, "wai": [40, 59], "wealth": [41, 60, 61], "weight": [62, 72], "when": 58, "whl": 101, "within": 58, "without": 75, "workflow": 105, "xgboost": 58, "zero": [40, 59]}})