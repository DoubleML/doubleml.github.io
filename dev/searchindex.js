Search.setIndex({"alltitles": {"(One-Way) Cluster Robust Double Machine Learing": [[44, "(One-Way)-Cluster-Robust-Double-Machine-Learing"], [63, "(One-Way)-Cluster-Robust-Double-Machine-Learing"]], "0. Problem Formulation": [[110, "problem-formulation"]], "1. Data-Backend": [[110, "data-backend"]], "1. Formulation of Causal Model & Identification Assumptions": [[71, "1.-Formulation-of-Causal-Model-&-Identification-Assumptions"]], "2. Causal Model": [[110, "causal-model"]], "2. Estimation of Causal Effect": [[71, "2.-Estimation-of-Causal-Effect"]], "3. ML Methods": [[110, "ml-methods"]], "3. Sensitivity Analysis": [[71, "3.-Sensitivity-Analysis"]], "4. Benchmarking Analysis": [[71, "4.-Benchmarking-Analysis"]], "4. DML Specifications": [[110, "dml-specifications"]], "5. Conclusion": [[71, "5.-Conclusion"]], "5. Estimation": [[110, "estimation"]], "6. Inference": [[110, "inference"]], "7. Sensitivity Analysis": [[110, "sensitivity-analysis"]], "A Motivating Example: Two-Way Cluster Robust DML": [[44, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"], [63, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"]], "API reference": [[0, "api-reference"]], "ATE Estimation and Sensitivity": [[60, "ATE-Estimation-and-Sensitivity"]], "ATE estimates distribution": [[72, "ATE-estimates-distribution"], [72, "id3"]], "ATTE Estimation": [[55, "ATTE-Estimation"], [55, "id2"]], "Acknowledgements": [[105, "acknowledgements"]], "Acknowledgements and Final Remarks": [[43, "Acknowledgements-and-Final-Remarks"]], "Additional Results: CATE estimates": [[66, "Additional-Results:-CATE-estimates"]], "Advanced: External Predictions": [[78, "advanced-external-predictions"]], "Advanced: Global and Local Learners, Stacked Ensembles": [[69, "Advanced:-Global-and-Local-Learners,-Stacked-Ensembles"]], "Algorithm DML1": [[73, "algorithm-dml1"]], "Algorithm DML2": [[73, "algorithm-dml2"]], "Application Results": [[44, "Application-Results"], [63, "Application-Results"]], "Application: 401(k)": [[70, "Application:-401(k)"]], "AutoML with less Computation time": [[62, "AutoML-with-less-Computation-time"]], "Average Potential Outcome (APOs)": [[49, "Average-Potential-Outcome-(APOs)"]], "Average Potential Outcomes (APOs)": [[79, "average-potential-outcomes-apos"], [81, "average-potential-outcomes-apos"], [95, "average-potential-outcomes-apos"]], "Average Potential Outcomes (APOs) for Multiple Treatment Levels": [[79, "average-potential-outcomes-apos-for-multiple-treatment-levels"]], "Benchmarking": [[95, "benchmarking"]], "Benchmarking Analysis": [[70, "Benchmarking-Analysis"]], "Binary Interactive Regression Model (IRM)": [[79, "binary-interactive-regression-model-irm"], [81, "binary-interactive-regression-model-irm"]], "CATEs for IRM models": [[77, "cates-for-irm-models"]], "CATEs for PLR models": [[77, "cates-for-plr-models"]], "CVaR Treatment Effects": [[54, "CVaR-Treatment-Effects"]], "CVaR of potential outcomes": [[77, "cvar-of-potential-outcomes"]], "CVaR treatment effects": [[77, "cvar-treatment-effects"]], "Causal Analysis with DoubleML": [[71, "Causal-Analysis-with-DoubleML"]], "Causal Contrasts": [[49, "Causal-Contrasts"]], "Causal estimation vs. lasso penalty \\lambda": [[57, "Causal-estimation-vs.-lasso-penalty-\\lambda"]], "Chernozhukov et al. (2023): Benchmarking": [[71, "Chernozhukov-et-al.-(2023):-Benchmarking"]], "Citation": [[105, "citation"]], "Cluster Robust Cross Fitting": [[44, "Cluster-Robust-Cross-Fitting"], [63, "Cluster-Robust-Cross-Fitting"]], "Cluster Robust Standard Errors": [[44, "Cluster-Robust-Standard-Errors"], [63, "Cluster-Robust-Standard-Errors"]], "Clustering and double machine learning": [[44, "Clustering-and-double-machine-learning"], [63, "Clustering-and-double-machine-learning"]], "Combined loss vs. lasso penalty \\lambda": [[57, "Combined-loss-vs.-lasso-penalty-\\lambda"]], "Compare Metrics for Nuisance Estimation": [[62, "Compare-Metrics-for-Nuisance-Estimation"]], "Comparing different learners": [[61, "Comparing-different-learners"]], "Comparison and summary": [[62, "Comparison-and-summary"]], "Comparison to AutoML with less Computation time and Untuned XGBoost Learners": [[62, "Comparison-to-AutoML-with-less-Computation-time-and-Untuned-XGBoost-Learners"]], "Comparison to did package": [[43, "Comparison-to-did-package"]], "Computation time": [[61, "Computation-time"]], "Conclusion": [[62, "Conclusion"]], "Conditional Value at Risk (CVaR)": [[54, "Conditional-Value-at-Risk-(CVaR)"]], "Conditional average treatment effects (CATEs)": [[77, "conditional-average-treatment-effects-cates"]], "Conditional value at risk (CVaR)": [[77, "conditional-value-at-risk-cvar"], [81, "conditional-value-at-risk-cvar"]], "Confidence bands and multiplier bootstrap for valid simultaneous inference": [[94, "confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference"], [104, "confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference"]], "Coverage Simulation": [[55, "Coverage-Simulation"], [55, "id3"]], "Cross-fitting with K folds": [[80, "cross-fitting-with-k-folds"]], "Cross-fitting, DML algorithms and Neyman-orthogonal score functions": [[107, "cross-fitting-dml-algorithms-and-neyman-orthogonal-score-functions"]], "Custom evaluation metrics": [[61, "Custom-evaluation-metrics"]], "DML: Bonus Data": [[47, "DML:-Bonus-Data"]], "Data": [[45, "Data"], [52, "Data"], [53, "Data"], [54, "Data"], [55, "Data"], [55, "id1"], [58, "Data"], [59, "Data"], [60, "Data"], [64, "Data"], [65, "Data"], [67, "Data"], [68, "Data"], [68, "id1"], [70, "Data"], [72, "Data"], [72, "id1"], [107, "data"]], "Data Generating Process (DGP)": [[42, "Data-Generating-Process-(DGP)"], [49, "Data-Generating-Process-(DGP)"], [51, "Data-Generating-Process-(DGP)"]], "Data Generation": [[62, "Data-Generation"]], "Data Simulation": [[41, "Data-Simulation"], [50, "Data-Simulation"]], "Data and Effect Estimation": [[70, "Data-and-Effect-Estimation"]], "Data generating process": [[74, "data-generating-process"]], "Data preprocessing": [[46, "Data-preprocessing"]], "Data-Backend for Cluster Data": [[44, "Data-Backend-for-Cluster-Data"], [63, "Data-Backend-for-Cluster-Data"]], "Dataset generators": [[0, "dataset-generators"]], "Dataset loaders": [[0, "dataset-loaders"]], "Datasets module": [[0, "datasets-module"]], "Define Helper Functions for Plotting": [[44, "Define-Helper-Functions-for-Plotting"], [63, "Define-Helper-Functions-for-Plotting"]], "Demo Example from did": [[43, "Demo-Example-from-did"]], "Details on Predictive Performance": [[43, "Details-on-Predictive-Performance"]], "Difference-in-Differences Models": [[81, "difference-in-differences-models"]], "Difference-in-Differences Models (DID)": [[79, "difference-in-differences-models-did"]], "Difference-in-Differences for Panel Data": [[95, "difference-in-differences-for-panel-data"]], "Difference-in-Differences for repeated cross-sections": [[95, "difference-in-differences-for-repeated-cross-sections"]], "Disclaimer": [[71, "Disclaimer"]], "Double Machine Learning Algorithm": [[105, "double-machine-learning-algorithm"]], "Double machine learning algorithms": [[73, "double-machine-learning-algorithms"]], "Double machine learning data class": [[0, "double-machine-learning-data-class"]], "Double machine learning literature": [[108, "double-machine-learning-literature"]], "Double machine learning models": [[0, "double-machine-learning-models"]], "Double/debiased machine learning": [[42, "Double/debiased-machine-learning"], [51, "Double/debiased-machine-learning"], [74, "double-debiased-machine-learning"]], "DoubleML": [[105, "doubleml"]], "DoubleML Object": [[70, "DoubleML-Object"]], "DoubleML Workflow": [[110, "doubleml-workflow"]], "DoubleML meets FLAML - How to tune learners automatically within DoubleML": [[62, "DoubleML-meets-FLAML---How-to-tune-learners-automatically-within-DoubleML"]], "DoubleMLData from arrays and matrices": [[75, "doublemldata-from-arrays-and-matrices"]], "DoubleMLData from dataframes": [[75, "doublemldata-from-dataframes"]], "Effect Heterogeneity": [[48, "effect-heterogeneity"]], "Empirical coverage vs. lasso penalty \\lambda": [[57, "Empirical-coverage-vs.-lasso-penalty-\\lambda"]], "Estimate DML models without sample-splitting": [[80, "estimate-dml-models-without-sample-splitting"]], "Estimate double/debiased machine learning models": [[107, "estimate-double-debiased-machine-learning-models"]], "Estimating Potential Quantiles and Quantile Treatment Effects": [[65, "Estimating-Potential-Quantiles-and-Quantile-Treatment-Effects"]], "Estimating local quantile treatment effects (LQTEs)": [[65, "Estimating-local-quantile-treatment-effects-(LQTEs)"]], "Estimating the Average Treatment Effect of 401(k) Eligibility on Net Financial Assets": [[45, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"], [64, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"]], "Estimating the treatment effect on the Conditional Value a Risk (CVaR)": [[65, "Estimating-the-treatment-effect-on-the-Conditional-Value-a-Risk-(CVaR)"]], "Estimation": [[72, "Estimation"], [72, "id2"]], "Estimation quality vs. \\lambda": [[57, "Estimation-quality-vs.-\\lambda"]], "Evaluate learners": [[78, "evaluate-learners"]], "Example: Sensitivity Analysis for Causal ML": [[71, "Example:-Sensitivity-Analysis-for-Causal-ML"]], "Examples": [[48, "examples"]], "Exploiting the Functionalities of did": [[43, "Exploiting-the-Functionalities-of-did"]], "Externally provide a sample splitting / partition": [[80, "externally-provide-a-sample-splitting-partition"]], "Flexible Covariate Adjustment in Regression Discontinuity Designs (RDD)": [[69, "Flexible-Covariate-Adjustment-in-Regression-Discontinuity-Designs-(RDD)"]], "Fuzzy RDD": [[69, "Fuzzy-RDD"]], "Fuzzy RDD Without Adjustment": [[69, "Fuzzy-RDD-Without-Adjustment"]], "Fuzzy RDD with Flexible Adjustment": [[69, "Fuzzy-RDD-with-Flexible-Adjustment"]], "Fuzzy RDD with Linear Adjustment": [[69, "Fuzzy-RDD-with-Linear-Adjustment"]], "Fuzzy Regression Discontinuity Design": [[79, "fuzzy-regression-discontinuity-design"]], "GATE Estimation and Sensitivity": [[60, "GATE-Estimation-and-Sensitivity"]], "GATET Estimation and Sensitivity": [[60, "GATET-Estimation-and-Sensitivity"]], "GATEs for IRM models": [[77, "gates-for-irm-models"]], "GATEs for PLR models": [[77, "gates-for-plr-models"]], "General Examples": [[48, "general-examples"]], "General algorithm": [[95, "general-algorithm"]], "Generate Fuzzy Data": [[69, "Generate-Fuzzy-Data"]], "Generate Sharp Data": [[69, "Generate-Sharp-Data"]], "Getting started": [[107, "getting-started"]], "Group Average Treatment Effects (GATEs)": [[58, "Group-Average-Treatment-Effects-(GATEs)"], [59, "Group-Average-Treatment-Effects-(GATEs)"]], "Group average treatment effects (GATEs)": [[77, "group-average-treatment-effects-gates"]], "Heterogeneous treatment effects": [[77, "heterogeneous-treatment-effects"]], "How to exploit more features of mlr3pipelines in DoubleML": [[46, "How-to-exploit-more-features-of-mlr3pipelines-in-DoubleML"]], "Hyperparameter tuning": [[78, "hyperparameter-tuning"], [78, "id16"]], "Hyperparameter tuning with pipelines": [[78, "hyperparameter-tuning-with-pipelines"]], "Implementation": [[95, "implementation"]], "Implementation Details": [[79, "implementation-details"]], "Implementation of the double machine learning algorithms": [[73, "implementation-of-the-double-machine-learning-algorithms"]], "Implementation of the score function and the estimate of the causal parameter": [[81, "implementation-of-the-score-function-and-the-estimate-of-the-causal-parameter"]], "Implemented Neyman orthogonal score functions": [[81, "implemented-neyman-orthogonal-score-functions"]], "Initialize DoubleMLClusterData object": [[44, "Initialize-DoubleMLClusterData-object"], [63, "Initialize-DoubleMLClusterData-object"]], "Initialize the objects of class DoubleMLPLIV": [[44, "Initialize-the-objects-of-class-DoubleMLPLIV"], [63, "Initialize-the-objects-of-class-DoubleMLPLIV"]], "Installing DoubleML": [[106, "installing-doubleml"]], "Instrumental Variables Directed Acyclic Graph (IV - DAG)": [[41, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"], [50, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"]], "Interactive IV Model (IIVM)": [[45, "Interactive-IV-Model-(IIVM)"], [64, "Interactive-IV-Model-(IIVM)"]], "Interactive IV model (IIVM)": [[79, "interactive-iv-model-iivm"], [81, "interactive-iv-model-iivm"]], "Interactive Regression Model (IRM)": [[45, "Interactive-Regression-Model-(IRM)"], [58, "Interactive-Regression-Model-(IRM)"], [64, "Interactive-Regression-Model-(IRM)"], [67, "Interactive-Regression-Model-(IRM)"]], "Interactive regression model (IRM)": [[95, "interactive-regression-model-irm"]], "Interactive regression models (IRM)": [[79, "interactive-regression-models-irm"], [81, "interactive-regression-models-irm"]], "Learners to estimate the nuisance models": [[107, "learners-to-estimate-the-nuisance-models"]], "Learners, hyperparameters and hyperparameter tuning": [[78, "learners-hyperparameters-and-hyperparameter-tuning"]], "Load Data": [[71, "Load-Data"]], "Load and Process Data": [[44, "Load-and-Process-Data"], [63, "Load-and-Process-Data"]], "Load bonus data using the dml datasets module": [[47, "Load-bonus-data-using-the-dml-datasets-module"]], "Local Average Treatment Effects of 401(k) Participation on Net Financial Assets": [[45, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"], [64, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"]], "Local Potential Quantile Estimation": [[68, "Local-Potential-Quantile-Estimation"]], "Local Potential Quantiles (LPQs)": [[68, "Local-Potential-Quantiles-(LPQs)"]], "Local Quantile Treatment Effects (LQTEs)": [[68, "Local-Quantile-Treatment-Effects-(LQTEs)"]], "Local potential quantiles (LPQs)": [[81, "local-potential-quantiles-lpqs"]], "Main Features": [[105, "main-features"]], "Minimum requirements for learners": [[78, "minimum-requirements-for-learners"], [78, "id2"]], "Missingness at Random": [[79, "missingness-at-random"], [81, "missingness-at-random"]], "Model-specific implementations": [[95, "model-specific-implementations"]], "Models": [[79, "models"]], "Motivation": [[44, "Motivation"], [63, "Motivation"]], "Multiple Average Potential Outcome Models (APOS)": [[49, "Multiple-Average-Potential-Outcome-Models-(APOS)"]], "Multiplier bootstrap and joint confidence intervals": [[104, "multiplier-bootstrap-and-joint-confidence-intervals"]], "Naive estimation": [[41, "Naive-estimation"], [50, "Naive-estimation"]], "No Clustering / Zero-Way Clustering": [[44, "No-Clustering-/-Zero-Way-Clustering"], [63, "No-Clustering-/-Zero-Way-Clustering"]], "Nonignorable Nonresponse": [[79, "nonignorable-nonresponse"], [81, "nonignorable-nonresponse"]], "One-Way Clustering with Respect to the Market": [[44, "One-Way-Clustering-with-Respect-to-the-Market"], [63, "One-Way-Clustering-with-Respect-to-the-Market"]], "One-Way Clustering with Respect to the Product": [[44, "One-Way-Clustering-with-Respect-to-the-Product"], [63, "One-Way-Clustering-with-Respect-to-the-Product"]], "One-dimensional Example": [[52, "One-dimensional-Example"], [53, "One-dimensional-Example"]], "Other models": [[0, "other-models"]], "Outcome missing at random (MAR)": [[72, "Outcome-missing-at-random-(MAR)"]], "Outcome missing under nonignorable nonresponse": [[72, "Outcome-missing-under-nonignorable-nonresponse"]], "Overcoming regularization bias by orthogonalization": [[42, "Overcoming-regularization-bias-by-orthogonalization"], [51, "Overcoming-regularization-bias-by-orthogonalization"], [74, "overcoming-regularization-bias-by-orthogonalization"]], "Panel Data": [[81, "panel-data"]], "Panel Data (Repeated Outcomes)": [[55, "Panel-Data-(Repeated-Outcomes)"]], "Panel data": [[79, "panel-data"]], "Parameter tuning": [[46, "Parameter-tuning"]], "Partialling out score": [[42, "Partialling-out-score"], [51, "Partialling-out-score"], [74, "partialling-out-score"]], "Partially Linear Regression Model (PLR)": [[45, "Partially-Linear-Regression-Model-(PLR)"], [59, "Partially-Linear-Regression-Model-(PLR)"], [64, "Partially-Linear-Regression-Model-(PLR)"]], "Partially linear IV regression model (PLIV)": [[79, "partially-linear-iv-regression-model-pliv"], [81, "partially-linear-iv-regression-model-pliv"]], "Partially linear models (PLM)": [[79, "partially-linear-models-plm"], [81, "partially-linear-models-plm"]], "Partially linear regression model (PLR)": [[79, "partially-linear-regression-model-plr"], [81, "partially-linear-regression-model-plr"], [95, "partially-linear-regression-model-plr"]], "Plot Coefficients and 95% Confidence Intervals": [[62, "Plot-Coefficients-and-95%-Confidence-Intervals"]], "Policy Learning with Trees": [[67, "Policy-Learning-with-Trees"], [77, "policy-learning-with-trees"]], "Potential Quantile Estimation": [[68, "Potential-Quantile-Estimation"]], "Potential Quantiles (PQs)": [[68, "Potential-Quantiles-(PQs)"]], "Potential quantiles (PQs)": [[77, "potential-quantiles-pqs"], [81, "potential-quantiles-pqs"]], "Python: Average Potential Outcome (APO) Models": [[49, "Python:-Average-Potential-Outcome-(APO)-Models"]], "Python: Basic Instrumental Variables calculation": [[50, "Python:-Basic-Instrumental-Variables-calculation"]], "Python: Basics of Double Machine Learning": [[51, "Python:-Basics-of-Double-Machine-Learning"]], "Python: Building the package from source": [[106, "python-building-the-package-from-source"]], "Python: Case studies": [[48, "python-case-studies"]], "Python: Choice of learners": [[61, "Python:-Choice-of-learners"]], "Python: Cluster Robust Double Machine Learning": [[63, "Python:-Cluster-Robust-Double-Machine-Learning"]], "Python: Conditional Average Treatment Effects (CATEs) for IRM models": [[52, "Python:-Conditional-Average-Treatment-Effects-(CATEs)-for-IRM-models"]], "Python: Conditional Average Treatment Effects (CATEs) for PLR models": [[53, "Python:-Conditional-Average-Treatment-Effects-(CATEs)-for-PLR-models"]], "Python: Conditional Value at Risk of potential outcomes": [[54, "Python:-Conditional-Value-at-Risk-of-potential-outcomes"]], "Python: Difference-in-Differences": [[55, "Python:-Difference-in-Differences"]], "Python: Difference-in-Differences Pre-Testing": [[56, "Python:-Difference-in-Differences-Pre-Testing"]], "Python: First Stage and Causal Estimation": [[57, "Python:-First-Stage-and-Causal-Estimation"]], "Python: GATE Sensitivity Analysis": [[60, "Python:-GATE-Sensitivity-Analysis"]], "Python: Group Average Treatment Effects (GATEs) for IRM models": [[58, "Python:-Group-Average-Treatment-Effects-(GATEs)-for-IRM-models"]], "Python: Group Average Treatment Effects (GATEs) for PLR models": [[59, "Python:-Group-Average-Treatment-Effects-(GATEs)-for-PLR-models"]], "Python: Impact of 401(k) on Financial Wealth": [[64, "Python:-Impact-of-401(k)-on-Financial-Wealth"]], "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)": [[65, "Python:-Impact-of-401(k)-on-Financial-Wealth-(Quantile-Effects)"]], "Python: Installing DoubleML": [[106, "python-installing-doubleml"]], "Python: Installing a released version from a .whl file": [[106, "python-installing-a-released-version-from-a-whl-file"]], "Python: Installing the latest release from pip or conda": [[106, "python-installing-the-latest-release-from-pip-or-conda"]], "Python: Learners and hyperparameters": [[78, "python-learners-and-hyperparameters"]], "Python: Optional Dependencies": [[106, "python-optional-dependencies"]], "Python: PLM and IRM for Multiple Treatments": [[66, "Python:-PLM-and-IRM-for-Multiple-Treatments"]], "Python: Policy Learning with Trees": [[67, "Python:-Policy-Learning-with-Trees"]], "Python: Potential Quantiles and Quantile Treatment Effects": [[68, "Python:-Potential-Quantiles-and-Quantile-Treatment-Effects"]], "Python: Sample Selection Models": [[72, "Python:-Sample-Selection-Models"]], "Python: Sensitivity Analysis": [[70, "Python:-Sensitivity-Analysis"]], "Quantile Treatment Effects (QTEs)": [[68, "Quantile-Treatment-Effects-(QTEs)"]], "Quantile treatment effects (QTEs)": [[77, "quantile-treatment-effects-qtes"]], "Quantiles": [[77, "quantiles"]], "R: Basic Instrumental Variables Calculation": [[41, "R:-Basic-Instrumental-Variables-Calculation"]], "R: Basics of Double Machine Learning": [[42, "R:-Basics-of-Double-Machine-Learning"]], "R: Case studies": [[48, "r-case-studies"]], "R: Cluster Robust Double Machine Learning": [[44, "R:-Cluster-Robust-Double-Machine-Learning"]], "R: DoubleML for Difference-in-Differences": [[43, "R:-DoubleML-for-Difference-in-Differences"]], "R: Ensemble Learners and More with mlr3pipelines": [[46, "R:-Ensemble-Learners-and-More-with-mlr3pipelines"]], "R: Impact of 401(k) on Financial Wealth": [[45, "R:-Impact-of-401(k)-on-Financial-Wealth"]], "R: Installing DoubleML": [[106, "r-installing-doubleml"]], "R: Installing the development version from GitHub": [[106, "r-installing-the-development-version-from-github"]], "R: Installing the latest release from CRAN": [[106, "r-installing-the-latest-release-from-cran"]], "R: Learners and hyperparameters": [[78, "r-learners-and-hyperparameters"]], "Ranking Treatment Effects under Treatment Propensity and Treatment Effect Heterogeneity": [[66, "Ranking-Treatment-Effects-under-Treatment-Propensity-and-Treatment-Effect-Heterogeneity"]], "Real-Data Application": [[44, "Real-Data-Application"], [63, "Real-Data-Application"]], "References": [[41, "References"], [43, "References"], [44, "References"], [46, "References"], [50, "References"], [57, "References"], [63, "References"], [66, "References"], [71, "References"], [74, "references"], [78, "references"], [80, "references"], [94, "references"], [104, "references"], [105, "references"], [107, "references"]], "Regression Discontinuity Designs (RDD)": [[79, "regression-discontinuity-designs-rdd"]], "Regularization Bias in Simple ML-Approaches": [[42, "Regularization-Bias-in-Simple-ML-Approaches"], [51, "Regularization-Bias-in-Simple-ML-Approaches"]], "Regularization bias in simple ML-approaches": [[74, "regularization-bias-in-simple-ml-approaches"]], "Release notes": [[109, "release-notes"]], "Repeated Cross-Sectional Data": [[55, "Repeated-Cross-Sectional-Data"], [81, "repeated-cross-sectional-data"]], "Repeated cross-fitting with K folds and M repetitions": [[80, "repeated-cross-fitting-with-k-folds-and-m-repetitions"]], "Repeated cross-sections": [[79, "repeated-cross-sections"]], "Sample Selection Models": [[81, "sample-selection-models"]], "Sample Selection Models (SSM)": [[79, "sample-selection-models-ssm"]], "Sample splitting to remove bias induced by overfitting": [[42, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [51, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [74, "sample-splitting-to-remove-bias-induced-by-overfitting"]], "Sample-splitting without cross-fitting": [[80, "sample-splitting-without-cross-fitting"]], "Sample-splitting, cross-fitting and repeated cross-fitting": [[80, "sample-splitting-cross-fitting-and-repeated-cross-fitting"]], "Sandbox": [[48, "sandbox"]], "Score functions": [[81, "score-functions"]], "Score mixin classes for double machine learning models": [[0, "score-mixin-classes-for-double-machine-learning-models"]], "Sensitivity Analysis": [[49, "Sensitivity-Analysis"], [70, "Sensitivity-Analysis"], [70, "id1"]], "Sensitivity Analysis with IRM": [[70, "Sensitivity-Analysis-with-IRM"]], "Sensitivity analysis": [[95, "sensitivity-analysis"]], "Set up learners based on mlr3pipelines": [[46, "Set-up-learners-based-on-mlr3pipelines"]], "Sharp RDD": [[69, "Sharp-RDD"]], "Sharp RDD Without Adjustment": [[69, "Sharp-RDD-Without-Adjustment"]], "Sharp RDD with Flexible Adjustment": [[69, "Sharp-RDD-with-Flexible-Adjustment"]], "Sharp RDD with Linear Adjustment": [[69, "Sharp-RDD-with-Linear-Adjustment"]], "Sharp Regression Discontinuity Design": [[79, "sharp-regression-discontinuity-design"]], "Simulate two-way cluster data": [[44, "Simulate-two-way-cluster-data"], [63, "Simulate-two-way-cluster-data"]], "Simulation Example": [[70, "Simulation-Example"]], "Simultaneous inference over different DoubleML models (advanced)": [[94, "simultaneous-inference-over-different-doubleml-models-advanced"]], "Single Average Potential Outcome Models (APO)": [[49, "Single-Average-Potential-Outcome-Models-(APO)"]], "Source code and maintenance": [[105, "source-code-and-maintenance"]], "Specify learner and estimate causal parameter: IRM model with Lasso as learner": [[47, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: IRM model with random forest as learner": [[47, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-random-forest-as-learner"]], "Specify learner and estimate causal parameter: PLR model with Lasso as learner": [[47, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: PLR model with random forest as learner": [[47, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-random-forest-as-learner"]], "Specifying alternative score functions via callables": [[81, "specifying-alternative-score-functions-via-callables"]], "Specifying learners and set hyperparameters": [[78, "specifying-learners-and-set-hyperparameters"], [78, "id9"]], "Standard approach": [[61, "Standard-approach"]], "Step 1: Custom API for FLAML Models within DoubleML": [[62, "Step-1:-Custom-API-for-FLAML-Models-within-DoubleML"]], "Step 1: Initialize and Train the AutoML Models:": [[62, "Step-1:-Initialize-and-Train-the-AutoML-Models:"]], "Step 2: Evaluate the Tuned Models": [[62, "Step-2:-Evaluate-the-Tuned-Models"]], "Step 2: Using the API when calling DoubleML\u2019s .fit() Method": [[62, "Step-2:-Using-the-API-when-calling-DoubleML's-.fit()-Method"]], "Step 3: Create and Fit DoubleML Model": [[62, "Step-3:-Create-and-Fit-DoubleML-Model"]], "Summary Figure": [[66, "Summary-Figure"]], "Summary of Results": [[45, "Summary-of-Results"], [64, "Summary-of-Results"]], "The Augmented Inverse Propensity Weighting Model estimates the ATE under arbitrary effect and propensity score heterogeneity": [[66, "The-Augmented-Inverse-Propensity-Weighting-Model-estimates-the-ATE-under-arbitrary-effect-and-propensity-score-heterogeneity"]], "The Data Backend: DoubleMLData": [[45, "The-Data-Backend:-DoubleMLData"], [64, "The-Data-Backend:-DoubleMLData"]], "The DoubleML package": [[45, "The-DoubleML-package"], [64, "The-DoubleML-package"]], "The Partially Linear Model performs overlap weighting": [[66, "The-Partially-Linear-Model-performs-overlap-weighting"]], "The basics of double/debiased machine learning": [[74, "the-basics-of-double-debiased-machine-learning"]], "The causal model": [[107, "the-causal-model"]], "The data-backend DoubleMLData": [[75, "the-data-backend-doublemldata"], [107, "the-data-backend-doublemldata"]], "Theory": [[95, "theory"]], "Tuning on the Folds": [[62, "Tuning-on-the-Folds"]], "Tuning on the full Sample": [[62, "Tuning-on-the-full-Sample"]], "Two-Dimensional Example": [[52, "Two-Dimensional-Example"], [53, "Two-Dimensional-Example"]], "Two-Way Clustering with Respect to Product and Market": [[44, "Two-Way-Clustering-with-Respect-to-Product-and-Market"], [63, "Two-Way-Clustering-with-Respect-to-Product-and-Market"]], "Untuned (default parameter) XGBoost": [[62, "Untuned-(default-parameter)-XGBoost"]], "Use ensemble learners based on mlr3pipelines": [[46, "Use-ensemble-learners-based-on-mlr3pipelines"]], "User guide": [[76, "user-guide"]], "Using DoubleML": [[41, "Using-DoubleML"], [50, "Using-DoubleML"]], "Using ML for DiD: Integrating DoubleML in did": [[43, "Using-ML-for-DiD:-Integrating-DoubleML-in-did"]], "Using learners from mlr3, mlr3learners and mlr3extralearners": [[46, "Using-learners-from-mlr3,-mlr3learners-and-mlr3extralearners"]], "Using pipelines to construct learners": [[78, "using-pipelines-to-construct-learners"]], "Utility classes": [[0, "utility-classes"]], "Utility classes and functions": [[0, "utility-classes-and-functions"]], "Utility functions": [[0, "utility-functions"]], "VanderWeele and Arah (2011): Benchmarking": [[71, "VanderWeele-and-Arah-(2011):-Benchmarking"]], "Variance estimation": [[94, "variance-estimation"]], "Variance estimation and confidence intervals": [[94, "variance-estimation-and-confidence-intervals"]], "Weighted Average Treatment Effects": [[77, "weighted-average-treatment-effects"]], "doubleml.DoubleMLAPO": [[1, "doubleml-doublemlapo"]], "doubleml.DoubleMLAPOS": [[2, "doubleml-doublemlapos"]], "doubleml.DoubleMLCVAR": [[3, "doubleml-doublemlcvar"]], "doubleml.DoubleMLClusterData": [[4, "doubleml-doublemlclusterdata"]], "doubleml.DoubleMLDID": [[5, "doubleml-doublemldid"]], "doubleml.DoubleMLDIDCS": [[6, "doubleml-doublemldidcs"]], "doubleml.DoubleMLData": [[7, "doubleml-doublemldata"]], "doubleml.DoubleMLIIVM": [[8, "doubleml-doublemliivm"]], "doubleml.DoubleMLIRM": [[9, "doubleml-doublemlirm"]], "doubleml.DoubleMLLPQ": [[10, "doubleml-doublemllpq"]], "doubleml.DoubleMLPLIV": [[11, "doubleml-doublemlpliv"]], "doubleml.DoubleMLPLR": [[12, "doubleml-doublemlplr"]], "doubleml.DoubleMLPQ": [[13, "doubleml-doublemlpq"]], "doubleml.DoubleMLQTE": [[14, "doubleml-doublemlqte"]], "doubleml.DoubleMLSSM": [[15, "doubleml-doublemlssm"]], "doubleml.datasets.fetch_401K": [[16, "doubleml-datasets-fetch-401k"]], "doubleml.datasets.fetch_bonus": [[17, "doubleml-datasets-fetch-bonus"]], "doubleml.datasets.make_confounded_irm_data": [[18, "doubleml-datasets-make-confounded-irm-data"]], "doubleml.datasets.make_confounded_plr_data": [[19, "doubleml-datasets-make-confounded-plr-data"]], "doubleml.datasets.make_did_SZ2020": [[20, "doubleml-datasets-make-did-sz2020"]], "doubleml.datasets.make_heterogeneous_data": [[21, "doubleml-datasets-make-heterogeneous-data"]], "doubleml.datasets.make_iivm_data": [[22, "doubleml-datasets-make-iivm-data"]], "doubleml.datasets.make_irm_data": [[23, "doubleml-datasets-make-irm-data"]], "doubleml.datasets.make_irm_data_discrete_treatments": [[24, "doubleml-datasets-make-irm-data-discrete-treatments"]], "doubleml.datasets.make_pliv_CHS2015": [[25, "doubleml-datasets-make-pliv-chs2015"]], "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021": [[26, "doubleml-datasets-make-pliv-multiway-cluster-ckms2021"]], "doubleml.datasets.make_plr_CCDDHNR2018": [[27, "doubleml-datasets-make-plr-ccddhnr2018"]], "doubleml.datasets.make_plr_turrell2018": [[28, "doubleml-datasets-make-plr-turrell2018"]], "doubleml.datasets.make_ssm_data": [[29, "doubleml-datasets-make-ssm-data"]], "doubleml.double_ml_score_mixins.LinearScoreMixin": [[30, "doubleml-double-ml-score-mixins-linearscoremixin"]], "doubleml.double_ml_score_mixins.NonLinearScoreMixin": [[31, "doubleml-double-ml-score-mixins-nonlinearscoremixin"]], "doubleml.rdd.RDFlex": [[32, "doubleml-rdd-rdflex"]], "doubleml.rdd.datasets.make_simple_rdd_data": [[33, "doubleml-rdd-datasets-make-simple-rdd-data"]], "doubleml.utils.DMLDummyClassifier": [[34, "doubleml-utils-dmldummyclassifier"]], "doubleml.utils.DMLDummyRegressor": [[35, "doubleml-utils-dmldummyregressor"]], "doubleml.utils.DoubleMLBLP": [[36, "doubleml-utils-doublemlblp"]], "doubleml.utils.DoubleMLPolicyTree": [[37, "doubleml-utils-doublemlpolicytree"]], "doubleml.utils.GlobalClassifier": [[38, "doubleml-utils-globalclassifier"]], "doubleml.utils.GlobalRegressor": [[39, "doubleml-utils-globalregressor"]], "doubleml.utils.gain_statistics": [[40, "doubleml-utils-gain-statistics"]]}, "docnames": ["api/api", "api/generated/doubleml.DoubleMLAPO", "api/generated/doubleml.DoubleMLAPOS", "api/generated/doubleml.DoubleMLCVAR", "api/generated/doubleml.DoubleMLClusterData", "api/generated/doubleml.DoubleMLDID", "api/generated/doubleml.DoubleMLDIDCS", "api/generated/doubleml.DoubleMLData", "api/generated/doubleml.DoubleMLIIVM", "api/generated/doubleml.DoubleMLIRM", "api/generated/doubleml.DoubleMLLPQ", "api/generated/doubleml.DoubleMLPLIV", "api/generated/doubleml.DoubleMLPLR", "api/generated/doubleml.DoubleMLPQ", "api/generated/doubleml.DoubleMLQTE", "api/generated/doubleml.DoubleMLSSM", "api/generated/doubleml.datasets.fetch_401K", "api/generated/doubleml.datasets.fetch_bonus", "api/generated/doubleml.datasets.make_confounded_irm_data", "api/generated/doubleml.datasets.make_confounded_plr_data", "api/generated/doubleml.datasets.make_did_SZ2020", "api/generated/doubleml.datasets.make_heterogeneous_data", "api/generated/doubleml.datasets.make_iivm_data", "api/generated/doubleml.datasets.make_irm_data", "api/generated/doubleml.datasets.make_irm_data_discrete_treatments", "api/generated/doubleml.datasets.make_pliv_CHS2015", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018", "api/generated/doubleml.datasets.make_plr_turrell2018", "api/generated/doubleml.datasets.make_ssm_data", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin", "api/generated/doubleml.rdd.RDFlex", "api/generated/doubleml.rdd.datasets.make_simple_rdd_data", "api/generated/doubleml.utils.DMLDummyClassifier", "api/generated/doubleml.utils.DMLDummyRegressor", "api/generated/doubleml.utils.DoubleMLBLP", "api/generated/doubleml.utils.DoubleMLPolicyTree", "api/generated/doubleml.utils.GlobalClassifier", "api/generated/doubleml.utils.GlobalRegressor", "api/generated/doubleml.utils.gain_statistics", "examples/R_double_ml_basic_iv", "examples/R_double_ml_basics", "examples/R_double_ml_did", "examples/R_double_ml_multiway_cluster", "examples/R_double_ml_pension", "examples/R_double_ml_pipeline", "examples/double_ml_bonus_data", "examples/index", "examples/py_double_ml_apo", "examples/py_double_ml_basic_iv", "examples/py_double_ml_basics", "examples/py_double_ml_cate", "examples/py_double_ml_cate_plr", "examples/py_double_ml_cvar", "examples/py_double_ml_did", "examples/py_double_ml_did_pretest", "examples/py_double_ml_firststage", "examples/py_double_ml_gate", "examples/py_double_ml_gate_plr", "examples/py_double_ml_gate_sensitivity", "examples/py_double_ml_learner", "examples/py_double_ml_meets_flaml", "examples/py_double_ml_multiway_cluster", "examples/py_double_ml_pension", "examples/py_double_ml_pension_qte", "examples/py_double_ml_plm_irm_hetfx", "examples/py_double_ml_policy_tree", "examples/py_double_ml_pq", "examples/py_double_ml_rdflex", "examples/py_double_ml_sensitivity", "examples/py_double_ml_sensitivity_booking", "examples/py_double_ml_ssm", "guide/algorithms", "guide/basics", "guide/data_backend", "guide/guide", "guide/heterogeneity", "guide/learners", "guide/models", "guide/resampling", "guide/scores", "guide/scores/apo_score", "guide/scores/cvar_score", "guide/scores/did_score", "guide/scores/didcs_score", "guide/scores/iivm_score", "guide/scores/irm_score", "guide/scores/lpq_score", "guide/scores/mar_score", "guide/scores/nr_score", "guide/scores/pliv_score", "guide/scores/plr_score", "guide/scores/pq_score", "guide/se_confint", "guide/sensitivity", "guide/sensitivity/apo_sensitivity", "guide/sensitivity/benchmarking", "guide/sensitivity/did_cs_sensitivity", "guide/sensitivity/did_sensitivity", "guide/sensitivity/implementation", "guide/sensitivity/irm_sensitivity", "guide/sensitivity/plr_sensitivity", "guide/sensitivity/theory", "guide/sim_inf", "index", "intro/install", "intro/intro", "literature/literature", "release/release", "workflow/workflow"], "envversion": {"nbsphinx": 4, "sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["api/api.rst", "api/generated/doubleml.DoubleMLAPO.rst", "api/generated/doubleml.DoubleMLAPOS.rst", "api/generated/doubleml.DoubleMLCVAR.rst", "api/generated/doubleml.DoubleMLClusterData.rst", "api/generated/doubleml.DoubleMLDID.rst", "api/generated/doubleml.DoubleMLDIDCS.rst", "api/generated/doubleml.DoubleMLData.rst", "api/generated/doubleml.DoubleMLIIVM.rst", "api/generated/doubleml.DoubleMLIRM.rst", "api/generated/doubleml.DoubleMLLPQ.rst", "api/generated/doubleml.DoubleMLPLIV.rst", "api/generated/doubleml.DoubleMLPLR.rst", "api/generated/doubleml.DoubleMLPQ.rst", "api/generated/doubleml.DoubleMLQTE.rst", "api/generated/doubleml.DoubleMLSSM.rst", "api/generated/doubleml.datasets.fetch_401K.rst", "api/generated/doubleml.datasets.fetch_bonus.rst", "api/generated/doubleml.datasets.make_confounded_irm_data.rst", "api/generated/doubleml.datasets.make_confounded_plr_data.rst", "api/generated/doubleml.datasets.make_did_SZ2020.rst", "api/generated/doubleml.datasets.make_heterogeneous_data.rst", "api/generated/doubleml.datasets.make_iivm_data.rst", "api/generated/doubleml.datasets.make_irm_data.rst", "api/generated/doubleml.datasets.make_irm_data_discrete_treatments.rst", "api/generated/doubleml.datasets.make_pliv_CHS2015.rst", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021.rst", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018.rst", "api/generated/doubleml.datasets.make_plr_turrell2018.rst", "api/generated/doubleml.datasets.make_ssm_data.rst", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin.rst", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin.rst", "api/generated/doubleml.rdd.RDFlex.rst", "api/generated/doubleml.rdd.datasets.make_simple_rdd_data.rst", "api/generated/doubleml.utils.DMLDummyClassifier.rst", "api/generated/doubleml.utils.DMLDummyRegressor.rst", "api/generated/doubleml.utils.DoubleMLBLP.rst", "api/generated/doubleml.utils.DoubleMLPolicyTree.rst", "api/generated/doubleml.utils.GlobalClassifier.rst", "api/generated/doubleml.utils.GlobalRegressor.rst", "api/generated/doubleml.utils.gain_statistics.rst", "examples/R_double_ml_basic_iv.ipynb", "examples/R_double_ml_basics.ipynb", "examples/R_double_ml_did.ipynb", "examples/R_double_ml_multiway_cluster.ipynb", "examples/R_double_ml_pension.ipynb", "examples/R_double_ml_pipeline.ipynb", "examples/double_ml_bonus_data.ipynb", "examples/index.rst", "examples/py_double_ml_apo.ipynb", "examples/py_double_ml_basic_iv.ipynb", "examples/py_double_ml_basics.ipynb", "examples/py_double_ml_cate.ipynb", "examples/py_double_ml_cate_plr.ipynb", "examples/py_double_ml_cvar.ipynb", "examples/py_double_ml_did.ipynb", "examples/py_double_ml_did_pretest.ipynb", "examples/py_double_ml_firststage.ipynb", "examples/py_double_ml_gate.ipynb", "examples/py_double_ml_gate_plr.ipynb", "examples/py_double_ml_gate_sensitivity.ipynb", "examples/py_double_ml_learner.ipynb", "examples/py_double_ml_meets_flaml.ipynb", "examples/py_double_ml_multiway_cluster.ipynb", "examples/py_double_ml_pension.ipynb", "examples/py_double_ml_pension_qte.ipynb", "examples/py_double_ml_plm_irm_hetfx.ipynb", "examples/py_double_ml_policy_tree.ipynb", "examples/py_double_ml_pq.ipynb", "examples/py_double_ml_rdflex.ipynb", "examples/py_double_ml_sensitivity.ipynb", "examples/py_double_ml_sensitivity_booking.ipynb", "examples/py_double_ml_ssm.ipynb", "guide/algorithms.rst", "guide/basics.rst", "guide/data_backend.rst", "guide/guide.rst", "guide/heterogeneity.rst", "guide/learners.rst", "guide/models.rst", "guide/resampling.rst", "guide/scores.rst", "guide/scores/apo_score.rst", "guide/scores/cvar_score.rst", "guide/scores/did_score.rst", "guide/scores/didcs_score.rst", "guide/scores/iivm_score.rst", "guide/scores/irm_score.rst", "guide/scores/lpq_score.rst", "guide/scores/mar_score.rst", "guide/scores/nr_score.rst", "guide/scores/pliv_score.rst", "guide/scores/plr_score.rst", "guide/scores/pq_score.rst", "guide/se_confint.rst", "guide/sensitivity.rst", "guide/sensitivity/apo_sensitivity.rst", "guide/sensitivity/benchmarking.rst", "guide/sensitivity/did_cs_sensitivity.rst", "guide/sensitivity/did_sensitivity.rst", "guide/sensitivity/implementation.rst", "guide/sensitivity/irm_sensitivity.rst", "guide/sensitivity/plr_sensitivity.rst", "guide/sensitivity/theory.rst", "guide/sim_inf.rst", "index.rst", "intro/install.rst", "intro/intro.rst", "literature/literature.rst", "release/release.rst", "workflow/workflow.rst"], "indexentries": {"aggregate_over_splits() (doubleml.rdd.rdflex method)": [[32, "doubleml.rdd.RDFlex.aggregate_over_splits", false]], "bootstrap() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.bootstrap", false]], "bootstrap() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.bootstrap", false]], "bootstrap() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.bootstrap", false]], "bootstrap() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.bootstrap", false]], "bootstrap() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.bootstrap", false]], "bootstrap() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.bootstrap", false]], "bootstrap() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.bootstrap", false]], "bootstrap() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.bootstrap", false]], "bootstrap() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.bootstrap", false]], "bootstrap() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.bootstrap", false]], "bootstrap() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.bootstrap", false]], "bootstrap() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.bootstrap", false]], "bootstrap() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.bootstrap", false]], "capo() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.capo", false]], "cate() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.cate", false]], "cate() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.cate", false]], "causal_contrast() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.causal_contrast", false]], "confint() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.confint", false]], "confint() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.confint", false]], "confint() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.confint", false]], "confint() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.confint", false]], "confint() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.confint", false]], "confint() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.confint", false]], "confint() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.confint", false]], "confint() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.confint", false]], "confint() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.confint", false]], "confint() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.confint", false]], "confint() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.confint", false]], "confint() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.confint", false]], "confint() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.confint", false]], "confint() (doubleml.rdd.rdflex method)": [[32, "doubleml.rdd.RDFlex.confint", false]], "confint() (doubleml.utils.doublemlblp method)": [[36, "doubleml.utils.DoubleMLBLP.confint", false]], "construct_framework() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.construct_framework", false]], "construct_framework() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.construct_framework", false]], "construct_framework() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.construct_framework", false]], "construct_framework() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.construct_framework", false]], "construct_framework() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.construct_framework", false]], "construct_framework() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.construct_framework", false]], "construct_framework() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.construct_framework", false]], "construct_framework() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.construct_framework", false]], "construct_framework() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.construct_framework", false]], "construct_framework() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.construct_framework", false]], "construct_framework() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.construct_framework", false]], "dmldummyclassifier (class in doubleml.utils)": [[34, "doubleml.utils.DMLDummyClassifier", false]], "dmldummyregressor (class in doubleml.utils)": [[35, "doubleml.utils.DMLDummyRegressor", false]], "doublemlapo (class in doubleml)": [[1, "doubleml.DoubleMLAPO", false]], "doublemlapos (class in doubleml)": [[2, "doubleml.DoubleMLAPOS", false]], "doublemlblp (class in doubleml.utils)": [[36, "doubleml.utils.DoubleMLBLP", false]], "doublemlclusterdata (class in doubleml)": [[4, "doubleml.DoubleMLClusterData", false]], "doublemlcvar (class in doubleml)": [[3, "doubleml.DoubleMLCVAR", false]], "doublemldata (class in doubleml)": [[7, "doubleml.DoubleMLData", false]], "doublemldid (class in doubleml)": [[5, "doubleml.DoubleMLDID", false]], "doublemldidcs (class in doubleml)": [[6, "doubleml.DoubleMLDIDCS", false]], "doublemliivm (class in doubleml)": [[8, "doubleml.DoubleMLIIVM", false]], "doublemlirm (class in doubleml)": [[9, "doubleml.DoubleMLIRM", false]], "doublemllpq (class in doubleml)": [[10, "doubleml.DoubleMLLPQ", false]], "doublemlpliv (class in doubleml)": [[11, "doubleml.DoubleMLPLIV", false]], "doublemlplr (class in doubleml)": [[12, "doubleml.DoubleMLPLR", false]], "doublemlpolicytree (class in doubleml.utils)": [[37, "doubleml.utils.DoubleMLPolicyTree", false]], "doublemlpq (class in doubleml)": [[13, "doubleml.DoubleMLPQ", false]], "doublemlqte (class in doubleml)": [[14, "doubleml.DoubleMLQTE", false]], "doublemlssm (class in doubleml)": [[15, "doubleml.DoubleMLSSM", false]], "draw_sample_splitting() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.draw_sample_splitting", false]], "evaluate_learners() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.evaluate_learners", false]], "fetch_401k() (in module doubleml.datasets)": [[16, "doubleml.datasets.fetch_401K", false]], "fetch_bonus() (in module doubleml.datasets)": [[17, "doubleml.datasets.fetch_bonus", false]], "fit() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.fit", false]], "fit() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.fit", false]], "fit() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.fit", false]], "fit() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.fit", false]], "fit() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.fit", false]], "fit() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.fit", false]], "fit() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.fit", false]], "fit() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.fit", false]], "fit() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.fit", false]], "fit() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.fit", false]], "fit() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.fit", false]], "fit() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.fit", false]], "fit() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.fit", false]], "fit() (doubleml.rdd.rdflex method)": [[32, "doubleml.rdd.RDFlex.fit", false]], "fit() (doubleml.utils.dmldummyclassifier method)": [[34, "doubleml.utils.DMLDummyClassifier.fit", false]], "fit() (doubleml.utils.dmldummyregressor method)": [[35, "doubleml.utils.DMLDummyRegressor.fit", false]], "fit() (doubleml.utils.doublemlblp method)": [[36, "doubleml.utils.DoubleMLBLP.fit", false]], "fit() (doubleml.utils.doublemlpolicytree method)": [[37, "doubleml.utils.DoubleMLPolicyTree.fit", false]], "fit() (doubleml.utils.globalclassifier method)": [[38, "doubleml.utils.GlobalClassifier.fit", false]], "fit() (doubleml.utils.globalregressor method)": [[39, "doubleml.utils.GlobalRegressor.fit", false]], "from_arrays() (doubleml.doublemlclusterdata class method)": [[4, "doubleml.DoubleMLClusterData.from_arrays", false]], "from_arrays() (doubleml.doublemldata class method)": [[7, "doubleml.DoubleMLData.from_arrays", false]], "gain_statistics() (in module doubleml.utils)": [[40, "doubleml.utils.gain_statistics", false]], "gapo() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.gapo", false]], "gate() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.gate", false]], "gate() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.gate", false]], "get_metadata_routing() (doubleml.utils.dmldummyclassifier method)": [[34, "doubleml.utils.DMLDummyClassifier.get_metadata_routing", false]], "get_metadata_routing() (doubleml.utils.dmldummyregressor method)": [[35, "doubleml.utils.DMLDummyRegressor.get_metadata_routing", false]], "get_metadata_routing() (doubleml.utils.globalclassifier method)": [[38, "doubleml.utils.GlobalClassifier.get_metadata_routing", false]], "get_metadata_routing() (doubleml.utils.globalregressor method)": [[39, "doubleml.utils.GlobalRegressor.get_metadata_routing", false]], "get_params() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.get_params", false]], "get_params() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.get_params", false]], "get_params() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.get_params", false]], "get_params() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.get_params", false]], "get_params() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.get_params", false]], "get_params() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.get_params", false]], "get_params() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.get_params", false]], "get_params() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.get_params", false]], "get_params() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.get_params", false]], "get_params() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.get_params", false]], "get_params() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.get_params", false]], "get_params() (doubleml.utils.dmldummyclassifier method)": [[34, "doubleml.utils.DMLDummyClassifier.get_params", false]], "get_params() (doubleml.utils.dmldummyregressor method)": [[35, "doubleml.utils.DMLDummyRegressor.get_params", false]], "get_params() (doubleml.utils.globalclassifier method)": [[38, "doubleml.utils.GlobalClassifier.get_params", false]], "get_params() (doubleml.utils.globalregressor method)": [[39, "doubleml.utils.GlobalRegressor.get_params", false]], "globalclassifier (class in doubleml.utils)": [[38, "doubleml.utils.GlobalClassifier", false]], "globalregressor (class in doubleml.utils)": [[39, "doubleml.utils.GlobalRegressor", false]], "linearscoremixin (class in doubleml.double_ml_score_mixins)": [[30, "doubleml.double_ml_score_mixins.LinearScoreMixin", false]], "make_confounded_irm_data() (in module doubleml.datasets)": [[18, "doubleml.datasets.make_confounded_irm_data", false]], "make_confounded_plr_data() (in module doubleml.datasets)": [[19, "doubleml.datasets.make_confounded_plr_data", false]], "make_did_sz2020() (in module doubleml.datasets)": [[20, "doubleml.datasets.make_did_SZ2020", false]], "make_heterogeneous_data() (in module doubleml.datasets)": [[21, "doubleml.datasets.make_heterogeneous_data", false]], "make_iivm_data() (in module doubleml.datasets)": [[22, "doubleml.datasets.make_iivm_data", false]], "make_irm_data() (in module doubleml.datasets)": [[23, "doubleml.datasets.make_irm_data", false]], "make_irm_data_discrete_treatments() (in module doubleml.datasets)": [[24, "doubleml.datasets.make_irm_data_discrete_treatments", false]], "make_pliv_chs2015() (in module doubleml.datasets)": [[25, "doubleml.datasets.make_pliv_CHS2015", false]], "make_pliv_multiway_cluster_ckms2021() (in module doubleml.datasets)": [[26, "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", false]], "make_plr_ccddhnr2018() (in module doubleml.datasets)": [[27, "doubleml.datasets.make_plr_CCDDHNR2018", false]], "make_plr_turrell2018() (in module doubleml.datasets)": [[28, "doubleml.datasets.make_plr_turrell2018", false]], "make_simple_rdd_data() (in module doubleml.rdd.datasets)": [[33, "doubleml.rdd.datasets.make_simple_rdd_data", false]], "make_ssm_data() (in module doubleml.datasets)": [[29, "doubleml.datasets.make_ssm_data", false]], "nonlinearscoremixin (class in doubleml.double_ml_score_mixins)": [[31, "doubleml.double_ml_score_mixins.NonLinearScoreMixin", false]], "p_adjust() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.p_adjust", false]], "p_adjust() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.p_adjust", false]], "p_adjust() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.p_adjust", false]], "p_adjust() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.p_adjust", false]], "p_adjust() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.p_adjust", false]], "p_adjust() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.p_adjust", false]], "p_adjust() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.p_adjust", false]], "p_adjust() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.p_adjust", false]], "p_adjust() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.p_adjust", false]], "p_adjust() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.p_adjust", false]], "p_adjust() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.p_adjust", false]], "p_adjust() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.p_adjust", false]], "plot_tree() (doubleml.utils.doublemlpolicytree method)": [[37, "doubleml.utils.DoubleMLPolicyTree.plot_tree", false]], "policy_tree() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.policy_tree", false]], "predict() (doubleml.utils.dmldummyclassifier method)": [[34, "doubleml.utils.DMLDummyClassifier.predict", false]], "predict() (doubleml.utils.dmldummyregressor method)": [[35, "doubleml.utils.DMLDummyRegressor.predict", false]], "predict() (doubleml.utils.doublemlpolicytree method)": [[37, "doubleml.utils.DoubleMLPolicyTree.predict", false]], "predict() (doubleml.utils.globalclassifier method)": [[38, "doubleml.utils.GlobalClassifier.predict", false]], "predict() (doubleml.utils.globalregressor method)": [[39, "doubleml.utils.GlobalRegressor.predict", false]], "predict_proba() (doubleml.utils.dmldummyclassifier method)": [[34, "doubleml.utils.DMLDummyClassifier.predict_proba", false]], "predict_proba() (doubleml.utils.globalclassifier method)": [[38, "doubleml.utils.GlobalClassifier.predict_proba", false]], "rdflex (class in doubleml.rdd)": [[32, "doubleml.rdd.RDFlex", false]], "score() (doubleml.utils.globalclassifier method)": [[38, "doubleml.utils.GlobalClassifier.score", false]], "score() (doubleml.utils.globalregressor method)": [[39, "doubleml.utils.GlobalRegressor.score", false]], "sensitivity_analysis() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.sensitivity_analysis", false]], "sensitivity_benchmark() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.sensitivity_benchmark", false]], "sensitivity_plot() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.sensitivity_plot", false]], "set_fit_request() (doubleml.utils.globalclassifier method)": [[38, "doubleml.utils.GlobalClassifier.set_fit_request", false]], "set_fit_request() (doubleml.utils.globalregressor method)": [[39, "doubleml.utils.GlobalRegressor.set_fit_request", false]], "set_ml_nuisance_params() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.set_ml_nuisance_params", false]], "set_params() (doubleml.utils.dmldummyclassifier method)": [[34, "doubleml.utils.DMLDummyClassifier.set_params", false]], "set_params() (doubleml.utils.dmldummyregressor method)": [[35, "doubleml.utils.DMLDummyRegressor.set_params", false]], "set_params() (doubleml.utils.globalclassifier method)": [[38, "doubleml.utils.GlobalClassifier.set_params", false]], "set_params() (doubleml.utils.globalregressor method)": [[39, "doubleml.utils.GlobalRegressor.set_params", false]], "set_sample_splitting() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlapos method)": [[2, "doubleml.DoubleMLAPOS.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlqte method)": [[14, "doubleml.DoubleMLQTE.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.set_sample_splitting", false]], "set_score_request() (doubleml.utils.globalclassifier method)": [[38, "doubleml.utils.GlobalClassifier.set_score_request", false]], "set_score_request() (doubleml.utils.globalregressor method)": [[39, "doubleml.utils.GlobalRegressor.set_score_request", false]], "set_x_d() (doubleml.doublemlclusterdata method)": [[4, "doubleml.DoubleMLClusterData.set_x_d", false]], "set_x_d() (doubleml.doublemldata method)": [[7, "doubleml.DoubleMLData.set_x_d", false]], "tune() (doubleml.doublemlapo method)": [[1, "doubleml.DoubleMLAPO.tune", false]], "tune() (doubleml.doublemlcvar method)": [[3, "doubleml.DoubleMLCVAR.tune", false]], "tune() (doubleml.doublemldid method)": [[5, "doubleml.DoubleMLDID.tune", false]], "tune() (doubleml.doublemldidcs method)": [[6, "doubleml.DoubleMLDIDCS.tune", false]], "tune() (doubleml.doublemliivm method)": [[8, "doubleml.DoubleMLIIVM.tune", false]], "tune() (doubleml.doublemlirm method)": [[9, "doubleml.DoubleMLIRM.tune", false]], "tune() (doubleml.doublemllpq method)": [[10, "doubleml.DoubleMLLPQ.tune", false]], "tune() (doubleml.doublemlpliv method)": [[11, "doubleml.DoubleMLPLIV.tune", false]], "tune() (doubleml.doublemlplr method)": [[12, "doubleml.DoubleMLPLR.tune", false]], "tune() (doubleml.doublemlpq method)": [[13, "doubleml.DoubleMLPQ.tune", false]], "tune() (doubleml.doublemlssm method)": [[15, "doubleml.DoubleMLSSM.tune", false]]}, "objects": {"doubleml": [[1, 0, 1, "", "DoubleMLAPO"], [2, 0, 1, "", "DoubleMLAPOS"], [3, 0, 1, "", "DoubleMLCVAR"], [4, 0, 1, "", "DoubleMLClusterData"], [5, 0, 1, "", "DoubleMLDID"], [6, 0, 1, "", "DoubleMLDIDCS"], [7, 0, 1, "", "DoubleMLData"], [8, 0, 1, "", "DoubleMLIIVM"], [9, 0, 1, "", "DoubleMLIRM"], [10, 0, 1, "", "DoubleMLLPQ"], [11, 0, 1, "", "DoubleMLPLIV"], [12, 0, 1, "", "DoubleMLPLR"], [13, 0, 1, "", "DoubleMLPQ"], [14, 0, 1, "", "DoubleMLQTE"], [15, 0, 1, "", "DoubleMLSSM"]], "doubleml.DoubleMLAPO": [[1, 1, 1, "", "bootstrap"], [1, 1, 1, "", "capo"], [1, 1, 1, "", "confint"], [1, 1, 1, "", "construct_framework"], [1, 1, 1, "", "draw_sample_splitting"], [1, 1, 1, "", "evaluate_learners"], [1, 1, 1, "", "fit"], [1, 1, 1, "", "gapo"], [1, 1, 1, "", "get_params"], [1, 1, 1, "", "p_adjust"], [1, 1, 1, "", "sensitivity_analysis"], [1, 1, 1, "", "sensitivity_benchmark"], [1, 1, 1, "", "sensitivity_plot"], [1, 1, 1, "", "set_ml_nuisance_params"], [1, 1, 1, "", "set_sample_splitting"], [1, 1, 1, "", "tune"]], "doubleml.DoubleMLAPOS": [[2, 1, 1, "", "bootstrap"], [2, 1, 1, "", "causal_contrast"], [2, 1, 1, "", "confint"], [2, 1, 1, "", "draw_sample_splitting"], [2, 1, 1, "", "fit"], [2, 1, 1, "", "sensitivity_analysis"], [2, 1, 1, "", "sensitivity_benchmark"], [2, 1, 1, "", "sensitivity_plot"], [2, 1, 1, "", "set_sample_splitting"]], "doubleml.DoubleMLCVAR": [[3, 1, 1, "", "bootstrap"], [3, 1, 1, "", "confint"], [3, 1, 1, "", "construct_framework"], [3, 1, 1, "", "draw_sample_splitting"], [3, 1, 1, "", "evaluate_learners"], [3, 1, 1, "", "fit"], [3, 1, 1, "", "get_params"], [3, 1, 1, "", "p_adjust"], [3, 1, 1, "", "sensitivity_analysis"], [3, 1, 1, "", "sensitivity_benchmark"], [3, 1, 1, "", "sensitivity_plot"], [3, 1, 1, "", "set_ml_nuisance_params"], [3, 1, 1, "", "set_sample_splitting"], [3, 1, 1, "", "tune"]], "doubleml.DoubleMLClusterData": [[4, 1, 1, "", "from_arrays"], [4, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLDID": [[5, 1, 1, "", "bootstrap"], [5, 1, 1, "", "confint"], [5, 1, 1, "", "construct_framework"], [5, 1, 1, "", "draw_sample_splitting"], [5, 1, 1, "", "evaluate_learners"], [5, 1, 1, "", "fit"], [5, 1, 1, "", "get_params"], [5, 1, 1, "", "p_adjust"], [5, 1, 1, "", "sensitivity_analysis"], [5, 1, 1, "", "sensitivity_benchmark"], [5, 1, 1, "", "sensitivity_plot"], [5, 1, 1, "", "set_ml_nuisance_params"], [5, 1, 1, "", "set_sample_splitting"], [5, 1, 1, "", "tune"]], "doubleml.DoubleMLDIDCS": [[6, 1, 1, "", "bootstrap"], [6, 1, 1, "", "confint"], [6, 1, 1, "", "construct_framework"], [6, 1, 1, "", "draw_sample_splitting"], [6, 1, 1, "", "evaluate_learners"], [6, 1, 1, "", "fit"], [6, 1, 1, "", "get_params"], [6, 1, 1, "", "p_adjust"], [6, 1, 1, "", "sensitivity_analysis"], [6, 1, 1, "", "sensitivity_benchmark"], [6, 1, 1, "", "sensitivity_plot"], [6, 1, 1, "", "set_ml_nuisance_params"], [6, 1, 1, "", "set_sample_splitting"], [6, 1, 1, "", "tune"]], "doubleml.DoubleMLData": [[7, 1, 1, "", "from_arrays"], [7, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLIIVM": [[8, 1, 1, "", "bootstrap"], [8, 1, 1, "", "confint"], [8, 1, 1, "", "construct_framework"], [8, 1, 1, "", "draw_sample_splitting"], [8, 1, 1, "", "evaluate_learners"], [8, 1, 1, "", "fit"], [8, 1, 1, "", "get_params"], [8, 1, 1, "", "p_adjust"], [8, 1, 1, "", "sensitivity_analysis"], [8, 1, 1, "", "sensitivity_benchmark"], [8, 1, 1, "", "sensitivity_plot"], [8, 1, 1, "", "set_ml_nuisance_params"], [8, 1, 1, "", "set_sample_splitting"], [8, 1, 1, "", "tune"]], "doubleml.DoubleMLIRM": [[9, 1, 1, "", "bootstrap"], [9, 1, 1, "", "cate"], [9, 1, 1, "", "confint"], [9, 1, 1, "", "construct_framework"], [9, 1, 1, "", "draw_sample_splitting"], [9, 1, 1, "", "evaluate_learners"], [9, 1, 1, "", "fit"], [9, 1, 1, "", "gate"], [9, 1, 1, "", "get_params"], [9, 1, 1, "", "p_adjust"], [9, 1, 1, "", "policy_tree"], [9, 1, 1, "", "sensitivity_analysis"], [9, 1, 1, "", "sensitivity_benchmark"], [9, 1, 1, "", "sensitivity_plot"], [9, 1, 1, "", "set_ml_nuisance_params"], [9, 1, 1, "", "set_sample_splitting"], [9, 1, 1, "", "tune"]], "doubleml.DoubleMLLPQ": [[10, 1, 1, "", "bootstrap"], [10, 1, 1, "", "confint"], [10, 1, 1, "", "construct_framework"], [10, 1, 1, "", "draw_sample_splitting"], [10, 1, 1, "", "evaluate_learners"], [10, 1, 1, "", "fit"], [10, 1, 1, "", "get_params"], [10, 1, 1, "", "p_adjust"], [10, 1, 1, "", "sensitivity_analysis"], [10, 1, 1, "", "sensitivity_benchmark"], [10, 1, 1, "", "sensitivity_plot"], [10, 1, 1, "", "set_ml_nuisance_params"], [10, 1, 1, "", "set_sample_splitting"], [10, 1, 1, "", "tune"]], "doubleml.DoubleMLPLIV": [[11, 1, 1, "", "bootstrap"], [11, 1, 1, "", "confint"], [11, 1, 1, "", "construct_framework"], [11, 1, 1, "", "draw_sample_splitting"], [11, 1, 1, "", "evaluate_learners"], [11, 1, 1, "", "fit"], [11, 1, 1, "", "get_params"], [11, 1, 1, "", "p_adjust"], [11, 1, 1, "", "sensitivity_analysis"], [11, 1, 1, "", "sensitivity_benchmark"], [11, 1, 1, "", "sensitivity_plot"], [11, 1, 1, "", "set_ml_nuisance_params"], [11, 1, 1, "", "set_sample_splitting"], [11, 1, 1, "", "tune"]], "doubleml.DoubleMLPLR": [[12, 1, 1, "", "bootstrap"], [12, 1, 1, "", "cate"], [12, 1, 1, "", "confint"], [12, 1, 1, "", "construct_framework"], [12, 1, 1, "", "draw_sample_splitting"], [12, 1, 1, "", "evaluate_learners"], [12, 1, 1, "", "fit"], [12, 1, 1, "", "gate"], [12, 1, 1, "", "get_params"], [12, 1, 1, "", "p_adjust"], [12, 1, 1, "", "sensitivity_analysis"], [12, 1, 1, "", "sensitivity_benchmark"], [12, 1, 1, "", "sensitivity_plot"], [12, 1, 1, "", "set_ml_nuisance_params"], [12, 1, 1, "", "set_sample_splitting"], [12, 1, 1, "", "tune"]], "doubleml.DoubleMLPQ": [[13, 1, 1, "", "bootstrap"], [13, 1, 1, "", "confint"], [13, 1, 1, "", "construct_framework"], [13, 1, 1, "", "draw_sample_splitting"], [13, 1, 1, "", "evaluate_learners"], [13, 1, 1, "", "fit"], [13, 1, 1, "", "get_params"], [13, 1, 1, "", "p_adjust"], [13, 1, 1, "", "sensitivity_analysis"], [13, 1, 1, "", "sensitivity_benchmark"], [13, 1, 1, "", "sensitivity_plot"], [13, 1, 1, "", "set_ml_nuisance_params"], [13, 1, 1, "", "set_sample_splitting"], [13, 1, 1, "", "tune"]], "doubleml.DoubleMLQTE": [[14, 1, 1, "", "bootstrap"], [14, 1, 1, "", "confint"], [14, 1, 1, "", "draw_sample_splitting"], [14, 1, 1, "", "fit"], [14, 1, 1, "", "p_adjust"], [14, 1, 1, "", "set_sample_splitting"]], "doubleml.DoubleMLSSM": [[15, 1, 1, "", "bootstrap"], [15, 1, 1, "", "confint"], [15, 1, 1, "", "construct_framework"], [15, 1, 1, "", "draw_sample_splitting"], [15, 1, 1, "", "evaluate_learners"], [15, 1, 1, "", "fit"], [15, 1, 1, "", "get_params"], [15, 1, 1, "", "p_adjust"], [15, 1, 1, "", "sensitivity_analysis"], [15, 1, 1, "", "sensitivity_benchmark"], [15, 1, 1, "", "sensitivity_plot"], [15, 1, 1, "", "set_ml_nuisance_params"], [15, 1, 1, "", "set_sample_splitting"], [15, 1, 1, "", "tune"]], "doubleml.datasets": [[16, 2, 1, "", "fetch_401K"], [17, 2, 1, "", "fetch_bonus"], [18, 2, 1, "", "make_confounded_irm_data"], [19, 2, 1, "", "make_confounded_plr_data"], [20, 2, 1, "", "make_did_SZ2020"], [21, 2, 1, "", "make_heterogeneous_data"], [22, 2, 1, "", "make_iivm_data"], [23, 2, 1, "", "make_irm_data"], [24, 2, 1, "", "make_irm_data_discrete_treatments"], [25, 2, 1, "", "make_pliv_CHS2015"], [26, 2, 1, "", "make_pliv_multiway_cluster_CKMS2021"], [27, 2, 1, "", "make_plr_CCDDHNR2018"], [28, 2, 1, "", "make_plr_turrell2018"], [29, 2, 1, "", "make_ssm_data"]], "doubleml.double_ml_score_mixins": [[30, 0, 1, "", "LinearScoreMixin"], [31, 0, 1, "", "NonLinearScoreMixin"]], "doubleml.rdd": [[32, 0, 1, "", "RDFlex"]], "doubleml.rdd.RDFlex": [[32, 1, 1, "", "aggregate_over_splits"], [32, 1, 1, "", "confint"], [32, 1, 1, "", "fit"]], "doubleml.rdd.datasets": [[33, 2, 1, "", "make_simple_rdd_data"]], "doubleml.utils": [[34, 0, 1, "", "DMLDummyClassifier"], [35, 0, 1, "", "DMLDummyRegressor"], [36, 0, 1, "", "DoubleMLBLP"], [37, 0, 1, "", "DoubleMLPolicyTree"], [38, 0, 1, "", "GlobalClassifier"], [39, 0, 1, "", "GlobalRegressor"], [40, 2, 1, "", "gain_statistics"]], "doubleml.utils.DMLDummyClassifier": [[34, 1, 1, "", "fit"], [34, 1, 1, "", "get_metadata_routing"], [34, 1, 1, "", "get_params"], [34, 1, 1, "", "predict"], [34, 1, 1, "", "predict_proba"], [34, 1, 1, "", "set_params"]], "doubleml.utils.DMLDummyRegressor": [[35, 1, 1, "", "fit"], [35, 1, 1, "", "get_metadata_routing"], [35, 1, 1, "", "get_params"], [35, 1, 1, "", "predict"], [35, 1, 1, "", "set_params"]], "doubleml.utils.DoubleMLBLP": [[36, 1, 1, "", "confint"], [36, 1, 1, "", "fit"]], "doubleml.utils.DoubleMLPolicyTree": [[37, 1, 1, "", "fit"], [37, 1, 1, "", "plot_tree"], [37, 1, 1, "", "predict"]], "doubleml.utils.GlobalClassifier": [[38, 1, 1, "", "fit"], [38, 1, 1, "", "get_metadata_routing"], [38, 1, 1, "", "get_params"], [38, 1, 1, "", "predict"], [38, 1, 1, "", "predict_proba"], [38, 1, 1, "", "score"], [38, 1, 1, "", "set_fit_request"], [38, 1, 1, "", "set_params"], [38, 1, 1, "", "set_score_request"]], "doubleml.utils.GlobalRegressor": [[39, 1, 1, "", "fit"], [39, 1, 1, "", "get_metadata_routing"], [39, 1, 1, "", "get_params"], [39, 1, 1, "", "predict"], [39, 1, 1, "", "score"], [39, 1, 1, "", "set_fit_request"], [39, 1, 1, "", "set_params"], [39, 1, 1, "", "set_score_request"]]}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function"}, "terms": {"": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 22, 23, 25, 26, 27, 28, 29, 32, 36, 38, 39, 41, 43, 44, 45, 46, 47, 49, 55, 58, 59, 60, 63, 64, 65, 69, 70, 71, 72, 73, 75, 78, 79, 81, 89, 90, 94, 95, 97, 104, 105, 107, 108, 109, 110], "0": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 97, 98, 99, 100, 101, 104, 106, 107, 109], "00": [59, 64, 65, 80], "000": [94, 104, 110], "000000": [47, 49, 64, 65, 75, 77, 107], "0000000": [94, 104], "0000000000000010000100": [46, 75, 107], "000000e": [59, 64, 65], "00000591": 68, "000006": [49, 68], "000017": 68, "000025": 63, "000034": 64, "000039": 63, "000064": 50, "000067": 63, "000091": [63, 77], "0001": [47, 64], "0001222989": 80, "000135": 79, "000219": [13, 77], "000242": [14, 77], "000341": 63, "0003730597": 80, "000442": 63, "00047580260495": 41, "000488": 63, "000494": 60, "0005": 47, "000522": 63, "0005a80b528f": 46, "000670": 63, "0006853734": 80, "000743": 70, "000915799": [94, 104], "0009157990": [94, 104], "000943": [52, 53], "000973": 80, "001": [41, 43, 44, 45, 46, 51, 78, 79, 80, 81, 94, 107, 110], "001051": 63, "001234": 65, "00133": 46, "00138944": [73, 81], "001403": 69, "001494": 79, "0016": [45, 64], "001714": 77, "00179": 80, "0018": [45, 64], "0019": 47, "002169338": [94, 104], "0021693380": [94, 104], "0021693381": [94, 104], "002277": 52, "002290": 56, "0023": 43, "00233481": 80, "002388": 62, "002436": 60, "002539": 79, "0026": 47, "002779": 70, "0028": [43, 45, 64], "002821": 71, "0028213335041910427": 71, "002983": 63, "003": [18, 19, 20], "003111": 49, "003134": 68, "003187": 52, "003220": 49, "003328": 68, "0034": 57, "003404": 49, "003415": 49, "003427": 63, "003607": 53, "003779": 60, "003836": 68, "003924": 60, "003944": 52, "003975": 52, "00409412": [73, 81], "0042": [45, 64], "004253": 49, "004392": 60, "004526": 49, "004688": 8, "0047": [45, 64], "004846": 71, "005": 66, "005339": [52, 53], "005857": 63, "005918111": 80, "005e": 79, "006055": 49, "006267": 53, "006425": 65, "006440872": 80, "0068101213851626": 62, "006922": 47, "006958": [52, 53], "007210e": 65, "00728": 107, "0073": 47, "007332": 54, "007332393760465": 54, "007659": 77, "00778625": 80, "0078540263583833": 62, "008": 71, "008023": 65, "008223": [52, 53], "008266e": 65, "008487": 47, "0084871742256079": 62, "008642": 77, "008883698": 81, "00888458890362062": 73, "008884589": 73, "008dbd": 66, "008e80": 66, "009": [66, 71], "009122": 68, "009255": 52, "009329847": 81, "009428": 54, "00944171905420782": 71, "00950122695463054": 73, "009501226954630540": 73, "009501227": 73, "009645422": 44, "009656": 68, "009670": 66, "00972": 47, "009790": 65, "009904": 77, "009986": 68, "01": [1, 2, 3, 5, 6, 8, 9, 10, 13, 14, 15, 37, 41, 44, 45, 46, 52, 53, 64, 65, 66, 67, 68, 69, 78, 79, 80, 81, 94, 107, 110], "010": 66, "010213": 70, "010269": 63, "010450": 44, "010572": 66, "010940": 63, "011131": 68, "01118373": 80, "0112": 43, "01128": 47, "011598": 68, "0118095": 44, "011823": 70, "011988e": 68, "012": [66, 110], "012187": 66, "01219": 46, "01274": 71, "012780": 65, "012831": 71, "013034": 71, "013128": 52, "013235": 66, "013313": 62, "01351638": 44, "013593": 70, "013617": 65, "013677": 69, "013712": 52, "0139012": 80, "01398951": 44, "013990": [94, 104], "014": 69, "01403089": 44, "014080": [52, 53], "014432": 56, "014522": 66, "014637": 63, "014681": 70, "014873e": 52, "015": [41, 46], "015038": 54, "015552": 52, "015565": 68, "0156853566737638": 62, "015698": 68, "01574297": 68, "015743": 68, "015831": 52, "016011": 53, "016154": 63, "016200": [52, 53], "016315": 58, "016429": 77, "01643": 108, "017": 46, "017140": 52, "017393e": 94, "01772": 97, "017777e": 53, "017800092": [94, 104], "0178000920": [94, 104], "018": [46, 110], "018023": 67, "018148": 68, "018508": 52, "018602": 79, "01903": [46, 78, 105, 107], "01916030e": 80, "01916052": 80, "01925597": 44, "019439633": [94, 104], "0194396330": [94, 104], "0194396331": [94, 104], "019596": 54, "01961964": 80, "019660": [14, 77], "01990373": 72, "019974": 65, "02": [52, 53, 64, 65, 68, 77, 79, 80], "02016117": 107, "020166": 68, "020271": 63, "020360838": [94, 104], "0203608380": [94, 104], "0203608381": [94, 104], "02052929": [73, 81], "02079162e": 80, "020819": 77, "02092": 107, "021269": [58, 59], "02163217": 44, "021690": 59, "021823": 62, "021866": 67, "021926": 54, "022181": 52, "02220425": 80, "022295e": 52, "02247976": 44, "02257486": 80, "022768": 47, "022783": 70, "022915": 63, "022954": 77, "022969": 65, "023": 66, "023020e": [64, 65], "023052": 53, "023256": 68, "023537": 62, "023563": [94, 104], "0237113467": 80, "023955": 65, "024346": 52, "024355": 56, "024364": 95, "024401": [58, 59], "024604": 63, "024782": 68, "024926": 56, "025": [52, 53, 58, 59, 66], "025077": [53, 94, 104], "02528067": 61, "0253": 46, "025300e": 53, "025443": 47, "025496": 52, "0257": 43, "025813114": [94, 104], "0258131140": [94, 104], "02584": 46, "025958": 77, "026669": 65, "026723": 54, "026822": 62, "027": 66, "02791": 47, "0281": 46, "028520": [52, 53], "02897287": 55, "02900983": 68, "029010": 68, "029022": 53, "029209": 110, "029364": [95, 100], "029831": 68, "029910e": [64, 65], "02e": 45, "03": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 49, 52, 53, 54, 60, 64, 65, 68, 69, 70, 71, 80, 95, 100, 110], "030087": 77, "0301": 46, "03018": [10, 77], "030346": 107, "0307": 46, "030934": 68, "030962": 68, "031007": 62, "03113": 72, "031134": 78, "031156": 53, "031269": 47, "031639": 68, "031820": 53, "03191": 108, "03220": 109, "0323": 43, "03244552": 78, "0325": 107, "03258": 62, "032580": 62, "032738": 62, "032941": 52, "032953": 70, "033": 41, "033203": 66, "033265": 62, "033756": 54, "033946": [58, 59], "034065": 53, "03411": 107, "034226": 65, "034690": 54, "034812763": [94, 104], "0348127630": [94, 104], "0348127631": [94, 104], "034846": 64, "03489": [26, 44, 63], "03504029": 80, "035119185": [94, 104], "0351191850": [94, 104], "0351191851": [94, 104], "035264": 53, "03536": 107, "03538": 46, "03539": 46, "035391": 47, "0354": 46, "035411": 107, "035441": 53, "03545": 46, "035545": 47, "035572": 47, "035730": 68, "03574": 47, "035762": 68, "035785": 53, "0359": 46, "036": 66, "036129015": [94, 104], "0361290150": [94, 104], "0361290151": [94, 104], "036143": 68, "036147": 68, "036240": 49, "03641665": 80, "036729": 63, "0368": 43, "036945": 65, "03698487": 68, "036985": 68, "037008": [58, 59], "0374": 46, "037504": 53, "037509": 72, "037747": [52, 53], "038845": 52, "039031": 66, "039036": 52, "039141": 49, "03917696": [81, 94], "03920960e": 80, "039310e": 54, "039991e": 52, "04": [19, 32, 45, 49, 52, 53, 64, 65, 68, 69, 70, 80, 110], "040079": 53, "040112": [94, 104], "040139": [52, 53], "040533": [81, 94], "04053339": 94, "040562": 52, "040688": 52, "0408": 52, "040912": 53, "040919": 53, "04107": 12, "041147": 54, "041284": 54, "041387": 54, "041459": 65, "041491e": 54, "04165": 79, "0418": 43, "041831": 54, "041925": 52, "042034": 71, "042249": 53, "042265": 54, "0425": 78, "04276412": 80, "0428": 72, "042822e": 65, "042844e": 68, "043108": 65, "0433": 43, "0434e374": 46, "04387": 78, "043998": 53, "044": [41, 66], "044113": 54, "04415": 46, "04424": 46, "04444978": [94, 104], "044449780": [94, 104], "0445": 78, "04465": 44, "044704": 53, "04486": 107, "04487585": [95, 100], "04491": 79, "04497975": [95, 100], "045": 66, "04501612": 94, "04502": [78, 81, 94], "045144": 63, "045313": 52, "045379": 107, "04552": 63, "045553": 54, "045624": 56, "04563": 78, "045638": 52, "045754": 68, "04586": 78, "045932": 68, "045993": 78, "04625": 78, "046405": 77, "046527": 54, "04653976": 68, "046540": 68, "04655998": 80, "046587": 53, "0466028": 44, "046728": 70, "04682310e": 80, "046922": 78, "047194": 8, "04721262": 80, "047652e": 53, "047724": 52, "047954": 63, "048220": 62, "048308": 59, "048699": 72, "048723": 78, "048853": 53, "049264": 49, "04973": 53, "05": [32, 41, 43, 44, 45, 46, 52, 53, 54, 57, 61, 63, 64, 65, 66, 68, 69, 71, 78, 79, 80, 81, 94, 107, 110], "050": 66, "05039": 70, "050494e": 53, "050538": 53, "050555": 66, "05068787": 80, "050856": [77, 78], "051": 46, "051651": 69, "051867e": 54, "052": 69, "052000e": 65, "052298": 68, "052380": 52, "052488": 59, "052502": 68, "052745": 54, "053": [46, 79], "053049": 53, "0533": 43, "053331": 54, "053342": 65, "053389": [94, 104], "053436": 9, "053541": 68, "053558": 54, "05382162": 80, "053849e": 52, "054": [46, 69], "054068": 63, "054162": 63, "054348": 94, "054370": 54, "054529": [94, 104], "054771e": 68, "055165": 70, "055171": 53, "055338e": 64, "055439": [62, 65], "055493": 71, "055680": [94, 104], "056": 69, "056499": 59, "056745": 52, "056764": 52, "057095": 68, "057274": 49, "0576": [45, 64], "057762": 68, "057792": 52, "057962": 54, "058042": [94, 104], "058276": 65, "058375": 49, "058463": 68, "058508": 72, "058595": 52, "0590": 43, "059128": 52, "059384": 68, "059627": 65, "059630": 56, "059685": 68, "06": [18, 19, 20, 49, 52, 53, 54, 64, 65, 68, 77, 78, 110], "06008533": 79, "060201": 68, "060212": [64, 65], "060417": 52, "06044945": 80, "060581": 61, "060845": [94, 104], "060933": 52, "0611": 43, "06111111": 46, "0615": 43, "062": [69, 79], "062414": 65, "062507": 68, "0628": 43, "062964": [94, 104], "062988": 52, "063": 66, "063017": 49, "0632": 43, "063234e": 53, "0635": 43, "063593": 53, "0636": 43, "063685": 49, "063700": 52, "0638": 43, "063881": 79, "0640": 43, "064161": 65, "064175": 49, "064213": 53, "06428": 64, "064280": 64, "0645": 43, "0646222": 45, "0647": 43, "0649": 43, "065": 71, "0653": 43, "065356": [58, 59], "065368": 62, "0654": 43, "065451": 65, "0655": 43, "0655304": 80, "065725": 54, "0659": 43, "065969": 79, "0662": 43, "066464": 70, "066889": 68, "0669": 43, "06692492": 80, "06694255": 79, "067046e": 52, "0671": 43, "067240": 68, "06724028": 68, "0673": 43, "0675": 43, "067528": 71, "067721": [94, 104], "068073": 53, "06827": 70, "06834315": 55, "068377": 65, "068514": 52, "068934": 49, "06895837": 44, "069443": 49, "0695854": 44, "069600": 65, "069882e": 52, "07": [52, 53, 65, 68, 69, 71, 80, 110], "070020": 68, "070196": 54, "0701961897676835": 54, "0702127": 44, "0704": 43, "070497": 71, "070534": 15, "070552": 52, "070574e": 65, "0707": 43, "070751": 52, "07085301": 79, "07087562": 80, "070884": 68, "0711": 43, "071285": 94, "07136": [44, 63], "071362": 52, "071488e": 54, "0716": 43, "07168291": 44, "071777": 78, "071782": [14, 77], "0719": 43, "07202564": [58, 59], "07222222": 46, "072293": 67, "0727": 79, "073": 69, "073013": 68, "073207": 63, "073275": 52, "07347676": 44, "07350015": [26, 29, 44, 63], "073520": 54, "0736": 43, "07366": [46, 78], "073694": 53, "0739130271918385": 62, "073929": 62, "0743": 43, "074304": 94, "07436521": 80, "074426": 68, "07456127": 44, "074617": 53, "07479278": 70, "074927": 49, "07511348": 80, "075261": 56, "075384": 68, "07538443": 68, "07544271e": 80, "07561": 107, "07564554e": 80, "0757538292": 80, "0758": 71, "075809": 49, "075869": 78, "075942": 62, "076": 66, "076019": 64, "076156": 94, "076179312": [94, 104], "0761793120": [94, 104], "076322": 68, "076347": 54, "0765": 46, "076559": [77, 78], "076596": 52, "0766209": 80, "076684": 107, "07685043": 80, "07689": 46, "07691847": 80, "076953": [58, 59], "076971": 47, "077144e": 53, "077161": 65, "07727773e": 80, "077319": 68, "077502": [95, 100], "077555": 52, "077702": 49, "0777777777777778": 78, "07777778": [46, 78], "077840": 65, "077883": 68, "077923e": 52, "07796": 79, "078017": 52, "078096": 94, "078207": 47, "07828372": [94, 104], "078474": [94, 104], "078709": 53, "078810": 68, "079085": 47, "07915": 46, "07919896": 80, "07942v3": 108, "079458e": 64, "079500e": 52, "079599": 66, "07961": 70, "07978296": 80, "08": [54, 65, 68, 71, 79], "080": 66, "08005229": 80, "08031571": 80, "080854": 65, "08091581": 80, "080947": 47, "081": 46, "081100": 68, "081230": [52, 53], "081396": 59, "081488": 63, "08154161": 80, "08181827e": 80, "08191204": 79, "0820": 43, "082263": 11, "082297": 80, "082400e": 52, "082574": 9, "082804": 56, "082858": 53, "082934": 65, "082973": 63, "083258": [94, 104], "083318": 94, "08333333": 46, "08333617": 80, "0835771416": 44, "083706": 71, "083750": 65, "083949": 71, "084": 44, "084156": 53, "084184": 54, "0841842065698133": 54, "084212": 60, "084269": 65, "084323": 52, "084337": 79, "084633": 58, "0853505": 44, "085395": 52, "085566": 54, "085671": 52, "085965": 65, "08602774e": 80, "0862": 105, "086264": 54, "08664208": 80, "086679": 78, "086889": 58, "0872": 43, "087222": 53, "08747": 80, "087561": 52, "087634": 52, "087745": 53, "087947": 68, "088048": 68, "088282": 59, "088357": 68, "08848": 78, "088482": [14, 77], "088504e": 11, "08888889": 46, "0894": 43, "08968939": 44, "089964": 62, "08e": 45, "09": [52, 53, 54, 64, 65, 68, 77], "09000000000000001": 78, "090025": 65, "09015": 43, "090255": 68, "090436": 53, "091179e": 52, "091263": 62, "09126946": 80, "091391": [94, 104], "091406": 95, "091535": 52, "0916": 43, "091824": 53, "091992": 67, "09211289": 80, "092229": 71, "092247": 68, "092263": 79, "092365": [94, 104], "0925": 80, "092919": 97, "092935": 52, "093043": 68, "09310496": [94, 104], "093153": 68, "093474": 68, "09347419": 68, "093746": 94, "093950": 63, "094026": 63, "094118": 68, "094378e": 52, "094381": 63, "09444444": 46, "094581e": 53, "094829": 79, "09498917": 80, "094999": 68, "095104": 49, "095475": 77, "095654": 52, "095781": 3, "095785": 49, "09603": 105, "09613774": 80, "096245": 77, "096337": 63, "096418": 49, "096550": 58, "096616": 77, "096688": 53, "096741": 55, "09682314": 79, "096915": 71, "097": 69, "097157": 71, "09741049": 80, "097468": 54, "097584064": 80, "09779675": [94, 104], "097796750": [94, 104], "098": 45, "09805712": 80, "098256": 68, "09830758": 70, "098308": 70, "098317": 65, "098319": 68, "0986": 43, "09861118": 80, "098712": 68, "09879814e": 80, "099": 69, "099001": 53, "099307": 53, "09934938": 80, "099647": 67, "099670": 65, "099731": [52, 53], "09980311": [94, 104], "09988": 108, "0_": 25, "0ff823b17d45": 46, "0x1747bdd4520": 47, "0x1747bdd6b90": 47, "0x2920d7b7150": 67, "0x7fa2babf3650": 71, "0x7fb1f7807200": 95, "0x7fb1f7824b30": 94, "0x7fb1f7826c60": 94, "0x7fb202e351c0": 110, "0x7fb2033d2360": 100, "0x7fb2035ee510": 78, "0x7fb20369a750": 78, "0x7fb203a0ad80": 79, "0x7fb203f1d250": 79, "0x7fb2084d0ad0": 94, "0x7fb2084d1e20": 94, "0x7fb2087c2870": 78, "0x7fb208ba37a0": 79, "0x7fb2096dd070": 79, "1": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109], "10": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 26, 27, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 105, 107, 108, 110], "100": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 26, 28, 29, 44, 46, 52, 53, 55, 57, 60, 61, 63, 66, 71, 72, 73, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 107, 109], "1000": [8, 10, 42, 50, 51, 55, 56, 58, 59, 60, 61, 62, 64, 65, 69, 70, 71, 74, 77, 79], "10000": [41, 52, 53, 56, 64, 65, 68], "100000e": 65, "100044": 59, "100154": 62, "100356": 54, "10038": 70, "100385": 62, "10039862": [72, 79], "100517": 94, "100715": 52, "10079785": 79, "100807": [52, 53], "100858": 70, "10089588": 68, "100896": 68, "10092": 65, "100923": 68, "100_000": 66, "101": [18, 19, 20, 43, 69, 77, 79, 108, 109], "10100220": 80, "10126": 65, "10127930": [94, 104], "101279300": [94, 104], "1015": [45, 64], "1016": [18, 19, 20, 43], "1016010": 45, "1018": 65, "102": [75, 77, 79, 107, 109], "10235": 65, "10258": 65, "102616": 54, "102775": 54, "10299": 64, "103": [52, 63, 69, 72, 77, 79, 109], "10307": 94, "1031": 65, "103189": 65, "10348": 64, "103497": 68, "1038": 65, "103806": 54, "103951906910721": 54, "103952": 54, "10396": 64, "104": [45, 64, 72, 77, 79, 109], "10406": 65, "1040729": 80, "104087": 52, "1041": 43, "10414": 65, "1045303": 44, "10458122": 80, "104787": 63, "104849": 52, "105": [25, 44, 63, 77, 79, 109], "1050": 71, "1050289": 80, "105318": 68, "1054": 46, "1055": 43, "106": [46, 77, 79, 109], "10607": [47, 75, 107], "10618": 65, "10637173e": 80, "106391": 94, "106595": 79, "106691": 77, "106746": 68, "1068960": 80, "107": [46, 71, 77, 79, 109], "107073": 54, "107295": 94, "1073": 65, "107413": 52, "10747": [47, 75, 107], "107872": 77, "10799": 65, "108": [77, 79, 105, 108, 109], "1080": [26, 29, 43, 44, 63], "10824": [47, 75, 107], "108257e": 65, "108259": 49, "10831": [47, 75, 107], "10878571": 68, "108786": 68, "109": [52, 77, 79], "109005": 68, "10903": 64, "109069": [94, 104], "109079e": 68, "109273": 63, "10928": 65, "1093": 57, "1094024": 80, "109454": 65, "109470": 53, "1096": 43, "10967": 64, "109811": 60, "109861": 107, "1099472942084532": 50, "10e": [54, 68], "11": [12, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 107, 110], "110": [77, 79, 109], "1101": 65, "11019365749799062": 71, "110194": 71, "110359": 63, "110365": 71, "110681": 70, "1107": 65, "11071087": [72, 79], "110717": [94, 104], "1109": 65, "110902": 54, "110902411746278": 54, "111": [53, 77, 79, 109], "1111": [16, 17, 27, 42, 44, 51, 57, 63, 71, 74, 79, 95, 100, 105], "111164": 67, "11120": 65, "1113212830424466686974808186888990949798": 80, "1118": 45, "11199615e": 80, "112": [46, 77, 79, 109], "1120": 64, "11208236": [73, 81], "1122": 65, "112216": 54, "1129": 65, "113": [16, 77, 79, 109], "113207": 68, "113270": 54, "113415": 65, "11375": 65, "113780": 63, "114": [77, 79, 109], "11409": 64, "11414": 64, "1144500": 44, "11447": 70, "114530": 58, "1145370": 44, "114570": 53, "11458": 65, "114647": 54, "1147": 43, "1148": 65, "114834": 65, "11488": 65, "11495": 65, "115": [77, 79, 109], "11500": [64, 110], "115060e": 68, "1151610541568202": 62, "115296e": 65, "115297e": 64, "1155142425200442": 62, "11552911": 70, "11559": 65, "115636": 53, "11570": 64, "115792e": 65, "115972": 52, "116": [77, 79, 109], "116027": 54, "11617": 65, "116274": 54, "116569": 65, "1166": 108, "1167": 64, "11673": 65, "11675": 65, "117": [52, 77, 79], "1170": 70, "11700": 110, "117072": 58, "117112": 53, "117242": 68, "11724226": 68, "117366": 68, "11743": 110, "11750": 65, "1176": 43, "1177": [43, 64], "117710": 54, "11771586": 80, "11792": 45, "11796": 65, "118": [77, 79], "11802": 65, "1182": 45, "11823404": 71, "118255": 68, "1186": 45, "118601": 63, "11861": 45, "1187339840850312": 63, "11879": 65, "118799": 65, "118938e": 79, "118952": 63, "119": [71, 77, 79, 109], "11906512": 80, "11932": 65, "11935": 70, "119669": 79, "119766": 68, "1198": [44, 63], "12": [15, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 58, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 105, 107, 108, 109, 110], "120": [55, 62, 72, 77, 79, 109], "12002": 64, "1202": 108, "120468": 68, "12046836": 68, "120567": [58, 59], "120721": 63, "12097": [16, 17, 27, 44, 57, 63, 74, 105], "121": [65, 77, 79, 109], "1210": 65, "12101": 65, "12105472": [94, 104], "121054720": [94, 104], "1211": 65, "1213405": 44, "121399": 65, "1214": [94, 104], "1214161719232932333537434652576061637692": 80, "121584e": 68, "121711": 65, "121774": 60, "121824": 53, "12196389e": 80, "122": [18, 19, 20, 43, 69, 75, 77, 79, 108, 109], "12214": 45, "12223182e": 80, "122408": 54, "122777": 94, "123": [32, 45, 46, 64, 71, 77, 79, 80, 109, 110], "1230": 65, "123192": 71, "12323": 65, "1234": [41, 42, 43, 47, 50, 51, 69, 74, 78, 80, 94, 104], "12348": 71, "1238": 65, "123917": 65, "124": [77, 79], "12410": 65, "124306": 62, "124480": 62, "12458152024383947495354646772839396": 80, "12458152024383947495354646772839396610182226273134364550515965717382849110011132128304244666869748081868889909497981214161719232932333537434652576061637692": 80, "124805": 64, "124825": 53, "125": [77, 109], "12500": 64, "125065": 94, "12539340": [94, 104], "1255": 65, "12579": 65, "1258": 44, "126": [77, 109], "12606": 65, "12612": 65, "126777": 94, "126802": 65, "12689": 65, "127": [18, 77, 109], "127006": 65, "12705095": [81, 94], "12707800": 44, "1272404618426184": 62, "1273988": 80, "12752825": [94, 104], "127563": 70, "1277": 66, "127778": 65, "128": [45, 77, 109], "12802": 45, "12814": 65, "128300e": 53, "128312": 68, "128408": 63, "1285": 43, "12858483": 80, "12861": 65, "128651": 53, "129": [63, 77, 109], "12945": 108, "1295": [43, 65], "129514": 65, "12955": 64, "129606": 52, "129798": 52, "1298": 65, "12980769e": 80, "12983057": 79, "13": [19, 20, 22, 24, 41, 42, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 62, 63, 64, 65, 68, 69, 70, 71, 73, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 107, 110], "130": [46, 58, 63, 77, 109], "130122": 70, "13034980e": 80, "130370": 54, "130526": 77, "1306": 70, "130829": 68, "13091": 65, "1309844442144665": 62, "131": [77, 109], "13102231": 79, "131024": 62, "13119": 70, "1312": 110, "131211": 65, "1313": [45, 110], "13137893e": 80, "1318": 43, "132": [46, 52, 63, 77, 109], "13208": 110, "1321": [64, 110], "1324": [45, 64], "132454": 56, "1325": 45, "132671": 54, "13288": 64, "132903": 65, "132982": 52, "133": [46, 75, 77, 108, 109], "13300": 65, "133202": 65, "133421": 65, "13356": 65, "133596": 68, "13398": 71, "133f5a": 66, "134": [63, 72, 77, 109], "1340371": 43, "1341": 45, "1341423": 80, "134146": 65, "1342": 65, "134211": 68, "1343": 64, "134542": 52, "134567": 65, "1346035": 45, "134687": 65, "13474": 65, "134765": 65, "134784e": 52, "1348": 64, "1349": 70, "13490": 65, "135": [46, 77, 79, 109], "13505272": 44, "135142": 53, "135329": 60, "135344": 49, "135352": 5, "135379": 94, "135665": 53, "135707": 78, "135755": 77, "135856": 68, "13585644": 68, "135871": 63, "136": [47, 63, 71, 77, 109], "1360": 45, "13602": 71, "136089": 63, "1361": 65, "136102": 52, "136178": 79, "1362430723104844": 62, "13642": 65, "136442": 63, "1366": 66, "1366751105": 80, "136836": 63, "137": [18, 46, 47, 77, 109], "1371": 65, "137213": 53, "137396": 68, "137529": 79, "1378": 65, "137809": 79, "138": [77, 109], "1380": 64, "138068": 58, "13809": 65, "138264": 71, "138378": 54, "1386": 43, "13868238": [94, 104], "138682380": [94, 104], "138698": [94, 104], "1387": 43, "138851": 58, "13893": 65, "138953": 49, "139": [71, 77, 107], "1390": 64, "139117e": 52, "139491": [94, 104], "13956": 70, "139582e": 12, "1398": 65, "1399": 43, "139921": 77, "14": [42, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 58, 59, 60, 62, 63, 64, 65, 68, 69, 70, 71, 73, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 107, 108, 110], "140": [55, 65, 72, 77, 109], "1400": 65, "14000073": 80, "140073": 52, "140081": 62, "1401": 43, "140770": [52, 53], "140833": 54, "140861": 44, "140926": 68, "141": [65, 77, 109], "141002": 53, "141098e": 65, "14114": 70, "141384": 60, "14141": 65, "141460": 49, "141546": [94, 104], "141820": 54, "142": [77, 109], "14200098": [94, 104], "142097168": 80, "142119": 52, "142270": 56, "142382": 52, "1424": 78, "14268": 79, "14281403493938022": 78, "14289": 65, "143": [75, 77, 109], "143342": 53, "143495": 77, "1435": 65, "143534": 52, "14368145": [94, 104], "144": [77, 109], "14400": 64, "14405": 65, "14406": 65, "144084": 54, "1441": 43, "144137": 55, "14418534": 80, "144241": 58, "1443": 65, "144500e": 65, "144669": 68, "1447": 65, "144800": 54, "144908": 67, "144971": 64, "145": [77, 109], "145027": 49, "145245": 68, "14532650": [94, 104], "145625": 68, "145748": 94, "14587": 65, "146": [77, 109], "146037": 68, "146087": 107, "146142808990006": 54, "146143": 54, "14625": 65, "146435": 53, "1465": 45, "146641": 94, "14667": 65, "1468115": 44, "146973": 54, "1469734445741286": 54, "147": [66, 77, 109], "147015e": 65, "14702": 47, "147121": 68, "14744": 65, "14772": 65, "1479": 65, "14790924": [94, 104], "147909240": [94, 104], "147927": 47, "14798": 65, "148": [77, 109], "14803": 65, "148134": [52, 53], "148161": 68, "148443": 77, "14845": 47, "1485": 65, "148750e": [64, 65], "148790": 65, "148802": 65, "149": [77, 109], "1492": 41, "149215e": 53, "149228": 71, "149285": 68, "149472": 71, "149714": 63, "14984": 65, "149858": [13, 77], "149882": 79, "149898": 68, "15": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 17, 42, 44, 45, 46, 49, 51, 52, 53, 54, 55, 58, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 107, 110], "150": [25, 46, 71, 77, 109], "1500": 80, "15000": [45, 64], "150000": 45, "15000000000000002": [54, 65, 68, 78], "150000e": 65, "1502": 44, "150200": 63, "150334": 65, "150408": 44, "150614": 47, "150719e": 64, "151": [77, 109], "151047e": 58, "151063": 52, "15113": 65, "151636": 54, "151819": 68, "15194": 64, "152": [77, 109], "152034": 65, "152148": [52, 53], "152353": 53, "15285": 65, "152896": 62, "152926": 56, "153": [66, 71, 77, 109], "1530959776797396": 54, "153096": 54, "153119": 54, "153314": 53, "15347": 65, "15354": 70, "153587": 63, "153633": 47, "153639": 80, "153935": 53, "154": 77, "154259": 66, "15430": 110, "154421": 94, "1545": 65, "154557": 68, "154758": 94, "154828": 54, "154890": 62, "155": [77, 109], "155000": 64, "155025": 68, "155120": 68, "155160": 49, "155174": 49, "155516": 67, "15556": 65, "1557093": 44, "156": [77, 109], "1560": 65, "156021": 68, "156169": 53, "156202": [52, 53], "156317": [52, 53], "1564": [94, 104], "156545": 94, "156684": 53, "1569": 65, "156969": 54, "157": [53, 77, 109], "157091": 94, "157154": 52, "1576": 65, "157733": 62, "1577657": 44, "157e": 79, "158": [64, 77, 109], "158007": 68, "15815035": 45, "158178": 54, "1582": 65, "1586": 65, "158697": [94, 104], "1589": 65, "15891559": 68, "158916": 68, "159": 109, "15916": 43, "159386": 70, "1596": 46, "159633e": 53, "159841": 52, "159959": 65, "16": [3, 41, 42, 44, 45, 46, 49, 52, 53, 54, 59, 60, 63, 64, 65, 68, 69, 70, 71, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 107, 110], "160": [55, 72, 109], "1604": 45, "160932": 54, "161": [46, 108, 109], "161049": 53, "161141": 63, "161198": 67, "161236": 68, "161243": 68, "161269": 52, "161288": [53, 62], "161543": 65, "1619": 45, "162": 109, "16201": 65, "16211": 64, "162146e": 66, "162153": 68, "1622": 65, "16241": 65, "162436": 71, "162593": 62, "1626685": 44, "162683": 71, "162710": 54, "162784": 79, "1628": 64, "162930": 65, "163": [65, 109], "163194": 68, "163566": 65, "163577": 49, "163816": 49, "163895": 54, "164": [49, 69, 109], "164034": 94, "164467": 64, "164608": 68, "164698": 60, "1648": 43, "164801": 68, "164805": 54, "164864": 63, "165": 109, "16500": 64, "165178": 68, "16536299": [94, 104], "165362990": [94, 104], "16539906e": 80, "1654": 65, "165419": 68, "165549": 107, "165707": 49, "16587": 64, "16590": 65, "16597": 65, "166": 109, "1661": 64, "166238": 62, "166375": 77, "167": [45, 64, 109], "16725": 65, "167547": 68, "167581e": 52, "1676": 65, "167765": 65, "167993": 94, "168": [80, 109], "16803512": [94, 104], "168089": 62, "168092": 94, "1681": 43, "168195": 70, "168282538": 80, "1683": 64, "168614": 68, "168931": 68, "169": [46, 109], "1691": [43, 65], "16910": 65, "169117": 71, "169196": 68, "169230e": 54, "16951": 65, "16984": 65, "17": [42, 44, 45, 46, 52, 53, 60, 63, 64, 65, 68, 69, 70, 71, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 107, 110], "170": 109, "1704": 65, "170709e": 53, "17083": 65, "171": 109, "1712": 108, "1714": 45, "171575": 68, "171815": 78, "171833": 53, "171848e": 52, "171942": 65, "172": [69, 109], "172022": [94, 104], "172083": 53, "172628": 62, "172793": 68, "173": 109, "1730868115": 80, "173504": 59, "17372": 65, "1738": 65, "17385178": 78, "173969": 94, "173e": 69, "174": 109, "174106": 70, "174185": 68, "174499": [94, 104], "174516e": 68, "17453": 65, "1746": 65, "174743": 77, "174835": 53, "174940": 77, "17499": 65, "175": 109, "1751": 64, "175176": 68, "17522": 65, "175284": 54, "175369": 53, "175635027": 44, "17576": 65, "175894": 71, "175931": 79, "176495": 68, "17655394": 68, "176554": 68, "1766353": 80, "176929": [94, 104], "177": [108, 109], "177007": 68, "17700723": 68, "177043": [52, 53], "1773": 65, "1774": 43, "177463": 67, "177496": 68, "177611": 68, "177740": 52, "177751": 68, "17778": 65, "177830": 53, "17799": 65, "177995": 68, "178": [60, 109], "178169": 58, "178218": 53, "17823": 46, "17842764": 80, "178704": 94, "178763": 68, "178934": 94, "179": [58, 109], "179026": 53, "1795850": 44, "179588e": 68, "179777": 53, "1798913180930109556": 66, "18": [42, 44, 45, 46, 47, 52, 53, 60, 61, 63, 64, 65, 68, 69, 70, 71, 75, 77, 78, 79, 80, 94, 104, 107, 110], "180": [55, 72, 109], "1801138966": 80, "180143": 49, "18015": 65, "180176e": 65, "180190": 79, "180262": 53, "1803": 43, "18030": 65, "180575": [58, 59], "1807": [43, 65], "1809": 108, "180951": 68, "181": 109, "1812": 65, "1814": 43, "18141": 65, "181446": 94, "182": 109, "1820": 43, "182427": 53, "182633": 68, "182849": 68, "183": [46, 79, 109], "183339": 52, "183373": 79, "183526": 54, "183553": 69, "18356413": 79, "18368": 65, "183855": 78, "183888": 63, "184": [46, 108, 109], "184247": 52, "184347": 53, "185": [45, 46], "18500": 65, "185130": 69, "18521021": 80, "1855": 65, "185585": 77, "185984": 52, "186": [65, 109], "18604": 65, "1862": 43, "186237": 53, "18631": 65, "18637": 105, "1864404740": 80, "186589": 49, "18666": 65, "186735": 68, "18678094e": 80, "186836": 68, "187": 109, "187153": 94, "187664": 52, "187690": 68, "18789": 65, "188": 109, "188175": 68, "1881752": 68, "188223": 68, "188400": 53, "1887": 79, "18888149e": 80, "188882": 53, "188991": 94, "189": [46, 69, 109], "189195": 65, "189248": 52, "189293": 65, "1895815": [26, 44, 63], "189737": 68, "189927": 65, "189998": 68, "19": [42, 44, 45, 46, 52, 53, 62, 63, 64, 65, 68, 69, 70, 71, 77, 78, 79, 80, 94, 107, 110], "190": [46, 109], "19000": 65, "190096": 94, "19031969": 68, "190320": 68, "19033538": 44, "190381": 79, "190648": 8, "19073905e": 80, "190809": 68, "190869": 77, "190892": 71, "1909": [26, 44, 63], "190915": 54, "190921": 59, "190976": 69, "190982": 68, "191": [46, 108, 109], "191192": 52, "1912": 108, "191223": 53, "1912705": 74, "191294": 53, "191319e": 64, "191397": 77, "191534": 64, "191716": 65, "19179933": 80, "1918": 43, "192": 109, "1922": 65, "192240": 94, "192505": 67, "192526": 70, "19252647": 70, "192539": [14, 77], "192587": 68, "192952": 49, "193": 109, "193060": 68, "193253": 52, "193285": 52, "193308": [14, 77], "193341": 53, "19374710e": 80, "19382": 65, "193849": 69, "19385": 65, "193f0d909729": 46, "194": [61, 65, 109], "194092": 52, "1941": 45, "19413": [64, 65], "194303": 53, "194601": 55, "195": 109, "19508": 71, "19508031003642462": 71, "19509680e": 80, "195377": 68, "195396": 68, "195547": 65, "195564": 63, "19559": [45, 64], "195761": 68, "195781": 52, "1959": 108, "196": 109, "196189": 68, "196437": 65, "196478e": 53, "19680840": [94, 104], "196e": 32, "197": 109, "1970": 65, "197000e": 65, "19705": 65, "197225": [47, 75, 107], "1972250000001000100001": [46, 75, 107], "197281": 66, "1974": 65, "197424": 78, "197484": 94, "19756": 65, "19758": 65, "197600": 56, "197711": 65, "197920": 52, "19793": 65, "19794": 65, "198": 109, "198218": 63, "19824": 65, "198351": 68, "198503": 69, "198549": 47, "198687": 45, "1988": [42, 51, 74, 79], "198953": 77, "199": 109, "1990": [45, 64, 65], "1991": [45, 64, 65, 110], "199281e": 68, "199282e": 65, "199412": 53, "199458": 94, "1995": [44, 63], "1998": 66, "19983954": 72, "199893": 58, "1999": [66, 72], "1_": [54, 68], "1e": [1, 3, 5, 6, 8, 9, 10, 13, 14, 15, 65], "1f77b4": 56, "1x_4x_3": 56, "2": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 32, 33, 37, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 94, 95, 96, 97, 100, 101, 102, 103, 104, 106, 107, 108, 109], "20": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 22, 23, 24, 26, 27, 28, 42, 44, 45, 46, 52, 53, 54, 55, 58, 60, 61, 63, 64, 65, 68, 70, 71, 72, 73, 74, 77, 78, 79, 80, 81, 94, 95, 100, 107, 110], "200": [21, 24, 25, 43, 54, 55, 57, 61, 67, 68, 72, 74, 78, 109], "2000": [15, 17, 45, 49, 52, 53, 54, 64, 65, 68, 72, 79], "20000": [45, 64], "20000000000000004": [54, 65, 68], "200000e": 65, "200049": 52, "200065": 49, "20010": 65, "200110": 65, "2003": [16, 108], "200303": 107, "2005": 55, "20055": 65, "2006": 65, "20073763": 61, "20074": 65, "201": [46, 65, 109], "2010": [44, 63], "2011": [44, 63, 105, 107], "2013": [57, 94, 104, 108], "2014": [94, 104, 108], "2015": [25, 108], "201528": [52, 53], "20158": 65, "2016": 66, "2017": [23, 108], "201768": 63, "201788e": 65, "201796": 60, "2018": [16, 17, 27, 28, 42, 44, 45, 51, 55, 57, 61, 63, 64, 65, 70, 74, 80, 94, 104, 105, 108, 109], "2019": [21, 46, 52, 53, 54, 58, 59, 65, 68, 70, 78, 81, 83, 88, 93, 105, 107, 108], "201e": 69, "202": 109, "2020": [5, 6, 18, 19, 20, 22, 24, 43, 46, 55, 71, 78, 79, 95, 97, 108], "2020435": 44, "2021": [26, 43, 44, 46, 52, 53, 63, 80, 108, 109], "20219609": 44, "2022": [70, 71, 79, 95, 97, 103, 105, 108], "2023": [29, 72, 79, 81, 89, 90, 108], "2024": [41, 50, 66, 69, 71, 79, 105, 108], "202603": 53, "202650e": 54, "20269": 65, "20274": 65, "202846": 53, "203": [45, 52, 64, 109], "203284": 54, "20329": 65, "2036": 65, "203828": 65, "203893": 77, "204": 109, "204007": 68, "20400735": 68, "204362": 71, "204455": 53, "204482": 68, "2044976": 80, "204626": 49, "204653": 77, "204794": 68, "205": [69, 70, 109], "205187": 54, "205224": 70, "2057670": 80, "205938": 63, "206": 109, "2061": 65, "206253": [64, 65], "2064": 65, "206614": 68, "207": [69, 79, 109], "207222": 64, "2075": 43, "207834": 53, "20783816": 44, "207840": 59, "207912": 94, "208": [49, 109], "208034e": 65, "2080787": 44, "20823898": 44, "2086": 65, "209": 49, "209014": 68, "209219e": 70, "209257": 5, "209546e": 65, "209894": 68, "21": [16, 17, 27, 42, 44, 45, 46, 52, 53, 57, 63, 64, 65, 68, 70, 71, 74, 77, 78, 79, 80, 94, 105, 107, 108, 110], "210": [19, 20, 24, 49, 66], "2103": [65, 105], "2103034": 44, "210319": [52, 53], "210323": 68, "2104": 109, "2107": 108, "21078": 65, "211": [49, 69, 109], "21105": [46, 78, 105, 107], "2112": 71, "21142": 65, "211534": 54, "21155656": 68, "211557": 68, "212": [49, 109], "2122": 65, "21257396e": 80, "212844": 63, "212863": 52, "213": [49, 66, 69, 108, 109], "213026": 65, "213070": 53, "213135": 53, "21361": 65, "213743e": 53, "2139": 22, "214458": 62, "214764": 70, "215": 49, "215069": 68, "215342": 68, "2155": 65, "21550": 65, "21562": 65, "21573": 65, "215967": 94, "216": 49, "216207": 78, "21624417": 44, "2163": 65, "216344": 68, "21669513e": 80, "216761": 67, "217": [49, 69, 108], "21716": 65, "2171802": [44, 63], "217244": [10, 77], "218": 49, "21804": [45, 64], "218176": 49, "218383": 49, "218767": 65, "2189": 65, "218938": 65, "219": [18, 19, 20, 43, 49, 108], "2191274": 44, "2197237644227434": 62, "21995244": 80, "22": [42, 44, 45, 46, 52, 53, 62, 63, 64, 68, 69, 70, 71, 77, 78, 79, 80, 94, 107, 110], "220": [32, 49, 109], "220088": 65, "220398": 52, "220407": 62, "220772": 68, "221": [49, 109], "2213": 63, "2214": 63, "221419": 65, "2215": 63, "2216": 63, "2217": [44, 63], "222": 109, "2222": [42, 44, 51, 79], "22222": 65, "22272803e": 80, "222843": 68, "222882": [53, 62], "223": [66, 69, 109], "223158": 62, "22336235": 44, "223485956098176": [58, 59], "223617": 62, "22375856": 44, "22390": 64, "223928": 62, "224": [69, 109], "22464765": 80, "224897": [52, 53], "225": [43, 72, 109], "225034": 55, "22505965": 44, "22507006e": 80, "225175": 68, "225222": 68, "22522221": 68, "22528": 65, "225350": 53, "225427": 49, "225459760731946": 54, "225460": 54, "225574": 63, "2256": 65, "22562": 65, "225670": 62, "225776": 71, "226": 109, "2264": 43, "226524": 68, "226598": 63, "226938": 59, "226969": 49, "227": [65, 109], "2271071": 29, "2276": 43, "2279": 65, "227932e": 64, "228035": 65, "2281": 65, "228214": 79, "228404": 62, "228597e": 53, "228630": 53, "228648": 45, "229": [45, 109], "22925": 65, "22937": 65, "229443": 68, "229452": 79, "229472": 64, "2295": 65, "229759": 78, "2298": 43, "229961": [52, 53], "229994": [52, 53], "23": [6, 39, 44, 45, 46, 52, 53, 55, 61, 63, 64, 65, 68, 70, 71, 75, 77, 78, 79, 80, 94, 105, 107, 108, 110], "230": 43, "230009": [58, 59], "2307": [44, 63, 74], "2308": 70, "230842": 52, "230956": 56, "231": [16, 109], "23113": 79, "231153": 53, "231310": 68, "231430": 94, "231467": 79, "231986": 68, "231e": 69, "232134": [52, 53], "232157": 53, "23237077": 80, "2328": 65, "232868e": 53, "232959": [58, 59], "232e": 79, "233": 23, "233029": 52, "233154": 110, "2335": 43, "233705": 53, "234": 108, "234137": 71, "234153": 71, "234205": 65, "234431": 62, "234534": 54, "234605": 47, "234798": 65, "234910": 63, "235": 109, "235291": 52, "2359": 110, "23590": 65, "236008": 54, "236015e": 52, "236309": 65, "236884": 62, "23690345e": 80, "237": 46, "23700737": 80, "237115": 53, "237200e": 52, "237252": 65, "237341": 52, "237461": 70, "23748": 65, "23751359e": 80, "237896": 68, "23789633": 68, "238": [44, 63, 109], "238101": 68, "238225": 94, "23823291": 80, "238251": 54, "238529": 9, "23856": 65, "238794": 68, "239": 109, "239243": 52, "239267": 62, "239313": 53, "23965": 65, "23e": 45, "24": [44, 45, 46, 52, 53, 61, 62, 63, 64, 65, 68, 70, 71, 72, 77, 78, 79, 80, 94, 107, 108, 109, 110], "240127": [52, 53], "240146": 53, "240295": 70, "240532": [52, 53], "2407": 43, "24080030a4d": 46, "240813": 60, "241049": 68, "241064": 53, "241596": 79, "2416": 43, "241609": 65, "241645": 53, "241678": 52, "241827": 53, "241962": 71, "24199": 65, "241e": 69, "242": [66, 108], "242000": 65, "242124": [64, 65], "242139": 94, "242158": [64, 65], "2424596822": 59, "242815": 94, "242902": 68, "2430561": 43, "243246": 68, "2438": 65, "2439": 65, "243e": 69, "244": [32, 65], "244090": 65, "244455": 68, "244622": 94, "24469564": 107, "245": [108, 109], "245062": 68, "2451": 43, "24510393": 45, "245370": 63, "245512": 68, "245531": 52, "245720": 56, "246": 109, "246624": 77, "246731": 64, "2467506": 44, "246753": 68, "246879": 68, "247": [69, 109], "247020": 54, "247057e": 68, "2471": 65, "2472": 65, "247617": 77, "247717": 65, "24774": [64, 65], "247826": 63, "247977": 52, "248171": 68, "248638": 54, "249": [44, 63, 66, 109], "2491": 65, "24917": 65, "249986": 62, "25": [14, 15, 18, 19, 20, 24, 25, 26, 27, 44, 45, 46, 52, 53, 54, 56, 57, 61, 62, 63, 64, 65, 66, 68, 71, 72, 77, 78, 79, 80, 94, 107, 110], "250": [41, 66, 109], "2500": 65, "25000000000000006": [54, 65, 68], "250073": 65, "250210": 54, "2503": 65, "250354": 68, "250425": 54, "251": [64, 65, 70], "251101": [77, 78], "251412": 53, "251480": 53, "251953": 65, "252133": 65, "252253": 70, "25240463": 79, "252524": 68, "252601": 94, "253026": [52, 53], "2532": 65, "253437": 67, "253724": 68, "25374": 65, "254": [65, 109], "25401679": 44, "254035": 62, "254038": 59, "254083": 53, "2543": 65, "254324": 54, "254400": 94, "255": [65, 109], "255034e": 53, "255995": 52, "256": [65, 78], "256002": 79, "256416": 68, "256567": 63, "25672": 65, "256944": 68, "256983": 12, "256992": 65, "257019": 53, "257207": 44, "257377": 56, "257523": 52, "258083": 53, "258158": [52, 53], "2583": 65, "258522": 52, "258541e": 15, "258951": 68, "259164": 53, "259395": 60, "2594": [45, 64], "259828": [52, 53], "259875": 53, "25x_3": 56, "26": [44, 45, 46, 47, 52, 53, 55, 61, 63, 64, 65, 72, 75, 77, 78, 79, 80, 94, 107], "26016": 65, "260161": [13, 77], "260211": [52, 53], "260356": 64, "260360": 68, "261": 69, "2610": 65, "2613": 65, "261520": 49, "261624": [64, 65], "261685": 65, "26175": 65, "261777": 65, "261903": 63, "2619317": 44, "262423e": 65, "262621": 63, "262829": 80, "263": [16, 65, 109], "2633": 65, "263942e": 53, "263974e": 68, "264": [108, 109], "264086": 56, "264274e": 65, "264884": 65, "265": 109, "2651": 79, "265119": 67, "2652": [46, 64, 65], "265547": 65, "265744": 62, "2658": 59, "265929": 69, "266": 109, "266147": 69, "266686": 52, "266922": 94, "267": 66, "2670691": 44, "267500": 63, "267581": 65, "267950": 68, "268": 109, "268055": 65, "268343": 62, "268628e": 53, "268942": 68, "268943": 52, "268998": 45, "269043": 68, "269977": 65, "26bd56a6": 46, "26e": 45, "27": [19, 20, 24, 42, 44, 45, 46, 47, 52, 53, 55, 61, 63, 64, 65, 72, 75, 77, 78, 79, 80, 94, 107, 108], "270": 109, "2700": 46, "270644": [52, 53], "271": 109, "271004": [64, 65], "271083": 65, "272296": 65, "272332e": 52, "272408": 53, "272662": 65, "273": 46, "273299": 53, "273356": 54, "27371": [45, 64], "27372": [45, 64], "274": [46, 65], "2740991": 43, "274251e": 64, "274267": 63, "27429763": 79, "274793": 68, "274825": [14, 77], "27487": 65, "2754": 43, "275596": 94, "276": [46, 109], "276148": 68, "276189e": 63, "2764": 65, "2766091": 45, "27713": 65, "277299": 47, "27751": 65, "277512": 53, "277561e": 63, "277968": 68, "278": [70, 109], "2780": 44, "278000": 63, "278035": 49, "278391": 65, "278434": 58, "278522": 49, "2786": [94, 104], "278804": 53, "279": 109, "27951256e": 80, "27986": 65, "279933e": 53, "28": [44, 45, 46, 52, 53, 57, 60, 61, 63, 64, 72, 77, 78, 79, 80, 94, 107, 109], "280196": 59, "280454dd": 46, "280514": 94, "280963": 67, "281": [69, 109], "281024": 68, "28111364": 45, "28139784": 80, "2815": 65, "2818": 43, "2819": [94, 104], "282": [69, 108, 109], "282200": 59, "2825": [105, 107], "28251": 65, "282870": 65, "2830": [105, 107], "283041": 52, "283207": 52, "28326": 65, "283386": 52, "2836": 43, "2836059": 44, "28382": 65, "283974": 68, "283992": 52, "283994": 68, "283e": 69, "284": 109, "28425026": 70, "284271": 60, "284397": 110, "28452": [45, 64], "2849": 65, "284987": 65, "285": [69, 79, 109], "285e": 69, "286": 109, "286027": 77, "286203": 52, "286371": 52, "2865": [43, 65], "286507": 54, "286563e": 65, "286593": 65, "287041": 68, "287196": 52, "287815": 70, "287926": 68, "288": 66, "288976": 65, "289": 108, "289062": 64, "289357": 53, "289440": [52, 53], "28973106": 80, "29": [12, 44, 45, 46, 52, 53, 61, 63, 64, 70, 72, 77, 78, 79, 80, 94, 107], "290": 79, "290565": 53, "290736e": 53, "290987": 64, "291": [41, 65, 69], "2910": 65, "291008": 52, "291011": 79, "291071": 68, "29107127": 68, "291405": 68, "291406": 68, "291434": 53, "291500e": [64, 65], "291517": [52, 53], "291963": 68, "292": 67, "292028": 54, "292047": 94, "292105": 68, "292178": 64, "292302995303554": 54, "292303": 54, "2925": 46, "2927": 65, "292997": 68, "29299726": 68, "293218": 68, "293617e": 65, "294067": [52, 53], "294449": 52, "295": 108, "295307": 52, "295481": 68, "29548121": 68, "295837": [47, 75, 107], "2958370000000100000100": [46, 75, 107], "2958370001000010011100": [46, 75, 107], "2958371000000010010100": [46, 75, 107], "296228": 65, "2966469": 80, "296729": 63, "29678199": [73, 81], "296901": 52, "297287": [52, 53], "2973": 65, "297349": [58, 59], "297682": 68, "297687": 65, "297749": 65, "29784405": 70, "298": [23, 46, 80], "298076": 52, "298120": 54, "298228e": 65, "299": [46, 69], "299537": 59, "299712": 58, "2999": 49, "2_": [29, 72, 95, 97, 103], "2_x": [29, 72], "2d": [81, 88], "2dx_5": [54, 68], "2e": [41, 43, 44, 45, 46, 78, 79, 81, 94, 107], "2f": 60, "2m": [95, 100, 103], "2n_t": 56, "2x": 68, "2x_0": [21, 52, 53, 58, 59], "2x_4": 56, "3": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 27, 32, 33, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 105, 106, 107, 108, 109], "30": [21, 41, 42, 44, 46, 49, 50, 51, 52, 53, 54, 55, 61, 63, 64, 65, 68, 69, 72, 77, 78, 79, 80, 94, 107], "300": [42, 51, 54, 65, 68, 74, 108], "3000": 49, "30000000000000004": [54, 65, 68], "300031": 52, "30031116e": 80, "300892e": 53, "30093956": 70, "301": 46, "301366": 94, "301371": 68, "3016": 64, "301737": 52, "30189": 65, "302149": 52, "30225500": 80, "302357": 68, "302382": 62, "302571": 77, "302648": 63, "303007": 52, "303324": 63, "303489": 68, "303613": 68, "30361321": 68, "30383": 65, "303835": 63, "303f00f0bd62": 46, "304130": 68, "304159": 68, "304201": 56, "305133": 77, "30527": 65, "305341": 68, "305612": 63, "305775": 68, "305b": 46, "306297": 52, "30645": 65, "30672815": 44, "306915": 63, "306963": 68, "307407": 68, "308": 65, "308245": 66, "308568": 53, "308774": 52, "30917769": [58, 59], "309539": 62, "309772": 63, "309823e": 65, "30982972": 68, "309830": 68, "31": [44, 45, 46, 49, 52, 53, 61, 63, 64, 65, 72, 77, 78, 79, 80, 94, 107, 110], "310000e": 65, "310145": 62, "310761": 67, "311": 69, "311253": 65, "311321": 53, "311667": 53, "311712": 58, "3120": 65, "312652": 69, "31288182": 80, "312888": 66, "313": 79, "313056": 94, "313209": 54, "313324": 65, "31337878": 65, "313535": 68, "31378": 46, "314": 80, "3141": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 44, 46, 47, 63, 73, 75, 77, 78, 81, 94, 104, 107], "314247": 71, "31429507": 80, "314341": 52, "3146": 15, "314625": 53, "314651": 58, "31476": [64, 65], "315031": 71, "315036": 52, "3151": 65, "315155": 53, "315223": 49, "315290": [58, 59], "315310": 52, "315769e": 52, "316": 46, "316193": 68, "31632": 65, "316407": 79, "316540": 63, "316717": [52, 53], "316826": 52, "316863": 53, "317394": 56, "317487": 68, "317607": 68, "317876988": 80, "318": 46, "318000e": 65, "318438": 65, "318552": 65, "318584": 94, "318753": [58, 59], "319": 46, "319100": [58, 59], "319759": 68, "319850": 68, "32": [44, 45, 46, 52, 53, 61, 62, 63, 64, 65, 72, 77, 78, 79, 80, 81, 94, 107], "320": 65, "320314": 64, "320633": 54, "321": 66, "321686": 94, "322186e": 52, "32236455588136": 55, "322404": 70, "322751": 53, "3234": 65, "323636": 64, "323679": 63, "324": [45, 65], "324476": 49, "324518": 67, "32458367": 44, "3245837": 68, "325056": 68, "325090": 65, "325486": 52, "325599": 52, "326": 69, "326025": 66, "326148": 53, "326721": 53, "326740": 68, "326871": 71, "3268714482135234": 71, "327257": 52, "327803": 77, "328471": 52, "329339": 55, "32950022e": 80, "33": [44, 45, 46, 52, 53, 58, 61, 62, 63, 64, 65, 72, 77, 78, 79, 80, 94, 107, 108], "330": 41, "3300": [45, 64], "330068": 52, "330100": 52, "330143": 68, "33014346": 68, "330163": 53, "330285": [52, 53], "3304269": 44, "330615": 68, "330731": [14, 77], "331365": 58, "331521": 68, "331602": 65, "33175566": 68, "331756": 68, "332502": 53, "332782": [14, 77], "3329": 65, "332996": 63, "3333": [42, 44, 51, 77, 78, 79], "3333333": 46, "33335939e": 80, "3335": 65, "333581": 64, "333655": 52, "333704": 53, "333955": 53, "334": [45, 66], "334649": 60, "334750": 54, "33500": 65, "335176": 65, "335446": 49, "335609e": 68, "335846": 68, "335853": 65, "336382": 53, "336461": 65, "336612": 56, "337380": 68, "3376": 43, "337619": 55, "338": 70, "33849": 65, "3386": 80, "338603": 52, "338775": 54, "338908": 54, "339269": 70, "33928": 65, "339443": 53, "339570": 68, "339875": [58, 59], "34": [42, 43, 44, 45, 46, 52, 53, 59, 61, 63, 64, 65, 70, 72, 77, 78, 79, 80, 94, 110], "340": [45, 65], "340029": 53, "340274": 70, "341336": [10, 77], "341472": 62, "341755e": 52, "3420": 65, "342362": 49, "342467": 77, "342632": 62, "342675": 44, "3427170": 80, "34276227": 80, "34287815": 70, "3428979": 80, "342989": 65, "342992": 63, "343": [65, 69], "343685": 52, "34375": 64, "343828": 52, "344212": 110, "344305": 60, "344505": [64, 65], "344640": 68, "344753": 49, "344787": [52, 53], "344834": 56, "345065e": 65, "345381": 54, "3453813031813522": 54, "3454": 65, "345852": 53, "345903": 68, "345989": 52, "346107": 64, "346206": 68, "346238": 70, "346269": 53, "346678": 67, "346964": 52, "347310": [14, 77], "347696": 54, "34769649731686": 54, "347929": 65, "348": 69, "348319": 53, "3484733872": 80, "34858240261807": 55, "348617": 68, "348622": 69, "348700": 53, "348980e": 53, "3492131": 43, "349383": 63, "34943627": 61, "3494958529": 80, "349638": 53, "34967621": 44, "349772": 59, "35": [45, 46, 52, 53, 54, 63, 64, 65, 68, 77, 78, 79, 80, 94, 95, 100, 110], "3500000000000001": [54, 65, 68], "350165": 78, "350208": 52, "350518": 68, "350712": [58, 59], "35077502": [95, 100], "351220": 53, "351629": 65, "351766": 67, "352": [45, 63], "352250e": 64, "352259e": 65, "3522697": 44, "352813": [77, 78], "35292": 65, "352990": 65, "352998": 65, "353105": 15, "353412": 68, "35341202": 68, "35365143": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "353748e": 68, "3538": 43, "354": 65, "354188": 56, "354371": 68, "354688": 11, "355065": 49, "355209": 68, "355651": 53, "356136e": 65, "356167": 59, "356183": 65, "35620768e": 80, "3564": 65, "3565": 65, "3568": 79, "357": 65, "357170": 52, "35731523": 79, "358158": [64, 110], "358289": 63, "358395": 70, "358799": 94, "358977": 64, "359": [69, 110], "359100": 65, "359161e": 52, "3593": 70, "359307": 53, "35th": 108, "36": [45, 46, 52, 53, 63, 64, 77, 78, 79, 80, 94], "360004": 68, "360065": 94, "360249": 60, "360475": [52, 53], "360572": 53, "360655": 65, "360683": 54, "360801": 54, "361": 69, "361518": 54, "361518457569366": 54, "361521": 11, "3619201": 22, "362157": 52, "36219192": 80, "36231307e": 80, "363276": 44, "364221": 52, "3643": [94, 104], "3643793": 80, "364595": 44, "3647": 46, "364800": 68, "365": 80, "36501": 65, "365551": 53, "36557195e": 80, "36566025e": 80, "366": 65, "36616": 65, "366310": [52, 79], "366529": 67, "366718627": 44, "366950": 52, "367": [32, 69], "367181": 52, "367323": 68, "367398": 62, "367571": 54, "367625": 68, "368152": 63, "3682": [45, 64, 65], "368324": 63, "36849039": 80, "368499": 54, "3684990272106954": 54, "369": 41, "369556": 54, "3696": 70, "369796": 68, "369869": 64, "369981": 63, "37": [45, 52, 53, 63, 64, 65, 66, 77, 78, 79, 80, 94], "3702770": 44, "370736": 63, "3707775": 44, "370908": 52, "3710": 65, "371357": [64, 65], "371429": 54, "371850e": 53, "372": 108, "37200": [64, 65], "372097": 54, "3722": 65, "37231324": 72, "3724": 65, "372427": 53, "3727679": 44, "373218e": 62, "3738573": 44, "374364": 68, "37436439": 68, "3745": 65, "374821e": 65, "374862": 52, "374917e": 52, "375081": 65, "3752073840": 80, "375274": 52, "375465": 68, "375621": 62, "375844": 62, "376760": 53, "376806": 53, "37702900": 80, "377060": 65, "377195": 49, "377311": 68, "377669": 53, "378351": 8, "378588": 52, "378596": 63, "378688": 68, "378727": 52, "378834": 68, "3788859": 44, "379": 108, "379038": 68, "3792540414855565862707577787985879599": 80, "37925404148555658627075777879858795991245815202438394749535464677283939611132128304244666869748081868889909497981214161719232932333537434652576061637692": 80, "37925404148555658627075777879858795991245815202438394749535464677283939661018222627313436455051596571738284911001113212830424466686974808186888990949798": 80, "37925404148555658627075777879858795991245815202438394749535464677283939661018222627313436455051596571738284911001214161719232932333537434652576061637692": 80, "3792540414855565862707577787985879599610182226273134364550515965717382849110011132128304244666869748081868889909497981214161719232932333537434652576061637692": 80, "37939": 65, "379614": 68, "379626": 52, "379981e": 53, "38": [46, 52, 53, 64, 77, 78, 79, 80, 94], "3800694": 44, "380837": [64, 65], "381": 69, "38103328": 80, "381072": 68, "381603": 52, "381685e": [64, 65], "381689": 68, "3817": 65, "381826": 12, "38192333": 80, "382286": 65, "382582e": 3, "382684": 77, "382872": 54, "383297": 68, "383531": 62, "384": 65, "384223": 79, "384443": 53, "384677": 49, "384777": 65, "384865": 53, "384928": 52, "385013": 49, "3851": 65, "385160": 53, "385240": 94, "385615": 49, "385917": 63, "386": [46, 65], "386102": 54, "386502": 65, "386831": 49, "386988": 55, "387": 46, "3871": 43, "387426": 68, "387780": 68, "388026": 52, "388071": 68, "388185": 49, "38818693": 80, "388216e": 78, "388668": 68, "38866808": 68, "38880558": 80, "388871": 65, "389": 46, "389126": 79, "389164": 62, "38922": 79, "389566": 67, "38973512e": 80, "389755": 52, "38990574": 80, "39": [41, 43, 44, 45, 46, 47, 49, 52, 53, 55, 59, 60, 61, 63, 64, 65, 70, 71, 72, 77, 78, 79, 80, 94], "39010121e": 80, "390379": 68, "391377": 71, "39163012": 80, "392128": 53, "392242": 60, "39236801": 61, "392400": 65, "392623": 53, "392752": 55, "392833": 70, "392864e": [64, 65], "392917": 52, "393060": 77, "393604": 54, "393654": 49, "394226": 53, "39425708": 44, "395076e": 65, "395136": 63, "395268": 77, "395569": 52, "395603": 52, "3958": 79, "395889": 65, "396": [32, 79], "39611477": 45, "396173": 58, "39621961e": 80, "396300": 58, "3964": 65, "396531": 65, "396985": 63, "396992": [52, 53], "397140": 54, "397155": 53, "397179": 49, "39727": 65, "397313": 43, "397536": 62, "397578": 60, "397811": 70, "398": [75, 107], "3985": 65, "398770": 68, "398999": 77, "399": 45, "399056": 68, "399223": 56, "399343e": 52, "399355": 56, "399692": 68, "399858": 71, "3cd0": 46, "3dx_1": [54, 68], "3e1c": 46, "3ec2": 46, "3f5d93": 66, "3x_": 68, "3x_4": [54, 68], "4": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 19, 20, 24, 29, 32, 33, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 107, 109], "40": [44, 52, 53, 54, 55, 62, 64, 65, 68, 72, 75, 77, 78, 79, 80, 94, 95, 100], "400": 63, "4000000000000001": 78, "40000000000000013": [54, 65, 68], "40029364": [95, 100], "400823": 68, "400855956463958": 54, "400856": 54, "401": [16, 110], "401247": [81, 94], "40127723e": 80, "401690e": 53, "401931": [58, 59], "402077": 65, "402113": 94, "402301e": 78, "402525": 66, "4028314": 80, "402902": 65, "403": 69, "403425": 68, "403626490670169": 73, "4036264906701690": 73, "403626491": 73, "403715": 3, "403771948": 81, "4039": 43, "404267": 52, "404300": 49, "404318": 43, "404411": 52, "40452": 65, "404550": 67, "405050": 53, "405203": 56, "405374": 65, "40583": 43, "405890": [14, 77], "406285": 68, "406446": 54, "4065173": 80, "40676": 43, "407": 69, "407558": 52, "407565": 52, "408476": [95, 100], "40847623": [95, 100], "408479": 63, "408509": 53, "408539": 68, "408565": 68, "409154": 43, "4093": 70, "409328": 65, "409395": 68, "409746": 54, "409848": [52, 53], "41": [49, 52, 53, 64, 65, 77, 78, 79, 80, 94, 104], "410100": 52, "410393": 54, "410667": 77, "410681": 56, "410682": 52, "410795": 63, "41093655": 80, "411146e": 53, "411190": [52, 53], "411291": 67, "411295": 68, "411304": [52, 53], "411447": 65, "411582": 68, "411768": 53, "412004": 58, "412127": 68, "412304": 71, "412477": 56, "412653": 63, "412714": 54, "412726": 53, "412941e": 53, "413247e": 52, "41336": 78, "41341040": 44, "413608": 68, "414": 69, "414073": 9, "414533": 53, "41525168e": 80, "415375": 52, "41566": 79, "415812": 110, "415988": 65, "416052": 49, "416132": 53, "4166": 65, "4166667": 46, "416757": 68, "416899": 52, "416919": 53, "416e": 69, "417640": 52, "417727": 64, "417736": 62, "417767": [58, 59], "417834": 49, "41798768e": 80, "418": 32, "418056": 68, "41805621": 68, "418438": 64, "418741": 49, "418806e": 54, "41918406e": 80, "419371": 68, "419871": 49, "41989983e": 80, "4199952": 44, "41e5": 46, "42": [5, 6, 24, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 65, 67, 68, 70, 71, 72, 77, 78, 79, 80, 94, 104, 108], "4200": 65, "420316e": 65, "420608e": 70, "42073312": 44, "420967": 54, "421083": 43, "4211349413": 44, "421163": 52, "421200": 71, "421234": 77, "421297e": 53, "421357": [58, 59], "421576e": 65, "421793": 70, "421919": 65, "422007": 70, "422266": 65, "422293e": 77, "422325": 54, "422561": 49, "422591": 53, "42338": 65, "4235839": [58, 59], "42388745": 72, "423921e": 77, "423951": 43, "424108": 54, "424127": 80, "42412729": 44, "424292": 52, "424328": 68, "424651": 79, "424717": 54, "424748": 71, "425": 63, "425103": 43, "425208": 65, "425493": 43, "42550": 65, "426055": 43, "426540": 63, "426540301": 44, "4266868314": 80, "426736": 65, "427": 65, "427486": [52, 53], "42755087": 70, "427551": 70, "427573": 63, "427725": 68, "428": [94, 104, 110], "428046": 67, "42811700": 110, "428255": 68, "428411": [64, 65], "428467": 68, "4284675": 68, "428771": [14, 77], "4290": 43, "429057": 53, "429230": 52, "429705": 52, "42ba": 46, "43": [45, 49, 52, 53, 77, 78, 79, 80, 94], "430298e": [64, 65], "430595": 53, "430608": 52, "431061e": 52, "4311947070055128": 78, "431253": 62, "431306": 68, "431701914": 105, "431998": 49, "432130e": 64, "432300e": 68, "43231359e": 80, "432707": 69, "43294": 46, "432f": 46, "433": [46, 69], "433221": 54, "4336": 65, "43374433": 72, "433750": 52, "433753": 62, "4339": 43, "434121": 62, "434519": 77, "434535": 68, "43453524": 68, "435": 46, "43503345": 79, "43511": 65, "435401": 63, "4357": 65, "435927": 65, "435967": 63, "43597565": 68, "435976": 68, "436": [46, 65], "436016": 62, "43627032": 55, "436327": 65, "436394": 62, "436764": 69, "436806": 65, "436817": 62, "437369": 66, "437667": 64, "437924": 65, "438": 63, "438219": 68, "438289": 65, "438569": 65, "438578e": 65, "43883": 59, "438834": 53, "4389": 65, "438960": 63, "439401e": 53, "439541": [64, 65], "439675": 69, "439699": 49, "43989": 77, "439958": 62, "43f0": 46, "44": [49, 52, 53, 55, 77, 78, 79, 80, 94], "440320": 65, "440364": 77, "440605": 78, "440747": 52, "440a": 46, "441153": 68, "441209": 68, "441219": 58, "44124313": 79, "441282": 52, "4416552": 44, "441676": 49, "441849": 52, "44301553": 80, "443016": 54, "443032": 64, "44312177": 45, "443686": 68, "4437": 65, "443701": 60, "443e": 69, "444046": 65, "4444": [42, 44, 51, 79], "444500": [64, 65], "444850": 65, "4449272": 65, "445": 69, "445476": 52, "44563945e": 80, "4461928741399595": 54, "446193": 54, "4462": 46, "44647451": 70, "44713577e": 80, "447492": 65, "447624": [52, 53], "447706": 54, "447849": 55, "448": 65, "448252": 53, "448456e": 53, "448569": 52, "448587": 54, "448745": 68, "448842": 53, "4489": 65, "44890536": 80, "448923": 60, "449107": 6, "449150": [14, 77], "44950": 65, "44fa97767be8": 46, "45": [49, 52, 53, 54, 58, 60, 62, 65, 68, 77, 78, 79, 80, 94], "4500": 64, "45000000000000007": [54, 65, 68, 78], "450031": 62, "450152": 63, "450258": 66, "450812e": 53, "450870601": 44, "451312e": 52, "452": 46, "452091": 65, "452114": 77, "452488701": 44, "452489": 63, "452623": 53, "453": 46, "453279": 52, "4535": 65, "4539": 46, "454081": 65, "454397": 68, "454406": 49, "45467447": 80, "455": 46, "45500": 65, "455078": 54, "455091": 53, "455107": 54, "455120": 68, "4552": 46, "455293": 54, "4552b8af": 46, "455448": 70, "455672": 65, "455981": 95, "456370": 63, "456458e": 52, "456552": 77, "4566031": 94, "45660310": 94, "4567": 70, "456892": 54, "457088": 68, "457667": 65, "458114": 65, "458307": 97, "458420": 65, "4584447": 44, "458784": 52, "458855": 45, "45888602": 80, "4592": 44, "459200": 63, "459383": 54, "459418": 53, "459436": 62, "45957837": 80, "459760": 65, "459812": 54, "46": [49, 52, 53, 60, 61, 66, 77, 78, 79, 80, 94, 104], "460": 65, "4601": 65, "460207": [52, 53], "460218": 54, "460289": 68, "460535": 77, "460744": 64, "4610": 110, "461227e": 52, "461629": 71, "461646": 49, "462321": 12, "462451": 54, "462567": 53, "462979": 52, "463": 41, "463325": 68, "4634": 65, "463418": 71, "463668": 65, "463766": 59, "463857": 65, "463903": 53, "463b": 46, "464": 79, "464076": 54, "464284": 63, "46448227": 80, "464668": [10, 77], "465": 49, "46507214": 70, "465424": 62, "465649": 71, "465730": 71, "4659651": 73, "465965114589023": 73, "4659651145890230": 73, "466047": 68, "46618738": 80, "466440": 54, "466756": 68, "467": 65, "46709481": 80, "46722576e": 80, "467613": 63, "467613401": 44, "467681": [52, 53], "467770": 54, "468072": 53, "468075": 68, "46807543": 68, "46811985": 68, "468120": 68, "468406": 65, "4685": 80, "468907": 49, "468919": 65, "468d": 46, "469": 46, "469474": 71, "46952141": 80, "469825": 54, "469895": 53, "469905": 53, "47": [45, 49, 52, 53, 55, 64, 70, 77, 78, 79, 80, 94, 109], "470055": 53, "470904": 52, "471": 49, "471435": 69, "471622": 52, "472": 65, "47222159": 72, "472255": 65, "472699": 53, "472891": 68, "472e": 46, "473099": 54, "47319": 79, "47419634": 107, "474214": [58, 59], "474731": 77, "475304": 65, "475517": 62, "475569": 52, "475e": 69, "476856": 54, "477130": [52, 53], "477150": 68, "477247": 53, "477357": 69, "477474": 63, "47759584": 80, "47761563": 55, "478032": 65, "478059": 53, "478064": 53, "4781": 65, "47857478": 80, "479025": 66, "479467136": 80, "479655": 62, "47966100e": 80, "479722": 53, "479860": 65, "479876": [58, 59], "479882": 53, "479928": 68, "47be": 46, "48": [46, 49, 52, 53, 59, 64, 65, 77, 78, 79, 80, 94], "480": [41, 49], "480133e": 68, "48029755": 70, "480579": 53, "48069071": [73, 81, 94], "480691": [81, 94], "480800e": 68, "481172": 68, "481218": 65, "481399": [64, 65], "481705": 79, "481761e": 65, "482": [46, 49], "482012": 58, "482038": 54, "48208358": 68, "482084": 68, "482179": 52, "482252": 66, "482461": [95, 100], "48246134": [95, 100], "482483": 68, "482616": 62, "482790": 56, "482898e": 53, "48296": 70, "483": [69, 79], "48315": 70, "483186": 56, "483192": [64, 65], "48331": 70, "4835": 65, "483711": 68, "483717": 54, "48390784": 79, "48404": 44, "484303": 53, "4845": 65, "484640": 68, "4849": 46, "485": [46, 65], "485197": 52, "48550": 71, "485617": [64, 65], "485812e": 65, "48583": [64, 65], "485871": 59, "486": [25, 65], "486178e": 52, "486202": 54, "486532": 68, "48661": 65, "487": [49, 65], "4873112": 80, "487467": 65, "487641e": 68, "487793": 53, "487872": 50, "488394": 52, "488460": 65, "488485": 65, "48873663": 55, "488811": 68, "488909": [64, 65], "488982e": 54, "4895498": 68, "489550": 68, "489699": 54, "489951": 53, "49": [46, 49, 52, 53, 77, 78, 79, 80, 94], "490": 110, "490000e": 65, "490070931": 44, "490488e": 64, "490504e": 65, "490700": 68, "490941": 65, "491034": 52, "491245": 63, "49135": 15, "4915707": 79, "4918821": 80, "492": 65, "4923156": 73, "49231564722955": 73, "492315647229550": 73, "492417e": 79, "4926130": 80, "492656": 53, "49270769e": 80, "493": [69, 79, 108], "493102e": 62, "493144": 71, "493219": 68, "493313": 65, "493325": 5, "493426": 69, "494": 69, "494089": 53, "494129": 68, "494324": 63, "494324401": 44, "495": 67, "495108": 62, "49530782": 44, "495657": 54, "495752": 68, "49596416e": 80, "496": [41, 67], "49650883": 70, "496551": 68, "496714": 71, "496777": 110, "49693": 78, "497": 67, "497168": 62, "497298": 77, "497422": 53, "497655": 6, "497674": 55, "497916": 66, "497964": 77, "498": 67, "4981471": 80, "498286": 62, "498921": 68, "498979": 65, "498992": 52, "498f": 46, "499": [65, 67, 75, 107], "499000e": [64, 65], "499749": 66, "499776": 65, "49d4": 46, "4a53": 46, "4b8f": 46, "4dba": 46, "4dd2": 46, "4e": [44, 45], "4ecd": 46, "4fee": 46, "4x": 68, "4x_0": [21, 52, 53, 58, 59], "4x_1": [21, 52, 53], "5": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 106, 107, 109], "50": [14, 44, 46, 54, 56, 59, 61, 62, 64, 65, 66, 68, 77, 78, 79, 80, 94], "500": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 22, 23, 27, 36, 42, 46, 47, 51, 52, 53, 58, 59, 61, 64, 67, 69, 70, 74, 75, 77, 78, 79, 81, 94, 95, 100, 104, 107, 110], "5000": [33, 52, 53, 54, 68], "50000": 63, "500000": [64, 65], "5000000000000001": [54, 65, 68], "500084": 68, "500251": 66, "500267": 60, "5003517412": 44, "500517": 68, "50093148e": 80, "501021": 65, "501047e": 52, "501983": 68, "502016": 62, "502084": [66, 79], "502205": 52, "502494": 54, "5025850": 44, "502595": 53, "502612": 68, "502901": 53, "502995": 68, "503": 32, "503374": 62, "503504": 78, "503511": 65, "503700": 49, "50398782e": 80, "504286": 63, "5042861": 44, "504548e": 53, "5050973": 44, "505264": 52, "505353": 53, "506050": 52, "506644": 52, "506659": 65, "506687": 65, "50672034": 44, "506900e": 68, "506903": 54, "507": 69, "50768b": 66, "50799641": 80, "508153": 67, "508433": 52, "508459": 63, "5085": 65, "508947": 79, "509059": 65, "509196": 68, "509461": 68, "50967": 71, "5097": 71, "5098": [47, 75, 107], "509853": 68, "5099": [46, 47, 75, 107], "509951": 54, "509958": 63, "51": [43, 45, 46, 58, 62, 77, 78, 79, 80, 94, 109], "510000e": [64, 65], "510121": 52, "510385": 63, "510555": 49, "51079110": 44, "511022": 77, "511257": 62, "511391": 64, "511515": 65, "511540": 65, "5115547": 73, "5115547181877": 73, "51155471818770": 73, "511665": 52, "511668": 71, "5116683753999614": 71, "511862": 68, "512": [41, 63], "512108": 68, "512149": 68, "51214922": 68, "51243406e": 80, "512519": 63, "512572": 68, "512672": [79, 95, 100], "5131": 64, "513992": 68, "514": 46, "514173": 53, "514545": 65, "515031": 52, "515338e": 52, "515358": 54, "5154": 65, "5154789948092002": 63, "5155": 46, "515672": 53, "515950": 79, "516": 46, "516125": 54, "516222": 68, "516242": 53, "516255": 68, "516256": 68, "516528": 68, "516797": 53, "516945": 49, "517": [46, 63], "517279": 53, "5175": 65, "517753": 52, "518175": 63, "518375": 53, "518446": 65, "518478": 49, "518782": 65, "518846": 63, "51966955": 44, "519710": 68, "52": [43, 46, 60, 62, 64, 69, 77, 78, 79, 80, 94], "520": 65, "520415": 52, "520641": 70, "520930": 54, "521002": 54, "521085": 77, "521233": 49, "521611": 53, "521632": 52, "5217596": 80, "521788": 52, "522753": 11, "522835": 56, "523030": 71, "523163": 54, "5232": 61, "52343523e": 80, "523794e": 68, "523807": 67, "523977545": 44, "52424539": 44, "524657": 68, "524934": [52, 53], "5250": 65, "525064": 49, "52510803": 45, "5251546891842586": 71, "5255": 46, "525722": 52, "52590": [45, 64], "526": 63, "526102": 79, "526532": 65, "526769": [52, 53], "526984": 53, "527226": 52, "52732": 78, "527452": 53, "527540": 52, "528381e": 72, "528580": 68, "528763": 53, "528937": [58, 59], "528996901": 44, "528997": 63, "529": 63, "529405": 43, "52957900": 80, "529782": 43, "53": [43, 46, 49, 64, 75, 77, 78, 79, 80, 94, 105, 108], "530793": 52, "530940": 68, "53094017": 68, "531": 46, "531223": 54, "531594": 65, "53209683": 79, "532266": 54, "53257": 78, "532738": 68, "53273833": 68, "532751": 58, "5329": 65, "533": 69, "533489": 56, "533900": 68, "5346": 46, "535179": 68, "535318": 68, "53533987": 80, "535609": 65, "535718e": 65, "53606675": 68, "536067": 68, "536082": 49, "536143": 65, "536219": 49, "536746": 68, "536778e": 53, "536798e": [64, 65], "537": 41, "537240": 68, "53724023": 68, "53791422": 79, "538": 46, "538013": 65, "538105": 53, "5382": 70, "538937": [64, 65], "539455": 68, "539475": 68, "53947541": 68, "539491": [58, 59], "53953": 80, "539767": 54, "54": [43, 45, 46, 55, 69, 74, 77, 78, 79, 80, 94, 109], "540240": 65, "540542": 64, "5408": 43, "541": 69, "541159": 68, "54163": 70, "5416844": 73, "541684435562712": 73, "541821": 65, "541990": 65, "542": 69, "542136": 52, "542159": 53, "542170": 53, "542333": 65, "542446": 59, "542451": 68, "542560": 71, "542584": 54, "5425843074324594": 54, "542647": 68, "542671": 63, "542816": 12, "542883": [95, 100], "5428834": [95, 100], "542919": 77, "542989": 68, "543": [63, 65], "543075": 54, "543136": 54, "543358": 77, "543380": 63, "5434231": 73, "543423145188043": 73, "5436005": 44, "543691": 53, "543764": 59, "54378": 70, "543832": 68, "544097": 68, "544383": 71, "544555": 63, "544669": 58, "54483": [81, 94], "5448331": [81, 94], "54517706e": 80, "545492": 49, "54550506": 69, "545605e": 68, "545919": 65, "546266": 49, "546294": 65, "5467606094959261": 54, "546761": 54, "546953": 53, "547039": 52, "5470775": 80, "54716": 70, "547324": 53, "547431": 67, "5476": 65, "5479": 65, "547909": 65, "549109e": 65, "549645": 77, "55": [41, 45, 46, 54, 64, 65, 68, 77, 78, 79, 80, 94], "5500000000000002": [54, 65, 68], "550242": 62, "55029594": 80, "551317": 53, "551586928482123": 54, "551587": 54, "551686": 54, "55176": 78, "5518": 65, "552": 65, "552058": 70, "552508": 65, "552694e": 52, "552727": 63, "552776": 68, "553004": 49, "55307": 78, "553522": 53, "553878": [13, 77], "553916": 65, "554076": 54, "554793e": 80, "555": 63, "555137": 53, "555150": 65, "555445": 67, "555498": 68, "5555": [42, 51], "555536": 52, "555949e": 65, "555954": 65, "556191": [52, 53], "556792": 68, "5574dcd4": 46, "557595": 63, "557731": 67, "557999": 63, "558134": [52, 53], "5584": 63, "5585": 63, "55863386": 79, "558655": 54, "5589": 63, "559": 110, "5590": 63, "559144": 54, "559186": 54, "5592": 63, "559394": 68, "559522": 68, "559592e": 52, "559680": 65, "55dc37e31fb1": 46, "55e": 45, "56": [41, 46, 74, 77, 78, 79, 80, 94, 105, 108], "560135": [81, 94], "56018481": 68, "560185": 68, "5602727": 55, "560530": 53, "560689": 43, "560723": 60, "561348": 53, "5616": 64, "561711": 65, "561785": 79, "562013": 68, "56223": 70, "562288": 71, "562452": 62, "562518": 65, "5625561": 43, "562712": [52, 53], "563067": 69, "563374e": 54, "563503": 68, "563528": 65, "563673": 65, "56387280e": 80, "56390147e": 80, "564045": 68, "564073": 65, "5641": 65, "564142": 54, "564232": [52, 53], "564451": 53, "564577": 65, "565": 79, "565066": 54, "565373": 52, "56555031": 80, "566": 71, "566024": 68, "566091": 65, "566388": 52, "567004": 70, "567215": 62, "567343": 65, "567364": 53, "567529": 68, "56755463": 80, "567695": 52, "567945": [58, 59], "568111": 77, "569315e": 53, "569444": 49, "569540": 53, "569590": 62, "56965663": 68, "569657": 68, "569911": 44, "5699994715": 44, "57": [46, 69, 77, 78, 79, 80, 94, 110], "570038": 54, "5700384030890744": 54, "570111": 67, "5702": 65, "570484": 80, "570486": 43, "570562": 43, "570722": 107, "570936": 52, "571707": 77, "571778": 43, "5718": 65, "572153": 77, "5722": 64, "572408e": 53, "57245066": 68, "572451": 68, "572991": 53, "573700": 56, "574": 46, "574003": 80, "5748": 78, "5749204": 80, "57496671": 44, "575": 17, "575381": 64, "57572422": 70, "575810": 52, "57585824": 70, "57592948e": 80, "57599221": 70, "575e": 69, "576": 46, "5763996": 44, "57643609": 70, "577": 46, "5770": 64, "57715074": 44, "577271": 63, "577273": 52, "577647": 49, "5776971": 70, "57775704": 70, "577807": [52, 53], "577813": 52, "577e": 69, "578081": 65, "578307": 68, "578523": 63, "578557": 53, "578846e": 54, "579125": 64, "57914935": 45, "579213": 71, "579238": 54, "579322e": 64, "579875e": 52, "57e": 45, "58": [18, 45, 64, 71, 77, 78, 79, 80, 94, 109], "5800": 65, "58000": 64, "5804": 46, "580414": 71, "580853": 52, "580922": 58, "581655": 65, "581827": 62, "581849": 53, "581896": 49, "582031": 64, "582146": 53, "58241568": 80, "582761": 54, "583034": 58, "583195": [52, 53], "583201": 53, "5833333": 46, "583534": 68, "583692": 62, "584012": 65, "584057e": 52, "584742": 59, "584849": 54, "584928": 52, "584942e": 63, "5852": 65, "585426": 80, "585793": 54, "586362": 68, "5864": 43, "5866": 65, "586719": 54, "586719493648897": 54, "586794": 52, "5868472": 44, "586921": 62, "587135": 53, "587292": 65, "5878979": 80, "588": 65, "588000": 77, "58812": 78, "588233": 52, "588364": 77, "5887": 80, "588854": 52, "589147e": 62, "589248": 70, "589440": 54, "589958": 53, "59": [53, 77, 78, 79, 80, 94], "590320": 56, "5905": 64, "590736": 68, "590813": 68, "590904": 53, "590911": 54, "590991": 54, "591080": 56, "591411": 58, "591441": 3, "591652": 64, "591678": 64, "591782": 68, "59199423e": 80, "592186": 53, "592681e": 54, "59307502e": 80, "593648": 78, "593981": 77, "594": 17, "594241": 77, "594316e": 68, "595353": 54, "596": 65, "596069e": 65, "5962": 64, "596270": [58, 59], "5964": 61, "596460": 53, "596758": 52, "597": 45, "597098": 65, "597923": 65, "598178": 65, "59854797": 79, "5985730": 45, "59861": 65, "598761e": 53, "599208": 49, "599297": 79, "5cb31a99b9cc": 46, "5d": [54, 68], "5x_2": 56, "5x_3": 56, "5z_i": 68, "6": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 24, 25, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 105, 107, 108, 109], "60": [44, 54, 55, 65, 66, 68, 72, 77, 78, 79, 80, 94, 108], "600": 63, "6000": 65, "6000000000000002": [54, 65, 68], "600000e": 65, "600195": 52, "600254": 67, "600694": 79, "600776": 49, "6008755": 80, "600934": 77, "601": [41, 45], "601061": 54, "601598": 63, "601783e": 53, "601984": 53, "602079": 59, "602168": 54, "602386e": 52, "602492": 52, "602587": 68, "602628": 54, "6029": 65, "6031013257": 80, "604016": 65, "604111": 65, "604343": 64, "604603": 6, "604825": 65, "604841": [64, 65], "605": 65, "605195": 59, "606034": 68, "606129": 68, "606342": 54, "606759": 65, "6068": 44, "606800": 63, "606954": 54, "607264": 52, "6075": 110, "607600": 65, "607900e": 53, "608": [57, 69], "608392": 68, "60857": 43, "608818": 70, "609": 69, "609522": 62, "609575": 79, "61": [77, 78, 79, 80, 94, 109], "6101822262731343645505159657173828491100": 80, "611": 110, "6110": 65, "611269": 63, "61170069": 69, "611859": 59, "612": 69, "612792": 65, "613244": 53, "6133": 45, "613314": 54, "613408": 68, "613498": 65, "613574": 60, "613622": 53, "613691": 79, "614": 69, "6140479": 80, "61404894": 79, "614188": 63, "614201": 49, "614556": 80, "614678": 65, "615": 49, "615498": 3, "615863": [58, 59], "616617": 53, "61669761": [95, 100], "616698": [95, 100], "616828": 65, "617": 63, "617283": 65, "6173": 46, "61771229": 69, "617877": 68, "618": 41, "618069": 64, "61810738": 45, "618574": 53, "618776": 55, "618881": 53, "619": 69, "619128": 53, "619351": [52, 53], "619390": [52, 53], "619454": 56, "619613": 64, "619903": 53, "61e": [45, 110], "62": [3, 59, 60, 77, 78, 79, 80, 94], "620156": 68, "620874e": 79, "620995": 72, "621": 110, "621094": [64, 65], "621318": 68, "62131806": 68, "621490": 68, "6215": 64, "621902": 49, "62191636": 80, "622": [65, 69], "622153": 65, "622272": 49, "6224": 44, "622750": 49, "623024": 54, "623173": 52, "624": 63, "6240": 70, "62403053": 55, "6243811": 44, "624535": 78, "624764": 53, "624798": 64, "624818": 53, "624919": 65, "624988": 65, "625": [44, 63], "625159": 60, "625183": 49, "625477": 68, "625766": 58, "625767": 52, "625891": [58, 59], "626433": 68, "6266": 65, "626633": 53, "627505": [58, 59], "627560": 68, "627564": 54, "6275762": 80, "627588e": 65, "628": 69, "628069": 63, "629346": 65, "629549": 53, "629595": 15, "629740": 52, "629e": 69, "63": [44, 63, 77, 78, 79, 80, 94, 108, 109], "630150e": 68, "630880": 69, "630914": 60, "631083": 53, "63117637": 79, "631333": 68, "6318": [64, 110], "632058": 63, "63245862e": 80, "632747e": 68, "632958": 67, "6330631": 94, "633433": 63, "634": [41, 69], "63407762": 110, "634078": [64, 110], "634577": 94, "63499": 65, "635": 32, "635000e": [64, 65], "635199": [64, 65], "635768": 52, "63593298": 79, "636048": 79, "636453": [10, 77], "636575": 54, "637326": 68, "6379": 64, "638264": 68, "638461": 62, "638488": 60, "639": 64, "639135": 63, "63916605": 45, "639345": 65, "639580": 53, "639603": 53, "64": [59, 64, 65, 69, 77, 78, 79, 80, 94, 107], "640": 65, "640334": 49, "640900": 65, "641528": 68, "641547": 68, "64154727": 68, "64197957": 68, "641980": 68, "642": 69, "6420": 65, "642016": 68, "642329": 49, "64269": 70, "642735": 64, "643133": 65, "64340": 70, "643512": 54, "643752": 68, "644113": 77, "644182": 77, "644371": 53, "644665": 54, "64476745e": 80, "644799": 56, "644985": 52, "645": 65, "6452968": 80, "645583": 49, "64579": 43, "6458": 44, "645800": 63, "646117": 53, "646937": 56, "647002": 65, "647004": 79, "647010": 65, "647196": 56, "64723": 70, "647254e": 52, "647689": 71, "647873": 68, "64797": 70, "648": 64, "648355": 52, "648690": 53, "648769": 53, "649": [41, 108], "649158": 68, "649514": 52, "649738": 52, "65": [54, 60, 65, 66, 68, 69, 77, 78, 79, 80, 94], "650": [57, 79], "6500000000000001": [54, 65, 68], "650000e": 65, "650234": 49, "650810": 65, "650867": 54, "65111620": 80, "651127": 53, "652071": 65, "6522": 108, "652312": 58, "652349": 68, "652350": 63, "652450e": [64, 65], "6527": 57, "652778": 63, "6528": 65, "6530": 65, "653820": 77, "653846": 54, "653901": [52, 53], "653991": 77, "654070e": 79, "654755": 56, "655284": 68, "6553": 110, "6554": 108, "655422": 65, "655547": 52, "65557405e": 80, "657": 46, "658": 63, "658267": 68, "658592": 53, "6586": 43, "658702": 53, "659": 46, "659245": [52, 53], "659339": 53, "659361": 49, "6593871": 43, "659423": [52, 53], "659473": 71, "659636": 54, "659735": 52, "659755": 69, "6598": 61, "659835": 53, "66": [49, 61, 66, 77, 78, 79, 80, 94, 107, 109], "660": [46, 79], "660073": 53, "6601633": 80, "660320": 59, "660479": 79, "6607402": 69, "660776": 68, "66133": 79, "661369": 67, "661388": 52, "661844": 66, "6625": 65, "662975": 62, "663081975281988": 54, "663082": 54, "663182": 54, "6634357241067617": 71, "663529": 68, "663533": 65, "663765": 53, "664103e": 65, "664147": 65, "664276": [77, 78], "664409": 53, "664797": 52, "664824": 65, "664850": 63, "665264": 68, "66601815": 79, "666104": 68, "666307": 56, "6666667": 46, "6667": 80, "667": 63, "667492e": 65, "667536": 68, "667614": 54, "667614205604159": 54, "667981": 52, "667985": 60, "668337": 65, "668452": 60, "668584": 56, "668981": 58, "669": 41, "669579": 53, "6698515": 80, "66989604": 55, "67": [41, 46, 64, 71, 77, 78, 79, 80, 94, 107], "670785": 49, "670867": [14, 77], "671224": 53, "671271": [52, 53], "67136": 65, "6716717587835648": 54, "671672": 54, "671690": 52, "6722": 46, "672234": [52, 53], "672368": 54, "6723684718264447": 54, "672384": [52, 53], "67245350": 44, "672511": 52, "673092": [52, 53], "673302": 63, "673330": 53, "67410934": 44, "6745349414": 44, "674552": 65, "67456": 71, "674609": 54, "674747": 62, "674949e": 70, "675233": 53, "675293": 67, "675625": 77, "675775": 62, "676405": 54, "6765": [45, 64], "676534": 94, "676641": 52, "676756": 68, "676807": 64, "677123": 52, "677614": 68, "677980": 54, "678": 69, "678117": 65, "678826": 54, "67936506": 79, "6795": 64, "679539": 63, "679789e": 52, "67ad635a": 46, "68": [46, 49, 70, 77, 78, 79, 80, 94], "680": 65, "6802164": 80, "6810775": 70, "681176": 63, "681246": 53, "681448": 65, "681521": 52, "681562": 65, "681817dcfcda": 46, "682": 79, "682122": 62, "682269": 65, "682875": 54, "683487": 53, "683581": 79, "683687": 53, "683942": 68, "683984": 11, "684": 110, "68410364": 45, "68411700": [45, 110], "684128": 53, "684142": 52, "684502": 68, "685104": 5, "685107": 68, "68554404e": 80, "68562150e": 80, "685807": 68, "686270": 53, "686627": 52, "687345": 68, "687612": 53, "687647": 68, "687697": 49, "687854": 56, "687871": 63, "6878711": 44, "688": 108, "688641": 62, "688747": 65, "688887": 79, "688918": 65, "688956": 52, "689088": [52, 53], "689188": 56, "689392": 68, "689600": 62, "689932": 52, "69": [60, 77, 78, 79, 80, 94, 109], "690": 66, "690334": 54, "6903344145051182": 54, "691097": 52, "691136": 77, "691157": 55, "69140475e": 80, "691423": 52, "691511": 64, "691848e": 53, "691911": 77, "692297": 53, "692460": 62, "692579": 53, "692725": 68, "692907": 65, "692959": 52, "693316": 65, "693497e": 65, "693690": 65, "693796": 63, "694154": 54, "694561": 69, "694845e": 65, "694919": 63, "6950": 65, "695045": 52, "69508862": 79, "695581": 60, "69562150e": 80, "695711": 62, "695928": 52, "696011": [13, 77], "696062": 66, "696289": [58, 59], "696770": 77, "69684828": 79, "696966": 53, "697": 63, "697000": 54, "697420": [58, 59], "697545": 68, "697616": 53, "697693": 52, "698223": 56, "698244": 56, "69840389e": 80, "698509": 52, "698651": 49, "698694": 63, "698751": 62, "699035": 68, "699082": 54, "69921": 46, "699259e": 68, "699333": 54, "699543": 49, "699616": 62, "699697": 53, "6_design_1a": 57, "6_r2d_0": 57, "6_r2y_0": 57, "6b": [94, 104], "6cea": 46, "7": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 19, 20, 24, 27, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 107, 108, 109], "70": [45, 54, 58, 64, 65, 68, 77, 78, 79, 80, 94, 109], "700": [52, 53, 57, 63], "7000000000000002": [54, 65, 68], "700015": 68, "70008779": 80, "700102": 68, "700458": 52, "701078": 68, "701088": 64, "701106": 60, "701265": 58, "701413": 65, "701672e": 54, "701841e": 59, "701866": 68, "7018663": 68, "701966": 65, "702489": 65, "703049": 52, "703772": 65, "703942": 77, "7040": 65, "704814": 52, "705090": 53, "705354": 52, "705581": 65, "7055958": 73, "705595810371231": 73, "7055958103712310": 73, "705794": 53, "70583": 70, "706056": 65, "706077": 53, "706122": 53, "706231": 77, "706430": 52, "706645": 54, "706657": 54, "706862": 6, "707125": 53, "707197": 77, "707441": 53, "707738": 53, "707868": 68, "707963e": 64, "708190": 63, "708235": 52, "708459": 68, "708472": 53, "708821": 49, "708837": 49, "709026": 56, "709596": 52, "709606": [14, 77], "71": [77, 78, 79, 80, 94, 109], "710059": 49, "710319": 53, "7104736": 80, "710515": 52, "710586e": 63, "711024": 65, "711328": 65, "711383e": 52, "711518": 65, "711638": 79, "712064": 52, "712082": 65, "712095": 49, "712157": 67, "712268": 52, "712372e": 53, "712503": 70, "712592": 64, "712774": 58, "712960": 54, "713": 65, "713407": 65, "713457": 52, "713986": 65, "713993": 53, "714": 66, "714240": 63, "714250": 53, "714534e": 53, "714651": 68, "71465114": 68, "715": 66, "715013": 65, "715180e": 65, "7154": 65, "715407": 54, "7155": 65, "7158581": 44, "716013e": 52, "7161": 65, "716387": 52, "716427e": 53, "716456": 68, "716595e": 65, "716762": 54, "716793": 54, "716799": 63, "7167991": 44, "716801": 62, "717": 65, "717130": 65, "717185": 68, "717860": 77, "718": 66, "718686": 71, "719552": 53, "72": [77, 78, 79, 80, 94, 109], "720559": 52, "720571": 68, "720573": 52, "720589": 69, "720664": 63, "721018": 52, "721071": 68, "721245": 53, "7215093d9089": 46, "72155839e": 80, "721609": 65, "722": 110, "722316": 68, "722634": 68, "722848": 54, "722881": 68, "7229": 65, "723": 46, "723314": 68, "723345e": 68, "723657": 52, "723846": 49, "7239": 65, "7241399": 44, "724338": 68, "724767": [58, 59], "724918": 71, "725": 46, "725061": 52, "725080": 49, "725087": 65, "725166": 68, "725565": 52, "725802": 6, "725820": 62, "725919": 52, "726": [46, 69], "726658": 62, "7268131": 44, "727159e": 53, "727543": 56, "727693": 65, "727704": 65, "727976": 54, "7282094": 79, "728294": 67, "728710": 68, "728734": 49, "72875815e": 80, "728852": 65, "728e": 69, "729867": 52, "73": [45, 49, 77, 78, 79, 80, 94], "730023": 65, "7308": 43, "730809": 52, "731174": 52, "731317": 54, "732": 69, "732067": 52, "732137": 52, "732150": 53, "732405": 64, "732586": 64, "7326": 65, "732638": 68, "73285": [10, 77], "732918": 58, "733": 65, "733047": 53, "733644": 52, "734278": 49, "734635": 52, "734770": 53, "734948": 68, "735369e": 77, "7357": 65, "735848": 77, "735941": 9, "735964": 56, "736082": [52, 53], "736084": 68, "73608412": 68, "736823": 53, "737052": 65, "7375615": 45, "73764317e": 80, "737951": [52, 53], "738065": 53, "738223": 65, "738315": 65, "738659e": 65, "738793": 77, "738876": 53, "739": 65, "739063": 52, "7395359436844482": 54, "739536": 54, "739595": 69, "739720": 65, "739817": 60, "74": [18, 45, 53, 64, 77, 78, 79, 80, 94, 109], "740": [41, 63, 64], "740180e": 68, "740367": 52, "740417": 64, "740505": 49, "740785": 52, "740869": 54, "741104": 54, "741380": 69, "741523": 49, "741702": 68, "7418": 43, "74189": 46, "742128": 68, "742375": 52, "742407": 67, "742411": 52, "742907": 68, "7432": 43, "743247": 65, "743341": 53, "743609": 52, "7437": 65, "74402577": 68, "744026": 68, "744236": 70, "74461783e": 80, "745": 65, "745022": 49, "745444": 52, "745638": 64, "745881": 52, "746361": 68, "746843": 59, "7470": 65, "747646": 65, "747945": 44, "747961": 65, "748084": 53, "748377": 64, "748513": 65, "748880": 65, "74938952": 79, "749443": 65, "749854893": 81, "75": [14, 18, 20, 46, 49, 54, 56, 64, 65, 68, 77, 78, 79, 80, 94, 104, 109], "75000": 71, "7500000000000002": [54, 65, 68], "750000e": 65, "750597": 53, "750701": 49, "751013": 65, "751261": 65, "751633": 65, "75171": 64, "751710": [54, 64], "751712655588833": 73, "7517126555888330": 73, "751712656": 73, "752015": 8, "752283": 65, "7533": 64, "753323": 52, "753393": 52, "753523": 68, "753866": 53, "754469": 52, "754499": 53, "754678": 62, "7548": 71, "754870": 63, "75551591": 80, "755527": 66, "755688": 52, "755701e": 52, "755910": 65, "7559417564883749": 54, "755942": 54, "7560824": 44, "756200": 49, "756805": 63, "756867e": 65, "756905": 6, "756969": 54, "756985636": 80, "757": [69, 108], "757151": [52, 53], "757183": 54, "757411": 68, "757819": 63, "757917e": 68, "758391": 65, "758831": 53, "75887": 46, "759006": 55, "759054": 53, "759833": 53, "76": [77, 78, 79, 80, 94, 108, 109], "760104": 68, "7603": 43, "760386": 79, "760778": 63, "760915": 56, "761": [44, 63], "761429": 53, "761714": 54, "762284": 68, "76228406": 68, "762748": 65, "763691": 65, "764093": [52, 53], "76419024e": 80, "764315": 68, "76444177e": 80, "764478": 67, "7646": 65, "764798": 68, "764953": 64, "765": 66, "765202": 65, "765363": [52, 53], "765500e": [64, 65], "765710e": 72, "765792": 68, "765864": 70, "76591188": 44, "765960": 52, "7660": 43, "7663": 65, "766499": 68, "766940": 49, "767": 41, "76702611e": 80, "767188": [58, 59], "767247": 77, "767349": 77, "767435": 71, "767549": 53, "767616": 49, "768071": 68, "768273": [58, 59], "768763": 53, "768798": 49, "769361": 68, "769805": 68, "77": [69, 77, 78, 79, 80, 94], "770556": 65, "770944": [58, 59], "7710": 70, "771157": 94, "771390e": 65, "7714": 66, "7716982": 45, "771741": 65, "771965": 65, "772104": 52, "77227783e": 80, "772396": 53, "772791": 65, "77289874e": 80, "773": 46, "773177": 54, "773488": 68, "77348822": 68, "773769": 62, "77401500e": 80, "774271e": 65, "775": [46, 65], "775191": [52, 53], "775285": 52, "775969": 70, "776254e": 52, "7763": 64, "776728e": 63, "776887": 64, "777545": 66, "7776071": 44, "777718": 62, "777728": 77, "777e": 69, "778400": 52, "7786": 43, "778852": 77, "779": 69, "779108": 52, "779167": 3, "779517": [52, 53], "779682": 54, "7799": 61, "779912": 65, "78": [69, 77, 78, 79, 80, 94, 109], "780": 46, "780068": 62, "780338": 52, "780458": 68, "780856": 64, "781": 65, "781233": 65, "781468": 66, "781530": 68, "781681": 68, "782": 46, "782050": 68, "782117": 49, "782555": 65, "782646": 77, "783": 46, "783276": 79, "7833": 43, "7838": 43, "784": [94, 104], "784238": 63, "784405": 70, "784483": 63, "784624": 54, "784792": 62, "785": 46, "785038": 53, "785153": 53, "78524467": 80, "785815": 49, "785911": 68, "785e": 32, "786": 46, "786090": 62, "786237": 52, "786563": 62, "786744": 54, "78711285e": 80, "78777": 70, "788": 108, "78818": 46, "788868": 53, "789032": 52, "789039": 53, "789330": 53, "789671": 54, "789671060840732": 54, "79": [49, 77, 78, 79, 80, 109], "790039e": 52, "790115": 65, "790261": 77, "790723": [58, 59], "791097": 64, "791241": 68, "791297": [14, 77], "792939": 54, "793316": 77, "79338596e": 80, "793570": 68, "793598": 53, "793735": 68, "793818": [52, 53], "794": 79, "794366": 65, "79458848e": 80, "794805": 58, "795": 69, "7955951": 80, "795647": 68, "7957": 65, "795932": 78, "796014": 53, "796203": 79, "796384": 53, "796444": 65, "796596e": 52, "796e": 69, "797086": 52, "797157": 49, "797280": 68, "797737": 94, "797868": 53, "79792890e": 80, "797965": 94, "798071": 5, "798308": 64, "798783": [58, 59], "799": 41, "7993425": 80, "799403": 68, "7999": 72, "7b428990": 46, "7x": 68, "8": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 107, 109, 110], "80": [54, 55, 65, 68, 72, 77, 78, 79, 80, 109], "800": 63, "8000": [29, 72], "8000000000000002": [54, 65, 68], "800143": 52, "800272": 77, "800326e": 52, "800351": 52, "801431": 66, "801623": 65, "802": 69, "802289": 65, "803112": 62, "803300": 52, "803492e": 68, "803563": 65, "803902e": 65, "804": 65, "804219": 68, "804284": 70, "804316": 68, "804484": 68, "8048": 45, "804828": 68, "804889": 65, "805": 66, "805007": 63, "805153e": [64, 65], "805293": 53, "8055563": 44, "805774": 52, "8059": 64, "806218e": 65, "806531": 65, "806554": 52, "80696592e": 80, "80714504e": 80, "807409": 66, "807879": 68, "808": [45, 94, 104], "808246": 64, "808284": 65, "808640": 65, "809125": 52, "8095": 66, "809913": [52, 53], "80a8": 46, "81": [44, 52, 57, 60, 61, 77, 78, 79, 80, 109], "810044": 64, "810134": 68, "8102": [43, 64], "810306": 49, "810322": 52, "810363": 65, "810382": [64, 65], "810419": 53, "810707": 65, "810895": 53, "811011": 53, "811155": 60, "811398": 77, "811513": 53, "8116912": [94, 104], "811696": 52, "811825": 63, "811901": 68, "81190107": 68, "812": 69, "8132463": 44, "813293": 68, "813342": [94, 104], "813682": 65, "814136": 54, "814246e": 53, "814351": 54, "814913": 63, "8152": 65, "815213e": 53, "815224": [94, 104], "815226": 79, "81568484": 68, "815685": 68, "815993": 68, "816176": 71, "816271": 66, "816318": 63, "816373": 52, "816645": 49, "816752": 65, "816982": 52, "817119": 52, "817291": 65, "8173602": 61, "817628": 79, "818": 66, "81827267": 68, "818273": 68, "818289": 68, "81828926": 68, "818313": 49, "818380": [52, 53], "81856": 46, "819507": 62, "82": [71, 77, 78, 79, 80, 109], "8202": 45, "820366": 63, "8209": 45, "820963": 49, "821": 108, "8210": 45, "821021": 54, "821457": 65, "821566": 68, "821855": 77, "821970": 62, "821995": 53, "8221": 43, "822289": [64, 110], "82228913": 110, "822482": 54, "8227": 65, "822822": 54, "823": 41, "823247": 68, "823273": [52, 53], "824350": [52, 53], "824657": 62, "824701": 54, "824750": 54, "824889": 54, "824961e": 65, "8250": 43, "825317": 66, "825587": 53, "825617": 63, "825801": 49, "825862": 68, "825980": 54, "8259803249536914": 54, "8260": 64, "826065": [52, 53], "82615647": 80, "826426": 79, "826467e": 52, "826492": 68, "826519": [14, 77], "82666866e": 80, "82684324": 70, "827375": 55, "827381": 68, "827445": 49, "827735": 68, "827938162750831": [58, 59], "828058": 65, "828157": 49, "828778e": 52, "828912": 52, "828915": [58, 59], "829162": 77, "829543": 54, "829730e": 53, "82985": 60, "83": [77, 78, 79, 80, 109], "830263": 62, "830301": 67, "830442": 52, "830467": 52, "830755e": 60, "831": 69, "831019": 54, "831190": 53, "831278": 52, "831741": 52, "832078": 49, "832086": 68, "8326928": 70, "832693": 70, "832875": 68, "83287529": 68, "833024": 63, "833227e": 78, "833464": 65, "833907": 63, "835": 69, "8350": 65, "835035": 62, "835596": 65, "835822": 49, "835935": 53, "836234": 79, "838": 66, "838114": 68, "838235": 66, "838457": 65, "839": 66, "83905": 5, "84": [46, 60, 69, 77, 78, 79, 80, 109], "840041": 65, "840303": 68, "84030318": 68, "840673": 52, "840718": 79, "840836": 68, "840995e": 64, "841": [44, 63], "841048084": 80, "841132": 64, "8415": 45, "841847": 65, "842132": 79, "842405": 54, "842589": 49, "842625": 63, "842746": 68, "8428": 64, "842853": 68, "843730": 63, "843796": 52, "8440": 65, "844107e": 53, "844308": 68, "844549": [58, 59], "844667": 94, "844707": 68, "844889": 63, "845241": 69, "845534": 62, "846388": 54, "847029": 53, "847555": 52, "847595": [13, 77], "847948": 54, "847962": 52, "847966": 65, "848": 41, "848688e": 62, "848757e": 64, "848868": 54, "849245": 49, "84930915e": 80, "849747": 70, "8497f641": 46, "8499": 65, "85": [23, 54, 60, 65, 68, 72, 77, 78, 79, 80], "8500000000000002": [54, 65, 68], "850038": 49, "850321": 63, "850439": 53, "850575": [52, 53], "850794": 68, "851": 108, "851198": 65, "8513": 46, "851366": 63, "852": 65, "85265193": 61, "85280376": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "85397773": 79, "855035": 52, "855780": 68, "855862": 53, "856404": 59, "8571": 43, "857161": 68, "857294": 49, "857544": 63, "857765": 65, "858212e": 53, "859": 65, "85911521e": 80, "85912862": 94, "859129": [81, 94], "85974356": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "85c5": 46, "85e": 45, "86": [77, 78, 79, 80, 109], "860663": [94, 104], "860804": 68, "860992": 65, "861519": 52, "862043": [58, 59], "862359": 54, "863772": 64, "863982270": 81, "864": 69, "86415573": 45, "86424193e": 80, "8644": 46, "864741e": 65, "865074": 49, "865313": 65, "865562": [52, 53], "865854": 65, "865860": [64, 65], "865914": 53, "866102": [52, 53], "866179899731091": 73, "866179900": 73, "866579": 65, "866798": 65, "867201": 62, "867565": 68, "8679": 65, "868": 46, "8685788": 68, "868579": 68, "8688": 64, "869": [46, 69], "869020": 54, "869195": 53, "869398": 53, "869477": 52, "869586": 60, "87": [45, 52, 60, 63, 77, 78, 79, 80, 109], "8700": 45, "870099": [58, 59], "870142": 79, "870260": 68, "870332": 68, "870857": 68, "871": 46, "871545e": 52, "871923": 53, "872": 69, "872132": 53, "872222": 65, "872727": 52, "872768": 68, "872852": 68, "87290240e": 80, "872994": 65, "873198": 65, "873677": [58, 59], "87384812361": 43, "87384812362": 43, "87430335": [94, 104], "874303353": [94, 104], "874702": [58, 59], "8750": 65, "8759": 65, "876": 69, "876083": 65, "87623301": 43, "876431e": 54, "876549": 65, "87674597e": 80, "8768": 43, "8771": 65, "877153": 65, "877455": 67, "877833": [52, 53], "878281": 68, "878289": 65, "878402": 52, "878746": 49, "878847e": 65, "878968e": 52, "879": 79, "879049": 65, "879058": 62, "879103": 54, "879509": 52, "87e": 45, "88": [45, 60, 69, 77, 79, 80], "880106": 63, "880579": 68, "880591": 67, "880808e": 65, "880880e": 65, "880886": 64, "8810": 64, "881201": 65, "88125046e": 80, "881465": 56, "881581": 9, "88173062": 44, "8817374": 80, "881937": 49, "882475": 54, "883485": 53, "883622": 68, "883914": 54, "883953": 62, "884132": 68, "8843": 70, "88435598": 80, "8845": 43, "884996": 54, "8850": 45, "885065": 68, "885832": 69, "885956": 52, "885978": [58, 59], "886041": 53, "886086": [52, 53], "886266": 65, "88629": 43, "886314": 53, "88664": 46, "887197": 49, "887345": 65, "887556": 54, "887648": 53, "887680": 52, "888146": 63, "8881461": 44, "8884225464": 80, "888445": 53, "888775": 59, "888804": 65, "889293": 68, "889309": 64, "889326": 53, "889638": 49, "889733": 68, "889792": 53, "88988263e": 80, "889913": [52, 53], "889963": 68, "88ad": 46, "89": [45, 53, 77, 79, 80, 108, 109], "890": [44, 63], "890229": 49, "89027368": [94, 104], "890273683": [94, 104], "890318": 52, "89035917": 60, "890372": [47, 75, 107], "8903720000100010000010": [46, 75, 107], "8904": 41, "890454": 78, "8909": [44, 64, 110], "891606": 64, "891752": 53, "891997": 52, "892": 46, "892648": 68, "892796": [52, 53], "893": 46, "8932105": 44, "893649": [52, 53], "893851": 68, "894": 46, "894307e": 65, "894448": 53, "89449": 64, "894490": 64, "895106": [52, 53], "895308": 65, "895333": 68, "895690": [52, 53], "895768e": 54, "896023": 68, "89700664": 80, "897220": 68, "897240": 65, "8974": 64, "897451": 52, "897495e": 53, "898722": 68, "899460": 68, "899662e": 52, "899716": 53, "8bdee1a1d83d": 46, "8da924c": 46, "8e3aa840": 46, "9": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 106, 107, 109, 110], "90": [25, 45, 54, 55, 65, 68, 72, 77, 79, 80, 109], "9000000000000002": [54, 65, 68], "900000e": 65, "900021": 78, "901013": 53, "901148": 68, "90136": 64, "901360": 64, "901526": 60, "901683": 65, "901705": 52, "902": [66, 94, 104], "902573": 54, "903056e": 68, "903135": 77, "903339": 54, "903351e": 54, "903406": 79, "903418": 63, "903674": 52, "903681": 68, "903767": [52, 53], "904156": 54, "9041560442482157": 54, "904315": 52, "904396": 52, "905": 66, "905042": 53, "905494": 54, "905858": 71, "905951": 70, "9061": 65, "906716732639898": [58, 59], "906757": 50, "907115": 68, "907176": 68, "9073": 65, "907491": 54, "907801": 63, "90794478": [94, 104], "907944783": [94, 104], "907961": 65, "908024": 71, "908663": 53, "908767": 62, "909304": [52, 53], "90963122e": 80, "909942e": 77, "909975": 65, "909997": [64, 110], "91": [77, 79, 80, 109], "910000e": 65, "9102": 64, "910321377": 80, "910895": 53, "9109": 46, "91102953": 68, "911030": 68, "911277": 53, "911662": 58, "912230": [52, 53], "9126": [45, 110], "9127": [45, 110], "912903": 52, "913": 46, "91315015": 44, "913280": 71, "913371": 53, "913415e": 52, "913485": 65, "913774": 54, "9142": 65, "91438767e": 80, "9145": 43, "915": [45, 46, 64, 65], "915000e": [64, 65], "915057e": 64, "915260e": 52, "915488": [58, 59], "9158080176561963": 62, "916236": 43, "916528": 58, "9166667": 46, "916914": 68, "916930": 52, "917": 46, "917000": 53, "917066": 65, "917248": 68, "91724807": 68, "917436": 68, "918": 69, "918227": 54, "919432": 68, "9197": 65, "919969": 52, "91e": 45, "92": [77, 78, 79, 80, 109], "920052": 53, "920335": 65, "920337": 59, "920645": 65, "9209": 43, "9210": 65, "921061": 71, "921256e": 53, "921372": 54, "921913": 63, "921956": [52, 53], "921e4f0d": 46, "922160": 65, "922251": 52, "9223": 65, "922996": 63, "923074e": 54, "923517": 72, "923607": 68, "92369755": 44, "923804": 54, "923943": 110, "923977": 65, "924002": 68, "9243": 65, "924396": [58, 59], "92463": 64, "924630": 64, "924634": 56, "9248": 46, "924821": 54, "924843": 63, "924921": 77, "925": 55, "925248": [58, 59], "925660": 52, "925736": 54, "925957": 58, "925995": 53, "926227": 53, "926493": 64, "926621": 54, "926901": 62, "927": [42, 66], "927074": 68, "927232": 65, "9274": 65, "927950": 65, "92827999": 79, "92881435e": 80, "928947": 63, "92905": 44, "929643": 52, "92972925e": 94, "929729e": [81, 94], "93": [45, 77, 78, 79, 80, 109], "9304028": 44, "931": 74, "931479": 68, "931978": 107, "932027": 54, "932404e": 65, "9325": 43, "9327": 43, "932973": 68, "933259": 49, "933322": 53, "933671": 53, "933857": 53, "933996": 54, "934058": 52, "934068": 49, "934243": 53, "934433": [52, 53], "9345": 46, "934500": 53, "934511": [94, 104], "934549": 65, "93458": 70, "934963": 53, "934992": 54, "935": [32, 41, 61, 79], "935591": 68, "935730": 68, "935764": 53, "935989": 63, "9359891": 44, "93648": 72, "936494": 52, "936739": 68, "937116": 63, "937586": 65, "938": [94, 104], "938975": [77, 78], "939068": [58, 59], "9392": 65, "939250": 52, "939458": 52, "9395": 65, "93958082416": 110, "94": [55, 61, 77, 79, 80, 109, 110], "940354721701296": 54, "940355": 54, "940373": 65, "940450": 49, "941440": 52, "941724": 65, "941788": 58, "942139": 59, "942312": 68, "942460e": 68, "942489": 65, "9425": 43, "942550": 65, "942661": 63, "942823": 65, "94309994e": 80, "943938": 68, "943949e": 68, "944149": 77, "944253e": 68, "944266": [58, 59], "944280": 65, "94441007e": 80, "944839": 49, "945881": 52, "94629": 72, "946297": 54, "946406": 59, "946433": 68, "946533": 52, "946658": 65, "946968": 54, "947440": 67, "947466": 78, "947613": 53, "9480": 65, "948112": 69, "948154e": 58, "948785e": 52, "948868": 65, "94906344": 44, "949241": [94, 104], "949456": 68, "949866": 53, "95": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 36, 43, 45, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 68, 69, 70, 71, 72, 77, 79, 80, 94, 95, 100, 109, 110], "9500": 65, "950158": 52, "950545": 50, "95062986e": 80, "951502": 68, "951532": 63, "951920": 67, "952": [45, 69, 110], "9523": 43, "952839": 68, "9534": 65, "953683": 63, "953704": 52, "95372559e": 80, "954": [94, 104], "95401167e": 80, "954536": 77, "955005e": 65, "9551": 65, "9552": 43, "955541": [14, 77], "95559917": 78, "955701": 52, "955e": 79, "956047": 44, "9561": 43, "956574": 65, "956724": 54, "9567242535070148": 54, "956877": 53, "956892": 65, "957229": 59, "957375": 63, "957745": 54, "9579": 45, "957996": 54, "958": [94, 104], "9580": 45, "958105": 77, "958541": 65, "959132": 53, "959384": 53, "95e": 45, "96": [45, 52, 53, 66, 77, 79, 80, 109], "960": 41, "9605": 65, "960808": 54, "960834": 53, "9609": 43, "961539": 65, "961962": 54, "962364": 49, "962373": 53, "962523": 49, "962954": 53, "963055": 65, "963427e": 53, "964025e": 68, "964065e": 53, "964261e": 63, "964318": 65, "9647": 43, "965341": 53, "965531": 79, "965696": 52, "965774": 65, "96582": 78, "966015": 68, "966097": 15, "966320": 49, "966659": 54, "9666592590622916": 54, "967092": 53, "967467": 70, "968127": 49, "968134e": 68, "968258e": 52, "968577": 55, "969141": 79, "9699": 64, "969925e": 53, "96e": 80, "97": [3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 47, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 77, 78, 79, 80, 81, 94, 104, 107, 109, 110], "970065": 68, "970150": 53, "971058": [58, 59], "972509": 53, "972745": 52, "972748": 54, "97276281": 68, "972763": 68, "97314470": 44, "973156": 77, "973229": 53, "973241": 68, "973331": 65, "973741": 53, "973890": 53, "974": 66, "974202": 54, "974213": 53, "97441062": [58, 59], "974414": 54, "974487": 52, "97470872": 70, "9748910611": 44, "975": [52, 53, 58, 59, 61, 66], "975289": 49, "9753": 46, "975447": 55, "975450": 53, "975461": 63, "975592": 49, "976088": 68, "976548e": 53, "976562": 68, "977": 66, "977202": 53, "977280": [52, 53], "977295": 65, "977507": 53, "977820": 52, "978303": 62, "9787": 65, "978977": 68, "978997": 49, "979": 69, "979475": 52, "979702": 52, "979857": 52, "979971e": 52, "98": [52, 53, 65, 77, 79, 80, 109], "980026": 65, "9802393": 44, "980440": 53, "980643e": 54, "981104": 67, "981403": 53, "981438": 52, "981672": 54, "981715": 52, "982019e": 53, "982353e": 65, "982417": 54, "982720": 52, "982797": 67, "983192": 68, "983253": 52, "983759": 110, "98393441": 70, "984024": 67, "984083": [58, 59], "984551": 8, "984562": 68, "984866": [94, 104], "984872": [52, 53], "984937": 54, "98505871e": 80, "985207": [52, 53], "985654": 53, "986383": 65, "986417": 52, "987": 66, "9870004": 46, "987220": 65, "987307": 62, "9875": 43, "987726": 53, "9880384": 46, "988421": [52, 53], "988463": 68, "988541": 52, "988709": 65, "988780": 65, "989": [41, 66], "989428": 66, "99": [45, 49, 52, 53, 66, 77, 79, 80, 109], "990210": 65, "990330": 66, "990903": 52, "991": [46, 66], "9914": [64, 65, 70], "991444e": 58, "9915": [45, 64, 65, 70], "991512": 45, "991963": [52, 53], "991977": 65, "991988": 52, "992": [66, 69], "99232145": 70, "992582": [52, 53], "993201": 53, "993575": 65, "994": 69, "994168239": 44, "994208": 49, "994214": 65, "994332": 50, "994377": 52, "9944": [61, 79], "994851": 65, "994937": 59, "995": 66, "995015": 65, "9951": 43, "995248": 68, "99549118e": 80, "99571372e": 80, "9961392": 44, "996313": 52, "996892": 62, "996934": 63, "9970": 65, "997034": 72, "997494": 72, "997571": 63, "997621": 54, "997934": [58, 59], "998": 110, "998063": 50, "99864670889": 110, "998766": 65, "9989": 64, "999": [55, 56, 60, 70, 110], "999207": 68, "9995": [52, 53, 56], "9996": [52, 53, 56], "9996553": 45, "9997": [52, 53, 56], "9998": [52, 53, 56], "9999": [52, 53, 56], "99c8": 46, "9e": 80, "A": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 23, 24, 28, 32, 34, 35, 36, 38, 39, 41, 42, 43, 45, 46, 50, 51, 57, 59, 66, 67, 69, 70, 71, 74, 75, 77, 78, 79, 94, 95, 96, 97, 101, 102, 103, 104, 105, 107, 108, 110], "ATE": [9, 15, 18, 45, 47, 49, 64, 70, 71, 77, 79, 81, 87, 95, 101], "ATEs": [49, 66], "And": [66, 72, 95, 98], "As": [42, 43, 44, 45, 46, 49, 51, 52, 53, 54, 55, 57, 60, 61, 62, 63, 64, 65, 66, 68, 71, 72, 73, 78, 79, 80, 81, 83, 94, 95, 97, 103, 104, 110], "At": [18, 19, 20, 44, 49, 55, 56, 60, 61, 63, 65, 68, 110], "Being": 110, "But": 61, "By": [43, 44, 63, 69, 71, 78, 79, 95, 100], "For": [1, 5, 6, 8, 9, 12, 20, 30, 31, 39, 41, 43, 44, 46, 49, 50, 55, 60, 61, 62, 63, 65, 67, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 101, 103, 104, 106, 107, 110], "ITE": [24, 49], "ITEs": 49, "If": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 38, 39, 42, 44, 51, 52, 53, 55, 61, 63, 65, 69, 74, 75, 77, 78, 79, 81, 82, 84, 85, 87, 94, 95, 97, 98, 99, 100, 102, 103, 105, 110], "In": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110], "It": [43, 44, 45, 52, 53, 57, 58, 59, 63, 64, 65, 69, 71, 78, 80, 105, 109], "No": [22, 41, 43, 45, 46, 47, 49, 55, 60, 64, 65, 69, 70, 72, 75, 78, 79, 81, 94, 107, 108], "Of": [61, 94, 110], "On": [42, 51, 62, 66, 74, 108], "One": [45, 64, 65, 71, 77, 94], "Or": 32, "Such": [71, 78], "That": [32, 110], "The": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 41, 42, 43, 44, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 87, 90, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 108, 109, 110], "Then": [20, 54, 68, 79, 94, 95, 103, 104, 105, 106], "There": [45, 64, 71, 79, 106, 110], "These": [45, 46, 48, 62, 64, 67, 69, 70, 77, 79, 110], "To": [31, 41, 42, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 58, 59, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 74, 75, 77, 78, 79, 80, 94, 95, 97, 100, 103, 104, 106, 107, 110], "With": [23, 52, 53, 78, 108], "_": [42, 44, 51, 52, 53, 54, 56, 57, 58, 59, 63, 64, 65, 67, 68, 69, 73, 74, 77, 79, 80, 81, 94, 95, 97, 100, 104], "_0": [42, 44, 51, 57, 63, 73, 74, 80, 81, 89, 90, 94, 95, 103], "_1": [18, 19, 20, 24, 66, 72, 81, 89, 90], "_2": [18, 19, 20, 24, 66], "_3": [18, 19, 20, 24], "_4": [18, 19, 20, 24], "_5": [18, 24], "__": [38, 39], "__init__": 62, "__version__": 106, "_all_coef": 80, "_all_s": 80, "_compute_scor": 31, "_compute_score_deriv": 31, "_coordinate_desc": 63, "_d": [69, 79], "_est_causal_pars_and_s": 109, "_estimator_typ": 62, "_h": [69, 79], "_i": [42, 51, 68, 72, 74], "_id": 80, "_j": [18, 19, 20, 24, 26, 44, 63, 94, 104], "_l": 78, "_m": [78, 80], "_n": [81, 84, 85, 87, 94, 95, 100, 102, 104], "_n_folds_per_clust": 63, "_rmse": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "_x": 33, "_y": [69, 79], "a0": 62, "a09a": 46, "a09b": 46, "a1": 62, "a3d9": 46, "a4a147": 66, "a5e6": 46, "a5e7": 46, "a6ba": 46, "a79359d2da46": 46, "a840": 46, "a_": 72, "a_0": 27, "a_1": 27, "a_j": 79, "ab": [43, 105], "ab71": 46, "abadi": [16, 55], "abb0fd28": 46, "abdt": [47, 75, 107], "abl": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 42, 51, 61, 65, 66, 78, 95, 97, 103], "about": [45, 61, 64, 79, 105, 107, 110], "abov": [42, 45, 49, 51, 52, 53, 58, 59, 61, 62, 64, 66, 67, 68, 69, 71, 74, 77, 78, 79, 106], "absolut": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 61, 78], "abstract": [31, 43, 44, 63, 81, 105, 109], "acc": [2, 43], "accept": [77, 78], "access": [34, 35, 43, 45, 58, 59, 60, 61, 70, 78, 95, 100, 110], "accord": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 42, 45, 49, 51, 54, 55, 64, 68, 69, 71, 72, 78, 79, 94, 95, 96, 98, 99, 101, 104, 110], "accordingli": [55, 61, 62, 64, 69, 72], "account": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 44, 45, 63, 64, 65, 70, 71, 95, 100, 103, 110], "accumul": [45, 64, 65, 70], "accuraci": [38, 43, 79], "acemoglu": 108, "achiev": [44, 63, 67, 71, 79, 94, 104], "acic_2024_post": 66, "acknowledg": [45, 46, 64], "acm": 108, "acov": 108, "across": [45, 64, 66, 110], "action": 109, "activ": [4, 7, 106, 109], "actual": [32, 60, 71], "acycl": [72, 110], "ad": [4, 7, 16, 17, 31, 38, 39, 60, 75, 78, 79, 94, 95, 97, 109], "adapt": [8, 64, 109], "add": [43, 44, 47, 49, 55, 56, 58, 59, 60, 66, 68, 69, 70, 71, 72, 78, 79, 108, 109], "add_trac": 71, "addit": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 20, 24, 26, 27, 28, 33, 36, 57, 71, 78, 79, 81, 88, 95, 96, 101, 103, 108, 109], "addition": [18, 19, 49, 54, 65, 70, 78, 79, 80, 94, 95, 100, 107], "address": 71, "adel": 108, "adj": [69, 71], "adj_coef_bench": 71, "adj_est": 71, "adj_vanderweelearah": 71, "adjust": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 37, 44, 56, 63, 65, 70, 71, 77, 79, 94, 95, 100, 104, 108, 109, 110], "adopt": [55, 79], "advanc": [62, 76, 80, 108], "advantag": [42, 43, 45, 49, 51, 64, 65, 74, 106], "advers": [95, 97], "adversari": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 70, 95, 100, 103], "ae": [42, 44, 45], "ae56": 46, "ae89": 46, "aesthet": 42, "aeturrel": 28, "afd9e4": 66, "affect": [49, 57, 79, 109, 110], "after": [43, 45, 46, 55, 57, 64, 65, 71, 72, 77, 78, 95, 98, 100, 106, 110], "after_stat": 42, "ag": [45, 64, 65, 67, 70, 110], "again": [42, 43, 44, 45, 49, 51, 55, 60, 62, 63, 64, 69, 70, 71, 72, 74, 95, 98], "against": [55, 60, 61, 67, 78], "agebra": 77, "agegt54": [46, 47, 75, 107], "agelt35": [46, 47, 75, 107], "agg": 43, "aggreg": [43, 73, 80, 109], "aggregate_over_split": 32, "aggt": 43, "aim": 69, "aipw": 66, "aipw_est_1": 66, "aipw_est_2": 66, "aipw_obj_1": 66, "aipw_obj_2": 66, "air": [44, 63], "al": [16, 17, 21, 23, 26, 27, 42, 44, 45, 46, 51, 52, 53, 54, 55, 57, 58, 59, 61, 63, 64, 65, 68, 70, 74, 79, 80, 81, 83, 88, 93, 94, 95, 97, 103, 104, 105, 107, 109], "alexandr": [57, 108], "algebra": 79, "algorithm": [41, 43, 44, 46, 49, 51, 54, 55, 61, 63, 65, 68, 70, 72, 76, 78, 79, 80, 81, 94, 109, 110], "alia": [38, 39], "align": [42, 44, 51, 54, 56, 61, 63, 64, 66, 67, 68, 72, 109], "all": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 38, 39, 40, 42, 43, 44, 45, 49, 51, 55, 60, 61, 62, 63, 64, 65, 67, 69, 71, 72, 74, 75, 77, 78, 79, 80, 94, 95, 103, 104, 105, 106, 109], "all_coef": 80, "all_dml1_coef": 73, "all_s": 80, "all_smpl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "all_smpls_clust": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "all_z_col": [44, 63], "allow": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 31, 38, 39, 45, 49, 64, 65, 69, 77, 78, 79, 80, 81, 94, 104, 105, 109, 110], "almqvist": 108, "along": 78, "alpha": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 25, 27, 42, 44, 45, 47, 49, 51, 52, 53, 54, 57, 61, 62, 63, 64, 65, 68, 73, 74, 77, 78, 79, 80, 81, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104], "alpha_": [26, 44, 63, 78], "alpha_0": [95, 103], "alpha_ml_l": 57, "alpha_ml_m": 57, "alpha_x": [8, 22, 79], "alreadi": [20, 55, 72, 78, 79], "also": [1, 5, 6, 8, 9, 12, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 62, 63, 64, 65, 67, 69, 70, 71, 74, 77, 78, 79, 80, 81, 94, 95, 97, 106, 107, 109, 110], "alter": [44, 63], "altern": [43, 45, 46, 64, 67, 76, 78, 94, 104, 105, 107], "although": 71, "alwai": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 39, 43, 69, 109], "always_tak": [8, 45, 64], "amamb": 63, "american": [25, 66], "amgrem": 63, "amhorn": 63, "amit": [71, 108], "amjavl": 63, "ammata": 63, "among": [45, 57, 64, 65, 70, 71], "amount": [45, 62, 64, 65, 110], "amp": [41, 44, 46, 55, 63, 65, 70, 72], "an": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 24, 34, 35, 38, 39, 42, 43, 44, 45, 46, 49, 51, 52, 53, 57, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 94, 95, 97, 100, 104, 105, 107, 108, 109, 110], "analog": [30, 31, 44, 63, 65, 70, 77, 79, 81, 84, 85, 94, 95, 100, 104], "analys": 110, "analysi": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 33, 42, 44, 45, 51, 63, 64, 65, 74, 76, 77, 97, 100, 103, 105, 109], "analyt": [66, 68], "analyz": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 45, 64, 65, 70, 110], "ancillari": 71, "andrea": 108, "angl": 45, "angrist": 66, "ani": [41, 42, 43, 46, 50, 51, 55, 71, 72, 74, 79, 106, 110], "anna": [5, 6, 18, 19, 20, 24, 43, 55, 79, 108], "annal": [94, 104, 108], "anneal": 78, "annot": 42, "annual": 108, "anoth": [42, 43, 44, 45, 51, 61, 62, 63, 74, 78, 79], "anticip": 43, "anymor": [44, 63], "aos1161": [94, 104], "aos1230": [94, 104], "aos1671": [94, 104], "ap": [45, 64], "ape_e401_uncond": 45, "ape_p401_uncond": 45, "api": [75, 105, 109], "apo": [1, 2, 82, 96], "apoorva": 109, "apoorva__l": 66, "apoorval": 66, "app": 109, "appeal": 71, "append": [51, 61, 74], "appendix": [23, 29, 70, 72, 95, 97], "appli": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 41, 42, 44, 45, 46, 51, 55, 56, 61, 63, 64, 65, 69, 71, 72, 74, 79, 80, 81, 94, 104, 105, 107, 109, 110], "applic": [42, 51, 55, 66, 71, 74, 77, 80, 108, 110], "apply_along_axi": 67, "apply_cross_fit": [42, 80], "apply_crossfit": 109, "appreci": 105, "approach": [1, 3, 5, 6, 8, 9, 10, 13, 14, 15, 43, 44, 49, 63, 69, 70, 71, 76, 78, 80, 94, 95, 97, 104, 106, 108, 110], "appropri": [45, 57, 64, 79, 80, 110], "approx": 77, "approxim": [42, 51, 52, 53, 54, 61, 68, 71, 74, 77, 79, 94, 104, 109, 110], "apt": 106, "ar": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 48, 49, 51, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 110], "arang": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 51, 54, 56, 65, 67, 68, 70, 71, 78], "arbitrarili": 39, "architectur": [81, 108], "arellano": 108, "arg": [62, 69, 77, 79], "argmin": 61, "argu": [42, 45, 51, 64, 65, 70, 74, 110], "argument": [1, 9, 12, 20, 26, 27, 28, 32, 33, 36, 45, 52, 53, 55, 60, 61, 64, 65, 73, 77, 78, 79, 109, 110], "aris": [42, 43, 44, 51, 63, 71, 74, 110], "aronow": 66, "around": [43, 45, 64, 65, 69, 79, 81], "arr": 67, "arrai": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 22, 23, 25, 26, 27, 28, 29, 36, 37, 38, 39, 49, 51, 52, 53, 54, 55, 61, 63, 66, 67, 70, 71, 72, 73, 74, 76, 77, 78, 80, 94, 95, 100, 104, 107, 109, 110], "arrang": 44, "array_lik": 14, "articl": [28, 105], "arxiv": [26, 43, 44, 63, 71, 105, 108, 109], "as_learn": [46, 78], "asarrai": [52, 53], "aspect": [45, 64, 65], "assert": 78, "assess": 43, "asset": [65, 70, 110], "assign": [4, 7, 45, 59, 64, 69, 77, 78, 79, 110], "assmput": 79, "associ": [45, 57, 64, 79, 94, 104, 108], "assum": [41, 44, 50, 55, 63, 66, 67, 71, 79, 81, 84, 85, 94, 95, 103, 110], "assumpt": [43, 44, 45, 55, 56, 61, 63, 64, 66, 69, 72, 79, 94, 110], "assur": 109, "astyp": [50, 69, 71], "asymptot": [30, 31, 42, 44, 51, 63, 74, 80, 94, 108], "ate": 49, "ate_estim": 72, "ates": 49, "athei": 108, "att": [9, 18, 43, 56, 60, 67, 71, 77, 79, 81, 87, 95, 101, 109], "att_gt": 43, "attach": 43, "atte_estim": 55, "attempt": [34, 35], "attenu": [45, 64], "attr": 45, "attribut": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 32, 36, 37, 38, 39, 61, 62, 73, 78, 80, 81, 94], "attributeerror": [34, 35], "attrict": 79, "attrit": [15, 72, 79], "au": [46, 78, 105, 107], "auc": 43, "author": [43, 71, 105], "auto_ml": 62, "autodoubleml": 62, "autom": 62, "automat": [42, 51, 60, 74, 77, 95, 100], "automl": 109, "automl_l": 62, "automl_l_lesstim": 62, "automl_m": 62, "automl_m_lesstim": 62, "automobil": [44, 63], "autos": 57, "autosklearn": 62, "auxiliari": [42, 51, 74], "avail": [22, 43, 45, 46, 49, 55, 57, 61, 64, 65, 66, 67, 69, 71, 74, 77, 78, 79, 95, 103, 105, 106, 109, 110], "avaiv": 37, "aver": 49, "averag": [1, 2, 8, 9, 12, 18, 19, 20, 41, 43, 46, 50, 55, 56, 60, 65, 66, 67, 69, 70, 71, 72, 76, 82, 87, 94, 96, 101, 108, 109, 110], "average_it": 49, "avoid": [42, 43, 51, 69, 79, 80, 106, 109], "awai": 70, "ax": [49, 51, 52, 53, 54, 56, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69], "ax1": [49, 54, 65, 68], "ax2": [49, 54, 65, 68], "axhlin": [56, 62, 69], "axi": [44, 45, 49, 57, 61, 63, 64, 66, 67, 69], "axvlin": [49, 51], "b": [5, 6, 28, 42, 44, 46, 51, 52, 53, 63, 66, 68, 69, 71, 74, 77, 78, 94, 95, 103, 104, 105, 107, 108], "b208": 46, "b371": 46, "b5d34a6f42b": 46, "b5d7": 46, "b_": 79, "b_0": 27, "b_1": 27, "b_j": 28, "bach": [71, 105, 108, 109], "backbon": 61, "backend": [4, 7, 43, 65, 70, 71, 76, 109], "backward": 109, "bad": 66, "balanc": [45, 64, 65], "band": [43, 76, 110], "bandwidth": [10, 13, 14, 32, 69, 79], "bar": [60, 62, 64, 77, 79, 81, 82, 87, 95, 96], "base": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 21, 24, 33, 37, 42, 43, 44, 45, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 94, 95, 97, 100, 104, 105, 107, 108, 109, 110], "base_estim": [38, 39, 69], "baselin": [24, 45, 62, 64], "basi": [1, 9, 12, 36, 52, 53, 77], "basic": [43, 44, 45, 55, 63, 64, 65, 66, 69, 70, 71, 76, 78], "batch": 46, "battocchi": 108, "bay": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 94, 104], "bb2913dc": 46, "bbotk": [46, 78, 109], "bbox_inch": 51, "bbox_to_anchor": 51, "bcallaway11": 43, "bd929a9e": 46, "bde4": 46, "becam": [45, 64, 65], "becaus": [39, 41, 42, 43, 44, 50, 51, 59, 60, 63, 66, 71, 74, 110], "becker": [46, 78], "becom": [44, 59, 62, 63, 77, 80], "bee": 56, "been": [44, 45, 62, 63, 64, 65, 70, 71, 77, 78, 109], "befor": [43, 45, 49, 56, 60, 64, 68, 71, 79, 110], "begin": [22, 25, 26, 42, 44, 45, 46, 51, 54, 56, 61, 63, 64, 66, 67, 68, 72, 73, 75, 78, 80, 94, 104, 107, 110], "behav": 59, "behavior": [45, 66, 78], "behaviour": 59, "behind": 79, "being": [24, 29, 30, 31, 33, 38, 39, 44, 63, 69, 71, 79, 80, 81, 83, 94, 95, 100, 104, 105], "belloni": [23, 57, 94, 104, 108], "below": [41, 45, 50, 64, 66, 79, 106, 107], "bench_x1": 71, "bench_x2": 71, "benchmark": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 49, 60, 97, 109], "benchmark_dict": [40, 70], "benchmark_inc": 70, "benchmark_pira": 70, "benchmark_result": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "benchmark_twoearn": 70, "benchmarking_set": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 49, 60, 70, 71, 95, 97], "benchmarking_vari": 60, "benefit": [42, 45, 51, 64, 74], "bernoulli": 22, "berri": [44, 63], "besid": 107, "best": [1, 9, 12, 36, 39, 52, 53, 58, 59, 62, 106], "best_loss": 62, "beta": [15, 22, 23, 25, 29, 45, 64, 67, 69, 72, 79], "beta_": 72, "beta_0": [21, 67, 72, 77], "beta_a": [18, 19, 71], "beta_j": [22, 23, 25, 29], "better": [43, 49, 61, 71], "between": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 41, 49, 50, 54, 56, 57, 62, 66, 68, 70, 71, 72, 79, 81, 84, 85, 87, 91, 92, 94, 95, 103, 104, 107, 109], "betwen": [41, 50], "beyond": 108, "bia": [29, 41, 50, 57, 69, 71, 72, 76, 79, 80, 81, 89, 90, 95, 103, 108, 109], "bias": [41, 45, 50, 64, 65, 70, 110], "bias_bench": 71, "bibtex": 105, "big": [57, 73, 80, 81, 85, 88, 94, 95, 98, 99, 101, 102, 103], "bigg": [44, 63, 81, 86, 87, 95, 101], "bilia": 17, "bin": [42, 49, 51, 106], "binari": [1, 3, 5, 6, 8, 9, 10, 12, 13, 15, 21, 33, 41, 43, 45, 46, 50, 55, 60, 61, 64, 66, 67, 71, 77, 78, 95, 96, 101, 109, 110], "binary_outcom": 33, "binary_treat": [21, 52, 58, 60], "bind": 109, "binder": [46, 78, 105, 107, 109], "binomi": [50, 66, 67, 68], "bischl": [46, 78, 105, 107], "black": [42, 46, 47, 75, 107], "blob": 43, "blog": 28, "blondel": [105, 107], "blp": [36, 44, 63], "blp_data": [44, 63], "blp_model": [58, 59], "blue": [42, 44, 63], "bodori": 108, "bond": [45, 64, 65], "bonferroni": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 94, 104], "bonu": [17, 46, 75, 107], "book": [46, 71, 78], "bool": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 21, 24, 32, 33, 34, 35, 36, 38, 39, 60, 69], "boolean": [29, 58, 59, 75, 80], "boost": [41, 45, 50, 55, 61, 64], "boost_class": [45, 64], "boost_summari": 64, "boostrap": [54, 109], "bootstrap": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 36, 49, 52, 53, 54, 58, 59, 65, 68, 76, 77, 80, 81, 105, 107, 109, 110], "both": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 19, 21, 43, 45, 46, 55, 56, 61, 62, 64, 65, 67, 69, 70, 71, 75, 78, 79, 94, 95, 97, 100, 102, 103, 109, 110], "bottom": [44, 45, 61, 63, 64, 65], "bound": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 24, 45, 49, 60, 64, 70, 71, 95, 97, 100, 103, 110], "branch": 46, "brantli": 43, "break": [42, 109], "breviti": 110, "brew": 106, "brewer": 44, "bridg": 71, "brief": 74, "bring": [41, 50], "brucher": [105, 107], "bsd": 109, "budget": [62, 78], "bug": [105, 109], "build": [44, 61, 63, 67], "build_design_matric": [52, 53], "build_sim_dataset": 43, "built": [37, 62, 78, 105], "bureau": [71, 80, 108], "busi": [26, 29, 44, 63, 71, 108], "b\u00fchlmann": 108, "c": [16, 17, 19, 20, 23, 25, 27, 41, 42, 43, 44, 45, 46, 47, 50, 51, 56, 57, 58, 59, 63, 64, 66, 69, 74, 75, 78, 79, 105, 106, 107, 108, 110], "c1": [16, 17, 27, 44, 57, 63, 74, 105, 108], "c68": [16, 17, 27, 44, 57, 63, 74, 105, 108], "c895": 46, "c_": [94, 104], "c_d": [23, 95, 101, 102, 103], "c_y": [23, 95, 103], "ca1af7be64b2": 46, "caac5a95": 46, "calcualt": 67, "calcul": [1, 9, 12, 43, 45, 49, 52, 53, 54, 58, 59, 61, 62, 64, 68, 70, 95, 100, 103], "calibr": [61, 62, 71], "call": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 39, 41, 43, 44, 45, 46, 50, 52, 53, 54, 55, 58, 59, 63, 64, 65, 67, 68, 69, 70, 71, 72, 75, 78, 80, 81, 94, 95, 100, 103, 104, 107, 109, 110], "callabl": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 42, 51, 52, 53, 61, 76, 78, 105], "callawai": 43, "camera": 57, "cameron": [44, 63], "can": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 21, 32, 37, 39, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 84, 85, 87, 91, 92, 94, 95, 96, 97, 100, 101, 102, 103, 104, 105, 106, 107, 109, 110], "candid": 71, "cannot": [61, 69, 71, 79, 110], "capabl": [4, 7, 41, 50], "capo": 1, "capsiz": [49, 62, 66, 69], "capthick": [49, 69], "cardin": [44, 63], "care": 78, "carlo": [18, 19, 21, 24, 52, 53, 58, 59, 71, 108], "casalicchio": [46, 78, 105, 107], "case": [1, 4, 7, 8, 9, 17, 21, 32, 41, 44, 45, 50, 52, 53, 54, 57, 59, 60, 62, 63, 67, 68, 69, 70, 71, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 107, 109, 110], "cat": [42, 109], "catboost": 61, "cate": [9, 12, 36, 76, 109], "cate_obj": 77, "cattaneo": [79, 108], "caus": [42, 51, 69, 74], "causal": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 22, 23, 25, 26, 27, 28, 29, 32, 41, 42, 44, 45, 46, 50, 51, 63, 64, 66, 70, 72, 73, 74, 75, 76, 79, 80, 94, 95, 100, 104, 108], "causal_contrast": [2, 49, 79], "causal_contrast_model": [49, 79], "causaldml": 108, "causalweight": 108, "caution": 94, "caveat": [59, 71], "cbind": 44, "cc": 64, "ccp_alpha": [9, 37, 64], "cd": 106, "cd_fast": 63, "cda85647": 46, "cdf": 77, "cdid": [44, 63], "cdot": [18, 19, 20, 24, 33, 44, 54, 56, 60, 63, 66, 68, 69, 71, 77, 79, 81, 82, 87, 88, 89, 90, 94, 95, 96, 104], "cdot1": 60, "cell": 62, "center": 57, "central": [80, 109], "certain": [59, 79], "cexcol": 44, "cexrow": 44, "cf_d": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 40, 49, 60, 70, 71, 95, 96, 97, 100, 101, 102, 103, 110], "cf_y": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 40, 49, 60, 70, 71, 95, 96, 97, 100, 101, 102, 103, 110], "chad": 71, "chain": 59, "chainedassignmenterror": 59, "challeng": [44, 63, 95, 97], "chang": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 39, 45, 55, 59, 65, 70, 71, 72, 79, 81, 87, 94, 95, 96, 97, 98, 99, 100, 101, 106, 108, 109], "channel": 110, "chapter": [30, 31, 46, 78, 95, 103], "charact": [45, 46, 78, 109], "characterist": [70, 110], "chart": 62, "check": [34, 35, 38, 39, 42, 45, 51, 61, 62, 64, 65, 73, 74, 105, 106, 109], "check_data": 109, "check_scor": 109, "checkmat": 109, "chernozhukov": [16, 17, 23, 25, 27, 42, 44, 45, 51, 57, 61, 63, 64, 65, 70, 74, 80, 94, 95, 97, 103, 104, 105, 108, 109], "chetverikov": [16, 17, 27, 44, 57, 63, 74, 94, 104, 105, 108], "chiang": [26, 44, 63, 108], "chieh": 108, "choic": [1, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 45, 57, 64, 67, 77, 78, 95, 97, 100, 103, 109], "choos": [41, 45, 50, 51, 57, 61, 64, 65, 73, 80, 81, 84, 85, 87, 91, 92, 94, 104, 107, 110], "chosen": [1, 19, 24, 61, 78, 79], "chou": 66, "chr": 45, "christian": [57, 108], "christoph": 108, "chunk": 78, "ci": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 32, 49, 52, 53, 54, 55, 56, 58, 59, 60, 62, 64, 65, 68, 69, 70, 71, 77, 79, 95, 100, 109, 110], "ci_at": 49, "ci_cvar": [54, 65], "ci_cvar_0": 54, "ci_cvar_1": 54, "ci_joint": 49, "ci_joint_cvar": 54, "ci_joint_lqt": 68, "ci_joint_qt": 68, "ci_length": 55, "ci_low": 49, "ci_lpq_0": 68, "ci_lpq_1": 68, "ci_lqt": [65, 68], "ci_pointwis": 49, "ci_pq_0": [65, 68], "ci_pq_1": [65, 68], "ci_qt": [65, 68], "ci_upp": 49, "cinelli": [71, 95, 97, 108], "circumv": 110, "citat": 109, "claim": 46, "clash": 43, "class": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 30, 31, 32, 34, 35, 36, 37, 38, 39, 45, 46, 47, 49, 55, 60, 62, 64, 65, 70, 72, 73, 75, 77, 78, 80, 81, 94, 105, 107, 109], "class_estim": 69, "class_learn": 65, "class_learner_1": 61, "class_learner_2": 61, "classes_": 62, "classic": [43, 44, 63, 110], "classif": [9, 38, 41, 43, 45, 46, 61, 62, 67, 70, 77, 78, 79, 110], "classifavg": 46, "classifi": [1, 3, 5, 6, 8, 9, 10, 12, 13, 14, 15, 32, 34, 38, 46, 49, 62, 69, 78, 109], "classmethod": [4, 7], "claudia": [108, 109], "claus": 109, "clean": 109, "cleaner": 61, "cleanup": 109, "clear": [44, 63], "clearli": 69, "clever": 61, "clone": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 41, 42, 46, 51, 61, 63, 65, 73, 78, 79, 80, 81, 94, 95, 100, 104, 106, 107], "close": [43, 45, 64, 71, 95, 97], "cluster": [1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 26, 108, 109], "cluster_col": [4, 44, 63], "cluster_var": [4, 26], "cluster_var_i": [4, 44, 63], "cluster_var_j": [4, 44, 63], "cmap": 63, "cmd": 109, "co": [28, 56], "codaci": 109, "code": [1, 9, 12, 28, 41, 43, 44, 45, 46, 50, 57, 64, 74, 77, 78, 79, 80, 81, 94, 106, 107, 109, 110], "codecov": 109, "coef": [3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 80, 81, 94, 107, 110], "coef_": 71, "coef_df": 44, "coef_valu": 62, "coeffici": [18, 19, 21, 36, 39, 45, 58, 59, 61, 64, 66, 67, 69, 71, 72, 77, 94, 95, 100, 104, 110], "coefs_t": 67, "coefs_w": 67, "coffici": [95, 100], "cofid": 36, "coincid": [56, 65], "col": [42, 44, 59, 64], "collect": [46, 55, 63, 72], "colnam": [44, 61], "color": [45, 49, 51, 52, 53, 54, 56, 62, 63, 64, 65, 66, 68, 69, 71], "color_palett": [49, 51, 63, 64, 65], "colorbar": 63, "colorblind": 49, "colorramppalett": 44, "colorscal": [52, 53], "colour": [42, 44], "column": [4, 7, 47, 49, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 69, 70, 71, 72, 75, 77, 78, 79, 80, 107, 109, 110], "column_stack": [49, 56, 58, 59, 69, 70, 71, 79], "colv": 44, "com": [28, 43, 45, 46, 57, 66, 71, 78, 106], "comb": 57, "combin": [43, 44, 46, 49, 55, 61, 62, 63, 71, 78, 80, 95, 100, 109], "combind": 65, "combined_loss": 57, "come": [73, 78, 81, 95, 97, 105, 110], "command": [106, 109], "comment": 75, "common": [61, 70, 71, 77, 79, 108], "companion": 108, "compar": [42, 44, 51, 52, 53, 54, 56, 58, 59, 63, 66, 68, 69, 71, 74, 78, 79, 95, 97], "comparevers": 45, "comparison": [49, 61, 66], "compat": [41, 43, 50, 109], "complement": 71, "complet": [62, 74, 95, 100, 106], "complex": [9, 43, 62], "compli": [69, 79], "complianc": [68, 69, 79, 81, 88], "complic": [46, 110], "complier": [45, 64, 65, 68, 69, 77, 79], "compon": [38, 39, 43, 45, 57, 61, 62, 64, 67, 77, 78, 80, 81, 82, 84, 85, 86, 87, 88, 91, 92, 109], "compont": 43, "composit": 108, "compris": [94, 104], "comput": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 36, 40, 42, 43, 45, 46, 51, 64, 65, 70, 71, 80, 81, 95, 96, 97, 98, 99, 100, 101, 105, 108, 109, 110], "computation": [95, 97], "concat": [62, 63, 64, 67, 94], "concaten": [56, 64, 94], "concentr": 94, "concern": 71, "conclud": [69, 71, 110], "cond": 79, "conda": [63, 108, 109], "condit": [1, 3, 9, 12, 18, 19, 21, 30, 31, 42, 44, 45, 49, 51, 55, 56, 60, 63, 64, 67, 69, 71, 72, 74, 76, 79, 94, 95, 96, 101, 103, 104, 107, 108, 109, 110], "conduct": [77, 79, 110], "conf": [43, 68], "confer": 108, "confid": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 36, 43, 44, 45, 49, 52, 53, 54, 55, 58, 59, 63, 65, 68, 69, 70, 72, 76, 77, 80, 81, 95, 100, 107, 108, 110], "confidenceband": 54, "confidenti": 71, "config": 66, "configur": [46, 62], "confint": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 36, 45, 49, 52, 53, 54, 55, 56, 58, 59, 61, 65, 67, 68, 69, 70, 72, 77, 80, 94, 104, 105, 107, 110], "conflict": 106, "confound": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 21, 40, 41, 45, 50, 60, 64, 68, 70, 71, 75, 79, 94, 95, 97, 100, 102, 103, 104, 107, 108, 109, 110], "congress": 108, "connect": [45, 64, 65], "consequ": [18, 19, 44, 60, 63, 70, 77, 79, 95, 96, 97, 101, 103], "conserv": [70, 71, 95, 103], "consid": [3, 8, 9, 10, 13, 33, 42, 44, 45, 51, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 80, 81, 94, 95, 97, 104, 105, 110], "consider": [71, 79], "consist": [11, 12, 39, 45, 55, 62, 64, 65, 66, 71, 74, 75, 79, 107, 109], "consol": [42, 109], "constant": [23, 39, 57, 67, 77, 79, 94, 104], "constrained_layout": 51, "construct": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 36, 46, 52, 53, 54, 56, 65, 70, 73, 77, 81, 83, 90, 94, 104, 109, 110], "construct_framework": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "construct_iv": 63, "constructiv": 44, "constructor": 46, "consum": [44, 63], "cont": 24, "cont_d": 49, "contain": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 24, 33, 34, 35, 38, 39, 42, 44, 45, 49, 51, 52, 53, 58, 59, 61, 63, 64, 74, 77, 78, 94, 95, 97, 100, 109], "context": [71, 79, 110], "contin": [24, 62], "continu": [24, 41, 46, 49, 50, 57, 66, 69, 79, 95, 103, 109, 110], "contour": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 57, 60, 70, 71, 95, 100], "contour_plot": 71, "contours_z": [52, 53], "contrast": [2, 54, 55, 79], "contribut": [106, 109], "contributor": 109, "control": [25, 33, 43, 57, 65, 67, 69, 71, 110], "convent": [32, 45, 64, 65, 69, 79], "converg": [42, 51, 61, 63, 74], "convergencewarn": 63, "convers": 63, "convert": [54, 63, 68], "convex": 66, "cooper": 109, "coor": [46, 78, 105, 107], "coordin": 71, "copi": [59, 62, 64, 67, 71], "cor": [95, 103], "core": [47, 49, 54, 55, 60, 63, 64, 65, 68, 70, 72, 75, 78, 107, 109], "cores_us": [54, 65, 68], "correct": [60, 71, 77, 94, 104, 109], "correctli": [38, 55, 66, 70, 95, 103], "correl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 44, 57, 63, 70, 72, 79, 95, 97, 103], "correpond": 79, "correspond": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 24, 30, 31, 42, 44, 45, 46, 49, 51, 52, 53, 55, 56, 57, 61, 63, 64, 65, 67, 68, 70, 71, 74, 77, 78, 79, 80, 94, 95, 97, 100, 101, 103, 104, 109, 110], "cosh": 28, "coul": 44, "could": [41, 46, 50, 52, 53, 62, 71, 109, 110], "counfound": [18, 19, 68, 70, 77, 95, 103], "count": [49, 64, 65], "countour": [95, 100], "coupl": [45, 64, 65], "cournapeau": [105, 107], "cours": [45, 61, 64, 71, 94, 110], "cov": [15, 18, 33, 69], "cov_nam": [69, 79], "cov_typ": [1, 9, 12, 36, 109], "covari": [4, 5, 6, 7, 9, 11, 12, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 32, 33, 36, 37, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 70, 71, 72, 74, 75, 77, 78, 79, 81, 84, 85, 94, 95, 97, 107, 108, 109], "cover": [43, 57, 70], "coverag": [61, 69, 77, 109], "cp": [45, 46, 78], "cpu": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "cpu_count": [54, 65, 68], "cran": [46, 108, 109], "creat": [21, 41, 44, 46, 49, 50, 51, 52, 53, 54, 58, 59, 63, 65, 67, 68, 71, 78, 95, 97, 100, 103, 106, 109], "create_synthetic_group_data": 67, "critic": [71, 110], "cross": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 20, 41, 42, 43, 45, 46, 51, 61, 62, 64, 65, 69, 71, 74, 76, 78, 84, 85, 90, 94, 98, 100, 109, 110], "cross_sectional_data": [6, 20, 55, 79], "crossfit": [61, 79], "crosstab": 66, "crucial": [57, 79, 110], "csail": [105, 107], "csv": 57, "cumul": 79, "current": [37, 43, 59, 81, 95, 103, 105, 106, 110], "custom": [42, 43, 51, 71, 78], "custom_measur": 43, "cut": 67, "cutoff": [32, 33, 69, 79], "cv": [46, 64, 78, 80], "cv_glmnet": [44, 45, 46, 78, 94, 104, 107], "cvar": [3, 14, 76, 83, 109], "cvar_0": 54, "cvar_1": 54, "d": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 36, 37, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 110], "d0": [54, 68, 94], "d0_true": 68, "d0cdb0ea4795": 46, "d1": [54, 66, 68, 94, 104], "d10": [94, 104], "d1_true": 68, "d2": [66, 94, 104], "d21ee5775b5f": 46, "d3": [94, 104], "d4": [94, 104], "d5": [94, 104], "d5a0c70f1d98": 46, "d6": [94, 104], "d7": [94, 104], "d8": [94, 104], "d9": [94, 104], "d_": [24, 26, 44, 49, 56, 63, 79, 94, 104], "d_0": 79, "d_1": [66, 94, 104], "d_2": 66, "d_col": [4, 7, 41, 42, 44, 45, 46, 50, 52, 53, 58, 59, 63, 64, 65, 67, 69, 70, 73, 74, 75, 78, 79, 80, 81, 107, 109, 110], "d_i": [21, 22, 23, 25, 27, 28, 29, 42, 49, 51, 54, 55, 66, 68, 69, 72, 74, 79], "d_j": [49, 79, 94, 104], "d_k": [79, 94, 104], "d_l": 79, "d_w": 67, "da1440": 66, "dag": [71, 72, 110], "dark": [42, 51], "darkblu": 44, "darkr": 44, "dash": 49, "dat": 75, "data": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 36, 38, 39, 43, 56, 57, 61, 66, 73, 76, 77, 78, 80, 94, 99, 100, 104, 108, 109], "data_apo": 49, "data_cvar": 65, "data_dict": [32, 52, 53, 58, 59, 60, 69, 79], "data_dml": 70, "data_dml_bas": [45, 52, 53, 58, 59, 64, 65, 67], "data_dml_base_iv": [45, 64, 65], "data_dml_flex": [45, 64], "data_dml_flex_iv": 45, "data_dml_iv_flex": 64, "data_dml_new": 67, "data_fram": 110, "data_lqt": 65, "data_pq": 65, "data_qt": 65, "data_transf": [44, 63, 64], "datafram": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 32, 36, 37, 44, 47, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 81, 94, 95, 97, 100, 107, 110], "dataset": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 32, 42, 43, 49, 51, 52, 53, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 94, 95, 100, 107, 110], "datatyp": 109, "db": [45, 64, 65, 70, 110], "dbl": [43, 44, 45, 46, 75, 94, 104, 107, 110], "dc13a11076b3": 46, "ddc9": 46, "de": [41, 50, 108], "deal": [41, 50], "debias": [16, 17, 26, 27, 44, 57, 63, 76, 78, 80, 105, 108, 109], "debt": [45, 64, 65], "decai": 72, "decid": [45, 64], "decis": [9, 41, 45, 50, 64, 65, 77, 79, 108, 110], "decision_effect": 41, "decision_impact": [41, 50], "decisiontreeclassifi": [9, 37, 64], "decisiontreeregressor": 64, "declar": 110, "decreas": 69, "deep": [34, 35, 38, 39, 62], "deeper": 9, "def": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 51, 54, 61, 62, 63, 66, 67, 68, 71, 78, 81], "default": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 24, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 43, 44, 55, 58, 59, 61, 63, 67, 69, 70, 71, 72, 73, 77, 78, 79, 80, 94, 95, 96, 100, 104, 107, 110], "default_convert": 63, "defier": [69, 79], "defin": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 39, 42, 45, 46, 49, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 65, 67, 68, 69, 70, 71, 77, 78, 79, 81, 84, 85, 95, 97, 100, 103], "definit": [28, 58, 59, 95, 96, 101], "defint": 95, "degre": [33, 45, 52, 53, 63, 64, 69, 77, 95, 97], "dekel": 108, "delete_origin": 46, "deliber": 66, "delta": [25, 43, 55, 71, 79], "delta_bench": 71, "delta_i": 43, "delta_j": 25, "delta_theta": [40, 49, 60, 70, 71, 95, 97], "delta_v": 71, "demand": [44, 63, 95, 97], "demir": [16, 17, 27, 44, 57, 63, 74, 80, 105, 108], "demo": 71, "demonstr": [42, 43, 44, 51, 63, 69, 71, 75, 79, 94, 104, 105, 107], "deni": 108, "denomin": [95, 96, 97, 101], "denot": [11, 44, 45, 55, 56, 63, 64, 69, 71, 72, 77, 79, 81, 95, 97, 100, 101, 103], "dens_net_tfa": 45, "densiti": [10, 13, 14, 42, 49, 51], "dep": 47, "dep1": [46, 47, 75, 107], "dep2": [46, 47, 75, 107], "depend": [1, 3, 9, 10, 14, 21, 46, 52, 53, 55, 58, 59, 60, 61, 62, 67, 69, 73, 77, 78, 79, 81, 88, 93, 95, 96, 97, 103, 107, 108], "deprec": [73, 80], "depreci": 109, "depth": [9, 37, 45, 46, 67, 73, 77, 78, 79, 80, 81, 94, 107, 110], "deriv": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 31, 79, 94], "describ": [43, 44, 63, 64, 65, 71, 78, 80, 106, 109], "descript": [45, 47, 70, 78, 80, 95, 97], "deserv": 79, "design": [32, 33, 49, 62, 76, 108, 109], "design_info": [52, 53], "design_matrix": [52, 53, 77], "desir": [19, 46, 67, 79, 106], "detail": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 30, 31, 42, 45, 46, 49, 51, 55, 56, 57, 62, 65, 69, 70, 71, 74, 75, 77, 78, 81, 83, 87, 88, 89, 90, 93, 94, 95, 97, 103, 104, 105, 106, 107, 109, 110], "determin": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 39, 45, 54, 64, 65, 68, 69, 70, 79, 94, 95, 103, 104], "determinist": [67, 69, 77, 79], "deutsch": 105, "dev": [106, 109], "develop": [43, 44, 46, 63, 71, 79, 109], "deviat": [61, 79, 95, 103], "dezeur": 108, "df": [4, 7, 41, 42, 44, 49, 50, 52, 53, 54, 56, 59, 63, 66, 68, 69, 70, 71, 72, 74, 77, 79], "df_agg": 57, "df_apo": 49, "df_apo_ci": 49, "df_apos_ci": 49, "df_ate": 49, "df_bench": 71, "df_binari": 71, "df_bonu": [46, 75, 107], "df_cate": [52, 53], "df_ci": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 36], "df_coef": 61, "df_cvar": 65, "df_fuzzi": 69, "df_lqte": 65, "df_ml_g0": 61, "df_ml_g1": 61, "df_ml_m": 61, "df_pa": [55, 72], "df_plot": 44, "df_pq": 65, "df_qte": 65, "df_result": 57, "df_sharp": 69, "df_sort": 49, "df_summari": 64, "df_wide": 63, "dfg": 105, "dgp": [20, 44, 54, 56, 57, 63, 66, 67, 68, 71, 72], "dgp1": 20, "dgp2": 20, "dgp3": 20, "dgp4": 20, "dgp5": 20, "dgp6": 20, "dgp_dict": 71, "dgp_tpye": 55, "dgp_type": [20, 55], "diagon": 71, "diagram": [41, 50, 79], "dichotom": [41, 50], "dict": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 34, 35, 36, 37, 38, 39, 40, 52, 53, 57, 62, 71, 78], "dict_kei": [95, 100], "dictionari": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 21, 24, 33, 40, 52, 53, 58, 59, 70, 77, 78, 95, 100], "dictonari": [45, 64], "did": [4, 7, 42, 55, 56, 63, 76, 109, 110], "diff": 64, "differ": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 21, 41, 42, 44, 45, 46, 49, 50, 51, 54, 58, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 76, 77, 78, 80, 84, 85, 106, 107, 108, 109, 110], "differenti": 79, "difficult": 71, "dillon": 108, "dim": [33, 45], "dim_x": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 22, 23, 25, 26, 27, 28, 29, 33, 42, 44, 46, 51, 61, 62, 63, 74, 77, 78, 79, 95, 100], "dim_z": [11, 25, 79], "dimens": [21, 26, 44, 63, 67, 80], "dimension": [11, 12, 21, 23, 57, 77, 79, 80, 94, 95, 100, 104, 107, 108], "direct": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 42, 51, 56, 72, 74, 79, 110], "directli": [32, 42, 43, 45, 49, 51, 61, 70, 74, 95, 100, 107, 110], "discontinu": [32, 33, 76, 108, 109], "discret": [2, 24, 49, 63, 79, 109], "discretis": 65, "discuss": [22, 44, 45, 63, 64, 108, 109, 110], "disjoint": [44, 58, 59, 63], "displai": [44, 49, 63, 71, 77, 78, 95, 100], "displot": 64, "disproportion": [45, 64], "disregard": 39, "dist": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "distr": 78, "distribut": [33, 42, 49, 51, 55, 61, 71, 74, 79, 95, 101, 106, 108, 109], "diverg": [32, 42, 51, 74], "divid": 79, "dmatrix": [52, 53, 77], "dml": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 30, 31, 32, 41, 42, 46, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 81, 94, 95, 100, 104, 106], "dml1": [76, 107, 109, 110], "dml2": [41, 44, 46, 47, 55, 63, 65, 76, 79, 81, 94, 107, 109, 110], "dml_apo_obj": 79, "dml_apos_obj": 79, "dml_base": 63, "dml_combin": 94, "dml_cv_predict": 109, "dml_cvar": [54, 65], "dml_cvar_0": 54, "dml_cvar_1": 54, "dml_cvar_obj": [3, 77], "dml_data": [43, 44, 47, 49, 55, 56, 60, 61, 63, 66, 70, 71, 72, 77, 78, 79, 94, 104, 110], "dml_data_bench": 71, "dml_data_bonu": [46, 107], "dml_data_df": 110, "dml_data_fuzzi": 69, "dml_data_lasso": 47, "dml_data_sharp": 69, "dml_data_sim": [46, 107], "dml_df": [44, 63], "dml_did": [55, 56], "dml_did_obj": [5, 6, 79], "dml_iivm_boost": [45, 64], "dml_iivm_forest": [45, 64], "dml_iivm_lasso": [45, 64], "dml_iivm_obj": [8, 50, 79], "dml_iivm_tre": [45, 64], "dml_irm": [52, 58, 61, 67], "dml_irm_at": 60, "dml_irm_boost": [45, 64], "dml_irm_forest": [45, 64], "dml_irm_gat": 60, "dml_irm_gatet": 60, "dml_irm_lasso": [45, 47, 64], "dml_irm_new": 67, "dml_irm_obj": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 70, 77, 78, 79], "dml_irm_obj_ext": 78, "dml_irm_rf": 47, "dml_irm_tre": [45, 64], "dml_long": 40, "dml_lpq_0": 68, "dml_lpq_1": 68, "dml_lpq_obj": [10, 77], "dml_lqte": [65, 68], "dml_obj": [43, 49, 70, 71], "dml_obj_bench": 71, "dml_pliv": [44, 63], "dml_pliv_obj": [11, 44, 63, 79], "dml_plr": [53, 59, 94, 104], "dml_plr_1": 94, "dml_plr_2": 94, "dml_plr_boost": [45, 64], "dml_plr_forest": [45, 64, 110], "dml_plr_lasso": [45, 47, 64], "dml_plr_no_split": 80, "dml_plr_obj": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 70, 73, 77, 78, 79, 80, 81, 94, 95, 97, 100], "dml_plr_obj_extern": 80, "dml_plr_obj_intern": 80, "dml_plr_obj_onfold": 62, "dml_plr_obj_untun": 62, "dml_plr_rf": 47, "dml_plr_tree": [45, 64, 110], "dml_pq_0": [65, 68], "dml_pq_1": [65, 68], "dml_pq_obj": [13, 77], "dml_procedur": [47, 73, 107, 109, 110], "dml_qte": [65, 68], "dml_qte_obj": [14, 77], "dml_short": 40, "dml_ssm": [72, 79], "dml_tune": 109, "dmldummyclassifi": 78, "dmldummyregressor": 78, "dmlmt": 108, "dnorm": 42, "do": [43, 44, 45, 46, 61, 63, 64, 65, 66, 71, 77, 78, 95, 103, 107, 110], "doabl": 81, "doc": [41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 105, 109], "doccument": 109, "docu": 109, "document": [48, 52, 53, 56, 58, 59, 62, 71, 105, 109], "doe": [2, 14, 43, 44, 45, 49, 63, 64, 66, 70, 71, 95, 103, 110], "doesn": [41, 50], "doi": [16, 17, 18, 19, 20, 22, 26, 27, 29, 43, 44, 46, 57, 63, 71, 74, 78, 80, 94, 104, 105, 107, 109], "domain": 67, "don": [43, 62], "done": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 62, 65, 78, 80, 95, 97], "dosag": 49, "dot": [15, 56, 67, 75, 77, 78, 79, 94, 104, 107], "doubl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 26, 27, 28, 29, 32, 45, 57, 64, 66, 76, 78, 80, 81, 94, 95, 97, 104, 109], "double_ml_bonus_data": 47, "double_ml_data_from_data_fram": [42, 74, 75, 110], "double_ml_data_from_matrix": [43, 46, 75, 78, 94, 104, 107], "double_ml_irm": [47, 67], "doubleiivm": 105, "doubleml": [42, 44, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 95, 100, 104, 107, 108, 109], "doubleml2022python": 105, "doubleml2024r": 105, "doubleml_did_eval_linear": 43, "doubleml_did_eval_rf": 43, "doubleml_did_linear": 43, "doubleml_did_rf": 43, "doubleml_framework": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "doublemlapo": [49, 79, 81, 82, 109], "doublemlblp": [1, 9, 12, 52, 53, 77, 109], "doublemlclusterdata": 26, "doublemlcvar": [54, 77, 81, 83, 109], "doublemldata": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 25, 27, 28, 29, 32, 41, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 94, 95, 100, 104, 109, 110], "doublemldid": [55, 56, 79, 81, 84, 109], "doublemldidc": [55, 79, 81, 85, 109], "doublemlframework": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 80, 94, 109], "doublemlframwork": 2, "doublemlidid": 79, "doublemlididc": 79, "doublemliivm": [41, 45, 50, 64, 78, 79, 80, 81, 86, 109], "doublemlirm": [1, 3, 5, 6, 8, 10, 11, 12, 13, 15, 43, 45, 47, 49, 52, 58, 60, 61, 64, 66, 67, 70, 71, 77, 78, 79, 80, 81, 87, 105, 109], "doublemllpq": [68, 77, 81, 88, 109], "doublemlpliv": [78, 79, 80, 81, 91, 105, 109], "doublemlplr": [1, 2, 3, 5, 6, 8, 9, 10, 11, 13, 14, 15, 42, 45, 46, 47, 51, 53, 59, 62, 64, 66, 70, 73, 74, 77, 78, 79, 80, 81, 92, 94, 95, 100, 104, 105, 107, 109, 110], "doublemlpolicytre": [9, 77], "doublemlpq": [65, 68, 77, 81, 93, 109], "doublemlqt": [54, 65, 68, 77, 94, 109], "doublemlresampl": 61, "doublemlsmm": 109, "doublemlssm": [72, 79, 81, 89, 90], "doubli": [18, 19, 20, 43, 108], "down": 71, "download": [41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 106, 107], "downward": 71, "dpg_dict": 70, "dpi": [42, 51, 66], "dramat": 43, "draw": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 71, 80, 109], "draw_sample_split": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 61, 80], "drawn": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 21, 33, 45, 64, 65, 67, 80], "drive": [42, 51, 74], "driven": [71, 110], "drop": [43, 62, 63, 66, 75, 78, 81, 84, 85, 94, 104], "dt": [81, 85, 95, 98], "dt_bonu": 75, "dta": 43, "dtype": [47, 49, 55, 58, 59, 60, 61, 63, 64, 65, 70, 72, 75, 77, 107], "dualiti": 63, "dubourg": [105, 107], "duchesnai": [105, 107], "due": [42, 43, 51, 52, 53, 60, 70, 71, 74, 79, 95, 97, 109, 110], "duflo": [16, 17, 27, 44, 57, 63, 74, 80, 105, 108], "dummi": [1, 9, 12, 34, 35, 36, 62, 71, 77, 78, 79, 109], "dummyclassifi": 34, "dummyregressor": 35, "duplic": 109, "durabl": [46, 47, 75, 107], "durat": 17, "dure": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 43, 44, 45, 46, 62, 63, 64, 78, 80, 107, 109, 110], "dx": 22, "dynam": [43, 108], "e": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 24, 27, 29, 30, 31, 32, 38, 39, 42, 43, 44, 45, 49, 51, 52, 53, 55, 57, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110], "e20ea26": 46, "e401": [45, 64, 65, 70, 110], "e4016553": 110, "e45228": 66, "e57c": 46, "each": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 24, 38, 39, 44, 46, 49, 56, 58, 59, 61, 62, 63, 65, 66, 67, 70, 71, 73, 75, 78, 79, 80, 94, 95, 100, 104, 110], "earlier": 110, "earn": [45, 64, 65], "earner": [45, 64, 70], "easi": [46, 81], "easier": 62, "easili": [46, 61, 62, 65, 109], "ec973f": 66, "ecolor": [49, 56, 64, 66], "econ": 108, "econml": 108, "econom": [25, 26, 28, 29, 44, 57, 63, 66, 71, 80, 108], "econometr": [16, 17, 18, 19, 20, 27, 28, 43, 44, 57, 63, 74, 105, 108], "econometrica": [23, 44, 63, 66, 74, 108], "ecosystem": [105, 110], "ectj": [16, 17, 27, 44, 57, 63, 74, 105], "ed": 108, "edge_color": 51, "edgecolor": 51, "edit": [106, 108], "edu": [105, 107], "educ": [45, 64, 65, 70, 110], "ee97bda7": 46, "effect": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 24, 33, 38, 39, 41, 42, 43, 44, 46, 49, 50, 51, 55, 56, 57, 60, 63, 67, 69, 72, 74, 76, 78, 79, 80, 81, 87, 94, 95, 97, 107, 108, 109, 110], "effici": [79, 108], "effort": 81, "eight": [44, 63], "either": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 21, 46, 56, 57, 67, 69, 77, 78, 79, 110], "eleanor": 108, "element": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 44, 52, 53, 54, 55, 61, 63, 65, 68, 70, 72, 81, 82, 84, 85, 95, 100, 102, 103, 109], "element_text": [44, 45], "elementari": 108, "elif": [58, 59, 67], "elig": [65, 70, 110], "eligibl": [45, 64, 70], "ell": [42, 44, 51, 57, 63, 74, 81, 91, 92, 107], "ell_0": [8, 11, 12, 42, 51, 57, 62, 74, 79], "ell_2": 61, "els": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 36, 43, 44, 45, 56, 58, 59, 63, 67, 71], "em": 108, "emphas": [44, 63], "empir": [30, 31, 42, 44, 51, 63, 66, 71, 74, 79, 80, 81, 94, 104], "emploi": [44, 57, 63, 71, 81, 86], "employ": [45, 64, 65], "employe": 110, "empti": 63, "emul": [95, 97], "enabl": [49, 67, 70, 77, 95, 97, 109], "enable_metadata_rout": [38, 39], "encapsul": [34, 35, 38, 39], "encod": 66, "end": [22, 25, 26, 42, 43, 44, 45, 51, 54, 56, 57, 61, 63, 64, 66, 67, 68, 72, 73, 75, 78, 80, 94, 104, 107, 110], "endogen": [45, 64, 65, 110], "enet_coordinate_descent_gram": 63, "engin": [46, 108], "enrol": [45, 64, 65], "ensembl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 47, 49, 51, 52, 53, 58, 59, 60, 61, 64, 67, 70, 71, 73, 77, 78, 79, 80, 81, 94, 95, 100, 107, 110], "ensemble_learner_pipelin": 78, "ensemble_pipe_classif": 46, "ensemble_pipe_regr": 46, "ensur": [38, 39, 44, 59, 62, 63, 67], "entir": [42, 45, 51, 64, 74, 95, 97], "entri": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 42, 44, 47, 49, 51, 55, 60, 63, 64, 65, 70, 72, 74, 75, 78, 105, 107, 109], "enumer": [49, 54, 56, 58, 59, 61, 63, 64, 65, 68, 73, 78, 80], "env": [63, 106], "environ": 106, "ep": 66, "epanechnikov": 32, "epsilon": [45, 54, 55, 56, 64, 68, 77, 79], "epsilon_": [44, 56, 63], "epsilon_0": 33, "epsilon_1": 33, "epsilon_i": [21, 54, 66, 67, 68], "epsilon_sampl": 67, "epsilon_tru": [54, 68], "eqnarrai": 45, "equal": [1, 9, 44, 63, 66, 72, 77, 78, 79, 95, 101], "equat": [33, 44, 45, 63, 64, 71, 73, 94, 104, 110], "equilibrium": [44, 63], "equival": [57, 80], "err": [3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 47, 49, 50, 52, 53, 54, 55, 58, 59, 60, 62, 63, 64, 65, 66, 68, 70, 71, 72, 77, 78, 79, 80, 81, 94, 107, 110], "error": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 38, 39, 41, 42, 43, 45, 46, 51, 56, 57, 58, 59, 61, 62, 64, 69, 71, 74, 78, 79, 80, 81, 94, 95, 100, 104, 107, 109, 110], "errorbar": [49, 56, 58, 59, 62, 64, 66, 69], "erstellt": [44, 45, 46], "esim": 69, "especi": [61, 62], "essenti": 71, "est": 69, "est_method": 43, "esther": [80, 108], "estim": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 30, 31, 32, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 49, 51, 52, 53, 54, 56, 58, 59, 61, 63, 67, 69, 73, 74, 76, 77, 78, 79, 83, 84, 85, 88, 90, 93, 95, 97, 100, 104, 105, 108, 109], "estimatior": [4, 7], "estimator_list": 62, "et": [16, 17, 21, 23, 26, 27, 42, 44, 45, 46, 51, 52, 53, 54, 55, 57, 58, 59, 61, 63, 64, 65, 68, 70, 74, 79, 80, 81, 83, 88, 93, 94, 95, 97, 103, 104, 105, 107, 109], "eta": [30, 31, 42, 44, 45, 56, 62, 63, 64, 68, 69, 73, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 103, 104, 107, 110], "eta1": 66, "eta2": 66, "eta_": [94, 95, 103, 104], "eta_0": [32, 73, 79, 81, 94], "eta_d": [69, 79], "eta_i": [21, 56, 67, 68, 69, 79], "eta_sampl": 67, "eta_tru": 68, "etc": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 44, 61, 62, 63, 109], "ev": [42, 51, 74], "eval": [46, 78], "eval_metr": [45, 64, 110], "eval_pr": 43, "eval_predict": 43, "evalu": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 23, 31, 43, 46, 52, 53, 54, 56, 60, 65, 68, 70, 73, 108, 109], "evaluate_learn": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 61, 62, 78, 109], "evalut": 78, "even": [45, 46, 64, 66, 69, 78, 79, 110], "eventu": [44, 63], "everi": [44, 63], "everyth": 105, "evid": [60, 62], "exact": 71, "exactli": [69, 71, 79], "exampl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 21, 32, 41, 42, 45, 46, 47, 49, 50, 51, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 80, 81, 94, 95, 100, 104, 105, 107, 109, 110], "example_attgt": 43, "example_attgt_dml_eval_linear": 43, "example_attgt_dml_eval_rf": 43, "example_attgt_dml_linear": 43, "example_attgt_dml_rf": 43, "except": [39, 57, 71, 109], "excess": 61, "exclud": 40, "exclus": [1, 9, 12, 58, 59, 77], "execut": [46, 110], "exemplarili": 107, "exemplatori": 67, "exhaust": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 78], "exhibit": [44, 63], "exist": [38, 39, 79, 95, 103], "exogen": [45, 64, 65, 79, 110], "exp": [18, 19, 20, 21, 23, 24, 27, 42, 51, 52, 53, 56, 58, 59, 66, 67, 74], "expect": [18, 19, 39, 43, 49, 55, 60, 61, 62, 69, 71, 72, 77, 79, 80, 94, 95, 96, 107], "experi": [17, 22, 23, 42, 45, 51, 64, 71, 74, 75, 80, 107, 108], "experiment": [5, 6, 20, 81, 84, 85, 95, 98, 99], "expertis": 71, "explain": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 70, 95, 97, 102, 103], "explan": [44, 55, 63, 70, 95, 102, 105, 110], "explanatori": [71, 94, 104], "explicit": 71, "explicitli": [60, 110], "exploit": [42, 51, 74, 79, 110], "explor": 62, "exponenti": [94, 104], "export": [62, 109], "exposur": 56, "express": [44, 57, 69, 95, 103], "extend": [71, 78, 105, 109], "extendend": [95, 103], "extens": [78, 81, 105, 108, 109], "extent": 57, "extern": [42, 51, 62, 76, 95, 97, 109], "external_predict": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 51, 78], "externalptr": 45, "extra": 46, "extract": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 62], "extralearn": 46, "extrem": [45, 64], "ey": 57, "f": [45, 46, 49, 51, 54, 55, 56, 57, 61, 63, 64, 65, 67, 68, 70, 71, 72, 78, 95, 103, 105, 107], "f00584a57972": 46, "f1718fdeb9b0": 46, "f2e7": 46, "f3d24993": 46, "f6ebc": 66, "f_": [18, 20, 56, 77], "f_loc": [54, 68], "f_p": 56, "f_scale": [54, 68], "f_x": 79, "face_color": 51, "facet_wrap": 45, "facilit": 62, "fact": [45, 64, 65], "factor": [33, 42, 43, 44, 45, 46, 51, 61, 74, 78, 110], "faculti": 108, "fail": 109, "fair": 61, "fake": [41, 50], "fals": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 24, 32, 33, 36, 38, 39, 42, 45, 46, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 75, 78, 79, 80, 81, 84, 85, 94, 95, 98, 99, 104, 110], "famili": [45, 64, 78], "fanci": 43, "far": [45, 64], "farbmach": 22, "fast": [61, 67, 78], "faster": 57, "fb5c25fa": 46, "fc9e": 46, "fd8a": 46, "featur": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 37, 39, 43, 47, 60, 61, 64, 67, 77, 78, 79], "featureless": [46, 78], "features_bas": [45, 64, 65, 70], "features_flex": 45, "featureunion": 46, "februari": 71, "femal": [46, 47, 75, 107], "fern\u00e1ndez": [23, 80, 108], "fetch": [45, 63, 64, 65, 75], "fetch_401k": [45, 64, 65, 70, 110], "fetch_bonu": [46, 47, 75, 107], "few": [45, 64, 65], "ff7f0e": 56, "field": [44, 63, 78, 110], "fifteenth": 108, "fifth": 44, "fig": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 49, 52, 53, 54, 56, 57, 61, 62, 65, 66, 68, 69, 71], "fig_al": 51, "fig_dml": 51, "fig_non_orth": 51, "fig_orth_nosplit": 51, "fig_po_al": 51, "fig_po_dml": 51, "fig_po_nosplit": 51, "figsiz": [47, 49, 52, 53, 54, 56, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69], "figur": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 27, 42, 44, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 62, 63, 64, 65, 68, 71, 74], "figure_format": 66, "file": [16, 17, 57, 66, 108, 109], "filenam": 42, "fill": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 42, 44, 45, 55, 61, 64, 72], "fill_between": [52, 53, 54, 65, 68], "fill_valu": 61, "filter": 46, "filterwarn": 51, "final": [42, 46, 49, 51, 52, 53, 54, 56, 58, 59, 60, 65, 68, 69, 72, 74, 79, 110], "final_estim": 69, "financi": [16, 70, 110], "find": [45, 56, 64, 71, 77, 78, 110], "finish": 46, "finit": [42, 45], "firm": [44, 63, 70], "firmid": 63, "first": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 26, 32, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 71, 72, 74, 77, 79, 80, 94, 95, 100, 104, 106, 107, 109, 110], "fit": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 81, 84, 85, 90, 94, 95, 97, 100, 104, 105, 109, 110], "fit_arg": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "fit_transform": [63, 64], "five": 63, "fix": [56, 61, 109], "flag": [20, 80, 106], "flake8": 109, "flamlclassifierdoubleml": 62, "flamlregressordoubleml": 62, "flatten": [62, 66], "flexibl": [32, 41, 43, 45, 46, 50, 55, 64, 79, 105, 108, 109, 110], "flexibli": [45, 64, 70], "float": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 32, 33, 36, 38, 39], "float32": [64, 65, 70], "float64": [47, 49, 55, 59, 60, 63, 64, 70, 72, 75, 78, 107], "floor": 46, "floor_divid": 63, "flt": 46, "flush": 42, "fmt": [49, 56, 58, 59, 62, 64, 66, 69], "focu": [44, 45, 63, 64, 65, 71, 77, 79, 110], "focus": [65, 70, 71, 110], "fold": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 41, 44, 45, 46, 55, 61, 63, 64, 65, 70, 72, 73, 76, 78, 79, 81, 84, 85, 94, 107, 110], "follow": [18, 19, 20, 21, 24, 42, 44, 45, 51, 52, 53, 54, 55, 56, 58, 59, 62, 63, 64, 65, 68, 69, 70, 71, 72, 74, 75, 77, 78, 79, 80, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 107, 110], "font_scal": [63, 64, 65], "fontsiz": [54, 65, 68], "force_all_x_finit": [4, 7], "forest": [22, 41, 42, 43, 45, 46, 50, 51, 55, 60, 61, 64, 70, 74, 78, 107, 110], "forest_summari": 64, "forg": [106, 108, 109], "form": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 21, 36, 38, 39, 45, 52, 53, 54, 55, 56, 58, 59, 60, 61, 64, 68, 69, 70, 72, 77, 79, 81, 82, 87, 95, 96, 97, 100, 101, 102, 103, 106, 107], "format": [51, 60, 95, 100], "formula": [44, 45, 63, 64, 69, 71, 109], "formula_flex": 45, "forschungsgemeinschaft": 105, "forthcom": [71, 108], "forum": 109, "forward": [9, 37], "found": [52, 53, 57, 58, 59, 62, 74, 75, 78, 79, 107], "foundat": [105, 108], "four": [45, 61, 64, 109], "fourth": [44, 63], "frac": [8, 18, 19, 20, 22, 23, 25, 27, 28, 29, 31, 39, 42, 44, 46, 51, 56, 57, 60, 63, 66, 69, 73, 74, 77, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104], "fraction": 46, "frame": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 36, 41, 42, 44, 45, 47, 49, 52, 53, 55, 58, 59, 60, 63, 64, 65, 66, 67, 70, 72, 74, 75, 107, 110], "framework": [31, 42, 44, 46, 51, 61, 62, 63, 66, 71, 74, 78, 94, 104, 105, 107, 109, 110], "freez": 106, "fribourg": 108, "friendli": 49, "from": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 36, 39, 41, 42, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 94, 95, 100, 104, 107, 109, 110], "from_arrai": [4, 7, 15, 32, 51, 54, 55, 56, 68, 74, 75, 78, 94, 104, 107], "from_product": 63, "front": 49, "fr\u00e9chet": [95, 103], "fs_kernel": [32, 79], "fs_specif": [32, 79], "fsize": [45, 64, 65, 70, 110], "full": [49, 51, 54, 55, 56, 58, 59, 61, 64, 65, 68, 69, 72, 74, 79], "fulli": [9, 45, 48, 62, 64, 79], "fun": 42, "func": 43, "function": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 27, 28, 30, 31, 32, 41, 42, 45, 46, 50, 51, 52, 53, 54, 55, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 98, 99, 103, 104, 105, 108, 109, 110], "fund": [45, 64, 65, 105], "further": [18, 19, 20, 21, 24, 26, 44, 46, 49, 52, 53, 54, 55, 56, 60, 61, 63, 65, 67, 68, 69, 70, 71, 72, 78, 79, 81, 83, 88, 89, 90, 93, 94, 95, 97, 100, 102, 103, 104, 105, 107, 109, 110], "furthermor": [51, 81, 82, 87], "futurewarn": 59, "fuzzi": [32, 33], "g": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 32, 38, 39, 42, 43, 46, 47, 51, 52, 53, 55, 56, 57, 60, 61, 65, 66, 67, 70, 72, 74, 77, 78, 79, 81, 82, 84, 85, 86, 87, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 110], "g_": [33, 49, 81, 83, 84, 85, 88, 93, 94, 104], "g_0": [1, 5, 6, 8, 9, 11, 12, 13, 27, 28, 32, 33, 42, 44, 45, 51, 61, 63, 64, 74, 77, 78, 79, 81, 82, 89, 90, 95, 96, 101, 103, 107, 110], "g_1": [33, 61], "g_all": [42, 45], "g_all_po": 42, "g_ci": 45, "g_d": [81, 83, 93], "g_dml": 42, "g_dml_po": 42, "g_hat": [11, 12, 42, 51, 81], "g_hat0": [8, 9], "g_hat1": [8, 9], "g_k": 77, "g_nonorth": 42, "g_nosplit": 42, "g_nosplit_po": 42, "g_x": 56, "gain": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 40, 61, 95, 97, 101, 109], "gain_statist": 109, "galleri": [74, 77, 78, 79, 105, 109], "gama": 62, "gamma": [25, 28, 29, 44, 63, 66, 67, 69, 71, 79, 81, 83, 88], "gamma_0": [21, 67, 72, 81, 83, 88], "gamma_a": [18, 19, 71], "gamma_bench": 71, "gamma_v": 71, "gap": [63, 71], "gapo": 1, "gate": [1, 9, 12, 36, 66, 67, 76, 109], "gate_obj": 77, "gatet": 77, "gaussian": [10, 13, 14, 42, 51, 74, 77, 78, 94, 104, 108], "ge": [18, 20, 21, 60, 67, 77], "geer": 108, "gelbach": [44, 63], "gener": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 39, 41, 43, 44, 45, 46, 47, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 87, 94, 96, 97, 98, 99, 101, 103, 104, 108, 109, 110], "generate_treat": 68, "geom_bar": 45, "geom_dens": 45, "geom_errorbar": 45, "geom_funct": 42, "geom_histogram": 42, "geom_hlin": 45, "geom_point": 45, "geom_til": 44, "geom_vlin": 42, "geq": [69, 79], "german": 105, "get": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 34, 35, 38, 39, 46, 49, 61, 66, 70, 71, 95, 97, 105, 106], "get_dummi": 66, "get_feature_names_out": [63, 64], "get_legend_handles_label": 49, "get_level_valu": 62, "get_logg": [42, 43, 44, 45, 46, 73, 78, 79, 80, 81, 94, 104, 107], "get_metadata_rout": [34, 35, 38, 39], "get_param": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 34, 35, 38, 39, 62, 78], "ggdid": 43, "ggplot": [42, 44, 45], "ggplot2": [42, 44, 45], "ggsave": 42, "ggtitl": 45, "gh": 109, "git": 106, "github": [43, 45, 57, 62, 66, 105, 108, 109], "githubusercont": 57, "give": [45, 64], "given": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 23, 27, 28, 31, 32, 33, 38, 39, 42, 44, 49, 51, 56, 58, 59, 63, 65, 66, 69, 71, 72, 74, 77, 81, 82, 94, 95, 96, 100, 101, 102, 103, 104, 107, 109], "glmnet": [45, 46, 78, 109], "global": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 39, 78, 79], "globalclassifi": 69, "globallearn": 69, "globalregressor": 69, "glrn": 46, "glrn_lasso": 46, "gname": 43, "go": [52, 53, 57, 62, 69, 71], "goal": [49, 58, 59, 79], "goe": 79, "goldman": 108, "good": [57, 95, 97, 110], "gradient": [45, 64], "gradientboostingclassifi": 61, "gradientboostingregressor": 61, "gradual": 71, "gramfort": [105, 107], "graph": [46, 72, 110], "graph_ensemble_classif": 46, "graph_ensemble_regr": 46, "graph_obj": 69, "graph_object": [52, 53, 57, 71], "graphlearn": [46, 78], "grasp": [49, 95, 97], "great": [56, 110], "greater": 110, "green": [42, 52, 53, 54, 68], "greg": 108, "grei": [45, 49], "grenand": 108, "grey50": 44, "grid": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 44, 46, 49, 52, 53, 54, 57, 65, 66, 68, 71, 78, 95, 100], "grid_arrai": [52, 53], "grid_bound": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 71], "grid_search": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 46, 78], "grid_siz": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 52, 53], "gridextra": 44, "gridsearchcv": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 78], "grisel": [105, 107], "grob": 44, "group": [1, 9, 12, 41, 43, 49, 50, 60, 65, 66, 67, 71, 76], "group_0": 77, "group_1": [58, 59, 77], "group_2": [58, 59, 77], "group_3": [58, 59], "group_effect": 67, "group_ind": 60, "group_treat": 60, "groupbi": [57, 64], "gruber": 22, "gt": [41, 43, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 107], "guarante": [44, 63], "guber": 22, "guess": [70, 95, 97], "guid": [30, 31, 34, 35, 38, 39, 42, 43, 44, 46, 49, 51, 56, 60, 63, 69, 70, 78, 105, 107, 109], "guidelin": 109, "gunion": [46, 78], "gxidclusterperiodytreat": 43, "h": [18, 19, 20, 22, 26, 43, 44, 63, 69, 79, 108], "h20": 62, "h_0": [49, 60, 70, 71, 95, 100, 110], "h_f": [32, 79], "ha": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 20, 36, 37, 38, 39, 42, 43, 44, 45, 51, 57, 61, 62, 63, 64, 65, 66, 69, 70, 71, 77, 78, 79, 95, 96, 97, 100, 101, 102, 103, 110], "half": [42, 51, 66, 74, 80], "hand": [32, 61, 62, 66, 110], "handbook": 66, "handl": [43, 49, 61, 78, 109], "hansen": [16, 17, 23, 25, 27, 44, 57, 63, 74, 105, 108], "happend": 61, "hard": [70, 95, 97], "harold": 108, "harsh": 38, "hat": [42, 44, 51, 57, 60, 63, 66, 69, 73, 74, 77, 79, 80, 81, 94, 95, 97, 100, 102, 104], "have": [1, 2, 9, 12, 14, 21, 24, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 56, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 75, 77, 78, 79, 94, 95, 96, 97, 103, 106, 107, 109, 110], "hazlett": [71, 95, 97], "hc": [43, 108], "hc0": [36, 109], "hdm": [44, 63], "he": 72, "head": [43, 44, 46, 47, 52, 53, 58, 59, 62, 63, 64, 66, 69, 71, 75, 77, 107], "heat": [44, 63], "heatmap": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 44, 63, 71], "heavili": 61, "hei": 108, "height": [42, 44, 57, 62], "help": [43, 45, 54, 61, 65, 67, 71, 80, 110], "helper": 109, "henc": [43, 45, 46, 64, 71, 78, 81, 110], "here": [10, 13, 14, 43, 44, 45, 46, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 71, 72, 75, 78, 79, 106], "heterogen": [9, 21, 45, 60, 64, 65, 67, 76, 79, 80, 108, 109, 110], "heteroskedast": [58, 59], "heurist": [42, 51, 74], "high": [11, 12, 23, 45, 56, 57, 64, 65, 73, 79, 94, 104, 105, 107, 108], "higher": [43, 45, 57, 64, 65, 66, 69, 109, 110], "highli": [45, 64, 105], "highlight": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 55, 62, 71, 109], "highlightcolor": [52, 53], "hint": 62, "hispan": 47, "hist": 49, "hist_e401": 45, "hist_p401": 45, "histogram": 49, "histplot": 51, "hjust": 45, "hline": [75, 94, 104, 107, 110], "hold": [29, 44, 45, 62, 63, 64, 72, 77, 78, 79], "holdout": [78, 80], "holm": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "home": [45, 64, 71], "homogen": 79, "hopefulli": 65, "horizont": [44, 56, 63], "hostedtoolcach": 64, "hot": 66, "hotstart_backward": [46, 78], "hotstart_forward": [46, 78], "household": [45, 64, 65, 70], "how": [34, 35, 38, 39, 41, 43, 44, 45, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 74, 78, 79, 105, 106], "howev": [42, 45, 51, 62, 64, 69, 71, 72, 74, 79, 110], "hown": [45, 64, 65, 70, 110], "hpwt": [44, 63], "hpwt0": 44, "hpwtairmpdspac": 44, "href": 105, "hspace": 61, "hstack": [15, 56], "html": [46, 59, 105, 107, 109], "http": [22, 28, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 78, 105, 106, 107, 109], "huber": [29, 72, 79, 81, 89, 90, 108], "hue": 64, "huge": 61, "hugo": 108, "husd": [46, 47, 75, 107], "hyperparamet": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 46, 47, 57, 61, 62, 64, 76, 107], "hypothes": [94, 104, 108], "hypothesi": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 64, 70, 95, 100, 108], "hypothet": 71, "i": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 90, 93, 94, 95, 96, 97, 100, 101, 103, 104, 105, 106, 107, 109, 110], "i0": [55, 56, 79], "i03": 105, "i1": [55, 79], "i_": [25, 63, 67], "i_1": [44, 63], "i_2": [44, 63], "i_3": [44, 63], "i_4": 56, "i_est": 51, "i_fold": 44, "i_k": [44, 63, 73, 80, 94, 104], "i_learn": 61, "i_level": 49, "i_rep": [42, 51, 55, 61, 72, 74], "i_split": 63, "i_train": 51, "icp": 108, "id": [43, 44, 46, 63], "id_var": 63, "idea": [45, 46, 64, 65, 71, 78, 79, 95, 97, 110], "ident": [18, 19, 20, 21, 24, 25, 37, 46, 49, 62, 69, 78, 79, 95, 100], "identfi": 71, "identif": [69, 79, 110], "identifi": [44, 45, 55, 60, 63, 64, 65, 69, 71, 77, 79, 95, 103, 109], "identifii": 77, "idnam": 43, "idx_tau": [54, 65, 68], "idx_treat": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 49, 95, 100], "ieee": 108, "ifels": 43, "ignor": [38, 39, 51, 69], "ii": [44, 63], "iid": 79, "iivm": [8, 22, 30, 31, 65, 73, 77, 86, 105, 109], "iivm_summari": 64, "iivmglmnet": 45, "iivmrang": 45, "iivmrpart": 45, "iivmxgboost11861": 45, "ij": [26, 44, 49, 63, 72], "ilia": 108, "illustr": [42, 44, 45, 46, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 67, 68, 70, 71, 72, 74, 78, 110], "iloc": [49, 55, 56, 61, 63, 66], "immedi": 106, "immun": [80, 108], "impact": [41, 50, 61, 66, 70], "implement": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 30, 31, 32, 38, 39, 42, 43, 44, 45, 46, 51, 55, 57, 61, 63, 64, 66, 69, 70, 71, 72, 74, 76, 77, 78, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 104, 105, 107, 108, 109, 110], "impli": [18, 19, 44, 45, 63, 64, 65, 69, 77, 79, 95, 96, 98, 99, 101], "implment": 56, "import": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 32, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 106, 107, 109, 110], "importlib": 57, "impos": 71, "improv": [55, 61, 67, 79, 109], "in_sample_norm": [5, 6, 55, 81, 84, 85, 95, 98, 99], "inbuild": 61, "inbuilt": 61, "inc": [45, 64, 65, 70, 110], "includ": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 43, 45, 49, 56, 58, 59, 64, 69, 70, 71, 77, 79, 94, 95, 96, 100, 101, 103, 104, 106, 109, 110], "include_bia": [63, 64], "include_scenario": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 71], "incom": [45, 64, 65, 67, 70, 110], "incorpor": [46, 70, 95, 100], "increas": [60, 61, 63, 71, 110], "increment": 109, "ind": 64, "independ": [5, 6, 18, 19, 20, 21, 33, 44, 46, 56, 60, 63, 67, 79, 81, 84, 85, 109], "index": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 42, 44, 47, 51, 56, 57, 58, 59, 62, 63, 64, 66, 67, 74, 75, 80, 81, 84, 85, 107], "index_col": 57, "india": [80, 108], "indic": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 24, 29, 32, 36, 44, 45, 56, 60, 63, 64, 65, 69, 71, 72, 73, 75, 77, 79, 80], "individu": [1, 9, 38, 39, 43, 45, 49, 56, 58, 59, 60, 62, 64, 65, 69, 70, 77, 79, 110], "individual_df": 56, "induc": [76, 80], "industri": [44, 63], "inf": [4, 7, 43], "inf_model": 81, "infer": [23, 25, 41, 42, 44, 50, 51, 57, 63, 74, 76, 79, 80, 105, 107, 108, 109], "inferenti": 110, "infinit": [4, 7, 109], "influenc": [39, 79], "info": [41, 46, 47, 49, 55, 60, 62, 63, 64, 65, 70, 72, 75, 107, 109, 110], "inform": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 34, 35, 36, 38, 39, 41, 46, 50, 52, 53, 61, 69, 70, 71, 79, 95, 97, 108], "infti": [42, 51, 74], "inher": 71, "inherit": [66, 109], "initi": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 32, 45, 46, 54, 55, 64, 65, 68, 69, 70, 71, 72, 75, 77, 78, 79, 80, 107, 109, 110], "inlin": [47, 66], "inlinebackend": 66, "inner": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 78], "innermost": 78, "input": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 39, 46, 70, 73, 94, 95, 97, 100, 104], "insensit": 79, "insid": [38, 39], "insight": [57, 71], "insignific": 70, "inspect": 107, "inspir": [18, 22, 23, 29, 71], "instal": [45, 62, 69, 79, 109], "install_github": 106, "instanc": [38, 39, 45, 46, 64, 78], "instanti": [44, 45, 63, 64, 78, 80], "instead": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 39, 41, 43, 45, 49, 50, 59, 60, 62, 64, 65, 77, 78, 79, 95, 98, 99, 101, 102, 109], "instruct": [106, 109], "instrument": [4, 7, 8, 11, 16, 22, 25, 44, 45, 46, 47, 49, 55, 60, 63, 64, 65, 68, 70, 72, 75, 78, 79, 81, 88, 94, 107, 110], "instrument_effect": 41, "instrument_impact": 50, "insuffienct": 62, "int": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 21, 24, 32, 33, 36, 37, 43, 44, 45, 50, 54, 55, 67, 68, 71, 72], "int64": [47, 61, 63, 75, 107], "int8": [64, 65, 70], "integ": [20, 46, 78], "integr": [62, 71, 95, 103, 109], "intend": [32, 46, 71, 110], "intent": [79, 110], "inter": 78, "interact": [1, 2, 8, 9, 18, 22, 23, 24, 32, 33, 49, 71, 76, 78, 96, 101, 105, 109, 110], "interchang": 94, "interest": [8, 9, 11, 12, 18, 19, 42, 45, 51, 55, 57, 64, 65, 69, 72, 74, 77, 79, 81, 94, 104, 107, 110], "interfac": [43, 45, 46, 75, 78, 80, 107], "intermedi": [59, 71], "intern": [43, 45, 46, 49, 62, 65, 78, 108], "internet": [45, 64, 65], "interpret": [58, 59, 71, 77, 95, 96, 97, 101, 102, 103, 106, 110], "intersect": [71, 95, 100, 109], "interv": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 36, 43, 44, 45, 49, 52, 53, 54, 55, 58, 59, 63, 65, 68, 69, 70, 72, 76, 77, 80, 81, 95, 100, 107, 108, 110], "intial": 69, "introduc": [42, 51, 74, 75, 94, 104, 109, 110], "introduct": [42, 44, 46, 51, 63, 65, 70, 78, 79, 95, 97], "introductori": [43, 71], "intrument": 72, "intspecifi": 32, "intuit": 71, "inuidur1": [46, 47, 75, 107], "inuidur1femaleblackothracedep1dep2q2q3q4q5q6agelt35agegt54durablelusdhusdtg": [46, 75, 107], "inuidur2": [47, 75, 107], "inv_sigmoid": 66, "invalid": [42, 51, 74], "invari": 79, "invers": [1, 3, 8, 9, 10, 13, 14, 15, 72, 95, 96, 101], "invert_yaxi": 63, "investig": [57, 62, 71], "involv": [77, 78, 81, 110], "io": [66, 109], "ipw_norm": 109, "ipykernel_45529": 59, "ipynb": [41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "ira": [45, 64, 65], "irm": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 23, 24, 30, 31, 36, 37, 61, 71, 73, 76, 78, 87, 96, 101, 105, 109, 110], "irm_summari": 64, "irmglmnet": 45, "irmrang": 45, "irmrpart": 45, "irmxgboost8047": 45, "irrespect": 71, "is_classifi": [1, 5, 6, 8, 9, 12], "is_gat": [1, 9, 12, 36], "isnan": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 61, 78], "isoton": 71, "isotonicregress": 71, "issn": 57, "issu": [71, 105, 108, 109], "ite": [49, 58, 59, 60], "item": [8, 64, 73, 78, 80], "iter": [32, 41, 55, 63, 69, 72, 78, 94, 104, 110], "itertool": 57, "its": [34, 35, 71, 73, 77, 78, 79, 80, 81, 94], "iv": [8, 11, 12, 22, 25, 26, 42, 44, 51, 63, 74, 75, 91, 92, 95, 102, 105, 109, 110], "iv_2": 41, "iv_var": [44, 63], "iv\u00e1n": [80, 108], "j": [16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 42, 43, 44, 46, 49, 51, 57, 63, 66, 72, 74, 78, 79, 94, 104, 105, 107], "j_": [44, 63], "j_0": 94, "j_1": [44, 63], "j_2": [44, 63], "j_3": [44, 63], "j_k": [44, 63], "jame": 108, "janni": [45, 64], "javanmard": 108, "jbe": [44, 63], "jeconom": [18, 19, 20, 43], "jerzi": 108, "jia": 71, "jk": 79, "jmlr": [46, 105, 107, 109], "job": [45, 64, 65], "joint": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 36, 49, 52, 53, 54, 58, 59, 65, 68, 79, 94, 109, 110], "jointli": [68, 77], "joss": [46, 78, 105, 107], "journal": [16, 17, 18, 19, 20, 26, 27, 29, 43, 44, 46, 57, 63, 66, 71, 74, 78, 105, 107, 108, 109], "jss": 105, "jump": [67, 69, 79], "jun": [43, 108], "jupyt": [41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "juraj": 108, "just": [43, 46, 49, 54, 55, 56, 58, 59, 60, 67, 68, 79, 81, 84, 85, 95, 97], "justif": [80, 95, 97], "k": [16, 19, 20, 22, 23, 25, 26, 27, 29, 42, 44, 46, 51, 61, 62, 63, 69, 73, 74, 76, 77, 79, 94, 104, 110], "k_h": [69, 79], "kaggl": [45, 64], "kallu": [54, 65, 68, 70, 81, 83, 88, 93, 108], "kappa": 79, "kato": [26, 44, 63, 94, 104, 108], "kb": [49, 55, 60, 63, 64, 65, 70, 75, 107], "kde": [10, 13, 14, 64], "kdeplot": [55, 61, 72], "kdeunivari": [10, 13, 14], "kecsk\u00e9sov\u00e1": 109, "keep": [39, 43, 59, 71, 110], "kei": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 32, 37, 44, 45, 52, 53, 58, 59, 62, 63, 64, 65, 69, 71, 78, 79, 81, 95, 100, 109], "keith": 108, "kengo": 108, "kernel": [10, 13, 14, 32, 39, 69, 79], "kernel_regress": 69, "kernelreg": 69, "keyword": [1, 9, 12, 20, 26, 27, 28, 33, 36], "kf": 80, "kfold": [63, 80], "kind": [41, 50, 64], "kj": [19, 20, 22, 23, 25, 26, 27, 29, 42, 44, 51, 63, 74], "klaassen": [22, 71, 105, 108], "klaa\u00dfen": 22, "knau": 108, "know": [55, 67], "knowledg": [41, 50, 61, 66, 67], "known": [60, 61, 69, 71, 78, 79], "kohei": 108, "kotthof": 46, "kotthoff": [46, 78, 105, 107], "krueger": 66, "kueck": [45, 64], "kurz": [105, 108, 109], "kwarg": [1, 9, 12, 18, 19, 20, 24, 26, 27, 28, 32, 33, 34, 36, 62, 79], "l": [44, 46, 47, 52, 53, 63, 71, 72, 78, 95, 102, 105, 107], "l1": [64, 72, 79], "l_hat": [11, 12, 42, 51, 81], "label": [38, 49, 51, 52, 53, 54, 56, 58, 59, 62, 65, 66, 68, 69], "labor": 66, "laffer": 108, "laff\u00e9r": [29, 72, 79, 81, 89, 90], "lal": [66, 109], "lambda": [44, 45, 46, 64, 66, 67, 78, 81, 85, 94, 104, 107], "lambda_": 57, "lambda_0": [81, 85], "lambda_t": 20, "land": 67, "lang": [46, 78, 105, 107], "langl": [21, 67], "lappli": 80, "larg": [42, 51, 60, 61, 62, 66, 71, 79], "larger": [9, 43, 69, 71, 95, 100], "largest": 61, "largli": 61, "lasso": [44, 45, 46, 64, 72, 78, 107, 108], "lasso_class": [45, 64], "lasso_pip": [46, 78], "lasso_summari": 64, "lassocv": [15, 57, 63, 64, 72, 78, 79, 94, 104, 107], "last": [20, 46, 106], "late": [8, 41, 45, 64, 79, 81, 86], "latent": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 70, 95, 102, 103], "later": [45, 46, 69, 71, 78, 110], "latter": [38, 39, 79], "layout": 57, "lbrace": [8, 9, 22, 23, 29, 44, 63, 73, 79, 80, 81, 82, 94, 95, 96, 104], "ldot": [11, 12, 44, 63, 72, 73, 79, 80, 94, 104, 107], "le": [20, 55, 67, 77, 79, 81, 88, 93], "lead": [43, 71, 79], "leadsto": 94, "lear": [46, 78, 105, 107], "learn": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 26, 27, 28, 29, 32, 41, 45, 46, 47, 49, 50, 54, 57, 61, 62, 64, 65, 66, 68, 69, 71, 75, 76, 78, 80, 81, 94, 95, 97, 104, 109, 110], "learner": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 41, 42, 43, 44, 45, 51, 52, 53, 55, 57, 63, 64, 65, 70, 71, 72, 73, 74, 76, 79, 80, 81, 94, 95, 100, 104, 109, 110], "learner_class": [15, 109], "learner_cv": 46, "learner_forest_classif": 46, "learner_forest_regr": 46, "learner_l": 70, "learner_lasso": 46, "learner_list": 61, "learner_m": 70, "learner_nam": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 78], "learner_param_v": 46, "learner_rf": 94, "learnerclassif": 46, "learnerregr": 46, "learnerregrcvglmnet": 46, "learnerregrrang": [46, 78], "learning_r": [51, 54, 65, 68, 69, 71, 74], "least": [41, 45, 50, 64, 65, 70, 79, 80], "leav": [71, 72], "left": [22, 23, 25, 26, 29, 42, 44, 49, 51, 61, 63, 64, 65, 66, 68, 69, 74, 79, 81, 84, 85, 94, 95, 96, 98, 99, 101, 104], "legend": [45, 49, 51, 52, 53, 54, 56, 58, 59, 61, 65, 66, 68], "len": [49, 54, 61, 62, 63, 65, 68], "length": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 42, 46, 55, 78], "leq": [44, 63], "less": [43, 45, 64, 65, 69, 71], "lester": 108, "let": [18, 19, 20, 24, 42, 43, 45, 46, 49, 51, 54, 55, 58, 59, 61, 64, 65, 68, 71, 72, 73, 74, 78, 79, 95, 97, 103, 110], "level": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 24, 32, 36, 44, 45, 49, 52, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 68, 70, 71, 72, 78, 81, 82, 95, 96, 100, 110], "level_0": [46, 63], "level_1": 63, "level_bound": 49, "levinsohn": [44, 63], "lewi": 108, "lgbmclassifi": [54, 55, 56, 61, 65, 68, 69, 71], "lgbmregressor": [51, 54, 55, 56, 61, 65, 69, 71, 74], "lgr": [42, 43, 44, 45, 46, 73, 78, 79, 80, 81, 94, 104, 107], "lib": [63, 64], "liblinear": [64, 72, 79], "librari": [41, 42, 43, 44, 45, 46, 73, 74, 75, 78, 79, 80, 81, 94, 104, 106, 107, 110], "licens": 109, "lie": 108, "lightgbm": [51, 54, 55, 56, 61, 65, 68, 69, 71], "like": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 39, 43, 45, 46, 57, 59, 64, 65, 71, 78, 80, 107, 110], "lim": 66, "lim_": [69, 79], "limegreen": [52, 53], "limit": [66, 79, 108], "limits_": 77, "lin": [69, 71, 79], "line": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 49, 56, 71], "linear": [1, 9, 11, 12, 18, 19, 24, 25, 26, 27, 28, 30, 31, 36, 41, 42, 43, 44, 46, 49, 50, 51, 52, 53, 55, 56, 57, 58, 61, 62, 63, 70, 71, 73, 74, 76, 77, 78, 80, 82, 84, 85, 86, 87, 91, 92, 94, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110], "linear_model": [1, 9, 12, 15, 36, 47, 49, 50, 57, 61, 63, 64, 69, 71, 72, 78, 79, 94, 104, 107], "linearli": [69, 79], "linearregress": [41, 49, 50, 61, 69, 71], "linearscoremixin": 81, "lineplot": 49, "linestyl": [49, 56, 62, 69], "linewidth": 56, "link": [71, 109], "linspac": [52, 53, 71], "lint": 109, "linux": 106, "list": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 39, 42, 43, 44, 45, 46, 51, 52, 53, 63, 65, 67, 74, 78, 80, 81, 106, 109], "listedcolormap": 63, "literatur": [71, 79], "littl": 60, "ll": [46, 94, 104, 110], "lllllllllllllllll": [75, 107], "lm": [41, 43, 71], "ln_alpha_ml_l": 57, "ln_alpha_ml_m": 57, "load": [41, 43, 45, 46, 57, 64, 65, 75, 106, 107], "loc": [49, 51, 54, 56, 57, 59, 63, 66, 68, 70, 71], "local": [8, 10, 77, 79, 108, 109], "localconvert": 63, "locat": [54, 68, 79], "log": [44, 57, 61, 63, 66, 70, 78, 79], "log_odd": 67, "log_p": [44, 63], "log_reg": [41, 43], "logarithm": 57, "logic": [8, 46, 78], "logical_not": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 61, 78], "logist": [18, 33, 41, 43, 45, 49, 50, 64, 71, 72, 110], "logisticregress": [41, 47, 49, 50, 69, 71], "logisticregressioncv": [15, 61, 64, 72, 79], "logit": [61, 66], "loglik": 46, "logloss": [45, 64, 110], "logo": 109, "logspac": 64, "long": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 42, 51, 61, 70, 71, 95, 97, 103, 108], "look": [43, 45, 46, 54, 55, 56, 61, 64, 65, 68, 69, 70], "loop": 49, "loss": [61, 62, 69, 70, 78, 79], "loss_ml_g0": 61, "loss_ml_g1": 61, "loss_ml_m": 61, "low": [56, 60, 77, 108], "lower": [45, 46, 49, 54, 56, 57, 60, 65, 66, 68, 69, 70, 71, 78, 95, 100, 103, 110], "lower_bound": [52, 53], "lpq": [10, 14, 65, 77, 88, 109], "lpq_0": 68, "lpq_1": 68, "lqte": 77, "lr": 69, "lrn": [41, 42, 43, 44, 45, 46, 73, 78, 79, 80, 81, 94, 104, 107, 110], "lrn_0": 46, "lt": [41, 43, 44, 45, 46, 47, 49, 55, 60, 63, 64, 65, 67, 70, 71, 72, 75, 107], "lucien": 109, "luka": 108, "luk\u00e1\u0161": 29, "lusd": [46, 47, 75, 107], "lvert": 57, "m": [15, 16, 17, 18, 25, 26, 27, 42, 44, 46, 47, 51, 57, 60, 63, 66, 74, 76, 77, 78, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 98, 99, 101, 102, 103, 105, 106, 107, 108, 109], "m_": [49, 79, 81, 82, 88, 94, 104], "m_0": [1, 3, 5, 6, 8, 9, 11, 12, 13, 27, 28, 32, 42, 44, 45, 51, 57, 60, 62, 63, 64, 74, 77, 78, 79, 81, 83, 84, 85, 88, 89, 90, 93, 107, 110], "m_hat": [8, 9, 11, 12, 42, 51, 81], "m_i": [69, 79], "ma": [26, 44, 63, 108], "mac": 106, "machin": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 26, 27, 28, 29, 32, 41, 45, 46, 47, 49, 50, 54, 55, 57, 62, 64, 65, 66, 68, 69, 70, 71, 72, 76, 78, 79, 80, 81, 94, 95, 97, 104, 109, 110], "machineri": [57, 108], "mackei": 108, "maco": 106, "made": [79, 110], "mae": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 61, 78], "maggi": 108, "magnitud": [95, 97], "mai": [39, 55, 72], "main": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 57, 65, 71, 79, 94, 95, 97, 104, 108, 110], "mainli": 71, "maintain": [43, 105, 109], "mainten": 109, "major": [46, 71, 109], "make": [41, 49, 50, 61, 62, 71, 77, 78, 109, 110], "make_confounded_irm_data": [71, 109], "make_confounded_plr_data": 70, "make_did_sz2020": [5, 6, 55, 79], "make_heterogeneous_data": [52, 53, 58, 59, 60], "make_iivm_data": [8, 10, 77, 79], "make_irm_data": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 61, 77, 78, 79], "make_irm_data_discrete_treat": 49, "make_pipelin": 64, "make_pliv_chs2015": [11, 79], "make_pliv_multiway_cluster_ckms2021": [4, 44, 63], "make_plr_ccddhnr2018": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 42, 51, 62, 73, 74, 77, 78, 79, 80, 81, 94, 95, 100], "make_simple_rdd_data": [32, 69, 79], "make_spd_matrix": 28, "make_ssm_data": [72, 79], "malt": [105, 108], "maltekurz": 105, "man": [41, 50], "manag": [78, 106], "mani": [25, 30, 31, 42, 43, 44, 46, 51, 55, 62, 63, 74, 81, 94, 104, 110], "manili": 36, "manipul": [45, 46, 69, 79], "manual": [45, 62, 70, 110], "mao": 108, "map": [8, 34, 35, 38, 39, 43, 44, 63, 77, 79], "mapsto": [73, 77], "mar": [29, 79], "margin": [52, 53, 71], "marit": [45, 64], "marker": [49, 71], "markers": 66, "market": 66, "markettwo": 44, "markov": [28, 108], "marr": [45, 64, 65, 70, 110], "marshal": 78, "martin": [29, 71, 105, 108, 109], "masatoshi": 108, "master": 43, "mat": 44, "match": [78, 95, 102], "math": 15, "mathbb": [8, 9, 11, 12, 18, 19, 20, 24, 30, 31, 44, 49, 55, 56, 60, 61, 62, 63, 66, 69, 72, 77, 79, 81, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 107, 110], "mathcal": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 42, 44, 51, 54, 56, 63, 67, 68, 72, 74], "mathop": 77, "mathrm": [18, 19, 69, 79], "matia": 108, "matplotlib": [47, 49, 51, 52, 53, 54, 55, 56, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72], "matric": [67, 76, 109], "matrix": [18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 39, 42, 44, 45, 46, 51, 63, 72, 74, 75, 78, 94, 104, 107, 109, 110], "matt": 108, "matter": [61, 66], "max": [45, 46, 64, 65, 73, 77, 78, 79, 80, 81, 83, 94, 107, 110], "max_depth": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 47, 64, 70, 73, 77, 78, 79, 80, 81, 94, 95, 100, 107, 110], "max_featur": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 47, 64, 70, 73, 77, 78, 79, 80, 81, 94, 95, 100, 107, 110], "max_it": [63, 64, 71], "maxim": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 67, 77, 79], "maxima": [94, 104], "maximum": [77, 78], "mb": [47, 72, 75, 107], "mb706": 109, "mea": 22, "mean": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 39, 41, 42, 44, 45, 49, 50, 51, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 74, 78, 79, 94, 110], "mean_absolute_error": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 61, 78], "meant": [77, 109], "measir": 70, "measur": [43, 46, 57, 62, 70, 71, 78, 79, 95, 96, 97, 101, 102, 103], "measure_col": 57, "measure_func": 43, "measure_pr": 43, "measures_r": 43, "mechan": [34, 35, 38, 39, 71], "median": [71, 80], "melt": 44, "membership": 71, "memori": [47, 49, 55, 60, 63, 64, 65, 70, 72, 75, 107], "mention": [60, 77], "merg": [45, 64], "mert": [80, 108], "meshgrid": [52, 53, 71], "messag": [42, 43, 44, 45, 46, 107, 109], "meta": [38, 39, 78, 107], "metadata": [34, 35, 38, 39], "metadata_rout": [38, 39], "metadatarequest": [34, 35, 38, 39], "method": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 58, 59, 61, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 80, 81, 94, 95, 97, 100, 104, 105, 107, 109], "methodolog": 108, "methodologi": 71, "metric": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 78], "michael": 108, "michaela": 109, "michel": [105, 107], "michela": [29, 108], "mid": [45, 64, 66, 69, 79], "mid_point": 49, "might": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 44, 54, 61, 63, 67, 69, 70, 71, 78, 79], "mild": [42, 51, 74], "militari": 66, "miller": [44, 63], "mimic": 71, "min": [44, 45, 46, 54, 63, 64, 65, 68, 69, 73, 78, 79, 80, 81, 94, 104, 107, 110], "min_": 77, "min_samples_leaf": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 37, 60, 64, 70, 73, 77, 78, 79, 80, 81, 94, 95, 100, 110], "min_samples_split": 64, "minim": [9, 37, 45, 61, 64, 69, 79], "minor": [42, 51, 74, 81, 109], "minsplit": 45, "minut": 62, "miruna": 108, "mislead": 109, "miss": [4, 7, 15, 46, 78, 79, 81, 89, 109], "missing": [29, 72], "misspecif": 55, "misspecifi": 55, "mit": [105, 107], "mixin": [30, 31, 81], "ml": [28, 44, 45, 46, 57, 62, 63, 64, 69, 73, 76, 78, 79, 80, 105, 108, 109], "ml_g": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 41, 42, 43, 45, 47, 49, 50, 51, 52, 54, 55, 56, 58, 60, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 77, 78, 79, 109], "ml_g0": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 43, 45, 47, 55, 61, 64, 70, 78, 79], "ml_g1": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 43, 45, 47, 55, 61, 64, 70, 78, 79], "ml_g_d0": [72, 79], "ml_g_d0_t0": [55, 79], "ml_g_d0_t1": [55, 79], "ml_g_d1": [72, 79], "ml_g_d1_t0": [55, 79], "ml_g_d1_t1": [55, 79], "ml_g_sim": 15, "ml_l": [11, 12, 42, 44, 45, 46, 47, 51, 53, 59, 62, 63, 64, 66, 70, 73, 74, 78, 79, 80, 81, 94, 95, 100, 104, 107, 109, 110], "ml_l_bonu": 107, "ml_l_forest": 46, "ml_l_forest_pip": 46, "ml_l_lasso": 46, "ml_l_lasso_pip": 46, "ml_l_rf": 110, "ml_l_sim": 107, "ml_l_tune": 78, "ml_l_xgb": 110, "ml_m": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 80, 81, 94, 95, 100, 104, 107, 109, 110], "ml_m_bench_control": 71, "ml_m_bench_treat": 71, "ml_m_bonu": 107, "ml_m_forest": 46, "ml_m_forest_pip": 46, "ml_m_lasso": 46, "ml_m_lasso_pip": 46, "ml_m_rf": 110, "ml_m_sim": [15, 107], "ml_m_tune": 78, "ml_m_xgb": 110, "ml_pi": [15, 72, 79], "ml_pi_sim": 15, "ml_r": [8, 11, 41, 44, 45, 50, 63, 64, 79, 109], "ml_r0": 79, "ml_r1": [45, 64, 79], "mlr": [46, 78], "mlr3": [41, 42, 43, 44, 45, 73, 78, 79, 80, 81, 94, 104, 105, 107, 109, 110], "mlr3book": [46, 78], "mlr3extralearn": [45, 78], "mlr3filter": 46, "mlr3learner": [41, 42, 43, 44, 45, 73, 78, 79, 80, 81, 94, 104, 107, 110], "mlr3measur": 43, "mlr3pipelin": [78, 109], "mlr3tune": [46, 78, 109], "mlr3vers": 45, "mlrmeasur": 43, "mode": [71, 106], "model": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 39, 40, 41, 42, 43, 44, 46, 50, 51, 54, 55, 56, 57, 60, 61, 63, 65, 68, 70, 73, 74, 75, 76, 78, 82, 84, 85, 86, 87, 91, 92, 96, 97, 100, 101, 102, 103, 104, 105, 108, 109], "model_data": [45, 64], "model_label": 62, "model_select": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 51, 63, 78, 80], "modelmlestimatelowerupp": 45, "modern": [46, 78, 105, 107], "modul": [69, 79, 106], "moment": [30, 31, 44, 63, 81, 94, 95, 97, 103, 104, 107], "monoton": 79, "mont": [18, 19, 21, 24, 52, 53, 58, 59], "montanari": 108, "more": [9, 36, 41, 43, 45, 49, 50, 52, 53, 57, 61, 62, 64, 65, 69, 70, 71, 73, 77, 78, 79, 81, 87, 94, 95, 97, 100, 103, 107, 110], "moreov": [45, 46, 57, 78, 94, 104, 110], "mortgag": [45, 64, 65], "most": [45, 54, 61, 64, 65, 68, 71, 77, 78, 79, 95, 100, 106], "motiv": [71, 74], "motivation_example_bch": 57, "mp": 43, "mpd": [44, 63], "mpg": 63, "mse": [46, 57, 78], "mserd": 69, "msr": [46, 78], "mtry": [45, 46, 73, 78, 79, 80, 81, 94, 110], "mu": 56, "mu_": 56, "mu_0": 79, "mu_mean": 56, "much": [45, 46, 64, 69, 71, 110], "muld": [47, 75, 107], "multi": [38, 43, 44, 52, 53, 63], "multiclass": [46, 62], "multiindex": 63, "multioutput": 39, "multioutputregressor": 39, "multipl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 24, 43, 44, 45, 55, 63, 64, 70, 71, 72, 75, 78, 80, 94, 95, 97, 104, 109, 110], "multipletest": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "multipli": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 51, 76, 77, 81, 110], "multiprocess": [54, 65, 68], "multitest": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "multivariate_norm": 15, "multiwai": [26, 44, 63, 108], "music": 108, "must": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 78, 79], "mutat": 46, "mutual": [1, 9, 12, 45, 58, 59, 64, 65, 77], "my_sampl": 80, "my_task": 80, "n": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 33, 41, 42, 44, 46, 49, 50, 51, 54, 56, 57, 60, 63, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 80, 94, 104, 105, 106], "n_": [24, 56], "n_coef": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 95, 100], "n_complier": 68, "n_core": [54, 65, 68], "n_estim": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 47, 51, 52, 53, 54, 55, 56, 58, 59, 60, 64, 65, 67, 68, 69, 70, 71, 73, 74, 77, 78, 79, 80, 81, 94, 95, 100, 107, 110], "n_eval": [46, 78], "n_featur": [38, 39], "n_fold": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 42, 43, 44, 45, 47, 51, 52, 53, 54, 55, 58, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 78, 80, 107, 110], "n_folds_per_clust": [44, 63], "n_folds_tun": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "n_iter": [32, 69, 79], "n_iter_randomized_search": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 78], "n_job": 64, "n_jobs_cv": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 61], "n_jobs_model": [2, 14, 54, 65, 68], "n_level": [24, 49], "n_ob": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 33, 36, 37, 42, 46, 49, 51, 52, 53, 55, 56, 58, 59, 60, 61, 62, 69, 70, 71, 72, 74, 75, 77, 78, 79, 80, 94, 95, 100, 104, 107], "n_output": [38, 39], "n_rep": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 42, 43, 44, 47, 49, 51, 55, 60, 61, 63, 69, 70, 71, 72, 74, 78, 80, 95, 100, 107, 110], "n_rep_boot": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 36, 49, 52, 53, 54, 58, 59, 65, 68, 94, 104], "n_sampl": [38, 39, 67], "n_samples_fit": 39, "n_split": 80, "n_t": 56, "n_target": [38, 39], "n_time_period": 56, "n_true": [54, 68], "n_var": [42, 46, 51, 74, 75, 78, 94, 104, 107], "n_w": 67, "n_x": [21, 52, 53, 58, 59, 60], "na": [4, 7, 42, 44, 74, 109], "na_real_": [44, 109], "naiv": [42, 51, 74], "name": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 34, 35, 38, 39, 42, 43, 44, 58, 59, 60, 62, 63, 69, 70, 71, 78, 106, 109], "namespac": 43, "nan": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 49, 51, 54, 55, 56, 58, 59, 61, 62, 64, 65, 68, 72, 74, 78], "nanmean": 51, "narita": 108, "nathan": 108, "nation": [71, 80, 108], "nativ": 43, "natt": 67, "natur": 71, "ncol": [44, 45, 46, 69, 75, 78, 94, 104, 107], "ncoverag": 61, "ndarrai": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 20, 22, 23, 25, 26, 27, 28, 29, 75], "nearli": 61, "necess": [44, 63], "necessari": [43, 44, 62, 63, 69, 79, 106], "need": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 31, 41, 42, 43, 45, 50, 51, 62, 65, 72, 78, 80, 95, 103, 109, 110], "neg": 39, "neighborhood": [69, 94], "neither": [4, 7, 44, 63, 75], "neng": 108, "neq": [69, 79], "nest": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 39, 78, 81, 90, 95, 100], "net": [65, 70, 110], "net_tfa": [45, 64, 65, 70, 110], "never": [8, 43, 44, 59, 63, 109], "never_tak": [8, 45, 64], "new": [41, 42, 43, 44, 45, 46, 52, 53, 62, 64, 67, 73, 74, 75, 77, 78, 79, 80, 81, 94, 104, 105, 107, 108, 109, 110], "new_data": [52, 53, 67], "newei": [16, 17, 27, 44, 57, 63, 71, 74, 105, 108], "newest": 109, "next": [43, 45, 46, 52, 53, 54, 60, 61, 64, 65, 67, 68, 71, 109], "neyman": [44, 63, 73, 76, 95, 103, 105, 108], "nfold": [44, 45], "nh": 79, "nice": 43, "nifa": [64, 65, 70], "nil": 71, "nine": [44, 63], "nn": 69, "noack": [69, 79, 108, 109], "node": [45, 46, 73, 79, 80, 81, 94, 107, 110], "nois": [33, 66, 67], "non": [20, 26, 27, 28, 32, 41, 42, 45, 50, 51, 56, 64, 65, 67, 69, 78, 80, 81, 94], "non_orth_scor": [42, 51, 81], "nondur": 47, "none": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 24, 32, 36, 38, 39, 44, 45, 47, 49, 50, 55, 60, 64, 65, 70, 71, 72, 75, 78, 79, 81, 94, 106, 107], "nonignor": [15, 90], "nonlinear": [31, 45, 64, 69, 79, 81, 88, 93, 109], "nonlinearscoremixin": 81, "nonparametr": [10, 13, 14, 69, 71, 95, 96, 97, 101, 102, 103, 108], "nop": 46, "nor": [4, 7, 44, 63, 75], "norm": 51, "normal": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 20, 42, 50, 51, 54, 55, 56, 60, 65, 66, 67, 68, 69, 72, 74, 75, 78, 79, 81, 84, 85, 94, 104, 107], "normalize_ipw": [1, 2, 3, 8, 9, 10, 13, 14, 15, 65, 72], "notat": [44, 55, 63, 72, 79], "note": [4, 7, 8, 9, 11, 12, 15, 30, 31, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 80, 81, 105, 107], "notebook": [41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 77, 78, 79, 110], "notic": [41, 50], "now": [43, 44, 45, 52, 53, 61, 63, 64, 67, 71, 72, 107, 109], "np": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 22, 23, 25, 26, 27, 28, 29, 32, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 107, 110], "nround": [42, 45, 110], "nrow": [43, 44, 46, 69, 75, 78, 94, 104, 107], "nu": [8, 20, 28, 72, 79, 95, 97, 100, 102, 103], "nu2": [95, 100], "nu_0": [95, 103], "nu_i": 72, "nuis_g0": 41, "nuis_g1": 41, "nuis_l": 110, "nuis_m": [41, 110], "nuis_r0": 41, "nuis_r1": 41, "nuis_rmse_ml_l": 57, "nuis_rmse_ml_m": 57, "nuisanc": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 27, 28, 32, 42, 43, 44, 45, 46, 51, 52, 53, 54, 55, 57, 60, 61, 63, 64, 65, 68, 70, 71, 72, 73, 74, 78, 79, 80, 81, 82, 84, 85, 88, 94, 95, 103, 105, 109, 110], "nuisance_el": [95, 96, 98, 99, 101, 102], "nuisance_loss": [61, 78, 109], "nuisance_target": 61, "null": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 43, 70, 78, 95, 100, 109], "null_hypothesi": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 70, 95, 100], "num": [45, 46, 73, 78, 79, 80, 81, 94, 107], "num_leav": [54, 56, 65, 68], "number": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 36, 37, 39, 42, 44, 51, 52, 53, 54, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 80, 94, 104, 105, 107, 110], "numer": [31, 41, 46, 66, 78, 81, 95, 96, 101, 109], "numeric_onli": 57, "numpi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 32, 36, 37, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 107], "ny": 108, "o": [49, 56, 58, 59, 62, 64, 66, 69, 94, 105, 107], "ob": [43, 45, 56, 69], "obei": 81, "obj_dml_data": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 41, 42, 44, 50, 51, 54, 62, 63, 68, 73, 74, 77, 78, 79, 80, 81, 94, 95, 100, 109], "obj_dml_data_bonu": 75, "obj_dml_data_bonus_df": 75, "obj_dml_data_from_arrai": [4, 7], "obj_dml_data_from_df": [4, 7], "obj_dml_data_sim": 75, "obj_dml_plr": [42, 51, 74], "obj_dml_plr_bonu": [46, 107], "obj_dml_plr_bonus_pip": 46, "obj_dml_plr_bonus_pipe2": 46, "obj_dml_plr_bonus_pipe3": 46, "obj_dml_plr_bonus_pipe_ensembl": 46, "obj_dml_plr_fullsampl": 62, "obj_dml_plr_lesstim": 62, "obj_dml_plr_nonorth": [42, 51], "obj_dml_plr_orth_nosplit": [42, 51], "obj_dml_plr_sim": [46, 107], "obj_dml_plr_sim_pip": 46, "obj_dml_plr_sim_pipe_ensembl": 46, "obj_dml_plr_sim_pipe_tun": 46, "obj_dml_sim": 15, "object": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 32, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 49, 52, 53, 54, 55, 59, 60, 62, 64, 65, 68, 69, 72, 75, 77, 78, 79, 80, 81, 94, 105, 107, 108, 109, 110], "obs_confound": [41, 50], "observ": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 84, 85, 94, 95, 97, 98, 99, 107, 108, 110], "obtain": [19, 41, 42, 43, 44, 50, 51, 52, 53, 54, 55, 57, 61, 63, 68, 71, 72, 73, 74, 77, 78, 80, 81, 94, 95, 97, 100, 104, 106, 107], "occur": [62, 109], "off": [67, 108], "offer": [43, 45, 64, 65, 71, 110], "offici": 106, "often": 68, "oka": 108, "ol": [1, 9, 12, 36], "olma": [69, 79, 108, 109], "omega": [60, 77, 81, 82, 87, 95, 96, 101], "omega_": [26, 44, 63], "omega_1": [26, 44, 63], "omega_2": [26, 44, 63], "omega_epsilon": [44, 63], "omega_v": [26, 44, 63], "omega_x": [26, 44, 63], "omit": [70, 71, 95, 97, 103, 108, 109, 110], "ommit": 71, "onc": [43, 62, 71, 79, 110], "one": [11, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 61, 63, 65, 66, 69, 70, 71, 74, 77, 78, 79, 80, 81, 84, 85, 87, 91, 92, 94, 95, 96, 97, 100, 101, 102, 104, 107, 109], "ones": [46, 54, 56, 62, 68, 70, 77], "ones_lik": [49, 68], "onli": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 36, 38, 39, 43, 44, 45, 52, 53, 58, 59, 60, 61, 62, 63, 64, 65, 69, 73, 77, 78, 79, 81, 83, 88, 93, 94, 95, 96, 97, 101, 103, 109], "onlin": 110, "onto": 61, "oo": 62, "oob_error": [46, 78], "oop": 109, "opac": [52, 53], "open": [46, 78, 105, 107], "oper": 46, "opposit": [67, 69, 79], "oprescu": [21, 52, 53, 58, 59, 108], "opt": 64, "optim": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 32, 46, 52, 53, 62, 67, 77, 78, 108], "option": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 38, 39, 41, 42, 44, 45, 49, 52, 53, 58, 59, 60, 61, 63, 64, 65, 72, 78, 79, 80, 81, 83, 88, 93, 94, 104, 109], "oracl": [24, 33, 49], "oracle_valu": [18, 19, 24, 33, 49], "orang": 42, "orcal": [18, 19], "order": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 43, 44, 45, 46, 63, 64, 69, 78, 79, 80, 81], "org": [22, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 78, 105, 106, 109], "orient": [46, 78, 81, 105, 107, 108, 109], "origin": [37, 38, 39, 43, 46, 59, 67, 70, 71, 77], "orign": [45, 64], "orth_sign": [36, 37], "orthogon": [36, 37, 44, 45, 63, 64, 73, 76, 79, 94, 95, 103, 104, 105, 108], "orthongon": [95, 103], "osx": 106, "other": [4, 7, 11, 12, 38, 39, 42, 44, 45, 46, 49, 51, 55, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 77, 78, 79, 80, 81, 87, 94, 95, 103, 105, 106, 107, 108, 109, 110], "other_ind": 63, "otherwis": [1, 5, 6, 8, 9, 12, 38, 39, 45, 64, 65, 67, 79], "othrac": [46, 47, 75, 107], "our": [42, 43, 45, 46, 51, 52, 53, 54, 55, 61, 62, 64, 65, 68, 69, 70, 71, 74, 79, 105, 107, 109, 110], "ourselv": 61, "out": [11, 12, 44, 46, 47, 55, 57, 61, 62, 63, 65, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 91, 92, 94, 95, 97, 100, 102, 105, 107, 109, 110], "outcom": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 24, 33, 41, 43, 44, 45, 46, 47, 50, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 75, 78, 82, 94, 96, 97, 100, 102, 103, 107, 109, 110], "outcome_0": 50, "outcome_1": 50, "outer": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 78], "output": [43, 61, 73, 94, 104, 110], "outshr": 63, "outsid": 42, "over": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 42, 49, 51, 57, 61, 74, 76, 78, 95, 100, 104], "overal": [67, 71], "overcom": [76, 81], "overfit": [62, 76, 80], "overlap": [55, 71, 79], "overrid": [78, 109], "overridden": 79, "overst": [45, 64, 65], "overview": [61, 94, 95, 100, 108], "overwrit": 109, "ownership": [45, 64], "p": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 32, 33, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 90, 93, 94, 95, 96, 101, 104, 105, 106, 107, 109], "p401": [45, 64, 65], "p_0": [81, 84, 85], "p_1": [94, 104], "p_adjust": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 80, 94, 104, 105, 107], "p_dbl": [46, 78], "p_int": 78, "p_n": 25, "p_val": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "p_x": [26, 44, 63], "p_x0": 66, "p_x1": 66, "packag": [41, 42, 44, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 62, 63, 65, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 80, 81, 94, 95, 97, 105, 107, 108, 109, 110], "packagedata": 63, "packagevers": 45, "page": [71, 105, 108], "pair": [41, 50], "pake": [44, 63], "paket": [44, 45, 46], "pal": 44, "palett": 49, "panda": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 36, 37, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 77, 79, 95, 97, 107], "pandas2ri": 63, "panel": [5, 20, 99, 108, 109], "paper": [22, 25, 46, 62, 66, 69, 70, 71, 95, 103, 105, 107, 108, 109], "par": 47, "par_grid": [46, 78], "paradox": [46, 78, 109], "parallel": [43, 49, 54, 55, 56, 61, 68, 79], "param": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 34, 35, 38, 39, 62, 78], "param_grid": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 78], "param_nam": 43, "param_set": [46, 78], "param_v": 46, "paramet": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 49, 51, 52, 53, 54, 55, 57, 60, 61, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 88, 93, 94, 95, 97, 100, 101, 103, 104, 105, 107, 108, 109, 110], "parametr": [43, 71, 74, 78, 110], "params_exact": 78, "params_nam": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 43], "parenttoc": 105, "part": [28, 42, 44, 45, 46, 51, 61, 62, 63, 64, 74, 78, 80, 95, 103, 109, 110], "parti": 28, "partial": [11, 12, 19, 25, 26, 27, 28, 31, 44, 46, 47, 57, 62, 63, 70, 73, 76, 78, 80, 91, 92, 94, 96, 100, 101, 102, 103, 104, 105, 107, 109, 110], "partial_": [81, 94], "partiallli": 70, "particip": [16, 65, 70, 110], "particular": [79, 105], "particularli": 62, "partion": [44, 63], "partit": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 44, 63, 73, 76], "partli": 110, "pass": [1, 9, 12, 36, 38, 39, 43, 46, 62, 78, 110], "passo": [105, 107], "past": 44, "paste0": 44, "pastel": 51, "path": [78, 79], "path_to_r": 57, "patsi": [52, 53, 77], "pattern": 71, "paul": 108, "pd": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 32, 36, 49, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 77, 79], "pdf": [51, 66], "pedregosa": [105, 107], "pedregosa11a": [105, 107], "pedro": [43, 108], "penal": 72, "penalti": [45, 46, 50, 64, 71, 72, 78, 79], "pennsylvania": [17, 75, 107], "pension": [45, 64, 65, 110], "peopl": [45, 64, 65], "pep8": 109, "per": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 44, 63], "percent": 78, "percentag": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19], "perf_count": 61, "perfectli": [69, 79], "perform": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 37, 42, 44, 46, 51, 55, 57, 59, 60, 61, 62, 63, 65, 70, 71, 72, 74, 78, 79, 80, 81, 94, 104, 105, 107, 108, 110], "perfrom": 60, "perhap": 110, "period": [5, 43, 55, 56, 79], "perp": 79, "perrot": [105, 107], "person": 110, "pessimist": 71, "peter": 108, "pfister": [46, 78, 105, 107], "phi": [44, 63, 77, 94], "philipp": [71, 105, 108], "philippbach": [105, 109], "pi": [15, 23, 25, 28, 77, 79, 81, 89, 90], "pi_": [26, 44, 63], "pi_0": [81, 89, 90], "pi_i": [72, 79], "pick": [69, 110], "pip": [69, 79], "pip3": 106, "pipe": 46, "pipe_forest_classif": 46, "pipe_forest_regr": 46, "pipe_lasso": 46, "pipelin": [38, 39, 46, 64, 109], "pipeop": 46, "pira": [45, 64, 65, 70, 110], "pivot": [57, 63, 108], "plai": [62, 110], "plan": [16, 45, 64, 65, 110], "plausibl": 71, "pleas": [34, 35, 38, 39, 43, 49, 62, 71, 80, 106], "plim": 66, "pliv": [11, 30, 31, 44, 63, 73, 77, 91, 105, 109], "plm": [76, 78, 94, 95, 100, 110], "plot": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 37, 42, 43, 45, 46, 49, 51, 52, 53, 54, 56, 57, 58, 59, 60, 64, 65, 66, 68, 69, 70, 71, 72, 77, 95, 100], "plot_tre": [37, 67, 77], "plotli": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 52, 53, 57, 69, 71], "plr": [12, 30, 31, 46, 62, 66, 70, 73, 78, 80, 92, 94, 100, 101, 102, 103, 104, 105, 107, 109, 110], "plr_est": 66, "plr_est1": 66, "plr_est2": 66, "plr_obj": 66, "plr_obj_1": 66, "plr_obj_2": 66, "plr_summari": 64, "plrglmnet": 45, "plrranger": 45, "plrrpart": 45, "plrxgboost8700": 45, "plt": [47, 49, 51, 52, 53, 54, 55, 56, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72], "plt_smpl": [44, 63], "plt_smpls_cluster": [44, 63], "plug": [60, 95, 96, 98, 99, 100, 101], "pm": [32, 44, 63, 94, 95, 100, 103, 104], "pmatrix": 72, "po": [46, 78], "point": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 43, 44, 58, 59, 63, 71, 77, 79, 110], "pointwis": [36, 54, 58, 59, 68], "poli": [45, 63, 64], "polici": [9, 11, 12, 37, 76, 79, 107, 108, 109], "policy_tre": [9, 67, 77], "policy_tree_2": 67, "policy_tree_obj": 77, "policytre": 67, "polit": 66, "poly_dict": 64, "polynomi": [16, 17, 33, 45, 47, 64, 69], "polynomial_featur": [16, 17, 45, 47], "polynomialfeatur": [63, 64], "popul": [71, 81], "popular": [61, 79, 95, 97], "porport": 70, "posit": [28, 45, 66, 71, 110], "posixct": [46, 78], "possibl": [4, 7, 38, 39, 43, 46, 52, 53, 58, 59, 60, 61, 62, 67, 69, 70, 71, 78, 79, 94, 95, 97, 109, 110], "possibli": [95, 97], "post": [25, 28, 79, 94, 104, 108], "postdoubl": 108, "poster": 66, "potenti": [1, 2, 3, 10, 13, 15, 18, 24, 33, 55, 66, 69, 72, 82, 83, 94, 96, 106, 109, 110], "potential_level": 49, "power": [46, 62, 71, 78, 108], "pp": 43, "pq": [10, 13, 14, 65, 93, 109], "pq_0": [65, 68], "pq_1": [65, 68], "pr": [15, 41, 44, 45, 46, 78, 79, 80, 81, 94, 107, 110], "practic": [61, 71, 108], "pre": [43, 55, 72, 78, 79], "precis": [43, 79, 95, 101, 110], "precomput": 39, "pred": [43, 62], "pred_df": 67, "pred_dict": 78, "pred_treat": 67, "predict": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 32, 34, 35, 36, 37, 38, 39, 42, 44, 45, 46, 51, 54, 57, 61, 62, 63, 64, 67, 71, 74, 77, 80, 95, 97, 100, 101, 109, 110], "predict_proba": [1, 3, 5, 6, 8, 9, 10, 12, 13, 14, 15, 32, 34, 38, 39, 62, 78], "predictor": [1, 9, 12, 36, 37, 52, 53, 58, 59, 71, 73], "prefer": [45, 64, 65, 110], "preliminari": [3, 42, 51, 69, 81, 83, 88, 90, 93], "prepar": [43, 44, 63, 109], "preprint": 108, "preprocess": [45, 63, 64, 65, 78], "presenc": [45, 64, 65], "present": [43, 71, 78, 110], "prespecifi": 70, "pretest": 43, "pretreat": [5, 6, 43, 55], "prettenhof": [105, 107], "preval": 71, "prevent": [80, 109], "previou": [56, 60, 66, 106, 110], "previous": [78, 110], "price": [44, 63], "priliminari": [10, 14], "primari": 49, "principl": [95, 97], "print": [32, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 106, 107, 109, 110], "print_detail": 43, "prior": [61, 79], "privat": 109, "prob": 46, "probabilit": 60, "probabl": [1, 3, 8, 9, 10, 13, 14, 15, 20, 24, 38, 42, 43, 49, 51, 55, 60, 66, 68, 69, 71, 72, 74, 79, 81, 84, 85, 88, 108], "problem": [45, 64, 65, 77, 78], "procedur": [42, 44, 45, 51, 61, 63, 64, 70, 71, 78, 94, 104, 106, 109], "proceed": [25, 108], "process": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 43, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 67, 68, 71, 72, 76, 94, 95, 97, 104, 108, 109], "produc": 66, "product": [52, 53, 57, 61, 71, 95, 103], "producton": 44, "program": [23, 45, 64, 65, 108, 110], "progress": 48, "project": [46, 52, 53, 77, 105, 109], "project_z": [52, 53], "prone": 81, "pronounc": 69, "propens": [10, 14, 18, 19, 45, 55, 60, 61, 64, 65, 71, 72, 77, 79, 95, 96], "properli": [62, 110], "properti": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 46, 61, 64, 65, 66, 70, 78, 79, 95, 100, 107, 109], "proport": [70, 95, 97, 102, 103], "propos": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 44, 46, 63, 69, 95, 97, 108, 109], "provid": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 32, 38, 39, 43, 44, 45, 46, 52, 53, 58, 59, 62, 63, 64, 69, 71, 73, 74, 75, 76, 78, 94, 104, 105, 107, 109, 110], "prune": [9, 37], "ps911c": 63, "ps944": 63, "pscore1": 66, "pscore2": 66, "psi": [30, 31, 42, 43, 44, 63, 73, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 103, 107], "psi_": [94, 95, 100, 102, 103, 104], "psi_a": [8, 9, 11, 12, 30, 42, 44, 51, 63, 80, 81, 82, 84, 85, 86, 87, 91, 92, 94], "psi_b": [8, 9, 11, 12, 30, 42, 51, 77, 80, 81, 82, 84, 85, 86, 87, 91, 92], "psi_el": [80, 81], "psi_j": [94, 104], "psi_nu2": [95, 100], "psi_sigma2": [95, 100], "public": [41, 50, 109], "publish": [71, 109], "pull": [45, 109], "purchas": 71, "pure": 71, "purp": [52, 53], "purpos": [42, 51, 60, 70, 71, 95, 97, 107], "pval": [94, 104], "px": [57, 69], "py": [59, 63, 64, 71, 105, 106, 109], "py3": 106, "py_al": 51, "py_dml": 51, "py_dml_nosplit": 51, "py_dml_po": 51, "py_dml_po_nosplit": 51, "py_double_ml_apo": 49, "py_double_ml_bas": 51, "py_double_ml_basic_iv": 50, "py_double_ml_c": 52, "py_double_ml_cate_plr": 53, "py_double_ml_cvar": 54, "py_double_ml_did": 55, "py_double_ml_did_pretest": 56, "py_double_ml_firststag": 57, "py_double_ml_g": 58, "py_double_ml_gate_plr": 59, "py_double_ml_gate_sensit": 60, "py_double_ml_learn": 61, "py_double_ml_meets_flaml": 62, "py_double_ml_multiway_clust": 63, "py_double_ml_pens": 64, "py_double_ml_pension_qt": 65, "py_double_ml_plm_irm_hetfx": 66, "py_double_ml_policy_tre": 67, "py_double_ml_pq": 68, "py_double_ml_rdflex": 69, "py_double_ml_sensit": 70, "py_double_ml_sensitivity_book": 71, "py_double_ml_ssm": 72, "py_non_orthogon": 51, "py_po_al": 51, "pydata": 59, "pypi": [108, 109], "pyplot": [47, 49, 51, 52, 53, 54, 55, 56, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72], "pyproject": 109, "python": [28, 43, 62, 71, 73, 74, 75, 76, 77, 79, 80, 81, 94, 95, 97, 100, 104, 105, 107, 108, 109, 110], "python3": [64, 106], "q": [46, 54, 68, 69, 78, 105, 107], "q2": [46, 47, 75, 107], "q3": [46, 47, 75, 107], "q4": [46, 47, 75, 107], "q5": [46, 47, 75, 107], "q6": [46, 47, 75, 107], "q_i": [69, 79], "qquad": 23, "qte": [54, 65, 109], "quad": [20, 45, 55, 64, 67, 69, 72, 77, 79, 81, 88, 94, 95, 98, 104], "quadrat": 72, "qualiti": [70, 73, 109], "quanitl": 65, "quant": 54, "quantifi": 71, "quantil": [2, 3, 10, 13, 14, 24, 49, 54, 70, 76, 78, 83, 88, 93, 108, 109], "quantiti": [41, 50, 71], "queri": 64, "question": [71, 110], "quick": 65, "quit": [61, 67, 70, 95, 97], "r": [8, 22, 38, 39, 51, 52, 53, 56, 57, 63, 66, 69, 71, 73, 74, 75, 76, 79, 80, 81, 86, 91, 94, 95, 96, 97, 101, 102, 103, 104, 105, 107, 108, 109, 110], "r2_d": [23, 61], "r2_score": 39, "r2_y": [23, 61], "r6": [46, 109], "r_0": [8, 11, 45, 64, 79], "r_all": 42, "r_d": 23, "r_df": 63, "r_dml": 42, "r_dml_nosplit": 42, "r_dml_po": 42, "r_dml_po_nosplit": 42, "r_double_ml_bas": 42, "r_double_ml_basic_iv": 41, "r_double_ml_did": 43, "r_double_ml_multiway_clust": 44, "r_double_ml_pens": 45, "r_double_ml_pipelin": 46, "r_hat": 11, "r_hat0": 8, "r_hat1": 8, "r_non_orthogon": 42, "r_po_al": 42, "r_y": 23, "rais": [4, 7, 34, 35, 38, 39, 78], "randint": 66, "randn": 15, "random": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 24, 28, 29, 32, 33, 41, 42, 43, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 77, 78, 80, 89, 94, 95, 100, 103, 104, 107, 108, 110], "random_search": 78, "random_st": [24, 51, 60, 67], "randomforest": [45, 61, 64], "randomforest_class": [45, 52, 64, 67], "randomforest_reg": [52, 67], "randomforestclassifi": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 47, 49, 52, 53, 58, 59, 60, 61, 64, 67, 69, 70, 71, 77, 78, 79, 110], "randomforestregressor": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 47, 49, 51, 52, 53, 58, 59, 60, 61, 64, 67, 69, 70, 71, 73, 77, 78, 79, 80, 81, 94, 95, 100, 107, 110], "randomized_search": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 78], "randomizedsearchcv": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 78], "randomli": [42, 44, 51, 63, 74, 80, 110], "rang": [42, 49, 51, 54, 55, 56, 58, 59, 61, 62, 63, 65, 67, 68, 69, 71, 72, 74, 78, 79], "rangeindex": [47, 49, 55, 60, 63, 64, 65, 70, 72, 75, 107], "ranger": [43, 45, 46, 73, 78, 79, 80, 81, 94, 107, 110], "rangl": [21, 67], "rank": 109, "rate": [57, 61, 79], "rather": [69, 71, 79], "ratio": [78, 80, 95, 97], "ravel": [52, 53], "raw": [45, 57, 64], "raw_res_manual_lasso_r_100_n_100_p_200_rho_0": 57, "rbind": 45, "rbindlist": 45, "rbinom": 41, "rbrace": [8, 9, 22, 23, 29, 44, 63, 73, 79, 80, 81, 82, 94, 95, 96, 104], "rcolorbrew": 44, "rcparam": [47, 52, 53, 54, 56, 58, 59, 63, 64, 65, 68], "rd": [79, 109], "rdbu": 44, "rdbu_r": 63, "rdbwselect": 79, "rdd": [4, 7, 76, 106], "rdflex": [69, 79, 109], "rdflex_fuzzi": 69, "rdflex_fuzzy_stack": 69, "rdflex_obj": [32, 79], "rdflex_sharp": 69, "rdflex_sharp_stack": 69, "rdrobust": [32, 69, 79, 106, 109], "rdrobust_fuzzi": 69, "rdrobust_fuzzy_noadj": 69, "rdrobust_sharp": 69, "rdrobust_sharp_noadj": 69, "rdt044": 57, "re": [63, 71, 106], "read": 106, "read_csv": 57, "readabl": 109, "readili": 105, "real": [45, 64, 65, 70, 95, 97], "realat": 79, "realiz": [69, 79], "reason": [4, 7, 41, 50, 70, 71, 95, 97, 110], "recal": [47, 95, 103], "receiv": [49, 69, 79], "recent": [62, 79], "recogn": [45, 64, 65], "recommend": [46, 61, 69, 71, 73, 80, 106, 108, 109], "recov": [41, 43, 50, 66], "recsi": 108, "red": [44, 58, 59, 62, 63], "reduc": [45, 60, 62, 64, 69, 70, 71, 79, 109], "redund": 109, "reemploy": [17, 75, 107], "refactor": 109, "refer": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 45, 49, 56, 60, 62, 64, 65, 69, 70, 75, 76, 77, 79, 95, 97, 100, 108, 109], "reference_level": [2, 49, 79], "refin": 109, "refit": [95, 97], "reflect": [67, 71, 77], "reg": [20, 45, 64, 110], "reg_estim": 69, "reg_learn": 65, "reg_learner_1": 61, "reg_learner_2": 61, "regard": [71, 105], "regener": 109, "region": [44, 54, 63, 94, 104, 108], "regr": [41, 42, 43, 44, 45, 46, 73, 78, 79, 80, 81, 94, 104, 107, 110], "regravg": [46, 78], "regress": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 22, 23, 24, 25, 26, 27, 28, 32, 33, 36, 41, 43, 44, 46, 49, 50, 57, 62, 63, 66, 70, 71, 72, 73, 74, 76, 77, 78, 80, 94, 96, 97, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110], "regressor": [35, 39, 42, 45, 49, 51, 54, 61, 62, 64, 74], "regular": [25, 76, 78, 81, 94, 104, 108], "reich": [46, 78], "reinforc": 108, "reject": [45, 64], "rel": [45, 64, 95, 96, 97, 101], "relat": [71, 110], "relationship": [41, 50, 57, 71, 94, 104], "relev": [4, 5, 6, 7, 21, 36, 38, 39, 54, 67, 68, 79, 95, 110], "reli": [52, 53, 55, 56, 60, 77, 78, 79, 95, 97, 110], "reload": 45, "remain": [43, 94, 104, 110], "remark": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 42, 49, 51, 52, 53, 54, 56, 58, 59, 60, 61, 65, 70, 77, 78, 79, 81, 84, 85, 88, 93, 94, 95, 101], "remot": 106, "remov": [45, 71, 76, 80, 109], "renam": [64, 109], "render": [70, 71], "reorgan": 109, "rep": [42, 74, 78, 94, 104], "repeat": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 41, 42, 44, 45, 46, 51, 60, 63, 64, 65, 66, 69, 70, 72, 74, 76, 78, 94, 98, 107, 109, 110], "repeatedkfold": 63, "repet": 70, "repetit": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 36, 52, 53, 57, 58, 59, 60, 61, 76, 78, 94, 107, 110], "repetiton": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32], "replac": [67, 71, 109], "replic": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 42, 45, 51, 57, 71], "repo": 109, "report": [45, 62, 64, 105, 109], "repositori": [57, 69, 109], "repr": [42, 44], "repres": [66, 71, 79], "represent": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 70, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 107, 109], "reproduc": 24, "request": [38, 39, 109], "requir": [11, 12, 38, 41, 45, 46, 49, 60, 64, 65, 70, 79, 94, 95, 97, 100, 104, 106, 109, 110], "requirenamespac": 43, "res_df": 63, "res_dict": [18, 19, 21, 24, 33], "resampl": [41, 44, 46, 55, 63, 65, 70, 72, 78, 79, 80, 81, 94, 105, 107, 110], "research": [44, 46, 63, 66, 71, 80, 105, 107, 108, 110], "resembl": 72, "reset": 43, "reset_index": [57, 63, 64], "reshap": [51, 52, 53, 56], "reshape2": 44, "residu": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 39, 70, 95, 97, 102, 103], "resolut": [46, 78], "resourc": 61, "resourcewis": 61, "respect": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 49, 64, 65, 69, 77, 79, 80, 95, 103, 110], "respons": [16, 46, 78], "rest": 79, "restart": 106, "restrict": 61, "restructur": 109, "restud": 57, "result": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 41, 42, 43, 46, 49, 51, 52, 53, 55, 56, 57, 60, 61, 67, 69, 70, 71, 72, 74, 78, 80, 81, 84, 85, 95, 97, 100, 107, 109], "result_iivm": 45, "result_irm": 45, "result_plr": 45, "retain": [38, 39], "retina": 66, "retir": [45, 64, 65, 70], "return": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 51, 54, 59, 61, 62, 63, 66, 67, 68, 70, 71, 72, 73, 78, 81, 95, 97, 109], "return_count": [49, 61], "return_tune_r": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "return_typ": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 42, 45, 46, 51, 55, 61, 62, 64, 65, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 94, 95, 100, 107, 110], "rev": 44, "reveal": 60, "review": [25, 57, 108], "revist": [44, 63], "rf": 69, "rho": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 49, 60, 69, 70, 71, 95, 97, 100, 103, 110], "rho_val": 71, "richter": [46, 78, 105, 107], "riesz": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 70, 95, 97, 98, 99, 100, 102, 103], "riesz_rep": [95, 100], "right": [22, 23, 25, 26, 29, 42, 44, 51, 61, 63, 64, 65, 66, 68, 69, 71, 74, 79, 81, 84, 85, 94, 95, 96, 98, 99, 101, 104], "rightarrow_": [42, 51, 74], "risk": [3, 76, 109], "ritov": 108, "rival": 63, "rival_ind": 63, "rmd": 43, "rmse": [43, 55, 61, 62, 65, 70, 72, 78, 79, 81, 94, 107, 109], "rmse_dml_ml_l_fullsampl": 62, "rmse_dml_ml_l_lesstim": 62, "rmse_dml_ml_l_onfold": 62, "rmse_dml_ml_l_untun": 62, "rmse_dml_ml_m_fullsampl": 62, "rmse_dml_ml_m_lesstim": 62, "rmse_dml_ml_m_onfold": 62, "rmse_dml_ml_m_untun": 62, "rmse_oos_ml_l": 62, "rmse_oos_ml_m": 62, "rmse_oos_onfolds_ml_l": 62, "rmse_oos_onfolds_ml_m": 62, "rnorm": [41, 46, 75, 78, 94, 104, 107], "robin": [16, 17, 27, 44, 57, 63, 74, 105, 108], "robinson": [42, 51, 74], "robject": 63, "robu": [58, 59], "robust": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 26, 32, 43, 49, 60, 69, 70, 71, 79, 95, 100, 108, 110], "roc\u00edo": 108, "role": [4, 7, 42, 51, 62, 74, 110], "romano": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 94, 104], "root": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 31, 57, 74, 78, 81, 108], "rotat": [62, 69], "roth": [69, 79, 108], "rough": [71, 110], "roughli": 71, "round": [45, 49, 61, 66, 71], "rout": [34, 35, 38, 39], "row": [42, 45, 47, 52, 53, 56, 62, 63, 67, 75, 80, 107, 110], "row_index": 59, "rownam": 44, "rowv": 44, "roxygen2": 109, "royal": [71, 108], "rpart": [45, 46, 78], "rpart_cv": 46, "rprocess": 61, "rpy2": 63, "rpy2pi": 63, "rsmp": [46, 78, 80], "rsmp_tune": [46, 78], "rssb": 71, "rtype": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "ruben": 108, "ruiz": [41, 50], "rule": [43, 77], "run": [43, 69, 79, 106, 109], "runif": 41, "runner": 71, "runtime_learn": 46, "rv": [49, 60, 70, 71, 95, 100, 110], "rva": [49, 60, 70, 71, 95, 100, 110], "rvert": 57, "rvert_": 57, "s1": 62, "s2": 62, "s_": [26, 44, 63, 79], "s_1": 27, "s_2": 27, "s_col": [4, 7, 69, 72, 79], "s_i": [29, 69, 72, 79], "s_x": [26, 44, 63], "safeguard": [55, 78], "sake": [45, 64, 71, 110], "same": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 24, 36, 42, 44, 51, 52, 53, 60, 61, 63, 65, 67, 69, 70, 71, 72, 78, 81, 84, 85, 94, 95, 101, 109], "samii": 66, "sampl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 26, 29, 32, 38, 39, 41, 43, 44, 46, 50, 55, 58, 59, 61, 63, 65, 67, 70, 76, 78, 94, 104, 107, 108, 109], "sample_weight": [32, 38, 39, 69], "sant": [5, 6, 18, 19, 20, 24, 43, 55, 79, 108], "sara": 108, "sasaki": [26, 44, 63, 108], "satisfi": [72, 78, 81, 94], "save": [42, 45, 51, 58, 59, 61, 62, 64, 65, 78, 95, 100, 110], "savefig": 51, "saveguard": 61, "saver": [45, 64, 65], "scalar": 79, "scale": [42, 44, 54, 56, 66, 68, 71, 94, 95, 103], "scale_color_manu": 42, "scale_fill_manu": [42, 44], "scatter": [49, 56, 58, 59, 66, 69, 71], "scatterplot": 49, "scenario": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 49, 60, 70, 71, 79, 95, 100, 110], "scene": [52, 53, 57], "scene_camera": 57, "schaefer": 66, "schedul": 109, "scheme": [44, 63, 78, 80, 105], "schneider": 46, "schratz": [46, 78, 105, 107], "scienc": [28, 41, 50, 66, 108], "scikit": [61, 64, 78, 105, 107, 109, 110], "scipi": 51, "score": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 30, 31, 32, 33, 38, 39, 41, 43, 44, 45, 46, 47, 52, 53, 54, 55, 57, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 98, 99, 100, 101, 102, 103, 105, 109, 110], "scoring_method": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "script": 106, "sd": 41, "se": [42, 44, 51, 70, 74, 78, 80, 94, 95, 100, 108, 110], "se_df": 44, "se_dml": [42, 51, 74], "se_dml_po": [42, 51, 74], "se_nonorth": [42, 51], "se_orth_nosplit": [42, 51], "se_orth_po_nosplit": [42, 51], "seaborn": [47, 49, 51, 55, 61, 63, 64, 65, 71, 72], "search": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 31, 78, 81], "search_mod": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 78], "searchabl": 45, "second": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 26, 42, 44, 46, 51, 61, 62, 63, 73, 74, 80, 94, 95, 97, 103, 104, 107], "secondari": 49, "section": [6, 20, 43, 44, 45, 46, 60, 62, 63, 65, 71, 98, 109], "secur": 66, "see": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 23, 29, 30, 31, 36, 38, 39, 41, 43, 44, 45, 46, 49, 50, 52, 53, 55, 59, 62, 63, 65, 66, 67, 69, 70, 71, 78, 79, 80, 81, 83, 87, 88, 89, 90, 93, 95, 97, 100, 103, 106, 107, 109], "seed": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 24, 32, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 94, 95, 100, 104, 107, 110], "seek": 66, "seem": [43, 45, 60, 64, 65, 110], "seen": [58, 59], "sel_cols_chiang": 63, "select": [4, 7, 15, 24, 25, 29, 57, 61, 69, 71, 73, 76, 78, 108, 109, 110], "selected_coef": 61, "selected_featur": [46, 78], "selected_learn": 61, "self": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 36, 37, 38, 39, 61, 62, 110], "selfref": 45, "semenova": [52, 53, 108], "semi": 74, "semiparametr": 16, "sens": [70, 71], "sensemakr": [95, 97], "sensit": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 40, 76, 77, 97, 100, 103, 109], "sensitivity_analysi": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 49, 60, 70, 71, 95, 100, 110], "sensitivity_benchmark": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 49, 60, 70, 71, 95, 97], "sensitivity_el": [95, 100], "sensitivity_param": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 70, 71, 95, 97, 100], "sensitivity_plot": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 49, 60, 70, 71, 95, 100], "sensitivity_summari": [49, 60, 70, 71, 95, 100, 110], "sensitvity_benchmark": 49, "sensiv": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "senstiv": [95, 102], "sep": 42, "separ": [66, 70, 78, 79, 109], "seper": [62, 69, 70, 80, 94, 95, 97], "seq_len": [42, 74], "sequenti": 17, "seri": [59, 71, 108], "serv": [75, 107, 109], "serverless": [108, 109], "servic": 66, "set": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 26, 27, 28, 37, 38, 39, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 73, 74, 75, 77, 79, 80, 81, 82, 84, 85, 87, 94, 95, 96, 97, 101, 102, 104, 106, 107, 109, 110], "set_as_param": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "set_config": [38, 39], "set_fit_request": [38, 39], "set_fold_specif": 78, "set_index": 64, "set_ml_nuisance_param": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 45, 47, 64, 78, 109], "set_param": [34, 35, 38, 39, 62, 78], "set_sample_split": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 61, 80, 109], "set_score_request": [38, 39], "set_styl": [64, 65], "set_text": 61, "set_threshold": [42, 43, 44, 45, 46, 73, 78, 79, 80, 81, 94, 104, 107], "set_tick": 63, "set_ticklabel": 63, "set_titl": [49, 62, 63, 69], "set_x_d": [4, 7], "set_xlabel": [49, 51, 62, 63, 69], "set_xlim": 51, "set_xtick": 66, "set_xticklabel": 66, "set_ylabel": [49, 62, 63, 66, 69], "set_ylim": [54, 62, 63, 68], "setdiff": 109, "setdiff1d": 63, "setminu": [44, 63, 94, 104], "settings_l": 62, "settings_m": 62, "setup": [106, 109], "seven": [44, 63], "sever": [40, 45, 46, 61, 62, 64, 65, 70, 71, 74, 78, 110], "shape": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 36, 37, 38, 39, 49, 52, 53, 56, 58, 59, 61, 63, 64, 67, 69, 70, 71, 78, 79], "share": [44, 45, 63, 64], "sharma": [71, 108], "sharp": 32, "shock": [44, 63], "short": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 70, 71, 95, 97, 108, 109, 110], "shortcut": 45, "shortli": [44, 46, 63, 78], "shota": 108, "should": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 31, 38, 39, 45, 49, 58, 59, 61, 64, 69, 70, 72, 75, 77, 78, 79, 94, 95, 97, 105], "show": [41, 42, 44, 47, 49, 50, 51, 52, 53, 55, 57, 60, 61, 62, 63, 66, 69, 71, 72, 74, 95, 102, 106], "showcas": 67, "showlabel": 71, "showlegend": 71, "shown": [41, 50, 66, 107], "showscal": [52, 53, 57], "shrink": 69, "shuffl": 80, "side": [69, 79, 95, 100], "sigma": [15, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 42, 44, 51, 63, 72, 74, 77, 80, 94, 95, 97, 100, 102, 103, 104], "sigma2": [95, 100], "sigma_": [19, 20, 22, 23, 25, 26, 27, 29, 42, 44, 51, 63, 74], "sigma_0": [95, 103], "sigma_j": [94, 104], "sigmoid": 66, "sign": 71, "signal": [36, 37], "signatur": [8, 9, 10, 11, 12, 13, 14, 81], "signif": [41, 43, 44, 45, 46, 78, 79, 80, 81, 94, 107, 110], "signific": [41, 44, 45, 46, 49, 60, 64, 67, 69, 70, 71, 78, 79, 80, 81, 94, 95, 100, 107, 110], "silverman": [10, 13, 14], "sim": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 42, 43, 44, 51, 54, 56, 63, 67, 68, 72, 74, 79], "similar": [19, 24, 43, 46, 52, 53, 60, 62, 65, 69, 70, 71, 79], "similarli": 62, "simpl": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 21, 38, 39, 43, 46, 52, 53, 58, 59, 60, 67, 71, 76, 79, 95, 97], "simplest": 77, "simpli": [46, 55, 110], "simplic": [45, 61, 64, 67, 71], "simplif": [95, 98], "simplifi": [66, 71, 77, 95, 102], "simul": [18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 42, 46, 51, 52, 53, 54, 57, 58, 59, 68, 69, 71, 72, 74, 78, 94, 104, 107], "simul_data": 15, "simulaten": 79, "simulation_run": 57, "simult": 43, "simultan": [76, 110], "sin": [21, 24, 28, 52, 53, 56, 58, 59], "sinc": [18, 19, 38, 45, 49, 55, 56, 58, 59, 60, 61, 62, 64, 66, 72, 78, 79, 95, 100, 101, 106, 109], "singl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 55, 58, 59, 65, 66, 78, 94, 104], "single_learner_pipelin": 78, "singleton": 80, "sinh": 28, "sipp": [45, 64, 65], "site": [63, 64], "situat": [44, 63], "six": 44, "sixth": 63, "size": [15, 42, 44, 45, 46, 51, 54, 56, 57, 60, 61, 62, 64, 66, 67, 68, 71, 73, 75, 78, 79, 80, 81, 94, 104, 107, 110], "sizeabl": 71, "skill": 108, "sklearn": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 28, 32, 37, 38, 39, 47, 49, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 69, 70, 71, 72, 73, 77, 78, 79, 80, 81, 94, 95, 100, 104, 107, 110], "skotara": 71, "slide": 66, "slightli": [56, 58, 59, 60, 61, 77, 81, 84, 85, 95, 97], "sligthli": [5, 6], "slow": [42, 51, 74], "slower": [42, 51, 74], "small": [21, 55, 56, 67, 72, 79, 95, 97, 101], "smaller": [45, 55, 58, 59, 60, 62, 64, 69, 71, 79, 110], "smallest": 61, "smpl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 42, 44, 51, 61, 63, 80, 81], "smpls_cluster": [44, 63], "smsg": 64, "sn": [47, 49, 51, 55, 61, 63, 64, 65, 71, 72], "so": [38, 39, 41, 45, 46, 50, 55, 62, 64, 66, 71, 72, 78, 94, 110], "social": [66, 108], "societi": [44, 63, 71, 108], "softwar": [46, 78, 105, 107, 108, 109], "solari": 109, "sole": 71, "solut": [73, 77, 81], "solv": [30, 44, 63, 77, 78, 94, 104], "solver": [64, 72, 79], "some": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 39, 45, 46, 47, 55, 56, 61, 62, 64, 65, 69, 70, 72, 77, 78, 79, 106, 109], "sometim": 61, "sonabend": [46, 78], "sophist": 78, "sort": [64, 79], "sort_valu": 49, "sourc": [46, 78, 107, 109], "sourcefileload": 57, "sp": 43, "space": [44, 63, 78], "spars": [57, 78, 94, 104, 107, 108], "sparsiti": 108, "spec": 108, "special": [44, 63, 79], "specif": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 31, 32, 44, 45, 49, 61, 63, 64, 71, 75, 76, 77, 78, 79, 80, 81, 87, 94, 100, 103, 105, 107], "specifi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 32, 41, 44, 45, 46, 49, 50, 52, 53, 54, 55, 58, 59, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 79, 82, 87, 106, 107, 109, 110], "specifii": 65, "speed": [2, 14, 61], "speedup": 61, "spefici": 8, "spindler": [25, 71, 105, 108, 109], "spine": [64, 65], "spline": [52, 53, 77], "spline_basi": [52, 53, 77], "spline_grid": [52, 53], "split": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 41, 44, 46, 55, 61, 63, 65, 67, 70, 72, 76, 77, 78, 79, 81, 94, 107, 109], "split_sampl": 61, "sponsor": [45, 64, 65], "sprintf": 42, "sq_error": 57, "sqrt": [18, 19, 20, 23, 24, 42, 44, 46, 47, 51, 54, 63, 68, 74, 80, 94, 95, 97, 104, 107], "squar": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 39, 45, 57, 64, 78, 79, 95, 103, 108], "squarederror": [45, 64, 110], "squeez": [54, 55, 68, 72], "src": 64, "ssm": [4, 7, 29, 76], "ssrn": 22, "stabil": 60, "stabl": [41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 105], "stack": [46, 78], "stackingclassifi": 69, "stackingregressor": 69, "stacklrn": 46, "stackrel": 79, "stage": [32, 52, 53, 58, 59, 67, 69, 78, 79, 109, 110], "standard": [20, 43, 46, 54, 58, 59, 69, 79, 80, 81, 94, 95, 100, 103, 104, 109, 110], "standard_norm": [75, 78, 94, 104, 107], "standardscal": 64, "star": 79, "start": [43, 45, 46, 52, 53, 57, 60, 61, 62, 63, 64, 68, 71, 79, 105, 110], "stat": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 32, 51, 69, 75, 78, 79, 94, 104, 105, 108], "stat_bin": 42, "stat_dens": 45, "state": 110, "stationar": 55, "stationari": 79, "statist": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 26, 29, 40, 44, 63, 70, 71, 94, 95, 100, 104, 105, 107, 108, 109, 110], "statsmodel": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 36, 69], "statu": [43, 45, 55, 64, 66, 69, 72], "std": [3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 41, 43, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 58, 59, 60, 62, 63, 64, 65, 66, 68, 70, 71, 72, 77, 78, 79, 80, 81, 94, 107, 110], "stefan": 108, "step": [42, 45, 46, 51, 58, 59, 60, 64, 67, 74, 78, 79, 94, 104, 105, 110], "stepdown": [94, 104], "stick": [45, 64], "still": [52, 53, 55, 58, 59, 60, 65, 69, 70, 72, 78], "stochast": [11, 12, 79, 107], "stock": [45, 64, 65], "store": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 73, 78, 80, 81, 94, 95, 100, 109], "store_model": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 62], "store_predict": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 43, 64, 67], "stori": [71, 108], "str": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 32, 36, 38, 39, 45, 49, 58, 59, 68, 69, 77, 79, 109], "straightforward": [58, 59, 61, 77], "strategi": [66, 71, 79, 110], "stratifi": 61, "stratum": 66, "strength": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 70, 71, 95, 97, 100, 102], "strictli": 79, "string": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 77, 94, 95, 100, 107, 109], "string_label": 66, "strong": [72, 95, 97], "stronger": [94, 110], "structur": [16, 17, 27, 44, 45, 57, 63, 64, 72, 74, 78, 105, 108, 110], "student": 108, "studi": [29, 44, 45, 57, 62, 63, 64, 65, 70, 107, 110], "style": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 62, 109], "styler": 109, "styliz": 71, "sub": [38, 39, 44, 63], "subclass": 109, "subfold": 78, "subgroup": [8, 45, 64, 109], "subject": [44, 63], "submiss": 109, "subobject": [34, 35, 38, 39], "subplot": [44, 49, 51, 52, 53, 54, 56, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69], "subplots_adjust": 61, "subpopul": 79, "subsampl": [46, 61], "subscript": [95, 97], "subsequ": [44, 63], "subset": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 38, 44, 61, 63, 67, 73, 77, 78, 95, 97], "subseteq": 77, "substanti": [45, 64, 66], "substract": 94, "subtract": 94, "sudo": 106, "suffic": 71, "suffici": [61, 62, 71], "suggest": [44, 45, 63, 64, 71, 109], "suitabl": [52, 53, 72], "sum": [39, 44, 45, 63, 64, 65, 68, 69, 77, 94, 104], "sum_": [33, 42, 44, 51, 63, 69, 73, 74, 77, 79, 94, 104], "sum_i": 66, "sum_oth": 63, "sum_riv": 63, "summar": [43, 49, 66, 71, 73, 95, 100], "summari": [3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 41, 43, 44, 46, 47, 49, 50, 52, 53, 54, 55, 58, 59, 60, 63, 65, 68, 70, 71, 72, 74, 75, 77, 78, 79, 80, 81, 94, 95, 107, 109, 110], "summary_result": 45, "suppli": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 52, 53, 58, 59, 60, 67, 77, 95, 96, 97, 100], "support": [8, 21, 32, 43, 44, 61, 63, 67, 69, 78, 79, 110], "support_s": [21, 52, 53, 58, 59, 67], "support_t": 67, "support_w": 67, "suppos": 71, "suppress": [43, 45, 46], "suppresswarn": 42, "suprema": [94, 104], "suptitl": [54, 61, 62, 65, 68], "supxlabel": [54, 65, 68], "supylabel": [54, 65, 68], "sure": [49, 78, 109], "surfac": [52, 53, 57], "surpress": [44, 107], "survei": [45, 64, 65, 110], "susan": 108, "sven": [71, 105, 108], "svenk": 63, "svenklaassen": 105, "svg": [42, 51], "switch": [42, 51, 71, 74], "symbol": 71, "symmetr": 28, "syntax": [69, 79], "synthet": [21, 33, 41, 50, 52, 53, 54, 58, 59, 62, 67, 68], "syrgkani": [71, 108], "system": 108, "szita": 108, "t": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 24, 32, 38, 39, 41, 43, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 77, 78, 79, 80, 81, 85, 94, 95, 98, 104, 107, 110], "t_1_start": 61, "t_1_stop": 61, "t_2_start": 61, "t_2_stop": 61, "t_3_start": 61, "t_3_stop": 61, "t_col": [4, 6, 7, 79], "t_df": 67, "t_diff": 56, "t_dml": 42, "t_i": [55, 67, 69, 79], "t_idx": 56, "t_nonorth": 42, "t_orth_nosplit": 42, "t_sigmoid": 67, "t_stat": 94, "tabl": [42, 44, 45, 46, 49, 73, 75, 78, 79, 80, 81, 94, 104, 107, 110], "tabular": [61, 75, 94, 104, 107, 110], "taddi": 108, "take": [8, 9, 11, 12, 18, 19, 21, 52, 53, 54, 55, 56, 57, 58, 59, 61, 65, 68, 69, 70, 72, 73, 77, 78, 79, 81, 82, 87, 95, 96, 101, 102, 107], "taken": [45, 64, 65, 110], "taker": [8, 109], "talk": 110, "target": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 30, 31, 38, 39, 41, 44, 45, 46, 52, 53, 61, 63, 77, 78, 79, 80, 81, 88, 93, 94, 95, 101, 103, 104, 105, 107, 109, 110], "task": [41, 62, 75, 80, 110], "task_typ": 109, "tau": [33, 54, 56, 65, 66, 68, 69, 77, 79, 81, 83, 88, 93], "tau_": [66, 69, 79], "tau_0": [69, 79], "tau_1": 66, "tau_2": 66, "tau_vec": [54, 65, 68], "tax": [45, 64, 65], "te": [43, 52, 53, 67], "techniqu": [42, 51, 74, 80, 110], "templat": 109, "ten": 62, "tend": [45, 64, 65, 79], "tensor": [52, 53], "tenth": 108, "term": [42, 44, 45, 46, 51, 56, 57, 63, 64, 66, 71, 74, 79, 105, 110], "termin": [46, 78], "terminatorev": 46, "test": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 22, 38, 39, 41, 42, 43, 44, 45, 46, 51, 60, 63, 71, 74, 78, 79, 80, 81, 94, 104, 107, 108, 109, 110], "test_id": [44, 80], "test_ind": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "test_set": 80, "test_siz": 51, "text": [18, 19, 20, 22, 24, 32, 33, 44, 45, 54, 57, 66, 67, 68, 69, 71, 77, 79, 80], "textbf": [73, 78, 110], "textposit": 71, "textrm": [95, 96, 97, 101, 102, 103], "tg": [46, 47, 75, 107], "th": [44, 63], "than": [9, 42, 43, 45, 51, 57, 61, 64, 65, 66, 69, 70, 71, 74, 79, 95, 100, 110], "thank": [43, 45, 46, 64, 109], "thatw": 56, "thei": [43, 45, 56, 58, 59, 64, 66, 79, 95, 103], "them": [45, 46, 52, 53, 54, 60, 62, 64, 68, 79], "theme": [44, 45], "theme_minim": [42, 45], "theorem": [95, 103], "theoret": [61, 71, 80, 108], "theori": [77, 108], "therebi": [44, 46, 63, 110], "therefor": [49, 66, 69, 70, 80, 81, 95, 102], "theta": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 22, 23, 24, 26, 28, 29, 30, 31, 42, 44, 46, 49, 51, 55, 56, 57, 60, 61, 63, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 100, 102, 103, 104, 107, 110], "theta_": [49, 69, 71, 77, 79, 94, 95, 103, 104], "theta_0": [8, 9, 11, 12, 21, 42, 44, 45, 49, 51, 52, 53, 57, 58, 59, 63, 64, 71, 72, 74, 77, 79, 81, 88, 93, 94, 95, 96, 101, 103, 107], "theta_dml": [42, 51, 74], "theta_dml_po": [42, 51, 74], "theta_initi": 51, "theta_nonorth": [42, 51], "theta_orth_nosplit": [42, 51], "theta_orth_po_nosplit": [42, 51], "theta_resc": 42, "theta_t": 56, "thi": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 31, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 77, 78, 79, 80, 81, 83, 84, 85, 88, 93, 94, 95, 96, 97, 100, 101, 105, 106, 107, 108, 109, 110], "think": 46, "third": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 42, 51, 63, 74, 80], "thirion": [105, 107], "this_df": [57, 64], "this_split_ind": 63, "those": [43, 45, 64, 65], "though": [41, 50, 66], "thread": [66, 78], "three": [44, 46, 58, 59, 106, 109], "threshold": [1, 3, 5, 6, 8, 9, 10, 13, 14, 15, 69, 71, 79], "through": [43, 54, 58, 59, 68, 69, 78, 79], "throughout": 60, "thu": [62, 69, 77, 79], "tibbl": 43, "tick_param": 69, "tight": 51, "tight_layout": [62, 63, 69], "tighter": 69, "tild": [18, 19, 20, 24, 44, 63, 66, 73, 77, 80, 81, 88, 89, 90, 93, 94, 95, 102, 103, 104], "time": [4, 5, 7, 25, 26, 42, 43, 44, 45, 51, 55, 56, 57, 58, 59, 63, 64, 65, 69, 70, 71, 72, 79, 109, 110], "time_budget": 62, "time_df": 56, "time_period": 56, "titiunik": [79, 108], "titl": [44, 45, 49, 52, 53, 54, 57, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69, 71, 105], "tmp": 59, "tname": 43, "tnr": [46, 78], "to_fram": 67, "to_numpi": [54, 60, 65, 68], "todo": [44, 47], "toeplitz": 57, "togeth": [58, 59, 94], "toler": 63, "tomasz": [108, 109], "toml": 109, "too": 61, "tool": [43, 46, 70, 110], "top": [44, 61, 63, 64, 65, 69, 71, 79, 105], "total": [39, 45, 62, 64], "tpot": 62, "tracker": 105, "tradit": [94, 104], "train": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 38, 39, 42, 44, 46, 51, 52, 53, 54, 58, 59, 61, 63, 67, 68, 73, 74, 80], "train_id": [44, 80], "train_ind": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "train_set": 80, "train_test_split": 51, "transact": 108, "transform": [18, 19, 33, 66, 71, 110], "translat": 57, "transpos": 56, "treament": 67, "treat": [9, 20, 43, 49, 55, 56, 60, 67, 69, 71, 77, 79, 94, 110], "treat1_param": 66, "treat2_param": 66, "treat_var": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 78], "treatment": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 27, 32, 41, 43, 44, 46, 47, 49, 50, 55, 56, 57, 60, 61, 62, 63, 67, 69, 70, 71, 72, 74, 75, 76, 78, 80, 81, 82, 83, 84, 85, 87, 88, 93, 94, 95, 96, 100, 102, 104, 105, 107, 108, 109, 110], "treatment_df": 56, "treatment_effect": [21, 52, 53], "treatment_level": [1, 2, 49, 79], "treatment_var": [4, 7], "tree": [9, 37, 45, 46, 55, 56, 61, 64, 73, 76, 78, 79, 80, 81, 94, 107, 109], "tree_param": [9, 37], "tree_summari": 64, "trees_class": [45, 64], "trend": [43, 55, 56, 63, 79, 108], "tri": [57, 95, 97], "triangular": [32, 69, 79], "trim": [1, 3, 5, 6, 8, 9, 10, 13, 14, 15, 45, 64, 65, 71], "trimming_rul": [1, 2, 3, 5, 6, 8, 9, 10, 13, 14, 15, 65], "trimming_threshold": [1, 2, 3, 5, 6, 8, 9, 10, 13, 14, 15, 45, 52, 64, 65, 67, 68, 71], "trm": [46, 78], "true": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 24, 29, 32, 33, 34, 35, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 78, 79, 80, 81, 82, 83, 88, 89, 90, 93, 94, 95, 98, 99, 103, 104, 107, 110], "true_effect": [52, 53, 56, 58, 59], "true_gatet_effect": 60, "true_group_effect": 60, "true_tau": 69, "truncat": [1, 2, 3, 5, 6, 8, 9, 10, 13, 14, 15, 65], "try": [61, 70], "tune": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 57, 69, 76, 79, 105, 107, 109], "tune_on_fold": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 78], "tune_r": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15], "tune_set": [46, 78], "tuned_model": 62, "tuner": 78, "tunergridsearch": 46, "tupl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "turn": 71, "turrel": 28, "tutori": 45, "tw": [64, 65], "twice": 79, "twinx": 49, "two": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 41, 42, 45, 46, 50, 51, 54, 55, 61, 62, 64, 65, 66, 67, 68, 70, 71, 73, 74, 77, 78, 79, 80, 81, 88, 94, 104, 110], "twoclass": 46, "twoearn": [45, 64, 65, 70, 110], "type": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 21, 24, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 51, 61, 62, 63, 69, 71, 74, 78, 79, 81, 91, 92, 94, 95, 102, 104, 109, 110], "typic": [59, 79, 105], "u": [8, 9, 10, 13, 14, 18, 19, 20, 21, 23, 29, 39, 42, 43, 44, 45, 49, 51, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 68, 70, 71, 74, 79, 95, 97, 106, 110], "u_hat": [42, 51, 81], "u_i": [22, 25, 28, 29], "u_t": 20, "uehara": 108, "uhash": 46, "ulf": 108, "unambigu": 71, "uncertainti": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 58, 59, 69, 70, 95, 100, 110], "unchang": [38, 39], "uncondit": [45, 64, 110], "unconfounded": [71, 108], "under": [15, 42, 45, 51, 55, 64, 67, 69, 71, 74, 79, 94, 108], "underbrac": [42, 51, 56, 74, 77], "underfit": 62, "underli": [18, 24, 45, 46, 49, 58, 59, 66, 67, 79, 95, 97, 110], "underlin": [44, 63], "underset": [69, 79], "understand": 71, "undesir": 78, "unevenli": 80, "uniform": [20, 32, 33, 50, 52, 53, 54, 56, 67, 68, 94], "uniform_averag": 39, "uniformli": [54, 65, 94, 104], "uniqu": [41, 49, 50, 61, 69, 81, 95, 103], "unique_label": 62, "unit": [42, 43, 55, 56, 60, 69, 72, 79, 81, 84, 85, 109], "univari": [21, 52, 53], "univers": 108, "unknown": 79, "unlik": [45, 64, 65, 71], "unobserv": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 41, 45, 50, 64, 65, 70, 71, 79, 95, 97, 103, 110], "unpen": 43, "unstabl": [95, 97], "unter": [44, 45, 46], "untest": 71, "until": [79, 109], "untreat": [71, 79], "up": [2, 14, 45, 57, 61, 62, 64, 65, 70, 71, 78, 79, 80, 95, 97, 106, 109, 110], "upcom": 109, "updat": [38, 39, 44, 59, 63, 108, 109], "update_layout": [52, 53, 57, 69, 71], "update_trac": [52, 53], "upload": 109, "upon": [81, 109], "upper": [45, 46, 49, 51, 54, 56, 60, 65, 68, 69, 70, 71, 78, 95, 100, 103, 110], "upper_bound": [52, 53], "upsilon": 72, "upsilon_i": 72, "upward": [45, 64, 65, 71], "upweight": 66, "url": [57, 105, 108], "us": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 36, 38, 39, 42, 44, 45, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 79, 80, 81, 84, 85, 94, 95, 97, 100, 101, 102, 103, 104, 105, 106, 107, 109, 110], "usa": 108, "usabl": 61, "usag": [43, 47, 49, 55, 60, 63, 64, 65, 70, 72, 75, 107, 109], "use_label_encod": [64, 110], "use_other_treat_as_covari": [4, 7, 75], "usecolormap": [52, 53], "user": [30, 31, 34, 35, 38, 39, 42, 43, 44, 45, 46, 49, 51, 60, 61, 63, 64, 69, 70, 77, 78, 79, 81, 94, 104, 105, 106, 107, 109, 110], "user_guid": 59, "userwarn": [64, 71], "usual": [44, 52, 53, 55, 61, 63, 69, 70, 71, 77, 78, 80, 95, 103], "util": [31, 61, 62, 66, 69, 78, 79, 109], "v": [8, 9, 11, 12, 16, 17, 23, 25, 26, 27, 29, 39, 42, 44, 45, 49, 51, 60, 63, 64, 66, 69, 73, 74, 77, 79, 94, 104, 105, 107, 108, 109, 110], "v108": 105, "v12": [105, 107], "v22": 46, "v23": 105, "v_": [26, 44, 63, 79], "v_i": [22, 23, 27, 28, 29, 42, 51, 74, 79], "v_j": [94, 104], "val": [23, 80, 108], "val_list": 57, "valid": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 22, 42, 43, 44, 45, 51, 54, 55, 61, 62, 63, 64, 65, 68, 74, 76, 77, 78, 80, 81, 83, 88, 93, 95, 97, 108, 110], "valu": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 69, 70, 71, 73, 76, 78, 79, 80, 83, 88, 89, 90, 93, 94, 95, 97, 100, 103, 104, 107, 109, 110], "value_count": 64, "van": 108, "vanderpla": [105, 107], "vanish": [42, 51, 74], "var": [18, 19, 20, 24, 44, 63, 66, 69, 95, 96, 97, 101, 102, 103], "var_ep": 71, "varepsilon": [8, 18, 19, 26, 44, 63, 72, 77, 79], "varepsilon_": [26, 44, 63], "varepsilon_0": 20, "varepsilon_1": 20, "varepsilon_d": [19, 24], "varepsilon_i": [24, 25, 54, 68, 72], "vari": [45, 56, 61, 64, 66, 71], "variabl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 32, 44, 45, 46, 47, 49, 55, 57, 60, 62, 63, 64, 65, 69, 70, 71, 72, 75, 77, 78, 79, 80, 81, 94, 95, 97, 100, 103, 104, 107, 108, 109, 110], "varianc": [30, 31, 44, 46, 63, 69, 70, 71, 76, 79, 80, 95, 97, 100, 101, 102, 103, 107], "variant": 43, "variat": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 19, 70, 95, 97, 103], "variou": [43, 62, 71, 78, 110], "varoquaux": [105, 107], "vasili": [71, 108], "vector": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 21, 22, 23, 25, 26, 28, 29, 41, 44, 45, 50, 55, 58, 59, 60, 63, 64, 67, 72, 79, 94, 104, 107, 109], "venv": 106, "verbos": [45, 51, 56, 61, 62, 69, 71], "veri": [43, 44, 46, 60, 61, 63, 71, 81, 105], "verifi": 66, "versa": [61, 66, 95, 100], "version": [18, 38, 39, 44, 45, 46, 71, 73, 77, 94, 95, 96, 98, 99, 101, 104, 109], "versoin": 71, "versu": 59, "vertic": [44, 49, 63], "via": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 31, 43, 54, 55, 56, 57, 58, 59, 60, 61, 69, 70, 72, 73, 75, 76, 77, 78, 79, 80, 83, 90, 94, 95, 97, 100, 103, 104, 105, 106, 107, 108, 109, 110], "viabl": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "vice": [61, 66, 95, 100], "victor": [57, 71, 80, 105, 108], "view": 59, "vignett": [43, 109], "villa": [41, 50], "violet": [54, 65, 68], "vira": 108, "virtual": 106, "virtualenv": 106, "visibl": [65, 69, 71], "visit": [105, 110], "visual": [44, 60, 62, 63, 69], "vol": 43, "volum": [71, 105], "voluntari": 66, "vv740": 63, "vv760g": 63, "w": [16, 17, 18, 19, 20, 27, 30, 31, 38, 39, 44, 57, 63, 66, 67, 73, 74, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 107], "w24678": 80, "w30302": 108, "w_": [20, 44, 63, 67, 79], "w_1": [20, 67], "w_2": [20, 67], "w_3": 20, "w_4": 20, "w_df": 67, "w_i": [29, 55, 67, 69, 73, 77, 79, 80, 81, 94, 104], "wa": [44, 56, 62, 63, 71, 109], "wager": 108, "wai": [45, 61, 62, 64, 71, 78, 81, 106], "wander": 28, "wang": 108, "want": [41, 44, 45, 46, 50, 54, 55, 61, 63, 68, 69, 78, 79, 105, 106, 108], "warn": [41, 42, 43, 44, 45, 46, 51, 64, 71, 73, 78, 79, 80, 81, 94, 104, 107, 109], "wayon": 44, "we": [9, 37, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 86, 94, 95, 97, 103, 104, 106, 107, 109, 110], "weak": [95, 97, 108], "wealth": [16, 70], "websit": [45, 46, 78, 105], "wedg": [44, 63], "week": 109, "wei": [94, 104], "weight": [1, 2, 3, 8, 9, 10, 13, 14, 15, 38, 39, 44, 45, 46, 49, 60, 63, 64, 69, 72, 76, 78, 79, 81, 82, 87, 94, 95, 96, 101, 104, 109], "weights_bar": [1, 9], "weiss": [105, 107], "well": [4, 7, 38, 39, 42, 44, 51, 57, 61, 62, 63, 73, 74, 75, 80, 106, 107], "were": [45, 64, 65, 72, 110], "what": [43, 57, 61], "when": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 34, 35, 38, 39, 45, 55, 59, 64, 66, 79, 81, 94, 104, 105, 106, 107, 109], "whenev": [45, 64], "whera": [95, 101], "where": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 36, 37, 39, 41, 42, 44, 45, 49, 50, 51, 54, 55, 56, 60, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 101, 103, 106, 107, 109, 110], "wherea": [21, 49, 55, 71, 72, 81, 87, 95, 96, 110], "whether": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 21, 24, 29, 32, 36, 45, 56, 61, 64, 65, 69, 71, 75, 78, 79, 95, 97, 109], "which": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 21, 31, 38, 41, 42, 43, 45, 46, 48, 49, 50, 51, 55, 57, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 72, 74, 75, 77, 78, 79, 81, 94, 95, 96, 97, 100, 101, 103, 104, 106, 109, 110], "while": [41, 50, 79], "white": [44, 58, 59, 63, 71], "whitegrid": [64, 65], "whitnei": [71, 108], "who": [43, 45, 64, 71], "whole": [42, 51, 55, 69, 74, 78, 95, 97], "whom": 79, "widehat": 79, "width": [42, 44, 52, 53, 57], "wiki": 109, "wiksel": 108, "wild": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 94, 104], "window": 106, "wise": [58, 59], "wish": 106, "within": [32, 44, 58, 59, 63, 67, 69], "without": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 24, 32, 41, 42, 50, 51, 61, 62, 71, 74, 76, 78, 79, 95, 97, 106, 109], "wolf": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 94, 104], "won": 71, "word": [32, 69, 79, 109, 110], "work": [34, 35, 38, 39, 48, 49, 59, 60, 61, 66, 70, 71, 78, 79, 94, 106, 108], "workflow": [105, 109], "workspac": 64, "world": 108, "worri": 71, "wors": 39, "would": [39, 43, 45, 46, 52, 53, 57, 61, 64, 65, 69, 70, 71, 77, 78, 95, 103, 110], "wrapper": [43, 69, 78], "write": [42, 43, 51, 55, 59, 72, 74, 95, 103], "written": [79, 81, 95, 96, 101], "wrong": [61, 66], "wspace": 61, "wurd": [44, 45, 46], "www": [105, 106], "x": [1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 38, 39, 42, 43, 44, 45, 46, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 107, 110], "x0": [49, 66, 69], "x1": [44, 46, 49, 55, 62, 63, 66, 69, 70, 71, 72, 75, 77, 78, 79, 81, 94, 95, 97, 107], "x10": [44, 46, 62, 63, 72, 75, 78, 79, 81, 94, 107], "x100": [44, 46, 63, 72, 75, 79, 107], "x11": [44, 46, 63, 72, 75, 78, 79, 81, 94, 107], "x12": [44, 46, 63, 72, 75, 78, 79, 81, 94, 107], "x13": [44, 46, 63, 72, 75, 78, 79, 81, 94, 107], "x14": [44, 46, 63, 72, 75, 78, 79, 81, 94, 107], "x15": [44, 46, 63, 72, 75, 78, 79, 81, 94, 107], "x16": [44, 46, 63, 72, 75, 78, 79, 81, 94, 107], "x17": [44, 46, 63, 72, 75, 78, 79, 81, 94, 107], "x18": [44, 46, 63, 72, 75, 78, 79, 81, 94, 107], "x19": [44, 46, 63, 72, 75, 78, 79, 81, 94, 107], "x1x2x3x4x5x6x7x8x9x10": 44, "x2": [44, 46, 49, 55, 62, 63, 69, 70, 71, 72, 75, 77, 78, 79, 81, 94, 107], "x20": [44, 46, 63, 72, 75, 78, 79, 81, 94, 107], "x21": [44, 46, 63, 72, 75, 79, 107], "x22": [44, 46, 63, 72, 75, 79, 107], "x23": [44, 46, 63, 72, 75, 79, 107], "x24": [44, 46, 63, 72, 75, 79, 107], "x25": [44, 46, 63, 72, 75, 79, 107], "x26": [44, 46, 63, 72, 75, 79, 107], "x27": [44, 46, 63, 72, 75, 79, 107], "x28": [44, 46, 63, 72, 75, 79, 107], "x29": [44, 46, 63, 72, 75, 79, 107], "x2_dummi": 71, "x2_preds_control": 71, "x2_preds_treat": 71, "x3": [44, 46, 49, 55, 62, 63, 70, 71, 72, 75, 77, 78, 79, 81, 94, 107], "x30": [44, 46, 63, 72, 75, 79, 107], "x31": [44, 46, 63, 72, 75, 79, 107], "x32": [44, 46, 63, 72, 75, 79, 107], "x33": [44, 46, 63, 72, 75, 79, 107], "x34": [44, 46, 63, 72, 75, 79, 107], "x35": [44, 46, 63, 72, 75, 79, 107], "x36": [44, 46, 63, 72, 75, 79, 107], "x37": [44, 46, 63, 72, 75, 79, 107], "x38": [44, 46, 63, 72, 75, 79, 107], "x39": [44, 46, 63, 72, 75, 79, 107], "x4": [44, 46, 49, 55, 62, 63, 70, 71, 72, 75, 78, 79, 81, 94, 107], "x40": [44, 46, 63, 72, 75, 79, 107], "x41": [44, 46, 63, 72, 75, 79, 107], "x42": [44, 46, 63, 72, 75, 79, 107], "x43": [44, 46, 62, 63, 72, 75, 79, 107], "x44": [44, 46, 62, 63, 72, 75, 79, 107], "x45": [44, 46, 62, 63, 72, 75, 79, 107], "x46": [44, 46, 62, 63, 72, 75, 79, 107], "x47": [44, 46, 62, 63, 72, 75, 79, 107], "x48": [44, 46, 62, 63, 72, 75, 79, 107], "x49": [44, 46, 62, 63, 72, 75, 79, 107], "x5": [44, 46, 62, 63, 71, 72, 75, 78, 79, 81, 94, 107], "x50": [44, 46, 62, 63, 72, 75, 79, 107], "x51": [44, 46, 63, 72, 75, 79, 107], "x52": [44, 46, 63, 72, 75, 79, 107], "x53": [44, 46, 63, 72, 75, 79, 107], "x54": [44, 46, 63, 72, 75, 79, 107], "x55": [44, 46, 63, 72, 75, 79, 107], "x56": [44, 46, 63, 72, 75, 79, 107], "x57": [44, 46, 63, 72, 75, 79, 107], "x58": [44, 46, 63, 72, 75, 79, 107], "x59": [44, 46, 63, 72, 75, 79, 107], "x6": [44, 46, 62, 63, 72, 75, 78, 79, 81, 94, 107], "x60": [44, 46, 63, 72, 75, 79, 107], "x61": [44, 46, 63, 72, 75, 79, 107], "x62": [44, 46, 63, 72, 75, 79, 107], "x63": [44, 46, 63, 72, 75, 79, 107], "x64": [44, 46, 63, 64, 72, 75, 79, 107], "x65": [44, 46, 63, 72, 75, 79, 107], "x66": [44, 46, 63, 72, 75, 79, 107], "x67": [44, 46, 63, 72, 75, 79, 107], "x68": [44, 46, 63, 72, 75, 79, 107], "x69": [44, 46, 63, 72, 75, 79, 107], "x7": [44, 46, 62, 63, 72, 75, 78, 79, 81, 94, 107], "x70": [44, 46, 63, 72, 75, 79, 107], "x71": [44, 46, 63, 72, 75, 79, 107], "x72": [44, 46, 63, 72, 75, 79, 107], "x73": [44, 46, 63, 72, 75, 79, 107], "x74": [44, 46, 63, 72, 75, 79, 107], "x75": [44, 46, 63, 72, 75, 79, 107], "x76": [44, 46, 63, 72, 75, 79, 107], "x77": [44, 46, 63, 72, 75, 79, 107], "x78": [44, 46, 63, 72, 75, 79, 107], "x79": [44, 46, 63, 72, 75, 79, 107], "x8": [44, 46, 62, 63, 72, 75, 78, 79, 81, 94, 107], "x80": [44, 46, 63, 72, 75, 79, 107], "x81": [44, 46, 63, 72, 75, 79, 107], "x82": [44, 46, 63, 72, 75, 79, 107], "x83": [44, 46, 63, 72, 75, 79, 107], "x84": [44, 46, 63, 72, 75, 79, 107], "x85": [44, 46, 63, 72, 75, 79, 107], "x86": [44, 46, 63, 72, 75, 79, 107], "x87": [44, 46, 63, 72, 75, 79, 107], "x88": [44, 46, 63, 72, 75, 79, 107], "x89": [44, 46, 63, 72, 75, 79, 107], "x9": [44, 46, 62, 63, 72, 75, 78, 79, 81, 94, 107], "x90": [44, 46, 63, 72, 75, 79, 107], "x91": [44, 46, 63, 72, 75, 79, 107], "x92": [44, 46, 63, 72, 75, 79, 107], "x93": [44, 46, 63, 72, 75, 79, 107], "x94": [44, 46, 63, 72, 75, 79, 107], "x95": [44, 46, 63, 72, 75, 79, 107], "x96": [44, 46, 63, 72, 75, 79, 107], "x96x97x98x99x100ydcluster_var_icluster_var_jz": 44, "x97": [44, 46, 63, 72, 75, 79, 107], "x98": [44, 46, 63, 72, 75, 79, 107], "x99": [44, 46, 63, 72, 75, 79, 107], "x_": [26, 27, 42, 44, 51, 56, 63, 71, 74], "x_0": [52, 53, 56, 58, 59, 60], "x_1": [11, 12, 18, 19, 20, 24, 52, 53, 54, 56, 58, 59, 60, 68, 71, 79, 95, 97, 107], "x_1x_3": [54, 68], "x_2": [18, 19, 20, 24, 52, 53, 54, 56, 58, 59, 60, 68, 71, 95, 97], "x_3": [18, 19, 20, 24, 52, 53, 56, 58, 59, 60, 95, 97], "x_4": [18, 19, 20, 24, 52, 53, 54, 58, 59, 60, 68], "x_5": [18, 19, 24, 52, 53, 58, 59], "x_6": [52, 53, 58, 59], "x_7": [52, 53, 58, 59], "x_8": [52, 53, 58, 59], "x_9": [52, 53, 58, 59], "x_binary_control": 71, "x_binary_tr": 71, "x_col": [4, 7, 41, 44, 45, 46, 50, 57, 63, 64, 65, 67, 69, 70, 71, 75, 78, 79, 107, 109, 110], "x_cols_bench": 71, "x_cols_binari": 71, "x_cols_poli": 63, "x_conf": 68, "x_conf_tru": 68, "x_df": 56, "x_domain": 46, "x_i": [21, 22, 23, 25, 27, 28, 29, 33, 42, 51, 54, 55, 58, 59, 66, 68, 69, 72, 74, 77, 79], "x_p": [11, 12, 79, 107], "x_train": 62, "x_true": [54, 68], "x_var": 46, "xaxis_titl": [52, 53, 57, 69, 71], "xformla": 43, "xgb": 62, "xgb_untuned_l": 62, "xgb_untuned_m": 62, "xgbclassifi": [61, 64, 66, 110], "xgboost": [42, 45, 61, 64, 66, 110], "xgbregressor": [61, 62, 64, 66, 110], "xi": [20, 24, 79], "xi_": [94, 104], "xi_0": [26, 44, 63], "xi_i": 72, "xiaoji": 108, "xintercept": 42, "xlab": [42, 44, 45], "xlabel": [49, 52, 53, 54, 56, 58, 59, 62, 64, 65, 68], "xlim": [42, 45], "xtick": [49, 62], "xval": [46, 78], "xx": 51, "y": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 38, 39, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 101, 102, 103, 104, 107, 110], "y0": [43, 49, 54, 68], "y0_cvar": 54, "y0_quant": [54, 68], "y1": [43, 54, 68], "y1_cvar": 54, "y1_quant": [54, 68], "y_": [26, 44, 55, 56, 63, 72, 79], "y_0": [5, 20, 33, 81, 84], "y_1": [5, 20, 33, 81, 84], "y_col": [4, 7, 41, 42, 44, 45, 46, 50, 52, 53, 57, 58, 59, 63, 64, 65, 67, 69, 70, 73, 74, 75, 78, 79, 80, 81, 107, 109, 110], "y_df": [56, 67], "y_diff": 56, "y_i": [21, 22, 23, 25, 27, 28, 29, 42, 51, 54, 55, 66, 67, 68, 69, 72, 74, 79], "y_pred": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 39, 61, 78], "y_train": 62, "y_true": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 39, 61, 78], "ya": 108, "yasui": 108, "yata": 108, "yaxis_titl": [52, 53, 57, 69, 71], "year": 105, "yerr": [49, 56, 58, 59, 62, 64, 66, 69], "yet": [44, 48], "yggvpl": 63, "yield": 79, "yintercept": 45, "ylab": [42, 44, 45], "ylabel": [49, 52, 53, 54, 56, 58, 59, 62, 64, 65, 68], "ylim": 64, "ymax": 45, "ymin": 45, "yname": 43, "york": 108, "you": [38, 39, 41, 42, 50, 56, 59, 63, 70, 79, 105, 106, 110], "your": [61, 106], "ython": 105, "yukun": 108, "yusuk": 108, "yuya": 108, "yy": 51, "z": [4, 7, 8, 10, 11, 15, 18, 19, 20, 22, 24, 25, 26, 29, 41, 44, 45, 50, 52, 53, 57, 63, 64, 68, 71, 72, 77, 79, 81, 86, 88, 90, 91, 94, 104, 109], "z1": [11, 79], "z2": 79, "z3": 79, "z4": 79, "z_": [26, 44, 63], "z_1": [18, 19, 24], "z_2": [18, 19, 24], "z_3": [18, 19, 24], "z_4": [18, 19, 24], "z_5": 18, "z_col": [4, 7, 8, 10, 11, 41, 44, 45, 50, 63, 64, 65, 72, 75, 77, 79, 109], "z_i": [25, 29, 68, 72, 79], "z_j": [18, 19, 20, 24], "z_true": 68, "zadik": 108, "zaxis_titl": [52, 53, 57], "zero": [20, 33, 54, 55, 56, 61, 67, 68, 70, 71, 79, 94], "zeros_lik": 68, "zeta": [8, 11, 12, 45, 64, 77, 79, 107], "zeta_": [26, 44, 63], "zeta_0": [26, 44, 63], "zeta_i": [23, 25, 27, 42, 51, 74], "zeta_j": [94, 104], "zhang": 108, "zhao": [5, 6, 18, 19, 20, 24, 43, 55, 79, 108], "zimmert": [55, 108], "zip": [52, 53], "zorder": 49, "\u03c4_x0": 66, "\u03c4_x1": 66, "\u2139": 42}, "titles": ["API reference", "doubleml.DoubleMLAPO", "doubleml.DoubleMLAPOS", "doubleml.DoubleMLCVAR", "doubleml.DoubleMLClusterData", "doubleml.DoubleMLDID", "doubleml.DoubleMLDIDCS", "doubleml.DoubleMLData", "doubleml.DoubleMLIIVM", "doubleml.DoubleMLIRM", "doubleml.DoubleMLLPQ", "doubleml.DoubleMLPLIV", "doubleml.DoubleMLPLR", "doubleml.DoubleMLPQ", "doubleml.DoubleMLQTE", "doubleml.DoubleMLSSM", "doubleml.datasets.fetch_401K", "doubleml.datasets.fetch_bonus", "doubleml.datasets.make_confounded_irm_data", "doubleml.datasets.make_confounded_plr_data", "doubleml.datasets.make_did_SZ2020", "doubleml.datasets.make_heterogeneous_data", "doubleml.datasets.make_iivm_data", "doubleml.datasets.make_irm_data", "doubleml.datasets.make_irm_data_discrete_treatments", "doubleml.datasets.make_pliv_CHS2015", "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "doubleml.datasets.make_plr_CCDDHNR2018", "doubleml.datasets.make_plr_turrell2018", "doubleml.datasets.make_ssm_data", "doubleml.double_ml_score_mixins.LinearScoreMixin", "doubleml.double_ml_score_mixins.NonLinearScoreMixin", "doubleml.rdd.RDFlex", "doubleml.rdd.datasets.make_simple_rdd_data", "doubleml.utils.DMLDummyClassifier", "doubleml.utils.DMLDummyRegressor", "doubleml.utils.DoubleMLBLP", "doubleml.utils.DoubleMLPolicyTree", "doubleml.utils.GlobalClassifier", "doubleml.utils.GlobalRegressor", "doubleml.utils.gain_statistics", "R: Basic Instrumental Variables Calculation", "R: Basics of Double Machine Learning", "R: DoubleML for Difference-in-Differences", "R: Cluster Robust Double Machine Learning", "R: Impact of 401(k) on Financial Wealth", "R: Ensemble Learners and More with <code class=\"docutils literal notranslate\"><span class=\"pre\">mlr3pipelines</span></code>", "DML: Bonus Data", "Examples", "Python: Average Potential Outcome (APO) Models", "Python: Basic Instrumental Variables calculation", "Python: Basics of Double Machine Learning", "Python: Conditional Average Treatment Effects (CATEs) for IRM models", "Python: Conditional Average Treatment Effects (CATEs) for PLR models", "Python: Conditional Value at Risk of potential outcomes", "Python: Difference-in-Differences", "Python: Difference-in-Differences Pre-Testing", "Python: First Stage and Causal Estimation", "Python: Group Average Treatment Effects (GATEs) for IRM models", "Python: Group Average Treatment Effects (GATEs) for PLR models", "Python: GATE Sensitivity Analysis", "Python: Choice of learners", "DoubleML meets FLAML - How to tune learners automatically within <code class=\"docutils literal notranslate\"><span class=\"pre\">DoubleML</span></code>", "Python: Cluster Robust Double Machine Learning", "Python: Impact of 401(k) on Financial Wealth", "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)", "Python: PLM and IRM for Multiple Treatments", "Python: Policy Learning with Trees", "Python: Potential Quantiles and Quantile Treatment Effects", "Flexible Covariate Adjustment in Regression Discontinuity Designs (RDD)", "Python: Sensitivity Analysis", "Example: Sensitivity Analysis for Causal ML", "Python: Sample Selection Models", "<span class=\"section-number\">6. </span>Double machine learning algorithms", "<span class=\"section-number\">1. </span>The basics of double/debiased machine learning", "<span class=\"section-number\">2. </span>The data-backend DoubleMLData", "User guide", "<span class=\"section-number\">4. </span>Heterogeneous treatment effects", "<span class=\"section-number\">7. </span>Learners, hyperparameters and hyperparameter tuning", "<span class=\"section-number\">3. </span>Models", "<span class=\"section-number\">9. </span>Sample-splitting, cross-fitting and repeated cross-fitting", "<span class=\"section-number\">5. </span>Score functions", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "<span class=\"section-number\">8. </span>Variance estimation and confidence intervals", "<span class=\"section-number\">10. </span>Sensitivity analysis", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "Confidence bands and multiplier bootstrap for valid simultaneous inference", "DoubleML", "Installing DoubleML", "Getting started", "Double machine learning literature", "Release notes", "DoubleML Workflow"], "titleterms": {"": 62, "0": 110, "1": [62, 71, 110], "2": [62, 71, 110], "2011": 71, "2023": 71, "3": [62, 71, 110], "4": [71, 110], "401": [45, 64, 65, 70], "5": [71, 110], "6": 110, "7": 110, "95": 62, "A": [44, 63], "ATE": [60, 66, 72], "No": [44, 63], "One": [44, 52, 53, 63], "The": [45, 64, 66, 74, 75, 107], "acknowledg": [43, 105], "acycl": [41, 50], "addit": 66, "adjust": 69, "advanc": [69, 78, 94], "al": 71, "algorithm": [73, 95, 105, 107], "altern": 81, "analysi": [49, 60, 70, 71, 95, 110], "api": [0, 62], "apo": [49, 79, 81, 95], "applic": [44, 63, 70], "approach": [42, 51, 61, 74], "arah": 71, "arbitrari": 66, "arrai": 75, "asset": [45, 64], "assumpt": 71, "att": 55, "augment": 66, "automat": 62, "automl": 62, "averag": [45, 49, 52, 53, 58, 59, 64, 77, 79, 81, 95], "backend": [44, 45, 63, 64, 75, 107, 110], "band": [94, 104], "base": 46, "basic": [41, 42, 50, 51, 74], "benchmark": [70, 71, 95], "bia": [42, 51, 74], "binari": [79, 81], "bonu": 47, "bootstrap": [94, 104], "build": 106, "calcul": [41, 50], "call": 62, "callabl": 81, "case": 48, "cate": [52, 53, 66, 77], "causal": [47, 49, 57, 71, 81, 107, 110], "chernozhukov": 71, "choic": 61, "citat": 105, "class": [0, 44, 63], "cluster": [44, 63], "code": 105, "coeffici": 62, "combin": 57, "compar": [61, 62], "comparison": [43, 62], "comput": [61, 62], "conclus": [62, 71], "conda": 106, "condit": [52, 53, 54, 65, 77, 81], "confid": [62, 94, 104], "construct": 78, "contrast": 49, "covari": 69, "coverag": [55, 57], "cran": 106, "creat": 62, "cross": [44, 55, 63, 79, 80, 81, 95, 107], "custom": [61, 62], "cvar": [54, 65, 77, 81], "dag": [41, 50], "data": [0, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 74, 75, 79, 81, 95, 107, 110], "datafram": 75, "dataset": [0, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 47], "debias": [42, 51, 74, 107], "default": 62, "defin": [44, 63], "demo": 43, "depend": 106, "design": [69, 79], "detail": [43, 79], "develop": 106, "dgp": [42, 49, 51], "did": [43, 79], "differ": [43, 55, 56, 61, 79, 81, 94, 95], "dimension": [52, 53], "direct": [41, 50], "disclaim": 71, "discontinu": [69, 79], "distribut": 72, "dml": [44, 47, 63, 80, 107, 110], "dml1": 73, "dml2": 73, "dmldummyclassifi": 34, "dmldummyregressor": 35, "doubl": [0, 42, 44, 51, 63, 73, 74, 105, 107, 108], "double_ml_score_mixin": [30, 31], "doubleml": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 50, 62, 64, 70, 71, 94, 105, 106, 110], "doublemlapo": [1, 2], "doublemlblp": 36, "doublemlclusterdata": [4, 44, 63], "doublemlcvar": 3, "doublemldata": [7, 45, 64, 75, 107], "doublemldid": 5, "doublemldidc": 6, "doublemliivm": 8, "doublemlirm": 9, "doublemllpq": 10, "doublemlpliv": [11, 44, 63], "doublemlplr": 12, "doublemlpolicytre": 37, "doublemlpq": 13, "doublemlqt": 14, "doublemlssm": 15, "effect": [45, 48, 52, 53, 54, 58, 59, 64, 65, 66, 68, 70, 71, 77], "elig": [45, 64], "empir": 57, "ensembl": [46, 69], "error": [44, 63], "estim": [41, 45, 47, 50, 55, 57, 60, 62, 64, 65, 66, 68, 70, 71, 72, 80, 81, 94, 107, 110], "et": 71, "evalu": [61, 62, 78], "exampl": [43, 44, 48, 52, 53, 63, 70, 71], "exploit": [43, 46], "extern": [78, 80], "featur": [46, 105], "fetch_401k": 16, "fetch_bonu": 17, "figur": 66, "file": 106, "final": 43, "financi": [45, 64, 65], "first": 57, "fit": [44, 62, 63, 80, 107], "flaml": 62, "flexibl": 69, "fold": [62, 80], "forest": 47, "formul": [71, 110], "from": [43, 46, 75, 106], "full": 62, "function": [0, 43, 44, 63, 81, 107], "fuzzi": [69, 79], "gain_statist": 40, "gate": [58, 59, 60, 77], "gatet": 60, "gener": [0, 42, 48, 49, 51, 62, 69, 74, 95], "get": 107, "github": 106, "global": 69, "globalclassifi": 38, "globalregressor": 39, "graph": [41, 50], "group": [58, 59, 77], "guid": 76, "helper": [44, 63], "heterogen": [48, 66, 77], "how": [46, 62], "hyperparamet": 78, "identif": 71, "iivm": [45, 64, 79, 81], "impact": [45, 64, 65], "implement": [73, 79, 81, 95], "induc": [42, 51, 74], "infer": [94, 104, 110], "initi": [44, 62, 63], "instal": 106, "instrument": [41, 50], "integr": 43, "interact": [45, 58, 64, 67, 79, 81, 95], "interv": [62, 94, 104], "invers": 66, "irm": [45, 47, 52, 58, 64, 66, 67, 70, 77, 79, 81, 95], "iv": [41, 45, 50, 64, 79, 81], "joint": 104, "k": [45, 64, 65, 70, 80], "lambda": 57, "lasso": [47, 57], "latest": 106, "lear": [44, 63], "learn": [0, 42, 44, 51, 63, 67, 73, 74, 77, 105, 107, 108], "learner": [46, 47, 61, 62, 69, 78, 107], "less": 62, "level": 79, "linear": [45, 59, 64, 66, 69, 79, 81, 95], "linearscoremixin": 30, "literatur": 108, "load": [44, 47, 63, 71], "loader": 0, "local": [45, 64, 65, 68, 69, 81], "loss": 57, "lpq": [68, 81], "lqte": [65, 68], "m": 80, "machin": [0, 42, 44, 51, 63, 73, 74, 105, 107, 108], "main": 105, "mainten": 105, "make_confounded_irm_data": 18, "make_confounded_plr_data": 19, "make_did_sz2020": 20, "make_heterogeneous_data": 21, "make_iivm_data": 22, "make_irm_data": 23, "make_irm_data_discrete_treat": 24, "make_pliv_chs2015": 25, "make_pliv_multiway_cluster_ckms2021": 26, "make_plr_ccddhnr2018": 27, "make_plr_turrell2018": 28, "make_simple_rdd_data": 33, "make_ssm_data": 29, "mar": 72, "market": [44, 63], "matric": 75, "meet": 62, "method": [62, 110], "metric": [61, 62], "minimum": 78, "miss": 72, "missing": [79, 81], "mixin": 0, "ml": [42, 43, 51, 71, 74, 110], "mlr3": 46, "mlr3extralearn": 46, "mlr3learner": 46, "mlr3pipelin": 46, "model": [0, 45, 47, 49, 52, 53, 58, 59, 62, 64, 66, 67, 71, 72, 77, 79, 80, 81, 94, 95, 107, 110], "modul": [0, 47], "more": 46, "motiv": [44, 63], "multipl": [49, 66, 79], "multipli": [94, 104], "naiv": [41, 50], "net": [45, 64], "neyman": [81, 107], "nonignor": [72, 79, 81], "nonlinearscoremixin": 31, "nonrespons": [72, 79, 81], "note": 109, "nuisanc": [62, 107], "object": [44, 63, 70], "option": 106, "orthogon": [42, 51, 74, 81, 107], "other": 0, "out": [42, 51, 74], "outcom": [49, 54, 55, 72, 77, 79, 81, 95], "over": 94, "overcom": [42, 51, 74], "overfit": [42, 51, 74], "overlap": 66, "packag": [43, 45, 64, 106], "panel": [55, 79, 81, 95], "paramet": [46, 47, 62, 81], "partial": [42, 45, 51, 59, 64, 66, 74, 79, 81, 95], "particip": [45, 64], "partit": 80, "penalti": 57, "perform": [43, 66], "pip": 106, "pipelin": 78, "pliv": [79, 81], "plm": [66, 79, 81], "plot": [44, 62, 63], "plr": [45, 47, 53, 59, 64, 77, 79, 81, 95], "polici": [67, 77], "potenti": [49, 54, 65, 68, 77, 79, 81, 95], "pq": [68, 77, 81], "pre": 56, "predict": [43, 78], "preprocess": 46, "problem": 110, "process": [42, 44, 49, 51, 63, 74], "product": [44, 63], "propens": 66, "provid": 80, "python": [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 72, 78, 106], "qte": [68, 77], "qualiti": 57, "quantil": [65, 68, 77, 81], "r": [41, 42, 43, 44, 45, 46, 48, 78, 106], "random": [47, 72, 79, 81], "rank": 66, "rdd": [32, 33, 69, 79], "rdflex": 32, "real": [44, 63], "refer": [0, 41, 43, 44, 46, 50, 57, 63, 66, 71, 74, 78, 80, 94, 104, 105, 107], "regress": [45, 58, 59, 64, 67, 69, 79, 81, 95], "regular": [42, 51, 74], "releas": [106, 109], "remark": 43, "remov": [42, 51, 74], "repeat": [55, 79, 80, 81, 95], "repetit": 80, "requir": 78, "respect": [44, 63], "result": [44, 45, 63, 64, 66], "risk": [54, 65, 77, 81], "robust": [44, 63], "sampl": [42, 51, 62, 72, 74, 79, 80, 81], "sandbox": 48, "score": [0, 42, 51, 66, 74, 81, 107], "section": [55, 79, 81, 95], "select": [72, 79, 81], "sensit": [49, 60, 70, 71, 95, 110], "set": [46, 78], "sharp": [69, 79], "simpl": [42, 51, 74], "simul": [41, 44, 50, 55, 63, 70], "simultan": [94, 104], "singl": 49, "sourc": [105, 106], "specif": [95, 110], "specifi": [47, 78, 81], "split": [42, 51, 74, 80], "ssm": 79, "stack": 69, "stage": 57, "standard": [44, 61, 63], "start": 107, "step": 62, "studi": 48, "summari": [45, 62, 64, 66], "test": 56, "theori": 95, "time": [61, 62], "train": 62, "treatment": [45, 52, 53, 54, 58, 59, 64, 65, 66, 68, 77, 79], "tree": [67, 77], "tune": [46, 62, 78], "two": [44, 52, 53, 63], "under": [66, 72], "untun": 62, "up": 46, "us": [41, 43, 46, 47, 50, 62, 78], "user": 76, "util": [0, 34, 35, 36, 37, 38, 39, 40], "v": 57, "valid": [94, 104], "valu": [54, 65, 77, 81], "vanderweel": 71, "variabl": [41, 50], "varianc": 94, "version": 106, "via": 81, "wai": [44, 63], "wealth": [45, 64, 65], "weight": [66, 77], "when": 62, "whl": 106, "within": 62, "without": [69, 80], "workflow": 110, "xgboost": 62, "zero": [44, 63]}})