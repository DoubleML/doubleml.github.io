Search.setIndex({"alltitles": {"(One-Way) Cluster Robust Double Machine Learing": [[35, "(One-Way)-Cluster-Robust-Double-Machine-Learing"], [53, "(One-Way)-Cluster-Robust-Double-Machine-Learing"]], "0. Problem Formulation": [[99, "problem-formulation"]], "1. Data-Backend": [[99, "data-backend"]], "1. Formulation of Causal Model & Identification Assumptions": [[60, "1.-Formulation-of-Causal-Model-&-Identification-Assumptions"]], "2. Causal Model": [[99, "causal-model"]], "2. Estimation of Causal Effect": [[60, "2.-Estimation-of-Causal-Effect"]], "3. ML Methods": [[99, "ml-methods"]], "3. Sensitivity Analysis": [[60, "3.-Sensitivity-Analysis"]], "4. Benchmarking Analysis": [[60, "4.-Benchmarking-Analysis"]], "4. DML Specifications": [[99, "dml-specifications"]], "5. Conclusion": [[60, "5.-Conclusion"]], "5. Estimation": [[99, "estimation"]], "6. Inference": [[99, "inference"]], "7. Sensitivity Analysis": [[99, "sensitivity-analysis"]], "A Motivating Example: Two-Way Cluster Robust DML": [[35, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"], [53, "A-Motivating-Example:-Two-Way-Cluster-Robust-DML"]], "API reference": [[0, "api-reference"]], "ATE Estimation and Sensitivity": [[51, "ATE-Estimation-and-Sensitivity"]], "ATE estimates distribution": [[61, "ATE-estimates-distribution"], [61, "id3"]], "ATTE Estimation": [[46, "ATTE-Estimation"], [46, "id2"]], "Acknowledgements": [[94, "acknowledgements"]], "Acknowledgements and Final Remarks": [[34, "Acknowledgements-and-Final-Remarks"]], "Additional Results: CATE estimates": [[56, "Additional-Results:-CATE-estimates"]], "Advanced: External Predictions": [[67, "advanced-external-predictions"]], "Algorithm DML1": [[62, "algorithm-dml1"]], "Algorithm DML2": [[62, "algorithm-dml2"]], "Application Results": [[35, "Application-Results"], [53, "Application-Results"]], "Application: 401(k)": [[59, "Application:-401(k)"]], "Average Potential Outcome (APOs)": [[40, "Average-Potential-Outcome-(APOs)"]], "Average Potential Outcomes (APOs)": [[68, "average-potential-outcomes-apos"], [70, "average-potential-outcomes-apos"], [84, "average-potential-outcomes-apos"]], "Average Potential Outcomes (APOs) for Multiple Treatment Levels": [[68, "average-potential-outcomes-apos-for-multiple-treatment-levels"]], "Benchmarking": [[84, "benchmarking"]], "Benchmarking Analysis": [[59, "Benchmarking-Analysis"]], "Binary Interactive Regression Model (IRM)": [[68, "binary-interactive-regression-model-irm"], [70, "binary-interactive-regression-model-irm"]], "CATEs for IRM models": [[66, "cates-for-irm-models"]], "CATEs for PLR models": [[66, "cates-for-plr-models"]], "CVaR Treatment Effects": [[45, "CVaR-Treatment-Effects"]], "CVaR of potential outcomes": [[66, "cvar-of-potential-outcomes"]], "CVaR treatment effects": [[66, "cvar-treatment-effects"]], "Causal Analysis with DoubleML": [[60, "Causal-Analysis-with-DoubleML"]], "Causal Contrats": [[40, "Causal-Contrats"]], "Causal estimation vs. lasso penalty \\lambda": [[48, "Causal-estimation-vs.-lasso-penalty-\\lambda"]], "Chernozhukov et al. (2023): Benchmarking": [[60, "Chernozhukov-et-al.-(2023):-Benchmarking"]], "Citation": [[94, "citation"]], "Cluster Robust Cross Fitting": [[35, "Cluster-Robust-Cross-Fitting"], [53, "Cluster-Robust-Cross-Fitting"]], "Cluster Robust Standard Errors": [[35, "Cluster-Robust-Standard-Errors"], [53, "Cluster-Robust-Standard-Errors"]], "Clustering and double machine learning": [[35, "Clustering-and-double-machine-learning"], [53, "Clustering-and-double-machine-learning"]], "Combined loss vs. lasso penalty \\lambda": [[48, "Combined-loss-vs.-lasso-penalty-\\lambda"]], "Comparing different learners": [[52, "Comparing-different-learners"]], "Comparison to did package": [[34, "Comparison-to-did-package"]], "Computation time": [[52, "Computation-time"]], "Conditional Value at Risk (CVaR)": [[45, "Conditional-Value-at-Risk-(CVaR)"]], "Conditional average treatment effects (CATEs)": [[66, "conditional-average-treatment-effects-cates"]], "Conditional value at risk (CVaR)": [[66, "conditional-value-at-risk-cvar"], [70, "conditional-value-at-risk-cvar"]], "Confidence bands and multiplier bootstrap for valid simultaneous inference": [[83, "confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference"], [93, "confidence-bands-and-multiplier-bootstrap-for-valid-simultaneous-inference"]], "Coverage Simulation": [[46, "Coverage-Simulation"], [46, "id3"]], "Cross-fitting with K folds": [[69, "cross-fitting-with-k-folds"]], "Cross-fitting, DML algorithms and Neyman-orthogonal score functions": [[96, "cross-fitting-dml-algorithms-and-neyman-orthogonal-score-functions"]], "Custom evaluation metrics": [[52, "Custom-evaluation-metrics"]], "DML: Bonus Data": [[38, "DML:-Bonus-Data"]], "Data": [[36, "Data"], [43, "Data"], [44, "Data"], [45, "Data"], [46, "Data"], [46, "id1"], [49, "Data"], [50, "Data"], [51, "Data"], [54, "Data"], [55, "Data"], [57, "Data"], [58, "Data"], [58, "id1"], [59, "Data"], [61, "Data"], [61, "id1"], [96, "data"]], "Data Generating Process (DGP)": [[33, "Data-Generating-Process-(DGP)"], [40, "Data-Generating-Process-(DGP)"], [42, "Data-Generating-Process-(DGP)"]], "Data Simulation": [[32, "Data-Simulation"], [41, "Data-Simulation"]], "Data and Effect Estimation": [[59, "Data-and-Effect-Estimation"]], "Data generating process": [[63, "data-generating-process"]], "Data preprocessing": [[37, "Data-preprocessing"]], "Data-Backend for Cluster Data": [[35, "Data-Backend-for-Cluster-Data"], [53, "Data-Backend-for-Cluster-Data"]], "Dataset generators": [[0, "dataset-generators"]], "Dataset loaders": [[0, "dataset-loaders"]], "Datasets module": [[0, "datasets-module"]], "Define Helper Functions for Plotting": [[35, "Define-Helper-Functions-for-Plotting"], [53, "Define-Helper-Functions-for-Plotting"]], "Demo Example from did": [[34, "Demo-Example-from-did"]], "Details on Predictive Performance": [[34, "Details-on-Predictive-Performance"]], "Difference-in-Differences Models": [[70, "difference-in-differences-models"]], "Difference-in-Differences Models (DID)": [[68, "difference-in-differences-models-did"]], "Difference-in-Differences for Panel Data": [[84, "difference-in-differences-for-panel-data"]], "Difference-in-Differences for repeated cross-sections": [[84, "difference-in-differences-for-repeated-cross-sections"]], "Disclaimer": [[60, "Disclaimer"]], "Double Machine Learning Algorithm": [[94, "double-machine-learning-algorithm"]], "Double machine learning algorithms": [[62, "double-machine-learning-algorithms"]], "Double machine learning data class": [[0, "double-machine-learning-data-class"]], "Double machine learning literature": [[97, "double-machine-learning-literature"]], "Double machine learning models": [[0, "double-machine-learning-models"]], "Double/debiased machine learning": [[33, "Double/debiased-machine-learning"], [42, "Double/debiased-machine-learning"], [63, "double-debiased-machine-learning"]], "DoubleML": [[94, "doubleml"]], "DoubleML Object": [[59, "DoubleML-Object"]], "DoubleML Workflow": [[99, "doubleml-workflow"]], "DoubleMLData from arrays and matrices": [[64, "doublemldata-from-arrays-and-matrices"]], "DoubleMLData from dataframes": [[64, "doublemldata-from-dataframes"]], "Effect Heterogeneity": [[39, "effect-heterogeneity"]], "Empirical coverage vs. lasso penalty \\lambda": [[48, "Empirical-coverage-vs.-lasso-penalty-\\lambda"]], "Estimate DML models without sample-splitting": [[69, "estimate-dml-models-without-sample-splitting"]], "Estimate double/debiased machine learning models": [[96, "estimate-double-debiased-machine-learning-models"]], "Estimating Potential Quantiles and Quantile Treatment Effects": [[55, "Estimating-Potential-Quantiles-and-Quantile-Treatment-Effects"]], "Estimating local quantile treatment effects (LQTEs)": [[55, "Estimating-local-quantile-treatment-effects-(LQTEs)"]], "Estimating the Average Treatment Effect of 401(k) Eligibility on Net Financial Assets": [[36, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"], [54, "Estimating-the-Average-Treatment-Effect-of-401(k)-Eligibility-on-Net-Financial-Assets"]], "Estimating the treatment effect on the Conditional Value a Risk (CVaR)": [[55, "Estimating-the-treatment-effect-on-the-Conditional-Value-a-Risk-(CVaR)"]], "Estimation": [[61, "Estimation"], [61, "id2"]], "Estimation quality vs. \\lambda": [[48, "Estimation-quality-vs.-\\lambda"]], "Evaluate learners": [[67, "evaluate-learners"]], "Example: Sensitivity Analysis for Causal ML": [[60, "Example:-Sensitivity-Analysis-for-Causal-ML"]], "Examples": [[39, "examples"]], "Exploiting the Functionalities of did": [[34, "Exploiting-the-Functionalities-of-did"]], "Externally provide a sample splitting / partition": [[69, "externally-provide-a-sample-splitting-partition"]], "GATE Estimation and Sensitivity": [[51, "GATE-Estimation-and-Sensitivity"]], "GATET Estimation and Sensitivity": [[51, "GATET-Estimation-and-Sensitivity"]], "GATEs for IRM models": [[66, "gates-for-irm-models"]], "GATEs for PLR models": [[66, "gates-for-plr-models"]], "General Examples": [[39, "general-examples"]], "General algorithm": [[84, "general-algorithm"]], "Getting started": [[96, "getting-started"]], "Group Average Treatment Effects (GATEs)": [[49, "Group-Average-Treatment-Effects-(GATEs)"], [50, "Group-Average-Treatment-Effects-(GATEs)"]], "Group average treatment effects (GATEs)": [[66, "group-average-treatment-effects-gates"]], "Heterogeneous treatment effects": [[66, "heterogeneous-treatment-effects"]], "How to exploit more features of mlr3pipelines in DoubleML": [[37, "How-to-exploit-more-features-of-mlr3pipelines-in-DoubleML"]], "Hyperparameter tuning": [[67, "hyperparameter-tuning"], [67, "id16"]], "Hyperparameter tuning with pipelines": [[67, "hyperparameter-tuning-with-pipelines"]], "Implementation": [[84, "implementation"]], "Implementation of the double machine learning algorithms": [[62, "implementation-of-the-double-machine-learning-algorithms"]], "Implementation of the score function and the estimate of the causal parameter": [[70, "implementation-of-the-score-function-and-the-estimate-of-the-causal-parameter"]], "Implemented Neyman orthogonal score functions": [[70, "implemented-neyman-orthogonal-score-functions"]], "Initialize DoubleMLClusterData object": [[35, "Initialize-DoubleMLClusterData-object"], [53, "Initialize-DoubleMLClusterData-object"]], "Initialize the objects of class DoubleMLPLIV": [[35, "Initialize-the-objects-of-class-DoubleMLPLIV"], [53, "Initialize-the-objects-of-class-DoubleMLPLIV"]], "Installing DoubleML": [[95, "installing-doubleml"]], "Instrumental Variables Directed Acyclic Graph (IV - DAG)": [[32, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"], [41, "Instrumental-Variables-Directed-Acyclic-Graph-(IV---DAG)"]], "Interactive IV Model (IIVM)": [[36, "Interactive-IV-Model-(IIVM)"], [54, "Interactive-IV-Model-(IIVM)"]], "Interactive IV model (IIVM)": [[68, "interactive-iv-model-iivm"], [70, "interactive-iv-model-iivm"]], "Interactive Regression Model (IRM)": [[36, "Interactive-Regression-Model-(IRM)"], [49, "Interactive-Regression-Model-(IRM)"], [54, "Interactive-Regression-Model-(IRM)"], [57, "Interactive-Regression-Model-(IRM)"]], "Interactive regression model (IRM)": [[84, "interactive-regression-model-irm"]], "Interactive regression models (IRM)": [[68, "interactive-regression-models-irm"], [70, "interactive-regression-models-irm"]], "Learners to estimate the nuisance models": [[96, "learners-to-estimate-the-nuisance-models"]], "Learners, hyperparameters and hyperparameter tuning": [[67, "learners-hyperparameters-and-hyperparameter-tuning"]], "Load Data": [[60, "Load-Data"]], "Load and Process Data": [[35, "Load-and-Process-Data"], [53, "Load-and-Process-Data"]], "Load bonus data using the dml datasets module": [[38, "Load-bonus-data-using-the-dml-datasets-module"]], "Local Average Treatment Effects of 401(k) Participation on Net Financial Assets": [[36, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"], [54, "Local-Average-Treatment-Effects-of-401(k)-Participation-on-Net-Financial-Assets"]], "Local Potential Quantile Estimation": [[58, "Local-Potential-Quantile-Estimation"]], "Local Potential Quantiles (LPQs)": [[58, "Local-Potential-Quantiles-(LPQs)"]], "Local Quantile Treatment Effects (LQTEs)": [[58, "Local-Quantile-Treatment-Effects-(LQTEs)"]], "Local potential quantiles (LPQs)": [[70, "local-potential-quantiles-lpqs"]], "Main Features": [[94, "main-features"]], "Minimum requirements for learners": [[67, "minimum-requirements-for-learners"], [67, "id2"]], "Missingness at Random": [[68, "missingness-at-random"], [70, "missingness-at-random"]], "Model-specific implementations": [[84, "model-specific-implementations"]], "Models": [[68, "models"]], "Motivation": [[35, "Motivation"], [53, "Motivation"]], "Multiple Average Potential Outcome Models (APOS)": [[40, "Multiple-Average-Potential-Outcome-Models-(APOS)"]], "Multiplier bootstrap and joint confidence intervals": [[93, "multiplier-bootstrap-and-joint-confidence-intervals"]], "Naive estimation": [[32, "Naive-estimation"], [41, "Naive-estimation"]], "No Clustering / Zero-Way Clustering": [[35, "No-Clustering-/-Zero-Way-Clustering"], [53, "No-Clustering-/-Zero-Way-Clustering"]], "Nonignorable Nonresponse": [[68, "nonignorable-nonresponse"], [70, "nonignorable-nonresponse"]], "One-Way Clustering with Respect to the Market": [[35, "One-Way-Clustering-with-Respect-to-the-Market"], [53, "One-Way-Clustering-with-Respect-to-the-Market"]], "One-Way Clustering with Respect to the Product": [[35, "One-Way-Clustering-with-Respect-to-the-Product"], [53, "One-Way-Clustering-with-Respect-to-the-Product"]], "One-dimensional Example": [[43, "One-dimensional-Example"], [44, "One-dimensional-Example"]], "Outcome missing at random (MAR)": [[61, "Outcome-missing-at-random-(MAR)"]], "Outcome missing under nonignorable nonresponse": [[61, "Outcome-missing-under-nonignorable-nonresponse"]], "Overcoming regularization bias by orthogonalization": [[33, "Overcoming-regularization-bias-by-orthogonalization"], [42, "Overcoming-regularization-bias-by-orthogonalization"], [63, "overcoming-regularization-bias-by-orthogonalization"]], "Panel Data": [[70, "panel-data"]], "Panel Data (Repeated Outcomes)": [[46, "Panel-Data-(Repeated-Outcomes)"]], "Panel data": [[68, "panel-data"]], "Parameter tuning": [[37, "Parameter-tuning"]], "Partialling out score": [[33, "Partialling-out-score"], [42, "Partialling-out-score"], [63, "partialling-out-score"]], "Partially Linear Regression Model (PLR)": [[36, "Partially-Linear-Regression-Model-(PLR)"], [50, "Partially-Linear-Regression-Model-(PLR)"], [54, "Partially-Linear-Regression-Model-(PLR)"]], "Partially linear IV regression model (PLIV)": [[68, "partially-linear-iv-regression-model-pliv"], [70, "partially-linear-iv-regression-model-pliv"]], "Partially linear models (PLM)": [[68, "partially-linear-models-plm"], [70, "partially-linear-models-plm"]], "Partially linear regression model (PLR)": [[68, "partially-linear-regression-model-plr"], [70, "partially-linear-regression-model-plr"], [84, "partially-linear-regression-model-plr"]], "Policy Learning with Trees": [[57, "Policy-Learning-with-Trees"], [66, "policy-learning-with-trees"]], "Potential Quantile Estimation": [[58, "Potential-Quantile-Estimation"]], "Potential Quantiles (PQs)": [[58, "Potential-Quantiles-(PQs)"]], "Potential quantiles (PQs)": [[66, "potential-quantiles-pqs"], [70, "potential-quantiles-pqs"]], "Python: Average Potential Outcome (APO) Models": [[40, "Python:-Average-Potential-Outcome-(APO)-Models"]], "Python: Basic Instrumental Variables calculation": [[41, "Python:-Basic-Instrumental-Variables-calculation"]], "Python: Basics of Double Machine Learning": [[42, "Python:-Basics-of-Double-Machine-Learning"]], "Python: Building the package from source": [[95, "python-building-the-package-from-source"]], "Python: Case studies": [[39, "python-case-studies"]], "Python: Choice of learners": [[52, "Python:-Choice-of-learners"]], "Python: Cluster Robust Double Machine Learning": [[53, "Python:-Cluster-Robust-Double-Machine-Learning"]], "Python: Conditional Average Treatment Effects (CATEs) for IRM models": [[43, "Python:-Conditional-Average-Treatment-Effects-(CATEs)-for-IRM-models"]], "Python: Conditional Average Treatment Effects (CATEs) for PLR models": [[44, "Python:-Conditional-Average-Treatment-Effects-(CATEs)-for-PLR-models"]], "Python: Conditional Value at Risk of potential outcomes": [[45, "Python:-Conditional-Value-at-Risk-of-potential-outcomes"]], "Python: Difference-in-Differences": [[46, "Python:-Difference-in-Differences"]], "Python: Difference-in-Differences Pre-Testing": [[47, "Python:-Difference-in-Differences-Pre-Testing"]], "Python: First Stage and Causal Estimation": [[48, "Python:-First-Stage-and-Causal-Estimation"]], "Python: GATE Sensitivity Analysis": [[51, "Python:-GATE-Sensitivity-Analysis"]], "Python: Group Average Treatment Effects (GATEs) for IRM models": [[49, "Python:-Group-Average-Treatment-Effects-(GATEs)-for-IRM-models"]], "Python: Group Average Treatment Effects (GATEs) for PLR models": [[50, "Python:-Group-Average-Treatment-Effects-(GATEs)-for-PLR-models"]], "Python: Impact of 401(k) on Financial Wealth": [[54, "Python:-Impact-of-401(k)-on-Financial-Wealth"]], "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)": [[55, "Python:-Impact-of-401(k)-on-Financial-Wealth-(Quantile-Effects)"]], "Python: Installing DoubleML": [[95, "python-installing-doubleml"]], "Python: Installing a released version from a .whl file": [[95, "python-installing-a-released-version-from-a-whl-file"]], "Python: Installing the latest release from pip or conda": [[95, "python-installing-the-latest-release-from-pip-or-conda"]], "Python: Learners and hyperparameters": [[67, "python-learners-and-hyperparameters"]], "Python: PLM and IRM for Multiple Treatments": [[56, "Python:-PLM-and-IRM-for-Multiple-Treatments"]], "Python: Policy Learning with Trees": [[57, "Python:-Policy-Learning-with-Trees"]], "Python: Potential Quantiles and Quantile Treatment Effects": [[58, "Python:-Potential-Quantiles-and-Quantile-Treatment-Effects"]], "Python: Sample Selection Models": [[61, "Python:-Sample-Selection-Models"]], "Python: Sensitivity Analysis": [[59, "Python:-Sensitivity-Analysis"]], "Quantile Treatment Effects (QTEs)": [[58, "Quantile-Treatment-Effects-(QTEs)"]], "Quantile treatment effects (QTEs)": [[66, "quantile-treatment-effects-qtes"]], "Quantiles": [[66, "quantiles"]], "R: Basic Instrumental Variables Calculation": [[32, "R:-Basic-Instrumental-Variables-Calculation"]], "R: Basics of Double Machine Learning": [[33, "R:-Basics-of-Double-Machine-Learning"]], "R: Case studies": [[39, "r-case-studies"]], "R: Cluster Robust Double Machine Learning": [[35, "R:-Cluster-Robust-Double-Machine-Learning"]], "R: DoubleML for Difference-in-Differences": [[34, "R:-DoubleML-for-Difference-in-Differences"]], "R: Ensemble Learners and More with mlr3pipelines": [[37, "R:-Ensemble-Learners-and-More-with-mlr3pipelines"]], "R: Impact of 401(k) on Financial Wealth": [[36, "R:-Impact-of-401(k)-on-Financial-Wealth"]], "R: Installing DoubleML": [[95, "r-installing-doubleml"]], "R: Installing the development version from GitHub": [[95, "r-installing-the-development-version-from-github"]], "R: Installing the latest release from CRAN": [[95, "r-installing-the-latest-release-from-cran"]], "R: Learners and hyperparameters": [[67, "r-learners-and-hyperparameters"]], "Ranking Treatment Effects under Treatment Propensity and Treatment Effect Heterogeneity": [[56, "Ranking-Treatment-Effects-under-Treatment-Propensity-and-Treatment-Effect-Heterogeneity"]], "Real-Data Application": [[35, "Real-Data-Application"], [53, "Real-Data-Application"]], "References": [[32, "References"], [34, "References"], [35, "References"], [37, "References"], [41, "References"], [48, "References"], [53, "References"], [56, "References"], [60, "References"], [63, "references"], [67, "references"], [69, "references"], [83, "references"], [93, "references"], [94, "references"], [96, "references"]], "Regularization Bias in Simple ML-Approaches": [[33, "Regularization-Bias-in-Simple-ML-Approaches"], [42, "Regularization-Bias-in-Simple-ML-Approaches"]], "Regularization bias in simple ML-approaches": [[63, "regularization-bias-in-simple-ml-approaches"]], "Release notes": [[98, "release-notes"]], "Repeated Cross-Sectional Data": [[46, "Repeated-Cross-Sectional-Data"], [70, "repeated-cross-sectional-data"]], "Repeated cross-fitting with K folds and M repetitions": [[69, "repeated-cross-fitting-with-k-folds-and-m-repetitions"]], "Repeated cross-sections": [[68, "repeated-cross-sections"]], "Sample Selection Models": [[70, "sample-selection-models"]], "Sample Selection Models (SSM)": [[68, "sample-selection-models-ssm"]], "Sample splitting to remove bias induced by overfitting": [[33, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [42, "Sample-splitting-to-remove-bias-induced-by-overfitting"], [63, "sample-splitting-to-remove-bias-induced-by-overfitting"]], "Sample-splitting without cross-fitting": [[69, "sample-splitting-without-cross-fitting"]], "Sample-splitting, cross-fitting and repeated cross-fitting": [[69, "sample-splitting-cross-fitting-and-repeated-cross-fitting"]], "Sandbox": [[39, "sandbox"]], "Score functions": [[70, "score-functions"]], "Score mixin classes for double machine learning models": [[0, "score-mixin-classes-for-double-machine-learning-models"]], "Sensitivity Analysis": [[40, "Sensitivity-Analysis"], [59, "Sensitivity-Analysis"], [59, "id1"]], "Sensitivity Analysis with IRM": [[59, "Sensitivity-Analysis-with-IRM"]], "Sensitivity analysis": [[84, "sensitivity-analysis"]], "Set up learners based on mlr3pipelines": [[37, "Set-up-learners-based-on-mlr3pipelines"]], "Simulate two-way cluster data": [[35, "Simulate-two-way-cluster-data"], [53, "Simulate-two-way-cluster-data"]], "Simulation Example": [[59, "Simulation-Example"]], "Simultaneous inference over different DoubleML models (advanced)": [[83, "simultaneous-inference-over-different-doubleml-models-advanced"]], "Single Average Potential Outcome Models (APO)": [[40, "Single-Average-Potential-Outcome-Models-(APO)"]], "Source code and maintenance": [[94, "source-code-and-maintenance"]], "Specify learner and estimate causal parameter: IRM model with Lasso as learner": [[38, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: IRM model with random forest as learner": [[38, "Specify-learner-and-estimate-causal-parameter:-IRM-model-with-random-forest-as-learner"]], "Specify learner and estimate causal parameter: PLR model with Lasso as learner": [[38, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-Lasso-as-learner"]], "Specify learner and estimate causal parameter: PLR model with random forest as learner": [[38, "Specify-learner-and-estimate-causal-parameter:-PLR-model-with-random-forest-as-learner"]], "Specifying alternative score functions via callables": [[70, "specifying-alternative-score-functions-via-callables"]], "Specifying learners and set hyperparameters": [[67, "specifying-learners-and-set-hyperparameters"], [67, "id9"]], "Standard approach": [[52, "Standard-approach"]], "Summary Figure": [[56, "Summary-Figure"]], "Summary of Results": [[36, "Summary-of-Results"], [54, "Summary-of-Results"]], "The Augmented Inverse Propensity Weighting Model estimates the ATE under arbitrary effect and propensity score heterogeneity": [[56, "The-Augmented-Inverse-Propensity-Weighting-Model-estimates-the-ATE-under-arbitrary-effect-and-propensity-score-heterogeneity"]], "The Data Backend: DoubleMLData": [[36, "The-Data-Backend:-DoubleMLData"], [54, "The-Data-Backend:-DoubleMLData"]], "The DoubleML package": [[36, "The-DoubleML-package"], [54, "The-DoubleML-package"]], "The Partially Linear Model performs overlap weighting": [[56, "The-Partially-Linear-Model-performs-overlap-weighting"]], "The basics of double/debiased machine learning": [[63, "the-basics-of-double-debiased-machine-learning"]], "The causal model": [[96, "the-causal-model"]], "The data-backend DoubleMLData": [[64, "the-data-backend-doublemldata"], [96, "the-data-backend-doublemldata"]], "Theory": [[84, "theory"]], "Two-Dimensional Example": [[43, "Two-Dimensional-Example"], [44, "Two-Dimensional-Example"]], "Two-Way Clustering with Respect to Product and Market": [[35, "Two-Way-Clustering-with-Respect-to-Product-and-Market"], [53, "Two-Way-Clustering-with-Respect-to-Product-and-Market"]], "Use ensemble learners based on mlr3pipelines": [[37, "Use-ensemble-learners-based-on-mlr3pipelines"]], "User guide": [[65, "user-guide"]], "Using DoubleML": [[32, "Using-DoubleML"], [41, "Using-DoubleML"]], "Using ML for DiD: Integrating DoubleML in did": [[34, "Using-ML-for-DiD:-Integrating-DoubleML-in-did"]], "Using learners from mlr3, mlr3learners and mlr3extralearners": [[37, "Using-learners-from-mlr3,-mlr3learners-and-mlr3extralearners"]], "Using pipelines to construct learners": [[67, "using-pipelines-to-construct-learners"]], "Utility classes": [[0, "utility-classes"]], "Utility classes and functions": [[0, "utility-classes-and-functions"]], "Utility functions": [[0, "utility-functions"]], "VanderWeele and Arah (2011): Benchmarking": [[60, "VanderWeele-and-Arah-(2011):-Benchmarking"]], "Variance estimation": [[83, "variance-estimation"]], "Variance estimation and confidence intervals": [[83, "variance-estimation-and-confidence-intervals"]], "Weighted Average Treatment Effects": [[66, "weighted-average-treatment-effects"]], "doubleml.DoubleMLBLP": [[1, "doubleml-doublemlblp"]], "doubleml.DoubleMLCVAR": [[2, "doubleml-doublemlcvar"]], "doubleml.DoubleMLClusterData": [[3, "doubleml-doublemlclusterdata"]], "doubleml.DoubleMLDID": [[4, "doubleml-doublemldid"]], "doubleml.DoubleMLDIDCS": [[5, "doubleml-doublemldidcs"]], "doubleml.DoubleMLData": [[6, "doubleml-doublemldata"]], "doubleml.DoubleMLIIVM": [[7, "doubleml-doublemliivm"]], "doubleml.DoubleMLIRM": [[8, "doubleml-doublemlirm"]], "doubleml.DoubleMLLPQ": [[9, "doubleml-doublemllpq"]], "doubleml.DoubleMLPLIV": [[10, "doubleml-doublemlpliv"]], "doubleml.DoubleMLPLR": [[11, "doubleml-doublemlplr"]], "doubleml.DoubleMLPQ": [[12, "doubleml-doublemlpq"]], "doubleml.DoubleMLQTE": [[13, "doubleml-doublemlqte"]], "doubleml.datasets.fetch_401K": [[14, "doubleml-datasets-fetch-401k"]], "doubleml.datasets.fetch_bonus": [[15, "doubleml-datasets-fetch-bonus"]], "doubleml.datasets.make_confounded_irm_data": [[16, "doubleml-datasets-make-confounded-irm-data"]], "doubleml.datasets.make_confounded_plr_data": [[17, "doubleml-datasets-make-confounded-plr-data"]], "doubleml.datasets.make_did_SZ2020": [[18, "doubleml-datasets-make-did-sz2020"]], "doubleml.datasets.make_heterogeneous_data": [[19, "doubleml-datasets-make-heterogeneous-data"]], "doubleml.datasets.make_iivm_data": [[20, "doubleml-datasets-make-iivm-data"]], "doubleml.datasets.make_irm_data": [[21, "doubleml-datasets-make-irm-data"]], "doubleml.datasets.make_pliv_CHS2015": [[22, "doubleml-datasets-make-pliv-chs2015"]], "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021": [[23, "doubleml-datasets-make-pliv-multiway-cluster-ckms2021"]], "doubleml.datasets.make_plr_CCDDHNR2018": [[24, "doubleml-datasets-make-plr-ccddhnr2018"]], "doubleml.datasets.make_plr_turrell2018": [[25, "doubleml-datasets-make-plr-turrell2018"]], "doubleml.datasets.make_ssm_data": [[26, "doubleml-datasets-make-ssm-data"]], "doubleml.double_ml_score_mixins.LinearScoreMixin": [[27, "doubleml-double-ml-score-mixins-linearscoremixin"]], "doubleml.double_ml_score_mixins.NonLinearScoreMixin": [[28, "doubleml-double-ml-score-mixins-nonlinearscoremixin"]], "doubleml.utils.DMLDummyClassifier": [[29, "doubleml-utils-dmldummyclassifier"]], "doubleml.utils.DMLDummyRegressor": [[30, "doubleml-utils-dmldummyregressor"]], "doubleml.utils.gain_statistics": [[31, "doubleml-utils-gain-statistics"]]}, "docnames": ["api/api", "api/generated/doubleml.DoubleMLBLP", "api/generated/doubleml.DoubleMLCVAR", "api/generated/doubleml.DoubleMLClusterData", "api/generated/doubleml.DoubleMLDID", "api/generated/doubleml.DoubleMLDIDCS", "api/generated/doubleml.DoubleMLData", "api/generated/doubleml.DoubleMLIIVM", "api/generated/doubleml.DoubleMLIRM", "api/generated/doubleml.DoubleMLLPQ", "api/generated/doubleml.DoubleMLPLIV", "api/generated/doubleml.DoubleMLPLR", "api/generated/doubleml.DoubleMLPQ", "api/generated/doubleml.DoubleMLQTE", "api/generated/doubleml.datasets.fetch_401K", "api/generated/doubleml.datasets.fetch_bonus", "api/generated/doubleml.datasets.make_confounded_irm_data", "api/generated/doubleml.datasets.make_confounded_plr_data", "api/generated/doubleml.datasets.make_did_SZ2020", "api/generated/doubleml.datasets.make_heterogeneous_data", "api/generated/doubleml.datasets.make_iivm_data", "api/generated/doubleml.datasets.make_irm_data", "api/generated/doubleml.datasets.make_pliv_CHS2015", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018", "api/generated/doubleml.datasets.make_plr_turrell2018", "api/generated/doubleml.datasets.make_ssm_data", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin", "api/generated/doubleml.utils.DMLDummyClassifier", "api/generated/doubleml.utils.DMLDummyRegressor", "api/generated/doubleml.utils.gain_statistics", "examples/R_double_ml_basic_iv", "examples/R_double_ml_basics", "examples/R_double_ml_did", "examples/R_double_ml_multiway_cluster", "examples/R_double_ml_pension", "examples/R_double_ml_pipeline", "examples/double_ml_bonus_data", "examples/index", "examples/py_double_ml_apo", "examples/py_double_ml_basic_iv", "examples/py_double_ml_basics", "examples/py_double_ml_cate", "examples/py_double_ml_cate_plr", "examples/py_double_ml_cvar", "examples/py_double_ml_did", "examples/py_double_ml_did_pretest", "examples/py_double_ml_firststage", "examples/py_double_ml_gate", "examples/py_double_ml_gate_plr", "examples/py_double_ml_gate_sensitivity", "examples/py_double_ml_learner", "examples/py_double_ml_multiway_cluster", "examples/py_double_ml_pension", "examples/py_double_ml_pension_qte", "examples/py_double_ml_plm_irm_hetfx", "examples/py_double_ml_policy_tree", "examples/py_double_ml_pq", "examples/py_double_ml_sensitivity", "examples/py_double_ml_sensitivity_booking", "examples/py_double_ml_ssm", "guide/algorithms", "guide/basics", "guide/data_backend", "guide/guide", "guide/heterogeneity", "guide/learners", "guide/models", "guide/resampling", "guide/scores", "guide/scores/apo_score", "guide/scores/cvar_score", "guide/scores/did_score", "guide/scores/didcs_score", "guide/scores/iivm_score", "guide/scores/irm_score", "guide/scores/lpq_score", "guide/scores/mar_score", "guide/scores/nr_score", "guide/scores/pliv_score", "guide/scores/plr_score", "guide/scores/pq_score", "guide/se_confint", "guide/sensitivity", "guide/sensitivity/apo_sensitivity", "guide/sensitivity/benchmarking", "guide/sensitivity/did_cs_sensitivity", "guide/sensitivity/did_sensitivity", "guide/sensitivity/implementation", "guide/sensitivity/irm_sensitivity", "guide/sensitivity/plr_sensitivity", "guide/sensitivity/theory", "guide/sim_inf", "index", "intro/install", "intro/intro", "literature/literature", "release/release", "workflow/workflow"], "envversion": {"nbsphinx": 4, "sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["api/api.rst", "api/generated/doubleml.DoubleMLBLP.rst", "api/generated/doubleml.DoubleMLCVAR.rst", "api/generated/doubleml.DoubleMLClusterData.rst", "api/generated/doubleml.DoubleMLDID.rst", "api/generated/doubleml.DoubleMLDIDCS.rst", "api/generated/doubleml.DoubleMLData.rst", "api/generated/doubleml.DoubleMLIIVM.rst", "api/generated/doubleml.DoubleMLIRM.rst", "api/generated/doubleml.DoubleMLLPQ.rst", "api/generated/doubleml.DoubleMLPLIV.rst", "api/generated/doubleml.DoubleMLPLR.rst", "api/generated/doubleml.DoubleMLPQ.rst", "api/generated/doubleml.DoubleMLQTE.rst", "api/generated/doubleml.datasets.fetch_401K.rst", "api/generated/doubleml.datasets.fetch_bonus.rst", "api/generated/doubleml.datasets.make_confounded_irm_data.rst", "api/generated/doubleml.datasets.make_confounded_plr_data.rst", "api/generated/doubleml.datasets.make_did_SZ2020.rst", "api/generated/doubleml.datasets.make_heterogeneous_data.rst", "api/generated/doubleml.datasets.make_iivm_data.rst", "api/generated/doubleml.datasets.make_irm_data.rst", "api/generated/doubleml.datasets.make_pliv_CHS2015.rst", "api/generated/doubleml.datasets.make_pliv_multiway_cluster_CKMS2021.rst", "api/generated/doubleml.datasets.make_plr_CCDDHNR2018.rst", "api/generated/doubleml.datasets.make_plr_turrell2018.rst", "api/generated/doubleml.datasets.make_ssm_data.rst", "api/generated/doubleml.double_ml_score_mixins.LinearScoreMixin.rst", "api/generated/doubleml.double_ml_score_mixins.NonLinearScoreMixin.rst", "api/generated/doubleml.utils.DMLDummyClassifier.rst", "api/generated/doubleml.utils.DMLDummyRegressor.rst", "api/generated/doubleml.utils.gain_statistics.rst", "examples/R_double_ml_basic_iv.ipynb", "examples/R_double_ml_basics.ipynb", "examples/R_double_ml_did.ipynb", "examples/R_double_ml_multiway_cluster.ipynb", "examples/R_double_ml_pension.ipynb", "examples/R_double_ml_pipeline.ipynb", "examples/double_ml_bonus_data.ipynb", "examples/index.rst", "examples/py_double_ml_apo.ipynb", "examples/py_double_ml_basic_iv.ipynb", "examples/py_double_ml_basics.ipynb", "examples/py_double_ml_cate.ipynb", "examples/py_double_ml_cate_plr.ipynb", "examples/py_double_ml_cvar.ipynb", "examples/py_double_ml_did.ipynb", "examples/py_double_ml_did_pretest.ipynb", "examples/py_double_ml_firststage.ipynb", "examples/py_double_ml_gate.ipynb", "examples/py_double_ml_gate_plr.ipynb", "examples/py_double_ml_gate_sensitivity.ipynb", "examples/py_double_ml_learner.ipynb", "examples/py_double_ml_multiway_cluster.ipynb", "examples/py_double_ml_pension.ipynb", "examples/py_double_ml_pension_qte.ipynb", "examples/py_double_ml_plm_irm_hetfx.ipynb", "examples/py_double_ml_policy_tree.ipynb", "examples/py_double_ml_pq.ipynb", "examples/py_double_ml_sensitivity.ipynb", "examples/py_double_ml_sensitivity_booking.ipynb", "examples/py_double_ml_ssm.ipynb", "guide/algorithms.rst", "guide/basics.rst", "guide/data_backend.rst", "guide/guide.rst", "guide/heterogeneity.rst", "guide/learners.rst", "guide/models.rst", "guide/resampling.rst", "guide/scores.rst", "guide/scores/apo_score.rst", "guide/scores/cvar_score.rst", "guide/scores/did_score.rst", "guide/scores/didcs_score.rst", "guide/scores/iivm_score.rst", "guide/scores/irm_score.rst", "guide/scores/lpq_score.rst", "guide/scores/mar_score.rst", "guide/scores/nr_score.rst", "guide/scores/pliv_score.rst", "guide/scores/plr_score.rst", "guide/scores/pq_score.rst", "guide/se_confint.rst", "guide/sensitivity.rst", "guide/sensitivity/apo_sensitivity.rst", "guide/sensitivity/benchmarking.rst", "guide/sensitivity/did_cs_sensitivity.rst", "guide/sensitivity/did_sensitivity.rst", "guide/sensitivity/implementation.rst", "guide/sensitivity/irm_sensitivity.rst", "guide/sensitivity/plr_sensitivity.rst", "guide/sensitivity/theory.rst", "guide/sim_inf.rst", "index.rst", "intro/install.rst", "intro/intro.rst", "literature/literature.rst", "release/release.rst", "workflow/workflow.rst"], "indexentries": {"bootstrap() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.bootstrap", false]], "bootstrap() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.bootstrap", false]], "bootstrap() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.bootstrap", false]], "bootstrap() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.bootstrap", false]], "bootstrap() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.bootstrap", false]], "bootstrap() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.bootstrap", false]], "bootstrap() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.bootstrap", false]], "bootstrap() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.bootstrap", false]], "bootstrap() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.bootstrap", false]], "bootstrap() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.bootstrap", false]], "cate() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.cate", false]], "cate() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.cate", false]], "confint() (doubleml.doublemlblp method)": [[1, "doubleml.DoubleMLBLP.confint", false]], "confint() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.confint", false]], "confint() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.confint", false]], "confint() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.confint", false]], "confint() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.confint", false]], "confint() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.confint", false]], "confint() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.confint", false]], "confint() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.confint", false]], "confint() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.confint", false]], "confint() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.confint", false]], "confint() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.confint", false]], "construct_framework() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.construct_framework", false]], "construct_framework() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.construct_framework", false]], "construct_framework() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.construct_framework", false]], "construct_framework() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.construct_framework", false]], "construct_framework() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.construct_framework", false]], "construct_framework() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.construct_framework", false]], "construct_framework() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.construct_framework", false]], "construct_framework() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.construct_framework", false]], "construct_framework() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.construct_framework", false]], "dmldummyclassifier (class in doubleml.utils)": [[29, "doubleml.utils.DMLDummyClassifier", false]], "dmldummyregressor (class in doubleml.utils)": [[30, "doubleml.utils.DMLDummyRegressor", false]], "doublemlblp (class in doubleml)": [[1, "doubleml.DoubleMLBLP", false]], "doublemlclusterdata (class in doubleml)": [[3, "doubleml.DoubleMLClusterData", false]], "doublemlcvar (class in doubleml)": [[2, "doubleml.DoubleMLCVAR", false]], "doublemldata (class in doubleml)": [[6, "doubleml.DoubleMLData", false]], "doublemldid (class in doubleml)": [[4, "doubleml.DoubleMLDID", false]], "doublemldidcs (class in doubleml)": [[5, "doubleml.DoubleMLDIDCS", false]], "doublemliivm (class in doubleml)": [[7, "doubleml.DoubleMLIIVM", false]], "doublemlirm (class in doubleml)": [[8, "doubleml.DoubleMLIRM", false]], "doublemllpq (class in doubleml)": [[9, "doubleml.DoubleMLLPQ", false]], "doublemlpliv (class in doubleml)": [[10, "doubleml.DoubleMLPLIV", false]], "doublemlplr (class in doubleml)": [[11, "doubleml.DoubleMLPLR", false]], "doublemlpq (class in doubleml)": [[12, "doubleml.DoubleMLPQ", false]], "doublemlqte (class in doubleml)": [[13, "doubleml.DoubleMLQTE", false]], "draw_sample_splitting() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.draw_sample_splitting", false]], "draw_sample_splitting() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.draw_sample_splitting", false]], "evaluate_learners() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.evaluate_learners", false]], "evaluate_learners() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.evaluate_learners", false]], "fetch_401k() (in module doubleml.datasets)": [[14, "doubleml.datasets.fetch_401K", false]], "fetch_bonus() (in module doubleml.datasets)": [[15, "doubleml.datasets.fetch_bonus", false]], "fit() (doubleml.doublemlblp method)": [[1, "doubleml.DoubleMLBLP.fit", false]], "fit() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.fit", false]], "fit() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.fit", false]], "fit() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.fit", false]], "fit() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.fit", false]], "fit() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.fit", false]], "fit() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.fit", false]], "fit() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.fit", false]], "fit() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.fit", false]], "fit() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.fit", false]], "fit() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.fit", false]], "fit() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.fit", false]], "fit() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.fit", false]], "from_arrays() (doubleml.doublemlclusterdata class method)": [[3, "doubleml.DoubleMLClusterData.from_arrays", false]], "from_arrays() (doubleml.doublemldata class method)": [[6, "doubleml.DoubleMLData.from_arrays", false]], "gain_statistics() (in module doubleml.utils)": [[31, "doubleml.utils.gain_statistics", false]], "gate() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.gate", false]], "gate() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.gate", false]], "get_metadata_routing() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.get_metadata_routing", false]], "get_metadata_routing() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.get_metadata_routing", false]], "get_params() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.get_params", false]], "get_params() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.get_params", false]], "get_params() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.get_params", false]], "get_params() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.get_params", false]], "get_params() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.get_params", false]], "get_params() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.get_params", false]], "get_params() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.get_params", false]], "get_params() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.get_params", false]], "get_params() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.get_params", false]], "get_params() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.get_params", false]], "get_params() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.get_params", false]], "linearscoremixin (class in doubleml.double_ml_score_mixins)": [[27, "doubleml.double_ml_score_mixins.LinearScoreMixin", false]], "make_confounded_irm_data() (in module doubleml.datasets)": [[16, "doubleml.datasets.make_confounded_irm_data", false]], "make_confounded_plr_data() (in module doubleml.datasets)": [[17, "doubleml.datasets.make_confounded_plr_data", false]], "make_did_sz2020() (in module doubleml.datasets)": [[18, "doubleml.datasets.make_did_SZ2020", false]], "make_heterogeneous_data() (in module doubleml.datasets)": [[19, "doubleml.datasets.make_heterogeneous_data", false]], "make_iivm_data() (in module doubleml.datasets)": [[20, "doubleml.datasets.make_iivm_data", false]], "make_irm_data() (in module doubleml.datasets)": [[21, "doubleml.datasets.make_irm_data", false]], "make_pliv_chs2015() (in module doubleml.datasets)": [[22, "doubleml.datasets.make_pliv_CHS2015", false]], "make_pliv_multiway_cluster_ckms2021() (in module doubleml.datasets)": [[23, "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", false]], "make_plr_ccddhnr2018() (in module doubleml.datasets)": [[24, "doubleml.datasets.make_plr_CCDDHNR2018", false]], "make_plr_turrell2018() (in module doubleml.datasets)": [[25, "doubleml.datasets.make_plr_turrell2018", false]], "make_ssm_data() (in module doubleml.datasets)": [[26, "doubleml.datasets.make_ssm_data", false]], "nonlinearscoremixin (class in doubleml.double_ml_score_mixins)": [[28, "doubleml.double_ml_score_mixins.NonLinearScoreMixin", false]], "p_adjust() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.p_adjust", false]], "p_adjust() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.p_adjust", false]], "p_adjust() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.p_adjust", false]], "p_adjust() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.p_adjust", false]], "p_adjust() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.p_adjust", false]], "p_adjust() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.p_adjust", false]], "p_adjust() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.p_adjust", false]], "p_adjust() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.p_adjust", false]], "p_adjust() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.p_adjust", false]], "p_adjust() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.p_adjust", false]], "policy_tree() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.policy_tree", false]], "predict() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.predict", false]], "predict() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.predict", false]], "predict_proba() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.predict_proba", false]], "sensitivity_analysis() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.sensitivity_analysis", false]], "sensitivity_analysis() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.sensitivity_analysis", false]], "sensitivity_benchmark() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.sensitivity_benchmark", false]], "sensitivity_benchmark() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.sensitivity_benchmark", false]], "sensitivity_plot() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.sensitivity_plot", false]], "sensitivity_plot() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.sensitivity_plot", false]], "set_ml_nuisance_params() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.set_ml_nuisance_params", false]], "set_ml_nuisance_params() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.set_ml_nuisance_params", false]], "set_params() (doubleml.utils.dmldummyclassifier method)": [[29, "doubleml.utils.DMLDummyClassifier.set_params", false]], "set_params() (doubleml.utils.dmldummyregressor method)": [[30, "doubleml.utils.DMLDummyRegressor.set_params", false]], "set_sample_splitting() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.set_sample_splitting", false]], "set_sample_splitting() (doubleml.doublemlqte method)": [[13, "doubleml.DoubleMLQTE.set_sample_splitting", false]], "set_x_d() (doubleml.doublemlclusterdata method)": [[3, "doubleml.DoubleMLClusterData.set_x_d", false]], "set_x_d() (doubleml.doublemldata method)": [[6, "doubleml.DoubleMLData.set_x_d", false]], "tune() (doubleml.doublemlcvar method)": [[2, "doubleml.DoubleMLCVAR.tune", false]], "tune() (doubleml.doublemldid method)": [[4, "doubleml.DoubleMLDID.tune", false]], "tune() (doubleml.doublemldidcs method)": [[5, "doubleml.DoubleMLDIDCS.tune", false]], "tune() (doubleml.doublemliivm method)": [[7, "doubleml.DoubleMLIIVM.tune", false]], "tune() (doubleml.doublemlirm method)": [[8, "doubleml.DoubleMLIRM.tune", false]], "tune() (doubleml.doublemllpq method)": [[9, "doubleml.DoubleMLLPQ.tune", false]], "tune() (doubleml.doublemlpliv method)": [[10, "doubleml.DoubleMLPLIV.tune", false]], "tune() (doubleml.doublemlplr method)": [[11, "doubleml.DoubleMLPLR.tune", false]], "tune() (doubleml.doublemlpq method)": [[12, "doubleml.DoubleMLPQ.tune", false]]}, "objects": {"doubleml": [[1, 0, 1, "", "DoubleMLBLP"], [2, 0, 1, "", "DoubleMLCVAR"], [3, 0, 1, "", "DoubleMLClusterData"], [4, 0, 1, "", "DoubleMLDID"], [5, 0, 1, "", "DoubleMLDIDCS"], [6, 0, 1, "", "DoubleMLData"], [7, 0, 1, "", "DoubleMLIIVM"], [8, 0, 1, "", "DoubleMLIRM"], [9, 0, 1, "", "DoubleMLLPQ"], [10, 0, 1, "", "DoubleMLPLIV"], [11, 0, 1, "", "DoubleMLPLR"], [12, 0, 1, "", "DoubleMLPQ"], [13, 0, 1, "", "DoubleMLQTE"]], "doubleml.DoubleMLBLP": [[1, 1, 1, "", "confint"], [1, 1, 1, "", "fit"]], "doubleml.DoubleMLCVAR": [[2, 1, 1, "", "bootstrap"], [2, 1, 1, "", "confint"], [2, 1, 1, "", "construct_framework"], [2, 1, 1, "", "draw_sample_splitting"], [2, 1, 1, "", "evaluate_learners"], [2, 1, 1, "", "fit"], [2, 1, 1, "", "get_params"], [2, 1, 1, "", "p_adjust"], [2, 1, 1, "", "sensitivity_analysis"], [2, 1, 1, "", "sensitivity_benchmark"], [2, 1, 1, "", "sensitivity_plot"], [2, 1, 1, "", "set_ml_nuisance_params"], [2, 1, 1, "", "set_sample_splitting"], [2, 1, 1, "", "tune"]], "doubleml.DoubleMLClusterData": [[3, 1, 1, "", "from_arrays"], [3, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLDID": [[4, 1, 1, "", "bootstrap"], [4, 1, 1, "", "confint"], [4, 1, 1, "", "construct_framework"], [4, 1, 1, "", "draw_sample_splitting"], [4, 1, 1, "", "evaluate_learners"], [4, 1, 1, "", "fit"], [4, 1, 1, "", "get_params"], [4, 1, 1, "", "p_adjust"], [4, 1, 1, "", "sensitivity_analysis"], [4, 1, 1, "", "sensitivity_benchmark"], [4, 1, 1, "", "sensitivity_plot"], [4, 1, 1, "", "set_ml_nuisance_params"], [4, 1, 1, "", "set_sample_splitting"], [4, 1, 1, "", "tune"]], "doubleml.DoubleMLDIDCS": [[5, 1, 1, "", "bootstrap"], [5, 1, 1, "", "confint"], [5, 1, 1, "", "construct_framework"], [5, 1, 1, "", "draw_sample_splitting"], [5, 1, 1, "", "evaluate_learners"], [5, 1, 1, "", "fit"], [5, 1, 1, "", "get_params"], [5, 1, 1, "", "p_adjust"], [5, 1, 1, "", "sensitivity_analysis"], [5, 1, 1, "", "sensitivity_benchmark"], [5, 1, 1, "", "sensitivity_plot"], [5, 1, 1, "", "set_ml_nuisance_params"], [5, 1, 1, "", "set_sample_splitting"], [5, 1, 1, "", "tune"]], "doubleml.DoubleMLData": [[6, 1, 1, "", "from_arrays"], [6, 1, 1, "", "set_x_d"]], "doubleml.DoubleMLIIVM": [[7, 1, 1, "", "bootstrap"], [7, 1, 1, "", "confint"], [7, 1, 1, "", "construct_framework"], [7, 1, 1, "", "draw_sample_splitting"], [7, 1, 1, "", "evaluate_learners"], [7, 1, 1, "", "fit"], [7, 1, 1, "", "get_params"], [7, 1, 1, "", "p_adjust"], [7, 1, 1, "", "sensitivity_analysis"], [7, 1, 1, "", "sensitivity_benchmark"], [7, 1, 1, "", "sensitivity_plot"], [7, 1, 1, "", "set_ml_nuisance_params"], [7, 1, 1, "", "set_sample_splitting"], [7, 1, 1, "", "tune"]], "doubleml.DoubleMLIRM": [[8, 1, 1, "", "bootstrap"], [8, 1, 1, "", "cate"], [8, 1, 1, "", "confint"], [8, 1, 1, "", "construct_framework"], [8, 1, 1, "", "draw_sample_splitting"], [8, 1, 1, "", "evaluate_learners"], [8, 1, 1, "", "fit"], [8, 1, 1, "", "gate"], [8, 1, 1, "", "get_params"], [8, 1, 1, "", "p_adjust"], [8, 1, 1, "", "policy_tree"], [8, 1, 1, "", "sensitivity_analysis"], [8, 1, 1, "", "sensitivity_benchmark"], [8, 1, 1, "", "sensitivity_plot"], [8, 1, 1, "", "set_ml_nuisance_params"], [8, 1, 1, "", "set_sample_splitting"], [8, 1, 1, "", "tune"]], "doubleml.DoubleMLLPQ": [[9, 1, 1, "", "bootstrap"], [9, 1, 1, "", "confint"], [9, 1, 1, "", "construct_framework"], [9, 1, 1, "", "draw_sample_splitting"], [9, 1, 1, "", "evaluate_learners"], [9, 1, 1, "", "fit"], [9, 1, 1, "", "get_params"], [9, 1, 1, "", "p_adjust"], [9, 1, 1, "", "sensitivity_analysis"], [9, 1, 1, "", "sensitivity_benchmark"], [9, 1, 1, "", "sensitivity_plot"], [9, 1, 1, "", "set_ml_nuisance_params"], [9, 1, 1, "", "set_sample_splitting"], [9, 1, 1, "", "tune"]], "doubleml.DoubleMLPLIV": [[10, 1, 1, "", "bootstrap"], [10, 1, 1, "", "confint"], [10, 1, 1, "", "construct_framework"], [10, 1, 1, "", "draw_sample_splitting"], [10, 1, 1, "", "evaluate_learners"], [10, 1, 1, "", "fit"], [10, 1, 1, "", "get_params"], [10, 1, 1, "", "p_adjust"], [10, 1, 1, "", "sensitivity_analysis"], [10, 1, 1, "", "sensitivity_benchmark"], [10, 1, 1, "", "sensitivity_plot"], [10, 1, 1, "", "set_ml_nuisance_params"], [10, 1, 1, "", "set_sample_splitting"], [10, 1, 1, "", "tune"]], "doubleml.DoubleMLPLR": [[11, 1, 1, "", "bootstrap"], [11, 1, 1, "", "cate"], [11, 1, 1, "", "confint"], [11, 1, 1, "", "construct_framework"], [11, 1, 1, "", "draw_sample_splitting"], [11, 1, 1, "", "evaluate_learners"], [11, 1, 1, "", "fit"], [11, 1, 1, "", "gate"], [11, 1, 1, "", "get_params"], [11, 1, 1, "", "p_adjust"], [11, 1, 1, "", "sensitivity_analysis"], [11, 1, 1, "", "sensitivity_benchmark"], [11, 1, 1, "", "sensitivity_plot"], [11, 1, 1, "", "set_ml_nuisance_params"], [11, 1, 1, "", "set_sample_splitting"], [11, 1, 1, "", "tune"]], "doubleml.DoubleMLPQ": [[12, 1, 1, "", "bootstrap"], [12, 1, 1, "", "confint"], [12, 1, 1, "", "construct_framework"], [12, 1, 1, "", "draw_sample_splitting"], [12, 1, 1, "", "evaluate_learners"], [12, 1, 1, "", "fit"], [12, 1, 1, "", "get_params"], [12, 1, 1, "", "p_adjust"], [12, 1, 1, "", "sensitivity_analysis"], [12, 1, 1, "", "sensitivity_benchmark"], [12, 1, 1, "", "sensitivity_plot"], [12, 1, 1, "", "set_ml_nuisance_params"], [12, 1, 1, "", "set_sample_splitting"], [12, 1, 1, "", "tune"]], "doubleml.DoubleMLQTE": [[13, 1, 1, "", "bootstrap"], [13, 1, 1, "", "confint"], [13, 1, 1, "", "draw_sample_splitting"], [13, 1, 1, "", "fit"], [13, 1, 1, "", "p_adjust"], [13, 1, 1, "", "set_sample_splitting"]], "doubleml.datasets": [[14, 2, 1, "", "fetch_401K"], [15, 2, 1, "", "fetch_bonus"], [16, 2, 1, "", "make_confounded_irm_data"], [17, 2, 1, "", "make_confounded_plr_data"], [18, 2, 1, "", "make_did_SZ2020"], [19, 2, 1, "", "make_heterogeneous_data"], [20, 2, 1, "", "make_iivm_data"], [21, 2, 1, "", "make_irm_data"], [22, 2, 1, "", "make_pliv_CHS2015"], [23, 2, 1, "", "make_pliv_multiway_cluster_CKMS2021"], [24, 2, 1, "", "make_plr_CCDDHNR2018"], [25, 2, 1, "", "make_plr_turrell2018"], [26, 2, 1, "", "make_ssm_data"]], "doubleml.double_ml_score_mixins": [[27, 0, 1, "", "LinearScoreMixin"], [28, 0, 1, "", "NonLinearScoreMixin"]], "doubleml.utils": [[29, 0, 1, "", "DMLDummyClassifier"], [30, 0, 1, "", "DMLDummyRegressor"], [31, 2, 1, "", "gain_statistics"]], "doubleml.utils.DMLDummyClassifier": [[29, 1, 1, "", "fit"], [29, 1, 1, "", "get_metadata_routing"], [29, 1, 1, "", "get_params"], [29, 1, 1, "", "predict"], [29, 1, 1, "", "predict_proba"], [29, 1, 1, "", "set_params"]], "doubleml.utils.DMLDummyRegressor": [[30, 1, 1, "", "fit"], [30, 1, 1, "", "get_metadata_routing"], [30, 1, 1, "", "get_params"], [30, 1, 1, "", "predict"], [30, 1, 1, "", "set_params"]]}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function"}, "terms": {"": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 20, 21, 22, 23, 24, 25, 26, 32, 34, 35, 36, 37, 38, 40, 46, 49, 50, 51, 53, 54, 55, 59, 60, 61, 62, 64, 67, 68, 70, 78, 79, 83, 84, 86, 93, 94, 96, 97, 98, 99], "0": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 86, 87, 88, 89, 90, 93, 95, 96, 98], "00": [54, 55, 69], "000": [83, 93, 99], "000000": [38, 40, 54, 55, 64, 66, 96], "0000000": [83, 93], "0000000000000010000100": [37, 64, 96], "000000e": [54, 55], "00000591": 58, "000006": [40, 58], "000017": 58, "000025": 53, "000034": 54, "000039": 53, "000064": 41, "000067": 53, "000091": [53, 66], "0001": [38, 54], "000135": 68, "000219": [12, 66], "000242": [13, 66], "000341": 53, "000442": 53, "00047580260495": 32, "000488": 53, "000494": 51, "0005": 38, "000522": 53, "0005a80b528f": 37, "000670": 53, "000743": 59, "000784623154372457": 62, "0007846231543724570": 62, "0007846232": 62, "000915799": [83, 93], "0009157990": [83, 93], "000943": [43, 44], "0009695237": 70, "001": [32, 34, 35, 36, 37, 42, 56, 67, 68, 69, 70, 83, 96, 99], "001051": 53, "0011963": 69, "001234": 55, "00133": 37, "00138944": [62, 70], "001494": 68, "0016": [36, 54], "001714": 66, "0018": [36, 54], "0019": 38, "002110": 44, "002169338": [83, 93], "0021693380": [83, 93], "0021693381": [83, 93], "002290": 47, "0023": 34, "002436": 51, "002539": 68, "0026": 38, "002779": 59, "0028": [34, 36, 54], "002821": 60, "0028213335041910427": 60, "002983": 53, "003": [16, 17, 18], "003111": 40, "003134": 58, "003220": 40, "003328": 58, "0034": 48, "003404": 40, "003415": 40, "003427": 53, "003779": 51, "003836": 58, "003924": 51, "003965": 43, "00409412": [62, 70], "0042": [36, 54], "004253": 40, "004392": 51, "00444": 69, "004526": 40, "004645": 44, "004688": 7, "0047": [36, 54], "004846": 60, "005339": [43, 44], "005387943": 69, "005857": 53, "006055": 40, "006066": 43, "006425": 55, "006922": 38, "006958": [43, 44], "007210e": 55, "00728": 96, "0073": 38, "007332": 45, "007332393760465": 45, "007659": 66, "00778625": 69, "007909": 43, "008": 60, "008023": 55, "008223": [43, 44], "008266e": 55, "008487": 38, "008642": 66, "008732851": 69, "008dbd": 56, "008e80": 56, "009": [56, 60], "0090193584": 70, "00902031947837708": 62, "0090203195": 62, "009122": 58, "009428": 45, "00944171905420782": 60, "009645422": 35, "009656": 58, "00972": 38, "009781": 56, "009790": 55, "009904": 66, "009986": 58, "01": [2, 4, 5, 7, 8, 9, 12, 13, 32, 35, 36, 37, 43, 44, 54, 55, 56, 57, 58, 67, 68, 69, 70, 83, 96, 99], "010": 32, "010117": 56, "010213": 59, "010269": 53, "010450": 35, "010940": 53, "011131": 58, "0112": 34, "01128": 38, "011511": 44, "011598": 58, "0118095": 35, "011815": 56, "011823": 59, "011988e": 58, "01219": 37, "01274": 60, "012780": 55, "012831": 60, "013": 56, "013034": 60, "013129": 56, "013469": 43, "01351638": 35, "013593": 59, "013617": 55, "01398951": 35, "013990": [83, 93], "01403089": 35, "014080": [43, 44], "014432": 47, "014637": 53, "014681": 59, "015": [37, 56], "015035": 43, "015038": 45, "015548": 44, "015565": 58, "015698": 58, "01574297": 58, "015743": 58, "015831": 43, "016011": 44, "016154": 53, "016200": [43, 44], "016315": 49, "016429": 66, "01643": 97, "017": 37, "01772": 86, "017800092": [83, 93], "0178000920": [83, 93], "017805": 43, "018": 37, "018023": 57, "018099": 43, "018148": 58, "018508": 43, "018602": 68, "019008": 44, "01903": [37, 67, 94, 96], "01916030e": 69, "01925597": 35, "019439633": [83, 93], "0194396330": [83, 93], "0194396331": [83, 93], "019596": 45, "019660": [13, 66], "01990373": 61, "019953": 43, "019974": 55, "02": [43, 44, 54, 55, 58, 66, 69], "02016117": 96, "020166": 58, "020271": 53, "020360838": [83, 93], "0203608380": [83, 93], "0203608381": [83, 93], "020387": 44, "02052929": [62, 70], "02079162e": 69, "020819": 66, "02092": 96, "021013": 43, "021269": [49, 50], "02163217": 35, "021866": 57, "021926": 45, "02247976": 35, "022768": 38, "022783": 59, "022915": 53, "022954": 66, "022969": 55, "022991": 44, "023020e": [54, 55], "023160": 43, "023256": 58, "023505": 43, "023563": [83, 93], "023955": 55, "024355": 47, "024364": 84, "024401": [49, 50], "024604": 53, "024782": 58, "024926": 47, "025": [43, 44, 49, 50, 56], "025077": [83, 93], "02528067": 52, "0253": 37, "025443": 38, "0257": 34, "025708e": 44, "025783e": 44, "025813114": [83, 93], "0258131140": [83, 93], "02584": 37, "025958": 66, "026518e": 43, "026669": 55, "026723": 45, "02672945": 69, "027329": 43, "02791": 38, "028001": 44, "0281": 37, "028520": [43, 44], "02897287": 46, "02900983": 58, "029010": 58, "029022": 44, "029209": 99, "029364": [84, 89], "029445": 56, "029831": 58, "029910e": [54, 55], "02e": 36, "03": [2, 4, 5, 7, 8, 9, 10, 11, 12, 40, 43, 44, 45, 51, 54, 55, 58, 59, 60, 69, 84, 89, 99], "030087": 66, "0301": 37, "03018": [9, 66], "030346": 96, "0307": 37, "030934": 58, "030962": 58, "03113": 61, "031134": 67, "031156": 44, "031269": 38, "031639": 58, "031820": 44, "03191": 97, "03220": 98, "0323": 34, "03244552": 67, "0325": 96, "032856": 56, "032953": 59, "033224": 43, "033737": 44, "033756": 45, "033946": [49, 50], "034097": 43, "03411": 96, "034226": 55, "034690": 45, "034812763": [83, 93], "0348127630": [83, 93], "0348127631": [83, 93], "034836": 54, "03489": [23, 35, 53], "034951": 56, "035088": 44, "035119185": [83, 93], "0351191850": [83, 93], "0351191851": [83, 93], "035264": 44, "03536": 96, "03538": 37, "03539": 37, "035391": 38, "0354": 37, "035411": 96, "035441": 44, "03545": 37, "035545": 38, "035572": 38, "035730": 58, "03574": 38, "035762": 58, "0359": 37, "036129015": [83, 93], "0361290150": [83, 93], "0361290151": [83, 93], "036143": 58, "036147": 58, "036240": 40, "036729": 53, "0368": 34, "036874e": 44, "036945": 55, "03698487": 58, "036985": 58, "037008": [49, 50], "0374": 37, "037509": 61, "037747": [43, 44], "03790021": 69, "038845": 43, "039036": 43, "039141": 40, "03917696": [70, 83], "03920960e": 69, "039310e": 45, "039660": 43, "039897": 44, "04": [17, 36, 40, 43, 44, 54, 55, 58, 59, 69, 99], "040112": [83, 93], "040139": [43, 44], "040141": 44, "040445": 43, "040533": [70, 83], "04053339": 83, "040688": 43, "0408": 43, "040912": 44, "040919": 44, "04107": 11, "041112": 44, "041147": 45, "041284": 45, "041373": 56, "041387": 45, "041459": 55, "041491e": 45, "04166": 68, "0418": 34, "041831": 45, "041925": 43, "042034": 60, "042249": 44, "042265": 45, "042266": 43, "0425": 67, "0428": 61, "042822e": 55, "042844e": 58, "043108": 55, "0433": 34, "0434e374": 37, "043998": 44, "044": 56, "044062": 44, "044113": 45, "04415": [37, 67], "04424": 37, "044334": 43, "04444978": [83, 93], "044449780": [83, 93], "04458": 67, "04465": 35, "044704": 44, "04486": 96, "04487585": [84, 89], "04491": 68, "04497975": [84, 89], "045": 56, "04512": [70, 83], "04512331": 83, "045144": 53, "04532": 67, "045379": 96, "04552": 53, "045553": 45, "04559": 67, "045624": 47, "045754": 58, "0459": 67, "045932": 58, "045993": 67, "046": 56, "04631": 67, "046405": 66, "046527": 45, "04653976": 58, "046540": 58, "0466028": 35, "046728": 59, "046757": 44, "04682310e": 69, "046922": 67, "047156": 43, "047194": 7, "047215": 44, "047375e": 43, "047954": 53, "048308": 50, "048326": 44, "048699": 61, "048723": 67, "04973": 44, "049959": 43, "05": [32, 34, 35, 36, 37, 43, 44, 45, 48, 52, 53, 54, 55, 56, 58, 60, 67, 68, 69, 70, 83, 96, 99], "05039": 59, "050399": 44, "050538": 44, "050843": 44, "050856": [66, 67], "051": 37, "051578e": 44, "051867e": 45, "052000e": 55, "052127": 56, "052298": 58, "052380": 43, "052488": 50, "052502": 58, "052745": 45, "053": 37, "0533": 34, "053331": 45, "053342": 55, "053389": [83, 93], "053436": 8, "053541": 58, "053558": 45, "054": 37, "054068": 53, "054162": 53, "054348": 83, "054370": 45, "054529": [83, 93], "054771e": 58, "055078": 43, "055165": 59, "055171": 44, "055338e": 54, "055439": 55, "055493": 60, "055680": [83, 93], "056052": 43, "056389": 44, "056499": 50, "056745": 43, "056953": 43, "057": 56, "057095": 58, "057274": 40, "0573614": 69, "0576": [36, 54], "057762": 58, "057962": 45, "058042": [83, 93], "058276": 55, "058463": 58, "058508": 61, "0590": 34, "059187": 44, "059384": 58, "059627": 55, "059630": 47, "059685": 58, "06": [16, 17, 18, 40, 43, 44, 45, 54, 55, 58, 66, 69, 70, 83], "06008533": 68, "060201": 58, "060212": [54, 55], "060417": 43, "060581": 52, "060845": [83, 93], "0611": 34, "06111111": 37, "0615": 34, "062414": 55, "062507": 58, "0628": 34, "062964": [83, 93], "063017": 40, "0632": 34, "0635": 34, "0636": 34, "063618": 44, "063685": 40, "063700": 43, "063768": 56, "0638": 34, "063881": 68, "0640": 34, "064161": 55, "064175": 40, "06428": 54, "064280": 54, "064400": 43, "0645": 34, "0646222": 36, "06464": 83, "0647": 34, "0649": 34, "065": 60, "065128": 43, "0653": 34, "065356": [49, 50], "0654": 34, "065451": 55, "0655": 34, "065725": 45, "0659": 34, "065969": 68, "0662": 34, "066464": 59, "066689e": 44, "066889": 58, "0669": 34, "06692492": 69, "06694255": 68, "0671": 34, "067240": 58, "06724028": 58, "0673": 34, "0675": 34, "067528": 60, "067721": [83, 93], "068073": 44, "06827": 59, "06834315": 46, "068377": 55, "068514": 43, "068934": 40, "06895837": 35, "069443": 40, "0695854": 35, "069600": 55, "07": [43, 44, 55, 58, 60, 69], "070020": 58, "070196": 45, "0701961897676835": 45, "0702127": 35, "0704": 34, "070497": 60, "070552": 43, "070574e": 55, "0707": 34, "070751": 43, "07085301": 68, "070884": 58, "0711": 34, "071285": 83, "07136": [35, 53], "071488e": 45, "0716": 34, "07168291": 35, "071777": 67, "071782": [13, 66], "0719": 34, "07202564": [49, 50], "072058": 43, "07222222": 37, "072293": 57, "072852": 43, "073": [56, 68], "073013": 58, "073207": 53, "073352": 43, "07347676": 35, "07350015": [23, 26, 35, 53], "073520": 45, "0736": 34, "07366": [37, 67], "073694": 44, "0743": 34, "074304": 83, "07436521": 69, "074426": 58, "07456127": 35, "074617": 44, "07479278": 59, "074927": 40, "075261": 47, "075384": 58, "07538443": 58, "07544271e": 69, "07561": 96, "07564554e": 69, "0758": 60, "075809": 40, "075869": 67, "076019": 54, "076156": 83, "076179312": [83, 93], "0761793120": [83, 93], "076322": 58, "076347": 45, "0765": 37, "076559": [66, 67], "076596": 43, "076684": 96, "07685043": 69, "07689": 37, "07691847": 69, "076953": [49, 50], "076971": 38, "077161": 55, "07727773e": 69, "077319": 58, "077502": [84, 89], "077702": 40, "0777777777777778": 67, "07777778": [37, 67], "077840": 55, "07786": 68, "077883": 58, "078096": 83, "078207": 38, "07828372": [83, 93], "078474": [83, 93], "078810": 58, "079085": 38, "07915": 37, "07919896": 69, "079458e": 54, "07961": 59, "07978296": 69, "08": [43, 44, 45, 55, 58, 60, 68], "080": 56, "08005229": 69, "08016873": 69, "08031571": 69, "080351": 44, "080854": 55, "080900": 43, "08091581": 69, "080947": 38, "081": 37, "081100": 58, "081230": [43, 44], "08134429": 69, "081488": 53, "08154161": 69, "08181827e": 69, "08191204": 68, "0820": 34, "082263": 10, "082297": 69, "082574": 8, "082804": 47, "082858": 44, "082934": 55, "082973": 53, "083258": [83, 93], "083318": 83, "08333333": 37, "08333617": 69, "0835771416": 35, "083706": 60, "083750": 55, "083949": 60, "084": 35, "084156": 44, "084184": 45, "0841842065698133": 45, "084212": 51, "084269": 55, "084337": 68, "084633": 49, "084771": 43, "0853505": 35, "085395": 43, "085566": 45, "085671": 43, "085965": 55, "08602774e": 69, "086109": 44, "0862": 94, "086264": 45, "086464": 43, "08664208": 69, "086679": 67, "086889": 49, "0872": 34, "087491e": 44, "087561": 43, "087634": 43, "087947": 58, "088048": 58, "088282": 50, "088357": 58, "08848": 67, "088482": [13, 66], "088504e": 10, "088696e": 44, "08888889": 37, "089064e": 43, "0894": 34, "08949063": 69, "089661": 50, "08968939": 35, "089825": 44, "08e": 36, "09": [43, 45, 54, 55, 58, 66], "09000000000000001": 67, "090025": 55, "09015": 34, "090255": 58, "091046": 50, "091391": [83, 93], "091406": 84, "091535": 43, "0916": 34, "091611": 44, "091992": 57, "092229": 60, "092247": 58, "092263": 68, "092365": [83, 93], "0923935": 69, "0927470": 69, "092919": 86, "093043": 58, "09310496": [83, 93], "093153": 58, "093474": 58, "09347419": 58, "093746": 83, "093950": 53, "094026": 53, "094118": 58, "094381": 53, "09444444": 37, "094829": 68, "094999": 58, "095104": 40, "095475": 66, "095781": 2, "095785": 40, "095835": 44, "09603": 94, "096245": 66, "096337": 53, "096418": 40, "096550": 49, "096616": 66, "096741": 46, "09682314": 68, "096915": 60, "096934": 44, "097157": 60, "097468": 45, "09779675": [83, 93], "097796750": [83, 93], "098": 36, "098256": 58, "09830758": 59, "098308": 59, "098317": 55, "098319": 58, "0986": 34, "0986187": 69, "098712": 58, "09879814e": 69, "09914283": 69, "099347": 56, "099647": 57, "099670": 55, "099731": [43, 44], "09980311": [83, 93], "09988": 97, "0_": 22, "0ff823b17d45": 37, "0x1747bdd4520": 38, "0x1747bdd6b90": 38, "0x2920d7b7150": 57, "0x7f4babc5f250": 67, "0x7f4bb9c57820": 99, "0x7f4bb9cca520": 84, "0x7f4bc3cad5b0": 89, "0x7f4bc3d123a0": 68, "0x7f4bc3e61820": 83, "0x7f4bcc67bf70": 83, "0x7f4bcc6ad400": 83, "0x7f4bcc6ad7f0": 83, "0x7f4bcc7c7a30": 67, "0x7f4bcc7c9280": 67, "0x7f4bcc7d8970": 68, "0x7f5e812758e0": 60, "1": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98], "10": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 23, 24, 26, 32, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 94, 96, 97, 99], "100": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 23, 25, 26, 35, 37, 42, 43, 44, 46, 48, 51, 52, 53, 56, 60, 61, 62, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 96, 98], "1000": [7, 9, 33, 41, 42, 46, 47, 49, 50, 51, 52, 54, 55, 59, 60, 63, 66, 68], "10000": [32, 43, 44, 47, 54, 55, 58], "100000e": 55, "100356": 45, "10038": 59, "10039862": [61, 68], "100517": 83, "10079785": 68, "100807": [43, 44], "100858": 59, "10089588": 58, "100896": 58, "10092": 55, "100923": 58, "100_000": 56, "101": [16, 17, 18, 34, 66, 68, 97, 98], "101076": 44, "10126": 55, "10127930": [83, 93], "101279300": [83, 93], "1015": [36, 54], "1016": [16, 17, 18, 34], "1016010": 36, "1018": 55, "102": [64, 66, 68, 96, 98], "10235": 55, "102553e": 43, "10258": 55, "102616": 45, "102775": 45, "10299": 54, "103": [53, 61, 66, 68, 98], "1031": 55, "1031190": 69, "103186": 44, "103189": 55, "10348": 54, "103497": 58, "1038": 55, "103806": 45, "103951906910721": 45, "103952": 45, "10396": 54, "104": [36, 54, 61, 66, 68, 98], "1040361": 69, "10406": 55, "1041": 34, "10414": 55, "1045303": 35, "104787": 53, "105": [22, 35, 43, 53, 66, 68, 98], "1050": 60, "105318": 58, "1054": 37, "1055": 34, "105722": 44, "105751e": 43, "105942": 43, "106": [37, 66, 68, 98], "10607": [38, 64, 96], "10618": 55, "10637173e": 69, "106391": 83, "106401e": 43, "106595": 68, "106691": 66, "106743": 44, "106746": 58, "107": [37, 56, 60, 66, 68, 98], "107073": 45, "107295": 83, "1073": 55, "10747": [38, 64, 96], "107872": 66, "10799": 55, "108": [66, 68, 94, 97, 98], "1080": [23, 26, 34, 35, 53], "10824": [38, 64, 96], "108257e": 55, "108259": 40, "10831": [38, 64, 96], "10878571": 58, "108786": 58, "109": [43, 66, 68], "109005": 58, "10903": 54, "109069": [83, 93], "109079e": 58, "109273": 53, "10928": 55, "1093": 48, "109454": 55, "1096": 34, "10967": 54, "109811": 51, "109861": 96, "1099472942084532": 41, "10e": [45, 58], "11": [11, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 58, 59, 60, 62, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 96, 99], "110": [66, 68, 98], "1100": 69, "1101": 55, "11019365749799062": 60, "110194": 60, "110359": 53, "110365": 60, "110681": 59, "1107": 55, "11071087": [61, 68], "110717": [83, 93], "1109": 55, "110902": 45, "110902411746278": 45, "111": [66, 68, 98], "1111": [14, 15, 24, 33, 35, 42, 48, 53, 60, 63, 68, 84, 89, 94], "111164": 57, "11120": 55, "1118": 36, "11199615e": 69, "112": [37, 66, 68, 98], "1120": 54, "11208236": [62, 70], "1122": 55, "112216": 45, "1129": 55, "113": [14, 66, 68, 98], "113207": 58, "113270": 45, "113415": 55, "11375": 55, "113780": 53, "114": [56, 66, 68, 98], "11409": 54, "11414": 54, "11437351": 69, "1144500": 35, "11447": 59, "114530": 49, "1145370": 35, "114570": 44, "11458": 55, "114591": 44, "114647": 45, "1147": 34, "1148": 55, "114834": 55, "11488": 55, "11495": 55, "115": [66, 68, 98], "11500": [54, 99], "115060e": 58, "115296e": 55, "115297e": 54, "11552911": 59, "11559": 55, "115636": 44, "11570": 54, "115792e": 55, "115972": 43, "116": [66, 68, 98], "116027": 45, "11617": 55, "116274": 45, "116483": 44, "116569": 55, "1166": 97, "1167": 54, "11673": 55, "11675": 55, "117": [43, 66, 68], "1170": 59, "11700": 99, "117072": 49, "117242": 58, "11724226": 58, "117366": 58, "11743": 99, "11750": 55, "1176": 34, "1177": [34, 54], "117710": 45, "11792": 36, "11796": 55, "118": [66, 68], "11802": 55, "1182": 36, "11823404": 60, "118255": 58, "1186": 36, "118601": 53, "11861": 36, "118721": [44, 50], "1187339840850312": 53, "11879": 55, "118799": 55, "118938e": 68, "118952": 53, "119": [60, 66, 68, 98], "11932": 55, "119348e": 44, "11935": 59, "119669": 68, "119766": 58, "1198": [35, 53], "12": [32, 33, 34, 35, 36, 37, 38, 40, 43, 44, 45, 46, 49, 50, 51, 53, 54, 55, 56, 58, 59, 60, 62, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 94, 96, 97, 98, 99], "120": [46, 61, 66, 68, 98], "12002": 54, "1202": 97, "120456": 50, "120468": 58, "12046836": 58, "120567": [49, 50], "120636": 43, "120721": 53, "12097": [14, 15, 24, 35, 48, 53, 63, 94], "121": [55, 66, 68, 98], "1210": 55, "12101": 55, "12105472": [83, 93], "121054720": [83, 93], "1211": 55, "1213405": 35, "121399": 55, "1214": [83, 93], "121584e": 58, "121711": 55, "121774": 51, "12196389e": 69, "122": [16, 17, 18, 34, 64, 66, 68, 97, 98], "12214": 36, "12223182e": 69, "122408": 45, "122777": 83, "123": [36, 37, 54, 60, 66, 68, 98, 99], "1230": 55, "123192": 60, "12323": 55, "1234": [32, 33, 34, 38, 41, 42, 63, 67, 69, 83, 93], "12348": 60, "1238": 55, "123806e": 44, "123917": 55, "124": [66, 68], "12410": 55, "124465": 43, "124805": 54, "125": [66, 98], "12500": 54, "125065": 83, "12539340": [83, 93], "1255": 55, "12579": 55, "1258": 35, "126": [66, 98], "12606": 55, "12612": 55, "126680": 56, "126777": 83, "126802": 55, "126875": 43, "12689": 55, "127": [16, 66, 68, 98], "127006": 55, "12705095": [70, 83], "12707800": 35, "12752825": [83, 93], "127563": 59, "1277": 56, "127778": 55, "127831": 44, "128": [36, 66, 98], "12802": 36, "12814": 55, "128273e": 43, "128312": 58, "128408": 53, "1284791": 69, "1285": 34, "12861": 55, "128651": 44, "129": [53, 66, 98], "129152": 43, "12945": 97, "1295": [34, 55], "129514": 55, "12955": 54, "1298": 55, "12980769e": 69, "12983057": 68, "13": [17, 18, 20, 33, 35, 36, 37, 38, 40, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 58, 59, 60, 62, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 96, 99], "130": [37, 49, 53, 66, 98], "130122": 59, "1303070": 69, "13034980e": 69, "130370": 45, "130526": 66, "1306": 59, "130829": 58, "13091": 55, "131": [66, 98], "13102231": 68, "13119": 59, "1312": 99, "131211": 55, "1313": [36, 99], "13137893e": 69, "131544": 43, "131771": 44, "1318": 34, "1318874": 69, "132": [37, 53, 66, 98], "13208": 99, "1321": [54, 99], "1324": [36, 54], "132454": 47, "1325": 36, "132671": 45, "13288": 54, "132903": 55, "133": [37, 64, 66, 97, 98], "13300": 55, "133202": 55, "133204": 43, "133343": 44, "133421": 55, "13356": 55, "133596": 58, "13398": 60, "133f5a": 56, "134": [53, 61, 66, 98], "1340371": 34, "1341": 36, "134146": 55, "1342": 55, "134211": 58, "1343": 54, "13442006": 69, "134542": 43, "134567": 55, "1346035": 36, "134687": 55, "13474": 55, "134765": 55, "1348": 54, "1349": 59, "13490": 55, "135": [37, 66, 98], "13505272": 35, "1351156": 69, "135329": 51, "135352": 4, "135379": 83, "135396": 43, "135707": 67, "135755": 66, "135856": 58, "13585644": 58, "135871": 53, "136": [38, 53, 60, 66, 98], "1360": 36, "13602": 60, "136089": 53, "1361": 55, "136178": 68, "13642": 55, "136442": 53, "1366": 56, "136836": 53, "137": [16, 37, 38, 66, 98], "1371": 55, "137213": 44, "1373266": 69, "137396": 58, "137529": 68, "1378": 55, "137809": 68, "138": [66, 98], "1380": 54, "138068": 49, "13809": 55, "13809544": 69, "138264": 60, "1382794": 69, "138378": 45, "1386": 34, "13868238": [83, 93], "138682380": [83, 93], "138698": [83, 93], "1387": 34, "138851": 49, "13893": 55, "138953": 40, "139": [60, 66, 96], "1390": 54, "139491": [83, 93], "1395": 69, "13956": 59, "139582e": 11, "1398": 55, "1399": 34, "139921": 66, "14": [33, 35, 36, 37, 38, 43, 44, 45, 46, 49, 50, 51, 53, 54, 55, 58, 59, 60, 62, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 96, 99], "140": [46, 55, 61, 66, 98], "1400": 55, "14000073": 69, "1401": 34, "140770": [43, 44], "140833": 45, "140861": 35, "140926": 58, "141": [55, 66, 98], "141098e": 55, "14114": 59, "141224333739414854575864697678798693100": 69, "1412243337394148545758646976787986931003715262835384749606566778588899091929621014192325434652535962677072738084879958131718223132404245555668717482959798": 69, "1412243337394148545758646976787986931006911162021272930343644505161637581839421014192325434652535962677072738084879958131718223132404245555668717482959798": 69, "1412243337394148545758646976787986931006911162021272930343644505161637581839437152628353847496065667785888990919296210141923254346525359626770727380848799": 69, "141224333739414854575864697678798693100691116202127293034364450516163758183943715262835384749606566778588899091929658131718223132404245555668717482959798": 69, "141347": 43, "141384": 51, "14141": 55, "141546": [83, 93], "141729": 44, "141820": 45, "1419096": 69, "142": [66, 98], "14200098": [83, 93], "142270": 47, "1423292": 69, "142382": 43, "1424": 67, "142624": 44, "14268": 68, "1427014": 69, "14281403493938022": 67, "14289": 55, "143": [64, 66, 98], "143495": 66, "1435": 55, "14368145": [83, 93], "144": [43, 44, 66, 98], "14400": 54, "14405": 55, "14406": 55, "144084": 45, "1441": 34, "144137": 46, "144241": 49, "1443": 55, "1444407": 69, "144500e": 55, "144669": 58, "1447": 55, "144800": 45, "144861": 54, "144908": 57, "1449738": 69, "145": [66, 98], "145245": 58, "14532650": [83, 93], "145513": 43, "145625": 58, "145748": 83, "14587": 55, "146": [66, 98], "146037": 58, "146046": 44, "146087": 96, "146142808990006": 45, "146143": 45, "14625": 55, "1465": 36, "146641": 83, "14667": 55, "1468115": 35, "146973": 45, "1469734445741286": 45, "147": [66, 98], "147015e": 55, "14702": 38, "147121": 58, "14744": 55, "1475538": 69, "14772": 55, "1479": 55, "14790924": [83, 93], "147909240": [83, 93], "147927": 38, "14798": 55, "148": [66, 98], "14803": 55, "148134": [43, 44], "148161": 58, "148443": 66, "14845": 38, "1485": 55, "148750e": [54, 55], "148790": 55, "148802": 55, "148950": 43, "149": [66, 98], "1492": 32, "149228": 60, "149285": 58, "149472": 60, "149671e": 44, "149714": 53, "14984": 55, "149858": [12, 66], "149882": 68, "149898": 58, "149973e": 44, "15": [2, 4, 5, 7, 8, 9, 10, 11, 12, 15, 33, 35, 36, 37, 43, 44, 45, 46, 49, 51, 52, 53, 54, 55, 58, 59, 60, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 96, 99], "150": [22, 37, 43, 44, 60, 66, 98], "15000": [36, 54], "150000": 36, "15000000000000002": [45, 55, 58, 67], "150000e": 55, "150136": 44, "1502": 35, "150200": 53, "150334": 55, "150408": 35, "150614": 38, "150719e": 54, "151": [66, 98], "151047e": 49, "151063": 43, "151087e": 43, "15113": 55, "151636": 45, "151819": 58, "15194": 54, "152": [66, 98], "152034": 55, "152148": [43, 44], "152772": 44, "15285": 55, "152926": 47, "153": [60, 66, 98], "1530959776797396": 45, "153096": 45, "153119": 45, "15347": 55, "15354": 59, "153587": 53, "1536148": 69, "153633": 38, "153639": 69, "154": 66, "15430": 99, "154421": 83, "1545": 55, "154557": 58, "154758": 83, "154811": 44, "154828": 45, "155": [56, 66, 98], "155000": 54, "155025": 58, "155120": 58, "155160": 40, "155516": 57, "15556": 55, "155610": 43, "155676": 43, "1557093": 35, "156": [66, 98], "1560": 55, "156021": 58, "156202": [43, 44], "156317": [43, 44], "1564": [83, 93], "156545": 83, "156567": 43, "1569": 55, "156969": 45, "157": [66, 98], "157091": 83, "1576": 55, "157613": 43, "1577657": 35, "158": [54, 66, 98], "158007": 58, "158087": 43, "15815035": 36, "158178": 45, "1582": 55, "1586": 55, "158697": [83, 93], "1589": 55, "15891559": 58, "158916": 58, "159": [56, 98], "159011": 43, "15916": 34, "159202e": 44, "159386": 59, "1596": 37, "159959": 55, "16": [2, 32, 33, 35, 36, 37, 43, 44, 45, 51, 53, 54, 55, 58, 59, 60, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 96, 99], "160": [46, 61, 98], "1604": 36, "160438": 43, "160932": 45, "161": [37, 50, 97, 98], "161049": 44, "161088": 44, "161141": 53, "161198": 57, "161236": 58, "161243": 58, "161288": 44, "161543": 55, "1619": 36, "162": 98, "16201": 55, "16211": 54, "162153": 58, "1622": 55, "16241": 55, "162436": 60, "1626685": 35, "162683": 60, "162710": 45, "162784": 68, "1628": 54, "162930": 55, "163": [55, 98], "163194": 58, "163393e": 44, "163566": 55, "163577": 40, "163816": 40, "163895": 45, "164": [40, 98], "164034": 83, "1645914": 69, "164608": 58, "164617": 54, "164698": 51, "1648": 34, "164801": 58, "164805": 45, "164864": 53, "165": 98, "16500": 54, "165178": 58, "16536299": [83, 93], "165362990": [83, 93], "16539906e": 69, "1654": 55, "165419": 58, "165549": 96, "165569": 43, "165707": 40, "16587": 54, "16590": 55, "16597": 55, "166": 98, "166079": 43, "1661": 54, "166375": 66, "167": [36, 54, 98], "1671246": 69, "16725": 55, "167547": 58, "1676": 55, "167765": 55, "167993": 83, "168": 98, "16803512": [83, 93], "168092": 83, "1681": 34, "168195": 59, "1683": 54, "168614": 58, "168931": 58, "169": [37, 98], "1691": [34, 55], "16910": 55, "169117": 60, "169196": 58, "169230e": 45, "16951": 55, "16984": 55, "17": [32, 33, 35, 36, 37, 40, 43, 44, 51, 53, 54, 55, 58, 59, 60, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 96, 99], "170": 98, "1704": 55, "17083": 55, "171": 98, "1712": 97, "1712219": 69, "1714": 36, "171575": 58, "171709": 43, "171815": 67, "171868e": 43, "171942": 55, "172": 98, "172022": [83, 93], "172083": 44, "172793": 58, "173": 98, "1736596": 69, "17372": 55, "1738": 55, "17385178": 67, "173969": 83, "174": 98, "174106": 59, "174185": 58, "174499": [83, 93], "174516e": 58, "17453": 55, "1746": 55, "174743": 66, "174884": 44, "174901": 44, "174940": 66, "17499": 55, "175": 98, "1751": 54, "175176": 58, "17522": 55, "175284": 45, "175342": 43, "175635027": 35, "17576": 55, "175894": 60, "175931": 68, "176495": 58, "17655394": 58, "176554": 58, "176929": [83, 93], "177": [32, 97, 98], "177007": 58, "17700723": 58, "177043": [43, 44], "1773": 55, "177304": 44, "1774": 34, "177463": 57, "177496": 58, "177611": 58, "177751": 58, "17778": 55, "177933e": 43, "17799": 55, "177995": 58, "178": [51, 98], "178169": 49, "178218": 44, "17823": 37, "178704": 83, "178763": 58, "178805": 50, "178934": 83, "178980": 44, "179": [49, 98], "1795850": 35, "179588e": 58, "1798913180930109556": 56, "18": [33, 35, 36, 37, 38, 43, 44, 51, 52, 53, 54, 55, 58, 59, 60, 64, 66, 67, 68, 69, 83, 93, 96, 99], "180": [46, 61, 98], "18015": 55, "180176e": 55, "180190": 68, "1803": 34, "18030": 55, "180348": 44, "180575": [49, 50], "1807": [34, 55], "1809": 97, "180951": 58, "181": 98, "1812": 55, "1814": 34, "18141": 55, "181446": 83, "182": 98, "1820": 34, "182208e": 43, "182393": 43, "182633": 58, "182692": 44, "182849": 58, "183": [37, 98], "183373": 68, "183526": 45, "18356413": 68, "18368": 55, "183855": 67, "183888": 53, "184": [37, 97, 98], "185": [36, 37], "18500": 55, "1855": 55, "185585": 66, "185984": 43, "186": [55, 98], "186027": 43, "18604": 55, "1862": 34, "186237": 44, "18631": 55, "18637": 94, "186589": 40, "18666": 55, "186735": 58, "18678094e": 69, "186795": 44, "18681020": 69, "186836": 58, "187": 98, "187153": 83, "187664": 43, "187690": 58, "1877689": 69, "18789": 55, "188": 98, "188175": 58, "1881752": 58, "188223": 58, "1887": 68, "18888149e": 69, "188991": 83, "189": [37, 98], "189195": 55, "189248": 43, "189293": 55, "189302": 43, "189493": 44, "1895815": [23, 35, 53], "189737": 58, "189927": 55, "189998": 58, "19": [33, 35, 36, 37, 43, 44, 53, 54, 55, 58, 59, 60, 66, 67, 68, 69, 83, 96, 99], "190": [37, 98], "19000": 55, "190096": 83, "190140": 43, "19031969": 58, "190320": 58, "19033538": 35, "190381": 68, "190648": 7, "19073905e": 69, "190809": 58, "190869": 66, "190892": 60, "1909": [23, 35, 53], "190915": 45, "190921": 50, "190982": 58, "191": [37, 97, 98], "1912": 97, "1912705": 63, "191320e": 54, "191397": 66, "191606": 54, "191716": 55, "1918": 34, "192": 98, "1922": 55, "192240": 83, "192505": 57, "192526": 59, "19252647": 59, "192539": [13, 66], "192587": 58, "192739": 44, "192952": 40, "193060": 58, "193069e": 43, "193300": 43, "193308": [13, 66], "19374710e": 69, "19382": 55, "19385": 55, "193f0d909729": 37, "194": [52, 55, 98], "1941": 36, "19413": [54, 55], "194232": 44, "194601": 46, "195": [69, 98], "19508": 60, "19508031003642462": 60, "19509680e": 69, "195377": 58, "195396": 58, "195547": 55, "195564": 53, "19559": [36, 54], "195761": 58, "1959": 97, "196": 98, "196189": 58, "196437": 55, "19680840": [83, 93], "1970": 55, "197000e": 55, "19705": 55, "1972088": 69, "197225": [38, 64, 96], "1972250000001000100001": [37, 64, 96], "1974": 55, "197424": 67, "197484": 83, "19756": 55, "19758": 55, "197600": 47, "197711": 55, "197920": 43, "19793": 55, "19794": 55, "198": 98, "198218": 53, "19824": 55, "198351": 58, "198549": 38, "198687": 36, "1988": [33, 42, 63], "198953": 66, "199": 98, "1990": [36, 54, 55, 68], "1991": [36, 54, 55, 99], "199206e": 43, "199281e": 58, "199282e": 55, "1993826": 69, "199412": 44, "199458": 83, "1995": [35, 53], "1998": 56, "19983954": 61, "199893": 49, "1999": [56, 61], "199959": 43, "1_": [45, 58], "1e": [2, 4, 5, 7, 8, 9, 12, 13, 55], "1f77b4": 47, "1x_4x_3": 47, "2": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 26, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 83, 84, 85, 86, 89, 90, 91, 92, 93, 96, 97, 98], "20": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, 21, 23, 24, 25, 32, 33, 35, 36, 37, 40, 43, 44, 45, 46, 49, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 66, 67, 68, 69, 70, 83, 84, 89, 96, 99], "200": [19, 22, 34, 42, 45, 46, 48, 52, 57, 58, 61, 63, 67, 98], "2000": [15, 36, 43, 44, 45, 54, 55, 58, 61, 68], "20000": [36, 54], "20000000000000004": [45, 55, 58], "200000e": 55, "200065": 40, "20010": 55, "200110": 55, "2003": [14, 97], "200303": 96, "2005": 46, "20055": 55, "2006": 55, "20073763": 52, "20074": 55, "200863": 43, "201": [37, 55, 98], "2010": [35, 53], "2011": [35, 53, 94, 96], "2013": [48, 83, 93, 97], "2014": [83, 93, 97], "2015": [22, 97], "201528": [43, 44], "20158": 55, "2016": 56, "2017": [21, 97], "201768": 53, "201788e": 55, "201796": 51, "2018": [14, 15, 24, 25, 33, 35, 36, 42, 46, 48, 52, 53, 54, 55, 59, 63, 69, 83, 93, 94, 97, 98], "2019": [19, 37, 43, 44, 45, 49, 50, 55, 58, 59, 67, 70, 72, 77, 82, 94, 96, 97], "202": 98, "2020": [4, 5, 16, 17, 18, 20, 34, 37, 46, 60, 67, 68, 84, 86, 97], "2020435": 35, "2021": [23, 34, 35, 37, 43, 44, 53, 97, 98], "20219609": 35, "2022": [59, 60, 68, 84, 86, 92, 94, 97], "2023": [26, 61, 68, 70, 78, 79, 97], "2024": [32, 41, 56, 60, 94, 97], "202650e": 45, "20269": 55, "20274": 55, "202846": 44, "203": [36, 54], "203284": 45, "20329": 55, "2036": 55, "203828": 55, "203893": 66, "204007": 58, "20400735": 58, "204362": 60, "204482": 58, "204626": 40, "204653": 66, "204794": 58, "2048642": 69, "205": [56, 59], "205187": 45, "205224": 59, "205656": 43, "205938": 53, "206": 98, "2061": 55, "206253": [54, 55], "2064": 55, "206614": 58, "206748": 44, "207222": 54, "2075": 34, "20783816": 35, "207840": 50, "207912": 83, "208": [40, 98], "208034e": 55, "2080787": 35, "20823898": 35, "2086": 55, "208922": 43, "209": [40, 56], "209014": 58, "209200828": 69, "209219e": 59, "209257": 4, "209546e": 55, "209894": 58, "21": [14, 15, 24, 32, 33, 35, 36, 37, 43, 44, 48, 53, 54, 55, 58, 59, 60, 63, 66, 67, 68, 69, 83, 94, 96, 97, 99], "210": [17, 18, 40], "210141923254346525359626770727380848799": 69, "2103": [55, 94], "2103034": 35, "210319": [43, 44], "210323": 58, "2104": 98, "21078": 55, "211": [40, 98], "21105": [37, 67, 94, 96], "2112": 60, "21142": 55, "211534": 45, "21155656": 58, "211557": 58, "212": [40, 98], "2122": 55, "21257396e": 69, "212844": 53, "213": [40, 97, 98], "213026": 55, "213070": 44, "213135": 44, "21361": 55, "213635": 43, "2139": 20, "2143960": 69, "214764": 59, "215": [40, 50], "215069": 58, "215342": 58, "215389": 43, "2155": 55, "21550": 55, "21562": 55, "21573": 55, "215967": 83, "216": 40, "216130e": 43, "216207": 67, "21624417": 35, "2163": 55, "216344": 58, "21669513e": 69, "216761": 57, "217": [40, 97], "21716": 55, "2171802": [35, 53], "217244": [9, 66], "218": [32, 40], "21804": [36, 54], "218176": 40, "218383": 40, "218767": 55, "2189": 55, "218938": 55, "219": [16, 17, 18, 34, 40, 97], "2191274": 35, "219196e": 44, "21997": 54, "22": [32, 33, 35, 36, 37, 43, 44, 53, 54, 58, 59, 60, 66, 67, 68, 69, 83, 96, 99], "220": [40, 98], "220088": 55, "220772": 58, "220773": 43, "221": [40, 56, 98], "221245": 44, "2213": 53, "2214": 53, "221419": 55, "2215": 53, "2215977": 69, "2216": 53, "2217": [35, 53], "222": 98, "2222": [33, 35, 42, 68], "22222": 55, "22272803e": 69, "222843": 58, "223": 98, "22336235": 35, "223485956098176": [49, 50], "22375856": 35, "22390": 54, "224": 98, "224539e": 43, "224546": 43, "224897": [43, 44], "225": [34, 61, 98], "225034": 46, "22505965": 35, "22507006e": 69, "225175": 58, "225222": 58, "22522221": 58, "22528": 55, "225427": 40, "225459760731946": 45, "225460": 45, "225574": 53, "2256": 55, "22562": 55, "225776": 60, "226": [56, 98], "2264": 34, "226524": 58, "226598": 53, "226776": 44, "226938": 50, "227": [55, 98], "2271071": 26, "227190": 50, "2276": 34, "2279": 55, "227931e": 54, "228035": 55, "2281": 55, "228214": 68, "228621": 43, "228630": 44, "228648": 36, "229": [36, 98], "2290": 69, "22925": 55, "22937": 55, "229443": 58, "229452": 68, "229472": 54, "2295": 55, "229759": 67, "2298": 34, "229897": 43, "229961": [43, 44], "229994": [43, 44], "23": [5, 35, 36, 37, 43, 44, 46, 52, 53, 54, 55, 58, 59, 60, 64, 66, 67, 68, 69, 83, 94, 96, 97, 99], "230": 34, "230009": [49, 50], "2307": [35, 53, 63], "2308": 59, "230956": 47, "231": [14, 98], "23113": 68, "231153": 44, "231310": 58, "231330e": 44, "231430": 83, "231467": 68, "231986": 58, "232134": [43, 44], "2328": 55, "232959": [49, 50], "233": 21, "233029": 43, "233154": 99, "2335": 34, "234": 97, "234137": 60, "234153": 60, "234205": 55, "234534": 45, "234605": 38, "234798": 55, "234812e": 44, "234910": 53, "235": 98, "2350870": 69, "235501e": 43, "235873": 43, "2359": 99, "23590": 55, "236008": 45, "236309": 55, "23690345e": 69, "237": 37, "237252": 55, "237292": 44, "237341": 43, "237430": 44, "237461": 59, "23748": 55, "23751359e": 69, "237896": 58, "23789633": 58, "238": [35, 53, 98], "238101": 58, "238225": 83, "238251": 45, "238529": 8, "23856": 55, "238794": 58, "239": 98, "239313": 44, "239317": 44, "23965": 55, "239799": 43, "23e": 36, "24": [35, 36, 37, 43, 44, 50, 52, 53, 54, 55, 58, 59, 60, 61, 66, 67, 68, 69, 83, 96, 97, 98, 99], "240127": [43, 44], "240295": 59, "240532": [43, 44], "2407": 34, "24080030a4d": 37, "240813": 51, "241049": 58, "241063": 43, "241064": 44, "241596": 68, "2416": 34, "241609": 55, "241678": 43, "241962": 60, "24199": 55, "242": 97, "242000": 55, "242124": [54, 55], "242139": 83, "242158": [54, 55], "2424596822": 50, "242815": 83, "242902": 58, "2430561": 34, "243246": 58, "2438": 55, "2439": 55, "244": 55, "244090": 55, "244455": 58, "244622": 83, "24469564": 96, "245": 97, "245062": 58, "2451": 34, "24510393": 36, "245370": 53, "245416": 44, "245512": 58, "245720": 47, "246": 98, "2466167": 69, "246624": 66, "246731": 54, "2467506": 35, "246753": 58, "246879": 58, "247": 98, "247020": 45, "247057e": 58, "2471": 55, "2472": 55, "247207": 44, "247617": 66, "247717": 55, "24774": [54, 55], "247826": 53, "248171": 58, "248638": 45, "249": [35, 53, 56], "2491": 55, "249109e": 44, "24917": 55, "25": [13, 16, 17, 18, 22, 23, 24, 35, 36, 37, 43, 44, 45, 47, 48, 52, 53, 54, 55, 58, 60, 61, 66, 67, 68, 69, 83, 96, 99], "250": 56, "2500": 55, "25000000000000006": [45, 55, 58], "250073": 55, "250210": 45, "2503": 55, "250354": 58, "250425": 45, "251": [55, 59], "251101": [66, 67], "251412": 44, "251480": 44, "251953": 55, "252133": 55, "252253": 59, "25240463": 68, "252524": 58, "252601": 83, "252644": 43, "253026": [43, 44], "2532": 55, "253437": 57, "253724": 58, "25374": 55, "254": [55, 98], "25401679": 35, "254038": 50, "2543": 55, "254324": 45, "254400": 83, "254551": 44, "255": [55, 98], "255598": 44, "256": [55, 67], "256002": 68, "25634323": 69, "256416": 58, "256567": 53, "25672": 55, "256944": 58, "256983": 11, "256992": 55, "257207": 35, "257377": 47, "258158": [43, 44], "2583": 55, "258951": 58, "259": 32, "259395": 51, "2594": [36, 54], "259828": [43, 44], "25x_3": 47, "26": [35, 36, 37, 38, 43, 44, 46, 52, 53, 54, 55, 61, 64, 66, 67, 68, 69, 83, 96], "26016": 55, "260161": [12, 66], "260211": [43, 44], "260356": 54, "260360": 58, "260687": 44, "2610": 55, "2613": 55, "261520": 40, "261624": [54, 55], "261685": 55, "26175": 55, "261777": 55, "261903": 53, "2619317": 35, "262000e": 43, "262357": 44, "262423e": 55, "262621": 53, "262829": 69, "263": [14, 55, 98], "2633": 55, "263672": 43, "2637": 68, "263974e": 58, "264": [97, 98], "264086": 47, "264274e": 55, "264884": 55, "265119": 57, "2652": [37, 54, 55], "265547": 55, "2658": 50, "2662342": 69, "266922": 83, "26693727": 69, "267": 56, "2670691": 35, "267099": 43, "267500": 53, "267581": 55, "267767": 44, "267950": 58, "268055": 55, "268942": 58, "268998": 36, "269043": 58, "269977": 55, "26bd56a6": 37, "26e": 36, "27": [17, 18, 33, 35, 36, 37, 38, 43, 44, 46, 52, 53, 54, 55, 61, 64, 66, 67, 68, 69, 83, 96, 97], "2700": 37, "270644": [43, 44], "270694e": 43, "271": 56, "271004": [54, 55], "271083": 55, "272296": 55, "272408": 44, "272662": 55, "273": 37, "273356": 45, "27371": [36, 54], "27372": [36, 54], "274": [37, 55], "2740991": 34, "274247e": 54, "274267": 53, "27429763": 68, "274430": 44, "274793": 58, "274825": [13, 66], "27487": 55, "2754": 34, "275535": 43, "275596": 83, "276": 37, "276148": 58, "276189e": 53, "2764": 55, "2766091": 36, "27713": 55, "277299": 38, "27751": 55, "277561e": 53, "277968": 58, "278": 59, "2780": 35, "278000": 53, "278035": 40, "278303e": 43, "278391": 55, "278434": 49, "278522": 40, "2786": [83, 93], "278683": 43, "27951256e": 69, "27986": 55, "28": [35, 36, 37, 43, 44, 48, 51, 52, 53, 54, 61, 66, 67, 68, 69, 83, 96, 98], "280196": 50, "280454dd": 37, "280514": 83, "280963": 57, "281024": 58, "28111364": 36, "2815": 55, "2818": 34, "2819": [83, 93], "282": 97, "282200": 50, "2825": [94, 96], "28251": 55, "2827508": 69, "282870": 55, "2830": [94, 96], "28326": 55, "2836": 34, "2836059": 35, "28382": 55, "283974": 58, "283994": 58, "2841487": 69, "28425026": 59, "284271": 51, "284397": 99, "28452": [36, 54], "2849": 55, "284949": 44, "284987": 55, "286027": 66, "286203": 43, "2865": [34, 55], "286507": 45, "286563e": 55, "286593": 55, "287011": 44, "287041": 58, "287434": 56, "287815": 59, "287926": 58, "288": 56, "288006": 54, "288850e": 43, "288976": 55, "289": 97, "289357": 44, "289440": [43, 44], "289718": 43, "29": [11, 35, 36, 37, 43, 44, 52, 53, 54, 59, 61, 66, 67, 68, 69, 83, 96], "29062075": 69, "290987": 54, "291": 55, "2910": 55, "291008": 43, "291011": 68, "291071": 58, "29107127": 58, "291405": 58, "291406": 58, "291434": 44, "291500e": [54, 55], "291517": [43, 44], "291963": 58, "292": 57, "292028": 45, "292047": 83, "292105": 58, "292178": 54, "292302995303554": 45, "292303": 45, "2925": 37, "2927": 55, "292997": 58, "29299726": 58, "293218": 58, "293617e": 55, "293960": 43, "294067": [43, 44], "295": 97, "295481": 58, "29548121": 58, "295642": 43, "295837": [38, 64, 96], "2958370000000100000100": [37, 64, 96], "2958370001000010011100": [37, 64, 96], "2958371000000010010100": [37, 64, 96], "296228": 55, "296585": 44, "296729": 53, "29678199": [62, 70], "296901": 43, "297": 69, "297287": [43, 44], "2973": 55, "297349": [49, 50], "297682": 58, "297687": 55, "297749": 55, "297779e": 44, "29784405": 59, "298": [21, 37], "298076": 43, "298120": 45, "298228e": 55, "299": [32, 37], "299535": 56, "299537": 50, "299712": 49, "2999": 40, "2_": [26, 61, 84, 86, 92], "2_x": [26, 61], "2d": [70, 77], "2dx_5": [45, 58], "2e": [32, 34, 35, 36, 37, 67, 68, 70, 83, 96], "2f": 51, "2m": [84, 89, 92], "2n_t": 47, "2x": 58, "2x_0": [19, 43, 44, 49, 50], "2x_4": 47, "3": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 24, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 94, 95, 96, 97, 98], "30": [19, 32, 33, 35, 37, 40, 41, 42, 43, 44, 45, 46, 52, 53, 54, 55, 58, 61, 66, 67, 68, 69, 83, 96, 99], "300": [33, 42, 45, 55, 58, 63, 97], "3000": 40, "30000000000000004": [45, 55, 58], "30031116e": 69, "30093956": 59, "301": 37, "301366": 83, "301371": 58, "3016": 54, "3017022": 69, "301737": 43, "30189": 55, "302357": 58, "302571": 66, "302648": 53, "303007": 43, "303324": 53, "303489": 58, "303613": 58, "30361321": 58, "30383": 55, "303835": 53, "303f00f0bd62": 37, "304130": 58, "304159": 58, "304201": 47, "304217": 43, "305133": 66, "305255": 44, "30527": 55, "305341": 58, "305612": 53, "305775": 58, "305b": 37, "30645": 55, "30672815": 35, "306915": 53, "306963": 58, "307176": 43, "307407": 58, "308": 55, "308568": 44, "308774": 43, "30917769": [49, 50], "309605": 43, "309772": 53, "309823e": 55, "30982972": 58, "309830": 58, "31": [35, 36, 37, 40, 43, 44, 52, 53, 54, 55, 61, 66, 67, 68, 69, 83, 96, 99], "310000e": 55, "310761": 57, "311253": 55, "311712": 49, "3120": 55, "312008": 44, "312882": 44, "313056": 83, "313209": 45, "313324": 55, "31337878": 55, "313535": 58, "31378": 37, "314": 69, "314071e": 43, "3141": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 37, 38, 53, 62, 64, 66, 67, 70, 83, 93, 96], "314247": 60, "314341": 43, "314625": 44, "314651": 49, "31476": [54, 55], "315031": 60, "3151": 55, "315155": 44, "315223": 40, "315290": [49, 50], "315310": 43, "316": 37, "316193": 58, "31632": 55, "316407": 68, "316540": 53, "316717": [43, 44], "316863": 44, "317064": 43, "317394": 47, "317487": 58, "317607": 58, "3177": 69, "318": 37, "318000e": 55, "318438": 55, "318552": 55, "318584": 83, "318753": [49, 50], "319": 37, "319100": [49, 50], "319759": 58, "319850": 58, "32": [35, 36, 37, 43, 44, 52, 53, 54, 55, 61, 66, 67, 68, 69, 70, 83, 96, 99], "320": [55, 56], "320314": 54, "320633": 45, "321520": 44, "321686": 83, "32236455588136": 46, "322404": 59, "3234": 55, "323622": 54, "323679": 53, "324": [36, 55], "3244477": 69, "324476": 40, "324518": 57, "32458367": 35, "3245837": 58, "325056": 58, "325090": 55, "326148": 44, "3266774": 69, "326740": 58, "326871": 60, "3268714482135234": 60, "327265": 44, "327803": 66, "329181": 44, "329339": 46, "32950022e": 69, "329679": 44, "33": [32, 35, 36, 37, 43, 44, 49, 52, 53, 54, 55, 61, 66, 67, 68, 69, 83, 96, 97, 99], "3300": [36, 54], "330143": 58, "33014346": 58, "330285": [43, 44], "3304269": 35, "330615": 58, "330731": [13, 66], "331365": 49, "331521": 58, "331602": 55, "331640": 44, "33175566": 58, "331756": 58, "332": 56, "332502": 44, "332782": [13, 66], "3329": 55, "332996": 53, "3333": [33, 35, 42, 66, 67, 68], "3333333": 37, "33335939e": 69, "3335": 55, "333575": 54, "333655": 43, "333704": 44, "334": 36, "3340247": 69, "334425": 43, "334649": 51, "334750": 45, "33500": 55, "335121": 44, "335176": 55, "335446": 40, "335609e": 58, "335846": 58, "335853": 55, "336153": 43, "336461": 55, "336510": 44, "336612": 47, "337380": 58, "3376": 34, "337619": 46, "338": 59, "33849": 55, "3386": 69, "338603": 43, "338775": 45, "338900": 44, "338908": 45, "339269": 59, "33928": 55, "339570": 58, "339875": [49, 50], "34": [33, 34, 35, 36, 37, 40, 43, 44, 50, 52, 53, 54, 55, 56, 59, 61, 66, 67, 68, 69, 83, 99], "340": [36, 55], "340274": 59, "340485e": 43, "341336": [9, 66], "3418902": 69, "3420": 55, "342362": 40, "342467": 66, "342675": 35, "34287815": 59, "342989": 55, "342992": 53, "343": 55, "344212": 99, "344305": 51, "344505": [54, 55], "344640": 58, "34475": 54, "344753": 40, "344787": [43, 44], "344834": 47, "345065e": 55, "345381": 45, "3453813031813522": 45, "3454": 55, "345852": 44, "345903": 58, "345989": 43, "346206": 58, "346238": 59, "346269": 44, "346678": 57, "347310": [13, 66], "347696": 45, "34769649731686": 45, "347929": 55, "34858240261807": 46, "348617": 58, "348700": 44, "3489065": 69, "3492131": 34, "349383": 53, "34943627": 52, "349638": 44, "34967621": 35, "349772": 50, "35": [36, 37, 43, 44, 45, 53, 54, 55, 58, 66, 67, 68, 69, 83, 84, 89, 99], "3500000000000001": [45, 55, 58], "350165": 67, "350208": 43, "350518": 58, "350712": [49, 50], "35077502": [84, 89], "351629": 55, "351766": 57, "352": [36, 53], "352250e": 54, "352259e": 55, "3522697": 35, "352365": 43, "352813": [66, 67], "35292": 55, "352990": 55, "352998": 55, "353412": 58, "35341202": 58, "35365143": [2, 4, 5, 7, 8, 9, 10, 11, 12], "353748e": 58, "3538": 34, "354": 55, "354188": 47, "354371": 58, "354688": 10, "355209": 58, "355699e": 43, "356136e": 55, "356167": 50, "356183": 55, "35620768e": 69, "3564": 55, "3565": 55, "356886e": 44, "3569": 68, "357": 55, "357170": 43, "35731523": 68, "358158": [54, 99], "358289": 53, "358395": 59, "358653": 44, "358799": 83, "358977": 54, "359": 99, "359100": 55, "3593": 59, "359307": 44, "35th": 97, "36": [36, 37, 43, 44, 53, 54, 66, 67, 68, 69, 83, 99], "360004": 58, "360065": 83, "360122": 43, "360249": 51, "360475": [43, 44], "360655": 55, "360683": 45, "360801": 45, "361060231": 69, "361518": 45, "361518457569366": 45, "361521": 10, "3619201": 20, "362155e": 44, "36231307e": 69, "363276": 35, "3643": [83, 93], "364595": 35, "3647": 37, "364800": 58, "36501": 55, "36557195e": 69, "36566025e": 69, "366": 55, "36616": 55, "366310": 68, "366529": 57, "366541e": 43, "366718627": 35, "366950": 43, "367056": 44, "367181": 43, "367323": 58, "367571": 45, "367625": 58, "368092": 44, "368152": 53, "3682": [36, 54, 55], "368324": 53, "368499": 45, "3684990272106954": 45, "369556": 45, "3696": 59, "369796": 58, "369869": 54, "369981": 53, "37": [36, 43, 44, 53, 54, 55, 66, 67, 68, 69, 83], "3702770": 35, "370736": 53, "3707775": 35, "3710": 55, "371357": [54, 55], "371429": 45, "37152628353847496065667785888990919296": 69, "371535": 43, "372": 97, "37200": [54, 55], "372097": 45, "3722": 55, "37231324": 61, "3724": 55, "372427": 44, "372628": 43, "3727679": 35, "372989": 43, "373802": 44, "3738573": 35, "374364": 58, "37436439": 58, "3745": 55, "374821e": 55, "374862": 43, "375077e": 43, "375081": 55, "375465": 58, "376760": 44, "376780": 43, "376806": 44, "377060": 55, "377195": 40, "3771967": 69, "377311": 58, "377669": 44, "378351": 7, "378588": 43, "378596": 53, "378688": 58, "378828e": 43, "378834": 58, "3788859": 35, "379": 97, "379038": 58, "379117": 43, "37939": 55, "379614": 58, "379626": 43, "38": [37, 43, 44, 54, 66, 67, 68, 69, 83], "3800694": 35, "380170e": 43, "380432e": 44, "380837": [54, 55], "381072": 58, "381603": 43, "381623e": 50, "381685e": [54, 55], "381689": 58, "3817": 55, "381826": 11, "382188e": 44, "382286": 55, "382582e": 2, "382684": 66, "382872": 45, "383297": 58, "384": 55, "384223": 68, "384443": 44, "384677": 40, "384777": 55, "384928": 43, "385013": 40, "3851": 55, "385240": 83, "3854110": 69, "385615": 40, "385877e": 44, "385917": 53, "386": [37, 55], "386102": 45, "386502": 55, "386831": 40, "386834": 44, "386894": 44, "386988": 46, "387": 37, "3871": 34, "387426": 58, "3874766": 69, "387780": 58, "388071": 58, "388185": 40, "38818693": 69, "388216e": 67, "388298e": 43, "388593e": 44, "388668": 58, "38866808": 58, "388871": 55, "389": [37, 40], "389126": 68, "38922": 68, "389566": 57, "38973512e": 69, "38990574": 69, "39": [32, 34, 35, 36, 37, 38, 40, 43, 44, 46, 50, 51, 52, 53, 54, 55, 59, 60, 61, 66, 67, 68, 69, 83], "390": 40, "39010121e": 69, "390379": 58, "390599": 44, "391": 40, "391377": 60, "39212301": 69, "392242": 51, "39236801": 52, "392400": 55, "392623": 44, "392752": 46, "392833": 59, "392864e": [54, 55], "393": 40, "393060": 66, "393604": 45, "393654": 40, "394": 40, "39425708": 35, "395": 40, "395076e": 55, "395136": 53, "395268": 66, "395603": 43, "395889": 55, "396": 40, "39611477": 36, "396173": 49, "39621961e": 69, "396300": 49, "3964": 55, "396531": 55, "3968184": 69, "396985": 53, "396992": [43, 44], "397140": 45, "397155": 44, "397179": 40, "39727": 55, "397313": 34, "397578": 51, "397811": 59, "398": [32, 40, 64, 96], "3985": 55, "398770": 58, "398999": 66, "399": 36, "399056": 58, "399207": 44, "399223": 47, "399355": 47, "399692": 58, "399858": 60, "3cd0": 37, "3dx_1": [45, 58], "3e1c": 37, "3ec2": 37, "3f5d93": 56, "3x_": 58, "3x_4": [45, 58], "4": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 17, 18, 26, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 96, 98], "40": [35, 43, 44, 45, 46, 50, 54, 55, 58, 61, 64, 66, 67, 68, 69, 83, 84, 89], "400": [40, 53], "4000000000000001": 67, "40000000000000013": [45, 55, 58], "40029364": [84, 89], "400823": 58, "400855956463958": 45, "400856": 45, "400910": 43, "401": [14, 99], "401247": [70, 83], "40127723e": 69, "401861": 43, "401931": [49, 50], "402077": 55, "402113": 83, "402301e": 67, "4027": 68, "402902": 55, "403": 99, "40339595": 69, "4034207": 69, "403425": 58, "4035699755": 62, "403569975514042": 62, "4035699755140420": 62, "403715": 2, "4037269089": 70, "4039": 34, "404300": 40, "404318": 34, "404411": 43, "40452": 55, "404550": 57, "405203": 47, "405374": 55, "405400e": 43, "40583": 34, "405890": [13, 66], "406": 54, "406285": 58, "406446": 45, "4065173": 69, "40676": 34, "407558": 43, "408476": [84, 89], "40847623": [84, 89], "408479": 53, "408539": 58, "408565": 58, "409154": 34, "4093": 59, "409328": 55, "409395": 58, "409746": 45, "409848": [43, 44], "41": [40, 43, 44, 54, 55, 66, 67, 68, 69, 83, 93], "410124": 44, "410393": 45, "410667": 66, "410681": 47, "410795": 53, "41093655": 69, "411190": [43, 44], "411291": 57, "411295": 58, "411304": [43, 44], "411447": 55, "411582": 58, "411869": 44, "412004": 49, "4121": 69, "412127": 58, "412304": 60, "412477": 47, "412653": 53, "412714": 45, "412726": 44, "412838": 44, "41336": 67, "41341040": 35, "413608": 58, "413933e": 44, "414073": 8, "414533": 44, "415": 32, "41525168e": 69, "415465": 44, "41566": 68, "415812": 99, "415988": 55, "416052": 40, "416132": 44, "4166": 55, "4166667": 37, "416757": 58, "416899": 43, "417640": 43, "417767": [49, 50], "417822": 54, "417834": 40, "41798768e": 69, "418056": 58, "41805621": 58, "41836": 54, "418360": 54, "41842982": 69, "418741": 40, "418806e": 45, "41918406e": 69, "419371": 58, "41979253": 69, "41989983e": 69, "4199952": 35, "41e5": 37, "42": [4, 5, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 66, 67, 68, 69, 83, 93, 97], "4200": 55, "420316e": 55, "420608e": 59, "42073312": 35, "420967": 45, "421083": 34, "4211349413": 35, "421200": 60, "421234": 66, "421357": [49, 50], "421576e": 55, "4216182": 69, "421793": 59, "421919": 55, "422007": 59, "422266": 55, "422293e": 66, "422325": 45, "422561": 40, "42338": 55, "4235839": [49, 50], "42388745": 61, "423921e": 66, "423951": 34, "424108": 45, "424127": 69, "42412729": 35, "424292": 43, "424328": 58, "424651": 68, "424700": 44, "424717": 45, "424748": 60, "425": 53, "425072": 50, "425103": 34, "425208": 55, "425493": 34, "42550": 55, "426055": 34, "426283": 43, "426540": 53, "426540301": 35, "426736": 55, "427": 55, "427101": 43, "427486": [43, 44], "42755087": 59, "427551": 59, "427573": 53, "427725": 58, "428": [83, 93, 99], "428046": 57, "42811700": 99, "428255": 58, "428411": [54, 55], "428467": 58, "4284675": 58, "428588": 43, "428771": [13, 66], "4290": 34, "429057": 44, "429705": 43, "429986": 44, "42ba": 37, "43": [36, 40, 43, 44, 66, 67, 68, 69, 83], "430298e": [54, 55], "430595": 44, "431": 32, "4311947070055128": 67, "431306": 58, "431701914": 94, "431848": 43, "431852": 44, "431998": 40, "432125e": 54, "432300e": 58, "43231359e": 69, "432484": 43, "43294": 37, "432f": 37, "433": 37, "433221": 45, "4336": 55, "43374433": 61, "433750": 43, "4339": 34, "434519": 66, "434535": 58, "43453524": 58, "434677": 44, "435": 37, "43503345": 68, "43511": 55, "435401": 53, "4357": 55, "435927": 55, "435967": 53, "43597565": 58, "435976": 58, "436": [37, 55], "436194": 43, "43627032": 46, "436327": 55, "436806": 55, "437594": 43, "437767": 54, "437924": 55, "438": 53, "438219": 58, "438289": 55, "4385284": 69, "438569": 55, "438578e": 55, "438709": 54, "43883": 50, "4389": 55, "438960": 53, "43904208": 69, "439541": [54, 55], "439699": 40, "43989": 66, "43f0": 37, "44": [40, 43, 44, 46, 66, 67, 68, 69, 83], "440320": 55, "440364": 66, "440605": 67, "440747": 43, "4408778": 69, "440a": 37, "441153": 58, "441209": 58, "441219": 49, "44124313": 68, "4416552": 35, "441676": 40, "441893": 43, "442202": 44, "442462": 44, "443016": 45, "443032": 54, "44312177": 36, "443686": 58, "4437": 55, "443701": 51, "444046": 55, "4444": [33, 35, 42, 68], "444500": [54, 55], "444850": 55, "4449272": 55, "445473": 43, "445476": 43, "44563945e": 69, "445642": 43, "446": 56, "4461928741399595": 45, "446193": 45, "4462": 37, "44647451": 59, "44713577e": 69, "447492": 55, "447624": [43, 44], "447706": 45, "447849": 46, "447999": 50, "448": [32, 55], "448587": 45, "448745": 58, "448842": 44, "4489": 55, "44890536": 69, "448923": 51, "448973": 44, "449107": 5, "449150": [13, 66], "449406e": 43, "44950": 55, "44fa97767be8": 37, "45": [40, 43, 44, 45, 49, 51, 54, 55, 58, 66, 67, 68, 69, 83], "4500": 54, "45000000000000007": [45, 55, 58, 67], "450152": 53, "450870601": 35, "450926e": 43, "452": 37, "452091": 55, "452114": 66, "452484e": 44, "452488701": 35, "452489": 53, "453": 37, "453279": 43, "4535": 55, "4539": 37, "454081": 55, "454185": 44, "454397": 58, "454406": 40, "45467447": 69, "455": 37, "45500": 55, "455078": 45, "455091": 44, "455107": 45, "455120": 58, "4552": 37, "455293": 45, "4552b8af": 37, "455448": 59, "455672": 55, "4559565": 83, "45595650": 83, "455981": 84, "456370": [44, 53], "456432": 43, "456552": 66, "4567": 59, "4568280": 69, "456892": 45, "457088": 58, "457252": 44, "457667": 55, "458114": 55, "458307": 86, "458420": 55, "4584447": 35, "458784": 43, "458855": 36, "458976": 44, "4592": 35, "459200": 53, "459383": 45, "45957837": 69, "459584e": 44, "459760": 55, "459812": 45, "459913": 43, "46": [40, 43, 44, 51, 52, 66, 67, 68, 69, 83, 93], "460": 55, "4601": 55, "460207": [43, 44], "460218": 45, "460289": 58, "460535": 66, "4610": 99, "461458": 44, "461629": 60, "461646": 40, "462321": 11, "462451": 45, "462567": 44, "462979": 43, "463325": 58, "4634": 55, "463418": 60, "463668": 55, "463766": 50, "463857": 55, "463903": 44, "463b": 37, "464076": 45, "464284": 53, "46448227": 69, "464668": [9, 66], "465": 40, "46507214": 59, "465212699957609": 62, "4652126999576090": 62, "4652127": 62, "465649": 60, "465730": 60, "465832": 44, "466047": 58, "46618738": 69, "466440": 45, "466756": 58, "467": 55, "46709481": 69, "46722576e": 69, "467613": 53, "467613401": 35, "467681": [43, 44], "467770": 45, "468051e": 44, "468072": 44, "468075": 58, "46807543": 58, "46811985": 58, "468120": 58, "468406": 55, "468907": 40, "468919": 55, "468d": 37, "469": 37, "469474": 60, "469825": 45, "469895": 44, "47": [36, 40, 43, 44, 46, 54, 59, 66, 67, 68, 69, 83, 98], "470458": 43, "470904": 43, "471": 40, "472": 55, "47222159": 61, "472255": 55, "472657": 44, "472891": 58, "472e": 37, "473": 32, "473099": 45, "474": 99, "47419634": 96, "474214": [49, 50], "474731": 66, "474846": 54, "475304": 55, "475569": 43, "47659": 68, "476856": 45, "477130": [43, 44], "477150": 58, "477247": 44, "477443": 43, "477474": 53, "47759584": 69, "47761563": 46, "478032": 55, "4781": 55, "47857478": 69, "4794855": 69, "479529": 56, "47966100e": 69, "479722": 44, "479860": 55, "479876": [49, 50], "479882": 44, "479928": 58, "47be": 37, "48": [37, 43, 44, 54, 55, 66, 67, 68, 69, 83], "480": 40, "480133e": 58, "48029755": 59, "480579": 44, "48069071": [62, 70, 83], "480691": [70, 83], "480800e": 58, "481172": 58, "481218": 55, "481399": [54, 55], "481705": 68, "481761e": 55, "482": [37, 40], "482012": 49, "482038": 45, "48208358": 58, "482084": 58, "482461": [84, 89], "48246134": [84, 89], "482483": 58, "482790": 47, "48296": 59, "48315": 59, "483186": 47, "483192": [54, 55], "48331": 59, "4835": 55, "483711": 58, "483717": 45, "48390784": 68, "483944": 43, "48404": 35, "4845": 55, "484640": 58, "4849": 37, "485": [37, 55], "4852427": 69, "485377": 43, "48550": 60, "485617": [54, 55], "485812e": 55, "48583": [54, 55], "485871": 50, "486": [22, 55], "486202": 45, "4864717": 69, "486532": 58, "48661": 55, "487": [40, 55], "487467": 55, "487641e": 58, "487872": 41, "488460": 55, "488485": 55, "48873663": 46, "488811": 58, "488909": [54, 55], "488982e": 45, "4895498": 58, "489550": 58, "489699": 45, "4899880": 69, "49": [37, 40, 43, 44, 66, 67, 68, 69, 83], "490000e": 55, "490070931": 35, "490488e": 54, "490504e": 55, "490700": 58, "490941": 55, "49098": 67, "491034": 43, "491245": 53, "4915707": 68, "492": 55, "492417e": 68, "492454": 44, "492656": 44, "49270769e": 69, "493": 97, "493144": 60, "493219": 58, "493313": 55, "493325": 4, "494089": 44, "494129": 58, "494324": 53, "494324401": 35, "495": 57, "49501411": 69, "49530782": 35, "495657": 45, "495752": 58, "4958502": 62, "495850216426873": 62, "4958502164268730": 62, "49596416e": 69, "496": 57, "49650883": 59, "496551": 58, "496714": 60, "496777": 99, "497": 57, "497287": 56, "497298": 66, "497422": 44, "497655": 5, "497674": 46, "497964": 66, "498": 57, "498340": 56, "498921": 58, "498979": 55, "498f": 37, "499": [55, 57, 64, 96], "499000e": [54, 55], "499776": 55, "49d4": 37, "4a53": 37, "4b8f": 37, "4dba": 37, "4dd2": 37, "4e": [35, 36], "4ecd": 37, "4fee": 37, "4x": 58, "4x_0": [19, 43, 44, 49, 50], "4x_1": [19, 43, 44], "5": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 95, 96, 98], "50": [13, 35, 37, 45, 47, 50, 52, 54, 55, 56, 58, 66, 67, 68, 69, 83], "500": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, 21, 24, 33, 37, 38, 42, 43, 44, 49, 50, 52, 54, 57, 59, 63, 64, 66, 67, 68, 70, 83, 84, 89, 93, 96, 99], "5000": [43, 44, 45, 58], "50000": 53, "500000": [54, 55], "5000000000000001": [45, 55, 58], "500084": 58, "500267": 51, "5003517412": 35, "500517": 58, "50093148e": 69, "501021": 55, "501660": 56, "501954": 44, "501983": 58, "502054": 44, "502084": 68, "502494": 45, "5025850": 35, "502595": 44, "502612": 58, "502713": 56, "502843e": 44, "502901": 44, "502995": 58, "503504": 67, "503511": 55, "503700": 40, "50398782e": 69, "504286": 53, "5042861": 35, "504569": 43, "5050973": 35, "505913": 43, "50593782": 69, "506050": 43, "506159e": 43, "506644": 43, "506659": 55, "506687": 55, "50672034": 35, "506900e": 58, "506903": 45, "50768b": 56, "508153": 57, "508433": 43, "508459": 53, "5085": 55, "508630": 44, "5087635": 69, "508947": 68, "509059": 55, "509196": 58, "509339693389362": 62, "5093396933893620": 62, "5093397": 62, "509461": 58, "50967": 60, "5097": 60, "509782": 44, "5098": [38, 64, 96], "509853": 58, "5099": [37, 38, 64, 96], "509951": 45, "509958": 53, "51": [34, 36, 37, 49, 66, 67, 68, 69, 83, 98], "510000e": [54, 55], "510385": 53, "510555": 40, "51079110": 35, "510982": 54, "511022": 66, "511293": 54, "511515": 55, "511540": 55, "511668": 60, "5116683753999614": 60, "511862": 58, "512": 53, "512081e": 43, "512108": 58, "512149": 58, "51214922": 58, "51243406e": 69, "512519": 53, "512572": 58, "512672": [68, 84, 89], "512832": 43, "513052": 43, "5131": 54, "513992": 58, "514": 37, "514160": 43, "514173": 44, "514545": 55, "515031": 43, "515358": 45, "5154": 55, "5154789948092002": 53, "5155": 37, "515950": 68, "516": 37, "516125": 45, "516222": 58, "516255": 58, "516256": 58, "516528": 58, "516888": 43, "516945": 40, "517": [37, 53], "517266": 44, "5175": 55, "517785": 43, "518175": 53, "518446": 55, "518682": 44, "518767": 43, "518782": 55, "518846": 53, "519622": 43, "51966955": 35, "519710": 58, "519888e": 44, "52": [34, 37, 51, 66, 67, 68, 69, 83], "520": 55, "520641": 59, "520930": 45, "521002": 45, "521085": 66, "521611": 44, "522753": 10, "522835": 47, "523030": 60, "523163": 45, "5232": 52, "5233": 69, "52343523e": 69, "523794e": 58, "523807": 57, "523977545": 35, "524088": 43, "52424539": 35, "524657": 58, "5249": 67, "524934": [43, 44], "5250": 55, "525064": 40, "52510803": 36, "525135": 44, "525138": 43, "5251546891842586": 60, "52520655": 69, "5255": 37, "52590": [36, 54], "526": 53, "526102": 68, "526532": 55, "526769": [43, 44], "527": 68, "527452": 44, "527728": 44, "5280295": 69, "528381e": 61, "528580": 58, "528937": [49, 50], "528996901": 35, "528997": 53, "529": 53, "529405": 34, "529782": 34, "529969": 44, "53": [34, 37, 40, 64, 66, 67, 68, 69, 83, 94, 97], "530940": 58, "53094017": 58, "531": 37, "531223": 45, "531594": 55, "53209683": 68, "532266": 45, "53257": 67, "532738": 58, "53273833": 58, "532751": 49, "5329": 55, "533489": 47, "533900": 58, "5346": 37, "535179": 58, "535278991538703": 62, "535279": 62, "5352871": 69, "535318": 58, "535609": 55, "535718e": 55, "53606675": 58, "536067": 58, "536082": 40, "5360866": 69, "536143": 55, "536219": 40, "536746": 58, "536798e": [54, 55], "537240": 58, "53724023": 58, "53791422": 68, "538": 37, "538013": 55, "5382": 59, "538937": [54, 55], "539455": 58, "539475": 58, "53947541": 58, "539491": [49, 50], "539767": 45, "54": [34, 36, 37, 46, 54, 56, 63, 66, 67, 68, 69, 83, 98], "540": 32, "540240": 55, "540270": 44, "540542": 54, "540789": 43, "5408": 34, "541159": 58, "54163": 59, "541821": 55, "541990": 55, "542159": 44, "542333": 55, "542451": 58, "542560": 60, "542584": 45, "5425843074324594": 45, "542647": 58, "542671": 53, "542816": 11, "5428753": 62, "54287532563466": 62, "542883": [84, 89], "5428834": [84, 89], "542919": 66, "542989": 58, "543": [53, 55], "543075": 45, "543136": 45, "543358": 66, "543380": 53, "5436005": 35, "543691": 44, "543764": 50, "54378": 59, "543832": 58, "544097": 58, "544383": 60, "5443965": [70, 83], "54440": [70, 83], "544555": 53, "544669": 49, "54517706e": 69, "545492": 40, "545602": 44, "545605e": 58, "545919": 55, "546266": 40, "546294": 55, "5467606094959261": 45, "546761": 45, "547039": 43, "54716": 59, "547324": 44, "547431": 57, "5476": 55, "5478319": 69, "5479": 55, "547909": 55, "5485104": 69, "549109e": 55, "549645": 66, "55": [36, 37, 45, 50, 54, 55, 58, 66, 67, 68, 69, 83], "5500000000000002": [45, 55, 58], "5501095": 69, "550241": 56, "551317": 44, "551355": 44, "551586928482123": 45, "551587": 45, "5516": 69, "551686": 45, "55173": 67, "5518": 55, "552": 55, "552058": 59, "552508": 55, "552727": 53, "552776": 58, "553004": 40, "55348": 67, "553878": [12, 66], "553916": 55, "553965": 43, "554076": 45, "554203": 44, "554793e": 69, "555": 53, "555137": 44, "555150": 55, "555445": 57, "555498": 58, "5555": [33, 42], "555536": 43, "555949e": 55, "555954": 55, "556191": [43, 44], "556792": 58, "55693079": 69, "557": 32, "557267": 43, "5574dcd4": 37, "557595": 53, "5576184": 69, "557731": 57, "557999": 53, "558134": [43, 44], "5584": 53, "5585": 53, "55863386": 68, "558655": 45, "5589": 53, "559": 99, "5590": 53, "559144": 45, "559186": 45, "5592": 53, "559394": 58, "559522": 58, "559680": 55, "55dc37e31fb1": 37, "55e": 36, "56": [37, 63, 66, 67, 68, 69, 83, 94, 97], "560135": [70, 83], "56018481": 58, "560185": 58, "5602727": 46, "560545e": 43, "560619": 56, "5606325": 69, "560689": 34, "560723": 51, "561183e": 44, "5616": 54, "561711": 55, "561785": 68, "561819": 43, "562001": 44, "562013": 58, "562153": 43, "56223": 59, "562288": 60, "562518": 55, "5625561": 34, "562557": 43, "5627004": 69, "562712": [43, 44], "563374e": 45, "563503": 58, "563528": 55, "563673": 55, "563851e": 43, "56387280e": 69, "56390147e": 69, "564045": 58, "564073": 55, "5641": 55, "564142": 45, "564232": [43, 44], "564451": 44, "564537": 44, "564577": 55, "565066": 45, "566": 60, "566024": 58, "566091": 55, "567004": 59, "567343": 55, "567364": 44, "567529": 58, "567531": 43, "567568": 43, "567695": 43, "567945": [49, 50], "568111": 66, "569135": 44, "569444": 40, "569540": 44, "56965663": 58, "569657": 58, "569684": 44, "569911": 35, "5699994715": 35, "57": [37, 66, 67, 68, 69, 83, 99], "570038": 45, "5700384030890744": 45, "570111": 57, "5702": 55, "570486": 34, "570562": 34, "570722": 96, "570936": 43, "571707": 66, "571778": 34, "5718": 55, "572153": 66, "5722": 54, "57245066": 58, "572451": 58, "572991": 44, "573": 32, "573700": 47, "574": 37, "574904": 44, "57496671": 35, "575": 15, "57505": 67, "57572422": 59, "575810": 43, "57585824": 59, "57592948e": 69, "57599221": 59, "576": 37, "5763996": 35, "57643609": 59, "577": 37, "5770": 54, "57715074": 35, "577271": 53, "577422": 43, "577647": 40, "5776971": 59, "57775704": 59, "577807": [43, 44], "577813": 43, "578081": 55, "578307": 58, "578523": 53, "578557": 44, "578846e": 45, "57914935": 36, "579213": 60, "579238": 45, "579322e": 54, "579605e": 44, "57e": 36, "58": [16, 36, 54, 60, 66, 67, 68, 69, 83, 98], "5800": 55, "58000": 54, "580231e": 44, "580368": 43, "5804": 37, "580414": 60, "580477e": 44, "580922": 49, "581": 56, "58131718223132404245555668717482959798": 69, "581655": 55, "581849": 44, "581868": 43, "581896": 40, "5821159": 69, "582146": 44, "58241568": 69, "582747": 44, "582761": 45, "5829762": 69, "583034": 49, "583195": [43, 44], "5833333": 37, "583404": 54, "583508": 43, "583534": 58, "584012": 55, "584742": 50, "58481": 69, "584849": 45, "584877": 44, "584928": 43, "584942e": 53, "5852": 55, "585426": 69, "585793": 45, "586362": 58, "5864": 34, "5866": 55, "5866438": 69, "586719": 45, "586719493648897": 45, "5868472": 35, "587135": 44, "587292": 55, "58765": 67, "588": 55, "588000": 66, "588364": 66, "588992e": 44, "589": 32, "589248": 59, "589389": 56, "589440": 45, "59": [66, 67, 68, 69, 83], "590320": 47, "5905": 54, "590736": 58, "590813": 58, "590911": 45, "590991": 45, "591080": 47, "591411": 49, "591441": 2, "591741": 54, "591782": 58, "591788": 54, "59199423e": 69, "592186": 44, "592681e": 45, "59307502e": 69, "593648": 67, "593754e": 50, "593981": 66, "594": 15, "594241": 66, "594316e": 58, "595353": 45, "5954085": 69, "59565361": 69, "596": 55, "596069e": 55, "5962": 54, "596270": [49, 50], "5964": 52, "596758": 43, "597": 36, "597098": 55, "597923": 55, "598080": 43, "598178": 55, "598539": 44, "59854797": 68, "5985730": 36, "59861": 55, "599208": 40, "599297": 68, "5cb31a99b9cc": 37, "5d": [45, 58], "5x_2": 47, "5x_3": 47, "5z_i": 58, "6": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 22, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 94, 96, 97, 98], "60": [35, 45, 46, 55, 56, 58, 61, 66, 67, 68, 69, 83, 97], "600": 53, "6000": 55, "6000000000000002": [45, 55, 58], "600000e": 55, "600254": 57, "600694": 68, "600776": 40, "600934": 66, "601": 36, "601061": 45, "601149": 43, "601314": 43, "601598": 53, "601645": 44, "602079": 50, "602168": 45, "602587": 58, "602628": 45, "6029": 55, "603273": 43, "604016": 55, "60401775": 69, "604111": 55, "604227": 54, "604603": 5, "604825": 55, "604841": [54, 55], "605": 55, "605195": 50, "606034": 58, "606129": 58, "606342": 45, "606759": 55, "6068": 35, "606800": 53, "606954": 45, "607080": 44, "6072469": 69, "607264": 43, "6075": 99, "607600": 55, "608": 48, "608003e": 44, "608392": 58, "60857": 34, "608818": 59, "6088979": 69, "609205": 43, "609575": 68, "61": [66, 67, 68, 69, 83, 98], "610": 32, "610195e": 43, "610559": 44, "611": 99, "6110": 55, "611269": 53, "611859": 50, "612151": 44, "612792": 55, "6133": 36, "613314": 45, "613408": 58, "613498": 55, "613574": 51, "613622": 44, "613691": 68, "614185e": 44, "614188": 53, "614201": 40, "614678": 55, "615": 40, "615498": 2, "615573e": 44, "615574": 44, "615863": [49, 50], "61669761": [84, 89], "616698": [84, 89], "616797": 44, "616828": 55, "617": 53, "617283": 55, "6173": 37, "617800": 44, "617877": 58, "618069": 54, "61810738": 36, "618256": 44, "618776": 46, "618922e": 43, "619128": 44, "619177": 54, "619351": [43, 44], "619390": [43, 44], "619454": 47, "619613": 54, "61e": [36, 99], "62": [2, 51, 66, 67, 68, 69, 83], "620156": 58, "620407": 43, "620874e": 68, "620995": 61, "621094": 55, "621318": 58, "62131806": 58, "621490": 58, "6215": 54, "621902": 40, "622": [55, 99], "622153": 55, "622301": 43, "6224": 35, "622750": 40, "622949": 43, "623024": 45, "623147": 50, "623173": 43, "623197": 54, "6233435": 69, "623681e": 83, "624": 53, "6240": 59, "62403053": 46, "624224e": 43, "6243811": 35, "624482e": 43, "624535": 67, "624798": 54, "624919": 55, "624988": 55, "625": [35, 53], "625159": 51, "625183": 40, "625477": 58, "625766": 49, "625891": [49, 50], "626433": 58, "6266": 55, "626633": 44, "627505": [49, 50], "627560": 58, "627564": 45, "627588e": 55, "628069": 53, "629306": 44, "629346": 55, "629549": 44, "629771": 44, "63": [35, 53, 66, 67, 68, 69, 83, 97, 98], "630150e": 58, "630914": 51, "6312679": 69, "631333": 58, "6318": [54, 99], "631821": 44, "6319631": 69, "632058": 53, "6320729": 69, "63245862e": 69, "632747e": 58, "6328366": 83, "632958": 57, "633350": 44, "633433": 53, "634055": 43, "63407762": 99, "634078": [54, 99], "634577": 83, "63499": 55, "635000e": [54, 55], "635199": [54, 55], "63593298": 68, "636048": 68, "636453": [9, 66], "636575": 45, "637326": 58, "6379": 54, "638264": 58, "638488": 51, "638742": 44, "639135": 53, "63916605": 36, "639345": 55, "639580": 44, "63e": 69, "64": [44, 54, 55, 66, 67, 68, 69, 83, 96], "640": 55, "640334": 40, "640900": 55, "641528": 58, "641547": 58, "64154727": 58, "64171": 56, "64197957": 58, "641980": 58, "6420": 55, "642016": 58, "64269": 59, "642735": 54, "643133": 55, "64340": 59, "643512": 45, "643752": 58, "644113": 66, "644182": 66, "644665": 45, "64476745e": 69, "644799": 47, "644985": 43, "645": 55, "645583": 40, "64579": 34, "6458": 35, "645800": 53, "646937": 47, "646997": 43, "647002": 55, "647004": 68, "647010": 55, "647196": 47, "64723": 59, "647689": 60, "647873": 58, "64797": 59, "649": 97, "649158": 58, "649891": 44, "65": [45, 51, 55, 56, 58, 66, 67, 68, 69, 83], "650": 48, "6500000000000001": [45, 55, 58], "650000e": 55, "650802": 44, "650810": 55, "650867": 45, "651127": 44, "6514": 69, "652071": 55, "6522": 97, "652312": 49, "652349": 58, "652350": 53, "652450e": [54, 55], "6527": 48, "652778": 53, "6528": 55, "6530": 55, "653820": 66, "653846": 45, "653901": [43, 44], "653991": 66, "654070e": 68, "654755": 47, "655284": 58, "6553": 99, "6554": 97, "655422": 55, "655547": 43, "65557405e": 69, "6557114": 69, "656526": 44, "657": 37, "657024": 43, "657470": 44, "658": 53, "658267": 58, "6586": 34, "658702": 44, "659": 37, "659245": [43, 44], "659339": 44, "659361": 40, "6593871": 34, "659423": [43, 44], "659473": 60, "659605e": 43, "659636": 45, "6598": 52, "66": [52, 56, 66, 67, 68, 69, 83, 96, 98], "660": 37, "66025064": 69, "660320": 50, "660479": 68, "660776": 58, "661369": 57, "661388": 43, "66184": 68, "6624355": 69, "6625": 55, "663081975281988": 45, "663082": 45, "663182": 45, "6634357241067617": 60, "663529": 58, "663533": 55, "664103e": 55, "664147": 55, "664276": [66, 67], "664824": 55, "664850": 53, "665264": 58, "665554": 43, "665585": 44, "66601815": 68, "666104": 58, "666259": 44, "666307": 47, "6666667": 37, "666865": 43, "666912": 44, "667": 53, "667492e": 55, "667536": 58, "667614": 45, "667614205604159": 45, "667985": 51, "66807003": 69, "668337": 55, "668452": 51, "668584": 47, "668981": 49, "66989604": 46, "67": [32, 37, 43, 54, 56, 60, 66, 67, 68, 69, 83, 96], "670": 56, "670785": 40, "670867": [13, 66], "671271": [43, 44], "67136": 55, "6716717587835648": 45, "671672": 45, "671690": 43, "6722": 37, "672234": [43, 44], "672368": 45, "6723684718264447": 45, "672384": [43, 44], "67245350": 35, "672667663": 69, "673092": [43, 44], "673302": 53, "673586": 43, "67410934": 35, "6745349414": 35, "674552": 55, "67456": 60, "674609": 45, "674936": 44, "674949e": 59, "675293": 57, "675625": 66, "67569563": 69, "675733e": 44, "676405": 45, "6765": [36, 54], "676534": 83, "676756": 58, "676807": 54, "677614": 58, "677715456": 69, "677980": 45, "678117": 55, "678369": 44, "678826": 45, "67936506": 68, "6795": 54, "679539": 53, "67ad635a": 37, "68": [37, 59, 66, 67, 68, 69, 83], "680": 55, "680620": 44, "6810775": 59, "681176": 53, "681246": 44, "681448": 55, "681521": 43, "681562": 55, "6817477": 69, "681817dcfcda": 37, "682269": 55, "682353": 44, "682631": 44, "682875": 45, "683487": 44, "683581": 68, "683942": 58, "683984": 10, "684": [32, 99], "68410364": 36, "68411700": [36, 99], "684142": 43, "684502": 58, "685104": 4, "685107": 58, "68554404e": 69, "68562150e": 69, "685807": 58, "686627": 43, "687345": 58, "687619": 44, "687647": 58, "687697": 40, "687854": 47, "687871": 53, "6878711": 35, "688": 97, "688747": 55, "688887": 68, "688918": 55, "689088": [43, 44], "68917799": 69, "689188": 47, "689392": 58, "69": [51, 56, 66, 67, 68, 69, 83, 98], "690334": 45, "6903344145051182": 45, "690668": 44, "690796e": 44, "69111620212729303436445051616375818394": 69, "691116202127293034364450516163758183943715262835384749606566778588899091929621014192325434652535962677072738084879958131718223132404245555668717482959798": 69, "691136": 66, "691157": 46, "69140475e": 69, "691423": 43, "691511": 54, "691814": 43, "691911": 66, "692199": 44, "692277": 56, "692297": 44, "692465": 44, "692725": 58, "692907": 55, "693316": 55, "693497e": 55, "693513": 44, "693632": 43, "693690": 55, "693796": 53, "694154": 45, "694839": 44, "694845e": 55, "694919": 53, "6950": 55, "695045": 43, "69508862": 68, "695581": 51, "69562150e": 69, "696011": [12, 66], "696289": [49, 50], "696770": 66, "69684828": 68, "697": 53, "697000": 45, "697089": 43, "697420": [49, 50], "697545": 58, "697616": 44, "698223": 47, "698244": 47, "69840389e": 69, "698509": 43, "698651": 40, "698694": 53, "699035": 58, "699082": 45, "69921": 37, "699259e": 58, "699333": 45, "699543": 40, "6_design_1a": 48, "6_r2d_0": 48, "6_r2y_0": 48, "6b": [83, 93], "6cea": 37, "7": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 17, 18, 24, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 96, 97, 98], "70": [36, 45, 49, 54, 55, 58, 66, 67, 68, 69, 83, 98], "700": [43, 44, 48, 53], "7000000000000002": [45, 55, 58], "700015": 58, "700102": 58, "701078": 58, "701088": 54, "701106": 51, "701265": 49, "701413": 55, "701672e": 45, "701866": 58, "7018663": 58, "701966": 55, "702489": 55, "703049": 43, "703772": 55, "703942": 66, "7040": 55, "704814": 43, "705090": 44, "705354": 43, "705456": 43, "705474": 50, "705581": 55, "70583": 59, "705841961": 69, "7060531": 69, "706056": 55, "7061435": 69, "706231": 66, "706645": 45, "706657": 45, "706862": 5, "707125": 44, "707197": 66, "707738": 44, "707868": 58, "707963e": 54, "708190": 53, "708235": 43, "708459": 58, "708465": 44, "708695": 62, "708695026860755": 62, "7086950268607550": 62, "708821": 40, "708837": 40, "709026": 47, "709596": 43, "709606": [13, 66], "71": [66, 67, 68, 69, 83, 98], "710059": 40, "710586e": 53, "711024": 55, "711328": 55, "711518": 55, "711638": 68, "711834": 44, "712082": 55, "712095": 40, "712157": 57, "712503": 59, "712592": 54, "712774": 49, "712960": 45, "713": 55, "713407": 55, "713457": 43, "713959": 44, "713986": 55, "714240": 53, "714557": 44, "714651": 58, "71465114": 58, "715013": 55, "715075e": 43, "715180e": 55, "7154": 55, "715407": 45, "7155": 55, "715515": 44, "7158581": 35, "7161": 55, "716316": 43, "716387": 43, "716456": 58, "716595e": 55, "716762": 45, "716793": 45, "716799": 53, "7167991": 35, "717": 55, "717130": 55, "717185": 58, "7176044": 69, "717860": 66, "718": 32, "718686": 60, "72": [66, 67, 68, 69, 83, 98], "720559": 43, "720571": 58, "720573": 43, "720664": 53, "721018": 43, "721071": 58, "721245": 44, "7215093d9089": 37, "72155839e": 69, "721609": 55, "722316": 58, "722634": 58, "722848": 45, "722881": 58, "7229": 55, "723": 37, "723314": 58, "723345e": 58, "723846": 40, "7239": 55, "7241399": 35, "724338": 58, "724603": 43, "724767": [49, 50], "724918": 60, "725": 37, "725080": 40, "725087": 55, "725166": 58, "725802": 5, "725820": 44, "726": 37, "7268131": 35, "727266": 56, "727543": 47, "727693": 55, "727704": 55, "727976": 45, "7282094": 68, "728294": 57, "728710": 58, "728734": 40, "72875815e": 69, "728852": 55, "73": [36, 66, 67, 68, 69, 83], "730023": 55, "7308": 34, "730884e": 44, "731317": 45, "732067": 43, "732405": 54, "732586": 54, "7326": 55, "732638": 58, "73285": [9, 66], "732918": 49, "733": 55, "733047": 44, "733644": 43, "734278": 40, "734635": 43, "734689": 43, "734770": 44, "734948": 58, "735048": 44, "735054": 44, "735369e": 66, "735656": 43, "7357": 55, "735848": 66, "735941": 8, "735964": 47, "736001": 43, "736082": [43, 44], "736084": 58, "73608412": 58, "736823": 44, "737052": 55, "7375615": 36, "73764317e": 69, "737694e": 43, "737951": [43, 44], "738065": 44, "738223": 55, "738315": 55, "738659e": 55, "738793": 66, "739": 55, "7395359436844482": 45, "739536": 45, "739720": 55, "739817": 51, "74": [16, 36, 54, 66, 67, 68, 69, 83, 98], "740": [53, 54], "740180e": 58, "740417": 54, "740505": 40, "740869": 45, "741104": 45, "741523": 40, "741702": 58, "7418": 34, "74189": 37, "742128": 58, "742375": 43, "742407": 57, "742758e": 44, "742907": 58, "7432": 34, "743247": 55, "743341": 44, "7437": 55, "74402577": 58, "744026": 58, "744228": 44, "744236": 59, "74461783e": 69, "745": 55, "745444": 43, "745714": 54, "745881": 43, "746361": 58, "746843": 50, "7470": 55, "747646": 55, "747945": 35, "747961": 55, "748377": 54, "748513": 55, "748880": 55, "74938952": 68, "749443": 55, "749540": 43, "75": [13, 16, 18, 37, 40, 43, 45, 47, 54, 55, 58, 66, 67, 68, 69, 83, 93, 98], "75000": 60, "7500000000000002": [45, 55, 58], "750000e": 55, "750571e": 44, "750597": 44, "750701": 40, "751": 32, "751013": 55, "751261": 55, "751482e": 50, "751633": 55, "75171": 54, "751710": [45, 54], "752015": 7, "752283": 55, "752998": 56, "7533": 54, "753393": 43, "753523": 58, "753866": 44, "754448": 43, "754710": 43, "7548": 60, "754870": 53, "755": [54, 56], "755688": 43, "755717": 43, "755910": 55, "7559417564883749": 45, "755942": 45, "7560824": 35, "756200": 40, "756647": 43, "756805": 53, "756867e": 55, "756905": 5, "756969": 45, "757": 97, "757151": [43, 44], "757183": 45, "757411": 58, "757819": 53, "757917e": 58, "758": 69, "758391": 55, "75887": 37, "759006": 46, "759833": 44, "76": [66, 67, 68, 69, 83, 97, 98], "760104": 58, "7603": 34, "760386": 68, "760494e": 44, "760778": 53, "760915": 47, "761": [35, 53], "761429": 44, "761714": 45, "762237": 43, "762284": 58, "76228406": 58, "762748": 55, "763219": 43, "763691": 55, "764093": [43, 44], "76419024e": 69, "764315": 58, "76444177e": 69, "764478": 57, "7646": 55, "764798": 58, "764953": 54, "765": 54, "765202": 55, "765363": [43, 44], "765500e": [54, 55], "765710e": 61, "765792": 58, "765864": 59, "76591188": 35, "7660": 34, "7663": 55, "766499": 58, "766850e": 44, "766940": 40, "76702611e": 69, "767188": [49, 50], "767247": 66, "767349": 66, "767435": 60, "767616": 40, "768071": 58, "768273": [49, 50], "768331": 44, "768798": 40, "769290": 43, "769361": 58, "769805": 58, "7698393": 69, "77": [66, 67, 68, 69, 83], "770556": 55, "770944": [49, 50], "7710": 59, "771157": 83, "771390e": 55, "7714": 56, "7716982": 36, "771741": 55, "771965": 55, "772253": 44, "77227783e": 69, "772291": 43, "772791": 55, "77289874e": 69, "773": 37, "773177": 45, "773488": 58, "77348822": 58, "77401500e": 69, "774253": 43, "774271e": 55, "775": [37, 55, 56], "775191": [43, 44], "775969": 59, "7762554": 69, "7763": 54, "776728e": 53, "776887": 54, "7776071": 35, "777728": 66, "778": 32, "7786": 34, "778730": 56, "778852": 66, "779167": 2, "779185": 43, "779350": 43, "779517": [43, 44], "779682": 45, "7799": 52, "779912": 55, "78": [44, 66, 67, 68, 69, 83, 98], "780": 37, "780120": 44, "780458": 58, "780857": 54, "780887e": 43, "781": 55, "7811465543": 70, "781233": 55, "781530": 58, "781681": 58, "782": 37, "782050": 58, "782117": 40, "782555": 55, "782646": 66, "783": 37, "7831243849": 62, "783124384910379": 62, "7831243849103790": 62, "783276": 68, "7833": 34, "7838": 34, "784": [83, 93], "784066": 44, "784238": 53, "784341": 43, "784405": 59, "784483": 53, "784624": 45, "785": 37, "785038": 44, "785815": 40, "785911": 58, "786": 37, "786744": 45, "78711285e": 69, "787396": 43, "787716": 43, "78777": 59, "788": 97, "78818": 37, "788400": 44, "7893661": 69, "789671": 45, "789671060840732": 45, "79": [40, 66, 67, 68, 69, 98], "790115": 55, "790261": 66, "790314": 43, "790723": [49, 50], "791023938": 69, "79122": 54, "791220": 54, "791241": 58, "791297": [13, 66], "791529": 43, "792939": 45, "793": 68, "793316": 66, "79338596e": 69, "793570": 58, "793735": 58, "793818": [43, 44], "794366": 55, "794526": 43, "79458848e": 69, "794805": 49, "795558": 44, "795647": 58, "7957": 55, "795932": 67, "796014": 44, "796203": 68, "796220": 44, "796384": 44, "796444": 55, "797157": 40, "797280": 58, "797737": 83, "79792890e": 69, "797965": 83, "798071": 4, "798309": 54, "798783": [49, 50], "799403": 58, "7999": 61, "7b428990": 37, "7x": 58, "8": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 96, 98, 99], "80": [45, 46, 55, 58, 61, 66, 67, 68, 69, 98], "800": 53, "8000": [26, 61], "8000000000000002": [45, 55, 58], "800272": 66, "800351": 43, "8007644": 69, "800854": 43, "801623": 55, "802289": 55, "803300": 43, "803492e": 58, "803563": 55, "803902e": 55, "804": 55, "804081e": 44, "804219": 58, "804284": 59, "804316": 58, "804484": 58, "8048": 36, "804828": 58, "804889": 55, "805007": 53, "805153e": [54, 55], "8055563": 35, "805774": 43, "8059": 54, "805962": 43, "806218e": 55, "806531": 55, "806554": 43, "806964": 44, "80696592e": 69, "80714504e": 69, "807879": 58, "808": [36, 83, 93], "808246": 54, "808284": 55, "808640": 55, "8095": 56, "809913": [43, 44], "80a8": 37, "81": [35, 48, 51, 52, 66, 67, 68, 69, 98], "810044": 54, "810134": 58, "8102": [34, 54], "810306": 40, "810363": 55, "810382": [54, 55], "810707": 55, "811155": 51, "811398": 66, "811686": 56, "8116912": [83, 93], "811696": 43, "811825": 53, "811901": 58, "81190107": 58, "812311": 43, "812484e": 43, "8132463": 35, "813293": 58, "813342": [83, 93], "813682": 55, "814136": 45, "814351": 45, "814410": 43, "814913": 53, "815": 32, "8152": 55, "815224": [83, 93], "815226": 68, "815574": 44, "81568484": 58, "815685": 58, "815993": 58, "816176": 60, "816318": 53, "816645": 40, "816752": 55, "817291": 55, "8173602": 52, "817628": 68, "81827267": 58, "818273": 58, "818289": 58, "81828926": 58, "818313": 40, "818380": [43, 44], "81856": 37, "818590": 43, "82": [60, 66, 67, 68, 69, 98], "8202": 36, "820366": 53, "8209": 36, "820963": 40, "8210": 36, "821021": 45, "821457": 55, "821566": 58, "821855": 66, "821870": 44, "8221": 34, "822289": [54, 99], "82228913": 99, "822482": 45, "8227": 55, "822822": 45, "823247": 58, "823273": [43, 44], "823769e": 43, "824350": [43, 44], "824493142": 69, "824701": 45, "824750": 45, "824889": 45, "824961e": 55, "8250": 34, "825140": 43, "825617": 53, "825801": 40, "825824": 44, "825862": 58, "825980": 45, "8259803249536914": 45, "8260": 54, "826065": [43, 44], "826215": 44, "826391": 44, "826426": 68, "826492": 58, "826519": [13, 66], "82666866e": 69, "826829": 43, "82684324": 59, "827192": 43, "827234": 43, "827375": 46, "827381": 58, "827438": 43, "827445": 40, "827735": 58, "827938162750831": [49, 50], "828058": 55, "828157": 40, "828915": [49, 50], "829": 40, "829162": 66, "829543": 45, "829619": 44, "82985": 51, "83": [66, 67, 68, 69, 98], "8300210": 69, "830301": 57, "830755e": 51, "831": 40, "831019": 45, "831741": 43, "832": 40, "832078": 40, "832086": 58, "8326928": 59, "832693": 59, "832844": 44, "832875": 58, "83287529": 58, "833": 40, "833024": 53, "833117": 43, "833227e": 67, "833464": 55, "833781": 43, "833907": 53, "834": 40, "834842": 56, "8350": 55, "835125": 44, "835596": 55, "835822": 40, "836234": 68, "836515": 44, "837680": 43, "838": 56, "838006e": 44, "838114": 58, "838235": 56, "838457": 55, "83905": 4, "84": [37, 51, 66, 67, 68, 69, 98], "840041": 55, "840303": 58, "84030318": 58, "840630": 43, "840673": 43, "840718": 68, "840836": 58, "840995e": 54, "841": [35, 53], "841132": 54, "8415": 36, "841847": 55, "842132": 68, "842405": 45, "842444": 43, "842589": 40, "842625": 53, "842746": 58, "842770e": 44, "8428": 54, "842853": 58, "842859": 44, "842901": 44, "843730": 53, "843796": 43, "8440": 55, "844308": 58, "844549": [49, 50], "844667": 83, "844707": 58, "844889": 53, "8449790": 69, "845": 69, "845059": 44, "846388": 45, "847555": 43, "847595": [12, 66], "847948": 45, "847966": 55, "848757e": 54, "848868": 45, "849245": 40, "84930915e": 69, "849747": 59, "8497f641": 37, "8499": 55, "85": [21, 45, 51, 55, 58, 61, 66, 67, 68, 69], "8500000000000002": [45, 55, 58], "850321": 53, "850439": 44, "850575": [43, 44], "850794": 58, "851198": 55, "8513": 37, "851366": 53, "852": 55, "85265193": 52, "85280376": [2, 4, 5, 7, 8, 9, 10, 11, 12], "85397773": 68, "855199e": 43, "855780": 58, "856117": 43, "856404": 50, "8571": 34, "857161": 58, "857294": 40, "857544": 53, "857765": 55, "857999": 56, "858579": 44, "859": 55, "85911521e": 69, "85912862": 83, "859129": [70, 83], "85974356": [2, 4, 5, 7, 8, 9, 10, 11, 12], "85c5": 37, "85e": 36, "86": [66, 67, 68, 69, 98], "860261": 44, "860663": [83, 93], "860804": 58, "860992": 55, "862043": [49, 50], "862359": 45, "863687": 43, "863772": 54, "86415573": 36, "86424193e": 69, "8644": 37, "8646627426": 70, "864741e": 55, "865074": 40, "865284": 43, "865313": 55, "8653886": 69, "865540": 44, "865562": [43, 44], "865854": 55, "865860": [54, 55], "866102": [43, 44], "866579": 55, "866798": 55, "8670337521": 62, "867033752141195": 62, "867565": 58, "8679": 55, "868": 37, "8685788": 58, "868579": 58, "8688": 54, "869": 37, "869020": 45, "869136": 44, "869425": 50, "869477": 43, "869586": 51, "869651": 44, "87": [36, 50, 51, 53, 66, 67, 68, 69, 98], "870": 56, "8700": 36, "870099": [49, 50], "870142": 68, "870185": 44, "870260": 58, "870332": 58, "870857": 58, "871": 37, "871887e": 44, "871923": 44, "872222": 55, "872768": 58, "872852": 58, "87290240e": 69, "872994": 55, "873048": 44, "873198": 55, "873677": [49, 50], "87384812361": 34, "87384812362": 34, "873972": 43, "87430335": [83, 93], "874303353": [83, 93], "874702": [49, 50], "8750": 55, "8759": 55, "876080": 43, "876083": 55, "87623301": 34, "876431e": 45, "876549": 55, "87674597e": 69, "8768": 34, "8771": 55, "877153": 55, "877455": 57, "877833": [43, 44], "878281": 58, "878289": 55, "878402": 43, "878847e": 55, "879049": 55, "879103": 45, "87e": 36, "88": [36, 51, 66, 68, 69], "880106": 53, "880202e": 44, "880579": 58, "880591": 57, "880808e": 55, "880880e": 55, "880886": 54, "8810": 54, "881201": 55, "88125046e": 69, "881465": 47, "881581": 8, "88173062": 35, "881937": 40, "882": 56, "882475": 45, "883485": 44, "883622": 58, "883778": 44, "883914": 45, "884132": 58, "8843": 59, "8845": 34, "884996": 45, "8850": 36, "885065": 58, "885978": [49, 50], "886041": 44, "886086": [43, 44], "886266": 55, "88629": 34, "886577": 44, "88664": 37, "886771e": 43, "886777e": 44, "886989": 44, "887197": 40, "887345": 55, "887556": 45, "888146": 53, "8881461": 35, "888775": 50, "888804": 55, "888863e": 43, "889293": 58, "8893": 54, "889300": 54, "889326": 44, "889638": 40, "889733": 58, "88988263e": 69, "889913": [43, 44], "889963": 58, "88ad": 37, "89": [36, 44, 66, 68, 69, 97, 98], "890": [35, 53], "890229": 40, "89027368": [83, 93], "890273683": [83, 93], "89035917": 51, "890372": [38, 64, 96], "8903720000100010000010": [37, 64, 96], "8904": 32, "890454": 67, "8909": [35, 54, 99], "891697": 54, "892": 37, "892331": 44, "892648": 58, "892796": [43, 44], "893": 37, "8932105": 35, "893649": [43, 44], "893851": 58, "894": [32, 37], "894307e": 55, "89449": 54, "894490": 54, "894609e": 43, "895106": [43, 44], "895308": 55, "895333": 58, "895690": [43, 44], "89576062": 69, "895768e": 45, "896023": 58, "896681e": 44, "896758": 43, "897035e": 56, "897220": 58, "897240": 55, "8974": 54, "898722": 58, "89932737": 69, "899460": 58, "899716": 44, "8bdee1a1d83d": 37, "8da924c": 37, "8e3aa840": 37, "9": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 96, 98, 99], "90": [22, 36, 45, 46, 55, 58, 61, 66, 68, 69, 98], "9000000000000002": [45, 55, 58], "900000e": 55, "900021": 67, "901013": 44, "901148": 58, "90136": 54, "901360": 54, "901526": 51, "901683": 55, "902": [83, 93], "902573": 45, "903056e": 58, "903135": 66, "903339": 45, "903351e": 45, "903406": 68, "903418": 53, "903681": 58, "903767": [43, 44], "904156": 45, "9041560442482157": 45, "904315": 43, "905": 56, "905042": 44, "905494": 45, "905858": 60, "905951": 59, "905998": 50, "906073": 44, "9061": 55, "9061913": 69, "906716732639898": [49, 50], "906757": 41, "906864": 43, "907115": 58, "907130": 43, "907176": 58, "907198": 44, "9073": 55, "907491": 45, "907702": 43, "907801": 53, "90794478": [83, 93], "907944783": [83, 93], "907961": 55, "908024": 60, "908620": 43, "9088312": 69, "909141": 44, "909304": [43, 44], "90963122e": 69, "909752": 44, "909942e": 66, "909975": 55, "909997": [54, 99], "91": [66, 67, 68, 69, 98], "910000e": 55, "9102": 54, "910895": 44, "9109": 37, "910991": 43, "91102953": 58, "911030": 58, "911662": 49, "912230": [43, 44], "9126": [36, 99], "9127": [36, 99], "913": 37, "91315015": 35, "913280": 60, "913285": 43, "913485": 55, "913774": 45, "9142": 55, "91438767e": 69, "9145": 34, "915": [36, 37, 54, 55], "915000e": [54, 55], "915057e": 54, "915488": [49, 50], "916236": 34, "916528": 49, "9166667": 37, "916806": 44, "916914": 58, "917": 37, "917066": 55, "917248": 58, "91724807": 58, "917436": 58, "918104": 43, "918227": 45, "918747": 44, "919432": 58, "9197": 55, "919814": 43, "91e": 36, "92": [66, 68, 69, 98], "920335": 55, "920337": 50, "920439": 43, "920645": 55, "9209": 34, "9210": 55, "921061": 60, "9213175": 69, "921372": 45, "921913": 53, "921956": [43, 44], "921e4f0d": 37, "922160": 55, "922201e": 43, "9223": 55, "922996": 53, "923": 40, "923074e": 45, "923517": 61, "923607": 58, "92369755": 35, "923804": 45, "923943": 99, "923977": 55, "924": 40, "924002": 58, "9243": 55, "924396": [49, 50], "92463": 54, "924630": 54, "924634": 47, "9248": 37, "924821": 45, "924843": 53, "924921": 66, "925": [40, 46], "925248": [49, 50], "925660": 43, "925736": 45, "925957": 49, "926": [32, 40, 56], "926493": 54, "926621": 45, "927": 33, "927074": 58, "927232": 55, "9274": 55, "927950": 55, "92827999": 68, "928611": 56, "92881435e": 69, "928947": 53, "92905": 35, "929363": 43, "929552": 43, "929598": 44, "92972925e": 83, "929729e": [70, 83], "93": [36, 66, 67, 68, 69, 98], "9304028": 35, "930417": 43, "931": 63, "931479": 58, "931507": 43, "931978": 96, "932027": 45, "932404e": 55, "9325": 34, "9327": 34, "932973": 58, "933028": 56, "9331580": 69, "933259": 40, "933322": 44, "933996": 45, "934068": 40, "934433": [43, 44], "9345": 37, "934511": [83, 93], "934549": 55, "93458": 59, "934992": 45, "935": 52, "935591": 58, "935730": 58, "935989": 53, "9359891": 35, "93648": 61, "936739": 58, "937116": 53, "937586": 55, "937857": 43, "938": [83, 93], "938975": [66, 67], "939068": [49, 50], "9392": 55, "939250": 43, "9395": 55, "93958082416": 99, "94": [46, 52, 66, 68, 69, 98, 99], "940354721701296": 45, "940355": 45, "940373": 55, "940450": 40, "941440": 43, "941724": 55, "941788": 49, "942139": 50, "942312": 58, "942460e": 58, "942489": 55, "9425": 34, "942550": 55, "942661": 53, "942823": 55, "943": 99, "94309994e": 69, "943200": 43, "943270": 43, "943465e": 43, "943938": 58, "943949e": 58, "944149": 66, "944253e": 58, "944266": [49, 50], "944280": 55, "94441007e": 69, "944839": 40, "945402e": 43, "945417": 43, "945881": 43, "94629": 61, "946297": 45, "946406": 50, "946433": 58, "946533": 43, "946658": 55, "946968": 45, "947": 99, "947440": 57, "947466": 67, "947613": 44, "9480": 55, "948154e": 49, "948344e": 44, "948868": 55, "94906344": 35, "949241": [83, 93], "949456": 58, "949866": 44, "95": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 36, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 58, 59, 60, 61, 66, 68, 69, 83, 84, 89, 98, 99], "9500": 55, "950131e": 44, "950545": 41, "95062986e": 69, "951115": 44, "951415": 43, "951502": 58, "951532": 53, "951550": 44, "951920": 57, "952": [32, 36, 99], "9523": 34, "952839": 58, "9534": 55, "953683": 53, "95372559e": 69, "954": [83, 93], "95401167e": 69, "954536": 66, "955005e": 55, "9551": 55, "9552": 34, "955541": [13, 66], "95559917": 67, "955701": 43, "955926": 44, "956": 69, "956047": 35, "9561": 34, "956110": 44, "956217": 43, "956574": 55, "956724": 45, "9567242535070148": 45, "956892": 55, "957375": 53, "957437": 43, "957745": 45, "9579": 36, "957996": 45, "958": [56, 83, 93, 99], "9580": 36, "958105": 66, "958541": 55, "959132": 44, "95e": [36, 69], "96": [36, 43, 44, 56, 66, 68, 69, 98], "960074": 43, "9605": 55, "960808": 45, "960875e": 44, "9609": 34, "961360": 44, "961539": 55, "961962": 45, "962523": 40, "963": 32, "963051": 44, "963055": 55, "963389": 43, "964025e": 58, "964261e": 53, "964318": 55, "9647": 34, "965341": 44, "965531": 68, "965696": 43, "965774": 55, "96582": 67, "966015": 58, "966320": 40, "966659": 45, "9666592590622916": 45, "967467": 59, "968134e": 58, "968577": 46, "968800": 43, "969141": 68, "9699": 54, "97": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 66, 67, 68, 69, 70, 83, 93, 96, 98, 99], "970065": 58, "971058": [49, 50], "971724": 43, "972088e": 43, "972509": 44, "972732": 44, "972748": 45, "97276281": 58, "972763": 58, "973": 56, "97314470": 35, "973156": 66, "973229": 44, "973241": 58, "973262": 43, "973331": 55, "973392e": 43, "973741": 44, "974202": 45, "974213": 44, "97441062": [49, 50], "974414": 45, "97470872": 59, "9748910611": 35, "975": [43, 44, 49, 50, 52, 56], "975232": 44, "9753": 37, "975447": 46, "975450": 44, "975461": 53, "975957e": 44, "976088": 58, "976562": 58, "977280": [43, 44], "977295": 55, "977507": 44, "978554": 43, "9787": 55, "978977": 58, "978997": 40, "979": [32, 56], "979857": 43, "979896": 44, "98": [43, 44, 55, 66, 68, 69, 98], "980026": 55, "9802393": 35, "980256e": 43, "980643e": 45, "980768161": 69, "981104": 57, "981438": 43, "981672": 45, "982353e": 55, "982417": 45, "982720": 43, "982797": 57, "982986e": 43, "983192": 58, "983253": 43, "983759": 99, "983896": 43, "98393441": 59, "984024": 57, "984083": [49, 50], "984551": 7, "984562": 58, "984821": 43, "984866": [83, 93], "984872": [43, 44], "984937": 45, "98505871e": 69, "985207": [43, 44], "986": 56, "986383": 55, "986417": 43, "9870004": 37, "987220": 55, "987329": 44, "9875": 34, "9880384": 37, "988421": [43, 44], "988463": 58, "988690": 44, "988709": 55, "988780": 55, "989291": 43, "989883": 56, "99": [36, 40, 43, 44, 56, 66, 68, 69, 98], "990210": 55, "990219": 56, "990377": 44, "991": [37, 56], "9914": [54, 55, 59], "991444e": 49, "9915": [36, 54, 55, 59], "991512": 36, "991539": 44, "991963": [43, 44], "991977": 55, "991988": 43, "99232145": 59, "992582": [43, 44], "993": 56, "993201": 44, "993575": 55, "994168239": 35, "994208": 40, "994214": 55, "994332": 41, "994377": 43, "9944": [52, 68], "994851": 55, "994937": 50, "995": 56, "995015": 55, "9951": 34, "995248": 58, "99549118e": 69, "99571372e": 69, "9961392": 35, "996454": 44, "996934": 53, "996946": 44, "997": 56, "9970": 55, "997034": 61, "997494": 61, "997571": 53, "997621": 45, "997934": [49, 50], "998063": 41, "99864670889": 99, "998766": 55, "9989": 54, "999": [46, 47, 51, 59, 99], "999207": 58, "9995": [43, 44, 47], "9996": [43, 44, 47], "9996553": 36, "9997": [43, 44, 47], "9998": [43, 44, 47], "9999": [43, 44, 47], "99c8": 37, "A": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 21, 25, 29, 30, 32, 33, 34, 36, 37, 41, 42, 48, 50, 56, 57, 59, 60, 63, 64, 66, 67, 68, 83, 84, 85, 86, 90, 91, 92, 93, 94, 96, 97, 99], "ATE": [8, 16, 36, 38, 40, 54, 59, 60, 66, 68, 70, 76, 84, 90], "ATEs": [40, 56], "And": [56, 61, 84, 87], "As": [33, 34, 35, 36, 37, 40, 42, 43, 44, 45, 46, 48, 51, 52, 53, 54, 55, 56, 58, 60, 61, 62, 67, 69, 70, 72, 83, 84, 86, 92, 93, 99], "At": [16, 17, 18, 35, 40, 46, 47, 51, 52, 53, 55, 58, 99], "Being": 99, "But": 52, "By": [34, 35, 53, 60, 67, 84, 89], "For": [4, 5, 7, 8, 11, 18, 27, 28, 32, 34, 35, 37, 40, 41, 46, 51, 52, 53, 55, 57, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 90, 92, 93, 95, 96, 99], "ITE": 40, "ITEs": 40, "If": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 33, 35, 42, 43, 44, 46, 52, 53, 55, 63, 64, 66, 67, 68, 70, 71, 73, 74, 76, 83, 84, 86, 87, 88, 89, 91, 92, 94, 99], "In": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99], "It": [34, 35, 36, 43, 44, 48, 49, 50, 53, 54, 55, 60, 67, 69, 94, 98], "No": [20, 32, 34, 36, 37, 38, 40, 46, 51, 54, 55, 59, 61, 64, 67, 68, 70, 83, 96, 97], "Of": [52, 83, 99], "On": [33, 42, 56, 63, 97], "One": [36, 54, 55, 60, 66, 83], "Such": [60, 67], "That": 99, "The": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 34, 35, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 76, 79, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 97, 98, 99], "Then": [18, 45, 58, 83, 84, 92, 93, 94, 95], "There": [36, 54, 60, 95, 99], "These": [36, 37, 39, 54, 57, 59, 66, 99], "To": [28, 32, 33, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 66, 67, 69, 83, 84, 86, 89, 92, 93, 95, 96, 99], "With": [21, 43, 44, 67, 97], "_": [33, 35, 42, 43, 44, 45, 47, 48, 49, 50, 53, 54, 55, 57, 58, 62, 63, 66, 69, 70, 83, 84, 86, 89, 93], "_0": [33, 35, 42, 48, 53, 62, 63, 69, 70, 78, 79, 83, 84, 92], "_1": [16, 17, 18, 56, 61, 70, 78, 79], "_2": [16, 17, 18, 56], "_3": [16, 17, 18], "_4": [16, 17, 18], "_5": 16, "__": 40, "__call__": 40, "__version__": [40, 95], "_all_coef": 69, "_all_s": 69, "_compute_scor": 28, "_compute_score_deriv": 28, "_coordinate_desc": 53, "_est_causal_pars_and_s": 98, "_i": [33, 42, 58, 61, 63], "_id": 69, "_ipython_display_": 40, "_j": [16, 17, 18, 23, 35, 53, 83, 93], "_l": 67, "_m": [67, 69], "_n": [70, 73, 74, 76, 83, 84, 89, 91, 93], "_n_folds_per_clust": 53, "_render": 40, "_rmse": [2, 4, 5, 7, 8, 9, 10, 11, 12], "a09a": 37, "a09b": 37, "a3d9": 37, "a4a147": 56, "a5e6": 37, "a5e7": 37, "a6ba": 37, "a79359d2da46": 37, "a840": 37, "a_": [40, 61], "a_0": 24, "a_1": 24, "a_i": 40, "a_j": [40, 68], "ab": [34, 94], "ab71": 37, "abadi": [14, 46], "abb0fd28": 37, "abdt": [38, 64, 96], "abl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 42, 52, 55, 56, 67, 84, 86, 92], "about": [36, 52, 54, 94, 96, 99], "abov": [33, 36, 42, 43, 44, 49, 50, 52, 54, 56, 57, 58, 60, 63, 66, 67, 68, 95], "absolut": [2, 4, 5, 7, 8, 9, 10, 11, 12, 52, 67], "abstract": [28, 34, 35, 53, 70, 94, 98], "acc": 34, "accept": [66, 67], "access": [29, 30, 34, 36, 49, 50, 51, 52, 59, 67, 84, 89, 99], "accord": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 36, 40, 42, 45, 46, 54, 58, 60, 61, 67, 83, 84, 85, 87, 88, 90, 93, 99], "accordingli": [46, 52, 54, 61], "account": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 36, 53, 54, 55, 59, 60, 84, 89, 92, 99], "accumul": [36, 54, 55, 59], "accuraci": 34, "acemoglu": 97, "achiev": [35, 53, 57, 60, 83, 93], "acic_2024_post": 56, "acknowledg": [36, 37, 54], "acm": 97, "acov": 97, "across": [36, 54, 56, 99], "action": 98, "activ": [3, 6, 95, 98], "actual": [51, 60], "acycl": [61, 99], "ad": [3, 6, 14, 15, 28, 51, 64, 67, 83, 84, 86, 98], "adapt": [7, 54, 98], "add": [34, 35, 38, 40, 46, 47, 49, 50, 51, 56, 58, 59, 60, 61, 67, 97, 98], "add_trac": 60, "addit": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 23, 24, 25, 48, 60, 67, 68, 70, 77, 84, 85, 90, 92, 97, 98], "addition": [16, 17, 40, 45, 55, 59, 67, 68, 69, 83, 84, 89, 96], "address": 60, "adel": 97, "adj": 60, "adj_coef_bench": 60, "adj_est": 60, "adj_vanderweelearah": 60, "adjust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 47, 53, 55, 59, 60, 66, 83, 84, 89, 93, 99], "adopt": [46, 68], "advanc": [65, 69, 97], "advantag": [33, 34, 36, 40, 42, 54, 55, 63, 95], "advers": [84, 86], "adversari": [2, 4, 5, 7, 8, 9, 10, 11, 12, 59, 84, 89, 92], "ae": [33, 35, 36], "ae56": 37, "ae89": 37, "aesthet": 33, "aeturrel": 25, "afd9e4": 56, "affect": [40, 48, 68, 98, 99], "after": [34, 36, 37, 46, 48, 54, 55, 60, 61, 66, 67, 84, 87, 89, 95, 99], "after_stat": 33, "ag": [36, 54, 55, 57, 59, 99], "again": [33, 34, 35, 36, 40, 42, 46, 51, 53, 54, 59, 60, 61, 63, 84, 87], "against": [46, 51, 52, 57, 67], "agebra": 66, "agegt54": [37, 38, 64, 96], "agelt35": [37, 38, 64, 96], "agg": 34, "aggreg": [34, 62, 69, 98], "aggt": 34, "aipw": 56, "aipw_est_1": 56, "aipw_est_2": 56, "aipw_obj_1": 56, "aipw_obj_2": 56, "air": [35, 53], "al": [14, 15, 19, 21, 23, 24, 33, 35, 36, 37, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 58, 59, 63, 68, 69, 70, 72, 77, 82, 83, 84, 86, 92, 93, 94, 96, 98], "alexandr": [48, 97], "algorithm": [32, 34, 35, 37, 40, 42, 45, 46, 52, 53, 55, 58, 59, 61, 65, 67, 68, 69, 70, 83, 98, 99], "align": [33, 35, 42, 45, 47, 52, 53, 54, 56, 57, 58, 61, 98], "all": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 31, 33, 34, 35, 36, 40, 42, 46, 51, 52, 53, 54, 55, 57, 60, 61, 63, 64, 66, 67, 68, 69, 83, 84, 92, 93, 94, 95, 98], "all_coef": 69, "all_dml1_coef": 62, "all_s": 69, "all_smpl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "all_smpls_clust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "all_z_col": [35, 53], "allow": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 28, 36, 40, 54, 55, 66, 67, 68, 69, 70, 83, 93, 94, 98, 99], "almqvist": 97, "along": 67, "alpha": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 22, 24, 33, 35, 36, 38, 40, 42, 43, 44, 45, 48, 52, 53, 54, 55, 58, 62, 63, 66, 67, 68, 69, 70, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93], "alpha_": [23, 35, 53, 67], "alpha_0": [84, 92], "alpha_ml_l": 48, "alpha_ml_m": 48, "alpha_x": [7, 20, 68], "alreadi": [18, 46, 61, 67, 68], "also": [4, 5, 7, 8, 11, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 46, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 63, 66, 67, 69, 70, 83, 84, 86, 95, 96, 98, 99], "alter": [35, 53], "altern": [34, 36, 37, 54, 57, 65, 67, 83, 93, 94, 95, 96], "although": 60, "alwai": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 98], "always_tak": [7, 36, 54], "amamb": 53, "american": [22, 56], "amgrem": 53, "amhorn": 53, "amit": [60, 97], "amjavl": 53, "ammata": 53, "among": [36, 48, 54, 55, 59, 60], "amount": [36, 54, 55, 99], "amp": [32, 35, 37, 46, 53, 55, 59, 61], "an": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 29, 30, 33, 34, 35, 36, 37, 40, 42, 43, 44, 48, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 83, 84, 86, 89, 93, 94, 95, 96, 97, 98, 99], "anaconda3": 40, "analog": [27, 28, 35, 53, 55, 59, 66, 68, 70, 73, 74, 83, 84, 89, 93], "analys": 99, "analysi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 35, 36, 42, 53, 54, 55, 63, 65, 66, 86, 89, 92, 94, 98], "analyt": [56, 58], "analyz": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 36, 54, 55, 59, 99], "ancillari": 60, "andrea": 97, "angl": 36, "angrist": 56, "ani": [32, 33, 34, 37, 41, 42, 46, 60, 61, 63, 95, 99], "anna": [4, 5, 16, 17, 18, 34, 46, 68, 97], "annal": [83, 93, 97], "anneal": 67, "annot": 33, "annual": 97, "anoth": [33, 34, 35, 36, 42, 52, 53, 63, 67, 68], "anticip": 34, "anymor": [35, 53], "aos1161": [83, 93], "aos1230": [83, 93], "aos1671": [83, 93], "ap": [36, 54], "ape_e401_uncond": 36, "ape_p401_uncond": 36, "api": [64, 94, 98], "apo": [71, 85], "apoorva": 98, "apoorva__l": 56, "apoorval": 56, "app": 98, "appeal": 60, "append": [42, 52, 63], "appendix": [21, 26, 59, 61, 84, 86], "appli": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 32, 33, 35, 36, 37, 42, 46, 47, 52, 53, 54, 55, 60, 61, 63, 68, 69, 70, 83, 93, 94, 96, 98, 99], "applic": [33, 42, 46, 56, 60, 63, 66, 69, 97, 99], "apply_along_axi": 57, "apply_cross_fit": [33, 69], "apply_crossfit": 98, "appreci": 94, "approach": [2, 4, 5, 7, 8, 9, 12, 13, 34, 35, 40, 53, 59, 60, 65, 67, 69, 83, 84, 86, 93, 95, 97, 99], "appropri": [36, 48, 54, 69, 99], "approx": 66, "approxim": [33, 42, 43, 44, 45, 52, 58, 60, 63, 66, 83, 93, 98, 99], "apt": 95, "ar": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 24, 25, 27, 28, 29, 30, 33, 34, 35, 36, 37, 39, 40, 42, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99], "arang": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 42, 45, 47, 55, 57, 58, 59, 60, 67], "architectur": [70, 97], "arellano": 97, "arg": 66, "argmin": 52, "argu": [33, 36, 42, 54, 55, 59, 63, 99], "argument": [18, 23, 24, 25, 36, 43, 44, 46, 51, 52, 54, 55, 62, 66, 67, 68, 99], "aris": [33, 34, 35, 42, 53, 60, 63, 99], "aronow": 56, "around": [34, 36, 54, 55, 70], "arr": 57, "arrai": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 20, 21, 22, 23, 24, 25, 26, 40, 42, 43, 44, 45, 46, 52, 53, 56, 57, 59, 60, 61, 62, 63, 65, 66, 67, 69, 83, 84, 89, 93, 96, 98, 99], "arrang": 35, "array_lik": 13, "articl": [25, 94], "arxiv": [23, 34, 35, 53, 60, 94, 97, 98], "as_learn": [37, 67], "asarrai": [43, 44], "aspect": [36, 54, 55], "assert": 67, "assess": 34, "asset": [55, 59, 99], "assign": [3, 6, 36, 50, 54, 66, 67, 68, 99], "assmput": 68, "associ": [36, 48, 54, 68, 83, 93, 97], "assum": [32, 35, 41, 46, 53, 56, 57, 60, 68, 70, 73, 74, 83, 84, 92, 99], "assumpt": [34, 35, 36, 46, 47, 52, 53, 54, 56, 61, 68, 83, 99], "assur": 98, "astyp": [41, 54, 60], "asymptot": [27, 28, 33, 35, 42, 53, 63, 69, 83, 97], "ate": 40, "ate_estim": 61, "ates": 40, "athei": 97, "att": [8, 16, 34, 47, 51, 57, 60, 66, 68, 70, 76, 84, 90, 98], "att_gt": 34, "attach": 34, "atte_estim": 46, "attempt": [29, 30], "attenu": [36, 54], "attr": 36, "attribut": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 52, 62, 67, 69, 70, 83], "attributeerror": [29, 30], "attrict": 68, "attrit": [61, 68], "au": [37, 67, 94, 96], "auc": 34, "author": [34, 60, 94], "automat": [33, 42, 51, 63, 66, 84, 89], "automobil": [35, 53], "autos": 48, "auxiliari": [33, 42, 63], "avail": [20, 34, 36, 37, 40, 46, 48, 52, 54, 55, 56, 57, 60, 63, 66, 67, 68, 84, 92, 94, 95, 98, 99], "aver": 40, "averag": [7, 8, 11, 16, 17, 18, 32, 34, 37, 41, 46, 47, 51, 55, 56, 57, 59, 60, 61, 65, 71, 76, 83, 85, 90, 97, 99], "average_it": 40, "avoid": [33, 34, 42, 69, 95, 98], "awai": 59, "ax": [40, 42, 43, 44, 45, 47, 49, 50, 52, 53, 54, 55, 56, 58], "ax1": [40, 45, 55, 58], "ax2": [40, 45, 55, 58], "axhlin": 47, "axi": [35, 36, 40, 48, 52, 53, 54, 56, 57], "axvlin": [40, 42], "b": [4, 5, 25, 33, 35, 37, 42, 43, 44, 53, 56, 58, 60, 63, 66, 67, 83, 84, 92, 93, 94, 96, 97], "b208": 37, "b371": 37, "b5d34a6f42b": 37, "b5d7": 37, "b_0": 24, "b_1": 24, "b_j": 25, "bach": [60, 94, 97, 98], "backbon": 52, "backend": [3, 6, 34, 55, 59, 60, 65, 98], "backward": 98, "bad": 56, "balanc": [36, 54, 55], "band": [34, 65, 99], "bandwidth": [9, 12, 13], "bar": [51, 54, 66, 70, 71, 76, 84, 85], "base": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 19, 33, 34, 35, 36, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 83, 84, 86, 89, 93, 94, 96, 97, 98, 99], "basedatatyp": 40, "basefigur": 40, "baselin": [36, 54], "basi": [1, 8, 11, 43, 44, 66], "basic": [34, 35, 36, 46, 53, 54, 55, 56, 59, 60, 65, 67], "batch": 37, "battocchi": 97, "bay": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 83, 93], "bb2913dc": 37, "bbotk": [37, 67, 98], "bbox_inch": 42, "bbox_to_anchor": 42, "bcallaway11": 34, "bd929a9e": 37, "bde4": 37, "becam": [36, 54, 55], "becaus": [32, 33, 34, 35, 41, 42, 50, 51, 53, 56, 60, 63, 99], "becker": [37, 67], "becom": [35, 50, 53, 66, 69], "bee": 47, "been": [35, 36, 53, 54, 55, 59, 60, 66, 67, 98], "befor": [34, 36, 40, 47, 51, 54, 58, 60, 68, 99], "begin": [20, 22, 23, 33, 35, 36, 37, 42, 45, 47, 52, 53, 54, 56, 57, 58, 61, 62, 64, 67, 69, 83, 93, 96, 99], "behav": 50, "behavior": [36, 56, 67], "behaviour": 50, "being": [26, 27, 28, 35, 53, 60, 69, 70, 72, 83, 84, 89, 93, 94], "belloni": [21, 48, 83, 93, 97], "below": [32, 36, 41, 54, 56, 95, 96], "bench_x1": 60, "bench_x2": 60, "benchmark": [2, 4, 5, 7, 8, 9, 10, 11, 12, 31, 40, 51, 86, 98], "benchmark_dict": [31, 59], "benchmark_inc": 59, "benchmark_pira": 59, "benchmark_result": [2, 4, 5, 7, 8, 9, 10, 11, 12], "benchmark_twoearn": 59, "benchmarking_set": [2, 4, 5, 7, 8, 9, 10, 11, 12, 40, 51, 59, 60, 84, 86], "benchmarking_vari": 51, "benefit": [33, 36, 42, 54, 63], "bernoulli": 20, "berri": [35, 53], "besid": 96, "best": [1, 8, 11, 43, 44, 49, 50, 95], "beta": [20, 21, 22, 26, 36, 54, 57, 61], "beta_": 61, "beta_0": [19, 57, 61, 66], "beta_a": [16, 17, 60], "beta_j": [20, 21, 22, 26], "better": [34, 40, 52, 60], "between": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 40, 41, 45, 47, 48, 56, 58, 59, 60, 61, 68, 70, 73, 74, 76, 80, 81, 83, 84, 92, 93, 96, 98], "betwen": [32, 41], "beyond": 97, "bia": [26, 32, 41, 48, 60, 61, 65, 68, 69, 70, 78, 79, 84, 92, 97, 98], "bias": [32, 36, 41, 54, 55, 59, 99], "bias_bench": 60, "bibtex": 94, "big": [48, 62, 69, 70, 74, 77, 83, 84, 87, 88, 90, 91, 92], "bigg": [35, 53, 70, 75, 76, 84, 90], "bilia": 15, "bin": [33, 40, 42, 95], "binari": [2, 4, 5, 7, 8, 9, 11, 12, 19, 32, 34, 36, 37, 41, 46, 51, 52, 54, 56, 57, 60, 66, 67, 84, 85, 90, 98, 99], "binary_treat": [19, 43, 49, 51], "bind": 98, "binder": [37, 67, 94, 96, 98], "binomi": [41, 56, 57, 58], "bischl": [37, 67, 94, 96], "black": [33, 37, 38, 64, 96], "blob": 34, "blog": 25, "blondel": [94, 96], "blp": [1, 35, 53], "blp_data": [35, 53], "blp_model": [49, 50], "blue": [33, 35, 53], "bodori": 97, "bond": [36, 54, 55], "bonferroni": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 83, 93], "bonu": [15, 37, 64, 96], "book": [37, 60, 67], "bool": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 19, 29, 30, 51], "boolean": [26, 49, 50, 64, 69], "boost": [32, 36, 41, 46, 52, 54], "boost_class": [36, 54], "boost_summari": 54, "boostrap": [45, 98], "bootstrap": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 43, 44, 45, 49, 50, 55, 58, 65, 66, 69, 70, 94, 96, 98, 99], "both": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 17, 19, 34, 36, 37, 46, 47, 52, 54, 55, 57, 59, 60, 64, 67, 83, 84, 86, 89, 91, 92, 98, 99], "bottom": [35, 36, 52, 53, 54, 55], "bound": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 40, 51, 54, 59, 60, 84, 86, 89, 92, 99], "branch": 37, "brantli": 34, "break": [33, 98], "breviti": 99, "brew": 95, "brewer": 35, "bridg": 60, "brief": 63, "bring": [32, 41], "brucher": [94, 96], "bsd": 98, "budget": 67, "bug": [94, 98], "build": [35, 52, 53, 57], "build_design_matric": [43, 44], "build_sim_dataset": 34, "built": [67, 94], "bundl": 40, "bureau": [60, 69, 97], "busi": [23, 26, 35, 53, 60, 97], "b\u00fchlmann": 97, "c": [14, 15, 17, 18, 21, 22, 24, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 47, 48, 49, 50, 53, 54, 56, 63, 64, 67, 94, 95, 96, 97, 99], "c1": [14, 15, 24, 35, 48, 53, 63, 94, 97], "c68": [14, 15, 24, 35, 48, 53, 63, 94, 97], "c895": 37, "c_": [83, 93], "c_d": [21, 84, 90, 91, 92], "c_y": [21, 84, 92], "ca1af7be64b2": 37, "caac5a95": 37, "calcualt": 57, "calcul": [8, 11, 34, 36, 40, 43, 44, 45, 49, 50, 52, 54, 58, 59, 84, 89, 92], "calibr": [52, 60], "call": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 34, 35, 36, 37, 40, 41, 43, 44, 45, 46, 49, 50, 53, 54, 55, 57, 58, 59, 60, 61, 64, 67, 69, 70, 83, 84, 89, 92, 93, 95, 96, 98, 99], "callabl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 42, 43, 44, 52, 65, 67, 94], "callawai": 34, "camera": 48, "cameron": [35, 53], "can": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 19, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 74, 76, 80, 81, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99], "candid": 60, "cannot": [52, 60, 99], "capabl": [3, 6, 32, 41], "capsiz": [40, 56], "capthick": 40, "cardin": [35, 53], "care": 67, "carlo": [16, 17, 19, 43, 44, 49, 50, 60, 97], "casalicchio": [37, 67, 94, 96], "case": [3, 6, 7, 8, 15, 19, 32, 35, 36, 41, 43, 44, 45, 48, 50, 51, 53, 57, 58, 59, 60, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 96, 98, 99], "cat": [33, 98], "catboost": 52, "cate": [1, 8, 11, 65, 98], "cate_obj": 66, "caus": [33, 42, 63], "causal": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 20, 21, 22, 23, 24, 25, 26, 32, 33, 35, 36, 37, 41, 42, 53, 54, 56, 59, 61, 62, 63, 64, 65, 68, 69, 83, 84, 89, 93, 97], "causal_contrast": [40, 68], "causal_contrast_model": [40, 68], "causaldml": 97, "causalweight": 97, "caution": 83, "caveat": [50, 60], "cbind": 35, "cc": 54, "ccp_alpha": [8, 54], "cd": 95, "cd_fast": 53, "cda85647": 37, "cdf": 66, "cdid": [35, 53], "cdot": [16, 17, 18, 35, 45, 47, 51, 53, 56, 58, 60, 66, 68, 70, 71, 76, 77, 78, 79, 83, 84, 85, 93], "cdot1": 51, "center": 48, "central": [69, 98], "certain": 50, "cexcol": 35, "cexrow": 35, "cf_d": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 31, 40, 51, 59, 60, 84, 85, 86, 89, 90, 91, 92, 99], "cf_y": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 31, 40, 51, 59, 60, 84, 85, 86, 89, 90, 91, 92, 99], "chad": 60, "chain": 50, "chainedassignmenterror": 50, "challeng": [35, 53, 84, 86], "chang": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 46, 50, 55, 59, 60, 61, 70, 76, 83, 84, 85, 86, 87, 88, 89, 90, 95, 97, 98], "channel": 99, "chapter": [27, 28, 37, 67, 84, 92], "charact": [36, 37, 67, 98], "characterist": [59, 99], "check": [29, 30, 33, 36, 42, 52, 54, 55, 62, 63, 94, 95, 98], "check_data": 98, "check_scor": 98, "checkmat": 98, "chernozhukov": [14, 15, 21, 22, 24, 33, 35, 36, 42, 48, 52, 53, 54, 55, 59, 63, 69, 83, 84, 86, 92, 93, 94, 97, 98], "chetverikov": [14, 15, 24, 35, 48, 53, 63, 83, 93, 94, 97], "chiang": [23, 35, 53, 97], "chieh": 97, "choic": [2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 36, 48, 54, 57, 66, 67, 84, 86, 89, 92, 98], "choos": [32, 36, 41, 42, 48, 52, 54, 55, 62, 69, 70, 73, 74, 76, 80, 81, 83, 93, 96, 99], "chosen": [17, 52, 67], "chou": 56, "chr": 36, "christian": [48, 97], "chunk": 67, "ci": [2, 4, 5, 7, 8, 9, 10, 11, 12, 40, 43, 44, 45, 46, 47, 49, 50, 51, 54, 55, 58, 59, 60, 66, 84, 89, 98, 99], "ci_at": 40, "ci_cvar": [45, 55], "ci_cvar_0": 45, "ci_cvar_1": 45, "ci_joint_cvar": 45, "ci_joint_lqt": 58, "ci_joint_qt": 58, "ci_length": 46, "ci_low": 40, "ci_lpq_0": 58, "ci_lpq_1": 58, "ci_lqt": [55, 58], "ci_pointwis": 40, "ci_pq_0": [55, 58], "ci_pq_1": [55, 58], "ci_qt": [55, 58], "ci_upp": 40, "cinelli": [60, 84, 86, 97], "circumv": 99, "citat": 98, "claim": 37, "clash": 34, "class": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 27, 28, 29, 30, 36, 37, 38, 40, 46, 51, 54, 55, 59, 61, 62, 64, 66, 67, 69, 70, 83, 94, 96, 98], "class_learn": 55, "class_learner_1": 52, "class_learner_2": 52, "classic": [34, 35, 53, 99], "classif": [8, 32, 34, 36, 37, 52, 57, 59, 66, 67, 68, 99], "classifavg": 37, "classifi": [2, 4, 5, 7, 8, 9, 11, 12, 13, 29, 37, 40, 67, 98], "classmethod": [3, 6], "claus": 98, "clean": 98, "cleaner": 52, "cleanup": 98, "clear": [35, 53], "clever": 52, "clone": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 37, 42, 52, 53, 55, 62, 67, 68, 69, 70, 83, 84, 89, 93, 95, 96], "close": [34, 36, 54, 60, 84, 86], "cluster": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 23, 97, 98], "cluster_col": [3, 35, 53], "cluster_var": [3, 23], "cluster_var_i": [3, 35, 53], "cluster_var_j": [3, 35, 53], "cmap": 53, "cmd": 98, "co": [25, 47], "codaci": 98, "code": [8, 11, 25, 32, 34, 35, 36, 37, 41, 48, 54, 63, 66, 67, 68, 69, 70, 83, 95, 96, 98, 99], "codecov": 98, "coef": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 66, 67, 68, 69, 70, 83, 96, 99], "coef_": 60, "coef_df": 35, "coeffici": [1, 16, 17, 19, 36, 49, 50, 52, 54, 56, 57, 60, 61, 66, 83, 84, 89, 93, 99], "coefs_t": 57, "coefs_w": 57, "coffici": [84, 89], "cofid": 1, "coincid": [47, 55], "col": [33, 35, 50, 54], "collect": [37, 46, 53, 61], "colnam": [35, 52], "color": [36, 40, 42, 43, 44, 45, 47, 53, 54, 55, 56, 58, 60], "color_palett": [40, 42, 53, 54, 55], "colorbar": 53, "colorblind": 40, "colorramppalett": 35, "colorscal": [43, 44], "colour": [33, 35], "column": [3, 6, 38, 40, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 64, 66, 67, 69, 96, 98, 99], "column_stack": [40, 47, 49, 50, 59, 60], "colv": 35, "com": [25, 34, 36, 37, 48, 54, 56, 60, 67, 95], "comb": 48, "combin": [34, 35, 37, 40, 46, 52, 53, 60, 67, 69, 84, 89, 98], "combind": 55, "combined_loss": 48, "come": [62, 67, 70, 84, 86, 94, 99], "command": [95, 98], "comment": 64, "common": [52, 59, 60, 66, 68, 97], "companion": 97, "compar": [33, 35, 42, 43, 44, 45, 47, 49, 50, 53, 56, 58, 60, 63, 67, 84, 86], "comparevers": 36, "comparison": [40, 52, 56], "compat": [32, 34, 41, 98], "complement": 60, "complet": [63, 84, 89, 95], "complex": [8, 34], "complianc": [58, 70, 77], "complic": [37, 99], "complier": [36, 54, 55, 58, 66], "compon": [34, 36, 48, 52, 54, 57, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 80, 81, 98], "compont": 34, "composit": 97, "compris": [83, 93], "comput": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 31, 33, 34, 36, 37, 42, 54, 55, 59, 60, 69, 70, 84, 85, 86, 87, 88, 89, 90, 94, 97, 98, 99], "computation": [84, 86], "concat": [53, 54, 57, 83], "concaten": [47, 54, 83], "concentr": 83, "concern": 60, "conclud": [60, 99], "cond": 68, "conda": [53, 97, 98], "condit": [2, 8, 11, 16, 17, 19, 27, 28, 33, 35, 36, 42, 46, 47, 51, 53, 54, 57, 60, 61, 63, 65, 68, 83, 84, 85, 90, 92, 93, 96, 97, 98, 99], "conduct": [66, 68, 99], "conf": [34, 58], "confer": 97, "confid": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 40, 43, 44, 45, 46, 49, 50, 53, 55, 58, 59, 61, 65, 66, 69, 70, 84, 89, 96, 97, 99], "confidenceband": 45, "confidenti": 60, "config": 56, "configur": 37, "confint": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 36, 40, 43, 44, 45, 46, 47, 49, 50, 52, 55, 57, 58, 59, 61, 66, 69, 83, 93, 94, 96, 99], "conflict": 95, "confound": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 19, 31, 32, 36, 41, 51, 54, 58, 59, 60, 64, 68, 83, 84, 86, 89, 91, 92, 93, 96, 97, 98, 99], "congress": 97, "connect": [36, 54, 55], "consequ": [16, 17, 35, 51, 53, 59, 66, 68, 84, 85, 86, 90, 92], "conserv": [59, 60, 84, 92], "consid": [2, 7, 8, 9, 12, 33, 35, 36, 42, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 66, 67, 68, 69, 70, 83, 84, 86, 93, 94, 99], "consider": 60, "consist": [10, 11, 36, 46, 54, 55, 56, 60, 63, 64, 68, 96, 98], "consol": [33, 98], "constant": [21, 48, 57, 66, 83, 93], "constrained_layout": 42, "construct": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 37, 43, 44, 45, 47, 55, 59, 62, 66, 70, 72, 79, 83, 93, 98, 99], "construct_framework": [2, 4, 5, 7, 8, 9, 10, 11, 12], "construct_iv": 53, "constructiv": 35, "constructor": 37, "consum": [35, 53], "cont_d": 40, "contain": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 29, 30, 33, 35, 36, 40, 42, 43, 44, 49, 50, 52, 53, 54, 63, 66, 67, 83, 84, 86, 89, 98], "context": [60, 68, 99], "continu": [32, 37, 40, 41, 48, 56, 84, 92, 98, 99], "contour": [2, 4, 5, 7, 8, 9, 10, 11, 12, 48, 51, 59, 60, 84, 89], "contour_plot": 60, "contours_z": [43, 44], "contrast": [40, 45, 46, 68], "contribut": [95, 98], "contributor": 98, "control": [22, 34, 48, 55, 57, 60, 99], "convent": [36, 54, 55], "converg": [33, 42, 52, 53, 63], "convergencewarn": 53, "convers": 53, "convert": [45, 53, 58], "convex": 56, "coor": [37, 67, 94, 96], "coordin": 60, "copi": [50, 54, 57, 60], "cor": [84, 92], "core": [38, 40, 45, 46, 51, 53, 54, 55, 58, 59, 61, 64, 67, 96, 98], "cores_us": [45, 55, 58], "correct": [51, 60, 66, 83, 93, 98], "correctli": [46, 56, 59, 84, 92], "correl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 48, 53, 59, 61, 68, 84, 86, 92], "correpond": 68, "correspond": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 27, 28, 33, 35, 36, 37, 42, 43, 44, 46, 47, 48, 52, 53, 54, 55, 57, 58, 59, 60, 63, 66, 67, 68, 69, 83, 84, 86, 89, 90, 92, 93, 98, 99], "correspondond": 40, "cosh": 25, "coul": 35, "could": [32, 37, 41, 43, 44, 60, 98, 99], "counfound": [16, 17, 58, 59, 66, 84, 92], "count": [40, 54, 55], "countour": [84, 89], "coupl": [36, 54, 55], "cournapeau": [94, 96], "cours": [36, 52, 54, 60, 83, 99], "cov": 16, "covari": [3, 4, 5, 6, 8, 10, 11, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 66, 67, 68, 70, 73, 74, 83, 84, 86, 96, 98], "cover": [34, 48, 59], "coverag": [52, 66, 98], "cp": [36, 37, 67], "cpu": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "cpu_count": [45, 55, 58], "cran": [37, 97, 98], "creat": [19, 32, 35, 37, 40, 41, 42, 43, 44, 45, 49, 50, 53, 55, 57, 58, 60, 67, 84, 86, 89, 92, 95], "create_synthetic_group_data": 57, "critic": [60, 99], "cross": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 32, 33, 34, 36, 37, 42, 52, 54, 55, 60, 63, 65, 67, 73, 74, 79, 83, 87, 89, 98, 99], "cross_sectional_data": [5, 18, 46, 68], "crossfit": 52, "crosstab": 56, "crucial": [48, 99], "csail": [94, 96], "csv": 48, "cumul": 68, "current": [34, 50, 70, 84, 92, 94, 99], "custom": [33, 34, 42, 60, 67], "custom_measur": 34, "cut": 57, "cv": [37, 54, 67, 69], "cv_glmnet": [35, 36, 37, 67, 83, 93, 96], "cvar": [2, 13, 65, 72, 98], "cvar_0": 45, "cvar_1": 45, "d": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 99], "d0": [45, 58, 83], "d0_true": 58, "d0cdb0ea4795": 37, "d1": [45, 56, 58, 83, 93], "d10": [83, 93], "d1_true": 58, "d2": [56, 83, 93], "d21ee5775b5f": 37, "d3": [83, 93], "d4": [83, 93], "d5": [83, 93], "d5a0c70f1d98": 37, "d6": [83, 93], "d7": [83, 93], "d8": [83, 93], "d9": [83, 93], "d_": [23, 35, 47, 53, 68, 83, 93], "d_0": 68, "d_1": [56, 83, 93], "d_2": 56, "d_col": [3, 6, 32, 33, 35, 36, 37, 41, 43, 44, 49, 50, 53, 54, 55, 57, 59, 62, 63, 64, 67, 68, 69, 70, 96, 98, 99], "d_i": [19, 20, 21, 22, 24, 25, 26, 33, 42, 45, 46, 56, 58, 61, 63, 68], "d_j": [68, 83, 93], "d_k": [68, 83, 93], "d_l": 68, "d_w": 57, "da1440": 56, "dag": [60, 61, 99], "dark": [33, 42], "darkblu": 35, "darkr": 35, "dash": 40, "dat": 64, "data": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 34, 47, 48, 52, 56, 62, 65, 66, 67, 69, 83, 88, 89, 93, 97, 98], "data_apo": 40, "data_cvar": 55, "data_dict": [43, 44, 49, 50, 51], "data_dml": 59, "data_dml_bas": [36, 43, 44, 49, 50, 54, 55, 57], "data_dml_base_iv": [36, 54, 55], "data_dml_flex": [36, 54], "data_dml_flex_iv": 36, "data_dml_iv_flex": 54, "data_dml_new": 57, "data_fram": 99, "data_lqt": 55, "data_pq": 55, "data_qt": 55, "data_transf": [35, 53, 54], "datafram": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 35, 38, 40, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 70, 83, 84, 86, 89, 96, 99], "dataset": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 33, 34, 40, 42, 43, 44, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 83, 84, 89, 96, 99], "datatyp": 98, "db": [36, 54, 55, 59, 99], "dbl": [34, 35, 36, 37, 64, 83, 93, 96, 99], "dc13a11076b3": 37, "ddc9": 37, "de": [32, 41, 97], "deal": [32, 41], "debias": [14, 15, 23, 24, 35, 48, 53, 65, 67, 69, 94, 97, 98], "debt": [36, 54, 55], "decai": 61, "decid": [36, 54], "decis": [8, 32, 36, 41, 54, 55, 66, 97, 99], "decision_effect": 32, "decision_impact": [32, 41], "decisiontreeclassifi": [8, 54], "decisiontreeregressor": 54, "declar": 99, "deep": [29, 30], "deeper": 8, "def": [2, 4, 5, 7, 8, 9, 10, 11, 12, 42, 45, 52, 53, 56, 57, 58, 60, 67, 70], "default": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 23, 24, 25, 29, 30, 34, 35, 40, 46, 49, 50, 52, 53, 57, 59, 60, 61, 62, 66, 67, 69, 83, 84, 85, 89, 93, 96, 99], "default_convert": 53, "defin": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 36, 37, 40, 42, 43, 44, 45, 46, 48, 49, 50, 52, 54, 55, 57, 58, 59, 60, 66, 67, 68, 70, 73, 74, 84, 86, 89, 92], "definit": [25, 49, 50, 84, 85, 90], "defint": 84, "degre": [36, 43, 44, 53, 54, 66, 84, 86], "dekel": 97, "delete_origin": 37, "deliber": 56, "delta": [22, 34, 46, 60, 68], "delta_bench": 60, "delta_i": 34, "delta_j": 22, "delta_theta": [31, 40, 51, 59, 60, 84, 86], "delta_v": 60, "demand": [35, 53, 84, 86], "demir": [14, 15, 24, 35, 48, 53, 63, 69, 94, 97], "demo": 60, "demonstr": [33, 34, 35, 42, 53, 60, 64, 83, 93, 94, 96], "deni": 97, "denomin": [84, 85, 86, 90], "denot": [10, 35, 36, 46, 47, 53, 54, 60, 61, 66, 68, 70, 84, 86, 89, 90, 92], "dens_net_tfa": 36, "densiti": [9, 12, 13, 33, 40, 42], "dep": 38, "dep1": [37, 38, 64, 96], "dep2": [37, 38, 64, 96], "depend": [2, 8, 9, 13, 19, 37, 43, 44, 46, 49, 50, 51, 52, 57, 62, 66, 67, 70, 77, 82, 84, 85, 86, 92, 96, 97], "deprec": [62, 69], "depreci": 98, "depth": [8, 36, 37, 57, 62, 66, 67, 68, 69, 70, 83, 96, 99], "deriv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 28, 83], "describ": [34, 35, 53, 54, 55, 60, 67, 69, 95, 98], "descript": [36, 38, 59, 67, 69, 84, 86], "design": 97, "design_info": [43, 44], "design_matrix": [43, 44, 66], "desir": [17, 37, 57], "detail": [2, 4, 5, 7, 8, 9, 10, 11, 12, 27, 28, 33, 36, 37, 40, 42, 46, 47, 48, 55, 59, 60, 63, 64, 66, 67, 68, 70, 72, 76, 77, 78, 79, 82, 83, 84, 86, 92, 93, 94, 96, 98, 99], "determin": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 36, 45, 54, 55, 58, 59, 68, 83, 84, 92, 93], "determinist": [57, 66], "deutsch": 94, "dev": 98, "develop": [34, 35, 37, 53, 60, 68, 98], "deviat": [52, 84, 92], "dezeur": 97, "df": [3, 6, 32, 33, 35, 40, 41, 43, 44, 45, 47, 50, 53, 56, 58, 59, 60, 61, 63, 66, 68], "df_agg": 48, "df_apo": 40, "df_apo_ci": 40, "df_apos_ci": 40, "df_ate": 40, "df_bench": 60, "df_binari": 60, "df_bonu": [37, 64, 96], "df_cate": [43, 44], "df_ci": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "df_coef": 52, "df_cvar": 55, "df_lqte": 55, "df_ml_g0": 52, "df_ml_g1": 52, "df_ml_m": 52, "df_pa": [46, 61], "df_plot": 35, "df_pq": 55, "df_qte": 55, "df_result": 48, "df_sort": 40, "df_summari": 54, "df_wide": 53, "dfg": 94, "dgp": [18, 35, 45, 47, 48, 53, 56, 57, 58, 60, 61], "dgp1": 18, "dgp2": 18, "dgp3": 18, "dgp4": 18, "dgp5": 18, "dgp6": 18, "dgp_dict": 60, "dgp_tpye": 46, "dgp_type": [18, 46], "diagon": 60, "diagram": [32, 41, 68], "dichotom": [32, 41], "dict": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 31, 43, 44, 48, 60, 67], "dict_kei": [84, 89], "dictionari": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 19, 31, 43, 44, 49, 50, 59, 66, 67, 84, 89], "dictonari": [36, 54], "did": [3, 6, 33, 46, 47, 53, 65, 98, 99], "diff": 54, "differ": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 32, 33, 35, 36, 37, 40, 41, 42, 45, 49, 50, 51, 53, 54, 55, 56, 58, 59, 60, 61, 62, 65, 66, 67, 69, 73, 74, 95, 96, 97, 98, 99], "difficult": 60, "dillon": 97, "dim": 36, "dim_x": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 20, 21, 22, 23, 24, 25, 26, 33, 35, 37, 42, 52, 53, 63, 66, 67, 68, 84, 89], "dim_z": [10, 22, 68], "dimens": [19, 23, 35, 53, 57, 69], "dimension": [10, 11, 19, 21, 48, 66, 68, 69, 83, 84, 89, 93, 96, 97], "direct": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 42, 47, 61, 63, 99], "directli": [33, 34, 36, 40, 42, 52, 59, 63, 84, 89, 96, 99], "discret": [40, 53, 68], "discretis": 55, "discuss": [20, 35, 36, 53, 54, 97, 98, 99], "disjoint": [35, 49, 50, 53], "displai": [35, 40, 53, 60, 66, 67, 84, 89], "displot": 54, "disproportion": [36, 54], "dist": [2, 4, 5, 7, 8, 9, 10, 11, 12], "distr": 67, "distribut": [33, 40, 42, 46, 52, 60, 63, 68, 84, 90, 95, 97, 98], "diverg": [33, 42, 63], "dmatrix": [43, 44, 66], "dml": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 27, 28, 32, 33, 37, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 70, 83, 84, 89, 93, 95], "dml1": [65, 96, 98, 99], "dml2": [32, 35, 37, 38, 46, 53, 55, 65, 68, 70, 83, 96, 98, 99], "dml_apo_obj": 68, "dml_apos_obj": 68, "dml_base": 53, "dml_combin": 83, "dml_cv_predict": 98, "dml_cvar": [45, 55], "dml_cvar_0": 45, "dml_cvar_1": 45, "dml_cvar_obj": [2, 66], "dml_data": [34, 35, 38, 40, 46, 47, 51, 52, 53, 56, 59, 60, 61, 66, 67, 68, 83, 93, 99], "dml_data_bench": 60, "dml_data_bonu": [37, 96], "dml_data_df": 99, "dml_data_lasso": 38, "dml_data_sim": [37, 96], "dml_dev": 40, "dml_df": [35, 53], "dml_did": [46, 47], "dml_did_obj": [4, 5, 68], "dml_iivm_boost": [36, 54], "dml_iivm_forest": [36, 54], "dml_iivm_lasso": [36, 54], "dml_iivm_obj": [7, 41, 68], "dml_iivm_tre": [36, 54], "dml_irm": [43, 49, 52, 57], "dml_irm_at": 51, "dml_irm_boost": [36, 54], "dml_irm_forest": [36, 54], "dml_irm_gat": 51, "dml_irm_gatet": 51, "dml_irm_lasso": [36, 38, 54], "dml_irm_new": 57, "dml_irm_obj": [2, 4, 5, 7, 8, 9, 10, 11, 12, 59, 66, 67, 68], "dml_irm_obj_ext": 67, "dml_irm_rf": 38, "dml_irm_tre": [36, 54], "dml_long": 31, "dml_lpq_0": 58, "dml_lpq_1": 58, "dml_lpq_obj": [9, 66], "dml_lqte": [55, 58], "dml_obj": [34, 40, 59, 60], "dml_obj_bench": 60, "dml_pliv": [35, 53], "dml_pliv_obj": [10, 35, 53, 68], "dml_plr": [44, 50, 83, 93], "dml_plr_1": 83, "dml_plr_2": 83, "dml_plr_boost": [36, 54], "dml_plr_forest": [36, 54, 99], "dml_plr_lasso": [36, 38, 54], "dml_plr_no_split": 69, "dml_plr_obj": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 59, 62, 66, 67, 68, 69, 70, 83, 84, 86, 89], "dml_plr_obj_extern": 69, "dml_plr_obj_intern": 69, "dml_plr_rf": 38, "dml_plr_tree": [36, 54, 99], "dml_pq_0": [55, 58], "dml_pq_1": [55, 58], "dml_pq_obj": [12, 66], "dml_procedur": [38, 62, 96, 98, 99], "dml_qte": [55, 58], "dml_qte_obj": [13, 66], "dml_short": 31, "dml_ssm": [61, 68], "dml_tune": 98, "dmldummyclassifi": 67, "dmldummyregressor": 67, "dmlmt": 97, "dnorm": 33, "do": [34, 35, 36, 37, 52, 53, 54, 55, 56, 60, 66, 67, 84, 92, 96, 99], "doabl": 70, "doc": [32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 94, 98], "docu": 98, "document": [39, 43, 44, 47, 49, 50, 60, 94, 98], "doe": [13, 34, 35, 36, 40, 53, 54, 56, 59, 60, 84, 92, 99], "doesn": [32, 41], "doi": [14, 15, 16, 17, 18, 20, 23, 24, 26, 34, 35, 37, 48, 53, 60, 63, 67, 69, 83, 93, 94, 96, 98], "domain": 57, "don": 34, "done": [2, 4, 5, 7, 8, 9, 10, 11, 12, 55, 67, 69, 84, 86], "dosag": 40, "dot": [47, 57, 64, 66, 67, 68, 83, 93, 96], "doubl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 23, 24, 25, 26, 36, 48, 54, 56, 65, 67, 69, 70, 83, 84, 86, 93, 98], "double_ml_bonus_data": 38, "double_ml_data_from_data_fram": [33, 63, 64, 99], "double_ml_data_from_matrix": [34, 37, 64, 67, 83, 93, 96], "double_ml_irm": [38, 57], "doubleiivm": 94, "doubleml": [33, 35, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 84, 89, 93, 96, 97, 98], "doubleml2022python": 94, "doubleml2024r": 94, "doubleml_did_eval_linear": 34, "doubleml_did_eval_rf": 34, "doubleml_did_linear": 34, "doubleml_did_rf": 34, "doubleml_framework": [2, 4, 5, 7, 8, 9, 10, 11, 12], "doublemlapo": [40, 68, 70, 71], "doublemlblp": [8, 11, 43, 44, 66, 98], "doublemlclusterdata": 23, "doublemlcvar": [45, 66, 70, 72, 98], "doublemldata": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 24, 25, 26, 32, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 83, 84, 89, 93, 98, 99], "doublemldid": [46, 47, 68, 70, 73, 98], "doublemldidc": [46, 68, 70, 74, 98], "doublemlframework": [2, 4, 5, 7, 8, 9, 10, 11, 12, 69, 83, 98], "doublemlidid": 68, "doublemlididc": 68, "doublemliivm": [32, 36, 41, 54, 67, 68, 69, 70, 75, 98], "doublemlirm": [2, 4, 5, 7, 9, 10, 11, 12, 34, 36, 38, 40, 43, 49, 51, 52, 54, 56, 57, 59, 60, 66, 67, 68, 69, 70, 76, 94, 98], "doublemllpq": [58, 66, 70, 77, 98], "doublemlpliv": [67, 68, 69, 70, 80, 94, 98], "doublemlplr": [2, 4, 5, 7, 8, 9, 10, 12, 13, 33, 36, 37, 38, 42, 44, 50, 54, 56, 59, 62, 63, 66, 67, 68, 69, 70, 81, 83, 84, 89, 93, 94, 96, 98, 99], "doublemlpolicytre": [8, 66], "doublemlpq": [55, 58, 66, 70, 82, 98], "doublemlqt": [45, 55, 58, 66, 83, 98], "doublemlresampl": 52, "doublemlsmm": 98, "doublemlssm": [61, 68, 70, 78, 79], "doubli": [16, 17, 18, 34, 97], "down": 60, "download": [32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 95, 96], "downward": 60, "dpg_dict": 59, "dpi": [33, 42, 56], "dramat": 34, "draw": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 60, 69, 98], "draw_sample_split": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 52, 69], "drawn": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 19, 36, 54, 55, 57, 69], "drive": [33, 42, 63], "driven": [60, 99], "drop": [34, 53, 56, 64, 67, 70, 73, 74, 83, 93], "dt": [70, 74, 84, 87], "dt_bonu": 64, "dta": 34, "dtype": [38, 40, 46, 49, 50, 51, 52, 53, 54, 55, 59, 61, 64, 66, 96], "dualiti": 53, "dubourg": [94, 96], "duchesnai": [94, 96], "due": [33, 34, 42, 43, 44, 51, 59, 60, 63, 68, 84, 86, 98, 99], "duflo": [14, 15, 24, 35, 48, 53, 63, 69, 94, 97], "dummi": [1, 8, 11, 29, 30, 60, 66, 67, 68, 98], "dummyclassifi": 29, "dummyregressor": 30, "duplic": 98, "durabl": [37, 38, 64, 96], "durat": 15, "dure": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 37, 53, 54, 67, 69, 96, 98, 99], "dx": 20, "dynam": [34, 97], "e": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 24, 26, 27, 28, 33, 34, 35, 36, 40, 42, 43, 44, 46, 48, 51, 52, 53, 54, 55, 56, 59, 60, 61, 63, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99], "e20ea26": 37, "e401": [36, 54, 55, 59, 99], "e4016553": 99, "e45228": 56, "e57c": 37, "each": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 37, 40, 47, 49, 50, 52, 53, 55, 56, 57, 59, 60, 62, 64, 67, 69, 83, 84, 89, 93, 99], "earlier": 99, "earn": [36, 54, 55], "earner": [36, 54, 59], "easi": [37, 70], "easili": [37, 52, 55, 98], "ec973f": 56, "ecolor": [40, 47, 54, 56], "econ": 97, "econml": 97, "econom": [22, 23, 25, 26, 35, 48, 53, 56, 60, 69, 97], "econometr": [14, 15, 16, 17, 18, 24, 25, 34, 35, 48, 53, 63, 94, 97], "econometrica": [21, 35, 53, 56, 63, 97], "ecosystem": [94, 99], "ectj": [14, 15, 24, 35, 48, 53, 63, 94], "ed": 97, "edge_color": 42, "edgecolor": 42, "edit": [95, 97], "edu": [94, 96], "educ": [36, 54, 55, 59, 99], "ee97bda7": 37, "effect": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 32, 33, 34, 35, 37, 40, 41, 42, 46, 47, 48, 51, 53, 57, 61, 63, 65, 67, 68, 69, 70, 76, 83, 84, 86, 96, 97, 98, 99], "effici": 97, "effort": 70, "eight": [35, 53], "either": [2, 4, 5, 7, 8, 9, 10, 11, 12, 19, 37, 47, 48, 57, 66, 67, 99], "eleanor": 97, "element": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 43, 44, 45, 46, 52, 53, 55, 58, 59, 61, 70, 71, 73, 74, 84, 89, 91, 92, 98], "element_text": [35, 36], "elementari": 97, "elif": [49, 50, 57], "elig": [55, 59, 99], "eligibl": [36, 54, 59], "ell": [33, 35, 42, 48, 53, 63, 70, 80, 81, 96], "ell_0": [7, 10, 11, 33, 42, 48, 63, 68], "ell_2": 52, "els": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 36, 40, 47, 49, 50, 53, 57, 60], "em": 97, "emphas": [35, 53], "empir": [27, 28, 33, 35, 42, 53, 56, 60, 63, 69, 70, 83, 93], "emploi": [35, 48, 53, 60, 70, 75], "employ": [36, 54, 55], "employe": 99, "empti": 53, "emul": [84, 86], "enabl": [57, 59, 66, 84, 86, 98], "encapsul": [29, 30], "encod": 56, "end": [20, 22, 23, 33, 34, 35, 36, 42, 45, 47, 48, 52, 53, 54, 56, 57, 58, 61, 62, 64, 67, 69, 83, 93, 96, 99], "endogen": [36, 54, 55, 99], "enet_coordinate_descent_gram": 53, "engin": [37, 97], "enrol": [36, 54, 55], "ensembl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 40, 42, 43, 44, 49, 50, 51, 52, 54, 57, 59, 60, 62, 66, 67, 68, 69, 70, 83, 84, 89, 96, 99], "ensemble_learner_pipelin": 67, "ensemble_pipe_classif": 37, "ensemble_pipe_regr": 37, "ensur": [35, 50, 53, 57], "entir": [33, 36, 42, 54, 63, 84, 86], "entri": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 35, 38, 40, 42, 46, 51, 53, 54, 55, 59, 61, 63, 64, 67, 94, 96, 98], "enumer": [40, 45, 47, 49, 50, 52, 53, 54, 55, 58, 62, 67, 69], "env": [40, 53, 95], "environ": 95, "ep": 56, "epsilon": [36, 45, 46, 47, 54, 58, 66, 68], "epsilon_": [35, 47, 53], "epsilon_i": [19, 45, 56, 57, 58], "epsilon_sampl": 57, "epsilon_tru": [45, 58], "eqnarrai": 36, "equal": [8, 35, 53, 56, 61, 66, 67, 84, 90], "equat": [35, 36, 53, 54, 60, 62, 83, 93, 99], "equilibrium": [35, 53], "equival": [48, 69], "err": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 41, 43, 44, 45, 46, 49, 50, 51, 53, 54, 55, 56, 58, 59, 60, 61, 66, 67, 68, 69, 70, 83, 96, 99], "error": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 32, 33, 34, 36, 37, 42, 47, 48, 49, 50, 52, 54, 60, 63, 67, 68, 69, 70, 83, 84, 89, 93, 96, 98, 99], "errorbar": [40, 47, 49, 50, 54, 56], "erstellt": [35, 36, 37], "especi": 52, "essenti": 60, "est_method": 34, "esther": [69, 97], "estim": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 27, 28, 29, 30, 33, 34, 35, 37, 40, 42, 43, 44, 45, 47, 49, 50, 52, 53, 57, 62, 63, 65, 66, 67, 68, 72, 73, 74, 77, 79, 82, 84, 86, 89, 93, 94, 97, 98], "estimatior": [3, 6], "et": [14, 15, 19, 21, 23, 24, 33, 35, 36, 37, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 58, 59, 63, 68, 69, 70, 72, 77, 82, 83, 84, 86, 92, 93, 94, 96, 98], "eta": [27, 28, 33, 35, 36, 47, 53, 54, 58, 62, 66, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 92, 93, 96, 99], "eta1": 56, "eta2": 56, "eta_": [83, 84, 92, 93], "eta_0": [62, 70, 83], "eta_i": [19, 47, 57, 58], "eta_sampl": 57, "eta_tru": 58, "etc": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 52, 53, 98], "ev": [33, 42, 63], "eval": [37, 67], "eval_metr": [36, 54, 99], "eval_pr": 34, "eval_predict": 34, "evalu": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 21, 28, 34, 37, 43, 44, 45, 47, 51, 55, 58, 59, 62, 97, 98], "evaluate_learn": [2, 4, 5, 7, 8, 9, 10, 11, 12, 52, 67, 98], "evalut": 67, "even": [36, 37, 54, 56, 67, 99], "eventu": [35, 53], "everi": [35, 53], "everyth": 94, "evid": 51, "exact": 60, "exactli": 60, "exampl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 32, 33, 36, 37, 38, 40, 41, 42, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 61, 62, 63, 66, 67, 68, 69, 70, 83, 84, 89, 93, 94, 96, 98, 99], "example_attgt": 34, "example_attgt_dml_eval_linear": 34, "example_attgt_dml_eval_rf": 34, "example_attgt_dml_linear": 34, "example_attgt_dml_rf": 34, "except": [48, 60, 98], "excess": 52, "exclud": 31, "exclus": [8, 11, 49, 50, 66], "execut": [37, 99], "exemplarili": 96, "exemplatori": 57, "exhaust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 67], "exhibit": [35, 53], "exist": [68, 84, 92], "exogen": [36, 54, 55, 99], "exp": [16, 17, 18, 19, 21, 24, 33, 42, 43, 44, 47, 49, 50, 56, 57, 63], "expect": [16, 17, 34, 46, 51, 52, 60, 61, 66, 69, 83, 84, 85, 96], "experi": [15, 20, 21, 33, 36, 42, 54, 60, 63, 64, 69, 96, 97], "experiment": [4, 5, 18, 70, 73, 74, 84, 87, 88], "expertis": 60, "explain": [2, 4, 5, 7, 8, 9, 10, 11, 12, 17, 59, 84, 86, 91, 92], "explan": [35, 46, 53, 59, 84, 91, 94, 99], "explanatori": [60, 83, 93], "explicit": 60, "explicitli": [51, 99], "exploit": [33, 42, 63, 99], "exponenti": [83, 93], "export": 98, "exposur": 47, "express": [35, 48, 84, 92], "extend": [60, 67, 94, 98], "extendend": [84, 92], "extens": [67, 70, 94, 97, 98], "extent": 48, "extern": [33, 40, 42, 65, 84, 86, 98], "external_predict": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 42, 67], "externalptr": 36, "extra": 37, "extract": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "extralearn": 37, "extrem": [36, 54], "ey": 48, "f": [36, 37, 40, 42, 45, 46, 47, 48, 52, 53, 54, 55, 57, 58, 59, 60, 61, 67, 84, 92, 94, 96], "f00584a57972": 37, "f1718fdeb9b0": 37, "f2e7": 37, "f3d24993": 37, "f6ebc": 56, "f_": [16, 18, 47, 66], "f_loc": [45, 58], "f_p": 47, "f_scale": [45, 58], "face_color": 42, "facet_wrap": 36, "fact": [36, 54, 55], "factor": [33, 34, 35, 36, 37, 42, 52, 63, 67, 99], "faculti": 97, "fail": 98, "fair": 52, "fake": [32, 41], "fals": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 33, 36, 37, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 60, 61, 64, 67, 68, 69, 70, 73, 74, 83, 84, 87, 88, 93, 99], "famili": [36, 54, 67], "fanci": 34, "far": [36, 54], "farbmach": 20, "fast": [52, 57, 67], "faster": 48, "fb5c25fa": 37, "fc9e": 37, "fd8a": 37, "featur": [2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 34, 38, 51, 52, 54, 57, 66, 67], "featureless": [37, 67], "features_bas": [36, 54, 55, 59], "features_flex": 36, "featureunion": 37, "februari": 60, "femal": [37, 38, 64, 96], "fern\u00e1ndez": [21, 69, 97], "fetch": [36, 53, 54, 55, 64], "fetch_401k": [36, 54, 55, 59, 99], "fetch_bonu": [37, 38, 64, 96], "few": [36, 54, 55], "ff7f0e": 47, "field": [35, 53, 67, 99], "fifteenth": 97, "fifth": 35, "fig": [2, 4, 5, 7, 8, 9, 10, 11, 12, 40, 43, 44, 45, 47, 48, 52, 55, 56, 58, 60], "fig_al": 42, "fig_dml": 42, "fig_non_orth": 42, "fig_orth_nosplit": 42, "fig_po_al": 42, "fig_po_dml": 42, "fig_po_nosplit": 42, "figsiz": [38, 40, 43, 44, 45, 47, 49, 50, 52, 53, 54, 55, 56, 58], "figur": [2, 4, 5, 7, 8, 9, 10, 11, 12, 24, 33, 35, 38, 40, 42, 43, 44, 45, 47, 48, 49, 50, 53, 54, 55, 58, 60, 63], "figure_format": 56, "file": [14, 15, 40, 48, 56, 97, 98], "filenam": 33, "fill": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 35, 36, 46, 52, 54, 61], "fill_between": [43, 44, 45, 55, 58], "fill_valu": 52, "filter": 37, "filterwarn": 42, "final": [33, 37, 40, 42, 43, 44, 45, 47, 49, 50, 51, 55, 58, 61, 63, 68, 99], "financi": [14, 59, 99], "find": [36, 47, 54, 60, 66, 67, 99], "finish": 37, "finit": [33, 36], "firm": [35, 53, 59], "firmid": 53, "first": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 23, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 58, 60, 61, 63, 66, 69, 83, 84, 89, 93, 95, 96, 98, 99], "fit": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 29, 30, 32, 33, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 70, 73, 74, 79, 83, 84, 86, 89, 93, 94, 98, 99], "fit_arg": [2, 4, 5, 7, 8, 9, 10, 11, 12], "fit_transform": [53, 54], "five": 53, "fix": [47, 52, 54, 98], "flag": [18, 69, 95], "flake8": 98, "flatten": 56, "flexibl": [32, 34, 36, 37, 41, 46, 54, 94, 99], "flexibli": [36, 54, 59], "float": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17], "float32": [55, 59], "float64": [38, 40, 46, 50, 51, 53, 54, 59, 61, 64, 67, 96], "floor": 37, "floor_divid": 53, "flt": 37, "flush": 33, "fmt": [40, 47, 49, 50, 54, 56], "focu": [35, 36, 53, 54, 55, 60, 66, 68, 99], "focus": [55, 59, 60, 99], "fold": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 35, 36, 37, 46, 52, 53, 54, 55, 59, 61, 62, 65, 67, 68, 70, 73, 74, 83, 96, 99], "follow": [16, 17, 18, 19, 33, 35, 36, 42, 43, 44, 45, 46, 47, 49, 50, 53, 54, 55, 58, 59, 60, 61, 63, 64, 66, 67, 68, 69, 84, 85, 86, 87, 88, 89, 90, 91, 92, 95, 96, 99], "font_scal": [53, 54, 55], "fontsiz": [45, 55, 58], "force_all_x_finit": [3, 6], "forest": [20, 32, 33, 34, 36, 37, 41, 42, 46, 51, 52, 54, 59, 63, 67, 96, 99], "forest_summari": 54, "forg": [95, 97, 98], "form": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 36, 43, 44, 45, 46, 47, 49, 50, 51, 52, 54, 58, 59, 61, 66, 68, 70, 71, 76, 84, 85, 86, 89, 90, 91, 92, 95, 96], "format": [42, 51, 84, 89], "formatt": 40, "formula": [35, 36, 53, 54, 60, 98], "formula_flex": 36, "forschungsgemeinschaft": 94, "forthcom": [60, 97], "forum": 98, "forward": 8, "found": [43, 44, 48, 49, 50, 63, 64, 67, 68, 96], "foundat": [94, 97], "four": [36, 52, 54, 98], "fourth": [35, 53], "frac": [7, 16, 17, 18, 20, 21, 22, 24, 25, 26, 28, 33, 35, 37, 42, 47, 48, 51, 53, 56, 62, 63, 66, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93], "fraction": 37, "frame": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 35, 36, 38, 40, 43, 44, 46, 49, 50, 51, 53, 54, 55, 56, 57, 59, 61, 63, 64, 96, 99], "framework": [28, 33, 35, 37, 42, 52, 53, 56, 60, 63, 67, 83, 93, 94, 96, 98, 99], "freez": 95, "fribourg": 97, "friendli": 40, "from": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 83, 84, 89, 93, 96, 98, 99], "from_arrai": [3, 6, 42, 45, 46, 47, 58, 63, 64, 67, 83, 93, 96], "from_product": 53, "front": 40, "fr\u00e9chet": [84, 92], "fsize": [36, 54, 55, 59, 99], "full": [40, 42, 45, 46, 47, 49, 50, 52, 54, 55, 58, 61, 63], "fulli": [8, 36, 39, 54, 68], "fun": 33, "func": 34, "function": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 24, 25, 27, 28, 32, 33, 36, 37, 41, 42, 43, 44, 45, 46, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 88, 92, 93, 94, 97, 98, 99], "fund": [36, 54, 55, 94], "further": [16, 17, 18, 19, 23, 35, 37, 40, 43, 44, 45, 46, 47, 51, 52, 53, 55, 57, 58, 59, 60, 61, 67, 68, 70, 72, 77, 78, 79, 82, 83, 84, 86, 89, 91, 92, 93, 94, 96, 98, 99], "furthermor": [42, 70, 71, 76], "futurewarn": 50, "g": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 33, 34, 37, 38, 42, 43, 44, 46, 47, 48, 51, 52, 55, 56, 57, 59, 61, 63, 66, 67, 68, 70, 71, 73, 74, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 99], "g_": [70, 72, 73, 74, 77, 82, 83, 93], "g_0": [4, 5, 7, 8, 10, 11, 12, 24, 25, 33, 35, 36, 42, 52, 53, 54, 63, 66, 67, 68, 70, 71, 78, 79, 84, 85, 90, 92, 96, 99], "g_1": 52, "g_all": [33, 36], "g_all_po": 33, "g_ci": 36, "g_d": [70, 72, 82], "g_dml": 33, "g_dml_po": 33, "g_hat": [10, 11, 33, 42, 70], "g_hat0": [7, 8], "g_hat1": [7, 8], "g_k": 66, "g_nonorth": 33, "g_nosplit": 33, "g_nosplit_po": 33, "g_x": 47, "gain": [2, 4, 5, 7, 8, 9, 10, 11, 12, 17, 31, 52, 84, 86, 90, 98], "gain_statist": 98, "galleri": [63, 66, 67, 68, 94, 98], "gamma": [22, 25, 26, 35, 53, 56, 57, 60, 70, 72, 77], "gamma_0": [19, 57, 61, 70, 72, 77], "gamma_a": [16, 17, 60], "gamma_bench": 60, "gamma_v": 60, "gap": [53, 60], "gate": [1, 8, 11, 56, 57, 65, 98], "gate_obj": 66, "gatet": 66, "gaussian": [9, 12, 13, 33, 42, 63, 66, 67, 83, 93, 97], "ge": [16, 18, 19, 51, 57, 66], "geer": 97, "gelbach": [35, 53], "gener": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 34, 35, 36, 37, 38, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 76, 83, 85, 86, 87, 88, 90, 92, 93, 97, 98, 99], "generate_treat": 58, "geom_bar": 36, "geom_dens": 36, "geom_errorbar": 36, "geom_funct": 33, "geom_histogram": 33, "geom_hlin": 36, "geom_point": 36, "geom_til": 35, "geom_vlin": 33, "german": 94, "get": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 37, 40, 52, 56, 59, 60, 84, 86, 94, 95], "get_dummi": 56, "get_feature_names_out": [53, 54], "get_legend_handles_label": 40, "get_logg": [33, 34, 35, 36, 37, 62, 67, 68, 69, 70, 83, 93, 96], "get_metadata_rout": [29, 30], "get_param": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 67], "get_real_method": 40, "ggdid": 34, "ggplot": [33, 35, 36], "ggplot2": [33, 35, 36], "ggsave": 33, "ggtitl": 36, "gh": 98, "git": 95, "github": [34, 36, 48, 54, 56, 94, 97, 98], "githubusercont": 48, "give": [36, 54], "given": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 21, 24, 25, 28, 33, 35, 40, 42, 47, 49, 50, 53, 55, 56, 60, 61, 63, 66, 70, 71, 83, 84, 85, 89, 90, 91, 92, 93, 96, 98], "glmnet": [36, 37, 67, 98], "global": [2, 4, 5, 7, 8, 9, 10, 11, 12, 67], "glrn": 37, "glrn_lasso": 37, "gname": 34, "go": [43, 44, 48, 60], "goal": [40, 49, 50], "goldman": 97, "good": [48, 84, 86, 99], "gradient": [36, 54], "gradientboostingclassifi": 52, "gradientboostingregressor": 52, "gradual": 60, "gramfort": [94, 96], "graph": [37, 61, 99], "graph_ensemble_classif": 37, "graph_ensemble_regr": 37, "graph_object": [43, 44, 48, 60], "graphlearn": [37, 67], "grasp": [40, 84, 86], "great": [47, 99], "greater": 99, "green": [33, 43, 44, 45, 58], "greg": 97, "grei": [36, 40], "grenand": 97, "grey50": 35, "grid": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 37, 40, 43, 44, 45, 48, 55, 56, 58, 60, 67, 84, 89], "grid_arrai": [43, 44], "grid_bound": [2, 4, 5, 7, 8, 9, 10, 11, 12, 60], "grid_search": [2, 4, 5, 7, 8, 9, 10, 11, 12, 37, 67], "grid_siz": [2, 4, 5, 7, 8, 9, 10, 11, 12, 43, 44], "gridextra": 35, "gridsearchcv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 67], "grisel": [94, 96], "grob": 35, "group": [8, 11, 32, 34, 40, 41, 51, 55, 56, 57, 60, 65], "group_0": 66, "group_1": [49, 50, 66], "group_2": [49, 50, 66], "group_3": [49, 50], "group_effect": 57, "group_ind": 51, "group_treat": 51, "groupbi": [48, 54], "gruber": 20, "gt": [32, 34, 35, 36, 37, 38, 40, 41, 43, 44, 45, 46, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 96], "guarante": [35, 53], "guber": 20, "guess": [59, 84, 86], "guid": [27, 28, 29, 30, 33, 34, 35, 37, 40, 42, 47, 51, 53, 59, 67, 94, 96, 98], "guidelin": 98, "gunion": [37, 67], "gxidclusterperiodytreat": 34, "h": [16, 17, 18, 20, 23, 34, 35, 53, 97], "h_0": [40, 51, 59, 60, 84, 89, 99], "ha": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 18, 33, 34, 35, 36, 42, 48, 52, 53, 54, 55, 56, 59, 60, 66, 67, 68, 84, 85, 86, 89, 90, 91, 92, 99], "half": [33, 42, 56, 63, 69], "hand": [52, 56, 99], "handbook": 56, "handl": [34, 40, 52, 67, 98], "hansen": [14, 15, 21, 22, 24, 35, 48, 53, 63, 94, 97], "happend": 52, "hard": [59, 84, 86], "harold": 97, "hat": [33, 35, 42, 48, 51, 53, 56, 62, 63, 66, 69, 70, 83, 84, 86, 89, 91, 93], "have": [1, 8, 11, 13, 19, 32, 33, 34, 35, 36, 37, 40, 41, 43, 44, 46, 47, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 64, 66, 67, 83, 84, 85, 86, 92, 95, 96, 98, 99], "hazlett": [60, 84, 86], "hc": [34, 97], "hdm": [35, 53], "he": 61, "head": [34, 35, 37, 38, 43, 44, 49, 50, 53, 54, 56, 60, 64, 66, 96], "heat": [35, 53], "heatmap": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 53, 60], "heavili": 52, "hei": 97, "height": [33, 35, 48], "help": [34, 36, 45, 52, 55, 57, 60, 69, 99], "helper": 98, "henc": [34, 36, 37, 54, 60, 67, 70, 99], "here": [9, 12, 13, 34, 35, 36, 37, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 58, 60, 61, 64, 67, 95], "heterogen": [8, 19, 36, 51, 54, 55, 57, 65, 68, 69, 97, 98, 99], "heteroskedast": [49, 50], "heurist": [33, 42, 63], "high": [10, 11, 21, 36, 47, 48, 54, 55, 62, 68, 83, 93, 94, 96, 97], "higher": [34, 36, 48, 54, 55, 56, 98, 99], "highli": [36, 54, 94], "highlight": [2, 4, 5, 7, 8, 9, 10, 11, 12, 46, 60, 98], "highlightcolor": [43, 44], "hispan": 38, "hist": 40, "hist_e401": 36, "hist_p401": 36, "histogram": 40, "histplot": 42, "hjust": 36, "hline": [64, 83, 93, 96, 99], "hold": [26, 35, 36, 53, 54, 61, 66, 67], "holdout": [67, 69], "holm": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "home": [36, 54, 60], "homogen": 68, "hopefulli": 55, "horizont": [35, 47, 53], "hostedtoolcach": 54, "hot": 56, "hotstart_backward": [37, 67], "hotstart_forward": [37, 67], "household": [36, 54, 55, 59], "how": [29, 30, 32, 34, 35, 36, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 67, 94, 95], "howev": [33, 36, 42, 54, 60, 61, 63, 99], "hown": [36, 54, 55, 59, 99], "hpwt": [35, 53], "hpwt0": 35, "hpwtairmpdspac": 35, "href": 94, "hspace": 52, "hstack": 47, "html": [37, 50, 94, 96, 98], "http": [20, 25, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 67, 94, 95, 96, 98], "huber": [26, 61, 68, 70, 78, 79, 97], "hue": 54, "huge": 52, "hugo": 97, "husd": [37, 38, 64, 96], "hyperparamet": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 37, 38, 48, 52, 54, 65, 96], "hypothes": [83, 93, 97], "hypothesi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 54, 59, 84, 89, 97], "hypothet": 60, "i": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 79, 82, 83, 84, 85, 86, 89, 90, 92, 93, 94, 95, 96, 98, 99], "i0": [46, 47, 68], "i03": 94, "i1": [46, 68], "i_": [22, 53, 57], "i_1": [35, 53], "i_2": [35, 53], "i_3": [35, 53], "i_4": 47, "i_est": 42, "i_fold": 35, "i_k": [35, 53, 62, 69, 83, 93], "i_learn": 52, "i_level": 40, "i_rep": [33, 42, 46, 52, 61, 63], "i_split": 53, "i_train": 42, "icp": 97, "id": [34, 35, 37, 53], "id_var": 53, "idea": [36, 37, 54, 55, 60, 67, 84, 86, 99], "ident": [16, 17, 18, 19, 22, 37, 67, 84, 89], "identfi": 60, "identif": [68, 99], "identifi": [35, 36, 46, 51, 53, 54, 55, 60, 66, 68, 84, 92, 98], "identifii": 66, "idnam": 34, "idx_tau": [45, 55, 58], "idx_treat": [2, 4, 5, 7, 8, 9, 10, 11, 12, 40, 84, 89], "ieee": 97, "ifels": 34, "ignor": 42, "ii": [35, 53], "iid": 68, "iivm": [7, 20, 27, 28, 55, 62, 66, 75, 94, 98], "iivm_summari": 54, "iivmglmnet": 36, "iivmrang": 36, "iivmrpart": 36, "iivmxgboost11861": 36, "ij": [23, 35, 53, 61], "ilia": 97, "illustr": [33, 35, 36, 37, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 60, 61, 63, 67, 99], "iloc": [40, 46, 47, 52, 53, 56], "immedi": 95, "immun": [69, 97], "impact": [32, 41, 52, 56, 59], "implement": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 27, 28, 33, 34, 35, 36, 37, 42, 46, 48, 52, 53, 54, 56, 59, 60, 61, 63, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99], "impli": [16, 17, 35, 36, 53, 54, 55, 66, 84, 85, 87, 88, 90], "implment": 47, "import": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 95, 96, 98, 99], "importlib": 48, "impos": 60, "improv": [46, 52, 57, 98], "in_sample_norm": [4, 5, 46, 70, 73, 74, 84, 87, 88], "inbuild": 52, "inbuilt": 52, "inc": [36, 54, 55, 59, 99], "includ": [2, 4, 5, 7, 8, 9, 10, 11, 12, 31, 34, 36, 40, 47, 49, 50, 54, 59, 60, 66, 68, 83, 84, 85, 89, 90, 92, 93, 98, 99], "include_bia": [53, 54], "include_scenario": [2, 4, 5, 7, 8, 9, 10, 11, 12, 60], "incom": [36, 54, 55, 57, 59, 99], "incorpor": [37, 59, 84, 89], "increas": [51, 52, 53, 60, 99], "increment": 98, "ind": 54, "independ": [4, 5, 16, 17, 18, 19, 35, 37, 47, 51, 53, 57, 68, 70, 73, 74, 98], "index": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 35, 38, 42, 47, 48, 49, 50, 53, 54, 56, 57, 63, 64, 69, 70, 73, 74, 96], "index_col": 48, "india": [69, 97], "indic": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 19, 26, 35, 36, 47, 51, 53, 54, 55, 60, 61, 62, 64, 66, 68, 69], "individu": [8, 34, 36, 40, 47, 49, 50, 51, 54, 55, 59, 66, 99], "individual_df": 47, "induc": [65, 69], "industri": [35, 53], "inf": [3, 6, 34], "inf_model": 70, "infer": [21, 22, 32, 33, 35, 41, 42, 48, 53, 63, 65, 69, 94, 96, 97, 98], "inferenti": 99, "infinit": [3, 6, 98], "info": [32, 37, 38, 40, 46, 51, 53, 54, 55, 59, 61, 64, 96, 98, 99], "inform": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 29, 30, 32, 37, 41, 43, 44, 52, 59, 60, 84, 86, 97], "infti": [33, 42, 63], "inher": 60, "inherit": [56, 98], "initi": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 36, 37, 45, 46, 54, 55, 58, 59, 60, 61, 64, 66, 67, 69, 96, 98, 99], "inlin": [38, 56], "inlinebackend": 56, "inner": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 67], "innermost": 67, "input": [2, 4, 5, 7, 8, 9, 10, 11, 12, 37, 59, 62, 83, 84, 86, 89, 93], "insight": [48, 60], "insignific": 59, "inspect": 96, "inspir": [16, 20, 21, 26, 60], "instal": [36, 40, 98], "install_github": 95, "instanc": [36, 37, 54, 67], "instanti": [35, 36, 53, 54, 67, 69], "instead": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 34, 36, 40, 41, 50, 51, 54, 55, 66, 67, 84, 87, 88, 90, 91, 98], "instruct": 98, "instrument": [3, 6, 7, 10, 14, 20, 22, 35, 36, 37, 38, 40, 46, 51, 53, 54, 55, 58, 59, 61, 64, 67, 68, 70, 77, 83, 96, 99], "instrument_effect": 32, "instrument_impact": 41, "int": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 34, 35, 36, 41, 45, 46, 57, 58, 60, 61], "int64": [38, 52, 53, 64, 96], "int8": [54, 55, 59], "integ": [18, 37, 67], "integr": [60, 84, 92, 98], "intend": [37, 60, 99], "intent": 99, "inter": 67, "interact": [7, 8, 16, 20, 21, 60, 65, 67, 85, 90, 94, 98, 99], "interchang": 83, "interest": [7, 8, 10, 11, 16, 17, 33, 36, 42, 46, 48, 54, 55, 61, 63, 66, 68, 70, 83, 93, 96, 99], "interfac": [34, 36, 37, 64, 67, 69, 96], "intermedi": [50, 60], "intern": [34, 36, 37, 40, 55, 67, 97], "internet": [36, 54, 55], "interpret": [49, 50, 60, 66, 84, 85, 86, 90, 91, 92, 95, 99], "intersect": [60, 84, 89, 98], "interv": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 40, 43, 44, 45, 46, 49, 50, 53, 55, 58, 59, 61, 65, 66, 69, 70, 84, 89, 96, 97, 99], "introduc": [33, 42, 63, 64, 83, 93, 98, 99], "introduct": [33, 35, 37, 42, 53, 55, 59, 67, 68, 84, 86], "introductori": [34, 60], "intrument": 61, "intuit": 60, "inuidur1": [37, 38, 64, 96], "inuidur1femaleblackothracedep1dep2q2q3q4q5q6agelt35agegt54durablelusdhusdtg": [37, 64, 96], "inuidur2": [38, 64, 96], "inv_sigmoid": 56, "invalid": [33, 42, 63], "invari": 68, "invers": [2, 7, 8, 9, 12, 13, 61, 84, 85, 90], "invert_yaxi": 53, "investig": [48, 60], "involv": [66, 67, 70, 99], "io": [40, 56, 98], "ipw_norm": 98, "ipykernel_13591": 50, "ipynb": [32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], "ipython": 40, "ipython_displai": 40, "ipythondisplayformatt": 40, "ira": [36, 54, 55], "irm": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 21, 27, 28, 52, 60, 62, 65, 67, 76, 85, 90, 94, 98, 99], "irm_summari": 54, "irmglmnet": 36, "irmrang": 36, "irmrpart": 36, "irmxgboost8047": 36, "irrespect": 60, "is_classifi": [4, 5, 7, 8, 11], "is_gat": [1, 8, 11], "isnan": [2, 4, 5, 7, 8, 9, 10, 11, 12, 52, 67], "isoton": 60, "isotonicregress": 60, "issn": 48, "issu": [54, 60, 94, 97, 98], "ite": [40, 49, 50, 51], "item": [7, 54, 62, 67, 69], "iter": [32, 46, 53, 61, 67, 83, 93, 99], "itertool": 48, "its": [29, 30, 60, 62, 66, 67, 68, 69, 70, 83], "iv": [7, 10, 11, 20, 22, 23, 33, 35, 42, 53, 63, 64, 80, 81, 84, 91, 94, 98, 99], "iv_2": 32, "iv_var": [35, 53], "iv\u00e1n": [69, 97], "j": [14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 33, 34, 35, 37, 40, 42, 48, 53, 56, 61, 63, 67, 68, 83, 93, 94, 96], "j_": [35, 53], "j_0": 83, "j_1": [35, 53], "j_2": [35, 53], "j_3": [35, 53], "j_k": [35, 53], "jame": 97, "janni": [36, 54], "javanmard": 97, "jbe": [35, 53], "jeconom": [16, 17, 18, 34], "jerzi": 97, "jia": 60, "jk": 68, "jmlr": [37, 94, 96, 98], "job": [36, 54, 55], "joint": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 40, 43, 44, 45, 49, 50, 55, 58, 68, 83, 98, 99], "jointli": [58, 66], "joss": [37, 67, 94, 96], "journal": [14, 15, 16, 17, 18, 23, 24, 26, 34, 35, 37, 48, 53, 56, 60, 63, 67, 94, 96, 97, 98], "jss": 94, "jump": 57, "jun": [34, 97], "jupyt": [32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], "juraj": 97, "just": [34, 37, 40, 45, 46, 47, 49, 50, 51, 57, 58, 70, 73, 74, 84, 86], "justif": [69, 84, 86], "k": [14, 17, 18, 20, 21, 22, 23, 24, 26, 33, 35, 37, 42, 52, 53, 62, 63, 65, 66, 83, 93, 99], "kaggl": [36, 54], "kallu": [45, 55, 58, 59, 70, 72, 77, 82, 97], "kato": [23, 35, 53, 83, 93, 97], "kb": [40, 46, 51, 53, 54, 55, 59, 64, 96], "kde": [9, 12, 13, 54], "kdeplot": [46, 52, 61], "kdeunivari": [9, 12, 13], "kecsk\u00e9sov\u00e1": 98, "keep": [34, 50, 60, 99], "kei": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 36, 43, 44, 49, 50, 53, 54, 55, 60, 67, 70, 84, 89, 98], "keith": 97, "kengo": 97, "kernel": [9, 12, 13], "keyword": [18, 23, 24, 25], "kf": 69, "kfold": [53, 69], "kind": [32, 41, 54], "kj": [17, 18, 20, 21, 22, 23, 24, 26, 33, 35, 42, 53, 63], "klaassen": [20, 60, 94, 97], "klaa\u00dfen": 20, "knau": 97, "know": [46, 57], "knowledg": [32, 41, 52, 56, 57], "known": [51, 52, 60, 67], "kohei": 97, "kotthof": 37, "kotthoff": [37, 67, 94, 96], "krueger": 56, "kueck": [36, 54], "kurz": [94, 97, 98], "kwarg": [16, 17, 18, 23, 24, 25, 29, 40], "l": [35, 37, 38, 43, 44, 53, 60, 61, 67, 84, 91, 94, 96], "l1": [54, 61, 68], "l_hat": [10, 11, 33, 42, 70], "label": [40, 42, 43, 44, 45, 47, 49, 50, 55, 56, 58], "labor": 56, "laffer": 97, "laff\u00e9r": [26, 61, 68, 70, 78, 79], "lal": [56, 98], "lambda": [35, 36, 37, 54, 56, 57, 67, 70, 74, 83, 93, 96], "lambda_": 48, "lambda_0": [70, 74], "lambda_t": 18, "land": 57, "lang": [37, 67, 94, 96], "langl": [19, 57], "lappli": 69, "larg": [33, 42, 51, 52, 56, 60], "larger": [8, 34, 60, 84, 89], "largest": 52, "largli": 52, "lasso": [35, 36, 37, 54, 61, 67, 96, 97], "lasso_class": [36, 54], "lasso_pip": [37, 67], "lasso_summari": 54, "lassocv": [48, 53, 54, 61, 67, 68, 83, 93, 96], "last": [18, 37, 40, 95], "late": [7, 32, 36, 54, 68, 70, 75], "latent": [2, 4, 5, 7, 8, 9, 10, 11, 12, 17, 59, 84, 91, 92], "later": [36, 37, 60, 67, 99], "layout": 48, "lbrace": [7, 8, 20, 21, 26, 35, 53, 62, 68, 69, 70, 71, 83, 84, 85, 93], "ldot": [10, 11, 35, 53, 61, 62, 68, 69, 83, 93, 96], "le": [18, 46, 57, 66, 68, 70, 77, 82], "lead": [34, 60], "leadsto": 83, "lear": [37, 67, 94, 96], "learn": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 23, 24, 25, 26, 32, 36, 37, 38, 40, 41, 45, 48, 52, 54, 55, 56, 58, 60, 64, 65, 67, 69, 70, 83, 84, 86, 93, 98, 99], "learner": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 36, 42, 43, 44, 46, 48, 53, 54, 55, 59, 60, 61, 62, 63, 65, 68, 69, 70, 83, 84, 89, 93, 98, 99], "learner_class": 98, "learner_cv": 37, "learner_forest_classif": 37, "learner_forest_regr": 37, "learner_l": 59, "learner_lasso": 37, "learner_list": 52, "learner_m": 59, "learner_nam": [2, 4, 5, 7, 8, 9, 10, 11, 12, 67], "learner_param_v": 37, "learner_rf": 83, "learnerclassif": 37, "learnerregr": 37, "learnerregrcvglmnet": 37, "learnerregrrang": [37, 67], "learning_r": [42, 45, 55, 58, 60, 63], "least": [32, 36, 41, 54, 55, 59, 69], "leav": [60, 61], "left": [20, 21, 22, 23, 26, 33, 35, 40, 42, 52, 53, 54, 55, 56, 58, 63, 70, 73, 74, 83, 84, 85, 87, 88, 90, 93], "legend": [36, 40, 42, 43, 44, 45, 47, 49, 50, 52, 55, 56, 58], "len": [40, 45, 52, 53, 55, 58], "length": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 37, 46, 67], "leq": [35, 53], "less": [34, 36, 54, 55, 60], "lester": 97, "let": [16, 17, 18, 33, 34, 36, 37, 40, 42, 45, 46, 49, 50, 52, 54, 55, 58, 60, 61, 62, 63, 67, 68, 84, 86, 92, 99], "level": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 36, 40, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 58, 59, 60, 61, 67, 70, 71, 84, 85, 89, 99], "level_0": [37, 53], "level_1": 53, "level_bound": 40, "levinsohn": [35, 53], "lewi": 97, "lgbmclassifi": [45, 46, 47, 52, 55, 58, 60], "lgbmregressor": [42, 45, 46, 47, 52, 55, 60, 63], "lgr": [33, 34, 35, 36, 37, 62, 67, 68, 69, 70, 83, 93, 96], "lib": [40, 53, 54], "liblinear": [54, 61, 68], "librari": [32, 33, 34, 35, 36, 37, 62, 63, 64, 67, 68, 69, 70, 83, 93, 95, 96, 99], "licens": 98, "lie": 97, "lightgbm": [42, 45, 46, 47, 52, 55, 58, 60], "like": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 36, 37, 48, 50, 54, 55, 60, 67, 69, 96, 99], "lim": 56, "limegreen": [43, 44], "limit": [56, 97], "limits_": 66, "lin": 60, "line": [2, 4, 5, 7, 8, 9, 10, 11, 12, 40, 47, 60], "linear": [1, 8, 10, 11, 16, 17, 22, 23, 24, 25, 27, 28, 32, 33, 34, 35, 37, 40, 41, 42, 43, 44, 46, 47, 48, 49, 52, 53, 59, 60, 62, 63, 65, 66, 67, 69, 71, 73, 74, 75, 76, 80, 81, 83, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99], "linear_model": [38, 40, 41, 48, 52, 53, 54, 60, 61, 67, 68, 83, 93, 96], "linearregress": [32, 40, 41, 52, 60], "linearscoremixin": 70, "lineplot": 40, "linestyl": [40, 47], "linewidth": 47, "link": [60, 98], "linspac": [43, 44, 60], "lint": 98, "linux": 95, "list": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 33, 34, 35, 36, 37, 42, 43, 44, 53, 55, 57, 63, 67, 69, 70, 95, 98], "listedcolormap": 53, "literatur": [60, 68], "littl": 51, "ll": [37, 83, 93, 99], "lllllllllllllllll": [64, 96], "lm": [32, 34, 60], "ln_alpha_ml_l": 48, "ln_alpha_ml_m": 48, "load": [32, 34, 36, 37, 48, 54, 55, 64, 95, 96], "loc": [40, 42, 45, 47, 48, 50, 53, 56, 58, 59, 60], "local": [7, 9, 66, 68, 97, 98], "localconvert": 53, "locat": [45, 58], "log": [35, 48, 52, 53, 56, 59, 67, 68], "log_odd": 57, "log_p": [35, 53], "log_reg": [32, 34], "logarithm": 48, "logic": [7, 37, 67], "logical_not": [2, 4, 5, 7, 8, 9, 10, 11, 12, 52, 67], "logist": [16, 32, 34, 36, 41, 54, 60, 61, 99], "logisticregress": [32, 38, 40, 41, 60], "logisticregressioncv": [52, 54, 61, 68], "logit": [52, 56], "loglik": [37, 67], "logloss": [36, 54, 99], "logo": 98, "logspac": 54, "long": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 33, 42, 52, 59, 60, 84, 86, 92, 97], "look": [34, 36, 37, 45, 46, 47, 52, 54, 55, 58, 59], "loop": 40, "loss": [52, 59, 67, 68], "loss_ml_g0": 52, "loss_ml_g1": 52, "loss_ml_m": 52, "low": [47, 51, 66, 97], "lower": [36, 37, 40, 45, 47, 48, 51, 55, 56, 58, 59, 60, 67, 84, 89, 92, 99], "lower_bound": [43, 44], "lpq": [9, 13, 55, 66, 77, 98], "lpq_0": 58, "lpq_1": 58, "lqte": 66, "lrn": [32, 33, 34, 35, 36, 37, 62, 67, 68, 69, 70, 83, 93, 96, 99], "lrn_0": 37, "lt": [32, 34, 35, 36, 37, 38, 40, 46, 51, 53, 54, 55, 57, 59, 60, 61, 64, 96], "lucien": 98, "luka": 97, "luk\u00e1\u0161": 26, "lusd": [37, 38, 64, 96], "lvert": 48, "m": [14, 15, 16, 22, 23, 24, 33, 35, 37, 38, 42, 48, 51, 53, 56, 63, 65, 66, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 87, 88, 90, 91, 92, 94, 95, 96, 97, 98], "m_": [68, 70, 71, 77, 83, 93], "m_0": [2, 4, 5, 7, 8, 10, 11, 12, 24, 25, 33, 35, 36, 42, 48, 51, 53, 54, 63, 66, 67, 68, 70, 72, 73, 74, 77, 78, 79, 82, 96, 99], "m_hat": [7, 8, 10, 11, 33, 42, 70], "ma": [23, 35, 53, 97], "mac": 95, "machin": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 23, 24, 25, 26, 32, 36, 37, 38, 40, 41, 45, 46, 48, 54, 55, 56, 58, 59, 60, 61, 65, 67, 68, 69, 70, 83, 84, 86, 93, 98, 99], "machineri": [48, 97], "mackei": 97, "maco": 95, "made": [68, 99], "mae": [2, 4, 5, 7, 8, 9, 10, 11, 12, 52, 67], "maggi": 97, "magnitud": [84, 86], "mai": [46, 61], "main": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 48, 55, 60, 83, 84, 86, 93, 97, 99], "mainli": 60, "maintain": [34, 94, 98], "mainten": 98, "major": [37, 60, 98], "make": [32, 40, 41, 52, 60, 66, 67, 98, 99], "make_confounded_irm_data": [60, 98], "make_confounded_plr_data": 59, "make_did_sz2020": [4, 5, 46, 68], "make_heterogeneous_data": [43, 44, 49, 50, 51], "make_iivm_data": [7, 9, 66, 68], "make_irm_data": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 52, 66, 67, 68], "make_irm_data_discrete_treat": 40, "make_pipelin": 54, "make_pliv_chs2015": [10, 68], "make_pliv_multiway_cluster_ckms2021": [3, 35, 53], "make_plr_ccddhnr2018": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 33, 42, 62, 63, 66, 67, 68, 69, 70, 83, 84, 89], "make_spd_matrix": 25, "make_ssm_data": [61, 68], "malt": [94, 97], "maltekurz": 94, "man": [32, 41], "manag": [67, 95], "mani": [22, 27, 28, 33, 34, 35, 37, 42, 46, 53, 63, 70, 83, 93, 99], "manili": 1, "manipul": [36, 37], "manual": [36, 59, 99], "mao": 97, "map": [7, 29, 30, 34, 35, 53, 66, 68], "mapsto": [62, 66], "mar": [26, 68], "margin": [43, 44, 60], "marit": [36, 54], "marker": [40, 60], "markers": 56, "market": 56, "markettwo": 35, "markov": [25, 97], "marr": [36, 54, 55, 59, 99], "marshal": 67, "martin": [26, 60, 94, 97, 98], "masatoshi": 97, "master": 34, "mat": 35, "match": [67, 84, 91], "mathbb": [7, 8, 10, 11, 16, 17, 18, 27, 28, 35, 40, 46, 47, 51, 52, 53, 56, 61, 66, 68, 70, 71, 72, 73, 74, 76, 77, 78, 79, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 96, 99], "mathcal": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 35, 42, 45, 47, 53, 57, 58, 61, 63], "mathop": 66, "mathrm": [16, 17], "matplotlib": [38, 40, 42, 43, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 56, 58, 60, 61], "matric": [57, 65, 98], "matrix": [16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 33, 35, 36, 37, 42, 53, 61, 63, 64, 67, 83, 93, 96, 98, 99], "matt": 97, "matter": [52, 56], "max": [36, 37, 54, 55, 62, 66, 67, 68, 69, 70, 72, 83, 96, 99], "max_depth": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 42, 54, 59, 62, 66, 67, 68, 69, 70, 83, 84, 89, 96, 99], "max_featur": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 42, 54, 59, 62, 66, 67, 68, 69, 70, 83, 84, 89, 96, 99], "max_it": [53, 54, 60], "maxim": [2, 4, 5, 7, 8, 9, 10, 11, 12, 57, 66], "maxima": [83, 93], "maximum": [66, 67], "mb": [38, 61, 64, 96], "mb706": 98, "mea": 20, "mean": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 35, 36, 40, 41, 42, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 63, 67, 83, 99], "mean_absolute_error": [2, 4, 5, 7, 8, 9, 10, 11, 12, 52, 67], "meant": [66, 98], "measir": 59, "measur": [34, 37, 48, 59, 60, 67, 68, 84, 85, 86, 90, 91, 92], "measure_col": 48, "measure_func": 34, "measure_pr": 34, "measures_r": 34, "mechan": [29, 30, 60], "median": [60, 69], "melt": 35, "membership": 60, "memori": [38, 40, 46, 51, 53, 54, 55, 59, 61, 64, 96], "mention": [51, 66], "merg": [36, 54], "mert": [69, 97], "meshgrid": [43, 44, 60], "messag": [33, 34, 35, 36, 37, 96, 98], "meta": [67, 96], "metadata": [29, 30], "metadatarequest": [29, 30], "method": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 49, 50, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 66, 67, 68, 69, 70, 83, 84, 86, 89, 93, 94, 96, 98], "methodolog": 97, "methodologi": 60, "metric": [2, 4, 5, 7, 8, 9, 10, 11, 12, 67], "michael": 97, "michaela": 98, "michel": [94, 96], "michela": [26, 97], "mid": [36, 54, 56], "mid_point": 40, "might": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 45, 52, 53, 57, 59, 60, 67], "mild": [33, 42, 63], "militari": 56, "miller": [35, 53], "mime": 40, "mimic": 60, "min": [35, 36, 37, 45, 53, 54, 55, 58, 62, 67, 68, 69, 70, 83, 93, 96, 99], "min_": 66, "min_samples_leaf": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 42, 51, 54, 59, 62, 66, 67, 68, 69, 70, 83, 84, 89, 99], "min_samples_split": 54, "minim": [8, 36, 52, 54], "minor": [33, 42, 63, 70, 98], "minsplit": 36, "miruna": 97, "mislead": 98, "miss": [3, 6, 37, 67, 68, 70, 78, 98], "missing": [26, 61], "misspecif": 46, "misspecifi": 46, "mit": [94, 96], "mixin": [27, 28, 70], "ml": [25, 35, 36, 37, 48, 53, 54, 62, 65, 67, 69, 94, 97, 98], "ml_g": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 36, 38, 40, 41, 42, 43, 45, 46, 47, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 63, 66, 67, 68, 98], "ml_g0": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 36, 38, 46, 52, 54, 59, 67, 68], "ml_g1": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 36, 38, 46, 52, 54, 59, 67, 68], "ml_g_d0": [61, 68], "ml_g_d0_t0": [46, 68], "ml_g_d0_t1": [46, 68], "ml_g_d1": [61, 68], "ml_g_d1_t0": [46, 68], "ml_g_d1_t1": [46, 68], "ml_l": [10, 11, 33, 35, 36, 37, 38, 42, 44, 50, 53, 54, 56, 59, 62, 63, 67, 68, 69, 70, 83, 84, 89, 93, 96, 98, 99], "ml_l_bonu": 96, "ml_l_forest": 37, "ml_l_forest_pip": 37, "ml_l_lasso": 37, "ml_l_lasso_pip": 37, "ml_l_rf": 99, "ml_l_sim": 96, "ml_l_tune": 67, "ml_l_xgb": 99, "ml_m": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 66, 67, 68, 69, 70, 83, 84, 89, 93, 96, 98, 99], "ml_m_bench_control": 60, "ml_m_bench_treat": 60, "ml_m_bonu": 96, "ml_m_forest": 37, "ml_m_forest_pip": 37, "ml_m_lasso": 37, "ml_m_lasso_pip": 37, "ml_m_rf": 99, "ml_m_sim": 96, "ml_m_tune": 67, "ml_m_xgb": 99, "ml_pi": [61, 68], "ml_r": [7, 10, 32, 35, 36, 41, 53, 54, 68, 98], "ml_r0": 68, "ml_r1": [36, 54, 68], "mlr": [37, 67], "mlr3": [32, 33, 34, 35, 36, 62, 67, 68, 69, 70, 83, 93, 94, 96, 98, 99], "mlr3book": [37, 67], "mlr3extralearn": [36, 67], "mlr3filter": 37, "mlr3learner": [32, 33, 34, 35, 36, 62, 67, 68, 69, 70, 83, 93, 96, 99], "mlr3measur": 34, "mlr3pipelin": [67, 98], "mlr3tune": [37, 67, 98], "mlr3vers": 36, "mlrmeasur": 34, "mode": [60, 95], "model": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 37, 41, 42, 45, 46, 47, 48, 51, 52, 53, 55, 58, 59, 62, 63, 64, 65, 67, 71, 73, 74, 75, 76, 80, 81, 85, 86, 89, 90, 91, 92, 93, 94, 97, 98], "model_data": [36, 54], "model_select": [2, 4, 5, 7, 8, 9, 10, 11, 12, 42, 53, 67, 69], "modelmlestimatelowerupp": 36, "modern": [37, 67, 94, 96], "moment": [27, 28, 35, 53, 70, 83, 84, 86, 92, 93, 96], "monoton": 68, "mont": [16, 17, 19, 43, 44, 49, 50], "montanari": 97, "more": [8, 32, 34, 36, 40, 41, 43, 44, 48, 52, 54, 55, 59, 60, 62, 66, 67, 68, 70, 76, 83, 84, 86, 89, 92, 96, 99], "moreov": [36, 37, 48, 67, 83, 93, 99], "mortgag": [36, 54, 55], "most": [36, 40, 45, 52, 54, 55, 58, 60, 66, 67, 84, 89, 95], "motiv": [60, 63], "motivation_example_bch": 48, "mp": 34, "mpd": [35, 53], "mpg": 53, "mse": [37, 48, 67], "msr": [37, 67], "mtry": [36, 37, 62, 67, 68, 69, 70, 83, 99], "mu": 47, "mu_": 47, "mu_mean": 47, "much": [36, 37, 54, 60, 99], "muld": [38, 64, 96], "multi": [34, 35, 43, 44, 53], "multiclass": 37, "multiindex": 53, "multipl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 46, 53, 54, 59, 60, 61, 64, 67, 69, 83, 84, 86, 93, 98, 99], "multipletest": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "multipli": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 42, 65, 66, 70, 99], "multiprocess": [45, 55, 58], "multitest": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "multiwai": [23, 35, 53, 97], "music": 97, "must": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 67, 68], "mutat": 37, "mutual": [8, 11, 36, 49, 50, 54, 55, 66], "my_sampl": 69, "my_task": 69, "n": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 32, 33, 35, 37, 40, 41, 42, 45, 47, 48, 51, 53, 56, 57, 58, 61, 62, 63, 66, 67, 69, 83, 93, 94, 95], "n_": 47, "n_coef": [2, 4, 5, 7, 8, 9, 10, 11, 12, 84, 89], "n_complier": 58, "n_core": [45, 55, 58], "n_estim": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 42, 43, 44, 45, 46, 47, 49, 50, 51, 54, 55, 57, 58, 59, 60, 62, 63, 66, 67, 68, 69, 70, 83, 84, 89, 96, 99], "n_eval": [37, 67], "n_fold": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 67, 69, 96, 99], "n_folds_per_clust": [35, 53], "n_folds_tun": [2, 4, 5, 7, 8, 9, 10, 11, 12], "n_iter_randomized_search": [2, 4, 5, 7, 8, 9, 10, 11, 12, 67], "n_job": 54, "n_jobs_cv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 52], "n_jobs_model": [13, 45, 55, 58], "n_level": 40, "n_ob": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 33, 37, 40, 42, 43, 44, 46, 47, 49, 50, 51, 52, 59, 60, 61, 63, 64, 66, 67, 68, 69, 83, 84, 89, 93, 96], "n_rep": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 34, 35, 38, 40, 42, 46, 51, 52, 53, 59, 60, 61, 63, 67, 69, 84, 89, 96, 99], "n_rep_boot": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 43, 44, 45, 49, 50, 55, 58, 83, 93], "n_sampl": 57, "n_split": 69, "n_t": 47, "n_time_period": 47, "n_true": [45, 58], "n_var": [33, 37, 42, 63, 64, 67, 83, 93, 96], "n_w": 57, "n_x": [19, 43, 44, 49, 50, 51], "na": [3, 6, 33, 35, 63, 98], "na_real_": [35, 98], "naiv": [33, 42, 63], "name": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 33, 34, 35, 49, 50, 51, 53, 59, 60, 67, 95, 98], "namespac": 34, "nan": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 40, 42, 45, 46, 47, 49, 50, 52, 54, 55, 58, 61, 63, 67], "nanmean": 42, "narita": 97, "nathan": 97, "nation": [60, 69, 97], "nativ": 34, "natt": 57, "natur": 60, "nbformat": 40, "ncol": [35, 36, 37, 64, 67, 83, 93, 96], "ncoverag": 52, "ndarrai": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 20, 21, 22, 23, 24, 25, 26, 64], "nearli": 52, "necess": [35, 53], "necessari": [34, 35, 53], "need": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 28, 32, 33, 34, 36, 41, 42, 55, 61, 67, 69, 84, 92, 98, 99], "neighborhood": 83, "neither": [3, 6, 35, 53, 64], "neng": 97, "neq": 68, "nest": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 67, 70, 79, 84, 89], "net": [55, 59, 99], "net_tfa": [36, 54, 55, 59, 99], "never": [7, 34, 35, 50, 53, 98], "never_tak": [7, 36, 54], "new": [32, 33, 34, 35, 36, 37, 43, 44, 54, 57, 62, 63, 64, 66, 67, 68, 69, 70, 83, 93, 94, 96, 97, 98, 99], "new_data": [43, 44, 57], "newei": [14, 15, 24, 35, 48, 53, 60, 63, 94, 97], "newest": 98, "next": [34, 36, 37, 43, 44, 45, 51, 52, 54, 55, 57, 58, 60, 98], "neyman": [35, 53, 62, 65, 84, 92, 94, 97], "nfold": [35, 36], "nice": 34, "nifa": [54, 55, 59], "nil": 60, "nine": [35, 53], "node": [36, 37, 62, 68, 69, 70, 83, 96, 99], "nois": [56, 57], "non": [18, 23, 24, 25, 32, 33, 36, 41, 42, 47, 54, 55, 57, 67, 69, 70, 83], "non_orth_scor": [33, 42, 70], "nondur": 38, "none": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 35, 36, 38, 40, 41, 46, 51, 54, 55, 59, 60, 61, 64, 67, 68, 70, 83, 95, 96], "nonignor": 79, "nonlinear": [28, 36, 54, 70, 77, 82, 98], "nonlinearscoremixin": 70, "nonparametr": [9, 12, 13, 60, 84, 85, 86, 90, 91, 92, 97], "nop": 37, "nor": [3, 6, 35, 53, 64], "norm": 42, "normal": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 33, 41, 42, 45, 46, 47, 51, 55, 56, 57, 58, 61, 63, 64, 67, 70, 73, 74, 83, 93, 96], "normalize_ipw": [2, 7, 8, 9, 12, 13, 55, 61], "notat": [35, 46, 53, 61, 68], "note": [3, 6, 7, 8, 10, 11, 27, 28, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 69, 70, 94, 96], "notebook": [32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 66, 67, 99], "notic": [32, 41], "now": [34, 35, 36, 43, 44, 52, 53, 54, 57, 60, 61, 96, 98], "np": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 20, 21, 22, 23, 24, 25, 26, 38, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 96, 99], "nround": [33, 36, 99], "nrow": [34, 35, 37, 64, 67, 83, 93, 96], "nu": [7, 18, 25, 61, 68, 84, 86, 89, 91, 92], "nu2": [84, 89], "nu_0": [84, 92], "nu_i": 61, "nuis_g0": 32, "nuis_g1": 32, "nuis_l": 99, "nuis_m": [32, 99], "nuis_r0": 32, "nuis_r1": 32, "nuis_rmse_ml_l": 48, "nuis_rmse_ml_m": 48, "nuisanc": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 24, 25, 33, 34, 35, 36, 37, 42, 43, 44, 45, 46, 48, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 67, 69, 70, 71, 73, 74, 77, 83, 84, 92, 94, 98, 99], "nuisance_el": [84, 85, 87, 88, 90, 91], "nuisance_loss": [52, 67, 98], "nuisance_target": 52, "null": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 59, 67, 84, 89, 98], "null_hypothesi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 59, 84, 89], "num": [36, 37, 62, 67, 68, 69, 70, 83, 96], "num_leav": [45, 47, 55, 58], "number": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 35, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 55, 57, 58, 60, 69, 83, 93, 94, 96, 99], "numer": [28, 32, 37, 56, 67, 70, 84, 85, 90, 98], "numeric_onli": 48, "numpi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 96], "ny": 97, "o": [40, 47, 49, 50, 54, 56, 83, 94, 96], "ob": [34, 36, 47], "obei": 70, "obj": 40, "obj_dml_data": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 35, 41, 42, 45, 53, 58, 62, 63, 66, 67, 68, 69, 70, 83, 84, 89, 98], "obj_dml_data_bonu": 64, "obj_dml_data_bonus_df": 64, "obj_dml_data_from_arrai": [3, 6], "obj_dml_data_from_df": [3, 6], "obj_dml_data_sim": 64, "obj_dml_plr": [33, 42, 63], "obj_dml_plr_bonu": [37, 96], "obj_dml_plr_bonus_pip": 37, "obj_dml_plr_bonus_pipe2": 37, "obj_dml_plr_bonus_pipe3": 37, "obj_dml_plr_bonus_pipe_ensembl": 37, "obj_dml_plr_nonorth": [33, 42], "obj_dml_plr_orth_nosplit": [33, 42], "obj_dml_plr_sim": [37, 96], "obj_dml_plr_sim_pip": 37, "obj_dml_plr_sim_pipe_ensembl": 37, "obj_dml_plr_sim_pipe_tun": 37, "object": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30, 32, 36, 37, 38, 40, 43, 44, 45, 46, 50, 51, 54, 55, 58, 61, 64, 66, 67, 68, 69, 70, 83, 94, 96, 97, 98, 99], "obs_confound": [32, 41], "observ": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 73, 74, 83, 84, 86, 87, 88, 96, 97, 99], "obtain": [17, 32, 33, 34, 35, 41, 42, 43, 44, 45, 46, 48, 52, 53, 58, 60, 61, 62, 63, 66, 67, 69, 70, 83, 84, 86, 89, 93, 95, 96], "occur": 98, "off": [57, 97], "offer": [34, 36, 54, 55, 60, 99], "offici": 95, "often": 58, "oka": 97, "omega": [51, 66, 70, 71, 76, 84, 85, 90], "omega_": [23, 35, 53], "omega_1": [23, 35, 53], "omega_2": [23, 35, 53], "omega_epsilon": [35, 53], "omega_v": [23, 35, 53], "omega_x": [23, 35, 53], "omit": [59, 60, 84, 86, 92, 97, 98, 99], "ommit": 60, "onc": [34, 60, 99], "one": [10, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 52, 53, 55, 56, 59, 60, 63, 66, 67, 68, 69, 70, 73, 74, 76, 80, 81, 83, 84, 85, 86, 89, 90, 91, 93, 96, 98], "ones": [37, 45, 47, 58, 59, 66], "ones_lik": [40, 58], "onli": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 43, 44, 49, 50, 51, 52, 53, 54, 55, 62, 66, 67, 68, 70, 72, 77, 82, 83, 84, 85, 86, 90, 92, 98], "onlin": 99, "onto": 52, "oob_error": [37, 67], "oop": 98, "opac": [43, 44], "open": [37, 67, 94, 96], "oper": 37, "opposit": 57, "oprescu": [19, 43, 44, 49, 50, 97], "opt": 54, "optim": [2, 4, 5, 7, 8, 9, 10, 11, 12, 37, 43, 44, 57, 66, 67, 97], "option": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 35, 36, 40, 43, 44, 49, 50, 51, 52, 53, 54, 55, 61, 67, 69, 70, 72, 77, 82, 83, 93, 98], "oracl": 40, "oracle_valu": [16, 17, 40], "orang": 33, "orcal": [16, 17], "order": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 36, 37, 53, 54, 67, 69, 70], "org": [20, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 67, 94, 95, 98], "orient": [37, 67, 70, 94, 96, 97, 98], "origin": [34, 37, 50, 57, 59, 60, 66], "orign": [36, 54], "orth_sign": 1, "orthogon": [1, 35, 36, 53, 54, 62, 65, 83, 84, 92, 93, 94, 97], "orthongon": [84, 92], "osx": 95, "other": [3, 6, 10, 11, 33, 35, 36, 37, 40, 42, 46, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 66, 67, 68, 69, 70, 76, 83, 84, 92, 94, 95, 96, 97, 98, 99], "other_ind": 53, "otherwis": [4, 5, 7, 8, 11, 36, 54, 55, 57, 68], "othrac": [37, 38, 64, 96], "our": [33, 34, 36, 37, 42, 43, 44, 45, 46, 52, 54, 55, 58, 59, 60, 63, 94, 96, 98, 99], "ourselv": 52, "out": [10, 11, 35, 37, 38, 46, 48, 52, 53, 55, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 80, 81, 83, 84, 86, 89, 91, 94, 96, 98, 99], "outcom": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 18, 32, 34, 35, 36, 37, 38, 41, 47, 48, 51, 53, 54, 55, 56, 57, 58, 59, 60, 64, 67, 71, 83, 85, 86, 89, 91, 92, 96, 98, 99], "outcome_0": 41, "outcome_1": 41, "outer": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 67], "output": [34, 52, 62, 83, 93, 99], "outshr": 53, "outsid": 33, "over": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 40, 42, 48, 52, 63, 65, 67, 84, 89, 93], "overal": [57, 60], "overcom": [65, 70], "overfit": [65, 69], "overlap": [46, 60, 68], "overrid": [67, 98], "overst": [36, 54, 55], "overview": [52, 83, 84, 89, 97], "overwrit": 98, "ownership": [36, 54], "p": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 21, 33, 34, 35, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 82, 83, 84, 85, 90, 93, 94, 95, 96, 98], "p401": [36, 54, 55], "p_0": [70, 73, 74], "p_1": [83, 93], "p_adjust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 69, 83, 93, 94, 96], "p_dbl": [37, 67], "p_int": 67, "p_n": 22, "p_val": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "p_x": [23, 35, 53], "p_x0": 56, "p_x1": 56, "packag": [32, 33, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 55, 57, 58, 59, 60, 61, 62, 63, 66, 67, 68, 69, 70, 83, 84, 86, 94, 96, 97, 98, 99], "packagedata": 53, "packagevers": 36, "page": [60, 94, 97], "pair": [32, 41], "pake": [35, 53], "paket": [35, 36, 37], "pal": 35, "palett": 40, "panda": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 38, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 66, 84, 86, 96], "pandas2ri": 53, "panel": [4, 18, 88, 97, 98], "paper": [20, 22, 37, 56, 59, 60, 84, 92, 94, 96, 97, 98], "par": 38, "par_grid": [37, 67], "paradox": [37, 67, 98], "parallel": [34, 40, 45, 46, 47, 52, 58, 68], "param": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 67], "param_grid": [2, 4, 5, 7, 8, 9, 10, 11, 12, 67], "param_nam": 34, "param_set": [37, 67], "param_v": 37, "paramet": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 40, 42, 43, 44, 45, 46, 48, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 77, 82, 83, 84, 86, 89, 90, 92, 93, 94, 96, 97, 98, 99], "parametr": [34, 60, 63, 67, 99], "params_exact": 67, "params_nam": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34], "parenttoc": 94, "part": [25, 33, 35, 36, 37, 42, 52, 53, 54, 63, 67, 69, 84, 92, 98, 99], "parti": 25, "partial": [10, 11, 17, 22, 23, 24, 25, 28, 35, 37, 38, 48, 53, 59, 62, 65, 67, 69, 80, 81, 83, 85, 89, 90, 91, 92, 93, 94, 96, 98, 99], "partial_": [70, 83], "partiallli": 59, "particip": [14, 55, 59, 99], "particular": 94, "partion": [35, 53], "partit": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 53, 62, 65], "partli": 99, "pass": [1, 34, 37, 67, 99], "passo": [94, 96], "past": 35, "paste0": 35, "pastel": 42, "path": [67, 68], "path_to_r": 48, "patsi": [43, 44, 66], "pattern": 60, "paul": 97, "pd": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 40, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 66], "pdf": [42, 56], "pedregosa": [94, 96], "pedregosa11a": [94, 96], "pedro": [34, 97], "penal": 61, "penalti": [36, 37, 41, 54, 60, 61, 67, 68], "pennsylvania": [15, 64, 96], "pension": [36, 54, 55, 99], "peopl": [36, 54, 55], "pep8": 98, "per": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 35, 53], "percent": 67, "percentag": [2, 4, 5, 7, 8, 9, 10, 11, 12, 17], "perf_count": 52, "perform": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 35, 37, 42, 46, 48, 50, 51, 52, 53, 55, 59, 60, 61, 63, 67, 68, 69, 70, 83, 93, 94, 96, 97, 99], "perfrom": 51, "perhap": 99, "period": [4, 34, 46, 47, 68], "perp": 68, "perrot": [94, 96], "person": 99, "pessimist": 60, "peter": 97, "pfister": [37, 67, 94, 96], "phi": [35, 53, 66, 83], "philipp": [60, 94, 97], "philippbach": [94, 98], "pi": [21, 22, 25, 66, 68, 70, 78, 79], "pi_": [23, 35, 53], "pi_0": [70, 78, 79], "pi_i": [61, 68], "pick": 99, "pio": 40, "pip3": 95, "pipe": 37, "pipe_forest_classif": 37, "pipe_forest_regr": 37, "pipe_lasso": 37, "pipelin": [37, 54, 98], "pipeop": 37, "pira": [36, 54, 55, 59, 99], "pivot": [48, 53, 97], "plai": 99, "plan": [14, 36, 54, 55, 99], "plausibl": 60, "pleas": [29, 30, 34, 40, 60, 69], "plim": 56, "pliv": [10, 27, 28, 35, 53, 62, 66, 80, 94, 98], "plm": [65, 67, 83, 84, 89, 99], "plot": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 34, 36, 37, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 54, 55, 56, 58, 59, 60, 61, 66, 84, 89], "plot_tre": [57, 66], "plotli": [2, 4, 5, 7, 8, 9, 10, 11, 12, 40, 43, 44, 48, 60], "plr": [11, 27, 28, 37, 56, 59, 62, 67, 69, 81, 83, 89, 90, 91, 92, 93, 94, 96, 98, 99], "plr_est": 56, "plr_est1": 56, "plr_est2": 56, "plr_obj": 56, "plr_obj_1": 56, "plr_obj_2": 56, "plr_summari": 54, "plrglmnet": 36, "plrranger": 36, "plrrpart": 36, "plrxgboost8700": 36, "plt": [38, 40, 42, 43, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 56, 58, 60, 61], "plt_smpl": [35, 53], "plt_smpls_cluster": [35, 53], "plug": [51, 84, 85, 87, 88, 89, 90], "pm": [35, 53, 83, 84, 89, 92, 93], "pmatrix": 61, "po": [37, 67], "point": [2, 4, 5, 7, 8, 9, 10, 11, 12, 34, 35, 49, 50, 53, 60, 66, 99], "pointwis": [1, 45, 49, 50, 58], "poli": [36, 53, 54], "polici": [8, 10, 11, 65, 68, 96, 97, 98], "policy_tre": [8, 57, 66], "policy_tree_2": 57, "policy_tree_obj": 66, "policytre": 57, "polit": 56, "poly_dict": 54, "polynomi": [14, 15, 36, 38, 54], "polynomial_featur": [14, 15, 36, 38], "polynomialfeatur": [53, 54], "popul": [60, 70], "popular": [52, 84, 86], "porport": 59, "posit": [25, 36, 56, 60, 99], "posixct": [37, 67], "possibl": [3, 6, 34, 37, 43, 44, 49, 50, 51, 52, 57, 59, 60, 67, 68, 83, 84, 86, 98, 99], "possibli": [84, 86], "post": [22, 25, 68, 83, 93, 97], "postdoubl": 97, "poster": 56, "potenti": [2, 9, 12, 16, 46, 56, 61, 71, 72, 83, 85, 95, 98, 99], "potential_level": 40, "power": [37, 60, 67, 97], "pp": 34, "pq": [9, 12, 13, 55, 82, 98], "pq_0": [55, 58], "pq_1": [55, 58], "pr": [32, 35, 36, 37, 67, 68, 69, 70, 83, 96, 99], "practic": [52, 60, 97], "pre": [34, 46, 61, 67, 68], "precis": [34, 84, 90, 99], "pred": 34, "pred_df": 57, "pred_dict": 67, "pred_treat": 57, "predict": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 29, 30, 33, 35, 36, 37, 42, 45, 48, 52, 53, 54, 57, 60, 63, 66, 69, 84, 86, 89, 90, 98, 99], "predict_proba": [2, 4, 5, 7, 8, 9, 11, 12, 13, 29, 67], "predictor": [1, 8, 11, 43, 44, 49, 50, 60, 62], "prefer": [36, 54, 55, 99], "preliminari": [2, 33, 42, 70, 72, 77, 79, 82], "prepar": [34, 35, 53, 98], "preprint": 97, "preprocess": [36, 53, 54, 55, 67], "presenc": [36, 54, 55], "present": [34, 60, 67, 99], "prespecifi": 59, "pretest": 34, "pretreat": [4, 5, 34, 46], "prettenhof": [94, 96], "preval": 60, "prevent": [69, 98], "previou": [47, 51, 56, 95, 99], "previous": [67, 99], "price": [35, 53], "priliminari": [9, 13], "primari": 40, "principl": [84, 86], "print": [33, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 95, 96, 98, 99], "print_detail": 34, "print_method": 40, "prior": [52, 68], "privat": 98, "prob": 37, "probabilit": 51, "probabl": [2, 7, 8, 9, 12, 13, 18, 33, 34, 42, 46, 51, 56, 58, 60, 61, 63, 68, 70, 73, 74, 77, 97], "problem": [36, 54, 55, 66, 67], "procedur": [33, 35, 36, 42, 52, 53, 54, 59, 60, 67, 83, 93, 98], "proceed": [22, 97], "process": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 34, 43, 44, 45, 46, 47, 48, 49, 50, 52, 57, 58, 60, 61, 65, 83, 84, 86, 93, 97, 98], "produc": 56, "product": [43, 44, 48, 52, 60, 84, 92], "producton": 35, "program": [21, 36, 54, 55, 97, 99], "progress": 39, "project": [37, 43, 44, 66, 94, 98], "project_z": [43, 44], "prone": 70, "propens": [9, 13, 16, 17, 36, 46, 51, 52, 54, 55, 60, 61, 66, 68, 84, 85], "properli": 99, "properti": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 37, 52, 54, 55, 56, 59, 67, 84, 89, 96, 98], "proport": [59, 84, 86, 91, 92], "propos": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 37, 53, 84, 86, 97], "provid": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 34, 35, 36, 37, 43, 44, 49, 50, 53, 54, 60, 62, 63, 64, 65, 67, 83, 93, 94, 96, 98, 99], "prune": 8, "ps911c": 53, "ps944": 53, "pscore1": 56, "pscore2": 56, "psi": [27, 28, 33, 34, 35, 53, 62, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 92, 96], "psi_": [83, 84, 89, 91, 92, 93], "psi_a": [7, 8, 10, 11, 27, 33, 35, 42, 53, 69, 70, 71, 73, 74, 75, 76, 80, 81, 83], "psi_b": [7, 8, 10, 11, 27, 33, 42, 66, 69, 70, 71, 73, 74, 75, 76, 80, 81], "psi_el": [69, 70], "psi_j": [83, 93], "psi_nu2": [84, 89], "psi_sigma2": [84, 89], "public": [32, 41, 98], "publish": [60, 98], "pull": [36, 98], "purchas": 60, "pure": 60, "purp": [43, 44], "purpos": [33, 42, 51, 59, 60, 84, 86, 96], "pval": [83, 93], "px": 48, "py": [40, 50, 53, 54, 60, 94, 95, 98], "py3": 95, "py_al": 42, "py_dml": 42, "py_dml_nosplit": 42, "py_dml_po": 42, "py_dml_po_nosplit": 42, "py_double_ml_apo": 40, "py_double_ml_bas": 42, "py_double_ml_basic_iv": 41, "py_double_ml_c": 43, "py_double_ml_cate_plr": 44, "py_double_ml_cvar": 45, "py_double_ml_did": 46, "py_double_ml_did_pretest": 47, "py_double_ml_firststag": 48, "py_double_ml_g": 49, "py_double_ml_gate_plr": 50, "py_double_ml_gate_sensit": 51, "py_double_ml_learn": 52, "py_double_ml_multiway_clust": 53, "py_double_ml_pens": 54, "py_double_ml_pension_qt": 55, "py_double_ml_plm_irm_hetfx": 56, "py_double_ml_policy_tre": 57, "py_double_ml_pq": 58, "py_double_ml_sensit": 59, "py_double_ml_sensitivity_book": 60, "py_double_ml_ssm": 61, "py_non_orthogon": 42, "py_po_al": 42, "pydata": 50, "pypi": [97, 98], "pyplot": [38, 40, 42, 43, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 56, 58, 60, 61], "python": [25, 34, 60, 62, 63, 64, 65, 66, 68, 69, 70, 83, 84, 86, 89, 93, 94, 96, 97, 98, 99], "python3": [54, 95], "q": [37, 45, 58, 67, 94, 96], "q2": [37, 38, 64, 96], "q3": [37, 38, 64, 96], "q4": [37, 38, 64, 96], "q5": [37, 38, 64, 96], "q6": [37, 38, 64, 96], "qquad": 21, "qte": [45, 55, 98], "quad": [18, 36, 46, 54, 57, 61, 66, 68, 70, 77, 83, 84, 87, 93], "quadrat": 61, "qualiti": [59, 62, 98], "quanitl": 55, "quant": 45, "quantifi": 60, "quantil": [2, 9, 12, 13, 40, 45, 59, 65, 72, 77, 82, 97, 98], "quantiti": [32, 41, 60], "queri": 54, "question": [60, 99], "quick": 55, "quit": [52, 57, 59, 84, 86], "r": [7, 20, 42, 43, 44, 47, 48, 53, 56, 60, 62, 63, 64, 65, 68, 69, 70, 75, 80, 83, 84, 85, 86, 90, 91, 92, 93, 94, 96, 97, 98, 99], "r2_d": [21, 52], "r2_y": [21, 52], "r6": [37, 98], "r_0": [7, 10, 36, 54, 68], "r_all": 33, "r_d": 21, "r_df": 53, "r_dml": 33, "r_dml_nosplit": 33, "r_dml_po": 33, "r_dml_po_nosplit": 33, "r_double_ml_bas": 33, "r_double_ml_basic_iv": 32, "r_double_ml_did": 34, "r_double_ml_multiway_clust": 35, "r_double_ml_pens": 36, "r_double_ml_pipelin": 37, "r_hat": 10, "r_hat0": 7, "r_hat1": 7, "r_non_orthogon": 33, "r_po_al": 33, "r_y": 21, "rais": [3, 6, 29, 30, 40, 67], "randint": 56, "random": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 19, 25, 26, 32, 33, 34, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 66, 67, 69, 78, 83, 84, 89, 92, 93, 96, 97, 99], "random_search": 67, "random_st": [42, 51, 57], "randomforest": [36, 52, 54], "randomforest_class": [36, 43, 54, 57], "randomforest_reg": [43, 57], "randomforestclassifi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 40, 43, 44, 49, 50, 51, 52, 54, 57, 59, 60, 66, 67, 68, 99], "randomforestregressor": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 38, 40, 42, 43, 44, 49, 50, 51, 52, 54, 57, 59, 60, 62, 66, 67, 68, 69, 70, 83, 84, 89, 96, 99], "randomized_search": [2, 4, 5, 7, 8, 9, 10, 11, 12, 67], "randomizedsearchcv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 67], "randomli": [33, 35, 42, 53, 63, 69, 99], "rang": [33, 40, 42, 45, 46, 47, 49, 50, 52, 53, 55, 57, 58, 60, 61, 63, 67], "rangeindex": [38, 40, 46, 51, 53, 54, 55, 59, 61, 64, 96], "ranger": [34, 36, 37, 62, 67, 68, 69, 70, 83, 96, 99], "rangl": [19, 57], "rank": 98, "rate": [48, 52], "rather": 60, "ratio": [67, 69, 84, 86], "ravel": [43, 44], "raw": [36, 40, 48, 54], "raw_res_manual_lasso_r_100_n_100_p_200_rho_0": 48, "rbind": 36, "rbindlist": 36, "rbinom": 32, "rbrace": [7, 8, 20, 21, 26, 35, 53, 62, 68, 69, 70, 71, 83, 84, 85, 93], "rcolorbrew": 35, "rcparam": [38, 43, 44, 45, 47, 49, 50, 53, 54, 55, 58], "rd": 98, "rdbu": 35, "rdbu_r": 53, "rdt044": 48, "re": [53, 60, 95], "read_csv": 48, "readabl": 98, "readili": 94, "real": [36, 54, 55, 59, 84, 86], "realat": 68, "realiz": 68, "reason": [3, 6, 32, 41, 59, 60, 84, 86, 99], "recal": [38, 84, 92], "receiv": 68, "recent": [40, 68], "recogn": [36, 54, 55], "recommend": [37, 52, 60, 62, 69, 95, 97, 98], "recov": [32, 34, 41, 56], "recsi": 97, "red": [35, 49, 50, 53], "reduc": [36, 51, 54, 59, 60, 98], "redund": 98, "reemploy": [15, 64, 96], "refactor": 98, "refer": [2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 36, 40, 47, 51, 54, 55, 59, 64, 65, 66, 68, 84, 86, 89, 97, 98], "reference_level": [40, 68], "refin": 98, "refit": [84, 86], "reflect": [57, 60, 66], "reg": [18, 36, 54, 99], "reg_learn": 55, "reg_learner_1": 52, "reg_learner_2": 52, "regard": [60, 94], "regener": 98, "region": [35, 45, 53, 83, 93, 97], "regr": [32, 33, 34, 35, 36, 37, 62, 67, 68, 69, 70, 83, 93, 96, 99], "regravg": [37, 67], "regress": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 20, 21, 22, 23, 24, 25, 32, 34, 35, 37, 41, 48, 53, 56, 59, 60, 61, 62, 63, 65, 66, 67, 69, 83, 85, 86, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99], "regressor": [30, 33, 36, 40, 42, 45, 52, 54, 63], "regular": [22, 65, 67, 70, 83, 93, 97], "reich": [37, 67], "reinforc": 97, "reject": [36, 54], "rel": [36, 54, 84, 85, 86, 90], "relat": [60, 99], "relationship": [32, 41, 48, 60, 83, 93], "releas": 54, "relev": [1, 3, 4, 5, 6, 19, 45, 57, 58, 84, 99], "reli": [43, 44, 46, 47, 51, 66, 67, 68, 84, 86, 99], "reload": 36, "remain": [34, 83, 93, 99], "remark": [2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 42, 43, 44, 45, 47, 49, 50, 51, 52, 55, 59, 66, 67, 68, 70, 73, 74, 77, 82, 83, 84, 90], "remot": 95, "remov": [36, 54, 60, 65, 69, 98], "renam": [54, 98], "render": [40, 59, 60], "render_on_displai": 40, "reorgan": 98, "rep": [33, 63, 67, 83, 93], "repeat": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 35, 36, 37, 42, 51, 53, 54, 55, 56, 59, 61, 63, 65, 67, 83, 87, 96, 98, 99], "repeatedkfold": 53, "repet": 59, "repetit": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 43, 44, 48, 49, 50, 51, 52, 65, 67, 83, 96, 99], "repetiton": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "replac": [57, 60, 98], "replic": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 33, 36, 42, 48, 60], "repo": 98, "report": [36, 54, 94, 98], "repositori": [48, 98], "repr": [33, 35, 40], "repres": [56, 60], "represent": [2, 4, 5, 7, 8, 9, 10, 11, 12, 17, 59, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 98], "request": 98, "requir": [10, 11, 32, 36, 37, 40, 51, 54, 55, 59, 68, 83, 84, 86, 89, 93, 95, 98, 99], "requirenamespac": 34, "res_df": 53, "res_dict": [16, 17, 19], "resampl": [32, 35, 37, 46, 53, 55, 59, 61, 67, 68, 69, 70, 83, 94, 96, 99], "research": [35, 37, 53, 56, 60, 69, 94, 96, 97, 99], "resembl": 61, "reset": 34, "reset_index": [48, 53, 54], "reshap": [42, 43, 44, 47], "reshape2": 35, "residu": [2, 4, 5, 7, 8, 9, 10, 11, 12, 17, 59, 84, 86, 91, 92], "resolut": [37, 67], "resourc": 52, "resourcewis": 52, "respect": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 40, 54, 55, 66, 68, 69, 84, 92, 99], "respons": [14, 37, 67], "restart": 95, "restrict": 52, "restructur": 98, "restud": 48, "result": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 33, 34, 37, 40, 42, 43, 44, 46, 47, 48, 51, 52, 57, 59, 60, 61, 63, 67, 69, 70, 73, 74, 84, 86, 89, 96, 98], "result_iivm": 36, "result_irm": 36, "result_plr": 36, "retina": 56, "retir": [36, 54, 55, 59], "return": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 33, 34, 35, 37, 40, 42, 45, 50, 52, 53, 56, 57, 58, 59, 60, 61, 62, 67, 70, 84, 86, 98], "return_count": [40, 52], "return_tune_r": [2, 4, 5, 7, 8, 9, 10, 11, 12], "return_typ": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 33, 36, 37, 42, 46, 52, 54, 55, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 83, 84, 89, 96, 99], "rev": 35, "reveal": 51, "review": [22, 48, 97], "revist": [35, 53], "rho": [2, 4, 5, 7, 8, 9, 10, 11, 12, 31, 40, 51, 59, 60, 84, 86, 89, 92, 99], "rho_val": 60, "richter": [37, 67, 94, 96], "riesz": [2, 4, 5, 7, 8, 9, 10, 11, 12, 17, 59, 84, 86, 87, 88, 89, 91, 92], "riesz_rep": [84, 89], "right": [20, 21, 22, 23, 26, 33, 35, 42, 52, 53, 54, 55, 56, 58, 60, 63, 70, 73, 74, 83, 84, 85, 87, 88, 90, 93], "rightarrow_": [33, 42, 63], "risk": [2, 65, 98], "ritov": 97, "rival": 53, "rival_ind": 53, "rmd": 34, "rmse": [34, 46, 52, 55, 59, 61, 67, 68, 70, 83, 96, 98], "rnorm": [32, 37, 64, 67, 83, 93, 96], "robin": [14, 15, 24, 35, 48, 53, 63, 94, 97], "robinson": [33, 42, 63], "robject": 53, "robu": [49, 50], "robust": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 23, 34, 40, 51, 59, 60, 84, 89, 97, 99], "role": [3, 6, 33, 42, 63, 99], "romano": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 83, 93], "root": [2, 4, 5, 7, 8, 9, 10, 11, 12, 28, 48, 63, 67, 70, 97], "roth": 68, "rough": [60, 99], "roughli": 60, "round": [36, 40, 52, 56, 60], "rout": [29, 30], "row": [33, 36, 38, 43, 44, 47, 53, 57, 64, 69, 96, 99], "row_index": 50, "rownam": 35, "rowv": 35, "roxygen2": 98, "royal": [60, 97], "rpart": [36, 37, 67], "rpart_cv": 37, "rprocess": 52, "rpy2": 53, "rpy2pi": 53, "rsmp": [37, 67, 69], "rsmp_tune": [37, 67], "rssb": 60, "rtype": [2, 4, 5, 7, 8, 9, 10, 11, 12], "ruben": 97, "ruiz": [32, 41], "rule": [34, 66], "run": [34, 95, 98], "runif": 32, "runner": 60, "runtime_learn": 37, "rv": [40, 51, 59, 60, 84, 89, 99], "rva": [40, 51, 59, 60, 84, 89, 99], "rvert": 48, "rvert_": 48, "s_": [23, 35, 53, 68], "s_1": 24, "s_2": 24, "s_col": [3, 6, 61, 68], "s_i": [26, 61, 68], "s_x": [23, 35, 53], "safeguard": [46, 67], "sake": [36, 54, 60, 99], "same": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 33, 35, 42, 43, 44, 51, 52, 53, 55, 57, 59, 60, 61, 67, 70, 73, 74, 83, 84, 90, 98], "samii": 56, "sampl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 23, 26, 32, 34, 35, 37, 41, 46, 49, 50, 52, 53, 55, 57, 59, 65, 67, 83, 93, 96, 97, 98], "sant": [4, 5, 16, 17, 18, 34, 46, 68, 97], "sara": 97, "sasaki": [23, 35, 53, 97], "satisfi": [61, 67, 70, 83], "save": [33, 36, 42, 49, 50, 52, 54, 55, 67, 84, 89, 99], "savefig": 42, "saveguard": 52, "saver": [36, 54, 55], "scalar": 68, "scale": [33, 35, 45, 47, 56, 58, 60, 83, 84, 92], "scale_color_manu": 33, "scale_fill_manu": [33, 35], "scatter": [40, 47, 49, 50, 56, 60], "scatterplot": 40, "scenario": [2, 4, 5, 7, 8, 9, 10, 11, 12, 40, 51, 59, 60, 84, 89, 99], "scene": [43, 44, 48], "scene_camera": 48, "schaefer": 56, "schedul": 98, "scheme": [35, 53, 67, 69, 94], "schneider": 37, "schratz": [37, 67, 94, 96], "scienc": [25, 32, 41, 56, 97], "scikit": [52, 54, 67, 94, 96, 98, 99], "scipi": 42, "score": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 27, 28, 32, 34, 35, 36, 37, 38, 43, 44, 45, 46, 48, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 94, 98, 99], "scoring_method": [2, 4, 5, 7, 8, 9, 10, 11, 12], "script": 95, "sd": 32, "se": [33, 35, 42, 59, 63, 67, 69, 83, 84, 89, 97, 99], "se_df": 35, "se_dml": [33, 42, 63], "se_dml_po": [33, 42, 63], "se_nonorth": [33, 42], "se_orth_nosplit": [33, 42], "se_orth_po_nosplit": [33, 42], "seaborn": [38, 40, 42, 46, 52, 53, 54, 55, 60, 61], "search": [2, 4, 5, 7, 8, 9, 10, 11, 12, 28, 67, 70], "search_mod": [2, 4, 5, 7, 8, 9, 10, 11, 12, 67], "searchabl": 36, "second": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 23, 33, 35, 37, 42, 52, 53, 62, 63, 69, 83, 84, 86, 92, 93, 96], "secondari": 40, "section": [5, 18, 34, 35, 36, 37, 51, 53, 55, 60, 87, 98], "secur": 56, "see": [2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 21, 26, 27, 28, 32, 34, 35, 36, 37, 40, 41, 43, 44, 46, 50, 53, 55, 56, 57, 59, 60, 67, 68, 69, 70, 72, 76, 77, 78, 79, 82, 84, 86, 89, 92, 95, 96, 98], "seed": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 83, 84, 89, 93, 96, 99], "seek": 56, "seem": [34, 36, 51, 54, 55, 99], "seen": [49, 50], "sel_cols_chiang": 53, "select": [3, 6, 22, 26, 48, 52, 60, 62, 65, 67, 97, 98, 99], "selected_coef": 52, "selected_featur": [37, 67], "selected_learn": 52, "self": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 40, 52, 99], "selfref": 36, "semenova": [43, 44, 97], "semi": 63, "semiparametr": 14, "sens": [59, 60], "sensemakr": [84, 86], "sensit": [2, 4, 5, 7, 8, 9, 10, 11, 12, 31, 65, 66, 86, 89, 92, 98], "sensitivity_analysi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 40, 51, 59, 60, 84, 89, 99], "sensitivity_benchmark": [2, 4, 5, 7, 8, 9, 10, 11, 12, 40, 51, 59, 60, 84, 86], "sensitivity_el": [84, 89], "sensitivity_param": [2, 4, 5, 7, 8, 9, 10, 11, 12, 59, 60, 84, 86, 89], "sensitivity_plot": [2, 4, 5, 7, 8, 9, 10, 11, 12, 40, 51, 59, 60, 84, 89], "sensitivity_summari": [40, 51, 59, 60, 84, 89, 99], "sensitvity_benchmark": 40, "sensiv": [2, 4, 5, 7, 8, 9, 10, 11, 12], "senstiv": [84, 91], "sep": 33, "separ": [56, 59, 67, 98], "seper": [59, 69, 83, 84, 86], "seq_len": [33, 63], "sequenti": 15, "seri": [50, 60, 97], "serv": [64, 96, 98], "serverless": [97, 98], "servic": 56, "set": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 23, 24, 25, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 46, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 66, 68, 69, 70, 71, 73, 74, 76, 83, 84, 85, 86, 90, 91, 93, 95, 96, 98, 99], "set_as_param": [2, 4, 5, 7, 8, 9, 10, 11, 12], "set_fold_specif": 67, "set_index": 54, "set_ml_nuisance_param": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 38, 54, 67, 98], "set_param": [29, 30, 67], "set_sample_split": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 52, 69, 98], "set_styl": [54, 55], "set_text": 52, "set_threshold": [33, 34, 35, 36, 37, 62, 67, 68, 69, 70, 83, 93, 96], "set_tick": 53, "set_ticklabel": 53, "set_titl": [40, 53], "set_x_d": [3, 6], "set_xlabel": [40, 42, 53], "set_xlim": 42, "set_xtick": 56, "set_xticklabel": 56, "set_ylabel": [40, 53, 56], "set_ylim": [45, 53, 58], "setdiff": 98, "setdiff1d": 53, "setminu": [35, 53, 83, 93], "setup": 95, "setuptool": 95, "seven": [35, 53], "sever": [31, 36, 37, 52, 54, 55, 59, 60, 63, 67, 99], "shape": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 40, 43, 44, 47, 49, 50, 52, 53, 54, 57, 59, 60, 67], "share": [35, 36, 53, 54], "sharma": [60, 97], "shock": [35, 53], "short": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 59, 60, 84, 86, 97, 98, 99], "shortcut": 36, "shortli": [35, 37, 53, 67], "shota": 97, "should": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 28, 36, 40, 49, 50, 52, 54, 59, 61, 64, 66, 67, 68, 83, 84, 86, 94], "show": [32, 33, 35, 38, 40, 41, 42, 43, 44, 46, 48, 51, 52, 53, 56, 60, 61, 63, 84, 91, 95], "showcas": 57, "showlabel": 60, "showlegend": 60, "shown": [32, 41, 56, 96], "showscal": [43, 44, 48], "shuffl": 69, "side": [84, 89], "sigma": [16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 33, 35, 42, 53, 61, 63, 66, 69, 83, 84, 86, 89, 91, 92, 93], "sigma2": [84, 89], "sigma_": [17, 18, 20, 21, 22, 23, 24, 26, 33, 35, 42, 53, 63], "sigma_0": [84, 92], "sigma_j": [83, 93], "sigmoid": 56, "sign": 60, "signal": 1, "signatur": [7, 8, 9, 10, 11, 12, 13, 70], "signif": [32, 34, 35, 36, 37, 67, 68, 69, 70, 83, 96, 99], "signific": [32, 35, 36, 37, 40, 51, 54, 57, 59, 60, 67, 68, 69, 70, 83, 84, 89, 96, 99], "silverman": [9, 12, 13], "sim": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 35, 42, 45, 47, 53, 57, 58, 61, 63], "similar": [17, 34, 37, 43, 44, 51, 55, 59, 60], "simpl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 19, 34, 37, 43, 44, 49, 50, 51, 57, 60, 65, 84, 86], "simplest": 66, "simpli": [37, 46, 99], "simplic": [36, 52, 54, 57, 60], "simplif": [84, 87], "simplifi": [56, 60, 66, 84, 91], "simul": [16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 33, 37, 42, 43, 44, 45, 48, 49, 50, 58, 60, 61, 63, 67, 83, 93, 96], "simulaten": 68, "simulation_run": 48, "simult": 34, "simultan": [65, 99], "sin": [19, 25, 43, 44, 47, 49, 50], "sinc": [16, 17, 36, 40, 46, 47, 49, 50, 51, 52, 54, 56, 61, 67, 68, 84, 89, 90, 98], "singl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 46, 49, 50, 55, 56, 67, 83, 93], "single_learner_pipelin": 67, "singleton": 69, "sinh": 25, "sipp": [36, 54, 55], "site": [40, 53, 54], "situat": [35, 53], "six": 35, "sixth": 53, "size": [33, 35, 36, 37, 42, 45, 47, 48, 51, 52, 54, 56, 57, 58, 60, 62, 64, 67, 68, 69, 70, 83, 93, 96, 99], "sizeabl": 60, "skill": 97, "sklearn": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 25, 38, 40, 41, 42, 43, 44, 48, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 66, 67, 68, 69, 70, 83, 84, 89, 93, 96, 99], "skotara": 60, "slide": 56, "slightli": [47, 49, 50, 51, 52, 66, 70, 73, 74, 84, 86], "sligthli": [4, 5], "slow": [33, 42, 63], "slower": [33, 42, 63], "small": [19, 46, 47, 57, 61, 84, 86, 90], "smaller": [36, 46, 49, 50, 51, 54, 60, 99], "smallest": 52, "smpl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 35, 42, 52, 53, 69, 70], "smpls_cluster": [35, 53], "smsg": 54, "sn": [38, 40, 42, 46, 52, 53, 54, 55, 60, 61], "so": [32, 36, 37, 41, 46, 54, 56, 60, 61, 67, 83, 99], "social": [56, 97], "societi": [35, 53, 60, 97], "softwar": [37, 67, 94, 96, 97, 98], "solari": 98, "sole": 60, "solut": [62, 66, 70], "solv": [27, 35, 53, 66, 67, 83, 93], "solver": [54, 61, 68], "some": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 37, 38, 46, 47, 52, 54, 55, 59, 61, 66, 67, 68, 98], "sometim": 52, "sonabend": [37, 67], "sophist": 67, "sort": [54, 68], "sort_valu": 40, "sourc": [37, 67, 96, 98], "sourcefileload": 48, "sp": 34, "space": [35, 53, 67], "spars": [48, 67, 83, 93, 96, 97], "sparsiti": 97, "spec": 97, "special": [35, 53], "specif": [2, 4, 5, 7, 8, 9, 10, 11, 12, 28, 35, 36, 40, 52, 53, 54, 60, 64, 65, 66, 67, 69, 70, 76, 83, 89, 92, 94, 96], "specifi": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 32, 35, 36, 37, 40, 41, 43, 44, 45, 46, 49, 50, 53, 54, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 71, 76, 96, 98, 99], "specifii": 55, "speed": [13, 52], "speedup": 52, "spefici": 7, "spindler": [22, 60, 94, 97, 98], "spine": [54, 55], "spline": [43, 44, 66], "spline_basi": [43, 44, 66], "spline_grid": [43, 44], "split": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 35, 37, 46, 52, 53, 55, 57, 59, 61, 65, 66, 67, 68, 70, 83, 96, 98], "split_sampl": 52, "sponsor": [36, 54, 55], "sprintf": 33, "sq_error": 48, "sqrt": [16, 17, 18, 21, 33, 35, 37, 38, 42, 45, 53, 58, 63, 69, 83, 84, 86, 93, 96], "squar": [2, 4, 5, 7, 8, 9, 10, 11, 12, 36, 48, 54, 67, 84, 92, 97], "squarederror": [36, 54, 99], "squeez": [45, 46, 58, 61], "src": 54, "ssm": [3, 6, 26, 65], "ssrn": 20, "stabil": 51, "stabl": [32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 94], "stack": [37, 67], "stacklrn": 37, "stage": [43, 44, 49, 50, 57, 67, 98, 99], "standard": [18, 34, 37, 45, 49, 50, 69, 70, 83, 84, 89, 92, 93, 98, 99], "standard_norm": [64, 67, 83, 93, 96], "standardscal": 54, "start": [34, 36, 37, 43, 44, 48, 51, 52, 53, 54, 58, 60, 68, 94, 99], "stat": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 42, 64, 67, 83, 93, 94, 97], "stat_bin": 33, "stat_dens": 36, "state": 99, "stationar": 46, "stationari": 68, "statist": [2, 4, 5, 7, 8, 9, 10, 11, 12, 23, 26, 31, 35, 53, 59, 60, 83, 84, 89, 93, 94, 96, 97, 98, 99], "statsmodel": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "statu": [34, 36, 46, 54, 56, 61], "std": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 34, 35, 36, 37, 38, 41, 43, 44, 45, 46, 49, 50, 51, 53, 54, 55, 56, 58, 59, 60, 61, 66, 67, 68, 69, 70, 83, 96, 99], "stefan": 97, "step": [33, 36, 37, 42, 49, 50, 51, 54, 57, 63, 67, 83, 93, 94, 99], "stepdown": [83, 93], "stick": [36, 54], "still": [43, 44, 46, 49, 50, 51, 55, 59, 61, 67], "stochast": [10, 11, 68, 96], "stock": [36, 54, 55], "store": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 62, 67, 69, 70, 83, 84, 89, 98], "store_model": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "store_predict": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 34, 54, 57], "stori": [60, 97], "str": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 36, 40, 49, 50, 58, 66, 98], "straightforward": [49, 50, 52, 66], "strategi": [56, 60, 99], "stratifi": 52, "stratum": 56, "strength": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 59, 60, 84, 86, 89, 91], "strictli": 68, "string": [2, 4, 5, 7, 8, 9, 10, 11, 12, 66, 83, 84, 89, 96, 98], "string_label": 56, "strong": [61, 84, 86], "stronger": [83, 99], "structur": [14, 15, 24, 35, 36, 48, 53, 54, 61, 63, 67, 94, 97, 99], "student": 97, "studi": [26, 35, 36, 48, 53, 54, 55, 59, 96, 99], "style": [2, 4, 5, 7, 8, 9, 10, 11, 12, 98], "styler": 98, "styliz": 60, "sub": [35, 53], "subclass": 98, "subfold": 67, "subgroup": [7, 36, 54, 98], "subject": [35, 53], "submiss": 98, "subobject": [29, 30], "subplot": [35, 40, 42, 43, 44, 45, 47, 49, 50, 52, 53, 54, 55, 56, 58], "subplots_adjust": 52, "subpopul": 68, "subsampl": [37, 52], "subscript": [84, 86], "subsequ": [35, 53], "subset": [2, 4, 5, 7, 8, 9, 10, 11, 12, 35, 52, 53, 57, 62, 66, 67, 84, 86], "subseteq": 66, "substanti": [36, 54, 56], "substract": 83, "subtract": 83, "sudo": 95, "suffic": 60, "suffici": [52, 60], "suggest": [35, 36, 53, 54, 60, 98], "suitabl": [43, 44, 61], "sum": [35, 36, 53, 54, 55, 58, 66, 83, 93], "sum_": [33, 35, 42, 53, 62, 63, 66, 83, 93], "sum_i": 56, "sum_oth": 53, "sum_riv": 53, "summar": [34, 40, 56, 60, 62, 84, 89], "summari": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 32, 34, 35, 37, 38, 40, 41, 43, 44, 45, 46, 49, 50, 51, 53, 55, 58, 59, 60, 61, 63, 64, 66, 67, 68, 69, 70, 83, 84, 96, 98, 99], "summary_result": 36, "suppli": [2, 4, 5, 7, 8, 9, 10, 11, 12, 43, 44, 49, 50, 51, 57, 66, 84, 85, 86, 89], "support": [7, 19, 34, 35, 52, 53, 57, 67, 68, 99], "support_s": [19, 43, 44, 49, 50, 57], "support_t": 57, "support_w": 57, "suppos": 60, "suppress": [34, 36, 37], "suppresswarn": 33, "suprema": [83, 93], "suptitl": [45, 52, 55, 58], "supxlabel": [45, 55, 58], "supylabel": [45, 55, 58], "sure": [40, 67, 98], "surfac": [43, 44, 48], "surpress": [35, 96], "survei": [36, 54, 55, 99], "susan": 97, "sven": [60, 94, 97], "svenk": [40, 53], "svenklaassen": 94, "svg": [33, 42], "switch": [33, 42, 60, 63], "symbol": 60, "symmetr": 25, "synthet": [19, 32, 41, 43, 44, 45, 49, 50, 57, 58], "syrgkani": [60, 97], "system": 97, "szita": 97, "t": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 32, 34, 35, 36, 37, 38, 41, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 66, 67, 68, 69, 70, 74, 83, 84, 87, 93, 96, 99], "t_1_start": 52, "t_1_stop": 52, "t_2_start": 52, "t_2_stop": 52, "t_3_start": 52, "t_3_stop": 52, "t_col": [3, 5, 6, 68], "t_df": 57, "t_diff": 47, "t_dml": 33, "t_i": [46, 57, 68], "t_idx": 47, "t_nonorth": 33, "t_orth_nosplit": 33, "t_sigmoid": 57, "t_stat": 83, "tabl": [33, 35, 36, 37, 62, 64, 67, 68, 69, 70, 83, 93, 96, 99], "tabular": [52, 64, 83, 93, 96, 99], "taddi": 97, "take": [7, 8, 10, 11, 16, 17, 19, 43, 44, 45, 46, 47, 48, 49, 50, 52, 55, 58, 59, 61, 62, 66, 67, 68, 70, 71, 76, 84, 85, 90, 91, 96], "taken": [36, 54, 55, 99], "taker": [7, 98], "talk": 99, "target": [2, 4, 5, 7, 8, 9, 10, 11, 12, 27, 28, 32, 35, 36, 37, 43, 44, 52, 53, 66, 67, 68, 69, 70, 77, 82, 83, 84, 90, 92, 93, 94, 96, 98, 99], "task": [32, 64, 69, 99], "task_typ": 98, "tau": [45, 47, 55, 56, 58, 66, 70, 72, 77, 82], "tau_": 56, "tau_1": 56, "tau_2": 56, "tau_vec": [45, 55, 58], "tax": [36, 54, 55], "te": [34, 43, 44, 57], "techniqu": [33, 42, 63, 69, 99], "templat": 98, "temporari": 54, "tend": [36, 54, 55], "tensor": [43, 44], "tenth": 97, "term": [33, 35, 36, 37, 42, 47, 48, 53, 54, 56, 60, 63, 94, 99], "termin": [37, 67], "terminatorev": 37, "test": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 20, 32, 33, 34, 35, 36, 37, 42, 51, 53, 60, 63, 67, 68, 69, 70, 83, 93, 96, 97, 98, 99], "test_id": [35, 69], "test_ind": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "test_set": 69, "test_siz": 42, "text": [16, 17, 18, 20, 35, 36, 45, 48, 56, 57, 58, 60, 66, 69], "textbf": [62, 67, 99], "textposit": 60, "textrm": [84, 85, 86, 90, 91, 92], "tg": [37, 38, 64, 96], "th": [35, 53], "than": [8, 33, 34, 36, 42, 48, 52, 54, 55, 56, 59, 60, 63, 84, 89, 99], "thank": [34, 36, 37, 54, 98], "thatw": 47, "thei": [34, 36, 47, 49, 50, 54, 56, 84, 92], "them": [36, 37, 43, 44, 45, 51, 54, 58], "theme": [35, 36], "theme_minim": [33, 36], "theorem": [84, 92], "theoret": [52, 60, 69, 97], "theori": [66, 97], "therebi": [35, 37, 53, 99], "therefor": [40, 56, 59, 69, 70, 84, 91], "theta": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 23, 25, 26, 27, 28, 33, 35, 37, 40, 42, 46, 47, 48, 51, 52, 53, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 89, 91, 92, 93, 96, 99], "theta_": [60, 66, 68, 83, 84, 92, 93], "theta_0": [7, 8, 10, 11, 19, 33, 35, 36, 40, 42, 43, 44, 48, 49, 50, 53, 54, 60, 61, 63, 66, 68, 70, 77, 82, 83, 84, 85, 90, 92, 96], "theta_dml": [33, 42, 63], "theta_dml_po": [33, 42, 63], "theta_initi": 42, "theta_nonorth": [33, 42], "theta_orth_nosplit": [33, 42], "theta_orth_po_nosplit": [33, 42], "theta_resc": 33, "theta_t": 47, "thi": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 66, 67, 68, 69, 70, 72, 73, 74, 77, 82, 83, 84, 85, 86, 89, 90, 94, 95, 96, 97, 98, 99], "think": 37, "third": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 42, 53, 63, 69], "thirion": [94, 96], "this_df": [48, 54], "this_split_ind": 53, "those": [34, 36, 54, 55], "though": [32, 41, 56], "thread": [56, 67], "three": [35, 37, 49, 50, 95, 98], "threshold": [2, 4, 5, 7, 8, 9, 12, 13, 60, 68], "through": [34, 45, 49, 50, 58, 67], "throughout": 51, "thu": 66, "tibbl": 34, "tight": 42, "tight_layout": 53, "tild": [16, 17, 18, 35, 53, 56, 62, 66, 69, 70, 77, 78, 79, 82, 83, 84, 91, 92, 93], "time": [3, 4, 6, 22, 23, 33, 34, 35, 36, 42, 46, 47, 48, 49, 50, 53, 54, 55, 59, 60, 61, 68, 98, 99], "time_df": 47, "time_period": 47, "titl": [35, 36, 40, 43, 44, 45, 48, 49, 50, 52, 53, 54, 55, 56, 58, 60, 94], "tmp": 50, "tname": 34, "tnr": [37, 67], "to_fram": 57, "to_numpi": [45, 51, 55, 58], "todo": [35, 38], "toeplitz": 48, "togeth": [49, 50, 83], "toler": 53, "too": 52, "tool": [34, 37, 59, 99], "top": [35, 52, 53, 54, 55, 60, 94], "total": [36, 54], "traceback": 40, "tracker": 94, "tradit": [83, 93], "train": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 33, 35, 37, 42, 43, 44, 45, 49, 50, 52, 53, 57, 58, 62, 63, 69], "train_id": [35, 69], "train_ind": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "train_set": 69, "train_test_split": 42, "transact": 97, "transform": [16, 17, 56, 60, 99], "translat": 48, "transpos": 47, "treament": 57, "treat": [8, 18, 34, 40, 46, 47, 51, 57, 60, 66, 68, 83, 99], "treat1_param": 56, "treat2_param": 56, "treat_var": [2, 4, 5, 7, 8, 9, 10, 11, 12, 67], "treatment": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 32, 34, 35, 37, 38, 40, 41, 46, 47, 48, 51, 52, 53, 57, 59, 60, 61, 63, 64, 65, 67, 69, 70, 71, 72, 73, 74, 76, 77, 82, 83, 84, 85, 89, 91, 93, 94, 96, 97, 98, 99], "treatment_df": 47, "treatment_effect": [19, 43, 44], "treatment_level": [40, 68], "treatment_var": [3, 6], "tree": [8, 36, 37, 46, 47, 52, 54, 62, 65, 67, 68, 69, 70, 83, 96, 98], "tree_param": 8, "tree_summari": 54, "trees_class": [36, 54], "trend": [34, 46, 47, 53, 68, 97], "tri": [48, 84, 86], "trim": [2, 4, 5, 7, 8, 9, 12, 13, 36, 54, 55, 60], "trimming_rul": [2, 4, 5, 7, 8, 9, 12, 13, 55], "trimming_threshold": [2, 4, 5, 7, 8, 9, 12, 13, 36, 43, 54, 55, 57, 58, 60], "trm": [37, 67], "true": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 26, 29, 30, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 67, 68, 69, 70, 71, 72, 77, 78, 79, 82, 83, 84, 87, 88, 92, 93, 96, 99], "true_effect": [43, 44, 47, 49, 50], "true_gatet_effect": 51, "true_group_effect": 51, "truncat": [2, 4, 5, 7, 8, 9, 12, 13, 55], "try": [52, 59], "tune": [2, 4, 5, 7, 8, 9, 10, 11, 12, 48, 65, 94, 96, 98], "tune_on_fold": [2, 4, 5, 7, 8, 9, 10, 11, 12, 67], "tune_r": [2, 4, 5, 7, 8, 9, 10, 11, 12], "tune_set": [37, 67], "tuner": 67, "tunergridsearch": 37, "tupl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "turn": 60, "turrel": 25, "tutori": 36, "tw": [54, 55], "twinx": 40, "two": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 19, 32, 33, 36, 37, 41, 42, 45, 46, 52, 54, 55, 56, 57, 58, 59, 60, 62, 63, 66, 67, 68, 69, 70, 77, 83, 93, 99], "twoclass": 37, "twoearn": [36, 54, 55, 59, 99], "type": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 29, 30, 31, 33, 34, 35, 36, 37, 40, 42, 52, 53, 60, 63, 67, 70, 80, 81, 83, 84, 91, 93, 98, 99], "typic": [50, 94], "u": [7, 8, 9, 12, 13, 16, 17, 18, 19, 21, 26, 33, 34, 35, 36, 40, 42, 45, 46, 47, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 63, 68, 84, 86, 95, 99], "u_hat": [33, 42, 70], "u_i": [20, 22, 25, 26], "u_t": 18, "uehara": 97, "uhash": 37, "ulf": 97, "unambigu": 60, "uncertainti": [2, 4, 5, 7, 8, 9, 10, 11, 12, 49, 50, 59, 84, 89, 99], "uncondit": [36, 54, 99], "unconfounded": [60, 97], "under": [33, 36, 42, 46, 54, 57, 60, 63, 68, 83, 97], "underbrac": [33, 42, 47, 63, 66], "underli": [16, 36, 37, 40, 49, 50, 56, 57, 84, 86, 99], "underlin": [35, 53], "understand": 60, "undesir": 67, "unevenli": 69, "uniform": [18, 41, 43, 44, 45, 47, 57, 58, 83], "uniformli": [45, 55, 83, 93], "uniqu": [32, 40, 41, 52, 70, 84, 92], "unit": [33, 34, 46, 47, 51, 61, 68, 70, 73, 74, 98], "univari": [19, 43, 44], "univers": 97, "unknown": 68, "unlik": [36, 54, 55, 60], "unobserv": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 32, 36, 41, 54, 55, 59, 60, 68, 84, 86, 92, 99], "unpen": 34, "unstabl": [84, 86], "unter": [35, 36, 37], "untest": 60, "until": [68, 98], "untreat": [60, 68], "up": [13, 36, 48, 52, 54, 55, 59, 60, 67, 68, 69, 84, 86, 95, 98, 99], "upcom": 98, "updat": [35, 50, 53, 97, 98], "update_layout": [43, 44, 48, 60], "update_trac": [43, 44], "upload": 98, "upon": [70, 98], "upper": [36, 37, 40, 42, 45, 47, 51, 55, 58, 59, 60, 67, 84, 89, 92, 99], "upper_bound": [43, 44], "upsilon": 61, "upsilon_i": 61, "upward": [36, 54, 55, 60], "upweight": 56, "url": [48, 94, 97], "us": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 33, 35, 36, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 66, 69, 70, 73, 74, 83, 84, 86, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99], "usa": 97, "usabl": 52, "usag": [34, 38, 40, 46, 51, 53, 54, 55, 59, 61, 64, 96, 98], "use_label_encod": [54, 99], "use_other_treat_as_covari": [3, 6, 64], "usecolormap": [43, 44], "user": [27, 28, 29, 30, 33, 34, 35, 36, 37, 40, 42, 51, 52, 53, 54, 59, 66, 67, 70, 83, 93, 94, 95, 96, 98, 99], "user_guid": 50, "userwarn": [54, 60], "usual": [35, 43, 44, 46, 52, 53, 59, 60, 66, 67, 69, 84, 92], "util": [28, 52, 56, 67, 98], "v": [7, 8, 10, 11, 14, 15, 21, 22, 23, 24, 26, 33, 35, 36, 40, 42, 51, 53, 54, 56, 62, 63, 66, 68, 83, 93, 94, 96, 97, 98, 99], "v108": 94, "v12": [94, 96], "v22": 37, "v23": 94, "v_": [23, 35, 53], "v_i": [20, 21, 24, 25, 26, 33, 42, 63, 68], "v_j": [83, 93], "val": [21, 69, 97], "val_list": 48, "valid": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 20, 33, 34, 35, 36, 40, 42, 45, 46, 52, 53, 54, 55, 58, 63, 65, 66, 67, 69, 70, 72, 77, 82, 84, 86, 97, 99], "valu": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 59, 60, 62, 65, 67, 68, 69, 72, 77, 78, 79, 82, 83, 84, 86, 89, 92, 93, 96, 98, 99], "value_count": 54, "valueerror": 40, "van": 97, "vanderpla": [94, 96], "vanish": [33, 42, 63], "var": [16, 17, 18, 35, 53, 56, 84, 85, 86, 90, 91, 92], "var_ep": 60, "varepsilon": [7, 16, 17, 23, 35, 53, 61, 66, 68], "varepsilon_": [23, 35, 53], "varepsilon_0": 18, "varepsilon_1": 18, "varepsilon_d": 17, "varepsilon_i": [22, 45, 58, 61], "vari": [36, 47, 52, 54, 56, 60], "variabl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 35, 36, 37, 38, 40, 46, 48, 51, 53, 54, 55, 59, 60, 61, 64, 66, 67, 68, 69, 70, 83, 84, 86, 89, 92, 93, 96, 97, 98, 99], "varianc": [27, 28, 35, 37, 53, 59, 60, 65, 69, 84, 86, 89, 90, 91, 92, 96], "variant": 34, "variat": [2, 4, 5, 7, 8, 9, 10, 11, 12, 17, 59, 84, 86, 92], "variou": [34, 60, 67, 99], "varoquaux": [94, 96], "vasili": [60, 97], "vector": [2, 4, 5, 7, 8, 9, 10, 11, 12, 19, 20, 21, 22, 23, 25, 26, 32, 35, 36, 41, 46, 49, 50, 51, 53, 54, 57, 61, 68, 83, 93, 96, 98], "venv": 95, "verbos": [36, 47, 52, 60], "veri": [34, 35, 37, 51, 52, 53, 60, 70, 94], "verifi": 56, "versa": [52, 56, 84, 89], "version": [16, 35, 36, 37, 40, 54, 60, 62, 66, 83, 84, 85, 87, 88, 90, 93, 98], "versoin": 60, "versu": 50, "vertic": [35, 40, 53], "via": [2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 28, 34, 45, 46, 47, 48, 49, 50, 51, 52, 59, 61, 62, 64, 65, 66, 67, 68, 69, 72, 79, 83, 84, 86, 89, 92, 93, 94, 95, 96, 97, 98, 99], "viabl": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13], "vice": [52, 56, 84, 89], "victor": [48, 60, 69, 94, 97], "view": 50, "vignett": [34, 98], "villa": [32, 41], "violet": [45, 55, 58], "vira": 97, "virtual": 95, "virtualenv": 95, "visibl": [55, 60], "visit": [94, 99], "visual": [35, 51, 53], "vol": 34, "volum": [60, 94], "voluntari": 56, "vv740": 53, "vv760g": 53, "w": [14, 15, 16, 17, 18, 24, 27, 28, 35, 48, 53, 56, 57, 62, 63, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 96], "w24678": 69, "w30302": 97, "w_": [18, 35, 53, 57], "w_1": [18, 57], "w_2": [18, 57], "w_3": 18, "w_4": 18, "w_df": 57, "w_i": [26, 46, 57, 62, 66, 69, 70, 83, 93], "wa": [35, 47, 53, 60, 98], "wager": 97, "wai": [36, 52, 54, 60, 67, 70, 95], "wander": 25, "wang": 97, "want": [32, 35, 36, 37, 41, 45, 46, 52, 53, 58, 67, 94, 95, 97], "warn": [32, 33, 34, 35, 36, 37, 42, 54, 60, 62, 67, 68, 69, 70, 83, 93, 96, 98], "wayon": 35, "we": [8, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 75, 83, 84, 86, 92, 93, 95, 96, 98, 99], "weak": [84, 86, 97], "wealth": [14, 59], "websit": [36, 37, 67, 94], "wedg": [35, 53], "week": 98, "wei": [83, 93], "weight": [2, 7, 8, 9, 12, 13, 35, 36, 37, 40, 51, 53, 54, 61, 65, 67, 70, 71, 76, 83, 84, 85, 90, 93, 98], "weights_bar": 8, "weiss": [94, 96], "well": [3, 6, 33, 35, 42, 48, 52, 53, 62, 63, 64, 69, 96], "were": [36, 54, 55, 61, 99], "what": [34, 48, 52], "when": [2, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30, 36, 46, 50, 54, 56, 68, 70, 83, 93, 94, 95, 96, 98], "whenev": [36, 54], "whera": [84, 90], "where": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 32, 33, 35, 36, 40, 41, 42, 45, 46, 47, 51, 53, 54, 56, 57, 58, 60, 61, 62, 63, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 89, 90, 92, 95, 96, 98, 99], "wherea": [19, 40, 46, 60, 61, 70, 76, 84, 85, 99], "whether": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 19, 26, 36, 47, 52, 54, 55, 60, 64, 67, 84, 86, 98], "which": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 19, 28, 32, 33, 34, 36, 37, 39, 40, 41, 42, 46, 48, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 64, 66, 67, 68, 70, 83, 84, 85, 86, 89, 90, 92, 93, 95, 98, 99], "while": [32, 41], "white": [35, 49, 50, 53, 60], "whitegrid": [54, 55], "whitnei": [60, 97], "who": [34, 36, 54, 60], "whole": [33, 42, 46, 63, 67, 84, 86], "width": [33, 35, 43, 44, 48], "wiki": 98, "wiksel": 97, "wild": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 83, 93], "window": 95, "wise": [49, 50], "wish": 95, "within": [35, 49, 50, 53, 57], "without": [2, 4, 5, 7, 8, 9, 10, 11, 12, 32, 33, 41, 42, 52, 60, 63, 65, 67, 84, 86, 95, 98], "wolf": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 83, 93], "won": 60, "word": 99, "work": [29, 30, 39, 50, 51, 52, 56, 59, 60, 67, 83, 95, 97], "workflow": [94, 98], "workspac": 54, "world": 97, "worri": 60, "would": [34, 36, 37, 43, 44, 48, 52, 54, 55, 59, 60, 66, 67, 84, 92, 99], "wrapper": [34, 67], "write": [33, 34, 42, 46, 50, 61, 63, 84, 92], "written": [70, 84, 85, 90], "wrong": [52, 56], "wspace": 52, "wurd": [35, 36, 37], "www": [94, 95], "x": [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 35, 36, 37, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 90, 91, 92, 93, 96, 99], "x0": [40, 56], "x1": [35, 37, 40, 46, 53, 56, 59, 60, 61, 64, 66, 67, 68, 70, 83, 84, 86, 96], "x10": [35, 37, 53, 61, 64, 67, 68, 70, 83, 96], "x100": [35, 37, 53, 61, 64, 68, 96], "x11": [35, 37, 53, 61, 64, 67, 68, 70, 83, 96], "x12": [35, 37, 53, 61, 64, 67, 68, 70, 83, 96], "x13": [35, 37, 53, 61, 64, 67, 68, 70, 83, 96], "x14": [35, 37, 53, 61, 64, 67, 68, 70, 83, 96], "x15": [35, 37, 53, 61, 64, 67, 68, 70, 83, 96], "x16": [35, 37, 53, 61, 64, 67, 68, 70, 83, 96], "x17": [35, 37, 53, 61, 64, 67, 68, 70, 83, 96], "x18": [35, 37, 53, 61, 64, 67, 68, 70, 83, 96], "x19": [35, 37, 53, 61, 64, 67, 68, 70, 83, 96], "x1x2x3x4x5x6x7x8x9x10": 35, "x2": [35, 37, 40, 46, 53, 59, 60, 61, 64, 66, 67, 68, 70, 83, 96], "x20": [35, 37, 53, 61, 64, 67, 68, 70, 83, 96], "x21": [35, 37, 53, 61, 64, 68, 96], "x22": [35, 37, 53, 61, 64, 68, 96], "x23": [35, 37, 53, 61, 64, 68, 96], "x24": [35, 37, 53, 61, 64, 68, 96], "x25": [35, 37, 53, 61, 64, 68, 96], "x26": [35, 37, 53, 61, 64, 68, 96], "x27": [35, 37, 53, 61, 64, 68, 96], "x28": [35, 37, 53, 61, 64, 68, 96], "x29": [35, 37, 53, 61, 64, 68, 96], "x2_dummi": 60, "x2_preds_control": 60, "x2_preds_treat": 60, "x3": [35, 37, 40, 46, 53, 59, 60, 61, 64, 66, 67, 68, 70, 83, 96], "x30": [35, 37, 53, 61, 64, 68, 96], "x31": [35, 37, 53, 61, 64, 68, 96], "x32": [35, 37, 53, 61, 64, 68, 96], "x33": [35, 37, 53, 61, 64, 68, 96], "x34": [35, 37, 53, 61, 64, 68, 96], "x35": [35, 37, 53, 61, 64, 68, 96], "x36": [35, 37, 53, 61, 64, 68, 96], "x37": [35, 37, 53, 61, 64, 68, 96], "x38": [35, 37, 53, 61, 64, 68, 96], "x39": [35, 37, 53, 61, 64, 68, 96], "x4": [35, 37, 40, 46, 53, 59, 60, 61, 64, 67, 68, 70, 83, 96], "x40": [35, 37, 53, 61, 64, 68, 96], "x41": [35, 37, 53, 61, 64, 68, 96], "x42": [35, 37, 53, 61, 64, 68, 96], "x43": [35, 37, 53, 61, 64, 68, 96], "x44": [35, 37, 53, 61, 64, 68, 96], "x45": [35, 37, 53, 61, 64, 68, 96], "x46": [35, 37, 53, 61, 64, 68, 96], "x47": [35, 37, 53, 61, 64, 68, 96], "x48": [35, 37, 53, 61, 64, 68, 96], "x49": [35, 37, 53, 61, 64, 68, 96], "x5": [35, 37, 53, 60, 61, 64, 67, 68, 70, 83, 96], "x50": [35, 37, 53, 61, 64, 68, 96], "x51": [35, 37, 53, 61, 64, 68, 96], "x52": [35, 37, 53, 61, 64, 68, 96], "x53": [35, 37, 53, 61, 64, 68, 96], "x54": [35, 37, 53, 61, 64, 68, 96], "x55": [35, 37, 53, 61, 64, 68, 96], "x56": [35, 37, 53, 61, 64, 68, 96], "x57": [35, 37, 53, 61, 64, 68, 96], "x58": [35, 37, 53, 61, 64, 68, 96], "x59": [35, 37, 53, 61, 64, 68, 96], "x6": [35, 37, 53, 61, 64, 67, 68, 70, 83, 96], "x60": [35, 37, 53, 61, 64, 68, 96], "x61": [35, 37, 53, 61, 64, 68, 96], "x62": [35, 37, 53, 61, 64, 68, 96], "x63": [35, 37, 53, 61, 64, 68, 96], "x64": [35, 37, 53, 54, 61, 64, 68, 96], "x65": [35, 37, 53, 61, 64, 68, 96], "x66": [35, 37, 53, 61, 64, 68, 96], "x67": [35, 37, 53, 61, 64, 68, 96], "x68": [35, 37, 53, 61, 64, 68, 96], "x69": [35, 37, 53, 61, 64, 68, 96], "x7": [35, 37, 53, 61, 64, 67, 68, 70, 83, 96], "x70": [35, 37, 53, 61, 64, 68, 96], "x71": [35, 37, 53, 61, 64, 68, 96], "x72": [35, 37, 53, 61, 64, 68, 96], "x73": [35, 37, 53, 61, 64, 68, 96], "x74": [35, 37, 53, 61, 64, 68, 96], "x75": [35, 37, 53, 61, 64, 68, 96], "x76": [35, 37, 53, 61, 64, 68, 96], "x77": [35, 37, 53, 61, 64, 68, 96], "x78": [35, 37, 53, 61, 64, 68, 96], "x79": [35, 37, 53, 61, 64, 68, 96], "x8": [35, 37, 53, 61, 64, 67, 68, 70, 83, 96], "x80": [35, 37, 53, 61, 64, 68, 96], "x81": [35, 37, 53, 61, 64, 68, 96], "x82": [35, 37, 53, 61, 64, 68, 96], "x83": [35, 37, 53, 61, 64, 68, 96], "x84": [35, 37, 53, 61, 64, 68, 96], "x85": [35, 37, 53, 61, 64, 68, 96], "x86": [35, 37, 53, 61, 64, 68, 96], "x87": [35, 37, 53, 61, 64, 68, 96], "x88": [35, 37, 53, 61, 64, 68, 96], "x89": [35, 37, 53, 61, 64, 68, 96], "x9": [35, 37, 53, 61, 64, 67, 68, 70, 83, 96], "x90": [35, 37, 53, 61, 64, 68, 96], "x91": [35, 37, 53, 61, 64, 68, 96], "x92": [35, 37, 53, 61, 64, 68, 96], "x93": [35, 37, 53, 61, 64, 68, 96], "x94": [35, 37, 53, 61, 64, 68, 96], "x95": [35, 37, 53, 61, 64, 68, 96], "x96": [35, 37, 53, 61, 64, 68, 96], "x96x97x98x99x100ydcluster_var_icluster_var_jz": 35, "x97": [35, 37, 53, 61, 64, 68, 96], "x98": [35, 37, 53, 61, 64, 68, 96], "x99": [35, 37, 53, 61, 64, 68, 96], "x_": [23, 24, 33, 35, 42, 47, 53, 60, 63], "x_0": [43, 44, 47, 49, 50, 51], "x_1": [10, 11, 16, 17, 18, 43, 44, 45, 47, 49, 50, 51, 58, 60, 68, 84, 86, 96], "x_1x_3": [45, 58], "x_2": [16, 17, 18, 43, 44, 45, 47, 49, 50, 51, 58, 60, 84, 86], "x_3": [16, 17, 18, 43, 44, 47, 49, 50, 51, 84, 86], "x_4": [16, 17, 18, 43, 44, 45, 49, 50, 51, 58], "x_5": [16, 17, 43, 44, 49, 50], "x_6": [43, 44, 49, 50], "x_7": [43, 44, 49, 50], "x_8": [43, 44, 49, 50], "x_9": [43, 44, 49, 50], "x_binary_control": 60, "x_binary_tr": 60, "x_col": [3, 6, 32, 35, 36, 37, 41, 48, 53, 54, 55, 57, 59, 60, 64, 67, 96, 98, 99], "x_cols_bench": 60, "x_cols_binari": 60, "x_cols_poli": 53, "x_conf": 58, "x_conf_tru": 58, "x_df": 47, "x_domain": 37, "x_i": [19, 20, 21, 22, 24, 25, 26, 33, 42, 45, 46, 49, 50, 56, 58, 61, 63, 66, 68], "x_p": [10, 11, 68, 96], "x_true": [45, 58], "x_var": 37, "xaxis_titl": [43, 44, 48, 60], "xformla": 34, "xgbclassifi": [52, 54, 56, 99], "xgboost": [33, 36, 52, 54, 56, 99], "xgbregressor": [52, 54, 56, 99], "xi": [18, 68], "xi_": [83, 93], "xi_0": [23, 35, 53], "xi_i": 61, "xiaoji": 97, "xintercept": 33, "xlab": [33, 35, 36], "xlabel": [40, 43, 44, 45, 47, 49, 50, 54, 55, 58], "xlim": [33, 36], "xtick": 40, "xval": [37, 67], "xx": 42, "y": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 89, 90, 91, 92, 93, 96, 99], "y0": [34, 40, 45, 58], "y0_cvar": 45, "y0_quant": [45, 58], "y1": [34, 45, 58], "y1_cvar": 45, "y1_quant": [45, 58], "y_": [23, 35, 46, 47, 53, 61, 68], "y_0": [4, 18, 70, 73], "y_1": [4, 18, 70, 73], "y_col": [3, 6, 32, 33, 35, 36, 37, 41, 43, 44, 48, 49, 50, 53, 54, 55, 57, 59, 62, 63, 64, 67, 68, 69, 70, 96, 98, 99], "y_df": [47, 57], "y_diff": 47, "y_i": [19, 20, 21, 22, 24, 25, 26, 33, 42, 45, 46, 56, 57, 58, 61, 63, 68], "y_pred": [2, 4, 5, 7, 8, 9, 10, 11, 12, 52, 67], "y_true": [2, 4, 5, 7, 8, 9, 10, 11, 12, 52, 67], "ya": 97, "yasui": 97, "yata": 97, "yaxis_titl": [43, 44, 48, 60], "year": 94, "yerr": [40, 47, 49, 50, 54, 56], "yet": [35, 39], "yggvpl": 53, "yintercept": 36, "ylab": [33, 35, 36], "ylabel": [40, 43, 44, 45, 47, 49, 50, 54, 55, 58], "ylim": 54, "ymax": 36, "ymin": 36, "yname": 34, "york": 97, "you": [32, 33, 41, 47, 50, 53, 59, 94, 95, 99], "your": [52, 95], "ython": 94, "yukun": 97, "yusuk": 97, "yuya": 97, "yy": 42, "z": [3, 6, 7, 9, 10, 16, 17, 18, 20, 22, 23, 26, 32, 35, 36, 41, 43, 44, 48, 53, 54, 58, 60, 61, 66, 68, 70, 75, 77, 79, 80, 83, 93, 98], "z1": [10, 68], "z2": 68, "z3": 68, "z4": 68, "z_": [23, 35, 53], "z_1": [16, 17], "z_2": [16, 17], "z_3": [16, 17], "z_4": [16, 17], "z_5": 16, "z_col": [3, 6, 7, 9, 10, 32, 35, 36, 41, 53, 54, 55, 61, 64, 66, 68, 98], "z_i": [22, 26, 58, 61, 68], "z_j": [16, 17, 18], "z_true": 58, "zadik": 97, "zaxis_titl": [43, 44, 48], "zero": [18, 45, 46, 47, 52, 57, 58, 59, 60, 83], "zeros_lik": 58, "zeta": [7, 10, 11, 36, 54, 66, 68, 96], "zeta_": [23, 35, 53], "zeta_0": [23, 35, 53], "zeta_i": [21, 22, 24, 33, 42, 63], "zeta_j": [83, 93], "zhang": 97, "zhao": [4, 5, 16, 17, 18, 34, 46, 68, 97], "zimmert": [46, 97], "zip": [43, 44], "zorder": 40, "\u03c4_x0": 56, "\u03c4_x1": 56, "\u2139": 33}, "titles": ["API reference", "doubleml.DoubleMLBLP", "doubleml.DoubleMLCVAR", "doubleml.DoubleMLClusterData", "doubleml.DoubleMLDID", "doubleml.DoubleMLDIDCS", "doubleml.DoubleMLData", "doubleml.DoubleMLIIVM", "doubleml.DoubleMLIRM", "doubleml.DoubleMLLPQ", "doubleml.DoubleMLPLIV", "doubleml.DoubleMLPLR", "doubleml.DoubleMLPQ", "doubleml.DoubleMLQTE", "doubleml.datasets.fetch_401K", "doubleml.datasets.fetch_bonus", "doubleml.datasets.make_confounded_irm_data", "doubleml.datasets.make_confounded_plr_data", "doubleml.datasets.make_did_SZ2020", "doubleml.datasets.make_heterogeneous_data", "doubleml.datasets.make_iivm_data", "doubleml.datasets.make_irm_data", "doubleml.datasets.make_pliv_CHS2015", "doubleml.datasets.make_pliv_multiway_cluster_CKMS2021", "doubleml.datasets.make_plr_CCDDHNR2018", "doubleml.datasets.make_plr_turrell2018", "doubleml.datasets.make_ssm_data", "doubleml.double_ml_score_mixins.LinearScoreMixin", "doubleml.double_ml_score_mixins.NonLinearScoreMixin", "doubleml.utils.DMLDummyClassifier", "doubleml.utils.DMLDummyRegressor", "doubleml.utils.gain_statistics", "R: Basic Instrumental Variables Calculation", "R: Basics of Double Machine Learning", "R: DoubleML for Difference-in-Differences", "R: Cluster Robust Double Machine Learning", "R: Impact of 401(k) on Financial Wealth", "R: Ensemble Learners and More with <code class=\"docutils literal notranslate\"><span class=\"pre\">mlr3pipelines</span></code>", "DML: Bonus Data", "Examples", "Python: Average Potential Outcome (APO) Models", "Python: Basic Instrumental Variables calculation", "Python: Basics of Double Machine Learning", "Python: Conditional Average Treatment Effects (CATEs) for IRM models", "Python: Conditional Average Treatment Effects (CATEs) for PLR models", "Python: Conditional Value at Risk of potential outcomes", "Python: Difference-in-Differences", "Python: Difference-in-Differences Pre-Testing", "Python: First Stage and Causal Estimation", "Python: Group Average Treatment Effects (GATEs) for IRM models", "Python: Group Average Treatment Effects (GATEs) for PLR models", "Python: GATE Sensitivity Analysis", "Python: Choice of learners", "Python: Cluster Robust Double Machine Learning", "Python: Impact of 401(k) on Financial Wealth", "Python: Impact of 401(k) on Financial Wealth (Quantile Effects)", "Python: PLM and IRM for Multiple Treatments", "Python: Policy Learning with Trees", "Python: Potential Quantiles and Quantile Treatment Effects", "Python: Sensitivity Analysis", "Example: Sensitivity Analysis for Causal ML", "Python: Sample Selection Models", "<span class=\"section-number\">6. </span>Double machine learning algorithms", "<span class=\"section-number\">1. </span>The basics of double/debiased machine learning", "<span class=\"section-number\">2. </span>The data-backend DoubleMLData", "User guide", "<span class=\"section-number\">4. </span>Heterogeneous treatment effects", "<span class=\"section-number\">7. </span>Learners, hyperparameters and hyperparameter tuning", "<span class=\"section-number\">3. </span>Models", "<span class=\"section-number\">9. </span>Sample-splitting, cross-fitting and repeated cross-fitting", "<span class=\"section-number\">5. </span>Score functions", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "<span class=\"section-number\">8. </span>Variance estimation and confidence intervals", "<span class=\"section-number\">10. </span>Sensitivity analysis", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "Confidence bands and multiplier bootstrap for valid simultaneous inference", "DoubleML", "Installing DoubleML", "Getting started", "Double machine learning literature", "Release notes", "DoubleML Workflow"], "titleterms": {"0": 99, "1": [60, 99], "2": [60, 99], "2011": 60, "2023": 60, "3": [60, 99], "4": [60, 99], "401": [36, 54, 55, 59], "5": [60, 99], "6": 99, "7": 99, "A": [35, 53], "ATE": [51, 56, 61], "No": [35, 53], "One": [35, 43, 44, 53], "The": [36, 54, 56, 63, 64, 96], "acknowledg": [34, 94], "acycl": [32, 41], "addit": 56, "advanc": [67, 83], "al": 60, "algorithm": [62, 84, 94, 96], "altern": 70, "analysi": [40, 51, 59, 60, 84, 99], "api": 0, "apo": [40, 68, 70, 84], "applic": [35, 53, 59], "approach": [33, 42, 52, 63], "arah": 60, "arbitrari": 56, "arrai": 64, "asset": [36, 54], "assumpt": 60, "att": 46, "augment": 56, "averag": [36, 40, 43, 44, 49, 50, 54, 66, 68, 70, 84], "backend": [35, 36, 53, 54, 64, 96, 99], "band": [83, 93], "base": 37, "basic": [32, 33, 41, 42, 63], "benchmark": [59, 60, 84], "bia": [33, 42, 63], "binari": [68, 70], "bonu": 38, "bootstrap": [83, 93], "build": 95, "calcul": [32, 41], "callabl": 70, "case": 39, "cate": [43, 44, 56, 66], "causal": [38, 40, 48, 60, 70, 96, 99], "chernozhukov": 60, "choic": 52, "citat": 94, "class": [0, 35, 53], "cluster": [35, 53], "code": 94, "combin": 48, "compar": 52, "comparison": 34, "comput": 52, "conclus": 60, "conda": 95, "condit": [43, 44, 45, 55, 66, 70], "confid": [83, 93], "construct": 67, "contrat": 40, "coverag": [46, 48], "cran": 95, "cross": [35, 46, 53, 68, 69, 70, 84, 96], "custom": 52, "cvar": [45, 55, 66, 70], "dag": [32, 41], "data": [0, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 68, 70, 84, 96, 99], "datafram": 64, "dataset": [0, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 38], "debias": [33, 42, 63, 96], "defin": [35, 53], "demo": 34, "detail": 34, "develop": 95, "dgp": [33, 40, 42], "did": [34, 68], "differ": [34, 46, 47, 52, 68, 70, 83, 84], "dimension": [43, 44], "direct": [32, 41], "disclaim": 60, "distribut": 61, "dml": [35, 38, 53, 69, 96, 99], "dml1": 62, "dml2": 62, "dmldummyclassifi": 29, "dmldummyregressor": 30, "doubl": [0, 33, 35, 42, 53, 62, 63, 94, 96, 97], "double_ml_score_mixin": [27, 28], "doubleml": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 41, 54, 59, 60, 83, 94, 95, 99], "doublemlblp": 1, "doublemlclusterdata": [3, 35, 53], "doublemlcvar": 2, "doublemldata": [6, 36, 54, 64, 96], "doublemldid": 4, "doublemldidc": 5, "doublemliivm": 7, "doublemlirm": 8, "doublemllpq": 9, "doublemlpliv": [10, 35, 53], "doublemlplr": 11, "doublemlpq": 12, "doublemlqt": 13, "effect": [36, 39, 43, 44, 45, 49, 50, 54, 55, 56, 58, 59, 60, 66], "elig": [36, 54], "empir": 48, "ensembl": 37, "error": [35, 53], "estim": [32, 36, 38, 41, 46, 48, 51, 54, 55, 56, 58, 59, 60, 61, 69, 70, 83, 96, 99], "et": 60, "evalu": [52, 67], "exampl": [34, 35, 39, 43, 44, 53, 59, 60], "exploit": [34, 37], "extern": [67, 69], "featur": [37, 94], "fetch_401k": 14, "fetch_bonu": 15, "figur": 56, "file": 95, "final": 34, "financi": [36, 54, 55], "first": 48, "fit": [35, 53, 69, 96], "fold": 69, "forest": 38, "formul": [60, 99], "from": [34, 37, 64, 95], "function": [0, 34, 35, 53, 70, 96], "gain_statist": 31, "gate": [49, 50, 51, 66], "gatet": 51, "gener": [0, 33, 39, 40, 42, 63, 84], "get": 96, "github": 95, "graph": [32, 41], "group": [49, 50, 66], "guid": 65, "helper": [35, 53], "heterogen": [39, 56, 66], "how": 37, "hyperparamet": 67, "identif": 60, "iivm": [36, 54, 68, 70], "impact": [36, 54, 55], "implement": [62, 70, 84], "induc": [33, 42, 63], "infer": [83, 93, 99], "initi": [35, 53], "instal": 95, "instrument": [32, 41], "integr": 34, "interact": [36, 49, 54, 57, 68, 70, 84], "interv": [83, 93], "invers": 56, "irm": [36, 38, 43, 49, 54, 56, 57, 59, 66, 68, 70, 84], "iv": [32, 36, 41, 54, 68, 70], "joint": 93, "k": [36, 54, 55, 59, 69], "lambda": 48, "lasso": [38, 48], "latest": 95, "lear": [35, 53], "learn": [0, 33, 35, 42, 53, 57, 62, 63, 66, 94, 96, 97], "learner": [37, 38, 52, 67, 96], "level": 68, "linear": [36, 50, 54, 56, 68, 70, 84], "linearscoremixin": 27, "literatur": 97, "load": [35, 38, 53, 60], "loader": 0, "local": [36, 54, 55, 58, 70], "loss": 48, "lpq": [58, 70], "lqte": [55, 58], "m": 69, "machin": [0, 33, 35, 42, 53, 62, 63, 94, 96, 97], "main": 94, "mainten": 94, "make_confounded_irm_data": 16, "make_confounded_plr_data": 17, "make_did_sz2020": 18, "make_heterogeneous_data": 19, "make_iivm_data": 20, "make_irm_data": 21, "make_pliv_chs2015": 22, "make_pliv_multiway_cluster_ckms2021": 23, "make_plr_ccddhnr2018": 24, "make_plr_turrell2018": 25, "make_ssm_data": 26, "mar": 61, "market": [35, 53], "matric": 64, "method": 99, "metric": 52, "minimum": 67, "miss": 61, "missing": [68, 70], "mixin": 0, "ml": [33, 34, 42, 60, 63, 99], "mlr3": 37, "mlr3extralearn": 37, "mlr3learner": 37, "mlr3pipelin": 37, "model": [0, 36, 38, 40, 43, 44, 49, 50, 54, 56, 57, 60, 61, 66, 68, 69, 70, 83, 84, 96, 99], "modul": [0, 38], "more": 37, "motiv": [35, 53], "multipl": [40, 56, 68], "multipli": [83, 93], "naiv": [32, 41], "net": [36, 54], "neyman": [70, 96], "nonignor": [61, 68, 70], "nonlinearscoremixin": 28, "nonrespons": [61, 68, 70], "note": 98, "nuisanc": 96, "object": [35, 53, 59], "orthogon": [33, 42, 63, 70, 96], "out": [33, 42, 63], "outcom": [40, 45, 46, 61, 66, 68, 70, 84], "over": 83, "overcom": [33, 42, 63], "overfit": [33, 42, 63], "overlap": 56, "packag": [34, 36, 54, 95], "panel": [46, 68, 70, 84], "paramet": [37, 38, 70], "partial": [33, 36, 42, 50, 54, 56, 63, 68, 70, 84], "particip": [36, 54], "partit": 69, "penalti": 48, "perform": [34, 56], "pip": 95, "pipelin": 67, "pliv": [68, 70], "plm": [56, 68, 70], "plot": [35, 53], "plr": [36, 38, 44, 50, 54, 66, 68, 70, 84], "polici": [57, 66], "potenti": [40, 45, 55, 58, 66, 68, 70, 84], "pq": [58, 66, 70], "pre": 47, "predict": [34, 67], "preprocess": 37, "problem": 99, "process": [33, 35, 40, 42, 53, 63], "product": [35, 53], "propens": 56, "provid": 69, "python": [39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 67, 95], "qte": [58, 66], "qualiti": 48, "quantil": [55, 58, 66, 70], "r": [32, 33, 34, 35, 36, 37, 39, 67, 95], "random": [38, 61, 68, 70], "rank": 56, "real": [35, 53], "refer": [0, 32, 34, 35, 37, 41, 48, 53, 56, 60, 63, 67, 69, 83, 93, 94, 96], "regress": [36, 49, 50, 54, 57, 68, 70, 84], "regular": [33, 42, 63], "releas": [95, 98], "remark": 34, "remov": [33, 42, 63], "repeat": [46, 68, 69, 70, 84], "repetit": 69, "requir": 67, "respect": [35, 53], "result": [35, 36, 53, 54, 56], "risk": [45, 55, 66, 70], "robust": [35, 53], "sampl": [33, 42, 61, 63, 68, 69, 70], "sandbox": 39, "score": [0, 33, 42, 56, 63, 70, 96], "section": [46, 68, 70, 84], "select": [61, 68, 70], "sensit": [40, 51, 59, 60, 84, 99], "set": [37, 67], "simpl": [33, 42, 63], "simul": [32, 35, 41, 46, 53, 59], "simultan": [83, 93], "singl": 40, "sourc": [94, 95], "specif": [84, 99], "specifi": [38, 67, 70], "split": [33, 42, 63, 69], "ssm": 68, "stage": 48, "standard": [35, 52, 53], "start": 96, "studi": 39, "summari": [36, 54, 56], "test": 47, "theori": 84, "time": 52, "treatment": [36, 43, 44, 45, 49, 50, 54, 55, 56, 58, 66, 68], "tree": [57, 66], "tune": [37, 67], "two": [35, 43, 44, 53], "under": [56, 61], "up": 37, "us": [32, 34, 37, 38, 41, 67], "user": 65, "util": [0, 29, 30, 31], "v": 48, "valid": [83, 93], "valu": [45, 55, 66, 70], "vanderweel": 60, "variabl": [32, 41], "varianc": 83, "version": 95, "via": 70, "wai": [35, 53], "wealth": [36, 54, 55], "weight": [56, 66], "whl": 95, "without": 69, "workflow": 99, "zero": [35, 53]}})